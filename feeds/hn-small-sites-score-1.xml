<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 13 Nov 2020 04:22:47 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 13 Nov 2020 04:22:47 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How to Write Unit Tests for Logging]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057372">thread link</a>) | @JanVanRyswyck
<br/>
November 11, 2020 | https://principal-it.eu/2020/11/unit-tests-for-logging/ | <a href="https://web.archive.org/web/*/https://principal-it.eu/2020/11/unit-tests-for-logging/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>
					<h2>
						How To Write Unit Tests For Logging
					</h2>
					<p><span>
						November 11, 2020
					</span>
				</p></div>

				
<p>Once in a while I get asked the question whether one should write <a href="https://principal-it.eu/2019/10/taxonomy-of-tests/">solitary tests</a> for 
logging functionality. My answer to this question is the typical consultant answer: “It depends”. In essence, logging 
is an infrastructure concern. The end result is log data that is being written to a resource which is external to 
an application. Usually the generated data ends up in a file, a database or it might even end up in a cloud service.</p>

<p>Because logging crosses the process boundary of an application, it is more useful to write 
<a href="https://principal-it.eu/2019/10/taxonomy-of-tests/">sociable tests</a> to verify this particular functionality. It doesn’t make sense to 
use solitary tests in this particular case.</p>

<p>That being said, there are situations where business requirements explicitly state that logging should be a part of the 
interface of an application. In this situation, the intent of logging should be expressed explicitly by the code which 
in turn should also be exercised by solitary tests. The excellent book 
<a href="https://bit.ly/tdd-goos2" target="blank" rel="noopener noreferrer nofollow">Growing Object Oriented Software 
Guided By Tests</a>, written by Steve Freeman and Nat Pryce, mentions that there are generally two separate types of 
logging:</p>

<ul>
  <li>Support logging</li>
  <li>Diagnostic logging</li>
</ul>

<p>A support log contains messages that are intended for those that perform operational activities. These messages are used 
to determine whether the system behaves correctly or not. The log level for these messages is usually of type <em>error</em> 
or <em>info</em>.</p>

<p>A diagnostic log on the other hand holds messages that are targeted towards software developers. These messages provide 
valuable insights into the details of a running system. The log level for these messages is usually of type <em>debug</em> or 
<em>trace</em>.</p>

<p>Given these two types of logging, the basic idea is that code which expresses the intent of support logging should be 
exercised by solitary tests. Code statements that initiate diagnostic logging are usually not covered by tests.</p>

<p>Let’s have a look at an example that demonstrates both support and diagnostic logging in action.</p>

<pre><code>public class ExpenseSheetController : Controller
{
    private readonly ICommandHandler&lt;CreateExpenseSheet&gt; _commandHandler;
    private readonly ISupportNotifier _supportNotifier;

    public ExpenseSheetController(ICommandHandler&lt;CreateExpenseSheet&gt; commandHandler,
                                  ISupportNotifier supportNotifier)
    {
        _commandHandler = commandHandler;
        _supportNotifier = supportNotifier;
    }
    
    [HttpPost]
    [ServiceFilter(typeof(PerformanceTracing))]
    public IActionResult Create(CreateExpenseSheetFormModel formModel)
    {
        try
        {
            var command = new CreateExpenseSheet(Guid.NewGuid(), formModel.EmployeeId);
            _commandHandler.Handle(command);
        }
        catch(Exception ex)
        {
            _supportNotifier.ErrorDuringExpenseSheetCreation(ex, formModel.EmployeeId);
            return BadRequest();
        }
        
        _supportNotifier.ExpenseSheetCreated(formModel.EmployeeId);
        return Ok();
    }
}
</code></pre>

<p>Here we have the implementation of a controller that can receive a request for creating a new expense sheet. Notice that 
the constructor of this controller class expects an instance of the <em>ISupportNotifier</em> interface. This dependency is 
being used by the implementation of the <em>Create</em> method for logging an error when an exception occurs. It is also used 
for logging when an expense sheet has been successfully created.</p>

<p>This is how the implementation of the <em>SupportNotifier</em> looks like.</p>

<pre><code>public class SupportNotifier : ISupportNotifier
{
    private readonly ILogger&lt;SupportNotifier&gt; _logger;

    public SupportNotifier(ILogger&lt;SupportNotifier&gt; logger)
    {
        _logger = logger;
    }
    
    public void ExpenseSheetCreated(Guid employeeId)
    {
        _logger.LogInformation("Expense sheet created for employee with ID '{employeeId}'.");
    }

    public void ErrorDuringExpenseSheetCreation(Exception ex, Guid employeeId)
    {
        _logger.LogError(ex, $"Unable to create a new expense sheet for employee with ID '{employeeId}'");
    }
}
</code></pre>

<p>This code demonstrates that support logging uses log levels <em>error</em> or <em>info</em> depending on the context. Verifying the
code of the <em>SupportNotifier</em> class itself can be done by using sociable tests. It’s not a good idea to write
solitary tests for the <em>SupportNotifier</em> class. This would imply that a test double should be used as an instance of 
<em>ILogger</em>. As we already touched on in a <a href="https://principal-it.eu/2020/05/test-double-heuristics/">previous blog post</a>, it’s much better to 
avoid using test doubles for types that you don’t own. In this particular case it would even be quite hard to do as 
the <em>Logxx</em> methods of <em>ILogger</em> are actually extension methods and not regular methods.</p>

<p>Let’s have a look at the tests for the <em>ExpenseSheetController</em>.</p>

<pre><code>[Specification]
public class When_handling_a_request_for_creating_a_new_expense_sheet
{
    [Establish]
    public void Context()
    {
        var commandHandler = Substitute.For&lt;ICommandHandler&lt;CreateExpenseSheet&gt;&gt;();
        _supportNotifier = Substitute.For&lt;ISupportNotifier&gt;();

        _sut = new ExpenseSheetController(commandHandler, _supportNotifier);
    }

    [Because]
    public void Of()
    {
        var formModel = new CreateExpenseSheetFormModel 
        { 
            EmployeeId = new Guid("94EDE8F3-9675-4DD7-A18F-E37B1F323699") 
        };

        _sut.Create(formModel);
    }
    
    [Observation]
    public void Then_it_should_notify_support()
    {
        _supportNotifier.Received()
            .ExpenseSheetCreated(new Guid("94EDE8F3-9675-4DD7-A18F-E37B1F323699"));
    }

    private ExpenseSheetController _sut;
    private ISupportNotifier _supportNotifier;
}

[Specification]
public class When_an_error_occurs_while_handling_a_request_for_creating_a_new_expense_sheet
{
    [Establish]
    public void Context()
    {
        _supportNotifier = Substitute.For&lt;ISupportNotifier&gt;();
        _exception = new InvalidOperationException("Meltdown");
        
        var commandHandler = Substitute.For&lt;ICommandHandler&lt;CreateExpenseSheet&gt;&gt;();
        commandHandler.WhenForAnyArgs(ch =&gt; ch.Handle(null))
            .Throw(_exception);
        
        _sut = new ExpenseSheetController(commandHandler, _supportNotifier);
    }
    
    [Because]
    public void Of()
    {
        var formModel = new CreateExpenseSheetFormModel 
        { 
            EmployeeId = new Guid("D1067157-5C73-4140-9D29-0FE5C1C4C2FB") 
        };

        _sut.Create(formModel);
    }
    
    [Observation]
    public void Then_it_should_notify_support_that_a_new_expense_sheet_has_been_created()
    {
        _supportNotifier.Received()
            .ErrorDuringExpenseSheetCreation(_exception, 
                new Guid("D1067157-5C73-4140-9D29-0FE5C1C4C2FB"));
    }
    
    private ExpenseSheetController _sut;
    private ISupportNotifier _supportNotifier;
    private Exception _exception;
}
</code></pre>

<p>These tests verify whether support logging occurs when an expense sheet has been created or when an exception gets 
raised. This way we express the intent of the operational requirements.</p>

<p>Notice that controller method has been decorated with a <em>ServiceFilter</em> attribute.</p>

<pre><code>[HttpPost]
[ServiceFilter(typeof(PerformanceTracing))]
public IActionResult Create(CreateExpenseSheetFormModel formModel)
{
    ...
}
</code></pre>

<p>By applying this attribute, the <em>PerformanceTracing</em> action filter is being registered to surround the execution of the 
controller method. Let’s have a look at the implementation of this action filter.</p>

<pre><code>public class PerformanceTracing : ActionFilterAttribute
{
    private readonly ILogger&lt;PerformanceTracing&gt; _logger;
    private readonly Stopwatch _stopWatch;

    public PerformanceTracing(ILogger&lt;PerformanceTracing&gt; logger)
    {
        _logger = logger;
        _stopWatch = new Stopwatch();
    }

    public override void OnActionExecuting(ActionExecutingContext context)
    {
        _stopWatch.Start();
    }

    public override void OnActionExecuted(ActionExecutedContext context)
    {
        _stopWatch.Stop();

        var controllerName = context.Controller.GetType().Name;
        var controllerActionName = context.ActionDescriptor.DisplayName;
        
        _logger.LogTrace($"Action '{controllerActionName}' of controller {controllerName} executed in " + 
            $"{_stopWatch.ElapsedMilliseconds} ms.");
    }
}
</code></pre>

<p>This implementation is a nice example of diagnostic logging. The action filter measures the execution time of a 
controller method and logs the result. Notice that we’re injecting the <em>ILogger</em> interface directly into the constructor.
By registering the <em>PerformanceTracing</em> action filter using the <em>ServiceFilter</em> attribute, we ensure that an instance 
of <em>ILogger</em> gets resolved and properly injected. We didn’t provide any tests for this implementation.</p>

<p>I think it’s useful to consider support logging and diagnostic logging as two separate concepts, even though they quite 
often use the same mechanisms under the hood.</p>


				<p>
						<em>
							If you and your team want to learn more about how to <u>write maintainable unit tests</u>
							and <u>get the most out of TDD practices</u>, make sure to have look at our
							<a href="https://principal-it.eu/training.html">trainings and workshops</a> or checkout
							the <a href="https://principal-it.eu/books.html">books section</a>. Feel free to reach
							out at <span>info@principal-it.be</span>.
						</em>
					</p>

				

				

				
			</div></div>]]>
            </description>
            <link>https://principal-it.eu/2020/11/unit-tests-for-logging/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057372</guid>
            <pubDate>Wed, 11 Nov 2020 11:06:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revolutionize your support with Chat Bot]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057330">thread link</a>) | @eugen_2pay
<br/>
November 11, 2020 | https://tap2pay.me/revolutionize-support-chat-bot/ | <a href="https://web.archive.org/web/*/https://tap2pay.me/revolutionize-support-chat-bot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p>Robots are taking over our daily routine in every aspect of our life: from paying bank bills to cleaning the house. It does not mean that within a year you will be leaving in a Matrix, but modern robots will for sure simplify your life in many ways.</p>

<p>Automation is everything. Chat support on smartphone saves our time and energy for more important things.</p>

<p>According to a survey, <strong>over 80% of customer problems will be solved with the help of chatbots.</strong></p>

<p>What kind of customers can really use the help of live support?</p>

<h4>Here are the Top 5 Business Areas that benefit from ChatBot support:</h4>

<p><strong>Banks</strong></p>
<p>• prompting nearest branch locations, self-service terminals<br>
• sending information about available credit programs and its terms<br>
• helping to choose the necessary type of deposit<br>
• accepting the request for required documents</p>

<p><strong>Events selling agencies</strong></p>
<p>• registering of new clients<br>
• answering basic queries about cost, time, and location<br>
• performing support functions<br>
• booking tickets online</p>

<p><strong>Online Stores</strong></p>
<p>• registering new customers<br>
• processing order placements<br>
• processing payments for products<br>
• conducting marketing surveys</p>

<p><strong>Mobile operators</strong></p>
<p>• onboarding of new users<br>
• processing payments<br>
• answering basic queries about cost, time, and location</p>

<p><iframe width="1140" height="641" src="https://www.youtube.com/embed/yCcQpyYSvks?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<p><strong>Providers of Education services</strong></p>
<p>• processing payments<br>
• helping to choose an educational program<br>
• accepting requests for required programs</p>

<p><img src="https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture.jpg" alt="" width="700" height="393" srcset="https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture.jpg 700w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-300x168.jpg 300w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-71x40.jpg 71w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-255x143.jpg 255w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-142x80.jpg 142w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-360x202.jpg 360w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-500x281.jpg 500w, https://tap2pay.me/wp-content/uploads/2020/11/chat-bot-picture-600x337.jpg 600w" sizes="(max-width: 700px) 100vw, 700px"></p>

<p><a href="https://secure.tap2pay.me/users/signup">Tap2Pay</a> strives for excellence in every aspect of creating smooth and friendly chat support on smartphones.</p>
<p>We have developed stunning software for effortless payment processing via the most well-known social media messengers Facebook, Instagram, Telegram, WhatsApp with built-in chatbot client support.</p>

<p><iframe width="1140" height="641" src="https://www.youtube.com/embed/jJxIfNR99Do?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<p>If you need any assistance with updating your payment processing method with built-in chat support, please <a href="https://tap2pay.me/contacts/">connect with our Customer Support Team.</a></p>
	
                </div></div>]]>
            </description>
            <link>https://tap2pay.me/revolutionize-support-chat-bot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057330</guid>
            <pubDate>Wed, 11 Nov 2020 10:58:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Telegram Bot with Azure Functions and Node.js]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057328">thread link</a>) | @qpbp_user
<br/>
November 11, 2020 | http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/ | <a href="https://web.archive.org/web/*/http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><ul><li><a href="#introduction">Introduction</a></li><li><a href="#flow-review">Flow Review</a></li><li><a href="#prerequisites">Prerequisites</a></li><li><a href="#create-an-azure-function-in-visual-studio-code">Create an Azure function in Visual Studio Code</a></li><li><a href="#folder-structure">Folder structure</a></li><li><a href="#run-function-locally">Run function locally</a></li><li><a href="#implement-the-bot">Implement the bot</a></li><li><a href="#running-bot-locally">Running bot locally</a></li><li><a href="#deploy-azure-function-to-the-portal">Deploy Azure Function to the portal</a></li><li><a href="#conclusion">Conclusion</a></li></ul><h2 id="introduction">Introduction</h2><p>In this tutorial, we will create an Azure Function with a simple Telegram Bot (Echo Bot). We will test it locally and then deploy it to Azure Portal. It means our bot will work only at the moment when someone is using it. So the function will be triggered only when someone is sending a message to a bot.</p><h2 id="flow-review">Flow Review</h2><ol><li>The user sends any message to Telegram Bot</li><li>Telegram sends requests via Webhook to our Azure Function</li><li>Azure Function replies to Webhook with a copied message</li></ol><h2 id="prerequisites">Prerequisites</h2><ul><li>node.js - v10.16.2</li><li>npm - v6.14.5</li><li>telegraf - v3.38.0</li><li>ngrok - v2.3.35</li><li>Azure subscribtion</li><li>you need to install <a href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azurefunctions">Azure Functions extension</a> to Visual Studio Code</li></ul><h2 id="create-an-azure-function-in-visual-studio-code">Create an Azure function in Visual Studio Code</h2><ol><li><p>click on Azure Icon in Visual Studio Code</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.48.39-1024x885.png" alt="Azure Icon in VSC"></p></li><li><p>login under your Azure subscription</p></li><li><p>click on “Create Function Icon”</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.51.16.png" alt="Create Function Icon"></p></li><li><p>you will be asked to use an existing project or create a new. Let’s create a new:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.54.40-1024x281.png" alt="Create a new project"></p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.55.13-1024x589.png" alt="Create new project folder"></p></li><li><p>select the function template. We will use <strong>HTTP trigger</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.55.36-1024x607.png" alt="Choose a Function Template"></p></li><li><p>provide a function name and select Enter:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.16-1024x213.png" alt="Enter the name of the function"></p></li><li><p>please provide a <strong>Function</strong> key for a <strong>Function authorization</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.27-1024x280.png" alt="Function Authorization level"></p></li><li><p>penultimate step. Select how you would like to open a project. We will use the current window:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.39-1024x291.png" alt="How to open a function project in Visual Studio Code"></p></li><li><p>you will be redirected to the <strong>default HTTP trigger function with Javascript code</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.57.02-1024x618.png" alt="The default function Code"></p></li><li><p>now this function will appear in Azure Functions section:</p></li></ol><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-11.23.30-1024x340.png" alt="Newly created function"></p><h2 id="folder-structure">Folder structure</h2><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-11.29.34-300x256.png" alt="Function Folder Structure"></p><ul><li><strong>package.json</strong> - metadata relevant to the Node.js project</li><li><strong>proxies.json</strong> - you can modify requests and responses from function</li><li><strong>host.json</strong> - metadata file relevant to the Azure project. It’s a global configuration for all functions in an application</li><li><strong>azure-bot-cloud-function</strong> - it’s our function folder. Each function has a separate folder with code file (.js in our case) and function.json. Function.json it’s a <a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-expressions-patterns">binding configuration file</a>.</li></ul><h2 id="run-function-locally">Run function locally</h2><ol><li><p>Select Run -&gt; Start Debugging in Visual Studio Code menu</p></li><li><p>If you have no Azure Functions Core Tools locally, you need to install them on this step. The instruction can be found in <a href="https://github.com/Azure/azure-functions-core-tools#installing">Azure repo:</a></p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-20.48.48-1024x127.png" alt="Install Azure Function Core Tools"></p></li><li><p>You should see how the NPM tasks will executing and finally get a link to the working function:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-21.08.28-1024x601.png" alt="Link to the local Azure function"></p></li><li><p>Let’s open our function in the browser:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-21.20.46-1024x274.png" alt="Azure Function is working locally"></p><p>As you see, the function responds to us with the behavior by default. Also, you can simply run the function using the <strong>func start</strong> command.</p></li></ol><h2 id="implement-the-bot">Implement the bot</h2><p>For work with Telegram API, we will use the most popular library for Node.js - <a href="https://github.com/telegraf/telegraf">Telegraf.js</a>. We need to install it in the project folder:</p><div><pre><code data-lang="bash">npm install telegraf --save
</code></pre></div><p>Please make sure the <code>package.json</code> has Telegraf after the running previous command.</p><p>Because Telegram will send webhook requests to our bot, we need to make an external HTTPS URL. For this purpose we can use <a href="https://ngrok.com/">ngrok library</a>:</p><p>If all is good, we can go to <code>function-folder&gt;/index.js</code> and create a simple Echo-bot:</p><div><pre><code data-lang="javascript"><span>const</span> <span>Telegraf</span> <span>=</span> <span>require</span>(<span>'telegraf'</span>)
<span>const</span> { <span>TELEGRAM_BOT_TOKEN</span>, <span>WEBHOOK_ADDRESS</span> } <span>=</span> <span>process</span>.<span>env</span>

<span>const</span> <span>bot</span> <span>=</span> <span>new</span> <span>Telegraf</span>(<span>TELEGRAM_BOT_TOKEN</span>, {<span>telegram</span><span>:</span> { <span>webhookReply</span><span>:</span> <span>true</span> }})

<span>bot</span>.<span>telegram</span>.<span>setWebhook</span>(<span>WEBHOOK_ADDRESS</span>)
<span>bot</span>.<span>on</span>(<span>'message'</span>, (<span>ctx</span>) =&gt; <span>ctx</span>.<span>telegram</span>.<span>sendCopy</span>(<span>ctx</span>.<span>chat</span>.<span>id</span>, <span>ctx</span>.<span>message</span>))

<span>module</span>.<span>exports</span> <span>=</span> <span>async</span> <span>function</span> (<span>context</span>, <span>req</span>) {
	<span>return</span> <span>bot</span>.<span>handleUpdate</span>(<span>req</span>.<span>body</span>, <span>context</span>.<span>res</span>)
}
</code></pre></div><p>You can take <code>TELEGRAM_BOT_TOKEN</code> value from <a href="https://telegram.me/BotFather">BotFather bot</a>. The <code>WEBHOOK_ADDRESS</code> will contain a link to the Azure Function. We will talk about this variable later. Our bot will work in Webhook mode - it’s a more preferable way to run Telegram bot. The Telegram will automatically inform our bot about all updates. In the polling mechanism, our bot needs to frequently ask Telegram about updates, so it requires non-stop work for our bot (most cases).</p><h2 id="running-bot-locally">Running bot locally</h2><p>To run this bot locally we need to create a public address using ngrok. By default, the local Azure function is running on port <code>7071</code>. We can use the following combination in the terminal to create a public URL:</p><p>In the terminal you will get your HTTPS link for testing Webhook:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.29.42-1024x400.png" alt="HTTPS public URL using ngrok"></p><p>Copy the ngrok-created link and add the route to the function. Something similar to this:</p><div><pre><code data-lang="javascript"><span>bot</span>.<span>telegram</span>.<span>setWebhook</span>(<span>'https://&lt;random-value&gt;.ngrok.io/api/azure-bot-cloud-function'</span>)
</code></pre></div><p>Also, don’t forget to pass a real Telegram token to the Telegraf constructor:</p><div><pre><code data-lang="javascript"><span>const</span> <span>bot</span> <span>=</span> <span>new</span> <span>Telegraf</span>(<span>'some-token-value'</span>, {
	<span>telegram</span><span>:</span> { <span>webhookReply</span><span>:</span> <span>true</span> },
})
</code></pre></div><p>It’s very dirty, but for a quick test it’s OK, so please remember to remove all real keys from the code.</p><p>Then you can run a function just using the simple command:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.49.14-1024x709.png" alt="Azure Functions is running locally"></p><p>Good job! Now open your bot in Telegram and send any message. Our bot should copy it and resend to you:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.41.16.png" alt="Echo-Bot example"></p><h2 id="deploy-azure-function-to-the-portal">Deploy Azure Function to the portal</h2><p>To deploy Azure Function we just need to click on this button:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.52.40-1024x730.png" alt="Deploy Azure Function"></p><p>Then choose your resource and press “Deploy”. The process will be started:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.53.55-1024x406.png" alt="The process of deploying Azure Function"></p><p>After successful deployment, we need to go to Azure Portal and update <strong>WEBHOOK_ADDRESS</strong> and <strong>TELEGRAM_BOT_TOKEN</strong> variables with real values.</p><p>To get a real function URL, go to “Functions”, then choose your Azure Function and press “Get Function Url” button:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.05.24-1024x275.png" alt="How to get Azure Function URL"></p><p>We need to copy this value and paste to Application Settings along with Telegram Token:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.59.12-1024x343.png" alt="Application Settings in Azure"></p><p>After adding our secret keys, press “Save” and restart our application:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.09.41-1024x424.png" alt="Restart Azure application"></p><p>That’s all. Our bot should work in the cloud and you can track all function executions in real-time:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.13.07-1024x325.png" alt="Azure Dashboard"></p><p>Each function execution means that our bot handled 1 single message.</p><h2 id="conclusion">Conclusion</h2><p>In this tutorial, we have created an Azure Function with a simple Echo-Bot for Telegram. Azure Functions its a cool way to host your bots. You will be chargeable by the simple formula - (Memory size)X(Execution time in ms)X(Executions per month) and also remember that the first 400,000 GB/s of execution and 1,000,000 executions are free. If you need to estimate your pricing costs you can use <a href="https://azure.microsoft.com/en-us/pricing/calculator/">this pricing calculator</a>.</p><p>P.s. don’t forget to delete/clean/stop all resources.</p><p><a href="https://disqus.com/">comments powered by </a></p></div></div></section></div>]]>
            </description>
            <link>http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057328</guid>
            <pubDate>Wed, 11 Nov 2020 10:57:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging the Kernel with QEMU]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057309">thread link</a>) | @__rompy
<br/>
November 11, 2020 | https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html | <a href="https://web.archive.org/web/*/https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4480419177723293408">
<p>Hi folks, in this post I'm going to walk through how to setup the linux kernel for debugging. I will also demonstrate that the setup works by setting a break-point to a test driver I wrote myself. All the code will be available from my gitlab, all the links to my gitlab will be re-posted at the end.&nbsp;</p><p>The setup I describe here re-uses some parts of the syzkaller setup, and for good reason later on in the post series I will break into a tutorial for the syzkaller tool as well. So lets get on with it.</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-u2vPJD5mvfQ/X6v9Jig2QOI/AAAAAAAAQFA/AeLKhrX1BXM8HY7pN694qJFyvWDilFojACLcBGAsYHQ/s1109/Screenshot%2Bfrom%2B2020-11-11%2B17-00-44.png" imageanchor="1"><img data-original-height="625" data-original-width="1109" height="360" src="https://1.bp.blogspot.com/-u2vPJD5mvfQ/X6v9Jig2QOI/AAAAAAAAQFA/AeLKhrX1BXM8HY7pN694qJFyvWDilFojACLcBGAsYHQ/w640-h360/Screenshot%2Bfrom%2B2020-11-11%2B17-00-44.png" width="640"></a></td></tr><tr><td>Screenshot of a successful debug session with full debug symbols for the kernel! We can even see the call to start_kernel and a frame before that as well!<br></td></tr></tbody></table><br>&nbsp;<h2>The Process</h2><p>Okay so we want to study kernel exploitation but given that the kernel isn't something totally accessible in userspace, its not as convenient to debug as userpace stuff, we need a bit of a run up before we can actually poke and prod the kernel to figure out how to write our exploits. So there's a number of important steps to how we get this done, here's what we're going to do:</p><ol><li>Build a kernel</li><li>Build an image</li><li>Launch the virtual machine&nbsp;</li><li>Attach and setup the debugger</li><li>Building, loading and debugging a test module <br></li></ol><p>We also need to be able to build our kernel because there may be build options that are important to configure in order to control exploit protection or include modules and functionality to the kernel when needed. <br></p><h2>Building a Kernel</h2><p>Okay so before we get going with launching our Qemu instances and debugging modules we need an environment. For convenience sake I'm working off of a fresh Ubuntu 18.04.5 LTS machine. I'll document the processes from fresh install to first successful kernel build.</p><p>To start we need to make sure we have everything we need to build a kernel:</p><p><span>$<b>sudo apt-get update</b></span></p><p><span>$<b>sudo apt-get upgrade </b><br></span></p><p><span>$<b>sudo apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison qemu-system-x86</b></span></p><p>Next we obviously need a kernel so lets download a brand new kernel:</p><p><span>$<b>wget https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.9.7.tar.xz</b><br>--2020-11-10 23:00:26--&nbsp; https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.9.7.tar.xz<br>Resolving cdn.kernel.org (cdn.kernel.org)... 151.101.225.176, 2a04:4e42:35::432<br>Connecting to cdn.kernel.org (cdn.kernel.org)|151.101.225.176|:443... connected.<br>HTTP request sent, awaiting response... 200 OK<br>Length: 115538096 (110M) [application/x-xz]<br>Saving to: ‘linux-5.9.7.tar.xz’<p>linux-5.9.7.tar.xz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 42%[=============&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]&nbsp; 46.79M&nbsp; 3.08MB/s&nbsp;&nbsp;&nbsp; eta 23s&nbsp;&nbsp; &nbsp;</p></span></p><p><span>... <br></span></p><p><span>$<b>tar -xf linux-5.9.7.tar.xz</b></span></p><p>We're just a couple steps from sending the final build commands, before we get to that lets make sure the kernel config is ready to rock. Because we're working on a Linux host we can simply swipe the .config for the virtual machine's Ubuntu kernel like so:</p><p><span>$<b>cp /boot/config-5.4.0-52-generic .config</b></span></p><p>We then need to select some options that make debugging and exploit dev a little easier. First thing we need is to merge some options for making the kernel easier to run in a virtual machine:</p><p><span>$<b>make kvmconfig</b></span></p><p><span>Using .config as base<br>Merging ./kernel/configs/kvm_guest.config<br>#<br># merged configuration written to .config (needs make)<br>#</span></p><p><span>...</span></p><p>Great, now we need to enable some options for debug symbols, kaslr and other awesome things. So open the <span>.config</span> somewhere in a text editor and make sure you either add or modify the file so these options are set:</p><p><span>CONFIG_KCOV=y<br>CONFIG_DEBUG_INFO=y<br>CONFIG_KASAN=y<br>CONFIG_KASAN_INLINE=y<br>CONFIG_CONFIGFS_FS=y<br>CONFIG_SECURITYFS=y </span><br><span><span># CONFIG_RANDOMIZE_BASE is not set<br></span></span></p><p>Cool now we need to make sure the config is ready to go for a build:</p><p><span>$<b>make savedefconfig</b></span></p><p><span>$<b>make -j4</b></span></p><p><span>&nbsp;...</span></p><p>Now you should grab some coffee, play a startcraft2 game because this may take a while. Okay so if your build worked you should have an object file in the following location:</p><p><span>[kernel_dir]/arch/x86_64/boot/bzImage</span>&nbsp;</p><h2>Build an image</h2><p>We're going to build an image for this kernel so we might as well plop a "image" directory in this folder:</p><p><span>$<b>mkdir [kernel_dir]/image/</b></span></p><p>Once you're kernel is build we need to start thinking about how to build a file system for this. Here I'm going to cheat and steal some tips from the syzkaller folks. We need to first download syzkaller, as follows:</p><p><span>$<b>git clone https://github.com/google/syzkaller.git</b></span></p><p><span>Cloning into 'syzkaller'...<br>remote: Enumerating objects: 1, done.<br>remote: Counting objects: 100% (1/1), done.<br>...<br></span></p><p>Move back to the kernel build and setup an image:</p><p><span>$<b>cd [kernel_dir]/image/</b></span></p><p><span>$<b>cp [syzkaller_dir]/tools/create_image.sh .</b></span></p><p>Okay so we can now create an image, all we need to do is simply invoke create_image.sh:</p><p><span>$<b>./create_image.sh&nbsp;</b></span></p><p><span>+ DIR=chroot<br>+ PREINSTALL_PKGS=openssh-server,curl,tar,gcc,libc6-dev,time,strace,sudo,less,psmisc,selinux-utils,policycoreutils,checkpolicy,selinux-policy-default,firmware-atheros,python,xrdp,g++,make,libtool,autoconf,nasm<br>+ '[' -z ']'<br>+ ADD_PACKAGE=make,sysbench,git,vim,tmux,usbutils,tcpdump</span></p><p><span>...</span><br></p><p>If that worked you should have the following in your folder:</p><p><span>$<b>ls</b>&nbsp;</span></p><p><span>chroot/</span></p><p><span>create-image.sh</span></p><p><span>stretch.id_rsa</span></p><p><span>stretch.id_rsa.pub</span></p><p><span>stretch.img</span><br></p><h2>Launch the virtual machine <br></h2><p>Now we can launch qemu with all the goodies in place:</p><p><span>qemu-system-x86_64 \<br>&nbsp; -kernel <b>../arch/boot/x86_64/bzImage</b> \<br>&nbsp; -append "console=ttyS0 root=/dev/sda earlyprintk=serial nokaslr"\<br>&nbsp; -hda <b>./stretch.img</b> \<br>&nbsp; -net user,hostfwd=tcp::10021-:22 -net nic \<br>&nbsp; -enable-kvm \<br>&nbsp; -nographic \<br>&nbsp; -m 2G \<br>&nbsp; -s \<br>&nbsp; -S \<br>&nbsp; -smp 2 \<br>&nbsp; -pidfile vm.pid \<br>&nbsp; 2&gt;&amp;1 | tee vm.log</span></p><p><span>...</span></p><p><br>The <span>-s</span> is a shorthand for <span>-gdb tcp::1234</span>, which means the gdbserver will be hosted at port 1234. -S tells qemu not to start the cpu automatically, this gives us a chance to set a breakpoint before the kernel starts executing. </p><p>So that's the image running smoothly, lets setup our debugging environment.</p><h2>Attach and setup the debugger<br></h2><p>We can then attach a gdb debugger to the qemu instance as follows. On another terminal, separate from the one running your qemu instance, start up gdb and issue the following commands:</p><p><span>$<b>cd [kernel_dir]/image/ </b><br></span></p><p><span>$<b>gdb ../vmlinux<br></b></span></p><p><span>Reading symbols from ../vmlinux...</span></p><p><span>(gdb)<b> target remote :1234<br></b></span></p><p><span>Remote debugging using :1234<br>0x000000000000fff0 in exception_stacks ()<br></span></p><p><span>(gdb) <b>c</b></span></p><p>We give the "c" command to continue execution. We can now set some of our own breakpoints. As part of the tutorial I've included a custom IOCTL driver and app code (code that invokes the ioctl from userspace), i thought this would be nifty since it shows full ability to develope and debug a driver, something crucial to hunting down modern bugs and exploit development. Anyway lets code and build our own module.</p><h2>Building, Loading and debugging a test module<br></h2><p>Okay so we need to make a test ioctl driver, so lets head over the to kernel source directory and make a new folder in the /driver/ subfolder:</p><p><span>$</span><b><span>cd&nbsp; [kernel_dir]/drivers/</span></b></p><p><span>$</span><b><span>mkdir debug_driver/</span></b></p><p><span>$</span><b><span>cd debug_driver/ <br></span></b></p><p><span>$</span><b><span>touch debug_driver.c</span></b></p><p><span>$</span><b><span>touch debug_driver_app.c</span></b></p><p><span>$</span><b><span>touch Makefile</span></b></p><p>The code for <span>debug_driver.c</span> and <span>debug_driver_app.c </span>as we well as the <span>Makefile</span> are available at this repo <a href="https://gitlab.com/k3170makan/linux-kernel-exploit-development">https://gitlab.com/k3170makan/linux-kernel-exploit-development</a>. All you need to do is download the repo and stick this in its own folder under <span>[kernel_dir]/drivers/</span>. To build the module the we need to set the "M" variable in the kernel make script:</p><p><span>$<b>cd [kernel_dir]; make -C . M=drivers/debug_driver/</b></span></p><p><span>make: Entering directory '/home/kh3m/Research/Kernel/debug_image/linux-5.5.3'<br>&nbsp; AR&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; drivers/debug_driver//built-in.a<br>&nbsp; CC [M]&nbsp; drivers/debug_driver//debug_driver.o</span></p><p><span>...</span></p><p>Now we need to get this module on our qemu host somehow, I do this the hard way, I'm sure there's all sorts of nifty ways to scp files onto the qemu host but I actually just re-create the image after copying the drivers to a folder to be baked into the start up filesystem. First we need to edit create-image.sh so it includes everything in a folder we specify, that way we can just dump stuff in the folder and run create-image.sh whenever we want those files on a live instance.</p><p>So before create-image.sh builds the disk image on line 129, stick this in there:</p><p>++ <span>sudo cp -r ./add/* $DIR/home/.</span><br></p><p>now we make a "add" folder and stick the kernel module and app code in there:</p><p><span>$<b> cd [kernel_dir]/image/</b></span></p><p><span>$ <b>mkdir add/</b></span></p><p><span>$ <b>cd add/</b></span></p><p><span>$ <b>cp ../../drivers/debug_driver/debug_driver.ko .</b><br></span></p><p><span>$ <b>cp ../../drivers/debug_driver/debug_driver_app.c .</b></span></p><p><span>$ <b>./create-image.sh</b> </span></p><p>Okay so we have a module, we have a symbol file debug_driver.ko, with stuff we need to set breakpoints. Lets load the module into the kernel, then check where it gets loaded before we actually set the breakpoint:</p><p><span>root@syzkaller:$ <b>cd /home/</b></span></p><p><span>root@syzkaller:$ insmod debug_driver.ko</span></p><p><span> [&nbsp;&nbsp; 32.792570] audit: type=1400 audit(1605058227.605:7): avc:&nbsp; denied&nbsp; { module_load } for&nbsp; pid=249 comm="insmod" path="/home/debug_driver.ko" dev="sda" ino=21253 scontext=system_u:system_r:kernel_t:s0 1<br>[&nbsp;&nbsp; 32.793766] debug_driver: loading out-of-tree module taints kernel.<br>[&nbsp;&nbsp; 32.800394] [debug_driver] loaded! <br>[&nbsp;&nbsp; 32.800826] [debug_driver] device registered successfully<br>[&nbsp;&nbsp; 32.802298] [debug_driver] device has been successfully created <b><br></b></span></p><p>Before we can debug it properly we need to know where it is loaded in kernel memory:</p><p><span>root@syzkaller:/home# <b>cat /proc/modules</b> <br>debug_driver 16384 0 - Live <b>0xffffffffa0000000</b> (O)</span></p><p>Okay lets now set our breakpoint and load the symbol file using the base address of the module:</p><div><p><span>&nbsp;(gdb) <b>add-symbol-file ../drivers/debug_driver/debug_driver.ko&nbsp; 0xffffffffa0000000</b><br>add symbol table from file "../drivers/debug_driver/debug_driver.ko" at<br>&nbsp;&nbsp; &nbsp;.text_addr = 0xffffffffa0000000<br>(y or n) <b>y</b><br>Reading symbols from ../drivers/debug_driver/debug_driver.ko...<br>(gdb) <b>break dev_read</b><br>Breakpoint 1 at <b>0xffffffffa0000010: file drivers/debug_driver//debug_driver.c</b>, line 81.<br>(gdb) c</span></p></div><p>Cool lets execute the driver program so we can trigger the code we want:</p><p><span>root@syzkaller:$ <b>gcc -o debug_driver_app.elf debug_driver_app.c<br></b></span></p><p><span><span>root@syzkaller:/home# <b>./debug_driver_app.elf </b><br>Usage: ./debug_driver_app.elf [message to write] [read length] <br></span></span></p><p><span><span>root@syzkaller:</span>$ <b>./debug_driver_app.elf "hello" 10</b></span></p><p><span>[&nbsp; 160.083320] [debug_driver] message successfully copied message =&gt; [hello]<br>[&nbsp; 160.083326] [debug_driver] buffer copied to message holder<br>[debug_driv…</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html">https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html</a></em></p>]]>
            </description>
            <link>https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057309</guid>
            <pubDate>Wed, 11 Nov 2020 10:53:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why electronic voting is dangerous]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057302">thread link</a>) | @ian_starts
<br/>
November 11, 2020 | https://blog.iankok.com/risk-electronic-voting | <a href="https://web.archive.org/web/*/https://blog.iankok.com/risk-electronic-voting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>With the 2020 US elections having mail in ballots,
I found myself wondering if a digital solution would be safer, more reliable and easier. As usual the answer isn't straightforward. </p>
<p>In this post I'll talk you through some possible solutions and their potential downsides.</p>
<p>I will mostly focus on Dutch elections, seeing as I can provide the best insights, and most arguments are easily
transferable to other nations.</p>
<h2>Requirements</h2>
<p>If we would develop a voting system from scratch it would need to have some features that protect our rights and make
sure the elected ruler is the one the people really wanted (questionable if that's the case with current electoral systems, but that's for another time).</p>
<ol>
<li><strong>Accuracy</strong> - are all the votes counted, do they represent the will o' the people?</li>
<li><strong>Anonymity</strong> - very difficult this one. We don't want the votes to be signed, that would leave opportunities for
coercion and intimidation. However, we do need to verify that the voter is eligible to vote (or a real person at all for that matter).</li>
<li><strong>Verifiability</strong> - we need to be able to verify if the process went correctly.</li>
<li><strong>Speed</strong> - it would be useful if votes would be counted quicker. </li>
</ol>
<p>A big problem with anonymity and verifiability is that making votes anonymous makes them difficult to verify.</p>
<p>If we had a database with all the people who voted, and their cast vote, verifiability would be tackled. However, it wouldn't be anonymous.</p>
<h2>e-voting vs i-voting</h2>
<p>When discussing electronic voting there are essentially two things at play. </p>
<ol>
<li><strong>e-voting</strong> - voting on a machine on location. Like 35 municipalities did in the Netherlands between roughly 1970 and 2007.</li>
<li><strong>i-voting</strong> - voting online using a device connected to the internet.</li>
</ol>
<p>e-voting is usually seen as the easier one. You can tackle anonymity by submitting anonymous votes, and verify it
manually with a passport check before entering the voting booth.</p>
<p>i-voting is much more difficult, because you can't have the manual check.</p>
<h2>We can protect our back accounts, so how hard can protecting votes be, right?</h2>
<p>Well, unless you're part of a secret society with unlimited wealth, chances are your bank account is not a very interesting target.</p>
<p>The scale of an election is massive. The decision made there has so much influence,
that it's an incredibly high value target.</p>
<blockquote>
<p>Most hackers aren't hardcore geeks typing away on their kali linux distro. It's usually a game of
influencing people, leaked data or a weak password. This can be summarised as the <em>human error</em>.</p>
</blockquote>
<p>It's much more likely hackers will pour resources into hacking an election than a bank account.</p>
<h2>e-voting</h2>
<p>e-voting seems like a pretty good idea. it's pretty straight forward on an abstract level: keep everything the same, only make the counting digital.</p>
<p>Too bad it's an oversimplification. It's impossible for most voters to check how the system works internally.
Even if the voters were all programmers, the source code doesn't have to be open-source. There's no rule against making the source code private. </p>
<p>So basically, it's a black box which we have to trust with one of the most important things in a democracy, and impossible for any voter to check the process.</p>
<p>This fear is backed by a <a href="https://www.bundesverfassungsgericht.de/SharedDocs/Pressemitteilungen/EN/2009/bvg09-019.html">2009 decision</a> by the Federal Constitutional Court of Germany:</p>
<blockquote>
<p>The use of voting machines which electronically record the voters’ votes and electronically ascertain the election
result only meets the constitutional requirements if the essential steps of the voting and of the ascertainment of the
result can be examined reliably and without any specialist knowledge of the subject.  </p>
</blockquote>
<p>Beside these 'lack of control' fears, a lot of systems have failed miserably over the years.</p>
<p>The lack of pen-testing (inviting good-guy hackers to attack your system and check for vulnerabilities) makes it very hard to pinpoint exact failures, but here's a curated list of found problems in the US:</p>
<ul>
<li>2003 – In Fairfax, new voting machines either didn’t work, or would lose the voter’s choice after a few moments.</li>
<li>2003 – The State of Maryland found that the Diebold Election Systems, Inc. (now rebranded as Premier Election Solutions) AccuVote-TS system “as implemented in policy, procedure, and technology, is at high risk of compromise.”</li>
<li>2002-2006 – During this period, Election Systems and Software, the US’s leading voting machine manufacture was shipping some of its systems with remote access software, making them vulnerable to hacking.  </li>
<li>2006 – Researchers from the Voting Systems Technology Assessment Advisory Board (VSTAAB) and the University of California corroborated previous research that found various Diebold voting machines can have the votes on their memory cards tampered with in a way that cannot be detected. They found a number of other security vulnerabilities as well.</li>
<li>2006 – Princeton researchers studied the Diebold AccuVote-TS and found that it was vulnerable to a range of serious attacks. These included the possibility of malware installation which could be used to alter the vote.</li>
<li>2015 – The Virginia Information Technologies Agency assessed the WinVote machine, which is manufactured by Advanced Voting Solutions. The agency recommended discontinuing the use of these machines after they found a range of serious flaws such as weak passwords, outdated security protocols, and insufficient system hardening.</li>
<li>2018 – At DEFCON, J. Alex Halderman showed that Diebold AccuVote TSX voting machines could be manipulated remotely in a mock election. The same vulnerable machines were being used in 18 different states. After the event, a 50 page report was released, detailing vulnerabilities in Election Systems &amp; Software’s M650 machine and the Diebold AccuVote TSX. Together, these machines are used in as many as 23 states.</li>
<li>2018 – Some voters in Texas allege that the Hart InterCivic’s eSlate machine was switching their vote to another candidate in the state’s election for senator.</li>
</ul>
<p>And of course a Dutch problem:</p>
<ul>
<li>2007 - It was possible to read and analyse the Electromagnetic radiation of voting machines from dozens of meters away. This caused the anonymity to be completely compromised.</li>
</ul>
<p>Side-note; this was known before an election took place. Still, parts of the election were held with the voting machines,
causing the Dutch government to be sued, losing, and going back to paper ballots.</p>
<p>So yeah, e-voting; not perfect.</p>
<h2>Hopes for e-voting</h2>
<p>More recently there has been talk of re-instating e-voting with some big adaptations. </p>
<p>The new version would basically be a computer with a printer. You can cast your vote in a voting booth with no
connectivity to the web. The voting machine would print your vote on a piece of paper, which you can then check for errors and deposit in the voting box.
These printed votes are easily read by a central computer, making counting them a lot easier and quicker.</p>
<p>Though this seems like an interesting concept, it's also doesn't have a lot of benefits over paper ballots. As the software axiom goes "keep it simple, stupid",
this doesn't really comply.</p>
<h2>i-voting</h2>
<p>I-voting, also known as remote e-voting, is casting your vote from the comfort of your own couch.
The only country which implemented such a system is Estonia. With tech giants migrating more of your life to the internet,
it seems that it's only logical to move to i-voting. Let's take a look at Estonia. How their system works,
what the vulnerabilities are, and whether we should follow suit.</p>
<h3>How it works</h3>
<p>Estonia's i-voting system builds on their ID card. This ID card is also a smart card and allows owners to digitally
sign documents and facilitates secure authentication. This already laid infrastructure makes it possible to tackle one of our demands; <strong>verifiability</strong>.</p>
<p>The i-voting system is available in an early voting period (sixth day to fourth day prior to Election Day). You can
change your vote an unlimited amount of times in that timeframe. You can also overwrite your vote by going to a
polling station, invalidating your i-vote.</p>
<p>When this new voting method was first introduced, the president Arnold Rüütel challenged i-voting, claiming breach of the principle of equality of voting.
The president brought a petition against the e-voting provisions to Estonian Supreme Court but lost. Rüütel was mostly
popular amongst the still Russian speaking elderly minority. About 1.9% voted online in the
<a href="https://archive.is/20120713045721/http://news.com.com/Estonia+pulls+off+nationwide+Net+voting/2100-1028_3-5898115.html">2005 election</a>.
This has increased over the years to <a href="https://rk2019.valimised.ee/en/voting-result/voting-result-main.html">43.8% in 2019</a>.</p>
<p>Estonia also open-sourced much of their source code to make the system as transparent as possible. They haven't
released everything (annoying some critics). Most notably, all the client side code is missing (more in that later).</p>
<p>One of the biggest things going for i-voting is potentially increasing voter turnout, however that
claim has been <a href="https://core.ac.uk/download/pdf/95665595.pdf">mostly invalidated.</a></p>
<h3>Vulnerabilities</h3>
<p>One peer <a href="https://estoniaevoting.org/findings/paper/">reviewed research paper</a> claims the researchers could be able to
breach the system, change votes and vote totals, and erase any evidence of their actions if they could install
malware on the election servers. Now of course, it's basically impossible to breach the security of election servers.
However, circling back to human error; what if someone is bribed, careless, or just malicious? The stakes are immense,
and these edge cases can not be ignored.</p>
<p>Another gaping security hole is the personal device of the voter. This may be the weakest link in the chain.
The system is quite robust after the ballot has been cast. However, sending that ballot is not trivial. </p>
<p>It's easy to write a fake web client (hence the hidden source code. That would make it too easy),
tricking people into thinking they've already voted. Or a piece of malware, sending a different vote than you typed.</p>
<p>The Estonian National Electoral parried these criticisms, <a href="http://vvk.ee/valimiste-korraldamine/vvk-uudised/vabariigi-valimiskomisjoni-vastulause-the-guardianis-ilmunud-artiklile">claiming</a>
they "give us no reason to suspend online balloting". The purported vulnerabilities were said to be either not feasible in reality or already accounted for in the design of the e-voting system.</p>
<p>The Estonian Information System Authority also responded. Claiming the criticisms as a political, rather …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.iankok.com/risk-electronic-voting">https://blog.iankok.com/risk-electronic-voting</a></em></p>]]>
            </description>
            <link>https://blog.iankok.com/risk-electronic-voting</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057302</guid>
            <pubDate>Wed, 11 Nov 2020 10:52:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free WebRTC Android, iOS and JavaScript SDKs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057259">thread link</a>) | @Iwontgo
<br/>
November 11, 2020 | https://antmedia.io/free-webrtc-android-ios-sdk/ | <a href="https://web.archive.org/web/*/https://antmedia.io/free-webrtc-android-ios-sdk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>
<div>
<article id="post-31205">
<div>
<div>
<section>
<div>
<div> <p>Developers all around the world, we have great news for you.</p> <p>We decided to offer you Ant Media Server iOS and Android SDKs for free. You can easily integrate it into your applications.</p> <p><img src="https://i0.wp.com/antmedia.io/img/ios-android-sdk/ios-icon.jpg" alt="Free WebRTC Android / iOS SDK 1" title="Free WebRTC Android / iOS SDK 1"> <img src="https://i0.wp.com/antmedia.io/img/ios-android-sdk/android-icon.jpg" alt="Free WebRTC Android / iOS SDK 2" title="Free WebRTC Android / iOS SDK 2"></p></div><p><img src="https://i0.wp.com/antmedia.io/img/ios-android-sdk/great-news.jpg" alt="Free WebRTC Android / iOS SDK 3" title="Free WebRTC Android / iOS SDK 3"></p></div></section>
<section>
<h2>Here are <span>Ant Media Server</span> <br>iOS and Android SDKs features</h2>
<div>
<div><p><img src="https://i0.wp.com/antmedia.io/img/ios-android-sdk/community.jpg" alt="Free WebRTC Android / iOS SDK 4" title="Free WebRTC Android / iOS SDK 4"></p> <p>Compatible with Community and Enterprise Edition</p></div><div><p><img src="https://i0.wp.com/antmedia.io/img/ios-android-sdk/webrtc.jpg" alt="Free WebRTC Android / iOS SDK 5" title="Free WebRTC Android / iOS SDK 5"></p> <p>WebRTC Publish and WebRTC Playback with sub-second latency*</p></div><div><p><img src="https://i0.wp.com/antmedia.io/img/ios-android-sdk/h264.jpg" alt="Free WebRTC Android / iOS SDK 6" title="Free WebRTC Android / iOS SDK 6"></p> <p>WebRTC Playback For H.265 streams is supported in Android SDK</p></div></div><p><small>*WebRTC Publishing is supported with Community Edition. WebRTC Publishing and Playing are supported with Enterprise Edition</small></p>
</section>
<section>
<h2>Get Started Now</h2>
<div>
<div>
<p>If you wonder how to use WebRTC SDKs, you can check out the <a href="https://antmedia.io/how-to-use-webrtc-sdk-in-native-ios-app/">iOS</a> and <a href="https://antmedia.io/how-to-create-webrtc-websocket-connection-in-android/">Android</a> installation guide.</p></div></div></section></div></div></article></div></div></div></div></div>]]>
            </description>
            <link>https://antmedia.io/free-webrtc-android-ios-sdk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057259</guid>
            <pubDate>Wed, 11 Nov 2020 10:41:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Choosing Boring Tech]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057240">thread link</a>) | @amzans
<br/>
November 11, 2020 | https://panelbear.com/blog/boring-tech/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/boring-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Over the years I have observed that many engineers tend to attribute much of the success or failure of a company to the technical choices made. I know I’m often guilty of this too. And while it is often justified, I would argue that for the vast majority of startups out there, the choice of programming language, framework, or even database doesn’t matter that much. This seems especially true during the early stages.</p><h2>Through the engineering lens</h2><p>This perception is understandable, we as engineers tend to look at the world from a specific lens, and are often biased by what we know best. Our daily activities may include things such as debugging CI pipelines, implementing new features, pairing with colleagues, or migrating the always present legacy codebase. The environment that surrounds us makes it easy to believe that it all boils down to those things that we see and understand. It’s an illusion that makes us feel like we’re fully in control of what makes or breaks the product.</p><p>Don’t get me wrong, it can be a huge advantage for many companies to make their product 3x more efficient than competitors, or to have elegant, composable code. But you might be focusing on the wrong problems if nobody cares about the product you’re actually building, and sooner or later your business will hit this wall.</p><p>I’m not saying that software doesn’t matter. A solid foundation for your startup goes a long way. If investing in this allows you to build better features faster than your competitors, more power to you. But finding the right balance is highly dependent on what you’re trying to solve and the resources you have at hand. There’s no right or wrong way to do it, and as usual, it mainly comes down to tradeoffs.</p><p><img src="https://panelbear.com/static/img/blog/lenses.png" alt="Different lenses"></p><h2>Boring makes me happy</h2><p>I believe aiming for a healthy balance of risk vs reward when it comes to your technical choices is something to strive for. In particular, if it decreases the chances you get stuck on the wrong problems down the road.</p><p>This is why I have come to appreciate ideas such as <a href="https://mcfunley.com/choose-boring-technology">Choose Boring Technology</a>. This is often interpreted as “picking old technologies over newer ones”, but it doesn’t necessarily mean that. For me, this comes down to using proven technologies in which the ways it can fail are mostly known, but occasionally experimenting with different, possibly newer tools that might suit me better.</p><p>Maybe you want to gain more experience by using the latest framework or programming language, or you just want to have some fun. You do what makes you happy. But if you’re trying to make a decision to increase the odds that your product or business will succeed, it’s worth stepping back and considering your options.</p><p>For me, mainly choosing software that has been around for longer is not about it being boring or older, it’s about the fact that the ways in which it fails are better known. There are fewer unknowns for you to deal with and this maximizes your chances of actually shipping the project.</p><p>For example the other day I had an issue with my Django app, and a quick search led me to tens of answers to this problem in various forums and websites. It took me at most 10 minutes to get back on track and that was the end of this issue.</p><p>I experienced the exact opposite a few years ago with a popular, but not so battle-tested Scala library my team had been using for a while. We were probably among the first to encounter the issues we were facing, and it seemed nobody had walked down this path before. Maybe it sounds like a fun challenge or a great chance to contribute back to OSS (which I’m happy to), but once you solve it, do your customers really care about it? How many days, weeks, or even months are you willing to invest in such issues? In my case, I’d rather use that time to ship new features or improve the existing ones.</p><h2>Proven tech vs new tools</h2><p>I try to follow an 80/20 distribution when it comes to my choice of tools. This means my stack consists of about 80% software I already know well, but I do allow myself 20% of the stack to explore tech I have less experience with. The exact ratio is not what’s important here, it’s more the fact that you should lean towards using proven technologies.</p><p>This also resonates with how <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed bandits</a> work. You try to maximize your expected gain by taking advantage of what worked well in the past, while sometimes exploring new things to avoid missing out on a possible goldmine.</p><p><img src="https://panelbear.com/static/img/blog/bandits.png" alt="Balance new vs proven"></p><p>A more recent example of mine is <a href="https://panelbear.com/">Panelbear</a>, it started as an embarrassingly simple Django app with no charts, all metrics were rendered on a plain HTML table, and all data was stored on a SQLite database. Took literally a weekend to get it up and running including manually deploying to a $5/mo VM. Low risk and high reward for my needs at the time.</p><p>Fast forward and as I added more features and began handling more page views for various websites, I started to notice that the codebase could use some refactoring. It also became increasingly repetitive to do things like deploying to new instances, issuing SSL certs, and keeping the DNS records up to date in case the IP address of my instances changed.</p><p>As a second iteration, I upgraded to a docker-compose setup plus lots of glue code. But soon enough I found myself reinventing what other tools already do well. There are multiple ways to solve each of these pain points, but in my case, it came down to using a tool I am very familiar with from my full-time job: Kubernetes.</p><p>Yes, I am well aware Kubernetes is an absolute overkill for a lot of projects out there, and I could have gotten away with a more traditional solution. But it allowed me to simplify the operational aspects tremendously, and I feel comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. That’s why I wouldn’t bindly recommend it to everyone. Do what you know best.
As an added benefit, it also made it trivial when I migrated from DigitalOcean to Linode, and most recently to AWS (each migration took mostly an evening of changing my Terraform files and deploying them - I’m being serious). But that’s for another post.</p><p>Another case in which it paid off once again, was when I wanted to experiment with using Clickhouse for data ingestion and the aggregation queries. It took me less than 10 minutes to write a basic deployment manifest and have it up and running. This included automated SSL certs, in-cluster service discovery, and unified logging/monitoring out of the box. It was a huge win since it allowed me to try things out faster than before.</p><p>Even better, I can deploy any container and operate it the exact same way as I deploy anything else on my cluster. Need more volume storage with zero downtime? It’s a simple manifest change, commit and deploy. Same thing when I needed Redis for caching, I was up and running in minutes, without increasing my costs or adding operational complexity.</p><h2>Focus on shipping</h2><p>My point is, I moved into these technologies as the pain with the previous solution was higher than dealing with the new tech. But more importantly, it helped me ship features even faster to my customers while reducing the operational overhead for me.</p><p>If I had started with the more advanced setup from day one, I might have lost all motivation before I would have had the first version of Panelbear. The key is to solve the problems that are getting between you and your goals, not potential issues you believe one day will be yours.</p><p>Hope you enjoyed this blog post. I plan on writing more about Panelbear’s tech stack, and lessons learned along the way. So stay tuned!</p></div></div></div>]]>
            </description>
            <link>https://panelbear.com/blog/boring-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057240</guid>
            <pubDate>Wed, 11 Nov 2020 10:37:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Option Hacking the Tektronix TDS 420A]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057162">thread link</a>) | @segfaultbuserr
<br/>
November 11, 2020 | https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html | <a href="https://web.archive.org/web/*/https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Previous installments in this series: <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html">In the Lab - Tektronix TDS 420A Oscilloscope</a>, 
 <a href="https://tomverbeure.github.io/2020/06/27/Tektronix-TDS420A-Remote-Control-over-GPIB.html">Tektronix TDS 420A Remote Control over GPIB</a>, 
 <a href="https://tomverbeure.github.io/2020/07/02/Extracting-the-Tektronix-TDS420A-Firmware.html">Extracting the Tektronix TDS 420A Firmware</a>, 
 <a href="https://tomverbeure.github.io/2020/07/03/TDS420A-Serial-Debug-Console-Symbol-Table-Ghidra.html">A Tektronix TDS 420A, a Serial Debug Console, a Symbol Table, and Ghidra</a></em></p>

<ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#how-a-tds400-oscilloscope-manages-hardware-features" id="markdown-toc-how-a-tds400-oscilloscope-manages-hardware-features">How a TDS400 Oscilloscope Manages Hardware Features</a></li>
  <li><a href="#the-key-to-enabling-option-05---video-triggering" id="markdown-toc-the-key-to-enabling-option-05---video-triggering">The Key to Enabling Option 05 - Video Triggering</a></li>
  <li><a href="#the-key-to-enabling-option-2f---advanced-dsp-math" id="markdown-toc-the-key-to-enabling-option-2f---advanced-dsp-math">The Key to Enabling Option 2F - Advanced DSP Math</a></li>
  <li><a href="#options-05-and-2f-enabled" id="markdown-toc-options-05-and-2f-enabled">Options 05 and 2F Enabled!</a></li>
  <li><a href="#option-1m---120k-sample-points---a-different-story" id="markdown-toc-option-1m---120k-sample-points---a-different-story">Option 1M - 120K Sample Points - A Different Story</a></li>
  <li><a href="#in-search-of-the-missing-memory" id="markdown-toc-in-search-of-the-missing-memory">In Search of the Missing Memory</a></li>
  <li><a href="#success-at-last" id="markdown-toc-success-at-last">Success at Last!</a></li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>



<p>I wrote <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html#the-tektronix-tds-420a-in-brief">earlier</a>
about the optional features of TDS 400 series of oscilloscopes:</p>

<ul>
  <li>Option 05: Video Trigger</li>
  <li>Option 13: RS-232/Centronics Hardcopy Interface</li>
  <li>Option 1F: File System/Floppy</li>
  <li>Option 2F: Advanced DSP Math</li>
  <li>Option 1M: 120k waveform sample points</li>
</ul>

<p>Most scopes, including mine, come with options 13 and 1F, but the remaining ones are less common.</p>

<p>The video triggering and advanced DSP math options are pure firmware functions, but even 
the 120k sample points option seemed like something that could be enabled with a software hack, since
the signal acquisition board has the 512KB of RAM available to store the data.</p>

<p>Here, I’ll describe how the TDS 400 series manages option enablement, and
how you can hack the scope into getting them to work.</p>



<p>Using Ghidra and the debug console, I figured out how the scope manages hardware
features: it has a function called <code>hwAccountantQuery</code> that has a single
parameter which I’ll call the ‘feature ID’.</p>

<p><code>hwAccountantQuery</code> will return an integer value for that feature ID. These values
can be boolean in nature (“Is a certain feature present or not”) or can be the
amount of DSP memory etc.</p>

<p>Here’s a very non-exhaustive list of codes that I’ve been able to identify:</p>

<div><div><pre><code>0x20d: number of scope channels
0x20f: size of acquisition RAM
0x216: ProbeD2MemSize
0x248: CPU clock period
0x255: InstrumentNameStringPtr
0x271: hwProbeSpecialDiagModeActive
0x2a0: hwProbeSpecialDiagLoopCount
0x2a1: hwProbeSpecialDaigSeqId
0x2b8: 30000 points -&gt; value when 1M option is not possible
0x2bf: TDS420A
0x2d2: RS232 Debug uart present
0x317: MathPak      -&gt; this is the advanced DSP math function
0x461: Floppy drive present
0x537: flashRomDateStringPtr
0x54c: TDS410A
0x560: TDS430A
0x700: hwProbeTvTrigPresent
</code></pre></div></div>

<p><code>hwAccountantQuery</code> calls <code>hwAccountantGetValue</code>. The first part of that function looks liks this:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwAccountantGetValue.png" alt="hwAccountantGetValue"></p>

<p>It’s a large <code>if-then-else</code> or <code>case</code> statement that calls a dedicated function for a particular
feature ID.</p>



<p>Did you see <code>_hwProbeTvTrigPresent()</code>? That’s the function that checks
if the video triggering feature should be enabled:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTvTrigPresent.png" alt="hwProbeTvTrigPresent"></p>

<p>And there we have it! To enable “Option 05 - Video Triggering”, all you need to do
is store a non-zero value in non-volatile RAM location 7!</p>

<p><em>This is not a shocking new discovery: plenty of online sources already mentioned this,
but it’s great to confirm it from first principles, by going to the source.</em></p>



<p>Internally, the Advanced Math DSP is called “MathPak”. Just like for video triggering, 
the <code>hwAccountGetValue</code> function issues a call to <code>hwProbeMathPakPresent()</code>:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeMathPakPresent.png" alt="hwProbeMathPakPresent"></p>

<p>Option 2F simply relies on a non-zero value in NVRAM location 9!</p>



<p>It’s now just a matter of issuing the following 2 commands on the debug console:</p>

<div><div><pre><code>libManagerWordAtPut 0x50007, 1
libManagerWordAtPut 0x50009, 1
</code></pre></div></div>

<p>My scope booted up with this image:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/options_05_and_2f_enabled.jpg" alt="Options 05 and 2F enabled"></p>

<p>Success! I’m now the proud owner of a scope that supports an entirely obsolete video triggering
mode, and a FFT math option!</p>

<p>Video Triggering Menu:
<img src="https://tomverbeure.github.io/assets/tds420a/video_triggering_features.jpg" alt="Video triggering features"></p>

<p>Live FFT of a 1kHz square wave:
<img src="https://tomverbeure.github.io/assets/tds420a/fft.jpg" alt="FFT"></p>



<p>Unfortunately, the <code>case</code> statement is only a small part of the <code>hwAccountGetValue</code> function: most
feature checking functions are performed by looping through an array of structs that
have the feature ID and a function pointer to the checking function. It’s a bit harder to figure 
out in Ghidra, but we already know that the function names to enable options start with <code>hwProbe</code>.</p>

<p>With Ghidra, we can filter on this, and that gives the <code>hwProbe1MOption</code> and the 
<code>hwProbe1MPresent</code> functions.</p>

<p><code>hwProbe1MPresent</code> looks very familiar:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MPresent.png" alt="hwProbe1MPresent"></p>

<p>Just like for the 05 and 2F options, we need to set a specific byte in the
NVRAM:</p>

<div><div><pre><code>libManagerWordAtPut 0x50006, 1
</code></pre></div></div>

<p><code>hwProbe1MOption</code> is a different story:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MOption.png" alt="hwProbe1MOption"></p>

<p>When you run <code>hwProbe1MOption</code> on the command line, the function returns a 0.</p>

<p>Feature IDs 0x216 and 0x20f are also part of the array of structs. They call the functions
<code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> respectively.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTable.png" alt="hwProbe table"></p>

<p><code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> both run a test to check the amount of RAM that 
is populated on the board.</p>

<p>When you run these query commands on the debug console, you get:</p>

<div><div><pre><code>hwAccountantQuery(0x216)    
262143
hwAccountantQuery(0x20f)    
131071
</code></pre></div></div>

<p>It’s now clear why option 1M doesn’t get enabled after changing the NVRAM value: 
feature ID 0x20f is fine (131071/0x1ffff is larger than 0x1fffe), but feature ID 0x216 is not 
(262143/0x3ffff is smaller than 0xffffe).</p>

<p>Whatever it is used for, the amount of “D2” memory in the scope is too small.</p>



<p>This finally gave me the crucial hint to start looking at other PCBs inside the scope and
try to find if there’s a place with empty footprints for RAM chips.</p>

<p>I call this the DSP PCB. Luckily, it’s a board that’s easy to remove from the chassis, without 
fragile flex cables or connectors.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_pcb.jpg" alt="DSP PCB"></p>

<p>Look at those 6 beautiful, unused footprints!</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/ram_footprints_closeup.jpg" alt="RAM footprints closeup"></p>

<p>The RAM chips are M5M51008 with a 100ns speed rating, made by Mitsubishi LSI.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_datasheet.jpg" alt="Memory Datasheet"></p>

<p>Surprisingly, Digikey still carries these parts: they’re now made by Rochester
Electronics, and only available in 70ns or 55ns version, but faster is better,
so that shouldn’t be a problem.</p>

<p>They’re cheap too at just $2.56 a piece.</p>

<p>The only issue is a minimum order quantity of 100 parts. $256 for a feature
on a 25 years old $190 oscilloscope is a bit too much! Luckily, the parts
are available at various Chinese chip brokers: I was able to buy them at 
<a href="https://utsource.net/">UTSource</a> for just $1.81 a piece. Even when buying 10 
of them (for redundancy), shipping was the biggest part of the cost:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_order.png" alt="Memory Order"></p>

<p><em>Once ordered, UTSource let me know that these parts were refurbished…</em></p>

<p>A few days later, the parts arrived at my front door, ready to be populated
on the DSP board:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_board_before_surgery.jpg" alt="DSP Board Before Surgery"></p>

<p>Note how I did not disconnect the battery that’s wired to the board: it’s used to
permanently provide power to those 4 RAMs chips on the left that are encased into 
some transparant polymer gu. Removing the battery will result in lost calibration
data (or so they say.)</p>

<p>I used a regular soldering iron instead of a hot air gun to attach the 6 RAMs:
there was enough solder on the pads and I’m most comfortable doing it that way.
Afterwards I Ohm’ed out most of the pins, and I’m glad I did because
there were some open connections.</p>

<p>The end result isn’t perfect, but it’s good enough:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/rams_populated.jpg" alt="RAMs Populated"></p>



<p>With the RAM populated, it’s time to power on the scope and check the result
of the enhancement surgery!</p>

<p>The scope bootup screen looks good:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/option_1m_enabled.jpg" alt="Option 1M enabled"></p>

<p>And this formerly grayed out 12000 points menu option is now available:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/120k_points.jpg" alt="120K Points"></p>

<p>Victory at Last!</p>



<p>The TDS 420A is an old oscilloscope, and even with those 3 new options enabled, it’s
far inferior to my Siglent 2304X or even my HP 54825A (Windows 95!) loaner.</p>

<p>120K sample points is obviously better than 30K, but it still pales in comparison
to the 140M sample points of the Siglent.</p>

<p>So what then was the point of this whole exercise?</p>

<p>I got a close up view of oscilloscope internals, I learned Ghidra from scratch and
applied it on a real, non-trival project, I added RAM to a 25 year old oscilloscope 
and it worked, I spent tons of late night hours decoding firmware, and 
I had an unreasonable amount of fun doing so.</p>

<p>I even started to appreciate the Tektronix user interface a little bit!</p>

<p>It was time well spent.</p>

<p>For now, the scope will remain on my bench while I start adding Tektronix support 
in glscopeclient. That was the whole point of acquiring the scope to being with!</p>

<p>And if it turns out that it’s really too limited for my use, I can always
sell it back on eBay, this time with 3 additional features enabled.</p>



<ul>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/hacking-my-tds460a-to-have-options-1m2f/">Hacking my TDS460A to have options 1M/2F?</a></p>
  </li>
  <li>
    <p><a href="https://forum.tek.com/viewtopic.php?t=140268">TDS420 Options Possible?</a></p>
  </li>
  <li>
    <p><a href="http://videohifi17.rssing.com/chan-62314146/all_p49.html">Upgrade Tektronix: FFT analyzer</a></p>

    <p>Story about upgrading the CPU board from 8MB to 16MB on a TDS420 (not the 420A?) and then FFT in the
  NVRAM.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=iJt2O5zaLRE">Enabling FFT option in Tektronix TDS 540A oscilloscope</a></p>

    <p>Not very useful for 420A owners: enables FFT by copying NVRAM EEPROM.</p>
  </li>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/tds420-with-lost-options/msg2032465/?PHPSESSID=021nnvu02ca549sh5le7s9r8i5#msg2032465">TDS420 with lost options</a></p>

    <p>Specific comment about how to enable options on the 420A over GPIB. I wasn’t able to get this to 
  work for some reason.</p>
  </li>
  <li>
    <p><a href="http://www.ko4bb.com/getsimple/index.php?id=enable-tds754d-options">Enable TDS754D Options using GPIB</a></p>

    <p>Another one about using GPIB.</p>
  </li>
</ul>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057162</guid>
            <pubDate>Wed, 11 Nov 2020 10:22:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four Steps to Take After Your Unsuccessful Job Interview]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057115">thread link</a>) | @eisabai
<br/>
November 11, 2020 | https://code.likeagirl.io/four-steps-to-take-after-your-unsuccessful-job-interview-d4e5df344b1a?source=your_stories_page------------------------------------- | <a href="https://web.archive.org/web/*/https://code.likeagirl.io/four-steps-to-take-after-your-unsuccessful-job-interview-d4e5df344b1a?source=your_stories_page-------------------------------------">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="1182">What to do when you’ve failed a job interview</h2><div><div><div><div><a href="https://medium.com/@eisabai?source=post_page-----d4e5df344b1a--------------------------------" rel="noopener"><div><p><img alt="Isabel Nyo" src="https://miro.medium.com/fit/c/96/96/1*BGXgVWhH-nqrX6VruxEvmA.jpeg" width="48" height="48"></p></div></a></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/12032/0*TadXdhbziKwvqTAg" width="6016" height="4016" srcset="https://miro.medium.com/max/552/0*TadXdhbziKwvqTAg 276w, https://miro.medium.com/max/1104/0*TadXdhbziKwvqTAg 552w, https://miro.medium.com/max/1280/0*TadXdhbziKwvqTAg 640w, https://miro.medium.com/max/1400/0*TadXdhbziKwvqTAg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*TadXdhbziKwvqTAg?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@benwhitephotography?utm_source=medium&amp;utm_medium=referral" rel="noopener">Ben White</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><blockquote><p id="b5c7">Dear {Name},</p><p id="03fa">We are sorry to inform you that the decision has been made not to progress with your application for the {role}. I’m sorry it isn’t better news.</p><p id="b9b8">Signed,<br>Recruiter/Hiring Manager</p></blockquote><p id="7790">We have all seen this kind of messages. Unfortunately though, it doesn’t get easier no matter how many times you have seen it.</p><p id="8f61">As someone who has been on the other side of the table many times as an interviewer and have had a good track record when it comes to nailing interviews as an interviewee, I still can’t completely escaped from such rejection messages.</p><p id="98d6">In this article, I’d like to share with you four steps that you can take to still walk away as a winner even after being rejected at an interview.</p></div></div></section><section><div><div><h2 id="f612">1. Obtain as much feedback as possible</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/10368/0*l_fDsPC7ZWbZo-RG" width="5184" height="3456" srcset="https://miro.medium.com/max/552/0*l_fDsPC7ZWbZo-RG 276w, https://miro.medium.com/max/1104/0*l_fDsPC7ZWbZo-RG 552w, https://miro.medium.com/max/1280/0*l_fDsPC7ZWbZo-RG 640w, https://miro.medium.com/max/1400/0*l_fDsPC7ZWbZo-RG 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*l_fDsPC7ZWbZo-RG?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@nshuman1291?utm_source=medium&amp;utm_medium=referral" rel="noopener">Nathaniel Shuman</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="3d09">If you don’t hear from the company a few days or week after your interview or if you receive a generic rejection email, it’s on you to try and obtain as much feedback as possible. Be polite and professional and tell them that this will help you understand what you had done well and what you could do to improve next time. As long as you were honest in your ask, most companies will get back to you with some form of feedback. You will be using this feedback to adjust your game plan and strategy as needed, which is part of step 3.</p><p id="8408">What you should avoid doing though is to argue or counter their feedback. The decision is already made. Don’t waste your time. However, in rare occasions, if incorrect assumption was made regarding your take home exercise, or live presentation interview, you can provide more information to address the feedback. But do not expect to be considered for the role again — in other words, do not keep your hopes up.</p></div></div></section><section><div><div><h2 id="48f7">2. Give yourself time to digest and process your emotion</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/9216/0*yV4AO854GZ9Pm1u9" width="4608" height="3456" srcset="https://miro.medium.com/max/552/0*yV4AO854GZ9Pm1u9 276w, https://miro.medium.com/max/1104/0*yV4AO854GZ9Pm1u9 552w, https://miro.medium.com/max/1280/0*yV4AO854GZ9Pm1u9 640w, https://miro.medium.com/max/1400/0*yV4AO854GZ9Pm1u9 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*yV4AO854GZ9Pm1u9?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@blitzer?utm_source=medium&amp;utm_medium=referral" rel="noopener">Niklas Rhöse</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="925f">Being rejected and being unsuccessful at an interview is disappointing. There is no other way to put it. Even if you have got another offer from a different company or a different role, you would still want to get an offer for all the roles that you applied for. That’s human nature.</p><p id="b688">It’s completely ok to feel disappointed, upset, angry, defeated, or any other negative emotion for a while. Take the time to process your emotion. Personally for me, I go through a cycle of disappointment, sadness, anger, and then finally, acceptance. It usually takes me two hours, but every person is different, so it might just be 20 minutes for you, or 20 hours for another person. The key here is to allow yourself to feel that negative emotion instead of trying to push it aside. Once you’ve felt all the emotions, you will find that you’re ready to move on and think clearly again.</p><p id="baf9">Maybe the interviewer made an error in judgement, maybe you said something that were taken on the face value, maybe your interview performance was not good enough, maybe there are more suitable candidates, it doesn’t matter what the reason is. What matter is for you to be able to move on without getting paralysed by what could have been.</p></div></div></section><section><div><div><h2 id="955e">3. Adjust your game plan and strategy if needed</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/12000/0*AvjW-1p4Xhn6LC15" width="6000" height="4000" srcset="https://miro.medium.com/max/552/0*AvjW-1p4Xhn6LC15 276w, https://miro.medium.com/max/1104/0*AvjW-1p4Xhn6LC15 552w, https://miro.medium.com/max/1280/0*AvjW-1p4Xhn6LC15 640w, https://miro.medium.com/max/1400/0*AvjW-1p4Xhn6LC15 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*AvjW-1p4Xhn6LC15?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@felix_mittermeier?utm_source=medium&amp;utm_medium=referral" rel="noopener">Felix Mittermeier</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="06dc">Based on the feedback that you receive, you can do one of three things. First, you may want to change how you present yourself and how you communicate your skills to be more aligned with what interviewers are looking for. Second, you may decide to gain additional knowledge and skills in the areas that were identified as gaps. Third, you may accept that you are not going to change your tactics but apply for different roles that are more aligned with your skills and experiences.</p><p id="fed4">To give you my personal example, one of the feedback that I receive from those who do not know me or have worked with me in the industry is that I do not have a leadership presence. The perception comes from the fact that technology is a male-dominated industry and people are used to seeing assertive leaders who value hierarchy and command and control. To add to the fact that I am female, petite and soft-spoken, it’s hard for some to accept that I am an effective leader. While it’s sad to see gender and leader stereotypes in the 21st century, I have come to accept the fact. I am not willing to put on an act during an interview and display the masculine attributes commonly associated with effective leadership, such as assertiveness and competition, just to get the job.</p><p id="0ad5">This doesn’t mean I do not apply for leadership roles nor get leadership positions. I just have to understand myself well and know how to present myself in the best possible light without losing my integrity. And if I am unsuccessful because it was still not good enough in the interviewer’s opinion, then so be it.</p></div></div></section><section><div><div><h2 id="ed95">4. Remember the golden rule</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7744/0*bzx94k8FR8OiGrQr" width="3872" height="2592" srcset="https://miro.medium.com/max/552/0*bzx94k8FR8OiGrQr 276w, https://miro.medium.com/max/1104/0*bzx94k8FR8OiGrQr 552w, https://miro.medium.com/max/1280/0*bzx94k8FR8OiGrQr 640w, https://miro.medium.com/max/1400/0*bzx94k8FR8OiGrQr 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*bzx94k8FR8OiGrQr?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@quentinreyphoto?utm_source=medium&amp;utm_medium=referral" rel="noopener">Quentin Rey</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="f2ae">What’s the golden rule, I hear you ask. Dalai Lama once said, “Remember that sometimes not getting what you want is a wonderful stroke of luck.” Whether the reason for rejection was because you didn’t yet have the technical skills required for the role, personal traits that were deemed necessary by the interviewers and/or company, or purely a misjudgement from the interviewer’s part (yes, interviewers are humans too and they may make wrong decision), know that your worth is not tied to the performance of an interview.</p><p id="ecf7">I truly believe that everything in this world happens for you, not to you. Every time after I was rejected for a role, I got a better offer from another company. So my advice for you is to spend your time and energy on becoming a better person every day instead of dwelling on the rejection, and trust that a superior offer is just around the corner.</p></div></div></section><section><div><div><h2 id="a25c">Take the next step forward</h2><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/10368/0*QY53jEzOGv_1Qgl5" width="5184" height="3888" srcset="https://miro.medium.com/max/552/0*QY53jEzOGv_1Qgl5 276w, https://miro.medium.com/max/1104/0*QY53jEzOGv_1Qgl5 552w, https://miro.medium.com/max/1280/0*QY53jEzOGv_1Qgl5 640w, https://miro.medium.com/max/1400/0*QY53jEzOGv_1Qgl5 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*QY53jEzOGv_1Qgl5?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@brett_jordan?utm_source=medium&amp;utm_medium=referral" rel="noopener">Brett Jordan</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="e65d">So what you were rejected for a role. Your life isn’t over, your career isn’t over. It’s ok. The important thing is for you to pick yourself up again and take the next step forward. You win some, you lose some, but those who are the ultimate winners are those who have the courage to keep going until they get what they deserve, in this case, a role that is aligned with what you’re looking for and a company and colleagues who will appreciate you for what you bring to the table.</p><p id="c752">Good luck!</p></div></div></section></div></div>]]>
            </description>
            <link>https://code.likeagirl.io/four-steps-to-take-after-your-unsuccessful-job-interview-d4e5df344b1a?source=your_stories_page-------------------------------------</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057115</guid>
            <pubDate>Wed, 11 Nov 2020 10:12:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forming Professional Dev Team Habits]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057078">thread link</a>) | @morchen
<br/>
November 11, 2020 | https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/ | <a href="https://web.archive.org/web/*/https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-v-f94c7cca=""> <!----> <div data-v-0cf44990="" data-v-f94c7cca=""><div><p>How does your workplace cultivate an environment of team development? How do you make sure your engineers have time for creative ideas and professional development, all the while meeting sprints, deadlines and deliverables? While branded photogenic team building activities are common in many tech companies — especially with rapidly growing teams, this strategy fails to help grow together as professionals and misses the aim in the long run.</p>
<p>For long, I’ve been toying with such questions, asking myself — how can companies keep “the fun bits”, but also cultivate purpose and a culture of self and team professional development. In this post you’ll find the pilot we’re launching at Swimm: the main goals of such a pilot and why we believe in it, as well as the execution strategy. We will follow-up and share our experiences in future posts.</p>
<h3><strong>The Why: Delivering Code Excellence</strong></h3>
<p><strong>Professionalism</strong>. First, we want to create a culture where all of our team members learn new things, on an ongoing basis. To become professionals, we need to keep learning all the time. To stay happy and challenged at work we need access to resources, and need our managers to invest in our development.</p>
<p><strong>Innovation</strong>. Second, reviewing together new topics and brainstorming on how they can be integrated into our products will provide new ideas and make us constantly rethink our current approaches.</p>
<p>While thinking about a way to achieve these goals, I was looking for best practice, study cases and models that worked well or gloriously failed in other places in the tech industry. Specifically, I was inspired by <a href="https://medium.com/@Idan.Bassuk/a-proven-methodology-for-becoming-an-a-i-expert-32d43887cb1e">this post</a> by Idan Bassuk from <strong>Aidoc</strong>. I contacted Idan and he was very kind to answer all my questions. I learned that they’ve been continuing their “Deep Snips” (where one of their team members learns a subject and presents it to the team) for the past 3 years, and that he still believes this method helps achieve its goals. I learned from their experience that many of their talks resulted in actual impact to their products. This gave me confidence that this method can indeed have a meaningful impact, and I was now more eager than before to put this to the test.</p>
<h3><strong>The How: Swimminars X 2 Weeks</strong></h3>
<p><strong>Swimminars.</strong> Every other week, one of our engineers will get to learn something new that they wish to dive deeper into and learn. It can be about anything at all, as long as it’s technological, and can be applied to our product(s), even if not in the foreseeable future. Then, the engineer will give a lecture, sharing their research and new knowledge with the team. After every session, we will also publish a blog post, summarising the lecture for our community or new hires to use if they wish.</p>
<p><strong>Technicalities</strong>. We plan to divide the session into two parts — the first will be technical, an in-depth overview of the relevant subject (will be covered on our blog posts). The second part will include holding internal discussions on the possible utilisation, adoption and impacts of the topic on our product(s). Are we already relying on some of this knowledge? Can it help us tackle a current or future issue? Perhaps we need to consider implementing it now?</p>
<p>During the two weeks of the engineer’s turn, (s)he gets as much time as needed to learn the subject and prepare the lecture. This will be prioritised over other tasks, and we assume it will take between one and two days. This is a huge commitment — with all the tasks that we have as a startup, every day is precious. Still, we decided that the impact we are hoping for is so valuable that it’s worth the price, and that we are willing to make the experiment.</p>
<h3><strong>Piloting: Managing Expectations</strong></h3>
<p><strong>Risks</strong>. Yet, as always, it’s easier said than done. Indeed this can go wrong in different ways — time management vs efficiency, getting to a high level of interesting presentations and useful technological insight, or getting every one’s voice heard on the team in a manner that compliments them. It’s a learning on the go activity. So we’re up for a team challenge.</p>
<p><strong>Upsides</strong>. For the duration of our team pilot, every other week, the entire dev team will get to learn something new while taking turns deepening knowledge, improving writing and presentation skills and becoming experts within the team on their Swimminar topics. This team exercise will provide each engineer individually and the team as whole, positive experiences of success. We hope.</p>
<p>I will be the first to give a Swimminar — specifically, on <strong>git internals</strong>. How it goes from there, only time will tell. We promise to report back on how this experiment is working for us. Stay tuned.</p>
<p><em>Swimm is a tool helping engineers contribute to any codebase faster and better with automatically generated hints and codebase insight.</em></p>
<p><em>Omer Rosenbaum, Swimm’s Chief Technology Officer. Cyber training expert and Founder of Checkpoint Security Academy. Author of <a href="https://data.cyber.org.il/networks/networks.pdf">Computer Networks (in Hebrew)</a>. Visit My <a href="https://www.youtube.com/watch?v=79jlgESHzKQ&amp;list=PL9lx0DXCC4BMS7dB7vsrKI5wzFyVIk2Kg">YouTube Channel</a>.</em></p>
</div></div> </section></div>]]>
            </description>
            <link>https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057078</guid>
            <pubDate>Wed, 11 Nov 2020 10:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We made our own x86 shellcode emulator and how it works]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25057062">thread link</a>) | @mdontu
<br/>
November 11, 2020 | https://hvmi.github.io/blog/2020/11/11/bdshemu.html | <a href="https://web.archive.org/web/*/https://hvmi.github.io/blog/2020/11/11/bdshemu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="introduction">Introduction</h2>

<p>Detecting exploits is one of the major strengths of Hypervisor Memory Introspection (HVMI). The ability to monitor guest physical memory pages against different kinds of accesses, such as write or execute, allows HVMI to impose restrictions on critical memory regions: for example, stack or heap pages can be marked as being non-executable at the EPT level, so when an exploit manages to gain arbitrary code execution, the introspection logic would step in and block the execution of the shellcode.</p>

<p>In theory, intercepting execution attempts from memory regions such as the stack or the heap should be enough to prevent most of the exploits. Real life is often more complicated, and there are many cases where legit software uses techniques that may resemble on attack - Just In Time compilation (JIT) in browsers is one good example. In addition, an attacker may store its payload in other memory regions, outside the stack or the heap, so a method of discerning good code from bad code is useful.</p>

<p>We will talk in this blog post about the Bitdefender Shellcode Emulator, or <a href="https://github.com/bitdefender/bddisasm">bdshemu</a> for short. bdshemu is a library capable of emulating basic x86  instructions (in all modes - 16, 32 and 64 bit), while observing shellcode-like behavior. Legitimate code, such as JIT code, will look different compared to a traditional shellcode, so this is what bdshemu is trying to determine: whether the emulated code behaves like a shellcode or not.</p>

<h2 id="bdshemu-overview">bdshemu Overview</h2>

<p>bdshemu is a library written in C, and is part of the bddisasm project (and of course, it makes use of bddisasm for instruction decoding). The bdshemu library is built to emulate x86 code only, so it has no support for API calls. In fact, the emulation environment is highly restricted and stripped down, and there are only two memory regions available:</p>

<ul>
  <li>The page(s) containing the emulated code;</li>
  <li>The stack;</li>
</ul>

<p>Both of these memory regions are virtualized, meaning that they are in fact copies of the actual memory being emulated, so modifications made to them don’t affect the actual system state. Any access made by the emulated code outside of these two areas (which we will call the shellcode and the stack, respectively) will trigger immediate emulation termination. For example, an API call will automatically cause a branch outside the shellcode region, thus terminating emulation. However, in bdshemu, all we care about is instruction-level behavior of the code, which is enough to tell us whether the code is malicious or not.</p>

<p>While bdshemu provides the main infrastructure for detecting shellcodes inside a guest operating-system, it is worth noting that this is not the only way HVMI determines that execution of a certain page is malicious - two other important indicators are used:</p>

<ul>
  <li>The executed page is located on the stack - this is common with stack-based vulnerabilities;</li>
  <li>The stack is pivoted - when a page is first executed and the <code>RSP</code> register points outside the normal stack allocated for the thread;</li>
</ul>

<p>These two indicators are enough on their own to trigger an exploit detection. If these are not triggered, bdshemu is used to take a good look at the executed code, and decide if it should be blocked or not.</p>

<h2 id="bdshemu-architecture">bdshemu Architecture</h2>

<p>bdshemu is created as a standalone C library, and it only depends on bddisasm. Working with bdshemu is fairly simple, as just like bddisasm, it is a single-API library:</p>
<div><div><pre><code><span>SHEMU_STATUS</span>
<span>ShemuEmulate</span><span>(</span>
    <span>SHEMU_CONTEXT</span> <span>*</span><span>Context</span>
    <span>);</span>
</code></pre></div></div>

<p>The emulator expects a single <code>SHEMU_CONTEXT</code> argument, containing all the needed information in order to emulate the suspicious code. This context is split in two sections - input parameters and output parameters. The input parameters must be supplied by the caller, and they contain information such as the code to be emulated, or initial register values. The output parameters contain information such as what shellcode indicators bdshemu detected. All these fields are well documented in the source-code.</p>

<p>Initially, the context is filled in with the following main information (please note that emulation outcome may change depending on the value of the provided registers and stack):</p>

<ul>
  <li>Input registers, such as segments, general purpose registers, MMX and SSE registers; they can be left 0, if they are not known, or if they are irrelevant;</li>
  <li>Input code, which is the actual code to be emulated;</li>
  <li>Input stack, which can contain actual stack contents, or can be left 0;</li>
  <li>Environment info, such as mode (32 or 64 bit), or ring (0, 1, 2 or 3);</li>
  <li>Control parameters, such as minimum stack-string length, minimum NOP sled length or the maximum number of instructions that should be emulated;</li>
</ul>

<p>The main output parameter is the <code>Flags</code> field, which contains a list of shellcode indicators detected during the emulation. Generally, a non-zero value of this field strongly suggests that the emulate code is, in fact, a shellcode.</p>

<p>bdshemu is built as a plain, quick and simple x86 instruction emulator: since it only works with the shellcode itself and a small virtual stack, it doesn’t have to emulate any architectural specifics - interrupts or exceptions, descriptor tables, page-tables, etc. In addition, since we only deal with the shellcode and stack memory, bdshemu does not do memory access checks, since it doesn’t even allow accesses to other addresses. The only state apart from the registers that can be accessed is the shellcode itself and the stack, and both are copies of the actual memory contents - the system state is never modified during the emulation, only the provided <code>SHEMU_CONTEXT</code> is. This makes bdshemu extremely fast, simple, and lets us focus on its main purpose: detecting shellcodes.</p>

<p>As far as instruction support goes, bdshemu supports all the basic x86 instructions, such as branches, arithmetic, logic, shift, bit manipulation, multiplication/divison, stack access and data transfer instructions. In addition, it also has support for other instructions, such as some basic MMX or AVX instructions - <code>PUNPCKLBW</code> or <code>VPBROADCAST</code> are two good examples.</p>

<h2 id="bdshemu-detection-techniques">bdshemu Detection Techniques</h2>

<p>In order to determine whether an emulated piece of code behaves like a shellcode, there are several indicators bdshemu uses.</p>

<h3 id="nop-sled">NOP Sled</h3>

<p>This is the classic presentation of shellcodes; since the exact entry point of the shellcode when gaining code execution may be unknown, attackers usually prepend a long sequence of <code>NOP</code> instructions, encoding <code>0x90</code>. The parameters for the NOP-sled length can be controlled when calling the emulator, via the <code>NopThreshold</code> context field. The default value is <code>SHEMU_DEFAULT_NOP_THRESHOLD</code>, which is <code>75</code>, meaning that minimum 75% of all the emulated instruction must be <code>NOP</code>.</p>

<h3 id="rip-load">RIP Load</h3>

<p>Shellcodes are designed to work correctly no matter what address they’re loaded at. This means that the shellcode has to determine, dynamically, during runtime, the address it was loaded at, so absolute addressing can be replaced with some form of relative addressing. This is typically achieved by retrieving the value of the instruction pointer using well-known techniques:</p>

<ul>
  <li><code>CALL $+5/POP ebp</code> - executing these two instructions will result in the value of the instruction pointer being stored in the <code>ebp</code> register; data can then be accessed inside the shellcode using offsets relative to the <code>ebp</code> value;</li>
  <li><code>FNOP/FNSTENV [esp-0xc]/POP edi</code> - the first instruction is any FPU instruction (not necessarily <code>FNOP</code>), and the second instruction, <code>FNSTENV</code> saves the FPU environment on the stack; the third instruction will retrieve the <code>FPU Instruction Pointer</code> from <code>esp-0xc</code>, which is part of the FPU environment, and contains the address of the last FPU executed - in our case, <code>FNOP</code>; from there on, addressing relative to the <code>edi</code> can be used to access shellcode data;</li>
</ul>

<p>Internally, bdshemu keeps track of all the instances of the instruction pointer being saved on the stack. Later loading that instruction pointer from the stack in any way will result in triggering this detection. Due to the way bdshemu keeps track of the saved instruction pointers, it doesn’t matter when, where or how the shellcode attempts to load the RIP in a register and use it, bdshemu will always trigger a detection.</p>

<p>In 64 bit, RIP-relative addressing can be used directly, since the instruction encoding allows it. However, surprisingly, a large number of shellcodes still use a classic method of retrieving the instruction pointer (generally the <code>CALL/POP</code> technique), which is somehow weird, but it probably indicated that 32 bit shellcodes were ported to 64 bit with minimal modifications.</p>

<h3 id="write-self">Write Self</h3>

<p>Most often, shellcodes come in encoded or encrypted forms, in order to avoid certain bad characters (for example, <code>0x00</code> in a shellcode that should resemble a string may break the exploit) or to avoid detection by security technologies (for example, AV scanners). This means that during runtime, the shellcode must decode itself (usually in-place), by modifying its own contents, and then executing the plain-text code. Typical methods of decoding involve <code>XOR</code> or <code>ADD</code> based decryption algorithms.</p>

<p>Certainly, bdshemu follows this kind of behavior, and keeps track internally of each modified byte inside the shellcode. Whenever the suspected shellcode writes any portion of itself, and then it executes it, the self-write detection will be triggered.</p>

<h3 id="tib-access">TIB Access</h3>

<p>Once a shellcode has gained code execution, it needs to locate several functions inside various modules, in order to carry its actual payload (for example, downloading a file, or creating a process). On Windows, the most common way of doing this is by parsing the user-mode loader structures, in order to locate the addresses where the required modules were loaded, and then locate the needed functions inside these modules. The sequence of structures the shellcode will access is:</p>

<ol>
  <li>The Thread Environment Block (<code>TEB</code>), which is located at <code>fs:[0]</code> (32 bit thread) or <code>gs:[0]</code> (64 bit thread);</li>
  <li>The Process Environment Block (<code>PEB</code>), which is located at <code>TEB+0x30</code> (32 bit) or <code>TEB+0x60</code> (64 bit)</li></ol></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hvmi.github.io/blog/2020/11/11/bdshemu.html">https://hvmi.github.io/blog/2020/11/11/bdshemu.html</a></em></p>]]>
            </description>
            <link>https://hvmi.github.io/blog/2020/11/11/bdshemu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057062</guid>
            <pubDate>Wed, 11 Nov 2020 10:01:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keyboardio Atreus: Yeah or Meh?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056988">thread link</a>) | @liveweird
<br/>
November 11, 2020 | https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5faba45f5480d10039a1a829">
	

	<section>
		<p>I've bought another mechanical keyboard (technically - I've backed <a href="https://www.kickstarter.com/projects/keyboardio/atreus">the Kickstarter campaign</a>). Feel free to call me an addict - I don't mind. It's my 4th and all three that I already have work well until now, so I have no valid reason to complain about them. Why waste money then (as they were not cheap - we're talking about an expenditure of 130+ USD per keyboard)?</p><p>The truth is, I use more than one computer (on a daily basis). Desktop PC powered by Windows 10, my private development machine (macOS), and the one provided by the company I currently cooperate with (Ubuntu 20). That means constant switching between very different keyboards and layouts. MacBook Pro's keyboard is pure rubbish (even the refined scissor 2020 model), Lenovo Thinkpad's one is a bit better but still very far from typing experience achievable only for mechanical keyboards, my desktop keyboard is fine but freakin' huge.</p><p>That's why I've decided that what I really need is a reliable mechanical keyboard <strong>I could carry with me easily</strong> and plug anywhere I want.</p><p>Sounds easy, but there are objective obstacles. Mechanical keyboards are generally large and heavy. Both Das Keyboards I own are 100% out of the question here. I have an 88 WASD keyboard as well, but even w/o a numerical keypad, it's too big to carry in the backpack.</p><p>Atreus to the rescue.</p><p>The brand "Atreus" is not new. If you're into mechanical keyboards, you've probably heard about <a href="https://atreus.technomancy.us/">Classic Atreus</a> - as it's available since 2014. The concept was very simple - to create a mechanical keyboard that is fully optimized for natural palms position, so you have all the keys within reach w/o making any move. That also means minimizing the number of keycaps by doing some crazy optimizations (more about that later).</p><p>The keyboard I've ordered is a product of cooperation of <strong>Atreus</strong> and <strong>Keyboardio</strong> - a refreshed, minimalistic version of Classic Atreus with few slight improvements aimed to make it even more compact and apply the lessons from previous models (e.g., adjust the keys in the very center area). You can read more about it (incl. specs and design decisions) <a href="https://shop.keyboard.io/products/keyboardio-atreus">here</a>.</p><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/11/atreus_top.jpg" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/11/atreus_top.jpg 600w, https://no-kill-switch.ghost.io/content/images/2020/11/atreus_top.jpg 900w" sizes="(min-width: 720px) 720px"></figure><p>I've ordered a blank model (no symbols on the top of keycaps) with <strong>Kailh BOX White switches</strong> and the dedicated case. It's the first model with Kailh switches I've ever tried. The white ones are clicky and have very early tactile feedback. I'm not going to delay that message - the switches turned out to be <u>AWESOME</u>. The typing experience is extremely satisfying (IMHO better than Cherry MX Clear or Gamma Zulu ones). It does require some (reasonable) force, but in exchange, you get the subliminal certainty (the one that doesn't involve conscious thinking) of whether you pressed the button effectively (once) or not.</p><p>OK, good switches are important, but what about the layout? If you've used previous models of Atreus before, you won't be surprised - the changes are subtle but not revolutionary. If you had no prior experience with Atreus, it may be a real shocker.</p><p>First of all, the keyboard has only <strong>44 keycaps</strong> (yay). The space bar is of the size of any other keycap. There are three modes - black, blue, and red (officially named: default, fun, and upper). Default is ... well, default. Fun is active when you <u>hold</u> the 'Fun' button (3rd from the left in the bottom row of the right part of the keyboard) and upper is <u>switched on</u> by (pressing, you don't need to hold them) <strong>Fun</strong> &amp; <strong>Esc</strong> combo.</p><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/11/atreus.png" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/11/atreus.png 600w, https://no-kill-switch.ghost.io/content/images/2020/11/atreus.png 680w"></figure><p>Some "standard" keys are entirely missing (e.g., <strong>Caps Lock</strong>), some have very un-intuitive positions (<strong>Escape</strong>, <strong>Tab</strong>, <strong>Backspace</strong>). You can read about the layout on the official page (linked above), so I'm not going to describe all the nuances - I'd like to focus on the impressions instead: how does it work? Is it easy to get used to? Convenient? How does it work for typical development keystrokes/routines?</p><p>It ... depends.</p><p>It didn't take me much time to get used to typing texts (articles, blog posts, e-mails) - the layout is a bit skewed, but still: it's QWERTY. The most mistakes I was making were in the 3rd row (<strong>'b'</strong>, <strong>'c'</strong> and <strong>'m'</strong>). However, getting accustomed to control/function keys is an entirely different kind of story:</p><ul><li><strong>Backspace</strong>/<strong>Space</strong> tandem is very different to what you know but once you try it, it gets very intuitive</li><li><strong>Ctrl</strong> and <strong>Alt</strong> are well within reach, but they force you to change your mechanical habits - that will take time</li><li><strong>Tab</strong>'s positioning is the most surprising - it's probably the least reachable keycap on the board</li><li>Having <strong>Delete</strong> in the red (upper) mode means that you're pretty much restricted to using <strong>Backspace</strong></li><li>All kinds of parenthesis (in the blue mode) require memorization from scratch</li><li>TBH I don't use red mode at all - it's just too much of a hassle (that means no <strong>PageUp</strong>, <strong>PageDown</strong>, <strong>F1 </strong>... <strong>F12 </strong>keys - but TBH I've used them very rarely anyway)</li></ul><hr><p><em>A side-note: I don't use Vim, I've also recently gave up on Spacemacs. Last months for codecrafting I've used mainly SublimeText + TabNine (80%) and Visual Studio Code (20%).</em></p><p>After two weeks of using Atreus, it feels like I'm still <u>terribly slow</u> - quite fluent, can manage without a cheatsheet, but still - just painfully slooow. The new automations (you don't need to think about) are not (yet) there, and the old ones got rusty already (when I try to use Das Keyboard occasionally). Ahh, yeah - I've mentioned the printed cheat sheet - it comes in the box with the keyboard, it's laminated, and it's a hell of help - especially in the first few days. A decent idea - kudos for that.</p><p>To be honest, I think that those few weeks are still too little to make a proper judgment, so let's consider it an early review and revisit in few months time.</p><p>IMHO, Atreus delivers what it promises. </p><p>It's compact and lightweight indeed. The quality (of manufacturing) is flawless - sharp, raw, minimalistic, yet beautiful.</p><p>Overall, it's my 2nd favorite of all mech keyboards I've ever used (runner up only to the <a href="https://www.wasdkeyboards.com/wasd-v3-88-key-iso-custom-mechanical-keyboard.html">Cherry MX Clear 88-key WASD</a>), and that says a lot. Yes, this position has been earned mainly by the outstanding switches and the unquestionable mobility, but it's not that I classify the layout as a con. It does require time to adjust your habits, but it's hard to name even a single, irrevocably bad design decision (in terms of positioning or spacing) - with <strong>Tab</strong> positioning being the most controversial one.</p><p>Btw. if you don't like any particular key position, there's a dedicated piece of software (Chrysalis: <a href="https://github.com/keyboardio/Chrysalis">https://github.com/keyboardio/Chrysalis</a>) you can use to conveniently remap it (in the end: I didn't remap any single key).</p><p>It should be stated very clearly - IMHO, this keyboard is <strong><u>much better suited for typists</u></strong> than e.g., developers (or gamers), but even for a typist, it will take several weeks to get used to it and regain a proper pace of typing. What does it mean 'proper pace'? Is it possible to get as effective as with a standard IBM Model M layout?</p><p>Opinions vary.</p><p>Personally, I don't think so, but please keep in mind that this is not a 105-cap but 44-cap keyboard - some efficiency is intended to be sacrificed for the compactness. Consider carefully the scenarios you'd like to use it for, before, not after buying.</p>
	</section>

	
</article></div>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056988</guid>
            <pubDate>Wed, 11 Nov 2020 09:45:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A curious case of stacks and queues]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25056603">thread link</a>) | @oecumena
<br/>
November 11, 2020 | http://www.cofault.com/2020/11/a-curious-case-of-stacks-and-queues.html | <a href="https://web.archive.org/web/*/http://www.cofault.com/2020/11/a-curious-case-of-stacks-and-queues.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When studying computing science we all learn how to convert an expression in the "normal" ("<a href="https://en.wikipedia.org/wiki/Infix_notation">infix</a>", "algebraic") notation to "<a href="https://en.wikipedia.org/wiki/Reverse_Polish_notation">reverse Polish</a>" notation. For example, an expression "<code>a*b + c*d</code>" is converted to "<code>a b * c d * +</code>". An expression in reverse Polish notation can be seen as a program for <a href="https://en.wikipedia.org/wiki/Pushdown_automaton">a stack automaton</a>:

</p><div><pre><code>PUSH A
PUSH B
MUL
PUSH C
PUSH D
MUL
ADD</code></pre></div>

<p>Where <code>PUSH</code> pushes its argument on the top of the (implicit) stack, while <code>ADD</code> and <code>MUL</code> pop 2 top elements from the stack, perform the respective operation and push the result back. 
</p><p>For reasons that will be clearer anon, let's re-write this program as
</p><div><pre><code>Container c;
c.put(A);
c.put(B);
c.put(c.get() * c.get())
c.put(C);
c.put(D);
c.put(c.get() * c.get())
c.put(c.get() + c.get())</code></pre></div>

<p>Where <code>Container</code> is the type of stacks, <code>c.put()</code> pushes the element on the top of the stack and <code>c.get()</code> pops and returns the top of the stack. <a href="https://en.wikipedia.org/wiki/LIFO">LIFO</a> discipline of stacks is so widely used (implemented natively on all modern processors, built in programming languages in the form of call-stack) that one never ask whether a different method of evaluating expressions is possible.
</p><p>Here is a problem: find a way to translate infix notation to a program for a queue automaton, that is, in a program like the one above, but where <code>Container</code> is the type of <a href="https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)">FIFO</a> <a href="https://en.wikipedia.org/wiki/Queue_(abstract_data_type)">queues</a> with <code>c.put()</code> enqueuing an element at the rear of the queue and <code>c.get()</code> dequeuing at the front. This problem was <a href="https://www.cs.utexas.edu/users/EWD/ewd08xx/EWD887.PDF">reportedly</a> solved by <a href="https://en.wikipedia.org/wiki/Jan_L._A._van_de_Snepscheut">Jan L.A. van de Snepscheut</a> sometime during spring 1984.

</p><p>While you are thinking about it, consider the following tree-traversal code (in some abstract imaginary language):
</p><div><pre><code>walk(Treenode root) {
        Container todo;
        todo.put(root);
        while (!todo.is_empty()) {
                next = todo.get();
                visit(next);
                for (child in next.children) {
                        todo.put(child);
                }
        }
}</code></pre></div>
<p>Where <code>node.children</code> is the list of node children suitable for iteration by <code>for</code> loop.
</p><p>Convince yourself that if <code>Container</code> is the type of stacks, tree-walk is depth-first. And if <code>Container</code> is the type of queues, tree-walk is breadth-first. Then, convince yourself that a depth-first walk of the parse tree of an infix expression produces the expression in Polish notation (unreversed) and its breadth-first walk produces the expression in "queue notation" (that is, the desired program for a queue automaton). Isn't it marvelous that traversing a parse tree with a stack container gives you the program for stack-based execution and traversing the same tree with a queue container gives you the program for queue-based execution?
</p><p>I feel that there is something deep behind this. <a href="https://en.wikipedia.org/wiki/Alexander_Stepanov">A. Stepanov</a> had an intuition (which cost him <a href="http://www.stlport.org/resources/StepanovUSA.html">dearly</a>) that <em>algorithms are defined on algebraic structures</em>. Elegant interconnection between queues and stacks on one hand and tree-walks and automaton programs on the other, tells us that the correspondence between algorithms and structures goes in both directions.

</p></div></div>]]>
            </description>
            <link>http://www.cofault.com/2020/11/a-curious-case-of-stacks-and-queues.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056603</guid>
            <pubDate>Wed, 11 Nov 2020 08:36:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Container Queries are coming to Chromium]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056551">thread link</a>) | @LorenzA
<br/>
November 11, 2020 | https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com | <a href="https://web.archive.org/web/*/https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div id="primary">
<main id="main">
<article id="post-25159">

<div>
<p><img loading="lazy" src="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png" alt="" width="2024" height="880" srcset="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png 2024w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-560x243.png 560w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1120x487.png 1120w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-768x334.png 768w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1536x668.png 1536w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1568x682.png 1568w" sizes="(max-width: 2024px) 100vw, 2024px" data-old-src="https://www.bram.us/wordpress/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png" data-srcset="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png 2024w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-560x243.png 560w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1120x487.png 1120w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-768x334.png 768w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1536x668.png 1536w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1568x682.png 1568w"></p>
<p>Just <a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/u1AKdrXhPGI/m/wrJb-unhAgAJ">announced</a> on the Chromium mailing list is an <a href="https://www.chromium.org/blink/launching-features">“Intent to Prototype”</a> Container Queries, which is quite exciting news 🎉</p>
<details>
<summary>🤔 Container Queries?</summary>
<p>Container Queries allow authors to style elements according to the size of a container. This is similar to a @media query, except that it evaluates against a container instead of the viewport.</p>
</details>
<p>The experimental implementation will follow <a href="https://gist.github.com/mirisuzanne/748169312f110d6246e092945673b16e">Miriam Suzanne’s proposal</a>, which looks like this:</p>
<pre><code>main,
aside {
  contain: size; /* (1) Create an implicit "container root" or "containment context" */
}

.media-object {
  display: grid;
  gap: 1em;
}

@container (max-width: 45em) { /* (2) When the nearest `contain: size` ancestor has a max-width of 45em … */
  .media-object { /* … apply these rules onto .media-object */
    grid-template: 'img content' auto / auto 1fr;
  }
}</code></pre>
<p>Using <code>contain: size</code> <em>(1)</em> will create an implicit “container root” or “containment context” on that element. Elements contained inside it can then have container queries applied onto them, by use of a new at-rule <code>@container (<em>&lt;container-media-query&gt;</em>)</code> <em>(2)</em>. The target selector and CSS rules to apply in that case are nested within the <code>@container</code> at-rule, just like we already do with other at-rules.</p>
<p>In the example above extra rules will be applied to <code>.media-object</code> whenever its nearest ancestor with size containment set — such as <code>&lt;main&gt;</code> or <code>&lt;aside&gt;</code> — has a <code>max-width</code> of <code>45em</code>.</p>
<p>~</p>
<p>A <a href="https://github.com/dbaron/container-queries-implementability#proposal">previous version of this proposal by L. David Baron</a> required a context selector to be set, but that has been dropped here. The <code>@container</code> rule from Miriam’s version will work in any containment context <em>(read: the nearest parent element that has <code>contain: size</code> set)</em>. The syntax might still change, but that’s irrelevant to the prototype which is to be implemented:</p>
<blockquote><p>This is not at all finalized, but the underlying problems we need to solve in Blink are (mostly) the same regardless of how the feature is accessed, so we’ll for now use this proposal as the temporary syntax.</p></blockquote>
<p>~</p>
<p><a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/u1AKdrXhPGI/m/wrJb-unhAgAJ">Intent to Prototype: Container Queries →</a><br><a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1145970">Chrome Tracking Bug →</a></p>
<div>
<p><b>Did this help you out? Like what you see?<br>Thank me with a coffee.</b></p><p>I don't do this for profit but a small one-time donation would always put a smile on my face. Thanks!</p>
<p><a href="https://www.paypal.me/bramus/3EUR">☕️ Buy me a Coffee <em>(€3)</em></a></p>
</div>
</div>

<div>

<p>
Bramus is a Freelance Web Developer from Belgium. From the moment he discovered view-source at the age of 14 <em>(way back in 1997)</em>, he fell in love with the web and has been tinkering with it ever since <i><a href="https://www.bram.us/about">(more …)</a></i> <a href="https://www.bram.us/author/bramus/" rel="author">
View more posts </a>
</p>
</div>
</article>
<nav role="navigation" aria-label="Posts">
<h2>Post navigation</h2>

</nav>

</main>
</div>
</div></div>]]>
            </description>
            <link>https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056551</guid>
            <pubDate>Wed, 11 Nov 2020 08:28:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Back to C# basics: Difference between “=” and “{ get; } =” for properties]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056344">thread link</a>) | @cincura_net
<br/>
November 10, 2020 | https://www.tabsoverspaces.com/id/233844 | <a href="https://web.archive.org/web/*/https://www.tabsoverspaces.com/id/233844">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<h3>Back to C# basics: Difference between "=&gt;" and "{ get; } =" for properties <a href="https://www.tabsoverspaces.com/id/233844" rel="bookmark nofollow" title="Permalink"><span aria-label="Permalink"></span></a></h3>
	<p>
	<span aria-label="Published"></span> 11 Nov 2020
	<span></span>
	<span aria-label="Time to read"></span> 1 mins
	<span></span>
	<span aria-label="Tags"></span> .NET
</p>
<p>I recently realized, the difference between <code>=&gt;</code> and <code>{ get; } =</code> for properties might not be as known as everybody thinks, based on code I saw multiple times.</p>
<!-- excerpt --> 
<p>Here’s an example code.</p>
<pre><code>public class C
{
	public Foo A { get; } = new Foo();
	public Foo B =&gt; new Foo();
}
</code></pre>
<p>Is it the same or is it not? The answer is, it’s not the same. The <code>A</code> property is property with <em>getter</em> only (aka read only or immutable property). When <code>C</code> instance is created a new instance of <code>Foo</code> is assigned to the property and will be returned from now on. The <code>B</code> property defines also only <em>getter</em>, but this time the <em>getter</em> contains the <code>new Foo();</code> as it’s body, aka returning new instance of <code>Foo</code> every time you access <code>B</code>.</p>
<p>Putting it into barebone C#, it would look like this.</p>
<pre><code>public class C
{
	readonly Foo _a = new Foo();
	
	public Foo A
	{
		get { return _a; }
	}

	public Foo B
	{
		get { return new Foo(); }
	}
}
</code></pre>
<p>Makes sense?</p>

</article><article>
	<p>
		<a href="https://www.tabsoverspaces.com/about"><img src="https://www.tabsoverspaces.com/assets/bio_image.png" alt="Profile Picture"></a>
		Jiří Činčura is an independent developer focusing on data and business layers, language constructs, parallelism and databases. Specifically Entity Framework, asynchronous and parallel programming, cloud and Azure. He's Microsoft Most Valuable Professional and you can read his articles, guides, tips and tricks at www.tabsoverspaces.com.
	</p>
</article></div>]]>
            </description>
            <link>https://www.tabsoverspaces.com/id/233844</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056344</guid>
            <pubDate>Wed, 11 Nov 2020 07:47:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cell Signaling Technologies – Detailed 3D model of human cells]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25055908">thread link</a>) | @ozten
<br/>
November 10, 2020 | http://www.digizyme.com/cst_landscapes.html | <a href="https://web.archive.org/web/*/http://www.digizyme.com/cst_landscapes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="u6389-bw">
     <div id="u6389"><!-- column -->
      <div id="u6389_align_to_page">
       <!-- m_editable region-id="editable-static-tag-U6264-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p><span id="u6264">Cell Signaling Technologies</span></p>
       <!-- /m_editable -->
       <!-- m_editable region-id="editable-static-tag-U6399-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p>Molecular Landscapes</p>
       <!-- /m_editable -->
       
       
       
      </div>
     </div>
    </div></div>]]>
            </description>
            <link>http://www.digizyme.com/cst_landscapes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055908</guid>
            <pubDate>Wed, 11 Nov 2020 06:02:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dive into BPF: a list of reading material]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055866">thread link</a>) | @moks
<br/>
November 10, 2020 | https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/ | <a href="https://web.archive.org/web/*/https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<ul id="markdown-toc">
  <li><a href="#what-is-bpf" id="markdown-toc-what-is-bpf">What is BPF?</a></li>
  <li><a href="#dive-into-the-bytecode" id="markdown-toc-dive-into-the-bytecode">Dive into the bytecode</a></li>
  <li><a href="#resources" id="markdown-toc-resources">Resources</a>    <ul>
      <li><a href="#generic-presentations" id="markdown-toc-generic-presentations">Generic presentations</a>        <ul>
          <li><a href="#about-bpf" id="markdown-toc-about-bpf">About BPF</a></li>
          <li><a href="#about-xdp" id="markdown-toc-about-xdp">About XDP</a></li>
          <li><a href="#about-other-components-related-or-based-on-ebpf" id="markdown-toc-about-other-components-related-or-based-on-ebpf">About other components related or based on eBPF</a></li>
        </ul>
      </li>
      <li><a href="#documentation" id="markdown-toc-documentation">Documentation</a>        <ul>
          <li><a href="#about-bpf-1" id="markdown-toc-about-bpf-1">About BPF</a></li>
          <li><a href="#about-tc" id="markdown-toc-about-tc">About tc</a></li>
          <li><a href="#about-xdp-1" id="markdown-toc-about-xdp-1">About XDP</a></li>
          <li><a href="#about-flow-dissectors" id="markdown-toc-about-flow-dissectors">About flow dissectors</a></li>
          <li><a href="#about-p4-and-bpf" id="markdown-toc-about-p4-and-bpf">About P4 and BPF</a></li>
        </ul>
      </li>
      <li><a href="#tutorials" id="markdown-toc-tutorials">Tutorials</a></li>
      <li><a href="#examples" id="markdown-toc-examples">Examples</a>        <ul>
          <li><a href="#from-the-kernel" id="markdown-toc-from-the-kernel">From the kernel</a></li>
          <li><a href="#from-package-iproute2" id="markdown-toc-from-package-iproute2">From package iproute2</a></li>
          <li><a href="#from-bcc-set-of-tools" id="markdown-toc-from-bcc-set-of-tools">From bcc set of tools</a></li>
          <li><a href="#other-examples" id="markdown-toc-other-examples">Other examples</a></li>
          <li><a href="#manual-pages" id="markdown-toc-manual-pages">Manual pages</a></li>
        </ul>
      </li>
      <li><a href="#the-code" id="markdown-toc-the-code">The code</a>        <ul>
          <li><a href="#bpf-code-in-the-kernel" id="markdown-toc-bpf-code-in-the-kernel">BPF code in the kernel</a></li>
          <li><a href="#xdp-hooks-code" id="markdown-toc-xdp-hooks-code">XDP hooks code</a></li>
          <li><a href="#bpf-logic-in-bcc" id="markdown-toc-bpf-logic-in-bcc">BPF logic in bcc</a></li>
          <li><a href="#code-to-manage-bpf-with-tc" id="markdown-toc-code-to-manage-bpf-with-tc">Code to manage BPF with tc</a></li>
          <li><a href="#bpf-utilities" id="markdown-toc-bpf-utilities">BPF utilities</a></li>
          <li><a href="#other-interesting-chunks" id="markdown-toc-other-interesting-chunks">Other interesting chunks</a></li>
          <li><a href="#llvm-backend" id="markdown-toc-llvm-backend">LLVM backend</a></li>
          <li><a href="#running-in-userspace" id="markdown-toc-running-in-userspace">Running in userspace</a></li>
          <li><a href="#commit-logs" id="markdown-toc-commit-logs">Commit logs</a></li>
        </ul>
      </li>
      <li><a href="#troubleshooting" id="markdown-toc-troubleshooting">Troubleshooting</a>        <ul>
          <li><a href="#errors-at-compilation-time" id="markdown-toc-errors-at-compilation-time">Errors at compilation time</a></li>
          <li><a href="#errors-at-load-and-run-time" id="markdown-toc-errors-at-load-and-run-time">Errors at load and run time</a></li>
        </ul>
      </li>
      <li><a href="#and-still-more" id="markdown-toc-and-still-more">And still more!</a></li>
    </ul>
  </li>
</ul>

<p><em>~ <a href="https://github.com/qmonnet/whirl-offload/commits/gh-pages/_posts/2016-09-01-dive-into-bpf.md">Updated</a> 2019-01-10 ~</em></p>



<p>BPF, as in <strong>B</strong>erkeley <strong>P</strong>acket <strong>F</strong>ilter, was initially conceived in 1992
so as to provide a way to filter packets and to avoid useless packet copies
from kernel to userspace. It initially consisted in a simple bytecode that is
injected from userspace into the kernel, where it is checked by a verifier—to
prevent kernel crashes or security issues—and attached to a socket, then run on
each received packet. It was ported to Linux a couple of years later, and used
for a small number of applications (tcpdump for example). The simplicity of the
language as well as the existence of an in-kernel Just-In-Time (JIT) compiling
machine for BPF were factors for the excellent performances of this tool.</p>

<p>Then in 2013, Alexei Starovoitov completely reshaped it, started to add new
functionalities and to improve the performances of BPF. This new version is
designated as eBPF (for “extended BPF”), while the former becomes cBPF
(“classic” BPF). New features such as maps and tail calls appeared. The JIT
machines were rewritten. The new language is even closer to native machine
language than cBPF was. And also, new attach points in the kernel have been
created.</p>

<p>Thanks to those new hooks, eBPF programs can be designed for a variety of use
cases, that divide into two fields of applications. One of them is the domain
of kernel tracing and event monitoring. BPF programs can be attached to kprobes
and they compare with other tracing methods, with many advantages (and
sometimes some drawbacks).</p>

<p>The other application domain remains network programming. In addition to socket
filter, eBPF programs can be attached to tc (Linux traffic control tool)
ingress or egress interfaces and perform a variety of packet processing tasks,
in an efficient way. This opens new perspectives in the domain.</p>

<p>And eBPF performances are further leveraged through the technologies developed
for the IO Visor project: new hooks have also been added for XDP (“eXpress Data
Path”), a new fast path recently added to the kernel. XDP works in conjunction
with the Linux stack, and relies on BPF to perform very fast packet processing.</p>

<p>Even some projects such as P4, Open vSwitch,
<a href="http://openvswitch.org/pipermail/ovs-dev/2014-October/047421.html">consider</a>
or started to approach BPF. Some others, such as CETH, Cilium, are entirely
based on it. BPF is buzzing, so we can expect a lot of tools and projects to
orbit around it soon…</p>



<p>As for me: some of my work (including for
<a href="https://qmonnet.github.io/whirl-offload/2016/07/15/beba-research-project/">BEBA</a>)
is closely related to eBPF, and several future articles on this site will focus
on this topic. Logically, I wanted to somehow introduce BPF on this blog before
going down to the details—I mean, a real introduction, more developed on BPF
functionalities that the brief abstract provided in first section: What are BPF
maps? Tail calls? What do the internals look like? And so on. But there are a
lot of presentations on this topic available on the web already, and I do not
wish to create “yet another BPF introduction” that would come as a duplicate of
existing documents.</p>

<p>So instead, here is what we will do. After all, I spent some time reading and
learning about BPF, and while doing so, I gathered a fair amount of material
about BPF: introductions, documentation, but also tutorials or examples. There
is a lot to read, but in order to read it, one has to <em>find</em> it first.
Therefore, as an attempt to help people who wish to learn and use BPF, the
present article introduces a list of resources. These are various kinds of
readings, that hopefully will help you dive into the mechanics of this kernel
bytecode.</p>



<figure>
  <img src="https://qmonnet.github.io/whirl-offload/img/icons/pic.svg">
</figure>

<h2 id="generic-presentations">Generic presentations</h2>

<p>The documents linked below provide a generic overview of BPF, or of some
closely related topics. If you are very new to BPF, you can try picking a
couple of presentation among the first ones and reading the ones you like most.
If you know eBPF already, you probably want to target specific topics instead,
lower down in the list.</p>

<h3 id="about-bpf">About BPF</h3>

<p>Generic presentations about eBPF:</p>

<ul>
  <li>
    <p><a href="https://blogs.igalia.com/dpino/2019/01/07/introduction-to-xdp-and-ebpf/"><em>A brief introduction to XDP and eBPF</em></a>
(Diego Pino García, January 2019): <br>
An excellent and accessible introduction providing context, history, and
details about the functioning of eBPF.</p>
  </li>
  <li>
    <p><a href="https://www.redhat.com/en/blog/introduction-ebpf-red-hat-enterprise-linux-7"><em>Introduction to eBPF in Red Hat Enterprise Linux 7</em></a>
(Stanislav Kozina, January 2019): <br>
Focusing on the eBPF features arriving in Red Hat.</p>
  </li>
  <li>
    <p><a href="http://fulvio.frisso.net/files/18HPSR%20-%20eBPF.pdf"><em>Toward Flexible and Efficient In-Kernel Network Function Chaining with IO Visor</em></a>
(Fulvio Risso, HPSR 2018, Bucharest, June 2018): <br>
A generic introduction to BPF, XDP, IO Visor, bcc and other components.</p>
  </li>
  <li>
    <p><a href="https://lwn.net/Articles/740157/"><em>A thorough introduction to eBPF</em></a>
(Matt Flemming, on LWN.net, December 2017): <br>
A well-written and accessible introduction providing an overview of eBPF
subsystem components.</p>
  </li>
  <li>
    <p><a href="http://schd.ws/hosted_files/ossna2017/da/BPFandXDP.pdf"><em>Making the Kernel’s Networking Data Path Programmable with BPF and XDP</em></a>
(Daniel Borkmann, OSSNA17, Los Angeles, September 2017):<br>
One of the best set of slides available to understand quickly all the basics about eBPF and XDP (mostly for network processing).</p>
  </li>
  <li>
    <p><a href="https://speakerdeck.com/tuxology/the-bsd-packet-filter">The BSD Packet Filter</a>
(Suchakra Sharma, June 2017): <br>
A very nice introduction, mostly about the tracing aspects.</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/brendangregg/bpf-tracing-and-more"><em>BPF: tracing and more</em></a>
(Brendan Gregg, January 2017):<br>
Mostly about the tracing use cases.</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/brendangregg/linux-bpf-superpowers"><em>Linux BPF Superpowers</em></a>
(Brendan Gregg, March 2016):<br>
With a first part on the use of <strong>flame graphs</strong>.</p>
  </li>
  <li>
    <p><a href="https://www.socallinuxexpo.org/sites/default/files/presentations/Room%20211%20-%20IOVisor%20-%20SCaLE%2014x.pdf"><em>IO Visor</em></a>
(Brenden Blanco, SCaLE 14x, January 2016):<br>
Also introduces <strong>IO Visor project</strong>.</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/ebpf_on_the_mainframe_lcon_2015.pdf"><em>eBPF on the Mainframe</em></a>
(Michael Holzheu, LinuxCon, Dublin, October 2015)</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/tracing-linux-ezannoni-linuxcon-ja-2015_0.pdf"><em>New (and Exciting!) Developments in Linux Tracing</em></a>
(Elena Zannoni, LinuxCon, Japan, 2015)</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/bpf_collabsummit_2015feb20.pdf"><em>BPF — in-kernel virtual machine</em></a>
(Alexei Starovoitov, February 2015):<br>
Presentation by the author of eBPF.</p>
  </li>
  <li>
    <p><a href="https://lwn.net/Articles/603983/"><em>Extending extended BPF</em></a>
(Jonathan Corbet, July 2014)</p>
  </li>
</ul>

<p><strong>BPF internals</strong>:</p>

<ul>
  <li>Daniel Borkmann has been doing an amazing work to present <strong>the internals</strong> of eBPF, in particular about <strong>its use with tc</strong>, through several talks and papers.
    <ul>
      <li><a href="http://netdevconf.org/1.2/session.html?daniel-borkmann"><em>Advanced programmability and recent updates with tc’s cls_bpf</em></a>
(netdev 1.2, Tokyo, October 2016):<br>
Daniel provides details on eBPF, its use for tunneling and encapsulation,
direct packet access, and other features.</li>
      <li><a href="http://netdevconf.org/1.2/slides/oct5/07_tcws_daniel_borkmann_2016_tcws.pdf"><em>cls_bpf/eBPF updates since netdev 1.1</em></a>
(netdev 1.2, Tokyo, October 2016, part of
<a href="http://netdevconf.org/1.2/session.html?jamal-tc-workshop">this tc workshop</a>)</li>
      <li><a href="http://www.netdevconf.org/1.1/proceedings/slides/borkmann-tc-classifier-cls-bpf.pdf"><em>On getting tc classifier fully programmable with cls_bpf</em></a>
(netdev 1.1, Sevilla, February 2016):<br>
After introducing eBPF, this presentation provides insights on many
internal BPF mechanisms (map management, tail calls, verifier). A
must-read! For the most ambitious,
<a href="http://www.netdevconf.org/1.1/proceedings/papers/On-getting-tc-classifier-fully-programmable-with-cls-bpf.pdf">the full paper is available here</a>.</li>
      <li><a href="https://archive.fosdem.org/2016/schedule/event/ebpf/attachments/slides/1159/export/events/attachments/ebpf/slides/1159/ebpf.pdf"><em>Linux tc and eBPF</em></a>
(fosdem16, Brussels, Belgium, January 2016)</li>
      <li><a href="https://fosdem.org/2017/schedule/event/ebpf_xdp/"><em>eBPF and XDP walkthrough and recent updates</em></a>
(fosdem17, Brussels, Belgium, February 2017)</li>
    </ul>

    <p>These presentations are probably one of the best sources of documentation to
understand the design and implementation of internal mechanisms of eBPF.</p>
  </li>
</ul>

<p>The <a href="https://www.iovisor.org/resources/blog"><strong>IO Visor blog</strong></a> has some
interesting technical articles about BPF. Some of them contain a bit of
marketing talks.</p>

<p>As of early 2019, there are more and more presentations being done around
multiple aspects of BPF. One nice example is
<a href="http://vger.kernel.org/lpc-bpf.html">the BPF track</a> that was held in parallel
to the Linux Plumbers Conference in late 2018 (and should be held again on
coming years), where lots of topics related to eBPF development or use cases
were presented.</p>

<p><strong>Kernel tracing</strong>: summing up all existing methods, including BPF:</p>

<ul>
  <li>
    <p><a href="http://www.slideshare.net/vh21/meet-cutebetweenebpfandtracing"><em>Meet-cute between eBPF and Kerne Tracing</em></a>
(Viller Hsiao, July 2016):<br>
Kprobes, uprobes, ftrace</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/vh21/linux-kernel-tracing"><em>Linux Kernel Tracing</em></a>
(Viller Hsiao, July 2016):<br>
Systemtap, Kernelshark, trace-cmd, LTTng, perf-tool, ftrace, hist-trigger,
perf, function tracer, tracepoint, kprobe/uprobe…</p>
  </li>
</ul>

<p>Regarding <strong>event tracing and monitoring</strong>, Brendan Gregg uses eBPF a lot and
does an excellent job at documenting some of his use cases. If you are in
kernel tracing, you should see his blog articles related to eBPF or to flame
graphs. Most of it are accessible
<a href="http://www.brendangregg.com/blog/2016-03-05/linux-bpf-superpowers.html">from this article</a>
or by browsing his blog.</p>

<p>Introducing BPF, but also presenting <strong>generic concepts of Linux networking</strong>:</p>

<ul>
  <li>
    <p><a href="http://www.slideshare.net/ThomasGraf5/linux-networking-explained"><em>Linux Networking Explained</em></a>
(Thomas Graf, LinuxCon, Toronto, August 2016)</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/ThomasGraf5/linuxcon-2015-linux-kernel-networking-walkthrough"><em>Kernel Networking Walkthrough</em></a>
(Thomas Graf, LinuxCon, Seattle, August 2015)</p>
  </li>
</ul>

<p><strong>Hardware offload</strong>:</p>

<ul>
  <li>eBPF with tc or XDP supports hardware offload, starting with Linux kernel
version 4.9 and introduced by Netronome. Here is a presentation about this
feature:<br>
<a href="http://netdevconf.org/1.2/session.html?jakub-kicinski">eBPF/XDP hardware offload to SmartNICs</a>
(Jakub Kicinski and Nic Viljoen, netdev 1.2, Tokyo, October 2016)</li>
  <li>An updated version was presented on year later:<br>
<a href="https://www.netdevconf.org/2.2/session.html?viljoen-xdpoffload-talk">Comprehensive XDP offload—Handling the edge cases</a>
(Jakub Kicinski and Nic Viljoen, netdev 2.2, Seoul, November 2017)</li>
  <li>I presented a shorter but updated version at FOSDEM 2018:<br>
<a href="https://fosdem.org/2018/schedule/event/xdp/">The Challenges of XDP Hardware Offload</a>
(Quentin Monnet, FOSDEM’18, Brussels, February 2018)</li>
</ul>

<p>About <strong>cBPF</strong>:</p>

<ul>
  <li>
    <p><a href="http://www.tcpdump.org/papers/bpf-usenix93.pdf"><em>The BSD Packet Filter: A New Architecture for User-level Packet Capture</em></a>
(Steven McCanne and Van Jacobson, 1992):<br>
The original paper about (classic) BPF.</p>
  </li>
  <li>
    <p><a href="http://www.gsp.com/cgi-bin/man.cgi?topic=bpf">The FreeBSD manual page about BPF</a>
is a useful resource to understand cBPF programs.</p>
  </li>
  <li>
    <p>Daniel Borkmann realized at least two presentations on cBPF,
<a href="http://borkmann.ch/talks/2013_devconf.pdf">one in 2013 on mmap, BPF and Netsniff-NG</a>, and
<a href="http://borkmann.ch/talks/2014_devconf.pdf">a very complete one in 2014 on tc and cls_bpf</a>.</p>
  </li>
  <li>
    <p>On Cloudflare’s blog, Marek Majkowski presented his
<a href="https://blog.cloudflare.com/introducing-the-bpf-tools/">use of BPF bytecode with the <code>xt_bpf</code> module for <strong>iptables</strong></a>.
It is worth mentioning that eBPF is also supported by this module, starting
with Linux kernel 4.10 (I do not know of …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/">https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/</a></em></p>]]>
            </description>
            <link>https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055866</guid>
            <pubDate>Wed, 11 Nov 2020 05:51:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personal epistemology, free speech, and tech companies]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25055742">thread link</a>) | @jseliger
<br/>
November 10, 2020 | https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies | <a href="https://web.archive.org/web/*/https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
						<p>The NYT describes “<a href="https://www.nytimes.com/2020/10/13/magazine/free-speech.html">The Problem of Free Speech in an Age of Disinformation</a>, and in response Hacker News commenter <a href="https://news.ycombinator.com/item?id=24813749">throwaway13337</a> says, in part, “It’s not unchecked free speech. Instead, it’s unchecked curation by media and social media companies with the goal of engagement.” There’s some truth to the idea that social media companies have evolved to seek engagement, rather than truth, but I think the social media companies are reflecting a deeper human tendency. I wrote back to throwaway13337: “Try teaching non-elite undergrads, and particularly assignments that require some sense of epistemology, and you’ll discover that the vast majority of people have pretty poor personal epistemic hygiene—it’s not much required in most people, most of the time, in most jobs.”</p>
<p>From what I can tell, we evolved to form tribes, not to be “right:” Jonathan’s Haidt’s <a href="https://jakeseliger.com/2012/03/25/jonathan-haidts-the-righteous-mind-and-what-were-really-arguing-about/"><em>The Righteous Mind: Why Good People Are Divided by Politics and Religion</em></a> deals with this topic well and at length, and I’ve not seen any substantial rebuttals of it. We don’t naturally take to tracking the question, “How do I know what I know?” Instead, we naturally seem to want to find “facts” or ideas that support our preexisting views. In the HN comment thread, someone asked for specific examples of poor undergrad epistemic hygiene, and while I’d prefer not to get super specific for reasons of privacy, I’ve had many conversations that take the following form: “How do you know article x is accurate?” “Google told me.” “How does Google work?” “I don’t know.” “What does it take to make a claim on the Internet.” “Um. A phone, I guess?” A lot of people—maybe most—will uncritically take as fact whatever happens to be served up by Google (it’s always Google and never Duck Duck Go or Bing), and most undergrads whose work I’ve read will, again uncritically, accept clickbait sites and similar as accurate. Part of the reason for this reasoning is that undergrads’s lives are minimally affected by being wrong or incomplete about some claim done in a short assignment that’s being imposed by some annoying professor toff standing between them and their degree.</p>
<p>The gap between elite information discourse and everyday information discourse, even among college students, who may be more sophisticated than their peer equivalents, is vast—so vast that I don’t think most journalists (who mostly talk to other journalists and to experts) and to other people who work with information, data, and ideas really truly understand it. We’re all living in bubbles. I don’t think I did, either, before I saw the epistemic hygiene most undergrads practice, or don’t practice. This is not a “kids these days” rant, either: many of them have never really been taught to ask themselves, “How do I know what I know?” Many have never really learned anything about the scientific method. It’s not happening much in most non-elite schools, so where are they going to get epistemic hygiene from?</p>
<p>The United States alone has 320 million people in it. Table DP02 in the Census at data.census.gov estimates that 20.3% of the population age 25 and older has a college bachelor’s degree, and 12.8% have a graduate or professional degree. Before someone objects, let me admit that a college degree is far from a perfect proxy for epistemic hygiene or general knowledge, and some high school dropouts perform much better at cognition, meta cognition, statistical reasoning, and so forth, than do some people with graduate degrees. With that said, though, a college degree is probably a decent approximation for baseline abstract reasoning skills and epistemic hygiene.</p>
<p>Almost anyone who wants a megaphone in the form of one of the many social media platforms available now has one. The number of people motivated by questions like “What is really true, and how do I discern what is really true? How do I enable myself to get countervailing data and information into my view, or worldview, or worldviews?” is not zero, again obviously, but it’s not a huge part of the population. And many very “smart” people in an IQ sense use their intelligence to build better rationalizations, rather than to seek truth (and I may be among the rationalizers: I’m not trying to exclude myself from that category).</p>
<p>Until relatively recently, almost everyone with a media megaphone had some kind of training or interest in epistemology, even they didn’t call it “epistemology.” Editors would ask, “How do you know that?” or “Who told you that?” or that sort of thing. Professors have systems that are supposed to encourage greater-than-average epistemic hygiene (again: these systems were not and are not perfect, and nothing I have written so far implies that they were or are).</p>
<p>Most people don’t care about the question, “How do you know what you know?” and they’ll be fairly surprised if it’s asked, implicitly or explicitly. Some people are intrigued by it but most aren’t, and view questions about sources and knowledge to be a hindrance. This is less likely to be true of people who aspire to be researchers or work in other knowledge-related professions, but that describes only a small percentage of undergraduates, particularly at non-elite schools. And the “elite schools” thing drives a lot of the media discourse around education. One of the things I like about Professor X’s book <a href="https://jakeseliger.com/2011/06/10/summary-judgement-in-the-basement-of-the-ivory-tower-confessions-of-an-accidental-academic-professor-x/"><em>In the Basement of the Ivory Tower</em></a> is how it functions as a corrective to that discourse.</p>
<p>For most people, floating a factually incorrect conspiracy theory online isn’t going to negatively affect their lives. If someone is a nurse and gives a patient a wrong medication or incorrect medication, that person is not going to be a nurse for long. If the nurse states or repeats a factually incorrect political or social idea online, particularly but not exclusively under a pseudonym, that nurse’s life likely won’t be affected. There’s no truth feedback loop. The same is true for someone working in, say, construction, or engineering, or many other fields. The person is free to state things that are factually incorrect, or incomplete, or misleading, and doing so isn’t going to have many negative consequences. Maybe it will have some positive consequences: one way to show that you’re really on team x is to state or repeat falsehoods that show you’re on team x, rather than on team “What is really true?”</p>
<p>I don’t want to get into daily political discourse, since that tends to raise defenses and elicit anger, but the last eight months have demonstrated many people’s problems with epistemology, and in a way that can have immediate, negative personal consequences—but not for everyone.</p>
<p><a href="https://www.pewresearch.org/fact-tank/2019/09/26/who-doesnt-read-books-in-america/">Pew Research data indicate that a quarter of US adults didn’t read a book in 2018</a>; this is consistent with <a href="https://www.newyorker.com/magazine/2007/12/24/twilight-of-the-books">other data</a> indicating that about half of US adults read zero or one books per year. Again, yes, there are surely many individuals who read other materials and have excellent epistemic hygiene, but this is a reasonable mass proxy, given the demands that reading makes on us.</p>
<p>Many people driving the (relatively) elite discourse don’t realize how many people are not only not like them, but wildly not like them, along numerous metrics. It may also be that <a href="http://www.arnoldkling.com/blog/gossip-at-scale/">we don’t know how to deal with gossip at scale</a>. Interpersonal gossip is all about personal stories, while many problems at scale are best understood through data—but the number of people deeply interested in data and data’s veracity is small. And elite discourse has some of its own possible epistemic falsehoods, or at least uncertainties, embedded within it: some of the populist rhetoric against elites is rooted in truth.</p>
<p>We are all caught in our bubble, and the universe of people is almost unimaginably larger than the number of people in our bubble. If you got this far, you’re probably in a nerd bubble: usually, anything involving the word “epistemology” sends people to sleep or, alternately, scurrying for something like “You won’t believe what this celebrity wore/said/did” instead. Almost no one wants to consider epistemology; to do so as a hobby is rare. One person’s disinformation is another person’s teambuilding. If you think the preceding sentence is in favor of disinformation, by the way, it’s not.</p>
					</div><!-- .entry-content -->
	</div></div>]]>
            </description>
            <link>https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055742</guid>
            <pubDate>Wed, 11 Nov 2020 05:28:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Foundation for securing communications plane of CPS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055601">thread link</a>) | @takko_the_boss
<br/>
November 10, 2020 | https://mikecurnow.com/csis_introduction/ | <a href="https://web.archive.org/web/*/https://mikecurnow.com/csis_introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mikecurnow.com/csis_introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055601</guid>
            <pubDate>Wed, 11 Nov 2020 04:53:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Business ideas (from my first million podcast)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055308">thread link</a>) | @micropoet
<br/>
November 10, 2020 | https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553 | <a href="https://web.archive.org/web/*/https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055308</guid>
            <pubDate>Wed, 11 Nov 2020 03:46:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning a New Language While Browsing the Web]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25055257">thread link</a>) | @rahulchowdhury
<br/>
November 10, 2020 | https://hulry.com/toucan-learn-language/ | <a href="https://web.archive.org/web/*/https://hulry.com/toucan-learn-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
<p>Around 2015, I picked up a hobby of learning a new language — Spanish.</p>



<p>However, after a few months of dedicated learning time, I couldn’t get myself to stick to the hobby.</p>



<p>I had other things to work on, and learning a language was not my priority.</p>



<p>But things have changed now.</p>



<p>In this post, I’ll talk about how I’m learning a bit of Spanish every single day using a new language learning tool called <a href="https://jointoucan.com/" target="_blank" rel="noreferrer noopener">Toucan</a>.</p>



<p>Let’s get started with:</p>



<h2>My experience with various language-learning apps</h2>



<p>I started my Spanish learning journey with the most popular language-learning app — <a href="https://www.duolingo.com/" target="_blank" rel="noreferrer noopener nofollow">Duolingo</a>.</p>



<p>While it was fun initially, I soon found myself missing practice days.</p>



<p>As time passed by, the gap widened. And soon enough, I stopped my Spanish sessions.</p>



<p>In the last few years, I’ve tried to rekindle the Spanish spark in me and continue learning with Duolingo. Still, I never succeeded in sticking to the classes.</p>



<p>Then came <a href="https://www.babbel.com/" target="_blank" rel="noreferrer noopener nofollow">Babbel</a>.</p>



<p>While I must say that Babbel has a better course in terms of learning proper grammar and dialects, it had the same problem as Duolingo:</p>



<p>It was hard for me to dedicate time from my schedule for learning sessions.</p>



<p>My only motivation for learning Spanish was to expand my skill set.</p>



<p>Since I’m not moving to a Spanish speaking country anytime soon, I didn’t feel the need to prioritise this hobby.</p>



<p>But then:</p>



<p>A few months ago, I spotted a new <a href="https://chrome.google.com/webstore/detail/toucan/lokjgaehpcnlmkebpmjiofccpklbmoci" target="_blank" rel="noreferrer noopener nofollow">Chrome extension called Toucan</a>. Around the same time, a similar extension launched called <a href="https://www.usefluent.co/" target="_blank" rel="noreferrer noopener">Fluent</a>.</p>



<p>The key selling point of these new extensions was to learn a new language while browsing the web.</p>



<p>You don’t need to dedicate time for picking up a new language. Club the learning sessions, along with activities we do every day — browsing the web and reading articles online.</p>



<p>After a quick test ride, here’s:</p>



<h2>Why I find language learning extensions interesting</h2>



<p>The first and most immense value — habit bundling.</p>



<p>I had previously talked about how I <a href="https://hulry.com/building-podcasts-habit/" target="_blank" rel="noreferrer noopener">clubbed my habit</a> of making tea every morning with listening to podcasts.</p>



<p>I saw a similar opportunity with these browser extensions.</p>



<p>The biggest hurdle for me in learning Spanish was making time for classes.</p>



<p>Now:</p>



<p>I don’t need to dedicate time out of my daily routine to learn a new language.</p>



<p>I browse and read lots of articles online. With Toucan or Fluent, I can learn and practice Spanish every time I read stuff online.</p>



<p>Here’s:</p>



<h2>How Toucan and Fluent work</h2>



<p>Install Toucan or Fluent, and browse the web as you’d typically do.</p>



<p>These extensions will translate and highlight some words from the page content into the language you’ve chosen.</p>



<p>Hovering over the highlighted word will bring up a popup card like this:</p>



<div><figure><img data-attachment-id="943" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-demo/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=1646%2C742&amp;ssl=1" data-orig-size="1646,742" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-demo" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=300%2C135&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=1024%2C462&amp;ssl=1" loading="lazy" width="1024" height="462" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1" alt="Toucan translating and showing up a word on Instapaper." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=300%2C135&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=768%2C346&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1536%2C692&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1200%2C541&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?w=1646&amp;ssl=1 1646w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=300%2C135&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=768%2C346&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1536%2C692&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1200%2C541&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?w=1646&amp;ssl=1 1646w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan translating and showing up a word on Instapaper.</figcaption></figure></div>



<p>Pretty neat. Right?</p>



<p>Apart from the convenience, another thing I like is that the translations are beautifully blended into the content.</p>



<p>For example, from the above screenshot, you can see Toucan seamlessly translated and blended the English word “event” into its Spanish counterpart — evento.</p>



<p>While reading an article, I can see a mixture of English and the language I want to learn.</p>



<p>To know more about the translated word, I can hover on it and Toucan will show me the word in English, with its definition.</p>



<p>I’ve tried both Toucan and Fluent on multiple websites, and they seem to blend in translations flawlessly with the page’s design.</p>



<p>Here’s an article on Forbes with Toucan translations:</p>



<div><figure><img data-attachment-id="947" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-forbes/" data-orig-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=1474%2C814&amp;ssl=1" data-orig-size="1474,814" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-forbes" data-image-description="" data-medium-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=300%2C166&amp;ssl=1" data-large-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=1024%2C565&amp;ssl=1" loading="lazy" width="1024" height="565" src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1" alt="Toucan translating words from an article on Forbes." srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=300%2C166&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=768%2C424&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1200%2C663&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?w=1474&amp;ssl=1 1474w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=300%2C166&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=768%2C424&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1200%2C663&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?w=1474&amp;ssl=1 1474w" data-lazy-src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan translating words from an article on Forbes.</figcaption></figure></div>



<p>Now:</p>



<p>Fluent, however, has a more targeted highlighting than Toucan. </p>



<p>If you’re using Fluent, it’ll highlight words with different colour based on gender.</p>



<div><figure><img data-attachment-id="983" data-permalink="https://hulry.com/toucan-learn-language/fluent-colour-highlights/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=1596%2C508&amp;ssl=1" data-orig-size="1596,508" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fluent-colour-highlights" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=300%2C95&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=1024%2C326&amp;ssl=1" loading="lazy" width="1024" height="326" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1" alt="Fluent highlighting words with a different colour." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=768%2C244&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1200%2C382&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?w=1596&amp;ssl=1 1596w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=768%2C244&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1200%2C382&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?w=1596&amp;ssl=1 1596w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Fluent highlighting words with a different colour.</figcaption></figure></div>



<p>In the paragraph shown above, Fluent highlighted the word “derrame” with a yellow tint (because it’s masculine), and “incluso” with a neutral grey-ish colour (because it’s gender-neutral).</p>



<p>That said, here are:</p>



<h2>Some features in Toucan that caught my attention</h2>



<p>Trying out both extensions, I chose to stick with Toucan, mainly due to a couple of subtle features.</p>



<p>The first being:</p>



<h3>Word definitions</h3>



<p>Toucan shows up the definition of a translated word on the hovercard that shows up.</p>



<div><figure><img data-attachment-id="952" data-permalink="https://hulry.com/toucan-learn-language/toucan-word-definition/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=1524%2C632&amp;ssl=1" data-orig-size="1524,632" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-word-definition" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=300%2C124&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=1024%2C425&amp;ssl=1" loading="lazy" width="1024" height="425" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1" alt="Toucan showing a word's definition." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1200%2C498&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?w=1524&amp;ssl=1 1524w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1200%2C498&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?w=1524&amp;ssl=1 1524w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan showing a word’s definition.</figcaption></figure></div>



<p>As a non-native English speaker, this feature is helpful to me. </p>



<p>If I don’t know the meaning of the translated word, I can read the definition on the card.</p>



<p>There’s one caveat though:</p>



<p>Right now, not all words show up a definition. However, the number of words without a description is low.</p>



<p>Also, the team at Toucan promised they are continuously working on adding more words and definitions to the tool.</p>



<p>Therefore, this caveat should no longer exist pretty soon.</p>



<p>Another feature I found helpful is:</p>



<h3>The ability to mark a word as learnt</h3>



<p>The Toucan hovercard has a little checkmark which lets me mark a word as learnt, like this:</p>



<div><figure><img data-attachment-id="958" data-permalink="https://hulry.com/toucan-learn-language/touch-mark-word-done/" data-orig-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=840%2C526&amp;ssl=1" data-orig-size="840,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="touch-mark-word-done" data-image-description="" data-medium-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=300%2C188&amp;ssl=1" data-large-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=840%2C526&amp;ssl=1" loading="lazy" width="840" height="526" src="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?resize=840%2C526&amp;ssl=1" alt="Marking a word as known in Toucan." data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Marking a word as known in Toucan.</figcaption></figure></div>



<p>What this does is it prevents the word from getting translated in future articles or content.</p>



<p>Since I had taken a couple of Spanish lessons in the past, I marked a handful of words as “I know this” and Toucan will leave those words in the source language — English, for me.</p>



<p>Also:</p>



<p>The Toucan team is working on some recommendation magic for this feature.</p>



<p>For example:</p>



<p>Marking the word “coffee” as learnt will set Toucan to translate tricky words like “hot coffee” or “nice coffee” in your future reads.</p>



<p>This is how I’ll be able to calibrate Toucan to show up more complicated words as I progress in my Spanish learning journey. </p>



<p>Now:</p>



<p>Everyone learns at a different pace.</p>



<p>To make it easy to progress comfortably, Toucan allows me to:</p>



<h3>Select language packs for translation</h3>



<p>Instead of being bombarded with a giant index of Spanish words, Toucan allows me to <a href="https://jointoucan.com/dashboard" target="_blank" rel="noreferrer noopener nofollow">select language packs</a> on the dashboard:</p>



<div><figure><img data-attachment-id="962" data-permalink="https://hulry.com/toucan-learn-language/toucan-language-packs/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=1860%2C1182&amp;ssl=1" data-orig-size="1860,1182" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-language-packs" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=300%2C191&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=1024%2C651&amp;ssl=1" loading="lazy" width="1024" height="651" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1" alt="Selecting language packs in Toucan." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=300%2C191&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=768%2C488&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1536%2C976&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1200%2C763&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?w=1860&amp;ssl=1 1860w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=300%2C191&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=768%2C488&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1536%2C976&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1200%2C763&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?w=1860&amp;ssl=1 1860w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Selecting language packs in Toucan.</figcaption></figure></div>



<p>Each language pack has a set of words that Toucan will search for in an article or web page content and translate.</p>



<p>For example, choosing the language pack “Get Around the City” will set Toucan to translate the following English words in the collection to their Spanish counterparts:</p>



<div><figure><img data-attachment-id="964" data-permalink="https://hulry.com/toucan-learn-language/toucan-get-around-city-pack/" data-orig-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=1420%2C834&amp;ssl=1" data-orig-size="1420,834" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-get-around-city-pack" data-image-description="" data-medium-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=1024%2C601&amp;ssl=1" loading="lazy" width="1024" height="601" src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1" alt="Toucan's &quot;Get Around the City&quot; language pack." srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=300%2C176&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=768%2C451&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1200%2C705&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?w=1420&amp;ssl=1 1420w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=300%2C176&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=768%2C451&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1200%2C705&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?w=1420&amp;ssl=1 1420w" data-lazy-src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan’s “Get Around the City” language pack.</figcaption></figure></div>



<p>This feature is beneficial for beginners because we can choose a handful of language packs and start learning.</p>



<p>Once we have mastered the words in the selected packs, we can remove them from our list and move on to more advanced packs.</p>



<p>So, overall, Toucan seems to be a useful tool for learning a language.</p>



<p>But, here’s a burning question:</p>



<h2>Can language extensions be a distraction?</h2>



<p>It depends on the translation density set for the extension.</p>



<p>For example, in Toucan, we can control the number of translations on a page with the following setting:</p>



<div><figure><img data-attachment-id="967" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-frequency/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=1600%2C1158&amp;ssl=1" data-orig-size="1600,1158" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-frequency" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=300%2C217&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=1024%2C741&amp;ssl=1" loading="lazy" width="1024" height="741" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1" alt="Choosing a translation density in Toucan." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=300%2C217&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=768%2C556&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1536%2C1112&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1200%2C869&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=300%2C217&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=768%2C556&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1536%2C1112&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1200%2C869&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Choosing a translation density in Toucan.</figcaption></figure></div>



<p>Choosing “Many” will set Toucan to replace and highlight a substantial number of words on the page with their translated counterparts.</p>



<p>I tried this setting for some time, and I found it somewhat distracting because there were a ton of words highlighted in the page fighting for my attention.</p>



<p>To take it easy and progress gradually, I started with the setting “Less”.</p>



<p>With “Less”, I get around 5–7 words translated in an article of 4–5 min read time.</p>



<p>Also:</p>



<p>With “Less” translations are distributed evenly in the article. Thus, the highlights don’t steal my attention from the content.</p>



<p>I can naturally spot a highlight as I read through the content, and hover on the translated word for the meaning.</p>



<p>Here’s what I recommend:</p>



<p>Start with “Less” → As you become comfortable with the translations → Move to “More”.</p>



<p>With a gradual transition, it’ll be easier to stick to this extension and interpret it as a tool instead of a distraction.</p>



<p>Similar to Toucan, Fluent also shows up an option to choose how many words you’d like to see translated:</p>



<div><figure><img data-attachment-id="992" data-permalink="https://hulry.com/toucan-learn-language/fluent-set-word-density/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=1584%2C662&amp;ssl=1" data-orig-size="1584,662" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fluent-set-word-density" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=300%2C125&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=1024%2C428&amp;ssl=1" loading="lazy" width="1024" height="428" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1" alt="Setting a translation density on Fluent." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=300%2C125&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=768%2C321&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1536%2C642&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1200%2C502&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?w=1584&amp;ssl=1 1584w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=300%2C125&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=768%2C321&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1536%2C642&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1200%2C502&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?w=1584&amp;ssl=1 1584w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Setting a translation density on Fluent.</figcaption></figure></div>



<p>Establishing the fact that these extensions are a tool rather than a distraction, here’s another critical question:</p>



<h2>Are there any privacy concerns?</h2>



<p>Privacy is a significant factor in an extension like this since we’re giving the extension full access to whatever we browse.</p>



<p>Both <a href="https://jointoucan.com/privacy" target="_blank" rel="noreferrer noopener nofollow">Toucan</a> and <a href="https://www.usefluent.co/privacy" target="_blank" rel="noreferrer noopener nofollow">Fluent</a> have addressed this concern with a friendly privacy policy.</p>



<p>Here’s a gist:</p>



<ul><li>They don’t sell user data for ads.</li><li>The extensions don’t store any browsing history.</li><li>They only store the translated words in a browsing session to keep track of your learning progress.</li></ul>



<p>But:</p>



<p>With a free product, there will always be privacy concerns, no matter how clean it’s privacy policy might be. The business needs to make money.</p>



<p>Here’s how Toucan generates revenue right now:</p>



<ul><li><strong>Premium memberships.</strong> Toucan offers a premium membership which unlocks a couple of advanced learning packs.</li><li><strong>Own a word.</strong> With Toucan, you can <a href="https://jointoucan.com/own-the-word/claim" target="_blank" rel="noreferrer noopener nofollow">own a word</a> for <strong>$0.99/week</strong>. This means that if I own the word “productivity”, then every time someone hovers over the translated word for “productivity”, they’ll see my name and website at the bottom of the card. Consider it a form of advertisement without the use of your browsing history.</li></ul>



<p>That said:</p>



<p>I would still recommend you turn off Toucan on sensitive websites like your email inbox, banking sites, etc.</p>



<p>Here’s how you can do it:</p>



<div><figure><img data-attachment-id="975" data-permalink="https://hulry.com/toucan-learn-language/turn-off-toucan/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=840%2C526&amp;ssl=1" data-orig-size="840,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="turn-off-toucan" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=300%2C188&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=840%2C526&amp;ssl=1" loading="lazy" width="840" height="526" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?resize=840%2C526&amp;ssl=1" alt="Turning off Toucan translations on a specific website." data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Turning off Toucan translations on a specific website.</figcaption></figure></div>



<p>Once Toucan is turned off for a particular website, the extension will never read any data from any page of the website.</p>



<p>Here are some of the websites where I have disabled Toucan:</p>



<ul><li>HEY email</li><li>Dropbox</li><li>Gmail</li><li>Banking websites I use</li><li>WordPress</li><li>Notion</li></ul>



<p>It’s always wise to fine-tune privacy settings so that we don’t leak any of our data to a company who might use it to their advantage.</p>



<p>Now that we talked about Toucan’s premium subscription, let’s see:</p>



<h2>Whether premium is worth the money</h2>



<p>Right now, the only selling point of …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hulry.com/toucan-learn-language/">https://hulry.com/toucan-learn-language/</a></em></p>]]>
            </description>
            <link>https://hulry.com/toucan-learn-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055257</guid>
            <pubDate>Wed, 11 Nov 2020 03:39:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Value for People]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055070">thread link</a>) | @mooreds
<br/>
November 10, 2020 | https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><em>This is a guest post from Minh Pham. Enjoy.</em></p>



<p>Dear new developer,</p>



<p>I want to start off by saying Congrats and Good job. If you’re reading this, it’s likely you know how to code – and even if you’re still working on getting that first job, that means you have one of the most desirable skill sets in the world today. I congratulate you because getting here took work. You weren’t born with this knowledge, and even if you felt like it came naturally, it was still a journey of discovery, learning, and practice that got you where you are today.</p>



<p>As you look towards your first job – I want to offer you a single piece of advice that may act as your career’s guiding north star:</p>



<p><strong>Create Value for People.</strong></p>



<p>When you have the power to create anything, you begin to realize the importance isn’t on the code you’re writing but rather why you’re writing it in the first place. What value are you creating through your skill? This is why companies hire people like yourself. They are seeking out individuals who can ultimately deliver value to their customers, particularly through software. As you mature, you will realize that much of engineering has little to do with how fancy your solution is, and instead has everything to do with what problem it solves for the user. Once you accept this, you’ll begin to see that discussions of tech choice and code structure rarely matters outside the context of what business value it represents.</p>



<p>This is where your focus should stay.</p>



<p>Obsessions with patterns and algorithms don’t serve anyone’s mission by themselves. Ignore the constant pressure to assert yourself through syntactic cleverness and obscure trivia. These things don’t matter. These things don’t drive value for anyone. No matter how many “experienced” engineers tell you these are important, I promise you no company hires people simply for them to recite principles and algorithms.</p>



<p>While coding might be your latest skill set, it is by no means an engineer’s only skillset. Remember that at the end of the day, it doesn’t matter if your code is ugly, fancy, verbose or concise – the value you create matters. Strive to be an excellent communicator, a quality teammate, and an outstanding human. These attributes will guide your engineering efforts to ensure you bring value.</p>



<p>No matter where your career goes, if you focus on creating value for people, opportunities will never be in short supply. Desire for specific skills may rise and fall, but people will always look to those who can create value.</p>



<p>With that, I wish you the best of luck and may our journeys cross again,</p>



<p>Minh Pham</p>



<p><em><a href="https://www.linkedin.com/in/miniseagoat/">Minh Pham</a> believes you should lead how you want to be led. This has been the guiding principle of his career since he started. As an Engineer, he always wished he had someone who would guide him – telling him what’s important, what he has to work on, and what he should ignore. Having gone through all that and then some, Minh now looks to be the positive influence he wishes he had.</em></p>



<p><em>As a manager, Minh’s greatest passion was teaching people the skills to create and drive the careers they want to have. Now as a career coach, he works to show people they have the power to build the life they want.</em></p>



<p><em>Minh believes anyone can do it – and he promises it doesn’t involve linked lists or graph traversals.</em></p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-11-09T09:27:00-07:00">November 9, 2020</time><time datetime="2020-10-23T21:27:22-06:00">October 23, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055070</guid>
            <pubDate>Wed, 11 Nov 2020 03:00:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facial-Recognition Software for Bears]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25054992">thread link</a>) | @sandworm101
<br/>
November 10, 2020 | https://www.cbc.ca/news/canada/british-columbia/grizzly-bear-facial-recognition-software-1.5797525 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/british-columbia/grizzly-bear-facial-recognition-software-1.5797525">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Facial recognition technology previously used on humans has huge implications for managing bear-human interactions, says UVic ecologist who has developed software to identify grizzly bears.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5797547.1605049994!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/bearid.JPG"></p></div><figcaption>BearID is grizzly bear facial recognition software developed 'from the ground up' with algorithms used to identify humans and primates. <!-- --> <!-- -->(Melanie Clapham)</figcaption></figure><p><span><p>Melanie Clapham has spent the last three years snapping images of grizzly bears at Knight Inlet, on the B.C. coast, using small camera traps housed in metal and strapped securely to the forest branches.</p>  <p>Three years and thousands of images later, the behavioural ecologist and postdoctoral student at the University of Victoria <a href="https://onlinelibrary.wiley.com/doi/10.1002/ece3.6840" target="_blank">has partnered with</a> two software developers living in Silicon Valley&nbsp;and a grizzly research centre in Alaska&nbsp;to develop facial recognition technology used to identify the bears.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/bearid-2.jpg 300w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/bearid-2.jpg 460w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/bearid-2.jpg 620w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/bearid-2.jpg 780w,https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/bearid-2.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5797551.1605050026!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/bearid-2.jpg"></p></div><figcaption>Melanie Clapham sets up a camera trap to capture images of grizzly bears for the BearID project.<!-- --> <!-- -->(Moira Le Patourel)</figcaption></figure></span></p>  <p>"They don't have distinctive markings on their bodies," said Clapham, whose&nbsp;interest in this technology stemmed from the need to "identify and recognize individual bears over time" as part of her behavioural research over the last 11 years.&nbsp;</p>  <p>Now, she says, the <a href="http://bearresearch.org/" target="_blank">open-source Bear ID software</a> can be used and adapted by anyone&nbsp;and could have huge implications for understanding the animals' behaviour and mitigating bear-human encounters.&nbsp;</p>  <h2>Technology based on human facial recognition</h2>  <p>Ed Miller and his partner Mary Nyugen are the software developers from California who connected with Clapham in an online forum for conservation technology in late 2017.&nbsp;</p>  <p>The pair were looking for photos of bears "for fun" as a way to learn more about recognition software, and so they connected with Clapham to offer their expertise in adapting artificial intelligence.</p>    <p>"The technology we're using is based on the same software [used] to recognize humans," said Miller, who added that human identification is far easier, as there are literally millions of images the software can learn from.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/bearid-3.JPG 300w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/bearid-3.JPG 460w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/bearid-3.JPG 620w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/bearid-3.JPG 780w,https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/bearid-3.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5797559.1605050036!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/bearid-3.JPG"></p></div><figcaption>Grizzly bears can be difficult to track, as many do not have distinctive markings on their bodies. <!-- --> <!-- -->(Melanie Clapham)</figcaption></figure></span></p>  <p>"We need (lots of) images of individual animals to tell the system which bear is which," said Clapham, who explained "deep learning" as the process where the software trains itself to recognize certain bears more accurately the more pictures it has.&nbsp;</p>    <p>This is especially important, given that a bear's appearance can change dramatically throughout the year as its fur moults and its weight fluctuates.&nbsp;</p>  <p>Claphams says BearID currently has an 84 per cent accuracy rate.</p>  <h2>Many practical applications</h2>  <p>Clapham said she hopes the technology will be adapted by municipalities, governments, non-profits — as many groups as possible — as it will allow people to understand animal behaviour, like how they move&nbsp;in and out of densely populated areas. It could also help researchers understand the movements of endangered species.</p>  <p>It can track bears as they move "in a similar way that a human is tracked through airports," she explained. From there, authorities could make better-informed land management and conservation decisions.&nbsp;</p>  <p>It could also help mitigate conflict encounters between bears and humans. </p>  <p>"If you have a bear digging through garbage cans, and you set cameras up … is this just one bear or is this five different bears coming into the area?" Clapham said.</p>  <p>Dallas Smith, president of the Nanwakolas Council, a group of five First Nations from Vancouver Island and the B.C. Coast&nbsp;formed to make land management decisions, said he's very excited for First Nations to use BearID, after connecting with Clapham.</p>  <p>"The grizzly bear is an icon in our cultural heritage. It's always been important to work in harmony with them," he explained. "It's really helping us gain a foothold in taking over the management of grizzly bear interactions in our territories."</p>  <p>He said the "collective territory" is working to gather more images for the system.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/british-columbia/grizzly-bear-facial-recognition-software-1.5797525</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054992</guid>
            <pubDate>Wed, 11 Nov 2020 02:44:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Great Code Reviews–The Superpower Your Team Needs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054556">thread link</a>) | @saranshk
<br/>
November 10, 2020 | https://shopify.engineering/great-code-reviews | <a href="https://web.archive.org/web/*/https://shopify.engineering/great-code-reviews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>There is a general consensus that code reviews are an important aspect of highly effective teams. <a href="https://sail.cs.queensu.ca/Downloads/EMSE_AnEmpiricalStudyOfTheImpactOfModernCodeReviewPracticesOnSoftwareQuality.pdf" target="_blank" title="An Empirical Study of the Impact of Modern Code Review Practices on Software Quality" rel="nofollow noopener noreferrer">This research paper</a> is one of many exploring this subject. Most organizations undergo code reviews of some form.</p>
<p>However, it’s all too common to see code reviews that barely scratch the surface, or that offer feedback that is unclear or hard to act upon. This robs the team the opportunity to speed up learning, share knowledge and context, and raise the quality bar on the resulting code.</p>
<p>At Shopify, we want to move fast while building for the long term. In our experience, having strong code review practices has a huge impact on the growth of our engineers and in the quality of the products we build.</p>

<p>Imagine you join a new team and you’re given a coding task to work on. Since you’re new on the team, you really want to show what you’re made of. You want to perform. So, this is what you do:</p>
<ol>
<li>You work frantically on your task for 3 weeks.</li>
<li>You submit a Pull Request for review with about 1000 new lines of code</li>
<li>You get a couple comments about code style and a question that shows the person has no clue what this work is about.</li>
<li>You get approval from both reviewers after fixing the code style and answering the question.</li>
<li>You merge your branch into master, eyes closed, shoulders tense, grinding your teeth. After a few minutes, CI completes. Master is not broken. Yet.</li>
<li>You live in fear for 6 months, not knowing when and how your code will break.</li>
</ol>
<p>You may have lived through some of the situations above, and hopefully you’ve seen some of the red flags in that process.</p>
<p>Let’s talk about how we can make it much better.</p>

<p>At Shopify, we value the speed of shipping, learning, and building for the long term. These values - which sometimes conflict - lead us to experiment with many techniques and team dynamics. In this article, I have distilled a series of very practical techniques we use at Shopify to ship valuable code that can stand the test of time.</p>
<p>A Note about terminology: We refer to Pull Requests (PR) as one unit of work that's put forth for review before merging into the base branch. Github and Bitbucket users will be familiar with this term.</p>
<h2>1. Keep Your Pull Requests Small</h2>
<p>As simple as this sounds, this is easily the most impactful technique you can follow to level up your code review workflow. There are 2 fundamental reasons why this works:</p>
<ul>
<li>It’s mentally easier to <strong>start and complete a review</strong> for a small piece. Larger PRs will naturally make reviewers delay and procrastinate examining the work, and they are more likely to be interrupted mid-review.</li>
<li>As a reviewer, it’s exponentially <strong>harder to dive deep</strong> if the PR is long. The more code there is to examine, the bigger the mental map we need to build to understand the whole piece.</li>
</ul>
<p>Breaking up your work in smaller chunks increases your chances of getting faster and deeper reviews.</p>
<p>Now, it’s impossible to set one universal standard that applies to all programming languages and all types of work. Internally, for our data engineering work, the guideline is around 200-300 lines of code affected. If we go above this threshold, we almost always break up the work into smaller blocks.</p>
<p>Of course, we need to be careful about breaking up PRs into chunks that are <strong>too small</strong>, since this means reviewers may need to inspect several PRs to understand the overall picture.</p>
<h2>2. Use Draft PRs</h2>
<p>Have you heard the metaphor of building a car vs. drawing a car? It goes something like this:</p>
<ol>
<li>You’re asked to build a car.</li>
<li>You go away for 6 months and build a beautiful Porsche.</li>
<li>When you show it to your users, they ask about space for their 5 children and the surf boards.</li>
</ol>
<p>Clearly, the problem here is that the goal is poorly defined and the team jumped directly into the solution before gathering enough feedback.If after step 1 we created a drawing of the car and showed it to our users, they would have asked the same questions and we would have discovered their expectations and saved ourselves 6 months of work. Software is no different—we can make the same mistake and work for a long time on a feature or module that isn't what our users need.</p>
<p>At Shopify, it’s common practice to use <strong>Work In Progress (WIP) PRs</strong> to elicit early feedback whose goal is validating direction (choice of algorithm, design, API, etc). Early changes mean less wasted effort on details, polish, documentation, etc.</p>
<p>As an author, this means you need to be open to changing the direction of your work. At Shopify, we try to embrace the principle of <a href="https://engineering.shopify.com/blogs/engineering/scaling-mobile-development-by-treating-apps-as-services" target="_blank" title="Scaling Mobile Development by Treating Apps as Services - Shopify Engineering" rel="noopener noreferrer"><strong>strong opinions, loosely held</strong></a>. We want people to make decisions confidently, but also be open to learning new and better alternatives, given sufficient evidence. In practice, we use Github’s <strong>Draft PRs</strong>—they clearly signal the work is still in flow and Github prevents you from merging a Draft PR. Other tools may have similar functionality, but at the very least you can create normal PRs with a clear <strong>WIP</strong> label to indicate the work is early stage. This will help your reviewers focus on offering the right type of feedback.</p>
<h2>3. One PR Per Concern</h2>
<p>In addition to line count, another dimension to consider is how many <em>concerns</em> your unit of work is trying to address. A concern may be a feature, a bugfix, a dependency upgrade, an API change, etc. Are you introducing a new feature while refactoring at the same time? Fixing two bugs in one shot? Introducing a library upgrade and a new service?</p>
<p>Breaking down PRs into individual concerns has the following effects:</p>
<ul>
<li>
<strong>More independent review units</strong> and therefore <strong>better review quality</strong>
</li>
<li>
<strong>Fewer affected people</strong>, therefore less domains of expertise to gather</li>
<li>
<strong>Atomicity of rollbacks,</strong>&nbsp;the ability of rolling back a small commit or PR. This is valuable because if something goes wrong, it will be easier to identify where errors were introduced and what to roll back.</li>
<li>
<strong>Separating easy stuff from hard stuff</strong>. Imagine a new feature that requires refactoring a frequently used API. You change the API, update a dozen call-sites, and then implement your feature. 80% of your changes are obvious and skimmable with no functional changes, while 20% are new code that needs careful attention to test coverage, intended behaviour, error handling, etc. and will likely go through multiple revisions. With each revision, the reviewer will need to skim through <em>all</em> of the changes to find the relevant bits. By splitting this in two PRs, it becomes easy to quickly land the majority of the work and to optimize the review effort applied to the harder work.</li>
</ul>
<p>If you end up with a PR that includes more than one concern, you can break it down into individual chunks. Doing so will accelerate the iteration cycle on each individual review, giving a faster review overall. Often part of the work can land quickly, avoiding code rot and merge conflicts.</p>
<p><img alt="Breaking down PRs into individual concerns" data-src="//cdn.shopify.com/s/files/1/0779/4361/files/Code_Reviews_at_Shopify_-_blog_article.jpg?v=1581342642" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Code_Reviews_at_Shopify_-_blog_article.jpg?v=1581342642"></p>
<meta charset="utf-8">
<p><em>Breaking down PRs into individual concerns</em></p>
<p>In the example above, we’ve taken a PR that covered three different concerns and broke it up. You can see how each reviewer has strictly less context to go over. Best of all, as soon as <em>any</em> of the reviews is complete, the author can begin addressing feedback while continuing to wait for the rest of the work. In the most extreme cases, instead of completing a first draft, waiting several days (and shifting focus), and then eventually returning to address feedback, the author can work almost continuously on their family of PRs as they receive the different reviews asynchronously.</p>
<h2>4. Focus on the Code, Not the Person</h2>
<p>Focus on the code, not the person practice refers to communication styles and relationships between people. Fundamentally, it’s about trying to focus on making the product better, and avoiding the author perceiving a review as personal criticism.</p>
<p>Here are some tips you can follow:</p>
<ul>
<li>As a reviewer, think, “This is <strong>our</strong> code, how can we improve on it?”</li>
<li>Offer positive remarks! If you see something done well, comment on it. This reinforces good work and helps the author balance suggestions for improvement.</li>
<li>As an author, assume best intention, and don’t take comments personally.</li>
</ul>
<p>Below are a few examples of not-so-great review comments, and a suggestion on how we can reword to emphasize the tips above.</p>
<table>
<tbody>
<tr>
<td>

<strong>Less of These</strong>
</td>
<td><strong>&nbsp;More of These</strong></td>
</tr>
<tr>
<td>

Move this to Markdown</td>
<td>

How about moving this documentation into our Markdown README file? That way we can more easily share with other users.<strong></strong>
</td>
</tr>
<tr>
<td>

Read the Google Python style guidelines</td>
<td>

We should avoid single-character variables. How about board_size or size instead?</td>
</tr>
<tr>
<td>

This feels too slow. Make it faster. Lightning fast.</td>
<td>&nbsp;This algorithm is very easy to read but I’m concerned about performance. Let’s test this with a large dataset to gauge its efficiency.</td>
</tr>
<tr>
<td>

Bool or int?</td>
<td>

Why did you choose a list of bool values instead of integers?</td>
</tr>
</tbody>
</table>
<p><br>Ultimately, a code review is a learning and teaching opportunity and should be celebrated as such.</p>
<h2>5. Pick the Right People to Review</h2>
<p>It’s often challenging to decide who should review your work. Here are some questions can use as guidance:</p>
<ul>
<li>Who has context on the feature or component you’re building?</li>
<li>Who has strong skills in the language, framework, or tool you’re using?</li>
<li>Who has strong opinions on the subject?</li>
<li>Who cares about the result of what you’re doing?</li>
<li>Who should learn this stuff? Or if you’re a junior reviewing someone more senior, use this as an opportunity to ask questions and learn. Ask all the silly questions, a strong team will find the time to share knowledge.</li>
</ul>
<p>Whatever rules your team might have, remember that it is your responsibility as an author to seek and receive a high-quality code review from a person or people with the right context.</p>
<h2>6. Give Your Reviewers a Map</h2>
<p>Last but definitely not least, the description on your PR is crucial. Depending on who you picked for review, different people will have different context. The onus is on the author to help reviewers by providing key information or links to more context so they can produce meaningful feedback.</p>
<p>Some questions you can include in <a href="https://help.github.com/en/github/building-a-strong-community/creating-a-pull-request-template-for-your-repository" target="_blank" title="Creating a pull request template for your repository - GitHub" rel="nofollow noopener noreferrer">your PR templates</a>:</p>
<ul>
<li>Why is this PR necessary?</li>
<li>Who benefits from this?</li>
<li>What could go wrong?</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/great-code-reviews">https://shopify.engineering/great-code-reviews</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/great-code-reviews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054556</guid>
            <pubDate>Wed, 11 Nov 2020 01:31:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Helped me be more Productive as a Software Developer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054231">thread link</a>) | @strikingloo
<br/>
November 10, 2020 | https://www.datastuff.tech/programming/productivity-software-developer-student/ | <a href="https://web.archive.org/web/*/https://www.datastuff.tech/programming/productivity-software-developer-student/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-884" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@strikingloo">
<meta name="twitter:title" content="How I Stay Productive as a Software Developer">
<meta name="twitter:description" content="Imagine getting more stuff done, more effectively, in less time.">
<meta name="twitter:image" content="https://cdn.pixabay.com/photo/2020/11/04/19/22/windmill-5713337_1280.jpg">
<p>Imagine getting more stuff done, more effectively, in less time. That is how I will define productivity for the rest of this piece.</p>
<p>I’ve been reading a lot of productivity articles, tips, tricks and Twitter threads. In a way, doing so is the worst kind of procrastination, entropy for entropy’s sake. But every once in a while you’ll glean some gold nugget among the rubble, and it will all be worth it.</p>
<p>This is my attempt at recollecting what nuggets I found. On each section I will:</p>
<ul><li>Cite sources I found interesting or relevant.</li><li>Mention whether the methods have worked for me and what exact impact they’ve had.</li></ul>
<p>I will add a big caveat though: I think every person’s optimal productivity engine should be different. Thus, all of this advice should be taken, tested, and left to rot if it doesn’t work for you. And that pretty much applies to all other posts of this kind, in any blog ever, in my opinion.</p>
<p>Without further ado, here are the things I’ve seen actually work to make me get more stuff done, or stay less stressed.</p>
<h2>Reduce cognitive load</h2>
<p>Cognitive load is a beautiful term. It roughly means “How full is your mind’s RAM?”. </p>
<p>Whenever you’re thinking of the next 5 things you have to do, your groceries list, and whether you left the stove on, you’re carrying cognitive load.</p>
<p>It should be evident, but cognitive load stresses you out. Reducing it can help you better focus on your task.</p>
<p>Here’s what has worked for me on this account:</p>
<ul><li>Keep a clean room, office and desk<sup><a href="#fn1">1</a></sup>. You shouldn’t have trouble finding anything you use often, and the things you use the most often should be very easy to reach. This also applies to your filesystem, bookmarks system, etc. If you know you’ll want to check a certain link again in the future, bookmark it under an intuitive path. Don’t find yourself looking for it through your twitter feed.</li><li>If something’s on your mind and it’s not useful to keep thinking of it, <strong>write it down and forget it</strong>. You can look it up later. </li></ul>
<p>Take this article, for instance: instead of pestering myself thinking ‘You have to write that article!’ I just added an item on my Trello backlog that said ‘article on productivity’ and forgot about it until I had free time again and checked.</p>
<p>My own setup for task tracking is a combination of Trello for daily/weekly tasks and a Google sheet for long term stuff -like a deferred backlog- but really, every person has their own perfect combination of tools and processes. Find your own. </p>
<p>I know many people who prefer physical post-its, or a board. I’d rather get the portability of a browser app and the tracking for future reference. This is especially good if you also practice journaling, because then it’s just “What did I do today? Oh ok I’ll check today’s cards”. Still, your mileage will vary, so try many things and see what works best for you.</p>
<h2>Keep productive habits</h2>
<blockquote><p>…Watch your actions, they become your habits; watch your habits, they become your character; watch your character, it becomes your destiny.”</p><cite><em>―&nbsp;</em><strong>Lao Tzu</strong></cite></blockquote>
<p>Some people recommend this book called “Atomic Habits”. I won’t lie, I haven’t read it. But I read a good summary on reddit and agree with most of it, thought I was already kind of doing most of what it talks about.</p>
<p>The gist of it is: don’t try to build productivity on its own, build systems that incentivize you to be productive.</p>
<p>Some people use pomodoros, others prefer to put on noise-blocking headphones; I personally prefer to hide my cell phone until I have got enough stuff done. </p>
<p>My technique for this is simple: every month, (or use whatever time frame works for you), I decide which routines I will keep.</p>
<p>Right now for instance, my routines are:</p>
<ul><li>Exercise 4 times a week.</li><li>Do everything I have to for work and school, obviously.</li><li>Journal every night</li><li>2 hours of Japanese study every day</li></ul>
<p>The painful side of having a very clear set of goals and habits is: you’re extremely accountable to them. Is the day ending and you haven’t done your daily study session? You better get down to it right now. </p>
<p>In my case, my own conscience is a harsh enough mistress, but if you are not that hard on yourself when your to-do lists have uncrossed items, you may want to try something like </p>
<ul><li>Asking your SO to make passive aggressive remarks to you if you don’t finish your tasks.</li><li>Reward yourself with something sweet.</li><li>Going full monk-mode and forfeiting cell phone time until everything is done.</li></ul>
<p>Now for the flip side: you’re accountable for your tasks, yes, but you also set them. So whenever you define what your habits will be, don’t overestimate yourself. It’s better to have realistic, achievable goals that fall a bit short of your <em>maximum effort</em>, than it is to overstep, burn out or just not build the habits because you can’t keep up with them. </p>
<p>Did you underestimate your time management skills and now you’re doing everything you planned for <em>and</em> then get a lot of free time anyway? Cool! You get to feel productive <em>and</em> have free time. </p>
<p>You definitely don’t want to optimize for minimum free time. It sounds obvious, but I’ve caught myself and others doing this without realizing it.</p>
<p>The devil doesn’t always make work with idle hands.</p>
<p>Another thing about incentives: this ties to the “unclutter” rule I mentioned earlier, but do try to turn everything around you into a big <strong>habit-keeping engine</strong>. </p>
<p>For instance, if your goal is to read a book every week, have your book on sight and within arm’s reach at all times. Carry it on your suitcase/backpack, take it out instead of your cell phone when you want to procrastinate, etc. </p>
<p>You’ll be surprised by how much stuff you get done when <strong>everything around you is making you do it</strong>.</p>
<p>For a small guide on creating habits that I found interesting (though maybe more complicated than necessary) see <a href="https://www.lesswrong.com/posts/vE7Z2JTDo5BHsCp4T/instrumental-rationality-4-2-creating-habits">creating habits</a>.</p>
<h2>Don’t use your head for things a PC was made for</h2>
<p>Really though, remember what I said about cognitive load? Defining daily goals is not cool if you end up spending 5 minutes every hour thinking “ok what comes next? I already crossed my Chinese practice and my Economics lecture, what was the next item?”. </p>
<p>You want whatever system you build to be maintainable in the long run, so you should make it as easy to consult as possible, and not depend on a very fallible piece of architecture (your head).</p>
<p>So keep everything written down, on a nice .txt file, a Google doc, a sheet, etc. Use whatever you like, but not your head. Really it’s that simple, and it works. </p>
<p>(Aside: I am not going into detail into different tools or task tracking systems because honestly? There are like 20 different articles on this topic posted on HackerNews every week, and they’re all the same).</p>
<h2>Effective Note Taking</h2>
<p>This is all I have to say about note taking.</p>
<p>I am not a very note taking inclined person. I started this particular habit this year, and even though it <em>feels</em> productive, I don’t feel like I can quite say it has actually made me perform better yet.</p>
<p>So my first tip on this will be: <strong>don’t take notes if you don’t think it will be worth it</strong>. Some people retain information better when they take notes, I am not one of those people but if you are, then that piece of advice doesn’t apply to you. Remember when I said systems needed to be custom?</p>
<p>I also say this because I see there’s this trend in the internet of “write everything down, take all the notes!” and I think we’re tending towards an excessive “pro-notes-taking” bias, which may be unwarranted.</p>
<p>Secondly: if you are not writing everything down, how do you decide what should be kept? Well, I’m open to better ideas, but in my case I optimize for (estimated) <strong>future searchability</strong>: is what I just read, heard or watched something I am <strong>likely to think of in the future</strong>? And maybe I will want to recall it exactly and won’t be able to? Well then, into the notes it goes.</p>
<p>Note that it doesn’t need to be a relevant piece of information per se. I take notes about interesting history facts, anime trivia and weird Japanese words, not because they’ll come up in my final exams (fingers crossed) or, gods forbid, my job. I keep those quotes and facts around because they may come up in conversation.</p>
<p>Generally though, I think the category that makes the best notes is “things that I am likely to forget and look up again in the future, but I don’t care to learn by heart right now”. </p>
<p>This includes things like very specific facts about a domain, convoluted bash commands that you put into a script to not have to remember again (but want to persist somewhere else in case you want them on a different pc), or syntax details in a programming language.</p>
<p>I will be reading an article and think “oh, $FRIEND_X surely would find this very funny” and just write it down. And then I may send it to them through IM, but let’s be honest I could forget… until I reread my notes in the future.</p>
<p>Oh, the topic of rereading notes. This one is a tricky bit I haven’t mastered yet, and I am also open to suggestions in this area. Personally, I only reread notes on technical topics whenever they come up and I want to refresh my memory, and any other topic if I am thinking of it.</p>
<p>I know some people like to go through all of their notes every X time and they say it improves their creativity and gets the writing juices flowing. I am not super concerned about my creativity or writing right now (in case my one year posting-gap didn’t make that clear), but I will definitely experiment with that in the future (and write about it if I get any relevant results).</p>
<p>Lastly, I’ve recently been using a <strong>personal wiki</strong> for some of my notes (only the polished, public-facing ones), and it’s really cool, but it just reinforces point one: I feel like part of why I use a personal wiki is just that it feels nice, and I haven’t yet seen a lot of improvement over a simple Evernote or Google Docs. Maybe it’s a matter of scale and the effects won’t be apparent until a few years in? We will see.</p>
<h2>Anki and SRS for studying and productivity.</h2>
<blockquote><p><strong>Anki makes memory a choice</strong>, rather than a haphazard event, to be left to chance.</p><cite>Michal …</cite></blockquote></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.datastuff.tech/programming/productivity-software-developer-student/">https://www.datastuff.tech/programming/productivity-software-developer-student/</a></em></p>]]>
            </description>
            <link>https://www.datastuff.tech/programming/productivity-software-developer-student/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054231</guid>
            <pubDate>Wed, 11 Nov 2020 00:47:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PilferShush Jammer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054222">thread link</a>) | @karlzt
<br/>
November 10, 2020 | https://www.cityfreqs.com.au/pilfer.php | <a href="https://web.archive.org/web/*/https://www.cityfreqs.com.au/pilfer.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
            Basic information about how the SDKs code function. They start with a call to the Android/Java API that deals with audio recording and playback. From there with a buffer array full of some audio data, it can then be sent to a native code library that is also installed as part of the SDK. These libraries handle the more CPU intensive work such as sifting through the data using various common methods (Goertzel et al) to find audio signals of interest. 
            </p><p>
            This first section shows some of the Android/Java function calls and parameters used.
            </p><p>
							<strong>alphonso</strong>
              <br>
              ALPHONSO_VERSION = "2.0.46";
              </p><pre>    private static final int RECORDER_AUDIO_BYTES_PER_SEC = 16000;
    private static final int RECORDER_AUDIO_ENCODING = 2;
    private static final int RECORDER_BIG_BUFFER_MULTIPLIER = 16;
    private static final int RECORDER_CHANNELS = 16;
    private static final int RECORDER_SAMPLERATE_44100 = 44100;
    private static final int RECORDER_SAMPLERATE_8000 = 8000;
    private static final int RECORDER_SMALL_BUFFER_MULTIPLIER = 4;
    public static final byte ACR_SHIFT_186 = (byte) 0;
    public static final byte ACR_SHIFT_93 = (byte) 1;
    public static final int ACR_SPLIT = 2;</pre>

              <p><strong>bitsound</strong>
              <br>
              VERSION_NAME = "v4.2.2"
              </p><pre>    public void a(int i) {
      try {
        this.d = new AudioRecord(6, this.b, 16, 2, i);
        if (this.d.getState() == 1) {
          try {
            this.d.startRecording();
            if (this.d.getRecordingState() != 3) {
              b.c(a, "Audio recording startDetection fail");
              this.d.release();
              this.e = false;
              return;
            }
            a(this.d);
            this.e = true;
            return;</pre>
            
              <p><strong>cifrasoft</strong>
              <br>
              VERSION_NAME = "1.0.3"
              </p><pre>    public static final int AUDIO_BUFFER_SIZE_MULTIPLIER = 4;
    public static final int AUDIO_THREAD_STOP_TIMEOUT = 3000;
    public static final int MAX_EMPTY_AUDIO_BUFFER_SEQUENTIAL_READS = 10;
    this.SAMPLE_RATE = 44100;</pre>
    
              <pre>    private int readAudioData(int currentPcmOffset, byte[] pcm) {
      AudioRecordService.handler.sendEmptyMessageDelayed(1, 3000);
      int result = this.mAudioRecord.read(pcm, currentPcmOffset * 2, this.bufferLength * 2);
      AudioRecordService.handler.removeMessages(1);
      return result;
    }</pre>

              <p><strong>copsonic</strong>
              <br>
              CORE_VERSION = "SonicAuth_CORE_v1.2.2.1";
              </p><pre>    "signalType": "ULTRASONIC_TONES",
    "content" : {
        "frequencies" : [ [18000, 20000, "TwoTones"] ]

    "signalType": "ZADOFF_CHU",
    "content": {
      "config": {
        "samplingFreq": 44100,
        "minFreq": 18000,
        "maxFreq": 19850,
        "filterRolloff": 0.5,
        "totalSignalTime": 0.3,
        "nMsgSymbols": 2,
        "filterSpan": 8
      },
      "set": {
        "centralFreq": 18925,
        "nElemSamples": 36,
        "nSymbolElems": 181</pre>

              <p><strong>dv (dov-e)</strong>
              <br>
              VERSION_NAME = "1.1.7"
              </p><pre>    private void recorderWork() {
      if (this.recordingActive) {
        int bytesReadNumber = this.myRecorder.read(this.myBuffer, 0, this.myBuffer.length);
        if (this.recordingActive) {
          DVSDK.getInstance().DVCRxAudioSamplesProcessEvent(this.myBuffer, 0, bytesReadNumber / 2);
        }
      }
    }</pre>
    
              <p><strong>fanpictor</strong>
              <br>
              VERSION_NAME = "3.2.3"
              </p><pre>    enum FNPFrequencyBand {
      Default,
      Low,
      High
    }
              </pre>

              <p><strong>fidzup</strong></p><pre>    a. this.frequency = paramBasicAudioAnalyzerConfig.frequency;   // 19000.0f
    b. this.samplingFrequency = paramBasicAudioAnalyzerConfig.samplingRate;    // 44100.0f
    c. this.windowSize = paramBasicAudioAnalyzerConfig.windowSize;   // 0x200 (512)
    d. /* pulseDuration = 69.66f */
    e. this.pulseWidth = Math.round(paramBasicAudioAnalyzerConfig.pulseDuration * (this.samplingFrequency / 1000.0F));
    f. this.pulseRatio = paramBasicAudioAnalyzerConfig.pulseRatio;   // 32.0f
    /* signalSize = 0x20 (32)
    g. this.signalPeriodPulses = paramBasicAudioAnalyzerConfig.signalSize;
    h. this.bitCounts = paramBasicAudioAnalyzerConfig.bitcounts;   // 0xb (11)</pre>         
            <pre>    paramf.a = 19000.0F;            
    paramf.b = 44100.0F;            
    paramf.c = 512;                 
    paramf.d = 69.66F;              
    paramf.e = 0.33333334F;         
    paramf.f = ((int)(paramf.d * 32.0F * 3.2F)); // 7133.184
    paramf.g = 32;                 
    paramf.h = new int[] { 15, 17, 19, 13, 11, 21, 23, 9, 7, 25, 27 };</pre>             

              <p><strong>fluzo</strong>
              <br>
              VERSION = "1.3.001"</p><pre>    this.p = jSONObject.getInt("frame_length_milliseconds");
    this.q = jSONObject.getInt("frame_step_milliseconds");
    this.r = (float) jSONObject.getDouble("preemphasis_coefficient");
    this.s = jSONObject.getInt("num_filters");
    this.t = jSONObject.getInt("num_coefficients");
    this.u = jSONObject.getInt("derivative_window_size");</pre>
    
              <p><strong>instreamatic</strong>
              <br>
              VERSION_NAME = "7.16.0"</p><pre>    private static final int BUFFER_SECONDS = 5;
    private static int DESIRED_SAMPLE_RATE = 16000;</pre>
 
              <p><strong>lisnr</strong>
              <br>
              VERSION_NAME = "5.0.1.1";
              </p><pre>    // LisnrIDTone          
    public long calculateToneDuration() {
        return ((long) (((double) (this.lastIteration + 1)) * 2.72d)) * 1000;
    }
    // LisnrTextTone
    public long calculateToneDuration() {
        return (long) (((this.text.length() * 6) * 40) + 1280);
    }
    // LisnrDataTone
    public long calculateToneDuration() {
        return (long) (((this.data.length * 6) * 40) + 1280);
    }
    AudioRecord audioRecord = new AudioRecord(0, d, 16, 2, 131072);</pre>  

              <pre>    ArrayAudioPlayer.this.audioOutput = new AudioTrack(3, ArrayAudioPlayer.this.samplerate, 4, 2, 16000, 1);
    ArrayAudioPlayer.this.audioOutput.play();
    int written = 0;
    while (!ArrayAudioPlayer.this.threadShouldStop) {
      try {
        if (ArrayAudioPlayer.this.buffer.getBufferLeftToRead() &gt; 0) {
          int size = ArrayAudioPlayer.this.buffer.getBufferLeftToRead();
          written += size;
          ArrayAudioPlayer.this.audioOutput.write(ArrayAudioPlayer.this.buffer.readFromBuffer(size), 0, size);
          } else {
            ArrayAudioPlayer.this.threadShouldStop = true;
          }
        } catch (IOException e) {
          e.printStackTrace();
        }</pre>
        
              <p><strong>moodmedia</strong>
              <br>
              getVersion() = "1.2.1";
              </p><pre>    b = new AudioRecord(5, 44100, 16, 2, Math.max(AudioRecord.getMinBufferSize(44100, 16, 2) * 4, 32768));
    this.b = Type.SONIC;
    this.b = Type.ULTRASONIC;
    if (num.intValue() == 44100 || num.intValue() == 48000)
    this.j.setName("Demodulator");
    this.k.setName("Decoder");
    this.l.setName("HitCounter");
              </pre>
 
              <p><strong>prontoly (sonarax)</strong>
              <br>
              VERSION_NAME = "4.2.0";
             </p><pre>    contentValues.put("time", cVar.a);
    contentValues.put("type", cVar.b.name());
    contentValues.put(NotificationCompat.CATEGORY_EVENT, cVar.c);
    contentValues.put("communication_type", cVar.d);
    contentValues.put("sample_rate", cVar.e);
    contentValues.put("range_mode", cVar.f);
    contentValues.put("data", cVar.g);
    contentValues.put("duration", cVar.h);
    contentValues.put("count", cVar.i);
    contentValues.put("volume", cVar.j);</pre>
    
              <p><strong>realitymine</strong>
              <br>
              getSdkVersion = "5.1.6";
              </p><pre>    this.e = AudioRecord.getMinBufferSize(44100, 16, 2);
    int i = this.e;
    this.d = new byte[i];
    this.c = new AudioRecord(1, 44100, 16, 2, i);</pre>

              <p><strong>redbricklane (zapr)</strong>
              <br>
              SDK_VERSION = "3.3.0";
              </p><pre>    AudioRecord localAudioRecord = new AudioRecord(1, 8000, 16, 2, 122880);
    if (localAudioRecord.getState() == 1) {
      this.logger.write_log("Recorder initialized", "finger_print_manager");
      this.logger.write_log("Recording started", "finger_print_manager");
      localAudioRecord.startRecording();</pre>

              <p><strong>runacr</strong>
              <br>
              release = "1.0.4"
              </p><pre>    int minBufferSize = AudioRecord.getMinBufferSize(11025, 16, 2);
    this.K = new AudioRecord(6, 11025, 16, 2, minBufferSize * 10);</pre>

              <p><strong>shopkick</strong></p><pre>    .field bitDetectThreshold:Ljava/lang/Double;
    .field carrierThreshold:Ljava/lang/Double;
    .field detectThreshold:Ljava/lang/Double;
    .field frFactors:Ljava/lang/String;
    .field gapInSamplesBetweenLowFreqAndCalibration:Ljava/lang/Integer;
    .field maxFracOfAvgForOne:Ljava/lang/Double;
    .field maxIntermediates:Ljava/lang/Integer;
    .field minCarriers:Ljava/lang/Integer;
    .field noiseThreshold:Ljava/lang/Double;
    .field numPrefixBitsRequired:Ljava/lang/Integer;
    .field numSamplesToCalibrateWith:Ljava/lang/Integer;
    .field presenceDetectMinBits:Ljava/lang/Integer;
    .field presenceNarrowBandDetectThreshold:Ljava/lang/Double;
    .field presenceStrengthRatioThreshold:Ljava/lang/Double;
    .field presenceWideBandDetectThreshold:Ljava/lang/Double;
    .field useErrorCorrection:Ljava/lang/Boolean;
    .field wideBandPresenceDetectEnabled:Ljava/lang/Boolean;
    .field highPassFilterType:Ljava/lang/Integer;</pre>
              <pre>    Java_com_shopkick_app_presence_NativePresencePipeline_setDopplerCorrectionEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setHighPassFilterEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setWideBandDetectEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setNumPrefixBitsRequiredParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setPresenceDetectNarrowBandDetectThresholdFCParam
    …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cityfreqs.com.au/pilfer.php">https://www.cityfreqs.com.au/pilfer.php</a></em></p>]]>
            </description>
            <link>https://www.cityfreqs.com.au/pilfer.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054222</guid>
            <pubDate>Wed, 11 Nov 2020 00:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eddie's Ink Chip Hack (2002)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054177">thread link</a>) | @userbinator
<br/>
November 10, 2020 | http://www.eddiem.com/photo/CIS/inkchip/chip.html | <a href="https://web.archive.org/web/*/http://www.eddiem.com/photo/CIS/inkchip/chip.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tr>
<td>
<p lang="en-GB"><a href="http://www.eddiem.com/photo/CIS/cis.htm">My CIS page.</a></p></td>
<th>
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/inkchip.JPG" name="Graphic2" width="401" height="400"></p></th>
<td>
<p lang="en-GB"><a href="http://www.eddiem.com/photo/printer/chipreset/resetchip.html">Part
				2 build your own reseter</a></p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><strong>What is a Intellidge ink chip.</strong><span size="5"><br>
</span>Epson fit
				small circuit boards to most of their ink cartridges. These
				record the amount of ink that is estimated to be in the
				cartridge. I read that the official epson line is that it is for
				the customers benefit and not an anti-refill device. Whether you
				believe this or not they are a bloody nuisance to anyone wanting
				to refill the cartridges or use bulk ink. It also stops people
				using old cartridges full of solvent for cleaning the heads.
				Another problem was early printer models didn't check if the
				cartridge had been changed while power was on. This was good if
				you wanted to trick the printer into copying a “full”
				chip to and empty one, however the reverse was also true and you
				could easily copy and “empty” one into your full
				one.<br>
They are just a small memory device holds 32 bytes of
				data, they do not measure real ink level and nor does the
				printer. The printer reads the chips on startup, estimates
				(sometimes badly) how much ink should have been used and writes
				this back at shutdown. They hold other data as well.<br>
So epson
				go to the trouble of fitting chips to cartridges and building all
				the extra sockets, wiring, electronics and software into the
				printer so you can use the computer to see the predicted level
				and it can stop you printing if it think you've used enough ink.
				High-end Canon's on the other hand make the inks tank clear so
				you can see and have optical sensor to detect emptiness. This
				make a lot more sense – unless you are making an
				anti-refill device that is. Canon almost got my business this
				time but nobody I could find has run pigment in them – too
				risky.<br>
To get around the chip problems someone usually end up
				producing read-only chip which always read full (for use with
				CIS) and chip reseters for those who want to refill. These are
				not available for 2100p at the time of writing as far as I can
				tell.<br>
Before ordering my 2100p I did my homework and it seemed
				fairly likely a chip reseter would become available at some point
				and read-only chips as well. I was also cocky enough to think I
				could crack it myself and I have. It didn't go quite as expected
				though.<br>
<strong>What do I want to do?</strong><br>
I want the easiest way
				to fool the printer into believing it has full cartridges present
				so I can build my CIS.<br>
<strong>What did I expect?</strong><br>
A logical
				interface for Intellidge is i2c (i squared c) or TWI (two wire
				interface). Then the chip could just be some standard i2c eeprom.
				The Intellidge have too many pads for this but I was hopeful.
				After that would could SPI or microwire – again this could
				use off the shelf parts. If the chips were micro-controllers then
				plain asynchronous serial would be my choice.<br>
<strong>I had a
				look.</strong><br>
To do this I use a AVR mega323 micro, I declined
				offers of logic analyzers being a homebrew type of guy. The 323
				has 2K of internal ram which is enough for some minimalist data
				logging. It was about $50AUS in parts ($30US) to make. I wired a
				cartridge to bring the signals out and took a quick look with a
				voltmeter.<br>
<strong>Nothing!</strong><br>
There was nothing there. I
				expected some power but no, the chips are only powered briefly
				when the are accessed. I used leds to get a rough idea what was
				what and hooked up the micro via resistors to give some degree of
				protection to the printer if I screwed up. The code in the micro
				was written is assembler and captured data sent via rs232 to my
				PC where I wrote a delphi program to display and process the
				data.</p></td></tr>
<tr>
<td colspan="3">
</td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><a href="http://www.eddiem.com/photo/CIS/inkchip/traces.html"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/fastendsml.gif" name="Graphic5" width="615" height="213"></a><br>
<a href="http://www.eddiem.com/photo/CIS/inkchip/traces.html">Click
				here for more traces.</a></p>
<p lang="en-GB">This is the sort of thing I got. No
				protocol I ever seen. Obviously synchronous with bi-directional
				data, very short format. I was confused a little by how short it
				was - because I expect much better precision for the ink
				level.<br>
The traces seem to be.<br>
Top – some sort of sync
				line, this always goes low before the start of transmission.<br>
Next
				– power this goes low (off) between chip reads at printer
				startup but stays high during the shutdown – when data is
				written to the chip.<br>
Next – the clock, data is read of
				the rising edge and changed on the falling.<br>
Bottom –
				bi-directional data, the first 4 bits are always from printer to
				the chip, the rest depend on whether it is a read or write. LSB
				first (left).</p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB">Convert to binary and some patterns emerge.<br>
It
				was not real obvious how the chips were addressed or which bits
				encoded ink levels. Some more data when some ink had been used
				made it easier.</p>
<p lang="en-GB">Below is one chip being read at startup, there
				are 7 accesses one for each chip. Only 3 block have data –
				the other chips must be hooked to different data lines.</p>
<div lang="en-GB"><p><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/strtbinary.gif" name="Graphic6" width="818" height="45"></p></div></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB">Below is the complete shutdown stream. Again we
				can only see 3 chips from here.</p>
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/endbinary.gif" name="Graphic7" width="297" height="199"><br clear="left">
After
				printing a few bits near the beginning of the bit stream did
				change. It looks to me like the first 3 bits are the chip address
				the next is a write bit then the ink level, I get the feeling
				there aren't many bits used to encode it (later looks like 6).<br>
So
				– the top one shows 252 bits of data being read out of the
				chip.<br>
The first part of the shutdown shows just the ink level
				being read out, this is to check the same chip is there.<br>
The
				second part is the ink-level and some other stuff (printer serial
				number maybe) being written into the chip. Seeing I didn't use
				any ink the bit-stream is identical to the read except for bit 3
				– presumably the write bit.</p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><span size="5"><br>
Tuesday
				24 Sept 2002. I fooled the printer.</span></p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/spoofed.gif" name="Graphic8" width="381" height="363"><span size="3">The
				interesting thing about this screen grab is the black cartridge
				is really only two thirds full. I spoofed the printer by pulling
				the serial data line low during the time the ink level bits are
				being clocked out of the ink chip.<br>
This is means 6 bits
				starting at the 5'th bit in the stream.</span></p>
<p lang="en-GB"><span size="3">The first 3 bits appear to be the
				chip address, I guess the next is a read/write select. I used a
				AVR mega323 to detect the start of the serial transmission look
				for the address of chip1+read (black apparently) then pull data
				low for 6 clock edges. </span></p>
<p lang="en-GB"><span size="3">I'm sure I can reset 3 of the chips
				by tapping into chip1 signal. Reseting the rest will mean tapping
				into at least one more. </span></p>
<p lang="en-GB"><span size="3">The current set up is for
				experimentation only – it is not “the real thing”.</span></p>
<p lang="en-GB"><span size="3">Shorting the data to ground may be a
				bit drastic but it is only for a very brief time. I hoped the
				data line would be open collector but this doesn't seem to be the
				case.</span></p></td></tr></div></div>]]>
            </description>
            <link>http://www.eddiem.com/photo/CIS/inkchip/chip.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054177</guid>
            <pubDate>Wed, 11 Nov 2020 00:41:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nadia Eghbal on working (and writing) in public]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053962">thread link</a>) | @jger15
<br/>
November 10, 2020 | https://www.thepullrequest.com/p/nadia-eghbal | <a href="https://web.archive.org/web/*/https://www.thepullrequest.com/p/nadia-eghbal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg&quot;,&quot;height&quot;:1200,&quot;width&quot;:900,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:399616,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>                                                                                              Portrait by <a href="https://www.katiasobolski.com/">Katia Sobolski</a>.</em></p><p><strong>Nadia Eghbal is uniquely positioned to write about open source having spent almost two years in developer relations at the Alexandrian library of open source, GitHub. She then spent two years continuing her quasi-anthropological study of open source at Protocol Labs, and now works in writer relations at Substack (host of this publication). Her new book is <a href="https://www.amazon.com/Working-Public-Making-Maintenance-Software/dp/0578675862/">Working in Public: The Making and Maintenance of Open Source Software</a>, which like her career trajectory, starts in open source software but ends up grappling with larger issues of creators in an unbundled digital economy. </strong><em><strong><a href="https://pullrequest.substack.com/p/the-glory-of-achievement">The Pull Request</a></strong></em><strong><a href="https://pullrequest.substack.com/p/the-glory-of-achievement"> review is here</a>.</strong></p><p><em>AGM: My naive mental model of open-source was this almost communitarian kibbutz model. And yet, the big lesson from your book is that that’s not really how it works. </em></p><p>NE: Part of the reason why I wrote this book was because I feel like we've had this communitarian kibbutz kind of model, which you've identified, is the prevailing model that people understand in open source and that gets frequently talked about. And I think that narrative has kind of been owned by the likes of [Richard] Stallman or Eric Raymond or anyone who kind of remembers those early days of open source. And that model definitely still exists within the matrix of different community models. The ‘clubs’ are kind of like that, where everyone is rolling up their sleeves and there's lots of different active contributors. And then we also have  the ‘federations’ that are kinda like the really big open source projects that we're used to thinking about like Linux, but then there’s the rise of the ‘stadium’ model that is, I think, much newer.</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png&quot;,&quot;height&quot;:408,&quot;width&quot;:934,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:57769,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>The Eghbal model of open-source communities (referenced copiously here), whose contours are readily applicable more broadly.</em></p><p>If you look at what's happened to open source for the past 20 years, at some point demand outpaced supply and the amount of context that anyone can really have around any one open source project—because every developer is relying on like hundreds of different projects—it's not really possible to become this roll-up-your-sleeves member of every single project. And so, yeah, I think the governance does look really different and it’s specifically something that I didn't want to bang people over the head about it in the book. But I think a stadium model lends itself a little bit more to that kind authoritarian model and there’s less the kind of governance issues that we see in like a federation where people are like <em>this is a democracy!</em> and everyone is gonna ask everyone for opinions and stuff even if you might only have one or a few contributors. The contributors [in a stadium] are kind of just making the decisions and I think they should feel comfortable leaning into that. Even though right now I think a lot of them feel uncomfortable doing that because they keep being told that open source is supposed to this super participatory thing.</p><p><em>AGM: And you think that it doesn't necessarily have to be.</em></p><p>NE: I think the tension in one of these stadium models is where you do have a lot of users. And then you have some of these casual contributors who are opening issues, making feature requests or just lost, and you are kind of sorting through all that volume from people that you don't know. In my view, it's kind of like, well, I don't understand why should that person have a say in your project, if they've never looked at it before, and they're just kind of coming in for the first time and you're the core developer of the project. </p><p>There is a set of rhetoric in open source that says every person is a contributor, and anyone who kind of comes in, you should treat them as a contributor and like invest in them and all this stuff, but I don't feel like we would do that for anything else. If you had a hobby meetup kind of group with you and your friends and someone came in once and then was like <em>I think we should runs a group like this</em>, you'd be like: W<em>ho are you?</em> <em>This is this is our thing. </em>I think I want people to feel more comfortable saying that. And there's obvious parallels between that and the Internet at large right now.</p><p><em>AGM: You took the words right out of my mouth. In the book, you’ve got a long riff on the <a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons">tragedy of the commons</a>. Not that I want to turn this interview into a Facebook thing, because having worked there and spent part of my career on it, it's like the last thing I want to talk about…but I do think it's somewhat relevant in that, Twitter or Facebook, is it actually the public forum and a commons? Can Zuck or Jack run it as you suggest? Can they run it like [Guido] van Rossum does Python, as officially-titled Benevolent Dictator For Life? In some sense that’s actually better? </em></p><p>NE: Yeah. Well, I don't think Facebook is a commons anymore, just by sheer size that we’re dealing with. One of the things that I'm trying to do in the book is go back through Elinor Ostrom’s definition of a commons and saying, okay, she makes the argument that we can avoid this tragedy of the commons by having people self govern. But she has very specific rules that she's laid out around what actually qualifies something as a commons, so we can self govern in a healthy way, assuming these conditions hold and a lot of those conditions have to do with having clear membership boundaries and very high context for your interactions with each other. And so if you think just about Facebook being 2.6 billion people or however many people are on Facebook now, it's impossible that literally multiple billions of people all have that kind of context for each other. I think of Facebook as being this substrate that fosters a bunch of smaller communities. You might have Facebook Messenger which resembles more like the group chats or the ‘club’-style communities. You might have the ‘stadium’ type situations that are more like one person broadcasting out to a group of people and you might have Facebook groups which could be like either ‘clubs’ or ‘federations’ depending how big they are. You actually have a permutation of lots of different types of communities that are across the entire platform. But I think having that kind of vocabulary can help us figure out, what does it actually mean to develop governance for any of these platforms? It's the same thing with Twitter also. I don't see a world where we have one policy or a certain set of guidelines. </p><p><em>AGM: That’s a somewhat shocking statement.</em></p><p>NE: Yeah, it's so it's funny that that’s controversial. Part of what I was trying to do in the book is saying like, okay, let's not like talk about social media, let's just talk about this other weird thing called open source. And let's look at the dynamics there and how that's evolved for 20 years. Can you depersonalize this a little bit and if you agree with me that these things seem to be happening in open source. And stacking this up against other economic frameworks we've had in the past, like the commons, and it doesn't seem to hold here, then can we take that conclusion and transfer it back over somewhere else…</p><p><em>AGM: Okay, that's the vibe I got from your book that you were trying to actually talk about the rest of it. So it's good to know that I wasn't over-reading into it. </em></p><p>NE: I was trying to be sensible about it. </p><p><em>AGM: Do you think the push on Facebook for content moderation, and Twitter, is a fool's errand? You know how Kevin Roose and Charles Warzel of </em>The Times<em> and that whole whiny mob that's constantly trying to get them to moderate everything. You think that's probably not the way forward?</em></p><p>NE: It seems beyond not just gonna happen, it seems actively wrong to me. It’s as though we're asking another country to govern the United States or something. I'm trying to look at where do those governance boundaries start and who should be moderating themselves or not, and just the thought that you would have a sort of widespread platform governance on some of these issues just seems, yeah, morally wrong to me.</p><p><em>AGM: Are you a free-speech absolutist, Nadia, that rarest of breeds?</em></p><p>NE: I'm not super public about my politics, but then I don’t mind poking my head out a little bit around it and publishing the book was kind of part of this for me because, to be totally frank, there are these democratic kind of ideals and these like communist-y ideals that we are holding about both the Internet and open source which are driving me crazy and, I'm trying to point out, you know, that's not always the case. And sometimes it's about one person who was doing a lot of things and we're just like couching it in a group cooperative. Yeah, I don't really know what my politics are, but I definitely err as far to that side as possible, as I think is reasonable. I do think this kind of moderation stuff, no one really has the answer to it. And so I'm not gonna sit here and be like, <em>I know how to fix it!</em> No one knows how to fix Facebook. Or any of these platforms. There's there's some humility that should be in place there, but I know what I stand for and what I'm aiming for.</p><p><em>AGM: I dislike looking always at the extreme example. But you know, Balaji [Srinivasan] had this whole dust-up with Taylor Lorenz and he's constantly getting into fights with these media people. And it's weird because he's often so right in so many ways, and he's good at getting attention. But somehow he hasn't parlayed into a mainstream following. </em></p><p>NE: I do feel like we need to have institutions a little bit in order to reinforce that. Well, I don't know if that's true or not, because people do follow like Elon Musk or Joe Rogan, or whatever. So that does exist. But I feel it would be so nice that if we had a publication that we could be proud of, that people would read outside of tech. There's no legible symbols for someone else to kind of follow. Like it's even weird that the most popular tech figures are not always the most popular figures actually in tech. Like Mark Cuban …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thepullrequest.com/p/nadia-eghbal">https://www.thepullrequest.com/p/nadia-eghbal</a></em></p>]]>
            </description>
            <link>https://www.thepullrequest.com/p/nadia-eghbal</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053962</guid>
            <pubDate>Wed, 11 Nov 2020 00:16:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analyzing Voting Systems]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053892">thread link</a>) | @shihn
<br/>
November 10, 2020 | https://shihn.ca/posts/2020/voting-systems/ | <a href="https://web.archive.org/web/*/https://shihn.ca/posts/2020/voting-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      
<h2>Introduction</h2>
<p>We encounter voting in some form around us all the time. We rate our Uber drivers, they rate us back. We up-vote and down-vote posts and trolls on Reddit. We give stars to movies and restaurants. We vote on who gets kicked out of our favorite reality television show. We vote for Presidents.</p>
<p>All these voting systems seem a bit different from one another, but one thing that's definitely common among them — we will find ways to complain about them. The way a voting system is designed can make an <em>election</em> trivial or really complicated in nature. In fact, sometimes, the winner of an election may be determined by the rules of the voting system and not the intent of the voters (electoral college anyone?). In this post I try to explore the core of different voting systems and wonder if there is a perfect voting system.</p>
<p>Here I am going to use the word <em>election</em> to define an event or a goal that requires voting. An election doesn't have to be political in nature.</p>
<p><em>Note and Acknowledgement: This blog post is influenced by the chapter on voting systems in video games in the book Power-Up by Matthew Lane.</em></p>
<h2>Plurality Voting</h2>
<p>This is the simplest form of voting. Most political elections in the United States are done using this form of voting. It's quite simple — every voter casts a vote for their favorite candidate. The candidate with the most number of votes wins.</p>
<p>Let's look at an example that we will continue to use in this post. We ask 100 people to vote for their favorite flavor of ice cream. The candidates are <em>Vanilla</em>, <em>Chocolate</em>, and <em>Strawberry</em>. Here's the result:</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>45</td>
</tr>
<tr>
<td>Chocolate</td>
<td>40</td>
</tr>
<tr>
<td>Strawberry</td>
<td>15</td>
</tr>
</tbody>
</table>
<p><strong>Vanilla has won!</strong> Now if you stare at the numbers a bit, you will find some downsides in declaring Vanilla the winner in this election of the flavors.</p>
<p>An obvious one is that more votes were cast for a flavor that is not the winning flavor. You could also argue that no flavor should win because none of them reached a majority.</p>
<p>Here Strawberry is acting as a <strong>spoiler</strong> — similar to how third-party candidates in US elections can be considered spoilers. Maybe we should have a <strong><em>run-off election</em></strong> where only Vanilla and Chocolate are considered. Perhaps more people favor Chocolate over Vanilla when Strawberry is out of the picture. (The US state of Georgia has rules akin to this. In the 2020 elections for the senate seats in Georgia, none of the candidates achieved a majority. So run-off elections will be held in January of 2021 with the top two candidates).</p>
<p>The essence of the Plurality voting system is that it does not capture the full spectrum of voters' preferences. If someone voted for Strawberry, it does not tell us how they feel about Vanilla or Chocolate.</p>
<p>This system does not truly determine the <em>'will of the people'</em>, unless.... there are only two candidates. One of the candidates is guaranteed to receive a majority, barring a tie. So if it were truly a <em>two-party system</em> some of the flaws of this system do not matter any more.</p>
<h2>Ranked Choice Voting</h2>
<p>Since the Plurality based system does not capture the full spectrum of the voter's preferences, we should probably ask for more information from the voters. What if we asked the voters to rank all the candidates, rather than cast a ballot for their favorite?</p>
<p>Let's look at the example we've been working with. We asked the 100 people to rank the candidate flavors. Here's the result:</p>
<table>
<thead>
<tr>
<th>1st</th>
<th>2nd</th>
<th>3rd</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>Strawberry</td>
<td>Chocolate</td>
<td>45</td>
</tr>
<tr>
<td>Strawberry</td>
<td>Chocolate</td>
<td>Vanilla</td>
<td>15</td>
</tr>
<tr>
<td>Chocolate</td>
<td>Strawberry</td>
<td>Vanilla</td>
<td>30</td>
</tr>
<tr>
<td>Chocolate</td>
<td>Vanilla</td>
<td>Strawberry</td>
<td>10</td>
</tr>
</tbody>
</table>
<p>All of the 45 people who voted for Vanilla had Strawberry as the second choice. All 15 people who voted for Strawberry, had Chocolate as their second choice. Of the 40 people who voted for Chocolate, 30 preferred Strawberry over Vanilla, and 10 preferred Vanilla. So, which flavor won? There are multiple ways to interpret this data. Let's look at a couple 👇</p>
<h2>Borda Count</h2>
<p>In this system for <code>n</code> candidates, each first-place vote receives <code>n</code> points. Second-place receives <code>n-1</code> points, and so on. The candidate with the most points wins.</p>
<p>Let's compute the points in our example. Vanilla received 45 first places, 10 second places, and 45 third places. So the score for Vanilla is <code>45n + 10(n-1) + 45(n-2)</code>. Here, <code>n</code> is <code>3</code>, giving Vanilla a score of <code>200</code>. Here's the final tally:</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Points</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>200</td>
</tr>
<tr>
<td>Chocolate</td>
<td>195</td>
</tr>
<tr>
<td>Strawberry</td>
<td>205</td>
</tr>
</tbody>
</table>
<p><strong>Strawberry has won!</strong> Strawberry, which had the fewest votes in the Plurality voting system, has the most points in the Borda ranking system. Totally ridiculous, isn't it? Well maybe, but maybe not. Strawberry did receive the fewest third-place votes. And 75% of the people had Strawberry as their second choice.  Perhaps Strawberry does deserve to win!</p>
<h2>Instant Runoff Voting</h2>
<p>Let's take a look at a different model of interpreting the ranked voting data. In an Instant Runoff, the candidate with the fewest first-place votes is eliminated, and its votes are distributed to the second choice. This is then repeated until we have one candidate left standing.</p>
<p>Some consider this model of iterative elimination a bit confusing and thereby not practical. But it's getting wide adoption, including in political elections (San Francisco and Oakland city elections, for example). It is also used to decide the winner of the Best Picture Academy Award.</p>
<p>Let's apply this to our current example.</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>45</td>
</tr>
<tr>
<td>Chocolate</td>
<td>40</td>
</tr>
<tr>
<td>Strawberry (eliminated)</td>
<td>15</td>
</tr>
</tbody>
</table>
<p>Strawberry is eliminated. Since all Strawberry voters preferred Chocolate over Vanilla, Chocolate gets Strawberry's 15 votes. Chocolate now has 55 votes, a majority. <strong>Chocolate has won!</strong></p>
<h2>Quick Recap</h2>
<p>We have discussed three systems so far, and in our example, we have had three different winners for the same election. You may decide subjectively that one of these systems may be better for the use case you have in mind, or you might think as I did at first: <strong>It's all pointless!</strong></p>
<h2>The Impossibility</h2>
<p>There is a concept in decision theory called the <strong><a href="https://en.wikipedia.org/wiki/Independence_of_irrelevant_alternatives">Independence of Irrelevant Alternatives (IIA)</a></strong> which states a voter's preference between two choices <code>x</code> and <code>y</code>, should not depend on any other choices.</p>
<p>This seems like a simple and a good rule to live by and our election systems should live by them as well. Sadly, all the systems we have looked at so far do not abide by this rule.</p>
<p>Let's look at the Plurality system - From the rankings we know that all of Strawberry voters prefer Chocolate over Vanilla. If the choice of Strawberry was not there, Chocolate would have won with 55 votes. But with Strawberry present, Vanilla wins with 45 votes.</p>
<p>For the Borda system, Chocolate is the spoiler. With Chocolate in the picture, Strawberry wins. Without Chocolate, Vanilla wins 55-45.</p>
<p>In the Instant Runoff, Chocolate wins when Vanilla is present but Strawberry wins 60-40 if Vanilla is not.</p>
<h3>Arrow's Impossibility Theorem</h3>
<p>In decision theory, here are some good things to have in an election or any voting system.</p>
<ul>
<li>Independence of Irrelevant Alternatives: which we have discussed and failed to account for so far.</li>
<li>Nondictatorship: Output should not be based on one individual, the wishes of multiple voters should be taken into consideration.</li>
<li>Pareto Efficiency (Unanimity): should have a notion of <a href="https://en.wikipedia.org/wiki/Pareto_efficiency">unanimity</a> — If every voter prefers candidate A over candidate B, candidate A should win.</li>
<li>Unrestricted Domain: Voting must account for all individual preferences.</li>
<li>Ordering:  Each individual should be able to order the choices in any way.</li>
</ul>
<p>All good rules, don't you think? Let's create the ultimate voting system! But here comes <a href="https://en.wikipedia.org/wiki/Kenneth_Arrow">Kenneth Arrow</a> to shatter our hopes.</p>
<p><strong><a href="https://en.wikipedia.org/wiki/Arrow's_impossibility_theorem">Arrow's Impossibility Theorem</a> states that in all cases where preferences are ranked, it is impossible to formulate a social ordering without violating one of these rules.</strong></p>
<p>In other words, any democracy that satisfies Unanimity and the Independence of Irrelevant Alternatives, must be a dictatorship! *<em>insert dramatic sound effects</em>*</p>
<p>So yeah, we will always find things to argue about in an election. 😒</p>
<h2>Dodging the Impossibility</h2>
<p>Since every system is flawed, is it the end of this essay? Unfortunately for you, I, like many of you, noticed this one clause in Arrow's impossibility theorem which provides a way for us to escape this gravity well.</p>
<p>The theorem assumes that we are dealing with a ranked choice voting system. Let's just not rank our candidates. 💡</p>
<p>Here I would remind you, that we're trying to look at voting systems in general, not just political elections.</p>
<p>We have implemented non rank based systems in Software numerous times. Think Netflix, Yelp, Reddit, Tinder. The key as you may have guessed is rating, and not ranking (Tinder being a more specific type of rating - approval voting, which I'll discuss later). A voting system based on rating is usually called <strong>Score Voting</strong>.</p>
<h2>Score Voting</h2>
<p>The idea behind score voting is that you give each candidate a score in one or many categories. This score is independent of the score the other candidates receive. Think Diving and Gymnastics in the Olympics. The judges rate each athlete based on form, routine, landings. One with the highest total score wins.</p>
<p>But is this system better? That's subjective but we know it lets us escape the impossibility mathematically, and yet conform to independence, unanimity and nondictatorship rules.</p>
<h2>Approval Voting</h2>
<p>There's a simpler form or Score Voting - Approval Voting. Think of it as a binary version of the score voting. Each person can give a candidate a score of <code>0</code> or <code>1</code>. In other words one can approve or disapprove any number of candidates.</p>
<p>This is similar to how people vote on dating apps like Tinder. They give prospects a score of <code>1</code> by swiping right, and a score of <code>0</code> by swiping left.</p>
<h2>Strategizing the Ranked Vote</h2>
<p>One key advantage for Score Voting and Approval Voting is that it never hurts to vote for your favorite candidate. It may seem obvious and trivial but it's not always satisfied by voting systems. For example, it is common in political elections for people to not vote for the third-party candidate even though the third-party candidate may be the voter's first …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shihn.ca/posts/2020/voting-systems/">https://shihn.ca/posts/2020/voting-systems/</a></em></p>]]>
            </description>
            <link>https://shihn.ca/posts/2020/voting-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053892</guid>
            <pubDate>Wed, 11 Nov 2020 00:09:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Frontload: Simple full-stack data loading for React]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053845">thread link</a>) | @davnicwil
<br/>
November 10, 2020 | https://davnicwil.com/react-frontload/ | <a href="https://web.archive.org/web/*/https://davnicwil.com/react-frontload/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactroot="" data-reactid="1" data-react-checksum="1067123220"><div data-reactid="6"><div data-reactid="7"><p><img src="https://davnicwil.com/image/react-frontload-logo.png" width="100" height="100" data-reactid="8"></p></div><p data-reactid="10"><h2 data-reactid="11">Simple full-stack data loading for React</h2></p><p><a href="https://www.npmjs.com/package/react-frontload" data-reactid="13"><img src="https://img.shields.io/npm/v/react-frontload?style=social&amp;logo=npm" data-reactid="14"></a><a href="https://github.com/davnicwil/react-frontload" data-reactid="15"><img src="https://img.shields.io/github/stars/davnicwil/react-frontload?style=social" data-reactid="16"></a><a href="https://www.npmjs.com/package/react-frontload" data-reactid="17"><img src="https://img.shields.io/npm/dm/react-frontload?style=social" data-reactid="18"></a><a href="https://twitter.com/davnicwil" data-reactid="19"><img src="https://img.shields.io/twitter/url?label=made%20by%20%40davnicwil&amp;style=social&amp;url=https%3A%2F%2Fdavnicwil.com" data-reactid="20"></a></p></div><p data-reactid="21">React Frontload is a library to load and manage data inline in React components that works on both client and server.</p><div data-reactid="22"><ul data-reactid="23"><li data-reactid="24"><span data-reactid="25">Load data with a hook which works on client and server</span></li><li data-reactid="26"><span data-reactid="27">Data is managed in component state - no need for Redux / MobX</span></li><li data-reactid="28"><span data-reactid="29">Written in TypeScript, typing is easy as everything's inline</span></li><li data-reactid="30"><span data-reactid="31">Less than 3.5KB Gzipped, zero dependencies</span></li></ul></div><div data-reactid="32"><div data-reactid="33"><!-- react-text: 34 --><p>v2 has just shipped! </p><!-- /react-text --><p><a href="https://davnicwil.com/react-frontload/v2" data-reactid="35">See here</a></p><!-- react-text: 36 --><p> for the motivation for v2 and comparison with v1</p><!-- /react-text --></div></div><div data-reactid="37"><p>Install</p><p>npm install react-frontload</p></div><div id="problem" data-reactid="53"><h3 data-reactid="54">What problem does this solve?</h3><p><a href="#problem" data-reactid="55">#</a></p></div><p data-reactid="56">React provides no built-in way to do data loading - it's left for you to implement. Doing this is tricky in a React app that uses server side rendering (SSR) because client and server rendering work quite differently: Client render is async so data can be loaded inside components when they render, but server render is completely synchronous - the data must be loaded before render happens.</p><p data-reactid="57">Data loading is, of course, async. The client component-centric data loading pattern is nice, but it's incompatible with synchronous server render. React simply has no mechanism to wait for data to load when components render on SSR. There's a further problem too: React also provides no built-in way to hydrate data loaded during SSR into client state on first render. This is also up to you to implement.</p><p data-reactid="58">So, full stack data loading in React is a tricky problem. A couple of solutions have emerged:</p><ol data-reactid="59"><li data-reactid="60"><p data-reactid="61">Load data at the route level, instead of the component level, then pass data to all components under the route. Works on SSR since the route is known in the request, so data can be loaded before render begins. Can be implemented by piecing together router and state manager libraries.</p></li><li data-reactid="62"><p data-reactid="63">Use a framework that wraps React and abstracts the problem away, perhaps by providing a framework-specific async data loading function for components that works on SSR, and also takes care of hydrating state on the client.</p></li></ol><p data-reactid="64">React Frontload aims to provide a third way - the component-centric data loading pattern available full stack, but without having to buy into a whole framework just to get this feature. It's just a small library that solves this one problem, and can be used in any React stack.</p><p data-reactid="68">Here's an example of loading data into a component with React Frontload</p><p><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span>
    stuff<span>:</span> <span>await</span> api<span>.</span><span>getStuff</span><span>(</span><span>)</span>
  <span>}</span><span>)</span><span>)</span>

  <span>if</span> <span>(</span>frontloadMeta<span>.</span>pending<span>)</span> <span>return</span> <span>&lt;</span>div<span>&gt;</span>loading<span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>if</span> <span>(</span>frontloadMeta<span>.</span>error<span>)</span>   <span>return</span> <span>&lt;</span>div<span>&gt;</span>error<span>&lt;</span><span>/</span>div<span>&gt;</span>

  <span>return</span> <span>&lt;</span>div<span>&gt;</span><span>{</span>data<span>.</span>stuff<span>}</span><span>&lt;</span><span>/</span>div<span>&gt;</span>
<span>}</span>
</p><p data-reactid="70"><!-- react-text: 71 -->Here we have a <!-- /react-text --><span data-reactid="72">Component</span><!-- react-text: 73 --> that needs to load <!-- /react-text --><span data-reactid="74">stuff</span><!-- react-text: 75 --> from an API, with the usual loading state whilst it loads and some sort of error state if loading fails for some reason.<!-- /react-text --></p><p data-reactid="76"><!-- react-text: 77 -->With React Frontload, we do this by passing an async data loading function to the <!-- /react-text --><span data-reactid="78">useFrontload</span><!-- react-text: 79 --> hook. The hook loads the return value of the function into<!-- /react-text --><!-- react-text: 80 --> <!-- /react-text --><span data-reactid="81">data</span><!-- react-text: 82 -->, and gives us<!-- /react-text --><!-- react-text: 83 --> <!-- /react-text --><span data-reactid="84">frontloadMetadata</span><!-- react-text: 85 --> out the box so we can see when it's still <!-- /react-text --><span data-reactid="86">pending</span><!-- react-text: 87 --> or if an <!-- /react-text --><span data-reactid="88">error</span><!-- react-text: 89 --> is thrown when running the function.<!-- /react-text --></p><p data-reactid="90"><!-- react-text: 91 -->That's it - we're done in those few lines of code. That's the power of doing data loading inline in a component. And the best part here is that this just works on the server. If we render<!-- /react-text --><!-- react-text: 92 --> <!-- /react-text --><span data-reactid="93">Component</span><!-- react-text: 94 --> in a route, any route,<!-- /react-text --><!-- react-text: 95 --> <!-- /react-text --><span data-reactid="96">stuff</span><!-- react-text: 97 --> will load.<!-- /react-text --></p><p data-reactid="98"><!-- react-text: 99 -->To emphasise the ease and lack of plumbing involved in making changes, let's have <!-- /react-text --><span data-reactid="100">Component</span><!-- react-text: 101 --> load some more stuff:<!-- /react-text --></p><p><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span>
    stuff<span>:</span> <span>await</span> api<span>.</span><span>getStuff</span><span>(</span><span>)</span><span>,</span>
    moreStuff<span>:</span> <span>await</span> api<span>.</span><span>getMoreStuff</span><span>(</span><span>)</span> 
  <span>}</span><span>)</span><span>)</span>

  <span>if</span> <span>(</span>frontloadMeta<span>.</span>pending<span>)</span> <span>return</span> <span>&lt;</span>div<span>&gt;</span>loading<span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>if</span> <span>(</span>frontloadMeta<span>.</span>error<span>)</span>   <span>return</span> <span>&lt;</span>div<span>&gt;</span>error<span>&lt;</span><span>/</span>div<span>&gt;</span>

  <span>return</span> <span>&lt;</span>div<span>&gt;</span><span>{</span>data<span>.</span>stuff<span>}</span> and <span>{</span>data<span>.</span>moreStuff<span>}</span><span>&lt;</span><span>/</span>div<span>&gt;</span> 
<span>}</span>
</p><p data-reactid="103"><!-- react-text: 104 -->It's literally that simple - just add whatever you need to<!-- /react-text --><!-- react-text: 105 --> <!-- /react-text --><span data-reactid="106">useFrontload</span><!-- react-text: 107 --> and use it. Remember that this is all automatically typed. If the value returned by the<!-- /react-text --><!-- react-text: 108 --> <!-- /react-text --><span data-reactid="109">getMoreStuff</span><!-- react-text: 110 --> api call is a<!-- /react-text --><span data-reactid="111">string</span><!-- react-text: 112 -->,<!-- /react-text --><!-- react-text: 113 --> <!-- /react-text --><span data-reactid="114">data.moreStuff</span><!-- react-text: 115 --> has the string type, and you'll get errors if you try to use it as a number.<!-- /react-text --></p><p data-reactid="116"><!-- react-text: 117 -->You may have noticed that the above code loads data less efficiently than it could. <!-- /react-text --><span data-reactid="118">api.getStuff()</span><!-- react-text: 119 --> and<!-- /react-text --><!-- react-text: 120 --> <!-- /react-text --><span data-reactid="121">api.getMoreStuff()</span><!-- react-text: 122 --> are called in serial, when they could probably be called in parallel. Since it's just Javascript, though, we can change this:<!-- /react-text --></p><p><span>const</span> <span>{</span> data<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>[</span>stuff<span>,</span> moreStuff<span>]</span> <span>=</span> Promise<span>.</span><span>all</span><span>(</span><span>[</span>
    api<span>.</span><span>getStuff</span><span>(</span><span>)</span><span>,</span>
    api<span>.</span><span>getMoreStuff</span><span>(</span><span>)</span>
  <span>]</span><span>)</span>

  <span>return</span> <span>{</span> stuff<span>,</span> moreStuff <span>}</span>
<span>}</span><span>)</span>
</p><p data-reactid="124">In fact as data loaders get more complex, you can use any combination of serial and parallel that you need. It's just Javascript - you have the full power of the language without any abstractions or misdirection on top.</p><p data-reactid="125"><!-- react-text: 126 -->There is one more piece to this - what about updating data? Since React Frontload uses React component state to hold<!-- /react-text --><!-- react-text: 127 --> <!-- /react-text --><span data-reactid="128">data</span><!-- react-text: 129 -->, updating it is just a case of updating that state. React Frontload provides another function, called<!-- /react-text --><!-- react-text: 130 --> <!-- /react-text --><span data-reactid="131">setData</span><!-- react-text: 132 -->, for this:<!-- /react-text --></p><p><span>const</span> <span>Component</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> setData<span>,</span> frontloadMeta <span>}</span> <span>=</span> <span>useFrontload</span><span>(</span><span>'my-component'</span><span>,</span> <span>async</span> <span>(</span><span><span>{</span> api <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span>
    stuff<span>:</span> <span>await</span> api<span>.</span><span>getStuff</span><span>(</span><span>)</span>
  <span>}</span><span>)</span><span>)</span>

  <span>if</span> <span>(</span>frontloadMeta<span>.</span>pending<span>)</span> <span>return</span> <span>&lt;</span>div<span>&gt;</span>loading<span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>if</span> <span>(</span>frontloadMeta<span>.</span>error<span>)</span>   <span>return</span> <span>&lt;</span>div<span>&gt;</span>error<span>&lt;</span><span>/</span>div<span>&gt;</span>

  <span>const</span> <span>updateStuff</span> <span>=</span> <span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>try</span> <span>{</span>
      <span>const</span> updatedStuff <span>=</span> <span>await</span> <span>updateStuff</span><span>(</span><span>'new value'</span><span>)</span> 
      <span>setData</span><span>(</span><span>data</span> <span>=&gt;</span> <span>(</span><span>{</span> <span>...</span>data<span>,</span> stuff<span>:</span> updatedStuff <span>}</span><span>)</span><span>)</span> 
    <span>}</span> <span>catch</span> <span>{</span>
      
    <span>}</span>
  <span>}</span>

  <span>return</span> <span>(</span>
    <span>&lt;</span><span>&gt;</span>
      <span>&lt;</span>div<span>&gt;</span><span>{</span>data<span>.</span>stuff<span>}</span><span>&lt;</span><span>/</span>div<span>&gt;</span>
      <span>&lt;</span>button onClick<span>=</span><span>{</span>updateStuff<span>}</span><span>&gt;</span>update<span>&lt;</span><span>/</span>button<span>&gt;</span>
    <span>&lt;</span><span>&gt;</span>
  <span>)</span>
</p><p data-reactid="134"><!-- react-text: 135 -->Again, this is all just inline in the component with zero plumbing. If you're coming from Redux, you can think of<!-- /react-text --><!-- react-text: 136 --> <!-- /react-text --><span data-reactid="137">setData</span><!-- react-text: 138 --> a little bit like a mini reducer. It takes the existing value of<!-- /react-text --><!-- react-text: 139 --> <!-- /react-text --><span data-reactid="140">data</span><!-- react-text: 141 --> as an argument, and you merge updates into it to return an updated value of<!-- /react-text --><!-- react-text: 142 --> <!-- /react-text --><span data-reactid="143">data</span><!-- react-text: 144 -->.<!-- /react-text --></p><p data-reactid="145">And that's it - full stack data loading and management inline in your React components.</p><p data-reactid="149"><!-- react-text: 150 -->The <!-- /react-text --><span data-reactid="151">useEffect</span><!-- react-text: 152 --> hook seen in the example above is the core of React Frontload - the code you'll actually work with in your components - but there is also a small amount of one-time setup code to write to get it to work.<!-- /react-text --></p><p data-reactid="153"><!-- react-text: 154 -->Essentially this is setting up wrappers around your server render logic, and your React application on both server and client, to make the<!-- /react-text --><span data-reactid="155">useFrontload</span><!-- react-text: 156 --> hook work, and also enable hydration of state loaded on server render to the client.<!-- /react-text --></p><p data-reactid="157">App Provider</p><p data-reactid="158">Wrap your app in the React Frontload provider</p><p><span>import</span> <span>{</span> FrontloadProvider <span>}</span> <span>from</span> <span>'react-frontload'</span>

<span>const</span> <span>App</span> <span>=</span> <span>(</span><span><span>{</span> frontloadState <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span>
  <span>&lt;</span>FrontloadProvider initialState<span>=</span><span>{</span>frontloadState<span>}</span><span>&gt;</span>
    <span>&lt;</span>Content<span>&gt;</span><span>...</span><span>&lt;</span><span>/</span>Content<span>&gt;</span>
  <span>&lt;</span><span>/</span>FrontloadProvider<span>&gt;</span>
<span>)</span>
</p><p data-reactid="160">Server render</p><p data-reactid="161"><!-- react-text: 162 -->On server render, you need to wrap your existing synchronous server render code with<!-- /react-text --><!-- react-text: 163 --> <!-- /react-text --><span data-reactid="164">reactFrontloadServerRender</span><!-- react-text: 165 -->.<!-- /react-text --></p><p data-reactid="166"><!-- react-text: 167 -->You can think of this as the polyfill that allows React Frontload to load data asynchronously on server render. It just uses regular React server rendering under the hood, and its output is exactly the same. Read more about this <!-- /react-text --><a href="#how-it-works" data-reactid="168">here</a><!-- react-text: 169 -->.<!-- /react-text --></p><p><span>import</span> <span>{</span> renderToString <span>}</span> <span>from</span> <span>'react-dom/server'</span>
<span>import</span> <span>{</span> createFrontloadState<span>,</span> frontloadServerRender <span>}</span> <span>from</span> <span>'react-frontload'</span>
<span>import</span> serverApi <span>from</span> <span>'./serverApi'</span>

app<span>.</span><span>get</span><span>(</span><span>'*'</span><span>,</span> <span>async</span> <span>(</span><span>req<span>,</span> res</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>...</span>

  
  
  <span>const</span> frontloadState <span>=</span> createFrontloadState<span>.</span><span>server</span><span>(</span><span>{</span>
    
    
    
    context<span>:</span> <span>{</span> api<span>:</span> serverApi <span>}</span>
  <span>}</span><span>)</span>

  <span>try</span> <span>{</span>
    
    <span>const</span> <span>{</span> rendered<span>,</span> data <span>}</span> <span>=</span> <span>await</span> <span>frontloadServerRender</span><span>(</span><span>{</span>
      frontloadState<span>,</span>
      <span>render</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>renderToString</span><span>(</span><span>&lt;</span>App frontloadState<span>=</span><span>{</span>frontloadState<span>}</span> <span>/</span><span>&gt;</span><span>)</span>
    <span>}</span><span>)</span>

    res<span>.</span><span>send</span><span>(</span><span><span>`</span><span>
      &lt;html&gt;
        ...
        &lt;!-- server rendered markup --&gt;
        </span><span><span>${</span>rendered<span>}</span></span><span>

        &lt;!-- loaded data (to be hydrated on client) --&gt;
        &lt;script&gt;window._frontloadData=</span><span><span>${</span><span>toSanitizedJSON</span><span>(</span>data<span>)</span><span>}</span></span><span>&lt;/script&gt;
        ...
      &lt;/html&gt;
    </span><span>`</span></span><span>)</span>
  <span>}</span> <span>catch</span> <span>(</span>err<span>)</span> <span>{</span>
    
  <span>}</span>
<span>}</span><span>)</span>
</p><p data-reactid="171"><!-- react-text: 172 -->The output of<!-- /react-text --><!-- react-text: 173 --> <!-- /react-text --><span data-reactid="174">reactFrontloadServerRender</span><!-- react-text: 175 --> contains a <!-- /react-text --><span data-reactid="176">rendered</span><!-- react-text: 177 --> string, which is just the server render output to inject into your HTML template as usual.<!-- /react-text --></p><p data-reactid="178"><!-- react-text: 179 -->It also contains a <!-- /react-text --><span data-reactid="180">data</span><!-- react-text: 181 --> object, which you should serialize into your HTML as sanitised JSON.<!-- /react-text --><!-- react-text: 182 --> <!-- /react-text --><span data-reactid="183">data</span><!-- react-text: 184 --> contains all the data loaded for the current view across all components, and the purpose of this is to hydrate this data into React Frontload on the client (using<!-- /react-text --><!-- react-text: 185 --> <!-- /react-text --><span data-reactid="186">initialState</span><!-- react-text: 187 -->) so that it does not have to be reloaded on first render. This pattern is essentially the same as the one you see with other state managers such as Redux.<!-- /react-text --></p><p data-reactid="188">Client render</p><p data-reactid="189">The last remaining step is client integration, which is rather simpler. Just initialise a React Frontload state object on the client using your serialized data from server render, and pass it to the provider.</p><p><span>import</span> clientApi <span>from</span> <span>'./clientApi'</span>

<span>const</span> frontloadState <span>=</span> createFrontloadState<span>.</span><span>client</span><span>(</span><span>{</span>
  
  
  context<span>:</span> <span>{</span> api<span>:</span> clientApi <span>}</span><span>,</span>

  
  serverRenderedData<span>:</span> window<span>.</span>_frontloadData
<span>}</span><span>)</span>
<span>...</span>
ReactDOM<span>.</span><span>render</span><span>(</span><span>&lt;</span>App frontloadState<span>=</span><span>{</span>frontloadState<span>}</span> <span>/</span><span>&gt;</span><span>,</span> <span>...</span><span>)</span>
</p><p data-reactid="194">For most usecases, you don't need to care about this.</p><p data-reactid="195">That said, all abstractions are leaky at some point, and it's always useful to understand how things work under the hood so that when they behave unexpectedly, you can figure out why.</p><p data-reactid="196">The mechanism used to polyfill async on server render is deliberately very simple. As shown in the code above, React Frontload wraps ordinary synchronous server render code with an async function.</p><p data-reactid="197"><!-- react-text: 198 -->It works by running that synchronous function, and collecting the promises encountered on each render of a<!-- /react-text --><!-- react-text: 199 --> <!-- /react-text --><span data-reactid="200">useFrontload</span><!-- react-text: 201 --> hook. After the render, the collected promises are then awaited, which loads the data in those functions the same as it would be on the client. Now, React Frontload runs the server render again - this time injecting the data loaded from the previous run into each component ahead of the render. In this new render round, if no new<!-- /react-text --><!-- react-text: 202 --> <!-- /react-text --><span data-reactid="203">useFrontload</span><!-- react-text: 204 --> hooks are encountered (i.e. if there are no nested components with a<!-- /react-text --><!-- react-text: 205 --> <!-- /react-text --><span data-reactid="206">useFrontload</span><!-- react-text: 207 --> hook), then the output of this render is returned as the final output. If nested<!-- /react-text --><!-- react-text: 208 --> <!-- /react-text --><span data-reactid="209">useFrontload</span><!-- react-text: 210 --> hooks<!-- /react-text --><!-- react-text: 211 --> <!-- /react-text --><span data-reactid="212">are</span><!-- react-text: 213 --> found, the process repeats.<!-- /react-text --></p><ul id="api-useFrontload" data-reactid="225"><li data-reactid="226"><span data-reactid="227">useFrontload</span><a href="#api-useFrontload" data-reactid="228">#</a></li></ul><p data-reactid="229"><span data-reactid="230">useFrontload</span><!-- react-text: 231 --> is the React Frontload hook.<!-- /react-text --></p><p><span>import</span> <span>{</span> useFrontload <span>}</span> <span>from</span> <span>'react-frontload'</span>

<span>useFrontload</span><span>(</span>
  …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davnicwil.com/react-frontload/">https://davnicwil.com/react-frontload/</a></em></p>]]>
            </description>
            <link>https://davnicwil.com/react-frontload/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053845</guid>
            <pubDate>Wed, 11 Nov 2020 00:03:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anonymous Donations to Universities Skyrocketing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25053747">thread link</a>) | @SilentDonor
<br/>
November 10, 2020 | https://silentdonor.com/anonymous-donations-to-universities/ | <a href="https://web.archive.org/web/*/https://silentdonor.com/anonymous-donations-to-universities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>		
		<div>
			
<p><span>We have been following a sustained trend that has hit higher-education institutions for a few years now: the rise of anonymous donations to universities. The desire among donors to remain private in their gifts to universities includes everything from millennials sending small sums, to wealthy donors giving gigantic</span><span> </span><a rel="noreferrer noopener" href="https://news.berkeley.edu/2020/02/29/largest-gift-in-berkeleys-history-will-create-a-hub-for-advancing-data-science/" target="_blank"><span><span>$252 million</span></span></a> <span>donations</span>. <span>Read more to <strong>see just how prevalent anonymous giving</strong> has become in donating to universities. </span></p>



<p><span>The choice to pursue anonymity as a donor is becoming more attractive for a variety of reasons (for more on the ‘why’ behind the choice to be anonymous, see our article</span> <a rel="noreferrer noopener" href="https://silentdonor.com/why-send-an-anonymous-donation/" target="_blank"><span><span>here</span></span></a>). <span>However, the traditional way of giving “anonymously” to a university almost always means that the university actually knows who the donor is, but simply agrees to keep it confidential. Some institutions try to set up private foundations to help conceal the donors’ identities, but, as this</span> <a rel="noreferrer noopener" href="https://www.chronicle.com/article/million-dollar-mystery-anonymous-donors-even-the-colleges-dont-know/" target="_blank"><span><span>Chronicle article</span></span></a> <span>reports,</span> “<em>In college fund raising, anonymous donors typically aren’t truly anonymous. Someone on campus — the president, or a top fund raiser who worked with the donor — knows the identity of the person who gave the gift.</em>” </p>



<p><span>Many times this <strong>current system fails</strong> both the donors and the recipient universities, as the donor is not getting the actual anonymity they desire and now famously bureaucratic universities have to fight to keep their identity under wraps – lest they risk angering and/or exposing their anonymous donor, which is exactly what happened to</span> <span><a rel="noreferrer noopener" href="https://www.bizjournals.com/portland/blog/health-care-inc/2014/08/the-news-pbj-readers-didnt-care-to-know-gert-boyle.html" target="_blank"><span>a $100 million anonymous donor</span></a> </span><span>to Oregon Health &amp; Science University. Or this $2 million </span><a rel="noreferrer noopener" href="https://www.ideastream.org/news/questions-over-myers-university" target="_blank"><span><span>anonymous donor to Myers University</span></span>, </a><span>who was outed by the&nbsp;Ohio Board of Regents Chancellor.</span></p>



<p><span>More people are turning to</span> <a rel="noreferrer noopener" href="http://silentdonor.com/" target="_blank"><span>Silent Donor</span></a> <span>to accomplish what they want – <strong>to give back to their favorite schools, but to do so in a manner that is consistent with the level of privacy they are comfortable with</strong>. In line with this, anonymous gifts have exploded over the past few years and have in fact regularly become the largest donations that universities have ever seen. We have a few of them chronicled below, representing both large and small institutions from all across the United States:</span></p>



<ul><li><a rel="noreferrer noopener" href="https://houston.innovationmap.com/university-of-houston-50-million-donation-2639988486.html" target="_blank"><span><span>University of Houston</span></span></a> <span>$50 million <em>anonymous</em> donation in 2019 (largest in school history)</span></li><li><a rel="noreferrer noopener" href="https://news.berkeley.edu/2020/02/29/largest-gift-in-berkeleys-history-will-create-a-hub-for-advancing-data-science/" target="_blank"><span><span>UC Berkely</span></span></a> <span>$252 million <em>anonymous </em>donation in 2020 (largest in school history)</span></li><li><a rel="noreferrer noopener" href="https://www.insidehighered.com/news/2020/02/12/suny-binghamton-receives-largest-donation-its-history" target="_blank"><span><span>SUNY Binghampton</span></span></a> <span>$60 million <em>anonymous </em>donation in 2020 (largest in school history)</span></li><li><a rel="noreferrer noopener" href="https://www.wbrz.com/news/university-in-louisiana-gets-a-20m-anonymous-donation/" target="_blank"><span><span>Xavier University of Louisiana</span></span></a> <span>$20 million <em>anonymous </em>donation in 2020 (largest in school history)</span></li><li><a rel="noreferrer noopener" href="https://diverseeducation.com/article/178191/" target="_blank"><span><span>University of Arkansas Little Rock</span></span></a> <span>$25 million <em>anonymous </em>donation in 2020 (largest in school history)</span></li><li><a rel="noreferrer noopener" href="https://www.wmbfnews.com/2020/07/27/transformational-gift-anonymous-donor-commits-million-ccu/" target="_blank"><span><span>Coastal Carolina University</span></span></a> <span>$95 million <em>anonymous </em>donation in 2020 (largest in school history)</span></li><li><span>And there are <em>COUNTLESS </em>more examples</span></li></ul>



<p><span><strong>Silent Donor</strong> <strong>partners with universities (and nonprofits) to allow them to seamlessly accept anonymous gifts from their donors</strong> all over the country (and world) in order to help these institutions fundraise in a way that connects with their donor-base. As we can see, a look at the US donor-base reveals a predilection towards anonymous giving, rather than following tired “ask-and-give” patterns. While we have shown that wealthy donors are very interested in anonymous donations, we also decided to dive a little deeper into one very interesting set of donors that often go overlooked, but provide a massive amount of smaller-dollar donations: millennials.</span></p>



<p><strong>MILLENNIALS</strong></p>



<p><span>Millennials as a donor group are not to be discounted. The generation is infamous for helping to carry campaigns like Bernie Sanders’ multimillion dollar fundraisers in which average donation amounts came in around $30. We wanted to find out more, so we conducted a small survey of college-graduate millennials who had donated to their alma mater and asked them a few questions about their experience.</span> </p>



<p><span>What we first heard <strong>overwhelmingly </strong>from respondents was that millennials were highly annoyed with the constant barrage of emails, calls, and physical mail that they receive from their university after they donated – some saying they almost felt like their school was begging them to send another donation. One said she “couldn’t throw away the [university solicitation] mail fast enough.” Some respondents simply wanted to remain private with their small donation. The millennials understood the reason for the junk (e)mailing efforts, but almost all respondents answered that they would have preferred to not provide any of their contact information to their university in an attempt to avoid the subsequent mailing and calling barrage. One millennial hinted that it was enough to make him wish he did not send a donation at all.  </span></p>



<p><span>It is clear that millennials are interested in giving back to their schools, but they also want to do so on their terms. We are not here to tell universities to significantly alter their communications strategy, but rather urging universities <strong>to offer the donation path of least resistance</strong> – one that offers an anonymous donation option (through Silent Donor!) to appeal to their career-climbing millennial audience, their wealthy audience, and millions of privacy-minded donors in between. </span></p>



<p><span>If you are in a fundraising role at a school or nonprofit, please reach out to us at <em>ContactUs@silentdonor.com</em> to learn more about how we can help your donations grow</span> for free!</p>
					</div><!-- .entry-content -->

		<!-- .entry-footer -->

				
			    
	    
	</div></div>]]>
            </description>
            <link>https://silentdonor.com/anonymous-donations-to-universities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053747</guid>
            <pubDate>Tue, 10 Nov 2020 23:54:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: You're paying too much for your superannuation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053546">thread link</a>) | @truffle_pig
<br/>
November 10, 2020 | https://pennycott.com/super | <a href="https://web.archive.org/web/*/https://pennycott.com/super">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://pennycott.com/super</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053546</guid>
            <pubDate>Tue, 10 Nov 2020 23:31:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Read Skew-T Charts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053467">thread link</a>) | @sytelus
<br/>
November 10, 2020 | https://weathertogether.net/weather-101/how-to-read-skew-t-charts/ | <a href="https://web.archive.org/web/*/https://weathertogether.net/weather-101/how-to-read-skew-t-charts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="page-6586" class="page">
                                                
        
        <div>
          <p>If you haven’t seen a Skew-T chart before, to say they can look a little intimidating is a huge understatement. But with a little practice, you can become a Skew-T master and open up new doors to learn about a variety of meteorological subjects. Skew-T charts are incredibly useful for quickly and accurately viewing the structure of the atmosphere all the way from the surface to 100,000 feet, and they’ve been around for a LONG time – since 1947, to be exact<sup>1</sup>.</p>
<p>Skew-T charts are most commonly used to plot parameters measured by radiosondes as they rise throughout the atmosphere. They only plot three measurements: temperature, dew point, and wind velocity (the speed AND direction of the wind). Additionally, there are 5 lines on a Skew-T: isotherms, isobars, dry adiabats, moist adiabats, and saturation mixing ratio lines.</p>
<div id="attachment_6963"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/skewt_lines_q.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6963" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/skewt_lines_q.jpg" alt="" width="500" height="400"></a></p><p id="caption-attachment-6963">Isobars (A), dry adiabats (B), moist adiabats (C), isotherms (D), and saturation mixing ratio lines. <br>Credit: <a href="http://www.meted.ucar.edu/mesoprim/skewt/index.htm">UCAR MetEd module on reading Skew-T charts</a>. If you are looking for more information, I suggest you try the module! You will need to register to join, but registration is free,</p></div>
<p>Besides simply acting as a template to plot the temperature, dewpoint, and wind, Skew-Ts are useful for easily finding the locations and values of important levels and parameters of the atmosphere. CAPE, the LCL, and the LFC are just a few things that can easily be found with a Skew-T.</p>
<p>Let’s start our journey by learning about each line on a Skew-T.</p>
<p><span><strong>Isotherms</strong></span></p>
<div id="attachment_6965"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/isotherms.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6965" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/isotherms.jpg" alt="" width="500" height="400"></a></p><p id="caption-attachment-6965">Credit: UCAR Comet Program Skew-T module</p></div>
<p>Isotherms are lines of constant temperature. They are the namesake of the Skew-T chart because they are skewed 45 degrees to the right. Skewing the Ts may seem a little unintuitive, but a Skew-T allows us to easily calculate important atmospheric levels and parameters like the Lifting Condensation Level (LCL), Level of Free Convection (LFC), the Equilibrium Level, and CAPE. A <em>Stüve</em> is like a Skew-T but without the skewed temperature lines. It is not as useful for most meteorological applications because the adiabats on it are not curved, meaning we can’t accurately calculate the things listed above.</p>
<p><span><strong>Isobars</strong></span></p>
<div id="attachment_6964"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/isobars.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6964" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/isobars.jpg" alt="" width="500" height="400"></a></p><p id="caption-attachment-6964">Credit: UCAR Comet Program Skew-T module</p></div>
<p>Isobars are defined as “lines of constant pressure.” On a Skew-T chart, pressure, NOT height, is plotted on the y-axis, so isobars are simply parallel to the x-axis. Because pressure decreases more slowly with height the higher you go, pressure is plotted in a logarithmic fashion on Skew-T charts. For this reason, Skew-T charts are also commonly called Skew-T/Log-P charts. If we didn’t plot pressure in logarithms, the Skew-T charts would be as high as the weather balloons they plot traveled – approximately 100,000 feet high!</p>
<p><span><strong>Dry Adiabats</strong></span></p>
<div id="attachment_6966"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/dry_adiabats.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6966" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/dry_adiabats.jpg" alt="" width="500" height="400"></a></p><p id="caption-attachment-6966">Credit: UCAR Comet Program Skew-T module</p></div>
<p>Adiabatic processes are processes in which no heat is exchanged with the outside system (in our case, the atmosphere), and dry adiabats show how much an <em>unsaturated</em> parcel cools when lifted through the atmosphere. You are probably thinking “how can a parcel cool and maintain the same heat content?” Well, keep in mind that as an air parcel rises, it expands due to the surrounding atmosphere exerting less pressure on it, so the total heat content remains the same.</p>
<p>Adiabatic processes are a consequence of the First Law of Thermodynamics, which states that the heat added to a certain mass of a gas is equal to its change in internal energy + the work done BY the gas ON the environment. My doing some nifty mathematical maneuvering and applying the ideal gas law, we find that the first law states that changes in temperature are positively correlated with changes in pressure. I’ll discuss this and more in a tutorial in the future, but the important thing to know is that when an unsaturated air parcel rises and ANY air parcel sinks, it will travel parallel to these adiabats.</p>
<p>These adiabats follow the “Dry Adiabatic Lapse Rate,” which is approximately 10 degrees Celsius per kilometer.</p>
<p><span><strong>Moist Adiabats</strong></span></p>
<div id="attachment_6967"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/sat_adiabats.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6967" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/sat_adiabats.jpg" alt="" width="500" height="400"></a></p><p id="caption-attachment-6967">Credit: UCAR Comet Program Skew-T module</p></div>
<p>When saturated air rises, it follows the “saturation” or “moist adiabats.” When air reaches saturation, gaseous water vapor condenses into liquid water droplets, and this phase change releases “latent heat” into the atmosphere. Because of this, the moist adiabatic lapse rate is ALWAYS less than the dry adiabatic lapse rate, but as you can see above, moist adiabats are NOT parallel and vary quite a bit with both temperature AND altitude.</p>
<p><strong>The most important thing to remember about moist adiabats is that a saturated air parcel will ONLY follow them if it is rising. If the parcel is sinking, it is warming away from saturation and will follow the dry adiabats.</strong></p>
<p><span><strong>Saturation Mixing Ratio Lines</strong></span></p>
<div id="attachment_6968"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/sat_mixing_ratio.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6968" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/sat_mixing_ratio.jpg" alt="" width="500" height="400"></a></p><p id="caption-attachment-6968">Credit: UCAR Comet Program Skew-T module</p></div>
<p>The saturation mixing ratio is the ratio, in grams of water vapor per kilogram of air, that an air parcel must have at a given pressure and temperature to be considered “saturated.” Once an air parcel is saturated, it generally cannot hold any more water vapor.</p>
<p>Now that you know the lines – let’s find out how we can use them to calculate some particularly important levels of the atmosphere. We’ll learn how to calculate the <strong>lifting condensation level (LCL)</strong>, the <strong>convective condensation level (CCL)</strong>, the<strong> level of free convection (LFC)</strong>, and the<strong> equilibrium level (EL)</strong>, as well as<strong> convective available potential energy (CAPE)</strong> and<strong> convective inhibition (CIN)</strong>.</p>
<p><span><strong>Lifting Condensation Level (LCL)</strong></span></p>
<div id="attachment_6970"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/lcl_proc.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6970" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/lcl_proc.jpg" alt="Lifting Condensation Level" width="350" height="290"></a></p><p id="caption-attachment-6970">Lifting Condensation Level<br>Credit: UCAR MetEd COMET Program</p></div>
<p>The LCL is the pressure level an air parcel would need to be raised (dry adiabatically) to to become saturated. To find the LCL, follow a dry adiabat from your surface environmental temperature and a saturation mixing ratio line from your surface dewpoint temperature. The intersection of these marks the location of the LCL. The LCL is important because it marks location where the air parcel stops rising at the dry adiabatic lapse rate and switches to the moist adiabatic lapse rate.</p>
<p><span><strong>Convective Condensation Level (CCL)</strong></span></p>
<div id="attachment_6971"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/ccl_proc.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6971" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/ccl_proc.jpg" alt="Convective Condensation Level" width="350" height="290"></a></p><p id="caption-attachment-6971">Convective Condensation Level. The Convective Temperature (Tc) can be found by taking a dry adiabat down from the CCL to the surface.</p></div>
<p>A closely related level is the <strong>Convective Condensation Level</strong>, or <strong>CCL</strong>. The CCL is the pressure level that a parcel, if heated to the “convective temperature,” would freely rise and form a cumulus cloud. The convective temperature is the temperature the surface must reach so that air can freely rise, and the CCL is at the intersection of the environmental temperature (NOT a dry adiabat from the surface… that’s the LCL) and the saturation mixing ratio line from the surface dewpoint temperature.</p>
<p><strong>Notes: </strong>The LCL and CCL are useful for determining the height of cloud bases. For non-convective clouds that are forced to rise, the LCL is a good approximation. On the other hand, the CCL is a better estimate for clouds formed by convection, like cumulus clouds. In reality, cloud bases are generally somewhere between the LCL and CCL.</p>
<p>The reason why thunderstorms in the desert often have high bases is because surface dewpoints are low there, causing the LCL and CCL to be high in the atmosphere. Conversely, thunderstorms in humid locations generally have lower bases because the LCL is lower.</p>
<p><span><strong>Level of Free Convection (LFC)</strong></span></p>
<div id="attachment_6972"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/lfc_proc.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6972" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/lfc_proc.jpg" alt="" width="350" height="290"></a></p><p id="caption-attachment-6972">Level of free convection. It is calculated by taking a moist adiabat from the LCL until you intersect the environmental temperature.</p></div>
<p>The LFC is the pressure level an air parcel would need to be raised so that its temperature is equal with the environmental temperature. It is found by taking the moist adiabat from the LCL until it intersects the environmental temperature. After this, the air parcel is warmer than its environment and can freely rise (hence the name – level of <em>free convection</em>).</p>
<p>There are a few isolated situations where this approach won’t work – for example, if the surface has reached the “convective temperature” mentioned above, the LFC is at the surface. But for the vast majority of situations, this method works beautifully.</p>
<p><strong>Not all soundings have an LFC. </strong>If the moist adiabat never intersects the environmental temperature because the atmosphere is relatively stable and does not exhibit a sharp decrease in temperature with height, there is no LFC. Additionally, many places that have an LFC during the day may not have one at night, when the surface is cooler and the atmosphere is more stable.</p>
<p><strong><u>Equilibrium Level (EL)</u></strong></p>
<div id="attachment_6944"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/Skew-T-Diagram.png" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-6944" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/Skew-T-Diagram.png" alt="" width="600" height="600"></a></p><p id="caption-attachment-6944">A Sample Skew-T Diagram. The slanted red lines are lines of constant temperature, the dotted purple lines are lines of constant mixing ratio, the solid curved green lines are dry adiabats, and the curved green lines are moist adiabats.<br>The Lifting Condensation Level (LCL), Level of Free Convection (LFC), and Equilibrium Level (EL) are labeled. The CAPE is bounded on the bottom by the LFC and the top by the EL and is the total area between the black line (path of the air parcel) and red line (environmental temperature).<br>Retrieved from <a href="http://wx4cast.blogspot.com/2014/04/the-basics-of-severe-weather-sounding.html">Rebecca Ladd’s Weather Blog</a></p></div>
<p>The equilibrium level only exists if there is an LFC, and it is defined as the level at which the moist adiabat denoting the parcel’s path recrosses the environmental temperature. At the EL, the air parcel is the same temperature as its environment, and above it, it is cooler and more dense. The EL can be found by looking at the “anvils” on thunderstorms, as these mark the location where a rising air parcel is no longer positively buoyant. The “overshooting top” of a thunderstorm exceeds the equilibrium level, but this is only because the momentum of the storm’s uber-powerful updraft is allowing it to reach a higher altitude, NOT because the air above the equilibrium level is positively buoyant.</p>
<p><span><strong>Convective Available Potential Energy (CAPE) and Convective Inhibition (CIN)</strong></span></p>
<div id="attachment_7034"><p><a href="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/cin_tephi.jpg" rel="tc-fancybox-group6586"><img aria-describedby="caption-attachment-7034" src="https://cdn.weathertogether.net/wp-content/uploads/sites/5/2017/05/cin_tephi.jpg" alt="" width="500" height="550"></a></p><p id="caption-attachment-7034">Sounding showing CIN and CAPE<br>Credit: UCAR</p></div>
<p><b>CAPE</b> is the area bounded by the environmental temperature and the temperature of a …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://weathertogether.net/weather-101/how-to-read-skew-t-charts/">https://weathertogether.net/weather-101/how-to-read-skew-t-charts/</a></em></p>]]>
            </description>
            <link>https://weathertogether.net/weather-101/how-to-read-skew-t-charts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053467</guid>
            <pubDate>Tue, 10 Nov 2020 23:22:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Priests upset by online 'mass-hoppers' rating performances, counting views]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25053433">thread link</a>) | @networked
<br/>
November 10, 2020 | https://www.independent.ie/irish-news/priests-upset-by-online-mass-hoppers-rating-performances-counting-views-39727993.html | <a href="https://web.archive.org/web/*/https://www.independent.ie/irish-news/priests-upset-by-online-mass-hoppers-rating-performances-counting-views-39727993.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <p>Priests have said they are upset by the "very hurtful criticism" of "mass-hoppers" who go from one online mass to another passing comments over their "performances".</p>
            
            
    

                                <p>ccording to Fr Tim Hazelwood, a spokesman for the Association of Catholic Priests (ACP), which represents over 1,000 Irish priests, "mass-hoppers" are undermining many priests who are already self-conscious and are "not performers".</p>                                                                                    
                                <p>In a presentation to the ACP's AGM, the Co Cork priest said some of the comments were "very hurtful" and some priests had stopped doing online services because "they couldn't take it" anymore.</p>                                                                                                                    
                
        
                        
                                
                                
                
            
                        
                                                                                                                                                                                                            
        
        

                                            
            
    
              
        </div></div>]]>
            </description>
            <link>https://www.independent.ie/irish-news/priests-upset-by-online-mass-hoppers-rating-performances-counting-views-39727993.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053433</guid>
            <pubDate>Tue, 10 Nov 2020 23:19:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Law of Large Numbers and the Central Limit Theorem (With Python)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053341">thread link</a>) | @rbanffy
<br/>
November 10, 2020 | https://randomvariable.cc/law-of-large-numbers-central-limit-theorem-python/ | <a href="https://web.archive.org/web/*/https://randomvariable.cc/law-of-large-numbers-central-limit-theorem-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <section data-aos="fade">
            


              <span data-visibility="public"></span>
            <div>
                
              
                <p>Law of Large Numbers &amp; CLT: Explanation, mathematical proof &amp; illustration of theorems with Python</p>
            </div>
          </section>
        <section data-aos="fade-up">
          <div>
            <header>
              
              
                <p>Law of Large Numbers &amp; CLT: Explanation, mathematical proof &amp; illustration of theorems with Python</p>
            </header>
            
            <section>
                <!--kg-card-begin: html--><!--kg-card-end: html--><p>Statistics does not usually go with the word "famous," but a few theorems and concepts of statistics find such universal application, that they deserve that tag. The Central Limit Theorem and the Law of Large Numbers are two such concepts. Combined with hypothesis testing, they belong in the toolkit of every quantitative researcher. These are some of the most discussed theorems in quantitative analysis, and yet, scores of people still do not understand them well, or worse, misunderstand them. Moreover, these calculations are usually not done manually—the datasets are too large, computations are time consuming—so it is equally important to understand the computation aspect of these theorems well.</p><p>A working knowledge of probability, random variables and their distributions is required to understand these concepts.</p><h2 id="sample-mean">Sample Mean</h2><p>A "sample" is a set of outcomes in an experiment or an event. A sample can sometimes also be replaced by "trials" or number of repetitions of the experiment. For example, tossing a coin with probability <em>p</em> of achieving a heads is <em><strong>n</strong></em> <em>Bernoulli (p)</em> trials. If the outcome is a random variable X, then <em>X~Binomial(n, p)</em> distribution (with <em>n</em> number of Bern(p) trials).</p><!--kg-card-begin: html--><p>
    The values in a sample, \(X_{1},X_{2},X_{3}, ..., X_{n}\), will all be random variables, all drawn from the same probabilistic distribution since they are outcomes of the same experiment. The \(X_{1},X_{2},X_{3}, ..., X_{n}\) here are not actual numbers but names of random variables. A realization of the random variable \(X_{1}\) will be \(x_{1}\), an actual number.
</p><!--kg-card-end: html--><p>A realization or an actual value of an experiment is one reading from the distribution. In a way, a probabilistic distribution is not a physical thing, and hence sometimes hard to relate to in everyday actions, even though highly applicable in everyday activities. It can be thought of as a tree. For example, a mango tree. We know the characteristics of the tree, what types of leaves it has, what types of fruits, their shape, size, color etc. We have a good idea of what a mango tree <em><strong>is</strong></em>, even if we don't physically see it &amp; know each and every value. That is similar to a probabilistic distribution of a random variable X. One specific leaf, x, plucked from a mango tree, is like a <em>realization</em> of the random variable X.</p><!--kg-card-begin: html--><p>
    <b>Sample Mean</b> is a random variable itself, as it is an average of other random variables. When referring to outcomes of the same experiment, all outcomes will belong to the same distribution, and hence will be identical in distribution. If each trial or sample is independent of the others, the random variables \(X_{1},X_{2},X_{3}, ..., X_{n}\), will also be independent. This is then a set of <b>I.I.D.</b> (Independent and Identically Distributed) random variables.</p>

<p>

For I.I.D. random variables \(X_{1},X_{2},X_{3}, ..., X_{n}\) the sample mean \({\overline{X_n}}\) is simply the arithmetic average of the set of random variables. (Note: the definition of sample mean applies to any set of random variables, but the fact that they are I.I.D. is going to be a special case scenario in common experiments, useful for deriving some important theorems.)
</p>

<p> \[{\bar{X_n}} =  \sum_{i=1}^{n}{X_i}/n\]<!--kg-card-end: html--></p><p>In a small lab experiment, like measuring the length of an instrument with Vernier Calipers, we normally observe and record 3-5 readings of a measurement, and take the average of the readings to report the final value, to cancel any errors. This is high-school level mathematics. In research experiments, this level of simplification is not possible. But the idea behind the averaging is the same. In real life, we draw samples, X<sub>i</sub>, and take the expectation of the samples to get the expectation of the sample mean. But the expectation of the sample mean is an average of all possible outcomes for each random variable X<sub>i</sub>, not just the realized values. So, in a sense, it is a <em><strong>theoretical average.</strong></em></p><!--kg-card-begin: html--><p>
\[E[{\overline{X_n}}] =  E[\sum_{i=1}^{n}{X_i}/n]\]
</p><!--kg-card-end: html--><p>When we take the expectation, the expectation of the errors becomes zero: E[e] = 0</p><h2 id="convergence-in-probability">Convergence in Probability</h2><p>A convergence in probability is defined as follows: a sequence of random variables X<sub>n</sub> is said to converge in probability to a number <em>a</em>, if for any given small number <em>ϵ, </em>the probability of the difference between <em>X<sub>n</sub></em> and <em>a</em> being greater than <em>ϵ</em> tends to zero as <em>n</em> approaches <em>∞</em>.</p><!--kg-card-begin: html--><p>
    For any \(\epsilon\) &gt; 0,
   \[\lim_{n \rightarrow  \infty } P(|X_n - a|   \geq  \epsilon ) = 0\]
    
</p><!--kg-card-end: html--><p>So, the distribution of X<sub>n</sub> bunches around the number<em> a</em> for a large enough number <em>n</em>. But it is <em>not always necessary</em> that the expectation E[X<sub>n</sub>] will converge to <em>a </em>too. This can be explained by the presence of outliers which might offset the expectation away from the number <em>a</em>, where the big proportion of the outcomes lie.</p><h2 id="law-of-large-numbers-lln-">Law of Large Numbers (LLN)</h2><p>As per the LLN, as the sample size <em>n</em> tends to ∞, the expectation of the sample mean tends to the true mean <em>μ </em>of the population with probability 1. This is true for a set of I.I.D. random variables X<sub>i</sub> with mean <em>μ</em> and variance <em>σ<sup>2</sup></em>. It is calculated as follows:</p><!--kg-card-begin: html--><p>
    \[E[{\overline{X_n}}] =  E[\sum_{i=1}^{n}{X_i}/n]  \longrightarrow  \mu \]
    
</p><!--kg-card-end: html--><p>This can be simulated and tested in Python by creating say 15 random variables, <em>X<sub>1</sub> </em>to <em>X<sub>15</sub></em> that are <em>X<sub>i</sub> ~Bin(n,p)</em> using the random generator of Numpy. The X<sub>i</sub> &nbsp;must be IID. We calculate the value of the sample mean by averaging the variables. The true mean ( <code>mu</code> in the code) is very close to the calculated value <code>mean</code> based on the randomly generated distributions.</p><p>Note that in Numpy, <code>np.random.binomial(n, p, size=None)</code> uses a slightly different notation for the Binomial distribution than what we have been using so far. Here <code>n</code><em> </em>refers to the number of trials in one variable, <code>p</code> is the probability of success, and <code>size</code> is the sample size (eg, number of coins tossed). It treats the Binomial distribution as a sum of indicator random variables; hence the output is the sum of number of successes for each sample (like each coin). So, if we take <code>size</code> as 5, and <code>n</code> (trials) as 100, the output will be a list of 5 numbers, with the sum of number of successes out of 100 for <em>each</em> sample (eg, for each coin).</p><p>For the sake of simplicity though, I have created 15 separate random variables, each with <code>size</code>= 1, for illustrative purposes. <code>XN</code> refers to the sample mean in the code.</p><pre><code>import numpy as np
import scipy.stats as sp

#Running the Simulation with 15 IID Binomial RV for size=1 each, with n=1000 trials, probability of success is p=0.5

X1 = np.random.binomial(1000, 0.5, 1)
X2 = np.random.binomial(1000, 0.5, 1)
X3 = np.random.binomial(1000, 0.5, 1)
X4 = np.random.binomial(1000, 0.5, 1)
X5 = np.random.binomial(1000, 0.5, 1)
X6 = np.random.binomial(1000, 0.5, 1)
X7 = np.random.binomial(1000, 0.5, 1)
X8 = np.random.binomial(1000, 0.5, 1)
X9 = np.random.binomial(1000, 0.5, 1)
X10 = np.random.binomial(1000, 0.5, 1)
X11 = np.random.binomial(1000, 0.5, 1)
X12 = np.random.binomial(1000, 0.5, 1)
X13 = np.random.binomial(1000, 0.5, 1)
X14 = np.random.binomial(1000, 0.5, 1)
X15 = np.random.binomial(1000, 0.5, 1)

XN = (X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8+ X9 + X10 + X11 + X12 + X13 + X14 + X15)/15        #Sample Mean
mean = np.mean(XN)   #Calculated mean of the sample
print("Sample Mean: "+ str(mean))

mu = sp.binom.mean(1000, 0.5)    #True Mean of the sample
print("True Mean: " + str(mu))</code></pre><pre><code>Output:

Sample Mean: 500.8666666666667
True Mean: 500.0</code></pre><p>This is the result for just 15 random variables. As the number increases, the sample mean gets closer to true mean. (Note: every time you run the code, it gives a new value for the sample mean because a new set of rv is generated every time. <a href="https://repl.it/@agarwalarti/LLN">You can check and run the code here.</a> )</p><!--kg-card-begin: html--><p>
    The variance of the Sample Mean \(\overline{X_n}\) is calculated as follows:
    
\[Var(\overline{X_n}) =\frac{Var(X_1 + X_2 + ... + X_n)}{n^2} = \frac{n \sigma^2}{n^2} = \frac{\sigma^2}{n} \]
    
    
</p><!--kg-card-end: html--><p>Since X<sub>i</sub> are independent, we can use the property of linearity of variances to find the variance of the sample mean. By using the variance calculated above, and the Chebyshev's inequality, we can prove the Weak Law of Large Numbers.</p><h3 id="weak-law-of-large-numbers">Weak Law of Large Numbers</h3><p>As per the Chebyshev's inequality, </p><!--kg-card-begin: html--><p>
    For any \(\epsilon\) &gt; 0,
   \[P(|Y_n - a|   \geq  \epsilon ) = \frac{Var(Y_n)}{ \epsilon ^2} \]
    
</p><!--kg-card-end: html--><p>Plugging in the values in this equation, we get:</p><!--kg-card-begin: html--><p>
    \[ P(|\overline{X_n} - \mu| \geq \epsilon ) = \frac{\sigma^2}{ n\epsilon ^2}  \underset{n  \longrightarrow \infty }{\overset{}{\longrightarrow}} 0
    \]
    
    
</p><!--kg-card-end: html--><p>As n approaches infinity, the probability of the difference between the sample mean and the true mean <em>μ</em> tends to zero, taking <em>ϵ </em>as a fixed small number.</p><h2 id="central-limit-theorem">Central Limit Theorem</h2><p>So far, we have not mentioned anything about which distribution the X<sub>i</sub> belong to and the distribution of the sample mean (which is a random variable too, remember?). Most of the times, knowing the mean is not enough; we would like to know more about the final distribution of the sample mean so we can understand its properties. The Central Limit Theorem describes exactly this.</p><p>The Central Limit Theorem (CLT) says:</p><!--kg-card-begin: html--><p>
    \[  \frac{\sqrt{n} (\overline{X_n} -  \mu )}{ \sigma }

\underset{n  \longrightarrow \infty }{\longrightarrow}N(0,1) \]
</p><!--kg-card-end: html--><pre><code>import numpy as np
import scipy.stats as sp
import matplotlib.pyplot as plt
import math

#Running the Simulation with 10 IID Binomial RV for 500 coins, with 1000 trials, probability of success is 0.5

X1 = np.random.binomial(1000, 0.5, 500)
X2 = np.random.binomial(1000, 0.5, 500)
X3 = np.random.binomial(1000, 0.5, 500)
X4 = np.random.binomial(1000, 0.5, 500)
X5 = …</code></pre></section></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://randomvariable.cc/law-of-large-numbers-central-limit-theorem-python/">https://randomvariable.cc/law-of-large-numbers-central-limit-theorem-python/</a></em></p>]]>
            </description>
            <link>https://randomvariable.cc/law-of-large-numbers-central-limit-theorem-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053341</guid>
            <pubDate>Tue, 10 Nov 2020 23:10:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon: The Roads Not Taken]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053236">thread link</a>) | @ingve
<br/>
November 10, 2020 | https://take.surf/2020/11/09/apple-silicon-the-roads-not-taken | <a href="https://web.archive.org/web/*/https://take.surf/2020/11/09/apple-silicon-the-roads-not-taken">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section><p>[Please note: This was written ahead of <a href="https://www.apple.com/newsroom/2020/11/introducing-the-next-generation-of-mac/">today's announcements</a>.]</p><p>My track record on predicting things out of the blue is pretty spotty, so here are a few things I can imagine but that will probably not materialize.</p><ul><li><h3>"Apple Pi"</h3><p>Raspberry Pi-like, "tinkerer-friendly" Mac, for under $100.</p><p>Compare the prices of most single-board computers and the x86 models are steadily either significantly more expensive, or running four year old Intel Atom CPUs, or both. Not only do ARM processors not have the issue of having to keep Intel afloat, Apple has itself had experience putting out small SoCs <a href="https://panic.com/blog/the-lightning-digital-av-adapter-surprise/">in surprising places</a>.</p><p>If they would do this, chances are they'd make it all about hosting stuff on iCloud, writing code in Swift (maybe using a connected iPad). I don't quite see how it can both be what the Raspberry Pi crowd likes and what Apple likes at the same time. Apple's not interested in enabling tinkering. It's interested in making kids code, but on a high-margin iOS device and up. With the way macOS has moved recently, there's little making this a Mac as such, but it's more a Mac than iOS/iPadOS.</p></li><li><h3>"Mac nano"</h3><p>A Mac mini the size of the Apple TV, for $199, with 4GB RAM, 64/128 GB of iPhone-like storage, hardly any I/O, and probably an A12, A13 or A14. <a href="https://www.youtube.com/watch?v=GJpZGeihy0s">BYODKM</a> – hook up the display with HDMI or USB-C, hook up keyboard and mouse wirelessly or with a USB-C hub/adapter.</p><p>The old Steve Jobs quote was "we don't know how to make a $500 computer that's not a piece of crap", and Apple can now comfortably pack in the computational power for an okay enough experience for what people are likely to plug into it. As long as it runs the software well enough, it's a candidate to bring people over from Windows, and they're about to lose the fallback "if all else fails you could use it as a Windows PC"; it needs to be cheaper.</p><p>("Mac SE" was already taken.)</p></li><li><h3>An affordable Mac mini</h3><p>Take the current Mac mini, make it a bit smaller and make it affordable. Again – the Intel tax is gone, and Apple, if they want to, can churn out silicon in large scales by themselves already. The first Mac mini was $499 – there's no reason the first ARM Mac mini can't be.</p></li></ul><p>All of these products essentially are based on this: there's an Apple that makes iPhones for $399 with industry-leading performance, and there's an Apple that sells wheels for almost twice that price. It's up to Apple to define what they want to sell and how they want to market it, and heading into a transition where you drop a hardware partner for your own designs is a perfect time to choose a new tack.</p><p>Say what you want about whether Apple wanted to offer lower-level products before, the price-to-performance ratio with Intel never made much sense. And if a Celeron or Atom didn't exactly scream high enough performance, neither did PowerPC chips that were lower-end than the ones they put in their low-end Macs back in those days. In a way, Apple's not had the opportunity to tackle this head-on at least for 20 years or so, so we don't really know that the idea has been rejected by Apple rather than by circumstance.</p></section></article></div>]]>
            </description>
            <link>https://take.surf/2020/11/09/apple-silicon-the-roads-not-taken</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053236</guid>
            <pubDate>Tue, 10 Nov 2020 22:59:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My personal experience with Ethereum contract development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052857">thread link</a>) | @buzzert
<br/>
November 10, 2020 | https://buzzert.net/posts/2020-11-01-octahedron | <a href="https://web.archive.org/web/*/https://buzzert.net/posts/2020-11-01-octahedron">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="right-container">
            <div id="diary-page">
	
	<p>“The Blockchain” has become a real buzzword in computing these days, but often without a coherent justification. I think it’s because there are a lot of venture capitalists and entrepreneurs who are trying to remain really tuned in to the “next big thing” in technology. I personally cringe every time I hear business people talking about “the blockchain”, because it was never supposed to a tool to make money, or even be a part of business at all. It was <em>always</em> a hacker thing, meant to subvert businesses in many ways.</p>

<p>Distributed and trust-less computing was frequently discussed on the cipherpunks Usenet newsgroups in the 1990’s. Borne from the early excitement of the Internet, imagining newfound possibilities for an already established decentralized network of computers, our hacker grandparents envisioned a literal <a href="https://www.activism.net/cypherpunk/crypto-anarchy.html">“crypto-anarchy”</a>. The Blockchain was never explicitly tied to currency in its inception. Currency, a thing that is controlled by governments, inhibits free market capitalism<sup id="fnref:1"><a href="#fn:1">1</a></sup>, and empowers individuals was simply the killer application for it, especially to the crypto-anarchists.</p>

<p>It’s interesting that the concept of a blockchain or even a cryptocurrency hadn’t even been conceived in Tim May’s original email (linked above), it was only the ideology. It wasn’t until <a href="http://www.weidai.com/bmoney.txt">Wei Dai’s textfile about b-money</a> did the idea of applying cryptography towards currency come about.</p>

<blockquote>
  <p>A community is defined by the cooperation of its participants, and efficient cooperation requires a medium of exchange (money) and a way to enforce contracts. Traditionally these services have been provided by the government or government sponsored institutions and only to legal entities. In this article I describe a protocol by which these services can be provided to and by untraceable entities.</p>
</blockquote>

<p>I think the most interesting thing about this textfile was the fact that Dai had also envisioned smart contracts. Smart contracts are the second killer application for the blockchain, in my opinion, but a far more difficult problem to solve.</p>

<p>Of course, all of this ultimately culminated in the anonymous hacker Satoshi Nakamoto’s paper about Bitcoin, and the rest is history. So why then did this idea–originating from hackers, some even anonymous to this day–grow so many leeches promising a completely new wave of technology startups?</p>


<p>I was very excited by an opportunity to learn more about all of this stuff when coming up with an idea to track finances with my brother, who is also currently my roommate. Previously, my brother and I had shared various household expenses by sending each other money over Square Cash. While I still think Square Cash is a wonderful service<sup id="fnref:5"><a href="#fn:5">2</a></sup>, at some point we tallied up all of the transactions we had sent over the period of multiple years and discovered that our sums were nearly identical! This means that in the end, if we hadn’t sent each other money at all, we still would’ve been mostly square. Since we try to share the burden of household expenses anyway, this was not entirely surprising.</p>

<p>After making this discovery, we thought it would be cool to develop a very simple piece of software that just <em>kept track</em> of these expenses rather than transfer any money. Although my brother and I trust each other (for the most part), we thought it would be far more interesting if we assumed we couldn’t trust each other at all, and developed an Ethereum Smart Contract built on the blockchain instead of running something on a server that one of us would have to own and operate.</p>

<p>In short, developing this application on the blockchain instead of using a centralized server was extraordinarily difficult, and at one point even became unaffordable. Before going into details with that, let me switch back to talking about some of the promises and myths of the blockchain in general.</p>


<p>There are a lot of hollow promises for blockchain technology, mostly from business people who don’t completely understand it themselves. If you’ve ever heard of a company who promised a “revolution in e-commerce” using the blockchain, this would be one of those. I won’t even mention the myriad of “get rich quick” schemes here.</p>

<p>However, there are a lot of actual features of the blockchain that <em>could</em> be appealing to application developers. Notably:</p>

<ul>
  <li><strong>A decentralized database.</strong> Centralized stores of data, particularly for data that would be perilous to lose, is a centralized point of failure. Application developers who would like to make guarantees about database integrity could count on the fact that their data is distributed among a large set of nodes across the globe.</li>
  <li><strong>Users have the ability to audit smart contract code.</strong> Although the developer is responsible for the development of the original code for a smart contract, if the source code of the contract was somehow published, users of the smart contract could actually guarantee that the contract they’re interacting with is the same as the one they personally audited by comparing the compiled bytecode stored in an actual blockchain transaction. Since the contract cannot be changed after the fact<sup id="fnref:2"><a href="#fn:2">3</a></sup>, users can also have confidence that as long as they interact with a contract at a particular address, that guarantee will also not suddenly change in the future.</li>
  <li><strong>The data stored on the blockchain is tamper-proof.</strong> Since the contents (inputs) of a transaction cannot be changed after it has been mined into the blockchain, the users of a contract can guarantee that rows in this decentralized database will not suddenly disappear or change without their authority.</li>
  <li><strong>Transactions are not forgeable.</strong> Thanks to the promises of asymmetric key cryptography.</li>
</ul>

<p>Taken at face value, all of these promises are pretty cool. What about some of the <em>myths</em>?</p>


<ul>
  <li><strong>Interactions with the Blockchain are anonymous.</strong> In order for a decentralized network like this to function, all interactions with smart contracts must be published and made widely available. Interactions with the blockchain can be anonymous if users are extremely careful with their keys, but this is not often practical or even feasible<sup id="fnref:3"><a href="#fn:3">4</a></sup>.</li>
  <li><strong>Applications on the Blockchain can be made easy to use by normal people.</strong> This, in my opinion, is also not practical or feasible for the same reason why PGP (email encryption) never took off. I will discuss more about this later in this post.</li>
  <li><strong>The blockchain is “unhackable.”</strong> While certainly <em>nice to have</em> in a world where data breaches are becoming evermore common, this is also not guaranteed by the blockchain by itself. <a href="https://www.nytimes.com/2016/06/18/business/dealbook/hacker-may-have-removed-more-than-50-million-from-experimental-cybercurrency-project.html">The Ethereum DAO hack</a> is an excellent counterexample of this.</li>
  <li><strong>The blockchain is a major cost-saving technology.</strong> Quite the opposite, in fact. The cost to run a distributed database is significantly higher regardless of how it is done<sup id="fnref:4"><a href="#fn:4">5</a></sup>.</li>
</ul>

<p>With that summarized, let me now explain how I came to learn all of this from personal experience…</p>


<p>We called our application “Octahedron”, named after the shape of the <a href="https://upload.wikimedia.org/wikipedia/commons/6/6f/Ethereum-icon-purple.svg">Ethereum logo</a>. It is implemented in two separate parts. The first part is the client, which we decided would be an iOS application (but could be anything), and the second part is the smart contract itself. The smart contract can be considered the “server” in a typical client-server abstraction, but of course since it’s distributed, there is no code that runs on one particular server.</p>

<p>We drafted out some of the features that we wanted before writing either the client or the smart contract, mostly coming from what we’re used to from Square Cash:</p>
<ul>
  <li>The ability to “request money” from another person</li>
  <li>The ability to either approve or deny that request</li>
  <li>An easy to access balance between each of us, represented as a positive number (I am owed money) or negative number (I owe money)</li>
  <li>A historical record of previous requests</li>
</ul>

<h2 id="the-smart-contract">The Smart Contract</h2>

<p>Implementing these features using a smart contract ended up being extremely interesting given the constraints. For example, smart contracts have very limited storage, and the more “space” you use in your contract the more you have to pay. Also, contracts can’t necessarily store arbitrary rows of data inside of them like you can with a SQL database, for example.</p>

<p>The design of the smart contract ended up being two separate code implementations. A request for money owed is a smart contract itself. The smart contract contains all the metadata about the request, such as the amount of money requested, the debtor and debtee’s wallet addresses, and a short description of the request. These are called “debt requests”, and they’re not created by the users themselves, but instead by the “main contract”.</p>

<p>The main contract is another contract implementation who effectively provides an API for creating debt requests, and keeps track of the balance between us. Therefore, the only storage the main contract has is a running balance, which is simply the amount of money “sent” by me minus the amount of money “sent” by my brother. Sent is in quotes here, because no money is actually sent (not even cryptocurrency), only <em>debt</em> is sent.</p>

<p>A typical use case might be as follows:</p>

<ol>
  <li>Brother A pays $20 for a new lamp for the living room.</li>
  <li>Brother A sends a debt request to Brother B for $10. A contract interaction transaction with the main contract is posted to the Ethereum blockchain with all of the metadata needed:
    <div><div><pre><code>Debtor: Brother A
Debtee: Brother B
Amount: 1000 (USD in cents)
Description: New Lamp
</code></pre></div>    </div>
  </li>
  <li>The main contract emits a <code>DebtRequested</code> event, containing the new debt request smart contract.</li>
  <li>Brother A sends a link to the debt request smart contract somehow, usually via the transaction hash or the address to the smart contract itself, to Brother B.</li>
  <li>Upon inspection of the metadata for the debt request contract, Brother B approves the debt request by “fulfilling” it.</li>
  <li>When fulfilling the debt request, the balance is updated in the main contract and the state of the debt request moves from “created” to “fulfilled”.</li>
</ol>

<p>Notice that an important feature about the way this works is that the balance is not updated <em>until the debt …</em></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://buzzert.net/posts/2020-11-01-octahedron">https://buzzert.net/posts/2020-11-01-octahedron</a></em></p>]]>
            </description>
            <link>https://buzzert.net/posts/2020-11-01-octahedron</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052857</guid>
            <pubDate>Tue, 10 Nov 2020 22:21:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exodus of Silicon Valley]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25052818">thread link</a>) | @Reedx
<br/>
November 10, 2020 | https://breakingground.us/exodus/ | <a href="https://web.archive.org/web/*/https://breakingground.us/exodus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4180">
					
					
					
					
					<div>
					<p>On the day the sun didn’t rise in San Francisco, the early warning signs came through the screen. The 6:30 a.m. Zoom always requires unnatural light, making the outlines of faces fuzzy. The natural morning light, combined with the “Touch Up My Appearance” feature on 2020’s preferred video conferencing system, hides the marks of age and sleeplessness that most of us seek to mask. But by 9:00, the fluorescent light was still dominating the screen, and the darkness outside our windows had turned to infernal orange.</p>
<p>The scientific explanation for our sunless day in September is pretty dull. The clouds of soot from the largest California wildfire in history intermixed with the Bay Area’s perennial fog, turning the usual sepia hue of dirty global cities into an apocalyptic blood-orange sky. Though Twitter blamed the hellscape on far more menacing forces, the direct cause of our Blade Runner Day was mostly carbon clinging to the blue-light hues while letting the red pierce through.</p>
<p>If we were more like ancient peoples, many joked, we would assume the gods were enraged. We’d be running for the hills to escape their wrath, or at least head straight for our prepper bunkers. That we are unlike ancient people is actually the only myth, as this is exactly the exodus that is happening in Silicon Valley right now—and will continue for the next few years as true believers deliver themselves from this promised land.</p>
<p><a href="https://breakingground.us/from-ashes/">It’s time to build</a>, yes. But it’s also time to leave.</p>
<p>The battle over tech’s supremacy has been waged and all of our premonitions came true: We wanted flying cars and got vertical take-off innovation hubs from every car maker in America. Software has not only eaten the world, but feasted on your screen-weary eyes. It has swallowed your children, your church, your bank, and your politics, and somehow it all feels inevitable. That these feats of human progress—of instant connectivity in a now homebound world—became the scapegoat of our time is another symptom of the era’s end, cueing the quiet exodus of builders who had bigger aspirations than the same-day shipping that keeps our households afloat.</p>
<p>Now, Silicon Valley is witnessing a reckoning, but it’s not the long-awaited one predicted by the New York press, or the antitrust bonanza that Washington longs for because too many people seem satisfied getting their news from Facebook. The reckoning is more of a realization that tech exceeded expectations and somehow squandered the fruit of its own garden, and that a city on a hill that could have supported so much innovation was not Florence in the Renaissance nor the Athenian Academy with MacBooks. Rather, it became a government-sponsored needle exchange, a haven for the homeless and forgotten that put government’s paralysis on display downtown on Market Street.</p>
<blockquote><p>2020 is not the great reckoning predicted in the book of Revelation, despite the fires, the plagues, and the wailing on Twitter. It is the resignation and determination of Exodus, of a dogged people packing up U-Hauls and fleeing this frontier state to seek an even newer, more eternal world.</p></blockquote>
<p>San Francisco had four times as many deaths from overdose this year as it did from the COVID-19 virus.</p>
<p>2020 is not the great reckoning predicted in the book of Revelation, despite the fires, the plagues, and the wailing on Twitter. It is the resignation and determination of Exodus, of a dogged people packing up U-Hauls and fleeing this frontier state to seek an even newer, more eternal world.</p>
<p>* * *</p>
<p>The computer revolution of the late twentieth century has yet to be named as an epoch, but we can assume that nomenclature will begin in the coming years, alongside the battle for what it all really meant.</p>
<p>What we now call our “technological age” was supposed to be a full-throated and enduring argument for the future, not unlike previous epochs in history that pushed art, science, philosophy, and religion forward in dizzying ways that run counter to ordinary time. The Enlightenment. The Renaissance. The French Revolution. These movements now sit as categories on our bookshelves with clear beginnings and ends, and more importantly, clear hubs and cities of frenetic building that drove the ethos forward. Many books assume that contemporary critics or philosophers were blissfully ignorant to the unraveling of their revolutions, but we should not assume that contemporaries did not feel the same twilight setting. The figurative orange skies always creep in before dawn.</p>


<p>Which brings us to the supposed death of Silicon Valley, a fate that has long been predicted but with data now finally catching up. San Francisco apartment rents in 2020 have deflated by 20 percent after an up-up-and-away decade that made the city truly unlivable. Home inventory has reached a fifteen-year high in a city blighted by restrictive housing policy that makes construction cranes as miraculous as stumbling upon a burning bush. The growth in online sales-tax collection, according to the <em>San Francisco Chronicle</em>, is the lowest of all counties in the state of California. And public tech companies, such as Pinterest, paid upwards of $90 million to break its lease in downtown San Francisco. Some would argue this is a clear end to Bay Area tech dominance, while others would point to the many new unicorns that popped up this year despite the once-in-a-century pandemic. No one’s living here, yet somehow the companies are still growing.</p>
<p>Silicon Valley doesn’t really have cultural critics to weigh in on whether this era is officially over, but we do have venture capitalists. And our Nostradomuses are telling us that change is afoot.</p>
<p><em>Do we really need this office? The founders all have left.</em></p>
<p><em>Their entire partnership is now living in Montana. It’s only a two-hour flight away!</em></p>
<p><em>Denver seems like a good option, but Reno has no state income tax.</em></p>
<p>The weirdness of this exodus is that it is not driven by fear. Technologists weren’t <em>really </em>driven out by plague or fire or San Francisco’s insatiable need for higher tax revenue. Those ills were always apparent, and yet people stayed to carry the torch.</p>
<p>The exodus of tech’s true believers may be that the covenant is finally fulfilled. That when America—along with the rest of the world—met their darkest hour and turned inward, the technology that was long ridiculed as frivolous or dangerous led us to relative normalcy. The Zooms. The Tiger Kings. The Signal chats. The Slack jokes. An election news cycle that plowed ruthlessly forward on Twitter. Though inconvenient, mothers and fathers set their children in front of screens to occupy them for <em>just</em> long enough to survive a terrible year. And maybe, just maybe, the same-day-shipping racket that made Jeff Bezos the richest man alive was actually a feat of human genius that held the country together when public infrastructure and the social fabric were fraying at the seams. Perhaps our lowly software revolution was actually the fruition of a long-held California dream, when the physical world forced us inside and virtual life prevailed.</p>
<blockquote><p>Silicon Valley is no longer a place, they’ll say. It’s a way of being, of building, and the latest embodiment of belief in human progress. And it’s spreading faster than the viruses and the wildfires and the apocalyptic threats that mire our physical world.</p></blockquote>
<p>For that triumph, the nerds can now smell the impending scapegoating of their success. And like so many of history’s prophets and heretics, those who believe most fervently in the promise of technology are beginning their long march away from the Valley.</p>
<p>And they will substitute the virtual world for the physical space that once defined this movement. Silicon Valley is no longer a place, they’ll say. It’s a way of being, of building, and the latest embodiment of belief in human progress. And it’s spreading faster than the viruses and the wildfires and the apocalyptic threats that mire our physical world.</p>
<p>Silicon Valley is over. The exodus is just beginning.</p>
					</div> <!-- .entry-content -->

				
				</article></div>]]>
            </description>
            <link>https://breakingground.us/exodus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052818</guid>
            <pubDate>Tue, 10 Nov 2020 22:19:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top 10 Most Important SQL Commands to Know]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052742">thread link</a>) | @jackmcclelland
<br/>
November 10, 2020 | https://blog.arctype.com/sql-cheat-sheet-top-10-most-important-sql-commands-to-know/ | <a href="https://web.archive.org/web/*/https://blog.arctype.com/sql-cheat-sheet-top-10-most-important-sql-commands-to-know/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <figure><img src="https://blog.arctype.com/content/images/2020/11/SQL-Cheat-Sheet.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2020/11/SQL-Cheat-Sheet.png 600w, https://blog.arctype.com/content/images/size/w1000/2020/11/SQL-Cheat-Sheet.png 1000w, https://blog.arctype.com/content/images/2020/11/SQL-Cheat-Sheet.png 1440w"></figure><p>As companies and organizations find themselves dealing with rapidly increasing amounts of data, there's a growing need for developers to effectively use databases to handle this data. SQL, which stands for Structured Query Language, is a programming language that helps manage data stored in relational databases (a popular type of database).</p><p>SQL commands can help a developer create tables, add and modify data in these tables, search the database, and more. This article will cover a list of ten basic SQL commands that are essential to know for developers working with SQL. You'll find for each SQL command a code snipped and brief description of what the code runs.</p><p>Whether you're a beginner or a pro at SQL, consider trying out <a href="http://arctype.com/"><strong>Arctype</strong></a>, a redesigned SQL client for PostgreSQL and MySQL developers and teams. It's free, fast, and easy-to-use: <a href="http://arctype.com/" rel="noopener noreferrer">http://arctype.com/</a></p><p>Let's get right into it! Here are ten basic building blocks of SQL programming.</p><hr><!--kg-card-begin: markdown--><h2 id="createtable">CREATE TABLE</h2>
<pre><code>CREATE TABLE table_name (
  column_1 datatype_1, 
  column_2 datatype_2, 
  column_3 datatype_3
);
</code></pre>
<!--kg-card-end: markdown--><p>This command allows you to create a new database or table; the example above adds a new table with a title and column names.</p><!--kg-card-begin: markdown--><h2 id="altertable">ALTER TABLE</h2>
<pre><code>ALTER TABLE table_name 
ADD column_name datatype;
</code></pre>
<!--kg-card-end: markdown--><p>Run this command to modify (add, drop, rename, etc) the structure (not the data) in your database; the example above adds a new column to a table with a specified datatype.</p><!--kg-card-begin: markdown--><h2 id="delete">DELETE</h2>
<pre><code>DELETE FROM table_name
WHERE some_condition = some_value;
</code></pre>
<!--kg-card-end: markdown--><p>This command can delete data from your table based on conditions specified with the WHERE keyword.</p><!--kg-card-begin: markdown--><h2 id="drop">DROP</h2>
<p><code>DROP TABLE table_name;</code></p>
<!--kg-card-end: markdown--><p>Similar to the create command, DROP deletes a database or table. Be careful when using this command – the code above will delete your whole table, including all data, indexes, and more.</p><!--kg-card-begin: markdown--><p><code>ALTER TABLE table_name DROP COLUMN column_name;</code></p>
<!--kg-card-end: markdown--><p>The ALTER TABLE and DROP statement above will remove a specific column from a table.</p><!--kg-card-begin: markdown--><h2 id="insertinto">INSERT INTO</h2>
<pre><code>INSERT INTO table_name (column_1, column_2, column_3) 
VALUES (value_1, value_2, value_3);
</code></pre>
<!--kg-card-end: markdown--><p>To add new records to your table, use the INSERT INTO command. You can use this command on one or more rows.</p><!--kg-card-begin: markdown--><h2 id="select">SELECT</h2>
<pre><code>SELECT column_name 
FROM table_name;
</code></pre>
<!--kg-card-end: markdown--><p>Every query begins with SELECT; this is how you grab data from your database. It's the most fundamental SQL query. After the SELECT command, you can use the keyword FROM to specify a table, the keyword WHERE to select with conditions, and the keyword ORDER BY to sort your results.</p><!--kg-card-begin: markdown--><h2 id="update">UPDATE</h2>
<pre><code>UPDATE table_name
SET some_column = some_value
WHERE some_column = some_value;
</code></pre>
<!--kg-card-end: markdown--><p>This command lets you edit data in your table by updating data based on conditions specified after the WHERE keyword.</p><!--kg-card-begin: markdown--><h2 id="as">AS</h2>
<pre><code>SELECT column_name AS 'Alias'
FROM table_name;
</code></pre>
<!--kg-card-end: markdown--><p>The AS keyword allows you to use a temporary alias when referring to a column or table.</p><!--kg-card-begin: markdown--><h2 id="count">COUNT</h2>
<pre><code>SELECT COUNT(column_name)
FROM table_name;
</code></pre>
<!--kg-card-end: markdown--><p>Use the COUNT() function to add up the number of rows where the specified column is not NULL.</p><!--kg-card-begin: markdown--><h2 id="between">BETWEEN</h2>
<pre><code>SELECT column_name(s)
FROM table_name
WHERE column_name BETWEEN value_1 AND value_2;
</code></pre>
<!--kg-card-end: markdown--><p>This operator filters the results to be within a specified range (numbers, text, dates, etc).</p><hr><p>These building blocks will get you started programming with SQL, which is a great language useful and definitely worth learning in 2020. Check out the <a href="https://insights.stackoverflow.com/survey/2020">StackOverflow Developers Survey 2020</a>, where 65k developers answered questions about the programming languages and tools they run: SQL was top three in the most popular technologies question!</p><figure><img src="https://blog.arctype.com/content/images/2020/11/devdev.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2020/11/devdev.png 600w, https://blog.arctype.com/content/images/2020/11/devdev.png 900w" sizes="(min-width: 720px) 720px"><figcaption>If you're curious you can check out the rest of the results of the survey here at the URL here: <a href="https://insights.stackoverflow.com/survey/2020" rel="noopener noreferrer">https://insights.stackoverflow.com/survey/2020</a></figcaption></figure><p>Database programming languages are popular and have active developer communities, and are becoming increasingly important as organizations seek to process the thousands of terabytes of data generated each day. If you're working with databases in SQL or are planning on doing so, check out the newly-designed <a href="http://arctype.com/"><strong>Arctype</strong></a> SQL client. It's faster and easier-to-use than many of the clients out there right now and is designed with your needs in mind as a modern developer.</p><p>Thanks for checking out my article covering these ten basic SQL commands! Let me know if you have any questions, or would like me to write a follow-up post with more intermediate SQL commands to check out. Happy coding!</p>
            </div></div>]]>
            </description>
            <link>https://blog.arctype.com/sql-cheat-sheet-top-10-most-important-sql-commands-to-know/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052742</guid>
            <pubDate>Tue, 10 Nov 2020 22:12:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantopian's open-source investment dream died]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25052699">thread link</a>) | @ugwigr
<br/>
November 10, 2020 | https://www.businessofbusiness.com/articles/how-quantopian-died-shut-down-quant-investment-robinhood/ | <a href="https://web.archive.org/web/*/https://www.businessofbusiness.com/articles/how-quantopian-died-shut-down-quant-investment-robinhood/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-section">
    <!-- .sidebar -->

    <section>
      
      

      <p>Back in 2011, John Fawcett and Jean Bredeche had the dream of democratizing investing. They envisioned a platform that would make quantitative analysis and investment accessible and understandable for anyone who was keen to give it a try, kicking down doors for the everyman that had mostly been open to hedge funds or super-rich angel investors until that point.</p>
<p>Quantopian was launched off the back of that dream. A platform that taught users about quant investment and gave them a platform to write and save their own code, Quantopian was supposed to be the first crowd-sourced hedge fund. For years, users iterated on each other’s code as a community developed on the platform, full of users with and without financial backgrounds. These users would pit their algorithms against one-another, and Quantopian would go on to use the winning equations to manage investor assets, giving the winners some returns.&nbsp;</p>
<p>Fawcett and Bredeche would go on to raise $48.8 million for Quantopian in the meantime. In 2016, Steven Cohen announced that he would be teaming up with Quantopian to the tune of $250 million, relying on some of the user models Quantopian managed and investing in Quantopian itself.</p>
<p><span>In February, the first cracks in the city wall took hold. For at least two years, Fawcett said in </span><a href="https://www.bizjournals.com/boston/news/2020/02/20/fintech-firm-quantopian-is-returning-investors.html"><span>an interview</span></a><span>, Quantopian’s low-risk, market-neutral strategy model hadn’t been yielding results. Fawcett and Bedeche announced that the company would be returning investor money and switching strategies in an attempt to keep things afloat, </span><a href="https://www.quantopian.com/posts/quantopian-strategic-pivot"><span>asking that users</span></a><span> now develop models beyond the market-neutral ones the company had relied on for years.</span></p>
<p>Now, the dream is dead.</p>
<p><span>This week, Quantopian </span><a href="https://www.quantopian.com/posts/quantopians-community-services-are-closing"><span>abruptly announced</span></a><span> that it would be shutting down its community services and that users would lose access to all their materials if not saved locally by November 14. No reason was given for the shutdown.&nbsp;</span><span>Quants across the finance community expressed equal parts shock and disappointment that Quantopian had </span><a href="https://www.linkedin.com/posts/dr-tom-starke-a0a9a3b3_tribute-to-quantopian-activity-6728150978325045248-Lrsf/"><span>come crashing down</span></a><span>.&nbsp;</span></p>
<p>“Our mission was to break open quant finance and make it accessible to everyone,” Fawcett wrote in a blog post on Quantopian’s website. "You helped realize this mission and came together to form the biggest community of quants the world has ever seen. For that, I am extremely proud and grateful. I sincerely hope that Quantopian is just one milestone in your journey through quantitative finance.”</p>
<p>The announcement was met with mixed reception. Some users gave tearful goodbyes to the platform and expressed interest in crowdfunding the site, while others expressed outrage at the seemingly abrupt decision.&nbsp;</p>
<hr>
<blockquote>
<h2>"Was there a heads-up so we could retrieve our results? backtests? :("</h2>
</blockquote>

<blockquote>
<h2>"My god no. is there any way to save the quantopian community site ??? why is this site closing down???"</h2>
<h2>"0-day notice! Are you kidding me &gt; where is all the code ???"</h2>
</blockquote>
<hr>
<p>Fawcett gave no answers. Users wondered the extent to which Quantopian would disappear; would the lectures and learning resources be preserved online somewhere? Would they be able to recover assets of theirs which had already been taken down? Where would they go to chat and organize with other quants and finance junkies?&nbsp;</p>
<p>The name Quantopian gave itself proved to be an ominous foreshadowing of its eventual fate. All utopias must fall, and Quantopian’s democratic dream had turned to sand and fallen through users' fingers before they could come to grips with what was happening.&nbsp;</p>
<p><span>In 2020, Quantopian’s dream of “democratizing finance” isn’t unique. Trading app Robinhood touts </span><a href="https://robinhood.com/us/en/support/articles/our-mission/#:~:text=Robinhood's%20mission%20is%20to%20democratize,for%20newcomers%20and%20experts%20alike."><span>the exact same mission</span></a><span>, and it’s trying to pick up where Quantopian left off. Yesterday, Fawcett announced that Quantopian and Robinhood would be </span><a href="https://www.quantopian.com/posts/were-joining-robinhood"><span>coming together</span></a><span> in what he described as a natural fit for the two companies.&nbsp;</span></p>
<p><span>“</span><span>Quantopian has always stood for greater access and deeper education, so we are fundamentally aligned with Robinhood’s mission to democratize finance for all,” Fawcett wrote. “Our merry band of Quantopians should fit right in as we work together to further expand access to financial information and education, and inspire greater participation in the financial markets.”</span></p>
<p>Fawcett offered little details as to how this deal would take form, but one thing was clear: the Quantopian of old would no longer exist.</p>
<p>These platforms are more than the sum of their parts, and Quantopian’s community structure — the factor which most makes it unmistakably itself — will not be preserved by Robinhood.&nbsp;</p>
<p>Robinhood has grown to considerable size and been downloaded by an ever-increasing number of users during the COVID-19 pandemic who are using it to invest and, hopefully, make a little extra money during trying times. Or, if they’re lucky enough, make it big.&nbsp;</p>
<p><span>But although Robinhood shares the same mission as Quantopian at first glance, it is propped up on something much uglier than Quantopian ever was. Robinhood lacks a community element, and what implementations it has tried have had </span><a href="https://fortune.com/2020/08/10/robinhood-popularity-data-robintrack-stock-market-trading-tracker/"><span>disastrous impacts</span></a><span>. A read through the replies to Quantopian’s shutdown announcement reveal the deep histories users had on the platform.</span></p>
<p>“Within a few months after joining in 2016, I'd learned Python, programmed all of my Excel-based strategies, entered and won Contest 22, [and] started live trading in IB,” user Roman Parker wrote. “With no relevant degree or experience, I was interviewing at large NYC funds. Q was changing my life.”</p>
<hr>
<blockquote>
<h2>"Never in my life have i seen a place where so many smart people were willing to share so much information with me without expecting anything in return. I am and will forever be grateful for what you have done for me." — Quantopian user Mattias Lamonte</h2>
</blockquote>

<hr>
<p>The communities that have sprouted up around Robinhood’s success are much darker. Communities like r/wallstreetbets and viral videos like the infamous “<a href="https://www.youtube.com/watch?v=A-tNkuYV4_Q">wsb yolo</a>,” which shows a man losing tens of thousands of dollars on the app in real time, keep sincerity at an arm’s length and sustain themselves with desperate humor. Though the output of Quantopian’s community was ultimately gobbled up by Quantopian itself and its investors, what Quantopian provided to its users was collaboration and experience. Robinhood’s frenzy is about who can win big, and who can lose bigger.</p>
<p><span>Even if the business end couldn’t keep itself afloat, the utopia existed, for a time, for the site’s users, many of whom had their lives and careers changed by Quantopian’s open platform and its catalog of resources. Today, other services like Quantiacs and QuantConnect operate off similar models to Quantopian’s. The first to do something isn’t always the best to do it, and perhaps one of these companies will perfect what Quantopian initially set out to do.</span></p>
<p>These lives wouldn't have been impacted if Quantopian had not put out the rallying call, but ultimately, users didn't need Quantopian as much as Quantopian needed them.&nbsp;Quantopian gave them the first rocks and sticks, and the community used it to build cities. In the end, it was the failure of the company itself, not those who used its tools, to deliver on the promise that attracted such a large community to begin with.</p>
      

      

      



    </section><!-- .article-body -->

    
  </div></div>]]>
            </description>
            <link>https://www.businessofbusiness.com/articles/how-quantopian-died-shut-down-quant-investment-robinhood/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052699</guid>
            <pubDate>Tue, 10 Nov 2020 22:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Birth of Unix with Brian Kernighan [audio]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052605">thread link</a>) | @spinningslate
<br/>
November 10, 2020 | https://corecursive.com/brian-kernighan-unix-bell-labs1/ | <a href="https://web.archive.org/web/*/https://corecursive.com/brian-kernighan-unix-bell-labs1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>When you work on your computer, there are so many things you take for granted: operating systems, programming languages, they all have to come from somewhere. </span></p><p><span>In the late 1960s and 1970s, that somewhere was Bell Labs, and the operating system they were building was UNIX. </span></p><p><span>They were building more than just an operating system though. They were building a way to work with computers that had never existed before.&nbsp; </span></p><p><span>In today’s episode I talk to Brian Kernighan about the history of Unix.</span></p><p><span>“If you wanted, you could go sit in your office and think deep thoughts or program, or write on your own blackboard or whatever, but then come back to the common space when you wanted to.“ – Brian Kernighan </span></p><p><span>“I found it easier to program when I was trying to figure out the logic for myself rather than trying to figure out where in the infinite stack of documentation was the function I needed. So for me, programming is more like creating something rather than looking it up, and too much of today’s programming is more like looking it up.” – Brian Kernighan </span></p><p><span>“If what I find challenging or hard or whatever is also something that other people find hard or challenging or whatever, then if I do something that will improve my lot, I’m perhaps improving their lot at the same time.” – Brian Kernighan</span></p><p><span><strong>Links:</strong></span></p><p><a href="https://www.cs.princeton.edu/people/profile/bwk" target="_blank" rel="noopener noreferrer">Brian’s Homepage</a></p><p><a href="https://www.amazon.com/dp/1695978552" target="_blank" rel="noopener noreferrer">Book: Unix: A History and a Memoir</a></p></div></div>]]>
            </description>
            <link>https://corecursive.com/brian-kernighan-unix-bell-labs1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052605</guid>
            <pubDate>Tue, 10 Nov 2020 22:01:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boring Tech Is More Fun]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052491">thread link</a>) | @amzans
<br/>
November 10, 2020 | https://panelbear.com/blog/boring-tech/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/boring-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Over the years I have observed that many engineers tend to attribute much of the success or failure of a company to the technical choices made. I know I’m often guilty of this too. And while it is often justified, I would argue that for the vast majority of startups out there, the choice of programming language, framework, or even database doesn’t matter that much. This seems especially true during the early stages.</p><h2>Through the engineering lens</h2><p>This perception is understandable, we as engineers tend to look at the world from a specific lens, and are often biased by what we know best. Our daily activities may include things such as debugging CI pipelines, implementing new features, pairing with colleagues, or migrating the always present legacy codebase. The environment that surrounds us makes it easy to believe that it all boils down to those things that we see and understand. It’s an illusion that makes us feel like we’re fully in control of what makes or breaks the product.</p><p>Don’t get me wrong, it can be a huge advantage for many companies to make their product 3x more efficient than competitors, or to have elegant, composable code. But you might be focusing on the wrong problems if nobody cares about the product you’re actually building, and sooner or later your business will hit this wall.</p><p>I’m not saying that software doesn’t matter. A solid foundation for your startup goes a long way. If investing in this allows you to build better features faster than your competitors, more power to you. But finding the right balance is highly dependent on what you’re trying to solve and the resources you have at hand. There’s no right or wrong way to do it, and as usual, it mainly comes down to tradeoffs.</p><p><img src="https://panelbear.com/static/img/blog/lenses.png" alt="Different lenses"></p><h2>Boring makes me happy</h2><p>I believe aiming for a healthy balance of risk vs reward when it comes to your technical choices is something to strive for. In particular, if it decreases the chances you get stuck on the wrong problems down the road.</p><p>This is why I have come to appreciate ideas such as <a href="https://mcfunley.com/choose-boring-technology">Choose Boring Technology</a>. This is often interpreted as “picking old technologies over newer ones”, but it doesn’t necessarily mean that. For me, this comes down to using proven technologies in which the ways it can fail are mostly known, but occasionally experimenting with different, possibly newer tools that might suit me better.</p><p>Maybe you want to gain more experience by using the latest framework or programming language, or you just want to have some fun. You do what makes you happy. But if you’re trying to make a decision to increase the odds that your product or business will succeed, it’s worth stepping back and considering your options.</p><p>For me, mainly choosing software that has been around for longer is not about it being boring or older, it’s about the fact that the ways in which it fails are better known. There are fewer unknowns for you to deal with and this maximizes your chances of actually shipping the project.</p><p>For example the other day I had an issue with my Django app, and a quick search led me to tens of answers to this problem in various forums and websites. It took me at most 10 minutes to get back on track and that was the end of this issue.</p><p>I experienced the exact opposite a few years ago with a popular, but not so battle-tested Scala library my team had been using for a while. We were probably among the first to encounter the issues we were facing, and it seemed nobody had walked down this path before. Maybe it sounds like a fun challenge or a great chance to contribute back to OSS (which I’m happy to), but once you solve it, do your customers really care about it? How many days, weeks, or even months are you willing to invest in such issues? In my case, I’d rather use that time to ship new features or improve the existing ones.</p><h2>Proven tech vs new tools</h2><p>I try to follow an 80/20 distribution when it comes to my choice of tools. This means my stack consists of about 80% software I already know well, but I do allow myself 20% of the stack to explore tech I have less experience with. The exact ratio is not what’s important here, it’s more the fact that you should lean towards using proven technologies.</p><p>This also resonates with how <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed bandits</a> work. You try to maximize your expected gain by taking advantage of what worked well in the past, while sometimes exploring new things to avoid missing out on a possible goldmine.</p><p><img src="https://panelbear.com/static/img/blog/bandits.png" alt="Balance new vs proven"></p><p>A more recent example of mine is <a href="https://panelbear.com/">Panelbear</a>, it started as an embarrassingly simple Django app with no charts, all metrics were rendered on a plain HTML table, and all data was stored on a SQLite database. Took literally a weekend to get it up and running including manually deploying to a $5/mo VM. Low risk and high reward for my needs at the time.</p><p>Fast forward and as I added more features and began handling more page views for various websites, I started to notice that the codebase could use some refactoring. It also became increasingly repetitive to do things like deploying to new instances, issuing SSL certs, and keeping the DNS records up to date in case the IP address of my instances changed.</p><p>As a second iteration, I upgraded to a docker-compose setup plus lots of glue code. But soon enough I found myself reinventing what other tools already do well. There are multiple ways to solve each of these pain points, but in my case, it came down to using a tool I am very familiar with from my full-time job: Kubernetes.</p><p>Yes, I am well aware Kubernetes is an absolute overkill for a lot of projects out there, and I could have gotten away with a more traditional solution. But it allowed me to simplify the operational aspects tremendously, and I feel comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. That’s why I wouldn’t bindly recommend it to everyone. Do what you know best.
As an added benefit, it also made it trivial when I migrated from DigitalOcean to Linode, and most recently to AWS (each migration took mostly an evening of changing my Terraform files and deploying them - I’m being serious). But that’s for another post.</p><p>Another case in which it paid off once again, was when I wanted to experiment with using Clickhouse for data ingestion and the aggregation queries. It took me less than 10 minutes to write a basic deployment manifest and have it up and running. This included automated SSL certs, in-cluster service discovery, and unified logging/monitoring out of the box. It was a huge win since it allowed me to try things out faster than before.</p><p>Even better, I can deploy any container and operate it the exact same way as I deploy anything else on my cluster. Need more volume storage with zero downtime? It’s a simple manifest change, commit and deploy. Same thing when I needed Redis for caching, I was up and running in minutes, without increasing my costs or adding operational complexity.</p><h2>Focus on shipping</h2><p>My point is, I moved into these technologies as the pain with the previous solution was higher than dealing with the new tech. But more importantly, it helped me ship features even faster to my customers while reducing the operational overhead for me.</p><p>If I had started with the more advanced setup from day one, I might have lost all motivation before I would have had the first version of Panelbear. The key is to solve the problems that are getting between you and your goals, not potential issues you believe one day will be yours.</p><p>Hope you enjoyed this blog post. I plan on writing more about Panelbear’s tech stack, and lessons learned along the way. So stay tuned!</p></div></div></div>]]>
            </description>
            <link>https://panelbear.com/blog/boring-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052491</guid>
            <pubDate>Tue, 10 Nov 2020 21:52:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I find 10x more content on Twitter in half the time]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25052286">thread link</a>) | @justanotherpm
<br/>
November 10, 2020 | https://blog.justanotherpm.com/discover-10x-more-content-on/ | <a href="https://web.archive.org/web/*/https://blog.justanotherpm.com/discover-10x-more-content-on/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
            <p>I am an avid Twitter user, and my Twitter goals are to consume meaningful content and share similarly interesting content with my followers. If in the process, I end up getting more followers, I welcome them with a smile.</p><p>I've always found that <em>discovering</em> good content is a more significant challenge than <em>sharing</em> useful content. Over the years, I've developed the following system to help me consume better content faster:</p><ol><li>Rather than following hundreds of accounts, I create Twitter lists and add relevant users to each list. For example, I have a list called "Product Tweeple", which includes those accounts which share relevant and interesting content on product management. Now, instead of aimlessly browsing my home feed, I scan the lists that I'm interested in at that time.</li><li>I like to know about certain content or events as soon as it's shared. For such accounts, I use the notification feature with the "all tweets" option. These are accounts that I like to engage with, and, secretly, want to be the first one to reply, like or RT their tweets.</li><li>Once a while, I find tweets that have long and engaging discussions. I use Tweetdeck for this. I search tweets with keywords of interest and then filter by the number of replies.</li><li>I bookmark Tweets, especially threads, that I want to have easy access to in the future.</li></ol><p>Let me know if you have any Twitter tricks that work for you.</p>
    </div>
        
</article>                            </main>
</div>
        </div></div>]]>
            </description>
            <link>https://blog.justanotherpm.com/discover-10x-more-content-on/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052286</guid>
            <pubDate>Tue, 10 Nov 2020 21:35:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get Rid of If-Else Ladder]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052170">thread link</a>) | @maniish_jaiin
<br/>
November 10, 2020 | https://maniishjaiin.tech/how-to-get-rid-of-if-else-ladder | <a href="https://web.archive.org/web/*/https://maniishjaiin.tech/how-to-get-rid-of-if-else-ladder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><h2 id="easy-way-to-write-clean-code-using-higher-order-functions-and-hashmaps">Easy way to write clean code using Higher-Order Functions and HashMaps</h2>
<p>In one of my previous articles, I talked about  <a target="_blank" href="https://maniishjaiin.tech/lets-talk-test-driven-development">Test-Driven Development</a>. There we ended up with a solution having a switch-case. In this one, we will see ways to avoid having a switch-case or an if-else ladder.</p>
<p>I will start with a problem known as Reverse Polish Notation. A lot of you might have heard of this problem, and it is a straightforward problem to solve. But our focus for this article is to understand how we can write <em>CLEAN CODE</em> by removing the <code>if-else</code> ladder by using Hashmaps and Higher-Order functions.</p>
<p>Before we start, the solution discussed here is in Java and Kotlin.</p>
<p>What is Reverse Polish Notation:</p>
<p><em>In reverse Polish notation, the operators follow their operands; for instance, to add 3 and 4, one would write</em> <code>_3 4 +_</code> <em>rather than</em> <code>_3 + 4_</code><em>. If there are multiple operations, operators are given immediately after their second operands; so the expression is written</em> <code>_3 − 4 + 5_</code> <em>in conventional notation would be written</em> <code>_3 4 − 5 +_</code> <em>in reverse Polish notation: 4 is first subtracted from 3, then 5 is added to it.</em></p>
<p>The solution to this problem is also pretty simple. We need to use a Stack and continuously push the elements until we find any operator <code>(+, –, *, /)</code>. Once we find an operator we pop the two numbers from the stack and perform the operation (Addition, Division, etc.) on them.</p>
<p>So, for input <code>3 4 +</code> we will push 3, and then push 4 and then when we encounter a <code>+</code> we will pop <code>3</code> and <code>4</code> and add them.</p>

<p>A naive solution in Java would look like this. We have a method <code>evaluate</code> which takes in the input, splits it using <code>“ ”</code> . And iterate over the char array pushing numbers to the stack and applying operations based on the operators encountered using the switch-case.</p>
<pre><code><span>import</span> java.util.Stack;

<span><span>class</span> <span>ReversePolishNotation</span> {</span>
    <span><span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(String[] args)</span>
    </span>{
        System.out.println(evaluate(<span>"5 1 2 + 4 * + 3 -"</span>));
    }
    <span><span>public</span> <span>static</span> <span>double</span> <span>evaluate</span><span>(String expr)</span>
    </span>{
        String[] digitString = expr . split (<span>" "</span>);
        Stack&lt;Float&gt; <span>stack</span> = <span>new</span> Stack&lt;Float&gt;();
        <span>for</span> (String s : digitString) {
        <span>switch</span>(s) {
            <span>case</span> <span>"+"</span>: {
            <span>float</span> numberOne = <span>stack</span> . pop ();
            <span>float</span> numberTwo = <span>stack</span> . pop ();
            <span>stack</span>.push(numberOne + numberTwo);
            <span>break</span>;
        }
            <span>case</span> <span>"-"</span>: {
            <span>float</span> numberOne = <span>stack</span> . pop ();
            <span>float</span> numberTwo = <span>stack</span> . pop ();
            <span>stack</span>.push(numberTwo - numberOne);
            <span>break</span>;
        }
            <span>case</span> <span>"*"</span>: {
            <span>float</span> numberOne = <span>stack</span> . pop ();
            <span>float</span> numberTwo = <span>stack</span> . pop ();
            <span>stack</span>.push(numberOne * numberTwo);
            <span>break</span>;
        }
            <span>case</span> <span>"/"</span>: {
            <span>float</span> numberOne = <span>stack</span> . pop ();
            <span>float</span> numberTwo = <span>stack</span> . pop ();
            <span>stack</span>.push(numberTwo / numberOne);
            <span>break</span>;
        }
            <span>default</span>: {
            <span>stack</span>.push(Float.parseFloat(s));
            <span>break</span>;
        }
        }
    }
        <span>return</span> <span>stack</span>.pop();
    }
}
</code></pre><p>This is the first iteration of the solution that works as expected. Now, let's think of a better solution to this. If you look at each of the cases we see a lot of duplication.</p>
<pre><code><span>float</span> numberOne = <span>stack</span>.pop();
<span>float</span> numberTwo = <span>stack</span>.pop();
<span>stack</span>.push(numberOne + numberTwo);
</code></pre><p>The common part in the above code is the stack operation. The only change is the operation that we perform. If we could parameterize the operation to a function we should be able to reuse the code. Let’s see how we can do that.</p>

<p>The <code>[BiFunction](https://docs.oracle.com/javase/8/docs/api/java/util/function/BiFunction.html)</code> is a specialization of the <code>[Function](https://learnjava.co.in/java-8-function-interface-example/)</code> interface that accepts 2 arguments. Just like a <code>Function</code>, it provides a method called <code>apply</code>. This method accepts 2 arguments of any data type and returns a result. Exactly what we need to perform the operations. Our add function takes in two parameters and returns the result back!</p>
<p>So we can pass addition, subtraction, multiplication, and division functions as BiFunctions.</p>
<pre><code><span>import</span> java.util.Stack;
<span>import</span> java.util.function.BiFunction;

<span><span>class</span> <span>ReversePolishNotation</span> {</span>

    <span><span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(String[] args)</span>
    </span>{
        System.out.println(evaluate(<span>"4 2 /"</span>));
    }

    <span><span>public</span> <span>static</span> <span>double</span> <span>evaluate</span><span>(String expr)</span>
    </span>{
        String[] digitString = expr . split (<span>" "</span>);
        Stack&lt;Float&gt; <span>stack</span> = <span>new</span> Stack&lt;Float&gt;();
        <span>for</span> (String s : digitString) {
        <span>switch</span>(s) {
            <span>case</span> <span>"+"</span>: {
            <span>stack</span>.push(operate((a, b) -&gt; a+b, <span>stack</span>));
            <span>break</span>;
        }
            <span>case</span> <span>"-"</span>: {
            <span>stack</span>.push(operate((a, b) -&gt; a-b, <span>stack</span>));
            <span>break</span>;
        }
            <span>case</span> <span>"*"</span>: {
            <span>stack</span>.push(operate((a, b) -&gt; a * b, <span>stack</span>));
            <span>break</span>;
        }
            <span>case</span> <span>"/"</span>: {
            <span>stack</span>.push(operate((a, b) -&gt; a / b, <span>stack</span>));
            <span>break</span>;
        }
            <span>default</span>: {
            <span>stack</span>.push(Float.parseFloat(s));
            <span>break</span>;
        }
        }
    }
        <span>return</span> <span>stack</span>.pop();
    }

    <span><span>public</span> <span>static</span> Float <span>operate</span><span>(BiFunction&lt;Float, Float, Float&gt; function, Stack&lt;Float&gt; <span>stack</span>)</span>
    </span>{
        <span>float</span> numberOne = <span>stack</span>.pop();
        <span>float</span> numberTwo = <span>stack</span>.pop();
        <span>return</span> function.apply(numberTwo, numberOne);
    }
}
</code></pre><p>In the above code the BiFunction is:</p>
<pre><code>(a, b) -&gt; a + b
</code></pre><p>And our method <code>operate</code> takes in the BiFunction as the input.</p>
<p>Now, we have removed the duplication by extracting a function from it and making it accept our operations as functions.</p>
<p>But there is still that switch-case ladder which is taking care of figuring out which operation we should use. What if we could get rid of that?</p>
<p>Let's think about that. Only if we could do a <code>operator</code> lookup, we would be able to remove this ladder.</p>
<p>And what can be used to do a lookup?</p>
<p>A HashMap indeed!</p>

<p>We map our operators with the functions and then when we iterate over the string, and fetch functions if we find an operator otherwise we just push that number to the stack.</p>
<pre><code>import java.util.HashMap;
import java.util.Stack;
import java.util.function.BiFunction;

<span><span>class</span> <span>ReversePolishNotation</span> </span>{

    <span>public</span> <span>static</span> <span>void</span> main(<span>String</span>[] args)
    {
        System.out.println(evaluate(<span>"4 2 /"</span>));
    }

    <span>public</span> <span>static</span> <span>double</span> evaluate(<span>String</span> expr)
    {
        <span>String</span>[] digitString = expr . split (<span>" "</span>);

        Stack&lt;<span>Float</span>&gt; stack = <span>new</span> Stack&lt;&gt;();
        HashMap&lt;<span>String</span>, BiFunction&lt;<span>Float</span>, <span>Float</span>, <span>Float</span>&gt;&gt; map = constructMapForOperator ();

        <span>for</span> (<span>String</span> s : digitString) {
        <span>if</span> (map.containsKey(s)) {
            stack.push(operate(map.get(s), stack));
        } <span>else</span> {
            stack.push(<span>Float</span>.parseFloat(s));
        }
    }
        <span>return</span> stack.pop();
    }

    <span>private</span> <span>static</span> HashMap&lt;<span>String</span>, BiFunction&lt;<span>Float</span>, <span>Float</span>, <span>Float</span>&gt;&gt; constructMapForOperator()
    {
        HashMap&lt;<span>String</span>, BiFunction&lt;<span>Float</span>, <span>Float</span>, <span>Float</span>&gt;&gt; map = <span>new</span> HashMap();
        map.put(<span>"+"</span>, (a, b) -&gt; a+b));
        map.put(<span>"-"</span>, (a, b) -&gt; a-b);
        map.put(<span>"*"</span>, (a, b) -&gt; a * b);
        map.put(<span>"/"</span>, (a, b) -&gt; a / b);
        <span>return</span> map;
    }

    <span>public</span> <span>static</span> <span>Float</span> operate(BiFunction&lt;<span>Float</span>, <span>Float</span>, <span>Float</span>&gt; <span><span>function</span>, <span>Stack</span>&lt;<span>Float</span>&gt; <span>stack</span>)
    </span>{
        <span>float</span> numberOne = stack.pop();
        <span>float</span> numberTwo = stack.pop();
        <span>return</span> function.apply(numberTwo, numberOne);
    }
}
</code></pre><p>This approach can be utilized in all those places where you see an if-else or a switch-case ladder. This works almost everywhere. You just have to carefully think about the Higher-Order function that you need to create.</p>
<p>For the Kotlin enthusiasts out there, here is the same solution in Kotlin.</p>
<pre><code><span>import</span> java.util.*

<span><span>fun</span> <span>main</span><span>()</span></span> {
    println(evaluate(<span>"4 2 /"</span>))
}

<span><span>fun</span> <span>evaluate</span><span>(expr: <span>String</span>)</span></span>: <span>Float</span> {
    <span>val</span> chars = expr.split(<span>" "</span>)
    <span>val</span> stack = Stack&lt;<span>Float</span>&gt;()
    <span>val</span> <span>operator</span> = operationForOperator()
    <span>for</span> (c <span>in</span> chars) {
        <span>operator</span>[c]?.let { stack.push(operate(it, stack)) } ?: stack.push(c.toFloat())
    }
    <span>return</span> stack.pop()
}

<span><span>fun</span> <span>operationForOperator</span><span>()</span></span>: Map&lt;String, (<span>Float</span>, <span>Float</span>) -&gt; <span>Float</span>&gt; {
    <span>return</span> mapOf(
        <span>"+"</span> to { a, b -&gt; a + b },
        <span>"-"</span> to { a, b -&gt; a - b },
        <span>"*"</span> to { a, b -&gt; a * b },
        <span>"/"</span> to { a, b -&gt; a / b }
    )
}

<span><span>fun</span> <span>operate</span><span>(function: (<span>a</span>: <span>Float</span>, <span>b</span>: <span>Float</span>) -&gt; <span>Float</span>, stack: <span>Stack</span>&lt;<span>Float</span>&gt;)</span></span>: <span>Float</span> {
    <span>val</span> numberOne = stack.pop()
    <span>val</span> numberTwo = stack.pop()
    <span>return</span> function(numberTwo, numberOne)
}
</code></pre><p>If you notice, we do not need an if-else here as in the for-loop at the top. We can utilize <strong>Kotlin’s Elvis Operator (?:)</strong> which will automatically execute the last part if there is no matching key in the map. We started with 50 lines of code and reached 30 lines of code using Kotlin.</p>
<p>You can follow me on <a target="_blank" href="https://twitter.com/manish_zainz1">Twitter</a> where I occasionally post from my learnings.</p>
<h2 id="you-might-be-interested-in-reading-these-as-well">You might be interested in reading these as well:</h2>
<p><a target="_blank" href="https://maniishjaiin.tech/3-habits-that-will-help-you-become-a-top-developer">3 Habits That Will Help You Become a Top Developer</a></p>
<p><a target="_blank" href="https://maniishjaiin.tech/5-mindsets-of-unsuccessful-developers">5 Mindsets of Unsuccessful Developers</a></p>
</div></div>]]>
            </description>
            <link>https://maniishjaiin.tech/how-to-get-rid-of-if-else-ladder</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052170</guid>
            <pubDate>Tue, 10 Nov 2020 21:25:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The value of anonymous employee feedback]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25051908">thread link</a>) | @mirvise
<br/>
November 10, 2020 | https://inkrement.io/blog/diversity-inclusion-and-anonymous-feedback/ | <a href="https://web.archive.org/web/*/https://inkrement.io/blog/diversity-inclusion-and-anonymous-feedback/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	<div>
		<p>A few years ago, I witnessed a particular coworker get singled out and eventually forced out of a company where we worked. What happened? She shared constructive feedback to our leadership during an all-staff meeting about our company’s pay disparities by race. She made suggestions for improvement and transparency as a way to truly demonstrate the company’s values. The leaders acted like they appreciated her feedback and promised to commit to the necessary changes.</p><p>Many of us applauded her courage after the meeting because she was the voice we all needed. According to her, it felt like the right thing to do since the company claimed they had an open feedback culture, where anyone could share their honest opinions. Little did she know what awaited her afterwards—she was treated differently and, in many overt ways, made to feel uncomfortable for an extended period. Eventually, she had to exit the company.</p><p>In recent times, we have seen a global reawakening around social issues relating to diversity and inclusion. Some of us would attest that conversations around diversity and inclusion have been ongoing for some time. Still, it feels like something is amiss.</p><p>According to a <a href="https://hbr.org/2018/12/to-retain-employees-focus-on-inclusion-not-just-diversity">Harvard Business Review</a> article, “most business leaders understand the diversity part of diversity and inclusion,… [but] it’s the inclusion part that eludes them... [and] the key to inclusion is understanding who your employees really are.” As an organizational leader, can you say that you understand who your employees are? And how do you know that?</p><p>A meaningful way to understand your employees is by creating feedback channels that allow all employees to share their opinions or suggestions about workplace practices, without fear of retaliation.</p><h3 id="why-anonymous-feedback-is-important-for-diversity-and-inclusion">Why Anonymous Feedback Is Important For Diversity And Inclusion</h3><p>More than ever, many workplaces are adopting initiatives to improve their diversity, equity, and inclusion efforts.</p><p>While many business leaders describe their organizations as transparent, most of their employees do not agree—a <a href="https://slack.com/intl/en-ng/blog/transformation/trust-tools-and-teamwork-what-workers-want">study</a> of over 1,400 workers conducted by Slack, a popular workplace communication platform, proves this. In this study, “55 percent of business owners described their organization as very transparent, but only 18 percent of their employees would agree.” Moreover, employees who complain about workplace issues have worse careers, mental health, and physical health than those who experience similar issues but do not complain, according to a recent <a href="https://www.umass.edu/employmentequity/sites/default/files/What_Works.pdf">report</a> titled, “What Works? Evidence-Based Ideas to Increase Diversity, Equity, and Inclusion in the Workplace.”</p><blockquote>55 percent of business owners described their organization as very transparent, but only <strong>18 percent</strong> of their employees would agree</blockquote><p>These findings tell me one thing: even though the mainstream opinion says that results from anonymous feedback can be <a href="https://hbr.org/2013/06/confidential-surveys-undermine">inaccurate, biased, or self-serving</a>, direct feedback isn’t proving to be sufficient for diversity, equity, and inclusion. Despite the open-door policies that many business leaders offer to make employees speak up, some employees may remain silent. Based on the experience I shared, employees may not speak up once they notice that they belong to a different race, gender, national origin, or other identities than most of their coworkers, to avoid being singled out.</p><p>As HR leaders and managers look to design diversity and inclusion programs, consider that some employees need a safe space to share honest feedback—especially when giving upward feedback.</p><p>Therefore, I would like to explore the use of anonymous feedback in the workplace.</p><h3 id="what-is-anonymous-feedback">What Is Anonymous Feedback?</h3><p>Unlike <a href="https://pdf.sciencedirectassets.com/277811/1-s2.0-S1877042815X00334/1-s2.0-S1877042815038082/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEEkaCXVzLWVhc3QtMSJHMEUCIFeIdtU0SvQQBr4CrqqFLWudksr2TbdKlUa+kW9kbBLbAiEA0PhEPPRyZFZdm8dX2M+VU8N78EkRIF+qq/MrZma+LS4qtAMIYhADGgwwNTkwMDM1NDY4NjUiDI+mxJgSmfyoAzLf8CqRA5jk/e+vnwOhG6oNrVnYPNYUahkFedQiraRdEdWL8Y1/Mcp3n/78kmcuBNWNaKwttN7qCpKXUWHlyl/cHatFc9uO6ASzzZ3cWSk5PgRg/32/VpQwqknXaOOOQy/t38qzCSkl2Pxnb2LOtGS4HZApRetHTIVuUGWoGA9WIy/ua2HEiUB+Flk1anVw9VOIE/JkkS7Ta/jujPLSAplPHo8YZfjK0cQ6iivDHtPrUpnalGhVza1OmhEKeLNilDmG9DZP/W5KfEpx3znpTaj0pP1uppHpP3Q6R+ECURoweAEfgbV/E2z0lFWQL9tkJtW+HOCqcoPxeTpmHqowV48dbI9CSDpldhiJsya6bJ/Sr9F7tuR22ZQOCNcmDBPHFT5rCUMdTKt9Jv49Z/4m27+fd/a2fY4vWtFv7g9bzYXSungpDNJbVozNLZPwR+i7t30ZTamCTzRweYoWbGsDgoKAzjBqlDVzJqL4kcUdVH6FqWz0z3G8smuSQGbzTNoalMQSASAHI99FvhnOqwQ6T67c3Ah1STKRMKaInvsFOusB5KfCoxZHyf9g2eqdY4+yWmaMOkGvYSHajRXp6gARqmp4xZaQ+gOiAgz057HrJ0GvPHPebTXWg8j3BXdkyeuGyw+Nm5UxT7A6Tf6OMZWEvDA+9DFjNiPYDaIUFSPNEQbVmY9l99FCTOdBcMGORqtKdtCv8IXFZp1zLEpKqU4uyagLZ0w3GvGXgGPKsFD/oRxT6DNLyntSoBnTv4kOk/eH540ZNUAH/Hzr5GAC+jfE8c2YlKL0t0q/aO6eXiyT4ttmKiJsuqHZw24019KbH/QkS5al0B3UWqiuy9U9OQRchISovRaQpKQ0IltOMA==&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Date=20200920T175956Z&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Expires=300&amp;X-Amz-Credential=ASIAQ3PHCVTY5GNJTVNN/20200920/us-east-1/s3/aws4_request&amp;X-Amz-Signature=9d0ad3f8f3df53985edd301e94c6c9f150d539190c7511f1bca02dac896b528d&amp;hash=77222c7c6d6bafa8ea5f37880b047d82f5134bf75835597008a0ed7650bdcd0b&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S1877042815038082&amp;tid=spdf-6bde122d-437c-4067-98d5-93f97e712e15&amp;sid=3344830398c1c441a209a100fe896d4ba43dgxrqb&amp;type=client">direct feedback</a>, where communication is open and in the form of emails, phone conversations, face-to-face meetings, or any medium that discloses people’s identity, anonymous feedback is simply the opposite. As the name implies, people share feedback to teammates or other organizational members while protecting their identities.</p><h3 id="pros-of-anonymous-feedback">Pros of Anonymous Feedback</h3><ul><li><strong>It provides the truth and protects the vulnerable:</strong> On topics that are considered sensitive, you’ll often find employees who are afraid to share their opinions. But when employees have the option to use anonymous feedback, you will be offering a safe space for them to share their insights and truths about sensitive workplace issues, without fear of victimization. Also, employers benefit from anonymous feedback because they can receive honest and diverse perspectives on critical issues, and they can quickly address those issues before they escalate.‌‌</li><li><strong>It allows every voice to be heard and respected:</strong> In workplaces, where they practice direct or attributed feedback, leaders may give preference to some voices over others. Due to our unconscious biases, people of higher authority, backgrounds, or eloquence tend to command respect and attention. In such situations, the issues they raise are likely to get immediate attention than those raised by the rest of the group. However, when feedback is collected anonymously, it eliminates biases and allows leaders to focus entirely on the feedback.‌‌</li><li><strong>It encourages new employees to share their opinions:</strong> <a href="https://journals.sagepub.com/doi/pdf/10.1177/0893318905279191">Research</a> has shown that new employees, who happen to be less senior or influential, see anonymous feedback as more appropriate for formal and informal evaluations than their older colleagues. Typically, the last thing a new employee wants is to start on the wrong foot. During my check-in sessions with new employees to discuss their experiences, most of them often took a neutral stance. So, using anonymous feedback can make new employees feel more comfortable sharing their real opinions on workplace issues.‌‌</li></ul><h3 id="cons-of-anonymous-feedback">Cons of Anonymous Feedback</h3><ul><li><strong>It can breed hostility: </strong>Many people kick against anonymous feedback because it can create hostility. According to this Harvard Business Review<strong> </strong><a href="https://hbr.org/2016/01/can-your-employees-really-speak-freely">article</a>, anonymity often sets off a “witch hunt,” where leaders seek to know the source of a negative comment. On the one hand, employees can hide behind anonymity to say personal and hurtful things about their colleagues or leaders. On the other hand, leaders may take constructive feedback as a personal attack and become suspicious and hostile to all their employees.‌‌</li><li><strong>It can be less impactful than attributed feedback:</strong> When using attributed feedback where responses carry the employees’ names, information can be analyzed for relevance and impact. However, with anonymous feedback, it can be difficult to analyze information accurately. It is not uncommon for companies who choose to practice anonymous feedback, to find <a href="https://www.forbes.com/sites/groupthink/2017/09/21/6-ways-anonymous-feedback-robs-your-team-blind-and-what-to-do-about-it/#7fc211a05ffd">less specific responses since details may reveal respondents’ identities</a>. Vague feedback from employees would have less power to influence behaviors or drive change in the organization.‌‌</li><li><strong>It can be difficult to act on:</strong> Anonymity defeats the purpose of feedback, which is to <a href="https://www.forbes.com/sites/forbescommunicationscouncil/2018/08/01/the-importance-of-the-employee-feedback-loop/#564d64e02026">create a reciprocal relationship</a> and an opportunity to work toward improvement. Since anonymous feedback is often difficult to trace, it can be challenging for the organization to get context or follow up on important issues, especially when a problem is peculiar to an individual. ‌‌</li></ul><figure><img src="https://better-feedback-image-assets.storage.googleapis.com/2020/11/64627.jpg" alt=""></figure><h3 id="anonymous-feedback-training-wheels">Anonymous Feedback: Training Wheels</h3><p>Ideally, everyone in your company should be able to give feedback publicly and not anonymously. They should share constructive criticism and not shy away from direct feedback if they believe and trust that their opinions will be heard and addressed.</p><p>However, it takes time to build trust. It’s no different than trusting to balance yourself on two wheels—you move slowly and incrementally. Anonymous feedback gives employees the training wheels to build that trust. They can use anonymous feedback to practice their feedback-giving skills, test the waters, and understand how people perceive their constructive (and sometimes critical) opinions. Is their feedback being ignored? Is management reacting emotionally to critical opinions?</p><p>Anonymous feedback allows people to develop trust and share their honest opinions and thoughts about company policies and processes, without fear of repercussions.</p><h3 id="how-to-request-for-anonymous-feedback">How to Request for Anonymous Feedback</h3><p>Traditionally, many organizations have collected anonymous feedback through suggestion boxes or ombudsmen. However, in recent times, technology platforms have created great channels for collecting feedback.</p><p>For example, <a href="http://inkrement.io/">Inkrement</a>, a feedback tool built for Slack, allows your team to request and deliver timely feedback effortlessly. Inkrement ensures that all voices are heard and empowers your team to give critical feedback directly or anonymously, without fear.</p><p>On a smaller scale, a manager can request anonymous feedback from peers or teammates in the form of feedback requests. You can ask thematic questions that ensure anonymity. The feedback you receive can inform your team’s discussions and determine training needs, team building, or performance improvement activities.</p><p>When requesting for anonymous feedback on an organizational level, it is necessary to:</p><ol><li><strong>Set expectations for employees:</strong> Let employees know how important their feedback is to the organization. Also, assure them that their responses will be non-identifiable (no identifiable names, titles, or other demographic details). According to a <a href="https://hbr.org/2002/02/getting-the-truth-into-workplace-surveys">Harvard Business Review</a> article, “respondents are much more likely to participate if they are confident that personal anonymity is guaranteed.” Set those expectations to increase the chances of response from employees. &nbsp;‌‌</li><li><strong><strong><strong>Provide Training: </strong></strong></strong>As referenced in our <a href="https://inkrement.io/blog/how-to-give-feedback/">Feedback Best Practices</a>, it’s important to train employees on how, when, where, and whom to give feedback. They need to keep their feedback objective and focused on the Situation, Behavior, Impact best practices. ‌‌</li><li><strong>Deploy a feedback platform: </strong>Use a trusted feedback platform to send feedback requests to employees. For example, when employees submit feedback requests through <a href="https://inkrement.io/">Inkrement</a>, the system protects and encrypts all personal information, both at rest and in transit, through secure connections to ensure anonymity. &nbsp;‌‌</li></ol><figure><img src="https://better-feedback-image-assets.storage.googleapis.com/2020/11/5236.jpg" alt=""><figcaption>Using feedback to grow incrementally</figcaption></figure><h3 id="how-to-act-on-anonymous-feedback">How to …</h3></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://inkrement.io/blog/diversity-inclusion-and-anonymous-feedback/">https://inkrement.io/blog/diversity-inclusion-and-anonymous-feedback/</a></em></p>]]>
            </description>
            <link>https://inkrement.io/blog/diversity-inclusion-and-anonymous-feedback/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051908</guid>
            <pubDate>Tue, 10 Nov 2020 21:06:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust as a productive high-level language]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051897">thread link</a>) | @csomar
<br/>
November 10, 2020 | https://omarabid.com/rust-high-level-language | <a href="https://web.archive.org/web/*/https://omarabid.com/rust-high-level-language">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="container">
  <article id="wBiL7EUi4Kw16ahNjk6hmU">
	<time datetime="2020-11-10">November 10, 2020</time>
  
	<p>Rust is often critiqued as a <a href="https://news.ycombinator.com/item?id=24536645">not a very productive</a> programming language. It is true that there is a bit of a learning curve to be able to program in Rust; but beyond that, I think it pays off in productivity; and massively I must say.</p>

<p>I haven’t been using Rust for production much; maybe a bit more than a year. The static type checks means I’m getting much less bugs in my code, and spend considerably less time in debugging. I can safely say that, for me, Rust is more productive than JavaScript, PHP or Python and the margin keeps getting larger as I get more acquainted with the ecosystem.</p>

<hr>

<p>To entice your interest, here is a situation that I handled lately: I have a program that writes logs to <a href="https://en.wikipedia.org/wiki/Syslog">syslog</a> and the terminal. The program compiles and functions correctly on my development machine. However, it returned an error when I deployed it to an <a href="https://alpinelinux.org/">Alpine</a> Docker container. Turns out, Alpine doesn’t have a running syslog service by default.</p>

<p>Now that’s fine, the program functioned correctly. But I don’t care much for syslog on deployment since the program is running inside a container. One solution is to remove the syslog <a href="https://en.wikipedia.org/wiki/Sink_(computing)">drain</a> but I need that for development. I can use <a href="https://doc.rust-lang.org/reference/conditional-compilation.html">conditional compilation</a>; but there is a better option: If syslog fails, for whatever reason, just ignore that and move on.</p>

<p>So let’s take a look at the old code. </p>

<pre><code>    let syslog_drain = syslog_drain()?;
    let term_drain = term_drain()?;
</code></pre>

<p>This code creates two logging drains: one for syslog and one for the terminal. It uses the <a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html">? operator</a> to evaluate the result. If the function returns an error, execution will stop and the error bubbles back to the top of the program.</p>

<p>I have no idea how the syslog or any particular drain fails. And honestly, I don’t want to get into these details. What I want is to check if there is a failure; and if so ignore that particular drain. Or return a <a href="https://docs.rs/slog/2.5.2/slog/struct.Discard.html">Discard drain</a>.</p>

<p>The <a href="https://doc.rust-lang.org/std/result/">Result</a> type and <code>? operator</code> make this particularly easy. So here is the code that does that.</p>

<pre><code>    let syslog_drain = syslog_drain().unwrap_or(discard_drain()?);
    let term_drain = term_drain().unwrap_or(discard_drain()?);
</code></pre>

<p>And that’s it. This code now compiles and runs correctly. If syslog is running, it’ll write logs to syslog and the terminal. Otherwise, it’ll write logs to the terminal and syslog is skipped. There are no conditions, no complicated checks and it’s perfectly readable.</p>

<hr>

<p>There is more to Rust productivity than that. Macros, Iterators, Advanced Traits and Types, the new Async system. Once you are comfortable with all of these, you are now able to be productive, safe and fast.</p>

  <figure id="kudo_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>113</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>113</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]>
            </description>
            <link>https://omarabid.com/rust-high-level-language</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051897</guid>
            <pubDate>Tue, 10 Nov 2020 21:04:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Messenger App Tutorial with Phoenix LiveView]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051678">thread link</a>) | @szsoppa
<br/>
November 10, 2020 | https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1 | <a href="https://web.archive.org/web/*/https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In a series of articles <strong>(don't forget to <a href="#c-newsletter" target="_blank">subscribe to our newsletter</a>!)</strong>, we'll convince you that Phoenix LiveView will revolutionize the way you create reactive UIs!</p>
<h2>Why Phoenix?</h2>
<p>The thing about Elixir, on top of Erlang/OTP, is that it offers a great mix of making life easy and being a scalable and reliable platform that will not let you down when your estimated traffic of 4000 users becomes 4,000,000 users.</p>
<p><strong>Phoenix Framework</strong> is Elixir's answer to the never-ending question of how to build rich web applications, and it's got a lot of tools that make the job easy - one of the latest being <strong>Phoenix LiveView</strong>.</p>
<p>Long story short, <strong>LiveView is a tool that lets an Elixir developer create reactive UIs without writing a single line of JS code</strong>. Which is great, given that many Elixir developers do not exactly consider themselves fluent at JS, or - just like myself - are not exactly in love with JS.</p>
<h2>Lessons learnt from reactive UI libraries</h2>
<p>Many JavaScript frameworks, both contemporary and not-so-contemporary ones, rely on manipulating the page's DOM for dynamic content updates.</p>
<p>Historically, for instance, developers using BackboneJS would define a <code>Backbone.View</code> to represent an <em>atomic chunk of user interface</em>, behind which there's a <code>Backbone.Model</code>, encapsulating the business logic of data.</p>
<p>Backbone remained unopinionated about how views were to be rendered, so it had no built-in tools to make the re-rendering of views on model changes efficient - the whole structure of a view had to be built from scratch and replaced, which tended to yield inefficient views.</p>
<p>In contrast, modern frameworks such as ReactJS or Vue.js don't care about how the data model layer works at all (loosely coupled data stores such as Redux are often used for this) - but they have a <strong>virtual DOM</strong> concept - long story short, a pattern of incrementally upgrading only those elements that need to be changed, based on changes in the state of particular components and their children.</p>
<p><strong>The challenge, though, is pretty much down to how to exchange data between the UI and the backend.</strong> You will usually need to implement a JSON API or a GraphQL service, or perhaps you could develop a WebSocket-based solution using Phoenix Channels.</p>
<p>Either way, the <a href="https://en.wikipedia.org/wiki/Pareto_principle" target="_blank">Pareto 80/20 principle</a> will imminently catch you, and when you get to the 20% of work needed to finish off your message-passing code, it'll soon become a <em>framework within a framework</em>.</p>
<h2>Why, where &amp; how LiveView excels</h2>
<p>Phoenix LiveView's concept is both groundbreaking and familiar, in different ways.</p>
<p>It is familiar in that it lets you define UI elements as nestable components composed of pure HTML markup, and it builds upon the experience of reactive UI frameworks in implementing mechanisms that calculate diffs between consecutive UI states to ensure efficient updates.</p>
<p>It is groundbreaking in the way it maintains the states of components and manages their updates - <strong>in Phoenix LiveView, components are stateful on the server, and their events and updates are communicated via a bidirectional WebSocket connection</strong>.</p>
<p><strong>Phoenix LiveView is built on top of Elixir processes and Phoenix Channels</strong> - every LiveView instance is a BEAM process, acting very much like a <a href="https://hexdocs.pm/elixir/GenServer.html" target="_blank">GenServer</a>, receiving messages and updating its state.</p>
<p>While modern JS frameworks such as React have server-side rendering capabilities, it is usually not convenient to do this in a non-NodeJS backend server. Rendering content via JavaScript often results in SEO issues, and some trickery is needed for search engines to index the page correctly. <strong>In Phoenix LiveView, the initial render is static as in the classic HTML request-response cycle</strong>, so you'll get good <a href="https://developers.google.com/web/tools/lighthouse" target="_blank">Lighthouse scores</a> and it won't hurt your SEO.</p>
<p>Erlang easily maintains thousands of processes concurrently, and Phoenix authors have even <a href="https://phoenixframework.org/blog/the-road-to-2-million-websocket-connections" target="_blank">managed to make it handle 2 million WebSocket connections</a> on a single (albeit pretty strong) machine. With the server using Elixir's strengths to manage LiveView states, <strong>the client-side logic can be thin and simple</strong>.</p>
<p>In fact, as stated in the introduction, <strong>in most LiveView-powered apps you won't write a single line of JS code</strong>. In many cases, when interacting with an element whose update is supposed to fetch data for a new UI state from the server, the workflow using a reactive JS framework would be:</p>
<ol>
<li>Handle the element's <code>change</code> event
</li>
<li>Send a request to the server containing the actual changes
</li>
<li>Receive response and update state store based on response data
</li>
<li>Let the view layer re-render the changed DOM elements
</li>
</ol>
<p>This involves annotating HTML elements so that they can be identified by JS code, writing browser-side scripts to handle the element's state change event, send a payload to the server, which processes the request as part of a Phoenix controller action.</p>
<p><strong>With Phoenix LiveView, you only write HTML and Elixir code, with the JS part being handled by a script bundled with the LiveView package.</strong></p>
<h2>Phoenix LiveView basic usage</h2>
<p>The basic idea behind Phoenix LiveView is very simple and straightforward. <strong>Be sure to <a href="#c-newsletter" target="_blank">subscribe to our newsletter</a> to learn more!</strong></p>
<p>LiveView is an Elixir behaviour, and your most basic LiveView definition will consist of two callback implementations:</p>
<ul>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:render/1" target="_blank"><code>render/1</code></a> function, containing the template of how your component is represented in HTML, with elements of the component's state interpolated. This is much like defining an ordinary view. The special <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#sigil_L/2" target="_blank"><code>~L</code> sigil</a> is used to interpolate <code>assigns</code> into your EEx syntax, and convert it into an HTML-safe structure.
</li>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:mount/2" target="_blank"><code>mount/2</code></a> function, wiring up socket assigns and establishing the LiveView's initial state.
</li>
</ul>
<pre><code>  <span><span>defmodule</span> <span>YourappWeb.CounterLive</span></span> <span>do</span>
    <span>use</span> Phoenix.LiveView

    <span><span>def</span> <span>render</span></span>(assigns) <span>do</span>
      ~L<span>""</span><span>"
      &lt;a href='#' phx-click='increment'&gt;
        I was clicked &lt;%= @counter %&gt; times!
      &lt;/a&gt;
      "</span><span>""</span>
    <span>end</span>

    <span><span>def</span> <span>mount</span></span>(params, socket) <span>do</span>
      {<span>:ok</span>, assign(socket, <span>:counter</span>, <span>0</span>)}
    <span>end</span>
  <span>end</span></code></pre>
<p>However, the whole fun of using LiveView is managing its state, and the next two callbacks will come in handy.</p>
<ul>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:handle_event/3" target="_blank"><code>handle_event/3</code></a> function, handling events coming <strong>from the browser</strong>. Noticed the <code>phx-click</code> attribute in our template's link? This is the name of an event that will be transported to the LiveView process via WebSockets. We'll define a function clause that will match to the event's name.
</li>
</ul>
<pre><code>  <span><span>def</span> <span>handle_event</span></span>(<span>"increment"</span>, params, %{<span>assigns:</span> %{<span>counter:</span> counter}} = socket) <span>do</span>
    {<span>:noreply</span>, assign(socket, <span>:counter</span>, counter + <span>1</span>)}
  <span>end</span></code></pre>
<p>  It will mutate the LiveView's state to have a new, incremented value of the counter, and the <code>render/1</code> function will be called with the new assigns.</p>
<p>  The second argument, here named <code>params</code>, is of special interest as well, because - in the case of a <code>phx-click</code> event - it contains the event's metadata:</p>
<pre><code>  %{
    <span>"altKey"</span> =&gt; <span>false</span>,
    <span>"ctrlKey"</span> =&gt; <span>false</span>,
    <span>"metaKey"</span> =&gt; <span>false</span>,
    <span>"pageX"</span> =&gt; <span>399</span>,
    <span>"pageY"</span> =&gt; <span>197</span>,
    <span>"screenX"</span> =&gt; <span>399</span>,
    <span>"screenY"</span> =&gt; <span>558</span>,
    <span>"shiftKey"</span> =&gt; <span>false</span>,
    <span>"x"</span> =&gt; <span>399</span>,
    <span>"y"</span> =&gt; <span>197</span>
  }</code></pre>
<p>  We trust that you won't now hesitate to try it out with a <code>&lt;form&gt;</code> tag and a <code>phx-change</code> attribute to see what event metadata are passed when a form element's value is changed. Either way, <strong>we'll explore this in more detail in later episodes of this tutorial - stay tuned and <a href="#c-newsletter" target="_blank">subscribe to our newsletter</a> so that you don't miss out</strong>!</p>
<ul>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:handle_info/2" target="_blank"><code>handle_info/2</code></a> callback, handling events coming from <strong>anywhere but the browser</strong>. This means events sent from external sources <em>(remember a LiveView is just an Elixir process, so you can do whatever's needed in order for it to receive messages!)</em>, or events sent from the LiveView to itself. For instance, it takes this to increment the counter every 5 seconds:
</li>
</ul>
<pre><code>  <span><span>def</span> <span>mount</span></span>(params, socket) <span>do</span>
    if connected?(socket), <span>do:</span> <span>:timer</span>.send_interval(<span>5000</span>, <span>self</span>(), <span>:increment</span>)

    {<span>:ok</span>, assign(socket, <span>:counter</span>, <span>0</span>)}
  <span>end</span>

  <span><span>def</span> <span>handle_info</span></span>(<span>:increment</span>, %{<span>assigns:</span> %{<span>counter:</span> counter}} = socket) <span>do</span>
    {<span>:noreply</span>, socket |&gt; assign(<span>:counter</span>, counter + <span>1</span>)}
  <span>end</span></code></pre>
<p>  To reduce code repetition, you could make <code>handle_event/3</code> send a message to <code>self()</code> that triggers the same <code>handle_info/2</code> routine.</p>
<p>You can now access your LiveView as a standalone route - to do this, put this in your <code>router.ex</code>:</p>
<pre><code><span>import</span> Phoenix.LiveView.Router

scope <span>"/"</span>, YourappWeb <span>do</span>
 live <span>"/counter"</span>, CounterLive
<span>end</span></code></pre>
<p>...or render the LiveView within any other template:</p>
<pre><code>&lt;%= Phoenix.LiveView.live_render(<span>@conn</span>, YourappWeb.CounterLive) %&gt;</code></pre>
<h2>The Curious Messenger Roadmap<a name="series" target="_blank"></a></h2>
<p>We'll make you familiar with how to wield the Phoenix LiveView sword, and you'll build a fully-fledged Messenger replacement, which will make you (almost) forget about any other instant messaging app you had ever used before...</p>
<p>Phoenix LiveView is obviously only part of the story, and there's a lot more ground that we'll cover. We'll do a few episodes, each of which touches a different set of concerns that we'll have to consider when designing the app.</p>
<ul>
<li><a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-2" target="_blank">At the beginning, we'll bootstrap the app and install all needed dependencies, design the app's database and context structure, with all of the app's business logic in mind.</a>
</li>
<li><a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-3" target="_blank">Then we'll implement the app's user authentication feature using Pow, a great library integrating all the tools you need to let users sign up and log into the application. Next, we'll go on to implement the actual awesome Curious Messenger features, and here's where most of the <strong>Phoenix LiveView</strong> magic will shine. We'll show you how to create a live-updated view of your contact list and of each of your conversations.</a>
</li>
<li><a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-4" target="_blank">Obviously, we'll also elaborate on what can go wrong when using LiveView, because the worst assumption one can make is that people's network connections are perfect. We'll see for ourselves that Phoenix LiveView is not the Holy Grail of reactive UI building solutions and that this approach has several shortcomings that need to be kept in mind.</a>
</li>
<li>Finally, we'll fine-tune the Curious Messenger app, adding some customizable settings and push notifications <em>(did we actually say there'll be no JS? We lied.)</em> so that you never miss out on any message from …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1">https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1</a></em></p>]]>
            </description>
            <link>https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051678</guid>
            <pubDate>Tue, 10 Nov 2020 20:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anatomy of OpenSSH Key Revocation List (KRL) File]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051381">thread link</a>) | @dbsentry
<br/>
November 10, 2020 | https://keyper.dbsentry.com/post/anatomy-of-openssh-krl/ | <a href="https://web.archive.org/web/*/https://keyper.dbsentry.com/post/anatomy-of-openssh-krl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="introduction">Introduction</h2><p>When I started working on the SSH Certificate feature for Keyper, the question of certificate revocation and its verification came up. I searched but could not find a lightweight python library for this (aim is to keep the docker image smaller than 100MB). As a first iteration, I implemented this using Python subprocess and <code>ssh-keygen</code>. <code>ssh-keygen</code> is an awesome utility and considered a Swiss Army Knife for SSH Keys. The same utility helps you when you are either setting up a certificate authority (CA) or OpenSSH Key Revocation List (KRL) file.</p><h2 id="krl-basics">KRL Basics</h2><p>A KRL can be created using <code>ssh-keygen</code>:</p><pre><code>[manish@getafix sshca]$ ssh-keygen -k -f ca_krl

[manish@getafix sshca]$ ls -l
total 4
-rw-r--r-- 1 manish manish 44 Nov  5 11:09 ca_krl
[manish@getafix sshca]$
</code></pre><p>A Key or a Certificate is revoked by adding them to the KRL using <code>ssh-keygen</code>:</p><pre><code>[manish@getafix sshca]$ ls -l
total 12
-rw-r--r-- 1 manish manish   44 Nov  5 11:09 ca_krl
-rw-r--r-- 1 manish manish 2009 Nov  5 11:13 id_rsa-cert.pub
-rw-r--r-- 1 manish manish  568 Nov  5 11:13 id_rsa.pub

[manish@getafix sshca]$ ssh-keygen -k -u -f ca_krl id_rsa.pub
Revoking from id_rsa.pub

[manish@getafix sshca]$ ssh-keygen -k -u -f ca_krl id_rsa-cert.pub
Revoking from id_rsa-cert.pub
[manish@getafix sshca]$ 
</code></pre><p>A Key or a Certificate revocation can be checked using <code>ssh-keygen</code>. The output is as follows when the Key/Certificate is not in the KRL:</p><pre><code>[manish@getafix sshca]$ ssh-keygen -Q -f ca_krl id_rsa.pub
id_rsa.pub (manish@getafix): ok

[manish@getafix sshca]$ ssh-keygen -Q -f ca_krl id_rsa-cert.pub
id_rsa-cert.pub (manish@getafix): ok
[manish@getafix sshca]$ 
</code></pre><p>And, as follows when Key/Certificate is in the KRL:</p><pre><code>[manish@getafix sshca]$ ssh-keygen -Q -f ca_krl id_rsa.pub
id_rsa.pub (manish@getafix): REVOKED

[manish@getafix sshca]$ ssh-keygen -Q -f ca_krl id_rsa-cert.pub
id_rsa-cert.pub (manish@getafix): REVOKED
[manish@getafix sshca]$ 
</code></pre><h2 id="ssh-keygen-limitation">ssh-keygen limitation</h2><p>Although <code>ssh-keygen</code> can revoke keys or certificates using their fingerprint or serial number, it needs full Key or the Certificate for the KRL verification. As a result, when using Keyper, each SSH server needs to be configured to send Public Key or the Certificate (configured using <code>%k</code> and <code>%t</code> in the <code>sshd_config</code> file). There is always an option to periodically copy the KRL file to each SSH server so that it performs local KRL lookup. I was not happy with sending the full Key or the Certificate as part of the API call during each authentication. But could neither find a way to perform KRL lookup using fingerprint or serial number using <code>ssh-keygen</code> nor find a lightweight Python library for it. So, I decided to write a KRL lookup myself in python. This post is about what I learned while doing this.</p><p><code>man ssh-keygen</code> defines OpenSSH format Key Revocation Lists (KRLs) as “binary files specify keys or certificates to be revoked using a compact format, taking as little as one bit per certificate if they are being revoked by serial number.”</p><h2 id="krl-anatomy">KRL Anatomy</h2><p>To understand its internal structure I started with the OpenSSH source code. File <code>krl.c</code> has the following relvant definition:</p><pre><code>/*
 * Trees of revoked serial numbers, key IDs and keys. This allows
 * quick searching, querying and producing lists in canonical order.
 */

/* Tree of serial numbers. XXX make smarter: really need a real sparse bitmap */
struct revoked_serial {
        u_int64_t lo, hi;
        RB_ENTRY(revoked_serial) tree_entry;
};
static int serial_cmp(struct revoked_serial *a, struct revoked_serial *b);
RB_HEAD(revoked_serial_tree, revoked_serial);
RB_GENERATE_STATIC(revoked_serial_tree, revoked_serial, tree_entry, serial_cmp);

/* Tree of key IDs */
struct revoked_key_id {
        char *key_id;
        RB_ENTRY(revoked_key_id) tree_entry;
};
static int key_id_cmp(struct revoked_key_id *a, struct revoked_key_id *b);
RB_HEAD(revoked_key_id_tree, revoked_key_id);
RB_GENERATE_STATIC(revoked_key_id_tree, revoked_key_id, tree_entry, key_id_cmp);

/* Tree of blobs (used for keys and fingerprints) */
struct revoked_blob {
        u_char *blob;
        size_t len;
        RB_ENTRY(revoked_blob) tree_entry;
};
static int blob_cmp(struct revoked_blob *a, struct revoked_blob *b);
RB_HEAD(revoked_blob_tree, revoked_blob);
RB_GENERATE_STATIC(revoked_blob_tree, revoked_blob, tree_entry, blob_cmp);

/* Tracks revoked certs for a single CA */
struct revoked_certs {
        struct sshkey *ca_key;
        struct revoked_serial_tree revoked_serials;
        struct revoked_key_id_tree revoked_key_ids;
        TAILQ_ENTRY(revoked_certs) entry;
};
TAILQ_HEAD(revoked_certs_list, revoked_certs);

struct ssh_krl {
        u_int64_t krl_version;
        u_int64_t generated_date;
        u_int64_t flags;
        char *comment;
        struct revoked_blob_tree revoked_keys;
        struct revoked_blob_tree revoked_sha1s;
        struct revoked_blob_tree revoked_sha256s;
        struct revoked_certs_list revoked_certs;
};
</code></pre><p>I started with <code>struct ssh_krl</code> and after spending a couple of hours trying to read and understand the OpenSSH code, my eyes were glazing. So, I went back back to the internet search to see if anyone has already figured this out. I found this
<a href="https://github.com/openssh/openssh-portable/blob/master/PROTOCOL.krl" target="_blank" rel="noopener">page</a>.</p><h2 id="krl-file-format">KRL File Format</h2><pre><code>This describes the key/certificate revocation list format for OpenSSH.

1. Overall format

The KRL consists of a header and zero or more sections. The header is:

#define KRL_MAGIC		0x5353484b524c0a00ULL  /* "SSHKRL\n\0" */
#define KRL_FORMAT_VERSION	1

	uint64	KRL_MAGIC
	uint32	KRL_FORMAT_VERSION
	uint64	krl_version
	uint64	generated_date
	uint64	flags
	string	reserved
	string	comment

Where "krl_version" is a version number that increases each time the KRL
is modified, "generated_date" is the time in seconds since 1970-01-01
00:00:00 UTC that the KRL was generated, "comment" is an optional comment
and "reserved" an extension field whose contents are currently ignored.
No "flags" are currently defined.

Following the header are zero or more sections, each consisting of:

	byte	section_type
	string	section_data

Where "section_type" indicates the type of the "section_data". An exception
to this is the KRL_SECTION_SIGNATURE section, that has a slightly different
format (see below).

The available section types are:

#define KRL_SECTION_CERTIFICATES		1
#define KRL_SECTION_EXPLICIT_KEY		2
#define KRL_SECTION_FINGERPRINT_SHA1		3
#define KRL_SECTION_SIGNATURE			4
#define KRL_SECTION_FINGERPRINT_SHA256		5

2. Certificate section

These sections use type KRL_SECTION_CERTIFICATES to revoke certificates by
serial number or key ID. The consist of the CA key that issued the
certificates to be revoked and a reserved field whose contents is currently
ignored.

	string ca_key
	string reserved

Where "ca_key" is the standard SSH wire serialisation of the CA's
public key. Alternately, "ca_key" may be an empty string to indicate
the certificate section applies to all CAs (this is most useful when
revoking key IDs).

Followed by one or more sections:

	byte	cert_section_type
	string	cert_section_data

The certificate section types are:

#define KRL_SECTION_CERT_SERIAL_LIST	0x20
#define KRL_SECTION_CERT_SERIAL_RANGE	0x21
#define KRL_SECTION_CERT_SERIAL_BITMAP	0x22
#define KRL_SECTION_CERT_KEY_ID		0x23

2.1 Certificate serial list section

This section is identified as KRL_SECTION_CERT_SERIAL_LIST. It revokes
certificates by listing their serial numbers. The cert_section_data in this
case contains:

	uint64	revoked_cert_serial
	uint64	...

This section may appear multiple times.

2.2. Certificate serial range section

These sections use type KRL_SECTION_CERT_SERIAL_RANGE and hold
a range of serial numbers of certificates:

	uint64	serial_min
	uint64	serial_max

All certificates in the range serial_min &lt;= serial &lt;= serial_max are
revoked.

This section may appear multiple times.

2.3. Certificate serial bitmap section

Bitmap sections use type KRL_SECTION_CERT_SERIAL_BITMAP and revoke keys
by listing their serial number in a bitmap.

	uint64	serial_offset
	mpint	revoked_keys_bitmap

A bit set at index N in the bitmap corresponds to revocation of a keys with
serial number (serial_offset + N).

This section may appear multiple times.

2.4. Revoked key ID sections

KRL_SECTION_CERT_KEY_ID sections revoke particular certificate "key
ID" strings. This may be useful in revoking all certificates
associated with a particular identity, e.g. a host or a user.

	string	key_id[0]
	...

This section must contain at least one "key_id". This section may appear
multiple times.

3. Explicit key sections

These sections, identified as KRL_SECTION_EXPLICIT_KEY, revoke keys
(not certificates). They are less space efficient than serial numbers,
but are able to revoke plain keys.

	string	public_key_blob[0]
	....

This section must contain at least one "public_key_blob". The blob
must be a raw key (i.e. not a certificate).

This section may appear multiple times.

4. SHA1/SHA256 fingerprint sections

These sections, identified as KRL_SECTION_FINGERPRINT_SHA1 and
KRL_SECTION_FINGERPRINT_SHA256, revoke plain keys (i.e. not
certificates) by listing their hashes:

	string	public_key_hash[0]
	....

This section must contain at least one "public_key_hash". The hash blob
is obtained by taking the SHA1 or SHA256 hash of the public key blob.
Hashes in this section must appear in numeric order, treating each hash
as a big-endian integer.

This section may appear multiple times.
...
</code></pre><h2 id="krl-internals-in-action">KRL Internals in action</h2><p>The above clarified a lot. However, I still wasn’t clear about how would a parser figure the length of any string in the KRL file? (for e.g. <code>string section_data</code>) I decided to start looking into the KRL file itself. I started with a freshly generated KRL file.</p><pre><code>[manish@getafix sshca]$ ssh-keygen -k -f ca_krl

[manish@getafix sshca]$ hexdump -C ca_krl
00000000  53 53 48 4b 52 4c 0a 00  00 00 00 01 00 00 00 00  |SSHKRL..........|
00000010  00 00 00 00 00 00 00 00  5f a4 36 97 00 00 00 00  |........_.6.....|
00000020  00 00 00 00 00 00 00 00  00 00 00 00              |............|
0000002c</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://keyper.dbsentry.com/post/anatomy-of-openssh-krl/">https://keyper.dbsentry.com/post/anatomy-of-openssh-krl/</a></em></p>]]>
            </description>
            <link>https://keyper.dbsentry.com/post/anatomy-of-openssh-krl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051381</guid>
            <pubDate>Tue, 10 Nov 2020 20:23:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Flaws of “Subscription Fatigue”, “SVOD Fatigue”, and the “Streaming Wars”]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25051292">thread link</a>) | @bschne
<br/>
November 10, 2020 | https://www.matthewball.vc/all/misnomers | <a href="https://web.archive.org/web/*/https://www.matthewball.vc/all/misnomers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-96dbb3b03808a860d80e"><div><p>When we consider the state of tech-media in 2020, there are a few common narratives. The most inescapable is the “Streaming Wars”. In November, I argued that <a href="https://www.matthewball.vc/all/minedmedia">this term was a misnomer</a>. Digital/streaming/OTT video is really just <em>a</em> battle in a much larger war: the “ecosystem war”. And for the most part, this war is fought asymmetrically. Apple and Amazon both sell digital media devices, third-party media content, and their own original content, for example. However, Apple isn’t an e-retailer nor a diversified enterprise cloud services provider, and Amazon doesn’t even have a smartphone, personal computer, watch or non-video app store. I’ll come back to this idea, but understanding the differences between these companies and their motivations is helpful when considering two other popular phases that are unhelpful at best and misleading at worst: “subscription fatigue” and “SVOD fatigue”.</p><p><strong>“Subscription Fatigue”</strong></p><p>The “subscription economy”, by definition, presumes that the overall “economy” – from products, to services, content, transportation, labor and more – is shifting over to “subscriptions”. Thus, to claim that consumers have “subscription fatigue” is to say that they have “spending fatigue”.</p><p>As always, most consumers will say they wish they spent less money, bought fewer things, and enjoyed lower prices. However, it makes little sense to say that the decision to buy TV subscriptions, radio subscriptions, toothbrush subscriptions, video gaming subscriptions, dog food subscriptions, car subscriptions, or productivity software subscriptions should drive “subscription fatigue” or mean each subscription competes with one another. For decades, consumers have bought TV, music, toothbrushes, video games, dog food, cars and Microsoft Office. What’s new is that they all have similar models – digitally-based, predominantly D2C subscriptions. This changes nothing about the individual value or baseline need for them.</p><p>Of course, the “subscription economy” does mean that step one of a recession will be to “re-evaluate all subscriptions”. However, this does not mean subscription <em>fatigue</em> should be considered a real “thing”, let alone a defining element of modern-day competition. Furthermore, payment model – upfront v. recurring, subscription v. á la carte, online v. offline – is irrelevant to what’s “re-evaluated” and not. Some subscriptions are “necessities”, like toilet paper, while others are concerned with discretionary spend, such as Office 365 or Netflix or Tinder. This latter group isn’t competitive because they’re “subscriptions”, but because there is, as always, finite spending money for non-essential items. </p><p>To this end, it’s important to highlight subscriptions are often a <em>preferred</em> buying path for consumers. Most would rather (or can only afford) $10 a month for a multi-year license to Microsoft Office for $300. Subscriptions also meaningfully reduce the cognitive burden of repeat decision making. No longer do you need to “track” your toothbrush for wear, risk “running out” of toilet paper and then be forced to overpay for a small-volume purchase, or need to scan and hoard coupons to ensure a great deal. Similarly, many consumers would rather marginally overpay for an all-you-can-eat subscription than optimize for specific tiers of use. In fact, most of us have caustic responses to per unit pricing, often to the point of irrationality (e.g. $40 for 35 loads of laundry detergent v. $1.00 per load). Amazon Prime is based on the <em>need</em> to get shipping fees out of the way once, versus fight them over and over and over and over, even if the effective shipping cost went up for a consumer, or the lack of shipping costs led to unnecessary purchases.</p><p>The rise of fully flexible monthly commitments also means that consumers no longer have to worry about having made a bad decision and being stuck with it. In this sense, every subscription is still á la carte, but unlike in the analog era, the default outcome of “doing nothing” is to keep getting value you enjoy rather than running out of a thing you need. </p><p><em>(Note that none of this means that a digital subscription business is a “good” one. Many sub-categories of CPGs and foodstuffs, not to mention music or fitness equipment, weren’t good business before the shift to subscription. The fact they shifted to subscriptions doesn’t inherently change this, just as it doesn’t mean they suddenly compete with all other subscriptions).</em></p><p><strong>“SVOD Fatigue”</strong></p><p>Of course, the nuances of “subscription fatigue” is separate from the question of “Subscription <em>VOD</em> fatigue”. It is obvious consumers don’t need 20 Netflixes. However, they’re not being asked to buy 20 Netflixes. It’s wrong to treat Fox Nation, Netflix, ESPN, and Twitch as competitors, let alone interchangeable “units of SVOD”. They serve very different functions and offer very different content. Just as Spotify and the <em>New York Times</em> and Amazon Prime shipping each do.</p><p>Amazon and Apple TV+, meanwhile, aren’t Netflixes – not in monetization, content volumes, or strategy. Now, if Amazon or Apple’s SVOD services can monetize so dramatically better through the Prime and iOS ecosystem than Netflix can via direct consumer spend and a singular focus, they can, in theory, “kill” Netflix – should they so choose – but that has nothing to do with SVOD fatigue nor the number of viable SVODs.</p><p>The question of SVOD fatigue isn’t about “how many SVODs will the average household have”. It’s really about “how many different roles are there to be played in video”. And the answer here is mostly path dependent – it depends on the innovation, risk taking, and discovery that happens in the marketplace, as well as timing. No one knew “live streaming video games” was an opportunity until Twitch, for example. And while Twitch likely steals <em>time</em> away from the video ecosystem, the viability of the Twitch subscription doesn’t mean that the number of viable OTT services has reduced.</p><p><strong>The Question</strong></p><p>All of which is to say what matters in SVOD is simple and not unique to SVOD: <span>A service will succeed if (1) it addresses a real, outstanding customer want/need; (2) at an appropriate price or value to the consumer; and (3) while generating sustainable economics</span>. </p><p>Quibi is a good example here. The company believes that there is an outstanding need for a new type of content, focused on a different time and place, under a different viewing behavior and focused on a specific audience. If it is right, and it can build up a defensible leadership position before other players replicate it, a new subscription will be possible and it doesn’t matter how many SVODs a customer already has (just as whether they have NYT or Spotify doesn’t matter). But of course, if you ask consumers “do you wish you had fewer subscriptions” or “fewer SVODs”, they will say yes – especially if they don’t really know what the new “thing” is. Note, too, that Pay-TV studies have been promising that 10%–30% of subscribers will cancel each year. They never do… because enough value remains. </p><p>More broadly, this three-point framework is well established (it actually has nothing to do with video). Over the past forty years, we have seen countless examples of “networks” launching into hyper-saturated marketplaces with hyper-specific but unproven (and often openly derided) theses regarding outstanding consumer wants and needs. Almost all of these have succeeded. In fact, they usually spawned several direct competitors – showing that the unmet want was even larger than originally anticipated. &nbsp;</p><p>For example…</p><ul data-rte-list="default"><li><p><em>1972: HBO launched a network focused on the most valuable TV time, Sunday night, with an unprecedented monetization model (á la carte consumer spend and no advertising), and focused only on reruns of Hollywood movies. It was ultimately bought by 25% of TV homes, became the most profitable network in the world and the market leader in quality. And this was despite the launches of Showtime (1976), Starz (1994) and Epix (2009).</em></p></li><li><p><em>1977: Nickelodeon launched 24/7 content only for kids. No longer was kids content relegated just to afternoon and Sunday morning blocks. In the 2000s, Nickelodeon became the most watched cable network, despite having spun-off several other Nick-branded channels and seen the launch of The Disney Channel in 1983.</em></p></li><li><p><em>1979: ESPN launched a 24/7 sports channel, ultimately with the highest programming budget in the world. In 2019, it brought in more than $2.5B in profits, with an annual revenue of roughly $9B. In 2009, Fox launched its own suite of 24/7 Fox-branded sports networks.</em></p></li><li><p><em>1980: CNN launched a 24/7 news channel. Today, it generates an estimated $800MM a year in cash flow on $2B in revenue, and several other 24/7 networks exist.</em></p></li><li><p><em>1981: MTV launched a 24/7 music video and culture channel that focused only on young audiences. The result was the first new Hollywood film/TV conglomerate in decades. Within years, MTV had launched several other 24/7 networks, while competitors launched even more focused versions, such as CMT.</em></p></li><li><p><em>1983: BET launched a 24/7 network focused on black American audiences. In 2001, the company was sold to Viacom for $3B. Several other black-focused networks exist today. </em></p></li><li><p><em>1996: Fox News launched a 24/7 news channel… only for half of news watchers. It now generates more than $1.5B in cash on $2.5B+ revenue</em></p></li></ul><p>Of course, this sort of logic can be used to justify faulty assumptions around what opportunity exists, where, how large it might be, how durable it is, etc. In addition, these specifics gaps were open because of technological limitations. A network like ABC could only air one thing at a time – and therefore there were structural impediments to serving “everyone”. Netflix, meanwhile, can air anything, at any time, to every viewer, and on an individual basis.</p><p>But the crucial point here is that it’s wrong to think about the “number” of subscription video services, just as it was wrong to think about how “many” networks were in the cable bundle in 1980, 1985, 1990, and so on. In fact, it’s incredibly close …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.matthewball.vc/all/misnomers">https://www.matthewball.vc/all/misnomers</a></em></p>]]>
            </description>
            <link>https://www.matthewball.vc/all/misnomers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051292</guid>
            <pubDate>Tue, 10 Nov 2020 20:18:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MCMC in JAX with benchmarks: 3 ways to write a sampler]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051196">thread link</a>) | @jeremiecoullon
<br/>
November 10, 2020 | https://www.jeremiecoullon.com/2020/11/10/mcmcjax3ways/ | <a href="https://web.archive.org/web/*/https://www.jeremiecoullon.com/2020/11/10/mcmcjax3ways/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        
<article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This post goes over 3 ways to write a sampler using JAX. I found that although there are a bunch of tutorials about learning the basics of JAX, it was not clear to me what was the best way to write a sampler in JAX. In particular, how much of the sampler should you write in JAX? Just the log-posterior (or the loss in the case of optimisation), or the entire loop? This blog post tries to answer this by going over 3 ways to write a sampler while focusing on the speed of each sampler.</p>

<p>I’ll assume that you already know some JAX, in particular the functions <code>grad</code>, <code>vmap</code>, and <code>jit</code>, along with the random number generator. If not, you can check out how to use these in this <a href="https://colinraffel.com/blog/you-don-t-know-jax.html">blog post</a> or in the <a href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html">JAX documentation</a>! I will rather focus on the different ways of using JAX for sampling (using the ULA sampler) and the speed performance of each implementation. I’ll then redo these benchmarks for 2 other samplers (MALA and SLGD) You can find the code to reproduce all these examples on <a href="https://github.com/jeremiecoullon/jax_MCMC_blog_post">Github</a>.</p>

<h2 id="sampler-and-model">Sampler and model</h2>

<p>To benchmark the samplers we’ll Bayesian logistic regression throughout. As sampler we’ll start with the unadjusted Langevin algorithm (ULA) with Euler dicretisation, as it is one of the simplest gradient-based samplers out there due to the lack of accept-reject step. Let  be the parameter at iteration ,   the gradient of the log-posterior,  the step size, and . Given a current position of the chain, the next sample is given by the equation:</p>



<p>The setup of the logistic regression model is the same as the one from this <a href="https://arxiv.org/abs/1907.06986">SG-MCMC review paper</a>:</p>

<ul>
  <li>Matrix of covariates , and vector responses: </li>
  <li>Parameters: </li>
</ul>

<p><strong>Model:</strong></p>

<ul>
  <li> with </li>
  <li>Prior:  with </li>
  <li>Likelihood: </li>
</ul>

<h2 id="version-1-python-loop-with-jax-for-the-log-posterior">Version 1: Python loop with JAX for the log-posterior</h2>

<p>In this version we only use JAX to write the log-posterior function (or the loss function in the case of optimisation). We use <code>vmap</code> to calculate the log-likelihood for each data point, <code>jit</code> to compile the function, and <code>grad</code> to get the gradient (see the code for the model on <a href="https://github.com/jeremiecoullon/jax_MCMC_blog_post/blob/master/logistic_regression_model.py">Github</a>). The rest of the sampler is a simple Python loop with NumPy to store the samples, as is shown below:</p>

<div><div><pre><code><span>def</span> <span>ula_sampler_python</span><span>(</span><span>grad_log_post</span><span>,</span> <span>num_samples</span><span>,</span> <span>dt</span><span>,</span> <span>x_0</span><span>,</span> <span>print_rate</span><span>=</span><span>500</span><span>):</span>
    <span>dim</span><span>,</span> <span>=</span> <span>x_0</span><span>.</span><span>shape</span>
    <span>samples</span> <span>=</span> <span>np</span><span>.</span><span>zeros</span><span>((</span><span>num_samples</span><span>,</span> <span>dim</span><span>))</span>
    <span>paramCurrent</span> <span>=</span> <span>x_0</span>

    <span>print</span><span>(</span><span>f</span><span>"Python sampler:"</span><span>)</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>num_samples</span><span>):</span>
        <span>paramGradCurrent</span> <span>=</span> <span>grad_log_post</span><span>(</span><span>paramCurrent</span><span>)</span>
        <span>paramCurrent</span> <span>=</span> <span>paramCurrent</span> <span>+</span> <span>dt</span><span>*</span><span>paramGradCurrent</span> <span>+</span>
                        <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>2</span><span>*</span><span>dt</span><span>)</span><span>*</span><span>np</span><span>.</span><span>random</span><span>.</span><span>normal</span><span>(</span><span>size</span><span>=</span><span>(</span><span>paramCurrent</span><span>.</span><span>shape</span><span>))</span>
        <span>samples</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>paramCurrent</span>
        <span>if</span> <span>i</span><span>%</span><span>print_rate</span><span>==</span><span>0</span><span>:</span>
            <span>print</span><span>(</span><span>f</span><span>"Iteration {i}/{num_samples}"</span><span>)</span>
    <span>return</span> <span>samples</span>
</code></pre></div></div>

<p>In this sampler we write the udpate equation using NumPy and store the samples in the array <code>samples</code>.</p>

<h2 id="version-2-jax-for-the-transition-kernel">Version 2: JAX for the transition kernel</h2>

<p>With JAX we can compile functions using <code>jit</code> which makes them run faster (we did this for the log-posterior function). Could we not put the bit inside the loop in a function and compile that? The issue is that for <code>jit</code> to work, you can’t have NumPy arrays or use the NumPy random number generator (<code>np.random.normal()</code>).</p>

<p>JAX does random numbers a bit differently to NumPy. I won’t explain how this bit works; you can read about them in the <a href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#JAX-PRNG">documentation</a>. The main idea is that jit-compiled JAX function don’t allow side effects, such as updating a global random state. As a result, you have to explicitly pass in a PRNG (called <code>key</code>) to every function that includes randomness, and split the key to get different pseudorandom numbers.</p>

<p>Below is a function for the transition kernel of the sampler rewritten to only include JAX functions and arrays (so it can be compiled). The point of the <code>partial</code> decorator and the <code>static_argnums</code> argument is to point to which arguments will not change once the function is compiled. Indeed, the function for the gradient of the log-posterior or the step size will not change throughout the sampler, but the PRNG key and the parameter definitely will! The means that the function will run faster as it can hardcode these static values/functions during compilation. Note that if the argument is a function (as is the case for <code>grad_log_post</code>) you don’t have a choice and must set it as static. See the <a href="https://jax.readthedocs.io/en/latest/jax.html#jax.jit">documentation</a> for info on this.</p>

<div><div><pre><code><span>@</span><span>partial</span><span>(</span><span>jit</span><span>,</span> <span>static_argnums</span><span>=</span><span>(</span><span>2</span><span>,</span><span>3</span><span>))</span>
<span>def</span> <span>ula_kernel</span><span>(</span><span>key</span><span>,</span> <span>param</span><span>,</span> <span>grad_log_post</span><span>,</span> <span>dt</span><span>):</span>
    <span>key</span><span>,</span> <span>subkey</span> <span>=</span> <span>random</span><span>.</span><span>split</span><span>(</span><span>key</span><span>)</span>
    <span>paramGrad</span> <span>=</span> <span>grad_log_post</span><span>(</span><span>param</span><span>)</span>
    <span>param</span> <span>=</span> <span>param</span> <span>+</span> <span>dt</span><span>*</span><span>paramGrad</span> <span>+</span> <span>jnp</span><span>.</span><span>sqrt</span><span>(</span><span>2</span><span>*</span><span>dt</span><span>)</span><span>*</span><span>random</span><span>.</span><span>normal</span><span>(</span><span>key</span><span>=</span><span>subkey</span><span>,</span> <span>shape</span><span>=</span><span>(</span><span>param</span><span>.</span><span>shape</span><span>))</span>
    <span>return</span> <span>key</span><span>,</span> <span>param</span>
</code></pre></div></div>

<p>The main loop in the previous function now becomes:</p>

<div><div><pre><code><span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>num_samples</span><span>):</span>
    <span>key</span><span>,</span> <span>param</span> <span>=</span> <span>ula_kernel</span><span>(</span><span>key</span><span>,</span> <span>param</span><span>,</span> <span>grad_log_post</span><span>,</span> <span>dt</span><span>)</span>
    <span>samples</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>param</span>
    <span>if</span> <span>i</span><span>%</span><span>print_rate</span><span>==</span><span>0</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>"Iteration {i}/{num_samples}"</span><span>)</span>
</code></pre></div></div>
<p>Notice how we split the random key inside <code>ula_kernel()</code> function which means it gets compiled (JAX’s random number generator can be <a href="https://github.com/google/jax/issues/968">slow in some cases</a>). We still save the samples in the NumPy array <code>samples</code> as in the previous case. Running this function several times with the same starting PRNG key will now produce exactly the sample samples, which means that the sampler is completely reproducible.</p>

<h2 id="version-3-full-jax">Version 3: full JAX</h2>

<p>We’ve written more of our function in JAX, but there is still some Python left. Could we rewrite the entire sampler in JAX? It turns out that we can! JAX does allow us write loops, but as it is designed to work on <a href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#%F0%9F%94%AA-Pure-functions">pure functions</a> you need to use the <a href="https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.scan.html"><code>scan</code></a> function. This function which allows you to loop over an array (similar to doing <code>for elem in mylist</code> in Python).</p>

<p>The way to use <code>scan</code> is to pass in a function that is called at every iteration. This function takes in <code>carry</code> which contains all the information you use in each iteration (and which you update as you go along). It also takes in <code>x</code> which is the value of the array you’re iterating over. It should return an updated version of <code>carry</code> along with anything who’s progress you want to keep track of: in our case, we want to store all the samples as we iterate.</p>

<p>Note that JAX also has a similar <a href="https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.fori_loop.html"><code>fori_loop</code></a> function which apparently you should only use if you can’t use scan (see the <a href="https://github.com/google/jax/discussions/3850">discussion on Github</a>). In the case of our sampler <code>scan</code> is easier to use as you don’t need to explicitly keep track of the entire chain of samples; <code>scan</code> does it for you. In contrast, when using <code>fori_loop</code> you have to pass an array of samples in <code>state</code> which you update yourself as you go along. In terms of performance I did quick benchmark for both and didn’t see a speed difference in this case, though the <a href="https://github.com/google/jax/discussions/3850">discussion on Github</a> says there can be speed benefits.</p>

<p>Here is the function that we’ll pass in <code>scan</code>. Note that the first line unpacks <code>carry</code>. The <code>ula_kernel</code> function then generates the new key and parameter. We then return the new version of <code>carry</code> (ie: <code>(key, param)</code>) which includes the updated key and parameter, and return the current parameter (<code>param</code>) which <code>scan</code> will save in an array.</p>

<div><div><pre><code><span>def</span> <span>ula_step</span><span>(</span><span>carry</span><span>,</span> <span>x</span><span>):</span>
  <span>key</span><span>,</span> <span>param</span> <span>=</span> <span>carry</span>
  <span>key</span><span>,</span> <span>param</span> <span>=</span> <span>ula_kernel</span><span>(</span><span>key</span><span>,</span> <span>param</span><span>,</span> <span>grad_log_post</span><span>,</span> <span>dt</span><span>)</span>
  <span>return</span> <span>(</span><span>key</span><span>,</span> <span>param</span><span>),</span> <span>param</span>
</code></pre></div></div>

<p>You can then pass this function along with the initial state in <code>scan</code>, and recover the final <code>carry</code> along with all the samples. The last two arguments in the <code>scan</code> function below mean that we don’t care what we’re iterating over; we simply want to run the sampler for <code>num_samples</code> number of iterations (as always, see the <a href="https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.scan.html">docs</a> for details).</p>

<div><div><pre><code><span>carry</span> <span>=</span> <span>(</span><span>key</span><span>,</span> <span>x_0</span><span>)</span>
<span>carry</span><span>,</span> <span>samples</span> <span>=</span> <span>lax</span><span>.</span><span>scan</span><span>(</span><span>ula_step</span><span>,</span> <span>carry</span><span>,</span> <span>None</span><span>,</span> <span>num_samples</span><span>)</span>
</code></pre></div></div>

<p>Putting it all together in a single function, we get the following. Notice that we compile the entire function with <code>grad_log_post</code>, <code>num_samples</code>, and <code>dt</code> kept as static. We allow the PRNG key and the starting point of the chain <code>x_0</code> to vary so we can get different realisations of our chain.</p>

<div><div><pre><code><span>@</span><span>partial</span><span>(</span><span>jit</span><span>,</span> <span>static_argnums</span><span>=</span><span>(</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>))</span>
<span>def</span> <span>ula_sampler_full_jax_jit</span><span>(</span><span>key</span><span>,</span> <span>grad_log_post</span><span>,</span> <span>num_samples</span><span>,</span> <span>dt</span><span>,</span> <span>x_0</span><span>):</span>

    <span>def</span> <span>ula_step</span><span>(</span><span>carry</span><span>,</span> <span>x</span><span>):</span>
        <span>key</span><span>,</span> <span>param</span> <span>=</span> <span>carry</span>
        <span>key</span><span>,</span> <span>param</span> <span>=</span> <span>ula_kernel</span><span>(</span><span>key</span><span>,</span> <span>param</span><span>,</span> <span>grad_log_post</span><span>,</span> <span>dt</span><span>)</span>
        <span>return</span> <span>(</span><span>key</span><span>,</span> <span>param</span><span>),</span> <span>param</span>

    <span>carry</span> <span>=</span> <span>(</span><span>key</span><span>,</span> <span>x_0</span><span>)</span>
    <span>_</span><span>,</span> <span>samples</span> <span>=</span> <span>lax</span><span>.</span><span>scan</span><span>(</span><span>ula_step</span><span>,</span> <span>carry</span><span>,</span> <span>None</span><span>,</span> <span>num_samples</span><span>)</span>
    <span>return</span> <span>samples</span>
</code></pre></div></div>

<p>Having the entire function written in JAX means that once the function is compiled it will usually be faster (see benchmarks below), and we can rerun it for different PRNG keys or different initial conditions to get different realisations of the chain. We can also run this function in <code>vmap</code> (mapping over the keys or inital conditions) to get several chains running in parallel. Check out this <a href="https://rlouf.github.io/post/jax-random-walk-metropolis/">blog post</a> for a benchmark of a Metropolis sampler in parallel using JAX and Tensorflow.</p>

<p>The only thing left to do this the full JAX version is to print the progress of the chain, which is especially useful for long runs. This is not as straightforwards to do with jitted functions as with standard Python functions, but this <a href="https://github.com/google/jax/discussions/4763">discussion on Github</a> goes over how to do this.</p>

<p>The final thing to point out is this JAX code ports directly to GPU without any modifications, so it might be possible to get an additional speedup in the full JAX version compared to those discussed below.</p>



<p>Now that we’ve gone over 3 ways to write an MCMC sampler we’ll show some speed benchmarks for ULA along with two other algorithms. We use the logistic regression model presented above and run <code>20 000</code> samples throughout.</p>

<h2 id="unadjusted-langevin-algorithm">Unadjusted Langevin algorithm</h2>

<h3 id="increase-amount-of-data">Increase amount of data:</h3>

<p>We run ULA for <code>20 000</code> samples for a 5 dimensional parameter. We vary the amount of data used and see how fast the algorithms are (time is in seconds).</p>

<table>
  <thead>
    <tr>
      <th>dataset size</th>
      <th>python</th>
      <th>JAX kernel</th>
      <th>full JAX (1st run)</th>
      <th>full JAX (2nd run)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td></td>
      <td>11</td>
      <td>3.4</td>
      <td>0.53</td>
      <td>0.18</td>
    </tr>
    <tr>
      <td></td>
      <td>11</td>
      <td>4.6</td>
      <td>2.0</td>
      <td>1.6</td>
    </tr>
    <tr>
      <td></td>
      <td>32</td>
      <td>32</td>
      <td>24</td>
      <td>24</td>
    </tr>
    <tr>
      <td></td>
      <td>280</td>
      <td>280</td>
      <td>250</td>
      <td>250</td>
    </tr>
  </tbody>
</table>

<p>We can see that for small amounts of data the full JAX sampler is much faster than the Python loop. In particular, for 1000 data points the full JAX sampler (once compiled) is almost 60 times faster than the Python loop version.</p>

<p>Note that all the samplers use JAX to get the gradient of the log-posterior …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jeremiecoullon.com/2020/11/10/mcmcjax3ways/">https://www.jeremiecoullon.com/2020/11/10/mcmcjax3ways/</a></em></p>]]>
            </description>
            <link>https://www.jeremiecoullon.com/2020/11/10/mcmcjax3ways/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051196</guid>
            <pubDate>Tue, 10 Nov 2020 20:11:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Large-Scale Geo-Replicated Conflict-Free Replicated Data Types [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051115">thread link</a>) | @simonebrunozzi
<br/>
November 10, 2020 | https://www.gsd.inesc-id.pt/~ler/reports/carlosbartolomeu-midterm.pdf | <a href="https://web.archive.org/web/*/https://www.gsd.inesc-id.pt/~ler/reports/carlosbartolomeu-midterm.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.gsd.inesc-id.pt/~ler/reports/carlosbartolomeu-midterm.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051115</guid>
            <pubDate>Tue, 10 Nov 2020 20:06:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Middle Management]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25050928">thread link</a>) | @duck
<br/>
November 10, 2020 | https://boz.com/articles/middle-management | <a href="https://web.archive.org/web/*/https://boz.com/articles/middle-management">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>There is an old saying in business that people don’t leave a job, they leave a
manager. I have found this to be generally accurate. But in my experience the
next most likely person to influence them isn’t their manager’s manager. It
is the CEO. </p>
<p>One reason I think middle managers so often feel like they are in no-man’s
land is because, well, they are. This is a chart I made up of how valuable a
connection is from each person to the various levels of management above
them.</p>
<p><img src="https://boz.com/middle-management.png" alt="horseshoe chart"></p>
<p>The ennui many middle managers feel at the trough of this diagram is
understandable. To the team you are the voice of management. But to
management you are the voice of the team. When I was at the nadir of this
chart in my own career it was the closest I came to leaving Facebook.</p>
<p>Eventually I managed to sort out a few strategies that helped me genuinely
enjoy middle management.</p>
<p>First, take pride in your job as the central link in the chain. Be an
efficient conduit of information in both directions. Don’t create any
friction in either direction unless you are sure you have unique value to
add. Too many middle managers create a layer for themselves when it isn’t
necessary which slows things down and is a form of value add disease.</p>
<p>Second, use this opportunity to sharpen your skills managing managers and
information flows. Those will be your core responsibilities for the rest of
your career from this point forward. </p>
<p>With those basic responsibilities sorted, you will find that this position in
the value chain allows you to identify opportunities nobody else sees. While
employees and senior leadership align on the work, you are effectively left to
operate the machinery by which work gets done. You have purview over the
processes that enable communication, escalation, and decision making. </p>
<p>As you advance in your career these things start to become obfuscated as
people push them below the surface to cater more to you. But they are always
there, as a hidden form of gravity that you will recognize if you invest the
time now. When teams slow down or drift from their mission, this is where the
problem is. When scope creeps or execution lags this is usually the first
place to look. I think this is one reason managers who were developed
internally often outperform those who arrived on top of an organization. It
helps if the machinery of progress isn’t entirely an abstraction.</p></section></div></div>]]>
            </description>
            <link>https://boz.com/articles/middle-management</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050928</guid>
            <pubDate>Tue, 10 Nov 2020 19:55:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[8 questions for writing]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25050838">thread link</a>) | @flreln
<br/>
November 10, 2020 | https://vasilishynkarenka.com/8questions/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/8questions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://vasilishynkarenka.com/content/images/size/w300/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 300w,
                            https://vasilishynkarenka.com/content/images/size/w600/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 600w,
                            https://vasilishynkarenka.com/content/images/size/w1000/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 1000w,
                            https://vasilishynkarenka.com/content/images/size/w2000/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://vasilishynkarenka.com/content/images/size/w2000/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg" alt="8 questions for writing">
            </figure>

            <section>
                <div>
                    <p>You cannot write productively if you do not have a plan.</p><p>That’s why most people struggle with writing: they have an idea to communicate but no specific plan of action to express their thought. As a result, they either procrastinate and never begin writing in the first place, or they hit writer’s block and spend hours staring at a blinking cursor on the top of a blank page.</p><p>The reason why people don’t plan writing is counterintuitive. They <em>think</em> they know how to write because they know the alphabet. But just like learning how to drive Toyota Prius in the suburbs doesn’t make you Michael Schumacher on track, knowing how to write symbols doesn’t make you a professional writer. You need to learn the skill.</p><p>The secret to good writing, as to any kind of knowledge work, is deliberate planning. If you do not have a plan, writing becomes a mysterious process you do only when you’re inspired. But if you document what you’re going to do, writing turns into a professional act with less opportunity for sloth. And the best way to plan writing is to ask questions.</p><p>If you think about something proactively, you run two mental processes at once. First, you keep the subject of your thought in your working memory. And second, you actively search through your mind for the object of interest. That’s a problem, given how much effort it takes to stay focused on a task.</p><p>But if you present yourself with a question, you change that. When you write the question down and look at it, you stay focused for longer. You benefit from your sensory channels to stay engaged, and you also run one mental process instead of two.</p><p>That’s why I’ve built a simple routine of asking myself a set of questions about what I’m planning to write. I apply it whenever I experience an itch like, “Oh, I could write an article about this!” After running the process for two months, I’ve empirically discovered how important it is to capture the idea right at the moment when it’s being formed. If I don’t turn my thought into an objective artifact that I can revisit later, I lose it.</p><p>Here are five reasons why questions work so well for writing:</p><ol><li>Good questions are like an advanced Google Search query to your mind. They have high suggestive value because the parameters that you pass to a question light up relevant areas of memory for you. If you do not have a question in mind and just roam through ideas, you’re like a first-time Google user who blindly presses “I’m Feeling Lucky” all the time.</li><li>Questions exist in the physical world. When you write a question down, you can get back to it later and think about it again. If you do not write your thought down, it will fly away from your unstable working memory, and you may never get into the same situation that triggered that thought in the first place. As it’s tough to trace back the system one thinking [1], you’re way better off writing things down.</li><li>Questions are discovery satellites for new knowledge. The best thing about questions is that you can ask yourself something you do not yet know. When you write down a problem with no answer, you may revisit it later and add new information as you develop more understanding. More interesting and less obvious is that asking yourself questions for which you have no answers triggers curiosity and programs your subconscious to think about it in the background.</li><li>Questions convince yourself that your work is important. This may sound trivial at first, but I’ve discovered that if I don’t have a decent argument why what I’m writing is important, I produce bad writing or get stuck in writer’s block. And it’s way easier to stay convinced that what you’re doing matters if you documented the reasons on paper – you can get back to your questions and get inspired when things get tough.</li><li>Questions help you avoid obvious mistakes. In many professions, checklists are a must. If you’re a pilot or a surgeon, you spend years mastering simple procedures because you don’t have time to do system two thinking when you have a problem in the field. You need to have already thought. I believe writers benefit from checklists even more because writing is considered to be a creative act, and most creative tasks usually benefit from systemic approaches and vice versa.</li></ol><p>Below are the questions I routinely ask myself when I’m profiling an idea.</p><h2 id="1-why-do-i-want-to-write-this-article">1. Why do I want to write this article?</h2><p>When you answer that question, you will discover the <em>actual</em> problem that you want to solve with the piece. Often, the problem will be different from the original idea of the article. If you have experience with the topic, you’ll likely see a better solution, a different angle of attack you can use to solve a reader’s problem.</p><p>For example, when I started <a href="https://vasilishynkarenka.com/learning/">my work on learning</a>, the original idea was to produce a theoretical piece describing the research that I’ve done. But when I answered the first question, I realized that my work aims to help a reader improve their learning process, and the best way to do that would be to write a description of my own process and embed principles into it of preaching theories.</p><p>The answer will often contradict the initial idea that you’ve come up with. That’s fine – just update the idea. What you must avoid doing is continuing with the initial plan if you’ve clearly discovered a better one after answering the question. Even if you already have the draft done, you must rewrite the whole thing because your job as a writer is to not waste reader’s time.</p><p>Here’s how I defined the “why” for this work:</p><blockquote>Q: Why do I want to write this article?<br>A: I want to help people improve their writing process by adding a simple routine of asking questions.</blockquote><p>The “why” question is also a test for abstractions. If you do not have a concise answer, you will find yourself attempting to write an all-covering piece. Avoid that mistake and define the purpose of the work first.</p><p>If you cannot answer the question, do not write this article.</p><h2 id="2-what-do-i-want-to-write-about">2. What do I want to write about?</h2><p>The answer to the question determines the subject of your article. The subject is what the article is about, the broader topic of the work [2]. For example:</p><ul><li>“I wanna write about productivity.”</li><li>“I want to write about learning.”</li><li>“I want to write a post about habits.”</li></ul><p>Here’s my subject for this post:</p><blockquote>Q: What do I want to write about?<br>A: I want to write about the writing process.</blockquote><p>When you answer the second question, you will grasp the category of knowledge you’re dealing with and enrich your writing.</p><p>Categories are a form of abstraction that we use to deal with complexity. Imagine a fridge. What I just did is I put some mental image in your head. But the refrigerator that you see is not some specific fridge, like the one you have in the kitchen, although it might be close. The fridge’s image in your head is an abstract fridge that combines details of fridges you have seen in the past. That’s what a category is.</p><p>The most value of categories comes from enrichment. When you see a new, tall, metallic rectangular object with two sections and a handle, you can’t help but guess it’s a fridge, because its properties match with the properties of fridges you have seen before. But you not only deduce the category of the unknown object based on how its features compare with the category representation that you know. You also <em>enrich</em> the concrete object with the features you expect an item of this category to have. In the fridge that you imagined, you’d expect to have some shelves inside, maybe a pack of eggs, or a cold bottle of Guiness. Without knowing it for sure, you pre-suppose to find this stuff in a new fridge that you see because of enrichment.</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@alexacea?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Alexandru Acea</a> on <a href="https://unsplash.com/s/photos/fridge?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</figcaption></figure><p>Once you understand the category of your work, you will be able to pull different ideas from the category level to enrich your article and better serve the reader. For example, suppose you’re writing a piece on fitness habits. In that case, you may jump to the category level and understand that fitness is about fitness habits <em>and</em> nutrition, <em>and</em> sleep. You could also level up to the habits category and see if there’s anything to pull from there – any similarities between building a habit of jogging and learning to play the piano? And if you have something to say on those things and it fits the context of your work, you can enrich your work.</p><p>The process of jumping between categories may sound complicated. I’d recommend taking a piece of paper and a pen to draw things when you’re getting started. The paper will make it easier to see the category literally “above” the object because of spatial cognition [3], and you will discover other objects from that category (i.e., nutrition, sleep) because of the white space effect when your mind fills in the missing details for you.</p><p>With experience, the process of jumping across categories of knowledge, and looking at a thing from different angles becomes automatic. It integrates into your perception so well that you don’t even notice it happening. Like a chess grandmaster, you just <em>know</em> a good move.</p><h2 id="3-what-do-i-want-to-say-about-the-subject">3. What do I want to say about the subject?</h2><p>The third question determines your theme. The theme is what you have to say about the subject you’re writing about. For example, here’s a subject-theme pair for this work:</p><p>Subject:</p><blockquote>Q: What do I want to write about? <br>A: I want to write about the writing process.</blockquote><p>Theme:</p><blockquote>Q: What do I want to say about the subject?<br>A: I want to convince my reader that asking yourself simple questions about an article helps a) flesh out the idea better and b) notice more ideas for writing. To make the process easier, one could use shortcuts and think of an article as a set of blocks rather than one big monolithic piece.</blockquote><p>The purpose of selecting your theme is to limit what you’re writing about and outline a course of work. As you may have noticed, there are many things one can say about the writing process. If I attempted to write a piece on the “writing process” as …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/8questions/">https://vasilishynkarenka.com/8questions/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/8questions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050838</guid>
            <pubDate>Tue, 10 Nov 2020 19:50:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Draft Array API Standard Released for Public Comment]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25050558">thread link</a>) | @travisoliphant
<br/>
November 10, 2020 | https://data-apis.org/blog/array_api_standard_release/ | <a href="https://web.archive.org/web/*/https://data-apis.org/blog/array_api_standard_release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post" itemprop="articleBody">
    
    <p>Array and tensor libraries - from NumPy, TensorFlow and PyTorch to Dask, JAX,
MXNet and beyond - could benefit greatly from a uniform API for creating and
working with multi-dimensional arrays (a.k.a tensors), as we discussed in
<a href="https://data-apis.org/blog/announcing_the_consortium/">our previous blog post</a>.
Today we’re pleased to announce a first version of our array API standard
(<a href="https://data-apis.github.io/array-api/latest">document</a>,
<a href="https://github.com/data-apis/array-api/">repo</a>) for review by the
wider community. Getting to this point took slightly longer than we had
initially announced because, well, it’s 2020 and hence nothing quite goes
according to plan.</p>
<p>The current status of the standard is that it is a coherent story (or at
least, we hope it is) that gives readers enough context about goals and scope
to understand and review the design decisions already taken and APIs it
contains. However, <em>it is not yet complete and we can still change direction
and make significant changes based on community feedback</em>. This is important
— no one likes a “take it or leave it” approach, and more eyes can make the
final result better. There’s still a few TODOs in places, and a couple of key
sections to be finished. The most important of those are the API for device
support, and the Python API for the
<a href="https://data-apis.github.io/array-api/latest/design_topics/data_interchange.html">data interchange protocol</a>
(proposed to be based on <a href="https://github.com/dmlc/dlpack">DLPack</a>).</p>
<p>It is worth repeating the main goal of this standard: make it easier to
switch from one array library to another one, or to support multiple array
libraries as compute backends in downstream packages. We’d also like to
emphasize that if some functionality is <em>not</em> present in the API standard,
that does <em>not</em> mean it’s unimportant, or that we’re asking existing array
libraries to deprecate it. Instead it simply means that that functionality at
present isn’t supported - likely due to it not being present in all or most
current array libraries, or not being used widely enough to have been
included so far. The <a href="https://data-apis.github.io/array-api/latest/use_cases.html">use cases section</a>
of the standard may provide more insight into important goals.</p>
<h2 id="some-key-design-topics">Some key design topics</h2>
<p>Two topics stood out so far in terms of complexity and choices that were hard
to make in such a way that they’d work well for all existing libraries:
mutability &amp; copy/view behaviour, and dtype casting rules.</p>
<h5 id="the-standard-will-contain-common-mutable-operations-such-as-slice-assignment-but-will-generally-avoid-in-place-mutation-in-apis-like-the-out-keyword">The standard will contain common mutable operations such as slice assignment, but will generally avoid in-place mutation in APIs like the <code>out</code> keyword</h5>
<p>NumPy, PyTorch, CuPy and MXNet provide strided arrays, and rely heavily on
mutating values in existing arrays and on the concept of a “view” for
performance. TensorFlow, JAX and Dask on the other hand have no or limited
support, given that they rely on an execution graph and/or JIT compiler which
provides constraints on how much mutability can be supported. The design
decisions described <a href="https://data-apis.github.io/array-api/latest/design_topics/copies_views_and_mutation.html">here</a>
will allow the most heavily used types of mutability - inplace operators,
item assignment and slice assignment - to be retained, while avoiding the use
of the <code>out=</code> keyword which is problematic to support for some libraries and
arguably a suboptimal API to begin with.</p>
<p>For libraries like SciPy and scikit-learn, the supported features are essential.
Code like this, from scikit-learn’s <code>ForestClassifier</code>:</p>
<div><pre><code data-lang="python"><span>for</span> <span>k</span> <span>in</span> <span>range</span><span>(</span><span>self</span><span>.</span><span>n_outputs_</span><span>):</span>
    <span>predictions</span><span>[</span><span>k</span><span>][</span><span>unsampled_indices</span><span>,</span> <span>:]</span> <span>+=</span> <span>p_estimator</span><span>[</span><span>k</span><span>]</span>
</code></pre></div><p>or this, from SciPy’s <code>optimize.linprog</code>:</p>
<div><pre><code data-lang="python"><span>r</span> <span>=</span> <span>b</span> <span>-</span> <span>A</span><span>@x</span>
<span>A</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span> <span>=</span> <span>-</span><span>A</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span>
<span>b</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span> <span>=</span> <span>-</span><span>b</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span>
<span>r</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span> <span>*=</span> <span>-</span><span>1</span>
</code></pre></div><p>is quite common and we see it as fundamental to how users work with array libraries.
<code>out=</code> is less essential though, and leaving it out is important for JAX,
TensorFlow, Dask, and future libraries designed on immutable data structures.</p>
<h5 id="casting-rules-for-mixed-type-families-will-not-be-specified-and-are-implementation-specific">Casting rules for mixed type families will not be specified and are implementation specific</h5>
<p>Casting rules are relatively straightforward when all involved dtypes are of
the same kind (e.g. all integer), but when mixing for example integers and
floats it quickly becomes clear that array libraries don’t agree with each
other. One may get exceptions, or dtypes with different precision. Therefore
we had to make the choice to leave the rules for “mixed kind dtype casting”
undefined - when users want to write portable code, they should avoid this
situation or use explicit casts to obtain the same results from different
array libraries. An example as simple as this one:</p>
<div><pre><code data-lang="python"><span>x</span> <span>=</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>5</span><span>)</span>  <span># will be integer</span>
<span>y</span> <span>=</span> <span>np</span><span>.</span><span>ones</span><span>(</span><span>5</span><span>,</span> <span>dtype</span><span>=</span><span>float16</span><span>)</span>
<span>(</span><span>x</span> <span>*</span> <span>y</span><span>)</span><span>.</span><span>dtype</span>
</code></pre></div><p>will show the issue. NumPy will produce <code>float64</code> here, PyTorch will produce
<code>float16</code>, and TensorFlow will raise <code>InvalidArgumentError</code> because it does not
support mixing integer and float dtypes.</p>
<p>See <a href="https://data-apis.github.io/array-api/latest/API_specification/type_promotion.html">this section of the standard</a>
for more details on casting rules.</p>
<h2 id="a-portable-test-suite">A portable test suite</h2>
<p>With the array API standard document we are also working on a
<a href="https://github.com/data-apis/array-api-tests">test suite</a>. This test suite
will be implemented with Pytest and Hypothesis, and won’t rely on any
particular array implementation, and is meant to test compliance with the API
standard.</p>
<p>It is still very much a work-in-progress, but the aim is to complete it by
the time the community review of the API standard wraps up. However, the
community is encouraged to check out the current work on the test suite on
<a href="https://github.com/data-apis/array-api-tests">GitHub</a> and try it out and
comment on it. The
<a href="https://github.com/data-apis/array-api-tests/blob/master/README.md">README</a>
in the test suite repo contains more information on how to run it and
contribute to it.</p>
<p>The test suite will be runnable with any existing library. This can be done
by specifying the array implementation namespace to be tested via an
environment variable:</p>
<div><pre><code data-lang="bash">$ <span>ARRAY_API_TESTS_MODULE</span><span>=</span>jax.numpy pytest
</code></pre></div><p>The test suite will also support vendoring so that array libraries can easily
include it in their own test suites.</p>
<p>The result of running the test suite will be an overview of the level of
compliance with the standard. We expect it will take time for libraries to
get to 100%; anything less shouldn’t just mean “fail”, 98% would be a major
step towards portable code compared to today.</p>
<h2 id="people--projects">People &amp; projects</h2>
<p>So who was involved in getting the API standard to this point, and which
libraries do we hope will adopt this standard? The answer to the latter is
“all existing and new array and tensor libraries with a Python API”. As for
who was involved, we were lucky to get contributions from creators and senior
maintainers of almost every project of interest - here’s a brief description:</p>
<ul>
<li>NumPy: Stephan Hoyer and Ralf Gommers are both long-time NumPy maintainers.
In addition we got to consult regularly with Travis Oliphant, creator of
NumPy, on the history behind some decisions made early on in NumPy’s life.</li>
<li>TensorFlow: Alexandre Passos was a technical lead on the TensorFlow team,
and has been heavily involved until a few weeks ago. Paige Bailey is the
product manager for TensorFlow APIs at Google Research. Edward Loper and
Ashish Agarwal, TensorFlow maintainers, replaced Alexandre recently as
Consortium members.</li>
<li>PyTorch: Adam Paszke is one of the co-creators of PyTorch. Ralf Gommers
leads a team of engineers contributing to PyTorch.</li>
<li>MXNet: Sheng Zha is a long-time MXNet maintainer. Markus Weimer is an
Apache PMC member and mentor for the MXNet incubation process into the
Apache Foundation.</li>
<li>JAX: Stephan Hoyer and Adam Paszke are two maintainers of JAX.</li>
<li>XArray: Stephan Hoyer is one of the co-creators, and still a maintainer, of Xarray.</li>
<li>Dask: Tom Augspurger is a senior Dask maintainer.</li>
<li>CuPy: we have no active participant from CuPy. However we have talked to
the CuPy team at Preferred Networks, who are supportive of the goals and
committed to following NumPy’s lead on APIs.</li>
<li>ONNX: Sheng Zha is an ONNX Steering Committee member.</li>
</ul>
<p>Many other people have made contributions so far, including the Consortium
members listed at <a href="https://github.com/data-apis/governance">https://github.com/data-apis/governance</a>.</p>
<h2 id="next-steps-to-a-first-complete-standard">Next steps to a first complete standard</h2>
<p>We are now looking for feedback from the wider community, and in particular
maintainers of array libraries. For each of those libraries, a Consortium
member involved in the library will be soliciting feedback from their own
project. We’d like to get to the point where it’s clear for each library that
there are no blockers to adoption and that the overall shape of the API
standard is considered valuable enough to support.</p>
<p>In addition, given that this API standard is completely new and drafting
something like it hasn’t been attempted before in this community, we’d love
to get meta feedback - is anything missing or in need of shaping in the
standard document, the goal and scope, ways to participate, or any other such
topic?</p>
<p>To provide feedback on the array API standard, please open issues or pull
requests on <a href="https://github.com/data-apis/array-api">https://github.com/data-apis/array-api</a>. For larger discussions
and meta-feedback, please open GitHub Discussion topics at
<a href="https://github.com/data-apis/consortium-feedback/discussions">https://github.com/data-apis/consortium-feedback/discussions</a>.</p>


</div></div>]]>
            </description>
            <link>https://data-apis.org/blog/array_api_standard_release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050558</guid>
            <pubDate>Tue, 10 Nov 2020 19:33:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons Learned Building an Open Source MLOps Platform]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25050500">thread link</a>) | @calebkaiser
<br/>
November 10, 2020 | https://www.cortex.dev/post/building-an-open-source-mlops-platform | <a href="https://web.archive.org/web/*/https://www.cortex.dev/post/building-an-open-source-mlops-platform">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div content-type="article"><p>For the last two years, we’ve been working on Cortex, our open source machine learning deployment platform. Over that time, we’ve been really fortunate to see it grow into what it is today, used in production by teams around the world, and supported by a fantastic community of contributors.</p><p>We’ve also had to change our thinking several times along the way. The understanding of the ML ecosystem we had at the beginning has not always turned out to be accurate, and this is reflected in various changes we’ve made to Cortex.</p><p>As interest in MLOps continues to increase, I thought it would be useful (for our sakes as much as anyone else’s) to document a few of the key lessons we’ve learned that’ve come to shape Cortex.</p><p>If you’re working on a production machine learning system, building machine learning infrastructure, or designing your own MLOps tool, hopefully the following lessons (listed in no particular order) are useful for you.</p><h3>1. Production machine learning runs in the cloud</h3><p>When Cortex was still in its idea stage, one of our most frequent discussions was whether or not it should support on-premise deployments. At the time, the worry was that a large portion of the machine learning ecosystem was going to remain on-premise indefinitely due to privacy and cost.</p><p>These worries were enflamed when we initially released Cortex. While we had some excited users, we also had plenty of people writing in requesting on-prem support. We worried that by going all-in on the public clouds, we’d cut off most of the machine learning ecosystem.</p><p>Over the last two years, things have changed. Production machine learning is almost entirely moving to the cloud, and there are a couple reasons why.</p><p>The first is the standard reason for moving to the cloud: scalability. As production machine learning systems become more powerful and responsible for more features, their workloads increase. If you need to autoscale to dozens of GPUs during peak hours, the cloud has obvious advantages.</p><p>The second is the investment by the major clouds into ML-specific offerings. Major clouds now offer both dedicated software and hardware for machine learning. For example, Google and AWS both offer ASICs (TPUs and Inferentia, respectively) that substantially improve machine learning performance, and both are only available on their respective clouds.</p><p>More and more, the cloud is becoming the only realistic way to deploy production machine learning systems.</p><h3>2. It’s too early for end-to-end MLOps tools</h3><p>Another misguided belief we held in Cortex’s early days was that Cortex needed to be an all-inclusive, end-to-end MLOps platform that automated your pipeline from raw data to deployed model.</p><figure id="w-node-a47abffb7609-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa9ad5cb4b8083a07ddc765_0*6z89yrFEvqkVBqIg.jpeg" alt=""></p></figure><p>We’ve written a full <a href="https://towardsdatascience.com/we-tried-to-build-an-end-to-end-ml-platform-heres-why-it-failed-190c0f503536" target="_blank">breakdown of why that was the wrong decision,</a> but the short version is that it’s still way too early in the lifespan of MLOps to build that sort of platform.</p><p>Every page of the production machine learning playbook is constantly being rewritten. For example, in the last several years:</p><ul role="list"><li><strong>Our notion of “big” models has exploded.</strong> We thought models with hundreds of millions of parameters were flirting with boundaries of being “too large” to deploy. Then Transformer models like GPT-2 started weighing in the billions—and people still built applications out of them.</li><li><strong>The ways we train models have changed. </strong>Transfer learning, neural architecture search, knowledge distillation—we have more techniques and tools than ever to design, train, and optimize models efficiently.</li><li><strong>The machine learning toolbox has grown rapidly</strong>. PyTorch was only released in 2016, shortly after TF Serving’s initial public release. ONNX came out in 2017. The frameworks, languages, and features that an end-to-end MLOps platform would need to support changes endlessly.</li></ul><p>We ran into all of these problems with our first release of Cortex. We provided a seamless experience—<em>if</em> <em>you used the narrow stack we supported.</em> Because everything (including language, pipeline, frameworks, and even team structure) can vary so wildly across ML orgs, we were almost always “one feature away” from fitting any given team’s stack.</p><p>As a modular platform, focused on one discrete part of the machine learning lifecycle—deployment—without opinions about the rest of the stack, Cortex has been adopted by many more teams at a much faster pace. We’ve seen rapid growth in other MLOps tools with similar “best of breed” approaches at different parts of the stack, including <a href="https://dvc.org/" target="_blank">DVC (Data Version Control) </a>and <a href="https://www.comet.ml/site/" target="_blank">Comet</a>.</p><h3>3. Data science, ML engineering, and ML infrastructure are all different — in theory</h3><p>With Cortex, we use the following high-level model of an ML function and its constituent parts:</p><ul role="list"><li><strong>Data science</strong>. Concerned with the development of models, from exploring the data to conducting experiments to training and optimizing models.</li><li><strong>Machine learning engineering</strong>. Concerned with the deployment of models, from productionizing models to writing inference services to designing inference pipelines.</li><li><strong>Machine learning infrastructure</strong>. Concerned with the design and management of the ML platform, from resource allocation to cluster management to performance monitoring.</li></ul><p>And in theory, these are nicely delineated functions with clear handoff points. Data science creates models which are turned into inference pipelines by ML engineering and deployed to a platform maintained by ML infrastructure.</p><p>But, this is an overview of the theoretical functions in an ML org, not the <em>actual roles</em> people hold. Oftentimes, a data scientist will also do ML engineering work, or an ML engineer will be tasked with managing an inference cluster.</p><p>Building a tool for these different use-cases gets complex, as the optimal ergonomics of an interface for one role can vary drastically from another.</p><p>For example, <a href="https://towardsdatascience.com/why-we-do-machine-learning-engineering-with-yaml-not-notebooks-a2a97f5e04f8" target="_blank">for reasons we’ve explained before</a>, Cortex APIs are written as Python scripts with YAML manifests, not notebooks, and are deployed via a CLI. </p><p>For MLEs, this is comfortable. For data scientists, however, it is often uncomfortable, as YAML and CLIs aren’t common tools in their ecosystem. Because of this, we needed to build a Python client for defining deployments in pure Python in order for some teams to use Cortex successfully.</p><p>Now, people who are more comfortable with CLIs can deploy like this:</p><figure id="w-node-b878c71bee4b-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa9ad5c272d5ce9d4c2dd28_0*yV51u9hxfGDvxtF3.png" alt=""></p></figure><p>And people more comfortable with pure Python can do this:</p><figure id="w-node-5864f8b2c1a4-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa9ad5c09e66f37c2c56cdf_1*1CO_-hPGhV9qNuH4c3Jxuw.png" alt=""></p></figure><p>The takeaway here is that if you’re building MLOps tooling, remember everyone who will be using it in practice, not just in theory.</p><h3>4. ML native companies have different needs</h3><p>Several years ago, the most common examples of production machine learning were popular products optimized by trained models. Payment processors would sprinkle in fraud detection models, streaming platforms would boost their engagement with recommendation engines, etc.</p><p>Now, however, there is a new wave of companies whose products aren’t enhanced by models—they <em>are</em> models.</p><p>These companies, which we refer to as ML native, operate in different ways. Some sell access to an inference pipeline as an API, as in the case of <a href="https://www.glisten.ai/" target="_blank">Glisten</a>, whose API allows retailers to tag and categorize products instantly:</p><figure id="w-node-dc634e21281f-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa47e5ab8c60a850d3f4032_0*mw_tAL1CeDD1Q8e3.png" alt=""></p></figure><p>Others build applications whose core functionality is provided by a trained model. For example, <a href="https://postera.ai/" target="_blank">PostEra’s</a> medicinal chemistry platform uses models to predict the most likely chemical reactions for creating a specific drug, and <a href="https://play.aidungeon.io/main/home" target="_blank">AI Dungeon</a> uses a trained language model to create an endless choose-your-own-adventure:</p><p>These ML native applications have different infrastructure needs. For one, they typically rely on realtime inference, meaning their models need to be deployed and available at all times.</p><p>Ensuring this availability can get very expensive. <a href="https://medium.com/@aidungeon/how-we-scaled-ai-dungeon-2-to-support-over-1-000-000-users-d207d5623de9" target="_blank">AI Dungeon uses a 6 GB model</a> that can only handle a few concurrent requests and requires GPUs for inference. To scale to even a few thousand concurrent users, they need many large GPU instances running at once—something that is costly to sustain for long periods.</p><p>When we first built Cortex, we hadn’t worked with many ML native teams. After working with them, we wound up prioritizing a new set of features, many of which were at least in part aimed at helping control inference costs:</p><ul role="list"><li>Request-based autoscaling to optimally scale each model for spend</li><li>Spot instance support to allow for cheaper base instance prices</li><li>Multi-model caching, live reloading, and multi-model endpoints to increase efficiency</li><li>Inferentia support for more cost-effective and performant instance types</li></ul><p>As the number of ML native companies continues to rise quickly, MLOps tools and platforms are going to have to build for their needs.</p><h3>5. MLOps is production machine learning’s biggest bottleneck</h3><p>This is one of the few things we believed before building Cortex that we still find to be true today. It is the feasibility of building and deploying a production machine learning system prevents teams from using ML. </p><p>Training and retraining models is not cheap. Deploying models to production isn’t cheap either. Building a platform to support those deployments is a full-scale infrastructure project, one that has to be maintained moving forward.</p><p>These costs make machine learning unapproachable for most companies. and the frustrating part is that they aren’t intrinsic qualities of machine learning. We can solve them with better infrastructure—no ML research breakthroughs needed.</p><p>As the MLOps ecosystem matures, new tools will continue to abstract away these parts of infrastructure and nullify the costs that prohibit teams from using ML in production. If you want to accelerate the proliferation of machine learning, consider contributing to any of the many open source MLOps projects—<a href="https://github.com/cortexlabs/cortex" target="_blank">like this one</a>.</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.cortex.dev/post/building-an-open-source-mlops-platform</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050500</guid>
            <pubDate>Tue, 10 Nov 2020 19:30:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Benefits of Being a Stoic]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25050456">thread link</a>) | @davefreiburger
<br/>
November 10, 2020 | https://gradually.co/the-benefits-of-being-a-stoic/ | <a href="https://web.archive.org/web/*/https://gradually.co/the-benefits-of-being-a-stoic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-893">
				<!-- <a href="https://gradually.co/the-benefits-of-being-a-stoic/">-->
					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              																			<p>								Wisdom								</p><!-- end cat-wrap -->
						<p><span>&nbsp; •&nbsp; </span>
						<span>Benefits of Being a Stoic</span>
						<span> &nbsp;•&nbsp; </span>
						<span>
							November 10, 2020						</span>

						<img width="640" height="340" src="https://gradually.co/wp-content/uploads/2020/11/GD24-Wisdom.gif" alt="" loading="lazy"></p><div>

																					<div>
								<p><a href="https://linkmix.co/1611480" target="_blank">
									[Image source: Eric Gerlach/Giphy]								</a></p><h5>
									<a href="http://nautil.us/issue/92/frontiers/the-joys-of-being-a-stoic" target="_blank">
										The Joys of Being a Stoic									</a>
									 &nbsp;by Massimo Pigliucci									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>“If there is nothing you can do about a particular situation, why beat yourself up about it?” — Massimo Pigliucci</span></li>
<li><span>Stoicism shouldn’t be about suppressing your emotions. Moreso, Stoicism is about adjusting your unhealthy emotions (anger) to a more mindful embrace of healthier ones (joy).&nbsp;</span></li>
<li><span>Stoicism receives a great deal of pushback regarding the negative effects of not acknowledging pain and the silent endurance and lack of emotion.&nbsp;</span></li>
<li><span>Massimo quotes Epictetus (Greek Philosopher), “Some things are within our power, while others are not. Within our power are opinion, motivation, desire, aversion, and, in a word, whatever is of our own doing; not within our power are our body, our property, reputation, office, and, in a word, whatever is not of our own doing.”&nbsp;</span></li>
<li><span>Massimo adds, “…the idea is to internalize our goals: Instead of focusing, as it comes natural, on outcomes, let’s pay attention to our intentions and efforts. The Stoics think that the only truly good thing for us is our own character, and that therefore the only truly bad things are whatever may undermine our character. Everything else (including health, wealth, reputation, etc.) has value, but does not define who we are.”</span></li>
<li><span>The four virtues:</span></li>
</ul>
<ol>
<li>
<ol>
<li><i><span>Practical wisdom</span></i><span> — the knowledge of what is truly good or bad for me. Will this undermine my character or not?&nbsp;</span></li>
<li><i><span>Courage</span></i><span> — doing something that frightens us.</span></li>
<li><i><span>Justice</span></i><span> — as treating other people, like my coworker, fairly and with respect.</span></li>
<li><i><span>Temperance</span></i><span> — we should do things in the right measure, neither too much nor too little.&nbsp;</span></li>
</ol>
</li>
</ol>
<ul>
<li><span>“Apply the dichotomy of control and the four virtues to everything you do and, as Epictetus promises, you will never be unhappy. You will be free, and you will live a life truly worth living.” — Massimo Pigliucci</span></li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>Massimo mentions that the four virtues help us form a sort of moral compass. Allowing people to navigate the world and weather the storm of whatever that’s thrown at us. Moral compass or not, Stoicism or not, knowing your own virtues that help you navigate the world seems like an exercise worth doing. </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->
				<!-- </a>-->
			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/the-benefits-of-being-a-stoic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050456</guid>
            <pubDate>Tue, 10 Nov 2020 19:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Note to a Newly Liquid Entrepreneur]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25050332">thread link</a>) | @lconstable
<br/>
November 10, 2020 | https://lembascapital.com/library/note-to-a-newly-liquid-entrepreneur/ | <a href="https://web.archive.org/web/*/https://lembascapital.com/library/note-to-a-newly-liquid-entrepreneur/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Congratulations!</p><p>Whether your company has IPO’d, was acquired, or just gave you the chance to take some money off the table, you are now well off. You’re about to receive a lot of advice about how to do things correctly – how to balance risk, how to earn exciting returns, how your friend’s startup is the next Facebook, etc.</p><p>I’m going to talk with you about how investments can go wrong.</p><p>I’ve seen many situations where an entrepreneur makes money the hard way, brick by brick, and then loses it in a flash due to a bad investment decision or, worse, a scam. Just as bad as the money lost are the emotions that come with it – embarrassment, shame, and a loss of trust that may keep you from working on your next project. Let’s take a few minutes to save you from years of anguish and millions of dollars lost.</p><p>Here are five lines of questioning that will help you avoid the worst mistakes:</p><p>1) Alignment – <em>Is the manager invested alongside you? How is the manager compensated?</em></p><p>2) Strategy – <em>Can you articulate why the investment strategy will work? How does it bring new information into the market?</em></p><p>3) Risk – <em>What would cause your investment to fail? Is the manager intellectually honest about the risks and working to mitigate those downside scenarios?</em></p><p>4) Fraud – <em>How can you tell if they’re a fraud? Are they offering Special Access or Risk-Free Returns?</em></p><p>5) Trust – <em>Do you trust your manager?</em></p><h2>Alignment</h2><p><em>Is the manager invested alongside you? How is the manager compensated?</em></p><p>Finance is an odd business. It’s just like manufacturing, except every few years the manufacturers accidentally blow up the factory. Your goal should be to avoid getting caught in the blast. The reason this keeps happening is that people are driven by misaligned incentives.</p><p>There are three main incentive structures in finance: transactional (commission on initial sale), management (% of assets under management), and outcome (% of profits). Every financial institution has an ongoing internal struggle between these factions. When the transactional group wins out, the institution may focus too much on trading commissions and not enough on good investments. That’s when you get the potential for a spectacular blowup.</p><p>You can mitigate these misaligned incentives by having the manager invest alongside you.</p><p><strong>Incentive Structures in Finance</strong></p><figure><img width="936" height="390" src="https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1.png" alt="" srcset="https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1.png 936w, https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1-300x125.png 300w, https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1-768x320.png 768w" sizes="(max-width: 936px) 100vw, 936px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1.png" data-srcset="https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1.png 936w, https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1-300x125.png 300w, https://lembascapital.com/library/wp-content/uploads/2020/10/Incentive-structures-in-finance-1-768x320.png 768w"><figcaption><em>Source: </em>Lembas Capital</figcaption></figure><p>There is no silver bullet, and a GP co-investment with the LP does not prevent an aggressive strategy from failing (see LTCM). Still, if your manager is willing to sell you a product but isn’t willing to personally invest the same way, you should think very carefully about investing. Even if the manager has different financial goals or if there is a good reason why the manager can’t co-invest in the same fund, you may learn a great deal by asking why.</p><h2>Strategy</h2><p><em>Can you articulate why the investment strategy will work? How does it bring new information into the market?</em></p><p>As I wrote in&nbsp;<a href="https://lembascapital.com/credo" target="_blank" rel="noreferrer noopener">Lembas’s credo</a>, capital markets are information markets. I believe an asset’s price is comprised of (1) an asset’s cash flows and (2) the capital flows of other investors in and out of that asset. Successful investors bring new information to the market about an asset’s cash flows or capital flows. That’s what people mean when they say they are looking for investors with an edge.</p><p>Your advisor should be able to articulate why they think their strategy has worked in the past and why it should keep working in the future. How are they sourcing new information? You should be able to understand it sufficiently such that it’s not a black box to you. Or, if it is a black box and you still want to make the investment, just recognize what you’re doing and then size your investment appropriately.</p><h2>Risk</h2><p><em>What would cause your investment to fail? Is the manager intellectually honest about the risks and working to mitigate those downside scenarios?</em></p><p>There are many facets to risk management, but, simply put, a prudent investor tries to anticipate future risks and to stay resilient in the face of unforeseen catastrophes.</p><p>Understand what would cause the investment to collapse. As a basic heuristic, the main risks for long-term strategies are thesis (did they properly analyze the cash flows and capital flows?) and structure (can they get forced to sell too soon, even if they are right about the long-term thesis?). In contrast, the main risk for short-term strategies tends to be operational (what is their current speed and/or research edge, and why will that continue to hold 3+ years down the line?).</p><p>Your advisor should be forthright about these risks – both for your sake and as a signal that they are vigilant in their own risk management. Part of being forthright is using an accurate measuring stick. An intellectually honest advisor won’t play games with portfolio marks that mask the underlying risk (e.g. make sure that no one convinces you that illiquid assets are less volatile just because there aren’t publicly available mark-to-market prices).</p><h2>Frauds</h2><p><em>How can you tell if they’re a fraud? Are they offering Special Access or Risk-Free Returns?</em></p><p>I’ve seen frauds come in two main flavors: Special Access and Risk-Free Returns.</p><p>Special Access fraudsters claim that&nbsp;<em>only they</em>&nbsp;can get you into the best private deals. They tend to prey on people who don’t live in the region or don’t work in the industry where those opportunities originate (e.g. selling Chinese monopoly stories to South Americans or selling Silicon Valley stories to Europeans). The best private investors often do have access advantages, the difference being that those are legitimate. You can sort one from the other by doing reference checks and by looking to see if other smart people in the ecosystem are also investing. For instance, virtually none of the top SF investors were taken into Theranos or Nikola.</p><p>The Risk-Free Returns fraud is more insidious. It’s so hard to earn that initial capital that you will naturally be protective of it. Every wealth manager will tell you to keep a portion of your wealth in low-risk, low-return investments. Someone may approach you to tell you about a way to earn a little bit of a higher return with no added risk, month in and month out. It sounds too good to be true. It often is.</p><p>The soft version of the Risk-Free Returns fraud is a misrepresentation of an investment strategy. Many funds generate returns by selling insurance (aka short volatility). They collect premiums every month like clockwork. There’s nothing wrong with the insurance business, so long as you are amply compensated for the risk you are insuring. The problem is that, someday, the bill will come due. You shouldn’t evaluate that kind of fund without recognizing what kind of major risk is being insured and what the true downside scenario entails.</p><p>The hard version of the Risk-Free Returns fraud is simply made-up returns. Bernie Madoff is the prime example here. Many Jewish charities in the New York and Palm Beach communities were ruined by the promise of steady, low-risk returns that were just a bit better than the standard low-risk low-return options.</p><p>To give you a taste of what to watch out for, here’s a snapshot of how Madoff presented his Sentry fund to his clients. You can easily imagine how he sold the story — <em>do a bit better than the market with none of the downside</em>, <em>long track record of steady returns</em>, <em>lets you sleep soundly</em>.</p><p><strong>Bernie Madoff’s “Risk-Free Returns”</strong></p><figure><img width="936" height="442" src="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1.png" alt="" srcset="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1.png 936w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1-300x142.png 300w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1-768x363.png 768w" sizes="(max-width: 936px) 100vw, 936px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1.png" data-srcset="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1.png 936w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1-300x142.png 300w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-graph-1-768x363.png 768w"></figure><figure><img width="936" height="542" src="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1.png" alt="" srcset="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1.png 936w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1-300x174.png 300w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1-768x445.png 768w" sizes="(max-width: 936px) 100vw, 936px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1.png" data-srcset="https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1.png 936w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1-300x174.png 300w, https://lembascapital.com/library/wp-content/uploads/2020/10/Madoff-sentry-table-1-768x445.png 768w"><figcaption><em>Source:</em> Bernie Madoff’s Sentry Fund</figcaption></figure><p>Unfortunately, even the most prestigious private banks have little to offer but an apology when you invest in a fraud through them. This is&nbsp;<a href="https://www.dropbox.com/s/ffovoxxuyi0bdfx/2008-12%20Union%20Bancaire%20Privee%20-%20%20Investing%20with%20Madoff.pdf?dl=0" target="_blank" rel="noreferrer noopener">Union Bancaire Privée’s statement</a>&nbsp;to their clients after Madoff was uncovered. The good news is that an experienced fund manager could have spotted the problem immediately (as many did).</p><p>If you’re approached with any special access, structured product, or volatility selling strategy, make sure that you understand the true risk profile or that you speak with someone who does. Many of those structures are fine, but the dangerous ones are the ones that blow up the factory.</p><h2>Trust</h2><p><em>Do you trust your manager?</em></p><p>All of this comes down to trust.</p><p>The best advisors will want to build a lifelong relationship with you. They’ll strive to earn your trust, and they’ll be figuring out how much they can trust you too. Outcome-driven investors look for clients who will back them to deploy capital during market downturns, just at the exact moment when others are uncomfortable doing so too. Great clients really do help investors earn great returns.</p><p>I don’t think there’s any trick I can tell you about assessing who you can trust. I’m sure you’ve had to figure this out in your own business, and I don’t think it will be any different here.</p><h2>What’s Next?</h2><p>It’s always exciting to see a project come to fruition, and it’s just as exciting to start the next one. I hope you can build on your success as a source of strength, not as a burden to be carried.</p><p>Wealth ownership can be a significant life transition. There are libraries of material to read. If you wanted to narrow it down to two selections, I would recommend&nbsp;<a href="https://www.amazon.com/Destructive-Power-Family-Wealth-Succession/dp/1119327520" target="_blank" rel="noreferrer noopener">The Destructive Power of Family Wealth</a>&nbsp;by Philip Marcovici (a book on wealth planning by the former chair of Baker McKenzie’s wealth management and tax practices) and&nbsp;<a href="https://grahamduncan.blog/letter-to-a-friend-who-just-made-a-lot-of-money/" target="_blank" rel="noreferrer noopener">Letter to a friend who just made a lot of money</a>&nbsp;by Graham Duncan (an essay on managing yourself and selecting a wealth manager by the head of a major family office).</p><p>Those should cover the basics, and I’m happy to go into more detail as specific questions come up. From there, you just have to pick and choose what works best for you.</p><p>Congrats again, and can’t wait to hear what you’re up to next,</p><p>Luke</p><p><em>Thanks to my friends in wealth management who helped me first learn these lessons, and credit to Benn Eifert for the factory analogy.</em></p><p><em>This essay was inspired by conversations I had with two friends who recently came into wealth – one a young SF tech executive whose company was sold, one a middle age Middle East entrepreneur who took a dividend from his family business. …</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lembascapital.com/library/note-to-a-newly-liquid-entrepreneur/">https://lembascapital.com/library/note-to-a-newly-liquid-entrepreneur/</a></em></p>]]>
            </description>
            <link>https://lembascapital.com/library/note-to-a-newly-liquid-entrepreneur/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050332</guid>
            <pubDate>Tue, 10 Nov 2020 19:20:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[.NET 5 Is Here]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049738">thread link</a>) | @twords
<br/>
November 10, 2020 | https://twords.com/view-article/TLDR_Code-Net-5-is-Here | <a href="https://web.archive.org/web/*/https://twords.com/view-article/TLDR_Code-Net-5-is-Here">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="root"><div><div><div><div><div><header><div><p><a tag="[object Object]" href="https://twords.com/"><img src="https://twords.com/static/media/inverse_cropped.0601fa81.svg"></a></p><div><div><div></div></div></div><div><p><a tag="[object Object]" href="https://twords.com/authentication/login">Login</a></p></div></div></header></div><div class="page"><div><div><p><a href="https://twords.com/#" data-rb-event-key="/" role="button"></a><a href="https://twords.com/">Home</a></p></div><div><p><a href="https://twords.com/#" data-rb-event-key="/trending" role="button"></a><a href="https://twords.com/trending">Trending</a></p></div><div><p><a href="https://twords.com/#" data-rb-event-key="/my-feed" role="button"></a><a href="https://twords.com/my-feed">My Feed</a></p></div></div><div><nav><a href="https://twords.com/"></a></nav></div><div><div><a href="https://twords.com/view-article/null"><div><p>Continue reading...</p></div></a></div><div></div></div><div><div><p><h3>Latest Articles</h3></p><div><div><p><span>Loading..</span></p></div><p><span>Loading...</span></p></div></div></div></div><div><nav><div><p><a tag="[object Object]" href="https://twords.com/about-us">About Us</a></p></div><div><p><a tag="[object Object]" href="https://twords.com/contact-us">Contact Us</a></p></div><div><p><a tag="[object Object]" href="https://twords.com/faq">FAQ</a></p></div><div><div><p><a href="https://twitter.com/official_twords">Twitter</a></p></div></div></nav></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://twords.com/view-article/TLDR_Code-Net-5-is-Here</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049738</guid>
            <pubDate>Tue, 10 Nov 2020 18:55:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Important Open Source projects should not use GitHub]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049619">thread link</a>) | @rolph
<br/>
November 10, 2020 | https://www.unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html | <a href="https://web.archive.org/web/*/https://www.unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>Published on <span id="pubdate">2020-10-23</span>. Modified on <span id="moddate">2020-10-25</span>.</p>
<p>Thousands of the worlds best Open Source projects are still hosting their code repositories on GitHub. Since Microsoft has purchased GitHub this has become a serious problem.</p>
<p><b>Update 2020-10-25:</b> This is not directly related as it could happen on other hosting platforms as well, but just a few hours after I wrote this the youtube-dl repository was taken down from GitHub by RIAA due to a <a href="https://github.com/ytdl-org/youtube-dl/">DMCA request</a>.</p>
<p>It is no news that <a href="https://en.wikipedia.org/wiki/GitHub#Acquisition_by_Microsoft">Microsoft purchased GitHub in 2018</a>, everyone knows that. Yet despite that fact thousands of the worlds most important Open Source projects continue to host their code on GitHub. People seem to have forgotten just how rotten Microsoft really is and how dangerous that situation is.</p>
<p>It is not so much the fact that many projects host their projects on GitHub, it is the fact that many projects haven't secured the code outside of GitHub! They rely fully on GitHub to maintain and protect the code.</p>
<p>Microsoft is very actively purchasing important projects related to Open Source and in April 2020 it was announced that they had now also acquired <a href="https://en.wikipedia.org/wiki/Npm_(software)">npm</a>, a JavaScript packaging vendor, for an undisclosed sum of money.</p>
<p>Perhaps the younger generation don't know anything about the past "evils" of Microsoft and naively believe that Microsoft is now the good friend to Open Source, but the truth is that all these acquisitions of Open Source projects is a business tactic that is put in place to improve Microsoft's loosing position to Open Source. It is a matter of control.</p>
<p>Just yesterday <a href="https://www.minecraft.net/en-us/article/java-edition-moving-house">Microsoft announced</a> that Minecraft will require a Microsoft account to play in 2021 and that owners of the classic version will be forced to migrate.</p>
<p>While this is not related to Open Source, it is a really good example of how bad it can get if Microsoft sometime in the future decides that projects on GitHub are required to do something which goes against these projects interests.</p>
<p>I will not name any names, because that is not important, but how in the world can any Open Source project that regards their code base as valuable not make sure that they have a completely up to date copy of every single line of code outside of GitHub!?</p>
<p>Some project developers only keep parts on the code in personal repositories, others haven't even got a backup but trust fully that GitHub will always have a working and current release of the latests commits.</p>
<p>For years people have warned about the position GitHub had in the world of Open Source because it concentrates too much of the power to make or break the community in a single entity. Having Microsoft behind the steering wheel makes the situation a thousand times worse.</p>
<p>Nobody in their right mind would ever have imagined uploading Open Source code to Microsoft servers just a decade ago. Microsoft where the archenemy of Open Source in the nineties and they deployed all kinds of dirty tactics to keep other operating systems out of the market, especially dirty tactics against Linux. In the early 2000s the then CEO Steve Ballmer said, <q>Linux is a cancer that attaches itself in an intellectual property sense to everything it touches.</q> And for many years they tried to gain control over Linux and manipulated the market in different ways in order to "crush the competition". When they realized they couldn't do that and that the battle was lost, they deployed a new tactic in which they instead try to make money of Linux, which is what that are doing now in a lot of areas, and which is why they seem "friendlier" to the Open Source community.</p>
<p>I myself do have some code residing on GitHub, but of course I also have multiple up-to-date clones and backups elsewhere. However, having the worlds largest repository of important Open Source code reside in the hands of Microsoft is just madness. Why haven't all the major projects migrated? Running a self-hosting Git server isn't that difficult and there even exists several solutions that are pretty solid.</p>
<p>More and more of all the good stuff about Open Source and community driven development and sharing of resources, code and experience is slowly getting either gobbled up or ruined and massacred by big corporations or economically based foundations. Why is it that as soon as money enters into the picture so many things are turned into "crap"? Of course, greed is the answer, but an even more important question than that is: Why is it that we have stopped caring?</p>
<p>Large projects should self-host their repositories in order to stay completely independent, but some alternative solutions to the more popular services such as GitHub, GitLab and BitBucket does exist (not an exhaustive list):</p>
<ul>
<li><a href="https://codeberg.org/">Codeberg</a><br>Codeberg is a registered German non-profit organization and I think it is the best alternative. Codeberg does not depend on external services. No third party cookies, no tracking. Hosted in the EU.<br>Relevant discussion on <a href="https://news.ycombinator.com/item?id=22795930">Hacker News</a>. Relevant <a href="https://codeberg.org/codeberg/org/src/branch/master/PrivacyPolicy.md">Privacy Policy</a></li>
<li><a href="https://notabug.org/">NotABug</a><br>NotABug.org is run by <a href="https://peers.community/">Peers</a>, a group of people interested in free software and free society. It is mostly for small projects though. Relevant <a href="https://notabug.org/tos">Privacy Policy</a>.</li>
<li><a href="https://sourcehut.org/">sourcehut</a><br>sourcehut is currently considered alpha and it is not going to stay free, but it does not have any tracking or advertising. All features work without JavaScript. Relevant <a href="https://man.sr.ht/privacy.md">Privacy Policy</a>. Relevant discussion on <a href="https://news.ycombinator.com/item?id=23030489">Hacker News</a>. After signing up you get the following message: <q>Payment is optional during the alpha, but be aware that it will become mandatory later. This service is funded by its users, not by investors.</q></li>
</ul>
<p>A few good solutions for self-hosting (not an exhaustive list):</p>
<ul>
<li><a href="https://gogs.io/">Gogs</a> - old discussion at <a href="https://news.ycombinator.com/item?id=11374003">Hacker News</a></li>
<li><a href="https://gitea.io/en-US/">Gitea</a> a community-managed fork of Gogs - discussed at <a href="https://news.ycombinator.com/item?id=17006503">Hacker News</a></li>
<li><a href="https://github.com/theonedev/onedev">OneDev</a> - discussed at <a href="https://news.ycombinator.com/item?id=22081419">Hacker News</a></li>
</ul>
<p>Other relevant reading: <a href="https://jacquesmattheij.com/what-is-wrong-with-microsoft-buying-github/">What is wrong with Microsoft buying GitHub</a></p>
</article></div>]]>
            </description>
            <link>https://www.unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049619</guid>
            <pubDate>Tue, 10 Nov 2020 18:51:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Innocent badgers behind “awful” and “disgusting” looting of Viking graves]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049599">thread link</a>) | @Bologo
<br/>
November 10, 2020 | https://www.psychnewsdaily.com/innocent-badgers-behind-awful-and-disgusting-looting-of-viking-graves/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/innocent-badgers-behind-awful-and-disgusting-looting-of-viking-graves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4973" role="main"><div><div><div><p>On November 4, various media reported on the looting of Viking graves in the Norwegian town of <a href="https://en.wikipedia.org/wiki/Oppdal">Oppdal</a>. <span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p>Malevolent grave robbers had allegedly ravaged a sacred Viking burial ground. Local newspapers attributed the misdeed to wanton vandals, greedy thieves, or both. The intruders had apparently drilled deep holes into 17 of the Viking graves.</p><p>“It’s awful!” <a href="https://www.adressa.no/nyheter/trondelag/2020/11/06/Anmeldte-vikinggrav-plyndring-i-Oppdal-n%C3%A5-har-saken-tatt-en-uventet-vending-22955618.ece">said Thora Nyborg</a>, a curator at the NTNU University Museum in Trondheim, according to local newspaper <em>OPP </em>(paywalled link <a href="https://opp.no/2020/11/nyheter/vikinggraver-plyndret-i-hostmorket/">here</a>). “Many organic objects have been lost, and more objects might be lost now that air has been allowed into the graves.”</p><p>Archaeology website AncientPages.com <a href="https://www.ancientpages.com/2020/11/06/disgusting-vandalism-and-looting-of-viking-graves-in-norway/">called the vandalism “disgusting.</a>” And commenters on the Facebook page The Heathen Underground <a href="https://www.facebook.com/heathenunderground/photos/pb.728159570530461.-2207520000../3763552250324496/?type=3&amp;eid=ARAk94RGYvhaVzFmr5C9yKMCmQ32q4-ZklASGYAnOI05bhST6Muv28ZWrAJzOp3mR3HLyVKKIZUIXIxy">said it was all “very sad.”</a></p><h2>Looting of Viking graves a blessedly rare event</h2><p>Their indignation was understandable. After all, the <a href="https://www.visitnorway.com/listings/the-burial-site-at-vang/204434/">Vang burial site</a>, and its more than 800 burial mounds, is Northern Europe’s largest remaining burial site from the Iron Age. As such, it is a site of major historical importance.<span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>The local newspaper <em>OPP </em>even suggested that the holes, which were of varying depths, <a href="https://opp.no/2020/11/nyheter/vikinggraver-plyndret-i-hostmorket/">had been dug using a special drill</a> (paywalled link), indicating a wicked degree of cunning on the part of the graverobbers.</p><p>Furthermore, except for an isolated case in 2014, there had been no looting at this major Viking burial ground since the 19th century.</p><h2>Badgers behind the looting of Viking graves</h2><p>But on November 6, events took a different turn. The <a href="https://www.psychnewsdaily.com/300-cocaine-packages-wash-ashore-on-dutch-beach-drug-tourists-look-for-more/">police</a> had suddenly closed the case, said Sjur Vammervold, a cultural consultant for the municipality of Oppdal.</p><p>The reason was that the suspect turned out to be impossible to prosecute. “It seems that a badger was behind it,” <a href="https://www.dagbladet.no/kultur/gravplyndrer-avslort/73037518">Vammervold told local newspaper <em>Dagbladet</em></a>.<span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>“At least now we know that people weren’t responsible,” he said. “The badger is quite innocent, and probably had no plans to rob any graves,” he added.</p><p>Vammervold said that while the badger hypothesis has not yet been proven, at this point it seems the most likely explanation.</p><p>“Based on how badgers dig holes, they are probably behind this,” he said of the short legged <a href="https://www.psychnewsdaily.com/category/animal-psychology/" target="_blank" rel="noreferrer noopener">animals</a>.</p><p>Most of the burial sites at Vang date from the Late Iron Age (400 – 1050 AD), which includes the <a href="https://en.wikipedia.org/wiki/Viking_Age">Viking Age</a> (793 – 1066 AD). Archaeologists have made many important discoveries there.</p><hr><p><strong>Photo credit: </strong><a href="https://pixabay.com/users/andyballard-1141862/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2030975">andy ballard</a>&nbsp;via&nbsp;<a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2030975">Pixabay</a>&nbsp;</p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/innocent-badgers-behind-awful-and-disgusting-looting-of-viking-graves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049599</guid>
            <pubDate>Tue, 10 Nov 2020 18:50:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Platform APIs in Qt 6]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049468">thread link</a>) | @Memosyne
<br/>
November 10, 2020 | https://www.qt.io/blog/platform-apis-in-qt-6 | <a href="https://web.archive.org/web/*/https://www.qt.io/blog/platform-apis-in-qt-6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            

                            <p>
                                Tuesday November 10, 2020 by <a href="https://www.qt.io/blog/author/tor-arne-vestb%C3%B8">Tor Arne Vestbø</a> | <a href="#commento">Comments</a>
                            </p>
                            
                            <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><span>While Qt solves many of the typical tasks of writing an application, there are always corner cases that Qt can not cover, or where it makes more sense to build a feature on top of the platform specific APIs, or another toolkit. One of the <a href="https://bugreports.qt.io/browse/QTBUG-80233" rel="noopener" target="_blank">tasks</a> we wanted to address for Qt 6 was to clean up and coordinate the various mechanisms we had for accessing platform-specific functionality. </span><span></span></p>
<!--more-->
<p><span>We'll now&nbsp; go through the result of this work in Qt 6. The full documentation is available in the documentation snapshots, as part of the new <a href="https://doc-snapshots.qt.io/qt6-dev/platform-integration.html" rel="noopener" target="_blank">Platform Integration </a></span><span>section.</span></p>
<h2 id="type-conversions">Type Conversions</h2>
<p>Many of Qt's basic data types, such as<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qstring.html">QString</a>,<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qpoint.html">QPoint</a>, or<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qimage.html">QImage</a>, provide conversions from and to the native equivalent types.</p>
<p>For example, to get the current user's username on Apple platforms:</p>
<div>
<pre><code>NSProcessInfo *processInfo = NSProcessInfo.processInfo;<br>QString userName = QString::fromNSString(processInfo.userName)</code></pre>
</div>
<p>For a complete list of all type conversions, see the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/platform-type-conversions.html">Type Conversions</a><span>&nbsp;</span>overview.</p>
<h2>Window Embedding<a href="https://doc-snapshots.qt.io/qt6-dev/platform-integration.html#window-embedding" title="Direct link to this headline"></a></h2>
<p>Windows created by the underlying platform APIs may be used as both parent containers for Qt windows, or embedded into Qt windows as child windows.</p>
<p>The former is useful if the application is mainly written using the native platform APIs, but where parts of the application use Qt, for example to draw a specialized UI. To embed Qt into the window hierarchy of the native application, use<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwindow.html#winId">QWindow::winId</a>() to get the native handle for the Qt window, and then use the native APIs to re-parent the window into the native UI.</p>
<a name="event-handling" id="event-handling" data-hs-anchor="true"></a>
<p>The latter is useful if the native platform, or another toolkit, exposes a specialized control as a native window. By using<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwindow.html#fromWinId">QWindow::fromWinId</a>() to wrap the native window handle in a<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwindow.html">QWindow</a>, the window can then be re-parented into the Qt window hierarchy as any other<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwindow.html">QWindow</a>. To re-parent this<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwindow.html">QWindow</a><span>&nbsp;</span>into a Qt Widget based UI, use the widgets-specific<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwidget.html#createWindowContainer">QWidget::createWindowContainer</a>() function.</p>
<h2><span>Event Handling</span></h2>
<p><span>Most event handling use-cases in Qt are sufficiently covered by the cross platform event delivery, via</span><span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwindow.html#event">QWindow::event</a><span>() and friends, or through</span><span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qobject.html#installEventFilter">QObject::installEventFilter</a><span>().</span></p>
<p>In cases where this is not enough, Qt provides access to the delivery of the native events. A global event filter that receives all native events can be installed by using<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qcoreapplication.html#installNativeEventFilter">QCoreApplication::installNativeEventFilter</a>(), while per-window native events can be handled in<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qwindow.html#nativeEvent">QWindow::nativeEvent</a>().</p>
<p><strong>Note:<span>&nbsp;</span></strong>Interfering with the native event flow may put Qt in an inconsistent state. These APIs should primarily be used to augment Qt's existing event handling, for example for events Qt doesn't handle yet.<span></span><span></span></p>
<h2 id="native-interfaces">Native Interfaces<a href="https://doc-snapshots.qt.io/qt6-dev/platform-integration.html#native-interfaces" title="Direct link to this headline"></a></h2>
<p>Platform specific functionality not covered by the APIs mentioned above are handled by the new generic<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/native-interfaces.html">native interface</a><span>&nbsp;</span>mechanism. This mechanism replaces the <a href="https://doc.qt.io/qt-5/qtplatformheaders-index.html" rel="noopener">platform headers</a> user-facing API, as well as the QPA-level <span><code>QPlatformNativeInterface</code></span> API. The interfaces provide access to native or platform specific APIs of the classes they extend.</p>
<p>The interfaces live in the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface.html">QNativeInterface</a><span>&nbsp;</span>namespace, and cover use-cases such as accessing underlying native handles, adopting existing native handles, or providing platform specific APIs.</p>
<p>The majority of the old <a href="https://doc.qt.io/qt-5/qtplatformheaders-index.html" rel="noopener">platform header </a>APIs can be found in the <span><code>QNativeInterface::Private</code></span> namespace, since these were largely used by other internal code. Over time we'll expose more of these APIs based on feedback and use-cases.<span></span></p>
<h3 id="accessing-underlying-native-handles">Accessing underlying native handles<a href="https://doc-snapshots.qt.io/qt6-dev/native-interfaces.html#accessing-underlying-native-handles" title="Direct link to this headline"></a></h3>
<p>In situations where a feature of the native platform is not exposed in Qt, it can be helpful to access the native handles maintained by Qt, and use those to call the native APIs instead.</p>
<p>For example, to access the underlying NSOpenGLContext of an<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/native-interfaces.html#qopenglcontext">QOpenGLContext</a><span>&nbsp;</span>on macOS, via the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface-qcocoaglcontext.html">QNativeInterface::QCocoaGLContext</a><span>&nbsp;</span>native interface:</p>
<div>
<pre><code><span>using</span><span> </span><span>namespace</span><span> </span><span><a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface.html">QNativeInterface</a></span><span>;</span><span><br></span><span>if</span><span> </span><span>(</span><span>auto</span><span> </span><span>*</span><span>cocoaGLContext </span><span>=</span><span> glContext</span><span>-</span><span>&gt;</span><span>nativeInterface</span><span>&lt;</span><span>QCocoaGLContext</span><span>&gt;</span><span>())</span><span><br>    </span><span>[</span><span>cocoaGLContext</span><span>-</span><span>&gt;</span><span>nativeContext</span><span>()</span><span> makeCurrentContext</span><span>]</span><span>;</span></code></pre>
</div>
<p>The native interface is accessed through the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qopenglcontext.html#nativeInterface">QOpenGLContext::nativeInterface</a>() accessor, which ensures that the requested interface is available, and otherwise returns<span>&nbsp;</span><code>nullptr</code>. The underlying NSOpenGLContext is then accessed through the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface-qcocoaglcontext.html#nativeContext">nativeContext()</a><span>&nbsp;</span>accessor.<span></span></p>
<h3 id="adopting-existing-native-handles">Adopting existing native handles<a href="https://doc-snapshots.qt.io/qt6-dev/native-interfaces.html#adopting-existing-native-handles" title="Direct link to this headline"></a></h3>
<p>Similarly to the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/platform-integration.html#window-embedding">window embedding</a><span>&nbsp;</span>use-case, there are situations where the native platform, or another toolkit, has created a native handle that you would like to pass on to Qt — wrapping the existing handle instead of creating a new one.</p>
<p>For example, to adopt an existing NSOpenGLContext, and use that to share resources with a context created by Qt:</p>
<div>
<pre><code><span>using</span><span> </span><span>namespace</span><span> </span><span><a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface.html">QNativeInterface</a></span><span>;</span><span><br></span><span><a href="https://doc-snapshots.qt.io/qt6-dev/qopenglcontext.html">QOpenGLContext</a></span><span> </span><span>*</span><span>adoptedContext </span><span>=</span><span> </span><span>QCocoaGLContext</span><span>::</span><span>fromNativeContext</span><span>(</span><span>nsOpenGLContext</span><span>);</span><span><br>anotherContext</span><span>-</span><span>&gt;</span><span>setShareContext</span><span>(</span><span>adoptedContext</span><span>);</span></code></pre>
</div>
<p>The adopted context is created by a platform specific factory function in the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface-qcocoaglcontext.html">QNativeInterface::QCocoaGLContext</a><span>&nbsp;</span>native interface.<span></span></p>
<h3 id="accessing-platform-specific-apis">Accessing platform specific APIs<a href="https://doc-snapshots.qt.io/qt6-dev/native-interfaces.html#accessing-platform-specific-apis" title="Direct link to this headline"></a></h3>
<p>In some cases an API is too platform specific to be included in the cross platform Qt classes, but is still useful to include. These APIs are available either in the same way as when accessing the underlying native handles, through the<span>&nbsp;</span><a href="https://doc-snapshots.qt.io/qt6-dev/qopenglcontext.html#nativeInterface">nativeInterface()</a><span>&nbsp;</span>accessor, or directly as static function in the native interface.</p>
<p>For example, to obtain the OpenGL module handle on Windows:</p>
<div>
<pre><code><span>using</span><span> </span><span>namespace</span><span> </span><span><a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface.html">QNativeInterface</a></span><span>;</span><span><br>HMODULE moduleHandle </span><span>=</span><span> </span><span>QWGLContext</span><span>::</span><span>openGLModuleHandle</span><span>();<br></span></code></pre>
<p><span>Or to tweak the border behavior of a window on Windows, via its platform window handle:</span></p>
<div>
<pre><code><span>using</span><span> </span><span>namespace</span><span> </span><span>QNativeInterface::Private</span><span>;<br></span><span>if (auto *windowsWindow = dynamic_cast&lt;QWindowsWindow*&gt;(window-&gt;handle()))<br>    windowsWindow-&gt;setHasBorderInFullScreen(true);</span></code></pre>
</div>
</div>
<h3 id="source-and-binary-compatibility">Source and Binary Compatibility<a href="https://doc-snapshots.qt.io/qt6-dev/native-interfaces.html#source-and-binary-compatibility" title="Direct link to this headline"></a></h3>
<p>One important thing to note is that are no source or binary compatibility guarantees for the native interface APIs, meaning that an application using these interfaces is only guaranteed to work with the Qt version it was developed against. This allows us to adjust and add to these APIs as needed -- making them more flexible in tracking the underlying native functionality.</p>
<h2>Extras modules</h2>
<p>As some of you have noticed, the "extras" modules are not part of the initial Qt 6.0 release. This is related to the work described in this blog post, as we still need to go through these modules to survey:</p>
<ul>
<li>Whether any features are deprecated and can be removed</li>
<li>Whether any features have more modern replacements that we should advocate instead</li>
<li>Whether any features can be better solved by integrating directly with the native APIs</li>
<li>Whether any features fit better in the API paradigms described earlier, for example as native interfaces</li>
</ul>
<p>The end goal would ideally be that we don't need any standalone "extras" module, but rather that the functionality is available directly in the relevant modules, e.g. QtGui or QtDeclarative.&nbsp; If you want to track this work you can follow <a href="https://bugreports.qt.io/browse/QTBUG-83251" rel="noopener">QTBUG-83251</a>.</p></span></p>
                            
                            
                                <hr>
                          
                                <h6>Blog Topics:</h6>        
                                
                            


                        </div></div>]]>
            </description>
            <link>https://www.qt.io/blog/platform-apis-in-qt-6</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049468</guid>
            <pubDate>Tue, 10 Nov 2020 18:42:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RIP Bill Morrow: Lead Developer Cinelerra-GG]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049358">thread link</a>) | @constantinum
<br/>
November 10, 2020 | https://www.cinelerra-gg.org/news-updates/our-developer-good-guy-has-passed-away/ | <a href="https://web.archive.org/web/*/https://www.cinelerra-gg.org/news-updates/our-developer-good-guy-has-passed-away/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="et-boc">
<div>
<div><div>
<div>
<div>
<div>
<div><p>It is with dismay and sadness that I have to announce this devastating news that our highly esteemed developer W.P. Morrow aka Good Guy died in a traffic accident last Monday at the age of 66. Bill, as he also called in private, was as so often in his free time, out for sports riding his bicycle when he was hit by a truck. He was taken to hospital, but unfortunately he succumbed to his severe injuries.</p>
<p>This news is shocking and makes me speechless, although I find it extremely difficult to find words due to my sadness, I would like to remember him at this point.</p>
<p>A look back shows that, together with Phyllis, he has pushed this project forward with great passion, dedication and commitment. His ingenuity and creative solutions were always an enrichment for this project. He was never too comfortable to tackle even small problems and improvements to make the life of the users easier. You could tell that he enjoyed programming a lot. He enjoyed improving Cinelerra-GG and interacting with the community. He has acted selflessly and for the good of all, and through his commitment to free and open software, he has made this world a bit freer and better.</p>
<p>The gap he leaves behind is huge and filling it will be hard.</p>
<p>Thanks for everything dear Bill. It was a great honor and pleasure to work with you. You will be remembered. We will miss you. Rest in peace.</p>
<p>I express my condolences to Phyllis, his family and friends.</p>
<p>Sam</p>
<p>P.S.: Phyllis has expressed the wish to resume work on the project at a later date, currently she needs some time off, and to participate in the documentation and correspondence as usual. I will continue to support this project as before. The monthly releases cannot be offered in the same way at the moment. Minor changes and improvements will take place from time to time. We are open for new developers and hope for your support.</p></div>
</div> 
</div> 
</div> 
</div>  </div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.cinelerra-gg.org/news-updates/our-developer-good-guy-has-passed-away/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049358</guid>
            <pubDate>Tue, 10 Nov 2020 18:33:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meet the world's first Kafka data catalog]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049235">thread link</a>) | @lefterisdvr
<br/>
November 10, 2020 | https://lenses.io/blog/2020/07/data-dump-real-time-data-catalog-apache-kafka/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/07/data-dump-real-time-data-catalog-apache-kafka/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>From data stagnating in warehouses to a growing number of real-time applications, in this article we explain why we need a new class of Data Catalogs: this time for real-time data.&nbsp;</p><p>The 2010s brought us organizations <i>“doing big data”</i>. Teams were encouraged to dump it into a data lake and leave it for others to harvest.&nbsp;</p><p>But data lakes soon became data swamps. There were no best practices, no visibility into service levels or quality of data, no data contracts, no naming conventions or standardizations.&nbsp;</p><p>Just as quickly as data had arrived, it was impossible to find or trust.&nbsp;</p><p>If you were mature you might have deployed an enterprise Data Catalog that discovered data across your data stores. If you were less mature this would have been a manual process of documentation.&nbsp;</p><p>Either way, this wouldn’t prepare you for what was to come in the world of data and <a href="https://lenses.io/dataops/">DataOps</a>.&nbsp;</p><h3>

New streaming data, same problem, bigger stakes</h3><p>
As a developer or data engineer, you still have a problem finding data. Answering simple questions such as: Where do I have customer data? How about surnames and phone numbers or credit cards?&nbsp;</p><p>Why is this?&nbsp;</p><p>It’s because the challenge to catalog data got harder. Data isn’t sitting in data warehouses any longer. It’s streaming. And it is data generated by applications run within engineering, not business teams. </p><p>A lot of applications.</p><p>Engineering teams haven’t got time nor can they be expected to follow traditional data governance practices.</p><p>And yet, if there is no way to know what data there is across different teams and how to find it - it may as well not exist.</p><p>Much of DataOps is about self-service to remove friction from delivery. Pure luck in speaking to the right person at the right time or endless back-and-forths to understand what data exists, how it looks, etc isn't right. </p><p>This won’t work in 2020.&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/1tMpPZhid4mgL7MmbBaKiQ/e3b84596b166d1eba6bd5b303c891726/dataops-workspace.png" alt="DataOps container for your data platform"></p><p>For real-time data, there is no alternative but to automate the data management processes. This includes the discovery of data entities, data lineage, classification and quality.&nbsp;</p><p>Automation will mean teams are free to develop new data-intensive applications without centralized data governance or manual procedures.&nbsp; What data is generated can be immediately socialized across a business for other teams to benefit from.</p><h3>Commandments of Cataloguing data
</h3><p>Metadata is Queen. </p><p>If you can collect it from your different data infrastructure and applications you’re on the right path. Then to make it valuable you need to serve this information in the right measure, and you can start to answer the right questions:&nbsp;</p><ul><li><p> <!-- -->What data exists and its profile?</p></li><li><p> <!-- -->What is its quality?</p></li><li><p> <!-- -->What service levels can I expect?</p></li><li><p> <!-- -->What is its data provenance?</p></li><li><p> <!-- -->How might other services be impacted?</p></li><li><p> <!-- -->How compliant is it?</p></li></ul><p>Being able to answer these sorts of questions is fundamentally important to the success of real-time data projects.&nbsp;</p><p>Gartner agrees:<i> </i></p><p><i>“By 2021, organizations that offer a curated catalog of internal and external data to diverse users will realize twice the business value from their data and analytics investments than those that do not”</i></p><p><b><i>Source: Augmented Data Catalogs: Now an Enterprise Must-Have for Data and Analytics Leaders,” Ehtisham Zaidi &amp; Guido de Simoni, Sept.12, 2019</i></b>

</p><h3>Enter the Lenses real-time Data Catalog
</h3><p>Lenses.io delivers the first and only <a href="https://lenses.io/usecases/discover">Data Catalog for streaming data</a>.</p><p><img src="https://downloads.ctfassets.net/tnuaj0t7r912/3wE5igSRxlgeTTNk7Qy4zc/6cfe43a2e8a7d7ef49c29b02d4d462c0/lenses.io_4.0_real_time_data_catalog.gif" alt="Lenses.io - Real time data catalog for Apache Kafka"></p><p>
It's an easy, secure and intuitive way to identify your data:</p><ul><li><p> <!-- -->It works in real-time</p></li><li><p> <!-- -->It continuously and automatically identifies all your streaming data</p></li><li><p> <!-- -->It works across any data serialization format</p></li><li><p> <!-- -->It enables your team to mask and protect all <a href="https://help.lenses.io/using-lenses/data/data-policies/">sensitive data</a>.</p></li></ul><p><img src="https://images.ctfassets.net/tnuaj0t7r912/7BkMWioUDyPJTjE08BZ25P/f8bf542b6892bc0551133aeac7ae6a66/lenses.io_4.0_data_policies.gif" alt="lenses.io 4.0 data policies - data masking for Apache Kafka"></p><p>Lenses not only provides a Google Search experience over streaming data, but also a Google Maps experience. </p><p>In addition to monitoring your pipelines (Kafka Connect, Flink, Spark Streaming etc.) and your microservices<b>,</b> Lenses will highlight which applications are consuming or producing such “sensitive” data.</p><p>Next, we’ll explain the thought process and key principles behind our real-time Data Catalog.</p><h3>Like Google but for Apache Kafka metadata

</h3><p>Building a real-time Data Catalog was a natural progression for our team. We’ve been giving visibility into Apache Kafka environments and applications that run on Kafka for years.&nbsp;&nbsp;</p><p>This was mainly developed to help engineers gain insight into their Kafka streams. Very useful when it came to debugging applications and inspecting message payload with SQL, partitioning information, overseeing infrastructure health or viewing consumer lag.</p><h3>It all starts with SQL
</h3><p>The SQL engine to explore topic data is particularly important. </p><p>To understand the data and its structure we connected to an AVRO schema registry or deserialized proprietary messages. This meant we had visibility into the metadata and payload of all data sitting in Kafka.</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/3H4HgRJRB2kIecDBxWrloU/be23f75b16a743698c0224577526af79/_Blog_-Data-Catalog---4.0-release---Alternative.jpg" alt="Lenses.io data catalog for Apache Kafka architecture"></p><p>
Last year we extended the capabilities to explore data in Elasticsearch with the same SQL engine and built a framework to connect to multiple different data stores in the future: Postgres, Redis, Cassandra.&nbsp;</p><p>We also register stream processing applications that run on our <a href="https://docs.lenses.io/4.0/sql/">streaming SQL engine</a> over Kubernetes.&nbsp;&nbsp;</p><p>We allow developers to register their external applications either as a REST endpoint or with a client for JVM-based applications.&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/VoX7OrBtso7pnE7dh66T5/d773f7955ba1d66ca978402f26ae8eb9/lenses-api-docs-external-apps.png" alt="Lenses API docs external apps"></p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/3iy2qCN9vTVzNpf5rDkwV6/6b1caba28603be4dc8680fc8f5670a01/topology-client-properties.png" alt="topology-client-properties"></p><p>This builds us an App Catalog and a Topology of all the dependencies between different flows and applications. Allowing us to build the data lineage of different data sets.&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/1tYvPfHqG2xHjfo7NfpVZ1/7394b4b2e3f409c1c12ff8c07b85fde6/_Blog_-Data-Catalog---4.0-release---Alternative_01.jpg" alt="Apache Kafka pipeline topology and data lineage lenses.io"></p><p>It also allows us to answer a few important questions:</p><ul><li><p> <!-- -->What applications generated this data?</p></li><li><p> <!-- -->How much can I trust the quality of the data and at what service levels?</p></li><li><p> <!-- -->What downstream applications consume this data to understand service disruption impact?</p></li></ul><p>The Topology, App Catalog and SQL Engine therefore give us the ability to maintain a metadata catalog of data flowing across a data platform.&nbsp;</p><p>Most importantly, this data is updated automatically and in real-time. </p><p>As engineering teams develop a new product, whether it be a consumer-facing microservice application or data processing pipeline, the data and topology will be discovered automatically, including payload and all metadata.&nbsp;&nbsp;</p><p>Or if an application writes to an Elasticsearch index, that too will automatically be picked up.</p><p>No need to manually maintain a catalog.&nbsp;</p><p>This information can then be presented and found in a free-text search fashion a la Google:&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/6xN1yqyFKhCyNTlik17Vb/caa0832fc2c1061daf9767bfd3823b73/image__25_.png" alt="Lenses.io - real time data catalog - searching metadata in Apache Kafka and Elasticsearch"></p><p>The catalog is protected with the same unified namespace-based security model that protects all data access in Lenses.&nbsp;</p><p>It opens up new use cases around how data can be accessed and drastically reduces the time or the duplicate effort compared to current methods of finding data.&nbsp;</p><p>Here are two examples.&nbsp;</p><h3>1. Scoping a new project
</h3><p>A business analyst is able to scope the feasibility of a new innovative stock management application by exploring what data can be used across multiple different lines of business, including service levels, quality and compliance requirements.</p><p>The analyst starts typing keywords such as <i>stock*</i> to find all metadata (indexes, documentation, field names, streamings) and generating applications that match.&nbsp;</p><p>They can drill down to the payload to explore the data or view in the context of a topology to understand upstream and downstream applications connected to the data. An analyst can only view data they have been granted access to, and/or may have certain sensitive fields masked in accordance with compliance requirements.&nbsp;</p><h3>2. Data access audit</h3><p>
An auditor needs to explore all data entities holding possible password information. </p><p>The auditor saves themselves weeks of data gathering and manual reporting by searching <i>pass*</i> to find all entities. They validate the Lenses user group namespaces for these entities to understand which users have access and understands the applications processing this information via a Topology.&nbsp;</p><p>This same process can help meet any number of compliance controls including GDPR, HIPPA, SOX, SEC and PCI.&nbsp;</p><p>You can try out these use cases (or your own) by exploring our real-time data catalog for free in a sandbox environment at <a href="https://portal.lenses.io/">portal.lenses.io</a> or see all deployment options at <a href="https://lenses.io/start">lenses.io/start</a></p></div></div>]]>
            </description>
            <link>https://lenses.io/blog/2020/07/data-dump-real-time-data-catalog-apache-kafka/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049235</guid>
            <pubDate>Tue, 10 Nov 2020 18:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Upgrade WSL/WSL2 Ubuntu Version to 20.04 LTS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049073">thread link</a>) | @flipchart
<br/>
November 10, 2020 | https://vivekdhami.com/learnings/upgrade-wslwsl2-ubuntu-version-to-20.04-lts/ | <a href="https://web.archive.org/web/*/https://vivekdhami.com/learnings/upgrade-wslwsl2-ubuntu-version-to-20.04-lts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
  
  <p><time datetime="2020-05-01T00:00:00Z">Fri, May 1, 2020</time></p><p>Its the time of the year again to upgrade Ubuntu version in WSL/WSL2 since the Ubuntu 20.04 LTS came out last week.</p>

<p>Please follow along the following steps in your WSL console to upgrade to the new version:</p>

<ul>
<li>Check installed Ubuntu version</li>
</ul>

<p>Take a note of your current Ubuntu version by running the following command:</p>
<div><pre><code data-lang="html">  No LSB modules are available.
  Distributor ID: Ubuntu
  Description:    Ubuntu 18.04.4 LTS
  Release:        18.04
  Codename:       bionic</code></pre></div>
<p>**<em>Upgrading to 20.04 should work seamlessly when upgrading from 18.04. However if you are on older versions then the suggested path should be upgrading first to 18.04 from 16.04 for example.</em></p>

<ul>
<li>Upgrade installed packages</li>
</ul>
<div><pre><code data-lang="bash">  sudo apt update
  sudo apt list --upgradable
  sudo apt upgrade</code></pre></div>
<ul>
<li>Remove unused packages</li>
</ul>
<div><pre><code data-lang="bash">  sudo apt --purge autoremove</code></pre></div>
<ul>
<li>Install update-manager-core package if not already installed</li>
</ul>
<div><pre><code data-lang="bash">  sudo apt install update-manager-core</code></pre></div>
<ul>
<li>Upgrade to 20.04</li>
</ul>

<p>If you receive the following message:</p>
<div><pre><code data-lang="html">  Checking for a new Ubuntu release
  There is no development version of an LTS available.
  To upgrade to the latest non-LTS develoment release 
  set Prompt=normal in /etc/update-manager/release-upgrades.</code></pre></div>
<p>Then do an upgrade forcefully using the following command:</p>
<div><pre><code data-lang="bash">  sudo <span>do</span>-release-upgrade -d</code></pre></div>
<ul>
<li>Finally check the version after upgrade is done:</li>
</ul>

<p>and you should receive the following similar output:</p>
<div><pre><code data-lang="html">  No LSB modules are available.
  Distributor ID: Ubuntu
  Description:    Ubuntu 20.04 LTS
  Release:        20.04
  Codename:       focal</code></pre></div>
</div>


    </div></div>]]>
            </description>
            <link>https://vivekdhami.com/learnings/upgrade-wslwsl2-ubuntu-version-to-20.04-lts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049073</guid>
            <pubDate>Tue, 10 Nov 2020 18:13:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Six of JavaScript's Biggest Design Flaws]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048950">thread link</a>) | @samwinter
<br/>
November 10, 2020 | https://thecarrots.io/blog/javascript-wtf-six-of-the-languages-gravest-design-flaws | <a href="https://web.archive.org/web/*/https://thecarrots.io/blog/javascript-wtf-six-of-the-languages-gravest-design-flaws">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>🥕 Join the Carrots community</p><p>We’re a hiring platform for software engineers. Our algorithm shows where you rank among world class talent and surfaces you to top companies.</p></div></div>]]>
            </description>
            <link>https://thecarrots.io/blog/javascript-wtf-six-of-the-languages-gravest-design-flaws</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048950</guid>
            <pubDate>Tue, 10 Nov 2020 18:04:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Million Dollar Hackathon Winner: ‘VC Robot’]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048932">thread link</a>) | @npguy
<br/>
November 10, 2020 | https://doublespend.io/2020/10/29/million-dollar-hackathon-winner-vc-robot/ | <a href="https://web.archive.org/web/*/https://doublespend.io/2020/10/29/million-dollar-hackathon-winner-vc-robot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
<article id="post-542">
	
				<p><a href="https://doublespend.io/wp-content/uploads/2020/10/robot.jpg"><img width="800" height="445" src="https://doublespend.io/wp-content/uploads/2020/10/robot-800x445.jpg" alt="" loading="lazy" srcset="https://doublespend.io/wp-content/uploads/2020/10/robot.jpg 800w, https://doublespend.io/wp-content/uploads/2020/10/robot-300x167.jpg 300w, https://doublespend.io/wp-content/uploads/2020/10/robot-768x427.jpg 768w" sizes="(max-width: 800px) 100vw, 800px"></a>
								</p>
			
	<div>

		
		

		
		<div>
			
<p>A team of Stanford students won the million dollar prize in the final round of the nationwide hackathon competition, for developing a stunning fully functional robot, called the ‘VC Robot’ in just 48 hours.</p>



<p>The judges and audience were all stunned during the demo of the winning entry – as the VC Robot made an entry on stage, with an iPad in hand and a smile that nobody could decrypt. The Stanford team had selected two scenes for the demo: a ‘Monday morning’ VC pitch meeting and a board meeting.</p>



<p>In the Monday morning VC pitch meeting, the VC Robot stunned the judges with an impeccable performance – never taking his eyes off his iPad for the whole duration of the pitch. Within 10 seconds of the pitch, the VC Robot suddenly blurted out “How do you plan to get to product-market fit?”. It then walked out of the room during the pitch, taking a phone call. When the VC Robot entered the room after a good minute or so, it looked at the entrepreneur and asked him “Why now, and Why you?”. As the entrepreneur ended the presentation, the VC Robot asked him “Who else is in? How many paying customers do you have?” and ended the meeting with “This sounds exciting. We’ll be in touch”. </p>



<p>The board meeting was a quick demo, with the VC Robot dialing into the call with coffee and bagels in hand. The Stanford team had kept this one very simple, with the VC Robot asking the following questions in five-minute intervals – “what is the ideal business model for our company?”, “can we be in two businesses at the same time?”, “do we need to build, own, and operate our payments system to be successful long term?”, and “can we build a sustainable business long term operating solely on Facebook?”. The VC Robot also won huge applause for the way it handled the iPad, the phone, coffee and bagels all at the same time.</p>



<p>The Stanford team plans to spend the million dollars on testing commercial viability of the VC Robot technology.</p>
		</div>

	</div>

	</article>

		</div></div>]]>
            </description>
            <link>https://doublespend.io/2020/10/29/million-dollar-hackathon-winner-vc-robot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048932</guid>
            <pubDate>Tue, 10 Nov 2020 18:03:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoid Else, Return Early (2013)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048842">thread link</a>) | @generichuman
<br/>
November 10, 2020 | https://blog.timoxley.com/post/47041269194/avoid-else-return-early | <a href="https://web.archive.org/web/*/https://blog.timoxley.com/post/47041269194/avoid-else-return-early">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
                        
                            
                        
        				
                        
                        <h3>tldr;</h3><ul><li>Return as soon as you know your method cannot do any more meaningful work</li><li>Reduce indentation by using <code>if/return</code> instead of a top-level <code>if/else</code></li><li>Try keep the “meat” of your method at the lowest indentation level.</li><li>Error handling is noise.</li></ul><hr><p>Programmers are often taught to have a ‘single exit point’ in their methods,
i.e. only return from a single location.</p><pre><code>
function () {
  var result;

  if () {
    result = x
  } else {
    if () {
      result = y
    } else {
      result = z
    }
  }

  return result // this return is single and lonely
}

</code></pre><p>This is a poor guideline in my opinion:</p><ul><li>“assign a result” doesn’t explain the intent: “this is the final value, processing stops here”</li><li>Leaves question open “is the result object finished? can it be modified? by whom?”</li><li>Allows accidental modification of the result</li><li>Encourages “happy path” to be wrapped in one or more if/else statements</li></ul><h3>Example if/else refactoring</h3><p>Consider this typical node callback code:</p><pre><code>
function(err, results) {
  if (!err) {
    doOtherStuff()
    doMoreStuff()
    // ... etc
    // ... etc
  } else {
    handleError(err)
  }
}
</code></pre><p>There’s a few problems here. First, our error handling is dangling off the end of the method. If the “happy path” is many lines long, it can easily become unclear what the <code>else</code> even refers to.</p><p>Let’s try keep the “meat” of the code at the bottom of the method, and keep any special cases together at the top:</p><pre><code>
function(err, results) {
  if (err) {
    handleError(err)
  } else {
    doOtherStuff()
    doMoreStuff()
    // ... etc
    // ... etc
  
  }
}
</code></pre><p><a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fcallbackhell.com%2F&amp;t=MjBmYmZhZDAyYzAyMWE5NzJjY2E4Njg1MmIyYjNiYzdlYjA2YjUzMixQcjBHSTJVWg%3D%3D&amp;b=t%3AxntNe-nPZGsWC3-V_vsCGA&amp;p=https%3A%2F%2Fblog.timoxley.com%2Fpost%2F47041269194%2Favoid-else-return-early&amp;m=1&amp;ts=1605241384">It’s very easy to get unweildy levels of indentation in JavaScript</a>,
so we should strive to reduce any unnecessary
nesting.</p><p>In this case, we can remove the <code>else</code> indentation around
our “happy path” by replacing the <code>else</code> with a return:</p><pre><code>
function(err, results) {
  if (err) {
    handleError(err)
    return
  }

  doOtherStuff()
  doMoreStuff()
  // ... etc
  // ... etc
}
</code></pre><p>Not only does this unindent a bunch of code, it also moves the
method’s main purpose/intention/meat to indentation level 0.</p><p>We often don’t care about return values in non-promise-based async JS, so we can
futher compact the method vertically by putting the <code>return</code> first,
removing a whole line and more braces:</p><pre><code>
function(err, results) {
  if (err) return handleError(err)

  doOtherStuff()
  doMoreStuff()
  // ... etc
  // ... etc
}
</code></pre><p><em>2018 edit</em>: To more clearly signal that the return value is unimportant you can use the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FJavaScript%2FReference%2FOperators%2Fvoid&amp;t=NzAwZTA2NzVmMjA1MDgzNzBmODE5NzdjZmVmMDJjMjIzMmM2YTk5MSxQcjBHSTJVWg%3D%3D&amp;b=t%3AxntNe-nPZGsWC3-V_vsCGA&amp;p=https%3A%2F%2Fblog.timoxley.com%2Fpost%2F47041269194%2Favoid-else-return-early&amp;m=1&amp;ts=1605241384">void operator</a>:</p><pre><code>
function(err, results) {
  if (err) return void handleError(err)
  // ...
}
</code></pre><p>It also obeys the “one logical statement per line” guideline,
compacting the error detection and handling noise to a
single line.</p><p>Another benefit is that the <code>return</code> keyword is generally syntax highlighted, so all exit points become very clear, as opposed to hidden inside <code>result = something</code> assignments.</p><p>This final form has:</p><ul><li>Method at lowest indentation level</li><li>No unecessary indentation.</li><li>Many fewer lines</li></ul><p>Rebecca Murphey has also <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Frmurphey.com%2Fblog%2F2012%2F12%2F10%2Fjs-conditionals%2F&amp;t=ZWNhZTNjY2IxZTAwZjNlZDYzMDc1NTY1YTQwMDVhZDY0OTQ5NTBkOCxQcjBHSTJVWg%3D%3D&amp;b=t%3AxntNe-nPZGsWC3-V_vsCGA&amp;p=https%3A%2F%2Fblog.timoxley.com%2Fpost%2F47041269194%2Favoid-else-return-early&amp;m=1&amp;ts=1605241384">written about this</a></p><p>The end.</p><hr><p><em>2018 edit</em>: As with any programming practice, one shouldn’t see this as a hard rule that must be obeyed at all times. Early returns make little difference for small functions, and may even increase the cognitive load. However, I find the logic-flattening benefits of early returns become increasingly compelling as the size and complexity of a function increases.</p><p>Lots of discussion about this post:</p><ul><li><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fnews.ycombinator.com%2Fitem%3Fid%3D16678209&amp;t=MDNmY2NhZWIyZTkxMmQ1NjZlZTc0ZWFiNmVjNGY1NTk3Y2RkMjY3NCxQcjBHSTJVWg%3D%3D&amp;b=t%3AxntNe-nPZGsWC3-V_vsCGA&amp;p=https%3A%2F%2Fblog.timoxley.com%2Fpost%2F47041269194%2Favoid-else-return-early&amp;m=1&amp;ts=1605241384">HackerNews</a>.</li><li><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.reddit.com%2Fr%2Fprogramming%2Fcomments%2F878zi2%2Favoid_else_return_early%2F&amp;t=ZGY1YzkwNzY4ODZlODVlM2Y3MmMzMjJiNDZjYjlkODVjZmZkZjYxMCxQcjBHSTJVWg%3D%3D&amp;b=t%3AxntNe-nPZGsWC3-V_vsCGA&amp;p=https%3A%2F%2Fblog.timoxley.com%2Fpost%2F47041269194%2Favoid-else-return-early&amp;m=1&amp;ts=1605241384">Reddit</a></li></ul>
						
						
                </div></div>]]>
            </description>
            <link>https://blog.timoxley.com/post/47041269194/avoid-else-return-early</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048842</guid>
            <pubDate>Tue, 10 Nov 2020 17:56:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Corporate Private Jet Tracker]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048723">thread link</a>) | @greatwave1
<br/>
November 10, 2020 | https://www.quiverquant.com/sources/corporateflights?hn= | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/sources/corporateflights?hn=">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="myTable">
 <tbody>
    <tr>
	    <th>Company</th>
            <th onclick="">Departure time</th>
	    <th onclick="">Departure city</th>
	    <th onclick="">Arrival city</th>
          </tr>
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/AXP">AXP</a></td>
            <td>Nov. 11, 2020, 4:43 p.m.</td>
	    <td>Oshkosh</td>
	    <td>Appleton</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/HD">HD</a></td>
            <td>Nov. 11, 2020, 4:20 p.m.</td>
	    <td>Dallas-Fort Worth</td>
	    <td>Atlanta</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/AXP">AXP</a></td>
            <td>Nov. 11, 2020, 4:13 p.m.</td>
	    <td>Milwaukee</td>
	    <td>Oshkosh</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/SENEA">SENEA</a></td>
            <td>Nov. 11, 2020, 3:52 p.m.</td>
	    <td>Trenton</td>
	    <td>Penn Yan</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/AXP">AXP</a></td>
            <td>Nov. 11, 2020, 3:40 p.m.</td>
	    <td>Appleton</td>
	    <td>Milwaukee</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 11, 2020, 3:27 p.m.</td>
	    <td>Ontario</td>
	    <td>Seattle</td>
          </tr>
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 11, 2020, 1:57 p.m.</td>
	    <td>Holt</td>
	    <td>Detroit</td>
          </tr>
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/HFC">HFC</a></td>
            <td>Nov. 11, 2020, 1:02 p.m.</td>
	    <td>Dallas</td>
	    <td>Dallas</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CNI">CNI</a></td>
            <td>Nov. 11, 2020, 1 p.m.</td>
	    <td>Toronto</td>
	    <td>MontrÃ©al</td>
          </tr>
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/PFE">PFE</a></td>
            <td>Nov. 11, 2020, 12:21 p.m.</td>
	    <td>Teterboro</td>
	    <td>Trenton</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/VFC">VFC</a></td>
            <td>Nov. 11, 2020, 12:11 p.m.</td>
	    <td>Santa Ana</td>
	    <td>Pittsburgh</td>
          </tr>
	  
          
	  
          
	  
          
	  
          
	  
          
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/HUM">HUM</a></td>
            <td>Nov. 11, 2020, 9:31 a.m.</td>
	    <td>Tampa</td>
	    <td>Louisville</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CNI">CNI</a></td>
            <td>Nov. 11, 2020, 9:23 a.m.</td>
	    <td>Calgary</td>
	    <td>Toronto</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/VFC">VFC</a></td>
            <td>Nov. 11, 2020, 9:17 a.m.</td>
	    <td>Denver</td>
	    <td>Santa Ana</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/PFE">PFE</a></td>
            <td>Nov. 11, 2020, 9:11 a.m.</td>
	    <td>Miami</td>
	    <td>Teterboro</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 11, 2020, 8:47 a.m.</td>
	    <td>San Diego</td>
	    <td>Riverside/Rubidoux/</td>
          </tr>
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/HD">HD</a></td>
            <td>Nov. 11, 2020, 7:28 a.m.</td>
	    <td>Atlanta</td>
	    <td>Dallas-Fort Worth</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CP">CP</a></td>
            <td>Nov. 11, 2020, 7:09 a.m.</td>
	    <td>Minneapolis</td>
	    <td>Bloomington/Normal</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/SENEA">SENEA</a></td>
            <td>Nov. 11, 2020, 7:03 a.m.</td>
	    <td>Janesville</td>
	    <td>Penn Yan</td>
          </tr>
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/HUM">HUM</a></td>
            <td>Nov. 11, 2020, 6:45 a.m.</td>
	    <td>Louisville</td>
	    <td>Los Angeles</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 11, 2020, 6:21 a.m.</td>
	    <td>Washington</td>
	    <td>Ottawa</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/PFE">PFE</a></td>
            <td>Nov. 11, 2020, 6:17 a.m.</td>
	    <td>Trenton</td>
	    <td>Miami</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 11, 2020, 2:42 a.m.</td>
	    <td>Manassas</td>
	    <td>Reading</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 11, 2020, 2:14 a.m.</td>
	    <td>Baltimore</td>
	    <td>Wernersville</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 11, 2020, 1:43 a.m.</td>
	    <td>Reading</td>
	    <td>Manassas</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 11, 2020, 1 a.m.</td>
	    <td>Teterboro</td>
	    <td>Reading</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 11, 2020, 12:58 a.m.</td>
	    <td>Manassas</td>
	    <td>Baltimore</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 11, 2020, 12:02 a.m.</td>
	    <td>Worcester</td>
	    <td>Teterboro</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 11:55 p.m.</td>
	    <td>Pittsburgh</td>
	    <td>Manassas</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 10:31 p.m.</td>
	    <td>Niagara Falls</td>
	    <td>Pittsburgh</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 10:08 p.m.</td>
	    <td>Reading</td>
	    <td>Worcester</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 9:50 p.m.</td>
	    <td>Rochester</td>
	    <td>Niagara Falls</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/UAA">UAA</a></td>
            <td>Nov. 10, 2020, 9:49 p.m.</td>
	    <td>Portsmouth</td>
	    <td>Baltimore</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 9:18 p.m.</td>
	    <td>Syracuse</td>
	    <td>Rochester</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 8:40 p.m.</td>
	    <td>Montour Falls</td>
	    <td>Syracuse</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 7:47 p.m.</td>
	    <td>Reading</td>
	    <td>Troy</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/UAA">UAA</a></td>
            <td>Nov. 10, 2020, 7:42 p.m.</td>
	    <td>Madison</td>
	    <td>Portsmouth</td>
          </tr>
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/UAA">UAA</a></td>
            <td>Nov. 10, 2020, 5:47 p.m.</td>
	    <td>Dallas</td>
	    <td>Madison</td>
          </tr>
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CP">CP</a></td>
            <td>Nov. 10, 2020, 4:18 p.m.</td>
	    <td>Calgary</td>
	    <td>Minneapolis</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/NEE">NEE</a></td>
            <td>Nov. 10, 2020, 4:17 p.m.</td>
	    <td>Milton</td>
	    <td>Belle Glade</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/NEE">NEE</a></td>
            <td>Nov. 10, 2020, 4:17 p.m.</td>
	    <td>Milton</td>
	    <td>Belle Glade</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 4:10 p.m.</td>
	    <td>Westhampton Beach</td>
	    <td>Centreville</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 4:10 p.m.</td>
	    <td>Westhampton Beach</td>
	    <td>Centreville</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/TGT">TGT</a></td>
            <td>Nov. 10, 2020, 4:09 p.m.</td>
	    <td>Dallas-Fort Worth</td>
	    <td>Minneapolis</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/TGT">TGT</a></td>
            <td>Nov. 10, 2020, 4:09 p.m.</td>
	    <td>Dallas-Fort Worth</td>
	    <td>Minneapolis</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CNI">CNI</a></td>
            <td>Nov. 10, 2020, 4:03 p.m.</td>
	    <td>Toronto</td>
	    <td>Calgary</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/TGT">TGT</a></td>
            <td>Nov. 10, 2020, 3:19 p.m.</td>
	    <td>Dallas</td>
	    <td>Panama City Beach</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/TGT">TGT</a></td>
            <td>Nov. 10, 2020, 3:19 p.m.</td>
	    <td>Dallas</td>
	    <td>Panama City Beach</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/HUM">HUM</a></td>
            <td>Nov. 10, 2020, 3:12 p.m.</td>
	    <td>Louisville</td>
	    <td>Lutz</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/HUM">HUM</a></td>
            <td>Nov. 10, 2020, 3:12 p.m.</td>
	    <td>Louisville</td>
	    <td>Lutz</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 3 p.m.</td>
	    <td>Syracuse</td>
	    <td>Riverhead</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 3 p.m.</td>
	    <td>Syracuse</td>
	    <td>Riverhead</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CNI">CNI</a></td>
            <td>Nov. 10, 2020, 2:51 p.m.</td>
	    <td>MontrÃ©al</td>
	    <td>Toronto</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CNI">CNI</a></td>
            <td>Nov. 10, 2020, 2:51 p.m.</td>
	    <td>MontrÃ©al</td>
	    <td>Toronto</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CTAS">CTAS</a></td>
            <td>Nov. 10, 2020, 2:45 p.m.</td>
	    <td>Indianapolis</td>
	    <td>Cincinnati</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/CTAS">CTAS</a></td>
            <td>Nov. 10, 2020, 2:45 p.m.</td>
	    <td>Indianapolis</td>
	    <td>Cincinnati</td>
          </tr>
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/BNS">BNS</a></td>
            <td>Nov. 10, 2020, 1:57 p.m.</td>
	    <td>MontrÃ©al</td>
	    <td>Toronto</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/BNS">BNS</a></td>
            <td>Nov. 10, 2020, 1:57 p.m.</td>
	    <td>MontrÃ©al</td>
	    <td>Toronto</td>
          </tr>
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 1:21 p.m.</td>
	    <td>Livermore</td>
	    <td>San Diego</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 1:21 p.m.</td>
	    <td>Livermore</td>
	    <td>San Diego</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/D">D</a></td>
            <td>Nov. 10, 2020, 1:16 p.m.</td>
	    <td>Akron</td>
	    <td>Ashland</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/D">D</a></td>
            <td>Nov. 10, 2020, 1:16 p.m.</td>
	    <td>Akron</td>
	    <td>Ashland</td>
          </tr>
	  
          
	  
          
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/TGT">TGT</a></td>
            <td>Nov. 10, 2020, 11:51 a.m.</td>
	    <td>Minneapolis</td>
	    <td>Dallas-Fort Worth</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/TGT">TGT</a></td>
            <td>Nov. 10, 2020, 11:51 a.m.</td>
	    <td>Minneapolis</td>
	    <td>Dallas-Fort Worth</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 10:37 a.m.</td>
	    <td>Rochester</td>
	    <td>Syracuse</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 10:37 a.m.</td>
	    <td>Rochester</td>
	    <td>Syracuse</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 10:12 a.m.</td>
	    <td>Manassas</td>
	    <td>Reading</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 10:12 a.m.</td>
	    <td>Manassas</td>
	    <td>Reading</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 10:03 a.m.</td>
	    <td>Seattle</td>
	    <td>Chicago/Romeoville</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 10:03 a.m.</td>
	    <td>Seattle</td>
	    <td>Chicago/Romeoville</td>
          </tr>
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/RF">RF</a></td>
            <td>Nov. 10, 2020, 9:25 a.m.</td>
	    <td>Baltimore</td>
	    <td>Pinson</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/RF">RF</a></td>
            <td>Nov. 10, 2020, 9:25 a.m.</td>
	    <td>Baltimore</td>
	    <td>Pinson</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 8:59 a.m.</td>
	    <td>Pittsburgh</td>
	    <td>Manassas</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 8:59 a.m.</td>
	    <td>Pittsburgh</td>
	    <td>Manassas</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 8:10 a.m.</td>
	    <td>Seattle</td>
	    <td>Livermore</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, 2020, 8:10 a.m.</td>
	    <td>Seattle</td>
	    <td>Livermore</td>
          </tr>
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 7:44 a.m.</td>
	    <td>Independence</td>
	    <td>Pittsburgh</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/DGX">DGX</a></td>
            <td>Nov. 10, 2020, 7:44 a.m.</td>
	    <td>Independence</td>
	    <td>Pittsburgh</td>
          </tr>
	  
          
	  
          
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/BNS">BNS</a></td>
            <td>Nov. 10, 2020, 7:23 a.m.</td>
	    <td>Toronto</td>
	    <td>MontrÃ©al</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/BNS">BNS</a></td>
            <td>Nov. 10, 2020, 7:23 a.m.</td>
	    <td>Toronto</td>
	    <td>MontrÃ©al</td>
          </tr>
	  
          
	  
          <tr>
	    <td><a href="https://www.quiverquant.com/dashboard/COST">COST</a></td>
            <td>Nov. 10, …</td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.quiverquant.com/sources/corporateflights?hn=">https://www.quiverquant.com/sources/corporateflights?hn=</a></em></p>]]>
            </description>
            <link>https://www.quiverquant.com/sources/corporateflights?hn=</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048723</guid>
            <pubDate>Tue, 10 Nov 2020 17:47:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rev.ng decompiler nightly builds have been released]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048645">thread link</a>) | @agiantleap
<br/>
November 10, 2020 | https://rev.ng/blog/the-road-ahead/post.html | <a href="https://web.archive.org/web/*/https://rev.ng/blog/the-road-ahead/post.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

<p>In this blog post we will briefly describe today's release, provide an overview of the components of rev.ng and introduce you the next steps the rev.ng project intends to take towards the 1.0 release.</p>
<p>We are inviting small groups of people to get access to nightly builds.
If you already registered, be patient and monitor our <a href="https://twitter.com/_revng">Twitter account</a>. Otherwise, <a href="https://rev.ng/register-for-nightly.html">register now</a>.</p>
<h2>Nightly builds release</h2>
<p>Today, we start releasing nightly builds of all the rev.ng components including <code>revng</code> (binary lifter and translator), <code>revng-c</code> (the decompiler) and <code>cold-revng</code> (the user interface).</p>
<p>rev.ng is an ambitious project which took the long route in several aspects.
We think this will prove to be a winning strategy to build an innovative product.</p>
<p>We're now starting to see the end of the tunnel that leads us to become a mature tool for binary analysis, but we're not there yet.
Nightly builds are our way to invite you to join us along the last mile of the journey.</p>
<h3>What to expect</h3>
<p>rev.ng can currently handle binaries compiled for Linux targeting x86-64, i386, ARM, AArch64, MIPS and SystemZ.
Here's a few things you can do with the current release.</p>
<h4>1. Try out the UI using test files</h4>
<p>The package we distribute includes a set of pre-lifted files.
You can open them in the UI right away.</p>
<div><pre><span></span><span>EXAMPLES</span><span>=</span>root/share/revng/qa/tests/runtime/x86_64/abi-enforced-for-decompilation
./revng ui <span>$EXAMPLES</span>/calc.bc
</pre></div>
<video controls="controls" width="945">
<source src="https://rev.ng/downloads/calc.mp4" type="video/mp4">
</video>
          
          
            <h4>2. Lift, translate and run ls</h4>
<p>You can also give a try to the binary translator.
For instance, you can lift <a href="https://rev.ng/downloads/ls-ubuntu-16.04"><code>ls</code></a> to LLVM IR, recompile it, and run it again:</p>
<div><pre><span></span>wget <span>'https://rev.ng/downloads/ls-ubuntu-16.04'</span>
chmod +x ls-ubuntu-16.04
./ls-ubuntu-16.04 --color<span>=</span>always -lhn
./revng translate ls-ubuntu-16.04
./ls-ubuntu-16.04.translated --color<span>=</span>always -lhn
</pre></div>

<p>Please note that translation support for non-x86-64 input architectures is working but has some limitations.</p>
<h4>3. Decompile ls</h4>
<p>The rev.ng UI also provides a wizard for decompilation.</p>
<video controls="controls" width="945">
<source src="https://rev.ng/downloads/ls.mp4" type="video/mp4">
</video><h3>What not to expect</h3>
<p>The builds are to be considered unstable and under heavy development, therefore keep in mind to:</p>
<ol>
<li>read the <code>README.md</code>
</li>
<li>perform frequent updates</li>
<li>expect suboptimal decompiled code and crashes</li>
<li>report anything unexpected/slow</li>
<li>expect rapid improvements</li>
</ol>
<p>For those, who have access to the nightly builds, the <a href="https://github.com/revng/help">revng/help</a> repository will contain a shortlist of known issues we're working on.</p>
<h2>Overview of the rev.ng components</h2>
<p>rev.ng is divided in several components, some of them are open source.</p>
<p>Let's start with the ones we forked from existing projects:</p>
<ul>
<li>
<code>qemu</code>: our fork provides a dynamic library able to produce tiny code instructions from a raw sequence of bytes.</li>
<li>
<code>llvm</code>: our LLVM 10 fork with minor changes.</li>
<li>
<code>qtcreator</code>: the base of our UI.</li>
</ul>
<p>The following projects are the open source parts of the rev.ng project:</p>
<ul>
<li>
<code>revng</code>. The core of rev.ng: the binary lifter and translator. Given a binary program, it lifts to tiny code instructions and then to LLVM IR. Produces an LLVM module, and, optionally recompiles it.</li>
<li>
<code>orchestra</code>. Our almighty meta-build system. It handles all the dependencies for you, fetches them from our binary archives or builds them from source. Don't try to build rev.ng by yourself, use <code>orchestra</code>.</li>
<li>
<code>revng-qa</code>. A repository for our test programs.</li>
</ul>
<p>The following projects will be released under a commercial license and are currently released as binaries only:</p>
<ul>
<li>
<code>revng-c</code>. Takes <code>revng</code> output and decompiles it to C.</li>
<li>
<code>caliban</code>. A project providing an API to perform high-level actions on binaries, on top of which the UI and, in the future, our scripting engine are built.</li>
<li>
<code>cold-revng</code>. The UI, a QtCreator plugin.</li>
</ul>
<h2>Roadmap towards the release</h2>
<p>In the following, we report a list of tasks to accomplish and components to develop/finalize in order to get to the final release.
You can expect one or more blog posts or some other form of publication for each item.</p>
<ul>
<li>
 Release the nightly builds</li>
<li>
 Create a <a href="https://github.com/revng/help">GitHub repository</a> to support nightly builds' users</li>
<li>
 Completely move the development of open source projects to GitHub</li>
<li>Requirements for tagging the beta:<ul>
<li>
 CFG combing</li>
<li>
 Improved ABI Analysis</li>
<li>
 Type Shrinking Analysis</li>
<li>
 Data Layout Analysis</li>
<li>
 Value Manipulation Analysis</li>
<li>
 Define a <em>data model</em> for the analyzed program and how to change it</li>
<li>
 Identify libraries using strings (BigMatch)</li>
<li>
 Full PE/COFF and Mach-O support</li>
</ul>
</li>
<li>Requirements for tagging the 1.0 release:<ul>
<li>
 Improve UI/UX</li>
<li>
 Python scripting engine</li>
<li>
 Windows and macOS port</li>
<li>
 Import C headers and debug information</li>
<li>
 Compatibility layer</li>
<li>
 Support for packers/self-modifying code</li>
<li>
 Support remote processing</li>
</ul>
</li>
</ul>
<h2>Conclusions</h2>
<p>We'd like to thank everyone who is participating in the nightly builds programme.
Your feedback will help us along the way towards the final release.</p>
<p>Releasing nightly builds, along with switching to a fully open air development of the open source components, is part of our effort to spread the word and collect feedback.
Our ultimate goal is to build a robust community to engage with and to grow a flourishing ecosystem of software based on rev.ng binary analysis framework.</p>
<p>Also, a shout-out to all those who put their hard work in order to make this first public release finally possible, in particular Pietro, <a href="https://twitter.com/carpikes">Alain</a>, <a href="https://twitter.com/fcremo">fcremo</a> and Andrea, but also all the others who contributed to spot bugs and share their opinions.</p>
<p>We hope you're excited as we are.
Enjoy!</p>
          
        </div></div>]]>
            </description>
            <link>https://rev.ng/blog/the-road-ahead/post.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048645</guid>
            <pubDate>Tue, 10 Nov 2020 17:42:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linus Torvalds' Home Office [YouTube]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048457">thread link</a>) | @bojanvidanovic
<br/>
November 10, 2020 | https://devandgear.com/posts/linus-torvalds-home-office/ | <a href="https://web.archive.org/web/*/https://devandgear.com/posts/linus-torvalds-home-office/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>When it comes to computer setups, there is one that always comes to my mind,
the setup of Linus Torvalds in the famous YouTube video <strong>“Linus Torvalds Guided
Tour of His Home Office”</strong>. The video is from 2014 with almost 300k views, and
his home office probably changed until now, but interestingly it gives
a glimpse of how one of the most influential figures in the open-source
community works.</p>
<p>One would have imagined multiple <a href="http://localhost:1314/products/categories/monitors/">monitors</a> connected together, with a bunch of
computers, and everything perfectly organized. But that’s not a case here,
Linus getting done his work on a medium-sized Dell monitor set on a walking
desk. I wasn’t expecting to see a walking desk, they are very rare to be seen,
but in theory, they are healthier than a standing desk that keeps you in
a static position. If you already own a standing desk, you can add a walking
pad to it like this <a href="https://amzn.to/38t9Ll8">one</a>, and make it a walking desk. Aside from that everything
else seems pretty normal, a clean productive space.</p>
<p>That is one side of the office, the other side of his office is a bit messy
with a bunch of hardware stacked one on top of each other, which he admits it’s
probably best to burn.</p>
<p>I’d like to see the evolution of Linus’s office, but if you don’t know he is
a very reserved person, so it will be hard. Anyway, if you haven’t seen the
video, here is the link and enjoy it.</p>



        </div></div>]]>
            </description>
            <link>https://devandgear.com/posts/linus-torvalds-home-office/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048457</guid>
            <pubDate>Tue, 10 Nov 2020 17:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Burnout can exacerbate work stress, further promoting a vicious circle]]>
            </title>
            <description>
<![CDATA[
Score 282 | Comments 181 (<a href="https://news.ycombinator.com/item?id=25048455">thread link</a>) | @rustoo
<br/>
November 10, 2020 | https://www.uni-mainz.de/presse/aktuell/12451_ENG_HTML.php | <a href="https://web.archive.org/web/*/https://www.uni-mainz.de/presse/aktuell/12451_ENG_HTML.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
            <!-- Hier kommen Imagescroller und ZGN, sowie... -->
            <!-- Offene Universität Scroller --><!-- Default Row -->
            <!-- Spaltenlayout gemäß Einstellungen für option_schalter_linke_spalte, option_schalter_rechte_spalte -->
            <!-- Ende linke Spalte -->
            <article id="spaltemitte">
               <!-- Beginn Inhalt Spalte Mitte -->
               <!-- Indexüberschrift:  -->
               <h3>
                  Work stress and burnout are mutually reinforcing / Surprisingly, the effect of work stress on burnout is much smaller than the effect of burnout on work stress
               </h3>
               <p>
                  10 November 2020
               </p>
               <p>
                  Stress and overload in the workplace are increasing worldwide and are often considered a cause of burnout. Indeed, a new study shows that work stress and burnout are mutually reinforcing. However, contrary to popular belief, burnout has a much greater impact on work stress than vice versa. "This means that the more severe a person's burnout becomes, the more stressed they will feel at work, such as being under time pressure, for example," said Professor Christian Dormann of Johannes Gutenberg University Mainz (JGU). Employees suffering from burnout should be timely provided with adequate support in order to break the vicious circle between work stress and burnout.
               </p>
               <p>
                  Symptoms of burnout include exhaustion, cynicism, and reduced performance. "The most important burnout symptom is the feeling of total exhaustion – to the extent that it cannot be remedied by normal recovery phases of an evening, a weekend, or even a vacation," said Dormann. "To protect themselves from further exhaustion, some try to build a psychological distance to their work, that is, they alienate themselves from their work as well as the people associated with it and become more cynical," added Dr. Christina Guthier. She conducted the study as part of her doctoral thesis in Dormann's research group and was awarded with the dissertation prize of the Alfred Teves Foundation in 2020. The study has recently been published in <em>Psychological Bulletin</em>.
               </p>
               <p>
                  For the joint publication with Professor Christian Dormann and Professor Manuel Völkle of Humboldt-Universität zu Berlin, Christina Guthier evaluated 48 longitudinal studies of burnout and work stress comprising 26,319 participants. The average age in the initial survey was about 42 years, 44 percent of the respondents were men. The longitudinal studies from 1986 to 2019 came from various countries, including predominantly European countries as well as Israel, the USA, Canada, Mexico, South Africa, Australia, China, and Taiwan.
               </p>
               <h4>
                  Stopping the downward spiral and reducing the effect of burnout on work stress
               </h4>
               <p>
                  The results challenge, or at least relativize, the common perception that work stress is the driving force behind burnout. "Burnout can be triggered by a work situation, but that is not always the case," Dormann pointed out. Once burnout begins, it develops only very gradually, building up slowly over time. Ultimately it leads to work being increasingly perceived as stressful: The amount of work is too much, time is too short, and work stress is too great. "When exhausted, the ability to cope with stress usually decreases. As a result, even smaller tasks can be perceived as significantly more strenuous," explained Guthier, the first author of the article. "We expected an effect of burnout on work stress; the strength of the effect was very surprising," she noted. The effect of burnout on perceived work stress can be somewhat mitigated if employees have more control over their own work and receive support from colleagues or superiors.
               </p>
               <p>
                  According to Dormann, a new research area is emerging on the basis of this unique data because the strong boomerang effect of burnout on work stress has not yet been investigated. Key questions that need to be addressed are: how can the effects of burnout on perceived work stress be reduced and how can the development of this vicious circle be prevented? Dormann and Guthier suggest that the place to start is with management behavior. Employees should have the opportunity to give feedback on their work stress at any time and be appreciated. Last but not least, proper recovery could also help to stop the downward spiral.
               </p><!-- Ende Inhalt Spalte Mitte -->
            </article>            <!--Ende-->
                     </div></div>]]>
            </description>
            <link>https://www.uni-mainz.de/presse/aktuell/12451_ENG_HTML.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048455</guid>
            <pubDate>Tue, 10 Nov 2020 17:25:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is it time to modernize the PostgreSQL Core Team?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048426">thread link</a>) | @MarkusWinand
<br/>
November 10, 2020 | https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/ | <a href="https://web.archive.org/web/*/https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <div>
                
                <div>
                    
<p>The PostgreSQL Community is large, diverse and global. There are users, enthusiasts, developers, contributors, advocates and commercial entities from around the world. All of them working in a loosely collaborative fashion to grow and make PostgreSQL succeed.</p>
<p>The Postgres Core Team is considered to be the steering committee for the Community. The definition of the group responsibilities can be <a href="https://www.postgresql.org/developer/core/">found here</a>. The core team members are listed on the <a href="https://www.postgresql.org/community/contributors/">Contributor Profiles</a> page.</p>
<p>On September 30th EnterpriseDB acquired 2ndQuadrant. At the time of the acquisition there were five members in Core; two of them were EnterpriseDB employees and another one a 2ndQuadrant employee. This meant that 60% of the Core members would be employed by EnterpriseDB. On October 20th, in an effort to diffuse concerns about a single commercial entity having majority control, the <a href="https://www.postgresql.org/about/news/statement-from-the-postgresql-core-team-on-the-edb-acquisition-of-2ndquadrant-2094/">Core Team announced</a> that this is an issue that they would be addressing:</p>
<p>“<em>There has long been an unwritten rule that there should be no more than 50% of the membership of the Core Team working for the same company</em>”</p>
<p>This rule was enacted back in the days of the <a href="https://www.postgresql.org/message-id/39181CCD.99531ADA@greatbridge.com">Great Bridge</a>. Core addressed the unwritten rule by appointing on November 2nd <a href="https://www.postgresql.org/about/news/new-postgresql-core-team-members-2103/">two new members: Andres Freund and Jonathan Katz</a>. This change in Core reduced the proportion of EnterpriseDB members to three out of seven. <strong>Fundación PostgreSQL</strong> would like to extend a very warm welcome to Andres and Jonathan. They are both well known and long time community contributors.</p>
<p>The addition of the new members allowed Core to be compliant with the 50% rule. However: was this organizational change the best choice? Was it the only change that could have been implemented? Could we have looked at the culture of our global community and used this opportunity to strengthen our ties?</p>
<p>Here are some facts about Core’s structure and membership:</p>
<ul>
<li><strong>Company influence</strong>:
<ul>
<li>Core has switched from having 40% of its members from a single company to now having 43% from a single company and 71% from two companies.</li>
<li>100% of the members are from only 4 companies.</li>
</ul>
</li>
<li><strong>Diversity</strong>:
<ul>
<li>100% of the current Core team members are white men.</li>
<li>All of the Core members are either US or European. No other region is represented.</li>
<li>All but one Core member work for US companies.</li>
</ul>
</li>
<li><strong>Democracy:</strong>
<ul>
<li>Core members are only appointed by existing Core members. In contrast, the “<a href="https://www.postgresql.org/community/recognition/#npos">Recognised Postgres Nonprofit Organisations</a>” (created and enforced by Core) has as a requirement that the “<em>board of directors MUST be elected by the membership</em>”. These rules were, in turn, created by Core itself.</li>
<li>Core members serve for an <em>unlimited</em> term. In contrast, the same Community recognition rules above also require that “<em>Lifetime directorships MUST NOT be allowed</em>”. Four of the current Core members <a href="https://web.archive.org/web/20051023004218/http://www.postgresql.org/developer/bios">have been serving in the Core team for more than 15 years</a>.</li>
</ul>
</li>
<li><strong>Transparency</strong>:
<ul>
<li>The election process, candidate selection, selection criteria, etc are all secret.</li>
<li>Core Team meeting minutes are secret.</li>
<li>Core team policies are enacted by declaration, without involvement of the global community.</li>
</ul>
</li>
</ul>
<p>Facts aside, there are some organizational concerns that may require some further analysis.</p>
<p>In the PostgreSQL distributed community, the <a href="https://www.postgresql.org/developer/core/">Core Team</a> acts as the <em>de facto</em> “central authority” for the project. The <a href="https://www.postgres.ca/">Postgres Association of Canada</a> (“CA”, in short), acts as its legal arm, holding assets (including intellectual property, like domain names and trademarks).</p>
<p>However, this presents an interesting dichotomy: Core makes decisions, but if these require a legal entity to be executed, they are executed by CA. Which has its own board of directors, that needs to approve them. What if they don’t? What if they don’t follow Core? Similarly, how is Core accountable, if it is not backed directly by a legal entity? Because of this, are there any potential liabilities faced directly by their members, as individuals? And what happens if CA’s Board goes haywire?</p>
<p>Other mature and successful open source projects, while distributed as Postgres and built from the contributions of people and organizations all around the world, are nowadays backed by clear and strong legal and organizational structure. Take for example the <a href="https://www.apache.org/foundation/">Apache Foundation</a>, or the <a href="https://www.fsf.org/working-together/fiscal-sponsorship">Free Software Foundation</a>. Or the <a href="https://www.cncf.io/">Cloud Native Computing Foundation (CNCF)</a>, which is a Charter of the Linux Foundation. Its structure <a href="https://www.cncf.io/blog/2019/12/06/cncf-toc-governance-structure-elections-2020/">has three main bodies</a>:</p>
<p>“<em>A <strong>Governing Board (GB)</strong> that is responsible for marketing, budget and other business oversight decisions for the CNCF, a <strong>Technical Oversight Committee (TOC)</strong> that is responsible for defining and maintaining the technical vision, and an <strong>End User Community (EUC)</strong> that is responsible for providing feedback from companies and startups to help improve the overall experience for the cloud native ecosystem</em>”</p>
<p>The <a href="https://www.cncf.io/people/governing-board/">Governing Board has currently 24 members</a>, and their <a href="https://www.cncf.io/about/governing-board-meeting-minutes/">meeting minutes are public</a> (they are not alone: MariaDB Foundation <a href="https://mariadb.org/bodminutes/2020-10-21/">is now publishing their board meetings too</a>); the <a href="https://www.cncf.io/people/technical-oversight-committee/">Technical Committee consists of 11 members and 77 contributors</a>; the <a href="https://docs.google.com/presentation/d/194SyKdHL7ws_DBOdbrXdowEJi54kIzDdDK_h-6Ag0uo/edit#slide=id.g9ffb40d42b_0_161">End User Community has more than 150 companies</a>; furthermore, there are dozens of <a href="https://www.cncf.io/people/ambassadors/">ambassadors</a>; and also dozens of <a href="https://www.cncf.io/people/staff/">staff</a> members. While possibly operating at a different scale than PostgreSQL, they all contribute, in different manners, to the steering, development and vision of the CNCF.</p>
<p>What do you think? <strong>Is PostgreSQL Core today what the PostgreSQL Community needs, or is it time to modernize its processes, structure and governance?</strong> If you think it is the latter, please leave your comments below. I hope this post serves as the starting point for a broader and constructive discussion that can serve as feedback to Core. Let’s ensure the best future for our beloved open source database!</p>

                </div>
                
                    
                
            </div>
        </div>
    </div>
</section></div>]]>
            </description>
            <link>https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048426</guid>
            <pubDate>Tue, 10 Nov 2020 17:22:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avo's Ultimate Tracking Plan Template (With Downloadable Worksheet)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048395">thread link</a>) | @kelseyfecho
<br/>
November 10, 2020 | https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet | <a href="https://web.archive.org/web/*/https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We talked in depth about <em>why</em> you need a tracking plan in our<a href="https://www.avo.app/blog/our-definitive-guide-to-tracking-plans"> definitive guide to tracking plans</a>; now, we’ll break down the awesome tracking plan template we created for you, so you’re ready to implement better product analytics via your tool of choice (possibly Avo 😉).</p><p>But before we dive in, here’s a quick refresher on what a tracking plan is (you may recognize this from our<a href="https://www.avo.app/blog/our-definitive-guide-to-tracking-plans"> definitive guide to tracking plans</a>):</p><p><em>A tracking plan is a document that defines the key stages of your customer life cycle and codifies a single source of truth for the data that supports it. It helps you standardize your data management and capture better and cleaner data.</em></p><p>As part of your tracking plan, you’ll need to outline the events and properties relevant to your goals, explain where in your codebase tracking code should be placed, and provide context for why you’re tracking what you are.</p><p>While each of the elements of your tracking plan will be as unique to your business as your product is to your market, you can save admin time up front by using a tracking plan template. There are dozens floating around the internet, so we went ahead and created our 🎉Ultimate Tracking Plan Template 🎉 that pulls together the 10 elements you absolutely must have. Use this template to spend less time researching how to make your tracking plan and more time using it.</p><h2><strong>What makes a good tracking plan?</strong></h2><p>Your tracking plan should include events and properties that help you understand your customers’ behavior and measure progress through your sales funnel and customer journeys so you can see how well your features are meeting customer needs. It shouldn’t aim to measure every drop of data under the sun—just those that are most important to you.</p><p><em>For the full breakdown of how to find the events and properties that mirror your customer journey, check out</em><a href="https://www.avo.app/blog/our-definitive-guide-to-tracking-plans"><em> our full guide on tracking plans</em></a><em>, and then meet us back here.</em></p><p>To get a full picture of your customers’ behaviors and experiences, you’ll need a mix of both <strong>qualitative metrics</strong> (the kind that reflect user sentiment) and <strong>quantitative metrics</strong> (the kind that reflect user actions).</p><p>Your tracking plan will focus on quantitative metrics. That's because it's possible to objectively measure whether an action happened. But it’s equally important that your sales and product teams reach out to customers and users via surveys, social media, and reviews to get qualitative data to complement your tracking plan.</p><h2><strong>The 10 key elements of your tracking plan</strong></h2><p>We have a lot of experience helping folks build killer tracking plans (and we’ve seen a lot of great examples of tracking plans from other companies, too). When we sat down and pulled from our experience—and the experiences of others—we noticed there were <strong>10 key elements</strong> that every great tracking plan included.</p><h3><strong>1. KPIs</strong></h3><figure id="w-node-530d128e532a-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8da57e1d363a3d9b0b_zFsYVY341ROFEJtzHTqKjGUl5B--qn1HOpQJveWLNR_qPh-UsdTVUqGCRatRYI8S9Y4z4ZM3U7bm__KHLqPCOEYSYsO-dvIwiyB57Y4sU1_D481F9IvaSCLtb9v687GfNMss5BvN.png" alt=""></p></figure><p>‍</p><p>Each event you track should tie directly to a business-end key performance indicator (KPIs) that affects your success, so you can easily reference the tie-in between metrics tracked and their real-world value.</p><p>These KPIs will change depending on your company maturity, product, and business strategy, but here are some examples:</p><ul role="list"><li>Signup funnel&nbsp;</li><li>Retention from signup to playing game&nbsp;</li><li>Monthly new signups&nbsp;</li></ul><p>This first section is what will give any business-end stakeholders the context they need to understand how the tracking plan ties into a wider strategy.</p><h3><strong>2. Event categories</strong></h3><figure id="w-node-4acb0f34daaa-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8d25d6db8b075c10f4_DU2hKDTJVw5geaQSvCWdZyykuvO9nbgj3zRVCYZgG8Lv3eAKNBRShY9_R0XpxJ7hY0KcAPgHKukstUyxK-n7mC_UQxJ622J3GsS01LFzSXbnwPWfZHkuQzvcdYcsKibJImCc9_us.png" alt=""></p></figure><p>‍</p><p>Your tracking plan should break down events tracked by macro category—typically reflecting the different kinds of KPIs you’ve set—so you can keep track of each segment of customer success.</p><p>Like all things on this list, the kinds of events you’ll track will depend on your goals and use case, but here are a few examples:</p><ul role="list"><li>Authentication&nbsp;</li><li>Gameplay</li><li>Tournaments&nbsp;</li><li>Navigation</li></ul><p>Once you’ve set the broad categories of events you care about, you can drill down and decide on the specific events and properties within each category.</p><h3><strong>3. Event names</strong></h3><figure id="w-node-187250f1dc30-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8fd082e416a91e7b79_TcJUo78HcU3SgDp2OEbWGP1kUdEwnKRCNvMBKYg3wctbFjMTcyr37VzBXFtiVQWmIzikz_XIAvHu1iL17HcPDyLiWG7H_R6DDMCDUPGrvJsQ1cShwvQ6qauCwydT-pFzwUMWaAKM.png" alt=""></p></figure><p>‍</p><p>Your tracking plan should include one row for each event name (each of which will have rows for child properties). Additionally, each of your events should be <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#a-namenaming-conventionsa-naming-conventions-for-events-and-properties">named in a consistent way</a> that’s in line with your agreed-on naming schema. This structure makes it easy for anyone to quickly scan and understand what events you’re tracking.</p><p>Your event names will depend on the kinds of events you’re tracking and on your naming schema. Within the categories we outlined above, some possible event names could include the following:</p><ul role="list"><li>Signup Started&nbsp;</li><li>Signup Completed&nbsp;</li><li>Login Completed&nbsp;</li><li>Game Started&nbsp;</li><li>Game Completed&nbsp;</li></ul><p>Note how each of these event names shares the same tense (past tense) and capitalization. This isn’t just to make your template look pretty; it makes everything easier to understand.</p><h3><strong>4. Event description</strong></h3><figure id="w-node-1dc7d6600a1b-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8e862fad531128fb1f_tHQLNeHbz4xZgGQ3UDyoKeIlRgTnEAInfIqB5SPwyCVGMzW8Is3gsevwEqNtDkAoBbEBFjggi_w5pBtynvHVoB1a16Hr9qE1EGK1uGG-zs0g3pTwRCeDDNhmWt_ZEK0yFUaBGhAk.png" alt=""></p></figure><p>‍</p><p>Your tracking plan should include a clear description for each event, including the event source (where the action is taking place) and <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#a-namedescriptionsa-descriptions-for-events-and-properties">any additional context of when and why the event happens</a>. That makes it easy for anyone looking at your template to quickly understand what the event is tracking.</p><p>Your event descriptions should be no longer than one or two sentences and should clearly and concisely explain what it is you’re measuring (and when). Let’s assume that we’re measuring the event “Game Completed.” Our description for this event might be:</p><p><em>Event sent when a user has successfully completed a game.&nbsp;</em></p><p>Creating consistent descriptions for each of your events will make it easy for anyone using your tracking plan to gain the context they need to interpret your data.</p><h3><strong>5. Properties</strong></h3><figure id="w-node-333264b27c1d-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8ee33289892753ad21_3EYStOV5VQlQYeGzMJPyMOp8QzHD8qKyZdFUxZp4ZAmQBmsKtm5gRQ-X1wUejDhl0AQRr2yjQ8F9uv4-0v-WDSn3lJJ5irFTq_c-S229dgHG8M9ts_0w0vdaSl4WAc4VMHbXMyIe.png" alt=""></p></figure><p>‍</p><p>For each event, you should include a full breakdown of its attached properties, with one row per property—again, all named consistently—so you can easily see which properties are being tracked for a given customer action.</p><p><em>Bonus: You should also define your property groups (these can be spaced across event groups) so you can easily see what kind of user behaviors you’re tracking.</em></p><p>It can be easy to let <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#properties">naming conventions for properties</a> slide, but ensuring that each property follows your schema will prevent data collection and compilation errors down the road. Let’s say we’re measuring gameplay events, particularly the “Game Completed” event we identified above. We might track the following properties:</p><ul role="list"><li>Game Mode&nbsp;</li><li>Game Count&nbsp;</li></ul><p>Each of these properties will tell us whether or not a specific user action was completed (e.g., “Game Mode” tells us the mode of the game the user played and “Game Count” tells us how many games the user has completed).&nbsp;&nbsp;</p><h3><strong>6. Property description</strong></h3><figure id="w-node-7f23661ce86e-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8dda8f2787d81a87d7_SRKyGBFh80amOWqLYm4bzJbJVTRc8dPooGC5elZjp7LEHi4ATelWDMowhRa3Jx0RdpBp68K52pDCGMe6smASuB6iYRY0gTZ1klOETv6ue1imXwlaJkmpuLJyd_AYaq2jfgNAcKEd.png" alt=""></p></figure><p>‍</p><p>Your tracking plan should include a clear description for each property so that any user can understand what the property is tracking and where the data is coming from.</p><p>Just like your event descriptions, your property descriptions should fill a column to the right of your property names and <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#properties-1">clearly and concisely describe what each property measures</a>.</p><p>For example, if we’re tracking how many games players complete during their session, we may track a property called “Game Count”. Our description of this property might look something like this:</p><p><em>The number of games a player has completed when this event is sent. Including the game that was just completed on Game Completed.&nbsp;</em></p><p>This extra context will help anyone looking at your tracking plan make sense of all your properties.</p><h3><strong>7. Property value types</strong></h3><figure id="w-node-a7b247d39bb4-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8d4c3a92f224aa4e6d_P3Be8oQWJnz8WdmT5_PSPQpWy7JYNkUaweT8IWfUYFgC1Q7-zXGDT9kMMAKYc8Uo4g3K1E9F_4rhTIBRdSM_-wcGvRH2H_Sm7F3YhG-stRmHQU4jtRpScWITAVLZzg00buHIrHz8.png" alt=""></p></figure><p>‍</p><p>Each property within your tracking plan will collect a different data type. These types should be explicitly laid out so developers implement across codepaths and platforms consistently. This also helps your data analysts know what to expect from the tracking analytics code output.&nbsp;</p><p>This is one of the few sections of your tracking plan that will not greatly vary. Instead, the data in this column should include these common data types:</p><ul role="list"><li>int</li><li>floating-point number</li><li>boolean</li><li>string</li><li>datetime</li><li>a list of any of the data types above&nbsp;</li></ul><p>When you formally identify these data types for each of your events and properties, you help your developers avoid coding errors that will impact data compilation down the line.</p><h3><strong>8. Platforms</strong></h3><figure id="w-node-27beb698434d-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8d3e80f7aef4929f6c_uE8HThZK-UHSz_XorkNrq5sj8lGQP5dYoD4Tr4jWi33Ky80JvVP_6wti3UGVtB1K4F2760jlQbO9zeYsK9CwjN94Yu-J93rG7TpLDpWKGWAy03pkK3tnB24ITLqB2vjPxz5-3u2W.png" alt=""></p></figure><p>‍</p><p>For each property, you should note what platform the data is coming from so you can keep track of which applications contribute what information to your dataset.</p><p>This will depend on the development platforms you use and how your codebase is structured. But here’s a general outline of some of the platforms you may need to think about:</p><ul role="list"><li><strong>For web: </strong>JavaScript, TypeScript or Reason</li><li><strong>For mobile (generally): </strong>React Native or Expo or Flutter for iOS and Android apps</li><li><strong>For mobile (Android): </strong>Java or Kotlin&nbsp;</li><li><strong>For mobile (iOS):</strong>Swift or Objective C&nbsp;</li><li><strong>For backend: </strong>one or more backend sources (depending on number of programming languages and micro services)&nbsp;</li><li><strong>For game engines: </strong>Unity</li></ul><p>Including this breakdown of platforms that contribute data to your app will ensure that developers know where to implement tracking analytics across the board, and you won’t forget about any key components of your product.</p><h3><strong>9. Status</strong></h3><figure id="w-node-1697c41ba975-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8ee332892c4253ad22_Kjv8rek4cO-Y02kJmcgee0I4Wm5Qy2WxefQzbBeqQCf3nuMUA8hYuAKJUYL7Oi2Dpx-5VBZP88VKAWdwnxGdvugItvH_SoBxIOHrdTTofdp35s9GE_gqsGI-6qXl77A2pJn1Ahnh.png" alt=""></p></figure><p>‍</p><p>This is a really important one: Your tracking plan must indicate the status of each step of tracking analytics implementation. This ensures that your team--and your tracking plan stakeholders--have a clear understanding of what work has been completed, what needs review, and what is in testing.&nbsp;</p><p>For example, let’s say you’re tracking events and properties related to your login authentication method. You’ll need to note when that analytics code is ready for review and testing so your developers know that it’s not ready to ship, and don’t prematurely launch what could be a buggy bit of code.&nbsp;</p><h3><strong>10. Code snippet</strong></h3><figure id="w-node-9cafc5601453-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8ee3ef37d419b6f69b_sBOY_kvaTx5H_ds77RHPB7lR0xEDQ1MZL4SAWDVD5ICI4O8FvrD30dNhnEfq8Xv7_1B3HOclQUWqkXmuE6RquaNN3YLNxcOSTa4jNGV4gNcLxwEZz-cg_eYd9FNk_amDfkjxjR9N.png" alt=""></p></figure><p>‍</p><p>Finally, your tracking plan should include your tracking code for each event and property that needs to be tracked so that your developers can easily place it into the correct spot without naming-convention or syntax errors.</p><p>If you’re doing this manually with a spreadsheet alone—instead of using a tool, like Avo, that can house your implementation code and send it directly to developers—this section can get a little lengthy.</p><p>By explicitly giving the code for each property, you reduce the likelihood of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet">https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet</a></em></p>]]>
            </description>
            <link>https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048395</guid>
            <pubDate>Tue, 10 Nov 2020 17:21:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The investor's approach to Machine Learning projects]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048341">thread link</a>) | @louisdorard
<br/>
November 10, 2020 | https://www.louisdorard.com/blog/investors-approach-to-machine-learning-projects | <a href="https://web.archive.org/web/*/https://www.louisdorard.com/blog/investors-approach-to-machine-learning-projects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5f6cb338b8f7ec6492e30cbb" data-item-id="5f6cb338b8f7ec6492e30cbb">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1600960584781" id="item-5f6cb338b8f7ec6492e30cbb"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1602690482673_47350"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1602692107760-K7GPOSWKXO3UDNCKC6QQ/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/keenan-constance-VTLcvV6UVaI-unsplash.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1602692107760-K7GPOSWKXO3UDNCKC6QQ/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/keenan-constance-VTLcvV6UVaI-unsplash.jpg" data-image-dimensions="2500x1667" data-image-focal-point="0.5,0.5" alt="Photo by  Keenan Constance  on  Unsplash" data-load="false" data-image-id="5f872409ba7a483b51f2165d" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1602692107760-K7GPOSWKXO3UDNCKC6QQ/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/keenan-constance-VTLcvV6UVaI-unsplash.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1601637086178_13362"><div><p>How do you set Machine Learning projects for success?</p>
<p>There are many opportunities to create value with ML: increasing productivity, avoiding undesirable events, automating repetitive tasks... But there are also many sources of cost and uncertainty. ML projects can feel like games of poker: you need to pay to see if you've got a winning idea, and you should avoid going all-in without strong odds in your favor!</p>
<p>How can you <strong>figure out your odds</strong>, <strong>maximize chances of success</strong>, and <strong>minimize costs</strong>? By thinking like an investor! Here are 9 steps:</p>
<ol>
<li>Write the plan</li>
<li>Conduct customer/user studies</li>
<li>Set up Proof of Value with simulations and AutoML</li>
<li>Invest in data to increase performance</li>
<li>Shadow-deploy a Minimum Viable Product</li>
<li>Update model with new data</li>
<li>Canary-test and monitor</li>
<li>Invest in larger-scale deployment</li>
<li>Increase value / generate new value</li>
</ol>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1601637086178_34141"><div><p>When starting a new business, you’d use the business model canvas. For ML projects, use the <a href="https://www.louisdorard.com/machine-learning-canvas">ML Canvas</a>. It helps connect a value proposition to a prediction problem, identify bottlenecks, anticipate costs, and define the desired performance level.</p>
<p>Here are some questions you'll need to answer:</p>
<ul>
<li>Which value are you proposing, for which end-user?</li>
<li>Which prediction problem are you targeting?</li>
<li>How are you turning predictions into the proposed value? (Tip: ask yourself "what would I do if I already had a perfect model?")</li>
<li>How are you changing the end-user workflow?</li>
<li>How will you monitor the impact, quantify, and prove that value is created?</li>
</ul>
<p>The MLC helps formalize your plan, which you can use to better communicate with others, and convince them to join your efforts. Starting with the MLC is <a href="https://aws.amazon.com/blogs/apn/building-the-business-case-for-machine-learning-in-the-real-world/">recommended practice at AWS</a>. There are a few other frameworks with similar names, but what's unique with this one is that it helps anticipate running costs of the ML system you set out to build. For instance, you'll have to think about the volume of models and predictions to create, and this will determine infrastructure costs.</p>
</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1604599100593_119255"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1604599451310-5XAR4DV2KR4718W9XS24/ke17ZwdGBToddI8pDm48kLl76CqolYQpYCK1tQUkpCVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzq3NVIIp6jYqnwxy-xF8aVXRy_AJKc5toB5m-gAPM7p7ivWsEabuWKGrHqsHOeNt4/wizardofoz.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1604599451310-5XAR4DV2KR4718W9XS24/ke17ZwdGBToddI8pDm48kLl76CqolYQpYCK1tQUkpCVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzq3NVIIp6jYqnwxy-xF8aVXRy_AJKc5toB5m-gAPM7p7ivWsEabuWKGrHqsHOeNt4/wizardofoz.jpg" data-image-dimensions="640x360" data-image-focal-point="0.5,0.5" alt="wizardofoz.jpg" data-load="false" data-image-id="5fa43e9ba12889310b6a5ee8" data-type="image" src="https://www.louisdorard.com/blog/wizardofoz.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1604596910029_94157"><div><h2 id="2-conduct-customer-user-studies">2. Conduct customer/user studies</h2>
<p>Wouldn't it be great if you could make sure that end-users of your ML system will be able to use it — and that they'll want to — before you start building? For this, you can use mockups and run "wizard-of-oz" experiments, where you fake the ML system. It's been <a href="https://medium.com/google-design/human-centered-machine-learning-a770d10562cd">recommended practice at Google for years</a>.</p>
<p>Early UX research can also result in a better plan that factors in feedback loops (those could hurt in the long term) and new data collection opportunities.</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1601637086178_32786"><p><h2 id="3-set-up-proof-of-value-with-simulations-and-automl">3. Set up Proof of Value with simulations and AutoML</h2></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1604599100593_18017"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          <a href="https://builtin.com/artificial-intelligence/artificial-intelligence-automotive-industry">
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1604599130437-46NUJM5BU389WTHKPZ6D/ke17ZwdGBToddI8pDm48kEhRb-mGDiEi0xC18_AR20gUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcsUFtfQr2yxuOzlidL-fYvTwqjsYaERXA-DujV44Tnn4ay3UZP6GxYjP38VLon1Vj/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1604599130437-46NUJM5BU389WTHKPZ6D/ke17ZwdGBToddI8pDm48kEhRb-mGDiEi0xC18_AR20gUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcsUFtfQr2yxuOzlidL-fYvTwqjsYaERXA-DujV44Tnn4ay3UZP6GxYjP38VLon1Vj/image-asset.jpeg" data-image-dimensions="1200x630" data-image-focal-point="0.5,0.5" alt="If ML was a car, AutoML would be Tesla’s Autopilot! Actually, H2o.ai’s solution is even called  Driverless AI …" data-load="false" data-image-id="5fa43d5afdc1165c0be072e5" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1604599130437-46NUJM5BU389WTHKPZ6D/ke17ZwdGBToddI8pDm48kEhRb-mGDiEi0xC18_AR20gUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcsUFtfQr2yxuOzlidL-fYvTwqjsYaERXA-DujV44Tnn4ay3UZP6GxYjP38VLon1Vj/image-asset.jpeg">
          </p>
        
          </a>
        

        
          
          <figcaption>
            <p>If ML was a car, AutoML would be Tesla’s Autopilot! Actually, H2o.ai’s solution is even called <a href="https://www.h2o.ai/products/h2o-driverless-ai/">Driverless AI</a>…</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1604599100593_26838"><div><p>Before investing too much time/money/efforts, you'll want to create a baseline model with minimal costs, and in the quickest way possible. This means small data (e.g. 50 examples of each class, for a classification problem), automated ML, and no data scientist!</p>
<p>You will then proceed to proving that this baseline model can create value, by running it through a simulation (aka “offline evaluation”). The idea is to see how much value it would create, by making correct predictions on a "test" dataset. For this, you'll be using cost/gain values for the different types of incorrect/correct predictions.</p>
<p>One way to get a test dataset is to split your existing data into training and test sets, but there's a risk of "data leakage". The most secure option is to collect some more data, and to use it as test.</p>
<p>If you've reached your desired performance value, great! Go to step 5.</p>
</div></div><div data-aspect-ratio="59.354838709677416" data-block-type="5" id="block-yui_3_17_2_1_1601637086178_25762"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1602522249592-8OG67A3QV5TCIWFNJWZ2/ke17ZwdGBToddI8pDm48kOJinPAM-bsCsrEW-EQQcxcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcCYIMmt3J8eCP_1Xh0vGN4k6MSBhLjzgoEU9_RArInQXRklPxf4HZO9xZsY6xv2wj/Learning%2Bcurve%2B%252B%2Bdrawing%2B%252B%2Bplayer.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1602522249592-8OG67A3QV5TCIWFNJWZ2/ke17ZwdGBToddI8pDm48kOJinPAM-bsCsrEW-EQQcxcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcCYIMmt3J8eCP_1Xh0vGN4k6MSBhLjzgoEU9_RArInQXRklPxf4HZO9xZsY6xv2wj/Learning%2Bcurve%2B%252B%2Bdrawing%2B%252B%2Bplayer.jpg" data-image-dimensions="1058x684" data-image-focal-point="0.5,0.5" alt="Learning curve extrapolation" data-load="false" data-image-id="5f848c89fc98834485f02380" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1602522249592-8OG67A3QV5TCIWFNJWZ2/ke17ZwdGBToddI8pDm48kOJinPAM-bsCsrEW-EQQcxcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcCYIMmt3J8eCP_1Xh0vGN4k6MSBhLjzgoEU9_RArInQXRklPxf4HZO9xZsY6xv2wj/Learning%2Bcurve%2B%252B%2Bdrawing%2B%252B%2Bplayer.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Learning curve extrapolation</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1601637086178_31953"><div><h2 id="4-invest-in-data-to-increase-performance">4. Invest in data to increase performance</h2>
<p>Where should you invest, to increase performance? Common ideas are to: a) tune the ML algorithm, b) collect more data, c) improve data preparation.</p>
<p>One of the highlights of my survey results on <a href="https://www.linkedin.com/pulse/survey-results-what-managers-should-know-machine-learning-dorard/">what managers should know about ML</a> was Sébastien Arnaud's "<em>invest in data, and activities around it: cleaning, analysis, processing pipeline, annotation, labelling, training/test set, validation</em>." Indeed, the most impactful improvements to your ML system will be coming from data collection and preparation. This means you should forget about a).</p>
<p>To choose between b) and c) you need to plot a <em>learning curve</em>. This consists in running the previous simulation again but with subsets of the training data that go from 10% to 100% in size (see illustration). You would look at how performance increases with the amount of training data that's available. Also consider how much time/money it took to acquire this training set (getting unbiased data can come at a cost, e.g. randomly approving transactions or loan applications). What happens if you extrapolate to more data?</p>
<p>How do you generate ideas to improve data preparation? The key is to inspect individual predictions among top errors, top predictions, and most uncertain ones. Prioritize ideas by grouping errors in different types, and counting occurrences of each type. Inspecting predictions also helps determine if you can trust the model: look at prediction explanations and check that they make sense.</p>
<p>Go through the implementation/inspection loop a few times, until performance is higher than the desired value. If you can't get there quickly enough, consider changing parameters of your prediction problem (e.g. reducing the time horizon).</p>
</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601637086178_28201"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1601637651959-NHYL1IQBA4PXJ3JJKJOM/ke17ZwdGBToddI8pDm48kFssEdhmOlK77ygr-KMi-Md7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYJJAAZHaP_gTcZnuU_XDM1zyL6r9YsGRTiIw9e6RuDCFlq8oZZwhhoTbTOjCpwBwg/ML+system+architecture.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1601637651959-NHYL1IQBA4PXJ3JJKJOM/ke17ZwdGBToddI8pDm48kFssEdhmOlK77ygr-KMi-Md7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYJJAAZHaP_gTcZnuU_XDM1zyL6r9YsGRTiIw9e6RuDCFlq8oZZwhhoTbTOjCpwBwg/ML+system+architecture.jpg" data-image-dimensions="1811x2039" data-image-focal-point="0.5,0.5" alt="ML system architecture.jpg" data-load="false" data-image-id="5f770d1215e48c4fbd5b9576" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5206b718e4b0bdc26006bae2/1601637651959-NHYL1IQBA4PXJ3JJKJOM/ke17ZwdGBToddI8pDm48kFssEdhmOlK77ygr-KMi-Md7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYJJAAZHaP_gTcZnuU_XDM1zyL6r9YsGRTiIw9e6RuDCFlq8oZZwhhoTbTOjCpwBwg/ML+system+architecture.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1601637086178_31096"><div><h2 id="5-shadow-deploy-a-minimum-viable-product">5. Shadow-deploy a Minimum Viable Product</h2>
<p>"Shadow-deployment" is the same as real deployment in production, except you don’t actually use predictions but you just log them. This allows to check whether model performance on production inputs is similar to what it was on test inputs. You'll also want to monitor performance through time, to see how fast it decreases, and thus to inform model refresh rate (i.e. updating with fresher data).</p>
<p>In the context of ML, a Minimum Viable Product (MVP) isn't just a model, but it's a <em>system</em> that's made of several components — read more in <a href="https://www.linkedin.com/feed/update/urn:li:activity:6717822425423245313/">this post</a> and see how these components are interconnected in the diagram above. You should use an ML platform to get (and configure) a production-ready model builder and a server, and you should start with manual orchestration (this doesn't need to be a software component at first).</p>
<p>Finally, use shadow-deployment to check all running costs (ML platform / tools / infrastructure / compute), and see if there are any additional ones you hadn’t anticipated, when going from a lab environment to production.</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1602690482673_70558"><div><h2 id="6-update-model-with-new-data">6. Update model with new data</h2>
<p>As hinted above, you can expect performance to go down with time. This is because the dataset used to build your model becomes less and less representative of the reality, as time goes by. You'll need to periodically retrain your model with fresher data.</p>
<p>In the previous section, I advised to start with manual orchestration, which means manual (re)training and deployment. This should be fine in most cases, but you should test your ability to do this in a timely manner and without errors. This will also be an opportunity to collect new inputs and outputs and thus to confirm the cost of data collection.</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1602690482673_69097"><div><h2 id="7-canary-test-and-monitor">7. Canary-test and monitor</h2>
<p>I already mentioned monitoring in step 5, but this was about the model's performance. You'll also want to monitor the impact of your ML system, and make sure that you're system is creating value. But for this, you need to act on predictions and to integrate them into your end-users' app / workflow. You can start doing this for just a small subset of them (the "canary test"), to minimize the risk of "breaking" things with your new ML system.</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1602520515337_171287"><div><h2 id="8-invest-in-larger-scale-deployment">8. Invest in larger scale deployment</h2>
<p>Larger scale means increasing the subset of end-users who will be exposed to the new ML system / product. This means more predictions, higher running costs, changing the workflow of more people...</p>
<p>These costs have to be paid before getting gains, but you’ve proved that your MVP creates value, so eventually it will pay off!</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1602690482673_149979"><div><h2 id="9-increase-value-or-generate-new-value-">9. Increase value or generate new value?</h2>
<p>If you're looking to invest more in ML, you have two options: 1) improve the current system and thus increase the value it creates, or 2) generate new value with a new ML use case.</p>
<h3 id="increase-value">Increase value</h3>
<p>Now's the right time to hire data scientists to <strong>tune modelling algorithms</strong>, or ML engineers to <strong>automate orchestration</strong>!</p>
<ul>
<li>Modelling improvements will result in higher performance, thus more value creation.</li>
<li>The idea with automation is to spend less time maintaining the system in production. You'll be setting up alerts (based on live performance, data drift detection...), triggers, and actions (train model, evaluate, deploy).</li>
</ul>
<h3 id="generate-new-value">Generate new value</h3>
<p>Targeting a new ML use case might provide a higher Return On Investment, if you <strong>make your ML assets reusable</strong>: reusing your previous data acquisition and preparation pipelines …</p></div></div></div></div></div></article></section></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.louisdorard.com/blog/investors-approach-to-machine-learning-projects">https://www.louisdorard.com/blog/investors-approach-to-machine-learning-projects</a></em></p>]]>
            </description>
            <link>https://www.louisdorard.com/blog/investors-approach-to-machine-learning-projects</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048341</guid>
            <pubDate>Tue, 10 Nov 2020 17:16:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Detecting click outside a component using React hooks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048169">thread link</a>) | @saranshk
<br/>
November 10, 2020 | https://www.wisdomgeek.com/development/web-development/react/detecting-click-outside-component-using-react-hooks/ | <a href="https://web.archive.org/web/*/https://www.wisdomgeek.com/development/web-development/react/detecting-click-outside-component-using-react-hooks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_70_afa"><div><p>If you have tried developing your own dropdown, modal, or popover in React, you would have come across this. “How do I detect a click outside my react component so that I can close it?” Detecting click outside component is luckily is not that difficult. This post will use react hooks to implement this functionality.</p><p>Before we get started with our process of detecting click outside component using React hooks, there is one hook in particular that we need to know about: useRef.</p><h2>The useRef hook</h2><p><span>- Advertisement -</span> <ins data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1198872678846288" data-ad-slot="2989761355"></ins> </p><p>useRef is a react hook that can be used to access DOM elements. It returns a mutable object whose current property is initialized to the argument that gets passed as an argument.</p><p>The syntax for using the hooks looks like this:</p><pre><code>const refContainer = useRef(initialValue);</code></pre><p>And a sample implementation to focus the component on render would be:</p><pre><code>function TextInputWithFocusButton() {
  const inputEl = useRef(null);
  const onButtonClick = () =&gt; {
    // `current` points to the mounted text input element
    inputEl.current.focus();
  };
  return (
    &lt;&gt;
      &lt;input ref={inputEl} type="text" /&gt;
      &lt;button onClick={onButtonClick}&gt;Focus the input&lt;/button&gt;
    &lt;/&gt;
  );
}</code></pre><p>ref can be used in element tags or components too. It provides a way to access the corresponding DOM nodes. If you pass in a reference object using ref = {}, React sets the current property of the corresponding node. This property is updated whenever the node changes too.</p><p>There are other use cases for the useRef hook as well. But this post will be focused only on detecting click outside component.</p><h2>Setting up event listeners</h2><p>Now that you know of useRef, we will use it along with an event listener (for mouseDown or click). This listener will be attached to the document whenever the component is rendered. It will also be unmounted whenever the component is hidden. For obtaining this functionality, the useEffect react hook can be used. If you want a deeper insight into the <a href="https://www.wisdomgeek.com/development/web-development/react/learning-context-api-and-the-usecontext-react-hook/">useEffect react hook</a>, you can read the previous post about it.</p><p>For the component, there is a showOptionsList variable that is being used as a state variable to determine whether the component is visible or not. Thus, the useEffect will have it as a dependency, and according to its value, the event listener will be added/removed.</p><pre><code> useEffect(() =&gt; {
    if (showOptionsList) {
      document.addEventListener('mousedown', handleClickOutside);
    } else {
      document.removeEventListener('mousedown', handleClickOutside);
    }
    return () =&gt; {
      document.removeEventListener('mousedown', handleClickOutside);
    };
  }, [showOptionsList]);</code></pre><h2>Detecting click outside component</h2><p>Now that the handleClick will be triggered every time a click is registered on the document, all that remains is to check if the click is outside the component or not. For this, a reference to the component is needed. This can be obtained by making use of the useRef hook that was discussed earlier. Thus:</p><pre><code>const Select = () =&gt; {
  const node = useRef();
  return (
    &lt;div ref={node}&gt;
      // Remaining code
    &lt;/div&gt;
  );
};
</code></pre><p>And then, all that needs to be done in the handle click outside function would be to check if the user clicked outside the component or not. An implementation could be to check the target element of the click and if that equals the reference. But that only works for a single level node. In the case of multiple sub-nodes, the simple comparison would not work.</p><p>The .contains() method can be used to solve that problem. It tells if a node is a child of a given node or not. Thus, the implementation of the function becomes:</p><pre><code>const handleClickOutside = (e) =&gt; {
  if (node.current &amp;&amp; node.current.contains(e.target)) {
    // inside click
    return;
  }
  // outside click
  setShowOptionsList(false);
};</code></pre><p>The completed source code for the Select implementation can be found on <a aria-label="undefined (opens in a new tab)" href="https://github.com/saranshkataria/react-select/blob/main/src/components/Select/index.js" target="_blank" rel="noreferrer noopener">Github</a> if you want to go through it. If you want to make yourself familiar with other react hooks like <a aria-label="undefined (opens in a new tab)" href="https://www.wisdomgeek.com/development/web-development/react/learning-context-api-and-the-usecontext-react-hook/" target="_blank" rel="noreferrer noopener">useState and useEffect</a>, <a aria-label="undefined (opens in a new tab)" href="https://www.wisdomgeek.com/development/web-development/react/understanding-the-usereducer-hook-in-react/" target="_blank" rel="noreferrer noopener">useReducer</a>, or <a aria-label="undefined (opens in a new tab)" href="https://www.wisdomgeek.com/development/web-development/react/learning-context-api-and-the-usecontext-react-hook/" target="_blank" rel="noreferrer noopener">useContext</a>, check out the respective posts.</p><p>If there are any other <a aria-label="undefined (opens in a new tab)" href="https://www.wisdomgeek.com/tag/react-hooks/" target="_blank" rel="noreferrer noopener">react hooks</a> related things that you would want to cover, or if you have any queries, feel free to drop a comment below.</p></div></div></div>]]>
            </description>
            <link>https://www.wisdomgeek.com/development/web-development/react/detecting-click-outside-component-using-react-hooks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048169</guid>
            <pubDate>Tue, 10 Nov 2020 17:04:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Little Crony – explore connections between Tories and contracted companies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048133">thread link</a>) | @davidbarker
<br/>
November 10, 2020 | https://sophieehill.shinyapps.io/my-little-crony/ | <a href="https://web.archive.org/web/*/https://sophieehill.shinyapps.io/my-little-crony/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
          A visualization of the connections between
          <strong>Tory politicians</strong>
          and
          <strong>companies being awarded government contracts during the pandemic,</strong>
          based on reporting by
          <a href="https://www.opendemocracy.net/en/dark-money-investigations/">openDemocracy,</a>
          <a href="https://bylinetimes.com/">Byline Times,</a>
          and more.
        </p>
    </div></div>]]>
            </description>
            <link>https://sophieehill.shinyapps.io/my-little-crony/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048133</guid>
            <pubDate>Tue, 10 Nov 2020 17:00:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predicting the Future of the Pandemic]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048095">thread link</a>) | @gloriosoc
<br/>
November 10, 2020 | https://realscience.community/covid-projections/ | <a href="https://web.archive.org/web/*/https://realscience.community/covid-projections/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div id="speakaboutWrapper"><p>US by State</p>



<figure><img loading="lazy" width="1024" height="443" src="https://realscience.community/wp-content/uploads/2020/11/image-2-1024x443.png" alt="" srcset="https://realscience.community/wp-content/uploads/2020/11/image-2-1024x443.png 1024w, https://realscience.community/wp-content/uploads/2020/11/image-2-300x130.png 300w, https://realscience.community/wp-content/uploads/2020/11/image-2-768x332.png 768w, https://realscience.community/wp-content/uploads/2020/11/image-2-1536x664.png 1536w, https://realscience.community/wp-content/uploads/2020/11/image-2-2048x885.png 2048w, https://realscience.community/wp-content/uploads/2020/11/image-2-1200x519.png 1200w, https://realscience.community/wp-content/uploads/2020/11/image-2-1388x600.png 1388w, https://realscience.community/wp-content/uploads/2020/11/image-2-960x415.png 960w, https://realscience.community/wp-content/uploads/2020/11/image-2-2000x865.png 2000w, https://realscience.community/wp-content/uploads/2020/11/image-2-1250x540.png 1250w, https://realscience.community/wp-content/uploads/2020/11/image-2-400x173.png 400w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="675" src="https://realscience.community/wp-content/uploads/2020/11/image-1-1024x675.png" alt="" srcset="https://realscience.community/wp-content/uploads/2020/11/image-1-1024x675.png 1024w, https://realscience.community/wp-content/uploads/2020/11/image-1-300x198.png 300w, https://realscience.community/wp-content/uploads/2020/11/image-1-768x507.png 768w, https://realscience.community/wp-content/uploads/2020/11/image-1-1536x1013.png 1536w, https://realscience.community/wp-content/uploads/2020/11/image-1-2048x1351.png 2048w, https://realscience.community/wp-content/uploads/2020/11/image-1-1200x792.png 1200w, https://realscience.community/wp-content/uploads/2020/11/image-1-910x600.png 910w, https://realscience.community/wp-content/uploads/2020/11/image-1-960x633.png 960w, https://realscience.community/wp-content/uploads/2020/11/image-1-1819x1200.png 1819w, https://realscience.community/wp-content/uploads/2020/11/image-1-1250x825.png 1250w, https://realscience.community/wp-content/uploads/2020/11/image-1-400x264.png 400w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p><strong>About: </strong>Projections were created by the founder of Real <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a>, Dr. Christin Glorioso. I produced a separate SIR model for each county with an empirically derived beta from real data from that county. US and state level data are calculated from the sum of the county model results. The primary data are from the JHU COVID repository. Feel free to reach out to me for more details. You can <a href="https://realscience.community/register-2/">join the site</a> and message me or leave a comment below. </p>



<div>
<div><p><a href="https://realscience.community/register-2/" target="_blank" rel="noreferrer noopener">JOIN REal Science</a></p></div>
</div>




</div>					</div></div>]]>
            </description>
            <link>https://realscience.community/covid-projections/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048095</guid>
            <pubDate>Tue, 10 Nov 2020 16:57:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking Pulsar and Kafka a More Accurate Perspective on Pulsar Performance]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25048083">thread link</a>) | @addisonj
<br/>
November 10, 2020 | https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance | <a href="https://web.archive.org/web/*/https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048083</guid>
            <pubDate>Tue, 10 Nov 2020 16:56:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Walrus Operator in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25047966">thread link</a>) | @renanmoura
<br/>
November 10, 2020 | https://renanmf.com/walrus-operator-python/ | <a href="https://web.archive.org/web/*/https://renanmf.com/walrus-operator-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The Walrus operator <code>:=</code> is an <a href="https://renanmf.com/assignment-operators-python/">assignment operator</a> and is available since Python 3.8.</p><p>It is called "walrus operator" due to its resemblance to the eyes and tusks of a walrus.</p><p>The walrus operator <strong>assigns and returns a value</strong> at the same time.</p><h2>Basic Example</h2><p>The regular way of asking for a piece of information in a terminal by using the <a href="https://renanmf.com/user-input-command-line-python/">input command</a> is as follows:</p><pre><code>&gt;&gt;&gt; age = input('How old are you? ')
How old are you? 30
&gt;&gt;&gt; print(f"You are {age} years old")
You are 30 years old
&gt;&gt;&gt; print(age)
30</code></pre><p>Using the walrus operator, you can make this code even shorter:</p><pre><code>&gt;&gt;&gt; print(f"You are {(age := input('How old are you? '))} years old")
How old are you? 30
You are 30 years old
&gt;&gt;&gt; print(age)
30</code></pre><h2>Example with a <code>while</code> loop</h2><p>Another example using <a href="https://renanmf.com/while-loops-python/">while loops</a> shows how you can simplify the code.</p><p>In this snippet, the loop will keep going until the user inputs the number 4.</p><pre><code>while True:
    number = int(input("Pick a number: "))
    if number == 4:
        break
    print(f'{number} squared is {number**2}')</code></pre><p>To have the same effect with the walrus operator, you do the following.</p><pre><code>while (number := int(input("Pick a number: "))) != 4:
    print(f'{number} squared is {number**2}')</code></pre><p>A simple test case for the while loop examples above is:</p><pre><code>Pick a number: 3
3 squared is 9
Pick a number: 5
5 squared is 25
Pick a number: 4</code></pre><h2>Example with a Regular Expression</h2><p>A simple example checking if the letter "Y" exists in "New York".</p><p>In the regular way to do it, we first get the result of the <code>search()</code> function, if there is no match, the function returns None which equals to <code>False</code> in the <code>if</code> statement.</p><p>If there is a match, the <code>res</code> variable will store a match object and pass the <code>if</code> statement.</p><pre><code>import re
text = "New York"
res = re.search("Y", text)
if res:
    print(res.group(0))</code></pre><p>To achieve the same result with the walrus operator, we can assign the result of the <code>search()</code> function directly to <code>res</code> in the <code>if</code> statement expression:</p><pre><code>import re
text = "New York"
if (res := re.search("Y", text)):
    print(res.group(0))</code></pre><h2>Example with a List Comprehension</h2><p>The use of the walrus operator with <a href="https://renanmf.com/list-comprehensions-in-python/">list comprehensions</a> enables the sharing of a subexpression.</p><p>In this case, without the walrus operator, we have to compute the operation <code>n**3</code> twice because we only want numbers whose cube is greater than 10.</p><pre><code>numbers = [1, 2, 3, 4, 5]
new_list = []
new_list = [n**3 for n in numbers if n**3 &gt; 10]
print(new_list)</code></pre><p>Using the walrus operator we can save this extra computation and reuse the value of <code>y</code> assigned in the <code>if</code> statement.</p><pre><code>numbers = [1, 2, 3, 4, 5]
new_list = []
new_list = [y for n in numbers if (y := n**3) &gt; 10]
print(new_list)</code></pre><p>Both will result in the same output, but the walrus operator allows a less expensive computation:</p><pre><code>[27, 64, 125]</code></pre><p>The code with the walrus operator might seem harder to read for some at first, use it only if it makes sense to you, and if it makes the code better overall.</p><h2>Controversy</h2><p>The Walrus Operator was controversial in the community and many people criticized it for some reasons:</p><ul><li>How will developers even use it?</li><li>Is this extra complexity needed?</li><li>This is confusing for new users of the language.</li></ul><p>These were the words that Guido van Rossum, the creator of Python,&nbsp;wrote after finishing PEP 572, which gave birth to the so-called Walrus Operator, saying he was resigning&nbsp;from his role.</p><blockquote><p>Now that PEP 572 is done, I don’t ever want to have to fight so hard for a PEP and find that so many people despise my decisions.</p><p>I would like to remove myself entirely from the decision process. I’ll still be there for a while as an ordinary core dev, and I’ll still be available to mentor people — possibly more available. But I’m basically giving myself a permanent vacation from being BDFL, and you all will be on your own.</p><p>After all that’s eventually going to happen regardless — there’s still that bus lurking around the corner, and I’m not getting younger… (I’ll spare you the list of medical issues.)</p><p>I am not going to appoint a successor.</p><p>So what are you all going to do? Create a democracy? Anarchy? A<br> dictatorship? A federation?</p><p>I’m not worried about the day to day decisions in the issue tracker or on GitHub. Very rarely I get asked for an opinion, and usually it’s not actually important. So this can just be dealt with as it has always been.</p><p>The decisions that most matter are probably</p><ul><li>How are PEPs decided</li><li>How are new core devs inducted</li></ul><p>We may be able to write up processes for these things as PEPs (maybe those PEPs will form a kind of constitution). But here’s the catch. I’m going to try and let you all (the current committers) figure it out for yourselves.</p><p>Note that there’s still the CoC — if you don’t like that document your only option might be to leave this group voluntarily. Perhaps there are issues to decide like when should someone be kicked out (this could be banning people from python-dev or python-ideas too, since those are also covered by the CoC).</p><p>Finally. A reminder that the archives of this list are public (<a href="https://mail.python.org/pipermail/python-committers/">https://mail.python.org/pipermail/python-committers/</a>) although membership is closed (limited to core devs).</p><p>I’ll still be here, but I’m trying to let you all figure something out for yourselves. I’m tired, and need a very long break.</p></blockquote><p>Personally speaking, as shown in the examples in this article, the walrus operator can be quite useful and help with some performant operations.</p><p>This is to show how even in the open source community, with highly smart people, there are disagreements that go beyond the professional level and get personal.</p><p>Projects are hard, designing programming languages is hard and we should thank those who take their time to build the tools we use every day to create awesome things.</p></div></div>]]>
            </description>
            <link>https://renanmf.com/walrus-operator-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047966</guid>
            <pubDate>Tue, 10 Nov 2020 16:46:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teach Testing First]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25047890">thread link</a>) | @kgashok
<br/>
November 10, 2020 | https://smalldata.tech/blog/2019/02/09/teach-testing-first | <a href="https://web.archive.org/web/*/https://smalldata.tech/blog/2019/02/09/teach-testing-first">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
The hallmark of an successful long term software project is its maintainablity. Maintainabity is a very loaded term in terms of software engineering and is usually dependent upon the software in question itself. In general however, decoupled code with a flexible overall system architecture is considered to be the best approach. Moreover, having comprehensive automated testing leads to highly resilient software. In recent years there has been a strong push towards Test Driven Development (TDD) which has become a rather polarising debate and this article does not focus on TDD but rather testing in general. 
</p>

<p>
Testing in this article can mean unit testing, integration testing as well as end-to-end integration testing interchangably. There is a well-know testing pyramid that visualizes the effort required for writing tests as one goes higher up. As the title suggests, the premise really is: <u><i>"Why isn't programming taught with a focus on testing first?"</i></u> and <u><i>"Will a focus on testing broaden the tip of the pyramid to make fully automated end-to-end integration testing easier?"</i></u>
</p>


<div>
  <p><a href="https://smalldata.tech/img/blog/testing-pyramid.png">
    <img alt="" src="https://smalldata.tech/img/blog/testing-pyramid.png">
  </a></p><p>
    The complexity and effort of writing and executing tests increases as one goes up the pyramid.
  </p>
</div>

<p>
When teaching programming, the general approach is to start with the basics such as setting up the environment, writing your first "Hello World" program, move on to programming concepts such as variables, loops, conditionals, etc. Towards the end, stuffed into advanced topics, is an introduction to unit testing. Some resources, such as the first hit on DDG for learning python (<a href="https://www.learnpython.org/">learnpython.org</a>) feature no testing at all! Recently however, testing has improved its position and can be found somewhere in the middle of the textbook in some instances, e.g <a href="https://www.learncpp.com/">learncpp.com</a>.
</p>

<blockquote>
  <p>If you're interested in learning a programming language or any other technical topic check out <a href="https://classpert.com/">classpert.com</a> for online courses!</p>
  
</blockquote>


<p>
Consider now that instead of jumping into variables and loops after "Hello World", we started with a test. It might be confusing at first as there are many concepts at play here, but assuming that "Hello World" was magic enough, a little bit more magic wouldn't harm given the long term benefits. In fact the hardest part here would be to actually enable a "Hello World" test to be written because we are not talking about a unit test, but rather a full integration test that runs the program which writes to <code>stdout</code> and then verifies that the output is correct.
</p>

<p>
Moving on, the teaching process itself could be simplified with excercises provided in the form of tests, e.g. write a program that makes this test pass. Of course, students will also need to learn that writing a program that makes a test pass does not necessarily mean that the program does what it is supposed to! The hardest part will likely be teaching UI testing. Currently, it is a lot of effort to setup end-to-end UI integration tests. There are many approaches and it might be enough to take a really simple approach to begin with, e.g. use an in-memory db with selenium for a web application, however, we should not let this deter us from coming up with better software that enable testing from the ground up.
</p>

<p>
The benefits of teaching testing first are rather clear, students will learn how to develop and test their software leading to better software being written. This will also force us to focus on making software testable, e.g. a desktop environment that can be programmatically queried regarding contents. There are of course, security concerns here but they could be mitigated by allowing a whitelist of software that can be interacted with on a per session basis but this is probably a post for a whole another article.
</p>

<!--
<div>
  <a class="image-popup-no-margins" href="/img/blog/016-automated-tests.jpg">
    <img class="img-responsive centered img-border" alt="" src="/img/blog/016-automated-tests.jpg">
  </a>
  <div class="img-desc">
    We need a goal to shoot for!
  </div>
</div>
-->

<p>
We can start small perhaps, teach unit testing for languages as early as possible and any new library or framework produced should also provide clear testing guidelines. Open source code should always have a section on testing along with project setup. The goal should be making testing a first class citizen!
</p>
<p><a href="https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fsmalldata.tech%2Fblog%2F2019%2F02%2F09%2Fteach-testing-first&amp;t=Teach%20testing%20first">HackerNews submission / discussion</a></p></div></div>]]>
            </description>
            <link>https://smalldata.tech/blog/2019/02/09/teach-testing-first</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047890</guid>
            <pubDate>Tue, 10 Nov 2020 16:39:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to beat the bank]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25047840">thread link</a>) | @venturegrit
<br/>
November 10, 2020 | https://andyjagoe.com/how-to-beat-the-bank/ | <a href="https://web.archive.org/web/*/https://andyjagoe.com/how-to-beat-the-bank/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://andyjagoe.com/content/images/size/w300/2020/11/felix-mittermeier-nAjil1z3eLk-unsplash.jpg 300w,
                            https://andyjagoe.com/content/images/size/w600/2020/11/felix-mittermeier-nAjil1z3eLk-unsplash.jpg 600w,
                            https://andyjagoe.com/content/images/size/w1000/2020/11/felix-mittermeier-nAjil1z3eLk-unsplash.jpg 1000w,
                            https://andyjagoe.com/content/images/size/w2000/2020/11/felix-mittermeier-nAjil1z3eLk-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://andyjagoe.com/content/images/size/w2000/2020/11/felix-mittermeier-nAjil1z3eLk-unsplash.jpg" alt="How to beat the bank">
            </figure>

            <section>
                <div>
                    <!--kg-card-begin: markdown--><blockquote>
<p>Show me the incentive and I will show you the outcome.<br>
— Charlie Munger</p>
</blockquote>
<!--kg-card-end: markdown--><p>Have you ever thought about how much better some products are than the same version ten years ago?</p><p>My iPhone 12 is <a href="https://gadgetversus.com/processor/apple-a4-vs-apple-a14-bionic/">8,000% faster</a> than my iPhone 4. On 5G it can download at 4,000 Mbps versus my iPhone 4's top speed of 2 Mbps. <a href="https://www.in2013dollars.com/us/inflation/2010?amount=649">And it's the same price</a>. Meanwhile, countless physical products have become <a href="https://www.makeuseof.com/tag/apps-replacing-modern-devices/">just apps on the phone</a>.</p><p>In 2010, I had 7 Mbps Internet at home. Today I have 1,000 Mbps Internet. For the same price. And our children do live online video school while my wife and I run live Zoom meetings. Without even a hiccup.</p><p>Let's compare this to financial services.</p><p>If my Internet is 142 times better today than in 2010, how much better is my mortgage? Zero. My checking and savings accounts? Zero. My insurance? Zero. My investment services? OK, not zero. But not even a fraction of 142x.</p><p>Why?</p><p>One reason is that phone and Internet have exponential tailwinds from <a href="https://en.wikipedia.org/wiki/Moore%27s_law">Moore's Law</a> and digitalization. Digital is different, as we discussed in detail in <a href="https://andyjagoe.com/software-eats-money/">how software eats money</a>.</p><p>But that's not the only reason. Many financial services haven't improved in decades. How can that be?</p><h2 id="incentives">Incentives</h2><p>Charlie Munger, the vice-chairman of Berkshire Hathaway, wrote in the <a href="https://static1.squarespace.com/static/5ca3e714d74562b554c38604/t/5caa07a9971a182374badc19/1554646956708/Psychology+of+Human+Misjudgment.pdf">Psychology of Human Misjudgment</a>:</p><!--kg-card-begin: markdown--><blockquote>
<p>I think I’ve been in the top five percent of my age cohorts almost all my adult life in understanding the power of incentives, and yet I’ve always underestimated that power. Never a year passes but I get some surprise that pushes a little further my appreciation of incentive superpower.</p>
</blockquote>
<blockquote>
<p>One of my favorite cases about the power of incentives is the Federal Express case. The integrity of the Federal Express system requires that all packages be shifted rapidly among airplanes in one central airport each night. The system has no integrity for the customers if the night work shift can’t accomplish its assignment fast.</p>
</blockquote>
<blockquote>
<p>Federal Express had one hell of a time getting the night shift to do the right thing. They tried moral suasion. They tried everything in the world without luck. And, finally, somebody got the happy thought that it was foolish to pay the night shift by the hour when what the employer wanted was not maximized billable hours of employee service but fault-free, rapid performance of a particular task. Maybe, this person thought, if they paid the employees per shift and let all night shift employees go home when all the planes were loaded, the system would work better. And, lo and behold, that solution worked.</p>
</blockquote>
<!--kg-card-end: markdown--><p>Incentives matter. And if you know the incentive, you can know the outcome. The reason financial services have not improved in decades is a problem of incentives.</p><p>All good organizations pick metrics to measure success. But because measuring actual human behavior is difficult, we typically choose a <a href="https://kortina.nyc/essays/metrics-incrementalism-and-local-maxima/">proxy metric</a> to represent it. In education, we use test scores as a proxy for aptitude. In media, we use attention as a proxy for customer value. In consumer internet, we use clicks as a proxy for 'looked at this' and time spent as a proxy for 'enjoyed this.'</p><p>What do we use in financial services? </p><p>What metric is used to measure the amount of value being delivered to a customer? Is there one?</p><p>If a student has a higher test score, we can infer a higher aptitude. If someone spends more time watching a video, we can infer more entertainment or information value.</p><p>What is the equivalent in finance?</p><p>If a customer has more loans, are they getting more value? If a customer paid more fees, are they getting more value? If a customer trades more or has more insurance, are they getting more value?</p><p>The truth is most financial services companies do not think about customer value when measuring success. Assets under management, accounts opened, loans per loan officer and the <a href="https://www.staceybarr.com/measure-up/how-banks-should-change-their-kpis/">countless other current KPIs</a> are all inward facing. They measure bank value, not customer value.</p><p>If no one is measuring customer value, it's no surprise customer value isn't improving. There's no incentive.</p><p>Optimizing for the wrong metric is why Wells Fargo employees opened millions of fake customer accounts. Even after the <a href="https://www.federalreserve.gov/newsevents/pressreleases/files/enf20180202a1.pdf">consent order</a>, employees report the <a href="https://www.nytimes.com/2019/03/09/business/wells-fargo-sales-culture.html">culture still hasn't changed</a>. Have the metrics changed? Show me the incentive, and I will show you the outcome.</p><p>If optimizing for the wrong metric isn't bad enough, there's a second problem. Proxy metrics are imperfect measures of human behavior and often have second-order consequences that system designers didn't want or anticipate.</p><p>There are situations where using a product encourages more use of the product. This creates a feedback mechanism where not only the production side of the system is optimizing for the metric, but the consumption side is as well. This <a href="http://www.jimcollins.com/article_topics/articles/the-flywheel-effect.html">flywheel</a> effect can cause an epidemic, like when the media industry optimizes for content designed to trigger a dopamine response (like a newsfeed filled with <a href="https://www.newyorker.com/magazine/2017/02/27/why-facts-dont-change-our-minds">fake news</a> or <a href="https://www.pnas.org/content/106/22/9115.full">baby photos</a>) or when the food industry optimizes for empty calories (like <a href="https://www.npr.org/sections/thesalt/2014/01/08/260781785/is-sugar-addiction-why-so-many-january-diets-fail">sugar</a>).</p><p>How different are the feedback loops in media and food from the feedback loop in consumer loans? How many loans is too many loans?</p><p><a href="https://www.institutionalinvestor.com/article/b1nnpcj5q3l8wd/Charles-Schwab-Is-Quietly-One-of-the-Biggest-Banks-in-America-That-s-a-Problem">Charles Schwab has quietly become one of America's biggest banks</a> and plans to focus on loans since interest rates are so low and trading commissions have gone to zero. Increasingly, all financial services companies are in all lines of financial services. And competition is only going to increase as bank platform as a service offerings <a href="https://a16z.com/2020/01/21/every-company-will-be-a-fintech-company/">enable every company to be a fintech</a>. </p><p>What happens if loans are one of the few places left in financial services to make money, but now they're available from literally everyone? The same old product. A commodity. </p><p>And what if <a href="https://a16z.com/2020/10/01/fintech-for-gen-z/">Gen Z decides they don't want as many loans</a>, as the evidence suggests?</p><p>What do you do?</p><h2 id="build-something-no-one-else-can-measure">Build something no one else can measure</h2><p>The prevailing wisdom in media is to maximize engagement. This means you want people to spend as long as possible on your website. Google, by contrast, is optimized to <a href="https://www.google.com/about/philosophy.html">minimize the time you spend on their website</a>:</p><!--kg-card-begin: markdown--><blockquote>
<p>We know your time is valuable, so when you’re seeking an answer on the web you want it right away–and we aim to please. We may be the only people in the world who can say our goal is to have people leave our website as quickly as possible.</p>
</blockquote>
<!--kg-card-end: markdown--><p>Uber and Lyft <a href="https://www.uber.com/us/en/ride/transit/">show public transportation options</a> for users in their app even though they make no money if a user chooses them. Why? They are optimizing for the best way to get a user from point A to point B. They know that in many cases Uber or Lyft are the best option. Their goal is to be the starting point for <em>all</em> a user's trips, so they can measure and optimize them. Something public transit operators cannot do.</p><figure><img src="https://andyjagoe.com/content/images/2020/11/bostonjp1.png" alt="" srcset="https://andyjagoe.com/content/images/size/w600/2020/11/bostonjp1.png 600w, https://andyjagoe.com/content/images/2020/11/bostonjp1.png 720w" sizes="(min-width: 720px) 720px"></figure><p>In a world where most retailers want to minimize returns, Zappos has optimized to maximize them. They made returns a delight and part of shopping, noting that <a href="https://www.fastcompany.com/1614648/zappos-best-customers-are-also-ones-who-return-most-orders">the more goods their customers returned, the better they were for business</a>:</p><!--kg-card-begin: markdown--><blockquote>
<p>Our best customers have the highest returns rates, but they are also the ones that spend the most money with us and are our most profitable customers.<br>
-Craig Adkins, VP of services and operations, Zappos</p>
</blockquote>
<!--kg-card-end: markdown--><p><a href="https://sriramk.com/about">Sriram Krishnan</a>, who's worked on the product teams at Twitter, Snap and Facebook, said one of his theories on how to compete with major platform companies is to "<a href="https://sriramk.com/building-unmeasurable-things">build something that optimizes for a metric they can't measure.</a>"</p><p>This is also true in financial services.</p><p>It's not enough for financial services companies to evolve from sales organizations into software companies. You cannot win by optimizing for today's inward looking metrics. They result in <a href="https://kortina.nyc/essays/metrics-incrementalism-and-local-maxima/">incrementalism and local maxima</a>. </p><p>Tomorrow's winners will optimize for a metric that measures <strong>customer value</strong>.</p><p>Perhaps it's wealth generated per customer. Or percent of monthly income saved. Or even average improvement in credit score.</p><p>Whatever the metric is, it will reflect the fact that financial services will soon improve at the rate of phones or Internet service. Just like all digital products do.</p><p>This may sound unimaginable today. </p><p>So was iPhone upending the value chain in wireless and claiming the majority of profits. Or Craigslist taking every US telecom provider's yellow pages business from $10 billion to zero. The list goes on and on.</p><p>It won't be easy. And there will be many failures. But companies that win will optimize for a metric that makes customers feel awesome. Like they have a superpower. In the same way that using Google or iPhone feels like a superpower.</p><p>They'll be loved by customers. And bigger businesses than ever seen before.</p><p><em>Did you like this article? <a href="#subscribe">Subscribe now</a> to get content like this delivered free to your inbox. Learn more about what I do: <a href="https://andyjagoe.com/services/" rel="nofollow noopener">https://andyjagoe.com/services/</a></em></p><hr><!--kg-card-begin: html--><!--kg-card-end: html-->
                </div>
            </section>

                <section>
    <h3>Subscribe to Andy Jagoe</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://andyjagoe.com/how-to-beat-the-bank/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047840</guid>
            <pubDate>Tue, 10 Nov 2020 16:35:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Gods on Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 303 | Comments 157 (<a href="https://news.ycombinator.com/item?id=25047838">thread link</a>) | @ivm
<br/>
November 10, 2020 | https://www.riknieu.com/the-gods-on-hackernews/ | <a href="https://web.archive.org/web/*/https://www.riknieu.com/the-gods-on-hackernews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>(Photo by <a href="https://unsplash.com/@tank_ghisletti?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Francisco Ghisletti</a> on <a href="https://unsplash.com/s/photos/greek-gods?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>)</p><p>(This post is mostly fun and tongue-in-cheek, please contain your indignation.)</p><p>Every so often I encounter a comment on HackerNews that involuntarily makes my jaw drop, head shake and eyes water. It's usually concerning what some on HackerNews consider a 'worthwhile' amount of money you can earn as an solopreneur or maker VS being an employee. </p><p>Obviously, it's probably a small minority of the silent masses who scroll through HN daily who have these views, but comments like the following, or a variant of it comes up so often I can't help but feel that a decent part of the community is <em>ridiculously</em> out of touch with the rest of humanity. </p><p>Behold.</p><!--kg-card-begin: html--><blockquote><p lang="und" dir="ltr">😂 <a href="https://t.co/mg1UFHxp08">https://t.co/mg1UFHxp08</a></p>— Pete from No CS Degree (@petecodes) <a href="https://twitter.com/petecodes/status/1326144308706209798?ref_src=twsrc%5Etfw">November 10, 2020</a></blockquote> <!--kg-card-end: html--><p>$1000 per month from a side project is considered meh. 😳 🙃</p><p>And here's another from the same day,</p><figure><img src="https://www.riknieu.com/content/images/2020/11/soundslikealot.png"></figure><p>And from the same user a few scrolls later,</p><figure><img src="https://www.riknieu.com/content/images/2020/11/FANG.png"></figure><p>My god. Look, the commenter had the self awareness to bring up regional cost of living and that not everyone can work at the FAMANGs of the world, but really? Getting $3.7 million dollars for just 7 years of work is, like, a bad deal?</p><p>To consider making $500K pa as a doable, realistic salary to be taken into account when deciding between starting a company or just seeking a job... Like us millennials say, "I can't. Even." </p><p>That annual salary far outstrips what I can reasonably expect to earn in a decade, and I'm a developer working for a fintech startup with a good couple of years under my belt. For most people in the world, $500K pa is a <em><strong>preposterous</strong></em> amount of money. </p><p>I'm too lazy to go dig up more examples, but I'm sure you'll find some more gems like these if you go digging around on past threads.</p><p>This kind of poo-pooing of what most - and I'm talking 90% of the US population, never mind the rest of the world! - would consider rather large amounts of money is incredibly mind-blowing and makes my head spin.</p><p>Now I'm sure that in commenters like the above's worlds, that kind of money is indeed average and peanuts, but I wanted to write this article for myself and the rest of us to just try and deal. </p><p>I'm trying to make sense of the fact that I'm on this forum, interacting with people everyday, talking about current events and issues, that make more money per year than I can even imagine. In a way we're peers, but more realistically they're like the gods of Olympus who occasionally slum it with the rest of us.</p><p>So if you're like me, and you consider even a $1000 as lot of money, let's look at this as average mortals should.</p><h2 id="1-1000pm-is-a-flippen-lot">1) $1000pm is a flippen lot</h2><p>Let's go with the $1000 pm example, because figures like $3.6 million is, to be frank, in the realms of La-La land for me and almost everyone I know personally. </p><p>And let's - for the sake of simplicity - assume that you can take home 60% of that revenue as net earnings. And that the project doesn't take up more free time with maintenance and support issues than you can handle on your own. That's $600 per month. Extra. From a thing on the side. </p><p>I realise that I live in one of those cheap, unappealing parts of the world, but that kinda money would easily cover me and my family's rent every month, and then some. Do you realise how much of a mental weight that can take off a persons shoulders? To know rent is covered over and above your day-job earnings?</p><p>Away with your $1000-is-not-worth-it malarky!</p><h2 id="2-making-money-with-your-own-products-is-hard-">2) Making money with your own products is HARD.</h2><p>Take a look at <a href="https://www.indiehackers.com/post/holy-heck-this-is-hard-8ebe864174">this post</a> by <a href="https://twitter.com/mccrmx">Chris McCormick</a>, titled "<a href="https://www.indiehackers.com/post/holy-heck-this-is-hard-8ebe864174">Holy heck this is hard</a>". </p><p>When he last checked, 12 solo founders out of 17207 made more than $10K MRR. Only 54 products made more than $2000pm. I don't think I need to express that in ratios for you to see the probability of making a profitable project.</p><p>Starting a product and <em>actually earning money from it</em> is hard. Insanely hard. Hell, if you manage to make even $100pm from a side project you've got my respect. You've got me beat by a lot!</p><p>When I see makers on IndieHackers or Twitter celebrate $100 in sales I get genuinely excited for them. It's really an incredible feat. Bravo to them, I wish them luck and more success in the future.</p><h2 id="that-1000-per-month-can-grow">That $1000 per month can grow</h2><p>Another thing to consider is that earning a $1000 pm means your project is basically validated and ready to explode. With work, you could probably scale it to much higher multiples. </p><p>Sure, the money it makes is negligible to the higher beings in Silicon Valley, but for us regular plebs that's a <em>strong</em> signal that your project potentially has legs. It might even be a project you could sell for $3.7 million dollars in 7 years time, if you put the work in and get a little lucky.</p><h2 id="ya-but-rik-cost-of-living">Ya, but Rik, cost of living</h2><p>Sure, things cost more in the States. And more so in SanFran. But I can't just up and go live in the States. Nor pretty much anywhere else in the First World. A heck of a lot of the people frequenting HN, TW and IH on a daily basis could probably not either.</p><p>So for people like us, it's inspiring to read about some rando making a $1000 pm, on their own, independently. It gives us hope that some dude in Alabama could start a thing and sell it for more money than we could expect to earn in a lifetime as a salaried employee. Because maybe that means we could too.</p><p>Because they used the same tools we have access too(except for Stripe 😝). They had access to the same markets we could reach. </p><p>And they make the kinds of money with those tools that could buy people like us freedom. Freedom from being chained to a job, freedom from financial stress, and possibly even the freedom to move our families to better places in the world. Places that others just get born in.</p><p>So when you see smarmy comments on HackerNews new putting down the success of others, take a step back and realise, it's not meant for you. It's not personal. </p><p>These are merely the musings of a few lucky, privileged gods, reflecting on the toils of the mortals.</p><p>Thanks for reading. If you have any comments or suggestions, follow and contact me on Twitter <a href="https://twitter.com/riknieu">@RikNieu</a>.</p><p>If you want to read more of my rants, sign up below and I'll mail you when I post new stuff. 👇</p>
			</section></div>]]>
            </description>
            <link>https://www.riknieu.com/the-gods-on-hackernews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047838</guid>
            <pubDate>Tue, 10 Nov 2020 16:34:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Origins of the youtube-dl project]]>
            </title>
            <description>
<![CDATA[
Score 492 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25047818">thread link</a>) | @rg3
<br/>
November 10, 2020 | https://rg3.name/202011071352.html | <a href="https://web.archive.org/web/*/https://rg3.name/202011071352.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<div>
<h3><a href="https://rg3.name/202011071352.html">Origins of the youtube-dl project</a></h3>
<p>Posted on <time>2020-11-07T13:52Z</time>. Updated on <time>2020-11-10T16:28Z</time>.</p>


<p>As you may know, as of the time this text is being written <a href="https://github.com/ytdl-org/youtube-dl">youtube-dl’s repository at GitHub</a> is blocked due to a <a href="https://github.com/github/dmca/blob/master/2020/10/2020-10-23-RIAA.md">DMCA takedown letter</a> received by GitHub on behalf of the RIAA. While I cannot comment on the current maintainers' plans or ongoing discussions, in light of the claims made in that letter I thought it would be valuable to put in writing the first years of youtube-dl as the project creator and initial maintainer.</p>
<div>
<h4 id="_copper_thieves">Copper thieves</h4>
<p>All good stories need at least a villain so I have arbitrarily chosen copper thieves as the villains of the story that set in motion what youtube-dl is today. Back in 2006 I was living in a town 5 to 10 kilometers away from <a href="https://en.wikipedia.org/wiki/Avil%C3%A9s">Avilés</a>, which is itself a small city or town in northern Spain. While people in Avilés enjoyed some nice infrastructures and services, including cable and ADSL Internet access, the area I lived in lacked those advantages. I was too far away from the telephone exchange to enjoy ADSL and copper thieves had been stealing copper wires along the way to it for years, causing telephone service outages from time to time and making the telephone company replace those wires with weaker and thinner wires, knowing they would likely be stolen again. This had been going on for several years at that point.</p>
<p>This meant my only choice for home Internet access so far had been a dial-up connection and a <a href="https://en.wikipedia.org/wiki/Modem#Standardized_56k_(V.90/V.92)">56k V.90 modem</a>. In fact, connection quality was so poor I had to limit the modem to 33.6 kbps mode so the connection would be at least stable. Actual download speeds rarely surpassed 4 KB/sec. <a href="https://en.wikipedia.org/wiki/YouTube">YouTube</a> was gaining popularity then to the point it was purchased by Google at the end of that year.</p>
</div>
<div>
<h4 id="_up_all_night_to_get_some_bits">Up all night to get some bits</h4>
<p>Watching any YouTube video on the kind of connection I described above was certainly painful, as you can imagine. Any video that was moderately big would take ages to download. For example, a short 10 MB video would take, if you do the math, 40 minutes to download, making streaming impossible. A longer and higher-quality video would take several hours and render the connection unusable for other purposes while you waited for it to be available, not to mention the possibility of the connection being interrupted and having to start the download process again. Now imagine liking a specific video a lot after watching it and wanting to watch it a second or third time. Going through that process again was almost an act of masochism.</p>
<p>This situation made me interested in the possibility of downloading the videos I was trying to watch: if the video was interesting, having a copy meant I could watch it several times easily. Also, if the downloader was any good, maybe the download process could be resumed if the connection was interrupted, as it frequently was.</p>
<p>At the time, there were other solutions to download videos from YouTube, including a quite popular <a href="https://addons.mozilla.org/en-US/firefox/addon/greasemonkey/">Greasemonkey</a> script. By pure chance, none of the few I tested were working when I did, so I decided to explore the possibility of creating my own tool. And that is, more or less, how youtube-dl was born. I made it a command-line program so it would be easy to use for me and wrote it in Python because it was easy thanks to its extensive standard library, with the nice side effect that it would be platform independent.</p>
</div>
<div>
<h4 id="_an_ethereal_start">An Ethereal start</h4>
<p>The initial version of the program only worked for YouTube videos. It had almost no internal design whatsoever because it was not needed. It did what it had to do as a simple script that proceeded straight to the point. Line count was merely 223, with only 143 being actual lines of code, 44 for comments and 36 of them blank. The name was chosen out of pure convenience: youtube-dl was an obvious name, hard to forget, and it could be intuitively typed as “Y-O-U-TAB” in my terminal.</p>
<p>Having been using Linux for several years at that point, I decided to publish the program under a free software license (MIT for those first versions) just in case someone could find it useful. Back then, GitHub did not exist and we had to “make do” with <a href="https://en.wikipedia.org/wiki/SourceForge">SourceForge</a>, which had a bit of a tedious form that you needed to fill to create a new project. So, instead of going to SourceForge, I quickly published it under <a href="https://web.archive.org/web/20060812055952/http://www.arrakis.es/~rggi3/youtube-dl/">the web space that my Internet provider gave me</a>. While not usual today, it was common for ISPs to give you an email address and some web space you could upload stuff to using FTP. That way, you could have your own personal website on the net. The first ever version made public was 2006.08.08, although I probably had been using the program for a few weeks at that point.</p>
<p>To create the program, I studied what the web browser was doing when watching a YouTube video using Firefox. If I recall correctly, Firefox didn’t yet have the development tools it has today to analyze network activity. Connections were mostly HTTP and <a href="https://en.wikipedia.org/wiki/Wireshark">Wireshark</a>, known as “Ethereal” up to that year, proved invaluable to inspect the network traffic coming in and out of my box when loading a YouTube video. I wrote youtube-dl with the specific goal of doing the same things the web browser was doing to retrieve the video. It even sent out a User-Agent string that was verbatim copied from Firefox for Linux, as a way to make sure the site would send the program the same version of video web pages that were used to study what the web browser was doing.</p>
<p>In addition, YouTube used <a href="https://en.wikipedia.org/wiki/Adobe_Flash">Adobe Flash</a> back then for the player. Videos were served as Flash Video files (FLV), and this all meant a proprietary plugin was required to watch them on the browser (many will remember the dreaded <code>libflashplayer.so</code> library), which would have made any browser development tools useless. This proprietary plugin was a constant source of security advisories and problems. I used a Firefox extension called <a href="https://en.wikipedia.org/wiki/Flashblock">Flashblock</a> that prevented the plugin from being loaded by default and replaced embedded content using the plugin, in web pages, with placeholder elements containing a clickable icon so content would be loaded only on demand and the plugin library was not used unless requested by the user.</p>
<p>Flashblock had two nice side effects apart from making the browsing experience more secure. On the one hand, it removed a lot of noisy and obnoxious ads from many web pages, which could also be a source of security problems when served by third parties. On the other hand, it eased analyzing how videos were being downloaded by the video player. I would wait until the video page had finished downloading completely and then start logging traffic with Wireshark just before clicking on the embedded video player placeholder icon, allowing it to load. This way, the only traffic to analyze was related to the plugin downloading the video player application and the application itself downloading the video.</p>
<p>It’s also worth noting the Flash Player plugin back then <a href="https://www.nirsoft.net/articles/copy_flash_flv_temp_file.html">was already downloading a copy of those videos to your hard drive</a> (they were stored in <code>/tmp</code> under Linux) and many users relied on that functionality to keep a copy of them without using additional tools. youtube-dl was simply more convenient because it could retrieve the video title and name the file more appropriately in an automated way, for example.</p>
</div>
<div>
<h4 id="_ahh_fresh_meat">Ahh, fresh meat!</h4>
<p>The Flash Player plugin was eventually <a href="https://www.omgubuntu.co.uk/2010/09/saving-flash-videos-in-linux-tmp-no-longer-works">modified so videos wouldn’t be so easily available to grab</a>. One of the first measures was to <a href="https://en.wikipedia.org/wiki/Unlink_(Unix)">unlink</a> the video file after creating it, so the i-node would still exist and be available to the process using it (until it was closed) while keeping the file invisible from the file system point of view. It was still possible to grab the file by using the <code>/proc</code> file system to examine file descriptors used by the browser process, but with every one of those small steps youtube-dl turned to be more and more convenient.</p>
<p>As many free and open source enthusiasts back then, I used <a href="https://en.wikipedia.org/wiki/Freecode">Freshmeat</a> to subscribe to new releases of projects I was interested in. When I created youtube-dl, I also created a project entry for it in that website so users could easily get notifications of new releases and a change log listing new features, fixes and improvements. Freshmeat could also be browsed to find new and interesting projects and its front page contained the latest updates, which usually amounted to only a few dozens a day. It’s only my guess that’s the way <a href="https://en.wikipedia.org/wiki/Joe_Barr">Joe Barr</a> (rest in peace), an editor for <a href="https://en.wikipedia.org/wiki/Linux.com">linux.com</a>, found out about the program and decided to write <a href="https://www.linux.com/news/cli-magic-enhance-your-youtube-viewing-pleasure/">an article about it</a> back in 2006. Linux.com was a bit different then and I think it was one of the frequently-visited sites for Linux enthusiasts together with other classics like <a href="https://en.wikipedia.org/wiki/Slashdot">Slashdot</a> or <a href="https://en.wikipedia.org/wiki/LWN.net">Linux Weekly News</a>. At least, it was for me.</p>
<p>From that point on, youtube-dl’s popularity started to grow and I started getting some emails from time to time to thank me for creating and maintaining the program.</p>
</div>
<div>
<h4 id="_measuring_buckets_of_bits">Measuring buckets of bits</h4>
<p>Fast forward to the year 2008. youtube-dl’s popularity had kept growing slowly and users frequently asked me to create similar programs to download from more sites, a request I had conceded a few times. It was at that point that I decided to rewrite the program from scratch and make it support multiple video sites natively. I had some simple ideas that would separate the program internals into several pieces. To simplify the most important parts: one would be the file downloader, common for every website, and another one would be the information extractors: objects (classes) that would contain code specific to a video site. When given a URL or pseudo-URL, the information extractors would be queried to know which one could handle that type of URL and then requested to extract information about that video or list of videos, with the primary goal of obtaining the video URL or a list of video URLs with available formats, together with some other metadata like the video titles, for example.</p>
<p>I also took the chance to switch version control systems and change where the project would be hosted. …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rg3.name/202011071352.html">https://rg3.name/202011071352.html</a></em></p>]]>
            </description>
            <link>https://rg3.name/202011071352.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047818</guid>
            <pubDate>Tue, 10 Nov 2020 16:33:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jack Ma's Bund Finance Summit Speech]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25047544">thread link</a>) | @ceohockey60
<br/>
November 10, 2020 | https://interconnected.blog/jack-ma-bund-finance-summit-speech/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/jack-ma-bund-finance-summit-speech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <!-- social share icon -->
                    

                    <p><em>I don’t normally do any translation, because Interconnected is focused on original work and thinking. But I felt compelled to provide an English version of Jack Ma’s speech on October 24 at the Bund Finance Summit in Shanghai, because mainstream media coverage of the speech and the subsequent cancellation of Ant Group’s IPO has been lacking and simplistic. The speech is worth reading in its entirety to have a deeper understanding the full picture. Below is my unofficial translation of the speech </em><a href="https://sfl.global/news_post/mayunshanghaiwaitanjinrongluntanyanjiangquanwenwushanjian/"><em>based on a Chinese transcript</em></a><em>, with minor edits for clarity and speechifying. To read my deep dive analysis on the speech and its broader context, please check out: "<a href="https://interconnected.blog/jack-ma-p2p-lending-responsibility-legacy/">Jack Ma, P2P Lending, Responsibility, Legacy</a>"</em></p><p><em>我通常不做任何翻译工作，因为《互联》专注于原创作品和思考。但我觉得有必要提供马云10月24日在上海外滩金融峰会上的演讲的一个英文版，尽管只是我个人非官方的翻译，因为主流媒体对演讲和随后蚂蚁集团取消上市的报道太欠缺，过于简单化。整套演讲值得一读来更深层的了解整个事情，可以在</em><a href="https://sfl.global/news_post/mayunshanghaiwaitanjinrongluntanyanjiangquanwenwushanjian/"><em>这里看全文</em></a><em>，在</em><a href="https://finance.sina.com.cn/chanjing/gsnews/2020-10-28/doc-iiznctkc8161643.shtml"><em>这里看视频</em></a><em>。想看我对这套演讲和有关大观景的深度分析，请读《<a href="https://interconnected.blog/jack-ma-p2p-lending-responsibility-legacy/">马云，P2P借贷，责任，留给社会的遗产</a>》</em></p><hr><p>Thank you for inviting me to this Summit. I am delighted to have this opportunity to learn, discuss, and exchange ideas together with you. In 2013, also in Shanghai, I came to the Lujiazui Finance Summit and shared some “pie in the sky” views about Internet-powered finance. Seven years later, today I'm back in Shanghai as an unofficial non-professional person here at the Bund Finance Summit, hoping to share more ideas for you to ponder.</p><p>Actually, I was quite torn about whether to speak here today. But I think there is one thing that is incumbent upon this group of people, and that is the responsibility to think about the future, because although the world has left us many opportunities for development, there are really only one or two critical opportunities. This is a most critical moment.</p><p>So I come here to share some of my own thoughts and views, which are the result of our own practical experience in the last 16 years, plus discussions and research I have had with scholars, experts, and practitioners from all over the world, during the period when I was honored to be the co-chair of the UN High-Level Panel on Digital Cooperation and an advocate for the UN Sustainable Development Goals (SDGs).</p><p>I’m basically retired at this point, so I thought I'd speak freely at this unofficial forum and share the non-professional views of a non-professional person. Fortunately, I've discovered that many professionals no longer speak about their professions anymore.</p><p>I have three points of view for you to consider. They may be immature, incorrect, or laughable. Just give them a listen, if they make no sense, just forget about them.</p><p>The first point of view is we have some inertia in our thinking, like we always feel that in order to keep pace with international standards, we must do what developed countries like Europe and the United States have done. If we don’t have something they have, the so-called “blank spot”, we must fill those blank spots domestically. Filling these spots has become the goal to pursue.</p><p>I have always felt that, given this year's situation, the phrase to “fill the blank spot” is problematic. Just because Europe and the United States have something does not mean that thing is always advanced and worth having ourselves. In fact, today, we should not be concerned about what things to align with, which country's standard to adapt to, what blank spots to fill. Today, we have to think about how to align with the future, how to adapt to the future’s standard, how to fill the future’s blank spots. We have to figure out what the future will be, and what we really want to do, and then look at how others do it. If we always repeat the language of others, discuss topics defined by others, we will not only be lost in the present, but also miss the future.</p><p>After World War II, the world needed to restore economic prosperity. The establishment of the Bretton Woods system was an enormous catalyst to the global economy. Later, after the Asian financial crisis occurred, the Basel Accords talked about risk control, which has been gaining more and more attention, to the point that it became an operational standard for risk control. Now the trend is, the world is talking more and more just about risk control, not development. Very few people talk about where the opportunities are for young people, for developing countries.</p><p>This, in fact, is the root cause of many of the world's problems today. We also see today that the Basel Accords have put great limitations on Europe’s ability to innovate as a whole, for example, in digital finance.</p><p>Basel, more like a seniors club, is about solving the problem of an aging financial system that has been operating for decades, and Europe’s aging system is extremely complex. But the problem in China is the opposite: it is not a problem of systemic financial risk, because China's financial sector basically doesn’t have a system. Its risk is actually a "lack of financial system."</p><p>China's financial sector, like other developing countries that have just grown up, is a young industry that does not have a mature ecosystem and is not fully moving. China has many big banks. They are more like big rivers or arteries in our body’s circulatory system, but today we need more lakes, ponds, streams and tributaries, all kinds of swamps. Without these parts of the ecosystem, we will die when we are flooded, and die when we are in a drought. So, today we are a country that bears the risk of lacking a healthy financial system, and we need to build a healthy financial system, not worry about financial systemic risks.</p><p>They are like two completely different diseases, like Alzheimer's disease and polio. Both look similar at first glance but are two totally different illnesses. If a child takes Alzheimer's medication, he or she will not only get the old person’s disease, but a lot of other strange diseases as well.</p><p>The Basel Accords is designed to treat the diseases of the elderly with an aging system and over-complexity, and what we have to think about is what can we learn from the elderly? You must remember, older people and younger people care about different issues. Younger people care about whether there are schools, older people care about whether there are hospitals.</p><p>So, the way the world is changing this year is fascinating and very fast. Last night in Shanghai, we decided on the pricing of Ant’s IPO. This is the largest listing ever priced in the history of the entire human race, and the pricing happened in a place other than New York City. This was unthinkable five years ago, even three years ago, but miracles happen.</p><p>Second, innovation must come at a price, and our generation must take on that responsibility.</p><p>President Xi once said, "success does not have to come from me." I understand this phrase to be about a sense of responsibility. It’s about taking responsibility for the future, for tomorrow, for the next generation. Many of the world's problems today, including China's, can only be solved by innovation. However, for real innovation to happen, no one will show you the way, and someone must shoulder that responsibility, because innovation is bound to make mistakes. But the question is not how not to make mistakes, but whether we can perfect and correct them after making mistakes and persistently innovate. To make risk-free innovation is to stifle innovation, and there is no risk-free innovation in this world. There is no such thing as risk-free innovation. Oftentimes, managing risk down to zero is the biggest risk.</p><p>When the battle of Red Cliff was fought, I believe Cao Cao’s act of connecting all the ships together was the first instance of an aircraft carrier, in China and the world, but after a fire burned it all down, for a thousand years, the Chinese people didn't dare to think about it again. Once they thought about that fire, who still wanted to make a bigger ship, who could still have this kind of system-level thinking?</p><p>Seven or eight years ago, also in Shanghai, I mentioned this concept of Internet-powered finance. We have always emphasized that Internet-powered finance must have three core elements: first, it must have rich data; second, it must have risk control technology based on rich big data; and third, it must have a credit-based system built on big data.</p><p>Using these three criteria to evaluate, we can see that P2P is not Internet-powered finance at all, but today we cannot negate the innovation that the Internet has brought to finance just because of P2P. In fact, let's think about it, how can there be thousands of Internet-powered finance companies in China within a few years? Shouldn't we examine what gave birth to thousands of “Internet-powered finance”, the so-called P2P companies?</p><p>Today, it's really difficult to regulate ourselves; it's hard to conduct regulation everywhere around the globe. Innovation mainly comes from the marketplace, innovation comes from the grassroots, innovation comes from young people. Regulatory challenges are getting bigger and bigger. In fact, <em>jian </em>[editor's note: English word is “supervision”, the first character in the word for “regulation” in Chinese] and <em>guan </em>[editor's note: English word is “management”, the second character in the word for “regulation” in Chinese] are two different things. "Supervision" means watching you as you develop and paying attention to your development. “Management” means intervening when there is a problem or when there is a foreseeable problem.</p><p>We are very good at “management”, but our “supervision” ability is sorely lacking.</p><p>Good innovation is not afraid of regulation, but is afraid of being subjected to yesterday's way to regulate. We cannot use the way to manage a railway station to manage an airport. We cannot use yesterday's way to manage the future.</p><p>"Supervision" and "management" are not the same, “policies” and “documents” are also not the same. This isn’t allowed, that isn’t allowed, those are all called “documents”. Policy …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/jack-ma-bund-finance-summit-speech/">https://interconnected.blog/jack-ma-bund-finance-summit-speech/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/jack-ma-bund-finance-summit-speech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047544</guid>
            <pubDate>Tue, 10 Nov 2020 16:10:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C source-to-source compiler enhancement from within]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25047169">thread link</a>) | @ingve
<br/>
November 10, 2020 | https://hal.inria.fr/hal-02998412 | <a href="https://web.archive.org/web/*/https://hal.inria.fr/hal-02998412">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <p><strong>Abstract</strong> : We show how locally replaceable code snippets can be used to easily
  specify and prototype compiler and language enhancements for the
  C language that work by local source-to-source
  transformation.
  A toolbox implements the feature and provides many directives that
  can be used for compile time configuration and tuning, code
  unrolling, compile time expression evaluation and program
  modularization.
  The tool is also easily extensible by simple filters that can be
  programmed with any suitable text processing framework.                    </p>
                                </div><p><small>
                https://hal.inria.fr/hal-02998412<br>
                Contributeur : <a rel="nofollow" href="https://hal.inria.fr/search/index/q/*/contributorId_i/105206" target="_blank">Jens Gustedt</a>                        &lt;<a href="" id="link5fae0a3db0209"></a>&gt;
                        <br>Soumis le : mardi 10 novembre 2020 - 15:02:12<br>DerniÃ¨re modification le : mercredi 11 novembre 2020 - 03:36:16</small>
        </p></div>]]>
            </description>
            <link>https://hal.inria.fr/hal-02998412</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047169</guid>
            <pubDate>Tue, 10 Nov 2020 15:42:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Event: How Apple Silicon Changes Mac Forever]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25047142">thread link</a>) | @aasthembolt
<br/>
November 10, 2020 | https://heartbeat.fritz.ai/how-apple-silicon-changes-mac-forever-d2682a9722df | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/how-apple-silicon-changes-mac-forever-d2682a9722df">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="cb2b">WWDC20</h2><h2 id="087c">Learn more about Apple’s ARM-based silicon chips for Mac, announced at WWDC20</h2><div><div><div><p><a href="https://medium.com/@vhanagwal?source=post_page-----d2682a9722df--------------------------------" rel="noopener"><img alt="Vardhan Agrawal" src="https://miro.medium.com/fit/c/96/96/1*ORFRUf6O2Tk4XbG3kElncQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><figure><div role="button" tabindex="0"><div><p><img alt="Image for post" src="https://miro.medium.com/max/5000/1*3RTZkevqc5ZvJpivlnc1mg.jpeg" width="2500" height="1599" srcset="https://miro.medium.com/max/552/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 276w, https://miro.medium.com/max/1104/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 552w, https://miro.medium.com/max/1280/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 640w, https://miro.medium.com/max/1456/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 728w, https://miro.medium.com/max/1632/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 816w, https://miro.medium.com/max/1808/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 904w, https://miro.medium.com/max/1984/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 992w, https://miro.medium.com/max/2160/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1080w, https://miro.medium.com/max/2700/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1350w, https://miro.medium.com/max/3240/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1620w, https://miro.medium.com/max/3780/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1890w, https://miro.medium.com/max/4320/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 2160w, https://miro.medium.com/max/4800/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*3RTZkevqc5ZvJpivlnc1mg.jpeg?q=20"></p></div></div></figure></div><div><div><p id="93b7">At the end of the WWDC20 Keynote, Apple announced that it’s switching from Intel processors to its own: Apple Silicon. The release of custom Apple chips, powered by ARM, comes after a long history of using Intel-based chips, for the greater part of the 21st century.</p><p id="0fc0">Modeled after Apple’s use of its own chips on the iPhone, iPad, and Apple Watch, the company is switching to its own chips to give the Mac more performance per watt and better GPU performance.</p><p id="ecaf">Though we won’t go in-depth into the specific implications for machine learning, there’s a lot to be excited about when it comes to the future of ML development on Mac. Inevitably, the enhanced GPU performance will be a boon to machine learning developers, with benefits ranging from faster model training to reduced reliance on transfer learning. It will be interesting to see how ML engineers capitalize on Apple Silicon over time.</p></div></div></section><section><div><div><p id="10c8">The Mac, often considered Apple’s flagship lineup, has seen a couple changes in the past. Let’s look at what those changes were and how they’ve contributed to the evolution of the Mac.</p><h2 id="114e">Motorola 68K to PowerPC</h2><p id="d699">One of the earliest transitions in chip architecture was the transition from Motorola 68K chips to IBM and Motorola PowerPC chips. This was an incredible transition, which significantly improved the Mac and played an important role in understanding future transitions.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1560/1*gf2Y6U112riltsrAmT6VaA.png" width="780" height="439" srcset="https://miro.medium.com/max/552/1*gf2Y6U112riltsrAmT6VaA.png 276w, https://miro.medium.com/max/1104/1*gf2Y6U112riltsrAmT6VaA.png 552w, https://miro.medium.com/max/1280/1*gf2Y6U112riltsrAmT6VaA.png 640w, https://miro.medium.com/max/1400/1*gf2Y6U112riltsrAmT6VaA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*gf2Y6U112riltsrAmT6VaA.png?q=20"></p></div></div></div><figcaption>The original iMac with a PowerPC processor.</figcaption></figure><h2 id="ed43">PowerPC to Intel x86</h2><p id="6ac1">The most notable transition was the move from PowerPC chips to Intel processors, which have been used for almost half of the Mac’s history so far. With this transition, Apple announced a developer kit to help with the transition, similar to what they announced in the switch to Apple Silicon.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2400/1*YIIun0yR2job_s0MRzSINg.png" width="1200" height="675" srcset="https://miro.medium.com/max/552/1*YIIun0yR2job_s0MRzSINg.png 276w, https://miro.medium.com/max/1104/1*YIIun0yR2job_s0MRzSINg.png 552w, https://miro.medium.com/max/1280/1*YIIun0yR2job_s0MRzSINg.png 640w, https://miro.medium.com/max/1400/1*YIIun0yR2job_s0MRzSINg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*YIIun0yR2job_s0MRzSINg.png?q=20"></p></div></div></div><figcaption>A recent, Intel-based MacBook Pro.</figcaption></figure></div></div></section><section></section><section><div><div><p id="4c63">Undoubtedly, a switch to ARM-based Macs has a huge advantage for the performance and usability of Macs. Let’s look at how Apple Silicon will improve the Mac’s experience.</p><h2 id="71ef">Performance per Watt</h2><p id="e98c">Apple Silicon promises a stark improvement in performance per watt, meaning that the Mac could potentially promise desktop-level performance with the power consumption of a notebook computer, as exemplified by Apple’s diagram:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3440/1*485W2PItyV9fz4UiWem0eQ.png" width="1720" height="953" srcset="https://miro.medium.com/max/552/1*485W2PItyV9fz4UiWem0eQ.png 276w, https://miro.medium.com/max/1104/1*485W2PItyV9fz4UiWem0eQ.png 552w, https://miro.medium.com/max/1280/1*485W2PItyV9fz4UiWem0eQ.png 640w, https://miro.medium.com/max/1400/1*485W2PItyV9fz4UiWem0eQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*485W2PItyV9fz4UiWem0eQ.png?q=20"></p></div></div></div><figcaption>Performance per watt for Apple Silicon</figcaption></figure><h2 id="95f4">Native Apps</h2><p id="b37d">Apps that support Apple Silicon natively will perform best on the new ARM-based Macs. Out-of-the-box, Apple’s own apps, including pro apps like Final Cut Pro and Logic Pro, will have native support for Apple Silicon. In addition, through their collaboration with Adobe, the Creative Cloud Suite will also have native support from the get-go. Eventually, Microsoft Office and other widely used programs will be able to take advantage of Apple Silicon’s performance.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2160/1*AkSiIGraS55x_sZV5vt6_A.png" width="1080" height="607" srcset="https://miro.medium.com/max/552/1*AkSiIGraS55x_sZV5vt6_A.png 276w, https://miro.medium.com/max/1104/1*AkSiIGraS55x_sZV5vt6_A.png 552w, https://miro.medium.com/max/1280/1*AkSiIGraS55x_sZV5vt6_A.png 640w, https://miro.medium.com/max/1400/1*AkSiIGraS55x_sZV5vt6_A.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*AkSiIGraS55x_sZV5vt6_A.png?q=20"></p></div></div></div><figcaption>Photoshop running natively on an ARM-based Mac.</figcaption></figure><h2 id="2e35">iOS Apps on Mac</h2><p id="3611">Another incredible benefit of using the ARM architecture across iOS, macOS, and watchOS is the ability to run iOS apps natively on Apple Silicon Macs. Without any additional work from the developer, most iOS apps can be installed from the Mac App Store.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6718/1*SdaPx8Kn2Nw08JFB6XbDvw.png" width="3359" height="1891" srcset="https://miro.medium.com/max/552/1*SdaPx8Kn2Nw08JFB6XbDvw.png 276w, https://miro.medium.com/max/1104/1*SdaPx8Kn2Nw08JFB6XbDvw.png 552w, https://miro.medium.com/max/1280/1*SdaPx8Kn2Nw08JFB6XbDvw.png 640w, https://miro.medium.com/max/1400/1*SdaPx8Kn2Nw08JFB6XbDvw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*SdaPx8Kn2Nw08JFB6XbDvw.png?q=20"></p></div></div></div><figcaption>Running Monument Valley and Fender Play, two popular iOS apps, on a Mac.</figcaption></figure><p id="4f66">To help developers transition their apps to support Apple Silicon, Apple has announced a whole host of tools to make native and simulated support for Apple Silicon as smooth as possible for users.</p><h2 id="0ebc">Universal 2</h2><p id="8277">As the name suggests, Universal 2 allows developers to quickly compile their apps for Apple Silicon while retaining support for Intel-based Macs. By using Universal 2 in Xcode, developers will be able to use the same binary for both Intel-based Macs, while providing a native experience for those who are using a Mac with Apple Silicon.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6720/1*4Krp5sFt3beXnXbpuenl9Q.png" width="3360" height="2100" srcset="https://miro.medium.com/max/552/1*4Krp5sFt3beXnXbpuenl9Q.png 276w, https://miro.medium.com/max/1104/1*4Krp5sFt3beXnXbpuenl9Q.png 552w, https://miro.medium.com/max/1280/1*4Krp5sFt3beXnXbpuenl9Q.png 640w, https://miro.medium.com/max/1400/1*4Krp5sFt3beXnXbpuenl9Q.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*4Krp5sFt3beXnXbpuenl9Q.png?q=20"></p></div></div></div><figcaption>Universal 2 for the same binary for Intel and ARM-based Macs.</figcaption></figure><h2 id="38e9">Rosetta 2</h2><p id="49cb">An upgrade from their previous version of Rosetta (for the Intel transition), Rosetta 2 provides similar capabilities as its previous counterpart — allowing Intel-based apps to run on Apple Silicon Macs. So if app developers haven’t yet recompiled their apps with Universal 2, their users can still access legacy versions of the app through Rosetta 2.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6720/1*2qVtb8FXZoJARJJa-Pq0IQ.png" width="3360" height="2100" srcset="https://miro.medium.com/max/552/1*2qVtb8FXZoJARJJa-Pq0IQ.png 276w, https://miro.medium.com/max/1104/1*2qVtb8FXZoJARJJa-Pq0IQ.png 552w, https://miro.medium.com/max/1280/1*2qVtb8FXZoJARJJa-Pq0IQ.png 640w, https://miro.medium.com/max/1400/1*2qVtb8FXZoJARJJa-Pq0IQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*2qVtb8FXZoJARJJa-Pq0IQ.png?q=20"></p></div></div></div><figcaption>Rosetta 2 for install-time translation for Intel-based apps.</figcaption></figure><h2 id="b5ed">Virtualization</h2><p id="d298">For developers who need to use Linux, Docker, or similar tools, Apple has also announced virtualization tools for ARM Macs. These tools are expected to provide a seamless transition to Apple Silicon for developers who need server-side development tools.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6718/1*z8L5KciHtXn7DOG5_HO8Ag.png" width="3359" height="1884" srcset="https://miro.medium.com/max/552/1*z8L5KciHtXn7DOG5_HO8Ag.png 276w, https://miro.medium.com/max/1104/1*z8L5KciHtXn7DOG5_HO8Ag.png 552w, https://miro.medium.com/max/1280/1*z8L5KciHtXn7DOG5_HO8Ag.png 640w, https://miro.medium.com/max/1400/1*z8L5KciHtXn7DOG5_HO8Ag.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*z8L5KciHtXn7DOG5_HO8Ag.png?q=20"></p></div></div></div><figcaption>Running an Apache server on an ARM-based Mac.</figcaption></figure><h2 id="f765">Developer Transition Kit</h2><p id="81af">Similar to the Intel transition, developers will be able to purchase a Developer Transition Kit, which comprises a Mac Mini enclosure fitted with the A12Z SoC — used on the latest iPad lineup. The Mac Mini will have 16GB of memory and a 512GB SSD — plenty for development needs. Also, macOS Big Sur and Xcode 12 will come pre-installed on the machine, which will be available for $500 (half the price of the Intel transition kit).</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2160/1*hpX5lvJahDiZXZxjGDDLMQ.png" width="1080" height="607" srcset="https://miro.medium.com/max/552/1*hpX5lvJahDiZXZxjGDDLMQ.png 276w, https://miro.medium.com/max/1104/1*hpX5lvJahDiZXZxjGDDLMQ.png 552w, https://miro.medium.com/max/1280/1*hpX5lvJahDiZXZxjGDDLMQ.png 640w, https://miro.medium.com/max/1400/1*hpX5lvJahDiZXZxjGDDLMQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*hpX5lvJahDiZXZxjGDDLMQ.png?q=20"></p></div></div></div><figcaption>Apple’s Mac Mini Based Developer Transition Kit</figcaption></figure><p id="de05">While Apple isn’t completely transitioning to Apple Silicon just yet, the announcement of their ARM-based chip for Mac is a huge step in a two year process to change Mac for the better.</p><p id="04c2">Stay tuned for some great new tutorials on the latest frameworks this week, and get ahead of the crowd by taking use of them before they’re released to the public in the fall.</p><p id="3993">In case you missed it, here’s the Keynote in all its glory:</p><figure><div></div></figure><p id="6139">Be sure to <strong>smash that “clap” button</strong> as many times as you can, <strong>share this article</strong> on social media, and <strong>follow me on Twitter.</strong></p></div></div></section><section><div><div><p id="d325"><em>Editor’s Note:</em><a href="http://heartbeat.fritz.ai/" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We’re committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="cfac"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don’t sell ads.</em></p><p id="5eba"><em>If you’d like to contribute, head on over to our</em><a rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and</em><a href="https://www.fritz.ai/newsletter" rel="noopener"><em> </em></a><em>the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/how-apple-silicon-changes-mac-forever-d2682a9722df</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047142</guid>
            <pubDate>Tue, 10 Nov 2020 15:40:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a weather station. Final post]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25047091">thread link</a>) | @kernelmode
<br/>
November 10, 2020 | https://blog.kdubovikov.ml/articles/rust/ui/weather-station-ui | <a href="https://web.archive.org/web/*/https://blog.kdubovikov.ml/articles/rust/ui/weather-station-ui">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
<p>November 4, 2020</p>

<p>In this last post of the series we are going to look at how to build a simple weather station UI dashboard.</p>

<!--more-->



<ol>
  <li><a href="https://blog.kdubovikov.ml/articles/hardware/build-yourself-a-weather-station">Build yourself a weather station. Part I</a></li>
  <li><a href="https://blog.kdubovikov.ml/articles/hardware/build-yourself-a-weathe-station-part-2">Building yourself a weather station. Part 2</a></li>
  <li><a href="https://blog.kdubovikov.ml/articles/rust/async-unicorns-love-rust">Async Unicorns love Rust</a></li>
  <li><a href="https://blog.kdubovikov.ml/articles/rust/building-a-weather-station-bot">Building a Weather Station Bot</a></li>
  <li>→ Building a Weather Station UI</li>
</ol>


<p>In <a href="https://blog.kdubovikov.ml/articles/rust/building-a-weather-station-bot">the previous post</a> we have built a weather station bot that can notify us about new measurements made by our weather station. Today, we are going to build a simple REST API to fetch the data from our server and draw a chart on a simple dashboard.</p>


<p>Our web interface will need historical data that will be displayed in the charts. Before building an actual UI we will create a REST API that will return all sensor readings that are stored in our database. The code for the API is located in the <a href="https://github.com/kdubovikov/weather-station-bot/blob/master/src/bin/weather_station_api.rs"><code>weather_station_api.rs</code></a> file. We will use the <a href="https://docs.rs/tower-web/0.3.7/tower_web/">tower_web</a> crate to create a service that will return all sensor measurements along with their timestamps. We already have the database related code covered in the previous post. The entire service code is very concise:</p>

<div><div><pre><code><span>/// This type will be part of the web service as a resource.</span>
<span>#[derive(Clone,</span> <span>Debug)]</span>
<span>struct</span> <span>WeatherApi</span><span>;</span>

<span>/// This will be the JSON response</span>
<span>#[derive(Response)]</span>
<span>struct</span> <span>WeatherMessageResponse</span> <span>{</span>
    <span>messages</span><span>:</span> <span>Vec</span><span>&lt;</span><span>WeatherMessage</span><span>&gt;</span>
<span>}</span>

<span>impl_web!</span> <span>{</span>
    <span>impl</span> <span>WeatherApi</span> <span>{</span>
        <span>#[get(</span><span>"/"</span><span>)]</span>
        <span>#[content_type(</span><span>"json"</span><span>)]</span>
        <span>fn</span> <span>get_all_weather_messages</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>WeatherMessageResponse</span><span>,</span> <span>()</span><span>&gt;</span> <span>{</span>
            <span>let</span> <span>conn</span> <span>=</span> <span>establish_connection</span><span>(</span><span>"./db.sqlite"</span><span>);</span> <span>// this is a magic string better to be left in a config file, but I'll let it as it is for the sake of simplicity</span>
            <span>let</span> <span>weather_messages</span> <span>=</span> <span>get_all_weather_messages</span><span>(</span><span>&amp;</span><span>conn</span><span>);</span>
            <span>Ok</span><span>(</span>
               <span>WeatherMessageResponse</span> <span>{</span> <span>messages</span><span>:</span> <span>weather_messages</span> <span>}</span>
            <span>)</span>
        <span>}</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>After that all we need is to run the server somewhere inside our <code>main</code> function:</p>

<div><div><pre><code><span>let</span> <span>cors</span> <span>=</span> <span>CorsBuilder</span><span>::</span><span>new</span><span>()</span>
        <span>.allow_origins</span><span>(</span><span>AllowedOrigins</span><span>::</span><span>Any</span> <span>{</span> <span>allow_null</span><span>:</span> <span>true</span> <span>}</span> <span>)</span>
        <span>.build</span><span>();</span>

<span>ServiceBuilder</span><span>::</span><span>new</span><span>()</span>
    <span>.resource</span><span>(</span><span>WeatherApi</span><span>)</span>
    <span>.middleware</span><span>(</span><span>cors</span><span>)</span>
    <span>.run</span><span>(</span><span>&amp;</span><span>addr</span><span>)</span>
    <span>.unwrap</span><span>();</span>
</code></pre></div></div>

<p>You can check that the API works as intended by running the server and issuing an HTTP GET request with <code>curl</code> or <a href="https://www.postman.com/">Postman</a>.</p>


<p>Now, let’s create a simple UI Dashboard. The purpose of our interface will be to display a historical plot of temperature, humidity and pressure readings from our weather station. We won’t use any complex javascript frameworks and stick to vanilla javascript. This is how the final result will look like:</p>

<figure><img src="https://blog.kdubovikov.ml/assets/img/esp32-weather-station/post-1/weather-dashboard.gif"><figcaption></figcaption></figure>

<h2 id="markup">Markup</h2>
<p>For a start, let’s look at <code>index.html</code>:</p>

<div><div><pre><code><span>&lt;html&gt;</span>
<span>&lt;head&gt;</span>
	<span>&lt;link</span> <span>rel=</span><span>"stylesheet"</span> <span>href=</span><span>"styles/weather_station.css"</span> <span>/&gt;</span>
	
    <span>&lt;!-- load fonts --&gt;</span>
	<span>&lt;link</span> <span>href=</span><span>"https://fonts.googleapis.com/css2?family=Open+Sans:wght@300&amp;display=swap"</span> <span>rel=</span><span>"stylesheet"</span><span>&gt;</span>
    
    <span>&lt;!-- a few libraries that we will use --&gt;</span>
    <span>&lt;!-- a css framework for animations --&gt;</span>
	<span>&lt;link</span> <span>rel=</span><span>"stylesheet"</span> <span>href=</span><span>"https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.0.0/animate.min.css"</span> <span>/&gt;</span>

    <span>&lt;!-- chart.js for plots --&gt;</span>
	<span>&lt;script </span><span>src=</span><span>"https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"</span><span>&gt;&lt;/script&gt;</span>

    <span>&lt;!-- moment.js for working with dates --&gt;</span>
	<span>&lt;script </span><span>src=</span><span>"https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.26.0/moment.min.js"</span><span>&gt;&lt;/script&gt;</span>

    <span>&lt;!-- our main script, we will look into this later 😉 --&gt;</span>
	<span>&lt;script </span><span>src=</span><span>"index.js"</span><span>&gt;&lt;/script&gt;</span>
<span>&lt;/head&gt;</span>
<span>&lt;body&gt;</span>
    <span>&lt;!-- let's use HTML5 section tags to group --&gt;</span>
    <span>&lt;!-- related content together instead of using ambiguous div's --&gt;</span>
	<span>&lt;header&gt;</span>
		<span>&lt;div</span> <span>class=</span><span>"weatherIcon"</span><span>&gt;</span>
			<span>&lt;object</span> <span>data=</span><span>"img/weather_icon.svg"</span> <span>type=</span><span>"image/svg+xml"</span><span>&gt;&lt;/object&gt;</span>
		<span>&lt;/div&gt;</span>
		
		<span>&lt;h1&gt;</span>How's the <span>&lt;span</span> <span>class=</span><span>"accent"</span><span>&gt;</span>weather<span>&lt;/span&gt;</span>?<span>&lt;/h1&gt;</span>
	<span>&lt;/header&gt;</span>
	
	<span>&lt;section&gt;</span>
        <span>&lt;!-- this is a group of radio buttons --&gt;</span> s
        <span>&lt;!-- that user can click to switch between different metrics --&gt;</span>
		<span>&lt;div</span> <span>class=</span><span>"group"</span><span>&gt;</span>
			<span>&lt;input</span> <span>type=</span><span>"radio"</span> <span>name=</span><span>"rb"</span> <span>id=</span><span>"temp_radio"</span> <span>/&gt;</span>
		    <span>&lt;label</span> <span>for=</span><span>"temp_radio"</span><span>&gt;</span>Temperature<span>&lt;/label&gt;</span>
		    <span>&lt;input</span> <span>type=</span><span>"radio"</span> <span>name=</span><span>"rb"</span> <span>id=</span><span>"humidity_radio"</span> <span>/&gt;</span>
		    <span>&lt;label</span> <span>for=</span><span>"humidity_radio"</span><span>&gt;</span>Humidity<span>&lt;/label&gt;</span>
		    <span>&lt;input</span> <span>type=</span><span>"radio"</span> <span>name=</span><span>"rb"</span> <span>id=</span><span>"pressure_radio"</span> <span>/&gt;</span>
		    <span>&lt;label</span> <span>for=</span><span>"pressure_radio"</span><span>&gt;</span>Pressure<span>&lt;/label&gt;</span>
		<span>&lt;/div&gt;</span>
		
        <span>&lt;!-- a canvas that we will pass on to chart.js in our main script --&gt;</span>
		<span>&lt;div</span> <span>class=</span><span>"chartContainer"</span><span>&gt;</span>
			<span>&lt;canvas</span> <span>id=</span><span>"tempChart"</span> <span>width=</span><span>"50"</span> <span>height=</span><span>"50"</span><span>&gt;&lt;/canvas&gt;</span>
		<span>&lt;/div&gt;</span>
	<span>&lt;/section&gt;</span>
<span>&lt;/body&gt;</span>
<span>&lt;/html&gt;</span>
</code></pre></div></div>

<h2 id="ui-logic">UI logic</h2>
<p>Having finished with the markup we now can transition to making our dashboard to be useful by implementing some logic in the <code>index.js</code> script. As a headstart, let’s start from the top abstraction level and look what the code does in overall:</p>

<div><div><pre><code><span>const</span> <span>API_URL</span> <span>=</span> <span>"</span><span>http://localhost:8080</span><span>"</span><span>;</span>

<span>// this will be called by browser as soon as</span>
<span>// all necessary resources were loaded and the page</span>
<span>// is ready to render</span>
<span>window</span><span>.</span><span>onload</span> <span>=</span> <span>async</span> <span>()</span> <span>=&gt;</span> <span>{</span>
    <span>// fetch data from our API</span>
    <span>// we use asynchronous calls to block execution only when necessary</span>
    <span>const</span> <span>data</span> <span>=</span> <span>await</span> <span>(</span><span>await</span> <span>fetch</span><span>(</span><span>API_URL</span><span>)).</span><span>json</span><span>()</span>

    <span>// convert timestamps to the label format we want to use in our charts</span>
    <span>const</span> <span>labels</span> <span>=</span> <span>data</span><span>.</span><span>messages</span><span>.</span><span>map</span><span>(</span><span>item</span> <span>=&gt;</span> <span>moment</span><span>(</span><span>item</span><span>.</span><span>timestamp</span><span>).</span><span>format</span><span>(</span><span>'</span><span>ddd HH a</span><span>'</span><span>));</span>

    <span>// render chart</span>
    <span>let</span> <span>chart</span> <span>=</span> <span>createChart</span><span>(</span><span>labels</span><span>,</span> <span>data</span><span>);</span>

    <span>// create handlers for radio buttons that can be used to select different metrics</span>
    <span>// that will be displayed on the chart</span>
    <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"</span><span>temp_radio</span><span>"</span><span>).</span><span>onclick</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
        <span>// this call will prepare data to be used in a </span>
        <span>// format that chart.js expects as an input</span>
        <span>const</span> <span>tempData</span> <span>=</span> <span>createChartDataset</span><span>(</span><span>data</span><span>,</span> <span>'</span><span>temp</span><span>'</span><span>);</span>

        <span>// this function will update the initialized chart with</span>
        <span>// new data, along with its minimal and maximal bounds</span>
        <span>updateChart</span><span>(</span><span>chart</span><span>,</span> <span>tempData</span><span>,</span> <span>tempData</span><span>.</span><span>min</span> <span>-</span> <span>5</span><span>,</span> <span>tempData</span><span>.</span><span>max</span> <span>+</span> <span>5</span><span>);</span>
    <span>};</span>

    <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"</span><span>pressure_radio</span><span>"</span><span>).</span><span>onclick</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
        <span>const</span> <span>pressureData</span> <span>=</span> <span>createChartDataset</span><span>(</span><span>data</span><span>,</span> <span>'</span><span>pressure</span><span>'</span><span>);</span>
        <span>updateChart</span><span>(</span><span>chart</span><span>,</span> <span>pressureData</span><span>,</span> <span>700</span><span>,</span> <span>pressureData</span><span>.</span><span>max</span> <span>+</span> <span>10</span><span>);</span>
    <span>};</span>

    <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"</span><span>humidity_radio</span><span>"</span><span>).</span><span>onclick</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
        <span>const</span> <span>humidityData</span> <span>=</span> <span>createChartDataset</span><span>(</span><span>data</span><span>,</span> <span>'</span><span>humidity</span><span>'</span><span>);</span>
        <span>updateChart</span><span>(</span><span>chart</span><span>,</span> <span>humidityData</span><span>,</span> <span>0</span><span>,</span> <span>100</span><span>);</span>
    <span>};</span>

    <span>// set default metric to temperature</span>
    <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'</span><span>temp_radio</span><span>'</span><span>).</span><span>click</span><span>();</span>
<span>};</span>
</code></pre></div></div>

<p>Now that we have seen the whole picture, let’s look at how the individual functions work. We will start with <code>createChart</code>, that uses our canvas to display a plot using chart.js library:</p>

<div><div><pre><code><span>/**
 * Creates a new chart
 * @param {Array.&lt;string&gt;} labels 
 * @param {Array} data 
 */</span>
<span>function</span> <span>createChart</span><span>(</span><span>labels</span><span>,</span> <span>data</span><span>)</span> <span>{</span>
    <span>let</span> <span>ctx</span> <span>=</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'</span><span>tempChart</span><span>'</span><span>).</span><span>getContext</span><span>(</span><span>'</span><span>2d</span><span>'</span><span>);</span>
    <span>// Set colors and fonts</span>
    <span>Chart</span><span>.</span><span>defaults</span><span>.</span><span>global</span><span>.</span><span>defaultFontColor</span> <span>=</span> <span>'</span><span>#636160ff</span><span>'</span><span>;</span>
    <span>Chart</span><span>.</span><span>defaults</span><span>.</span><span>global</span><span>.</span><span>defaultFontFamily</span> <span>=</span> <span>'</span><span>"Open Sans", sans-serif</span><span>'</span><span>;</span>
    <span>Chart</span><span>.</span><span>defaults</span><span>.</span><span>global</span><span>.</span><span>defaultFontSize</span> <span>=</span> <span>20</span><span>;</span>

    <span>// Create chart </span>
    <span>let</span> <span>chart</span> <span>=</span> <span>new</span> <span>Chart</span><span>(</span><span>ctx</span><span>,</span> <span>{</span>
        <span>"</span><span>type</span><span>"</span><span>:</span> <span>"</span><span>line</span><span>"</span><span>,</span>
        <span>"</span><span>data</span><span>"</span><span>:</span> <span>{</span>
            <span>"</span><span>labels</span><span>"</span><span>:</span> <span>labels</span><span>,</span>
            <span>"</span><span>datasets</span><span>"</span><span>:</span> <span>[{</span>
                <span>"</span><span>label</span><span>"</span><span>:</span> <span>""</span><span>,</span>
                <span>"</span><span>data</span><span>"</span><span>:</span> <span>data</span><span>,</span>
                <span>"</span><span>fill</span><span>"</span><span>:</span> <span>false</span><span>,</span>
                <span>"</span><span>borderColor</span><span>"</span><span>:</span> <span>"</span><span>#6e2594ff</span><span>"</span><span>,</span>
                <span>"</span><span>lineTension</span><span>"</span><span>:</span> <span>0.1</span>
            <span>}]</span>
        <span>},</span>
        <span>"</span><span>options</span><span>"</span><span>:</span> <span>{</span>
            <span>"</span><span>legend</span><span>"</span><span>:</span> <span>{</span>
                <span>"</span><span>display</span><span>"</span><span>:</span> <span>false</span>
            <span>},</span>
            <span>"</span><span>aspectRatio</span><span>"</span><span>:</span> <span>1</span><span>,</span>
            <span>"</span><span>maintainAspectRatio</span><span>"</span><span>:</span> <span>false</span><span>,</span>
            <span>"</span><span>scales</span><span>"</span><span>:</span> <span>{</span>
                <span>"</span><span>yAxes</span><span>"</span><span>:</span> <span>[{</span>
                    <span>"</span><span>offset</span><span>"</span><span>:</span> <span>true</span><span>,</span>
                    <span>"</span><span>gridLines</span><span>"</span><span>:</span> <span>{</span>
                        <span>"</span><span>display</span><span>"</span><span>:</span> <span>false</span>
                    <span>},</span>
                    <span>"</span><span>ticks</span><span>"</span><span>:</span> <span>{</span>
                        <span>"</span><span>suggestedMin</span><span>"</span><span>:</span> <span>0</span><span>,</span>
                        <span>"</span><span>suggestedMax</span><span>"</span><span>:</span> <span>35</span>
                    <span>}</span>
                <span>}],</span>
                <span>"</span><span>xAxes</span><span>"</span><span>:</span> <span>[{</span>
                    <span>"</span><span>offset</span><span>"</span><span>:</span> <span>true</span><span>,</span>
                    <span>"</span><span>gridLines</span><span>"</span><span>:</span> <span>{</span>
                        <span>"</span><span>display</span><span>"</span><span>:</span> <span>false</span>
                    <span>}</span>
                <span>}]</span>
            <span>}</span>
        <span>}</span>
    <span>});</span>

    <span>return</span> <span>chart</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Now, let’s look at how we can prepare data to be rendered by chart.js uring <code>createChartDataset</code> function:</p>

<div><div><pre><code><span>/**
 * Transforms API response into an object that can be used in the {@link updateChart} call. 
 * @param {Object} data 
 * @param {string} selector 
 */</span>
<span>function</span> <span>createChartDataset</span><span>(</span><span>data</span><span>,</span> <span>selector</span><span>)</span> <span>{</span>
    <span>let</span> <span>series</span> <span>=</span> <span>data</span><span>.</span><span>messages</span><span>.</span><span>map</span><span>(</span><span>item</span> <span>=&gt;</span> <span>item</span><span>[</span><span>selector</span><span>]);</span>
    <span>return</span> <span>{</span>
        <span>'</span><span>dates</span><span>'</span><span>:</span> <span>data</span><span>.</span><span>messages</span><span>.</span><span>map</span><span>(</span><span>item</span> <span>=&gt;</span> <span>item</span><span>.</span><span>timestamp</span><span>),</span>
        <span>'</span><span>data</span><span>'</span><span>:</span> <span>series</span><span>,</span>
        <span>'</span><span>min</span><span>'</span><span>:</span> <span>Math</span><span>.</span><span>min</span><span>.</span><span>apply</span><span>(</span><span>series</span><span>),</span>
        <span>'</span><span>max</span><span>'</span><span>:</span> <span>Math</span><span>.</span><span>max</span><span>.</span><span>apply</span><span>(</span><span>series</span><span>)</span>
    <span>};</span>
<span>}</span>
</code></pre></div></div>

<p>Finally, let’s look at how to update the existing chart’s data:</p>

<div><div><pre><code><span>/**
 * Updates given chart using data and sets y axis min and max values 
 * @param {ChartJS object} chart 
 * @param {Object} data 
 * @param {number} min 
 * @param {number} max 
 */</span>
<span>function</span> <span>updateChart</span><span>(</span><span>chart</span><span>,</span> <span>data</span><span>,</span> <span>min</span><span>,</span> <span>max</span><span>)</span> <span>{</span>
    <span>chart</span><span>.</span><span>data</span><span>.</span><span>datasets</span><span>[</span><span>0</span><span>].</span><span>data</span> <span>=</span> <span>data</span><span>.</span><span>data</span><span>;</span>
    <span>chart</span><span>.</span><span>data</span><span>.</span><span>datasets</span><span>[</span><span>0</span><span>].</span><span>labels</span> <span>=</span> <span>data</span><span>.</span><span>dates</span><span>.</span><span>map</span><span>(</span><span>item</span> <span>=&gt;</span> <span>moment</span><span>(</span><span>item</span><span>.</span><span>timestamp</span><span>).</span><span>format</span><span>(</span><span>'</span><span>ddd HH a</span><span>'</span><span>));</span>
    <span>chart</span><span>.</span><span>options</span><span>.</span><span>scales</span><span>.</span><span>yAxes</span><span>[</span><span>0</span><span>].</span><span>ticks</span><span>.</span><span>suggestedMin</span> <span>=</span> <span>min</span><span>;</span>
    <span>chart</span><span>.</span><span>options</span><span>.</span><span>scales</span><span>.</span><span>yAxes</span><span>[</span><span>0</span><span>].</span><span>ticks</span><span>.</span><span>suggestedMax</span> <span>=</span> <span>max</span><span>;</span>
    <span>chart</span><span>.</span><span>update</span><span>();</span>

<span>}</span>
</code></pre></div></div>

<p>That is everything that we neet to fetch and render our weather station measurements using an API. Now, let’s switch to the styling part and make things look a bit prettier.</p>

<h2 id="styling">Styling</h2>

<p>In this project, we will use <a href="https://sass-lang.com/">SASS</a> extension language as a handy abstraction upon regular CSS. It allows to write stylesheets in a more clean and readable manner. I won’t do a detailed walkthrough of the stylesheet and encourage you to clone the repository, open the <code>index.html</code> file in the browser and play with the styles yourself. Page styling and design are better to be learned in practice: install <code>sass</code>, read documentation and experiment.</p>



<p>By this post, we conclude the journey that led us from building ESP32 based weather station hardware, writing firmware, coding the backend service that tracks all measurements, building a Telegram notification bot and creating a simple web dashboard …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.kdubovikov.ml/articles/rust/ui/weather-station-ui">https://blog.kdubovikov.ml/articles/rust/ui/weather-station-ui</a></em></p>]]>
            </description>
            <link>https://blog.kdubovikov.ml/articles/rust/ui/weather-station-ui</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047091</guid>
            <pubDate>Tue, 10 Nov 2020 15:35:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Use OpenAPI with API Gateway REST APIs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046983">thread link</a>) | @sashee
<br/>
November 10, 2020 | https://advancedweb.hu/how-to-use-openapi-with-api-gateway-rest-apis/ | <a href="https://web.archive.org/web/*/https://advancedweb.hu/how-to-use-openapi-with-api-gateway-rest-apis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <h2 id="rest-api-resources-with-openapi">REST API resources with OpenAPI</h2> <p>Similar to API Gateway HTTP APIs, REST APIs also support importing an OpenAPI document. This document is a standardized way to define APIs and various tools, such as validators and generators, can consume this format. API Gateway also supports it which gives a convenient way to set up the resources needed for the API.</p> <div> <p> Related </p> <div> <p><a href="https://advancedweb.hu/how-to-use-openapi-to-deploy-an-api-gateway-http-api/"> <img src="https://advancedweb.hu/assets/3a9d0c-e17731062a958aeb7b52b3dea994d2bde848598abc49aafcf6db5d3bd81a04ee.jpg" integrity="sha256-djc+uKXhNM0bvbpFhAC1V40PQoiICGzQZhsGj9dCR3A=" crossorigin="anonymous"> </a> </p> <div>  <p> Import and initialize an HTTP API using an OpenAPI document </p> </div> </div> </div> <p>To initialize a REST API using OpenAPI, choose import:</p> <p><img alt="Import REST API using OpenAPI" src="https://advancedweb.hu/assets/posts/openapi_rest_api/import-e34948d6e912777024b7508c863550bab1528fc5503c13cc2accf405867c2e19.png" integrity="sha256-40lI1ukSd3Akt1CMhjVQurFSj8VQPBPMKsz0BYZ8Lhk=" crossorigin="anonymous"></p> <p>The document defines the paths and operations:</p> <div><div><pre><code><span>paths</span><span>:</span>
  <span>/user</span><span>:</span>
    <span>post</span><span>:</span>
      <span>operationId</span><span>:</span> <span>createUser</span>
      <span>summary</span><span>:</span> <span>Create user</span>
      <span>requestBody</span><span>:</span>
        <span># ...</span>
      <span>responses</span><span>:</span>
        <span>default</span><span>:</span>
          <span>description</span><span>:</span> <span>Success</span>
</code></pre></div></div> <p>The import process then creates all the API Gateway resources that are needed for the API. For example, it creates a route for the path:</p> <p><img alt="Imported resources" src="https://advancedweb.hu/assets/posts/openapi_rest_api/resources-4ccd0930db5049b822010e535c6135622ee7776315ed2000b04287a3c3c91148.png" integrity="sha256-TM0JMNtQSbgiAQ5TXGE1Yi7nd2MV7SAAsEKHo8PJEUg=" crossorigin="anonymous"></p> <p>Apart from the routes, it creates data models. For example, the operation can define a request body using a JSON schema:</p> <div><div><pre><code><span>paths</span><span>:</span>
  <span>/user</span><span>:</span>
    <span>post</span><span>:</span>
      <span># ...</span>
      <span>requestBody</span><span>:</span>
        <span>content</span><span>:</span>
          <span>'</span><span>application/json'</span><span>:</span>
            <span>schema</span><span>:</span>
              <span>type</span><span>:</span> <span>object</span>
              <span>properties</span><span>:</span>
                <span>name</span><span>:</span>
                  <span>type</span><span>:</span> <span>string</span>
              <span>required</span><span>:</span>
                <span>-</span> <span>name</span>
              <span>additionalProperties</span><span>:</span> <span>false</span>
        <span>required</span><span>:</span> <span>true</span>
</code></pre></div></div> <p>The import process creates a model based on this schema:</p> <p><img alt="Imported models" src="https://advancedweb.hu/assets/posts/openapi_rest_api/model-48b9fad17584868429d9b6ac66d5a1f7ab4cafee7721353459505a0febcf4081.png" integrity="sha256-SLn60XWEhoQp2basZtWh96tMr+53ITU0WVBaD+vPQIE=" crossorigin="anonymous"></p> <p>And also associates the model with the method’s body:</p> <p><img alt="Imported models is associated with the request" src="https://advancedweb.hu/assets/posts/openapi_rest_api/request_model-a0471f965d11bdf9eb2b25463e0c85f3b88e5cae6020abda66bd4514077bb1c9.png" integrity="sha256-oEcfll0RvfnrKyVGPgyF87iOXK5gIKvaZr1FFAd7sck=" crossorigin="anonymous"></p> <p> Learn the services needed to build a serverless HTTP-based API on AWS from our <a href="#" data-toggle="modal" data-target="#contextual-promo-popup">free email course</a> . </p> <h3 id="vendor-extensions">Vendor extensions</h3> <p>OpenAPI supports vendor extensions which are properties starting with <code>x-</code>. These properties can define configurations that are not supported by the base OpenAPI specification. API Gateway <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-swagger-extensions.html">supports many such extensions</a> for various purposes. Usually, anything that you can set using the Console can be configured embedded in the OpenAPI document.</p> <h4 id="integration">Integration</h4> <p>One of the most important is how to define an integration. It specifies where and how to send the request for a given operation. This uses the <code>x-amazon-apigateway-integration</code> property.</p> <p>Unlike HTTP APIs, REST APIs don’t support using <code>$ref</code>s for integrations, so you need to specify all its properties for every operation. Here is how to use a Lambda function to handle an operation:</p> <div><div><pre><code><span>paths</span><span>:</span>
  <span>/user</span><span>:</span>
    <span>post</span><span>:</span>
      <span>x-amazon-apigateway-integration</span><span>:</span>
        <span>type</span><span>:</span> <span>aws_proxy</span>
        <span>uri</span><span>:</span> <span>arn:${AWS::Partition}:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/&lt;lambda arn&gt;/invocations</span>
        <span>httpMethod</span><span>:</span> <span>POST</span>
      <span># ...</span>
</code></pre></div></div> <p>The <code>aws_proxy</code> defines the lambda proxy integration type. It forwards everything to the function and does not transform the response besides extracting the values from the JSON object.</p> <p>The <code>uri</code> has a specific format: <code>arn:&lt;partition&gt;:apigateway:&lt;region&gt;:lambda:path/2015-03-31/functions/&lt;lambda arn&gt;/invocations</code>. This seems complicated, but API Gateway <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/import-api-aws-variables.html">supports variables</a> that make it easier to construct. By using the <code>${AWS::Partition}</code> and the <code>${AWS::Region}</code> placeholders the only moving part is the ARN of the Lambda function.</p> <p>The <code>httpMethod</code> is how API Gateway calls the Lambda, which is always POST.</p> <p>This integration makes this flow:</p> <p><img alt="Method execution flow" src="https://advancedweb.hu/assets/posts/openapi_rest_api/flow-f42333e998eec45e0981de12d31cfa9b5a7e6fca839c3566b78085e59fa5532b.png" integrity="sha256-9CMz6ZjuxF4Jgd4S0xz6m1p+b8qDnDVmt4CF5Z+lUys=" crossorigin="anonymous"></p> <h4 id="request-validation">Request validation</h4> <p>REST APIs support validation both for parameters and for the request body. This is especially useful as it makes the OpenAPI document the source of truth for which requests are accepted and which are not.</p> <p>You can enable validation for the whole API in one place, and all operations inherit from there. To do this, add a named validator under <code>x-amazon-apigateway-request-validators</code> and configure it to validate both the request body and the parameters.</p> <p>To select this validator for the whole API as the default, use the <code>x-amazon-apigateway-request-validator</code>:</p> <div><div><pre><code><span>x-amazon-apigateway-request-validators</span><span>:</span>
  <span>all</span><span>:</span>
    <span>validateRequestBody</span><span>:</span> <span>true</span>
    <span>validateRequestParameters</span><span>:</span> <span>true</span>
<span>x-amazon-apigateway-request-validator</span><span>:</span> <span>all</span>
</code></pre></div></div> <p>This setup adds the <code>all</code> validator to every method:</p> <p><img alt="Method validator" src="https://advancedweb.hu/assets/posts/openapi_rest_api/validator-bd53bffcaaea6ab6ff55109f15340d150f5d8c621b90a35c30de0640fc350230.png" integrity="sha256-vVO//Krqarb/VRCfFTQNFQ9djGIbkKNcMN4GQPw1AjA=" crossorigin="anonymous"></p> <p>Let’s see how it works!</p> <p>The API expects a request body with only a <code>name</code> property. When there is extra fields in the object, API Gateway returns an error without contacting the Lambda function:</p> <div><div><pre><code><span>---</span> ~ » curl <span>-X</span> POST <span>-i</span> <span>"</span><span>$API</span><span>/user"</span> <span>-H</span> <span>"Content-Type: application/json"</span> <span>-d</span> <span>"{</span><span>\"</span><span>name</span><span>\"</span><span>:</span><span>\"</span><span>testuser</span><span>\"</span><span>,</span><span>\"</span><span>userid</span><span>\"</span><span>:</span><span>\"</span><span>123</span><span>\"</span><span>}"</span>
HTTP/2 400
content-type: application/json
content-length: 35

<span>{</span><span>"message"</span>: <span>"Invalid request body"</span><span>}</span>
</code></pre></div></div> <h2 id="backend">Backend</h2> <p>On the backend, the <code>operationId</code> is available in the event object under the name <code>operationName</code>. This makes it easy to handle multiple operations in a single function.</p> <div><div><pre><code>	<span>const</span> <span>operationName</span> <span>=</span> <span>event</span><span>.</span><span>requestContext</span><span>.</span><span>operationName</span><span>;</span>
	<span>const</span> <span>method</span> <span>=</span> <span>event</span><span>.</span><span>httpMethod</span><span>;</span>
	<span>const</span> <span>body</span> <span>=</span> <span>event</span><span>.</span><span>body</span><span>;</span>

	<span>if</span> <span>(</span><span>operationName</span> <span>===</span> <span>"</span><span>getUser</span><span>"</span><span>)</span> <span>{</span>
		<span>// ...</span>
	<span>}</span><span>else</span> <span>if</span> <span>(</span><span>operationName</span> <span>===</span> <span>"</span><span>updateUser</span><span>"</span> <span>)</span> <span>{</span>
		<span>// ...</span>
	<span>}</span>
</code></pre></div></div> <p>The path parameters are also extracted from the request. For example, this path has a placeholder called <code>userid</code>:</p> <div><div><pre><code><span>paths</span><span>:</span>
  <span>'</span><span>/user/{userid}'</span><span>:</span>
    <span>parameters</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> <span>userid</span>
      <span>in</span><span>:</span> <span>path</span>
      <span>required</span><span>:</span> <span>true</span>
      <span>schema</span><span>:</span>
        <span>type</span><span>:</span> <span>string</span>
    <span>delete</span><span>:</span>
      <span>operationId</span><span>:</span> <span>deleteUser</span>
      <span>summary</span><span>:</span> <span>Delete user</span>
      <span>responses</span><span>:</span>
        <span>200</span><span>:</span>
          <span>description</span><span>:</span> <span>Success</span>
</code></pre></div></div> <p>The event object contains the extracted value:</p> <div><div><pre><code><span>const</span> <span>userid</span> <span>=</span> <span>event</span><span>.</span><span>pathParameters</span><span>.</span><span>userid</span><span>;</span>
</code></pre></div></div> <p>Unlike HTTP APIs, REST APIs only support the Lambda integration format 1.0. This means there is no shortcut return type, and every response must define the <code>statusCode</code> and stringify the <code>body</code>:</p> <div><div><pre><code><span>return</span> <span>{</span>
	<span>statusCode</span><span>:</span> <span>200</span><span>,</span>
	<span>headers</span><span>:</span> <span>{</span>
		<span>"</span><span>Content-Type</span><span>"</span><span>:</span> <span>"</span><span>application/json</span><span>"</span><span>,</span>
	<span>},</span>
	<span>body</span><span>:</span> <span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>items</span><span>.</span><span>Items</span><span>),</span>
<span>};</span>
</code></pre></div></div> <p>Also, it’s a bit slower than an HTTP API, as it does more things. And more importantly, it does not support the <code>$default</code> stage.</p> <div> <p> Related </p> <div> <p><a href="https://advancedweb.hu/how-to-use-the-aws-apigatewayv2-api-to-add-an-http-api-to-a-lambda-function/"> <img src="https://advancedweb.hu/assets/dbb39c-7051aa276e739bd77b8fe10336b4a9a16f9f322a381b4292dc009d1cfaf5d005.jpg" integrity="sha256-v8mShbwhEPRTMuMZRsSWSLLye+t+p9JZx1Q7LPlYQc0=" crossorigin="anonymous"> </a> </p> <div>  <p> Learn how to use AWS HTTP APIs to easily expose a Lambda-backed API </p> </div> </div> </div> <h2 id="terraform">Terraform</h2> <p>To specify a Lambda function that is managed by Terraform, the OpenAPI document needs to define placeholders for the functions’ ARNs:</p> <div><div><pre><code><span>paths</span><span>:</span>
  <span>/user</span><span>:</span>
    <span>post</span><span>:</span>
      <span>x-amazon-apigateway-integration</span><span>:</span>
        <span>type</span><span>:</span> <span>aws_proxy</span>
        <span>uri</span><span>:</span> <span>arn:$${AWS::Partition}:apigateway:$${AWS::Region}:lambda:path/2015-03-31/functions/${users_lambda_arn}/invocations</span>
        <span>httpMethod</span><span>:</span> <span>POST</span>
</code></pre></div></div> <p>This construct defines the <code>users_lambda_arn</code> which will be substituted when Terraform deploys the stack. But since this interpolation uses the same <code>${...}</code> syntax as the AWS variables, the latter needs to be escaped using <code>$${...}</code>.</p> <p>In the <code>tf</code> file, the <code>templatefile</code> function provides a way to insert values for the placeholders:</p> <div><div><pre><code><span>resource</span> <span>"aws_api_gateway_rest_api"</span> <span>"rest_api"</span> <span>{</span>
	<span>name</span> <span>=</span> <span>"</span><span>${</span><span>random_id</span><span>.</span><span>id</span><span>.</span><span>hex</span><span>}</span><span>-rest-api"</span>
	<span>body</span> <span>=</span> <span>templatefile</span><span>(</span><span>"api.yml"</span><span>,</span> <span>{</span><span>users_lambda_arn</span> <span>=</span> <span>aws_lambda_function</span><span>.</span><span>users_lambda</span><span>.</span><span>arn</span><span>})</span>
<span>}</span>
</code></pre></div></div> <p>During <code>terraform apply</code> Terraform creates the function then initializes the API using an OpenAPI document that references the Lambda function. This wires the API to the backend.</p> <p>The other required resource is a deployment that creates a stage and deploys the API:</p> <div><div><pre><code><span>resource</span> <span>"aws_api_gateway_deployment"</span> <span>"deployment"</span> <span>{</span>
	<span>rest_api_id</span> <span>=</span> <span>aws_api_gateway_rest_api</span><span>.</span><span>rest_api</span><span>.</span><span>id</span>
	<span>stage_name</span>  <span>=</span> <span>"stage"</span>
<span>}</span>
</code></pre></div></div> <p>And finally, the permission to allow the API to call the Lambda function:</p> <div><div><pre><code><span>resource</span> <span>"aws_lambda_permission"</span> <span>"apigw"</span> <span>{</span>
	<span>action</span>        <span>=</span> <span>"lambda:InvokeFunction"</span>
	<span>function_name</span> <span>=</span> <span>aws_lambda_function</span><span>.</span><span>users_lambda</span><span>.</span><span>arn</span>
	<span>principal</span>     <span>=</span> <span>"apigateway.amazonaws.com"</span>

	<span>source_arn</span> <span>=</span> <span>"</span><span>${</span><span>aws_api_gateway_rest_api</span><span>.</span><span>rest_api</span><span>.</span><span>execution_arn</span><span>}</span><span>/*/*/*"</span>
<span>}</span>
</code></pre></div></div> <h2 id="conclusion">Conclusion</h2> <p>The OpenAPI document provides a central place to describe various aspects of an API. API Gateway REST API supports many parts of this specification and adds its own to it. As a result, you can define all aspects of the API in the document and deploy everything in this format, letting API Gateway create the resources.</p> </div></div>]]>
            </description>
            <link>https://advancedweb.hu/how-to-use-openapi-with-api-gateway-rest-apis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046983</guid>
            <pubDate>Tue, 10 Nov 2020 15:27:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking Pulsar and Kafka – The Full Benchmark Report]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25046908">thread link</a>) | @tuhaihe
<br/>
November 10, 2020 | https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report | <a href="https://web.archive.org/web/*/https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046908</guid>
            <pubDate>Tue, 10 Nov 2020 15:22:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Mass Effect not require admin rights, or how not to write a boolean check]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046894">thread link</a>) | @zdw
<br/>
November 10, 2020 | https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/ | <a href="https://web.archive.org/web/*/https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>Hi all, it’s me again, your favorite modder who publishes a single research blog post a year. Welcome to my new blog, where I will also post maybe once a year! I got fed up with blogger’s endless unfixed bugs. I’m going to leave the content there though for historical sake.</p>
<p>I just finished a hardcore crunch to ship ALOT Installer V4, which is a complete rewrite of ALOT Installer. ALOT Installer is the Mass Effect modding scene’s main texture installation tool, built on top of aquadran’s MassEffectModder program, which can be used to install textures in a more advanced fashion. In V4 of ALOT Installer, I split the main ‘core’ features into a cross-platform .NET Core library so I can also write a frontend that works on Linux. But that’s not why I’m here today – I’m here to follow up on how I fixed Mass Effect on PC to not require elevation for good.</p>
<h2>Mass Effect on PC: About what you’d be expect from a mid 2000’s console port</h2>
<p>For those of you not in the know, Mass Effect came out on PC back in 2008, and was ported from the Xbox 360 by a studio named Demiurge, who also developed Pinnacle Station for Mass Effect. It’s… a really meh port that has not aged very well. It’s passable as a game but it has a lot of problems, even when it came out. Particle LODs not working properly, texture LODs being read backwards, ini settings being randomly reset to their defaults, the problems are pretty numerous, just to name a few. But nothing completely game breaking.</p>
<p>Well, kind of. There is one, but it’s not specifically due to Mass Effect. The big issue is that Mass Effect requires administrator rights to run, because Demiurge seems to have assumed everyone would run the game as administrator – which <em>might</em> have been OK if the game was only really developed when Windows XP existed, but Windows Vista had already been out for over a year by the time the game had released. Even back then though, Windows XP had a concept of LUA (Least User Access) with separated user accounts. For more information on this, you should check out the original post I wrote, <a href="https://www.me3tweaks.com/blog/modding/why-mass-effect-requires-administrator-rights-and-how-we-fixed-origin-not-running-it/">Why Mass Effect on PC requires administrator</a>. It describes a lot of backstory to this post.</p>
<h2>Oh boy, PhysX, my favorite physics library!</h2>
<figure id="attachment_67" aria-describedby="caption-attachment-67"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/ageialogo1.gif" alt="" width="236" height="134"><figcaption id="caption-attachment-67">I may have a slight beef with this SDK.</figcaption></figure><p>
Mass Effect for PC runs on a lightly modified version of Unreal Engine 3, which appears to be dated around late 2006. According to some former BioWare developers, this version of Unreal Engine was not very mature yet, to put it lightly. According to some stories from these developers, it was really difficult to work with because Epic Games was focused on Gears of War and not dedicating much time to their partners who were also using the engine.</p>
<p>Unreal Engine 3 uses PhysX for physics interactions, so Epic Games built a dll that interfaces PhysX to Unreal Engine data formats through a file named PhysXLoader.dll, which loads the PhysX libraries from both parties. PhysX is a physics simulation library that was acquired by AGEIA Technologies in the mid 2000s before AGEIA was sold to Nvidia in early 2008. If you remember Physics Processing Unit cards, or PPU, they were using PhysX before Nvidia promptly killed that idea.</p>
<figure id="attachment_66" aria-describedby="caption-attachment-66"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25.png" alt="" width="360" height="136" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25.png 360w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25-300x113.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25-250x94.png 250w" sizes="(max-width: 360px) 100vw, 360px"><figcaption id="caption-attachment-66">PhysXLoader.dll, PhysXCore.dll, and NxCooking.dll make up the PhysX dlls for Mass Effect.</figcaption></figure>
<p>All three Mass Effect games use PhysX, but Mass Effect 2 and Mass Effect 3 use the system’s install of PhysX, while Mass Effect uses the local game’s PhysX. Mass Effect 2 and Mass Effect 3 also use the ‘modern’ version of PhysX, rather than the legacy one that was shipped by AGEIA. Nvidia changed some paths under the hood when it took over, which separates Legacy out from it’s ‘modern’ versions. </p>
<p>But that doesn’t seem to stop Legacy PhysX’s uninstaller from deleting modern PhysX’s files/registry keys, so during the course of testing this fix, my other copies of Mass Effect 2/3 didn’t work, even after installing the ‘modern’ PhysX redistributable. It’s really annoying how BioWare couldn’t just ship a 8MB library with the game – they already shipped the installer for PhysX with the game, so it’s not like it saved space!</p>
<p>But anyways…</p>
<h2>The issue with Epic Games’ PhysXLoader.dll is that it can load PhysXCore.dll locally, or from the system’s installed version</h2>
<p>Err… wait, how is that an issue? Can’t you just load the local dll, and if that doesn’t exist, load the system one? How is that an issue exactly?</p>
<figure id="attachment_73" aria-describedby="caption-attachment-73"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1.jpg" alt="OH BOY HERE WE GO" width="294" height="294" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1.jpg 294w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-150x150.jpg 150w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-48x48.jpg 48w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-250x250.jpg 250w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-180x180.jpg 180w" sizes="(max-width: 294px) 100vw, 294px"><figcaption id="caption-attachment-73">You won’t believe how many facepalms there were as I making this fix.</figcaption></figure><p>
On boot, Mass Effect writes two values to the Windows HKEY_LOCAL_MACHINE registry:</p>
<blockquote><p>REG_BINARY HKLM\SOFTWARE\AGEIA Technologies enableLocalPhysXCore [mac address, 6 bytes]<br>
REG_DWORD HKLM\SOFTWARE\AGEIA Technologies EpicLocalDllHack [1]</p></blockquote>
<p>*Mass Effect is a 32-bit program, so on 64-bit systems it goes into HKLM\SOFTWARE\WOW6432Node\AGEIA Technologies instead, if you’re looking for yourself.</p>
<p>Remember these registry values, they’re going to be important later!</p>
<p>These registry values are why Mass Effect requires administrative permissions. In my previous blog post linked above, we explored why these writings were enough to make Microsoft put Mass Effect into it’s compatibility database, which forces it to run as admin when matching on certain executable criteria, which we worked around by modifying the executable criteria to no longer match. </p>
<p>We have to modify the executable to enable Large Address Aware, so the game could load higher resolution textures without running out of memory, so there was no way to avoid breaking the signature. This in turn caused Origin to no longer run the game as it would not elevate games without a valid EA signature. But if the game cannot write these registry keys on boot, the game may crash… </p>
<p>So it’s already a big fun chain of problems, but we worked around Mass Effect needing administrative rights by simply giving the user account permissions to that specific AGEIA Technologies registry key. This would let the game process write the values it needed, and would we could go on our merry way. I assumed the game crashed because it was denied write permissions and Demiurge couldn’t be bothered to write a try/catch around the registry writing code.</p>
<h2>You probably shouldn’t name your registry values as a hack if you want me to think this is a good idea</h2>
<p>Our solution to this problem did not change Mass Effect’s behavior – the values it wanted to write to the registry were going to be written one way or another, so we were just letting it do the thing it’s always done, just without administrative rights. There wasn’t really any change in application behavior.</p>
<figure id="attachment_81" aria-describedby="caption-attachment-81"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59.png" alt="" width="362" height="154" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59.png 362w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59-300x128.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59-250x106.png 250w" sizes="(max-width: 362px) 100vw, 362px"><figcaption id="caption-attachment-81">The two registry values that Mass Effect writes.</figcaption></figure>
<p>mirh, a moderator for <a href="https://www.pcgamingwiki.com/wiki/Home">PC Gaming Wiki</a>, sounded the alarm for years that somehow we were breaking other games in ALOT Installer – even though our application didn’t actually change how Mass Effect was behaving writing these values, so there’s no way our change would break other games.</p>
<p>After many months, he wrote a fairly detailed reason why ALOT Installer (when, in reality, it was Mass Effect) is breaking other games: <b>enableLocalPhysXCore</b> being in the registry <em>is used by other games using Epic Game’s PhysXLoader.dll.</em> When I was writing V4 of ALOT Installer, I told mirh I would take a more serious look into his idea of a solution that would not break other games, even though at the time I did not really understand how a registry key with the system’s MAC address would break other games – or why it even used a MAC address to begin with.</p>
<p>mirh seems to have determined this enableLocalPhysXCore lets Mass Effect use the local directory’s PhysXCore.dll/NxCooking.dll, instead of loading the one from the installed PhysX redistributable. Mass Effect doesn’t install the PhysX redistributable, so it could not rely on it existing, so it needed to use the local libraries.</p>
<p>Hope you’re strapped in because this is where it gets really dumb: </p>
<h4>The MAC address stored in in the registry by MassEffect.exe is read by PhysXLoader.dll and compared against your system’s MAC address to determine if it should load the local directory’s PhysX libraries or the system’s.</h4>
<p>Which MAC address? </p>
<h3>¯\_(ツ)_/¯</h3>
<p>So the way Mass Effect works:</p>
<ol>
<li>Very early in the boot process of MassEffect.exe, your MAC address is read and written to the registry as enableLocalPhysXCore (along with EpicLocalDllHack)</li>
<li>MassEffect.exe loads PhysXLoader.dll</li>
<li>PhysXLoader.dll reads the value of enableLocalPhysXCore and compares your system’s MAC address against it</li>
<li>If it matches, it uses the local folder’s PhysX, if not, it uses the system’s redistributable version of PhysX</li>
</ol>
<p>Yes, you read that right.</p>
<p>It turns out that other games, such as Mirror’s Edge, have a PhysXLoader.dll that also reads these values (as they’re based on the same code), <em>but they don’t include local PhysX libraries</em>. So those games boot up, see enableLocalPhysXCore, and try to load the local library, which fails, and the game doesn’t start. This information is second hand from mirh – I have not tested other games broken by this registry value.</p>
<p>Normally that value wouldn’t exist, and it should use the system PhysX. This behavior can be tested in Mass Effect by denying it write permissions to the registry key, deleting the values, and having Legacy PhysX installed – it will use the system libraries instead. If system PhysX is not installed, the application will not boot – this is why we originally had to let Mass Effect write these keys, otherwise it could appear that the installer broke Mass Effect, when it actually was a terrible implementation by Epic Games.</p>
<figure id="attachment_157" aria-describedby="caption-attachment-157"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1.png" alt="Facepalm" width="782" height="433" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1.png 782w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-300x166.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-768x425.png 768w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-250x138.png 250w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-550x305.png 550w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-325x180.png 325w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-542x300.png 542w" sizes="(max-width: 782px) 100vw, 782px"><figcaption id="caption-attachment-157">It’s hard to imagine any possible scenario where this was a good idea.</figcaption></figure><p>
If you’re interfacing with a library that has exports you can call to initialize/load the PhysX SDK… couldn’t you just, you know, pass a boolean to tell it to locally load? Why does it not locally look to begin with? And what’s up with the MAC address? Why is this in the registry, where it behaves LIKE A GLOBAL SETTING??? </p>
<p>All of these seem like terrible design decisions – and after disassembling the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/">https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/</a></em></p>]]>
            </description>
            <link>https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046894</guid>
            <pubDate>Tue, 10 Nov 2020 15:21:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Homegrown KDP doubling crystal for Nd:YAG laser]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046806">thread link</a>) | @buescher
<br/>
November 10, 2020 | http://www.milankarakas.org/pub/KDP/HomegrownKDP.html | <a href="https://web.archive.org/web/*/http://www.milankarakas.org/pub/KDP/HomegrownKDP.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><span>

<p>
Long time ago I had idea to add a doubling crystal to my
Nd:YAG laser to get green output. But the problem is
that I have no idea which one to buy. There is many
choices, but no simple guide which one will be
appropriate for such Q-switched Nd:YAG laser. I have
another Nd:YAG laser without Q-switch, and this
complicates things a bit more if I want to get doubled
frequency from that laser too.

</p><p>
I heard of KDP (chemical formula
KH<sub>2</sub>PO<sub>4</sub>), and I have that chemical
for hydroponic use, but did not believe that it is
possible to grow decent crystal for SHG (Second Harmonic
Generation). Since my school days, I know how to grow
crystals with jar, chemical and just fiber. This type of
growing crystals give only heap of crystals bond
together, for which I not believe that it is possible to
use as a SHG.

</p><p>
Just by accident, I watched video on YouTube about
growing another type of crystal, so called
‘alum’, and there is explanation how to get
single seeded crystal. Aside that, I saw another video
where they grow KDP crystal for NIF (National Ignition
Facility). Second video looks too complicated to me, so
I decided to follow procedure for growing alum crystal,
but with KH<sub>2</sub>PO<sub>4</sub> chemical. Result
was disappointing. I got many crystals aside from the
seeded one, and mostly bonded together. I tried re-seed
bigger one, but it lead to even worst situation.

</p><p>
After few attempts I gave up. What I get is hundreds of
small crystals, for what I believed that there is no
even smallest chance to get frequency doubling, or
making other harmonics (THG, FHG, etc.). I tried to find
information on the internet about whether someone got
homegrown KDP crystal and use it as SHG. There is no
results. Only result I got is about purchasing such
crystals, but price is... huh... &nbsp; :-p

</p><p> In private conversation with my friend
<a href="http://www.jarrodkinsey.com/">
Jarrod Kinsey</a>
he pushed me to try to put some small crystal at the
output beam from the Nd:YAG laser anyway. I argued that
this is not possible and that for such frequency
doubling it is required special cut of the crystal,
precision aligning, polarized laser, and so on.

</p><p>
Later on, I wanted to check what is necessary to get
proper angle, but all I got is many offers for buying
finished crystals with instructions how to use. At few
pages they mentioned some angles, but also many other
data, for what at this time I have no idea what they
means. Until today I am not sure about many of that, but
I am much more close to understanding it.

</p><p>
Laser is there, crystals are there, but also many
questions too. Finally, I got courage to try it. During
preparing for this test, I had all the time idea how to
tell him that it failed, and that he is wrong. Also, I
remember conversation with another friend,
<a href="http://www.jossresearch.org/">
Jon Singer,</a>
a long time ago about this subject, before my attempt to
grow crystals. He mentioned to me that this may be
difficult too, but not impossible. He also mentioned
that it is worth to try to grow crystals;
“What’s to lose?”

</p><p>
With all of that on my mind, and with serious doubt, I
wear safety goggles and fire my laser with focusing lens
onto small KDP crystal. I had no idea where to point
that focus. I tried few times with different angles, and
WOW! Green light popped right out of the crystal. At
first very weak, but at that moment, my excitement
increased my perception of such intensity to the
extreme. By slightly changing angle, I got even more
green light out.

</p><p>
It took me a while until cool down my mind and realized
what I got. Then I reported to my friends on the
<a href="https://mail.neurotica.com/mailman/listinfo/lasers">
Lasers -- Laser and high-energy physics hacking </a>
mailing list, who congratulated me for this achievement.

<br>

</p>
<p>
At third picture from the left, there is glued crystal
at approximately 42° to the incoming beam. Note that
I am not sure of the exact angle, because incoming beam
is focused, which produce cone of light. Such cone is
not so good, and part of the incoming energy is wasted.
I tried to use binocular as a beam shrinker. Instead of
3 mm beam, my attempt is to narrow it to about 0.3 mm
(if binocular has magnification 8x, then reversed should
narrow or shrink beam to very narrow beam. Such narrow
beam has high divergence, but at short distance it is
okay. After beam pass crystal, it will be good to use
beam expander to back to the original beam diameter, or
to expand beam even more to achieve lower divergence.
But I forgot that in binocular are glued two lenses
together to correct chromatic aberration. Here is how it
looks after a few laser pulses:

<br>

</p>

<div><p>
There is glue, or optical cement between that two lenses.
It seems that some glues/cements don’t like IR (infra
red) radiation. I noticed that at first, there is only
burning spot, but as room temperature changes, one of
two lenses made different expansion rate and produce
crack.

</p></div>
<p>
I am mentioned birefringence which is visible on the
green spot. By slightly adjusting (rotating) angle, that
two groups of spots becomes one. When collimating to the
infinite, such phenomena is less visible, because both
spots make one small spot, slightly elliptic.

</p><p>
My both Nd:YAG lasers are non-polarized. For that reason
I use so called ‘Type II’ phase matching. Since I
am ‘newbie’ in that field, on the Internet you may
find some nice article(s) about phase matching. One of
them is:
</p>

<a href="http://ilphotonics.com/CD/Crystech-Crystals/Non_Linear_Crystals/nlo.pdf">
http://ilphotonics.com/CD/Crystech-Crystals/Non_Linear_Crystals/nlo.pdf</a>

<p>
And another document:

</p>
<a href="http://www.quantumtech.com/apps/916.pdf">http://www.quantumtech.com/apps/916.pdf</a>

<p> Citation from page 5:

</p><p>*4.

</p><p>
“When the cell is mounted horizontally in an optical
mount, the screw (for filling the fluid) should face the
ceiling. The polarization for the input beam should make
and angle of 45° with respect to the horizontal or
vertical plane. Slight Rotation and/or angular
adjustment is required to obtain optimum efficiency.”

</p><p>
*5.

</p><p>
"Type II process is more efficient because the
acceptance angle is wider, making alignment and thermal
control less critical than Type I process, especially
for doubling 1060nm. For tripling two orthogonally
polarized beams, this process is attractive if the
crystal is cut at the proper angle for tripling. The
distance between the doubler and tripler should be as
small as possible for best efficiency. Two orthogonally
polarized beams should make an angle of 45° when the
cell is oriented as in instruction *4." [End of
citation]

</p><p>
I tried tripling Nd:YAG laser, but since my laser is not
polarized, and because there is huge amount of white
light from flashlamp, can’t be sure whether I got 355 nm
(THG) in UV range. For tripling frequency, there must be
actually two crystals. One after another, carefully
oriented, aligned and so on. Too much complicated for me
at this moment.

</p><p>
One of the beauty for such wide acceptance angle is for
beginners like me. Even when holding KDP crystal in
hand, one may be able to adjust close to the proper
angle, so that there is at least some green light.
Further adjusting is then easier, because it increase or
decrease intensity of doubled frequency very gently. Not
so sharp like Phase I matching. I tried that too, but it
works bad for non-polarized lasers.

</p><p>
Another good thing is that even completely fogged
crystal produce some green light. Not much, but crystal
glow green anyway. There is almost no output beam (no
visible spot), just diffuse green glowing. Even most
clear crystal produce some fluorescence which is
consequence of change in refraction indexes. I am not
completely sure how and why, because in relatively short
period read so much documents, and this matter is very
complex.

</p><p>
Such fluorescence can bee seen in clear crystals, so
that one may see the path of the laser beam.

</p><p>
In one document (can’t remember which one), they said
that fine powder can produce SHG too, but with helps of
PMT (Photo Multiplier Tube). This means that random
oriented small crystals, many of them will be
accidentally oriented close to the proper angle, so that
they can make frequency doubling. At that way, they get
very dim green light which can be seen only with aid of
PMT.

</p><div><p>
About conversion efficiency. I have no instruments for
measuring efficiency, and suppose that in my case,
efficiency of conversion is low. In one of my post to
the lasers mailing list, I mentioned that it is possible
to put KDP crystal intracavity for lasers which has not
Q-switch. On that way, one may get greater efficiency by
counting on standing waves inside laser resonator, But
this is very problematic if laser is not polarized.  My
friend Douglas Little tried it and got some green light
out too. But after few shots, one or both HR mirrors,
got optical damage. Standing wave become stronger and
stronger each time passes lasing media. Just one part is
‘extracted’ and converted into harmonic. It will be good
that conversion efficiency is high, so that both laser
mirrors are HR, but one of them with added high
reflectance for 532 nm. If both HR mirrors are for 1064
nm, then doubled frequency will exit at both end of the
Nd:YAG doubled laser.

</p></div><div><p>
About making seed crystals. You may use an old method of
growing crystals as a start for growing small KDP
crystals for seeds.

</p></div> 

<div><p>
An old method with string may give you bad result, so
consider alternative method, which is also simple.
</p></div> 
<p>
If you are lucky enough, and get big crystal, after
cutting to proper size and angle for SHG or THG use,
rest of the crystal may serve as seed crystal. Chose
part which is clear. Shape it and put it as a seed. Or,
if big crystal not met quality requirement, at least one
part of such crystal may serve as a seed crystal. Mostly
clear part is pyramidal part of the KDP crystal.
Prismatic part may be with inclusions, bubbles, water
pockets, and other defects.

</p><p>
I have no chance to get enough big crystal yet. For such
growing of near perfect crystals, it require more or
less sophisticated apparatus, ultra pure water, well
prepared solution etc. I use ’industrial grade’
KH<sub>2</sub>PO<sub>4</sub>, which bought in hydroponic
store. It is marked as MKP 0-52-34. The problem with
that chemical is that there is small amount of</p></span></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.milankarakas.org/pub/KDP/HomegrownKDP.html">http://www.milankarakas.org/pub/KDP/HomegrownKDP.html</a></em></p>]]>
            </description>
            <link>http://www.milankarakas.org/pub/KDP/HomegrownKDP.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046806</guid>
            <pubDate>Tue, 10 Nov 2020 15:13:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading, Wisely – How I'm Using Readwise to Improve My Learning]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25046762">thread link</a>) | @ggnall
<br/>
November 10, 2020 | https://www.grahamgnall.com/blog/2020/11/9/reading-wisely | <a href="https://web.archive.org/web/*/https://www.grahamgnall.com/blog/2020/11/9/reading-wisely">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="44" id="block-9da5bc9359b1bdaa3cf4"><div><p>Readwise is a utility that’s changed the way I read. I'm thoroughly enjoying it and I recommend it to anyone looking to improve their learning. You can sign up for a trial here:</p>
<p><a href="https://readwise.io/">Readwise - plain link</a></p>
<p><a href="https://t.co/3y8bAXryW7?amp=1">Readwise - my referral link</a></p>
<h2 id="about">About</h2>
<p>Readwise is an app (browser extension, web app, mobile app) that organizes information from the books you read. The app relies on learning techniques like <a href="https://en.wikipedia.org/wiki/Spaced_repetition">spaced repetition</a> to train your memory on your reading highlights and annotations.</p>
<h2 id="benefits">Benefits</h2>
<p><strong>Retention</strong></p>
<p>Readwise makes it easy to retain information you’ve read and deemed important in the past. I try to read constantly, but when I look at my <a href="https://www.grahamgnall.com/books">Books</a> list, there are plenty of subjects that are blurry or shockingly, missing altogether from my memory. I’ve been a Kindle device/app enthusiast and previously built my own scripts to export and organize my highlights. It was fun, but I ended up spending more time writing the so-called automation than actually reviewing the highlights. Readwise handles all of the syncing automatically from all your ebooks and articles, and even supports input from physical books. Its Daily Readwise review feature is a daily, randomized feed of highlights that surfaces old and new content to train on.</p>
<p><strong>Making New Connections</strong></p>
<p>There is a thrilling feeling when your mind makes connections between two seemingly disparate topics. This is foundational in my belief in <a href="https://www.grahamgnall.com/blog/2014/7/9/learn-disciplines-not-skills-startups-for-liberal-arts-majors">liberal arts education</a> and it's applications. The simple act of viewing highlights from multiple, unrelated books in the Daily Readwise allows your brain to play with these concepts on the same plane. Readwise’s tagging feature allows you to group highlights about the same topic or theme, so you can build your knowledge base with more examples and perspectives. Both of these features aid in constructing, expanding, and applying mental models to the world, or what Charlie Munger called a <a href="https://fs.blog/great-talks/a-lesson-on-worldly-wisdom/">“latticework”</a> of models from different disciplines.</p>
<h2 id="how-i-use-it">How I Use It</h2>
<p><strong>Set Up</strong></p>
<p>I mostly use the core Readwise syncing sources:</p>
<ol>
<li>Kindle - automated</li>
<li>Pocket - automated</li>
<li>Non-kindle ebooks - semi-automated, requires one manual step when I finish a book</li>
<li>Physical books - manual, but with highly reliable OCR.</li>
</ol>
<p>There are also other a growing number of non-traditional sources like Twitter threads and podcast annotations. I haven’t tried them out yet, but they look promising.</p>
<p>The default settings are thoughtfully done to maximize your learning right out of the box (e.g. 5 daily items, mix of old and new highlights). You can get really granular configuring these settings, down to the book/article level. So far, I’ve only used this to filter out certain things, like definitions from a Javascript textbook I read in 2012. </p>
<p><strong>Developing a Review Habit</strong> </p>
<p>The best product experiences create new habits and rituals around them, for a positive result. Readwise has created a few distinct habits for me. I look forward to my Daily Readwise and it’s one of the few things I let myself do on my phone when waking up. This takes less than a minute and is easy to implement. I never have to schedule in time for this and I never miss it.</p>
<p>Readwise sits on my home screen and I’ve started to open it whenever I need a “feed fix”. It takes my boredom trigger and offers something more valuable than a dopamine hit. Sometimes I’ll do a few cycles of 5 items before calling it quits and going back to whatever I was supposed to be doing. </p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1604955485534_44801"><div><p><strong>Developing Better Reading Habits</strong></p>
<p>Readwise has also changed the way I read. I now look for insights that I want to extract and return to later far more deliberately. I’ve found that even for books I abandon, if I was able to pull a single interesting idea out of it, I got some value out of it. This has reduced the guilt of putting down a book that can’t hold my attention. Or in the case of many business books, lets me extract the primary bits in the beginning without slogging through the filler.</p>
<p>The same applies to how I approach articles. I now view all types of text as holding information I can extract for my own purposes. I'm excited to uncover items to clip and have been delighted by the easy inputs into Readwise, including: highlighting directly in my browser, copy/pasting text from a mobile app, or taking an image of a physical book or magazine. This lets me jot things down, like book recommendations, without having to leave the text and pick them up later. </p>
<p><strong>Organizing Information</strong></p>
<p>I’ve always liked the idea of linking ideas together and this was lacking in my homegrown version of this tool. In addition to notes, you can also add freeform tags to your highlights. This makes it easy to view all your highlights that relate to theme like <code>writing</code> or <code>decision-making</code>. I use this feature to learn about a specific topic. I’m very interested in learning about the routines and processes of interesting creators, and I’ve started to aggregate tags for <code>routine</code> and <code>process</code> for instance. </p>
<p>I use the Daily Review to tag anything that fits into my ongoing areas of interest.</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1604956577898_10298"><p>The free-form search is also a great way to pull in notes on a specific topic. Feeling homesick recently, I typed in “new york” and saw some highlights that made me smile:</p></div><div data-block-type="44" id="block-yui_3_17_2_1_1604955485534_70588"><div><h2 id="last-word">Last Word</h2>
<p>I was happy to drop my hacky version for a simple, easy, and well-designed product. It's helping me to create better habits and reinvigorating my reading pracitce.</p>
<p>I'm training myself to spend on well-designed software products so that such things can exist. Unfortunately paid apps are still a boundary for many - and hopefully the COVID trend of increased subscription spending will change that. For me, the $8.99 / month is well worth the increased utility from books I’ve already purchased (usually for the low Amazon set price of $9.99). I’m sure this was intentional: get more out of your books for less than the already low price of a book a month. Better yet, it makes me <em>excited</em> to buy and read more books.</p>
<p>Of course, if you want to apply these lessons to a self-hosted system you can. You can scrape (pun intended) together your own version by parsing the Kindle Cloud Reader (and other reading apps) to a database (including no-code databases in Notion, Airtable, and even Google Sheets) and building out the necessary views. Or you can keep it lo-fi. I’ve heard of several non-fiction authors using a index card based version of Readwise, where they group passages from different sources by them. I wouldn’t be surprised if this tradition influenced Readwise's card ui and tag features. </p>
<p>And then you <em>could</em> always take it further. While many in the <em>organized thinking</em> movement (or <a href="https://twitter.com/cultroam?lang=en">roamcult</a>) are using Readwise’s Notion and Roam exports to develop fully mapped information on <em>everything</em>, I find the Readwise experience to be fully satisfactory on its own.</p>
</div></div></div>]]>
            </description>
            <link>https://www.grahamgnall.com/blog/2020/11/9/reading-wisely</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046762</guid>
            <pubDate>Tue, 10 Nov 2020 15:08:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What to Care About in a Job]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046633">thread link</a>) | @StokoeKeagan
<br/>
November 10, 2020 | https://www.keaganstokoe.com/post/what-to-care-about-in-a-job | <a href="https://web.archive.org/web/*/https://www.keaganstokoe.com/post/what-to-care-about-in-a-job">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.3.0"><div dir="ltr"><div><p id="viewer-foo"><span><em>This post contains <strong>factors to underweight</strong> and <strong>factors to overweight</strong> when making career decisions. I've included the factors to underweight as </em>avoiding<em> bad decisions is often more impactful than making good ones.</em></span></p><h2 id="viewer-b83g7"><span><span><strong>Why It Pays To Know</strong></span></span></h2><p id="viewer-bcfas"><span><span>Entering the job market, and observing friends doing the same, I’ve noticed that people get caught up in a mindset similar to teenage dating — you get so excited that someone likes you, that you lose sight of whether or not you even like them back.  When taking a step in the wrong direction can be detrimental for years to come, knowing what you want in a job provides sure footing.</span></span></p><p id="viewer-cj7or"><span><span>It’s all too easy to view a job as a job, a day’s work as a day’s pay. I hate this approach to work. Your work is an opportunity to do something meaningful. It’s an opportunity to make art, create a gift, and to do something that matters. It’s an opportunity to invoke change. And it starts with the right job. </span></span></p><p id="viewer-c1m15"><span><span>Knowing what you want enables you to move backwards from that point. It makes it possible to identify the skills and traits that will help you land your dream role. My dream is to work at Shopify. Knowing what I value in a job, I've identified Shopify as the place that aligns most with those values, and I'm able to focus on developing skills that are relevant and beneficial to the application I'll be sending them in a few years time. I've identified specific technical skills that I need to develop. I've observed that they place a premium on being able to think and communicate with clarity. Instead of playing hit and miss with getting your dream job, work backwards to develop the magic needed to receive an offer letter. This is beneficial to you as an individual, but it's equally beneficial to future employers. Magic happens when values align.</span></span></p><p id="viewer-e9uov"><span><span>I’ve written this post because I believe that your career plays a disproportionately large role in the way you experience life. The points below highlight what I seek, and value, in a job. They’re not the only things to value in a job. They’re more relevant to people in the early stages of their career, and particularly those interested in a career in technology.</span></span></p><p id="viewer-cbjf9"><span><span>I suspect that they’ll differ from person to person, but the real benefit comes from taking the time to think about them. It can be difficult to start with a blank piece of paper, so use this as a framework if you’d like. I strongly encourage you to make a list of your own because it’ll change how you approach your work and perceive opportunities.</span></span></p><h2 id="viewer-crnib"><span><span><strong>Factors to underweight in career decisions</strong></span></span></h2><h3 id="viewer-55ehc"><span><span><strong>1. Perks are multiplicative, not additive</strong></span></span></h3><p id="viewer-7bsd6"><span><span>Free lunch, beautiful office space, and Friday's off to work on your side projects are perks. They're great perks, and they'll make the job more enjoyable, but they're only perks. The perks are not the job.</span></span></p><p id="viewer-bg2gd"><span><span>Perks are multiplicative. To get a feel for what I mean by this, assign a value to each perk you get. The unlimited Nespresso and in-house chef are worth 5 points, the office with an ocean view </span>comes<span> in at a cool 3 points, and your company replicating Google's famous</span><a href="https://en.wikipedia.org/wiki/20%25_Project" target="_blank" rel="noopener"> <span><u>20% Project</u></span></a><span> is worth 5 points. Now take the work you'll be doing on a daily basis, and ask yourself how much you want to do it. Be brutally honest, because that's the work you're going to spend the majority of your time doing. </span></span></p><p id="viewer-bc748"><span><span>If the day-to-day work is enjoyable, the perks amplify that and make your dream position even better. But if you hate the day-to-day work, don’t fool yourself into thinking that the perks can make up for it. If you hate the day-to-day, it’ll slowly seep into your life, mood and relationships. It’s difficult to be happy when you spend the majority of your time consumed by something you despise. It's impossible to win if you're multiplying by zero.</span></span></p><h3 id="viewer-5ieeb"><span><span><strong>2. Work-life balance isn't as important as it's made out to be</strong></span></span></h3><p id="viewer-f06u4"><span><span>Having a work-life balance doesn't concern me. Perhaps it's because I'm early in my career and don't have too many other responsibilities, or perhaps it's because I've found something that I like to do, but I don't feel the need to draw a distinct line between work and life. Provided I have enough time to maintain my relationship and look after my body, I'm happy to spend the rest of my time working. </span></span></p><p id="viewer-1ftip"><span><span>I imagine that in future - when I wish to have children - my views will change. I suspect that I'll work more than necessary in the early stages of my career, which will turn into </span><a href="https://www.forbes.com/sites/laurashin/2013/05/22/7-steps-to-developing-career-capital-and-achieving-success/?sh=79752ea57a9fhttps://www.forbes.com/sites/laurashin/2013/05/22/7-steps-to-developing-career-capital-and-achieving-success/?sh=79752ea57a9f" target="_blank" rel="noopener"><span><u>career capital</u></span></a><span> that I can trade in for more flexibility and autonomy when the time calls for it.</span></span></p><h3 id="viewer-4nlad"><span><span><strong>3. Compensation</strong></span></span></h3><p id="viewer-8btdr"><span><span>In light of the above, compensation is something to underweight. </span><a href="https://haseebq.com/about/" target="_blank" rel="noopener"><span><u>Haseeb Quresh</u></span><span><u>i</u></span></a><span> has an interesting initiative. He </span><a href="https://haseebq.com/how-to-break-into-tech-job-hunting-and-interviews/#information" target="_blank" rel="noopener"><span><u>donates 33%</u></span></a><span> of what he earns. I like that, and in that scenario, I can see how compensation plays an important role in your ability to make an impact. Interestingly, I suspect that his personal contributions are dwarfed by the contributions of people that have joined his cause. It supports the idea that your actions, not your wallet, carry the most potential to make a difference.</span></span></p><p id="viewer-85sfi"><span><span>I’m not saying that you shouldn’t be concerned with compensation. Ensure that you can pay your bills, have a decent quality of life, and build in some form of financial security for the future. Over and above that, income is far less important than the other factors on this list. This becomes even more applicable if you share my views on work-life balance, since the increased work hours results in decreased lifestyle hours, and decreased expenses. </span></span></p><p id="viewer-1689k"><span><span><em>(Note: This is, of course, irrelevant if your goal is to make as much money as possible.)</em></span></span></p><h2 id="viewer-8pm18"><span><span><strong>Factors to overweight in career decisions</strong></span></span></h2><h3 id="viewer-4fv24"><span><span><strong>1. Important work &gt; Difficult work</strong></span></span></h3><p id="viewer-92h86"><span><span>When I think about a job, the overarching purpose of having one is to make an impact. I find it easy to think more money means more impact: making more money means you're in a position to give more money. I'm currently making more, yet giving less. It leads me to believe that if I'm going to make an impact it will be through the work I do, not the money I give (or have available to give).</span></span></p><p id="viewer-a2qj6"><span><span>That's why I seek to do important work. Building, creating and developing things that make life better for others, particularly for those unable to make life better for themselves. </span></span></p><p id="viewer-d5qau"><span><span>For a long time, I was under the impression that difficult implies important. It must have been difficult for Cardi B to sell over </span><a href="https://v1019.com/2019/09/06/cardi-b-becomes-riaa-most-certified-woman-rapper-surpassing-nicki-minaj/#:~:text=Cardi%20B%20has%20recently%20hit,surpassing%20her%20nemesis%2C%20Nicki%20Minaj" target="_blank" rel="noopener"><span><u>31 million singles</u></span></a><span>, but I struggle to find one iota of importance in her work. Starting a charity is arguably less difficult, but far more important. </span></span></p><p id="viewer-29ru4"><span><span>There's plenty of grey area involved in this importance vs. difficulty point, but I find it helpful to be aware of when looking at jobs.</span></span></p><h3 id="viewer-82ip0"><span><span><strong>2. Prioritise people </strong></span></span></h3><p id="viewer-5haoo"><span><span>Working under the guidance of a good mentor takes care of most of the things on this list. When you're surrounded by great people who provide you with guidance and feedback, you get better really quickly.</span></span></p><p id="viewer-eoimb"><span><span>This is particularly important if your chosen profession is one in which you require deep expertise to be successful. Expertise is directly related to the people you spend time around. Cedric Chin, of the </span><a href="https://commoncog.com/blog/" target="_blank" rel="noopener"><span><u>Commonplace Blog</u></span></a><span>, has dealt extensively with what it requires to become an expert. </span></span></p><p id="viewer-2tchb"><span><span>Expertise comes from a pattern-matching </span><a href="https://www.amazon.com/Sources-Power-People-Make-Decisions/dp/0262611465" target="_blank" rel="noopener"><span><u>model</u></span></a><span> in which the expert pattern-matches the current situation against a bank of stored prototypes. It is part of implicit memory, meaning that it happens extremely quickly, like recognising a face. The level of expertise shown in a given situation is dependent upon the following four steps:</span></span></p><ul><li id="viewer-dr28t"><p><span><strong>Relevant cues:</strong> These tell the brain what to focus on. For example, when turning at an intersection you'll focus on the indicator and the oncoming traffic, but won't worry about the speedometer.</span></p></li><li id="viewer-1u819"><p><span><strong>Plausible goals:</strong> Given the current situation, what goals are plausible? These are ranked, with the ranking done in terms of prior experience.</span></p></li><li id="viewer-5bk4l"><p><span><strong>Expectancies:</strong> These are a list of things which should happen in the given situation. If something is amiss, the expert experiences what we would call a 'bad feeling' and returns to pattern matching mode.</span></p></li><li id="viewer-ebp2b"><p><span><strong>Action script:</strong> Based on the patterns that have emerged, these are the actions to take.</span></p></li></ul><p id="viewer-7bh29"><span><span>Surrounding yourself with the right people enables you to increase your bank of stored experiences. It trains you to select the most effective action script to follow when a pattern emerges. Prioritising people in your career decisions means prioritising time spent around experts. This fast tracks your path to expertise and puts you in a commanding position for the rest of your career. </span></span></p><p id="viewer-f22go"><span><span><em>(I strongly recommend reading the </em></span><a href="https://commoncog.com/blog/everything-you-need-to-know-about-human-learning-and-memory-retention/" target="_blank" rel="noopener"><em><span><u>entire piece</u></span></em></a><span><em> from Cedric, as well as his series on </em></span><a href="https://commoncog.com/blog/the-tacit-knowledge-series/" target="_blank" rel="noopener"><em><span><u>tacit knowledge</u></span></em></a><span><em>.) </em></span></span></p><h3 id="viewer-bsghe"><span><span><strong>3. Seeing eye-to-eye with coworkers</strong></span></span></h3><p id="viewer-c44h"><span><span>I have a </span><a href="https://www.zachwolpe.com/" target="_blank" rel="noopener"><span><u>friend</u></span></a><span> who I work on almost all </span><a href="https://www.keaganstokoe.com/entrepreneurship" target="_blank" rel="noopener"><span><u>projects</u></span></a><span> with. We're good friends - we chat most days, grab coffee whenever we can, and generally get along very well. We also work extraordinarily well with one another. The reason for that isn't because we're good friends. It's because we see eye-to-eye on the work we want to do. When working on something together, there’s complete freedom to criticise and disagree. We're brutally honest, and because of it, at the end of a meeting, we’re on the same page and ready to move ahead. We trust each other, and with that comes autonomy and freedom to get the work done.</span></span></p><p id="viewer-ek2ia"><span><span>When it comes to a job, seeing eye-to-eye with your co-workers isn't about feeling comfortable to go to lunch with them. It's about being on the same page when it comes to prioritising work, putting in the effort, and making decisions. It's about being in a job where you can be honest, transparent and straightforward. Great work is a byproduct of being aligned with the vision and values of the company. You’ll do your best work when you’re surrounded by people who are invested in you doing your best work, regardless of the path required to get there. </span></span></p><h3 id="viewer-8607g"><span><span><strong>4. Company growth</strong></span></span></h3><p id="viewer-cfji1"><span><span>Working for a growing company takes care of almost everything mentioned above. In a growing company, growing pains present themselves in the form of problems to solve and customers to please. Learning to solve these problems makes your …</span></span></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.keaganstokoe.com/post/what-to-care-about-in-a-job">https://www.keaganstokoe.com/post/what-to-care-about-in-a-job</a></em></p>]]>
            </description>
            <link>https://www.keaganstokoe.com/post/what-to-care-about-in-a-job</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046633</guid>
            <pubDate>Tue, 10 Nov 2020 14:57:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Death to “Just-Add-Water Team Jelling”]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046561">thread link</a>) | @mcrittenden
<br/>
November 10, 2020 | https://critter.blog/2020/11/10/death-to-just-add-water-team-jelling/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/11/10/death-to-just-add-water-team-jelling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-3080">

	
<!-- .entry-header -->

	<div>

		<div>

			
<ul><li>“Top 5 tips for jelling your team!”</li><li>“Use this kickoff activity to jump start team jelling!”</li><li>“Onboarding do’s and don’ts to help your new employee jell!”</li></ul>



<p>No. <a href="https://critter.blog/2016/10/27/the-whys-and-hows-of-jelling-teams/">Team jelling</a> is not a series of steps. That’s trivializing. Replace “jelling” with “success” to understand how silly that sounds. We wouldn’t look for a “kickoff activity to jump start <em>success</em>” because that doesn’t even make sense. </p>



<p>Jelling is <em>everything</em>. It serves everything. It comes from everywhere. It belongs to everyone. It deserves to be taken seriously. It’s not a bunch of checkboxes. </p>



<p>Brené Brown says this of earning trust:</p>



<blockquote><p>It turns out that trust is in fact earned in the smallest of moments. It is earned not through heroic deeds, or even highly visible actions, but through paying attention, listening, and gestures of genuine care and connection.</p><cite>Brené Brown, <em>Dare To Lead</em></cite></blockquote>



<p>And what is jelling but the result of trust? </p>



<p>Like trust, jelling is the long game. It’s difficult to build but <a href="https://critter.blog/2020/10/28/the-all-powerful-bad-apple/">easy to break</a>. It takes months of consistent <em>small moments</em> of listening, <a href="https://critter.blog/2020/11/05/respond-to-vulnerability-with-vulnerability/">vulnerability</a>, reliability, <a href="https://critter.blog/2020/10/30/the-i-suck-awards/">empathy</a>, silliness, authenticity. </p>



<p>Please treat it with the respect it deserves.</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/11/10/death-to-just-add-water-team-jelling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046561</guid>
            <pubDate>Tue, 10 Nov 2020 14:51:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everyone Talks About Insecure Randomness, but Nobody Does Anything About It]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046519">thread link</a>) | @airza
<br/>
November 10, 2020 | https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html | <a href="https://web.archive.org/web/*/https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<section>
		
		<p>In which I take a crack at pointing a neural network at random noise, and achieve 95+% predictive bitwise accuracy against my hated foe in this world, Xorshift128.</p>
		<blockquote><p>"Any one who considers arithmetical methods of producing random digits is, of course, in a state of sin."</p></blockquote>
	</section>
	<section>
		<h2>What exactly are you up to here?</h2>
		<p>The motivation for this blog was a secure code review a few years ago, when looking at a client's email token generation<label for="1"></label><span>I don't actually work as an RNN jockey for work- I'm a security consultant. </span>. Frankly, I don't remember what their code looked like at <i>all</i>, but it probably looked something like this:</p>
		<figure><pre><code data-lang="python"><span>"""gotta make a token and send it to the client!"""</span>
<span>very_random_number</span> <span>=</span> <span>get_random_number</span><span>()</span>
<span>two_factor_token</span> <span>=</span> <span>convert_representation</span><span>(</span><span>very_random_number</span><span>)</span>
<span>send_email</span><span>(</span><span>"Your two factor authentication token is:"</span>
	<span>+</span><span>two_factor_token</span><span>,</span><span>user_email</span><span>)</span>
<span>save_token_to_user</span><span>(</span><span>user_id</span><span>,</span><span>two_factor_token</span><span>)</span>
		</code></pre></figure>
		<p>Code like this undergirds the security of much of the internet. A user wants to reset their password, so they enter their email. We generate a secret code and send it to their email; opening the link in the email proves that the requestor is legitimate. Sometimes we text codes like this to users when they try to login to their banks; this type of association between a random number and a user is also the backbone of a huge chunk of cookie-based authentication.</p><p>Is this code secure?  Well, it depends. Naturally, we might attack the email component (as emails are sometimes sent unencrypted, whoops) or we might attack the association between the data (maybe the token and the email are derived from attacker controlled data or whatever). The quality of the random number generation here matters as well, at least in theory: some random number generators are predictable, while others are provably difficult to attack. If we could predict this, it would be super bad- we'd just trigger the email to the victim, somehow predict the RNG, and be on our way. On the other hand, even if we are able to 'predict' this, we are still in trouble: there is no obvious way to go about it without prior knowledge of what <i>convert_representation</i> is up to.</p>
		<p>I think machine learning provides the bridge here. The thought has hung in my mind for a few years, in fact; I've picked the brains of everyone I know remotely related to the field, and I've even hired some people to take a crack at it. So far, I haven't seen any prior literature suggesting that it's been possible or done, and nobody was really sure how to approach it. Finally, thanks to a generous grant from the Phil Brass Weird Ideas Foundation<label for="2"></label><span>AKA <a href="https://www.directdefense.com/">DirectDefense</a> who was happy to sponsor this research while I was not busy bug hunting for them! </span> I was able to take a few weeks to think about it methodically.</p>
		<p>The rest of this blog is structured in a pretty straightforward way: I talk about how numbers are generated at random in a computer, then talk about how to transform that notion of randomness into a learnable problem<label for="3"></label><span>A basic knowledge of machine learning, and especially gradient descent will be helpful for understanding some of my thought process through this blog. </span>. Not surprisingly, I will then solve that problem, and propose a roadmap for how to continue chipping away at the distance between my current progress and a usable attack.</p>
	</section>
	<section>
		<h2>Our Constant State of Sin</h2>
		<p>Computers, these fucked up little rocks we have forced to think, are gambling creatures. Despite the rigid constraints that we have imposed on them, we sometimes instead demand them to be fickle beyond our own capabilities, to choose a number more wildly than any human dare dream. For example, by invoking <code>Xorshift128</code>, a rather stylishly named fellow, you can choose a number between zero and about four billion (<code>2**32</code>, to be precise), which is a number that, while you do not often have a reason to choose at random, is at least a number whose neighbors you encounter at least occasionally. More excitingly, you can invoke this function a staggering <code>2**128</code> times<label for="4"></label><span>More or less the number of atoms in every living person on earth. </span> before you encounter a repetition in its pattern of randomness.</p>
		<p><i>But how?</i> I hear you cry. That is to say, A particular problem arises here, the one I think Von Neumann was referring to above: programming a computer is the art of telling it exactly what you want it to do, more or less in advance, and telling it exactly what random stuff to come up with, <i>in advance</i>, both defeats the purpose of the program in the first place and also poses fascinating logical challenges at the programming level. Certainly you do not have time to roll four billion of <i>anything</i>, and even if you did, writing each of those numbers down in some way would be a miserable use of time and hard disk space. On the other hand, cycling through just a few of the available numbers also sounds wrong; if you cycle through just a few hundred of the integers between 0 and 2**32, you're not really providing a lot of randomness.</p>
		<p>We will set aside the question of what randomness really <i>is</i> and think about it from a programming perspective. We can define a Random Number Generator (RNG) as something that outputs a sequence of numbers. In order to make sure that they are as random as possible, we're also going to introduce something new: <i>state</i>. The state gets passed into this RNG function, and in addition to outputting a random-ish number, it is going to output <i>new</i> state- this state will be as big or bigger (usually much bigger) than the output. Then we're just going to feed this output state <i>back</i> into the RNG to generate the next number in the sequence- and that's going to give us new state, which will let us continue this for quite a while. One point of confusion is that sometimes the output is <i>also</i> used as the state<label for="5"></label><span>Astute readers will wonder: where does the original state come from? Fascinatingly, movement of the mouse, entries into the keyboard, and other minutiae of computer operation are used to generate a very small amount of randomness- that is, at some level the start comes from the simple uncertainty of everyday computer use. There isn't a lot of randomness available here, so the RNG serves to <i>stretch</i> it out over a longer period of time. </span>.</p>
		<p>To take this into the concrete, we will consider an RNG, the <b>Middle-square method</b>. Relatively ancient by RNG standards, it was invented by Von Neumann sometime in the 1940s, when he was busy inventing almost everything else. A number of <code>N</code> digits is squared, and the <code>N/2</code> middle digits of the result are taken both as the <i>output</i> as well as the <i>state</i> to square for the next iteration. The simplest case, n=2, works as follows: we start with 43, square it to produce 1849, and then take the middle two digits to get our result, 84. This 84 is also our new state, so next time we're fiending for the results of a d100, we square it again, 7056, taking the middle to get 5, our output and our new state. Okay, so next is 25, which we'll call 0025, which gives us 2, which gives us 0004, translated as 0...</p>
		<p>Uh oh. We seem to have run into a dead end here. 0 squared is of course 0. These numbers are not looking so random anymore. In fact, the behavior is pretty bad no matter what number you begin with. The figure below lists all the states/outputs showing that the tendency to degrade towards cycles is pretty unavoidable.</p>
		<figure>
			<svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="100%" height="100%" viewBox="-307 -5 300 450">
 <title>Middle square method 2 digits</title>
 <desc></desc>
 
 <defs>
  <path id="arrow" d="M 9.5,0 H 14 m -2,-2 l 2,2 l -2,2"></path>
  <g id="loop1">
   <path d="M 9,0 V 10 H 0"></path>
   <use xlink:href="#arrow" transform="translate(0,19) rotate(-90)"></use>
  </g>
  <g id="loop2">
   <path d="M 9,0 V -10 H -20"></path>
   <use xlink:href="#arrow" transform="translate(-20,-19) rotate(90)"></use>
  </g>
 </defs>
 <g font-family="sans-serif" font-size="10" font-weight="bold" text-anchor="middle" stroke-linejoin="round" stroke-linecap="round" stroke="none" fill="none">
  <rect x="-4999" y="-4999" width="9999" height="9999"></rect>
  <g>
   <g transform="translate(-20 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">00</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#loop1" transform="translate(0,  0)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">01</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">04</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">07</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="10" dy="0.7ex" transform="scale(0.75,1)">71</text><path d="M 5, 10 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">02</text><path d="M 5, 20 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">05</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">84</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">29</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">36</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">19</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">14</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">12</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">11</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">46</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-240,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">92</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-260,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">77</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-280,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">76</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-300,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">42</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-300,0)"><text x="0" y="30" dy="0.7ex" transform="scale(0.75,1)">69</text><path d="M 5, 30 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-260,0)"><text x="0" y="40" dy="0.7ex" transform="scale(0.75,1)">89</text><path d="M 5, 40 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="50" dy="0.7ex" transform="scale(0.75,1)">37</text><path d="M 5, 50 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="60" dy="0.7ex" transform="scale(0.75,1)">58</text><path d="M 5, 60 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="70" dy="0.7ex" transform="scale(0.75,1)">43</text><path d="M 5, 70 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">62</text><path d="M 5, 80 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">25</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">16</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">13</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">56</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">81</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="90" dy="0.7ex" transform="scale(0.75,1)">87</text><path d="M 5, 90 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="100" dy="0.7ex" transform="scale(0.75,1)">68</text><path d="M 5,100 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="100" dy="0.7ex" transform="scale(0.75,1)">41</text><path d="M 5,100 H 9 V 100"></path><use xlink:href="#arrow" transform="translate(0,100)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="110" dy="0.7ex" transform="scale(0.75,1)">75</text><path d="M 5,110 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">32</text><path d="M 5,120 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">18</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">72</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">27</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="130" dy="0.7ex" transform="scale(0.75,1)">61</text><path d="M 5,130 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="140" dy="0.7ex" transform="scale(0.75,1)">82</text><path d="M 5,140 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="150" dy="0.7ex" transform="scale(0.75,1)">73</text><path d="M 5,150 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="160" dy="0.7ex" transform="scale(0.75,1)">45</text><path d="M 5,160 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="170" dy="0.7ex" transform="scale(0.75,1)">55</text><path d="M 5,170 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="180" dy="0.7ex" transform="scale(0.75,1)">95</text><path d="M 5,180 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">03</text><path d="M 5,190 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">06</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">08</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">09</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">64</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">93</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">44</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">21</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">96</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">31</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="200" dy="0.7ex" transform="scale(0.75,1)">63</text><path d="M 5,200 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="210" dy="0.7ex" transform="scale(0.75,1)">38</text><path d="M 5,210 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="220" dy="0.7ex" transform="scale(0.75,1)">33</text><path d="M 5,220 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">78</text><path d="M 5,230 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">28</text><path d="M 5,230 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">17</text><path d="M 5,230 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="240" dy="0.7ex" transform="scale(0.75,1)">91</text><path d="M 5,240 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="240" dy="0.7ex" transform="scale(0.75,1)">54</text><path d="M 5,240 H 9 V 240"></path><use xlink:href="#arrow" transform="translate(0,240)"></use></g>
  </g>
  <g transform="translate(0,10)">
   <g transform="translate(-20 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">10</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#loop1" transform="translate(0,250)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">90</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">30</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">48</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">22</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">15</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">34</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="260" dy="0.7ex" transform="scale(0.75,1)">35</text><path d="M 5,260 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="260" dy="0.7ex" transform="scale(0.75,1)">66</text><path d="M 5,260 H 9 V 260"></path><use xlink:href="#arrow" transform="translate(0,260)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="270" dy="0.7ex" transform="scale(0.75,1)">65</text><path d="M 5,270 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="280" dy="0.7ex" transform="scale(0.75,1)">85</text><path d="M 5,280 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="290" dy="0.7ex" transform="scale(0.75,1)">59</text><path d="M 5,290 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="300" dy="0.7ex" transform="scale(0.75,1)">67</text><path d="M 5,300 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="300" dy="0.7ex" transform="scale(0.75,1)">26</text><path d="M 5,300 H 9 V 300"></path><use xlink:href="#arrow" transform="translate(0,300)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">70</text><path d="M 5,310 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">52</text><path d="M 5,310 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">23</text><path d="M 5,310 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="320" dy="0.7ex" transform="scale(0.75,1)">39</text><path d="M 5,320 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="320" dy="0.7ex" transform="scale(0.75,1)">86</text><path d="M 5,320 H 9 V 320"></path><use xlink:href="#arrow" transform="translate(0,320)"></use></g>
  </g>
  <g>
   <g transform="translate(-20 ,0)"><text x="0" y="330" dy="0.7ex" transform="scale(0.75,1)">50</text><path d="M 5,330 H 9 V 330"></path><use xlink:href="#loop1" transform="translate(0,330)"></use></g>
  </g>
  <g transform="translate(0,10)">
   <g transform="translate(-20 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">60</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#loop1" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">40</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">20</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">47</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">74</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">88</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">83</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">94</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="350" dy="0.7ex" transform="scale(0.75,1)">49</text><path d="M 5,350 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="360" dy="0.7ex" transform="scale(0.75,1)">80</text><path d="M 5,360 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="360" dy="0.7ex" transform="scale(0.75,1)">53</text><path d="M 5,360 H 9 V 360"></path><use xlink:href="#arrow" transform="translate(0,360)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="370" dy="0.7ex" transform="scale(0.75,1)">99</text><path d="M 5,370 H 9 V 360"></path><use xlink:href="#arrow" transform="translate(0,360)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="380" dy="0.7ex" transform="scale(0.75,1)">97</text><path d="M 5,380 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="390" dy="0.7ex" transform="scale(0.75,1)">51</text><path d="M 5,390 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="400" dy="0.7ex" transform="scale(0.75,1)">98</text><path d="M 5,400 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
  </g>
  <g transform="translate(0,20)">
   <g transform="translate(-20 ,0)"><text x="0" y="410" dy="0.7ex" transform="scale(0.75,1)">24</text><path d="M 5,410 H 9 V 410"></path><use xlink:href="#loop2" transform="translate(0,410)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="410" dy="0.7ex" transform="scale(0.75,1)">57</text><path d="M 5,410 H 9 V 410"></path><use xlink:href="#arrow" transform="translate(0,410)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="420" dy="0.7ex" transform="scale(0.75,1)">79</text><path d="M 5,420 H 9 V 410"></path><use xlink:href="#arrow" transform="translate(0,410)"></use></g>
  </g>
 </g>
</svg>

			<label for="mn-demo">⊕</label>
			
			<span>
				<i>Directed graph of all 100 2-digit pseudorandom numbers obtained using the middle-square method</i>, by CMG Lee.
			</span>
		</figure>
		<p>Performance for the version with 4 digits of state is better; the average length of time before being trapped in a cycle is after 43 outputs<label for="6"></label><span>Another useful property of these RNGs is that it is pretty obvious when they are starting to break down- among the 10000 numbers the 4-digit version can output, only <i><code>0, 9600, 1600, 5600, 8100, 100, 4100, 2916, 2500, 3009, 5030, 3600, 7600, 3792, 2100, 6100, 540</code></i> immediately lead to decay. </span>. That code looks something like this, just so you get the idea:</p>
		<figure><pre><code data-lang="python"><span>def</span> <span>von_neumann_generator</span><span>(</span><span>state</span><span>):</span>
	<span>"""The version with a 4 digit state/output
	not to be confused with the one above, that
	has two."""</span>

	<span>#e.g. 1234**2-&gt;1522756
</span>	<span>square</span> <span>=</span> <span>state</span><span>**</span><span>2</span> 

	<span>#1522756 -&gt; 01522756
</span>	<span>formattedSquare</span> <span>=</span> <span>"%08d"</span> <span>%</span> <span>square</span>

	<span>#01522756 -&gt; 5227
</span>	<span>next_state</span> <span>=</span> <span>output</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>2</span><span>:</span><span>6</span><span>])</span>
	<span>return</span> <span>(</span><span>next_state</span><span>,</span><span>output</span><span>)</span>
<span>state</span> <span>=</span> <span>1234</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>20</span><span>):</span>
	<span>state</span><span>,</span><span>output</span> <span>=</span> <span>von_neumann_generator</span><span>(</span><span>state</span><span>)</span>
	<span>print</span><span>(</span><span>output</span><span>)</span>
		</code></pre></figure>
		<p>You can see in the above example that the state and the output are identical, but there is no particular reason this has to be the case. For example, we could have the state be the inner four numbers, with the output being the <i>outer</i> four numbers:</p>
		<figure><pre><code data-lang="python"><span>def</span> <span>much_better_von_neumann_generator</span><span>(</span><span>state</span><span>):</span>
	<span>square</span> <span>=</span> <span>state</span><span>**</span><span>2</span> <span># e.g. 1234**2-&gt;1522756
</span>	<span>formattedSquare</span> <span>=</span> <span>"%08d"</span><span>%</span><span>square</span>
	<span>output</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>0</span><span>:</span><span>2</span><span>]</span><span>+</span><span>formattedSquare</span><span>[</span><span>6</span><span>:])</span>
	<span>next_state</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>2</span><span>:</span><span>6</span><span>])</span>
	<span>return</span> <span>(</span><span>next_state</span><span>,</span><span>output</span><span>)</span>
<span>state</span> <span>=</span> <span>1234</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>40</span><span>):</span>
	<span>state</span><span>,</span><span>output</span> <span>=</span> <span>much_better_von_neumann_generator</span><span>(</span><span>state</span><span>)</span>
	<span>print</span><span>(</span><span>output</span><span>)</span>
		</code></pre></figure>
		<p>This RNG is also not quite ready for prime time, but the relationship between the output and state is already harder to guess. However, they are clearly <i>interconnected</i> in some causal sense, a fact we will return to in a bit. For now, we are starting to see a few important tensions in the design of RNGs already:</p>
		<ul>
			<li><b>Unpredictability</b> – Increasing the number of digits in the output/state increases the unpredictability of the output. Sometimes less adroitly designed algorithms (like the one above) will eventually degenerate to some kind of undesirable low-randomness state, but most ones in use in computers simply will iterate through their entire state in some order before returning to the original one. Among the generators that look superficially okay, there are a lot of mathematically interesting ways to verify this intuition: we can count the number of bits to make sure it is evenly distributed; we can figure out if the runs of ones and zeros look OK, and a …</li></ul></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html">https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html</a></em></p>]]>
            </description>
            <link>https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046519</guid>
            <pubDate>Tue, 10 Nov 2020 14:46:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Product-Led Growth Flywheel]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046415">thread link</a>) | @mooreds
<br/>
November 10, 2020 | https://www.productled.org/foundations/the-product-led-growth-flywheel | <a href="https://web.archive.org/web/*/https://www.productled.org/foundations/the-product-led-growth-flywheel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header><div><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5cc32a73a349764b789711fe_dot-circle-dark.svg" alt=""><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5cc32a73a349764b789711fe_dot-circle-dark.svg" alt=""></p><div data-ix="default-scroll-slide-in"><div><p>The funnel is dead. Long live the Flywheel!</p></div></div><p><a href="#go" data-w-id="1bd70af8-4f8d-6ed9-fe79-0d73491deb1a"><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5cab68d23be1929718823851_Down-Arrow.svg" alt=""></a></p><div><div><p>Product‑led&nbsp;Growth&nbsp;cOLLECTIVE</p></div></div></div></header><section id="go" data-w-id="16913989-f06b-77b6-8eee-b10f7720c01c"><div><div><div id="Intro"><div><p>As product transitions from a supporting role to lead actor, companies are transforming the way they communicate with users, nurture relationships, and understand user behavior. <br>‍<br>This product-led approach shifts the balance of power in favor of the user and upsets traditional ideas about what the customer lifecycle looks like. Leading with the product (versus sales or marketing) means that the product experience begins earlier and plays a much larger role in the user journey as a whole. &nbsp;<br>‍<br>The way we understand and visualize this journey has been evolving for some time. SaaS businesses have been using Dave McClure’s pirate metrics framework for over a decade now. The pirate metrics—acquisition, activation, revenue, retention, and referral—have been so widely adopted and remain so useful because they provide companies with a way to quantify the customer lifecycle and offer a framework for a more scientific approach to growth.<br>‍<br>But the pirate metrics were developed in 2007. While the principles behind the framework are still sound, a lot has changed since then. User expectations have never been higher, and there’s more competition than ever. To stay ahead, innovative companies in every vertical have been transitioning away from traditional business methodologies and embracing the opportunities and challenges of <a href="https://www.productled.org/foundations/what-is-product-led-growth">product-led growth</a>.</p><p>Part of this transition involves rethinking the user journey and the strategies teams use to affect it at every stage. To this end, companies have been saying goodbye their siloed funnels and introducing variations of the flywheel model instead. <br>‍<br>A flywheel model encourages companies to consider the user experience in its entirety and understand its potential for compounding growth. <br>‍<br>We, the Product-Led Growth Collective, believe that making the transition from funnel to flywheel is critical to fully realizing product-led growth.</p></div></div><div id="Chap1"><p><h3>What is the Product-Led Growth Flywheel?</h3></p><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5d039b493011839d1761767f_gifofflywheel-2.gif" alt="This is a gif image of the Product-Led Growth Flywheel model that shows an animated infographic of the SaaS user journey. The inter circle of the flywheel shows 4 user segments—evaluators, beginners, regulars, champions—while the outer circle shows how companies can move users through the flywheel—activate, adopt, adore, advocate. These sections all fill in with color gradients in a clockwise order."></p><p>The Product-Led Growth Flywheel is a framework for growing your business by investing in a product-led user experience. In this framework, the experience is designed to generate higher user satisfaction and increased advocacy, which in turn drives compounding growth of new user acquisition.<br>‍<br>It depicts 4 sequential user segments that correlate with stages in the user journey from awareness to evangelism—evaluator, beginner, regular, and champion—and the key actions that users need to take to graduate to the next stage—activate, adopt, adore, and advocate. <br>‍<br>The goal is to focus company- and team-level strategies on optimizing the user experience to move users from one stage to the next. As the rate of users completing each action increases, the flywheel will spin faster, increasing the rate that users move from one segment to the next. This creates a positive feedback loop—as more users become advocates, they drive more acquisition, and growth increases exponentially.<br>‍<br>We’ll take a much deeper look at each part of the flywheel in the chapters below. But first, a bit about how we developed the Product-Led Growth Flywheel.<br></p></div><div id="Chap2"><p><h3>Methodology</h3></p><div><p>We interviewed over 50 companies covering a range of sizes and business models—from direct-to-consumer companies with over 500 employees to B2B SaaS businesses with fewer than 10. Some companies relied strictly on large enterprise contracts with low volume and long sales cycles, while others were dealing with high volume and a diverse customer composition.<br>‍<br>Over the course of our interviews, we talked with people in marketing, sales, customer success, support, and product. We asked them how they think about users, how they leverage product experiences to drive behavior, and what they thought was the most important accelerant for their company’s growth in the near and long term. <br>‍<br>What we found was a consistent pattern: Companies are beginning to refocus their efforts on improving the end-user experience through their products, and this change can be felt across every functional area of the business. The top performers are rethinking their approach to sales, marketing, and service in an effort to meet today’s user expectations and deliver high-quality, self-service touchpoint at scale—typically through the product itself.<br>‍<br>The companies we talked to are also becoming smarter about how they segment their users. They’re becoming more thoughtful and analytical about the goals their users are trying to achieve—and how they can support those goals—at different stages of their journey. </p><p>We used the insights from our conversations to inform the creation of the Product-Led Growth Flywheel. We shared working versions with the participants of our survey and iterated on new versions until we identified a model that best represented the way these forward-looking companies are thinking about their product users.</p><p>Now, let’s get to the flywheel.</p></div></div><div id="Chap3"><div><h3>The Product-Led Growth Flywheel</h3><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5d039b6d1c2fede3a7c27d84_found3.2-svgsFLYWHEEL%20FULL.svg" alt="This is an image of the Product-Led Growth Flywheel model that shows an illustration of the SaaS user journey. The inter circle of the flywheel shows 4 user segments—evaluators, beginners, regulars, champions—while the outer circle shows how companies can move users through the flywheel—activate, adopt, adore, advocate. The flywheel replaces traditional business funnels."></p></div></div><div id="evaluators"><div><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5d039daa81e4f5cef0733ada_evaluators-icon-final.svg" width="20" alt=""></p><h3>Evaluators</h3></div><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5d039ba2dc6c677440a206b2_found3.2-svgsevaluators.svg" alt="This is an image of the Product-Led Growth Flywheel model that shows an illustration of the SaaS user journey. In this image, the focus is on the evaluator user segment. The flywheel replaces traditional business funnels."></p><div><p>Evaluators are just browsing right now, thanks. <br>‍<br>These users are cautiously excited about your product as a solution to their problems. Whether they were compelled by your marketing or heard great things about your product from a current user, they’re here to realize the value they were promised. <br>‍<br>If you have a free trial, freemium tier, or even a low-cost monthly plan, they’re probably evaluating a variety of solutions—including your competitors.</p><p><strong>Evaluators are typically:</strong></p></div><ul role="list"><li><p>In a trial or demo phase—they’ve just started playing around with your product</p></li><li><p>Not installed or using real data</p></li><li><p>Not using your product in their current workflows</p></li><li><p>Still searching for a solution to a problem they are trying to solve</p></li></ul><div><p><strong>What they want from your product<p>‍</p></strong>Evaluators want to know that you understand their problem and can offer them a clear path to solving it. They don’t care about the nuances of your product or the wide range of use cases that you can address—they are solely focused on how you relate to their most pressing needs. <br>‍<br>They are gauging the tradeoffs between your product, those of your competitors, and possible internal solutions. Ease of use, core functionality, and unique features are at the forefront of these users’ minds. Evaluators are searching for value but don’t want to work hard to find it. </p><p><strong>How to deliver value<br>‍<br>‍</strong>In short, guide evaluators to their <a href="https://www.appcues.com/blog/aha-moment-guide" target="_blank">aha moment</a>. <br>‍<br>Let evaluators experience your product in action and get a basic understanding of its core functionality. Don’t drag them through an exhaustive tour of every single feature—assume they are starting with zero knowledge but firm goals in mind. Use your onboarding experience to gather information about these goals and then selectively guide users toward the features that will help them realize value. <br>‍<br>Remember: Evaluators need a map to initial success, not an advanced user manual. If they want to dive deeper on a specific functionality, be ready to help them via in-product support, opt-in walkthroughs, or a user-friendly help center—but don’t overwhelm them with this information all at once. Make sure they don’t get buried in the details of your product and that they stay focused on finding value and addressing the problem they came to you to solve. <br>‍<br>The goal is to guide evaluators to value and get them to <strong>activate</strong>.</p></div></div><div id="activate"><h3>Activate</h3><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5d039bae81e4f53abb7333ee_found3.2-svgsactivate.svg" alt="This is an image of the Product-Led Growth Flywheel model that shows an illustration of the SaaS user journey. In this image, the activation phase is highlighted. The flywheel replaces traditional business funnels."></p><div><p>Activation looks different for every company. But at its core, activation is a feeling that the user experiences—it’s a moment of relief and excitement when a user discovers the solution to their problem. <br>‍<br>Entering a credit card or signing a purchase order is not a prerequisite for activating—in fact, companies can have a lot of users who purchase but don’t activate. (You’ll likely see them listed as churned accounts a few months later). <br>‍<br>Instead, activation happens when a user sees your product’s value, has that critical aha moment, and experiences buy-in. Activated users <em>want</em> to learn more and are willing to invest time and energy into a product because they’ve seen it can be an asset in their life. &nbsp;<br>‍<br>To help your evaluators activate, you need to identify the in-product actions that users experience as aha moments and which trigger activation. Identifying your activation events can be done by analyzing product usage data, user testing, and interviewing customers.<br>‍<br>Once you’ve identified the activation events within your product, your goal should be to help your users get there quickly and minimize their <a href="https://www.appcues.com/blog/time-to-value" target="_blank">time-to-value</a>. </p><p><strong>Who is responsible for activation?<br></strong>‍<br>Product-led growth requires coordination and collaboration across teams, and every department contributes to activation in one way or another. <br>‍<br>That being said, sales and marketing typically own the evaluator stage, sometimes with the help of a dedicated growth, product, or customer success team member. Together, these teams will bear much of the responsibility for driving evaluators to activate. <br>‍<br>To do this, they will need to focus on understanding users’ needs and reducing friction on the path to activation.<br>‍<br>Secondarily, your product managers, designers, and engineers should be working to optimize your product for new users and collaborating with marketing or growth on in-app messaging and user onboarding experiences. <br>‍<br>And while much of their focus will be on customers further along in the flywheel, customer success and support teams should be communicating customer pain points and insights about their evaluator experience to improve your activation engine.<br>‍<br>Once a user has activated through these combined efforts, they progress in their user journey and graduate to the <strong>beginner</strong> stage of the flywheel.</p></div></div><div id="beginners"><div><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5d039db9dc6c67acf3a221d2_beginners-icon-final.svg" width="20" alt=""></p><h3>Beginners</h3></div><p><img src="https://assets.website-files.com/5c9ccce9e3044dd92e5814bc/5d039bbe81e4f582a97333fd_found3.2-svgsbeginners.svg" alt="This is an image of the Product-Led Growth Flywheel model that shows an illustration of the SaaS user journey. In this image, the focus is on the beginner user segment. The flywheel replaces traditional business funnels."></p><div><p>Beginners understand how your product can meet their needs and deliver value—and they’re excited about it! <br>‍<br>Due to this excitement, they’re spending more time with your product and exploring its features and functionality more deeply. These users may or may not be paying customers yet, but they’re mentally prepared to make that leap now that they’ve experienced the value that your product provides.</p><p><strong>Beginners are typically:</strong></p></div><ul role="list"><li><p>Incorporatin…</p></li></ul></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.productled.org/foundations/the-product-led-growth-flywheel">https://www.productled.org/foundations/the-product-led-growth-flywheel</a></em></p>]]>
            </description>
            <link>https://www.productled.org/foundations/the-product-led-growth-flywheel</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046415</guid>
            <pubDate>Tue, 10 Nov 2020 14:38:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The state of JavaScript at the end of 2020]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25046293">thread link</a>) | @milo_im
<br/>
November 10, 2020 | https://www.ideamotive.co/javascript-business-guide | <a href="https://web.archive.org/web/*/https://www.ideamotive.co/javascript-business-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
           <p><span id="hs_cos_wrapper_pillarPage_content" data-hs-cos-general-type="widget_container" data-hs-cos-type="widget_container"><p id="hs_cos_wrapper_widget_1603280203415" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    
      <h2>
        
          <span>00</span>
        
        
          <span>State of JavaScript in 2020 [INFOGRAPHIC]</span>
        
      </h2>
    
  </section>

</p>
<div id="hs_cos_wrapper_widget_1603200140243" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <p><img src="https://www.ideamotive.co/hs-fs/hubfs/Pillar%20JS/JavaScript%20in%202020%20C%20(4).png?width=1439&amp;quality=low" alt="JavaScript in 2020 C (4)"></p>

    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1603280336294" data-hs-cos-general-type="widget" data-hs-cos-type="module">









  <div>
    <p> Share the infographic in social media </p>
    
  </div>


</div>
<p id="hs_cos_wrapper_widget_1601646578122" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    
      <h2>
        
          <span>01</span>
        
        
          <span>What is JavaScript?</span>
        
      </h2>
    
  </section>

</p>
<div id="hs_cos_wrapper_widget_1601646616007" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <p>You might have heard that “JavaScript is everywhere.” Which is where exactly?&nbsp;&nbsp;</p>
<p>According to <a href="https://w3techs.com/technologies/details/cp-javascript" rel="noopener" target="_blank">Web3Techs</a> — on over 96% of all websites. Google, LinkedIn, Yahoo, YouTube, eBay, Amazon, you name it. There’s JavaScript all over the place.&nbsp;</p>
<p>Created in 1995 by Brendan Eich, JavaScript is a scripting language used to build and manage dynamic web content, such as multimedia, interactive forms, animations, photo slideshows, calendars, autocomplete suggestions, and much more.</p>
<p>JS is one of the three core technologies of frontend web development, along with HTML and CSS. While HTML is a markup language responsible for giving the structure to a website, and CSS is a language used to apply styles to HTML content, JavaScript is responsible for creating and managing dynamic, interactive website elements.</p>
    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1602069795205" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <div id="">
    
      <h3>
        Who is the JavaScript creator?
      </h3>
    
    
      <div>
        <p>Born in 1961, <a href="https://www.linkedin.com/in/brendaneich/" rel="noopener" target="_blank"><span>Brendan Eich</span></a> is an American technologist, software engineer, and keynote speaker. After joining Netscape Communications in 1995, Eich created a language to support the browser. It was designed based on Java’s syntax and standard library, and with object names that corresponded to Java classes.&nbsp;</p>
<p>In 1998, Eich co-founded the Mozilla project, ultimately leading to the creation of the Mozilla Foundation, which later became <a href="https://www.mozilla.org/en-US/foundation/moco/" rel="noopener" target="_blank"><span>Mozilla Corporation</span></a>. After leaving Mozilla, Eich set up another company, <a href="https://brave.com/" rel="noopener" target="_blank"><span>Brave Software</span></a>, developing a privacy-oriented browser combined with a blockchain-based digital advertising platform.</p>
      </div>
    
  </div>

</div>
<div id="hs_cos_wrapper_widget_1601646749682" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <h3>Is JavaScript a programming language?</h3>
<p>Yes! As the name implies — JavaScript is a <em>scripting language</em>. Traditionally, scripting languages are executed one line at a time by an interpreter, so a computer program that directly executes the written instructions. This stands in opposition to <em>compiled languages</em>, such as C++, for instance, which must run through a compiler before they can be translated into binary code.&nbsp;</p>
<p>Currently, it is possible to run JS with a just-in-time compiler, too. It compiles the code on the fly and caches the result to speed up the subsequent runs. Still, JavaScript remains a scripting language.</p>
<p>&nbsp;As a programming language, JavaScript is:</p>
<ul>
<li><strong>High-level</strong> – high-level languages resemble natural languages or mathematical notation, which helps simplify programming, including code updates and extensions.</li>
<li><strong>Dynamic </strong>– as a dynamic language, JS uses dynamically-written code to quickly implement functionality to an application, in a way that enhances programming efficiency.</li>
<li><strong>Prototype-based </strong>– JavaScript’s structure is based on prototypical objects, which can be cloned and reused as templates to build new objects. Prototypes also enable building associations between objects in JS. Copying and modifying objects are more direct than in class-based languages such as Java, which simplifies coding and reduces the programmer’s cognitive load.</li>
<li><strong>Multi-paradigm </strong>– JS supports event-driven, functional, and imperative programming styles, which makes it a multi-paradigm language. This results in its flexibility and enables different approaches to development.&nbsp;</li>
</ul>
<h3>Is JavaScript open source?</h3>
<p>Open source applies to software, and JS is a programming language, so no, JS is not open source. However, it’s an open standard that conforms to <a href="https://www.ecma-international.org/ecma-262/" rel="noopener" target="_blank"><span>ECMAScript</span></a> specification. Anyone can use it to develop their own implementations.&nbsp;</p>
<p>For JS to produce any output, we need <a href="https://en.wikipedia.org/wiki/Interpreter_(computing)" rel="noopener" target="_blank"><span>interpreter engines</span></a>, each of which is subject to its own license agreement. For example, <a href="https://v8.dev/" rel="noopener" target="_blank"><span>Google’s V8</span></a>, <a href="https://github.com/facebook/hermes" rel="noopener" target="_blank"><span>Facebook’s Hermes</span></a>, or <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Projects/Rhino" rel="noopener" target="_blank"><span>Mozilla’s Rhino</span></a>, they are all open source. By contrast, <a href="https://jerryscript.net/" rel="noopener" target="_blank"><span>Jerryscript</span></a> is licensed under the Apache License.</p>
<h3>The difference between JavaScript library and framework</h3>
<p>While interpreters are essential to generate JS output, frameworks and libraries are optional but highly recommended. These are <strong>prewritten components that your JavaScript team can use to build robust, highly-performant code faster</strong>. They offer significant advantages to your business, too, from reducing code size and complexity to speeding up the deployment of your project.&nbsp;</p>
<p>Sometimes, e.g., in the case of React, it’s hard to categorically determine whether a given resource is a framework or a library. Nevertheless, in theory, the two notions are distinct.</p>
<p><strong><img src="https://www.ideamotive.co/hubfs/The%20difference%20between%20JavaScript%20library%20and%20framework%20(2).png" alt="The difference between JavaScript library and framework (2)"></strong></p>
<h4>Framework</h4>
<p>A <strong>framework </strong>is a software platform that lays the groundwork for programmers to develop applications. You can compare it to a house plan or blueprint that needs to be populated with input before the construction begins.&nbsp;</p>
<p>Same with a software framework; it is pre-equipped with code for predefined classes, workflows, and functions, but needs specific details to be supplied by the programmer before it can run a complete code.&nbsp;</p>
<p>Popular JS frameworks include Angular, Bootstrap, and Vue.js.</p>
<p><strong>Jump to </strong><a href="https://www.ideamotive.co/javascript-business-guide#the-most-popular-javascript-frameworks" rel="noopener"><strong><span>this section</span></strong></a><strong> to learn more about JS frameworks.&nbsp;</strong></p>
<h4>Library</h4>
<p>A <strong>library</strong>, like a framework, refers to a reusable piece of code; however, libraries are usually focused on delivering a specific functionality/component, and give developers greater freedom over the code structure than frameworks. Coming back to the house metaphor: libraries can be compared to ready-made pieces of furniture or appliances that we choose to make our home complete.&nbsp;</p>
<p>The main difference between a library and a framework is that a library contains snippets of ready-made code that needs to be still arranged by the developer into a workflow. Frameworks, on the other hand, are in charge of running workflows. Additionally, one framework can utilize multiple libraries.</p>
<p>There are dozens of JS libraries available, with DOJO, jQuery, and React topping popularity charts.&nbsp;</p>
    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1602069971226" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <div id="">
    
    
      <p>While most JavaScript developers rely on specific frameworks and libraries, some of them also build applications using the so-called “Vanilla JavaScript,” i.e., pure JS code without any additional resources. However, this approach is infrequent.</p>
    
  </div>

</div>
<div id="hs_cos_wrapper_widget_1601647248048" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <h3>How does JavaScript work?</h3>
<p>JavaScript is primarily used in the form of<strong> client-side JavaScript</strong>. This means it is typically running on client devices (laptops, smartphones, PCs, and others) communicated with the network.&nbsp;</p>
<p>In the client-side context, scripts execute directly in the browser, which results in faster processing and immediate response to the user’s requests. Because of the speed and more lightweight script processing on the client side, this model is preferred to implement dynamic, interactive web content and handle user interactions.</p>
<p>An extended version of JS allows it to be run on the server side, with backend access to files, databases, and servers. In this context, JS code is created similarly to C, Java, or any other server-side language.</p>
<p><strong>Server-side JavaScript</strong> can be applied to handle logging in, manage personal information and preferences, and fetch specific files or data as requested by the user. <a href="https://nodejs.org/" rel="noopener" target="_blank"><span>NodeJS</span></a> is commonly used as a runtime environment to execute JavaScript code outside a web browser</p>
<p><strong>See also section <a href="https://www.ideamotive.co/javascript-business-guide#the-most-popular-javascript-frameworks" rel="noopener">The most popular JavaScript frameworks</a>.</strong></p>
<p>Currently, JS is the only commonly-recognized client-side language for browsers apart from WebAssembly, which is rather to be seen as a complementary technology. Alternative solutions like Java applets, Silverlight, or ActiveX, have all been discontinued by now.&nbsp;</p>
    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1603785890114" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <div id="">
    
      <h3>
        What is the difference between Java and JavaScript?
      </h3>
    
    
      <p>We’ve seen it happen too many times... A job posting for JavaScript talent with a “Java Developer” header. A few years ago, the confusion between the two languages was so common it became anecdotal. Today, it seems to be a thing of the past.The two languages could not be further from the same thing. Still, just in case you (or your HR department) need a little recap, here are the core differences between Java and JS:</p>
    
  </div>

</div>

<div id="hs_cos_wrapper_widget_1601896662232" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <h3>What can you build with JavaScript?</h3>
<p>Originally, JavaScript was conceived to add interactivity into static browser pages. While today, it is still mostly used to enrich websites with animated, lively components, its capabilities also cover the creation of:</p>
<ul>
<li>Robust web and server applications</li>
<li>Stunning business presentations</li>
<li>Interactive gaming platforms</li>
<li>Multi-functional mobile apps</li>
<li>Smart device applications&nbsp;</li>
</ul>
<p><strong><br>For more details</strong><a href="https://www.ideamotive.co/javascript-business-guide#what-is-javascript-used-for" rel="noopener"><strong><span> jump to the next chapter</span></strong></a></p>
<h3><span>How is JavaScript different from TypeScript?</span></h3>
<p>If you already have some grasp of JavaScript, you might have stumbled upon <a href="https://www.typescriptlang.org/" rel="noopener" target="_blank"><span>TypeScript</span></a>. A superset of JS, TypeScript is a modern programming language developed and maintained by Microsoft. It was publicly released in 2012 as a tool for the development of large applications in JS (“JavaScript that scales” — states the official slogan). TypeScript simplifies JavaScript code, making it easier to read and debug, and at the same time, it expands on JS capabilities.</p>
<p><strong>See also: </strong><a href="https://www.ideamotive.co/javascript-business-guide#javascript-vs-typescript" rel="noopener"><strong><span>JavaScript vs. TypeScript</span></strong></a></p>
    </div>
  </section>

</div>
<p id="hs_cos_wrapper_widget_1601896842863" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="what-is-javascript-used-for">
    
      <h2>
        
          <span>02</span>
        
        
          <span>What is JavaScript used for?</span>
        
      </h2>
    
  </section>

</p>
<div id="hs_cos_wrapper_widget_1601896857056" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <p>In the introduction, we have already covered some of the key JavaScript applications. Here, we will add some more details about each use of the language.</p>
<h3>Adding interactive website components</h3>
<p>JavaScript was made to create and control dynamic website content, and this task remains its primary application. A vast majority of developers use JS to enhance Internet web pages with interactive features such as:</p>
<ul>
<li>dynamic forms</li>
<li>animated graphics</li>
<li>autocomplete suggestions</li>
<li>photo slideshows</li>
</ul>
<p>If we said that everyone uses JS on their website, this wouldn’t be much of an overstatement. JS powers over 90% of all global sites, including those of …</p></div></section></div></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ideamotive.co/javascript-business-guide">https://www.ideamotive.co/javascript-business-guide</a></em></p>]]>
            </description>
            <link>https://www.ideamotive.co/javascript-business-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046293</guid>
            <pubDate>Tue, 10 Nov 2020 14:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Contempt Culture (2015)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046192">thread link</a>) | @riffraff
<br/>
November 10, 2020 | https://blog.aurynn.com/2015/12/16-contempt-culture | <a href="https://web.archive.org/web/*/https://blog.aurynn.com/2015/12/16-contempt-culture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
          <h2>
              <a href="https://blog.aurynn.com/2015/12/16-contempt-culture">Contempt Culture</a>
          </h2>
    
          
    
          <p>So when I started programming in 2001, it was <em>du jour</em> in the communities I participated in to be highly critical of other languages. Other languages <em>sucked</em>, the people using them were <em>losers</em> or <em>stupid</em>, if they would just use <em>a real language</em>, such as the one we used, everything would just be <em>better</em>.</p>
<p>Right?</p>
<p>This sort of culturally-encoded language was really prevalent around condemning <span>PHP</span> and Java. Developers in these languages were actively referred to as less competent than developers in the other, <em>more blessed</em> languages.</p>
<p>And at the time, as a new developer, I internalised this pretty heavily. The language I was in was blessed, obviously, not because I was using it but because it was <em>better designed</em> than a language like <span>PHP</span>, <em>less wordy and annoying</em> than Java, <em>more flexible</em> than many other options.</p>
<p>It didn’t matter that it was (and remains) difficult to read, it was that we were <em>better</em> for using it.</p>
<p>I repeated this pattern for a really long time, and as I learned new languages and patterns I’d repeat the same behaviour in those new environments. I was almost certainly not that fun to be around, a microcosm of the broader unpleasantness in tech.</p>
<p>At least, until I got called on it.</p>
<h4 id="have-you-thought-about..."><span>“</span>Have you thought about…”</h4>
<p>I’d been making critical comments about <span>PHP</span> the language, and <span>PHP</span> developers, nothing more than standard<span></span> <span>“</span><span>PHP</span> sucks” sort of language. The same thing I’d been doing, and supported in doing, for years.</p>
<p>Getting called out was hard, and I was asked to consider who and what I was criticising. I was able to access a very specific version of the self-taught narrative, where I used <em><span></span><span>“</span>real”</em> programming languages and had <em><span></span><span>“</span>real”</em> passion and drive, the result of which was that I fit the early hacker archetypes and was permitted status - as long as I participated in gate keeping. My self-taught narrative is not other peoples’ self-taught narrative, and I was very firmly reminded of that. Other self-taught narratives, such as starting with Wordpress-based design backgrounds and moving from more simple themes to more complex themes where <span>PHP</span> knowledge is required, to plugin development is a completely valid narrative, but a path that is <em>predominately for women</em>.</p>
<p>This was a bombshell. I’d been <em>loudly</em> criticising the language and, through that criticism, implying that people using the language weren’t as good me, <em>weren’t good programmers</em>. And suddenly I was thinking about all the myriad ways that someone with that background would feel othered by me, like they didn’t belong and weren’t welcome in the communities I was a part of.</p>
<p>All of the ways in which I was actively participating in the exclusion of women from <span>STEM</span>.</p>
<h4 id="intent-is-not-magic1">Intent is Not Magic<a href="#footnote-1GRF" id="ref-1GRF"><sup>1</sup></a></h4>
<p>Of course, I hadn’t intended to do any of these things, but as I came to realise, it doesn’t matter what I intended to do, what matters is that I did it and that it had real repercussions.</p>
<p>I <em>intended</em> to make fun of a language, the repercussion is that people from minority backgrounds wouldn’t want to talk to me about the things they’d done in that language, they wouldn’t feel safe talking about their achievements and exploits.</p>
<p>And why would they feel safe? If they say what they use, we as a culture laugh at their choice. We tell them they should know better, tell them that it’s a horrible tool. Tell them that they are <em>wrong</em>. We ignore the achievement and focus exclusively on how it was reached, on how much <em>better we are</em> because we had access to narratives that the broader culture had already deemed <em>more real</em>.</p>
<p>Not better narratives or better tools, just more accepted, more permitted, more discriminatory.</p>
<h4 id="contempt-currency">Contempt Currency</h4>
<p>I was taught to be contemptuous of the non-blessed narratives, and I was taught to pay for my continued access to the technical communities through perpetuating that contempt. I was taught to have an elevated sense of self-worth, driven by the elitism baked into the <em>hacker ethos</em> as I learned to program. By adopting the same patterns that other, more knowledgable people expressed I could feel more credible, more like a real part of the community, more like I belonged.</p>
<p>I bought my sense of belonging, with contempt, and paid for it with contempt and exclusionary behaviour.</p>
<p>And now, I realise how much of it is an anxiety response. What if I chose the wrong thing? What if other people judge me for my choices and assert that my hard-earned skills actually aren’t worth anything?</p>
<p><em>What if people find out I’m a fraud?</em></p>
<p>By perpetuating a culture of contempt as the means of acquiring credibility, I was able to avoid these difficult, introspective questions. We don’t have to look at how we’re harming other people who want in, don’t have to acknowledge the niggling little voice in the back of our head asking <em>are you good enough</em>. It wasn’t me that was wrong, it was <em>them</em>.</p>
<p>Instead, I was taught to use emotional weaponry to silence and exclude others, resulting in the remaining voices being the most toxic and exclusionary, the most able to tolerate toxicity and exclusionary attitudes.</p>
<p>This pattern is <em>common</em> in tech, from extremely high-profile projects like the Linux kernel to the ongoing os/language/editor<span></span> <span>“</span>wars” to the vile reactionary attitudes towards the introduction of Codes of Conduct, to any developers making disparaging comments about other peoples’ ability to code, and the growing contempt around people whose first or primary language is JavaScript.</p>
<h4 id="and-now">And now</h4>
<p>This culture has ramifications. <span>PHP</span> communities, for example, have lacked access to the development of DevOps tooling, the use of <span>PHP</span> is widely derided as being insecure by default, are they are widely mocked for being an<span></span> <span>“</span>objectively bad language.”</p>
<p>Yet people make their livings working with <span>PHP</span>, deploying <span>PHP</span>, trying to secure <span>PHP</span>. Don’t they deserve the help that we received, the help of good practises and security-first development? These people who can’t improve their work because we won’t work with them and drive them away from our communities with mockery and spite.</p>
<p>And then they engineer things on their own, because they still need these tools, and we have the gall to ask why they didn’t use these other tools.</p>
<p>Tools that we mocked them for asking about, telling them to get a real language, to rewrite their entire app, to rebuild from scratch because their particular path was <em>not blessed enough</em>.</p>
<p>Because <em>we</em> were the problematic elements.</p>
<h4 id="im-tired-of-this">I’m Tired of This</h4>
<p>It’s 2015, and I saw a presenter at a Python conference make fun of Java. How would that feel to people trying to move from Java into something else? I wouldn’t feel welcome, and I’d have learned that the idea that the Python community is welcoming wasn’t true.</p>
<p>I’m tired of calling people out again and again for dumping on <span>PHP</span>.</p>
<p>I’m tired of people dumping on Windows, that most popular operating system, because it’s not what we choose to use, tired of the fact that we don’t make it easy to use our tools and teach them how to move, when they’re ready.</p>
<p>Instead, we lecture and dismiss and heap scorn upon them. We don’t reinforce our communities with respect or a sense of achievement, but with shame and contempt and awfulness. We exclude people.</p>
<p>I’ve excluded people. Directly, me. I have to own up to that and deal with it.</p>
<p><em>We</em> excluded people. Directly. All of us. Even if we didn’t intend to, <em>it does not matter</em>. We make fun of the things others care about, make them feel small, make them feel like their achievements didn’t matter. Make them feel like they’re not welcome.</p>
<h4 id="what-can-we-do">What can we Do?</h4>
<p><em><span>SHUT</span>.</em> <em><span>UP</span>.</em></p>
<p>No, really, <em>cut it out.</em> If you need to make fun of a language, do it with your own language, inside your own community. JavaScript is really good at this, because they’re trying to help people write better code <em>within JavaScript</em>.</p>
<p>Do it around friends only, and acknowledge that it’s extremely problematic that you’re doing it at all.</p>
<p>Find some amazing project to celebrate in a language you’re contemptuous of.</p>
<p>Go to meetups of what you despise. Say you don’t know anything, and see how welcoming they are to new people. See what they say, what they do, and ask if you’d be as welcoming to them when they come to your meetups.</p>
<p>Work to change your community. Ask people who try to pay for their membership in contempt to stop, or to leave. Make it unacceptable to use these behaviours as a means of obtaining social wealth.</p>
<p>The best advice we give programmers is to leave things better than how they started. We do it with code, why don’t we do it with communities? Why don’t we do it with people, colleagues, friends?</p>
<p>Ask why it’s okay to do these things in your community, and leave things better than when you started.</p>
<section>
<hr>
<ol>
<li id="footnote-1GRF"><p><a href="http://www.shakesville.com/2011/12/harmful-communication-part-one-intent.html">Intent is magic!</a><a href="#ref-1GRF">↩</a></p></li>
</ol>
</section>
    
          
      </article>
    </div></div>]]>
            </description>
            <link>https://blog.aurynn.com/2015/12/16-contempt-culture</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046192</guid>
            <pubDate>Tue, 10 Nov 2020 14:20:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vue 3.0 Components Library]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046142">thread link</a>) | @quatro444
<br/>
November 10, 2020 | https://quatrochan.github.io/Equal/ | <a href="https://web.archive.org/web/*/https://quatrochan.github.io/Equal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://quatrochan.github.io/Equal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046142</guid>
            <pubDate>Tue, 10 Nov 2020 14:17:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benefits of Infrastructure as Code]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046111">thread link</a>) | @FedericoRazzoli
<br/>
November 10, 2020 | https://vettabase.com/blog/benefits-of-infrastructure-as-code/ | <a href="https://web.archive.org/web/*/https://vettabase.com/blog/benefits-of-infrastructure-as-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p id="post-modified-info"><em>Last updated on 11 November 2020</em></p>
<p>Infrastructure As Code is a paradigm that consists of describing our infrastructure (servers and their configuration) as code that is understood by automation software like Ansible, Puppet, Terraform, and so on. Automation software can then be used to recreate the infrastructure we described or, more commonly, to fix differences between code current version and the way the infrastructure is now. Which means that, for example, we can upgrade our MariaDB version in the code, run Ansible, and have MariaDB upgraded in the relevant servers.</p>
<p>But what are the benefits of Infrastructure As Code? In this article I will list one of them.</p>
<figure><img src="https://vettabase.com/blog/wp-content/uploads/2020/11/inverness_castle-1.jpg" alt="Inverness Castle and Ness Bridge" srcset="https://vettabase.com/blog/wp-content/uploads/2020/11/inverness_castle-1.jpg 799w, https://vettabase.com/blog/wp-content/uploads/2020/11/inverness_castle-1-300x196.jpg 300w, https://vettabase.com/blog/wp-content/uploads/2020/11/inverness_castle-1-768x503.jpg 768w, https://vettabase.com/blog/wp-content/uploads/2020/11/inverness_castle-1-16x10.jpg 16w" sizes="(max-width: 799px) 100vw, 799px"><figcaption>Inverness Castle and Ness Bridge, Scotland</figcaption></figure>

<h2><span id="Deployment_speed">Deployment speed</span></h2>
<p>How much time do you need to setup a MariaDB replica? Hint: I bet that your first answer is too optimistic. Consider you need to feed the server, setup replication, maybe a job for backups, monitoring, let proxies know about the new server, find out what the hell you did wrong in a previous step, etc.</p>
<p><strong>Automation software will do it in no more than half minute</strong>, plus the time needed to import a backup (I never said it’s magic). When you have to setup or modify several servers, automation is precious. Even with 5-10 servers, it makes the difference between a reasonable activity and a miserable life. With 20 servers, it makes the difference between being able to deploy or not.</p>
<h2><span id="Avoiding_human_mistakes">Avoiding human mistakes</span></h2>
<p>Depending on which tools we use, the code could describe the configuration we want to have <strong>or</strong> the steps to reach the result we want. But whichever approach we use, deployments can be tested on staging before applying them to production. The software we use will always apply configuration in the same way. It will not forget a variable and will not mistype a command. <strong>Automation is much more reliable than humans</strong>, when it comes to repetitive tasks.</p>
<h2><span id="Testable_operations">Testable operations</span></h2>
<p>Applying a series of commands automatically instead of doing it manually is important, but it’s not all. <strong>The commands themselves can also be tested</strong>. We can run our automation against staging servers and see the results. We can also automate some tests. For example, an Ansible task can make the whole playbook fail if mysqld is not running when it should.</p>
<h2><span id="Think_declarative_think_idempotent">Think declarative, think idempotent</span></h2>
<p>Automation technologies are, in general, declarative. <strong>You describe what you want, you don’t write the steps to reach the goal</strong>. For example, you state that a certain directory should exist, and specify its owner, group, and mode, but you don’t write the system commands to make it happen. When you setup a new system, the two approaches are more or less equivalent. But when you modify an existing system, the declarative approach is incredibly simpler. You don’t have to check if the directory exists, who its owner is, and so on. Your code will be <strong>shorter, quicker to write, easier to understand</strong>.</p>
<p>Idempotent means that you can run the same code twice and obtain exactly the same result. This is very important. You can apply your code again to a production system to update something. You state that mysqld should be running? If it’s not, it will be started. If not, nothing will happen. This avoid a lot of problems.</p>
<h2><span id="Documenting_operations">Documenting operations</span></h2>
<p><strong>The code that describes your infrastructure also serves as a form of documentation</strong>. If you want to know the Xtrabackup version in your servers, Infrastructure As Code probably allows you to know it by just checking a variable. Even if it’s not so clear because your code is less than optimal, a tool like Ansible allows you to run <code>xtrabackup --version</code> against a group of servers with a simple command. Once you get used to this way of working, connecting to servers via SSH to check their configuration will appear as a waste of time.</p>
<h2><span id="Conclusions">Conclusions</span></h2>
<p>Vettabase highly recommends having proper automation in place for your database infrastructure. We discussed the reasons that seem to us most important reasons.</p>
<ul><li>Automation saves you plenty of time every day.</li><li>Automation is more reliable than humans.</li><li>Automation makes operations testable.</li><li>You describe your goal, not how to achieve it. You can safely apply your code twice.</li><li>The code serves as documentation.</li></ul>
<p>If you disagree with us, or on the contrary if you have more reason to recommend proper automation, <strong>please comment</strong>. We’ll be happy to discuss.</p>
<p><em>Federico Razzoli</em></p>
<p><a href="https://www.flickr.com/photos/91779914@N00/3938586256">Photo credit</a></p>

			</div></div>]]>
            </description>
            <link>https://vettabase.com/blog/benefits-of-infrastructure-as-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046111</guid>
            <pubDate>Tue, 10 Nov 2020 14:14:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EU has plans for a European Internet with a firewall [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25046096">thread link</a>) | @MaKey
<br/>
November 10, 2020 | https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39 | <a href="https://web.archive.org/web/*/https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>UÉÆ}ªÈžÎ6ž·26ÌkþîçoÙÛ©9·-æ¶ãsíð\;zò–ÏÇ–ÁÊÛ2|î¸ú}òz›Vê´×°ÑÚ.}nÝþÚ‡|ÞÅ_—³H�
endstream
endobj
2614 0 obj
&lt;&gt;stream
H‰´WÛrÜÆ}ß¯˜GLÊXÎ¸\®ŠHI–-Ñ¤¸ªTŠN¥jEo¢%%RŠÊùzŸîž`—+^b™hôôõôéG‹ÙÞ‘úî»½ûÏ”Qßÿè`_ÍööOŒ:»VfîÃ&nbsp;ÔõÙÅloaÿi”U‹·3gç�j
Ä�›•ìÜ©&lt;\¬g�Ò‹Ï¿ -£f[4ÑféVÁw¢ÂûÛT¸QEkç©‡è›/ˆú
Ñ&gt;¦/‹†û‹ÆûÐÝ_kº¿h†ûkµfCÖÝ¦ÖÚÈn&amp;Ìßjƒ€ÞðÙøÙš47�ÉÞ-Ÿîðï1zëÉêüÓÕrü¦æåÃÌº4.ª€ë€«�È©÷Ð5$dL]-gSÜ{Šf&lt;¿žeßwQqç°œ1&amp;%ÊB`¸ófnÐ�§�­g{ÏÖF\ÎŽovTÍü1Ùã4aìzå]�ª&nbsp;&amp;Ï6<z"xaá‚qøßù(ýŒÇ€†3´ôÜ8§Ÿ•Ï�«�ÔØ�…~´÷is¨ Õ,?këæi5ê@üà¿ÚÍ-®ï="" us©="ð¥y/âëå…ö–ä?ê…ÍµÆ?¥ÿ±ø‘b}|O3«�!nÛ™" Ž‹}*v®´¡s.´¥8ª…oÍý„="ùí¹¶�ÞæŸuO&amp;¾Ö�<y‡àˆ:a+§Q²t8">‡£pN›å•¦859«3m=}¼¼.ÈÎ]GŽ…Þe—H¡aObÁT¾ð¨ú’Ërq³ì¤"¹ÿ—ˆÛ5P¦š�OokDóÍgµ5lBQ¹ =AŒàÑ¯ºµ9Á­åT^ñ�§ðÕtþ_m�îœ™÷åü¦ÍAøZº)¸E·úcº)»]©�´#ŽÔÕaŒä/�n;
˜“�¹8«}¢›_t~ÿ�&amp;|A	®9è¸[jGæ4ojá"ô½j&gt;ißÓ§ë¯›ßõZ
|ŠR
èîF|êï“ƒœ‚ˆ|ÕHÆã7;ZÀoÒÖn•›:Zq¨‹»š6:ä,IÙ)àŒûõB&lt;|¸&amp;&lt;|GÔsGJ~}.x5X@NÒOÇújFd€kCW�ð£nÁi è6ô&lt;ãƒT1ÎTýà%ü­ï&amp;	ð[¿©DR½gœ‰E3n®®qçdÌŒïžÎô �Næp§`8#}€èÖ[Ýtu]½&amp;Wõ”«â:ˆQv=ò¤l1ã@ƒnÓ x]L¸ÐüšbÞòtP°Q÷‚¢ŽÁ^7ð˜Y­ù¶—™hþp°0KZ*ÝQoÕ²"îÇ£x®bð¤2ZwTËió–¬qcæ¯èê³ubœÙbû¨M³ƒ*MŠ×ß&amp;í
è6rrÎ0h	.æv®Î),0s%á¨Ê‘£œÔè^q&nbsp;<g_rrÃze8t”¥¿ò“Žjhd4Ø¶q‡Çxõ`»õ1†>ïUBâbÇjiöAéÛ&lt;ÔWx°ù;“à­EQ#…5=Ê‘i}ÿ—›V˜¤ÈôÊ‘i�½°ÆÏí0L¼™@Yö&gt;ºóL¬,ßß‰i¾›`š-ë©ÿ£Õ
¾¨pIXË%aË¶éàd7§ˆ)†£Ì)/µ 
1¶ ì‹â7-ÀŽê�`’!ù÷Ú1ËãŠ¸Ò®bêùå:]èAä¹z«#À§¥ñCPKë¹ég‰r~‘,ªÊïµXÈ&gt;¦˜q˜~¸ú‚
«bCuQ±!‹&amp;ÂšNªX¬ÂÝ±ŽÜßŸt4™Þ²Š–çþå5Z˜Œi4¶9ºùœÈF(Ö	kW?ÜÈJÏÙvîz_\?¼¿�/Ó*êëÚ`«ÈaŠÑn²ƒ1Íf(&gt;�íØïM†º�{Þ	xk%û—Ä¤Ò(òš~SïoÃ uËd RÁºZ°Væ¡/~œ6Oµ•…		ât`U‡“&lt;$ÉP}¥\5™W‹œz¦CÎ°—b:¥¢¨Ë/¶RiåÄ²ÂTB4ø1ï(aü½ÜNƒé-éu-«#¯.§CR!Q¤ZC%(Ád;™ƒ—DÃ9»Uó¾KÓi¼qDJçº}ý4DK¦á”ô2Ø½ÿ0à2Í�q¢Ù†Ÿ`Îùš™)Çf&nbsp;ÝÙüú¾Þ|“Ï}ÎuÔñê¤¸[×ÕË’­á5”:„ôöÅÆnbã¯åsù€sÙF'(“»ï„¹¿žÐ¸ž\_–=,[¿OäH5âNYè^ GLÎF”Q÷®Ïå!‘«6ˆÑY]IØEv­¦²(ºøŸÞô˜ËmëŽ¸B7êX$?p†…›ÜYPyCñOšýþY‹wG™¸?Ñ6æ%‰¡Çª‡æG¸+&lt;Ðç¥´¯aòBEèt#ø(Ìâi`´eQn°’\‘TÙ¤—¯Øy.%g%ôÎL�*ˆYOeUi¢ªÊP&gt;ÆçWÌe|1"M
“�a|"À{Hº¦¡bkàóóçåîp»Íü&lt;ÞŽ¹ÁM0·ôŸ�B~Q	9ƒq�´í¥ƒ‚�ÊCk¬jRÔ]Pê7m)'¶d©åí­/´c&nbsp;ö|ÒoøÅçŒ3|Ð®õiƒÍf^Aw¾£ªfƒ¥z»ÅÀBÜb`ÑÀ“¨�ÌÒ=á.»XH#ãoA'‰$s„K{åmd©­l©îbh ÛQN˜€Ñ$Ð,^=&gt;ÌíøL»Vç3ÍµÄ"~…w;v±ÎŒcXÚÝj:×sk‡�YïÍ˜E7�„çM&gt;ìûÝ”•7Œ”dyh &amp;56ÔÜ©'h¢-‰å	@HùJðþ€VEÕü}Jÿï&lt;;röä !ÉÓ“j�Ž7£mPÐ�²G-¡Ë
'Ž;™`L˜x—½`"Æ.¼$—I€ðƒîh‚1ù&lt;ä;!1ïŸF6Tžsê_„�7SäEŽVÞ,ÁFÐöŽðJØÇ¾ˆ:Ž÷U€Q¤šÃT+dç®×+Ýy¯'ó•PìÆž‰vî‡
LúR1M6™€
í-íZÖ¡:‰|²8çæÃlï)ÐàüzÆ¯ÝÈ‡bfÀ¦"”PŠŒÇ¬Jp›†
¯³õlïÙÚªƒK$l·)q¬k‰§æà9žGë	âMkð²£ÃÓÀÆ°	&gt;ƒì†ÁY…ÅÝš:ð_±ÄM,9žý.ÀïkÎ(
endstream
endobj
2615 0 obj
&lt;&gt;stream
H‰b``œáèâäÊ$ÀÀ�›WRää¥À~ž���™“‹|@ì¼ü¼Tðí#ˆ¾¬2S/`M.(*Ò€Ø(%µ8HâÌò’&nbsp;8c�-’”
fƒÔ‰d‡9Ù@6_IjHŒÁ9¿&nbsp;²(3=£DÁÐÒÒRÁ1%?)U!¸²¸$5·XÁ3/9¿¨ ¿(±$5¨jð»%V*¸'ææ&amp;*é‘èr"(,!¬Ï!à0b;�C€äÒ¢2(“‘É˜� ÀIÆ8/
endstream
endobj
2616 0 obj
&lt;&gt;stream
H‰|U{TgŸa˜Iä1ÃHt&amp;Z�«õ…Š‚¨”‡J"BWM„(!èé¶†­§n·Ý]QD@°¢Ö"A¤�WD@VYuÕ={ê�øáé°í9ûÏþó�ûøîoîýîýÍÅ1{;Çq�€&nbsp;5aÑê¹tq•A?_­�OMŒ3Œ99~*Î»ÛóÓœ´å¾{÷n	Ù“¡vÊ­©Ób¥�ãä™ÒÀTƒ~­&gt;IˆO0*{zzÎ;½”«5ú�ZeÄÁ£v_Š2xÿ.½!Ioˆ3j5”«•ê±€¥Z›¢5˜ÆŒ‘"(UÂ…ýFe€×R¯yK}/˜ÈL©KQÆ)
Úx�€fÐj”FCœF»/Î°W©ßýÿ¾´p]ÄæƒIZ¥�R£Ý�a¸PFÙcN.‹aJæ¯À¶aX,†%à˜ÃÒ0ì†µbX;†=À°A?‚aÛ…§Â6b*ì&gt;¯Ãíh»@»=vGìòìnØu,±†È ^Ù/±Ï!qr&amp;YFÍ¤vRÇ©¢¹¢ÇâùâoÄ¯&amp;LJœ”=é•ƒ›Ã|‡í_;\pä“ï8¹;e9½rÞèœà|Æù�$H’'±JÐd§És'ŸrqtÙèrsŠË”ð)ýÒÒ(i‰tH
´ž¾NÛ\5®íŒ‚If¾eÞË¼e¸©Ý2ÜòÝž»‹ÜW¹«Ü{¸{|&amp;'å;å�)�G«ù—Õ¸pÎ¬&amp;ŽÚó6Õh¹¨�A~ð	#R¢ZÆ”Ñ?‹F©íã2ø!A§øfLBcš½“&nbsp;3¸ð
iÒzpø]?Ýs`s‚7’s©£F’¼„â˜rËù²rca¼Î�ŸP�t‰“€ápínœ¯-¨…ÄZiI;¬lq¬j£ËÍf›Ã,
Xƒd’e·÷)u¶Â4p	k_ÄÙÂüh	^¹4ycøæÄ¦þ®¿¸ùKëÍUï1†§mËÈjTú~I×˜ùõüìq ·q&nbsp;�&gt;ÅÀ�ê�"÷ÞÈæúK I™¹Eg²‘�Ò�&gt;Þ=t%�È¿’íº–p9þrõ�âGù?‹WPŸ-3…$þ~GUh—ºEœ+z[[Yß!Rï�ìUÞË?&gt;SËfˆèJ¿¸ÍÊgu/·®fË­–6êóœ&gt; ¦+Qfã«¾ÓÓñÃµrwéýåWbÅ	{c’Õ
º4Ÿ¿ÇÔY¶íTÇÆ¯×pûËS+ªä5Å7êX‰Í/
¿#6?Æ�üAjxý—îE7®fKÐ·ÈÙV�7uea6x!×,-FQ­Èõ®ÛF¼Þ®°NÁµ ³þ“ý5fY‰'È™i¼4l•Ct¸†ö³ë©ÎÙ·�+Z/GA›‘,`6+)<k‚ôfn7pš fÐ!d="" jo‚t05"iæšðs°ˆèe“˜¢ï¯aœ“în^“¤4©„4óà�Íx="" %j ž="" �£Í"‰¤x="" 8@˜™="" ËùòŠ”Â„còîøñ‰ai¶Õix¼&zv1pjÓ‘ë)tñ½Ž”¨Í­|i+^þòŸpr˜ä="">9¡ýÚ›ówä´föƒ’a×*�&nbsp;iÜë™áÊÈùî˜±hEÔX�õÿèá$ê³&amp;¾¹ÿhšÌƒt˜eƒ6ÖŸ¢ÛÐŒ�Nù#™CIÔG­üß¬8ðO~‡ÌŠ¾ËÕT‘ÂT¹?~	NòÕ¤ôÕk·³EÉs%7Kî(^^ÜÌeÍñ÷F¾hñº ÷H‘�t|Ýš)&lt;
¦G®–2¦‹MF«&lt;û†ÿ=Ò¸"�ËÑo_¹}OÞÞ�\ƒ
k	%ÏU[j}¥Û¢ü|÷„r1Á7)zd°_ã™ÍEf'¬E¤bSø¹&lt;Ãx=Ø�ƒøÉ!Ð
üL·yò³ç‰ÐµÑ%d8Ô¡@ÒA“#‚%�œ_’Wtæ²G.•©ËÒéähßDª—[Á»ÛÁÚX5Qq¨™Ì-(&gt;V¡Y}˜w6çé£Úr&amp;/‰M
"Ó.4¦u(`ú›ç@÷ÇÕo-æ
vEÿ5Z‘òifæ¸s°BØÔXç&nbsp;¡&lt;»ñK�Á"`{Ùf3Ÿ¤fIæ–§¯Ý¹Eºmr•£UÃ}`BC}�hm¤ng"›A�|k}¬åÜ1Kv~–Í-bÆô¾ÍäòŽÿò/ì÷7Kk}µlÝà?Ñâ.+Î;&gt;#n•¬�ŽL*í$‡)(ç‡È†±‚›ø«w¥OC åQÈm_xÆÐC+t1áËåóú}a*¸¼ì²7ú¶ïE6WD÷&lt;¼|þN�¼oC/’"Ê+p&amp;K[#.DtêØgèªéÝÐ’ËýTYÝý
ûÄP§])§­Á[£W²Ù¼àîé½¥Ú±+âç&amp;¦¬YpÖ_©²²uú}ð½7ïá•�áÄñ"�9›U”}ñOí_µ•Tß7ýTõ&gt;�ƒïrÀ�òXŒ04÷—À¤æšÂëål.uÈ/Q½C³;ácÓÖÃû2R3äˆÁKàì³Êeˆø4#ý‹Ï9�qÛ~•â£˜Û}Ïj[º8�ˆSàÀod„çcl,ã*²Œç	†¤Ýã¿ðlôóoöÂ1{ò„]à=+7‚ñàWî~8ÁýT•ø_¼v|!TÏá¿h’B˜ÞSñ+üq‚¯…§Lãèñ0m��$ÈGH‹Ïè”
ýwœó¶ÉŒý‚y™±§ôÝzØÌd�Ëø!ï»ë5Uõ—«[åÝQH´%â“”ÿp]¥QQdWXÄ*ÚÑ)#u›®XA&amp;ŠaÐí£¢B@qDTÐQY»7\XeqCAÑ@°»•Equ„†FdÀnQÜã-òð$�œääï«÷nÝ{ß÷Ýï{Áì7âlaÙ)Ó�Zì-Þ¸i
»ne¬ÇQ¯ôpýò
òýRË&amp;Îïå`r¨Úõ?Ã‰Û0©ÚðÚÝÁ&amp;ð¸	3ïÒ½ñüOp\ˆ%æ¯ñ^N«ßè’Ê¡Ö_u¹IÉY\é¨XµÙkŸ'ƒÌ‘Þ08€/F`ó´&amp;h‡�#�§‹w’¶O™Ó¡€å¢SáA'üÄY ý�Ã�oøÔß¯.º§d3I|À=ùJX3Ø«ƒïÀM„)ÈE Sä‚6£5À¡É0ÿÑ�“EuU�9/mu'c…üº“w©°
I	¬ìqXMH‹õñ©)‘×,l‚µýòtùÉò¬2A:™˜�ãÛ„¼DÔÎ„fÈn‚ÈG†ZˆÖ-&nbsp;?v¤“Šª“î30¾#ÿZ
§¸\PY/~·è¶ë�+¾õâµ»�âÛ²2éEVá¿:Ç–q÷H8ÄiW
3²2ÊÝýPÇk6ÌãÉåÚHúã«®&nbsp;yóC¬B#Ò2â8*+¾�¯Öl—ªèþb¿0Nº&amp;Þ‹AóçüÀ’�ïÁúNÍ¾]—9úÊ¹V‚n9å•gÏ&nbsp; ÜS´…ƒ)ú&lt;{æž)á¨×	jþZ‹^‡–ŸÔ¯�SO¬¼•üÓ†

\Ã/Š0^zÒ'ulÝJë"4•Yê–pÐ‹Óº
�(2«p{1Ù¤rhÅlSä¼--3š¥$‡5�ÔÁXŸ—ð"!Ê�`(ÖŒŽûlÇOÁ’I�CRóñMÔ·AÔ—}FZ¨‡ãmè8DA‘ý‹¤:µÁN5Ó„ŽUËOî£‡øgðIˆ"–Àt´‘Ü/&lt;ˆ1d5ó=ü’O`~sÕÞ]*Ž~:VùPö÷\	ƒdˆEfhc*g¢²ª_Íº5õ†`ú;²K9ªgÐÒJ9Îºtú#vÂÏvZh�.Ô¢±³AJÔJÌ®Þs²;ù—D¿î±Ã«&gt;ø2@®!Z}�8,¬¥’áG�Å²{Î—*a@&nbsp;«Ž_kk@íüo\nù°"P/ñ‰Îð"H†R�#1b�ÆEÇFÆ†'Ã[’²ÀŠúæ÷Sü$
*çßàUØ›	Íd|¯Ö°~d16baÔGúcü"}«{A_Ùnéç"H&amp;ãÔQí;±&amp;@—¥Ã|0¾%ó&nbsp;âèû#@¤÷§“g.Ù–Ì`U×CíD‰ÇH·bào}]XìRí�"âÈ\¥;¤¥Œø	“§£^õÐ&gt;`måt(LHyšØÇf¤)œ«Ö,2†ôŠÀ=\€”$�k’¾à¸›’º­%°u]—1
…AbÎg;\Æ¤øVþf«žê%ÿã€&gt;|q¢exVÿ	… ?˜ŠXX
‹`L�ÝàƒÍÊäÆ%-Â,5Þ"Fs%ˆÆ&lt;]B˜	æm`39*ßk®ŠÆ&nbsp;
	_»]@&amp;æ_H½Èô=.¬­æÊ¼ëÄ÷£k·”°ª·üï™%?%òç´nÂÌœ¢Œ«Ìë?kKWo“‘éGb¸ÿKsdV¸Ð3ËùÌ²\A¦L(íÆ2à$†
8?äŠV âP(ÚŽaú
Ø&amp;°§³³¹'aÏÃú#¨l„è�Ž8cÓ4f§¶a¹4cÀT�1ÈR‚%’å¨m¸†ª&amp;8öèj¨ê!»’UÒ|Ë³ö9ž'å‚äž‹»£w©C¯¯ÍÃF»õÂ�{ÏÅ·bªƒ‹Ù«þ¹–Œ‡[â_Në.ÌÌ.Î¬`R‚lÅWz[²Ö$µ0^Ã_oÁ¯lNwb“©j•72`ÓÙ?üvU"+9KÕæ¿7ˆ«•uªäûÎ³tÕL¯ÎÜíëÎ,eÐ4[‰ÉœfOÈõKU[ÝÄ.k}¬=&lt;ó/²”3öCØùaßég¤ã‡`sûh’ø“T'nç?åz�uÐ®ÓŒ)5:Ã
;³A¯X~ºÍ¨©²p]nfµì!ü™åM
¨}‡_,£�a&amp;ÿ3#HÀˆ·$‰ž�Þf§]ŒD�BÆvEôìè7�&gt;Ñ\Â0Ú)(:üÞAÆ7ÿ†‘›3ò�ö†b£×0LÐÒBmNÓ©Gx²ŸpÉ^~îû&gt;4,Â^g5ŽkMZ£—}Zf³h�»¿5¶;¦{¼ý…´B/£leñËŒSÈ}�±½ò^Í#á‡±ß¥}ez!Ÿ§Ï_3B[à-øÃSÂŒœ‡¬#üâBcŒ“ÉXUŒ"¢Ò¬E³IX�žaæïÈ§`®¼wVu¶Óò\àù-JÏgÈBDíød¸›�Œ&nbsp;Ìdü4Âœü¹‡{GùÆøâDd5òòð›sÀ]dNBð¨ˆ@¥Tž…½b&gt;^¿Øˆ�×Œ~›Aò¾‚¸=ºÁ^%Œ~3ZIPKÐTüîå“õMXÇ'ß0&nbsp;FœåzJ°ÐÇ¾b“ðdÛ¥ásõ«DaýÐ¸({eß"ƒÃ€j4TêÀ¿�®å­à†phë{dî¾*.&lt;€Í_EœWÔdW1oOþÀí7@i¦®h¢xÉ�¥oZn)®^ÂŒÞ}Ì�è&amp;.§”Wˆíj„tí�”ýÉØÍ{Ü˜MA—î‚^îëŽJ�WÉx‰¶É
5ZPéèZ
LÒ»ýRÖ§„°$]›ÙMd�®ª;ajÆ�Þ3pâÀ,ÍîšÌHVK×„r)p×–ÔŽ:	³3N¥gý›ô²
jêJã81Þ°;™™ëfrÛ{«TÀŠÚŠ¬® EÛ*(E!lPAÅ"J…AÖ"	�(²ˆò‘ßÄ‚@©+¢"`_ÚuÇ©ÏMûrBëv¿ï—{fÎÌùŸsžç&gt;ÿó{˜Ó•¦úIÇê÷ÿs¯å›ƒš{SXíqmA�Dˆ„øµâÕcðv§4#Sƒé%
ÂÜ=÷€áœF]Âž¼Ièãe†í4Z±ÃåbäüÔ	¿í4êO±Â¯4Ã»åœç&nbsp;õÀõ¡˜s²H)Ô¬4$×¬£Ñ&lt;'gä–Ã"§œÁîÎµ¦KŒ‡$oq‡Ì:—Ýn–p÷®3y”*[�¥fDí&gt;ŠÀÝ[i—�»?¾º4ö¨ÿ‚,ÀÀæjr”‰pƒf&lt;úÀ¡�W?ø\È©œ|]¡Iòpf&nbsp;h� GäøÐß¾h,¬b”}„*r�Æ—vý°ÞÐ²9}Tï±†{éŸÊVdã¶²
×°Û¬æÝÃ�ÜÚùœØ
 »Ó‚ïOôß*7e|e`ô7‰c)±Ç¢é°©Q‘lØnå–�’„�Þ7gÜp×ŠöÂÂ°jfƒP&gt;‰_ñxI‰î^Ó5èjORô<s=¡%å²l*üw–¡Õh2±þp««¶µ‚Õ’hèó—ü‚m'£¬Ís\Ã u7Ý{³°¥�mk.½="" |Éjx‹rjs2”l@²ô‹@Ÿ;oanÏðø="" ó® b6o�“ª”•ø.kfp6x#s ™â�ÌŸ‚vÒ˜c8ªg.·6^¥ïwú¬eqÕ~ÑÀÝ¡qsdô!e«llt´ÕÂewrˆb•ä¤�Ïþ:ðo‰¦Ám="">—ì:“Œ»ÑË***!&gt;zi|UMiÙ™l¶J^ÉÑŠ´�³«F~]�"¨¶Å

¬¹¥¨÷‰„Ûâ:³D€lïŽ�eä	û4áY¶¢°ÞÒMEbÅ˜’ƒçjJÊ+g£¡ãì) ßçe%þ«VþS:	›ÈÖÀJâ‰»Özðƒb‰"wUJŠ\�‚=Bˆ&amp;±“H­A°FÀ"Å—#–sÿ§hdöO@ô„èîÈü	�"]ÑQÓRØØr™¨ðd‘yºÅ¹ÅyzÆ\ÔP×AW,cQÅÔÀÃ¥y³,J�Ã$)“åÊXlšWåÁ�&gt;´{èNY,›…k4s”ð$sÃsÂ‚_gÄº­5!¢ÛÖŒ´X÷Ì+`Ú‹Z›ºqF6áŒœ�‚f¬qhôv•Å3ZRÔš1F¬}­#×ôsóúq©BÛ|¨âÒ($Yà‚þ„–¾X;xs6‚óÒˆeµ&gt;ÔË&amp;‡?#ž¯Ç*·OÇ~~Üúì%6ô‰ü9þ�æµ»&lt;ARjŠudHå•7h ž€õàäú²óðß·5‚ÅÇ¸›yŸð u2]ðÉ¤ŒÒçrÑó~ãs=Ýi5–À—ùnkîU°Ú­Þ ¦Ïn5ÄÍÒ¼ö…çœÞkŠ;�;ršuMÌj\YÖ²h‹®ó¢!;wäƒœ/bôRý…Ó¬ŽáÜÔ¬”L5ói’tŸ?ýžlüð.ß~Ôß&amp;œ5•»X&amp;ñû÷5Iµ^KÔ;‚1¢G¸P§gúõ-m×i}~¶6ŸîD½º´ôœCôÖma›ÙLRT™õÔš«Ð©?VZÿk�/Žƒä¿á•TÝ®ºHƒ&nbsp;¿÷Áw;›W�e}ËbL�’ÚÊ3]­5
õ	¦ôQ»³PJ;øn^ûYSÈd4ûm|yÂ.Iøþ¨Í;d&amp;c®Œ4ÍÀoz‚?Í
Q+¼¼o!£À?gy_rNÕDWW|}ÌÈfö™©*m&lt;-M©îa¡ì�=Ø
„Éš‘0k)ØM�rJÔÊä’)WÔA*²©ÌnEXØVÚýÀõÇ,”¸¢Zò|´ëo��
§¬N›|Ôƒ%³ê³[:$ÂG¦¼g¥\¨(Ö€uÀw&amp;™'ÁŸK&amp;–“KQ9†ÅU¸&amp;Sõ¡ÆÔFE‹”‹…°æÈ8\{‚ÙÂd	Õ™¬KñÒ1rRpfì*êÐwcÆÐû†¿G
ñ	ïcÕ•ä”©ðO
J“b"Ð´«:¿ìö‚ñ:Òe+¶)¶k¬ó‡;R;T—6C¶XøæÂ#Ip&lt;‰÷
çÇ/¶î´B^èñ·¬<s¥±¼ø fclqì‰Ãˆ'þ;‰<!·‡©„¹ñ]eœâ "«**”å_vlx):#{¹å�$^="">ÂÏ·Jnœñ'ò4ºôIFVzæa&amp;)tÿñÉq‰1ªÄôÒuâÒ<s‘¹¾§Ëü Ö€~ #— :õ¾c{Ç`�i«t×kÎ.€±-<2Ï†y&îm¾i="">÷öªÕ‘¥å'ËNV@4T‹s.3ÄÇP¤%ã’äqèªÇ«ÆQî/JÞÄÂr˜ú—rà¥@xÂJúíÛ¯qoöˆê°9ÚÀ^ªGWZ^K×ÖÉÚpÏ5X«n¤¯w7ÀÜÖ�ü&lt;;%&amp;‚Þ»×TÄŠ^œõŽ2ì¢79å±Â{.Òy×þm³AcÃï´xSÅ(�¸D!�¢h+üTCçkø9ý²Ô
?~ƒH;þûd¬l²IÄDô	$ô`ÌòåŸ�:Ê�óíX…&lt;­Büi‹'¥ù8ÖAþÙ•¯ÅçÍ`sê¾m÷!&lt;ç�ø¿sÂWgšî™¡Ú&lt;ÙÄ«í˜ìâætðaÚò…<qÃÃà¯à<a-Ž<ƒ»#o„gäÁf‡q¸sšƒæaqaÖqf‹wsÐ°…Åp�90 iésc‹¶ÓŽ|„hÇw°m>ÿÍ©V]O(öhÂéåÒ¾Ñ±ó=OÚêéöw¶¸¿á\µøàBs ú°�Ñ;ñÿÒÆwù�®}Úx¿ïýÃw¹„_
ûîòãœèŠù‹—­([˜Ÿ_R’_°&nbsp;x…üw?1¸X)Pl&gt;PLøåÇßo(u¤6ûR¡´}ªôé¶£¯X{ÙŽê°žgÓz¹Xh“ZÑÀÊ«¯�%V	È‹�…w
oûîG´w~g0%¾„«D.á‚.Üs|ïw¯‹BçY&gt;þñ£ø¥h]Ily˜´ð—ÐÈy›ÒäV–ok&gt;Êñ}ý6á¿·±Mêž0QjfÏ¬žrß·ìý½šmê�ù;V®àX¿vû¼ƒÒ;¶ÖÖ.‘Ÿ–uV~ìœiK¯Ü°ùä¤ÜÀzWÏÈcl]µ]5ÕmÝmmRAQ'Ù¦8/	Ü˜È¸÷rÎé³û,X%Ï×0í§ÙôßqÓ¾ëOÛ3íOÉ$¶^ûLü“?mÇÄÙå$¸6ÍüÏÃyŽë1÷ã~ÞïÉ"À&nbsp;0Eo©á
endstream
endobj
2617 0 obj
&lt;&gt;stream
H‰œ–yTSwÇoÉž�•°Ãc
[€°�5la‘QIBHØADED„ª•2ÖmtFOE�.®c­Ö}êÒõ0êè8´×Ž�8G�Ng¦Óïï÷9÷wïïÝß½÷�ó&nbsp;'¥ªµÕ0�Ö&nbsp;ÏJŒÅb¤	
 2y­.-;!à’ÆK°ZÜ	ü‹ž^�i½"LÊÀ0ðÿ‰-×é
@8(”µrœ;q®ª7èLöœy¥•&amp;†Qëñq¶4±jž½ç|æ9ÚÄ
�V�³)g�B£0ñiœW×•8#©8wÕ©•õ8_ÅÙ¥Ê¨QãüÜ«QÊj@é&amp;»A)/ÇÙgº&gt;'K‚óÈtÕ;\ú”
Ó¥$ÕºF½ZUnÀÜå˜(4TŒ%)ë«”ƒ0C&amp;¯”é˜¤Z£“i˜¿óœ8¦Úbx‘ƒE¡ÁÁBÑ;…ú¯›¿P¦ÞÎÓ“Ì¹žAüom?çW=
€x¯Íú·¶Ò-Œ¯Àòæ[›Ëû0ñ¾¾øÎ}ø¦y)7ta¾¾õõõ&gt;j¥ÜÇTÐ7úŸ¿@ï¼ÏÇtÜ›ò`qÊ2™±Ê€™ê&amp;¯®ª6ê±Z�L®Ä„?â_øóyxg)Ë”z¥�ÈÃ§L­UáíÖ*ÔuµSkÿSeØO4?×¸¸c¯¯Ø°.òò·åÒR´
ß�Þô-•’2ð5ßáÞüÜÏ	ú÷Sá&gt;Ó£V­š‹“då`r£¾n~ÏôY&nbsp;&amp;à+`œ�;ÂA4ˆÉ ä€°ÈA9Ð=¨-&nbsp;t�°lÃ`;»Á~pŒƒ�Á	ðGp|	®�[`Lƒ‡`&lt;¯ "AˆYA�+äùCb(Š‡R¡,¨*�T�2B-Ð
¨ê‡†¡Ðnè÷ÐQètº}MA&nbsp;ï&nbsp;—0Óal»Á¾°Ž�Sàx	¬‚kà&amp;¸^Á£ð&gt;ø0|&gt;_ƒ'á‡ð,ÂG!"F$H:Rˆ”!z¤éF‘Qd?r9‹\A&amp;‘GÈ”ˆrQ¢áhš‹ÊÑ´íE‡Ñ]èaô4z�BgÐ×Á–àE#H	‹*B=¡‹0HØIøˆp†p�0MxJ$ùD1„˜D, V›‰½Ä­ÄÄãÄKÄ»ÄY‰dEò"E�ÒI2’�ÔEÚBÚGúŒt™4MzN¦‘Èþär!YKî ’÷�?%_&amp;ß#¿¢°(®”0J:EAi¤ôQÆ(Ç()Ó”WT6U@�&nbsp;æP+¨íÔ!ê~êêmê�æD¥eÒÔ´å´!ÚïhŸÓ¦h/èº']B/¢éëèÒ�Ó¿¢?a0nŒhF!ÃÀXÇØÍ8ÅøšñÜŒkæc&amp;5S˜µ™�˜6»lö˜Iaº2c˜K™MÌAæ!æEæ#…åÆ’°d¬VÖë(ëk–Íe‹Øél
»—½‡}Ž}ŸCâ¸qâ9
N'çÎ)Î].ÂuæJ¸rî
î÷wšGä	xR^¯‡÷[ÞoÆœchžgÞ`&gt;bþ‰ù$á»ñ¥ü*~ÿ ÿ:ÿ¥…�EŒ…Òb�Å~‹ËÏ,m,£-•–Ý–,¯Y¾´Â¬â­*­6X�[Ý±F­=­3­ë­·YŸ±~dÃ³	…</qããà¯à<a-ž<ƒ»#o„gäáf‡q¸sšƒæaqaöqf‹wsð°…åp�90 iésc‹¶óž|„hçw°m></s‘¹¾§ëü ö€~></s¥±¼ø></s=¡%å²l*üw–¡õh2±þp««¶µ‚õ’hèó—ü‚m'£¬ís\ã></k‚ôfn7pš></g_rrãze8t”¥¿ò“žjhd4ø¶q‡çxõ`»õ1†></z"xaá‚qøßù(ýœç€†3´ôü8§ÿ•ï�«�ôø�…~´÷is¨></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39">https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39</a></em></p>]]>
            </description>
            <link>https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046096</guid>
            <pubDate>Tue, 10 Nov 2020 14:12:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitdefender: UPX Unpacking Featuring Ten Memory Corruptions]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046084">thread link</a>) | @landave
<br/>
November 10, 2020 | https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/ | <a href="https://web.archive.org/web/*/https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>This post breaks the two-year silence of this blog, showcasing a selection of memory corruption vulnerabilities in Bitdefender’s anti-virus engine.</p>
<h2 id="introduction">Introduction</h2>
<p>The goal of binary packing is to compress or obfuscate a binary, usually to save space/bandwidth or to evade malware analysis.
A packed binary typically contains a compressed/obfuscated data payload. When the binary is executed, a loader decompresses this payload and then jumps to the actual entry point of the (inner) binary.
Most anti-virus engines support binary unpacking at least for packers (such as <a href="https://upx.github.io/">UPX</a>) that are very popular and that are also used by non-malware software.</p>
<p>This blog post is about UPX unpacking of PE binaries in the Bitdefender core engine. The main steps in UPX unpacking of PE binary files are the following:</p>
<ol>
<li>Detect the loader from the entry point</li>
<li>Find the compressed data payload and extract it</li>
<li>Unfilter the extracted code</li>
<li>Rebuild various structures (such as the import table, the relocation table, the export table, and the resources)</li>
</ol>
<p>The following vulnerabilities are presented in the control-flow order of the UPX unpacker.</p>
<p><strong>Disclaimer</strong>: In the following, decompiled code from Bitdefender’s core engine is presented.
The naming of variables, fields, and macros is heavily inspired by the <a href="https://github.com/upx/">original UPX</a>. For some snippets, a reference to the original function is added for comparison. It is likely that some types are incorrect.</p>

<p>After the UPX loader has been detected, the Bitdefender engine tries to detect whether the loader applies a specific kind of deobfuscation to the compressed data payload before extracting it. The (de)obfuscation is very simple, making only use of the three operations ADD, XOR, and ROTATE_LEFT.
If this deobfuscation is detected, then the engine iterates through the corresponding instructions of the loader and parses them with their operands in order to be able to deobfuscate the data as well. This looks as follows:</p>
<div><pre><code data-lang="cpp"><span>int32_t</span> operation[<span>16</span>]; <span>// on the stack
</span><span></span><span>int32_t</span> operand[<span>16</span>]; <span>// on the stack
</span><span></span><span>int</span> i <span>=</span> <span>0</span>;
<span>int</span> pos <span>=</span> <span>0</span>;
<span>do</span> {
  <span>bool</span> op_XOR_or_ADD <span>=</span> <span>false</span>;
  <span>if</span> (loaderdata[pos] <span>==</span> <span>0x81u</span>
    <span>&amp;&amp;</span> (loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>0x34</span>  <span>||</span> loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>0x4</span>)) {
      operation[i] <span>=</span> (loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>0x34</span>) <span>?</span> <span>OP_XOR</span> : OP_ADD;
      operand[i] <span>=</span> <span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>loaderdata[pos <span>+</span> <span>3</span>];
<span>      <span>++</span>i;
</span>      pos <span>+=</span> <span>7</span>;
      op_XOR_or_ADD <span>=</span> <span>true</span>;
    }
  }
  <span>if</span> (loaderdata[pos] <span>==</span> <span>0xC1u</span> <span>&amp;&amp;</span> loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>4</span>) {
    operation[i] <span>=</span> OP_ROTATE_LEFT;
    operand[i] <span>=</span> loaderdata[pos <span>+</span> <span>3</span>];
<span>    <span>++</span>i;
</span>    pos <span>+=</span> <span>4</span>;
<span>    <span>if</span> (i <span>==</span> <span>16</span>) <span>break</span>;
</span>    <span>continue</span>;
  }
  <span>if</span> (op_XOR_or_ADD) {
<span>    <span>if</span> (i <span>==</span> <span>16</span>) <span>break</span>;
</span>    <span>continue</span>;
  }
  <span>if</span> (loaderdata[pos] <span>==</span> <span>0xE2u</span>) { <span>/* omitted: apply collected operations */</span> }
  pos <span>+=</span> <span>2</span>;
} <span>while</span> (pos <span>+</span> SOME_SLACK <span>&lt;</span> loaderdata_end);
</code></pre></div><p>Observe how the bound-check on the index variable <code>i</code> is performed. As the buffer <code>loaderdata</code> is fully attacker-controlled, it is easy to verify that we can increase the index variable <code>i</code> by two before running into one of the checks <code>i == 16</code>. In particular, we can increase <code>i</code> from 15 to 17, after which we can overwrite the stack with completely arbitrary data.</p>
<div><pre><code data-lang="python">(<span>10</span>ec<span>.</span><span>12</span>dc): Break instruction exception <span>-</span> code <span>80000003</span> (first chance)
<span>00000000</span><span>`</span><span>0601</span>fe42 cc              <span>int</span>     <span>3</span>
</code></pre></div><p>The debug break is due to the stack canary which we have overwritten. If we continue, we see that the return fails because the stack is corrupted.</p>
<div><pre><code data-lang="python"><span>0</span>:<span>000</span><span>&gt;</span> g
(<span>10</span>ec<span>.</span><span>12</span>dc): Access violation <span>-</span> code c0000005 (first chance)
First chance exceptions are reported before <span>any</span> exception handling<span>.</span>
This exception may be expected <span>and</span> handled<span>.</span>
<span>00000000</span><span>`</span><span>06006603</span> c3              ret

<span>0</span>:<span>000</span><span>&gt;</span> dd rsp
<span>00000000</span><span>`</span><span>0014</span>ed98  deadbeef deadbeef deadbeef deadbeef
<span>00000000</span><span>`</span><span>0014</span>eda8  deadbeef deadbeef deadbeef deadbeef
</code></pre></div>
<p>The collected operations (for the deobfuscation shown in //1//) are applied to the payload buffer at an attacker-controlled offset <code>write_offset</code>.
Obviously, this offsets needs to be checked before writing to it. There are two checks on <code>write_offset</code>. The first is</p>
<div><pre><code data-lang="cpp"><span>if</span> (write_offset <span>&lt;=</span> extractobj<span>-&gt;</span>dword10 <span>+</span> <span>3</span>) 
</code></pre></div><p>and the second one is</p>
<div><pre><code data-lang="cpp"><span>if</span> (loaderdata[pos] <span>==</span> <span>0xE2u</span>) {
  <span>if</span> (write_offset <span>&gt;=</span> extractobj<span>-&gt;</span>dword10 <span>-</span> <span>3</span>)
</code></pre></div><p>Both checks test against the field <code>dword10</code>. The field <code>dword10</code>, sitting on the calling functions’s stack frame, is never initialized. This makes the bound check useless and introduces a fully attacker-controlled heap buffer overflow.</p>

<p>After the extraction, the engine attempts to deobfuscate the extracted data with a static XOR key.</p>
<div><pre><code data-lang="cpp"><span>for</span>(<span>int</span> i<span>=</span><span>0</span>; i<span>&lt;</span><span>0x300</span>; i<span>++</span>) {
  <span>if</span> (<span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>entrypoint_data[i] <span>==</span> <span>0x4243484B</span>) {
    <span>int32_t</span> j <span>=</span> i <span>+</span> <span>0x4A</span>;
    <span>uint8_t</span> xor_key <span>=</span> entrypoint_data[j]; <span>// attacker-controlled
</span><span></span>    <span>int32_t</span> xor_len <span>=</span> <span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>entrypoint_data[j <span>-</span> <span>7</span>]; <span>// attacker-controlled
</span><span></span>    <span>if</span> (xor_len <span>&gt;</span> packer<span>-&gt;</span>set_to_size_of_rawdata) <span>return</span> j; <span>// &lt;-- wrong bound check
</span><span></span>    <span>for</span>(<span>int32_t</span> k<span>=</span><span>0</span>; k<span>&lt;</span>xor_len; k<span>++</span>) {
<span>      packer<span>-&gt;</span>extracted_data[k] <span>^=</span> xor_key; <span>// &lt;-- oob write
</span></span><span></span>    }
    <span>*</span>info_string <span>=</span> <span>"encrypted"</span>;
  }
}
</code></pre></div><p>The bound check is completely wrong. It should check against the size of the extracted data buffer. Instead, it checks against a value that is previously set to the raw data size of the section we extracted the data from. Those two sizes have nothing to do with each other. In particular, one can be much smaller than the other, or vice-versa.</p>
<p>As the function does not return after the first deobfuscation run, the memory corruption can be triggered up to 0x300 times in a row.
This allows us to bypass the limitation that in a single deobfuscation run we always XOR with the same byte. We would simply XOR as follows:</p>
<div><pre><code data-lang="cpp">First run (i<span>=</span><span>0</span>)<span>:</span>  XOR with B0 B0 B0 B0 B0 B0 B0
Second run (i<span>=</span><span>1</span>)<span>:</span> XOR with B1 B1 B1 B1 B1
Third run (i<span>=</span><span>2</span>)<span>:</span>  XOR with B2 B2
</code></pre></div><p>Overall, we then have XORed with C0 C0 C1 C1 C1 C2 C2 for completely arbitrary C0, C1, and C2. We can essentially XOR with such a pattern of almost arbitrary length, and switch the byte at most 0x300 times.</p>
<p>Needless to say, this vulnerability is a useful exploitation primitive as it enables very powerful memory corruptions: XORing allows us to modify selectively only certain parts of data, leaving other parts (for example heap metadata or critical objects) untouched.</p>
<h2 id="4-heap-buffer-overflow-in-the-filters">//4//: Heap Buffer Overflow in the Filters</h2>
<p>A filter is a simple transformation on binary code (say, x86-64 code) that is applied before compression, with the goal to make the code more compressible. After we have decompressed the data, we need to revert this filtering.
Bitdefender supports about 15 different filters. Here is one of them (filter 0x11):</p>
<div><pre><code data-lang="cpp"><span>int32_t</span> bytes_to_filter <span>=</span> <span>/* omitted. is guaranteed not to be oob. */</span>; 
<span>int</span> i <span>=</span> <span>0</span>;
<span>while</span> (<span>1</span>) {
  <span>do</span> {
    <span>if</span> (<span>--</span>bytes_to_filter <span>&lt;</span> <span>0</span>) <span>break</span>;
  } <span>while</span> (extracted_data[i<span>++</span>] <span>!=</span> <span>0xE8u</span>);
  <span>if</span> (bytes_to_filter <span>&lt;</span> <span>0</span>) <span>break</span>;
  <span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>extracted_data[i] <span>-=</span> i; <span>// &lt;-- oob write
</span><span></span>  i <span>+=</span> <span>4</span>;
}
</code></pre></div><p>The problem is that <code>bytes_to_filter</code> is only updated when <code>i</code> is incremented by one, but not when it is later incremented by four.</p>
<p>Of the 15 filters, about 8 seem to be affected by such a heap buffer overflow. I treated them all together as one bug (after all, it is not unlikely that they share code).</p>
<h2 id="5-heap-buffer-overflow-when-rebuilding-imports">//5//: Heap Buffer Overflow when Rebuilding Imports</h2>
<p>The following memory corruption occurs in a loop of the function PeFile::rebuildImports (cf. <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2832">PeFile::rebuildImports</a>). It looks like this:</p>
<div><pre><code data-lang="cpp"><span>this</span><span>-&gt;</span>im<span>-&gt;</span>iat <span>=</span> <span>this</span><span>-&gt;</span>iatoffs;
<span>this</span><span>-&gt;</span>newiat <span>=</span> <span>&amp;</span>extract_obj<span>-&gt;</span>extracted_data[<span>this</span><span>-&gt;</span>iatoffs <span>-</span> (<span>uint64_t</span>)(<span>uint32_t</span>)pefile<span>-&gt;</span>rvamin];
<span>while</span> (<span>*</span>p) {
  <span>if</span> (<span>*</span>p <span>==</span> <span>1</span>) {
    ilen <span>=</span> strlen(<span>++</span>p) <span>+</span> <span>1</span>;
    <span>if</span> (<span>this</span><span>-&gt;</span>inamespos) {
      <span>if</span> (ptr_diff(<span>this</span><span>-&gt;</span>importednames,<span>this</span><span>-&gt;</span>importednames_start) <span>&amp;</span> <span>1</span>) <span>--</span><span>this</span><span>-&gt;</span>importednames;
<span>      memcpy(<span>this</span><span>-&gt;</span>importednames <span>+</span> <span>2</span>, p, ilen); <span>// &lt;-- memory corruption
</span></span><span></span>      <span>*</span><span>this</span><span>-&gt;</span>newiat <span>=</span> ptr_diff(<span>this</span><span>-&gt;</span>importednames,extract_obj<span>-&gt;</span>extracted_data <span>-</span> pefile<span>-&gt;</span>rvamin);
      <span>this</span><span>-&gt;</span>importednames <span>+=</span> ilen <span>+</span> <span>2</span>;
      p <span>+=</span> ilen;
    }
    <span>else</span> {
      <span>//omitted, see below //5//
</span><span></span>    }
  }
  <span>else</span> <span>if</span> (<span>*</span>p <span>==</span> <span>0xFFu</span>) {
    p <span>+=</span> <span>3</span>;
    <span>*</span><span>this</span><span>-&gt;</span>newiat <span>=</span> ord_mask <span>+</span> <span>*</span>(<span>uint16_t</span> <span>*</span>)(p <span>+</span> <span>1</span>);
  }
  <span>else</span> {
    <span>// omitted
</span><span></span>  }
  <span>++</span><span>this</span><span>-&gt;</span>newiat;
}
</code></pre></div><p>The length <code>ilen</code> that is passed to memcpy is completely attacker-controlled and thus needs to be checked. Observe that the <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2847">original UPX</a> does a checked omemcpy at this place.</p>
<h2 id="6-another-heap-buffer-overflow-when-rebuilding-imports">//6//: Another Heap Buffer Overflow when Rebuilding Imports</h2>
<p>In the same loop of the function PeFile::rebuildImports (cf. <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2832">PeFile::rebuildImports</a>), there is another memory corruption:</p>
<div><pre><code data-lang="cpp"><span>this</span><span>-&gt;</span>im<span>-&gt;</span>iat <span>=</span> <span>this</span><span>-&gt;</span>iatoffs;
<span>this</span><span>-&gt;</span>newiat <span>=</span> <span>&amp;</span>extract_obj<span>-&gt;</span>extracted_data[<span>this</span><span>-&gt;</span>iatoffs <span>-</span> (<span>uint64_t</span>)(<span>uint32_t</span>)pefile<span>-&gt;</span>rvamin];
<span>while</span> (<span>*</span>p) {
  <span>if</span> (<span>*</span>p <span>==</span> <span>1</span>) {
    ilen <span>=</span> strlen(<span>++</span>p) <span>+</span> <span>1</span>;
    <span>if</span> (<span>this</span><span>-&gt;</span>inamespos) {
      <span>//omitted, see above //5//
</span><span></span>    }
    <span>else</span> {
      extracted_data <span>=</span> extract_obj<span>-&gt;</span>extracted_data;
      dst_ptr <span>=</span> (extracted_data <span>-</span> pefile<span>-&gt;</span>rvamin) <span>+</span> (<span>*</span><span>this</span><span>-&gt;</span>newiat <span>+</span> <span>2</span>);
      <span>if</span> (dst_ptr <span>&lt;</span> extracted_data) <span>return</span> <span>0</span>;
      extracted_data_end <span>=</span> <span>&amp;</span>extracted_data[extract_obj<span>-&gt;</span>extractbuffer_bytes_written];
      <span>if</span> (dst_ptr <span>&gt;</span> extracted_data_end <span>||</span> <span>&amp;</span>dst_ptr[ilen <span>+</span> <span>1</span>] <span>&gt;</span> extracted_data_end) <span>return</span> <span>0</span>;
<span>      strcpy(dst_ptr,p); <span>// &lt;-- memory corruption
</span></span><span></span>      p <span>+=</span> ilen;
    }
  }
  <span>else</span> <span>if</span> (<span>*</span>p <span>==</span> <span>0xFFu</span>) {
    p <span>+=</span> <span>3</span>;
    <span>*</span><span>this</span><span>-&gt;</span>newiat <span>=</span> ord_mask <span>+</span> <span>*</span>(<span>uint16_t</span> <span>*</span>)(p <span>+</span> <span>1</span>);
  }
  <span>else</span> {
    <span>// omitted
</span><span></span>  }
  <span>++</span><span>this</span><span>-&gt;</span>newiat;
}
</code></pre></div><p>The problem is that the strings <code>dst_ptr</code> and <code>p</code> can overlap, so we overwrite the string that we called strlen() on earlier.
This can turn a terminating null-byte into a non-null byte and when strcpy() is called, the string is longer than expected, overflowing the buffer.</p>
<p>A possible fix is to replace the <code>strcpy(dst_ptr,p)</code> with <code>memmove(dst_ptr,p,ilen)</code>.</p>
<p>It looks like <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2832">original UPX</a> is affected as well. The two commits <a href="https://github.com/upx/upx/commit/14992260c60b8d6677a677a9cdfae98b11353df7">14992260</a> and <a href="https://github.com/upx/upx/commit/1faaba8f4ce56eb5df8ce24bb4f04d665b87b4fa">1faaba8f</a> are an attempt to fix the problem in the devel branch of UPX.</p>
<h2 id="7-heap-buffer-overflow-when-unoptimizing-the-relocation-table">//7//: Heap Buffer Overflow when Unoptimizing the Relocation Table</h2>
<p>Another memory corruption is in the function Packer::unoptimizeReloc (cf. <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/packer.cpp#L990">Packer::unoptimizeReloc</a>):</p>
<div><pre><code data-lang="cpp"><span>for</span> (<span>uint8_t</span> <span>*</span> p <span>=</span> <span>*</span>in; <span>*</span>p; p<span>++</span>, relocn<span>++</span>) {
  <span>if</span> (<span>*</span>p <span>&gt;=</span> <span>0xF0u</span>) {
    <span>if</span> (<span>*</span>p <span>==</span> <span>0xF0u</span> <span>&amp;&amp;</span> <span>!*</span>(<span>uint16_t</span> <span>*</span>)(…</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/">https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/</a></em></p>]]>
            </description>
            <link>https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046084</guid>
            <pubDate>Tue, 10 Nov 2020 14:11:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating a random identifier grew my bundle size by 300kb]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25046036">thread link</a>) | @ThePadawan
<br/>
November 10, 2020 | https://blog.prat.ch/2020/11/10/randomstring-bundle-size | <a href="https://web.archive.org/web/*/https://blog.prat.ch/2020/11/10/randomstring-bundle-size">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div href="/2020/11/10/randomstring-bundle-size">
    <h2>How generating a random identifier grew my bundle size by 300kb</h2>
  </div><div>
    <p>Recently, I added a notification box to
<a href="https://github.com/ThePadawan/beevenue">Beevenue</a>, a small booru I am building
as a side project:</p>

<p><img src="https://blog.prat.ch/assets/img/2020-11-10-notification-box.png" alt="Notification box with two separate notifications"></p>

<p>Being the good developer that I am, I got annoyed the warning that every React
developer has probably seen at least once:</p>

<div><div><pre><code>Each child in an array should have a unique "key" prop.
</code></pre></div></div>

<p>I won’t repeat the reasoning behind this, since
<a href="https://reactjs.org/docs/lists-and-keys.html#keys">React’s documentation</a>
explains it very concisely.</p>

<h2 id="what-i-wanted">What I wanted</h2>

<p>Since notifications were not unique (they could have the same contents and timestamp),
I decided to add a randomly chosen identifier of the form “notification-abc123”.</p>

<p>Simple, right?</p>

<p>High on life, and eager to install NPM packages instead of building it myself,
the <a href="https://www.npmjs.com/package/randomstring">randomstring</a> package looked
like just what I needed.</p>

<p>It would allow me to generate an identifier of a great enough length to avoid
duplicates with a very high probability:</p>

<div><div><pre><code><span>randomstring</span><span>.</span><span>generate</span><span>({</span>
  <span>length</span><span>:</span> <span>12</span><span>,</span>
  <span>charset</span><span>:</span> <span>"</span><span>alphabetic</span><span>"</span><span>,</span>
<span>});</span>
<span>// &gt;&gt; "AqoTIzKurxJi"</span>
</code></pre></div></div>

<p>So I installed the package via npm, called <code>randomstring.generate</code>, tested the
functionality successfully, and moved on with my life.</p>

<h2 id="but-wait">…but wait</h2>

<p>Now, the notification box is a top-level component in Beevenue, meaning it is
visible on practically all pages. For that reason, it is reasonable to not lazy
load it, but eagerly package it in the bundle that is requested on initial load
of the application.</p>

<p>A while later (having implemented some other features and added more and more
npm packages), I wondered why my bundle size had at some point ballooned
significantly.</p>

<p>Since the project uses <a href="https://create-react-app.dev/">Create React App</a>, I
simply fired up the recommended
<a href="https://create-react-app.dev/docs/analyzing-the-bundle-size/">Source Map Explorer</a>:</p>

<p><img src="https://blog.prat.ch/assets/img/2020-11-10-sme-before.png" alt="Source Map Explorer output before (more than 700KB)"></p>

<p>Many of these dependencies make sense: React itself has the biggest impact at
&gt;100KB, fontawesome icons weigh in at &gt;30KB (both in blue).</p>

<p>But what’s <a href="https://www.npmjs.com/package/elliptic">elliptic</a> (in red)? A library for
<a href="https://en.wikipedia.org/wiki/Elliptic-curve_cryptography">elliptic-curve cryptography</a>?
I certainly have no need for that in my simple SPA to access a REST API.</p>

<p>It must have snuck in as a transitive runtime dependency of one of the packages
I <em>did</em> install.</p>

<p>The one thing that came to mind was that one library that I only used once, to
randomly generate a unique identifier. Could that be it?</p>

<p><img src="https://blog.prat.ch/assets/img/2020-11-10-sme-after.png" alt="Source Map Explorer output after (more than 400KB)"></p>

<p>Gotcha!</p>

<p>The bundle shrunk from 747KB to 448KB, by nearly a whopping 300KB.</p>

<h2 id="the-fix">The fix</h2>

<p>The fix is obvious:</p>

<p>Don’t try and be clever.</p>

<p>Implementing a simple version of the feature I <em>actually</em> needed took only
<a href="https://github.com/ThePadawan/beevenue-ui/commit/ef94e025adc5e3223ab63dc69b7885d2016986c3">four lines of code</a>:</p>

<div><div><pre><code><span>const</span> <span>getRandomInt</span> <span>=</span> <span>(</span><span>max</span><span>:</span> <span>number</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>Math</span><span>.</span><span>floor</span><span>(</span><span>Math</span><span>.</span><span>random</span><span>()</span> <span>*</span> <span>Math</span><span>.</span><span>floor</span><span>(</span><span>max</span><span>));</span>
<span>};</span>

<span>const</span> <span>id</span> <span>=</span> <span>`</span><span>notification-</span><span>${</span><span>getRandomInt</span><span>(</span><span>1024</span> <span>*</span> <span>1024</span><span>)}</span><span>`</span><span>;</span>
</code></pre></div></div>

<p>This obviously is only pseudorandom, as opposed to <code>randomstring</code>’s possibly
cryptographically random - but that’s not what I needed in the first place.</p>

<p>And that’s certainly not what I would pay 300KB of bundle size for.</p>

  </div></div>]]>
            </description>
            <link>https://blog.prat.ch/2020/11/10/randomstring-bundle-size</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046036</guid>
            <pubDate>Tue, 10 Nov 2020 14:07:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hands on with: MeiliSearch – A next generation search engine for modern web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25045927">thread link</a>) | @piterrro
<br/>
November 10, 2020 | https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web | <a href="https://web.archive.org/web/*/https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <div>
                            <p><strong>In this post, I’m gonna review the Meilisearch repository which describes itself as a “Lightning Fast, Ultra Relevant and Typo-Tolerant Search Engine”. There were couple of things that caught my eye with this project...</strong></p>

<h3>Quick intro: What is the “Hands on with X” series?</h3>
<p>This is a series of blog posts in which we focus on open source technologies encountered in the course of our research for new development projects or while browsing latest news from a development environment which is close to our minds in our day to day work. One day I realized that my Github account is full of starred repositories containing interesting tools, databases, libraries and other cutting-edge technologies that seem to be very interesting for me. I was alway staring at them on Github for later review but never got a chance to really use them. That’s when the idea for this blog post series was born. I was having a feeling that a lot of users are in the same situation, they starred a repository because they might have used it in the future and was curious how it works, but never got a chance to do that. So for the next couple of posts I’m gonna focus on reviewing and using interesting and popular repositories I’ve found on Github for the past couple of years.
</p>



<h3 id="h">Table of contents</h3>
<ul>
    <li><a href="#h2"> - Motivations for reviewing Meilisearch</a></li>
    <li><a href="#h3"> - Github repository and Readme</a></li>
    <li><a href="#h4"> - The data set for testing purposes</a></li>
    <li><a href="#h5"> - Kicking it off - Download binary and start the server</a></li>
    <li><a href="#h6"> - Prepare the data to be ingested</a></li>
    <li><a href="#h7"> - Indexing first collection</a></li>
    <li><a href="#h8"> - Indexing speed</a></li>
    <li><a href="#h9"> - Making search queries</a></li>
    <li><a href="#h10"> - Frontend integration</a></li>
    <li><a href="#h11"> - Would I recommend MeiliSearch?</a></li>
    <li><a href="#h12"> - Conclusions</a></li>
</ul>
<hr>

<h3 id="h2">Motivations for reviewing Meilisearch</h3>
<p><strong>Its search engine</strong>. I’m not a heavy user of search engines in my day-to-day projects. I know Elasticsearch and Spinx are among the most popular ones. I also have some experience with TSvector in Postgresql which allowed to create simple “search engine features” within Postgresql database. But that's it, so I’m curious how that new Meilisearch project accommodates itself in this long-inhabited environment.</p>

<p><strong>Its written in Rust</strong> which is interesting so that Rust is very close to bare metal. It’s also a new technology and most of the search engines we have are written in C++ or Java. I feel that a new perspective from a totally new language might be worth a try.</p>

<p>Since it’s Rust, it compiles to a single binary and it's portable, so that means no more long hours of building a project which would make deploying along with any other project a breeze.</p>

<p><strong>It claims to have “search as-you-type experience”</strong> which means that it is able to return results so fast that it returns results for EVERY keystroke. Interesting given the fact that the Readme file doesn’t contain information about reference dataset authors used to support that claim. Of course it is not possible for a dataset of any size and for smaller data sets it's trivial, so I wanted to learn how long Meilisearch is able to support that claim, given that I’ll be using a bigger than usual dataset.
</p>

<h3 id="h3">Github repository and Readme</h3>
<p>The url address of Github repository is <a href="https://github.com/meilisearch/MeiliSearch">https://github.com/meilisearch/MeiliSearch</a>. As of the beggining of the September 2020, the repository has over 9k stars and over 30 contributors. The commits are pushed more or less weekly. The tool seem to have small community around it so its definitely not a dead project. In addition Meili raised 1,5M euros in their first funding round (<a href="https://blog.meilisearch.com/meili-fundraise/">https://blog.meilisearch.com/meili-fundraise/</a>) which shows that they are determined to develop the product and compete with big players, which is what they also claim on their website, they want to be an alternative to search engine APIs like Algolia.</p>
<p>What is more important for us - developers is the documentation and its clarity. The readme page is short and compact, with only relevant information which is a plus, because they also have a full blown documentation hosted as a separate website at <a href="https://docs.meilisearch.com/">https://docs.meilisearch.com/</a>.</p>
<p>The readme contains all of the basic informations need to start using the engine which means it has recipes for building from source as well as downloading a compiled binary or using a docker image. In addition there are examples how to index a first collection and make queries. All that is compact enough so that following it step by step should take no more than 10-15 minutes to complete.</p>
<p>The documentation contains description of the main concepts that were used when building the engine as well as advanced guides starting from installation and configuration up to the most advanced features of the engine. It is well written but after reading it I was left with a feeling that it is still immature project with a long road ahead of it.</p>




<h3 id="h4">The data set for testing purposes</h3>
<p>Of course testing the search engine with a small data set doesn’t make much sense since today’s hardware capabilities allows to easily keep in memory datasets weighing a couple hundreds of megabytes. So I took a different approach, I decided to find a data set that consists mostly of text and would be useful in real world examples. My choice went to Kaggle dataset: Cornell University arXiv index (<a href="https://www.kaggle.com/Cornell-University/arxiv">https://www.kaggle.com/Cornell-University/</a>). As per Wikipedia, arXiv is an open-access repository of electronic preprints (known as e-prints) approved for posting after moderation, but not full peer review. It consists of scientific papers in the fields of mathematics, physics, astronomy, electrical engineering, computer science, quantitative biology, statistics, mathematical finance and economics, which can be accessed online. The dataset hosted on Kaggle is just a friction of the whole arXiv and it contains an index of publications with information like: author, title, category and short excerpt. The dataset format is JSON and weights about 2.7gb all you need to do to download it and unzip.</p>

<h3 id="h5">Kicking it off - Download binary and start the server</h3>
<p>Now that I have a data set we can start testing MeiliSearch. The installation is pretty straightforward, I used a ready to use bash script (of course I reviewed the script in the first place as I know these bash installations are basically an attack vector).</p>
<pre><code>$ curl -L https://install.meilisearch.com | sh
$ ./meilisearch
Server is listening on: http://127.0.0.1:7700</code></pre>
<p>That was very smooth, it went well without any problems, point for Meilisearch.</p>


<h3 id="h6">Prepare the data to be ingested</h3>
<p>In order to search the data we have to create an index first (think of it as a database table) and ingest the data to it in a Meilisearch instance. For index creation I used:</p>
<pre><code>curl -i -X POST 'http://127.0.0.1:7700/indexes' --data '{ "name": "arxiv", "uid": "arxiv" }'</code></pre>
<p>After the command completed I tried to feed the index with raw data, but there are couple of constraints to the format. First thing is that the file must be less than 10 megabytes and second is that the JSON should actually be a JSON array where each element is a separate document identified by unique id field. I tried to use good old split, awk, sed unix tools in the first place, but after some time I gave up and switched to Node.js. </p>
<p>You can check the whole script below. Its not very sophisticated but it does the job.
</p>




<h3 id="h7">Indexing first collection</h3>
<p>The script above does basically two things. It first reads the file contents line by line and builds a payload containing about 1000 documents. It then sends the payload to MeiliSearch, in return we get an “updateId” which is an identifier that we can later use to ask our MeiliSearch instance whether the indexation operation for that batch finished. If the indexation batch is finished, then we can resume the file consumption, assemble another data batch and send it to MeiliSearch. And here comes the first surprise, as the documentation doesn’t clearly lay that out and I had to figure it (how it works). It seems that MeiliSearch has an internal queue that is able to accept any number of data payloads for ingesting and it processes this queue at its own pace. Makes sense to me, but as it turned out later, it’s not so lovely.
</p>

<h3 id="h8">Indexing speed</h3>
<p>Buffering incoming data has a lot of advantages, having that buffer you are able to not overwhelm your processing units with work, while still maintaining the work pace. In addition you can scale your work capacity by adding more workers, that’s when the buffers shine, because you can quickly consume additional data by throwing more resources at it. Unfortunately MeiliSearch indexing queue is processed only by one worker even on a multi-core CPU. That means, you can throw a lot of data for indexing at it but it will basically take the same amount of time, if you would do it one payload at a time. </p>
<p>It actually gets worse as the indexation time increases as your data set size increases. That is not a bad thing as long as the growth is linear and it's not too significant. Unfortunately again with MeiliSearch it's exactly the opposite. The indexation time grows exponentially and even with small data sets it gets to a point where indexing 3gb of data would take unknown time (from my calculations). I was having high hopes downloading a 2.7gb data set and trying to index it with MeiliSearch, unfortunately I was only able to index 115mb (yes, megabytes) which is about 80 000 lines from the file. Just to give you the context, the first 20 000 items were indexed in less than 1 minute, another 20 000 items took about 4 minutes. Reaching 88 000 items took 10 minutes and arXiv data set has almost 1 800 000 items. </p>

<p>That being said, the indexation time is too long and I didn’t want to spend the next few days waiting for it to finish. I did spend some more time trying to find how to speed up the indexing process, I looked through the documentation and Issues on Github, unfortunately I was not the only one that had that problem. This issue: <a href="https://github.com/meilisearch/MeiliSearch/issues/876">https://github.com/meilisearch/MeiliSearch/issues/876</a> highlights it. Until the indexing process can be paralleled at least in …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web">https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web</a></em></p>]]>
            </description>
            <link>https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045927</guid>
            <pubDate>Tue, 10 Nov 2020 13:57:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kraftwerk song performed with 5 Arduinos]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25045818">thread link</a>) | @alanjay
<br/>
November 10, 2020 | https://marquisdegeek.com/music_kraftwerk01 | <a href="https://web.archive.org/web/*/https://marquisdegeek.com/music_kraftwerk01">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://marquisdegeek.com/music_kraftwerk01</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045818</guid>
            <pubDate>Tue, 10 Nov 2020 13:46:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HTML Forms: How (and Why) to Prevent Double Form Submissions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25045789">thread link</a>) | @roosgit
<br/>
November 10, 2020 | https://www.bram.us/2020/11/04/preventing-double-form-submissions/ | <a href="https://web.archive.org/web/*/https://www.bram.us/2020/11/04/preventing-double-form-submissions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>When double clicking a submit button your form will be sent twice. Using JavaScript you can prevent this from happening, but wouldn’t it be nice if this behavior could be tweaked by use of an attribute on the <code>&lt;form&gt;</code>? If you think so, feel free to <a href="https://github.com/whatwg/html/issues/5312">give this issue a thumbs up</a>.</p>
<p><img loading="lazy" src="https://www.bram.us/wordpress/wp-content/uploads/2020/11/double-form-submit.gif" alt="" width="496" height="280" data-old-src="https://www.bram.us/wordpress/wp-content/plugins/native-lazyload/assets/images/placeholder.svg"></p>
<p>Today Sebastian wondered:</p>
<blockquote>
<p lang="en" dir="ltr">Disabling a form submit button while submitting: yay or nay?</p>
<p>(I thought I saw some research that discourages it, but can't remember where or why)</p>
<p>— Sebastian De Deyne (@sebdedeyne) <a href="https://twitter.com/sebdedeyne/status/1323921783729377280?ref_src=twsrc%5Etfw">November 4, 2020</a></p></blockquote>

<p>I quickly chimed in saying that I do tend to lock up forms when submitting them. Let me explain why …</p>
<p>~</p>
<p>I started locking up submitted forms as users of the apps I’m building reported that sometimes the actions they had taken — such as adding an entry — were performed twice. I took me some time to figure out what exactly was going on, but eventually I found out <b>this was because they were double clicking the submit button of the forms</b>. As they double clicked the button, the form got sent over twice. By locking up forms after their first submission, all successive submissions — such as those triggered by that second click of a double click — are ignored.</p>
<p>~</p>
<p>To prevent these extra form submissions from being made I don’t hijack the form with Ajax nor do I perform any other complicated things. I let the inner workings of the web and forms in the browser be: when pressing the submit button the browser will still collect all form data, build a new HTTP request, and execute that request.</p>
<p>What I simply do is extend the form’s capabilities by adding a flag — by means of a CSS class — onto the form to indicate whether it’s being submitted or not. I can then use this flag’s presence to deny any successive submissions, and also hook some CSS styles on. — <em>Progressive Enhancement, Yay! 🎉</em></p>
<p>The code looks as follows:</p>
<pre><code> // Prevent Double Submits
document.querySelectorAll('form').forEach(form =&gt; {
	form.addEventListener('submit', (e) =&gt; {
		// Prevent if already submitting
		if (form.classList.contains('is-submitting')) {
			e.preventDefault();
		}
		
		// Add class to hook our visual indicator on
		form.classList.add('is-submitting');
	});
});</code></pre>
<p>💡 Although the problem initially was a double click problem, we don’t listen for any clicks on the submit button but listen for the form’s <code>submit</code> event. This way our code not only works when clicking any of the submit buttons, but also when pressing enter to submit.</p>
<p>With that <code>.is-submitting</code> class in place, we can then attach some extra CSS onto the form to give the user visual feedback. Here’s a few examples:</p>
<p data-height="265" data-theme-id="light" data-default-tab="result" data-user="bramus" data-slug-hash="JjKZVPW" data-pen-title="Prevent Form Double Submits">
<span>See the Pen <a href="https://codepen.io/bramus/pen/JjKZVPW"><br>
Prevent Form Double Submits</a> by Bramus (<a href="https://codepen.io/bramus">@bramus</a>)<br>
on <a href="https://codepen.io/">CodePen</a>.</span>
</p>

<p data-height="265" data-theme-id="light" data-default-tab="result" data-user="bramus" data-slug-hash="NWrzmrV" data-pen-title="Prevent Form Double Submits (Alternative version)">
<span>See the Pen <a href="https://codepen.io/bramus/pen/NWrzmrV"><br>
 Prevent Form Double Submits (Alternative version)</a> by Bramus (<a href="https://codepen.io/bramus">@bramus</a>)<br>
on <a href="https://codepen.io/">CodePen</a>.</span>
</p>

<p>Note that this solution might not cover 100% of all possible scenarios, as it doesn’t take failing networks and other things that might go wrong into account. However, as I’m relying on the basic mechanisms of the web I think I can also rely on the browser to show that typical “Confirm Form Resubmission” interstitial should a timeout occur. Additionally, if need be, one could always unlock the form after a fixed amount of time. That way the user will be able to re-submit it again.</p>
<p>~</p>
<p>Dealing with double form submissions isn’t a new issue at all. You’ll find quite some results when running a few queries through Google — something I only found out after stumbling over the issue myself.</p>
<p>Back in 2015 (!) Mattias Geniar <a href="https://ma.ttias.be/double-clicking-on-the-web/">also pondered about this</a>, after being pulled into the subject from a sysadmin view. Now, when even sysadmins are talking about an HTML/UX issue you know there’s something going on. This made me wonder why browsers behaved like that and how we could solve it:</p>
<blockquote>
<p lang="en" dir="ltr">🤔 Why is it that browsers don't prevent double form submissions by default? Some users (mistakingly) double click on submit buttons.</p>
<p>💡 An attribute on &lt;form&gt; to tweak this behavior – instead of having to rely on JavaScript – would come in handy …</p>
<p>/cc <a href="https://twitter.com/WHATWG?ref_src=twsrc%5Etfw">@WHATWG</a> <a href="https://twitter.com/w3c?ref_src=twsrc%5Etfw">@w3c</a></p>
<p>— Bramus! (@bramus) <a href="https://twitter.com/bramus/status/1227925285041065986?ref_src=twsrc%5Etfw">February 13, 2020</a></p></blockquote>

<p>As a result I decided to open <a href="https://github.com/whatwg/html/issues/5312">an issue at the WHATWG HTML Standard repo</a>, suggesting for a way to fix this at spec level:</p>
<blockquote>
<p>An attribute on <code>&lt;form&gt;</code> to tweak this behavior – instead of having to rely on JavaScript – would come in handy and form a nice addition to the spec.</p>
<p>I see two options to go forward:</p>
<ol>
<li>Browsers/the standard keeps the current behavior and allow multiple submits. Developers must opt-in to prevent multiple submissions using a <code>preventmultiplesubmits</code> attribute.</li>
<li>Browsers/the standard adjust the current behavior to only submit forms once. Developers must opt-in to allow multiple submissions using a <code>allowmultiplesubmits</code> attribute.</li>
</ol>
</blockquote>
<p>Initial response on the issue was very low, and it looks like this isn’t that big of a priority.</p>
<p>Back then I was more in favor of the second solution, but now I’m quite undecided as changing the default behavior — which has been around for ages — is quite tricky.</p>
<p>~</p>
<p>Another way that this issue could be fixed is at the browser level: if they were to treat double clicks on form submit buttons as single clicks, then the double click problem — but not the double submit problem — could also be taken care of.</p>
<p>To then attach styles to forms being submitted a CSS Pseudo Class <code>:submitting</code> would come in handy. Come to think of it, this Pseudo Class would be a quite nice addition to CSS in itself, no matter whether this double click issue gets solved or not.</p>
<p>~</p>
<p>Winging back to <a href="https://github.com/whatwg/html/issues/5312">the addition to the HTML spec I suggested</a>: If you do think it could be something the HTML spec could benefit from, feel free to add a thumbs up to the issue to indicate that you want this, or add an extra comment to it if you have more input on the subject.</p>
<div>
<p><b>Did this help you out? Like what you see?<br>Thank me with a coffee.</b></p><p>I don't do this for profit but a small one-time donation would always put a smile on my face. Thanks!</p>
<p><a href="https://www.paypal.me/bramus/3EUR">☕️ Buy me a Coffee <em>(€3)</em></a></p>
</div>
</div></div>]]>
            </description>
            <link>https://www.bram.us/2020/11/04/preventing-double-form-submissions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045789</guid>
            <pubDate>Tue, 10 Nov 2020 13:43:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[cyclog – safely log standard input to status files and log directories]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25045778">thread link</a>) | @oftenwrong
<br/>
November 10, 2020 | https://jdebp.eu/Softwares/nosh/guide/cyclog.html | <a href="https://web.archive.org/web/*/https://jdebp.eu/Softwares/nosh/guide/cyclog.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div title="cyclog"><div><h2>Name</h2><p>cyclog — safely log standard input to status files and log directories</p></div><div title="Synopsis"><h2>Synopsis</h2><p><code>cyclog</code>  [--max-file-size <em><code>max-file-size</code></em>] [--max-total-size <em><code>max-total-size</code></em>] [--margin <em><code>margin</code></em>] {<em><code>directories</code></em>...}</p></div><div title="Description"><h2>Description</h2><p>
<span><strong>cyclog</strong></span> is a simple logging utility that logs everything that it receives on its standard input to a set of log file directories named as its command arguments.
It automatically timestamps logs, produces time-sortable log file names, rotates log files, and caps log directory sizes.
</p><p>
At startup, <span><strong>cyclog</strong></span> attempts to open all of the <em><code>directories</code></em>.
If they are directories (or symbolic links to the same), it treats them as log directories.
Otherwise, if they don't exist or are other types of file such as regular files, device files, or FIFOs, it aborts startup without reading from standard input.
</p><p>
It keeps a file descriptor open to each log directory for its lifetime, and accesses files relative to that open file descriptor.
Log directories can thus be renamed as it is running, and it will continue to use the original directory, wherever it is renamed to.
</p><div title="Log directory"><h3>Log directory</h3><p>
A log directory is compatible with the log directories employed by daemontools' and daemontools-encore's <span><span>multilog</span>(1)</span>, s6's <span><span>s6-log</span>(1)</span>, and runit's <span><span>svlog</span>(1)</span>.
It contains:
</p><div><ul type="disc"><li><p>
a <code>lock</code> file (compatible with <span><span>setlock</span>(1)</span>) that prevents two logging processes from sharing an active log directory;
</p></li><li><p>
a set of old log files, named as <code>@</code> followed by a TAI64N timestamp in external form (16 hexadecimal digits of seconds and 8 hexadecimal digits of nanoseconds) and either <code>.s</code> (safely written to disc) or <code>.u</code> (aborted whilst writing to disc and possibly incomplete);
and
</p></li><li><p>
a <code>current</code> file where incoming log data are currently being appended.
</p></li></ul></div><p>
An active <code>current</code> file, or an old log file or a <code>current</code> file that was not written to disc by <span><strong>cyclog</strong></span> properly shutting down, has permissions 0644.
A <code>current</code> file or an old log file where <span><strong>cyclog</strong></span> properly shut down has permissions 0744.
(See the <a href="#COMPATIBILITY" title="Compatibility">Compatibility</a> section.)
</p><p>
<span><strong>cyclog</strong></span> shuts down when either it sees EOF on its standard input, or it receives one of the "good" termination signals (<code>SIGTERM</code>, <code>SIGPIPE</code>, <code>SIGINT</code>, or <code>SIGHUP</code>).
At shut down, <span><strong>cyclog</strong></span> writes all pending data that it has already read from standard input, flushes <code>current</code> to disc, and changes <code>current</code>'s permissions.
At start up, it checks <code>current</code>'s permissions, creating the file with permissions 0744 if it does not already exist.
If they indicate proper shutdown, as they will also do if the file was created because it did not exist, it carries on.
If they indicate that the file was not properly written at shutdown, it performs <a href="#ROTATION" title="Automatic log rotation">automatic log rotation</a> to prevent appending to a potentially corrupt file (that may be sparse or contain ranges of zeroed blocks).
</p></div><div title="Reliable piped input"><h3>Reliable piped input</h3><p>
In the normal case, the standard input of <span><strong>cyclog</strong></span> will be a pipe; and both ends of the the pipe will be open in a long-lived supervisor process such as <span><span>service-manager</span>(1)</span>.
<span><strong>cyclog</strong></span>, as aforementioned, ensures that it writes all data read from its standard input, even if it is terminated by a (good) signal.
</p><p>
Thus no log data are lost, even if <span><strong>cyclog</strong></span> is shut down and restarted.
</p></div><div title="Automatic log rotation"><h3>Automatic log rotation</h3><p>
<span><strong>cyclog</strong></span> performs automatic log rotation when it writes a linefeed within <em><code>margin</code></em> bytes of the maximum size (<em><code>max-file-size</code></em>) of the <code>current</code> file, when it is about to exceed that size, when it receives a <code>SIGALRM</code>, or when it finds an improperly written to disc <code>current</code> file at startup.  
When recovering from an improperly finalized <code>current</code>, it simply renames it to a timestamped <code>.u</code> name.
Otherwise, it renames it to a timestamped <code>.u</code> name, flushes it to disc, changes its permissions, and then renames it to a timestamped <code>.s</code> name.
In both cases, it then creates a new <code>current</code> file.
The TAI64N timestamp of an old log file is the timestamp of when <span><strong>cyclog</strong></span> rotated <code>current</code> to that file.
</p><p>
At log rotation, and also at startup, it checks to ensure that the total size of all log files in the directory does not exceed the maximum total size (<em><code>max-total-size</code></em>).
(It only totals the sizes of <code>current</code> and old log files.  
Other files, not managed or created by <span><strong>cyclog</strong></span>, are ignored.)
If the total exceeds that maximum, it deletes each old log file with the numerically lowest name until either the total is less than the maximum or there is only the <code>current</code> file left.
</p><p>
Thus the maximum size of all log files at any time is <em><code>max-total-size</code></em> (the total size after the last rotation) plus <em><code>max-file-size</code></em> (the data written since that rotation).
The default <em><code>max-file-size</code></em> is 16MiB and the default <em><code>max-total-size</code></em> is 1GiB.
</p><p>
<span><strong>cyclog</strong></span> totals file sizes rather than space allocated on disc.
The amount of space allocated to all files may be, depending from the filesystem type and the maxima chosen, higher or lower than the space usage calculated by <span><strong>cyclog</strong></span>.
</p></div><div title="Timestamps"><h3>Timestamps</h3><p>
<span><strong>cyclog</strong></span> writes a timestamp at the beginning of every line written to <code>current</code>, which is the time when it processes the beginning of a line.  
This is slightly after it has read the beginning of that line.
The timestamp is in TAI64N external form (16 hexadecimal digits of seconds and 8 hexadecimal digits of nanoseconds), which can be converted to human-readable form using <span><span>tai64nlocal</span>(1)</span>.
</p><p>
<span><strong>cyclog</strong></span> uses the <code>CLOCK_REALTIME</code> clock of the <span><span>clock_gettime</span>(2)</span> system call.
On many systems this has nanosecond resolution.
</p><p>
<span><strong>cyclog</strong></span> attempts to generate real TAI timestamps.
On a Linux system where it detects an Olson "right" timezone currently in use, it knows that the system clock is TAI seconds since the Epoch and performs a simple conversion.
On other Linux systems, and on BSDs, it assumes that the system clock is UTC seconds since the Epoch and attempts to correct for (known) UTC leap seconds in order to determine TAI.
</p></div></div><div title="Compatibility"><h2>Compatibility</h2><p>
A <span><span>cyclog</span>(1)</span> utility was part of daemontools version 0.53.
This utility is a workalike, with some minor additions to automatic log rotation and changes to log directory semantics.
</p><p>
daemontools later replaced <span><span>cyclog</span>(1)</span> with <span><span>multilog</span>(1)</span>, which treats its command arguments as a script and has the abilities to do pattern matching and run external commands.
<span><strong>cyclog</strong></span> is intended for the commonest, simple, use cases of logging services where there is just one plain logging directory with no bells and whistles.
As such, it does not implement a script syntax, does not have pattern matching, and does not invoke other programs at all.
</p><p>
The daemontools version 0.53 <span><span>cyclog</span>(1)</span> used permissions 0644 and 0444 to flag files that had not been written to disc.
<span><strong>cyclog</strong></span> adopts the convention employed by the later <span><span>multilog</span>(1)</span>, and thence <span><span>s6-log</span>(1)</span> and <span><span>svlog</span>(1)</span>.
This convention changed to using the owner execute permission bit rather than the owner write permission bit as the flag.
<span><strong>cyclog</strong></span> sets and clears the execution bit as appropriate for interoperability with those tools, and <a href="#LOGDIRECTORY" title="Log directory">uses it itself for the same purpose</a>.
<span><span>multilog</span>(1)</span> altered the convention in order to cope with scenarios where it would end up trying to open a read-only file for writing.
</p><p>
The daemontools version 0.53 <span><span>cyclog</span>(1)</span> used the TAI64 timestamp of when a log file was started as its timestamp.
Again <span><strong>cyclog</strong></span> adopts the convention employed by later tools.
</p><p>
daemontools' and daemontools-encore's <span><span>multilog</span>(1)</span> uses a timer with only microsecond resolution, and for the same events will thus produce different timestamps to <span><strong>cyclog</strong></span>.
</p><p>
See <a href="https://jdebp.eu/Softwares/nosh/guide/timestamps.html" target="_top">the timestamps section of the <em>nosh Guide</em></a> for detailed information on the differences from daemontools, daemontools-encore, and other toolsets in how <span><strong>cyclog</strong></span> handles TAI.
</p></div></div></div>]]>
            </description>
            <link>https://jdebp.eu/Softwares/nosh/guide/cyclog.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045778</guid>
            <pubDate>Tue, 10 Nov 2020 13:41:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sven Yrvind on provisioning for a sea voyage]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25045749">thread link</a>) | @oftenwrong
<br/>
November 10, 2020 | https://www.yrvind.com/provisioning/ | <a href="https://web.archive.org/web/*/https://www.yrvind.com/provisioning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content">

<div>
	<div id="primary">
		<main id="main" role="main">

			
<article id="post-7486">
		<!-- .entry-header -->

	
	<div>
		<p>I will eat twice a day, breakfast and lunch four hours later.<br>
Me, I am afraid of insulin. Alzheimer is diabetes type 3. After four hours of no eating there be no insulin in the blood and my mitocondrias switches over to use stored fat for fuel. That’s the food strategy.<br>
Some people say, “Thats not much of a variation”<br>
I say, “Cows only eat grass and wolfs only eat meat”<br>
Modern society is so boring and there is so much food that we have to be stimulated by spices and chefs and different foods to eat. At sea in a small boat its different. Life itself out there is so interesting that I do not need stimulants.<br>
My breakfast consists of one can of sardines, one slice of dense dark rye bread and muesli.<br>
One meal of muesli contains:<br>
Almond flour 25 grams<br>
Dried grinded blueberries 15 grams<br>
Whole milk powder 30 grams<br>
Oats flakes 60 grams<br>
Raisins 20 grams<br>
Walnuts 20 grams<br>
Total 170 grams of muesli for each meal<br>
My lunch is the same as breakfast but no sardines.<br>
I hope to make the voyage in about 300 days, but 2018 may turn out to be a bad year weather vise. To have a margin I will load Exlex with food for 400 days. The weight of that food is 240 kilos. It breaks down into:<br>
136 kilos muesli, 64 kilos sardines and 40 kilos bread.<br>
My water capacity is 56 liters. There are two rain catchers. Hopefully there will be some rain otherwise I have to beg.<br>
A big job is to vacuum pack the muesli and the bread and store it safely in Exlex.<br>
I will also have plenty of multivitamin/mineral supplements.<br>
I look forward to be out on the deep, wet, endless, eternal ocean eating muesli and sardines.<br>
To be continued…<br>
Regards Yrvind.</p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article><!-- #post-## -->

		</main><!-- #main -->
	</div><!-- #primary -->
	
<!-- #secondary -->
</div><!-- .wrap -->


		</div><!-- #content -->

		<!-- #colophon -->
	</div></div>]]>
            </description>
            <link>https://www.yrvind.com/provisioning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045749</guid>
            <pubDate>Tue, 10 Nov 2020 13:38:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating a Web Performance Team]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25045594">thread link</a>) | @mostlystatic
<br/>
November 10, 2020 | https://www.debugbear.com/blog/web-performance-team | <a href="https://web.archive.org/web/*/https://www.debugbear.com/blog/web-performance-team">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>
    <div>
    
      
      

      

      <div>
        
        

        <p>Creating a web performance team is essential for many online businesses. Improving web performance for the long term requires a culture that understands the value of performance and treats it as a priority.</p>
<p>Setting up a team comes with a variety of challenges, many of them depending on your company and its culture. This post guides you through some of these difficulties.</p>
<h2 id="get-support-from-someone-higher-up-in-your-organization">Get support from someone higher up in your organization</h2>
<p>Creating a performance team is a lot of work. There are many things to prepare before the team starts making its first performance optimizations.</p>
<p>Starting is much easier if you have someone higher up in your organization supporting your efforts. Ideally, this is someone in management with budgetary responsibility. But if that's not the case, your team lead can also take on this role.</p>
<p>This person pushes web performance inside your company. They could promote your successes, organize budget, or help you to handle internal politics. They should understand the importance of performance and invest in your team.</p>
<p>To find someone, you need to promote your initiative. For example, you can speak at internal or public conferences. Company events like hackathons are a good way to start working on performance topics and form a group of co-workers that's interested in web performance.</p>
<h2 id="speaking-the-right-language">Speaking the right language</h2>
<p>Website performance means different things to different people. For a front-end developer, performance means site speed or load time. For a marketer, website performance relates to engagement, conversion rates, or page views. SEO experts talk about the ranking of key pages.</p>
<p>Managers look at the business value the website generates.</p>
<p>Planning for the long term requires these people to understand why web performance matters. They need to know the correlation between speed and measurable outcomes. You need to speak their language to convince these different disciplines.</p>
<p>You can find many performance case-studies on <a href="https://wpostats.com/">WPO stats</a> (WPO stands for Web Performance Optimization). These case studies show how performance impacts business results. You can filter the case studies by category, to find ones discussing metrics that are relevant to the person in your organization you're targeting.</p>
<h2 id="building-the-team">Building the team</h2>
<p>No matter how big your company, start by finding like-minded people. People that are passionate about web performance and who recognize its value.</p>
<p>Use your company meetings, hackathons, or any other events that your company already organizes. Pick a web performance topic and start forming a team around it. The advantage of finding like-minded people is that you don't need to convince them of the value web performance brings.</p>
<p>A good size to start with is 3 to 5 team members. Not all of them need to be performance engineers. Depending on your company's tech stack, the team could consist of many disciplines, including front-end developers, back-end developers, data analysts, marketers, and managers. A cross-functional or mixed performance team approach is a good option, but usually the team will lean toward technical roles.</p>
<p>Each development team could have a performance ambassador who's also a member of the performance team.</p>
<p><img src="https://www.debugbear.com/public/blog/web-performance-team/team-members.png" alt="Performance team and performance ambassadors"></p>
<h2 id="setting-up-a-performance-plan">Setting up a performance plan</h2>
<p>After you've found a group of people who care about performance, start creating a performance plan that captures what your team will do.</p>
<p>It describes <a href="https://www.debugbear.com/docs/web-performance-metrics">performance metrics</a>, monitoring, infrastructure, and accountability for performance issues. Additionally, it defines the tools you use and how you'll educate and incentivize the people in your organization.</p>
<h3 id="goals-and-engagement">Goals and Engagement</h3>
<p>To decide what goals to put into your performance plan, you need to identify what's most important for your users. What keeps them engaging with your website?</p>
<p>The resulting goal might be time on site or custom metrics like clicking on a link. You need to start measuring these metrics as they will form your baseline data for any changes you make in the future.</p>
<h3 id="mapping-performance-metrics-to-business-and-or-marketing-metrics">Mapping performance metrics to business and or marketing metrics</h3>
<p>Once you've gathered enough data, make sure that your team understands each metric. This knowledge is essential, as it forms the basis of all your future work.</p>
<p>In the next step, tie your performance metrics to business or marketing outcomes. For example, you could take the time it takes until the product page is interactive and compare that to the number of product purchases.</p>
<p><img src="https://www.debugbear.com/public/blog/web-performance-team/page-views-vs-bounce-rate.png" alt="Page views versus bounce rate"></p>
<p>Mapping business or marketing metrics to performance metrics is necessary for any performance team. The results will be the most potent arguments to push your work within the organization. And the results will help you estimate the impact of any optimizations you plan to make.</p>
<h3 id="accountability-education-and-empowerment">Accountability, education, and empowerment</h3>
<p>Accountability is a core part of your performance plan. One goal of the performance team is to educate, incentivize, and empower people to care about performance.</p>
<p>Depending on the size of your company, you can't be accountable for every issue. You should teach people how they can care about performance. They should know how to use your performance tools.</p>
<p>Everybody who touches your website (developer, content manager, marketing consultant) is responsible for its performance. Make people accountable by giving them ownership, and help them identify performance issues on their own.</p>
<p><a href="https://www.debugbear.com/docs/performance-budgets">Performance budgets</a> are a reliable way to monitor a page. You can specify a threshold for a metric, and you'll need to take action when this is exceeded. How you define your budget depends on your goals and user engagement metrics. For example, you could pick a certain Lighthouse score, or set a threshold for the download size of your images.</p>
<p>A quick tip for performance budgets: you can motivate your employees by choosing the status quo as your first performance budget. Whenever you've optimized your website, reduce the budget to the new values.</p>
<p><img src="https://www.debugbear.com/public/blog/web-performance-team/performance-budget.png" alt="Example of a JavaScript size performance budget chart"></p>
<p>Suppose your company is too big to educate everyone about web performance. Your performance team will be busy and you don't don't want them to be gatekeepers who are blocking the work of other teams.</p>
<p>In that case, you can create performance ambassadors inside each team who can take charge without being reliant on the performance team.</p>
<p><img src="https://www.debugbear.com/public/blog/web-performance-team/performance-team-relationships.png" alt="Performance ambassadors in each team together form a performance team"></p>
<h3 id="use-performance-tools-and-infrastructure">Use performance tools and infrastructure</h3>
<p>Web performance tools vary a lot. Some tools collect real user data, while others test site performance <a href="https://www.debugbear.com/blog/web-performance-metrics-lab-vs-rum">in a lab environment</a>. Some are very good at monitoring your key pages, while others give you a better overview of your entire site. Which tool you should use depends on your website or project. In most cases, it will be a combination of multiple tools.</p>
<p>A developer could use Lighthouse to check if the code has a performance issue. After a commit, continuous integration can spin up some test servers, and you can test if any performance budgets have been breached.</p>
<p>Another milestone could be a performance test after each new release. You have to decide which of these approaches fits your needs. Testing on each commit could be pricey, but testing only releases makes it challenging to identify the cause of a performance regression.</p>
<h3 id="celebrate-your-wins">Celebrate your wins</h3>
<p>Celebrating wins is an essential part of building a performance team. Actively celebrate successes periodically.</p>
<p>You could write a tweet or a blog post. Appoint a web performance employee of the month. Award a performance hero price. The hero doesn't need to be a developer or a performance engineer. A performance hero could also be your marketing manager.</p>
<h3 id="internal-or-public-pr">Internal or public PR</h3>
<p>No matter where you work, it is vital to communicate your wins within the organization. You show your successes to your boss or team lead to get a promotion someday. The same goes for your web performance wins. Modestly show them around your company, create simple graphs, or write internal blog posts. The people in your company shouldn't take it for granted that your website is fast.</p>
<h3 id="optimization">Optimization</h3>
<p>Optimization is one core job of your performance team. The performance team identifies and prioritizes opportunities for improvement. What aspects of your website you can optimize depends on your site and your users. Before you start, you need to analyze and monitor the performance of your website.</p>
<p>First, identify performance issues on your site and can create a list of potential improvements.</p>
<p>Next, estimate the impact of each issue and how much effort would be required to address it.</p>
<p>In the beginning, this might be a little tricky as you won't have any past optimizations to compare to. You could start by creating a sample issue that everybody can estimate, and then compare other issues to the sample issue. It's simpler to compare a new issue to an existing one rather than speculate about the impact.</p>
<p>For example, let's say reducing all your images to under 100 KB takes two days and speeds up your site by 500 ms. One of your current issues could be to hide some pictures on mobile. In our case, removing images on mobile devices could influence load times, but it won't take much time to finish.</p>
<h3 id="regressions">Regressions</h3>
<p>One of your biggest enemies as a web performance team are regressions. Regressions happens more often than you think, as it's easier to make a website fast once than keeping it fast long-term. Sometimes preventing regressions can be more impactful than shipping optimizations.</p>
<p>Depending on your infrastructure, you could use your tools to prevent regression. Put in place continuous integration for performance testing. If an issue happens, send daily, weekly or monthly reports. Besides that, you should send performance alerts to an accountable person in real-time.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Building a dedicated web performance team depends on web performance culture. This team's primary goal is to promote and encourage this culture. The members are doing this by sharing knowledge and educating all other employees.</p>
<p>Becoming and staying fast can not be done without a group of people who care about web performance. The …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.debugbear.com/blog/web-performance-team">https://www.debugbear.com/blog/web-performance-team</a></em></p>]]>
            </description>
            <link>https://www.debugbear.com/blog/web-performance-team</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045594</guid>
            <pubDate>Tue, 10 Nov 2020 13:18:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aesthetics over Usability – Google's New App Icons]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25045441">thread link</a>) | @moeminm
<br/>
November 10, 2020 | https://blog.moeminmamdouh.com/aesthetics-over-usability-googles-new-app-icons | <a href="https://web.archive.org/web/*/https://blog.moeminmamdouh.com/aesthetics-over-usability-googles-new-app-icons">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1605012940954/mO5AoN3Ie.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605011290156/BFSvCYtdr.png?auto=format&amp;q=60" alt="Google-Workspace-Icons-bad.png"></p>
<p>Google's new app icons are, well, a massive disappointment. They are so bad, there's a <a target="_blank" href="https://restoreoldicons.xyz/">Chrome extension</a> that you can download to restore the old icons. Design changes are always met with some sort of backlash, that's understandable, people don't like change. Facebook's desktop redesign, Instagram's icon redesign, Macbook's touchbar, etc. The problem here; however, revolves around usability, and that's when user feedback should be seriously taken into consideration.</p>
<p>Aside from the icon's shapes, there is nothing else distinguishable about them. They are all made from a palette of four colors; blue, green, yellow, and red. There's a reason why people hate them, and it's not colors, it's usability. </p>
<p>Browsing through the internet, here are some common complaints:</p>
<blockquote>
<p>I had to manually change every Google app icon on my Android phone. I had trouble finding the Maps icon even though it is in the same place. All the new icons look similar to Google drive icon.</p>
</blockquote>
<p>The complaints all revolve around not being to <em>find</em> the apps they want to launch.</p>
<blockquote>
<p>Bring back the old version. Like the new icons aren't even close. They're so unrecognizable that when I go search for them, I forget what I'm looking for before I get to them. It takes me 3 tries to create new events in my calendar or check my email lol</p>
</blockquote>
<p>I believe this comment summarizes why this change rolled out and is live</p>
<blockquote>
<p>To me, this is a symptom of a large company with lots of internal politics and friction, where it is not safe for a designer to push back and say "no, this is not a good idea" to their manager.</p>
<p>Or, even more likely, someone did, and were forced to execute anyway.</p>
</blockquote>
<p>Unfortunately, this is the current state of UX and Design in a lot of companies. Stakeholders are ultimately the one making decisions despite being met with proven statistics from designers. </p>
<p>I also feel like this is a great lesson to any aspiring designer that working for FANG companies isn't always rainbows and sunshine. I can't be sure why these icons rolled out, if it actually was internal politics or not, but it <strong>does</strong> happen. It isn't always about working for FANG companies, but working for a company that aligns with your values. </p>
<p>See you in another Google rebrand. </p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.moeminmamdouh.com/aesthetics-over-usability-googles-new-app-icons</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045441</guid>
            <pubDate>Tue, 10 Nov 2020 12:59:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bidirectional Scrolling: Why Not Both?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25045390">thread link</a>) | @bradley_taunt
<br/>
November 10, 2020 | https://uglyduck.ca/bidirectional-scrolling/ | <a href="https://web.archive.org/web/*/https://uglyduck.ca/bidirectional-scrolling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <section>
        
          <p><time datetime="2020-11-09T00:00:00+00:00">November 9, 2020</time></p>
        
        
        
          <p><em>Discussing the design decisions of bidirectional scrolling in regards to performance</em></p>
        
        <p>I recently came across Adam Silver’s post <a href="https://adamsilver.io/articles/bidirectional-scrolling-whats-not-to-like/">about the merits and pitfalls of bidirectional scrolling</a> and found myself conflicted with the design arguments put forth in the article. It’s a very good article overall, and I suggest giving it a read before digging deeper into my post here.</p>

<h2 id="the-premise">The Premise</h2>

<p>The original article argues that displaying page content via horizontal scrolling (and therefore slightly hiding interactive content) creates a few major issues:</p>

<ul>
  <li>it increases the chance users won’t see it</li>
  <li>there’s a greater reliance on digital literacy</li>
  <li>it’s generally more labour intensive for users</li>
</ul>

<p>Adam also makes a solid statement here:</p>

<blockquote>
  <p>Having to scroll down and across in a zig zag fashion can be tiresome, especially for people with motor impairments.</p>
</blockquote>

<p>But I don’t believe these issues create a need to completely remove the horizontal “scrolling” design altogether. You can still implement the <code>See All Items</code> category link, while allowing the horizontal content to load in <em>dynamically</em>. Balance is always key.</p>

<h2 id="not-all-at-once-please">Not All At Once, Please!</h2>

<p>So what exactly do I mean by <em>dynamically</em> loading in horizontal content?</p>

<ul>
  <li>The user is shown the top 4 items in a given category</li>
  <li>From there, the user can use the <code>See All Items</code> link to jump into a full category page</li>
  <li>If they so desire, they can begin scroll horizontally in a given category row
    <ul>
      <li>Once they reach the end of the row, 4 more items will load in automatically to expand the list</li>
      <li>To avoid a never-ending list, it might be best to limit total row items to ~20 items. At this point the UI could prompt the user to <code>View All Items</code> in that category.</li>
    </ul>
  </li>
</ul>

<p>By loading the row content in piece-by-piece, initial loads for users will be faster and subsequent list items will load quickly as well (since they would limit to a set default - in this case only 4).</p>

<h2 id="final-improvements">Final Improvements</h2>

<p>Below you can find a quick, static version of this concept. Here you can see the horizontal list items, along with their corresponding <code>See All Items</code> links. You’ll have to use your imagination for how new items would load once you each the end of a horizontal row. (I’m too lazy to spend extra time building out that functionality for a hypothetical blog post)</p>

<p data-height="844" data-theme-id="dark" data-default-tab="result" data-user="bradleytaunt" data-slug-hash="pobxpXz" data-pen-title="Bidirectional Scrolling CSS">
  <span>See the Pen <a href="https://codepen.io/bradleytaunt/pen/pobxpXz">
  Bidirectional Scrolling CSS</a> by Bradley Taunt (<a href="https://codepen.io/bradleytaunt">@bradleytaunt</a>)
  on <a href="https://codepen.io/">CodePen</a>.</span>
</p>



        
<br>

      </section>
    </div></div>]]>
            </description>
            <link>https://uglyduck.ca/bidirectional-scrolling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045390</guid>
            <pubDate>Tue, 10 Nov 2020 12:52:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is a Single Source of Truth and why do you need it]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25045127">thread link</a>) | @gabeadami
<br/>
November 10, 2020 | https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it | <a href="https://web.archive.org/web/*/https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.3.0"><div dir="ltr"><div><p id="viewer-foo"><span>Nowadays, too many companies struggle with difficulties organizing multiple data sources, low data accuracy or poor data accessibility. Most organizations have their company information scattered across several sources, databases, email threads. Thus, many teams end up having multiple conflicting versions of the same information, which may lead to severe errors. According to&nbsp;<a href="https://assets.kpmg/content/dam/kpmg/xx/pdf/2016/10/building-trust-in-analytics.pdf" target="_blank" rel="noopener"><u>KPMG and Forrester's survey</u></a>,&nbsp;only 34% of decision-makers report that they feel confident in the accuracy of the information they use.</span></p><div id="viewer-fbd7q"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Single source of truth anyone?"><p><img data-pin-url="https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it" data-pin-media="https://static.wixstatic.com/media/78f01e_5ff465f2e4e74c5aac029c4c8c76ef2f~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/78f01e_5ff465f2e4e74c5aac029c4c8c76ef2f~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt="Single source of truth anyone?"></p></div><p><span dir="auto">Our take on SSOT visual representation</span></p></div></div></div><p id="viewer-f0t8v"><span>Just imagine the following scenario: you have three teams that work independently but within the same project's frames. Everything's going smooth: each week you are updated by your teams – you know that they all are on track, and the project is finally moving to its final milestone. But in the end, it turns out that the product cannot be delivered as expected: the teams have worked each with a different goal in mind, supported by entirely different sources of information.&nbsp;</span></p><p id="viewer-cf90a"><span>For example:</span></p><ul><li id="viewer-fhjll"><p>Team A relied on your email guidance;</p></li><li id="viewer-ca2eq"><p>Team B followed specific client requirements without sharing them;</p></li><li id="viewer-ep6c9"><p>Team C followed the notes they made during the check-up meetings.</p></li></ul><p id="viewer-6hh0r"><span>So, what Is the main problem? We all have too many information channels, and instead of investing time into the right organization, we waste it on information search and verification. Besides, many employees search for the necessary information only when they need it, but they don't have it always at hand and don't follow the updates regularly.</span></p><p id="viewer-d6ekj"><span>Afterwards, we get what we deserve­ — dozens of communication channels, each carrying its own version of the information. Solution? A concept called Single Source of Truth (SSOT). This article will uncover what SSOT is, its characteristics and benefits, how it is organized, and why you clearly need it.</span></p><h2 id="viewer-6bo5l"><span>What is a Single Source of Truth (SSOT)?</span></h2><p id="viewer-ajjgd"><span>Here's one more example. Imagine that you're watching a football match with your friend, enjoying popcorn on the couch. And then your friend suddenly declares that Ronaldo is the best football player in the world, but you insist that it's Neymar, and the situation is getting tense. To settle this, you have to agree on the source with trusted stats, such as the number of played matches, wins, goals, etc. In other words, you agree upon your Single Source of Truth, to check who really is the best of these two talented guys, based on the trustful information.</span></p><p id="viewer-o8ll"><span>SSOT is a concept used to ensure that everyone in an organization bases business decisions on the same data. It is a platform where all company knowledge and information are stored and managed centrally to avoid overlaps and duplication. This platform might include decisions, processes, and operations of various company departments, e.g., Management, Human Resources, Sales, Marketing, etc.</span></p><p id="viewer-2va09"><span>A single source of truth provides employees, employers, and stakeholders with a clearer picture of information they possess, which in turn makes the decision-making process much simpler. SSOT ensures that the provided information is most recent and accurate; the reports are up-to-date so that you can rely on this data.</span></p><h2 id="viewer-b5js8"><span>Why have a Single Source of Truth?</span></h2><p id="viewer-csc4b"><span>SSOT is important for the times when an employee needs only one right answer. Organizations must ensure that their personnel is provided with one source that stores the information they need.&nbsp;You don't want your projects to fail. And you clearly don't need those dozens of tools in use, numerous apps to get the job done, and not a single one integrated with another. That doesn't sound good, right? The main idea is to put away the useless discussions and argues on which numbers/sources/stats and other data you should primarily rely on.</span></p><p id="viewer-d8cru"><span>Here are the primary and inarguable benefits of having SSOT:</span></p><ul><li id="viewer-9ojf9"><p>Decision-makers are provided with the right data;</p></li><li id="viewer-5oorj"><p>Reduction of the time spent on identifying the source with the correct and updated information;</p></li><li id="viewer-9erl8"><p>Eliminate duplicates and overlaps;</p></li><li id="viewer-7b7eh"><p>Increased clarity, transparency; and productivity;</p></li><li id="viewer-d1dag"><p>Reduction of tools and communication channels and associated costs;&nbsp;</p></li><li id="viewer-8a36v"><p>Reduction of error chances.</p></li></ul><h2 id="viewer-9mir1"><span>How organizations put an SSOT in place?</span></h2><p id="viewer-3m9v8"><span>For organizations, the best way to establish a Single Source of Truth is to connect and organize all the company information in one integrated software toolkit/suite. Creating SSOT isn't as complicated as it may seem from the first sight, especially if you already use a centralized task and project management tool. The project management tool that fits your team's needs has everything to become a single source of truth for your team.</span></p><div id="viewer-1mbnb"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Many ideas, single place to keep them "><p><img data-pin-url="https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it" data-pin-media="https://static.wixstatic.com/media/78f01e_879787ef1ad04e5b9e98ce8bf8dde07f~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/78f01e_879787ef1ad04e5b9e98ce8bf8dde07f~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt="Many ideas, single place to keep them "></p></div><p><span dir="auto">Many ideas, single place to keep them </span></p></div></div></div><p id="viewer-5uptg"><span>An SSOT should be agreed upon and declared so that everyone knows where is the right information stored, when/how often it should be updated. If this works for your team, you're almost here. But wait, you still need to choose the right tool that will serve you as an SSOT.</span></p><p id="viewer-530g7"><span>Here are some ways how task and project management tools, used as a single source of truth might help your team to deliver better results:</span></p><h3 id="viewer-fntmo"><span>Reduced number of meetings and emails</span></h3><p id="viewer-1feth"><span>You simply wouldn't need so many. Suppose your team has a central place to store important information, project progress, and updates. In that case, many status/sync meetings can be transformed into project chat messages or short comments/descriptions in task cards. The number of delayed projects due to miscommunications will decrease as well. So, it is highly recommended to choose a task management tool that has chat functionality.</span></p><h3 id="viewer-83nqs"><span>Greater team accountability</span></h3><p id="viewer-2lk02"><span>Task management tools ensure clarity and transparency, which leads to increased employee accountability. The past projects are stored, the future projects are planned, and everyone is on the same page. Each team member can track the team’s progress, always in the know of who is working on what and by when. An extra layer of clarity/personalization can be added with custom fields: priority, notes, comments, progress, or any other additional information. When everyone has up-to-date information on the project progress and is informed about the deadlines, it is more likely to be delivered in time. By updating Statuses in real-time, you provide more visibility for everyone in your team on their accomplishments.</span></p><div id="viewer-3dgdd"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Greater team accountability"><p><img data-pin-url="https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it" data-pin-media="https://static.wixstatic.com/media/78f01e_c8965819ce9a4f5d9c19f65dc48186e5~mv2.png/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/78f01e_c8965819ce9a4f5d9c19f65dc48186e5~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="Greater team accountability"></p></div><p><span dir="auto">With great team comes great accountability?</span></p></div></div></div><h3 id="viewer-dafal"><span>One task – many details</span></h3><p id="viewer-9il29"><span>Emails and meetings are a part of our lives for some time now, and we got used to them. But aren't they getting a little outdated? With a task management tool, you don't have to send long emails with task descriptions and many attachments, which might later get lost in your inbox. Create a task, add subtasks or checklists (if needed), attach any documents you need, set due dates and responsible assignees, add tags, and any other details you wish in custom fields. You can be very specific, writing a task description, and avoid a lot of questions. Knowing that you have everything about the task in one place makes everyone more confident in doing their jobs. And you always know where to look for the updates.</span></p><div id="viewer-8sb4v"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="One task — many details"><p><img data-pin-url="https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it" data-pin-media="https://static.wixstatic.com/media/78f01e_75ef8487eb5a45bca47c5888c553187c~mv2.png/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/78f01e_75ef8487eb5a45bca47c5888c553187c~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="One task — many details"></p></div><p><span dir="auto">Looks like this one is already overdue</span></p></div></div></div><h3 id="viewer-6m04o"><span>One place for everything</span></h3><p id="viewer-c872n"><span>The most crucial benefit of any task management tool is that it is an all-in-one place to manage people, projects, and everything in between. You control the team's and projects' process; you share files, communicate, brainstorm, provide comments in one place, and collaborate in real-time. You can store all your reports, tables, presentations, lists, and links in spaces and update when needed. The only important rule to adhere to: this is the only source of truth for your team, and it contains the most accurate and up-to-date information. As a Manager or a Team Lead, you should be responsible for keeping this source updated or for selecting responsible employees to delegate this important task.</span></p><div id="viewer-3g5sl"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="One place for everything task and project related"><p><img data-pin-url="https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it" data-pin-media="https://static.wixstatic.com/media/78f01e_93c82284c88945ab8ebac8a6bbec6262~mv2.png/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/78f01e_93c82284c88945ab8ebac8a6bbec6262~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="One place for everything task and project related"></p></div><p><span dir="auto">Nobody said you can't keep tasty recipes in you task management tool!</span></p></div></div></div><h2 id="viewer-bouro"><span>How to choose the right project management tool for your team?</span></h2><p id="viewer-12uah"><span>Everyone knows there are tons of project and task management tools available right now. And many of them are really great. But how to choose the best one? We would say that the "best "is very subjective and unfair evaluation. When choosing your project management software, you need to consider many factors, such as team size and particular features needed, functionality, security, budget, and more. It's obvious that a small start-up team will need a completely different tool compared to the needs of a vast organization with many departments and hundreds of employees. Thus, we have prepared some recommendations that you can take into consideration:</span></p><p id="viewer-5822p"><span><strong>Freelancers/ individuals:</strong></span></p><ul><li id="viewer-6k06r"><p><a href="https://www.infolio.co/" target="_blank" rel="noopener"><u><span>Infolio</span></u></a></p></li><li id="viewer-8ak3i"><p><a href="https://trello.com/" target="_blank" rel="noopener"><u><span>Trello</span></u></a></p></li><li id="viewer-acgm7"><p><a href="https://todoist.com/" target="_blank" rel="noopener"><u><span>Todoist</span></u></a></p></li><li id="viewer-6s6go"><p><a href="https://www.taskpigeon.co/" target="_blank" rel="noopener"><u><span>Task Pigeon</span></u></a></p></li></ul><p id="viewer-bbff8"><span><strong>Small to mid-size teams:</strong></span></p><ul><li id="viewer-ev7dd"><p><a href="https://asana.com/" target="_blank" rel="noopener"><u><span>Asana</span></u></a></p></li><li id="viewer-ubks"><p><a href="https://airtable.com/" target="_blank" rel="noopener"><u><span>Airtable</span></u></a></p></li><li id="viewer-57khb"><p><a href="https://clickup.com/" target="_blank" rel="noopener"><u><span>ClickUp</span></u></a></p></li><li id="viewer-98jr0"><p><a href="https://www.infolio.co/" target="_blank" rel="noopener"><u><span>Infolio</span></u></a> (yes, we are mentioned twice here because it's our list!)</p></li><li id="viewer-ak3mf"><p><a href="https://toggl.com/" target="_blank" rel="noopener"><u><span>Toggl</span></u></a></p></li><li id="viewer-10mbf"><p><a href="https://www.wrike.com/" target="_blank" rel="noopener"><u><span>Wrike</span></u></a></p></li></ul><p id="viewer-836h4"><span><strong>Bigger teams:</strong></span></p><ul><li id="viewer-ek0ka"><p><a href="https://monday.com/" target="_blank" rel="noopener"><u><span>Monday.com</span></u></a></p></li><li id="viewer-a8upa"><p><a href="https://www.atlassian.com/software/jira" target="_blank" rel="noopener"><u><span>Jira</span></u></a></p></li><li id="viewer-mp9j"><p><a href="https://asana.com/" target="_blank" rel="noopener"><u><span>Asana</span></u></a></p></li><li id="viewer-irit"><p><a href="https://www.teamwork.com/" target="_blank" rel="noopener"><u><span>Teamwork</span></u></a></p></li><li id="viewer-dmp08"><p><a href="https://www.hubspot.com/" target="_blank" rel="noopener"><u><span>Hubspot</span></u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.infolio.co/post/what-is-a-single-source-of-truth-and-why-do-you-need-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045127</guid>
            <pubDate>Tue, 10 Nov 2020 12:18:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Does Pwd Operate?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25045067">thread link</a>) | @gclv
<br/>
November 10, 2020 | https://www.gclv.es/how-does-pwd-operate | <a href="https://web.archive.org/web/*/https://www.gclv.es/how-does-pwd-operate">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>After re-reading some of the papers from Bell Labs, something clicked in my mind, and I'm hooked. I'm now reading <a href="https://en.wikipedia.org/wiki/The_Unix_Programming_Environment" rel="nofollow">“The UNIX Programming Environment”</a>, by Kernighan and Pike. It's got that fun style you're probably familiar with, if you've read K&amp;R or the <a href="https://gopl.io/" rel="nofollow">blue book</a>. One of the first exercise questions, on the chapter on file systems:</p>

<blockquote><p>(harder) How does the <code>pwd</code> command operate?</p></blockquote>

<p>Seems like a fun one. My first guess is that it used <code>$PWD</code> from the environment. Let's test that.</p>

<pre><code>~ % PWD=/usr/local pwd
/home/gg
</code></pre>

<p>There's a non-standard <code>-L</code> flag that seems to use <code>$PWD</code>. Maybe that one would do?</p>

<pre><code>~ % PWD=/usr/local pwd -L
/home/gg
</code></pre>

<p>Not that either. Wait a second, what's <code>pwd</code> again?</p>

<pre><code>~ % type pwd
pwd is a shell builtin
</code></pre>

<p>Hah, so I was calling the wrong one. So I replace <code>pwd</code> with <code>/bin/pwd</code> in my queries above, but the results are the same.</p>

<p>My next hypothesis is that it would somehow expand <code>.</code> to absolute. I'm not aware of a UNIX command that performs such an expansion, so I <code>man -k</code> some keywords. Nothing.</p>

<p>Maybe <code>pwd(1)</code>? It's not terribly descriptive (it's such a simple utility after all.) It doesn't explain the implementation at all, but links me to <code>getcwd(3)</code>. Alright, let's just look at the source.</p>

<h2 id="openbsd-implementation">OpenBSD implementation</h2>

<pre><code>int
main(int argc, char *argv[])
{
	int ch, lFlag = 0;
	const char *p;

	/* pledge(), parse flags... */

	if (lFlag)
		p = getcwd_logical();
	else
		p = NULL;
	if (p == NULL)
		p = getcwd(NULL, 0);

	if (p == NULL)
		err(EXIT_FAILURE, NULL);

	puts(p);

	exit(EXIT_SUCCESS);
}
</code></pre>

<p>Unless <code>-P</code> is passed, it just calls <code>getcwd</code>. Let's see what that “logical”
function does:</p>

<pre><code>static char *
getcwd_logical(void)
{
	char *pwd, *p;
	struct stat s_pwd, s_dot;

	/* Check $PWD -- if it's right, it's fast. */
	pwd = getenv("PWD");
	puts("PWD found in the ENV");
	puts(pwd);
	if (pwd == NULL)
		return NULL;
	if (pwd[0] != '/')
		return NULL;

	/* check for . or .. components, including trailing ones */
	for (p = pwd; *p != '\0'; p++)
		if (p[0] == '/' &amp;&amp; p[1] == '.') {
			if (p[2] == '.')
				p++;
			if (p[2] == '\0' || p[2] == '/')
				return NULL;
		}

	if (stat(pwd, &amp;s_pwd) == -1 || stat(".", &amp;s_dot) == -1)
		return NULL;
	if (s_pwd.st_dev != s_dot.st_dev || s_pwd.st_ino != s_dot.st_ino)
		return NULL;
	return pwd;
}
</code></pre>

<p>So <code>-L</code> <em>does</em> check for <code>$PWD</code>, but only returns it if it's pointing to the same inode, on the same device. You can't just manually override it to be anything you want. In that case, it falls back to the libc call to <code>getcwd</code>.</p>

<p>Makes me wonder what use this <code>-L</code> flag is in the first place. Maybe it has to do with symlinks?</p>

<pre><code>/tmp % mkdir one
/tmp % ln -s one two
/tmp % cd one
/tmp/one % /bin/pwd
/tmp/one
/tmp/one % cd ../two
/tmp/two % /bin/pwd
/tmp/one
/tmp/two % /bin/pwd -L
/tmp/two
</code></pre>

<p>Makes sense. Anyway, that's not a very satisfying answer. I doubt the authors' intended answer would have been “defer to the libc”.</p>

<h2 id="plan9">Plan9</h2>

<p>Ok, OpenBSD source didn't help. But Plan9 is <em>Unicibus ipsis Unicior</em>, so maybe we can find the answer there. Let's inspect <code>pwd(1)</code>:</p>

<pre><code>     DESCRIPTION
          Pwd prints the path name of the working (current) directory.
          Pwd is guaranteed to return the same path that was used to
          enter the directory.  If, however, the name space has
          changed, or directory names have been changed, this path
          name may no longer be valid.  (See fd2path(2) for a descrip-
          tion of pwd's mechanism.)
</code></pre>

<p>Hah, that was helpful! Now, from <code>fd2path(2)</code>:</p>

<pre><code>          As an example, getwd(2) is implemented by opening . and exe-
          cuting fd2path on the resulting file descriptor.
</code></pre>

<p>So my hypothesis above was correct, at least when it comes to Plan9. Also, another cool thing about Plan9 is that it lets me inspect a folder (“everything is a file”, right?)</p>

<pre><code>% cat . &gt; foo
% cat foo
</code></pre>

<p>I can then run <code>foo</code> through <code>hexdump</code> and see what's in there.</p>

<h2 id="gnu">GNU</h2>

<p>Let's see <a href="https://github.com/coreutils/coreutils/blob/master/src/pwd.c" rel="nofollow">how coreutils implements it</a>... nope. Just nope.</p>

<h2 id="wrapping-up">Wrapping up</h2>

<p>So that was it, a brief excursion into different implementations of a simple command in UNIX. The difference in complexity is palpable. The Plan9 documentation is fun to read, and so is the code.</p>
</div></div>]]>
            </description>
            <link>https://www.gclv.es/how-does-pwd-operate</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045067</guid>
            <pubDate>Tue, 10 Nov 2020 12:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Micro 3.0 is a platform for cloud native development]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25044604">thread link</a>) | @asim
<br/>
November 10, 2020 | https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html | <a href="https://web.archive.org/web/*/https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      
      
      

      <p>This is the official announcement for the release of Micro 3.0 better known as M3O - a platform for cloud native development. 
Our 3.0 release is a major refactor and consolidation of the existing tooling into something that addresses the entire workflow 
of build, run, manage and consume all from the developers perspective.</p>

<p>Read on to learn more or go straight to the <a href="https://github.com/micro/micro/releases/latest">latest release</a>. 
Head to <a href="https://m3o.com/">m3o.com</a> for the hosted offering.</p>

<h2 id="overview">Overview</h2>

<p>Micro focuses on developer productivity for the backend. It’s clear that the Cloud has become infinitely more complex 
over the past few years. Micro attempts to create order out of that chaos by distilling it all down to a handful of 
primitives for distributed systems development.</p>

<p>Why should you care? If you’re reading this you’ve no doubt encountered the tedious nature of infrastructure management, 
wrangling a kubernetes cluster on AWS or the thousands of things you need to do to cobble together a platform before 
starting to build a product. We think we’ve nailed the solution for that just as Android did for Mobile. Keep reading 
if you want to find out more.</p>

<h2 id="quick-flashback">Quick Flashback</h2>

<p>Micro started out as a <a href="https://micro.mu/blog/2016/03/20/micro.html">toolkit for microservices</a> development, 
incorporating an api gateway, web dashboard and cli to interact with services built using a Go RPC framework. 
Back then it felt like getting anyone to buy into PaaS again was going to be a losing battle. So we chose 
to write single purpose tools around an RPC framework thinking it might allow people to adopt it piece by piece 
until they saw the need for a platform. It was really straight forward right until it wasn’t.</p>

<p>There was a simple Go framework plus some surrounding 
components to query and interact with them, but like any long lived project, the complexity grew as we 
tried to solve for that platform experience that just couldn’t be done with a swiss army knife. The repo 
exploded with a number of independent libraries. To the creator its obvious what these are all for but to 
the user there is nothing but cognitive overload.</p>

<p>In 2019 we went through a <a href="https://micro.mu/blog/2019/06/10/the-great-consolidation.html">consolidation</a> of all those libraries 
which helped tremendously but there was still always one outstanding question. What’s the difference between 
<a href="https://github.com/micro/micro">micro</a> and <a href="https://github.com/micro/go-micro">go-micro</a>? It’s a good 
question and one we’ve covered before. We saw go-micro as a framework and micro as a toolkit but these 
words were basically empty and meaningless because multiple projects working in coordination really need a 
crisp story that makes sense and we didn’t have one.</p>

<p>In 2020 we’re looking to rectify that but let’s first let’s talk about platforms.</p>

<h2 id="paas-in-2020">PaaS in 2020</h2>

<p>5 years ago the world exploded with a proliferation of “cloud native” tooling as containers and 
container orchestration took centre stage. More specifically, Docker and Kubernetes redefined the 
technology landscape along with a more conscious move towards building software in the cloud.</p>

<p>Micro took a forward looking view even as far back as 2015. It was clear distributed systems and cloud native 
was going to become the dominant model for backend services development over the coming years but, what wasn’t clear 
is just how long we’d spend wrangling all sorts tools like docker, kubernetes, grpc, istio and everything else. 
It felt like we were rebuilding the stack and weren’t really ready to talk about development aspects of it all.</p>

<p>In fact at that time, people mostly wanted to kick the tyres on all these tools and piece something together. 
Running kubernetes yourself became all the rage and even using service mesh as the holy grail for solving 
all your distributed systems problems. Many of us have come to realise while all of this tech is fun 
it’s not actually solving development problems.</p>

<p>We’ve gotten to the point of managed kubernetes and even things like Google Cloud Run or DigitalOcean App 
Platform, but none of these things are helping with a development model for a cloud native era. Our 
frustrations with the existing developer experience have grown and Micro felt like something that 
could solve for all that, but only if we took a drastic step to overhaul it.</p>

<p>We think PaaS 3.0 is not just about running your container or even your source code but something that 
encapsulates the entire developer experience including a model for writing code for the cloud. Based on that 
Micro 3.0 aka M3O is a platform for cloud native development.</p>

<h2 id="what-even-is-cloud-native">What even is Cloud Native?</h2>

<p>What is cloud native? What does it mean to build for the cloud? What is a cloud service?</p>

<p>Cloud native is basically a descriptive term for something that was built to run in the cloud. That’s it. It’s not 
magic, it might sound like a buzzword, but the reality is it simply means, that piece of software was built 
to run in the cloud. How does that differ from the way we used to build before? Well the idea behind the cloud 
is that its ephemeral, scalable and everything can be accessed via an API.</p>

<p>Our expectation for services running in the cloud is that they’re mostly stateless, leveraging external services 
for the persistence, that they are identified by name rather than IP address and they themselves provide an 
API that can be consumed by multiple clients such as web, mobile and cli or other services.</p>

<p>Cloud native applications are horizontally scalable and operate within domain boundaries that divide them as 
separate apps which communicate over the network via their APIs rather than as one monolithic entity. 
We think cloud services require a fundamentally different approach to software creation and why Micro 3.0 
was designed with this in mind.</p>

<h2 id="micro-30-aka-m3o">Micro 3.0 aka M3O</h2>

<p>Micro 3.0 (M3O) reimagines Micro as a platform for cloud native development. What does that mean? Well we think of 
it as PaaS 3.0, a complete solution for source to running and beyond. Micro has moved from just being a Go 
framework to incorporating a standalone server and hosted platform. Our hosted offering is called 
<a href="https://m3o.com/">M3O</a>, a hat tip to Micro 3.0 or M[icr]o, whichever way you want to see it.</p>

<p>Another way to think about it. What Git is to GitHub, Micro is to the M3O platform. Let’s dig into it.</p>

<p>Micro 3.0 includes the following.</p>

<h3 id="server">Server</h3>

<p>The server is our abstraction for cloud infrastructure and underlying systems you might need for writing 
distributed systems. The server encapsulates all of these concerns as gRPC services which you can 
query via any language. The goal here is to say developers don’t really need to be thinking about infrastructure 
but what they do need is design patterns and primitives for building distributed systems.</p>

<p><img src="https://micro.mu/images/micro-3.0.png"></p>

<p>The server includes the following:</p>

<ul>
  <li>
    <p><strong>Authentication</strong>: Auth whether its authentication or authorization is part of the system. Create JWT tokens, define access rules, use one system to govern everything in a simple and straight forward manner. Whether it’s for a user or a service.</p>
  </li>
  <li>
    <p><strong>Configuration</strong>: Dynamic config management allows you to store relevant config that needs to be updated without having to restart services. Throw API keys and business logic related configuration into the secure config service and let your services pick up the changes.</p>
  </li>
  <li>
    <p><strong>Key-Value Storage</strong>: We’re focused on best practices for microservices development which means keeping services mostly stateless. To do this we’re providing persistent storage on the platform. Key-Value allows you to rapidly write code and store data in the format you care about.</p>
  </li>
  <li>
    <p><strong>Event Streaming</strong>: Distributed systems are fundamentally in need of an event driven architecture to breakdown the tight dependencies between them. Using event streaming and pubsub allows you to publish and subscribe to relevant events async.</p>
  </li>
  <li>
    <p><strong>Service Registry</strong>: Micro and M3O bake in service discovery so you can browse a directory of services to explore your service APIs and enable you to query services by name. Micro is all about microservices and multi-service development.</p>
  </li>
  <li>
    <p><strong>Service Network</strong>: Because you don’t want to have to resolve those service names to addresses and deal with the load balancing aspect, the server bakes in a “service mesh” which will handle your inter-service requests (as gRPC) and route to the 
appropriate instance.</p>
  </li>
  <li>
    <p><strong>Identity Proxy</strong>: We include a separate identity proxy for external requests using gRPC via the CLI and other means. This enables you to query from your local machine or anywhere else using valid auth credentials and have it seamlessly work as if 
you were in the platform itself.</p>
  </li>
  <li>
    <p><strong>API Gateway</strong>: Finally there’s an API gateway that automatically exposes your services to the outside world over HTTP. Internally writing service to service using gRPC makes sense, but at the end of the day we want to build APIs consumed from clients via HTTP.</p>
  </li>
</ul>

<h3 id="clients">Clients</h3>

<p>The server provides inter-service communication and two means of external communication with a HTTP API and gRPC proxy but that 
experience is made much better when there’s user experience on the client side that works. Right now we’ve got two ways of doing this.</p>

<ul>
  <li>
    <p><strong>Command Line</strong>: The CLI provides a convenient and simple way to talk to the server via gRPC requests through the proxy. 
The most convenient commands are builtin but every service you write also gets beautiful dynamic generated commands 
for each endpoint.</p>
  </li>
  <li>
    <p><strong>gRPC SDKs</strong>: Every service in the server is accessible via gRPC. We’re code generating clients for the server itself 
so you can access them from any language. What this enables is a wide array of experiences on the client side without 
having to handcraft libraries for each language.</p>
  </li>
  <li>
    <p><strong>Web Interface</strong>: Coming soon is a dynamically generated web interface that creates a simple query mechanism through a 
browser for any of your services. We’ve got a http api, gRPC proxy and command line interface but feel like the browser 
could use some love too.</p>
  </li>
</ul>

<h3 id="framework">Framework</h3>

<p>One thing we really understood from our time working on go-micro was that the developer experience …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html">https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html</a></em></p>]]>
            </description>
            <link>https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044604</guid>
            <pubDate>Tue, 10 Nov 2020 11:00:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to revert HP printer’s ban on 3rd-party ink cartridges]]>
            </title>
            <description>
<![CDATA[
Score 407 | Comments 247 (<a href="https://news.ycombinator.com/item?id=25044597">thread link</a>) | @kdeldycke
<br/>
November 10, 2020 | https://kevin.deldycke.com/2020/11/revert-hp-printer-ban-on-third-party-ink-cartridges/ | <a href="https://web.archive.org/web/*/https://kevin.deldycke.com/2020/11/revert-hp-printer-ban-on-third-party-ink-cartridges/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
     <p>
      Hewlett
      <span>
       &amp;
      </span>
      Packard, the founders, had great lessons to teach us (managers in high-tech) about culture. I even
      <a href="https://github.com/kdeldycke/awesome-engineering-team-management/commit/de3e64647c911f78a37b3e54c7e46197acb061e1">
       quoted them
      </a>
      in my
      <a href="https://github.com/kdeldycke/awesome-engineering-team-management#readme">
       awesome list on engineering team management
      </a>
      .&nbsp;👨‍💼
     </p>
     <p>
      <span>
       HP
      </span>
      Inc., the company, sucks. At least their
      <a href="https://news.ycombinator.com/item?id=25045024">
       printer division’s business model
      </a>
      . They recently pushed a
      <strong>
       firmware update to ban third-party compatible toner cartridges
      </strong>
      .&nbsp;💔
     </p>
     <p>
      The timeline is&nbsp;straightforward:
     </p>
     <ul>
      <li>
       <p>
        2020, March: general lockdown. 🦠 I need a home office.
        <span>
         SO
        </span>
        is a scientist and spend her time printing papers for review. Got her an
        <a href="https://amzn.com/B073R2WVKB/?tag=kevideld-20">
         <span>
          HP
         </span>
         Color LaserJet M254dw
        </a>
        to keep her productive workflow (
        <a href="https://en.wikipedia.org/wiki/Publish_or_perish">
         publish or perish!
        </a>
        ).
       </p>
      </li>
      <li>
       <p>
        2020, October:
        <span>
         HP
        </span>
        release a new firmware (versioned
        <code>
         20201021
        </code>
        ).
       </p>
      </li>
     </ul>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-20201021-firmware.jpg">
     </p>
     <ul>
      <li>
       2020, November: my printer auto-upgrade. I’m welcomed with this
       <em>
        Supply Problem
        <a href="https://en.wikipedia.org/wiki/Screen_of_death">
         Screen of Death
        </a>
       </em>
       :
      </li>
     </ul>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-supply-problem-screen-of-death.jpg">
     </p>
     <p>
      I can’t print anymore.&nbsp;🤯
     </p>
     <p>
      Eight months. My printer worked for only 8 months.&nbsp;😤
     </p>
     <p>
      <span>
       OK
      </span>
      . It’s my fault. I should have spent more money buying certified™ gear.&nbsp;😑
     </p>
     <p>
      <img alt="" src="https://comdoc.com/wp-content/uploads/2019/01/copier-printer-meme-03.jpg">
     </p>
     <p>
      The solution is to travel back in time when things were working just great, and downgrade to the previous&nbsp;firmware.
     </p>
     <h2 id="disable-auto-upgrade">
      Disable Auto-Upgrade
      <a href="#disable-auto-upgrade" title="Permanent link">
       ¶
      </a>
     </h2>
     <p>
      We will start by stopping this madness for good, and prevent the printer from downloading a firmware behind our&nbsp;back.
     </p>
     <p>
      In the control panel, go to
      <code>
       Setup
      </code>
      &gt;
      <code>
       Service
      </code>
      &gt;
      <code>
       LaserJet Update
      </code>
      &gt;
      <code>
       Manage Updates
      </code>
      :
     </p>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-manage-updates-menu.jpg">
     </p>
     <p>
      Then set these&nbsp;options:
     </p>
     <ul>
      <li>
       Allow Downgrade:
       <code>
        Yes
       </code>
      </li>
      <li>
       Check Automatically:
       <code>
        Off
       </code>
      </li>
      <li>
       Prompt Before Install:
       <code>
        Always Prompt
       </code>
      </li>
      <li>
       Allow Updates:
       <code>
        No
       </code>
      </li>
     </ul>
     <p>
      I’m quite surprised downgrades are allowed. 🤔 It seems out of character. Therefor, with my
      <em>
       Evil Product Manager
      </em>
      hat, I advise
      <span>
       HP
      </span>
      to monetize this feature under a monthly Enterprise Subscription of sort.&nbsp;😈
     </p>
     <h2 id="download-old-firmware">
      Download Old Firmware
      <a href="#download-old-firmware" title="Permanent link">
       ¶
      </a>
     </h2>
     <p>
      I got lucky and found the previous
      <code>
       20200612
      </code>
      firmware referenced in
      <a href="https://ftp.hp.com/pub/networking/software/pfirmware/pfirmware.glf">
       <code>
        https://ftp.hp.com/pub/networking/software/pfirmware/pfirmware.glf
       </code>
      </a>
      .
     </p>
     <p>
      There you’ll get a direct link to the
      <code>
       .rfu
      </code>
      file (Remote Firmware Update):
      <a href="http://ftp.hp.com/pub/networking/software/pfirmware/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu">
       <code>
        http://ftp.hp.com/pub/networking/software/pfirmware/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
       </code>
      </a>
      .
     </p>
     <p>
      And just in case it disappear from its original location, here is a
      <a href="https://kevin.deldycke.com/uploads/2020/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu">
       copy of
       <code>
        HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
       </code>
      </a>
      .
     </p>
     <p>
      The checksum of that file&nbsp;is:
     </p>
     <div>
      <pre><span></span><code><span data-linenos="1 "></span><span>$</span> sha256sum ./HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
<span data-linenos="2 "></span><span>91c7f51ceba2386f3b94dcb9da20c669ab10b1ee3a9b1e1f742c40091920188e</span>
</code></pre>
     </div>
     <h2 id="downgrade-firmware">
      Downgrade Firmware
      <a href="#downgrade-firmware" title="Permanent link">
       ¶
      </a>
     </h2>
     <p>
      Once you get the
      <code>
       .rfu
      </code>
      file, list all your printers from a macOS&nbsp;terminal:
     </p>
     <div>
      <pre><span></span><code><span data-linenos="1 "></span><span>$</span> lpstat -p -d
<span data-linenos="2 "></span><span>printer HP_Color_LaserJet_M254dw_0 is idle.  enabled since Fri Nov  6 17:47:06 2020</span>
<span data-linenos="3 "></span><span>system default destination: HP_Color_LaserJet_M254dw_0</span>
</code></pre>
     </div>
     <p>
      And run the firmware downgrade
      <span>
       CLI
      </span>
      :
     </p>
     <div>
      <pre><span></span><code><span data-linenos="1 "></span><span>$</span> lpr -P HP_Color_LaserJet_M254dw_0 /Users/kde/Downloads/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
</code></pre>
     </div>
     <p>
      Nothing gets printed to the&nbsp;console.
     </p>
     <p>
      I don’t know what happens here but it seems the
      <code>
       .rfu
      </code>
      file is pushed to the printer’s queue and then gets consumed as any other printable document. See,
      <a href="https://www.jsof-tech.com/unpacking-hp-firmware-updates-part-1/">
       the
       <span>
        RFU
       </span>
       file format is a matryoshka doll
      </a>
      embedding printing commands, encoded data and raw
      <span>
       NAND
      </span>
      code.
     </p>
     <p>
      After a minute  or two, the printers reboots and upgrades&nbsp;itself:
     </p>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-firmware-updating.jpg">
     </p>
     <p>
      And we’re back in business!&nbsp;🥳
     </p>
     <p>
      A detour via
      <code>
       Setup
      </code>
      &gt;
      <code>
       Service
      </code>
      &gt;
      <code>
       Firmware Datecode
      </code>
      menu confirm we’re running the the previous&nbsp;firmware:
     </p>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-20200612-firmware.jpg">
     </p>
     <h2 id="printer-security">
      Printer Security
      <a href="#printer-security" title="Permanent link">
       ¶
      </a>
     </h2>
     <p>
      In my research for this article, I found out about
      <a href="https://github.com/RUB-NDS/PRET">
       <span>
        PRET
       </span>
       , a printer exploitation toolkit
      </a>
      . It’s a brilliant tool, in a malignant way. It allows for pen-testing and hacking, using the same vectors as the firmware update.&nbsp;🤫
     </p>
     <p>
      I’ll probably play with it in the future. For fun, but also to try enhance the security of the printer. In the mean time, I guess a password is the bare minimum. And if my printer get kidnapped by a cyber gang, I now have a way to restore my printer’s firmware!&nbsp;😬
     </p>
     <h3>
      Related content
     </h3>
     
     
    </div></div>]]>
            </description>
            <link>https://kevin.deldycke.com/2020/11/revert-hp-printer-ban-on-third-party-ink-cartridges/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044597</guid>
            <pubDate>Tue, 10 Nov 2020 10:59:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Plant Tweets]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044512">thread link</a>) | @luu
<br/>
November 10, 2020 | http://sarabee.github.io/2020/04/19/plant-tweets-part-1/ | <a href="https://web.archive.org/web/*/http://sarabee.github.io/2020/04/19/plant-tweets-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="http://sarabee.github.io/images/monstera.jpg" width="180">
This past week my monstera deliciosa, a lovely tropical houseplant, <a href="https://twitter.com/monsterasays">started to
tweet</a>. This is the first of two posts on this here skeleton of a blog showing
how I helped it get its voice out into the internet. First, we’ll take a look at the hardware and code
needed to read my plant’s mind; Part 2 will look at how those thoughts are
broadcast to the world. These posts should make sense even if you’ve never
played with hardware before, so please @ me
(<a href="https://twitter.com/SaraBee">@SaraBee</a>) if you have questions!</p>

<p>A month ago, I was shopping for a cheap soil moisture meter to help me care
for my growing army of plants. In my search results were hits for the simple
mechanical sensors I was looking for, but also inexpensive hardware sensors for use in
projects with, for example, Arduinos. Of course, my first thought was: “My
plant needs to connect to the internet.”</p>

<p><img src="http://sarabee.github.io/images/tweets.jpg" width="500"></p>

<p>In researching which sensors to buy, I saw that there were two types
available: resistive and capacitive. Resistive sensors work by measuring the
conductivity of the soil in which it is placed by running electricity through
it, and if you remember back to
high school science class you may remember something something electrolysis
something something ionization (that’s about where I’m at) – basically the
electricty creates a chemical reaction with the water and metal that removes copper from the sensor
over time, eventually causing it to stop working. Capacitive sensors, on the other hand, do not have exposed
electrodes, and so should not fail due to electrolysis over time. I really
enjoyed <a href="https://www.youtube.com/watch?v=udmJyncDvw0">this video</a>, which gets into how each sensor type works and
demonstrates this particular failure mode of resistive sensors. Needless to
say, I went capacitive, since I was planning to leave my sensor in-place over
long periods of time.</p>

<p><img src="http://sarabee.github.io/images/sensor.jpg" width="500"></p>

<p>The sensor on its own wouldn’t really get me anywhere, all it does is output
an analog value (like 273, or 418, or 550) for something else to read. I had
already set up a <a href="https://www.raspberrypi.org/products/raspberry-pi-3-model-b/">Raspberry
Pi</a> as an always-on linux server that I use as my
dev box, so initially I was interested in connecting the sensor straight to
the rpi’s GPIO pins (general-purpose input/output pins, for use with sensors
and other stuff). One small problem: rpi’s GPIO pins only work with digital
input and output, not analog like my sensor’s output. If I plugged the sensor directly into my rpi, it wouldn’t
be able to make sense of the signal.</p>

<p><img src="http://sarabee.github.io/images/adc.jpg" width="180">
My first thought was to use a small, inexpensive component in between the two
called an ADC - analog-to-digital converter - which would convert the sensor’s
signal into something that my rpi could use. I bought two of these when
I bought my sensor, and got as far as soldering header pins on them so that
I could seat them on a breadboard before realising that they were both
duds. Bummer!</p>

<p>All was not lost, however. In my bin of hardware toys was an <a href="https://store.arduino.cc/usa/arduino-uno-rev3">Arduino
Uno</a>,
which was a good fit for this project for a number of reasons. First, Arduinos
do have analog connections built right in, meaning I wouldn’t need any extra
components, I could plug the sensor straight into the Arduino. Second, while
the Arduino Uno doesn’t have a way to connect to the internet itself, it does have
a USB port (more on this later).</p>

<p>Arduinos run small snippets of code called Sketches, which are flashed into
their onboard memory by the tinkerer (that’s me) and can run continuously as long
as the board is receiving power. I plugged my sensor into my Arduino’s first analog pin (number 0), and so the sketch to read its output once every 100ms and write it
out to the serial port looks like
this:</p>

<pre><code>void setup() {
        Serial.begin(9600); // open serial port, set the baud rate as 9600 bps
}
void loop() {
        int val;
        val = analogRead(0); //connect sensor to Analog 0
        Serial.println(val); //print the value to serial port
        delay(100);
}
</code></pre>

<p>Something that might not make sense yet is this serial business. What’s
a serial port, and why is the sketch writing to it? Serial communciation is
a simple way for two computers (or components, or circuits) to talk to
each other, one bit at a time. The baud rate is how many bits are sent per
second, and both sides need to agree so they each know how to receive bits from the other. I found <a href="https://learn.sparkfun.com/tutorials/serial-communication/all">this article over on SparkFun</a> to
be a really great deep-dive on how all of this works. In the case of my Arduino, the serial
input and output can be done via pins (like how the sensor is hooked up) or,
handily, over USB (which, remember, is short for universal <em>serial</em> bus).</p>

<p>Plugging the Arduino into my Raspberry Pi via USB gets the signal from my
plant into Linux land, which opens up all kinds of possibilities for using the
data in code. In <a href="http://sarabee.github.io/2020/05/10/plant-tweets-part-2/">Part 2</a>, I’ll talk through how I explored just one of those
possibilities, hooking this mess up to Twitter.</p>

</div></div>]]>
            </description>
            <link>http://sarabee.github.io/2020/04/19/plant-tweets-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044512</guid>
            <pubDate>Tue, 10 Nov 2020 10:43:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Revisit Your First GitHub Commit Ever]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25044482">thread link</a>) | @amitmerchant
<br/>
November 10, 2020 | https://www.amitmerchant.com/your-first-commit-ever/ | <a href="https://web.archive.org/web/*/https://www.amitmerchant.com/your-first-commit-ever/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
              <h3>Revisit Your First GitHub Commit Ever!</h3>
            </p>
          </div></div>]]>
            </description>
            <link>https://www.amitmerchant.com/your-first-commit-ever/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044482</guid>
            <pubDate>Tue, 10 Nov 2020 10:37:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The myriad meanings of pwd in Unix systems]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25044131">thread link</a>) | @quyleanh
<br/>
November 10, 2020 | https://qmacro.org/2020/11/08/the-meaning-of-pwd-in-unix-systems/ | <a href="https://web.archive.org/web/*/https://qmacro.org/2020/11/08/the-meaning-of-pwd-in-unix-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Last week I ran a poll on Twitter to see what people considered with respect to the meaning of ‘pwd’ in Unix and Linux systems. The results were varied, for perhaps good reason.</em></p>

<p>At the end of Oct 2020 I ran a <a href="https://twitter.com/qmacro/status/1322567992551624705">brief poll on Twitter</a>, on which 82 people voted. Here’s that poll, and the results. They’re quite mixed, which at first might seem surprising. But there are reasons for that, as we’ll find out.</p>

<p><img src="https://qmacro.org/content/images/2020/11/twitter-poll-pwd.png" alt="Poll on Twitter: &quot;Fun Saturday afternoon shell poll. In Unix (and Linux), what do you think the P in $PWD (or pwd) stand for?&quot;"></p>

<p><strong>Print working directory</strong></p>

<p>The most popular option was “print working directory”. At first sight it seems logical: “print out the current working directory, i.e. where I am right now”. Moreover, the description in various versions of the manual for <code>pwd</code> help to drive home that notion. Typically we see sentences like “<a href="https://linux.die.net/man/1/pwd">print name of current/working directory</a>” or “<a href="https://www.mankier.com/1/pwd">print the current directory</a>”.</p>

<p>But there are lots of commands that print stuff, and are described in that way too. Take the <code>id</code> command. Here’s what one man page says: “<a href="https://man7.org/linux/man-pages/man1/id.1.html">print real and effective user and group IDs</a>”. There’s “print” again. But the command isn’t <code>pid</code>, it’s <code>id</code>. When you think about it, many, many commands in Unix send information to STDOUT, i.e. to the terminal. That’s sort of the point of many of them.</p>

<p>This time arguably only superficially definitive, it would seem, the Wikipedia entry states, on the <a href="https://en.wikipedia.org/wiki/Pwd">page for <code>pwd</code></a>: “the pwd command (print working directory) writes the full pathname of the current working directory to the standard output”. As if to underline the hopeful authority of this statement, there are five (!) footnotes that supposedly link to resources that back this up.</p>

<p>Unfortunately, the first footnote points to a Wayback Machine copy of the <a href="https://web.archive.org/web/20050520231659/http://cm.bell-labs.com/7thEdMan/v7vol1.pdf">UNIX PROGRAMMERS MANUAL - Seventh Edition, Volume 1 - January, 1979</a>, wherein there are actually zero references to <code>pwd</code> being short for “print working directory”:</p>

<p><img src="https://qmacro.org/content/images/2020/11/programmers-manual-pwd.png" alt="excerpt from UNIX PROGRAMMERS MANUAL on pwd"></p>

<p>I don’t know about you, but this historic document carries more weight for me than other sources I’ve come across, and it only serves here to undermine the credibility of the Wikipedia entry.</p>

<p>The rest of the footnote links seem dubious at best, except for the one pointing to the <a href="https://www.gnu.org/software/coreutils/manual/coreutils.html#pwd-invocation">GNU Coreutils manual on pwd</a> which has it as “print working directory”. But everything else I’ve seen so far makes me think that this is a misunderstanding that has spread for obvious and innocent reasons. In addition, the one footnote in the Wikipedia page that is not used to back this claim up is a pointer to <a href="https://pubs.opengroup.org/onlinepubs/9699919799/utilities/pwd.html">The Open Group Base Specifications Issue 7, 2018 edition’s information on pwd</a>, which almost seems like it’s actually avoiding using the word “print” at all: “return working directory name” … “The pwd utility shall write to standard output an absolute pathname of the current working directory, which does not contain the filenames dot or dot-dot.”. Very specific, very not-print.</p>

<p>So I’m thinking that “print working directory” isn’t what <code>pwd</code> stands for. In fact, “print working directory” may be common to some man pages, but on this macOS machine, with its <a href="https://en.wikipedia.org/wiki/Berkeley_Software_Distribution">BSD</a> heritage, we have, instead: “pwd – return working directory name”. Moreover, it goes on to say “The pwd utility writes the absolute pathname of the current working directory to the standard output”.</p>

<p><strong>Pathname of working directory</strong></p>

<p>So perhaps it really is “pathname of working directory”. That would, at least to me, make more sense. Not only does it eschew the redundancy of “print”, it also is more specific about the output - if I’m in <code>/home/dja/</code> for example, then invoking pwd will tell me that, i.e. where I am, including the whole path, and not just <code>dja</code>:</p>



<p><strong>Process working directory</strong></p>

<p>As for the other options, I do favour “process working directory”, mostly because it makes a lot of sense to me; every process in Unix has the concept of a current working directory, and that’s exactly what I’m asking for when I’m in my shell process and enter <code>pwd</code> - there’s a part in the video <a href="https://youtu.be/hgFBRZmwpSM?t=165">Unix terminals and shells</a> that explains this very well.</p>

<p>I’d love to be able to point to some old Unix sources that definitively explain the answer, but unfortunately that search has come up with very little - the <code>pwd</code> source in both the <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V5/usr/source/s2/pwd.c">5th</a> and <a href="https://github.com/yisooan/unix-v6/blob/master/source/s2/pwd.c">6th</a> Editions of Unix shed no light on this whatsoever.</p>

<p><strong>Present working directory</strong></p>

<p>What about “present working directory”? Well, that option seems to have legs, in the form of the Korn shell. While <a href="https://northstar-www.dartmouth.edu/doc/solaris-forte/ipe-help/dbx/dbx88cc.html">one source</a> implies that the answer might well be “pathname of current working directory”, in that <code>pwd</code> just emits the value of the <code>$PWD</code> environment variable (and a variable called “print working directory” makes no sense at all) … it would seem that in ksh-land, at least, “present working directory” is what <code>pwd</code> represents. Take, for example, the <a href="https://osr507doc.xinuos.com/en/man/html.C/ksh.C.html">ksh man page</a> which states “PWD - The present working directory set by the cd command”.</p>

<p>There’s a ton of discussion, both direct and indirect, on this very question. Take for example these two entries in the Unix &amp; Linux Stack Exchange forum: <a href="https://unix.stackexchange.com/questions/399026/etymology-of-pwd">Etymology of $PWD</a> and <a href="https://unix.stackexchange.com/questions/174990/what-is-pwd-vs-current-working-directory">What is $PWD? (vs current working directory)</a>. Of course, perhaps the definitive answer will never be found, as computing history is nothing if not varied and prone to forking.</p>

<p><strong>Multics and print_wdir</strong></p>

<p>Talking of history, we could go further back to pre-Unix roots, in the form of Multics, which indirectly gave rise to Unix (originally “Unics”). In the <a href="https://multicians.org/multics-commands.html">list of Multics Commands</a>, we see, nestled amongst other similarly named commands, something that jumps out at us:</p>

<div><div><pre><code>print_mail (pm)	display mail in a mailbox
print_messages (pm)	display interactive messages in a mailbox
print_motd (pmotd)	display message of the day (source)
print_proc_auth (ppa)	display process's sensitivity level and compartments
print_request_types (prt)	display list of I/O daemon request types
print_search_paths (psp)	display search paths
print_search_rules (psr)	display ready messages
print_wdir (pwd)	display working directory
</code></pre></div></div>

<p>There’s <code>pwd</code>, and in fact, just like its sibling <code>pmotd</code>, for example, which is short for <code>print_motd</code>, it’s short for <code>print_wdir</code>. Now, given the context of the original poll being set to Unix and Linux, perhaps we must discount this information. But as someone who is fascinated with Unix history in general - how can I?</p>

<p>I guess there are few things to conclude. The history is rich and diverse, and maybe we’ll never know for sure. Perhaps, in fact, the answer will depend on whom we ask. In the grand scheme of things, it doesn’t really matter … but to those who delight in minutiae, it’s a fun topic worth exploring.</p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://qmacro.org/2020/11/08/the-meaning-of-pwd-in-unix-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044131</guid>
            <pubDate>Tue, 10 Nov 2020 09:30:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[More SaaS and less visibility = offboarding mess]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044123">thread link</a>) | @andrazrp
<br/>
November 10, 2020 | https://www.cleanshelf.com/resources/complete-offboarding-checklist/ | <a href="https://web.archive.org/web/*/https://www.cleanshelf.com/resources/complete-offboarding-checklist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-rpi-area=""><p><strong>Employee offboarding is back in the spotlight this year as workforce disruption, layoffs, and resignations unexpectedly hit. IT and HR leaders are swamped transitioning stay-at-home workers and managers. The amount of SaaS these workers use – some sanctioned and some not – adds complexity. Secure offboarding is critical. But companies can’t deprovision what they can’t see.</strong></p><p>Scroll down to preserve data security with our complete offboarding checklist and bonus offboarding insights.</p><p>Or you can hit one of the options below to jump straight to the section:</p><ul><li><a href="#offboarding-risks" "="">Employee offboarding risks</a></li><li><a href="#offboarding-checklist">Employee offboarding checklist</a></li><li><a href="#it-checklist">IT checklist for employee offboarding</a></li><li><a href="#bonus-insights">Bonus insights</a></li></ul><h2 id="offboarding-risks">Employee offboarding risks</h2><p>Information Week shares a sobering stat: <a href="https://www.darkreading.com/vulnerabilities---threats/50--of-ex-employees-can-still-access-corporate-apps/d/d-id/1329672" target="_blank" rel="noopener noreferrer">50% of ex-employees can still access corporate cloud applications</a>. Their findings, based on a study of five hundred IT decision-makers, indicate that few firms have adequate provisioning, deprovisioning, termination, and login management processes in place.</p><p>Notably, 20% of respondents report that “their failure to deprovision employees from corporate applications has contributed to a data breach at their organization.”</p><p>It is now common for companies to deprovision 20-30 licenses per employee, versus the usual four to five in years past, according to the report. But the reality might be worse.</p><p>Cleanshelf’s annual <a href="https://www.cleanshelf.com/resources/business-saas-spend-up-to-30-wasted-every-day/">State of Business SaaS Spend</a> report found that in 2019, the <strong>typical employee at a U.S. enterprise with 800 or more employees used 44 cloud applications</strong>. The companies themselves use licenses from 140 vendors on average. Because so few companies know what they actually own, up to $4 million (or nearly 30% of spend) is wasted yearly.</p><figure id="attachment_2116" aria-describedby="caption-attachment-2116"><a href="https://www.cleanshelf.com/resources/the-state-of-business-saas-spend-2019/"><img src="https://1t7st7202zsklkcbf3yj41y6-wpengine.netdna-ssl.com/wp-content/uploads/2020/07/30-percent-SaaS-Spend-Waste-in-2019-Shadow-2.jpg" alt="Enterprise SaaS Management platform Cleanshelf found that 30 percent of SaaS spend is wasted which poses one more reason to use it for IT termination." width="1368" height="866" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201368%20866'%3E%3C/svg%3E" data-lazy-src="https://1t7st7202zsklkcbf3yj41y6-wpengine.netdna-ssl.com/wp-content/uploads/2020/07/30-percent-SaaS-Spend-Waste-in-2019-Shadow-2.jpg"></a><figcaption id="caption-attachment-2116">Cleanshelf found that enterprises wasted almost 30% of all SaaS spend in 2019.</figcaption></figure><p>The implications of the unawareness is startling. Companies clearly underestimate the <a href="https://www.cleanshelf.com/resources/3-saas-risks-to-look-out-for-in-2020/">SaaS risks</a> and the amount of SaaS used by their employees. <strong>If IT doesn’t know what apps employees are using, how can they turn access off when staff turns over? They can’t.</strong></p><p>A recent <a href="https://gurucul.com/news/1-in-10-tech-employees-plan-to-steal-company-information-before-leaving-a-job" target="_blank" rel="noopener noreferrer">study</a> from Gurucul found 1 in 10 would take as much corporate information with them as possible when they left, while another 15% said they would delete files or change passwords.</p><p>Terminated employee access has financial, legal, and competitive implications.</p><ul><li>An ex-salesperson could access forecasts, contracts, and prospect lists.</li><li>Former operational or financial staff may have access to non-public revenue and performance data.</li><li>Engineers may maintain unauthorized access to code.</li></ul><h3>More SaaS + less visibility = offboarding mess</h3><p>The most complete offboarding workflow is still fragile when IT can’t see what cloud apps employees use. The process of identifying and deprovisioning should take seconds; not hours or days of accessing logs, verifying credit card records, and cross-referencing HR and vendor files to establish who has what. In many cases, these don’t reconcile anyway.</p><p>It’s now common – especially given today’s stay-at-home phenomena – for workers to buy SaaS on their personal cards and seek reimbursement. And beyond the data and compliance benefits, once companies have a full view of their licenses, they can thoughtfully re-deploy unused licenses elsewhere.</p><figure id="attachment_2116" aria-describedby="caption-attachment-2116"><a href="https://www.cleanshelf.com/product"><img src="https://1t7st7202zsklkcbf3yj41y6-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/cleanshelf-app-inventory.jpg" alt="Dashboard of a Cleanshelf's demo account showing app inventory" width="1368" height="866" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201368%20866'%3E%3C/svg%3E" data-lazy-src="https://1t7st7202zsklkcbf3yj41y6-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/cleanshelf-app-inventory.jpg"></a><figcaption id="caption-attachment-2116">With Cleanshelf, companies can have a full view of their licenses so they can thoughtfully re-deploy unused licenses elsewhere.</figcaption></figure><h2 id="offboarding-checklist">Employee offboarding checklist</h2><p>Establish a simple, repeatable, employee offboarding process with a focus on communication and security for the reasons mentioned above.</p><p>The offboarding process is divided into two sections. Steps from 1 and up to 4 are made to check off the general formalities, while step 5 is made for the IT department that will prevent potential security issues.</p><blockquote><p>“The off-boarding process is a step in the system, access, and data lifecycle process. The off-boarding process can be no more secure than the onboarding and control processes. If you properly authorize access to inventory, data, and authentication systems, you can make sure that access is removed.” by Timothy Fawcett, <a href="http://guernsey.us/cybersecurity" target="_blank" rel="noopener noreferrer">Guernsey</a> (Follow him on <a href="https://www.linkedin.com/in/timothy-fawcett/" target="_blank" rel="noopener noreferrer">LinkedIn</a>)</p></blockquote><h3><span>1.</span> Communicate employee’s exit</h3><p>Everyone in the team, their managers, and members should be notified of the employee's exit. This will give them the opportunity to thank the employee for their work.<br> If the employee was in a customer-facing position, let them know of the employee’s departure and who will take over the account.</p><h3><span>2.</span> Resolve paperwork</h3><p>Besides filing the employee’s termination or resignation letter, also file non-disclosure or non-compete agreements.</p><h3><span>3.</span> Finish payroll process</h3><p>Communicate with the payroll department to complete their final pay. Settle other requirements for Benefits, 401K, PTO Balance, Insurance, and Tax related forms.</p><h3><span>4.</span> Exit interview</h3><p>Conducting an open interview to receive honest feedback on what works and what not will eventually help you improve your work environment, leadership, and organization in general.</p><p>As you finish the formalities above it’s time to check-off the IT offboarding points to preserve data security in your enterprise.</p><h3 id="it-checklist"><span>5.</span> IT checklist for employee offboarding</h3><p><strong>Access and inventory control is a process, where the entire lifecycle is important for completeness.</strong></p><p>Below we compiled nine basic steps from the IT perspective where some will depend on the employee and what kind of data they were able to access.</p><p>We recommend full deprovisioning (Step 3) that starts with verifying every app an employee uses. Make sure to review license usage once accounts are deprovisioned (Step 9). This ensures consistent cost management.</p><ol><li><strong>Reclaim all assigned equipment</strong><br> Make someone responsible. If you’re not responsible for recovering the assets then make someone else do it. This way you can follow up and keep track of the assets as they return. Revoke all devices that are associated with company apps and not just a company laptop.</li><li><strong>Revoke access</strong><br> Revoke access to Identity Provider, Single-Sign-On and Production systems, and all internal user accounts to which the employee had access.</li><li><strong>Unassign SaaS or software licenses</strong> <span>(cross-reference in SaaS management tool)</span><br> Verify every app an employee used and deprovision accordingly. Pay attention to <a href="https://www.cleanshelf.com/resources/enterprise-saas-visibility-and-discovery/">shadow IT</a> as it is most often a missed step especially when offboarding employees. If you don’t control your data, you may not be aware of what access to remove.</li><li><strong>Perform a backup of user’s data</strong><br> Perform a complete backup of the user’s data. If you already have it saved and archived as part of your routine manage it according to your internal compliance policy.</li><li><strong>Take forensic images of computing devices</strong><br> High-risk organizations should take forensic images of computing devices, PCs, Phone, Email, etc. for any employee that is terminated for cause or has access to IP including customer lists. Having this data may prove essential if the employee disputes their termination.</li><li><strong>Disable access to email account</strong><br> Create an out-of-office message for email or forward employee’s emails to the superior or person responsible. Remove the email address from generic distribution lists and manage them according to your internal policy.</li><li><strong>Change passwords</strong><br> If there are any passwords that were shared between employees in the organization or department itself, require staff to change those to remove the potential risk of any unauthorized access.</li><li><strong>Update Credit Card payments</strong><br> If an employee leaving had a company credit card, make sure to uncover which SaaS services were paid with it so you don’t get any disturbances in services that would potentially mean loss of data or employee productivity.</li><li><strong>Optimize licensing plans</strong><br> As you offboard employees, the number of users that were initially planned and signed to use SaaS in contracts is now changed. Make sure to optimize your licensing plans when possible (<a href="https://www.cleanshelf.com/resources/saas-negotiations-and-how-understanding-pricing-will-help-you/">negotiate</a>, if needed).</li></ol><figure id="attachment_2116" aria-describedby="caption-attachment-2116"><a href="https://www.cleanshelf.com/product"><img src="https://1t7st7202zsklkcbf3yj41y6-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/cleanshelf-reduce-licenses.jpg" alt="Cleanshel's demo account shows Salesforce CRM SaaS spend by department and it's utilization based on the usage." width="1368" height="866" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201368%20866'%3E%3C/svg%3E" data-lazy-src="https://1t7st7202zsklkcbf3yj41y6-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/cleanshelf-reduce-licenses.jpg"></a><figcaption id="caption-attachment-2116">Uncover the SaaS service utilization and optimize licensing plans accordingly.</figcaption></figure><h2 id="bonus-insights">Bonus insights for effective employee offboarding</h2><p>Our team has helped dozens of companies manage the software side of offboarding. Once you complete the initial IT termination checklist here are few additional insights to improve the experience:</p><ul><li><strong>Be notified in advance</strong><br> IT departments should be <a href="https://securityboulevard.com/2019/07/assessing-the-risk-of-the-former-employee/" target="_blank" rel="noopener noreferrer">notified in advance</a>, when applicable, of an employee termination. This allows preparation for backup, restoration and preservation of any corporate data the employee was responsible for managing.</li><li><strong>Don’t close only tools with active accounts</strong><br> Don’t only close out SaaS tools for which the employee has an active account. Review the tools they’ve used in the past. Long-running sessions or API access tokens may still be in place.</li><li><strong>Pay attention to remote access software</strong><br> Double check that no remote access software remains on company workstations. These ‘backdoors’ – through logging into a VPN or using a remote desktop – are common given remote IT support trends.</li><li><strong>Reassess SaaS contracts</strong><br> Reassess licensing models for popular cloud applications after staff departures. This is most relevant in cases where layoffs hit a department that uses speciality software. For example, if the marketing team loses staff, move off an enterprise license agreement (ELA) and <a href="https://www.cleanshelf.com/resources/five-ideas-for-successful-saas-vendor-negotiation/">negotiate SaaS contract</a> to pay per license for applications like Marketo, Intercom, Buffer, or Mailchimp.</li><li><strong>Double check vulnerable areas</strong><br> Focus on vulnerable areas. Unwinding cloud office suite access (for G-Suite and Office 365) seems simple but may trap even vigilant admins. Double-check: are IMAP/POP sync settings disabled? As well, verify that no automatic email forwarded remains. Also, delete or reassign email aliases. For example, your customer support employee may have received an email at their “name@company.com” domain, while <i>additionally</i> receiving email from “support@company.com” too.</li><li><strong>Review integration logs</strong><br> Review integration logs of business essential tools. A tool like Slack or Zapier may have integrations dependent on a user’s account staying active. First, understand what applications a former employee used, then assign changes to reduce the likelihood of disruption.</li></ul><p>The stakes for effective …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cleanshelf.com/resources/complete-offboarding-checklist/">https://www.cleanshelf.com/resources/complete-offboarding-checklist/</a></em></p>]]>
            </description>
            <link>https://www.cleanshelf.com/resources/complete-offboarding-checklist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044123</guid>
            <pubDate>Tue, 10 Nov 2020 09:28:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Automation Part 4: Who made it, why, and in what context?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25044097">thread link</a>) | @nonoesp
<br/>
November 10, 2020 | https://sketch.nono.ma/who-made-it-why-and-in-what-context | <a href="https://web.archive.org/web/*/https://sketch.nono.ma/who-made-it-why-and-in-what-context">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    <div>

    
          <svg data-name="sketch.nono.ma" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 600 153"><defs></defs><title>Sketch.Nono.MA</title><path d="M182.51,57.42v1.29a8.6,8.6,0,0,0,.48,3.47,1.85,1.85,0,0,0,1.82,1c1.34,0,2-1.05,2-3.14a8,8,0,0,0-.12-1.42,6.27,6.27,0,0,0-.44-1.38,11.32,11.32,0,0,0-.84-1.52c-.36-.54-.81-1.17-1.36-1.9l-2.22-3.23c-.71-1-1.3-1.92-1.77-2.72a18.44,18.44,0,0,1-1.13-2.28,10,10,0,0,1-.61-2,11.93,11.93,0,0,1-.17-2,6.9,6.9,0,0,1,1.79-5,6.43,6.43,0,0,1,4.84-1.85,6,6,0,0,1,3.86,1.23,5.77,5.77,0,0,1,2,3.43c.06.28.11.53.14.74a6.16,6.16,0,0,1,.07.69c0,.25,0,.57,0,1v1.57l-4.4.43c0-.83,0-1.42,0-1.79a6.37,6.37,0,0,0-.12-1.07c-.16-1.33-.78-2-1.86-2-1.24,0-1.86,1-1.86,3a9.55,9.55,0,0,0,.07,1.26,4.32,4.32,0,0,0,.39,1.21,16.05,16.05,0,0,0,1,1.66l1.77,2.66,2.27,3.23a21.45,21.45,0,0,1,2.4,4.58,12.66,12.66,0,0,1,.84,4.34,6.61,6.61,0,0,1-1.7,4.89,6.53,6.53,0,0,1-4.85,1.71,6.34,6.34,0,0,1-6.55-4.73,14.33,14.33,0,0,1-.29-3.26v-.83a8.51,8.51,0,0,1,.05-.88Z"></path><path d="M211.28,66.84h-4.69l-3.33-15L201.32,57v9.8h-4.54V35.11h4.54V47.05l4.4-11.94h4.6l-4.07,10.71Z"></path><path d="M226.51,35.11V39.3h-6.38v8.8h4.45v4.18h-4.45V62.65h6.77v4.19H215.59V35.11Z"></path><path d="M234.59,39.3h-4.21V35.11h13.15V39.3h-4.4V66.84h-4.54Z"></path><path d="M259.92,55.52c0,.85.06,1.51.08,2s0,.91,0,1.36q0,8.46-6.53,8.46-6.33,0-6.33-7.61V42.25q0-7.61,6.33-7.61Q260,34.64,260,43V44a13.8,13.8,0,0,1-.1,1.45h-4.54a12,12,0,0,0,.09-1.21v-1a10.26,10.26,0,0,0-.4-3.54,1.54,1.54,0,0,0-1.58-.93,1.44,1.44,0,0,0-1.43.69,6.93,6.93,0,0,0-.36,2.77V59.67a6.93,6.93,0,0,0,.36,2.77,1.44,1.44,0,0,0,1.43.69,1.56,1.56,0,0,0,1.56-.88,9,9,0,0,0,.42-3.36c0-.53,0-1,0-1.49s0-1.09-.07-1.88Z"></path><path d="M270.13,52.28V66.84h-4.55V35.07h4.55v13h3.57v-13h4.55V66.84H273.7V52.28Z"></path><path d="M283.91,62.08h4.54v4.76h-4.54Z"></path><path d="M309.34,66.84h-4.55l-5.22-16.65V66.84H295V35.11h3.85l5.91,18.7V35.11h4.55Z"></path><path d="M328.34,58.75c0,1,0,1.73,0,2.33s-.08,1.12-.14,1.55a4.63,4.63,0,0,1-.29,1.09,7.46,7.46,0,0,1-.53,1,5.56,5.56,0,0,1-2.25,1.92,7.4,7.4,0,0,1-6.24,0,5.56,5.56,0,0,1-2.25-1.92,7.46,7.46,0,0,1-.53-1,5.11,5.11,0,0,1-.31-1.09,10.43,10.43,0,0,1-.15-1.55c0-.6,0-1.38,0-2.33V43.15c0-.95,0-1.73,0-2.33a10.28,10.28,0,0,1,.15-1.54,5.21,5.21,0,0,1,.31-1.1,7.39,7.39,0,0,1,.53-1,5.63,5.63,0,0,1,2.25-1.88,7.4,7.4,0,0,1,6.24,0,5.63,5.63,0,0,1,2.25,1.88,7.39,7.39,0,0,1,.53,1,4.72,4.72,0,0,1,.29,1.1c.06.42.11.94.14,1.54s0,1.38,0,2.33ZM323.8,41.38a3.47,3.47,0,0,0-.43-2,1.6,1.6,0,0,0-1.41-.6,1.62,1.62,0,0,0-1.39.6,3.29,3.29,0,0,0-.45,2V60.57a3.51,3.51,0,0,0,.42,2,2,2,0,0,0,2.81,0,3.33,3.33,0,0,0,.45-2Z"></path><path d="M348.84,66.84H344.3l-5.23-16.65V66.84h-4.54V35.11h3.85l5.92,18.7V35.11h4.54Z"></path><path d="M367.84,58.75c0,1,0,1.73,0,2.33s-.08,1.12-.14,1.55a4.63,4.63,0,0,1-.29,1.09,7.46,7.46,0,0,1-.53,1,5.56,5.56,0,0,1-2.25,1.92,7.4,7.4,0,0,1-6.24,0,5.56,5.56,0,0,1-2.25-1.92,7.46,7.46,0,0,1-.53-1,5.11,5.11,0,0,1-.31-1.09,10.43,10.43,0,0,1-.15-1.55c0-.6,0-1.38,0-2.33V43.15c0-.95,0-1.73,0-2.33a10.28,10.28,0,0,1,.15-1.54,5.21,5.21,0,0,1,.31-1.1,7.39,7.39,0,0,1,.53-1,5.63,5.63,0,0,1,2.25-1.88,7.4,7.4,0,0,1,6.24,0,5.63,5.63,0,0,1,2.25,1.88,7.39,7.39,0,0,1,.53,1,4.72,4.72,0,0,1,.29,1.1c.06.42.11.94.14,1.54s0,1.38,0,2.33ZM363.3,41.38a3.38,3.38,0,0,0-.43-2,1.6,1.6,0,0,0-1.41-.6,1.62,1.62,0,0,0-1.39.6,3.29,3.29,0,0,0-.45,2V60.57a3.42,3.42,0,0,0,.43,2,1.62,1.62,0,0,0,1.41.59,1.64,1.64,0,0,0,1.39-.59,3.33,3.33,0,0,0,.45-2Z"></path><path d="M374.37,62.08h4.55v4.76h-4.55Z"></path><path d="M397.19,35.11h5.42V66.84h-3.87V44.44L395,66.84H393l-3.77-22.4v22.4h-3.77V35.11h5.32L394,50.9Z"></path><path d="M412.62,66.84h-4.36l4.4-31.73h5.81l4.2,31.73h-4.4l-.82-7.14h-4.06Zm2.8-26-1.55,14.7H417Z"></path><path d="M96.84,97.69c-1.56,0-2.5.76-2.5,1.8s1.21,1.63,2.34,1.9l1.3.32c2.08.5,4,1.59,4.06,4s-1.93,4.09-5.24,4.09-5.26-1.54-5.36-4.29H93.9c.1,1.45,1.31,2.15,2.88,2.15s2.75-.79,2.76-2-1-1.53-2.48-1.91l-1.58-.41c-2.27-.58-3.68-1.72-3.68-3.71,0-2.44,2.17-4.07,5.07-4.07s4.93,1.65,5,4H99.44C99.32,98.38,98.33,97.69,96.84,97.69Z"></path><path d="M103.78,95.76h2.44v7.61h.17l3.73-4.16H113l-4,4.47,4.25,5.89h-2.93l-3.16-4.43-.9,1v3.48h-2.44Z"></path><path d="M113.33,104.45c0-3.19,1.94-5.37,4.91-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C115.24,109.77,113.33,107.7,113.33,104.45Zm7.3-1a2.3,2.3,0,0,0-2.36-2.43,2.5,2.5,0,0,0-2.51,2.43Z"></path><path d="M129.83,101.1h-2v5.36c0,1,.49,1.2,1.11,1.2a3.12,3.12,0,0,0,.71-.1l.41,1.91a4.8,4.8,0,0,1-1.43.24c-1.84.06-3.26-.9-3.24-2.85V101.1h-1.47V99.21h1.47V96.73h2.44v2.48h2Z"></path><path d="M131,104.43c0-3.16,1.91-5.35,5-5.35,2.53,0,4.28,1.47,4.45,3.72H138a2,2,0,0,0-2.09-1.75c-1.5,0-2.51,1.25-2.51,3.34s1,3.39,2.51,3.39A2,2,0,0,0,138,106h2.33c-.18,2.2-1.84,3.74-4.44,3.74C132.82,109.77,131,107.57,131,104.43Z"></path><path d="M144.42,109.57H142V95.76h2.39V101h.12a3,3,0,0,1,3.09-1.89c2.15,0,3.56,1.39,3.56,3.9v6.59H148.7v-6.22a2,2,0,0,0-2-2.21,2.15,2.15,0,0,0-2.24,2.36Z"></path><path d="M152.8,104.45c0-3.19,1.94-5.37,4.91-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C154.71,109.77,152.8,107.7,152.8,104.45Zm7.3-1a2.3,2.3,0,0,0-2.36-2.43,2.49,2.49,0,0,0-2.51,2.43Z"></path><path d="M170.09,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c2,.43,2.9,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.15-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.45-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.69-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M178,106.66c0-2.33,1.92-2.93,3.93-3.15,1.83-.19,2.57-.22,2.57-.93v0c0-1-.62-1.59-1.76-1.59a2.06,2.06,0,0,0-2.12,1.31l-2.28-.32c.54-1.89,2.21-2.86,4.39-2.86,2,0,4.21.82,4.21,3.56v6.93h-2.35v-1.42h-.08a3.21,3.21,0,0,1-3,1.63C179.52,109.78,178,108.7,178,106.66Zm6.5-.8v-1.23a7.34,7.34,0,0,1-2.24.51c-1.09.15-1.9.55-1.9,1.48s.72,1.37,1.74,1.37A2.21,2.21,0,0,0,184.53,105.86Z"></path><path d="M191.5,109.57h-2.45V99.21h2.34V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59H195.7v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M199.83,104.41c0-3.46,1.89-5.33,4.28-5.33a3.08,3.08,0,0,1,3,1.84h.1V95.76h2.45v13.81h-2.4v-1.63h-.15a3.13,3.13,0,0,1-3,1.81C201.66,109.75,199.83,107.82,199.83,104.41Zm7.39,0c0-2-.86-3.31-2.44-3.31s-2.46,1.38-2.46,3.31.85,3.36,2.46,3.36S207.22,106.4,207.22,104.39Z"></path><path d="M222.15,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c1.95.43,2.9,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.14-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.45-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.7-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M231.42,101.1h-2v5.36c0,1,.49,1.2,1.11,1.2a3.12,3.12,0,0,0,.71-.1l.41,1.91a4.8,4.8,0,0,1-1.43.24c-1.84.06-3.25-.9-3.24-2.85V101.1h-1.47V99.21h1.47V96.73h2.44v2.48h2Z"></path><path d="M232.53,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S232.53,107.64,232.53,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.51,1.52-2.51,3.42.83,3.39,2.51,3.39S240,106.32,240,104.43Z"></path><path d="M244.15,99.21h2.36v1.73h.11a2.6,2.6,0,0,1,2.56-1.88,5.79,5.79,0,0,1,.87.07v2.25a4.54,4.54,0,0,0-1.13-.14,2.21,2.21,0,0,0-2.33,2.24v6.09h-2.44Z"></path><path d="M251.11,96.42a1.42,1.42,0,1,1,1.42,1.32A1.38,1.38,0,0,1,251.11,96.42Zm.19,2.79h2.44v10.36H251.3Z"></path><path d="M255.43,104.45c0-3.19,1.94-5.37,4.9-5.37,2.55,0,4.74,1.6,4.74,5.23v.75h-7.22a2.55,2.55,0,0,0,2.64,2.81,2.17,2.17,0,0,0,2.2-1.33l2.28.25c-.44,1.8-2.09,3-4.51,3C257.34,109.77,255.43,107.7,255.43,104.45Zm7.3-1a2.31,2.31,0,0,0-2.36-2.43,2.48,2.48,0,0,0-2.51,2.43Z"></path><path d="M272.72,102.19a1.82,1.82,0,0,0-1.91-1.29c-1,0-1.8.48-1.79,1.18s.41,1,1.46,1.21l1.77.37c2,.43,2.91,1.33,2.92,2.81,0,2-1.84,3.3-4.43,3.3s-4.14-1.12-4.44-3l2.38-.23a1.85,1.85,0,0,0,2.05,1.41c1.16,0,1.93-.53,1.93-1.24s-.44-1-1.39-1.18l-1.77-.37c-2-.41-2.92-1.41-2.91-2.92,0-1.92,1.69-3.14,4.18-3.14s3.84,1.12,4.17,2.87Z"></path><path d="M281.25,95.76h2.44v5.16h.1a3.09,3.09,0,0,1,3-1.84c2.4,0,4.28,1.87,4.28,5.33s-1.83,5.34-4.27,5.34a3.14,3.14,0,0,1-3-1.81h-.14v1.63h-2.4Zm4.83,12c1.61,0,2.46-1.42,2.46-3.36s-.83-3.31-2.46-3.31-2.44,1.3-2.44,3.31S284.52,107.75,286.08,107.75Z"></path><path d="M292.27,113.33l.57-2c1.07.31,1.77.22,2.23-.92l.25-.66-3.76-10.58h2.59l2.39,7.83h.1l2.4-7.83h2.59l-4.18,11.71a3.65,3.65,0,0,1-3.64,2.68A4.33,4.33,0,0,1,292.27,113.33Z"></path><path d="M318.74,109.57h-2.23l-6.5-9.41h-.12v9.41h-2.5V95.76h2.24l6.5,9.41h.12V95.76h2.49Z"></path><path d="M320.53,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S320.53,107.64,320.53,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.5,1.52-2.5,3.42.82,3.39,2.5,3.39S328,106.32,328,104.43Z"></path><path d="M334.59,109.57h-2.44V99.21h2.33V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.56,1.41,3.55,3.9v6.59H338.8v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M342.91,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.92,5.34-5,5.34S342.91,107.64,342.91,104.43Zm7.45,0c0-1.9-.82-3.42-2.48-3.42s-2.5,1.52-2.5,3.42.83,3.39,2.5,3.39S350.36,106.32,350.36,104.43Z"></path><path d="M362,95.76l4.1,10h.16l4.1-10h3.06v13.81h-2.4v-9.49h-.13l-3.81,9.45h-1.8l-3.81-9.47h-.13v9.51H359V95.76Z"></path><path d="M375.47,106.66c0-2.33,1.92-2.93,3.93-3.15,1.83-.19,2.56-.22,2.56-.93v0c0-1-.62-1.59-1.75-1.59a2.06,2.06,0,0,0-2.12,1.31l-2.28-.32c.54-1.89,2.21-2.86,4.39-2.86,2,0,4.21.82,4.21,3.56v6.93h-2.35v-1.42H382a3.21,3.21,0,0,1-3,1.63C377,109.78,375.47,108.7,375.47,106.66Zm6.5-.8v-1.23a7.41,7.41,0,0,1-2.24.51c-1.09.15-1.91.55-1.91,1.48s.73,1.37,1.75,1.37A2.21,2.21,0,0,0,382,105.86Z"></path><path d="M386.49,99.21h2.37v1.73H389a2.58,2.58,0,0,1,2.55-1.88,5.92,5.92,0,0,1,.88.07v2.25a4.54,4.54,0,0,0-1.13-.14,2.21,2.21,0,0,0-2.34,2.24v6.09h-2.44Z"></path><path d="M399.47,101.1h-2.05v5.36c0,1,.5,1.2,1.11,1.2a3.33,3.33,0,0,0,.72-.1l.41,1.91a4.88,4.88,0,0,1-1.44.24c-1.83.06-3.25-.9-3.24-2.85V101.1h-1.47V99.21H395V96.73h2.44v2.48h2.05Z"></path><path d="M401.13,99.21h2.45v10.36h-2.45Zm1.8-4.44h2.39l-2.07,3.08h-1.83Z"></path><path d="M408.15,109.57h-2.44V99.21H408V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59h-2.44v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M416.47,104.45c0-3.19,1.93-5.37,4.9-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C418.38,109.77,416.47,107.7,416.47,104.45Zm7.29-1A2.3,2.3,0,0,0,421.4,101a2.5,2.5,0,0,0-2.51,2.43Z"></path><path d="M427.66,108l5.34-6.7v-.08h-5.17v-2H436v1.67l-5.09,6.58v.09h5.26v2h-8.5Z"></path><path d="M441.63,109.57l4.87-13.81h3.08l4.87,13.81h-2.67l-1.14-3.4h-5.2l-1.14,3.4Zm8.33-5.41-1.87-5.57H448l-1.87,5.57Z"></path><path d="M458.24,109.57h-2.45V95.76h2.45Z"></path><path d="M459.92,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S459.92,107.64,459.92,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.5,1.52-2.5,3.42.82,3.39,2.5,3.39S467.37,106.32,467.37,104.43Z"></path><path d="M474,109.57h-2.44V99.21h2.33V101H474a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59h-2.44v-6.22a2,2,0,0,0-2-2.21A2.12,2.12,0,0,0,474,103.5Z"></path><path d="M488.7,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c1.95.43,2.91,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.14-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.44-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.7-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M492.35,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S492.35,107.64,492.35,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.51,1.52-2.51,3.42.83,3.39,2.51,3.39S499.8,106.32,499.8,104.43Z"></path></svg>
    
    

            <p><img src="https://nono.imgix.net/img/u/sketch-191102-cordoba-las-ramblas-alfar-torres-ferreras-ceramic-artisan.jpg?auto=format%2Ccompress&amp;ixlib=php-3.3.0&amp;w=2500"></p>

    <p>Andy Warhol's artworks have sold for millions of dollars. His most famous works—think of Campbell's Soup Cans (1962) and Marylin Diptych (1962)—are limited edition paintings. Campbell's Soup Cans' piece consists of 32 images produced over five months<sup id="fnref:wikipedia-warhol-andy"><a href="#fn:wikipedia-warhol-andy" role="doc-noteref">1</a></sup>, and Marilyn Monroe's artwork consists of 50 portraits.<sup id="fnref:wikipedia-warhol-marilyn"><a href="#fn:wikipedia-warhol-marilyn" role="doc-noteref">2</a></sup></p>
<p>After hand-painting thirty-two soup cans by hand, Warhol moved to photo-silkscreen, a printmaking technique originally invented for commercial use that allowed Warhol and other artists to create reproductions of the same artwork using a silkscreen.<sup id="fnref:warhol-moma-learning"><a href="#fn:warhol-moma-learning" role="doc-noteref">3</a></sup></p>
<p>Warhol painted the soup cans with acrylic paint. Each canvas corresponded to a soup variety sold by Campbell's back in the 1960s.</p>
<p>Screen printing speeds up the reproduction of an artwork. Once the silkscreen is ready, colors are applied, one by one, using a squeegee to push the ink through the mesh screen<sup id="fnref:dickblick-screen-printing"><a href="#fn:dickblick-screen-printing" role="doc-noteref">4</a></sup>, either by hand or automatically with a machine, a process being used at the time to mass-produce advertisements.<sup id="fnref:warhol-moma-learning__2"><a href="#fn:warhol-moma-learning" role="doc-noteref">3</a></sup></p>
<p>"I don't think art should be only for the select few," Warhol claimed, "I think it should be for the mass of the American people."</p>
<p>Nowadays, we could argue this vision is a reality. Large corporations and artisans deploy a wide range of mediums to automate what used to be done by hand, producing goods en masse, lessening their price and uniqueness while improving its quality and availability. You can buy a ready-to-hang print of Vang Goh's&nbsp;<em>The Starry Night</em>&nbsp;at IKEA for $49.99 while the Museum of Modern Art in Midtown Manhattan shields and exhibits the original painting.</p>
<p>Contrary to his statement, Warhol created artwork for the selected few that could pay for it. In 2007, a 1964&nbsp;<em>Large Campbell's Soup Can</em>&nbsp;sold for $7.4 million, and&nbsp;<em>Silver Car Crash</em>&nbsp;sold for $105.4 million in 2013.</p>
<p>Aesthetics and taste aside, it's all about the story behind each piece.</p>
<p>Who made it, why, and in what context?</p>
<!-- References -->



  </div>



  </div><div>
      <p><img src="https://nono.imgix.net/folio/images/veil.gif" data-src="https://nono.imgix.net/img/u/sketch-nono-ma-logo.svg"></p>
<hr>
<p>
My sketches and stories, in&nbsp;your&nbsp;inbox.
</p>

<p><span>One email per week. No spam ever.</span></p>

<p><img src="https://sketch.nono.ma/img/u/profile-nono-ma-sketch.jpg" alt="Pencil sketch of Nono Martínez Alonso.">
</p>


      </div></div>]]>
            </description>
            <link>https://sketch.nono.ma/who-made-it-why-and-in-what-context</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044097</guid>
            <pubDate>Tue, 10 Nov 2020 09:24:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Low Hanging Fruits in Front End Performance Optimization]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044079">thread link</a>) | @pawurb
<br/>
November 10, 2020 | https://pawelurbanek.com/frontend-performance-optimization | <a href="https://web.archive.org/web/*/https://pawelurbanek.com/frontend-performance-optimization">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    <p><img title="Web apps frontend performance is represented by grapes Photo by Amos Bar-Zeev on Unsplash" alt="Web apps frontend performance is represented by grapes Photo by Amos Bar-Zeev on Unsplash" data-src="https://pawelurbanek.com/assets/frontend-optimization-fruits-6ff2f8bc957fe4e1142ab67c3a460ce9dc962eba5b1dc2f10c5125292c558b37.jpg" src="https://pawelurbanek.com/assets/frontend-optimization-fruits-thumb-90ff9c113ed86f833b4e2fa0bbe34e130f2ee5871d3b08aa033fe1e1cbc0e7ad.jpg">
    </p>
  

  

  

  <p>I conduct Rails performance audits for a living. Clients usually approach me with a request to speed up the backend, i.e., optimize the bottleneck API endpoint or tune the database queries. After the initial research, it often turns out that tweaking the frontend will make a better impact on the perceivable performance than fine-tuning the backend.</p>

<p>In this blog post, I describe the often-overlooked techniques that can significantly improve your web app’s overall performance.</p>

<p>These tips apply to all the web technologies like Ruby on Rails, NodeJS, Python Django, or Elixir Phoenix. It does not matter if you render an HTML or serve an API consumed by the JavaScript SPA framework. It all comes down to transferring bytes over the HTTP protocol. Frontend performance optimization is all about making this process as efficient as possible.</p>

<h2 id="why-is-frontend-performance-critical-for-your-websites-success">Why is frontend performance critical for your website’s success?</h2>

<p>I guess that developers often disregard the frontend performance because it doesn’t directly affect the infrastructure costs. Rendering the unoptimized website is offloaded to the visitor’s desktop or mobile device and cannot be measured using backend monitoring tools.</p>

<p>Developers usually work on top-notch desktop computers with a high-speed internet connection. They do not experience poor performance themselves. The UX of visiting your landing page on a 15 inch Mac Book Pro with a fiber connection cannot be compared to an old Android device on a shaky 3G network.</p>

<p>A typical web app issues dozens of requests on initial load. Only a few are backend-related, i.e., website HTML, API calls, etc. The majority of requests are static assets, JavaScript libraries, images. Fine-tuning the frontend-related requests will give a much greater return than shaving a couple of hundered milliseconds off a database query.</p>

<p>Google Bot measures the performance of your website, and it directly affects the SEO rating. Since <a href="https://developers.google.com/search/mobile-sites/mobile-first-indexing" target="_blank" rel="noopener noreferrer">July 2019</a>, Google Bot is using a <em>“Mobile first”</em> approach to assessing your website.</p>

<p>You might not care about frying the CPU and wasting the bandwidth of your mobile users. Maybe landing a sweet spot in Google search results should convince you to focus on your frontend performance?</p>

<h2 id="test-in-your-clients-shoes">Test in your client’s shoes</h2>

<p><em>“If you want to write fast websites, use slow internet.”</em>.</p>

<p>You should regularly throttle the internet speed during the development process to experience first-hand how your app will behave for most users.</p>

<p>On macOS, you can use the <a href="https://nshipster.com/network-link-conditioner/" target="_blank" rel="noopener noreferrer">Network Link Conditioner</a> to do it:</p>

<p><img alt="Simulate mobile network on a desktop computer" title="Simulate mobile network on a desktop computer" loading="lazy" src="https://pawelurbanek.com/assets/3g-network-performance-4273c3bd62edbdaddfdc36d7dad126747f3d69804a7ce8c1227cd8f96ff0a1ed.png"></p>

<p>Also, both Firefox and Chrome developer tools offer the option to throttle the internet speed in the <strong>Network</strong> tab:</p>

<p><img alt="Chrome network throttle setting" title="Chrome network throttle setting" loading="lazy" src="https://pawelurbanek.com/assets/chrome-network-throttle-ed2b0e3cb5163dbf3d6fe89601bd32c072af9a2b7146e82d8004f8e536ca208d.png"></p>

<p>Chrome network throttle</p>

<p><img alt="Firefox network throttle setting" title="Firefox network throttle setting" loading="lazy" src="https://pawelurbanek.com/assets/firefox-network-throttle-d11d6b54034fff903c4cc721f05a66747904fd72d3d9760ab7f1141491875434.png"></p>

<p>Firefox network throttle</p>


<p>Maybe the internal demos of the new features should also be done on the throttled network? Everyone in the company should have the chance to see how the app really works for most users.</p>

<h2 id="reconnaissance">Reconnaissance</h2>

<p>Discovering frontend issues is usually more straightforward than backend ones. You don’t even need admin access to the website. By definition, the frontend issues are in the <em>frontend</em>. You can scan and diagnose every website out there. I use the following tools to perform the initial scan:</p>

<p><a href="https://www.fastorslow.com/" target="_blank" rel="noopener noreferrer">FastOrSlow</a></p>

<p><a href="https://www.webpagetest.org/" target="_blank" rel="noopener noreferrer">WebPageTest</a></p>

<p><a href="https://developers.google.com/speed/pagespeed/insights/" target="_blank" rel="noopener noreferrer">Google PageSpeed Insights</a></p>

<p><a href="https://github.com/GoogleChrome/lighthouse" target="_blank" rel="noopener noreferrer">GoogleChrome lighthouse</a></p>

<p>There’s no reason why ANY website shouldn’t score top on each of those tools. Read on if your score is anywhere below 90%.</p>

<p><img alt="Abot for Slack FastOrSlow score" title="Abot for Slack FastOrSlow score" loading="lazy" src="https://pawelurbanek.com/assets/abot-fastorslow-28336ad9b7b74849a6a1d85a1ad269be81dd6288a960ee3b3ecbe69e6cf6b6a7.png"></p>

<p><img alt="Abot for Slack WebPageTest score" title="Abot for Slack WebPageTest score" loading="lazy" src="https://pawelurbanek.com/assets/abot-webpagetest-e33807bf28e738ced4aa16f48cdf17e44836a986b283aca9d673c8504ff045fa.png"></p>

<p><img alt="Abot for Slack Google speed score" title="Abot for Slack FastOrSlow score" loading="lazy" src="https://pawelurbanek.com/assets/abot-googlespeed-03d18ebbc637cce72357f44e3ed65e1cf60062e633df52bafc2eb178e0cca7ac.png"></p>

<p>The <a href="https://abot.app/" target="_blank">Abot landing page</a> is a dynamic Rails website getting top performance rating</p>





<h2 id="client-side-caching">Client-side caching</h2>

<p>Correctly configuring client-side caching is the most critical frontend optimization. I’ve seen it misconfigured in multiple production apps so far. <a href="https://github.com/webpack/webpack" target="_blank" rel="noopener noreferrer">Webpack</a> comes with a great mechanism to easily leverage client-side caching, i.e., <em>MD5 digest</em>. The production assets generation process must be configured to append the <em>MD5 digest</em> tag to the filename.</p>

<p>It means that in the production environment, the <code>application.js</code> file becomes <code>application-5bf4f97...95c2147.js</code>. The random suffix is generated based on the file contents, so it is guaranteed to change if the file changes. You must add the correct <code>cache-control</code> header to make sure that once downloaded, the file will persist in the browser cache:</p>

<figure><pre><code data-lang="bash">cache-control: public, max-age<span>=</span>31536000, immutable</code></pre></figure>

<p>The <code>immutable</code> parameter ensures that cache is not cleared when the user explicitly refreshes the website on the Chrome browser.</p>

<p>If you’re using NGINX as reverse proxy you can use the following directive:</p>

<figure><pre><code data-lang="nginx"><span>location</span> <span>~</span><span>*</span> <span>\</span><span>.(?:ico|css|js|gif|jpe?g|png|woff2)</span>$ <span>{</span>
  <span>add_header</span> <span>Cache-Control</span> <span>"public,</span> <span>max-age=31536000,</span> <span>immutable"</span><span>;</span>
  <span>try_files</span> <span>$uri</span> <span>=</span><span>404</span><span>;</span>
<span>}</span></code></pre></figure>

<p>I’ve seen many apps using <code>Etag</code> and <code>Last-Modified</code> headers instead of <code>Cache-Control</code>. <code>Etag</code> is also generated based on the file contents, but the client has to talk to the server to confirm that the cached version is still correct. It means that on every page visit, the browser has to issue a request to validate its cache contents and wait for <code>304 Not Modified</code> response. This  completely unnecessary network roundtrip can be avoided if you add a <code>Cache-Control</code> header.</p>

<h2 id="limit-bandwidth-usage">Limit bandwidth usage</h2>

<p>Nowadays, websites are just MASSIVE. It often takes multiple MBs to render a static landing page. Let me point out the most common mistakes that affect it and how they can be resolved.</p>

<h3 id="compress-and-resize-images">Compress and resize images</h3>

<p>There’s no excuse for serving uncompressed images on your website. You must make sure to process all your images with tools like <a href="https://compressor.io/" target="_blank" rel="noopener noreferrer">Compressor.io</a>. There’s often no perceivable difference for images processed with <strong>Lossy</strong> compression, and it usually means ~70% size reduction.</p>

<p>Resizing an image to the size that it actually needs is often overlooked. To check it, visit your website using Firefox on a large desktop screen, right-click the image, and select <strong>View image info</strong>. You’ll see what dimensions the image needs vs. how large it is now:</p>

<p><img alt="Checking real image" title="Checking real image" loading="lazy" src="https://pawelurbanek.com/assets/real-image-size-524abe8437774180a233461deb8ada35092fda22cee4b3dfe85c0d0ad2e757b8.png"></p>

<p>Make sure first to resize the image and only then compress it. Otherwise, you might lose quality.</p>

<h3 id="defer-images-loading">Defer images loading</h3>

<p>You should defer the loading of the images that are not visible in the initial viewport. During the initial load, dozens of requests are competing for network throughput. Delaying the transfer of unnecessary images will leave more resources for necessary assets like CSS stylesheets etc.</p>

<p>There’s <a href="https://github.com/aFarkas/lazysizes" target="_blank" rel="noopener noreferrer">plenty</a> of <a href="https://github.com/tuupola/lazyload" target="_blank" rel="noopener noreferrer">different</a> <a href="https://github.com/vvo/lazyload" target="_blank" rel="noopener noreferrer">JavaScript libraries</a> that offer this feature. Including them means additional bandwidth usage, so I prefer to keep things simple and use a native <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/img#attr-loading" target="_blank" rel="noopener noreferrer"><code>loading='lazy'</code></a> HTML attribute.</p>

<p>It has decent <a href="https://caniuse.com/loading-lazy-attr" target="_blank" rel="noopener noreferrer">browser support</a>. Have a look at how it affected one of my blog posts:</p>

<p><img alt="Checking real image " title="Checking real image " loading="lazy" src="https://pawelurbanek.com/assets/before-lazy-images-a0e8cdb9099f3d5a348f853f4f222b67149aa058e59ecd29d2d5338be81cd8c0.png"></p>

<p>Without lazy loaded images</p>

<p><img alt="Checking real image " title="Checking real image " loading="lazy" src="https://pawelurbanek.com/assets/after-lazy-images-836f1781a9b7bf56cd8883a0ad0d252f52223f74b856e7e994ecef1d52efd029.png"></p>

<p>Lazy loading for images enabled</p>



<p>As you can see, adding <code>loading='lazy'</code> to all the images reduced ten requests and over <em>250kb</em> of transfer on the initial load. That’s a massive deal for slower internet connections!</p>

<h3 id="enough-with-the-gifs-already">Enough with the GIFs already…</h3>

<p>GIFs are HUGE! I understand you want to showcase a fancy UI on your landing page, but maybe you could use a lazy-loaded movie clip instead? <em>10MB</em> GIF can be converted to <em>250kb</em> mp4 file… Twitter automatically changes <em>GIF</em> images to <em>mp4</em> files, so I’d trust them on this one.</p>

<h3 id="cherry-pick-and-measure-dependencies-size">Cherry-pick and measure dependencies size</h3>

<p>Many frontend libraries offer a modular approach to including them in your application. For example, <a href="https://getbootstrap.com/docs/3.4/customize/" target="_blank" rel="noopener noreferrer">Bootstrap</a> allows you to customize the build to include only the components you need.</p>

<p>Some popular libraries have lightweight alternatives. Since recently, <a href="https://twitter.com/addyosmani/status/1304676118822174721" target="_blank" rel="noopener noreferrer">ChromeDevTools suggests them</a>, so make sure to use it for your application.</p>

<h3 id="reconsider-3rd-party-dependencies">Reconsider 3rd party dependencies</h3>

<p>Overusing externally hosted 3rd party JavaScript libraries is the simplest way to kill the performance of your website.</p>

<p>Dropping in yet another <code>&lt;script src="..."&gt;</code> tag might not seem like a big deal. It’s easy to forget that one script can result in a cascade of requests, each including more resources. Here’s the cost of embedding sample 3rd party JavaScript libraries:</p>

<table>
  <tbody><tr>
    <th></th>
    <th>Requests</th>
    <th>Bandwidth (total/gzipped)</th>
  </tr>
  <tr>
    <td><a href="https://www.google.com/analytics/" target="_blank" rel="noopener noreferrer">Google Analytics</a></td>
    <td>4</td>
    <td>104.09 KB / 40.37 KB</td>
  </tr>
  <tr>
    <td><a href="https://simpleanalytics.com/" target="_blank" rel="noopener noreferrer">Simple Analytics</a></td>
    <td>2</td>
    <td>5.29 KB / 3.12 KB</td>
  </tr>
  <tr>
    <td><a href="https://developer.twitter.com/en/docs/twitter-for-websites/follow-button/overview.html" target="_blank" rel="noopener noreferrer">Twitter button</a></td>
    <td>8</td>
    <td>173.68 KB / 59.30 KB</td>
  </tr>
  <tr>
    <td><a href="https://disqus.com/" target="_blank" rel="noopener noreferrer">Disqus</a></td>
    <td>26</td>
    <td>862.55 KB / 271.48 KB</td>
  </tr>
  <tr>
    <td><a href="https://commento.io/" target="_blank" rel="noopener noreferrer">Commento.io</a></td>
    <td>5</td>
    <td>64.73 KB / 19.25 KB</td>
  </tr>
</tbody></table>



<p>The only 3rd party JavaScript dependency I use for this blog is <a href="https://commento.io/" target="_blank" rel="noopener noreferrer">Commento.io</a> for comments. It’s over <strong>10x</strong> lighter than its alternative Disqus.</p>

<p>I’ve switched from using Google Analytics to SimpleAnalytics long ago. Recently I’ve decided I don’t need to track the visitors of this blog at all. Summary visit stats from Cloudflare are enough for me.</p>

<p><img alt="CloudFlare visits stats" title="CloudFlare visits stats" loading="lazy" src="https://pawelurbanek.com/assets/cloudflare-total-stats-2af208b0332a799e70e0aaa5495ef01c05c12ccc24514110accd3a4005817863.png"></p>

<p>All the tracking I need. No JavaScript dependencies required</p>


<p>Including 3rd party libraries from external sources often reduces your ability to set correct caching headers, thus hurting your performance score.</p>

<p>You should always look for the most straightforward tool that meets your requirements and only resort to using 3rd party if you cannot develop the lightweight solution yourself.</p>

<h2 id="http-2">HTTP 2</h2>

<p><em>HTTP 2</em> offers massive performance improvement over <em>HTTP 1.1</em> for loading static assets. Headers are compressed to reduce bandwidth. Even more important is that multiple assets can be loaded in parallel over a single HTTP connection.</p>

<p>It might not be critical for API calls, but for static assets, you should enable <em>HTTP 2</em> and expect serious performance gains.</p>

<p>How to do it depends on your infrastructure. If you’re using custom infrastructure with NGINX reverse proxy, you can check out <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-nginx-with-http-2-support-on-ubuntu-18-04" target="_blank" rel="noopener noreferrer">this tutorial</a>.</p>

<p>If you’re using Heroku, you’re out of luck because currently, it <a href="https://help.heroku.com/JAOCNZ25/does-heroku-have-plans-to-support-http-2" target="_blank" rel="noopener noreferrer">does not support HTTP 2</a>. The simplest way to add HTTP 2 support for Heroku is to proxy your traffic through <a href="https://pawelurbanek.com/cloudflare.com/" target="_blank" rel="noopener noreferrer">Cloudflare</a>.</p>

<p>If you don’t want to move your application to Cloudflare’s DNS, you can always use a custom domain just for serving assets from their CDN.</p>

<h2 id="physical-server-location-and-cdn">Physical server location and CDN</h2>

<p>The usage of CDN (<em>Content Delivery Network</em>) is critical if your user base is spread across the globe. Correctly configured CDN will cache static assets on the edge locations, significantly reducing the request’s duration. We’re talking like <em>50ms</em> vs. <em>800ms</em> (<strong>16x</strong> …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pawelurbanek.com/frontend-performance-optimization">https://pawelurbanek.com/frontend-performance-optimization</a></em></p>]]>
            </description>
            <link>https://pawelurbanek.com/frontend-performance-optimization</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044079</guid>
            <pubDate>Tue, 10 Nov 2020 09:20:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software development: should we stop? Maybe we should]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044031">thread link</a>) | @enz
<br/>
November 10, 2020 | http://blog.spencermounta.in/2020/should-we-stop/index.html | <a href="https://web.archive.org/web/*/http://blog.spencermounta.in/2020/should-we-stop/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://blog.spencermounta.in/2020/should-we-stop/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044031</guid>
            <pubDate>Tue, 10 Nov 2020 09:09:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Awful Edge Case in Bash's Set -e]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044030">thread link</a>) | @jbrot
<br/>
November 10, 2020 | http://jbrot.com/blog/dash_e_problems.html | <a href="https://web.archive.org/web/*/http://jbrot.com/blog/dash_e_problems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <header>
                
                
            </header>

            <p>
            The last six months, I've been building out the automated testing infrastructure at a start up.
            Our infrastructure is mostly in Python, but writing Bash scripts is inevitable.
            At the end of the day, automated testing is all about running commands in a row—and Bash is the right tool for the job.
            </p>

            <p>
            There are a <a href="https://mywiki.wooledge.org/BashPitfalls">whole</a> <a href="https://github.com/anordal/shellharden/blob/master/how_to_do_things_safely_in_bash.md">bunch</a> <a href="https://sipb.mit.edu/doc/safe-shell/">of</a> <a href="https://wizardzines.com/comics/bash-errors/">articles</a> about how to write safe Bash scripts, and the standard advice is to add <code>set -euo pipefail</code> to make your scripts "safe."
            In this article, I'm going to describe one edge case where <code>set -e</code> completely fails to work.
            </p>

            <h2> Background </h2>

            <p>
            Suppose we have two projects in a git repo, say MyLibrary and MyApplication, where MyApplication depends on MyLibrary. And suppose each project provides a script <code>test.sh</code> that looks something like this:
            </p>

<pre><code>#!/bin/bash

set -e

./configure
make

python fancy_test_driver.py tests/first_tests
python fancy_test_driver.py --option-1 tests/second_tests
python fancy_test_driver.py --option-2 tests/third_tests
</code></pre>

            <p>
            This is a pretty reasonable script.
            We can now require that all changes pass both <code>my_library/test.sh</code> and <code>my_application/test.sh</code> before being merged.
            </p>

            <p>
            As time goes on, the amount of tests (and projects!) can spiral out of control.
            Eventually, someone (me) gets tasked with trying to optimize things.
            One obvious thing to do is to abort early.
            If MyLibrary fails testing, we don't need to bother with testing MyApplication.
            </p>

            <p>
            Of course, the developers who used to get errors from both projects aren't very happy about this change.
            Now passing the <code>test.sh</code> scripts is like peeling an onion: you resolve the first layer of errors only to find more errors lurking underneath—hidden by the early abort.
            However, there's a middle ground.
            We can test MyApplication only if MyLibrary fails while running test cases.
            If MyLibrary fails during compilation, continuing on is pointless since MyApplication depends on MyLibrary.
            </p>

            <p>
            So how do we distinguish when <code>test.sh</code> fails during compilation from when it fails during testing?
            Exit codes, naturally:
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE

python fancy_test_driver.py tests/first_tests
python fancy_test_driver.py --option-1 tests/second_tests
python fancy_test_driver.py --option-2 tests/third_tests
</code></pre>

            <p>
            And we're done!
            An exit code of 0 means we passed the tests, an exit code of 79 means compilation failure (no need to test further projects), and any other exit code means we failed in testing—so we can continue testing the other projects.
            </p>

            <h2> Finding the Problem </h2>

            <p>
            The above solution works fine when we only have two lines that need the special exit code.
            However, it quickly becomes unwieldly when it needs to be applied to more lines:
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

pushd codegen_tool1 || exit $COMPILE_FAILURE_CODE
./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE
./codegen_tool1 || exit $COMPILE_FAILURE_CODE
popd || exit $COMPILE_FAILURE_CODE

pushd codegen_tool2 || exit $COMPILE_FAILURE_CODE
./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE
./codegen_tool2 || exit $COMPILE_FAILURE_CODE
popd || exit $COMPILE_FAILURE_CODE

./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE

# Run some tests...
</code></pre>

            <p>
            Gross!
            Clearly, we should factor out the <code>|| exit $COMPILE_FAILURE_CODE</code> line and have it apply to all of our lines at once.
            We can easily do this by creating a separate <code>build.sh</code> script:
            </p>

<pre><code>#!/bin/bash

set -e

pushd codegen_tool1
./configure
make
./codegen_tool1
popd

# snip

./configure
make
</code></pre>

            <p>
            And then adjusting <code>test.sh</code> to just have:
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

./build.sh || exit $COMPILE_FAILURE_CODE

# Run some tests...
</code></pre>

            <p>
            And this, too, works great!
            But wait!
            Why even use a second script?
            Can't we do the exact same thing with a subshell?
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

(
    pushd codegen_tool1
    ./configure
    make
    ./codegen_tool1
    popd

    # snip

    ./configure
    make
) || exit $COMPILE_FAILURE_CODE

# Run some tests...
</code></pre>

            <p>
            <strong>No!</strong>
            This subshell implementation is dangerously broken.
            The rest of this article will explore how and why the subshell code does not function as expected.
            </p>

            <h2> There's a Problem? </h2>

            <p>
            Let's run some simple bash programs and see what happens.
            First, we'll confirm <code>set -e</code> works as expected.
            </p>

<pre><samp>$ cat script1.sh
#!/bin/bash
echo "Statement 1"
(exit 3)
echo "Statement 2"

$ echo "$?"
0

#!/bin/bash
set -e
echo "Statement 1"
(exit 3)
echo "Statement 2"

$ ./script2.sh
Statement 1

$ echo "$?"
3
</samp></pre>

            <p>
            Yep, that's what we expected.
            Without <code>set -e</code> Bash ran every statement, and with <code>set -e</code> Bash stopped after the first non-zero exit code.
            What if we put our statements in a subshell?
            </p>

<pre><samp>$ cat script3.sh
#!/bin/bash
(
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
)

$ ./script3.sh
Statement 1
Statement 2

$ echo "$?"
0

$ cat ./script4.sh
#!/bin/bash
set -e
(
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
)

$ ./script4.sh
Statement 1

$ echo "$?"
3
</samp></pre>

        <p>
        And again, that's what we expected.
        The subshell made no difference.
        Note that <code>set -e</code> does propagate into the subshell.
        Alright. What if we mask the subshell's exit code?
        </p>

<pre><samp>$ cat script5.sh
#!/bin/bash
set -e
(
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
) || exit 9

$ ./script5.sh
Statement 1
Statement 2

$ echo "$?"
0
</samp></pre>

        <p>And again everything works as...</p>

        <h2> Wait, what? </h2>

        <p>Okay. Maybe <code>set -e</code> doesn't propagate?</p>

<pre><samp>$ cat script6.sh
#!/bin/bash
set -e
(
    set -e
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
) || exit 9

$ ./script6.sh
Statement 1
Statement 2

$ echo "$?"
0

$ cat script7.sh
#!/bin/bash
(
    set -e
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
) || exit 9

$ ./script7.sh
Statement 1
Statement 2

$ echo "$?"
0
</samp></pre>

        <p>
        Nope. Still doesn't work.
        Even if we just have <code>set -e</code> in the subshell and not in the outer script, it doesn't work.
        </p>

        <h2>So what's going on?</h2>

        <p>
        Well, if we dig into the Bash man page, we find this excerpt about <code>set -e</code>:
        </p>

        <blockquote>
              Exit  immediately  if a pipeline (which may consist of a single simple command), a list, or a compound command (see SHELL GRAMMAR above), exits with a non-zero status.
              The shell does not exit if the  command  that  fails  is part  of  the command list immediately following a while or until keyword, part of the test following the if or elif reserved  words, <em>part of any command executed in a &amp;&amp; or || list except the command following the final &amp;&amp; or ||,</em> any command in a pipeline but the last, or if the command's return value is being inverted with !.
        </blockquote>

        <p>
        So, the spec says that if you're using <code>&amp;&amp;</code> or <code>||</code>, only the last command's exit code can cause the shell to exit.
        This makes sense, because you expect  <code>command_1 || command_2</code> to execute <code>command_2</code> if <code>command_1</code> fails.
        Without this exception, it would be very hard to have any logical statements when <code>-e</code> is set.
        </p>

        <p>
        The behavior we just witnessed is, therefore, Working as Intended™.
        When we try to mask the subshell's exit code, we put the subshell at the start of an <code>||</code> list.
        So, the subshell's exit code will not cause an exit despite <code>-e</code> being set.
        But, every single command inside the subshell is <em>also</em> considered part of the <code>||</code> list, and thus no exit code anywhere in the subshell can cause the subshell to exit.
        It's as if <code>set +e</code> is being run implicitly in the subshell—only, as we've seen, we can't override it with an explicit <code>set -e</code> in the subshell.
        </p>

        <p>
        Is there anything we can do to fix this?
        Well, you're probably better off with one of the approaches I presented earlier.
        If you need to stay inside the same shell script, the solution with <code>trap</code> below is probably what you want.
        And if you truly need to use a subshell, I was able to come up with this mess:
        </p>

<pre><samp>$ cat script8.sh
#!/bin/bash
set -e
echo "Some stuff with -e set"

set +e
(
    set -e
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
)
[[ $? -ne 0 ]] &amp;&amp; exit 9
set -e

echo "More code with -e set (unreachable)"

$ ./script8.sh
Some stuff with -e set
Statement 1

$ echo "$?"
9
</samp></pre>

        <h3>Bonus Solution</h3>

        <p>
        I ended up using <code>trap</code> for error masking:
        </p>

<pre><samp>$ cat script9.sh
#!/bin/bash

set -e

trap 'exit 9' ERR

echo "Statement 1"
(exit 3)
echo "Statement 2"

trap - ERR

$ ./script9.sh
Statement 1

$ echo "$?"
9
</samp></pre>

        <p>
        The nice part about this solution is it allows you to stick with just one script (useful if you need to use functions), and the logic is straightforward.
        This option can be harder to make work if you're already using <code>trap ERR</code> for cleanup, though.
        </p>

        </article></div>]]>
            </description>
            <link>http://jbrot.com/blog/dash_e_problems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044030</guid>
            <pubDate>Tue, 10 Nov 2020 09:09:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Become Covid Savvy in 10 Steps]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044022">thread link</a>) | @datashrimp
<br/>
November 10, 2020 | https://adsp.ai/articles/how-to-become-covid-savvy-in-10-steps/ | <a href="https://web.archive.org/web/*/https://adsp.ai/articles/how-to-become-covid-savvy-in-10-steps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://adsp.ai/articles/how-to-become-covid-savvy-in-10-steps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044022</guid>
            <pubDate>Tue, 10 Nov 2020 09:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[iOS 14 IDFA changes. Research on change in mobile ad market]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044000">thread link</a>) | @iwitaly
<br/>
November 10, 2020 | https://blog.adapty.io/ios-14-idfa-attribution-a-global-change-in-the-mobile-advertising-market/ | <a href="https://web.archive.org/web/*/https://blog.adapty.io/ios-14-idfa-attribution-a-global-change-in-the-mobile-advertising-market/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>The mobile industry is undergoing one of the most fundamental changes of recent years. Apple has decided that early 2021, app developers will no longer have access to IDFA by default.</p><p>IDFA is a unique device identifier used for ad attribution, retargeting, alike audiences, analytics and other tasks. After the change, in order to receive the IDFA, an app developer must explicitly request the user’s permission (which is similar to allowing push notifications in an app). According to various estimates, the share of users who will provide access to their IDFA doesn’t exceed 10%.</p><p>Apple has provided privacy-friendly alternatives for attribution, but they fail to cover even a small fraction of the tasks that teams working on developing and promoting mobile apps currently have.</p><p>This shift means that mobile marketing (estimated at $80 billion), and by extension the mobile industry, are about to change drastically. In this essay, we will discuss in detail what will change, how it will affect the main players in the mobile advertising market such as developers, ad systems, attribution service providers, and advertisers.</p><figure><img src="https://blog.gopractice.io/wp-content/uploads/2020/09/for-post.jpg"></figure><h2 id="a-short-summary-of-the-key-changes-and-implications-of-ios-14-release-and-limiting-default-access-to-idfa"><strong><strong>A short summary of the key changes and implications of iOS 14 release and limiting default access to IDFA</strong></strong></h2><p><strong><strong># 1 Access restrictions: In iOS 14, IDFA will only be accessible upon user permission.</strong></strong></p><p>IDFA (Identifier for Advertisers) is a unique identifier of an iOS device. It is used in mobile apps for user attribution and tells advertisers where a user came from.</p><p>With iOS 14, to be released in early 2021, every app that wants to use an advertising user ID (IDFA) will have to explicitly ask permission from the user.</p><p>This will work in the same way as requesting permission to send push notifications.</p><figure><img src="https://lh4.googleusercontent.com/ary-L0VrnuIGlsebGQyVjv9IvP--cr9L0G2gMnSXBsP399mw2VnRal5OGOr7u9oqR9oVOOdOuWovqElUe8XyDaPb4gSYrOTRhlSnOqprRQRCEDoDQESdrFvOiMM_GEHTr-3_YMdR"></figure><p>Request to use IDFA will look like this – the text on the popup will ask: “Would you like to give permission to track you across apps and websites owned by other companies?”</p><p>The text is very straightforward, and the button to refuse is located below, making it more convenient to deny access to the IDFA. <a href="https://mobiledevmemo.com/mobile-advertising-without-the-idfa-a-comprehensive-overview/" rel="noopener noreferrer">Most experts</a> agree that 9 out of 10 people will most probably not opt in. After the initial declaration, Apple suggested a milder design for the popup, yet the idea remains largely the same and won’t bring fundamental changes.</p><p>Thus Apple is breaking the existing ad traffic attribution infrastructure under the pretext of privacy concerns. And this will affect everyone: ad networks systems, mobile developers, advertisers, and users.</p><p><strong><strong># 2. Lack of access to IDFA will lead to a decrease in the quality of mobile traffic attribution and an increase in the cost of user acquisition.</strong></strong></p><p>Previously, mobile developers and ad networks could use the IDFA without the explicit consent of the user. But now, the situation is radically changing:</p><p>1. Without access to IDFA, mobile ad attribution services (Appsflyer, Adjust and others) will no longer be able to trace back a significant portion of mobile traffic. It is important to understand that IDFA is now the primary accurate attribution tool. Appsflyer, Adjust and others will be forced to switch to less accurate and less efficient methods of determining the source of installs (e.g., device fingerprinting).</p><p>2. This will reduce the accuracy of traffic attribution, which will complicate things for companies developing and promoting mobile apps. In the future, it could lead to an increase in the cost of attribution.</p><p>3. We can expect a rise in acquisition costs as accurate targeting will become much more limited. Such popular and effective tools as lookalike audiences and retargeting will now be available only for a small portion of users who agreed to honor a request to provide access to the IDFA or used a relevant email or phone number while signing up.</p><p><strong><strong># 3. Apple presented its own attribution system, but it still doesn’t cover all mobile developers’ needs.</strong></strong></p><p>Apple offered the market an alternative, privacy-friendly traffic attribution system. This system makes it possible to send information about installs to advertising networks without explicitly revealing information about the user. But, unfortunately, the capabilities of this system are severely limited and don’t cover basic marketing needs.</p><p>One of the biggest problems is that developers and ad systems will no longer have access to user-level data. They will only see aggregated data in the account.</p><p>Developers will no longer be able to calculate and segment ROI or link attribution data to product events.</p><p><strong><strong>#4. Impact of IOS 14 Changes: rising user acquisition costs, accelerating mobile market consolidation, difficulties for large advertising networks and ad-attribution services</strong></strong></p><p>It’s hard to predict the results of this change. But here are some possible scenarios:</p><ul><li>As iOS 14 takes over (users will be gradually updating their devices to a newer iOS version with a IDFA), the cost of user acquisition will increase. The key factors here will be a lower quality of attribution and limited access to ad-targeting tools like lookalike audiences and retargeting.</li><li>Companies that provide attribution services will find themselves in a difficult position. Prior to iOS 14, they held a central position in the mobile advertising market. Without these companies developers wouldn’t be able to run mobile marketing efficiently. Apple’s decision will shatter their positions in the market. And there’s a possibility that Google will follow suit.</li><li>Large ad networks will also suffer. In its <a href="https://www.facebook.com/audiencenetwork/news-and-insights/preparing-audience-network-for-ios14/" rel="noopener noreferrer">latest report</a>, Facebook has already declared that it sees the changes in iOS 14 as a risk to its advertising business. Google, Twitter, Snapchat, Tiktok, and other big players have voiced <a href="https://www.facebook.com/audiencenetwork/news-and-insights/preparing-audience-network-for-ios14/" rel="noopener noreferrer">similar concerns.</a></li><li>It will become even more difficult for small players to compete with large publishers on the mobile market. They will lose the ability to accurately calculate ROI for ad campaigns. Without the ability to precisely link users’ payments to ad campaigns, it will be impossible to calculate the profit from acquired users. For small players, ineffective marketing can be a disaster, and many will have to be much more careful or even abandon paid channels. Big players have greater error tolerance and more tools to solve the emerging problems, although the problem will be no less relevant to them. Due to this asymmetry, it makes sense to expect an acceleration of the consolidation process on the mobile market.</li></ul><p><strong><strong>If you want to understand in more details what and why will happen, then here is what we will discuss further on:</strong></strong></p><ul><li>How traffic attribution currently works for mobile apps and why IDFA is so important?</li><li>What exactly will change in iOS 14?</li><li>What is the alternative Apple is offering to replace IDFA and existing mobile traffic attribution mechanisms?</li><li>Why do we expect an increase in user acquisition costs?</li><li>What do the leaders of the mobile market say?</li><li>When can we expect this change to take place?</li><li>How to prepare your app for iOS 14?</li><li>What will be the broader implications for mobile advertising and attribution?</li><li>How traffic attribution currently works for mobile apps, and why IDFA is so important?</li></ul><h2 id="how-traffic-attribution-works-for-mobile-apps"><strong><strong>How traffic attribution works for mobile apps</strong></strong></h2><p>Traffic attribution helps find out where a particular user came from. This is a critical task for performance marketing, as without high-quality attribution, it is impossible to determine which advertising campaigns are profitable (i.e., are making money) and which are not.</p><p>On the web, attribution is tackled in a simple way – we just need to add special parameters (usually utm-parameters) to the ad links leading to the site.</p><p>This scheme doesn’t work with mobile apps largely because mobile app stores add an intermediate step to the process and do not provide information about where the user came from.</p><p>Another reason is the policy of a number of leading advertising systems on the market. For example, Facebook doesn’t allow you to add any parameters when promoting mobile apps through its ad network.</p><p>Therefore, there are other methods for traffic attribution for mobile apps out there. Say you have a mobile app or a mobile game. To acquire users to your app, you purchase ad traffic. This is what happens in order to link ad clicks to an app’s install:</p><ul><li>The app developer has to integrate the SDK of a mobile attribution service into the app to track the traffic source of new users. Examples include AppsFlyer, Adjust, and Kochava.</li><li>The developer purchases ads in the advertising network, while using special links from the traffic-tracking service (Appsflyer, Adjust, etc.).</li><li>After clicking on the ad, the user is redirected to a special page, where various information is collected about him, including IDFA and his traffic source (it is transmitted from the advertising network, while access to IDFA is limited on the web). The user is then redirected to the app’s page in App Store or Google Play. Users will see none of this happen.</li><li>When a new user launches the app for the first time, the information about this action is sent to the mobile attribution service (AppsFlyer, Adjust, Kochava), which tries to find a match between the data received and the data collected at the previous step. If there is a match, then this user is attributed to the corresponding ad campaign. Absent a match, the traffic is considered organic.</li><li>The developer must set up a postback from a partner to the ad network, so that the ad system understands which campaigns are working well and which are not, and can optimize the display of ads on its side.</li><li>In some ad networks, the logic differs slightly. For example, the logic is different for Facebook, which is directly integrated with Appsflyer, Adjust and other providers.</li></ul><p>If you are not familiar with this topic, then here is a good <a href="https://www.appagent.co/blog/2019/01/09/the-principles-of-mobile-ad-attribution-analytics-and-tracking/" rel="noopener noreferrer">essay</a>.</p><figure><img src="https://lh4.googleusercontent.com/UfaVT2cgGlrEBil86RyIVr4tzeJi-pS3YLNVluew3DvgRDJ0lYjWotReEUaOZdVs8j8B_2RO09oNWdcplvBLW6agdeLEqyrSiZOMb7BFaHZZlAw-DxeYpbC9niIoi22u5hH8x0NM"></figure><h2 id="why-idfa-is-a-central-element-of-mobile-traffic-attribution">Why IDFA is a central element of mobile traffic attribution</h2><p>As is evident in the process described above, data about users who click on ads is key to the logic behind mobile traffic attribution systems. The IDFA is the central element of the data collected, and if IDFA is missing, the accuracy of this attribution method will drop <a href="https://medium.com/@gsimmons/your-attribution-may-be-more-wrong-than-right-903cde0ce4ca#:~:text=Fingerprinting%20accuracy%3A,result%20as%20a%20deterministic%20match)." rel="noopener noreferrer">dramatically.</a></p><p>Without IDFA, …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.adapty.io/ios-14-idfa-attribution-a-global-change-in-the-mobile-advertising-market/">https://blog.adapty.io/ios-14-idfa-attribution-a-global-change-in-the-mobile-advertising-market/</a></em></p>]]>
            </description>
            <link>https://blog.adapty.io/ios-14-idfa-attribution-a-global-change-in-the-mobile-advertising-market/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044000</guid>
            <pubDate>Tue, 10 Nov 2020 09:02:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Five Keys to create a killer CLI in Go]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25043979">thread link</a>) | @alexellisuk
<br/>
November 10, 2020 | https://blog.alexellis.io/5-keys-to-a-killer-go-cli/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/5-keys-to-a-killer-go-cli/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><p>We're having a renaissance of CLIs - every programming language from Node.js to Go to less fashionable ones like .NET all have CLIs and developers love them. You should love them too and make sure your next CLI is a killer.</p>
<blockquote>
<p>CLIs (command-line interfaces) are text-based interfaces for your applications which are easily automated, fast to work with and can be combined with other CLIs to create workflows.</p>
</blockquote>
<h3 id="1pickgo">1. Pick Go</h3>
<p>Here's why I prefer the OpenFaaS CLI in Go over the Serverless Framework Inc Node.js CLI:</p>
<ul>
<li>Compiles to a single static binary</li>
</ul>
<p>With Go you can easily provide a single static binary that contains your whole application or CLI for your chosen platform. To target a different CPU or OS you just pass in an environmental override when building.</p>
<p>Here's a binary for Windows, 64-bit Linux and Raspberry Pi:</p>
<pre><code>GOOS=windows go build -o cli.exe
GOOS=linux go build -o cli
GOARCH=armv7 GOOS=linux go build -o cli-rpi
</code></pre>
<p>That's it - and there are more platforms available too - like FreeBSD. You won't need to install any dependencies and the final output binary can be tiny.</p>
<ul>
<li>Consistent style</li>
</ul>
<p>Go is an opinionated language and while there may be some differences between which editors a project prefers - you will encounter a consistent standard for styling, formatting and build tools. Something like Node.js could involve any number of "task runners" or "transpilers" - or a more esoteric flavour of the language like TypeScript or CoffeeScript.</p>
<p>Go has a consistent style and was deliberately designed to be unambiguous. This makes it attractive to contributors and easy for on-boarding.</p>
<ul>
<li>Fast on every platform</li>
</ul>
<p>A statically compiled Go binary is super fast to load - compared to Node.js. For instance: Node.js on a single-core Raspberry Pi can take 1.5-3.0 seconds to load before executing any code.</p>
<ul>
<li>Easy to create a REST client</li>
</ul>
<p>Go includes a no-nonsense <code>http</code> client and has built-in support for working with <code>xml</code>, <code>json</code> and binary formats. There's also a very good library for working with YAML which is used in OpenFaaS here: <a href="https://github.com/openfaas/faas-cli/blob/master/stack/stack.go">stack.go</a></p>
<p>There may be reasons why Node.js or another language is more suitable for your use-case. If you've already decided to build a CLI in Go - then you can reap the benefits of a fast binary that's small and easy to distribute.</p>
<h3 id="2parseflagsarguments">2. Parse flags &amp; arguments</h3>
<p>The standard Go library includes a <code>flags</code> package that can be used to parse flags or arguments in a couple of lines of code.</p>
<pre><code>package main

import (
	"flag"
	"fmt"
	"os"
)

func main() {
	var image string
	flag.StringVar(&amp;image, "image", "", "Docker image")
    flag.Parse()
    
	if len(image) == 0 {
		fmt.Fprintf(os.Stderr, "You must specify a Docker image name")
	}

	fmt.Printf("Your Docker image was: %s", image)
}
</code></pre>
<blockquote>
<p>From my experiences in the world of enterprise development - the average C# developer would have written his own string parser and then created a ConsoleApp as an entry-point then a DLL Library for the parsing and one more for the application code. Contrast that to the snippet above.</p>
</blockquote>
<p>Go is unpretentious - you can have a single file that compiles to a tiny binary and be done with that.</p>
<p>I suggest you start here and then once you've stretched <code>flags</code> to the limit you can look at something more modular like <a href="https://github.com/spf13/cobra">Cobra</a>.</p>
<p>Cobra is used by Docker, Kubernetes and the OpenFaaS projects and means that handlers/commands can live in separate files or modules. It also makes documenting each command really simple. <a href="https://github.com/openfaas/faas-cli/blob/master/commands/list.go">Checkout the code here for our 'list functions' command</a>.</p>
<p>Another advantage of using "cobra" is that it has a verb noun syntax. This helped us when designing our user experience. We went from a somewhat jarring experience to something more fluid:</p>
<pre><code>faas-cli -deploy -image=functions/alpine -name=cat -fprocess=/bin/cat
</code></pre>
<p>To:</p>
<pre><code>faas-cli deploy --image=functions/alpine --name=cat --fprocess=/bin/cat
</code></pre>
<p>We also took feedback about managing multiple functions and created a YAML format which meant the CLI command could be as simple as:</p>
<pre><code>faas deploy -f stack.yml
</code></pre>
<p>Or</p>
<pre><code>faas deploy -f https://git.raw/stack.yml
</code></pre>
<blockquote>
<p>Tip: pick verbs / commands carefully and ask other people if they make sense. If something jars with you then it's probably wrong. It can take several iterations but what you're aiming for is an intuitive experience.</p>
</blockquote>
<h3 id="3automateeverything">3. Automate everything</h3>
<p>Create an automated build using a free and public CI platform like Travis so that contributors or collaborators know whether their changes can be integrated.</p>
<p>Use GitHub releases to track changes in the project and milestones. You can set up a post-build action in Travis to publish binary artifacts automatically for every platform you target.</p>
<p>If you have a Docker image - publish that on the Docker store at the same time as pushing a new release artifact. Tools like Travis can obfuscate credentials and keys so that they do not show up in logs.</p>
<p>Go projects are very easy to build in Docker. Here's an example from one of our projects:</p>
<ul>
<li><a href="https://github.com/openfaas/faas/blob/master/gateway/Dockerfile">Dockerfile for API Gateway</a></li>
</ul>
<p>Make sure you use <a href="https://docs.docker.com/engine/userguide/eng-image/multistage-build/">multi-stage builds</a> so you ship a lean image.</p>
<ul>
<li><a href="https://github.com/openfaas/faas/blob/master/.travis.yml">OpenFaaS main project CI .travis.yml file</a></li>
</ul>
<p>While it's easy to start with - you do not want to be building 3-5 binary files on your own machine for every release then uploading them to a web-form every time you need an update.</p>
<h3 id="4integratewithpackagemanagers">4. Integrate with package managers</h3>
<p>If you want to make it easy for your target audience to be able get hold of your CLI then you need to make that as easy as possible. This means integrating with package managers.</p>
<ul>
<li><code>brew</code> - if your target audience is the developer - then a large percentage of them may have a Mac. brew is a package manage which means most CLIs are only one command away <code>brew install faas</code> for instance</li>
<li>Linux - for Linux there are many package managers so I've chosen to build a download utility which can be run as root or as a regular user. To get the OpenFaaS CLI: <code>curl -sL https://cli.openfaas.com | sh</code> - or to get hold of Docker: <code>curl -sL https://get.docker.com | sh</code>.</li>
<li>Windows - Windows users have good options available for shells including Git Bash (my preferred option) and the Windows Subsystem for Linux. WSL can use the Linux <code>curl</code> utility, but if you are targeting "point and click" developers you may want to create a "double-click" installer.</li>
</ul>
<p>Whatever you do - make sure it's automated and evaluate each package manager you support. Will you have time to maintain the integration? Is it provided by the project or by the community? What if it breaks? For instance - we maintain a guide on how to <a href="https://github.com/openfaas/faas-cli/blob/master/CONTRIBUTING.md#how-to-update-the-brew-formula">upgrade our brew formula</a>.</p>
<blockquote>
<p>Tip: Make sure the update/release cycle of chosen packages can match the cadence of your project. How many times have you had to install Ubuntu packages from a third-party PPA due to them being out of date?</p>
</blockquote>
<h3 id="5acceptcontributionsandgatherfeedback">5. Accept contributions and gather feedback</h3>
<p>Provide an easy way for people to provide feedback and contributions. A CLI should be designed for its operators - so make it easy for them to submit code changes or suggestions.</p>
<p>User feedback is essential, but when running an Open Source Software project I often hear people struggle to understand how or if their software is being used.</p>
<p>Basic feedback can be gathered from the download statistics on GitHub or <code>brew</code>. Several key projects have started gathering usage data automatically using an analytics platform - examples include: <code>brew</code>, Visual Studio Code, Atom and Docker for Mac/Windows. If you go down this route make sure you provide a privacy policy and comply with any potential data-protection regulations.</p>
<p>Here's some things we're looking at collecting for <a href="https://github.com/openfaas/faas-cli/issues/108">OpenFaaS in issue #108</a>:</p>
<ul>
<li>which commands were used</li>
<li>what programming languages functions are being scaffolded for</li>
<li>operating system / CLI version / location in the world etc</li>
</ul>
<blockquote>
<p>OpenFaaS contributor John McCabe has been leading this initiative for the project.</p>
</blockquote>
<h3 id="wrappingup">Wrapping up</h3>
<p>There are many reasons to use Go to build your next killer CLI - from the speed of compilation and execution, the availability of built-in or high-quality packages, to the ease of automation. It may not be right for everyone and other languages and platforms do have different pros and cons.</p>
<p>If you're starting out wanting to take your CLI to the next level then take inspiration from this post and the experience we've built up over the last 8 months building the <a href="https://github.com/openfaas/faas-cli">OpenFaaS CLI</a>. <em>If you would like to contribute to the code-base we're always looking for help and have an thriving community.</em></p>
<p><strong>Follow and share on Twitter</strong></p>
<p>Do you have questions, comments and suggestions? Follow me on <a href="https://twitter.com/alexellisuk">Twitter</a> and never miss a post again.</p>
<blockquote data-lang="en"><p lang="en" dir="ltr">5 keys to create a killer CLI in Go - <a href="https://t.co/AoHfHgv5w3">https://t.co/AoHfHgv5w3</a> <a href="https://twitter.com/golang?ref_src=twsrc%5Etfw">@golang</a> <a href="https://twitter.com/Docker?ref_src=twsrc%5Etfw">@docker</a> <a href="https://twitter.com/kubernetesio?ref_src=twsrc%5Etfw">@kubernetesio</a> <a href="https://twitter.com/openfaas?ref_src=twsrc%5Etfw">@openfaas</a></p>— Alex Ellis (@alexellisuk) <a href="https://twitter.com/alexellisuk/status/947487509533085696?ref_src=twsrc%5Etfw">December 31, 2017</a></blockquote> 
<h4 id="seealso">See also:</h4>
<p><a href="https://www.openfaas.com/">OpenFaaS.com</a> - Serverless Functions Made Simple</p>
<p><img src="https://raw.githubusercontent.com/openfaas/media/master/OpenFaaS_logo_stacked_opaque.png" width="450px" height="450px"></p>
<p>With OpenFaaS you can build serverless functions in any language in seconds and run them anywhere at scale.</p>
<blockquote>
<p>Serverless functions are small, discrete, reusable chunks of code that can be built once and deployed the same way everywhere. They do one thing and do it really well - the best uses for functions are integrating event driven systems or building integrations between existing microservices.</p>
</blockquote>
<p>Find out more on the <a href="https://www.openfaas.com/">project website</a> or read <a href="https://github.com/openfaas/faas">the code on GitHub</a>.</p>
<blockquote>
<p>Acknowledgements - thanks to John McCabe and Richard Gee for reviewing the post and for all their <a href="https://github.com/openfaas/faas-cli/graphs/contributors">contributions to the OpenFaaS CLI</a> through code, testing and feedback.</p>
</blockquote>
</div>
        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://blog.alexellis.io/5-keys-to-a-killer-go-cli/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043979</guid>
            <pubDate>Tue, 10 Nov 2020 08:56:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Messaging via SEPAtransfercomments [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043965">thread link</a>) | @zanfr
<br/>
November 10, 2020 | https://franzkruhm.com/SEPA2020.pdf | <a href="https://web.archive.org/web/*/https://franzkruhm.com/SEPA2020.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://franzkruhm.com/SEPA2020.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043965</guid>
            <pubDate>Tue, 10 Nov 2020 08:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Productivity Guide: All You Need to Know to Be Efficient]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043892">thread link</a>) | @iuliangulea
<br/>
November 10, 2020 | https://iuliangulea.com/productivity/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/productivity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://iuliangulea.com/images/productivity.png" alt="Productivity"></p><h2 id="productivity-definition">Productivity Definition</h2><blockquote><p>Productivity is a measure of the efficiency of a person to perform a specific task.</p></blockquote><p>We often think it is a state of constant efficiency that allows us to do everything faster and better, but this is wrong. <em>Productivity is a measurement per individual task.</em></p><p>If you try to measure productivity as the number of tasks you accomplish daily, you still have to count in each individual assignment, which endorses the idea that productivity is a measurement per task.</p><h2 id="productivity-from-within-and-without">Productivity From Within And Without</h2><p>There are different strategies for productivity, and all those strategies can be classified into two main categories: <strong>external productivity</strong> and <strong>internal productivity.</strong></p><p><strong>External productivity</strong> is what usually people put their emphasis on. Also, it is what all those products, apps, and services promise to deliver. External productivity is all about automation, better tools, frameworks, software, and anything that allows you to perform your work better and faster. It has a significant potential to improve your performance by taking advantage of technology and advanced tools.</p><p><strong>Internal productivity,</strong> on the other hand, is often overlooked. Unlike the external one, internal productivity is all about your cognitive and physical performance, about your ability to focus, sustain your attention on the task at hand, manage your energy, and, generally speaking, understand how your body and mind works.</p><h2 id="gaining-productivity-expertise--the-pyramid-of-mastery">Gaining Productivity Expertise — The Pyramid Of Mastery</h2><p><img src="https://iuliangulea.com/images/the-pyramid-of-mastery/the-pyramid-of-mastery-1.png" alt="Pyramid of Mastery"></p><p><a href="https://iuliangulea.com/pyramid-of-mastery/">The Pyramid of Mastery</a> is a model that defines any domain in terms of 4 categories:</p><p><strong>Elements</strong> are the fundamental building blocks that make up a domain. In productivity, elements are abstract: focus, attention, working memory, sensory channels, etc.</p><p><strong>Rules</strong> are the laws by which the elements interact with each other and general principles that govern a domain. Some rules are: goal-directed attention is easily distracted, senses have a different throughput, working memory cannot perform two tasks simultaneously (hence multitasking is a myth), etc.</p><p><strong>Tools</strong> are the instruments that help you operate with the Elements and Rules. The majority of productivity tools nowadays are software apps. One of the best productivity tools is pen and paper.</p><p><strong>Frameworks</strong> are a combination of the previous layers. A Framework is a layer of abstraction that hides the underlying fundamentals behind a friendly facade that is easy to use to achieve a specific goal. Some frameworks in productivity are office suites and various productivity methods (e.g., <a href="https://en.wikipedia.org/wiki/Pareto_principle">80/20 Rule</a>, <a href="https://en.wikipedia.org/wiki/Time_management#The_Eisenhower_Method">The Eisenhower Method</a>, and others).</p><p>All four layers together allow you to be an expert in your field. Leave one out, and there will always be something you do not fully understand. And when you don’t understand something, you cannot be fully efficient at it.</p><p>If you would like to find out more about how the Pyramid of Mastery applies to the field of productivity, I wrote a separate <a href="https://iuliangulea.com/pyramid-of-mastery/productivity/">article</a> on that topic.</p><h2 id="productivity-approaches">Productivity Approaches</h2><p>Generally speaking, you can be more productive by taking one or several of the following approaches:</p><p><strong>1. Delegate/Outsource the task.</strong> This approach is the most efficient from the time standpoint as it frees all your time and allows you to focus on other tasks. Although it is limited in how much you can delegate/outsource, it is crucial to keep in mind that you can and need to delegate.</p><p><strong>2. Automate the task.</strong> If you cannot delegate/outsource, think about whether your work on a task can be either fully or partially automated. There are lots of services, products, and programs that can do the work for you in a broad range of areas. If their cost is smaller than the value of the time you can save using them, then do it.</p><p><strong>3. Use better tools and learn them well.</strong> If automation is also not an option, then it means <em>you</em> need to do it. Having good tools is crucial if you want to be productive. A thorough understanding of their functions can make a big difference. In the case of software, learn its features and the shortcuts of the most frequently used functionality by you.</p><p><strong>4. Understand cognitive processes and learn what works best for you.</strong> Whenever we need to perform mental work, understanding <em>how</em> our <a href="https://iuliangulea.com/human-senses/">senses</a>, <a href="https://iuliangulea.com/attention/">attention</a>, <a href="https://iuliangulea.com/working-memory/">working memory</a>, and other relevant processes work can make a huge difference. As a plant flourishes, when the conditions are right, our brains can be incredibly performant whenever we offer them the right environment in which they can function.</p><h2 id="my-top-productivity-strategies">My Top Productivity Strategies</h2><p><strong>The Rule Of Threes.</strong> This is a meta strategy I came up with some time ago that help me make the right decisions when it comes to taking on new opportunities. No matter how productive you are, if you have too much on your plate, your attention and energy will split into too many places, and that will affect your productivity. The rule is simple: at any one point in time, I should have no more than three ongoing projects, and by an ongoing project, I mean any work that spans for longer than one week. Having more than that will scatter your energy and attention to the detriment of effectiveness.</p><p><strong>Plan Your Day In Advance.</strong> It is much easier to follow a predefined list of steps rather than having only the destination in mind and think about your next course of action after each task. The 10–15 minutes spent in the evening to decide and prioritize what you will work on will save you plenty of energy and time the following day.</p><h2 id="more-productivity-tips-for-every-day">More Productivity Tips For Every Day</h2><p><strong>1. Reduce Distractions As Much As Possible.</strong> If there is something that can distract you, sooner or later, it will distract you. Therefore, if you want to keep focused for a longer time, remove as many distractions as you can. This includes visual distractions on your table and screen (yes, those Facebook and Twitter tabs are hooking your attention pretty easy, aren’t they?), audial distractions (buy yourself a good pair of noise-canceling headphones), and other types of disturbances that distract you regularly.</p><p><strong>2. Put Your Phone Away.</strong> Although it is also a distraction, this tip deserves a separate mention. Put your phone on silent mode and away from your sight (not in your pocket). All those sounds (including notifications, calls, etc.) and flashes are nothing else than stimuli that have their primary goal to grab your attention and distract you from the thing you are focused on. It is also essential to put the phone away, as having it in your area of sight will also urge you to grab it when you see it on the table.</p><p><strong>3. Split Your Tasks Into Manageable Chunks.</strong> If an assignment is too big for you to comprehend, consider splitting it into several smaller subtasks until you get them of a size that you can easily accomplish. A positive side-effect of this is that smaller tasks provide a sense of progress, positively affecting your overall state and mood.</p><p><strong>4. Use Good Tools And Learn Them Properly.</strong> If you use software tools, learn the shortcuts of the programs you work in as it will save you dozens of hours within a year. If you use physical tools, buy high-quality tools, as they will pay off multiple times.</p><p><strong>5. Your Energy Is More Important Than The Allocated Time.</strong> Time Management is overrated. It’s not that timing your tasks is not essential, but <em>time is absolute.</em> It is independent of anything. Consider your energy levels when planning your tasks. Your energy is what matters when working on a job. You can spend 2 hours banging your head against something in the evening when you are tired and then complete that task in 30 minutes the next morning. Know when you are more productive and work on the most important tasks then.</p><p><strong>6. Use Visual Aids.</strong> A pen and a piece of paper are sometimes the best, simple, and most efficient productivity tools you can use. If the task you are working on relies on manipulating multiple pieces of information at a time, write them on paper or draw a diagram. That will free up resources necessary to store them in your working memory so that you can focus on processing and manipulating them instead. This will also involve your visual sense, allowing you to make more potentially relevant connections between ideas.</p><h2 id="all-productivity-articles">All Productivity Articles</h2><p>These are all articles I have written on productivity. Enjoy!</p><ul><li><a href="https://iuliangulea.com/keyboard-shortcuts/">6 Shortcuts That Save Me 62 Hours Each Year</a></li><li><a href="https://iuliangulea.com/pyramid-of-mastery/productivity/">The Ultimate Productivity Guide — Scientifically Proven Techniques To Get Things Done</a></li><li><a href="https://iuliangulea.com/attention/">The Dual Nature Of Attention — 5 Ways To Stay Less Distracted And Be More Productive</a></li><li><a href="https://iuliangulea.com/working-memory/">How People Learn — Working Memory And The 3 Basic Rules Of Productivity</a></li><li><a href="https://iuliangulea.com/the-most-substantial-word/">Your Name — The Most Substantial Word</a></li><li><a href="https://iuliangulea.com/how-i-automated-things/">How I Saved 14 Hours Of Working Time Each Month</a></li><li><a href="https://iuliangulea.com/one-percent-rule/">The One Percent Rule - How Tiny Changes Can Bring Big Results</a></li><li><a href="https://iuliangulea.com/team-processes-what/">Increase Your Team’s Productivity by Establishing Processes - Part III</a></li><li><a href="https://iuliangulea.com/team-processes-how/">Increase Your Team’s Productivity by Establishing Processes - Part II</a></li><li><a href="https://iuliangulea.com/team-processes-why/">Increase Your Team’s Productivity by Establishing Processes - Part I</a></li></ul><hr></div></div>]]>
            </description>
            <link>https://iuliangulea.com/productivity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043892</guid>
            <pubDate>Tue, 10 Nov 2020 08:38:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smartphone Upgrades Are Impacting the Environment]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043889">thread link</a>) | @scottbucks
<br/>
November 10, 2020 | https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.3.0"><div dir="ltr"><div><div id="viewer-16t2j"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" data-pin-media="https://static.wixstatic.com/media/f361a8_da6af0458bd5469fb370e704386f86a3~mv2.jpeg/v1/fit/w_1000%2Ch_635%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_da6af0458bd5469fb370e704386f86a3~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p></div><p><span dir="auto">Photo by Daniel Romero on Unsplash</span></p></div></div></div><p id="viewer-7arqh"><span>Smartphone technology is evolving rapidly. Every year there are better cameras, performance, refresh rates, screens and batteries. Tempted by a host of new features, people can't help but upgrade to the latest model, but what happens to all the smartphones we go through?

</span></p><p id="viewer-5o3kt"><span>The average lifespan of a smartphone is 3 to 4 years, perhaps even 5, but by that time the battery's capacity is likely to have decreased significantly. After an average lifespan has been reached, most people will throw away their smartphone and upgrade to a more recent model.</span></p><blockquote id="viewer-cmiam"><span><em>On average only 12,5% of electronic waste is recycled, with approximately 20 to 50 million metric tons of e-waste disposed of worldwide every year.</em></span></blockquote><p id="viewer-74ml0"><span>This is a huge problem for the environment due to the chemicals in these devices leaching into the groundwater system from landfills, polluting the land, water and air.</span></p><div id="viewer-bm1b6"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" data-pin-media="https://static.wixstatic.com/media/f361a8_e577402e314d40939016a7c158736c28~mv2.jpeg/v1/fit/w_794%2Ch_528%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_e577402e314d40939016a7c158736c28~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p></div></div></div></div><p id="viewer-87pmv"><span>With companies constantly encouraging people to upgrade by stopping updates for older models, it renders them obsolete.

</span></p><p id="viewer-31crc"><span>Not only is this a problem for the environment, but by throwing away these devices, we are wasting precious metals such as copper, silver, gold, palladium and other raw materials, that would require significant resources to mine and manufacture.</span></p><div id="viewer-d1tql"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" data-pin-media="https://static.wixstatic.com/media/nsplsh_6a58643246537663527238~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/nsplsh_6a58643246537663527238~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-bqd9o"><span>
This is why it is important to recycle old cell phones and preserve these increasingly scarce materials where possible.


</span></p><p id="viewer-c1me1"><span>Here are some suggestions on how to alleviate these problems:

</span></p><ol><li id="viewer-4p3cu"><p>Instead of buying a new phone, why not change the battery? Often the smartphone is still in good condition.</p></li><li id="viewer-bqu6i"><p>Once you have had your smartphone for several years and have already changed the battery, you could recycle it and buy a new one. Some companies offer trade-ins fo credit to use on your next phone.</p></li><li id="viewer-16hl3"><p>You could buy a refurbished product; they are often as good as brand new with the added benefit it helps the environment and saves you money.</p></li><li id="viewer-1aql"><p>Instead of throwing the phone away you could sell it, or give it to a friend/family member.</p></li></ol><p id="viewer-26bo7"><span>The bottom line is currently we change smartphones too often. There is no specific amount of time that you should keep the same phone but when changing, think about where your phone may end up if you don't recycle it, sell it or pass it on to someone else.</span></p><p id="viewer-5oobg"><span>If you enjoyed this article, why not consider subscribing to our newsletter, or check out some of our <a href="http://thedetechtor.com/all-news" target="_blank" rel="noopener"><u>other posts</u></a><u>.</u> </span></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043889</guid>
            <pubDate>Tue, 10 Nov 2020 08:37:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YSFlight HQ: “START HERE – What you need to know”]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043835">thread link</a>) | @app4soft
<br/>
November 10, 2020 | https://forum.ysfhq.com/viewtopic.php?f=306&t=10520&p=116962#p116962 | <a href="https://web.archive.org/web/*/https://forum.ysfhq.com/viewtopic.php?f=306&t=10520&p=116962#p116962">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://forum.ysfhq.com/viewtopic.php?f=306&amp;t=10520&amp;p=116962#p116962</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043835</guid>
            <pubDate>Tue, 10 Nov 2020 08:26:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is how I git]]>
            </title>
            <description>
<![CDATA[
Score 223 | Comments 133 (<a href="https://news.ycombinator.com/item?id=25043731">thread link</a>) | @ingve
<br/>
November 10, 2020 | https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Every now and then I get questions on how to work with git in a smooth way when developing, bug-fixing or extending curl – or how I do it. After all, I <a href="https://daniel.haxx.se/blog/2020/10/26/working-open-source/" data-type="post" data-id="14901">work on open source full time</a> which means I have very frequent interactions with git (and GitHub). Simply put, I work with git all day long. Ordinary days, I issue git commands several hundred times.</p>



<p>I have a very simple approach and way of working with git in curl. This is how it works.</p>



<h2>command line</h2>



<p>I use git almost exclusively from the command line in a terminal. To help me see which branch I’m working in, I have this little bash helper script.</p>



<pre>brname () {
  a=$(<code>git rev-parse --abbrev-ref HEAD 2&gt;/dev/null</code>)
  if [ -n "$a" ]; then
    echo " [$a]"
  else
    echo ""
  fi
}
PS1="\u@\h:\w\$(brname)$ "</pre>



<p>That gives me a prompt that shows username, host name, the current working directory and the current checked out git branch.</p>



<p>In addition: I use Debian’s <a href="https://salsa.debian.org/debian/bash-completion/-/blob/master/README.md">bash command line completion</a> for git which is also really handy. It allows me to use tab to complete things like git commands and branch names. </p>



<h2>git config</h2>



<p>I of course also have my customized <code>~/.gitconfig</code> file to provide me with some convenient aliases and settings. My most commonly used git aliases are:</p>


<pre title="">st = status --short -uno
ci = commit
ca = commit --amend
caa = commit -a --amend
br = branch
co = checkout
df = diff
lg = log -p --pretty=fuller --abbrev-commit
lgg = log --pretty=fuller --abbrev-commit --stat
up = pull --rebase
latest = log @^{/RELEASE-NOTES:.synced}..
</pre>


<p>The ‘latest’ one is for listing all changes done to curl since the most recent RELEASE-NOTES “sync”. The others should hopefully be rather self-explanatory.</p>



<p>The config also sets <code>gpgsign = true</code>, enables mailmap and a few other things.</p>



<h2>master is clean and working</h2>



<p>The main curl development is done in the single <a href="https://github.com/curl/curl">curl/curl</a> git repository (primarily hosted on GitHub). We keep the master branch the bleeding edge development tree and we work hard to always keep that working and functional. We do our releases off the master branch when that day comes (every eight weeks) and we provide “<a href="https://curl.haxx.se/snapshots/">daily snapshots</a>” from that branch, put together – yeah – daily.</p>



<p>When merging fixes and features into master, we avoid merge commits and use rebases and fast-forward as much as possible. This makes the branch very easy to browse, understand and work with – as it is 100% linear.</p>



<h2>Work on a fix or feature</h2>



<p>When I start something new, like work on a bug or trying out someone’s patch or similar, I first create a local branch off master and work in that. That is, I don’t work directly in the master branch. Branches are easy and quick to do and there’s no reason to shy away from having loads of them!</p>



<p>I typically name the branch prefixed with my GitHub user name, so that when I push them to the server it is noticeable who is the creator (and I can use the same branch name locally as I do remotely).</p>



<pre>$ git checkout -b bagder/my-new-stuff-or-bugfix</pre>



<p>Once I’ve reached somewhere, I commit to the branch. It can then end up one or more commits before I consider myself “done for now” with what I was set out to do.</p>



<p>I try not to leave the tree with any uncommitted changes – like if I take off for the day or even just leave for food or an extended break. This puts the repository in a state that allows me to easily switch over to another branch  when I get back – should I feel the need to. Plus, it’s better to commit and explain the change <em>before</em> the break rather than having to recall the details again when coming back.</p>



<h2>Never stash</h2>



<p>“git stash” is therefore not a command I ever use. I rather create a new branch and commit the (temporary?) work in there as a potential new line of work.</p>



<h2>Show it off and get reviews</h2>



<p>Yes I am the lead developer of the project but I still maintain the same work flow as everyone else. All changes, except the most minuscule ones, are done as pull requests on GitHub.</p>



<p>When I’m happy with the functionality in my local branch. When the bug seems to be fixed or the feature seems to be doing what it’s supposed to do and the test suite runs fine locally.</p>



<p>I then clean up the commit series with “<code>git rebase -i</code>” (or if it is a single commit I can instead use just “<code>git commit --amend</code>“).</p>



<p>The commit series should be a set of logical changes that are related to this change and not any more than necessary, but kept separate if they are separate. Each commit also gets its own proper commit message. Unrelated changes should be split out into its own separate branch and subsequent separate pull request.</p>



<pre>git push origin bagder/my-new-stuff-or-bugfix</pre>



<h2>Make the push a pull request</h2>



<p>On GitHub, I then make the newly pushed branch into a <a href="https://github.com/curl/curl/pulls">pull request</a> (aka “a PR”). It will then become visible in the list of pull requests on the site for the curl source repository, it will be announced in the #curl IRC channel and everyone who follows the repository on GitHub will be notified accordingly.</p>



<p>Perhaps most importantly, a pull request kicks of a flood of CI jobs that will build and test the code in numerous different combinations and on several platforms, and the results of those tests will trickle in over the coming hours. When I write this, we have around 90 different CI jobs – per pull request – and something like 8 different code analyzers will scrutinize the change to see if there’s any obvious flaws in there.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png"><img loading="lazy" width="2686" height="1510" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png" alt=""></a><figcaption>CI jobs per platform over time. Graph snapped on November 5, 2020</figcaption></figure>



<h2>A branch in the actual curl/curl repo</h2>



<p>Most contributors who would work on curl would not do like me and make the branch in the curl repository itself, but would rather do them in their own forked version instead. The difference isn’t that big and I <em>could</em> of course also do it that way.</p>



<h2>After push, switch branch</h2>



<p>As it will take some time to get the full CI results from the PR to come in (generally a few hours), I switch over to the next branch with work on my agenda. On a normal work-day I can easily move over ten different branches, polish them and submit updates in their respective pull-requests.</p>



<p>I can go back to the&nbsp;master branch again with ‘<code>git checkout master</code>‘ and there I can “<code>git pull</code>” to get everything from upstream – like when my fellow developers have pushed stuff in the mean time.</p>



<h2>PR comments or CI alerts</h2>



<p>If a reviewer or a CI job find a mistake in one of my PRs, that becomes visible on GitHub and I get to work to handle it. To either fix the bug or discuss with the reviewer what the better approach might be.</p>



<p>Unfortunately, flaky CI jobs is a part of life so very often there ends up one or two red markers in the list of CI jobs that can be ignored as the test failures in them are there due to problems in the setup and not because of actual mistakes in the PR…</p>



<p>To get back to my branch for that PR again, I “<code>git checkout bagder/my-new-stuff-or-bugfix</code>“, and fix the issues.</p>



<p>I normally start out by doing follow-up commits that repair the immediate mistake and push them on the branch:</p>



<pre>git push origin <code>bagder/my-new-stuff-or-bugfix</code></pre>



<p>If the number of fixup commits gets large, or if the follow-up fixes aren’t small, I usually end up doing a squash to reduce the number of commits into a smaller, simpler set, and then force-push them to the branch.</p>



<p>The reason for that is to make the patch series easy to review, read and understand. When a commit series has too many commits that changes the previous commits, it becomes hard to review.</p>



<h2>Ripe to merge?</h2>



<p>When the pull request is ripe for merging (independently of who authored it), I switch over to the master branch again and I merge the pull request’s commits into it. In special cases I cherry-pick specific commits from the branch instead. When all the stuff has been yanked into master properly that should be there, I push the changes to the remote.</p>



<p>Usually, and especially if the pull request wasn’t done by me, I also go over the commit messages and polish them somewhat before I push everything. Commit messages should follow our style and mention not only which PR that it closes but also which issue it fixes and properly give credit to the bug reporter and all the helpers – using the right syntax so that our automatic tools can pick them up correctly!</p>



<p>As already mentioned above, I merge fast-forward or rebased into master. No merge commits.</p>



<h2>Never merge with GitHub!</h2>



<p>There’s a button GitHub that says “rebase and merge” that could theoretically be used for merging pull requests. I <em>never</em> use that (and if I could, I’d disable/hide it). The reasons are simply:</p>



<ol><li>I don’t feel that I have the proper control of the commit message(s)</li><li>I can’t select to squash a subset of the commits, only all or nothing</li><li>I often want to cleanup the author parts too before push, which the UI doesn’t allow</li></ol>



<p>The downside with not using the merge button is that the message in the  PR says “closed by [hash]” instead of “merged in…” which causes confusion to a fair amount of users who don’t realize it means that it actually means the same thing! I consider this is a (long-standing) GitHub UX flaw.</p>



<h2>Post merge</h2>



<p>If the branch has nothing to be kept around more, I delete the local branch again with “<code>git branch -d [name]</code>” and I remove it remotely too since it was completely merged there’s no reason to keep the work version left.</p>



<p>At any given point in time, I have some 20-30 different local branches alive using this approach so things I work on over time all live in their own branches and also submissions from various people that haven’t been merged into master yet exist in branches of various maturity levels. Out of those local branches, the number of concurrent pull requests I have in progress can be somewhere between just a few up to ten, twelve something.</p>



<h2>RELEASE-NOTES</h2>



<p>Not strictly related, but in order to keep interested people informed about what’s happening in the tree, we sync the <a href="https://github.com/curl/curl/blob/master/RELEASE-NOTES">RELEASE-NOTES</a> file every once in a while. Maybe every 5-7 days or so. It …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043731</guid>
            <pubDate>Tue, 10 Nov 2020 08:08:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Event, 18th Nov: Building a Notion Website Live]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25043693">thread link</a>) | @saviorand
<br/>
November 9, 2020 | http://optemization.com/how-to-build-notion-website | <a href="https://web.archive.org/web/*/http://optemization.com/how-to-build-notion-website">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-how-to-build-notion-website"><div id="block-128d927961c546d8870b1a51a5579a93"><picture><source srcset="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=1500" alt="image" loading="lazy"></picture></div><h2 id="block-d2269dc812f14b90932490290a797437"><span id="d2269dc812f14b90932490290a797437"></span><span><span>🖥️ You can do websites on Notion?</span></span></h2><blockquote id="block-2d6de681f9a04563af1656151a4a72ac"><span><span>If you spend anytime on #productivity Twitter or r/Notion you know that building websites on Notion, is the new normal :)  Thanks to projects like Super and Fruition, Notion pages can turn into real websites, with custom domains, analytics, and styling!

My new teammate Valentine, just shared a </span><span><a target="_blank" rel="noopener noreferrer" href="https://optemization.com/notion-landing-page-guide">comprehensive guide</a></span><span> on how to build your own Notion website. 

However, this stuff is really visual, so we thought it'd be super fun to host an </span><span><strong>event where we conceptualize, design and ship a Notion website LIVE</strong></span><span>! 

So two things: RSVP below and tell us what kind of website do you want to build!</span></span></blockquote><h2 id="block-1b34e201f6484d4680c97fe88b965d4c"><span id="1b34e201f6484d4680c97fe88b965d4c"></span><span><span>🖋️ Sign Up</span></span></h2><h2 id="block-b67496c5fc8b4bdcb04d5891dc6baf0b"><span id="b67496c5fc8b4bdcb04d5891dc6baf0b"></span><span><span>😃 Are you excited?</span></span></h2><div id="block-c91d2a953127494f86a21d77c34339ea"><div id="block-f2134537e8d04052915c6399871b09eb"><blockquote id="block-7d5a84aa13624e43ba7e69fbac453dea"><span><span>Share the event on the ze twitter 🙏</span></span></blockquote></div></div></article></div></div></div>]]>
            </description>
            <link>http://optemization.com/how-to-build-notion-website</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043693</guid>
            <pubDate>Tue, 10 Nov 2020 07:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2020 Haskell Is Ready for Prime Time]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043675">thread link</a>) | @_query
<br/>
November 9, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There’s been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it’s ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That’s how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It’s really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it’s highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it’s finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there’s now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it’s finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043675</guid>
            <pubDate>Tue, 10 Nov 2020 07:50:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Poignant Guide to Ruby]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043544">thread link</a>) | @creolabs
<br/>
November 9, 2020 | https://poignant.guide/book/chapter-2.html | <a href="https://web.archive.org/web/*/https://poignant.guide/book/chapter-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<h2>1. Opening This Book</h2>

<p>Pretend that you’ve opened this book (although you probably <em>have</em> opened this
book), just to find a huge onion right in the middle crease of the book. (The
manufacturer of the book has included the onion at my request.)</p>

<p>So you’re like, “Wow, this book comes with an onion!” (Even if you don’t
particularly like onions, I’m sure you can appreciate the logistics of shipping
any sort of produce discreetly inside of an alleged programming manual.)</p>

<p>Then you ask yourself, “Wait a minute. I thought this was a book on Ruby, the
incredible new programming language from Japan. And although I can appreciate
the logistics of shipping any sort of produce discreetly inside of an alleged
programming manual: Why an onion? What am I supposed to do with it?”</p>

<p>No. Please don’t puzzle over it. You don’t need to do anything with the onion.
Set the onion aside and let <em>it</em> do something with <em>you</em>.</p>

<p>I’ll be straight with you. I want you to cry. To weep. To whimper sweetly. This
book is a <strong>poignant</strong> guide to Ruby. That means code so beautiful that tears
are shed. That means gallant tales and somber truths that have you waking up the
next morning in the arms of this book. Hugging it tightly to you all the day
long. If necessary, fashion a makeshift hip holster for <em>Why’s (Poignant) Guide
to Ruby</em>, so you can always have this book’s tender companionship.</p>

<p>You really must sob once. Or at least sniffle. And if not, then the onion will
make it all happen for you.</p>





<h2>2. The Dog Story</h2>

<p>So try this first bit of poignancy on for size:</p>

<p>One day I was walking down one of those busy roads covered with car dealerships
(this was shortly after my wedding was called off) and I found an orphaned dog
on the road. A woolly, black dog with greenish red eyes. I was kind of feeling
like an orphan myself, so I took a couple balloons that were tied to a pole at
the dealership and I relocated them to the dog’s collar. Then, I decided he
would be my dog. I named him Bigelow.</p>

<p>We set off to get some Milkbones for Bigelow and, afterwards, head over to my
place, where we could sit in recliners and listen to Gorky’s Zygotic Mynci. Oh,
and we’d also need to stop by a thrift store and get Bigelow his own recliner.</p>

<p>But Bigelow hadn’t accepted me as his master. So five minutes later, the stupid
dog took a different crosswalk than I did and I never caught up. So whereas he
had previously only been lost once, he was now lost twice. I slowed my pace
towards the life of Milkbones and an extra recliner. I had a dog for five
minutes.</p>

<p>Stupid Benedict Arnold of a dog. I sat on a city bench and threw pine cones at a
statue of three sheep crossing a bridge. After that, I wept for hours. The tears
just came. Now there’s a little something poignant to get you started.</p>

<p>I wonder where he went with all those balloons. That crazy dog must have looked
like a party with legs.</p>

<p>It wasn’t much later that I pulled my own Bigelow. I printed out a bunch of
pages on Ruby. Articles found around the Web. I scanned through them on a train
ride home one day. I flipped through them for five minutes and then gave up. Not
impressed.</p>

<p>I sat, staring out the window at the world, a life-sized blender mixing graffiti
and iron smelts before my eyes. <em>This world’s too big for such a a little
language</em>, I thought. <em>Poor little thing doesn’t stand a chance. Doesn’t have
legs to stand on. Doesn’t have arms to swim.</em></p>

<p>And yet, there I was. One little man on a flimsy little train (and I even still
had a baby tooth to lose at the time) out of billions of people living on a
floating blue rock. How can I knock Ruby? Who’s to say that I’m not going to
happen to choke on my cell phone and die later that evening. Why’s dead, Ruby
lives on.</p>

<p>The gravestone:</p>

<blockquote>
  <p>What’s in his trachea? Oh, look, a Nokia!</p>
</blockquote>

<p>Just my luck. Finally get to have a good, long sleep underground, only to be
constantly disturbed by <em>Pachelbel’s Canon</em> going off in my stomach.</p>



<h2>3. The Red Sun Rises</h2>

<p>So, now you’re wondering why I changed my mind about Ruby. The quick answer is:
we clicked.</p>

<p>Like when you meet Somebody in college and they look like somebody who used to
hit you in the face with paintbrushes when you were a kid. And so, impulsively,
you conclude that this new Somebody is likely a non-friend. You wince at their
hair. You hang up phones loudly during crucial moments in their anecdotes. You
use your pogo stick right there where they are trying to walk!</p>

<p>Six months later, somehow, you and Somebody are sitting at a fountain having a
perfectly good chat. Their face doesn’t look so much like that childhood
nemesis. You’ve met the Good Twin. You clicked.</p>

<p>So whereas I should probably be pounding your teeth in with hype about Ruby and
the tightly-knit cadre of pertinent acronyms that accompany it everywhere
(whetting the collective whistles of your bosses and their bosses’ bosses),
instead I will just let you coast. I’ll let you free-fall through some code,
interjecting occasionally with my own heartfelt experiences. It’ll be quite
easy, quite natural.</p>

<p>I should offer you some sort of motivation, though. So, Smotchkkiss, I’m going
to give my three best reasons to learn Ruby and be done with it.</p>

<ol>
  <li>
    <p><strong>Brain health.</strong></p>

    <p>Vitamin R. Goes straight to the head. Ruby will teach you to <em>express</em> your
ideas through a computer. You will be writing stories for a machine.</p>

    <p>Creative skills, people. Deduction. Reason. Nodding intelligently. The
language will become a tool for you to better connect your mind to the world.
I’ve noticed that many experienced users of Ruby seem to be clear thinkers and
objective. (In contrast to: heavily biased and coarse.)</p>
  </li>
  <li>
    <p><strong>One man on one island.</strong></p>

    <p>Ruby was born in Japan. Which is freaky. Japan is not known for its
software. And since programming languages are largely written in English, who
would suspect a language to come from Japan?</p>

    <p>And yet, here we have Ruby. Against the odds, Yukihiro Matsumoto created
Ruby on February 24, 1993. For the past ten years, he has steadily brought Ruby
to a global audience. It’s triumphant and noble and all that. Support diversity.
Help us tilt the earth just a bit.</p>
  </li>
  <li>
    <p><strong>Free.</strong></p>

    <p>Using Ruby costs nothing. The code to Ruby itself is open for all of the
world to inhale/exhale. Heck, this book is free. It’s all part of a great, big
giveaway that should have some big hitch to it.</p>

    <p>You’d think we’d make you buy vacuums or timeshare or fake Monets. You’d
think there’d be a 90 minute presentation where the owner of the company comes
out at the end and knuckles you into sealing the deal.</p>

    <p>Nope, free.</p>
  </li>
</ol>

<p>With that, it’s time for the book to begin. You can now get out your highlighter
and start dragging it along each captivating word from this sentence on. I think
I have enough hairspray and funny money on my person to keep me sustained until
the final page.</p>



<h2>4. How Books Start</h2>

<p>Now, if you ever have read a book, you know that no book can properly start
without an exorbitant amount of synergy. Yes, synergy. Maybe you didn’t know
this. Synergy means that you and I are supposed to cooperate to make this a
great reading experience.</p>

<p>We start off the book by getting along well in the Introduction. This
togetherness, this <strong>synergy</strong>, propels us through the book, with me guiding you
on your way. You give me a reassuring nod or snicker to indicate your progress.</p>

<p>I’m Peter Pan holding your hand. Come on, Wendy! Second star to the right and on
till morning.</p>

<p>One problem here. I don’t get along well with people. I don’t hold hands very
well.</p>

<p>Any of my staff will tell you. At the Opening Ceremonies of This Book (a catered
event with stadium seating), I discovered that the cucumber sandwiches weren’t
served in tea towels. As a result, the butter hadn’t set with the cucumbers
right… Anyways, I made a big scene and set fire to some of the advertising
trucks outside. I smashed this spotlight to pieces and so on. I had this loud
maniacal laughing thing going on deep into that night. It was a real mess.</p>

<p>But, since I don’t get along well with people, I hadn’t invited anyone but
myself to the Opening Ceremonies of This Book. So it wasn’t really that
embarrassing. I kept it under wraps and no one found out about the whole ordeal.</p>

<p>So you’ve got to know that <strong>synergy</strong> doesn’t actually mean <strong>synergy</strong> in this
book. I can’t do normal <strong>synergy</strong>. No, in this book, <strong>synergy</strong> means
<strong>cartoon foxes</strong>. What I’m saying is: this book will be starting off with an
exorbitant amount of <strong>cartoon foxes</strong>.</p>

<p>And I will be counting on you to turn them into <strong>synergy</strong>.</p>


      <p>
      <a href="https://poignant.guide/book/chapter-3.html">Turn page.</a>
      </p>
    </div></div>]]>
            </description>
            <link>https://poignant.guide/book/chapter-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043544</guid>
            <pubDate>Tue, 10 Nov 2020 07:26:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My new GoBlog-Blog is finally alive]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043497">thread link</a>) | @jlelse
<br/>
November 9, 2020 | https://jlelse.blog/posts/new-blog-goblog | <a href="https://web.archive.org/web/*/https://jlelse.blog/posts/new-blog-goblog">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I spent months coding and it’s finally time to say “Hello World”!</p><p>Until a few hours ago I used a complicated setup of Hugo, Drone, Webmentiond, Caddy and some self-programmed tools for my blog to have an IndieWeb compatible blog with support for MicroPub, Webmentions, ActivityPub, IndieAuth, Telegram notifications and more. A use case that actually calls for a dynamic backend.</p><p>The dynamic backend is finally here. Finally no more workarounds!</p><p>I decided to develop my own CMS because it gives me the opportunity to know my code inside and out and in case of problems I know directly where to look for it. I developed the code to the best of my conscience so that everything is done as efficiently as possible. And I will be able to add more features to my blog much easier in the future!</p><p>I am especially happy about the function that I can now finally edit or delete posts. Far too often it happened to me that I had mistakes in the text or made stupid mistakes while creating the post itself. These can now be corrected directly.</p><p>To the technology behind the blog: The CMS is written in Go (my current favorite programming language!) and SQLite is used for database purposes.</p><p>The code is available <a href="https://jlel.se/goblog" target="_blank" rel="noopener">on my Gitea instance</a>. In the next days I will fix bugs I find and add a documentation and license.</p><p>P.S.: Sorry for the name of this project, “GoBlog” is a pretty lame name, feel free to send me better suggestions!</p></div></div>]]>
            </description>
            <link>https://jlelse.blog/posts/new-blog-goblog</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043497</guid>
            <pubDate>Tue, 10 Nov 2020 07:15:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hottest FinTech Accelerators in London]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043490">thread link</a>) | @cpepper
<br/>
November 9, 2020 | https://codeandpepper.com/fintech-accelerators-in-london/ | <a href="https://web.archive.org/web/*/https://codeandpepper.com/fintech-accelerators-in-london/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
<p>London is a sprawling economic hub that boasts a mind-boggling 750 FinTech companies. The “Big Smoke” represents <a rel="nofollow" href="https://www.whitecapconsulting.co.uk/articles/20-essential-stats-about-uk-fintech/">84 percent</a>&nbsp;of the UK’s VC, CVC, and PE investment volume, making it a desirable place for startups to find their financial feet. Looking for investors? Connections? Opportunities? Here are 6 FinTech accelerators in London you need to know about in 2020.&nbsp;</p>



<h2 id="h-a-list-of-fintech-accelerators-for-startups-in-london"><strong>A list of FinTech accelerators for startups in London</strong></h2>



<p>Below you will find the most interesting FinTech accelerators for startups based in London.</p>
<ul>
<li data-amp-original-style="text-decoration: none;">Seedcamp</li>
<p>Where? <a href="https://www.google.com/search?q=5+Bonhill+St%252C+Shoreditch%252C+London+EC2A+4BX&amp;oq=5+Bonhill+St%252C+Shoreditch%252C+London+EC2A+4BX&amp;aqs=chrome..69i57&amp;sourceid=chrome&amp;ie=UTF-8%23" rel="nofollow">5 Bonhill St, Shoreditch, London EC2A 4BX</a></p>
<p>Smack-bang in trendy Shoreditch, <a href="https://seedcamp.com/" rel="nofollow">Seedcamp</a> calls itself “Europe’s seed fund,” and this isn’t an exaggeration. <strong>London FinTech company</strong> identifies and invests in early-stage companies and establishes connections through its network of partners. There’s an emphasis on European founders, but Seedcamp, founded in 2007, has a truly global reach and has powered FinTech companies like Revolut and TransferWise.&nbsp;</p>
<p><a href="https://twitter.com/seedcamp" rel="nofollow">Follow Seedcamp on Twitter</a></p>
<li data-amp-original-style="text-decoration: none;">Ignite</li>
<p><i>Where?</i> <a href="https://www.google.com/search?q=113+Walton+St%2C+Chelsea%2C+London+SW3+2HP&amp;oq=113+Walton+St%2C+Chelsea%2C+London+SW3+2HP&amp;aqs=chrome..69i57&amp;sourceid=chrome&amp;ie=UTF-8#" rel="nofollow"><em>113 Walton St, Chelsea, London SW3 2HP</em></a></p>
<p>Founded in 2011, <a href="https://www.ignite.io/" rel="nofollow">Ignite</a> is one of the leading accelerator programs in the world. It has invested in more than 150 companies so far and even partnered with Google. With backing from the European Union, their three-month pre-accelerator and six-month accelerator programs provide you with the resources you need to scale your business. Ignite offers investment opportunities to FinTech accelerators worldwide, so you don’t need to be a UK-based company.&nbsp;</p>
<p><i>What to expect: £20,000 in exchange for 8 percent equity.&nbsp;</i></p>
<p><a href="https://twitter.com/igniteaccel?lang=en" rel="nofollow">Twitter</a></p>
<figure><amp-img width="2560" height="1707" src="https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-scaled.jpg" alt="FinTech in London - vital companies." srcset="https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-scaled.jpg 2560w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-300x200.jpg 300w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-1024x683.jpg 1024w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-768x512.jpg 768w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-1536x1024.jpg 1536w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-2048x1365.jpg 2048w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-314x209.jpg 314w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-150x100.jpg 150w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-720x480.jpg 720w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-864x576.jpg 864w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-432x288.jpg 432w" sizes="(max-width: 2560px) 100vw, 2560px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="2560" height="1707" src="https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-scaled.jpg" alt="FinTech in London - vital companies." srcset="https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-scaled.jpg 2560w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-300x200.jpg 300w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-1024x683.jpg 1024w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-768x512.jpg 768w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-1536x1024.jpg 1536w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-2048x1365.jpg 2048w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-314x209.jpg 314w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-150x100.jpg 150w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-720x480.jpg 720w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-864x576.jpg 864w, https://codeandpepper.com/wp-content/uploads/2020/03/benjamin-davies-Oja2ty_9ZLM-unsplash-1-432x288.jpg 432w" sizes="(max-width: 2560px) 100vw, 2560px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzE3MDcnIHdpZHRoPScyNTYwJyB4bWxucz0naHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmcnIHZlcnNpb249JzEuMScvPg=="></amp-img></figure>
<li data-amp-original-style="text-decoration: none;">Bethnal Green Ventures</li>
<p><i>Where?</i> <a href="https://www.google.com/search?q=20-30+Whitechapel+Rd%2C+Shadwell%2C+London+E1+1EW&amp;oq=20-30+Whitechapel+Rd%2C+Shadwell%2C+London+E1+1EW&amp;aqs=chrome..69i57&amp;sourceid=chrome&amp;ie=UTF-8#" rel="nofollow"><em>20-30 Whitechapel Rd, Shadwell, London E1 1EW</em></a></p>
<p>If you’re a <strong>FinTech startup</strong> based around a good cause, <a href="https://bethnalgreenventures.com/" rel="nofollow">Bethnal Green Ventures </a>wants to hear from you! This accelerator provides investments to companies that want to change the world. There’s a focus on sustainable and democratic tech, but this accelerator is open to all ideas, with an intensive program that runs twice a year. Launched in 2010, Bethnal Green Ventures offers mentorship and educational opportunities as well as funding.&nbsp;</p>
<p><i>What to expect: £20,000 in return for 6 percent equity.&nbsp;&nbsp;</i></p>
<p><a href="https://twitter.com/bg_ventures" rel="nofollow">Follow Bethnal Freen Ventures on Twitter</a></p>
<li>Startupbootcamp</li>
<p><i>Where? </i><a href="https://www.google.com/search?q=Techspace+Shoreditch+25+Luke+St%2C+London+EC2A+4DS&amp;oq=Techspace+Shoreditch+25+Luke+St%2C+London+EC2A+4DS&amp;aqs=chrome..69i57&amp;sourceid=chrome&amp;ie=UTF-8#" rel="nofollow"><i>Techspace Shoreditch 25 Luke St, London EC2A 4DS</i></a></p>
<p>The name says it all. This accelerator attracts FinTech startups looking for investment and mentoring opportunities in London. The super-intensive 3+3 month program connects 10 selected companies with more than 100 industry experts and office space in the middle of London. <a href="https://www.startupbootcamp.org/accelerator/fintech-london/" rel="nofollow">Startupbootcamp</a> was founded in 2010.</p>
<p><a href="https://twitter.com/sbootcamp" rel="nofollow">Follow Startupbootcamp on Twitter</a></p>
<li>Barclays Accelerator</li>
<p><i>Where?</i><a href="https://www.google.com/search?q=41+Luke+St%2C+Hackney%2C+London+EC2A+4DP&amp;oq=41+Luke+St%2C+Hackney%2C+London+EC2A+4DP&amp;aqs=chrome..69i57&amp;sourceid=chrome&amp;ie=UTF-8#" rel="nofollow"><em> </em><i>41 Luke St, Hackney, London EC2A 4DP</i></a></p>
<p>Powered by Techstars, <a rel="nofollow" href="https://home.barclays/who-we-are/innovation/barclays-accelerator/">Barclays Accelerator</a> is an award-winning 13-week program based in New York City, Tel Aviv, and, of course, London. Lucky startups will get access to Rise, the largest FinTech co-working space in the capital and the chance to meet the world’s most influential investors. Alumni include credit score company Aire and cloud-based payroll service Dotpay, as well as a number of Code &amp; Pepper partners:&nbsp; <a href="https://codeandpepper.com/case-studies/nearshore-it-outsourcing-lusid/">Fibourne</a>, <a href="https://codeandpepper.com/case-studies/insurtech-development-design-nimbla/">Nimbla</a>, <a href="https://codeandpepper.com/case-studies/legaltech-design-development-oathello/">Oathello </a>and <a href="https://www.simudyne.com/">Simudyne</a>.</p>
<p><i>What to expect: Up to £120,000 for 6 percent equity.</i></p>
<p><a rel="nofollow" href="https://twitter.com/ThinkRiseLDN">Follow Rise on Twitter</a></p>
<li>Accenture Fintech Innovation Lab</li>
<p>Where? <a href="https://www.bing.com/maps?where=Accenture%20%2C%20London%2C%20London%20EC3M%203BD%2C%20GB">Accenture, London, London EC3M 3BD, GB</a></p>
<p>The <a rel="nofollow" href="https://www.fintechinnovationlab.com/london/london-fintech-innovation-lab/">FinTech Innovation Lab London </a>has been an annual accelerator program started and conducted by Accenture since 2012. It operates by offering zealous, newly-founded companies business mentoring for three months, as well as chances for networking with banking giants and good advice from experienced entrepreneurs. What drives the London branch of FinTech Innovation Lab is the opportunity to be close to promising projects at the very beginning.</p>
<p>Besides the word “London” in its name, the accelerator program accepts applications from the whole world.</p>
<p><a rel="nofollow" href="https://www.linkedin.com/company/fintech-innovation-lab-london/">Follow FinTech Innovation Lab London on Linkedin</a>.</p>
</ul>



<h2 id="h-fintech-accelerators-in-london-your-thoughts"><strong>FinTech accelerators in London – your thoughts</strong></h2>



<p>So that’s our curated list of 6 places to drop by. Do you have any experiences connected with these accelerators? Or maybe you’ve benefited directly from their initiatives, just like some of our <a href="https://codeandpepper.com/clients/">clients</a>? Tell your story on our Facebook profile! If you feel like this post might prove useful to other founders and business owners you know, feel free to share it with them. Sharing is caring, and we deeply care about the growth of the FinTech community.</p>
          </div></div>]]>
            </description>
            <link>https://codeandpepper.com/fintech-accelerators-in-london/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043490</guid>
            <pubDate>Tue, 10 Nov 2020 07:13:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kotlin for Interviews – Part 5: Frequently Used Code Snippets]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043477">thread link</a>) | @joannawyka
<br/>
November 9, 2020 | https://blog.kotlin-academy.com/kotlin-for-interviews-part-5-frequently-used-code-snippets-444ad4d137f5 | <a href="https://web.archive.org/web/*/https://blog.kotlin-academy.com/kotlin-for-interviews-part-5-frequently-used-code-snippets-444ad4d137f5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://medium.com/@sherryyuan?source=post_page-----444ad4d137f5--------------------------------" rel="noopener"><img alt="Sherry Yuan" src="https://miro.medium.com/fit/c/96/96/1*vPHsbna8rWXF2trnsf3w3Q.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/9792/0*_88Jukrh3Lx8aLKV" width="4896" height="3264" srcset="https://miro.medium.com/max/552/0*_88Jukrh3Lx8aLKV 276w, https://miro.medium.com/max/1104/0*_88Jukrh3Lx8aLKV 552w, https://miro.medium.com/max/1280/0*_88Jukrh3Lx8aLKV 640w, https://miro.medium.com/max/1400/0*_88Jukrh3Lx8aLKV 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*_88Jukrh3Lx8aLKV?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@fabulu75?utm_source=medium&amp;utm_medium=referral" rel="noopener">Fabrice Villard</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="26ee">This is Part 5 of Kotlin for Interviews, a series where I go over Kotlin functions and code snippets that came up often during my Android interview prep. I also compiled a cheatsheet that covers all 5 parts of this series, which you can find <a rel="noopener" href="https://blog.kotlin-academy.com/kotlin-for-interviews-cheatsheet-88a9831e9d55">here</a>.</p><p id="01a2">You can find Part 1: Common Data Types <a rel="noopener" href="https://blog.kotlin-academy.com/kotlin-for-interviews-part-1-common-data-types-886ea1e40645">here,</a> Part 2: Collection Functions <a rel="noopener" href="https://blog.kotlin-academy.com/kotlin-for-interviews-part-2-collection-functions-a4a488fa0a14">here</a>, Part 3: Numbers and Math <a rel="noopener" href="https://blog.kotlin-academy.com/kotlin-for-interviews-part-3-numbers-and-math-786660295cea">here</a>, and Part 4: Iteration <a rel="noopener" href="https://blog.kotlin-academy.com/kotlin-for-interviews-part-4-iteration-b176dee4f1ae">here</a>.</p><p id="b016">This part covers:</p><ul><li id="54c0"><a href="#7ff6" rel="noopener">Creating graphs in adjacency list form</a></li><li id="7140"><a href="#41f6" rel="noopener">Breadth first search</a></li><li id="59ac"><a href="#04fe" rel="noopener">Depth first search</a></li><li id="c993"><a href="#de2a" rel="noopener">Tree traversal</a></li><li id="1f74"><a href="#a810" rel="noopener">Dynamic programming/memoization</a></li></ul><p id="f75e">We’ll go over blocks of code that I found myself using frequently for many different problems. For example, a lot of interview problems boil down to depth-first search, and I used variations of the basic depth-first search code snippet to solve them.</p><p id="44f7">For many graph problems, you’ll be given a list of pairs of nodes, where the second node depends on the first node (or vice versa depending on your interviewer). For example, a pair that looks like [0, 1] means in to visit node 1 you have to first visit 0. However, most graph algorithms require an <a href="https://www.geeksforgeeks.org/graph-and-its-representations/" rel="noopener">adjacency list representation</a>, so here’s an algorithm that takes in a list of pairs of nodes and transforms it into an adjacency list.</p><p id="8a38">Given this sample input:</p><p id="5c2b">[[1, 2], [1, 3], [1, 4], [2, 4], [2, 5], [3, 6], [4,6], [4, 7], [5, 4], [5, 7]]</p><p id="534e">Which represents this graph:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/678/0*rgGD2S73ez7BXF3p.gif" width="339" height="196" srcset="https://miro.medium.com/max/552/0*rgGD2S73ez7BXF3p.gif 276w, https://miro.medium.com/max/678/0*rgGD2S73ez7BXF3p.gif 339w" sizes="339px" data-old-src="https://miro.medium.com/freeze/max/60/0*rgGD2S73ez7BXF3p.gif?q=20"></p></div></div></div></figure><p id="ed37">We want to create the following adjacency list:</p><p id="4281">[[1: [2, 4, 3]], [2: [4, 5]], [3: [6]], [4: [6, 7, 3]], [5: [4, 7]], [7: [6]]]</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/822/0*5sXb9IqIdUnslrrg.gif" width="411" height="339" srcset="https://miro.medium.com/max/552/0*5sXb9IqIdUnslrrg.gif 276w, https://miro.medium.com/max/822/0*5sXb9IqIdUnslrrg.gif 411w" sizes="411px" data-old-src="https://miro.medium.com/freeze/max/60/0*5sXb9IqIdUnslrrg.gif?q=20"></p></div></div></figure><pre><span id="d234"><strong>fun createAdjacencyList(pairs: Array&lt;IntArray&gt;) {<br>    val graph: HashMap&lt;Int, MutableList&lt;Int&gt;&gt; = <em>hashMapOf</em>()<br>    pairs.<em>forEach </em>{ pair -&gt;<br>        if (!graph.containsKey(pair[0])) {</strong><br><em>            // If the current node isn't in the adjacency list yet, <br>            // add it and create its dependency list starting with <br>            // pair[1]</em><br>            <strong>graph[pair[0]] = <em>mutableListOf</em>(pair[1])</strong><br>        <strong>} else {</strong><br><em>            // Otherwise, append pair[1] to its existing dependency  <br>            // list.<br>            </em><strong>val dependencies = graph[pair[0]]                 <br>            dependencies.add(pair[1])<br>            graph[pair[0]] = dependencies<br>        }<br>    }<br>}</strong></span></pre><p id="85d8">Note that this algorithm is for directed graphs. If you’re told the graph is undirected — meaning the pair [0, 1] just means 0 and 1 have an edge between them — just repeat the code in the <code>forEach()</code> loop with <code>pair[0]</code> and <code>pair[1]</code> swapped, so that the <code>MutableList</code>s in the graph represent all adjacent nodes rather than directed dependencies only.</p><p id="f882">Many interview problems require traversing graphs — from finding a node to checking for cycles to finding the length of a path between two nodes. Breadth-first search is one way to do it. The algorithm starts at some node of the graph and, with the help of a queue, explores all of the neighbor nodes at the present depth before moving on to the nodes at the next depth level.</p><p id="f276">Here’s a basic version that traverses through all nodes reachable from the first one. You can modify it depending on the graph problem you’re solving.</p><pre><span id="3d8a"><strong>fun bfs(nodes: List&lt;List&lt;Int&gt;&gt;) {<br>    val visited = BooleanArray(nodes.size) { false }<br>    </strong><em>// Create a queue and add 0 to represent the index of the <br>    // first node</em><strong><br>    val queue: MutableList&lt;Int&gt; = mutableListOf(0)<br>    while (queue.isNotEmpty()) {<br>        </strong><em>// Dequeue a node from queue</em><br><strong>        val node = queue.removeAt(0)<br>        </strong><em>// Add all of the node's unvisited neighbors to the queue</em><br><strong>        if (!visited[node]) {<br>            nodes[node].forEach {<br>                queue.add(it)<br>            }<br>            </strong><em>// Mark the dequeued node as visited</em><strong><br>            visited[node] = true<br>        }<br>    }<br>}</strong></span></pre><p id="b5d9">Depth first search can also be used for graph traversal problems. The algorithm uses a stack instead of a queue, and explores the current node branch as far as possible before being forced to backtrack and expand to other nodes.</p><p id="1695">Here’s a recursive version that relies on a function call stack rather than an explicit stack variable. You could write an iterative version of the algorithm using a stack variable, as well.</p><pre><span id="6674"><strong>fun dfs(nodes: List&lt;List&lt;Int&gt;&gt;) {<br>    val visited = BooleanArray(nodes.size) { false }<br>    helper(nodes, 0, visited)<br>}<p> fun helper(nodes: List&lt;List&lt;Int&gt;&gt;, node: Int, visited: BooleanArray){<br>    visited[node] = true<br>    nodes[node].forEach { <br>        if (!visited[it]) {<br>            helper(nodes, it, visited)<br>        }<br>    }<br>}</p></strong></span></pre><p id="fe20">Tree problems are very common in interviews. Some examples are finding the lowest common ancestor of two nodes, summing values of all nodes in a tree, etc.</p><h2 id="af17">Binary tree</h2><p id="210a">Binary trees are the most common tree you’ll encounter in interviews. A node for a binary tree will look something like this:</p><pre><span id="799f"><strong>class Node(<br>    var key: Int, <br>    var left: Node? = null, <br>    var right: Node? = null<br>)</strong></span></pre><p id="f740">Note that not all binary trees are binary search trees, and you shouldn’t assume you’re given a BST unless your interviewer confirms it. A binary tree is only a BST if it also fulfills the following criteria:</p><ul><li id="3333">The left subtree of a node contains only nodes with keys lesser than the node’s key.</li><li id="ac35">The right subtree of a node contains only nodes with keys greater than the node’s key.</li><li id="cc9a">The left and right subtree each must also be a binary search tree.</li></ul><p id="404d">Let’s use this tree (which isn’t a BST!) as an example:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/692/1*h1NH-OTJ8cfHdoHa2eyRSQ.png" width="346" height="258" srcset="https://miro.medium.com/max/552/1*h1NH-OTJ8cfHdoHa2eyRSQ.png 276w, https://miro.medium.com/max/692/1*h1NH-OTJ8cfHdoHa2eyRSQ.png 346w" sizes="346px" data-old-src="https://miro.medium.com/max/60/1*h1NH-OTJ8cfHdoHa2eyRSQ.png?q=20"></p></div></div></figure><p id="e216">You can construct it using the following code:</p><pre><span id="4e2f"><strong>val node4 = Node(4)<br>val node7 = Node(7)<br>val node6 = Node(6, node4, node7)<br>val node11 = Node(11)<br>val node9 = Node(9, node6, node11)<br>val node2 = Node(2)<br>val node5 = Node(5)<br>val node12 = Node(12, node2, node5)<br>val node3 = Node(3, node12)<br>val node1 = Node(1, node9, node3)</strong></span></pre><p id="1981">Here’s what a pre-order traversal would look like:</p><pre><span id="c617"><strong>fun preOrder(n: Node?) {<br>    n?.let { node -&gt;<br>        print(node.key)<br>        preOrder(node.left)<br>        preOrder(node.right)<br>    }<br>}</strong></span><span id="1af2"><strong>preOrder(node1)</strong> <em>// prints 1 9 6 4 7 11 3 12 2 5</em></span></pre><p id="1b19">Here’s what an in-order traversal would look like:</p><pre><span id="fdff"><strong>fun inOrder(n: Node?) {<br>    n?.let { node -&gt;<br>        inOrder(node.left)<br>        print(node.key)<br>        inOrder(node.right)<br>    }<br>}</strong></span><span id="d60d"><strong>inOrder(node1</strong>) <em>// prints 4 6 7 9 11 1 2 12 5 3</em></span></pre><p id="9ac2">Here’s what a post-order traversal would look like:</p><pre><span id="f525"><strong>fun postOrder(n: Node?) {<br>    n?.let { node -&gt;<br>        postOrder(node.left)<br>        postOrder(node.right)<br>        print(node.key)<br>    }<br>}</strong></span><span id="6e90"><strong>postOrder(node1)</strong> <em>// prints 4 7 6 11 9 2 5 12 3 1</em></span></pre><h2 id="e208">Tree with multiple children</h2><p id="21d6">You may also encounter trees that have an array of children rather than left and right nodes. An example of this data structure would be the Android view hierarchy, where each view may have multiple children.</p><pre><span id="c915"><strong>class Node(var value: Int) {<br>  val children: List&lt;Node&gt;<br>}</strong></span></pre><p id="12a8">In this case, you’d have to recursively call your function on all the children and the code would look something like this:</p><pre><span id="646a"><strong>fun traverse(node: Node) {<br>    print(node.key)<br>    node.children.forEach {<br>        traverse(it)<br>    }<br>}</strong></span></pre><p id="a239">Whenever you end up with a recursive algorithm that has repeated calls with same inputs, you can likely optimize it using dynamic programming. The idea is to store the results of subproblems in a table so that we don’t have to re-compute them when needed later. This reduces time complexities from exponential to polynomial. It can be implemented using either iteration or recursion.</p><h2 id="9498">Iteration</h2><p id="edbd">We start from the smallest <code>i</code> and fill the results table from there. Every subproblem we need for the current iteration should be solved already. In the final iteration, we solve for <code>i=n</code> and return that result.</p><pre><span id="df7b"><strong>fun fibonacci(n: Int): Int {</strong><br>    <em>// Initialize an array to keep track of results of subproblems<br>    // We'll use 0 as the placeholder initial value</em><br>    <strong>val results = Array(n + 1) { 0 }<br></strong><em>    // Set the base cases</em><strong><br>    results[1] = 1<br>    results[2] = 1<br>    for (i in 3..n) {<br>        results[i] = results[i-1] + results[i-2]<br>    }<br>    return results[n]</strong><br><strong>}</strong></span></pre><h2 id="093e">Recursion</h2><p id="4d62">We start from <code>i = n</code>. If the results of the subproblems we need for the current iteration already exist in the results table, we can use them. If not, we’ll call the function recursively to solve them and store the results.</p><pre><span id="e752"><strong>fun fibonacci(n: Int): Int {<br></strong><em>    // Initialize an array to keep track of results of subproblems<br>    // We'll use 0 as the placeholder initial value</em><strong><br>    val results = Array(n + 1) { 0 } <br>    </strong><em>// Set the base cases</em><strong><br>    results[1] = 1<br>    results[2] = 1<br>    return helper(n, results)<br>}</strong></span><span id="cb7e"><em>// Write a helper function that takes in the results array as an <br>// argument</em><strong><br>fun helper(n: Int, results: Array&lt;Int&gt;): Int {<br></strong><em>    // Check for the result of the subproblem you need in the <br>    // results table first</em><strong><br>    val nMinusOne: Int = if (results[n-1] != 0) {<br>        results[n-1]<br>    } else {<br></strong><em>        // Only make the recursive call to the subproblem if it's <br>        // not in the results table yet</em><strong><br>        helper(n-1, results)<br>    }<br>    val nMinusTwo: Int = if (results[n-2] != 0) {<br>        results[n-2]<br>    } else {<br>        helper(n-2, results)<br>    }<br></strong><em>    // Fill in the results table with the current results</em><strong><br>    results[n] = nMinusOne + nMinusTwo<br>    return nMinusOne + nMinusTwo<br>}</strong></span></pre><p id="8fec">And that’s the end of the Kotlin for Interview series. Here’s the <a rel="noopener" href="https://blog.kotlin-academy.com/kotlin-for-interviews-cheatsheet-88a9831e9d55">link to the cheatsheet</a> covering all 5 parts again. Good luck on your interviews!</p></div></div></section></div>]]>
            </description>
            <link>https://blog.kotlin-academy.com/kotlin-for-interviews-part-5-frequently-used-code-snippets-444ad4d137f5</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043477</guid>
            <pubDate>Tue, 10 Nov 2020 07:10:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Mass Effect not require admin rights, or how to not write a boolean check]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25042910">thread link</a>) | @__david__
<br/>
November 9, 2020 | https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/ | <a href="https://web.archive.org/web/*/https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>Hi all, it’s me again, your favorite modder who publishes a single research blog post a year. Welcome to my new blog, where I will also post maybe once a year! I got fed up with blogger’s endless unfixed bugs. I’m going to leave the content there though for historical sake.</p>
<p>I just finished a hardcore crunch to ship ALOT Installer V4, which is a complete rewrite of ALOT Installer. ALOT Installer is the Mass Effect modding scene’s main texture installation tool, built on top of aquadran’s MassEffectModder program, which can be used to install textures in a more advanced fashion. In V4 of ALOT Installer, I split the main ‘core’ features into a cross-platform .NET Core library so I can also write a frontend that works on Linux. But that’s not why I’m here today – I’m here to follow up on how I fixed Mass Effect on PC to not require elevation for good.</p>
<h2>Mass Effect on PC: About what you’d be expect from a mid 2000’s console port</h2>
<p>For those of you not in the know, Mass Effect came out on PC back in 2008, and was ported from the Xbox 360 by a studio named Demiurge, who also developed Pinnacle Station for Mass Effect. It’s… a really meh port that has not aged very well. It’s passable as a game but it has a lot of problems, even when it came out. Particle LODs not working properly, texture LODs being read backwards, ini settings being randomly reset to their defaults, the problems are pretty numerous, just to name a few. But nothing completely game breaking.</p>
<p>Well, kind of. There is one, but it’s not specifically due to Mass Effect. The big issue is that Mass Effect requires administrator rights to run, because Demiurge seems to have assumed everyone would run the game as administrator – which <em>might</em> have been OK if the game was only really developed when Windows XP existed, but Windows Vista had already been out for over a year by the time the game had released. Even back then though, Windows XP had a concept of LUA (Least User Access) with separated user accounts. For more information on this, you should check out the original post I wrote, <a href="https://www.me3tweaks.com/blog/modding/why-mass-effect-requires-administrator-rights-and-how-we-fixed-origin-not-running-it/">Why Mass Effect on PC requires administrator</a>. It describes a lot of backstory to this post.</p>
<h2>Oh boy, PhysX, my favorite physics library!</h2>
<figure id="attachment_67" aria-describedby="caption-attachment-67"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/ageialogo1.gif" alt="" width="236" height="134"><figcaption id="caption-attachment-67">I may have a slight beef with this SDK.</figcaption></figure><p>
Mass Effect for PC runs on a lightly modified version of Unreal Engine 3, which appears to be dated around late 2006. According to some former BioWare developers, this version of Unreal Engine was not very mature yet, to put it lightly. According to some stories from these developers, it was really difficult to work with because Epic Games was focused on Gears of War and not dedicating much time to their partners who were also using the engine.</p>
<p>Unreal Engine 3 uses PhysX for physics interactions, so Epic Games built a dll that interfaces PhysX to Unreal Engine data formats through a file named PhysXLoader.dll, which loads the PhysX libraries from both parties. PhysX is a physics simulation library that was acquired by AGEIA Technologies in the mid 2000s before AGEIA was sold to Nvidia in early 2008. If you remember Physics Processing Unit cards, or PPU, they were using PhysX before Nvidia promptly killed that idea.</p>
<figure id="attachment_66" aria-describedby="caption-attachment-66"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25.png" alt="" width="360" height="136" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25.png 360w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25-300x113.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25-250x94.png 250w" sizes="(max-width: 360px) 100vw, 360px"><figcaption id="caption-attachment-66">PhysXLoader.dll, PhysXCore.dll, and NxCooking.dll make up the PhysX dlls for Mass Effect.</figcaption></figure>
<p>All three Mass Effect games use PhysX, but Mass Effect 2 and Mass Effect 3 use the system’s install of PhysX, while Mass Effect uses the local game’s PhysX. Mass Effect 2 and Mass Effect 3 also use the ‘modern’ version of PhysX, rather than the legacy one that was shipped by AGEIA. Nvidia changed some paths under the hood when it took over, which separates Legacy out from it’s ‘modern’ versions. </p>
<p>But that doesn’t seem to stop Legacy PhysX’s uninstaller from deleting modern PhysX’s files/registry keys, so during the course of testing this fix, my other copies of Mass Effect 2/3 didn’t work, even after installing the ‘modern’ PhysX redistributable. It’s really annoying how BioWare couldn’t just ship a 8MB library with the game – they already shipped the installer for PhysX with the game, so it’s not like it saved space!</p>
<p>But anyways…</p>
<h2>The issue with Epic Games’ PhysXLoader.dll is that it can load PhysXCore.dll locally, or from the system’s installed version</h2>
<p>Err… wait, how is that an issue? Can’t you just load the local dll, and if that doesn’t exist, load the system one? How is that an issue exactly?</p>
<figure id="attachment_73" aria-describedby="caption-attachment-73"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1.jpg" alt="OH BOY HERE WE GO" width="294" height="294" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1.jpg 294w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-150x150.jpg 150w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-48x48.jpg 48w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-250x250.jpg 250w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-180x180.jpg 180w" sizes="(max-width: 294px) 100vw, 294px"><figcaption id="caption-attachment-73">You won’t believe how many facepalms there were as I making this fix.</figcaption></figure><p>
On boot, Mass Effect writes two values to the Windows HKEY_LOCAL_MACHINE registry:</p>
<blockquote><p>REG_BINARY HKLM\SOFTWARE\AGEIA Technologies enableLocalPhysXCore [mac address, 6 bytes]<br>
REG_DWORD HKLM\SOFTWARE\AGEIA Technologies EpicLocalDllHack [1]</p></blockquote>
<p>*Mass Effect is a 32-bit program, so on 64-bit systems it goes into HKLM\SOFTWARE\WOW6432Node\AGEIA Technologies instead, if you’re looking for yourself.</p>
<p>Remember these registry values, they’re going to be important later!</p>
<p>These registry values are why Mass Effect requires administrative permissions. In my previous blog post linked above, we explored why these writings were enough to make Microsoft put Mass Effect into it’s compatibility database, which forces it to run as admin when matching on certain executable criteria, which we worked around by modifying the executable criteria to no longer match. </p>
<p>We have to modify the executable to enable Large Address Aware, so the game could load higher resolution textures without running out of memory, so there was no way to avoid breaking the signature. This in turn caused Origin to no longer run the game as it would not elevate games without a valid EA signature. But if the game cannot write these registry keys on boot, the game may crash… </p>
<p>So it’s already a big fun chain of problems, but we worked around Mass Effect needing administrative rights by simply giving the user account permissions to that specific AGEIA Technologies registry key. This would let the game process write the values it needed, and would we could go on our merry way. I assumed the game crashed because it was denied write permissions and Demiurge couldn’t be bothered to write a try/catch around the registry writing code.</p>
<h2>You probably shouldn’t name your registry values as a hack if you want me to think this is a good idea</h2>
<p>Our solution to this problem did not change Mass Effect’s behavior – the values it wanted to write to the registry were going to be written one way or another, so we were just letting it do the thing it’s always done, just without administrative rights. There wasn’t really any change in application behavior.</p>
<figure id="attachment_81" aria-describedby="caption-attachment-81"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59.png" alt="" width="362" height="154" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59.png 362w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59-300x128.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59-250x106.png 250w" sizes="(max-width: 362px) 100vw, 362px"><figcaption id="caption-attachment-81">The two registry values that Mass Effect writes.</figcaption></figure>
<p>mirh, a moderator for <a href="https://www.pcgamingwiki.com/wiki/Home">PC Gaming Wiki</a>, sounded the alarm for years that somehow we were breaking other games in ALOT Installer – even though our application didn’t actually change how Mass Effect was behaving writing these values, so there’s no way our change would break other games.</p>
<p>After many months, he wrote a fairly detailed reason why ALOT Installer (when, in reality, it was Mass Effect) is breaking other games: <b>enableLocalPhysXCore</b> being in the registry <em>is used by other games using Epic Game’s PhysXLoader.dll.</em> When I was writing V4 of ALOT Installer, I told mirh I would take a more serious look into his idea of a solution that would not break other games, even though at the time I did not really understand how a registry key with the system’s MAC address would break other games – or why it even used a MAC address to begin with.</p>
<p>mirh seems to have determined this enableLocalPhysXCore lets Mass Effect use the local directory’s PhysXCore.dll/NxCooking.dll, instead of loading the one from the installed PhysX redistributable. Mass Effect doesn’t install the PhysX redistributable, so it could not rely on it existing, so it needed to use the local libraries.</p>
<p>Hope you’re strapped in because this is where it gets really dumb: </p>
<h4>The MAC address stored in in the registry by MassEffect.exe is read by PhysXLoader.dll and compared against your system’s MAC address to determine if it should load the local directory’s PhysX libraries or the system’s.</h4>
<p>Which MAC address? </p>
<h3>¯\_(ツ)_/¯</h3>
<p>So the way Mass Effect works:</p>
<ol>
<li>Very early in the boot process of MassEffect.exe, your MAC address is read and written to the registry as enableLocalPhysXCore (along with EpicLocalDllHack)</li>
<li>MassEffect.exe loads PhysXLoader.dll</li>
<li>PhysXLoader.dll reads the value of enableLocalPhysXCore and compares your system’s MAC address against it</li>
<li>If it matches, it uses the local folder’s PhysX, if not, it uses the system’s redistributable version of PhysX</li>
</ol>
<p>Yes, you read that right.</p>
<p>It turns out that other games, such as Mirror’s Edge, have a PhysXLoader.dll that also reads these values (as they’re based on the same code), <em>but they don’t include local PhysX libraries</em>. So those games boot up, see enableLocalPhysXCore, and try to load the local library, which fails, and the game doesn’t start. This information is second hand from mirh – I have not tested other games broken by this registry value.</p>
<p>Normally that value wouldn’t exist, and it should use the system PhysX. This behavior can be tested in Mass Effect by denying it write permissions to the registry key, deleting the values, and having Legacy PhysX installed – it will use the system libraries instead. If system PhysX is not installed, the application will not boot – this is why we originally had to let Mass Effect write these keys, otherwise it could appear that the installer broke Mass Effect, when it actually was a terrible implementation by Epic Games.</p>
<figure id="attachment_157" aria-describedby="caption-attachment-157"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1.png" alt="Facepalm" width="782" height="433" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1.png 782w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-300x166.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-768x425.png 768w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-250x138.png 250w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-550x305.png 550w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-325x180.png 325w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-542x300.png 542w" sizes="(max-width: 782px) 100vw, 782px"><figcaption id="caption-attachment-157">It’s hard to imagine any possible scenario where this was a good idea.</figcaption></figure><p>
If you’re interfacing with a library that has exports you can call to initialize/load the PhysX SDK… couldn’t you just, you know, pass a boolean to tell it to locally load? Why does it not locally look to begin with? And what’s up with the MAC address? Why is this in the registry, where it behaves LIKE A GLOBAL SETTING??? </p>
<p>All of these seem like terrible design decisions – and after disassembling the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/">https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/</a></em></p>]]>
            </description>
            <link>https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042910</guid>
            <pubDate>Tue, 10 Nov 2020 04:53:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AppleCrate II: A New Apple II-Based Parallel Computer (2015)]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25042551">thread link</a>) | @aresant
<br/>
November 9, 2020 | http://michaeljmahon.com/AppleCrateII.html | <a href="https://web.archive.org/web/*/http://michaeljmahon.com/AppleCrateII.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<b><span face="Arial, helvetica" size="4"><p>AppleCrate II:  A New Apple II-Based Parallel Computer</p>
</span><span face="Arial, helvetica" size="2"><p>
Michael J. Mahon – July 26, 2008<br>
Revised – September 23, 2015</p>

<p><img src="http://michaeljmahon.com/CrateII.jpg" width="500" height="612"></p>

</span><span face="Arial, helvetica"><p>Introduction</p>
</span></b><span face="Arial, helvetica" size="2"><p>
In 2004 I built the first <a href="http://michaeljmahon.com/Applecrate.html">AppleCrate</a>, an 8-board system, as an inexpensive, easy to program
vehicle for experiments in parallel programming—a kind of "blade server" for the Apple II, if
you will!  AppleCrate I (at the time I didn't realize that it was number "I" ;-) was great fun, and it
enabled some very interesting experiments, but over time I discovered some of its shortcomings.</p>

<p>First and foremost, since the boards were supported by only two edges and not clamped in place, it
was relatively fragile and hard to transport.  Second, I had come across situations in which more
than 8 slave processors would have been useful.  Third, my arrangement for collecting audio signals
synthesized by the slaves was quite makeshift and delivered sound with lots of digital "hash"
as background noise.  And finally, the original AppleCrate made no provision for plugging I/O cards
into any of its boards, so it had to be hosted by a separate Apple II, adding to the problem of
transporting it for demonstrations.</p>

<p>The AppleCrate II is designed to be significantly improved in all of the areas that were
problems for the AppleCrate I.</p>

<b></b></span><b><span face="Arial, helvetica"><p>Description</p>
</span></b><span face="Arial, helvetica" size="2">

<p>The AppleCrate II is made from 17 Enhanced Apple //e main boards.  (Fifteen of these boards were
obtained in the same eBay auction that netted the eight unenhanced boards for the original AppleCrate.)
Because they are enhanced ROMs, the original NadaNet boot ROM code would not fit and a new
boot protocol had to be developed, as described below.</p>

<p>Instead of mounting the cards vertically in a frame, as in the original, I decided to mount them
horizontally in a stack secured with standoffs—3/4" long hexagonal rods, each with a screw protruding from
one end and a tapped hole in the other.  The AppleCrate II has nine "columns" of these standoffs—six
metal columns at the back and corners of the boards and three nylon columns interior to the boards
to add stiffness, as shown in the photo below at the 2-board construction stage:</p>

<p><img src="http://michaeljmahon.com/TwoBoards.jpg" width="800" height="554"></p>

<p>This "hi-rise" construction makes the "stack" quite rigid and sturdy, while eliminating the need
for a space-consuming exoskeleton.  It also has the advantage of leaving the top board unobstructed
so that I/O cards can be plugged in, allowing it to serve as the host machine for the AppleCrate.  (In fact,
I used 17 boards so that the top board can serve as master and leave 16 slave machines for parallel
programs.)</p>

<p>The Pushbutton 1 input and Annunciator 1 output bus wires and the AN2-to-PB2 GETID daisy chain wires are connected to
machined-pin sockets inserted into the 16-pin game port connector.  These connections support <a href="http://michaeljmahon.com/NadaNet.html">NadaNet</a>,
which is the only signal connection between the boards.  The network adapter (described below) is shown
with its mounting bracket under what will be the third board.  The power bus card is supported by a
similar angle bracket, and the standoffs immediately beneath them are filed down to accomodate the
bracket thickness.</p>

<p>The boards are powered by a PC AT power supply.  The average power consumed by an Apple //e
board is about 4.2 watts, so the whole 17-board crate consumes only about 70 watts in total,
and both the AppleCrate and the power supply run only a few degrees above ambient temperature.</p>

<p>I decided to use #12 copper bus wires
to distribute power to all boards (visible on the right side of the first photo).  I would have preferred
a connectorized approach, but I could not come up with a connector scheme with a
reasonable mating/unmating force.  As a result, I decided to go with soldered power connections.
(It's a good thing that Apple //e's are so reliable, since replacing one in the middle of the
stack would be relatively difficult!)</p>

<p>The top board is used as the "master" machine with I/O cards and an external keyboard plugged into it.
The Master boots the 16 slave Apples in the AppleCrate II and uses them to run parallel programs.
Once they have been booted and started, they can run independently of the master—though they are clearly
I/O-constrained!</p>

<b></b></span><b><span face="Arial, helvetica"><p>Indicators</p>
</span></b><span face="Arial, helvetica" size="2">

<p>It has proven useful to have some real-time indication of each board's activity.  The stock board contains a
red "power" LED (at the right) and a red "speaker" LED at the left.  Both are easily visible from the back of the
boards (the "front" of the AppleCrate).  The function of the power LED is fixed, but the speaker LED is usable
as an indicator that software running on the board can operate, just by toggling the speaker.  For example,
printing a "beep"—CHR$(07)—causes the speaker LED to flash for 0.1 second, and can be used to indicate some
condition in the software.  (The speaker LED will not light when a speaker is installed, but AppleCrate
boards have no speakers attached.)</p>

<p>Although the Applecrate network interface described below incorporates an LED to show global network activity,
it is very useful to be able to see when any particular board is sending on the network.  This need is met by
using the PDL 3 timer to "stretch" each packet send operation into a visible flash of a green rectangular LED.</p>

<p><img src="http://michaeljmahon.com/SendLED.jpg" width="762" height="263"></p>

<p>These photos show the modification made to the 558 timer chip, in which a 267-ohm resistor (just what I
had handy—any value between 220 and 560 ohms is fine) is connected
between pins 5 and 8, and the "send" signalling LED is connected between pin 8 and ground, with pin 8 going to the
anode.  The rectangular LED is carefully pressed between the cassette input and output jacks.  On some boards,
the jacks were so close together that it was necessary to "shave" the upper plastic swage on the side of the input
jack with an Exacto knife to make room for the LED to press fit between them.  (Note that in these photos the red
wire connected to the anode of the LED has not yet been soldered.)</p>

</span><b><span face="Arial, helvetica"><p>Network Boot in NadaNet 3.x</p>
</span></b><span face="Arial, helvetica" size="2">

<p>Since AppleCrate machines have no I/O capabilities other than
the network, they must be booted from the network.  This requires that the ROMs on the boards be replaced with
EPROMs containing modified RESET code to perform the network boot.</p>

<p>As with the AppleCrate I, replacement of the self-test code was the easiest path, since it is self-contained,
contiguous, and is executed upon power-on reset if no keyboard is connected.  However, the Enhanced //e ROM contains
only $200 bytes of self-test code, just half the size of the unenhanced //e self-test, requiring a new
design for the network boot.</p>

<p>The AppleCrate I used an "active" boot protocol, in which each board enabled by the "GETID daisy chain" (connected from
AN2 of the previous machine to PB2 of the current machine) continuously sent GETID requests to ID 1, until it was assigned
a permanent ID and received a NadaNet boot image.  The complexity of this protocol, requiring both sending and receiving
packets over the network, resulted in a boot ROM requirement of almost $400 bytes—which fit in an <b>Unenhanced</b> //e ROM.</p>

<p>Since the <b>Enhanced</b> //e ROM has only $200 bytes available, a new "passive" boot protocol had to be devised.
The <a href="http://michaeljmahon.com/PASSIVEBOOT.ROM.pdf">new ROM code</a> continuously monitors the network for a broadcast BOOTREQ control packet
containing  the load address and length of the immediately following boot code data.  When the boot image has been correctly
read from the network, control is passed to its starting address.  This passive boot code only needs to <b>read</b> packets from the
net, and so occupies just $190 bytes, which comfortably fits in place of the Enhanced //e ROM self-test code at $C600.</p>

<p>The new boot protocol capitalizes on the fact that boot code is sent as a broadcast transaction, so the
machines being booted do not need IDs to receive boot code.  A page of "second-stage boot" code is added at the
front of the slave machine boot image.  This code is given control immediately after the boot image is received, and,
when enabled by the "GETID daisy chain", it sends a GETID request to the machine that &amp;BOOTed it, making use of the
code in the full NadaNet boot image to do so (see the BOOT2 code in the <a href="http://michaeljmahon.com/NADA.CRATE.pdf">NADA.CRATE</a>
listing for details).</p>

<p>The GETID daisy chain functions just as it did in the AppleCrate I.  The "first" machine is permanently enabled
by connecting its PB2 to ground.  AN2 of each machine is connected
to PB2 of the "next" machine.  The second-stage boot code running in each machine initially sets its AN2.
Then it waits until it sees its PB2 go low, enabling it to send its GETID request.  When its GETID is successful
it drops its AN2, enabling the next machine.  Then it clears its video display, writes a banner showing the
machine ID, and enters its server loop.</p>

<p>This results in permanent
IDs being assigned in the fixed order of the physical daisy chain, while allowing all ROMs to be identical.
An LED on the AppleCrate II NadaNet adapter board is wired to the last machine's AN2, so that when the last
machine drops its AN2, the red LED extinguishes, signalling that all machines have booted successfully.</p>

<p>When a network-booting machine is reset, it first checks the network state.  If the network is low (ZERO),
it performs a cold start.  If the network is being held high (ONE), it checks page 3 to see if it is being cold started or warm reset.  If it is
a warm reset, it re-enters its Server loop.  If it is a cold start, it initializes and enters the ROM boot code, again waiting
for a BOOTREQ packet.  (This approach has the advantage of reliably forcing a reboot on a power cycle, while
still permitting boards to be warm reset while holding the network high.)</p>

<p>As of NadaNet 3.1, all AppleCrate boot ROMs must be <a href="http://michaeljmahon.com/PASSIVEBOOT.ROM.pdf">NadaNet 3.x capable</a>.</p>

</span><b><span face="Arial, helvetica"><p>AppleCrate II NadaNet Interface</p>
</span></b><span face="Arial, helvetica" size="2">
<p><a href="http://michaeljmahon.com/NadaNet.html">NadaNet</a> is a TTL-level serial network in which logic high is represented by a voltage greater than +2 volts
and logic low is represented by a voltage less than +0.7 volts.  The fanout capability of a TTL annunciator output
is sufficient to  drive a dozen or so TTL pushbutton inputs if they are not otherwise …</p></span></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://michaeljmahon.com/AppleCrateII.html">http://michaeljmahon.com/AppleCrateII.html</a></em></p>]]>
            </description>
            <link>http://michaeljmahon.com/AppleCrateII.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042551</guid>
            <pubDate>Tue, 10 Nov 2020 03:23:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stakes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25042480">thread link</a>) | @exolymph
<br/>
November 9, 2020 | https://www.sonyasupposedly.com/stakes/ | <a href="https://web.archive.org/web/*/https://www.sonyasupposedly.com/stakes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://www.sonyasupposedly.com/content/images/size/w300/2020/11/1411922_o2.jpg 300w,
                                https://www.sonyasupposedly.com/content/images/size/w600/2020/11/1411922_o2.jpg 600w,
                                https://www.sonyasupposedly.com/content/images/size/w1200/2020/11/1411922_o2.jpg 1000w,
                                https://www.sonyasupposedly.com/content/images/size/w2000/2020/11/1411922_o2.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://www.sonyasupposedly.com/content/images/size/w2000/2020/11/1411922_o2.jpg" alt="Stakes">
                </figure>
                <section>
                    <div>
                        <p>Hi friends! What a year, what a year. That's all I have to say about electoral politics. Seriously though, can you believe it's November already? Time to plan the holiday movie roster ❄️</p><p>Perhaps you'd enjoy a serene interlude. <a href="https://wanderverse.org/wanderpath/gazebo/">Visit the Wanderpath gazebo</a> to contemplate "icicles which glimmer and glitter in the faint sunlight." Or run your eyes over the dreamy hues of <a href="https://wanderverse.org/wanderpath/indian_balsam/">flowers pressed in warmer days</a>. (Thank you <a href="http://polyducks.co.uk/">Polyducks</a> 💝)</p><p>Today's soundtrack: <a href="https://lovecrypt.bandcamp.com/album/revelations-ii"><em>Revelations II</em> by Khan &amp; Polo</a>. "alone, you build new structures; some that you live inside, some that live inside you."</p><p>I have something to celebrate. Twelve months ago, I stopped drinking:</p><figure><blockquote data-width="550"><div lang="en" dir="ltr"><p>Hello friends. I want to tell you something, because I need to declare it to make it part of myself.</p><p>I'm quitting alcohol. I commit to never touching another drop.</p><p>I like it too much, and I don't like the person I turn into because of liking alcohol too much.</p></div>— 🎀 sonyasupposedly.com 🤖 (@sonyasupposedly) <a href="https://twitter.com/sonyasupposedly/status/1185916407906738177?ref_src=twsrc%5Etfw">October 20, 2019</a></blockquote>

<figcaption>Helpful support groups: <a href="https://www.reddit.com/r/stopdrinking/">/r/stopdrinking</a> and <a href="https://www.reddit.com/r/dryalcoholics/">/r/dryalcoholics</a>.</figcaption></figure><p>For me, eschewing booze was an unequivocally wonderful decision. But a difficult one, as you might expect. I want to share two hard-won realizations:</p><ol><li>Change requires loss. To <em>be</em> different, you have to <em>do</em> different things, to the exclusion of the things that you used to do. Maybe that sounds obvious, but the actual practice is terrifying (or at least it was for me). Change requires sacrificing the old self — stabbed through the heart and consigned to the grave, a vampire destroyed for its predatory concupiscence! Ideally with compassion, since that used to be you... Nonetheless, the old self's cherished pleasures are precisely what you must relinquish. It will torment you to retaliate for the privation of venal delights. Thus, like the vampire, the old self has gotta go. Ready your stake!</li><li>Change requires <em>choosing</em> that pain and strife over the comfortable familiarity of stasis. It will hurt. But the price is the price —&nbsp;either pay up or accept that you don't want the finer things in life more than you want to avoid what it takes to attain them.</li></ol><p>Related: <a href="https://drmaciver.substack.com/p/dont-just-try-harder">"Don't just try harder,"</a> writes <a href="https://twitter.com/DRMacIver">David MacIver</a>. Do different things!<em> </em>While you're at it, read <em><a href="https://amzn.to/2UcRBM4">The Voyage of the Dawn Treader</a></em>.</p><p>In unrelated happy news, <strong>the <a href="https://www.sonyasupposedly.com/membership/">membership</a> setup is fixed</strong>. Now I can tell you how I broke it: by changing my prices, which scrambled the Ghost-Stripe integration. Anyway, I got that sorted out. The new monthly price is $1.50 cheaper than before —&nbsp;$12/month instead of $13.50, or $120/year versus $135. Hooray for small economies of scale!</p><p>Current members, the price change is prorated, and no action is needed on your part. Potential members, if you'd like to receive monthly <a href="https://www.sonyasupposedly.com/tag/zines/">zines</a> (both printed and digital!) as well as occasional <a href="https://www.sonyasupposedly.com/down-the-line/">Top Secret Special Notes</a>, please <a href="https://www.sonyasupposedly.com/account/">go here</a> to proceed.</p><p>Launches you may like:</p><ul><li><a href="http://threadhelper.com/">ThreadHelper</a>, a power-up for Twitter addicts <a href="https://chrome.google.com/webstore/detail/threadhelper/nfadnflafdfmekapgcgddbccooagpndk">who use Chrome</a>:</li></ul><figure><blockquote data-width="550">— Rival Voices 🦁 (@nosilverv) <a href="https://twitter.com/nosilverv/status/1321518942033186822?ref_src=twsrc%5Etfw">October 28, 2020</a></blockquote>

</figure><ul><li><a href="https://otherlife.co/strauss/">Other Life's course on Leo Strauss</a> (whose Wikipedia page, in screenshot form, graces the cover of <a href="https://www.sonyasupposedly.com/clandestine-motives/">Clandestine Motives</a>, fun fact)</li><li><a href="https://www.boethi.us/">Boethius</a>, a service offering "Classical education for a digital age," by <a href="https://twitter.com/JaysonVirissimo">Jayson Virissimo</a></li><li><a href="https://gumroad.com/l/WEdDl">Other Futures</a>, a sci-fi zine by <a href="https://twitter.com/atroyn">Anton Troynikov</a> 🤖🔮</li></ul><p>Plus one bonus not-quite-launch snagged from <a href="https://tinyletter.com/auerbook/letters/auerbook-election-hangover-william-gass-the-tunnel-enneadecameron-meganets">David Auerbach's newsletter</a>:</p><blockquote>The videos/lectures from my class <a href="http://https//www.youtube.com/playlist?list=PL4kdFWi1bM_HaWZNRHeRVLlbfg3vx6naG">FIVE PARADIGMS OF ARTIFICIAL INTELLIGENCE</a> are available. The course was very rewarding for me and the material is extremely relevant to present-day debates. They also form the historical basis of my forthcoming book from PublicAffairs, MEGANETS, which has been occupying most of my time recently.</blockquote><p>In addition to his TinyLetter and that YouTube playlist, David has a <a href="https://davidauerba.ch/">website</a>, a <a href="https://www.waggish.org/">blog</a>, and <a href="https://twitter.com/AuerbachKeller">Twitter</a>.</p><p>A few things to read:</p><ul><li><a href="https://uncivilizedbooks.com/authors/kaczynski-tom/">Tom Kaczynski's Uncivilized comics</a></li><li><a href="https://theprepared.com/blog/a-giant-waxed-cheese-wheel-is-the-apocalypse-prep-you-didnt-know-you-needed/">"A giant waxed cheese wheel is the apocalypse prep you didn't know you needed"</a> by <a href="https://twitter.com/jonst0kes">Jon Stokes</a></li><li><a href="https://quillette.com/2020/10/29/the-evolutionary-history-of-mans-best-friend-revealed/">"The Evolutionary History of Man's Best Friend Revealed"</a> by <a href="https://twitter.com/razibkhan">Razib Khan</a></li><li><a href="https://www.precursorpoets.com/newsletter-october2020/">"Galatea, pt. 3"</a> by <a href="https://twitter.com/PreCursorPoets">Timothy Wilcox</a></li><li><a href="https://livingideas.substack.com/p/how-culture-drives-human-evolution">"How Culture Drives Human Evolution"</a> by <a href="https://twitter.com/sachinmaini">Sachin Maini</a></li><li><a href="https://solana.substack.com/p/zen-and-the-art-of-political-censorship">"Zen and the Art of Political Censorship"</a> by <a href="https://twitter.com/micsolana">Mike Solana</a></li><li><a href="https://diff.substack.com/p/big-tech-sees-like-a-state">"Big Tech Sees Like a State"</a> by <a href="https://twitter.com/ByrneHobart">Byrne Hobart</a></li></ul><p>That's all for now. Talk soon 😘</p><p>P.S. I dare you to <a href="https://www.sonyasupposedly.com/mystery-zine-bundle/">buy a Mystery Zine Bundle</a>. Great stocking stuffers, jussayin...</p><hr><p><a href="https://www.slam.org/collection/objects/27247/">Still life by Pieter Claesz</a> (1643).</p>
                    </div>
                </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.sonyasupposedly.com/stakes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042480</guid>
            <pubDate>Tue, 10 Nov 2020 03:06:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Kills Cname Cloaking on iOS/iPadOS]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25042374">thread link</a>) | @fenier
<br/>
November 9, 2020 | https://cunderwood.dev/2020/11/06/using-cnames-to-bypass-itp-has-been-put-to-torch/ | <a href="https://web.archive.org/web/*/https://cunderwood.dev/2020/11/06/using-cnames-to-bypass-itp-has-been-put-to-torch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cunderwood.dev/2020/11/06/using-cnames-to-bypass-itp-has-been-put-to-torch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042374</guid>
            <pubDate>Tue, 10 Nov 2020 02:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Networking for Introverts]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25042288">thread link</a>) | @davefreiburger
<br/>
November 9, 2020 | https://gradually.co/how-to-network-as-an-introvert/ | <a href="https://web.archive.org/web/*/https://gradually.co/how-to-network-as-an-introvert/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-876">

					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              			<p>																								Health								</p><!-- end cat-wrap -->
						<p><span>&nbsp; •&nbsp; </span>
						<span>Networking for Introverts</span>
						<span> &nbsp;•&nbsp; </span>
						<span>
							November 9, 2020						</span>

						<img width="640" height="312" src="https://gradually.co/wp-content/uploads/2020/11/GD23-Health.gif" alt="" loading="lazy"></p><div>

																					<div>
								<p><a href="https://giphy.com/gifs/giphydiscovery-dogs-VzGQrj8sLH4GLcSiG1" target="_blank">
									[Image source: Giphy]								</a></p><h5>
									<a href="https://medium.com/@byrnehobart/writing-is-networking-for-introverts-5cac14ad4c77" target="_blank">
										Writing is Networking for Introverts									</a>
									 &nbsp;by Byrne Hobart									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>“Networking is painful, and I’m suspicious of anyone who claims to enjoy it. Unfortunately for me, networking is effective: most good opportunities come from personal connections” — Byrne Hobart</span></li>
<li><span>Networking works, but it doesn’t work very well for people who are bad at striking up and maintaining conversations with strangers.&nbsp;</span></li>
<li><span>“There is a solution: be famous. You lose the ability to filter out who you want to talk to, but at least everyone starts the conversation with some context; you’re outsourcing the extroversion to them.” — Byrne Hobart</span>
<ul>
<li><span>Fame doesn’t just grow on trees. Byrne says there’s a second alternative called being </span><i><span>microfamous</span></i><span>, though. “Microfame is the best kind of fame because it combines an easier task (be famous to fewer people) with a better outcome (be famous to the right people).”</span></li>
<li><span>“If you’re trying to calibrate how hard it is to achieve micro-fame, focus on the micro, not the fame. Micro-fame just means your friends-of-friends have a nonzero chance of knowing who you are, and striking up a conversation with you about something mutually interesting.” — Byrne Hobart</span></li>
</ul>
</li>
<li><span>To achieve microfame for introverts, Byrne believes one way is to write. Specifically, “writing-as-networking strategy is that writing about your other interests gets other people interested. You’re not just identifying neighbors in your intellectual ghetto; you’re recruiting more. If more of your friends do it, you get exposed to more ideas.”&nbsp;</span></li>
<li><span>“This is not for everyone. There are some people who really love the idea of walking into a room full of strangers with a fat stack of business cards and making a bunch of valuable connections. But for those of us who faintly dread the prospect, writing is an alternative. If you put in the effort, you can substitute the worst parts of socializing for time spent alone with your computer.” — Byrne Hobart</span></li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>I certainly identify as an introvert and I used to think it was a weakness (and it somewhat is to a certain extent), but it’s also somewhat of a superpower too. You have the ability to listen more intently, pick up on things others probably wouldn’t, and weaponize your empathy for good. Writing can act as a bat signal for others interested in what you’re interested in. </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->

			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/how-to-network-as-an-introvert/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042288</guid>
            <pubDate>Tue, 10 Nov 2020 02:26:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1984 by George Orwell [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25042280">thread link</a>) | @bra-ket
<br/>
November 9, 2020 | https://snewd.com/wp-content/uploads/2020/01/1984-George-Orwell.pdf | <a href="https://web.archive.org/web/*/https://snewd.com/wp-content/uploads/2020/01/1984-George-Orwell.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://snewd.com/wp-content/uploads/2020/01/1984-George-Orwell.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042280</guid>
            <pubDate>Tue, 10 Nov 2020 02:24:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Practices for Writing Clean Interfaces in Go]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25042085">thread link</a>) | @lanecwagner
<br/>
November 9, 2020 | https://qvault.io/2020/03/15/best-practices-for-writing-clean-interfaces-in-go/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/03/15/best-practices-for-writing-clean-interfaces-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Interfaces in Go allow us to treat different types as the same data type temporarily. They are central to a Go programmers toolbelt and are often used improperly by new Go developers… leading to hard to read and buggy code. Let’s take a look at some of the best practices for Golang interfaces.</p>



<h2>Recap on Interfaces</h2>



<p>I often look to the standard library as an example of the way to write clean Go. The standard error interface is simple:</p>



<pre><code lang="go">type error interface {
    Error() string
}</code></pre>



<p>The error interface encapsulates any type that has an <code>Error()</code> method defined on it. That method accepts no parameters, and returns a <em>string</em>. For example, let’s define a struct that represents a network problem:</p>



<pre><code lang="go">type networkProblem struct {
	message string
	code    int
}</code></pre>



<p>Then we define an <code>Error()</code> method:</p>



<pre><code lang="go">func (np networkProblem) Error() string {
	return fmt.Sprintf("network error! message: %s, code: %v", np.message, np.code)
}</code></pre>



<p>Now, we can use an instance of the <code>networkProblem</code> struct wherever an error is accepted.</p>



<pre><code lang="go">func handleErr(err error) {
	fmt.Println(err.Error())
}

np := networkProblem{
	message: "we received a problem",
	code:    404,
}

handleErr(np)

// prints "network error! message: we received a problem, code: 404"</code></pre>



<h2>Keep Interfaces Small</h2>



<p>If there is only one piece of advice that you take away from this article, make it this: <strong>keep interfaces small!</strong> Interfaces are meant to define the <em>minimal</em> behavior necessary to accurately represent an idea or concept. </p>



<p>Here is an example from the standard <a aria-label="HTTP package (opens in a new tab)" href="https://golang.org/pkg/net/http/#pkg-overview" target="_blank" rel="noreferrer noopener nofollow">HTTP package</a> of a larger interface that’s a good example of defining minimal behavior:</p>



<pre><code lang="go">type File interface {
    io.Closer
    io.Reader
    io.Seeker
    Readdir(count int) ([]os.FileInfo, error)
    Stat() (os.FileInfo, error)
}</code></pre>



<p>Any type that satisfies the interface’s behaviors can be considered by the HTTP package as a <em>File</em>. This is convenient because the HTTP package doesn’t need to know if it’s dealing with a file on disk, a network buffer, or a simple <code>[]byte</code>. </p>



<h2>Interfaces Should Have No Knowledge of Satisfying Types </h2>



<p>An interface should define what is necessary for other types to classify as a member of that interface. They shouldn’t be aware of any types that happen to satisfy the interface at design time.</p>



<p>For example, let’s assume we are building an interface to describe the components necessary to define a car.</p>



<pre><code lang="go">type car interface {
	GetColor() string
	GetSpeed() int
	IsFiretruck() bool
}</code></pre>



<p><code>GetColor()</code> and <code>GetSpeed()</code> make perfect sense, they are methods confined to the scope of a car. <code>IsFiretruck()</code> is an anti-pattern. We are forcing all cars to declare whether or not they are firetrucks. In order for this pattern to make any amount of sense, we would need a whole list of possible subtypes. <code>IsPickup()</code>, <code>IsSedan()</code>, <code>IsTank()</code>… where does it end??</p>



<p>Instead, the developer should have relied on the native functionality of <a href="https://yourbasic.org/golang/type-assertion-switch/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener nofollow">type assertion</a> to derive the underlying type when given an instance of the <strong>car</strong> interface. Or, if a sub-interface is needed, it can be defined as:</p>



<pre><code lang="go">type firetruck interface {
	car
	HoseLength() int
}</code></pre>



<p>Which inherits the required methods from <code>car</code> and adds one additional required method to make the car a <code>firetruck</code>.</p>



<h2>Interfaces Are Not Classes</h2>



<ul><li>Interfaces are not classes, they are slimmer.</li><li>Interfaces don’t have constructors or deconstructors that require that data is created or destroyed.</li><li>Interfaces aren’t hierarchical by nature, though there is syntactic sugar to create interfaces that happen to be supersets of other interfaces.</li><li>Interfaces define function signatures, but not underlying behavior. Making an interface often won’t <a aria-label="DRY (opens in a new tab)" href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself" target="_blank" rel="noreferrer noopener nofollow">DRY</a> up your code in regards to struct methods. For example, if five types satisfy the error interface, they all need their own version of the <code>Error()</code> function.</li></ul>







<h2>Related Work</h2>



<ul><li><a href="https://qvault.io/2020/03/29/how-to-separate-library-packages-in-go/">How To Separate Library Packages in Go</a></li><li><a href="https://qvault.io/2020/03/19/golang-mutexes-what-is-rwmutex-for/">Golang Mutexes – What Is RWMutex For?</a></li><li><a href="https://qvault.io/2020/02/20/how-to-build-jwts-in-go-golang/">How To Build JWT’s in Go (Golang)</a></li></ul>
		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/03/15/best-practices-for-writing-clean-interfaces-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042085</guid>
            <pubDate>Tue, 10 Nov 2020 01:53:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debunking an election fraud claim using open data and Dolt]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25041998">thread link</a>) | @proverbialbunny
<br/>
November 9, 2020 | https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p>After four years of incredibly rancorous discourse about whether the
US President was illegitimately elected with the help of foreign
interference, it should surprise no one that the 2020 presidential
election is mired in similar claims of illegitimacy. This time around,
the people calling foul play aren't blaming Russians for the outcome:
they're blaming good old fashioned <a href="https://www.heritage.org/election-integrity/report/where-theres-smoke-theres-fire-100000-stolen-votes-chicago">election fraud of the kind that
put 63 people in Chicago behind bars following the 1982 presidential
election</a>. Or
the 2018 <a href="https://www.theatlantic.com/politics/archive/2019/02/north-carolina-9th-fraud-board-orders-new-election/583369/">fraud in North Carolina's 9th congressional district that
caused the election result to be thrown
out</a>.</p>
<p>But proven cases of election fraud are a lot rarer than vague
allegations. Since the election, there have been a lot of vague
allegations of election fraud being thrown around on social media. And
like most politically motivated claims on social media, they have been
widely signal-boosted without much attempt to demonstrate if they're
true or not. I saw a lot of these, and some of them actually had data
sources attached to them. Being a software engineer at a data-sharing
startup, I got curious. I decided to dig into a specific claim and see
for myself if there might be any truth to it.</p>
<p><strong>Publication day update: I saw another claim about Pennsylvania's
mail-in ballots this morning, and checked it out. Unlike the first
claim, this one is corroborated by the data provided by the
Pennsylvania Department of State. <a href="#Update">Skip to this update</a></strong>.</p>

<p>On Friday night, I saw this (since-deleted) tweet being shared,
already having collected several hundred retweets and likes.</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/b24618dd6fa186603eddd75af8f3b471/7527b/pa-election-fraud-tweet.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="1M elderly PA voters?" title="1M elderly PA voters?" src="https://www.dolthub.com/blog/static/b24618dd6fa186603eddd75af8f3b471/7527b/pa-election-fraud-tweet.png" srcset="https://www.dolthub.com/blog/static/b24618dd6fa186603eddd75af8f3b471/a48b3/pa-election-fraud-tweet.png 214w,
https://www.dolthub.com/blog/static/b24618dd6fa186603eddd75af8f3b471/47730/pa-election-fraud-tweet.png 428w,
https://www.dolthub.com/blog/static/b24618dd6fa186603eddd75af8f3b471/7527b/pa-election-fraud-tweet.png 754w" sizes="(max-width: 754px) 100vw, 754px" loading="lazy">
  </a>
    </span></p>
<p>This person claims to have analyzed <a href="https://data.pa.gov/Government-Efficiency-Citizen-Engagement/2020-General-Election-Mail-Ballot-Requests-Departm/mcba-yywm/data">data on mail ballots published by
the Pennsylvania Department of
State</a>,
and found that over a million people over the age of 85 had returned
mail-in ballots in that state. Since there are only about 230 thousand
people that old in Pennsylvania, that certainly sounds fishy! So let's
get to the bottom of this. I downloaded the PA ballot data as a CSV
file and got to work.</p>

<p><a href="https://github.com/dolthub/dolt/">Dolt</a> is Git for Data. It's a SQL
database that you can branch, merge, clone, fork, push and pull, just
like files in Git. It also comes with a built-in SQL engine to run
queries against the data that you store in it. The query I wanted to
write was very simple:</p>
<div data-language="sql"><pre><code><span>select</span> <span>count</span><span>(</span><span>*</span><span>)</span> <span>from</span> pa
    <span>where</span> date_of_birth <span>&lt;</span> <span>'1935-11-05'</span> 
    <span>and</span> ballot_returned_date <span>is</span> <span>not</span> <span>null</span><span>;</span></code></pre></div>
<p>But to write that query, I had to import the data first. Anyone who
has ever worked with data knows this is much harder than it should be.</p>
<p>To start, I had to give the data a primary key, which is currently
required by Dolt (although we're working on fixing that). The easiest
way to do this was with a quick and dirty perl script:</p>
<div data-language="perl"><pre><code><span>my</span> <span>$i</span> <span>=</span> <span>0</span><span>;</span>
<span>while</span> <span>(</span><span>&lt;&gt;</span><span>)</span> <span>{</span>
    <span>print</span> <span>"$i,"</span><span>;</span>
    <span>print</span> <span>$_</span><span>;</span>
    <span>$i</span><span>++</span><span>;</span>
<span>}</span></code></pre></div>
<p>The script just puts an incrementing integer ID onto the front of
every row in the CSV file it's given. I ran it like so:</p>
<div data-language="bash"><pre><code>% perl id.pl <span>\</span>
    <span>&lt;</span> 2020_General_Election_Mail_Ballot_Requests_Department_of_State.csv
    <span>&gt;</span> 2020_pa.csv</code></pre></div>
<p>This gives me a schema that Dolt can import. To automate its creation,
I tried to use the <code>dolt schema import</code> command to divine it
automatically, which would save me a lot of typing. Unfortunately, it
thought that all the date columns were actually just strings.</p>
<div data-language="bash"><pre><code>% dolt schema <span>import</span> -c --pks<span>=</span><span>"id"</span> pa 2020_pa.csv
CREATE TABLE <span><span>`</span>pa<span>`</span></span> <span>(</span>
  <span><span>`</span>County_Name<span>`</span></span> longtext NOT NULL,
  <span><span>`</span>Applicant_Party_Designation<span>`</span></span> longtext NOT NULL,
  <span><span>`</span>Date_of_Birth<span>`</span></span> longtext NOT NULL,
  <span><span>`</span>Mail_Application_Type<span>`</span></span> longtext NOT NULL,
  <span><span>`</span>Application_Approved_Date<span>`</span></span> longtext NOT NULL,
  <span><span>`</span>Application_Return_Date<span>`</span></span> longtext NOT NULL,
  <span><span>`</span>Ballot_Mailed_Date<span>`</span></span> longtext NOT NULL,
  <span><span>`</span>Ballot_Returned_Date<span>`</span></span> longtext NOT NULL,
  <span><span>`</span>State_House_District<span>`</span></span> longtext NOT NULL,
  <span><span>`</span>State_Senate_District<span>`</span></span> longtext NOT NULL,
  <span><span>`</span>Congressional_District<span>`</span></span> longtext NOT NULL,
  PRIMARY KEY <span>(</span><span><span>`</span><span>id</span><span>`</span></span><span>)</span>
<span>)</span> <span>ENGINE</span><span>=</span>InnoDB DEFAULT <span>CHARSET</span><span>=</span>utf8mb4<span>;</span></code></pre></div>
<p>This is because all the dates provided by the Pennsylvania Department
of State were formatted in that peculiar American style that much of
the software in the world just refuses to work with: <code>MM/DD/YYYY</code>.</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/8573d3ef91433062c4f9aff373f7c5b7/37523/dateformat.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="date formats of the world" title="date formats of the world" src="https://www.dolthub.com/blog/static/8573d3ef91433062c4f9aff373f7c5b7/37523/dateformat.png" srcset="https://www.dolthub.com/blog/static/8573d3ef91433062c4f9aff373f7c5b7/a48b3/dateformat.png 214w,
https://www.dolthub.com/blog/static/8573d3ef91433062c4f9aff373f7c5b7/47730/dateformat.png 428w,
https://www.dolthub.com/blog/static/8573d3ef91433062c4f9aff373f7c5b7/37523/dateformat.png 720w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span></p>
<p>(Note that as crazy as America is in this decision, Canada manages to
be even worse somehow)</p>
<p>So I had to modify this schema by hand to change the types, and to
change the nullability of these columns. Not a huge deal. But of
course, importing the data failed for the same reason.</p>
<div data-language="bash"><pre><code>% dolt table <span>import</span> -u pa 2020_pa.csv
Rows Processed: <span>0</span>, Additions: <span>0</span>, Modifications: <span>0</span>, Had No Effect: <span>0</span>
A bad row was encountered <span>while</span> moving data.
Bad Row:County_Name:<span>"ADAMS"</span> <span>|</span> Applicant_Party_Designation:<span>"R"</span> <span>|</span> Date_of_Birth:<span>"08/31/2000"</span> <span>|</span> Mail_Application_Type:<span>"OLREGV"</span> <span>|</span> Application_Approved_Date:<span>"09/26/2020"</span> <span>|</span> Application_Return_Date:<span>"09/26/2020"</span> <span>|</span> Ballot_Mailed_Date:<span>"10/03/2020"</span> <span>|</span> Ballot_Returned_Date:nil <span>|</span> State_House_District:<span>"91ST LEGISLATIVE DISTRICT"</span> <span>|</span> State_Senate_District:<span>"33RD SENATORIAL DISTRICT"</span> <span>|</span> Congressional_District:<span>"13TH CONGRESSIONAL DISTRICT"</span>
value <span>"09/26/2020"</span> can<span>'t be converted to time.Time
These can be ignored using the '</span>--continue'</code></pre></div>
<p>But being a software engineer on the open-source project you're trying
to use has its advantages: I knew right where to change the code to
make the date processing logic more forgiving. I also <a href="https://github.com/dolthub/dolt/issues/1006">filed an issue
to fix this for
everybody</a>.</p>
<p>With those changes, my import finally completed successfully.</p>
<div data-language="bash"><pre><code>% dolt table <span>import</span> -u pa 2020_pa.csv
Rows Processed: <span>3098705</span>, Additions: <span>3098705</span>, Modifications: <span>0</span>, Had No Effect: <span>0</span>
Import completed successfully.</code></pre></div>
<p>Finally, I could run my query!</p>

<div data-language="sql"><pre><code>pa_voters<span>&gt;</span> <span>select</span> <span>count</span><span>(</span><span>*</span><span>)</span> <span>from</span> pa 
    <span>where</span> date_of_birth <span>&lt;</span> <span>'1935-11-05'</span> 
    <span>and</span> ballot_returned_date <span>is</span> <span>not</span> <span>null</span><span>;</span>
<span>+</span>
<span>|</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>|</span>
<span>+</span>
<span>|</span> <span>126766</span>   <span>|</span>
<span>+</span></code></pre></div>
<p>So it turns out: a million extremely elderly people did not return
mail-in ballots in Pennsylvania. About 126,000 did. This is a turnout
of around 50% for this age bracket, totally plausible (and actually
kind of low for this year).</p>
<p>Deboonked!</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/e39745caeba98f73c6860fcc5f08d4cb/644c5/deboonker.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Deboonker" title="Deboonker" src="https://www.dolthub.com/blog/static/e39745caeba98f73c6860fcc5f08d4cb/79a4e/deboonker.jpg" srcset="https://www.dolthub.com/blog/static/e39745caeba98f73c6860fcc5f08d4cb/606a2/deboonker.jpg 214w,
https://www.dolthub.com/blog/static/e39745caeba98f73c6860fcc5f08d4cb/65a3f/deboonker.jpg 428w,
https://www.dolthub.com/blog/static/e39745caeba98f73c6860fcc5f08d4cb/79a4e/deboonker.jpg 856w,
https://www.dolthub.com/blog/static/e39745caeba98f73c6860fcc5f08d4cb/99aeb/deboonker.jpg 1284w,
https://www.dolthub.com/blog/static/e39745caeba98f73c6860fcc5f08d4cb/644c5/deboonker.jpg 1440w" sizes="(max-width: 856px) 100vw, 856px" loading="lazy">
  </a>
    </span></p>

<p>So what gives? It's easy to come up with explanations for why so many
people accepted this wild claim at face value. But what about the
person propagating it? Were they simply lying?</p>
<p>I don't think so. The tweet has since been deleted so I can't
demonstrate it, but the poster seemed sincere in his analysis. He just
got it wrong. And from what I could tell, a big reason he got it wrong
is that he used Excel to import and analyze a 446MB, 3 million row
CSV file.</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/3b7a792c89143462d9ebd4f73ea1d00b/5a190/excel-heat-map-hack.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Heat map in excel" title="Heat map in excel" src="https://www.dolthub.com/blog/static/3b7a792c89143462d9ebd4f73ea1d00b/5a190/excel-heat-map-hack.png" srcset="https://www.dolthub.com/blog/static/3b7a792c89143462d9ebd4f73ea1d00b/a48b3/excel-heat-map-hack.png 214w,
https://www.dolthub.com/blog/static/3b7a792c89143462d9ebd4f73ea1d00b/47730/excel-heat-map-hack.png 428w,
https://www.dolthub.com/blog/static/3b7a792c89143462d9ebd4f73ea1d00b/5a190/excel-heat-map-hack.png 800w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span></p>
<p>Excel is an amazing piece of software, and it's responsible for a
truly mind-boggling fraction of business and data analysis
workloads. But it has grown into these roles in a very haphazard and
at times reluctant fashion. When you throw certain kinds or magnitudes
of data at it, like a half gigabyte of text with 3 million rows, it
doesn't always work right.</p>
<p>Or, maybe I don't know what I'm talking about and it did work right!
Maybe the guy just sorted the spreadsheet by date of birth, it worked
perfectly, and he read the row number wrong. But my claim is that it
doesn't actually matter. The point is that we can never know, because
the analysis he performed is not reproducible or sharable. It's
forever lost in time, like tears in the rain.</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/2f53444578046c5397fcc7d4f0ef5042/874d1/tears-in-the-rain.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="tears in the rain" title="tears in the rain" src="https://www.dolthub.com/blog/static/2f53444578046c5397fcc7d4f0ef5042/ad12c/tears-in-the-rain.png" srcset="https://www.dolthub.com/blog/static/2f53444578046c5397fcc7d4f0ef5042/a48b3/tears-in-the-rain.png 214w,
https://www.dolthub.com/blog/static/2f53444578046c5397fcc7d4f0ef5042/47730/tears-in-the-rain.png 428w,
https://www.dolthub.com/blog/static/2f53444578046c5397fcc7d4f0ef5042/ad12c/tears-in-the-rain.png 856w,
https://www.dolthub.com/blog/static/2f53444578046c5397fcc7d4f0ef5042/7a18f/tears-in-the-rain.png 1284w,
https://www.dolthub.com/blog/static/2f53444578046c5397fcc7d4f0ef5042/874d1/tears-in-the-rain.png 1310w" sizes="(max-width: 856px) 100vw, 856px" loading="lazy">
  </a>
    </span></p>
<p>We built Dolt because we think that the way we share data on the
internet is broken. <a href="https://www.dolthub.com/blog/2019-12-06-the-history-of-data-exchange/">We're stuck mailing zip files of CSV files around
like it's
1975</a>. And
once you get one of these files, most of your work is still ahead of
you. As a rule, it's not easy to import non-trivial CSV data in a
usable form. Industry research indicates that professional <a href="https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114">data
scientists spend nearly 80% of their time finding and cleaning
datasets</a>.
Eliminate this janitorial work, and every data scientist becomes five
times as effective overnight.</p>
<p>Imagine a world where the data from the Pennsylvania Department of
State was <a href="https://www.dolthub.com/repositories/dolthub/pa_mail_ballots_2020">already distributed in Dolt
format</a>. Not
only is the data 1/3 the size of the uncompressed CSV file, it arrives
in a fully usable form: there's no import process, no trying to figure
out what the types of the columns are, whether they're nullable,
etc. You just run one command:</p>
<div data-language="bash"><pre><code>% dolt clone dolthub/pa_mail_ballots_2020</code></pre></div>
<p>... and you have all the data, ready to start querying immediately. If
the data is updated in the future, you can get the latest copy with
one more command.</p>

<p>If I'm a budding amateur electoral fraud analyst with a hot scoop I
want to share with my 4chan Pepe buddies, I can <a href="https://www.dolthub.com/blog/2020-02-28-announcing-saved-queries/">save my analysis as a
query that then travels alongside the
database</a>.</p>
<div data-language="bash"><pre><code>% dolt sql -q <span>\</span>
    <span>"select count(*) from pa where date_of_birth &lt; '1935-11-05' and ballot_returned_date is not null;"</span> <span>\</span>
    -s <span>"PA voters over 85"</span>
+----------+
<span>|</span> COUNT<span>(</span>*<span>)</span> <span>|</span>
+----------+
<span>|</span> <span>126766</span>   <span>|</span>
+----------+</code></pre></div>
<p>Now when my fellow election sleuths pull the database, they can verify
or expand on my work with a single command:</p>
<div data-language="bash"><pre><code>% dolt sql -x <span>"PA voters over 85"</span>
Executing saved query <span>'PA voters over 85'</span><span>:</span>
<span>select</span> count<span>(</span>*<span>)</span> from pa where date_of_birth <span>&lt;</span> <span>'1935-11-05'</span> and ballot_returned_date is not null<span>;</span>
+----------+
<span>|</span> COUNT<span>(</span>*<span>)</span> <span>|</span>
+----------+
<span>|</span> <span>126766</span>   <span>|</span>
+----------+</code></pre></div>
<p>And of course, they can <a href="https://www.dolthub.com/repositories/dolthub/pa_mail_ballots_2020">view and query the data themselves on
DoltHub</a>
if they're too lazy to download it.</p>

<p>This morning I saw an additional claim about Pennsylvania's mail
ballots: <a href="https://twitter.com/VC4351/status/1325538470593400832">many of them were apparently registered as having been
returned on the same day they were mailed out to the voter, or earlier
in some cases</a>.</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/7f8537e270a027fb2a6aabf9d75adc8b/1b1d5/pa-early-ballot-tweet.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="early ballots" title="early ballots" src="https://www.dolthub.com/blog/static/7f8537e270a027fb2a6aabf9d75adc8b/ad12c/pa-early-ballot-tweet.png" srcset="https://www.dolthub.com/blog/static/7f8537e270a027fb2a6aabf9d75adc8b/a48b3/pa-early-ballot-tweet.png 214w,
https://www.dolthub.com/blog/static/7f8537e270a027fb2a6aabf9d75adc8b/47730/pa-early-ballot-tweet.png 428w,
https://www.dolthub.com/blog/static/7f8537e270a027fb2a6aabf9d75adc8b/ad12c/pa-early-ballot-tweet.png 856w,
https://www.dolthub.com/blog/static/7f8537e270a027fb2a6aabf9d75adc8b/1b1d5/pa-early-ballot-tweet.png 876w" sizes="(max-width: 856px) 100vw, 856px" loading="lazy">
  </a>
    </span></p>
<p>Unlike the previous claim, this one actually seems to have some
merit. About 23,000 ballots in Pennsylvania are reported to have been
returned before they were mailed to the voter:</p>
<div data-language="sql"><pre><code>pa_voters<span>&gt;</span> <span>select</span> <span>count</span><span>(</span><span>*</span><span>)</span> <span>from</span> pa <span>where</span> Ballot_Returned_date <span>&lt;</span> Ballot_mailed_date<span>;</span>
<span>+</span>
<span>|</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>|</span>
<span>+</span>
<span>|</span> <span>23305</span>    <span>|</span>
<span>+</span></code></pre></div>
<p>And a great many more were returned the same day or a day later, just
as the twitter thread claims. Here's a query that measures ballot
latency, counting how many ballots were returned by each day after
being mailed to the voter. That is: how many ballots were returned 1
day after being mailed, 2 …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/">https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/</a></em></p>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041998</guid>
            <pubDate>Tue, 10 Nov 2020 01:34:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Try Design Thinking]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25041961">thread link</a>) | @gbasin
<br/>
November 9, 2020 | https://garybasin.com/try-design-thinking/ | <a href="https://web.archive.org/web/*/https://garybasin.com/try-design-thinking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2081">
	<img width="362" height="410" src="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=362%2C410&amp;ssl=1&amp;is-pending-load=1" alt="" loading="lazy" data-lazy-src="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=362%2C410&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">	<div>
		<!-- .entry-header -->

		<div>
			
<p>It’s 9pm, you’re at your friend’s house, and the show you’re watching ends. You scramble to change the channel but you can’t figure out the remote. You stare at dozens of buttons with no clue where to start. <strong>Doesn’t it make you feel stupid?</strong> Some experimentation might get you somewhere, but it’s not easy. Why can’t you figure it out?</p>



<p>In these situations, we often blame ourselves. We’re not smart, patient, or capable enough. This conclusion is incorrect ⏤ <strong>product design is the direct cause of the stress</strong>.</p>



<p>This realization won’t help you with your frustrating remote experience. However, it does emphasize the importance of user experience design. <strong>We can redesign experiences to create new feelings</strong>.</p>



<p>Next time you’re confronted with a bad user experience, <a href="https://twitter.com/garybasin/status/1324908038524899329">spend some time brainstorming better designs</a>. You never know where your experiments will take you.</p>



<div><figure><img loading="lazy" width="362" height="950" src="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=362%2C950&amp;ssl=1" alt="" srcset="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?w=362&amp;ssl=1 362w, https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=114%2C300&amp;ssl=1 114w" sizes="(max-width: 362px) 100vw, 362px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?w=362&amp;ssl=1 362w, https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=114%2C300&amp;ssl=1 114w" data-lazy-src="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=362%2C950&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>




					</div><!-- .entry-content -->

		<!-- .entry-meta -->
	</div>

	
</article></div>]]>
            </description>
            <link>https://garybasin.com/try-design-thinking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041961</guid>
            <pubDate>Tue, 10 Nov 2020 01:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Replacing my phone battery with a cheap AliExpress knock-off]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25041894">thread link</a>) | @flotwig
<br/>
November 9, 2020 | https://zach.bloomqu.ist/blog/2020/11/aftermarket-cell-phone-battery.html | <a href="https://web.archive.org/web/*/https://zach.bloomqu.ist/blog/2020/11/aftermarket-cell-phone-battery.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>This is a story of one manâ€™s quest for power.</p> <p>I purchased my current phone, a OnePlus 5T, in 2017. This summer, after about two and a half years of ownership, I noticed that it was no longer holding a charge all day. Frequently, the phone would reach 0% and shut off, right in the middle of tracking an evening bike ride or watching Netflix while cooking dinner. Although cell phone battery wear is a well-known issue, I got tired of it pretty quickly.</p> <p>I used the <a href="https://play.google.com/store/apps/details?id=com.digibites.accubattery&amp;hl=en_US&amp;gl=US">AccuBattery</a> app for about two months to try and get a handle on my battery health. It measured my phoneâ€™s amperage draw during the day and used that to estimate that of the 3300 milliamp-hour (mAh) capacity that my battery originally offered, only about 2400 mAh of capacity remained - only about 75% of the batteryâ€™s original health:</p> <p><img src="https://zach.bloomqu.ist/assets/battery/oem-capacity.png" alt="Screenshot of AccuBattery app for OEM battery capacity"></p> <p>This answered the question of â€œwhy does it feel like my phone is shutting off so quickly?â€� pretty clearly. Now, it was up to me to get a replacement battery.</p> <h3 id="attempting-to-get-a-genuine-battery">Attempting to get a genuine battery</h3> <p>My first thought was that I could simply order the OEM OnePlus 5T battery somewhere online. Why not? I found a page on the OnePlus website where prices are listed for replacement parts. The USA page was down at the time of this writing, but the <a href="https://www.oneplus.in/support/pricing/detail?code=7">India support page</a> lists a OnePlus 5T OEM battery replacement as being about $15.</p> <p>This seemed acceptable to me. My first thought was to email OnePlus support asking how to purchase the battery. Unfortunately, according to the service rep, they do not ship or sell OEM batteries without service:</p> <blockquote> <p>We would like to inform you that we do not ship or sell the accessories in any parts of the world, and all the repairs are carried out by our Authorized service centers only. So if you wish to get the device repaired, you can send it to the OnePlus authorized service center and get the same repaired.</p> </blockquote> <p>This is in line with what other OnePlus customers have reported - nobody, as far as I can tell, has ever been able to source OEM batteries from OnePlus, leaving DIY customers like myself to try and find knock-offs elsewhere.</p> <p>I wouldâ€™ve sent my phone in for repairs, but after I received the above email, I had such a long and terrible customer support experience trying to arrange the repair that by the end of it, I no longer trusted OnePlus to reliably service and return my phone. This lack of trust was reinforced by horror stories from other OnePlus customers - one customerâ€™s phone was <a href="https://www.reddit.com/r/oneplus/comments/eleckw/sent_my_oneplus_5_to_fort_worth_tx_for_repair_no/">lost by the Fort Worth, TX service center</a>, anotherâ€™s was <a href="https://www.reddit.com/r/oneplus/comments/depgkg/oneplus_lost_my_coworkers_phone_during_repair_at/">lost and took 4 weeks before being returned</a>, and yet another customer had <a href="https://www.reddit.com/r/oneplus/comments/jke2kd/sent_my_op3t_for_a_battery_replacement_oneplus/">their phone held hostage unless they agreed to repairing EVERYTHING instead of just getting the battery replaced</a>. These stories, combined with my awful customer support experience, convinced me that sending my phone in would be a truly bad idea.</p> <h3 id="buying-an-aftermarket-battery">Buying an aftermarket battery</h3> <p>Many people on the /r/oneplus5t subreddit have recommended purchasing a <a href="https://www.ifixit.com/Store/Android/OnePlus-5-5T-Replacement-Battery/IF330-018?o=2">replacement battery from iFixit</a>, but I felt like iFixit was simply selling cheap Chinese batteries with a nice label on them. I mean, if OnePlus can fix it for $15, why does the iFixit battery cost $30, if not for marketing?</p> <p>So, I hit up eBay and AliExpress, and eventually found the [sic] â€œSpecail Mobilephone Parts Storeâ€�, where they offer a <a href="https://web.archive.org/web/20201109223630/https://www.aliexpress.com/item/4000438352423.html">â€œ4650 mAhâ€� â€œPerfect business batteryâ€�</a> for the OnePlus 5T. With slogans like <a href="https://zach.bloomqu.ist/assets/battery/giant-energy-huge-capacity.webp">â€œGiant energy; huge capacityâ€�</a>, <a href="https://zach.bloomqu.ist/assets/battery/safety-does-not-explode.webp">â€œSafety does not explodeâ€�</a>, and <a href="https://zach.bloomqu.ist/assets/battery/ensure-qualified-and-safe-to-use.webp">â€œEnsure qualified and safe to useâ€�</a>, I felt confident that my $11.87 was going to a good place. I placed the order and, about 3 weeks later, I received the battery in my mailbox.</p> <h3 id="battery-physics-101">Battery Physics 101</h3> <p><img src="https://zach.bloomqu.ist/assets/battery/oem-and-aftermarket.jpg" alt="Photo of the OEM battery and the aftermarket battery side-by-side"> <small>The OEM battery (left) and the aftermarket battery installed (right).</small></p> <p>The first thing I noticed about the replacement battery was that the capacity was even HIGHER than what I ordered. The OnePlus 5T OEM battery is rated at 3300 mAh capacity, the AliExpress product page advertised a battery with 4650 mAh capacity, and the label on the battery I received claimed an astounding <em>5350 mAh</em> capacity - 162% of the OEM capacity. Clearly, I had gotten a great deal!</p> <p>The second thing I noticed was that the aftermarket battery was significantly lighter than the OEM battery. So much lighter that I weighed the batteries out of curiosity. The OEM OnePlus 5T battery weighed 47.0g. The aftermarket OnePlus 5T battery weighed 38.7g, or about 17% less.</p> <p>Itâ€™s amazing that Da Da Xiong was able to achieve 162% capacity with 17% less weight. Too amazing to be true, in fact.</p> <p>Via Wikipedia, I learned that the <a href="https://en.wikipedia.org/wiki/Specific_energy">specific energy</a> of a lithium-ion polymer battery can be up to <a href="https://en.wikipedia.org/wiki/Lithium-ion_battery">265 watt-hours per kilogram (Wh/kg)</a>. The nominal voltage of the lithium-ion polymer batteries here is about 3.8V. We can use <a href="https://en.wikipedia.org/wiki/Ohm%27s_law">Ohmâ€™s law</a> to calculate the maximum possible capacity of each battery based on weight, assuming that each battery is always supplying the nominal 3.8V.</p> <p>Letâ€™s start by calculating the maximum possible Amp-hours (Ah) per kilogram (kg) for a Li-ion poly battery at 3.8V, using Ohmâ€™s law:</p> <div><div><pre><code>265 Wh/kg / 3.8 V = 69 Ah/kg
</code></pre></div></div> <p>Now, we can calculate the maximum physically possible capacity for each battery by multiplying this number by the weights of each battery:</p> <div><div><pre><code>OEM battery:          .047 kg * 69 Ah/kg = 3.2 Ah = 3200 mAh
Aftermarket battery: .0387 kg * 69 Ah/kg = 2.6 Ah = 2600 mAh
</code></pre></div></div> <p>The astute reader might be wondering why this estimate for the maximum capacity of the OEM battery (3200 mAh) is less than the capacity OnePlus advertises (3300 mAh). Why is this? Well, itâ€™s because the assumption we made - that each battery is always supplying the nominal 3.8V - is false. The voltage output of a Li-ion poly battery <a href="https://learn.adafruit.com/li-ion-and-lipoly-batteries/voltages">drops over time</a>, so the calculation shown is only a lower bound approximation of each batteryâ€™s maximum capacity.</p> <p>I donâ€™t have information about the exact chemical composition of these batteries, nor the voltage charts, nor do I know what the upper and lower voltage limits are on the OnePlus 5T charging circuit. However, if we estimate that the voltage drops from 3.8V to 3.0V in a linear fashion (<code>V = 3.8 - .8t, 0 &lt;= t &lt;= 1</code>), we can use integration to arrive at approximately 3600 mAh maximum capacity for the OEM battery and 2900 mAh maximum capacity for the aftermarket battery.</p> <p>Even without exact numbers, these calculations demonstrate that <em>something</em> is fishy about the Da Da Xiong batteryâ€™s mAh claims.</p> <h3 id="real-world-usage">Real-world usage</h3> <p>Anyways, I didnâ€™t buy this shady AliExpress battery just so that I could do a bunch of math. I purchased it to restore my phoneâ€™s ability to last all day, and it has definitely succeeded at that. From a qualitative perspective, I now have enough juice to keep my phoneâ€™s battery fueled all day until I can recharge it at night.</p> <p>From a quantitative perspective, AccuBattery reports that the aftermarket battery has an estimated 3360 mAh capacity, which about matches the capacity of the OEM battery:</p> <p><img src="https://zach.bloomqu.ist/assets/battery/aftermarket-capacity.png" alt="Screenshot of AccuBattery app for aftermarket battery capacity"></p> <p>However, what AccuBattery fails to account for is the fact that once the aftermarket battery reaches 15%, the battery percentage begins to free-fall until it reaches 0% and shuts off. It seems like 15% on the aftermarket battery is equivalent to 1% on the OEM battery. I think this is because the Android OS cannot correctly estimate the batteryâ€™s remaining charge because it has different voltage characteristics than the OEM battery, but it doesnâ€™t really bother me, I just have to make sure that to charge the phone at 15% instead of 1%. This seems to be an extremely common experience with DIY battery replacements - even folks using the iFixit battery run in to this issue.</p> <p>If we take 15% off of AccuBatteryâ€™s estimated capacity, we get 2856 mAh, which is really really close to what a brand new OnePlus 5T reports - AccuBattery estimates the OEM battery as having ~3000 mAh capacity when it is brand new. That about matches my experience - with the Da Da Xiong battery, the phone is staying alive longer, almost like when it was new.</p> <h3 id="conclusions">Conclusions</h3> <ul> <li>Random Chinese batteries do not work as advertised - they will not magically double your phoneâ€™s battery capacity.</li> <li>However, random Chinese batteries work <em>almost as well</em> as brand new OEM batteries, but your battery percentage will forever be miscalibrated.</li> <li>Never trust OnePlus customer service.</li> </ul> </div></div>]]>
            </description>
            <link>https://zach.bloomqu.ist/blog/2020/11/aftermarket-cell-phone-battery.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041894</guid>
            <pubDate>Tue, 10 Nov 2020 01:14:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ladders of Wealth Creation]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25041361">thread link</a>) | @davefreiburger
<br/>
November 9, 2020 | https://gradually.co/roadmap-to-building-wealth/ | <a href="https://web.archive.org/web/*/https://gradually.co/roadmap-to-building-wealth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-878">
				<!--<a href="https://gradually.co/roadmap-to-building-wealth/">-->
					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              											<p>																Wealth								</p><!-- end cat-wrap -->
						<p><span>&nbsp; •&nbsp; </span>
						<span>Roadmap to Building Wealth</span>
						<span> &nbsp;•&nbsp; </span>
						<span>
							November 9, 2020						</span>

						<img width="640" height="418" src="https://gradually.co/wp-content/uploads/2020/11/GD23-Wealth-1024x668.png" alt="" loading="lazy" srcset="https://gradually.co/wp-content/uploads/2020/11/GD23-Wealth-1024x668.png 1024w, https://gradually.co/wp-content/uploads/2020/11/GD23-Wealth-300x196.png 300w, https://gradually.co/wp-content/uploads/2020/11/GD23-Wealth-768x501.png 768w, https://gradually.co/wp-content/uploads/2020/11/GD23-Wealth-1536x1002.png 1536w, https://gradually.co/wp-content/uploads/2020/11/GD23-Wealth-2048x1336.png 2048w" sizes="(max-width: 640px) 100vw, 640px"></p><div>

																					<div>
								<p><a href="https://nathanbarry.com/wealth-creation/" target="_blank">
									[Image source: Nathan Barry]								</a></p><h5>
									<a href="https://nathanbarry.com/wealth-creation/" target="_blank">
										The ladders of wealth creation: a step-by-step roadmap to building wealth									</a>
									 &nbsp;by Nathan Barry									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>“…Making money is a skill—like playing the drums or piano—that you can get better at over time. I wouldn’t expect to be able to sit down at a piano for the first time and immediately play a concerto.” — Nathan Barry</span></li>
</ul>
<ul>
<li><b><i>Your time for money</i></b><span>: the only skills you need are showing up consistently, being reliable, and learning new skills on the job. Nathan goes on to say, “Then in order to take the next step up the ladder you will need to specialize in certain skills (design, copywriting, legal, becoming a nurse, etc) to gain a salaried position.”&nbsp;</span></li>
</ul>
<ul>
<li><b><i>Your own service business</i></b><span>: This next rung on the ladder requires skills such as setting up a company, finding clients, creating proposals, pricing services, hiring employees, establishing an online presence, accounting, finance, business ops, etc.&nbsp;</span></li>
</ul>
<ul>
<li>
<ul>
<li><span>However, these two are probably the most important: follow up with customers and doing what you said you were going to do.&nbsp;</span></li>
</ul>
</li>
</ul>
<ul>
<li><b><i>Productized services</i></b><span>: Nathan mentions, “…To truly reach new levels of income you need to learn a different lesson: how to sell without ever talking to the customer.” This rung of the ladder requires you to learn how to write quality sales copy, design a sales page, process online payments, and create systems to deliver repeatable quality with each service.&nbsp;</span></li>
</ul>
<ul>
<li><b><i>Selling products</i></b><span>: Nathan continues, “A product takes far more work to create upfront, but then each individual sale and the fulfillment of that sale happens without much (or any) additional effort from the business owner.”&nbsp;</span></li>
</ul>
<ul>
<li><span>“All across society extra money—whether from a raise or working extra—disappears into lifestyle inflation or temporary purchases, when it could be put to work so much more effectively.” — Nathan Barry</span></li>
<li><span>You should always trade your time for money if:</span>
<ul>
<li><span>You’re early in your career and just starting out</span></li>
<li><span>You’re getting paid to learn a new skill while growing your earning potential</span></li>
<li><span>It’s a step in getting to a higher rung or on to the next ladder</span></li>
<li><span>You’re building relationships or finding mentors</span></li>
<li><span>The work is rewarding and meaningful in its own right</span></li>
</ul>
</li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>There’s no secret formula for building wealth. It takes a ton of hard work and time. At the end of the day, it boils down to how much of your time you’re willing to give up to make more money. If you’re able to learn how to make more money while giving up less of your time, you’re learning how to build wealth. There are no shortcuts.&nbsp; </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->
				<!--</a>-->
			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/roadmap-to-building-wealth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041361</guid>
            <pubDate>Mon, 09 Nov 2020 23:47:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking Pulsar and Kafka]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25041342">thread link</a>) | @ubolonton_
<br/>
November 9, 2020 | https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance | <a href="https://web.archive.org/web/*/https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041342</guid>
            <pubDate>Mon, 09 Nov 2020 23:43:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forget security champions, what about security advocates?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25041132">thread link</a>) | @designthinker
<br/>
November 9, 2020 | https://jwgoerlich.com/security-culture-needs-security-advocates-design-monday/ | <a href="https://web.archive.org/web/*/https://jwgoerlich.com/security-culture-needs-security-advocates-design-monday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<p>“Everything is design. Everything.” — <a href="https://www.paulrand.design/">Paul Rand (1914–1996)</a></p>



<p>Paul Rand is behind so many stories this series has covered. The Olivetti Valentine typewriter designed by <a href="https://jwgoerlich.com/design-monday-valuing-assets/">Ettore Sottsass</a> and used by <a href="https://jwgoerlich.com/security-architecture-principles-design-monday/">Dieter Rams</a> in his documentary? Paul Rand did Olivetti’s US advertising. Speaking of Deiter Rams, the Braun shavers that made Rams famous? Paul Rand bought every model. (Though <a href="https://www.paulrand.design/life/interviews/1988-artograph.html">Rand once said</a> he would “buy just for their beauty and then put them in a drawer.”) IDEO, the birthplace of design thinking? Paul Rand did IDEO’s logo. He collaborated on a team with Charles Eames on <a href="https://www.paulrand.design/life/books-articles/articles/print/2011-the-interface.html">IBM’s Design Program</a>. I like to think some of that work was in the IBM plaza building that <a href="https://jwgoerlich.com/mies-and-ibm-plaza-knowing-when-more-is-more-design-monday/">Ludwig Mies van der Rohe</a> designed. The building, by the way, sported the iconic IBM logo which was, you guessed it, designed by Paul Rand.</p>



<p>Paul Rand was instrumental in creating the culture and discipline of graphic design. He taught the next generation at Yale from 1956 to 1985, with a break in the 1970s. Rand was visiting professor and critic at a number of other institutions. Check out the book <em>Paul Rand: Conversations with Students </em>for a view into that work. “What is design?” Paul would often ask. When he wasn’t creating, Rand was instructing, and through instruction, he was creating culture.</p>



<p>Like Paul Rand fostered designers who brought ideas to wider audiences, security leaders need to foster advocates who will bring security ideas to the wider workforce.</p>



<p>We don’t talk much about advocates. A security advocate is a member of the security team who focuses on getting practices into the hands of the workforce. It’s more common for us to talk about security champions. A security champion is a member of the business itself, who collaborates with the security team on best practices. A fully fleshed out security capability has advocates working with champions to interpret and implement security controls. In a well-run security capability, those controls will be usable and widely adopted, because of the partnership of advocates and champions.</p>



<p>To learn more about cyber security advocates and what they need to succeed, check out the “<a href="https://www.usenix.org/conference/soups2018/presentation/haney-perceptions">It’s Scary…It’s Confusing…It’s Dull</a>” research paper. These professionals “advocate for systems and policies that are usable, minimize requisite knowledge, and compensate for the inevitability of user error.”</p>



<p>Here are four practices from Paul Rand that we can apply to designing a security advocacy program:</p>



<p><strong>(1) Coach on tangible work, not abstract principles</strong>. Rand’s courses were practical not theoretical, with advice given based on the student’s work. He focused stories, literature, examples, and more through the lens of the work at hand.</p>



<p><strong>(2) Coach one-on-one, avoid one size fits all</strong>. Paul Rand worked individually with students, and a session on their work “went on as long as was necessary to set the student on the right track and was laced with stories from Paul’s vast career as they were appropriate to the issue at hand. When he worked with students, he poured his heart and soul into it.”</p>



<p><strong>(3) Use short cycle times</strong>. Typically, the criticism on individual work in Rand’s courses came weekly. Feedback was quick, specific, and direct. Compare this to many security programs where manager feedback comes at annual reviews.</p>



<p><strong>(4) Encourage personalization</strong>. Rand taught designers to build their own set of techniques, their own visual vocabulary, to solve problems. That’s not for the sake of originality. “Don’t try to be original,” Rand often said, “just try to be good.” It’s to develop a sense of the designer’s personal needs and strengths and how to mesh those with the audience’s instincts and intuitions. </p>



<p>When designing a cyber security program, give thought into how leadership will coach advocates. Give thought to how advocates will cultivate security champions. With a nod to Paul Rand, prompt both with a deceptively simple question. “What is security?”</p>



<figure><img loading="lazy" width="514" height="640" src="https://jwgoerlich.com/wp-content/uploads/2020/11/paul-rand-abacus.jpg" alt="" srcset="https://jwgoerlich.com/wp-content/uploads/2020/11/paul-rand-abacus.jpg 514w, https://jwgoerlich.com/wp-content/uploads/2020/11/paul-rand-abacus-241x300.jpg 241w" sizes="(max-width: 514px) 100vw, 514px"><figcaption>Abacus Photogram, Photography by Paul Rand</figcaption></figure>



<hr>



<p><em>This article is part of a series on designing cyber security capabilities. To see other articles in the series, including a full list of design principles,&nbsp;</em><a href="https://jwgoerlich.com/principles-for-designing-security-capabilities/"><em>click here</em></a><em>.</em></p>
																		<p><span>Posted </span><a href="https://jwgoerlich.com/security-culture-needs-security-advocates-design-monday/" title="6:00 am" rel="bookmark"><time datetime="2020-11-09T06:00:00-05:00" pubdate="">November 9, 2020</time></a> by 					</p></div></div>]]>
            </description>
            <link>https://jwgoerlich.com/security-culture-needs-security-advocates-design-monday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041132</guid>
            <pubDate>Mon, 09 Nov 2020 23:13:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A positive version of BLACK MIRROR (book of short stories)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25041043">thread link</a>) | @curatecuriosity
<br/>
November 9, 2020 | https://tinkeredthinking.com/bookstore/products/v1/ | <a href="https://web.archive.org/web/*/https://tinkeredthinking.com/bookstore/products/v1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
			<div>
				<h3>The Lucilius Parables Vol. I</h3><hr>
				<p>34.50 -<span>Illustrated Edition, Hardcover - 284 pages</span></p>
			</div>
		</div>
		
		 
		<div>
			<p>A collections of modern parables from Tinkered Thinking.  </p>

<p>These short parables are for curious intellectuals - people who want to explore the strange possibilities of our time through short, lean narratives.  Read these stories in any order and let them stretch your brain with mind-bending meditations taking place in the past, present and the future.</p>

<p>Follow Lucilius through these tiny snapshots of his many lives, from the burning of the magnificent library of Alexandria, to his quiet ruminations aboard a whaling ship, to his exploration of distant planets and realities.  He exists at no time and all times, at every age, always meditating on that which makes us human and all that might make us more.  He is a selcouthist - a wanderer of human experience.</p>

<p> This edition of the parables has been fully edited, expanded and professionally reviewed.</p>

<p>In addition, each Parable is accompanied by a beautiful hand drawn illustration relating to each story.</p>

<p>Make this a thoughtful gift for those who have yet to discover Tinkered Thinking or carry the adventures of Lucilius with you for a refreshing reminder of the possibilities that exist behind each and every moment.</p>
		</div>
	</div><div>
		


		<div>
			<div>
				<h3>The Lucilius Parables Vol. I</h3><hr>
				<p>34.50</p>
				<p>Illustrated Edition, Hardcover - 284 pages</p>
				<p>A collections of modern parables from Tinkered Thinking.  </p>

<p>These short parables are for curious intellectuals - people who want to explore the strange possibilities of our time through short, lean narratives.  Read these stories in any order and let them stretch your brain with mind-bending meditations taking place in the past, present and the future.</p>

<p>Follow Lucilius through these tiny snapshots of his many lives, from the burning of the magnificent library of Alexandria, to his quiet ruminations aboard a whaling ship, to his exploration of distant planets and realities.  He exists at no time and all times, at every age, always meditating on that which makes us human and all that might make us more.  He is a selcouthist - a wanderer of human experience.</p>

<p> This edition of the parables has been fully edited, expanded and professionally reviewed.</p>

<p>In addition, each Parable is accompanied by a beautiful hand drawn illustration relating to each story.</p>

<p>Make this a thoughtful gift for those who have yet to discover Tinkered Thinking or carry the adventures of Lucilius with you for a refreshing reminder of the possibilities that exist behind each and every moment.</p> <br>
			</div>
			 
		</div>

	</div><p>
		<h5><em>Cost Transparency &amp; Sustainability</em></h5>
	</p><div id="collapseExample">
	  <div>
		    	<h4>Commitment to Sustainability</h4>
				<p>For Every purchase, <span>Tinkered Thinking</span> is allocating a portion of the proceeds to plant a tree.  Through a partnership with <a target="_blank" href="https://onetreeplanted.org/">OneTreePlanted</a> <span>Tinkered Thinking</span> is committed to making a contribution to the health of our planet.  It's thought of this way: a tree is cut down in order to make products like books, so why not plant a tree for every book sold?  This system creates a virtuous cycle where the cutting down of a tree used to make many books results in many more trees, each book like a seed, helping the movement towards a better future take root.</p>
				
				<p><img src="https://tinkeredthinking.com/static/img/OneTreeStamp.png">
				</p>

				<h4>Cost transparency</h4>
				<div><p>The cost of this book is a bit higher than what might be expected.  The reasons for this are several.  As an extension of <span>Tinkered Thinking</span>'s commitment to sustainable practice, the method by which this book is being produced is <em>print-on-demand</em>.  This means there is no stock.  A copy of this book is not physically produced <em>until a purchase is made</em>.  Not only does this make sense from a business perspective, but it eliminates the enormous risk of waste that often results when traditional book production creates a large quantity of books that are never purchased or read.  <em>Print-on-demand</em> solves this issue of waste in a powerful way.  The tradeoff is that when copies are produced individually, the cost is quite a bit higher than the per-unit-price of mass production.  A slight bummer, but the technology is still young and all signs point to <em>print-on-demand</em> as the way of the future.  Chances are high that costs will come down as the technology continues to scale.  </p><p><span>Tinkered Thinking</span> hopes you will consider these important details while perusing the bookstore.  And keep in mind, when you give a <span>Tinkered Thinking</span> Book <em>as a gift to someone</em>, you aren't just giving a book, you also get bragging rights: you get to say you planted a tree in that person's honor.</p></div>
	  </div>
	</div></div>]]>
            </description>
            <link>https://tinkeredthinking.com/bookstore/products/v1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041043</guid>
            <pubDate>Mon, 09 Nov 2020 23:03:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Totem Alfa Romeo GT Electric]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25041002">thread link</a>) | @simonebrunozzi
<br/>
November 9, 2020 | https://www.totemautomobili.com/exterior/ | <a href="https://web.archive.org/web/*/https://www.totemautomobili.com/exterior/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-page" data-elementor-id="29" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="7ad74aa" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
							
							<div>
							<div>
					<div data-id="d7256f5" data-element_type="column">
			<div>
							<div>
						
				
				<div data-id="d7758da" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="heading.default">
				<p>
			<h2>A LEGEND REBORN WITH ELECTRIC SOUL</h2>		</p>
				</div>
				
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="9afbc47" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="7dce961" data-element_type="column">
			<div>
							<div>
						
				<div data-id="9167192" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="heading.default">
				<p>
			<h2>With the idea of revamping the car we elegantly redesigned the original lines giving the car a stunning shape whilst maintaining the authentic signature of the Giulia GTA.</h2>		</p>
				</div>
				<section data-id="1c78337" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="54c315c" data-element_type="column">
			<div>
							<div>
						<div data-id="734005a" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<p>Starting from one of the best iconic Italian cars of the 60’s &amp; 70’s, the Alfa Romeo Giulia GTA, we have created one of the most advanced restomod in the business, producing the ever fastest and most fascinating Giulia GTA.&nbsp;<br><span>The Giulia GTA was presented in 1965 and in the following seven&nbsp;</span><br></p>
				</div>
				</div>
						</div>
					</div>
		</div>
				<div data-id="7467847" data-element_type="column">
			<div>
							<div>
						<div data-id="2466c45" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<p><span>years obtained a series of successes and prizes which led this car to be&nbsp;</span><span>considered as a legend.&nbsp;</span>Our goal was to rebuild a car which remembers in spirit and shape the victorious Alfa of the 60ies, emerging as a reference for sportsmanship and craftsmanship.</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="a4079dc" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
							
							<div>
							<div>
					<div data-id="11124bb" data-element_type="column">
			<div>
							<div>
						
				
				<div data-id="957679a" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<div><p>Not only looking back to the past but also glancing at the future, we elegantly redesigned the original lines giving the car a stunning shape whilst maintaining the authentic signature of the Giulia GTA.</p><p><span>Similar considerations applied to the engineering and mechanical elements, planning the very best components and working with a team of Italian experts, we developed the new chassis setup designed to enclose an electric heart, bringing the car to extraordinary performance, whilst projecting it into the future.</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="33563bc" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="8f0a8bb" data-element_type="column">
			<div>
							<div>
						
				
				
				<div data-id="dddf15e" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<p>The design of our GT electric has been reshaped in forms and materials to create a timeless car with a smoother line. The formal search for details has given continuity to the past recovering some original features to apply in the new design.<br>We removed the roof drip molding from the external body, which was reconstructed entirely in carbon fiber, in order to make the car as light as possible and to obtain a perfect surface using new milling molds.</p>
				</div>
				</div>
				<section data-id="25e8e57" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						
		</section>
						</div>
					</div>
		</div>
				<div data-id="3f208ce" data-element_type="column">
			<div>
							<div>
						<div data-id="28a6348" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="2560" height="1707" src="https://www.totemautomobili.com/wp-content/uploads/2020/10/IMG_5484-scaled.jpg" alt="" loading="lazy" srcset="https://www.totemautomobili.com/wp-content/uploads/2020/10/IMG_5484-scaled.jpg 2560w, https://www.totemautomobili.com/wp-content/uploads/2020/10/IMG_5484-300x200.jpg 300w, https://www.totemautomobili.com/wp-content/uploads/2020/10/IMG_5484-1024x683.jpg 1024w, https://www.totemautomobili.com/wp-content/uploads/2020/10/IMG_5484-768x512.jpg 768w, https://www.totemautomobili.com/wp-content/uploads/2020/10/IMG_5484-1536x1024.jpg 1536w, https://www.totemautomobili.com/wp-content/uploads/2020/10/IMG_5484-2048x1365.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="7f2162b" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="425b843" data-element_type="column">
			<div>
							<div>
						<section data-id="8cea9f6" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="86eda9b" data-element_type="column">
			<div>
							<div>
						<div data-id="11f0ed2" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="475" height="488" src="https://www.totemautomobili.com/wp-content/uploads/2020/10/About.png" alt="" loading="lazy" srcset="https://www.totemautomobili.com/wp-content/uploads/2020/10/About.png 475w, https://www.totemautomobili.com/wp-content/uploads/2020/10/About-292x300.png 292w" sizes="(max-width: 475px) 100vw, 475px">											</p>
				</div>
				</div>
				<div data-id="62bc7be" data-element_type="widget" data-settings="{&quot;_position&quot;:&quot;absolute&quot;}" data-widget_type="image.default">
				<div>
					<p><img width="365" height="379" src="https://www.totemautomobili.com/wp-content/uploads/2020/10/about_2.png" alt="" loading="lazy" srcset="https://www.totemautomobili.com/wp-content/uploads/2020/10/about_2.png 365w, https://www.totemautomobili.com/wp-content/uploads/2020/10/about_2-289x300.png 289w" sizes="(max-width: 365px) 100vw, 365px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				<div data-id="2db8cdc" data-element_type="column">
			<div>
							<div>
						
				
				<div data-id="01606d3" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<div><p>Redesigning the Alfa Romeo Giulia GTA with a revived design that preserves the iconic soul, whilst reaches distinction for the craftsmanship of each component, Totem Giulia GT electric runs the road of the future as a result of advanced electrical technology, which improve its performance.</p>
<p><span>Maintaining 10% of the original chassis, to which a new full aluminum suspensions, specifically designed for the car, has been coupled, we substituted the classic fuel engine with an electric motor, able to grant an unparalleled power, a longer duration and a greener vision.</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="e61219f" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="d0ecafe" data-element_type="column">
			<div>
							<div>
						
				
				
				<div data-id="ad7c83b" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<div><p>The conversion process started from our beloved classic Alfa Romeo Giulia GT Junior 1300/1600, built between 1970 and 1975. We totally disassembled, stripped, unmounted the external panels. The frame was finely tuned and stiffened by hand to grant the significant power increase from the original 192bhp to 518bhp.</p><p>At the front axle we designed new MacPerson suspensions, at the rear axle we incorporated a multilink aluminum system, connected to a new rear sub-frame, which supports the electric motor, in line with the semiaxle.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				<div data-id="ba22c8b" data-element_type="column">
			<div>
							<div>
						<div data-id="4ec10b9" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="1600" height="1067" src="https://www.totemautomobili.com/wp-content/uploads/2020/10/Chassis.jpg" alt="" loading="lazy" srcset="https://www.totemautomobili.com/wp-content/uploads/2020/10/Chassis.jpg 1600w, https://www.totemautomobili.com/wp-content/uploads/2020/10/Chassis-300x200.jpg 300w, https://www.totemautomobili.com/wp-content/uploads/2020/10/Chassis-1024x683.jpg 1024w, https://www.totemautomobili.com/wp-content/uploads/2020/10/Chassis-768x512.jpg 768w, https://www.totemautomobili.com/wp-content/uploads/2020/10/Chassis-1536x1024.jpg 1536w" sizes="(max-width: 1600px) 100vw, 1600px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="9d5624a" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="b0a8f18" data-element_type="column">
			<div>
							<div>
						<div data-id="ecb2218" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="800" height="534" src="https://www.totemautomobili.com/wp-content/uploads/2020/10/IMG_5511-1024x683.jpg" alt="" loading="lazy" srcset="https://www.totemautomobili.com/wp-content/uploads/2020/10/IMG_5511-1024x683.jpg 1024w, https://www.totemautomobili.com/wp-content/uploads/2020/10/IMG_5511-300x200.jpg 300w, https://www.totemautomobili.com/wp-content/uploads/2020/10/IMG_5511-768x512.jpg 768w, https://www.totemautomobili.com/wp-content/uploads/2020/10/IMG_5511-1536x1024.jpg 1536w, https://www.totemautomobili.com/wp-content/uploads/2020/10/IMG_5511-2048x1365.jpg 2048w" sizes="(max-width: 800px) 100vw, 800px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="4641253" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					
				<div data-id="e1b0c30" data-element_type="column">
			<div>
							<div>
						
				
				<div data-id="281d3c3" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<p>The car is stiffened by an internal hidden roll bar, made in steel Fia fe45 40×2.5mm.<br><span>The bull-bar is applied in substitution of the external bumpers to improve its beauty while making it safer and reliable. To preserve quality and assure lifelong corrosion resistance, the whole chassis received a cataphoresis treatment.</span></p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="a9484a3" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="12ae684" data-element_type="column">
			<div>
							<div>
						
				
				<div data-id="66a9b2e" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<p>Thanks to McFly technology by our partner 2electron, the car reproduces a realistic package of <b>performance</b>, <b>sound</b> and <b>vibration</b> starting from the soul of ICE engines up to completely blank sheet, where the customer can design with us his own experience.</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="fb8bbfd" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="7d5271e" data-element_type="column">
			<div>
							<div>
						<div data-id="69dd5fd" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<p>Thanks to the fusion of gaming and ICE calibration, engine torque, gear ratios, number of gear, power band, engine brake, sound and vibration and so many other features are realistic and customizable. We can use a <b>gear lever selector</b> digitally connected to our controller with the same mechanical feeling of a conventional one.</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				<div data-id="f47fe9c" data-element_type="column">
			<div>
							<div>
						<div data-id="9264661" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<p><span>It’s&nbsp;</span><span>easy to change</span><span>: you can switch engines, select the features and drive.<br></span><span>It will be possible to choose from unlimited sound layers, building your own and unique experience, even those that exist only in the creative mind.<br>Very wide possibility of customization in every engine point.</span></p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="36c455bd" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						
		</section>
				<section data-id="3fbf672" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="cf01059" data-element_type="column">
			<div>
							<div>
						<div data-id="b2497a8" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="heading.default">
				<p>
			<h2>Engine torque, power band, number of gears, gear ratios, rev limiter and other amazing features will be tailor-made designed.</h2>		</p>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="25ab659" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="48a5be6" data-element_type="column">
			<div>
							<div>
						<div data-id="ae5d8d8" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="1141" height="557" src="https://www.totemautomobili.com/wp-content/uploads/2020/10/casse-2.jpg" alt="" loading="lazy" srcset="https://www.totemautomobili.com/wp-content/uploads/2020/10/casse-2.jpg 1141w, https://www.totemautomobili.com/wp-content/uploads/2020/10/casse-2-300x146.jpg 300w, https://www.totemautomobili.com/wp-content/uploads/2020/10/casse-2-1024x500.jpg 1024w, https://www.totemautomobili.com/wp-content/uploads/2020/10/casse-2-768x375.jpg 768w" sizes="(max-width: 1141px) 100vw, 1141px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="cd5ae48" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						
		</section>
				<section data-id="0dfe93c" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="17ac646" data-element_type="column">
			<div>
							<div>
						
				<div data-id="b377055" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<p>Take full advantage of the torque curves of the emulated engine: the Sw will manage in real time the optimal gear based on your driving style.<br>Get to the limiter when you drive on track or shift to the next gear at low revs if you want to enjoy the view! To have a more aggressive behavior you can use the gear lever to interact even when the mode is active.</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				<div data-id="a44926d" data-element_type="column">
			<div>
							<div>
						<div data-id="603db8d" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="2096" height="824" src="https://www.totemautomobili.com/wp-content/uploads/2020/11/Gear-Ratio-GT-electric.png" alt="" loading="lazy" srcset="https://www.totemautomobili.com/wp-content/uploads/2020/11/Gear-Ratio-GT-electric.png 2096w, https://www.totemautomobili.com/wp-content/uploads/2020/11/Gear-Ratio-GT-electric-300x118.png 300w, https://www.totemautomobili.com/wp-content/uploads/2020/11/Gear-Ratio-GT-electric-1024x403.png 1024w, https://www.totemautomobili.com/wp-content/uploads/2020/11/Gear-Ratio-GT-electric-768x302.png 768w, https://www.totemautomobili.com/wp-content/uploads/2020/11/Gear-Ratio-GT-electric-1536x604.png 1536w, https://www.totemautomobili.com/wp-content/uploads/2020/11/Gear-Ratio-GT-electric-2048x805.png 2048w" sizes="(max-width: 2096px) 100vw, 2096px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="a11ea71" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="3160b71" data-element_type="column">
			<div>
							<div>
						
				<div data-id="26c8493" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<p>The software controls acceleration based on engine specifications to make the car accelerate smoothly and as fast as possible, avoiding spinning of the drive wheels to ensure you the best standing start procedure matching also with immersive sound and rev limiter feature</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				<div data-id="b266ae3" data-element_type="column">
			<div>
							<div>
						
				<div data-id="6f0e305" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<p>Use the emulated engine braking in downshift to start a drift.<br>The Sw will manage the regenerative braking in order to reproduce the engine inertia increasing the Rpm during the downshift. The behavior is completely customizable by driver.</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="2b3e806" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						
		</section>
				<section data-id="43f4f07" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="aaffbee" data-element_type="column">
			<div>
							<div>
						
				
				<div data-id="9f22d6b" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<p>The front and the rear of our GT electric were redesigned to give a specific identity to the car, to enhance the emotional driving experience and its sporty and contemporary character, whilst staying true to the original car personality and its legendary past.</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="a32f60c" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="b1eb9e6" data-element_type="column">
			<div>
							<div>
						<div data-id="3bb9685" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="1600" height="1051" src="https://www.totemautomobili.com/wp-content/uploads/2020/10/foto-due-frontale-copia.jpg" alt="" loading="lazy" srcset="https://www.totemautomobili.com/wp-content/uploads/2020/10/foto-due-frontale-copia.jpg 1600w, https://www.totemautomobili.com/wp-content/uploads/2020/10/foto-due-frontale-copia-300x197.jpg 300w, https://www.totemautomobili.com/wp-content/uploads/2020/10/foto-due-frontale-copia-1024x673.jpg 1024w, https://www.totemautomobili.com/wp-content/uploads/2020/10/foto-due-frontale-copia-768x504.jpg 768w, https://www.totemautomobili.com/wp-content/uploads/2020/10/foto-due-frontale-copia-1536x1009.jpg 1536w" sizes="(max-width: 1600px) 100vw, 1600px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				<div data-id="e6d4aed" data-element_type="column">
			<div>
							<div>
						
				
				<div data-id="51cff60" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<p><span>At the front we evoked the competitive fame of the Giulia GTam making it 180mm wider, selecting headlights in LED technology inspired by rally cars and a carbon front grille embellished with geometric patterns.</span></p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="4bc9b67" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="21486d3" data-element_type="column">
			<div>
							<div>
						
				
				<div data-id="e08c28d" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="text-editor.default">
				<div>
					<p>The rear was redesigned to provide a curvy shape, while accommodating new LED taillights and two large extractors based on an initial aerodynamic study of the whole coefficient. To balance the design we also agreed to move down the license plate.<br></p>
				</div>
				</div>
						</div>
					</div>
		</div>
				<div data-id="355159e" data-element_type="column">
			<div>
							<div>
						<div data-id="8f54fde" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="1600" height="1055" src="https://www.totemautomobili.com/wp-content/uploads/2020/10/3.jpg" alt="" loading="lazy" srcset="https://www.totemautomobili.com/wp-content/uploads/2020/10/3.jpg 1600w, https://www.totemautomobili.com/wp-content/uploads/2020/10/3-300x198.jpg 300w, https://www.totemautomobili.com/wp-content/uploads/2020/10/3-1024x675.jpg 1024w, https://www.totemautomobili.com/wp-content/uploads/2020/10/3-768x506.jpg 768w, https://www.totemautomobili.com/wp-content/uploads/2020/10/3-1536x1013.jpg 1536w" sizes="(max-width: 1600px) 100vw, 1600px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="655fe3f" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="9459db0" data-element_type="column">
			<div>
							<div>
						<div data-id="bfb885b" data-element_type="widget" data-widget_type="flip-box.default">
				<div>
					<div>
			
			<div>
			<div>
				<div>
					
											<p>
							The electric motor in place generates 518bhp, with a couple of 940 Nm (or 692 Ft lbs), which
accelerates our Totem GT electric from 0 to 100 Km/h in 3,4”.<br>We implemented also an electronic power control to manage the power, with 3 efficiency settings: D (dynamic), N (natural) and A
(advanced).						</p>
					
								</div>
		</div>
		</div>
		</div>
				</div>
				</div>
						</div>
					</div>
		</div>
				<div data-id="f15b940" data-element_type="column">
			<div>
							<div>
						<div data-id="526cd3c" data-element_type="widget" data-widget_type="flip-box.default">
				<div>
					<div>
			
			<div>
			<div>
				<div>
					
											<p>
							We are proud to present one of the safest and lightest battery packs in the world, with only 350 Kg of weight and 50,4 Kwh.<br>The internal modules are certified UN38.3 (Immersion Cooled Modular
Battery Pack System submerges cells directly in 3M™ Novec™ Engineered Fluid to deliver unprecedented continuous power to electric vehicles).<br>With a full charge pack you will be able to
drive your Totem GT electric for about 320 KM at a standard pace.						</p>
					
								</div>
		</div>
		</div>
		</div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="db749be" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}">
						<div>
							<div>
					<div data-id="72bc0f2" data-element_type="column">
			<div>
							<div>
						<div data-id="f7fd38b" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="heading.default">
				<p>
			<h4>Subscribe to our newsletter</h4>		</p>
				</div>
				<div data-id="3e72f97" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;}" data-widget_type="heading.default">
				<p>
			<h5>Don't miss new updates on your email</h5>		</p>
				</div>
				
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://www.totemautomobili.com/exterior/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041002</guid>
            <pubDate>Mon, 09 Nov 2020 22:59:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to ARIA for Web Accessibility]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25040841">thread link</a>) | @kliwo
<br/>
November 9, 2020 | https://kliwo.com/aria-for-web-accessibility/ | <a href="https://web.archive.org/web/*/https://kliwo.com/aria-for-web-accessibility/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			

<p>In this article I will introduce you to ARIA for web accessibility is and how you can implement it to help your community; especially people with a disability; to be included and to be able to access and navigate your blog or website. To not make anyone digitally impaired.</p>



<p>Disability is not uncommon, it is estimated that about 15% of the world’s population suffers from some level of disability; that is about a billion people, mind-boggling isn’t it?</p>



<p>While not all of the billion people’s ability is impaired to interact with the web it is nevertheless important to create an environment that is accessible to everyone.</p>



<h2><span id="what_is_aria_for_web_accessibility"></span>What is ARIA for web accessibility<span></span></h2>



<p>ARIA stands for <a href="https://www.w3.org/WAI/standards-guidelines/aria/" target="_blank" aria-label="Accessible Rich Internet Application (opens in a new tab)" rel="noreferrer noopener">Accessible Rich Internet Application</a> and was created for the main purpose to provide accessibility and usability for users with disabilities who use AT (Assistive Technologies).</p>



<p>An example of an AT is a screen reader; this is a program that reads information out loud meanwhile it permits the user to navigate with a keyboard. A screen reader is the main tool for the visually impaired to navigate on the web.</p>



<p>In other words, ARIA just provides more explicative coding that the AT converts to information about parts of the UI, for example, menus, forms, and pop-up alerts.</p>



<h2><span id="use_aria_for_a_raking_boost"></span>Use ARIA for a raking boost<span></span></h2>



<p>A website that offers accessibility usually uses good principles when coding and in web design and therefore works better on the computer and mobile devices that ultimately rank higher on <a aria-label="SEO (opens in a new tab)" href="https://kliwo.com/on-page-seo/" target="_blank" rel="noreferrer noopener">SEO</a>.</p>



<p>You may not know that accessibility is an important part of SEO; not offering accessibility may lead to ranking penalties from Google and other search engines. By making simple changes to your HTML source code can give your site an SEO boost.</p>



<h2><span id="how_to_implement_aria"></span>How to implement ARIA<span></span></h2>



<p>With only simple changes in your HTML coding you can make your website accessible; adding <strong>alt text</strong> to your images, utilize <strong>headings,</strong> and include keyboard controls for interactive elements.</p>



<p>HTML 5 made it very easy, just using the default syntaxes and using them correctly you already completed the first step of making your webpage ARIA friendly. However the screen readers don’t have the ability to see what’s on the site, yet, so some dynamic, interactive, and javascript elements will be skipped by the screen readers. This is where ARIA can help bridge those gaps.</p>



<h2><span id="html_before_aria"></span>HTML before ARIA<span></span></h2>



<p>Always use HTML syntaxes primarily. HTML is, as you just learned, the foundation of web accessibility; and you should ONLY use ARIA when the semantics you are searching for is not available in HTML.</p>



<p>Screen readers work in such a way that they translate and read out loud HTML code that describes accessibility information for example a &lt;nav&gt; or &lt;button&gt; but not a &lt;div&gt;.</p>



<p>An example of how NOT to use HTML coding is to create a button using a &lt;div&gt;, you could ALWAYS use the correct HTML semantic, &lt;button&gt;.</p>



<h2><span id="aria_roles"></span>ARIA roles<span></span></h2>



<p>Elements on a page such as navigation bar, buttons, and links are defined as roles. The role function is to help screen readers tell the user how to interact with elements and what they do. Roles are divided into four different categories, landmark, document, widgets, and abstract roles.</p>



<h3><span id="landmark_roles"></span>Landmark roles<span></span></h3>



<p>Landmark roles separate a page into different parts, menu, main content search bar, etc. To separate the page into different sections helps the user to easier find information and to navigate.</p>



<h3><span id="document_roles"></span>Document roles<span></span></h3>



<p>The document roles define the content of a webpage, they define particular sections within a page, documents, articles, headings, and lists are some examples.</p>



<h3><span id="widgets_roles"></span>Widgets roles<span></span></h3>



<p>Widget roles are elements and interfaces of a page, they often describe javascript-based interfaces or the more complex parts of a web page, some examples are alerts, buttons, and text boxes.</p>



<h3><span id="abstract_roles"></span>Abstract roles<span></span></h3>



<p>The abstract roles are used by the browser and are the basis of how the other ARIA roles, landmark, document, and widget roles are defined. You don’t bother with them, one thing less to worry about.</p>



<h3><span id="aria_testing"></span>ARIA testing<span></span></h3>



<p>Once you implement ARIA on your web page I strongly recommend that you test it using a screen reader. You would want everything to go smoothly and to provide the best possible experience for all your users. To test your web page you download a free screen reader, eg. ChromeVox if you use Chrome, ideally blindfold so you can get the full user experience.&nbsp;</p>



<p>These are the basics of ARIA, hopefully, it feels not as intimidating as it did in the beginning. Once you break down something into smaller parts it automatically gets much simpler to grasp. However this is just the beginning of ARIA, you would be surprised how much you can do and achieve with ARIA.</p>



<p>I strongly believe to include everyone and everybody can contribute towards that goal; whether you can contribute by using ARIA to make someone feel included or you achieve this goal another way does not matter, you made a difference.</p>
		</div></div>]]>
            </description>
            <link>https://kliwo.com/aria-for-web-accessibility/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25040841</guid>
            <pubDate>Mon, 09 Nov 2020 22:41:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abstract Machines: Interpreters for Computer Scientists]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25040388">thread link</a>) | @sinistersnare
<br/>
November 9, 2020 | https://drs.is/post/abstract-machines/ | <a href="https://web.archive.org/web/*/https://drs.is/post/abstract-machines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>
Nov 09, 2020
· 21 min
</p><nav>
<ul>
<li>
<a href="https://drs.is/tags/plt/">
PLT
</a>
</li>
<li>
<a href="https://drs.is/tags/computer-science/">
Computer Science
</a>
</li>
<li>
<a href="https://drs.is/tags/interpreters/">
Interpreters
</a>
</li>
<li>
<a href="https://drs.is/tags/abstract-machines/">
Abstract Machines
</a>
</li>
<li>
<a href="https://drs.is/tags/continuations/">
Continuations
</a>
</li>
</ul>
</nav>
<hr>


<hr>

<p>So im a PhD student now, so I need to write about cool computer science things!
As part of my learnings, I have been writing a bunch of 'Abstract Machines'.
I think of them as how computer scientists do programming languages research without computers.
I mean, they have to use <em>something</em> to write their super complex papers.</p>
<blockquote>
<p>"Computer Science is no more about computers than astronomy is about telescopes"</p>
<ul>
<li>Edsger Dijkstra</li>
</ul>
</blockquote>
<p>We love computers, but they are merely a tool of computing. The real study
of computation can be done without them, and the theories of how programming
languages function is not excluded from that. So how do computer scientists
study interpreters without a computer? The theory of
abstract machines is one of the more popular ways.</p>

<p>What does it mean to compute something? Humans are pretty good at just looking at things
and formulating an answer. For example, a person does not use a sorting algorithm when matching
socks after their laundry is finished. But computers can't just intuit a solution. They are given
precise instructions on what to do to accomplish something. So how can we model that,
and use it to inform the science behind computation?</p>
<p>'Abstract Machines' were created to model real computation strategies. These are functions that take program states, and return some value. Program states can be composed of many different things. The simplest abstract machines simply use the current point that the program is at. Others include a mapping of variables to values, so we can keep state around. We will describe such machines, and what kind of languages they can describe.</p>
<p>These machines, in practice, are interpreters. They are called 'abstract' because the theory on them is not specific to any exact language. You can make an abstract machine for whatever you could want: Lisp, Java bytecode, RISC-V assembly language...</p>

<p>Operational Semantics are how we can write semantics of a language
using pen and paper. Using a simple syntax, we can get the idea of
'if the syntax looks like this, it can be evaluated into this'.</p>
<p>The idea of semantics is separate from execution of a program. Semantics describe what something 'means', based on how it looks. Here are two different kinds of 'operational semantics', big-step and small-step.</p>
<h2 id="big-step">Big Step</h2>
<p>Big step evaluations have the type <code>State -&gt; Value</code>,
meaning that you give them a state, and it will tell you which value
it exactly evaluates to. These are nice and simple generally, because they
give you the values in a single step.</p>
<p>To use a small example expression, <code>if cond then e_true else e_false</code>
there are two rules that will be used.</p>
<ol>
<li>If cond evaluates to <code>true</code>, then the result is what <code>e_true</code> evaluates to.</li>
<li>If cond evaluates to <code>false</code>, then the result is what <code>e_false</code> evaluates to.</li>
</ol>
<p>These rules assume that we have some way to fully evaluate whatever <code>cond</code> is. But whatever that way is is unimportant to the rule of evaluating <code>if</code> statements. This separation is very important for operational semantics. We can write small rules for specific parts of the language, all of which get composed together into a fully formalized machine.</p>
<p>I like using big step when thinking exactly about what expressions <em>do</em>.</p>
<h2 id="small-step">Small Step</h2>
<p>Small step semantics have the type <code>State -&gt; State</code>. They will
show you what to do step by step to evaluate a term. They work iteratively,
explicitly, to show how a given state is computed.</p>
<p>For example, if the term is <code>if cond then e_true else e_false</code>,
There will be a few different rules.</p>
<ol>
<li>If cond is an atomic value, and that value is <code>true</code>, the resulting state is <code>e_true</code>.</li>
<li>If cond is an atomic value, and that value is <code>false</code>, the resulting state is <code>e_false</code>.</li>
<li>If cond is not an atommic value, then evaluate it to <code>cond'</code> , and return <code>if cond' then e_true else e_false</code>.</li>
</ol>
<p>An atomic value is a value that can not be broken up any more. This means a datatype, not a complex expression. In these simple machines, the only atomic datatype is a number. Don't tell computer scientists about quarks, they may go insane.</p>
<p>By going from a state to a next state, small step mechanics more closely follow
how our computers work. They dont evaluate to values directly, they just... keep going.</p>
<p>This may confuse a new reader, if it keeps going, how do we know its done? Big step rules
directly result in a value, full stop. How do we know a state in small step semantics is the one with the value? We use what is called a 'fixpoint', or more simply, we evaluate until there isnt a meaningful change in the state after running. If we evaluate a math expression enough times,
it will decompose into a single number, upon which evaluation will lead to itself. That means there is no more work to be done, and evaluation stops.</p>
<p>The same is true in a language like <code>C</code>, after the final instruction in <code>main</code>, if we try to evaluate any more, nothing will happen, theres nothing left to do. That is a fixpoint.</p>
<p>Small step semantics are a bit more precise in my opinion, and they are much easier to translate
to <em>real</em> interpreters. But it is very useful to understand both styles, they have different uses. Using small steps, we can also more closely trace how an expression is evaluated.</p>

<p>I dont mean the the C language, especially because I would not use simple to describe it!
C in this case stands for 'control'. You may remember things like 'if' are called 'control flow
operators'. Control is the currently running 'thing' in your program. The <code>if</code> operator, is a way to change the control based on a condition. This machine will be called
the C machine because you only need control to represent the state of the entire program.</p>
<p>C machines are not capable of much, only simple rewriting of expresions, because they dont have any information other than the program's control itself to go off of.
One kind of language we can formalize with a C machine is that of mathematical expressions.</p>
<p>Here is a big-step semantics of type  (takes a math expression and returns a number). This means that the control we choose to use is a math expression. The result of evaluating a math expression is a number, of course, so thats the value.</p>


<p>This rule shows how to add expressions to end up with a number. You can understand it by reading the half under the bar as 'this is what we start and end with' and the half above the bar as 'these must be true to use these semantics'. You read  as 'evalutes to'.</p>
<p>You can read this rule like so:</p>
<ol>
<li>If we have some control that looks like  (this is from the bottom left, before the arrow)</li>
<li>if  evaluates to some number  (the first expression above the bar),</li>
<li>if  evaluates to some number  (the second expression above the bar),</li>
<li>if  added to  is equal to some number  (the third expression above the bar).</li>
<li>THEN we know that the expression in step 1 evaluates to .</li>
</ol>
<p>This may seem a bit backwards, we implement adding by adding? Well, the key is that expressions are complex, they can be composed of other expressions or just values. These rules show how to do math on expressions by first evaluating them to values. Then once they are values, it is quite easy to do math operations on them.</p>
<p>Note the distinction between the arrow  and  here.  is saying "left evaluates to right by virtue of applying this machine's rules." and  is saying "you can substitute left for right".</p>
<p>Authors of semantics like these love to use different looking arrow symbols, they all mean the same thing. Usually in big step they use a cool down-facing arrow like . In small step they will use a more boring arrow like .</p>
<h3 id="example">Example</h3>
<p>Lets evaluate a simple math expression to show how you can use these rules to prove that expressions are evaluated correctly using a machines rules.</p>

<p>Here, at the first, bottom most level,  and . Then we need to prove that <code>7 + 3 = 10</code>, and we do that with another application of the addition rule! We could have chosen <code>3 + 4</code> to be be , but it doesnt matter for addition, and we leave issues like that to a parser. I noted each level with the rule that was used to evaluate it. It is generally showed like this, but I usually dont show them. I only have so much horizontal space on this webpage!</p>
<p>To evaluate simple mathematical expressions, we only need a control for the state. C machines are only capable of evaluating simple programs. What if we want to add a simple programming construct like variables? For that, we need a place to store them. And so, the CE machine is born!</p>

<p>To evaluate variables, we need to be able to keep track of what value they hold at a given program point. in a C machine, if we are given <code>a + 2</code>, we have no way of know what <code>a</code> is, because its not a number, and we can only deal with syntax as we see it. But if we gave a machine both <code>a + 2</code>, the control, and a mapping <code>{a : 4}</code>, an environment, we can evaluate the expression to 6!</p>
<p>So, a big-step CE machine doesnt just have <code>MathExp</code> (C) for state anymore, we need an <code>Env</code> (E) to accompany it! The function is now of type . This means that our machine will take 2 arguments, a math expression and an environment, and it will return a computed number.</p>


<p>This simply states that if the expression is a variable, not an artithmetic expression,
the value it returns is what the environment says it is. We use the greek
letter rho ('ρ') (not the letter 'p') to represent the environment. This is what is used
in the literature, and its always best to follow along with norms to avoid confusion! For the history on why they used  for this task, you will have to ask someone smarter than me.</p>
<p>We dont have variable binding yet, but you can imagine an expression like:
<code>m*c*c</code> with an environment <code>{m : 12 c : 299792458}</code>, which will return some number for us.
We have made a calculator with predefined constants! We can put pi in there,
or tau if you are a lunatic...</p>

<p>Wow, it seems like we can do a lot with just a control and an environment. We could further extend this to things like variable assignment (again, these are big-step …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://drs.is/post/abstract-machines/">https://drs.is/post/abstract-machines/</a></em></p>]]>
            </description>
            <link>https://drs.is/post/abstract-machines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25040388</guid>
            <pubDate>Mon, 09 Nov 2020 21:50:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple approach to time series spike detection, using website visits data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25040241">thread link</a>) | @querystash
<br/>
November 9, 2020 | https://app.querystash.com/query/d72aac44f94c57cf513d29e625a34201 | <a href="https://web.archive.org/web/*/https://app.querystash.com/query/d72aac44f94c57cf513d29e625a34201">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://app.querystash.com/query/d72aac44f94c57cf513d29e625a34201</link>
            <guid isPermaLink="false">hacker-news-small-sites-25040241</guid>
            <pubDate>Mon, 09 Nov 2020 21:35:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WebRTC Video Streaming]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25040014">thread link</a>) | @Iwontgo
<br/>
November 9, 2020 | https://antmedia.io/webrtc-video-streaming/ | <a href="https://web.archive.org/web/*/https://antmedia.io/webrtc-video-streaming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="panel-34528-0-0-1" data-index="1"><div>
<div> <p><span>WebRTC stands for web real-time communications. <a href="https://webrtc.org/" target="_blank" rel="noopener noreferrer nofollow">WebRTC</a> is a very exciting, powerful, and highly disruptive cutting-edge technology and streaming protocol.</span></p> <p><span>WebRTC is HTML5 compatible and you can use it to add real-time media communications directly between browser and devices. And you can do that without the need of any prerequisite of plugins to be installed in the browser. </span><span>And Webrtc is progressively becoming supported by all major modern browser vendors </span><span>including Safari, Google Chrome, Firefox, Opera and others</span><span>.&nbsp;</span></p> <p><span>Thanks to WebRTC technology, you can embed the real-time video directly into your browser-based solution to create an engaging and interactive streaming experience for your audience without worrying about the delay. WebRTC video streaming is just changing the way of engagement in the new normal.</span></p></div></div></div></div>]]>
            </description>
            <link>https://antmedia.io/webrtc-video-streaming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25040014</guid>
            <pubDate>Mon, 09 Nov 2020 21:15:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons Learned Building an Open Source MLOps Platform]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25039872">thread link</a>) | @ChefboyOG
<br/>
November 9, 2020 | https://www.cortex.dev/post/building-an-open-source-mlops-platform | <a href="https://web.archive.org/web/*/https://www.cortex.dev/post/building-an-open-source-mlops-platform">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div content-type="article"><p>For the last two years, we’ve been working on Cortex, our open source machine learning deployment platform. Over that time, we’ve been really fortunate to see it grow into what it is today, used in production by teams around the world, and supported by a fantastic community of contributors.</p><p>We’ve also had to change our thinking several times along the way. The understanding of the ML ecosystem we had at the beginning has not always turned out to be accurate, and this is reflected in various changes we’ve made to Cortex.</p><p>As interest in MLOps continues to increase, I thought it would be useful (for our sakes as much as anyone else’s) to document a few of the key lessons we’ve learned that’ve come to shape Cortex.</p><p>If you’re working on a production machine learning system, building machine learning infrastructure, or designing your own MLOps tool, hopefully the following lessons (listed in no particular order) are useful for you.</p><h3>1. Production machine learning runs in the cloud</h3><p>When Cortex was still in its idea stage, one of our most frequent discussions was whether or not it should support on-premise deployments. At the time, the worry was that a large portion of the machine learning ecosystem was going to remain on-premise indefinitely due to privacy and cost.</p><p>These worries were enflamed when we initially released Cortex. While we had some excited users, we also had plenty of people writing in requesting on-prem support. We worried that by going all-in on the public clouds, we’d cut off most of the machine learning ecosystem.</p><p>Over the last two years, things have changed. Production machine learning is almost entirely moving to the cloud, and there are a couple reasons why.</p><p>The first is the standard reason for moving to the cloud: scalability. As production machine learning systems become more powerful and responsible for more features, their workloads increase. If you need to autoscale to dozens of GPUs during peak hours, the cloud has obvious advantages.</p><p>The second is the investment by the major clouds into ML-specific offerings. Major clouds now offer both dedicated software and hardware for machine learning. For example, Google and AWS both offer ASICs (TPUs and Inferentia, respectively) that substantially improve machine learning performance, and both are only available on their respective clouds.</p><p>More and more, the cloud is becoming the only realistic way to deploy production machine learning systems.</p><h3>2. It’s too early for end-to-end MLOps tools</h3><p>Another misguided belief we held in Cortex’s early days was that Cortex needed to be an all-inclusive, end-to-end MLOps platform that automated your pipeline from raw data to deployed model.</p><figure id="w-node-a47abffb7609-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa9ad5cb4b8083a07ddc765_0*6z89yrFEvqkVBqIg.jpeg" alt=""></p></figure><p>We’ve written a full <a href="https://towardsdatascience.com/we-tried-to-build-an-end-to-end-ml-platform-heres-why-it-failed-190c0f503536" target="_blank">breakdown of why that was the wrong decision,</a> but the short version is that it’s still way too early in the lifespan of MLOps to build that sort of platform.</p><p>Every page of the production machine learning playbook is constantly being rewritten. For example, in the last several years:</p><ul role="list"><li><strong>Our notion of “big” models has exploded.</strong> We thought models with hundreds of millions of parameters were flirting with boundaries of being “too large” to deploy. Then Transformer models like GPT-2 started weighing in the billions—and people still built applications out of them.</li><li><strong>The ways we train models have changed. </strong>Transfer learning, neural architecture search, knowledge distillation—we have more techniques and tools than ever to design, train, and optimize models efficiently.</li><li><strong>The machine learning toolbox has grown rapidly</strong>. PyTorch was only released in 2016, shortly after TF Serving’s initial public release. ONNX came out in 2017. The frameworks, languages, and features that an end-to-end MLOps platform would need to support changes endlessly.</li></ul><p>We ran into all of these problems with our first release of Cortex. We provided a seamless experience—<em>if</em> <em>you used the narrow stack we supported.</em> Because everything (including language, pipeline, frameworks, and even team structure) can vary so wildly across ML orgs, we were almost always “one feature away” from fitting any given team’s stack.</p><p>As a modular platform, focused on one discrete part of the machine learning lifecycle—deployment—without opinions about the rest of the stack, Cortex has been adopted by many more teams at a much faster pace. We’ve seen rapid growth in other MLOps tools with similar “best of breed” approaches at different parts of the stack, including <a href="https://dvc.org/" target="_blank">DVC (Data Version Control) </a>and <a href="https://www.comet.ml/site/" target="_blank">Comet</a>.</p><h3>3. Data science, ML engineering, and ML infrastructure are all different — in theory</h3><p>With Cortex, we use the following high-level model of an ML function and its constituent parts:</p><ul role="list"><li><strong>Data science</strong>. Concerned with the development of models, from exploring the data to conducting experiments to training and optimizing models.</li><li><strong>Machine learning engineering</strong>. Concerned with the deployment of models, from productionizing models to writing inference services to designing inference pipelines.</li><li><strong>Machine learning infrastructure</strong>. Concerned with the design and management of the ML platform, from resource allocation to cluster management to performance monitoring.</li></ul><p>And in theory, these are nicely delineated functions with clear handoff points. Data science creates models which are turned into inference pipelines by ML engineering and deployed to a platform maintained by ML infrastructure.</p><p>But, this is an overview of the theoretical functions in an ML org, not the <em>actual roles</em> people hold. Oftentimes, a data scientist will also do ML engineering work, or an ML engineer will be tasked with managing an inference cluster.</p><p>Building a tool for these different use-cases gets complex, as the optimal ergonomics of an interface for one role can vary drastically from another.</p><p>For example, <a href="https://towardsdatascience.com/why-we-do-machine-learning-engineering-with-yaml-not-notebooks-a2a97f5e04f8" target="_blank">for reasons we’ve explained before</a>, Cortex APIs are written as Python scripts with YAML manifests, not notebooks, and are deployed via a CLI. </p><p>For MLEs, this is comfortable. For data scientists, however, it is often uncomfortable, as YAML and CLIs aren’t common tools in their ecosystem. Because of this, we needed to build a Python client for defining deployments in pure Python in order for some teams to use Cortex successfully.</p><p>Now, people who are more comfortable with CLIs can deploy like this:</p><figure id="w-node-b878c71bee4b-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa9ad5c272d5ce9d4c2dd28_0*yV51u9hxfGDvxtF3.png" alt=""></p></figure><p>And people more comfortable with pure Python can do this:</p><figure id="w-node-5864f8b2c1a4-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa9ad5c09e66f37c2c56cdf_1*1CO_-hPGhV9qNuH4c3Jxuw.png" alt=""></p></figure><p>The takeaway here is that if you’re building MLOps tooling, remember everyone who will be using it in practice, not just in theory.</p><h3>4. ML native companies have different needs</h3><p>Several years ago, the most common examples of production machine learning were popular products optimized by trained models. Payment processors would sprinkle in fraud detection models, streaming platforms would boost their engagement with recommendation engines, etc.</p><p>Now, however, there is a new wave of companies whose products aren’t enhanced by models—they <em>are</em> models.</p><p>These companies, which we refer to as ML native, operate in different ways. Some sell access to an inference pipeline as an API, as in the case of <a href="https://www.glisten.ai/" target="_blank">Glisten</a>, whose API allows retailers to tag and categorize products instantly:</p><figure id="w-node-dc634e21281f-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fa47e5ab8c60a850d3f4032_0*mw_tAL1CeDD1Q8e3.png" alt=""></p></figure><p>Others build applications whose core functionality is provided by a trained model. For example, <a href="https://postera.ai/" target="_blank">PostEra’s</a> medicinal chemistry platform uses models to predict the most likely chemical reactions for creating a specific drug, and <a href="https://play.aidungeon.io/main/home" target="_blank">AI Dungeon</a> uses a trained language model to create an endless choose-your-own-adventure:</p><p>These ML native applications have different infrastructure needs. For one, they typically rely on realtime inference, meaning their models need to be deployed and available at all times.</p><p>Ensuring this availability can get very expensive. <a href="https://medium.com/@aidungeon/how-we-scaled-ai-dungeon-2-to-support-over-1-000-000-users-d207d5623de9" target="_blank">AI Dungeon uses a 6 GB model</a> that can only handle a few concurrent requests and requires GPUs for inference. To scale to even a few thousand concurrent users, they need many large GPU instances running at once—something that is costly to sustain for long periods.</p><p>When we first built Cortex, we hadn’t worked with many ML native teams. After working with them, we wound up prioritizing a new set of features, many of which were at least in part aimed at helping control inference costs:</p><ul role="list"><li>Request-based autoscaling to optimally scale each model for spend</li><li>Spot instance support to allow for cheaper base instance prices</li><li>Multi-model caching, live reloading, and multi-model endpoints to increase efficiency</li><li>Inferentia support for more cost-effective and performant instance types</li></ul><p>As the number of ML native companies continues to rise quickly, MLOps tools and platforms are going to have to build for their needs.</p><h3>5. MLOps is production machine learning’s biggest bottleneck</h3><p>This is one of the few things we believed before building Cortex that we still find to be true today. It is the feasibility of building and deploying a production machine learning system prevents teams from using ML. </p><p>Training and retraining models is not cheap. Deploying models to production isn’t cheap either. Building a platform to support those deployments is a full-scale infrastructure project, one that has to be maintained moving forward.</p><p>These costs make machine learning unapproachable for most companies. and the frustrating part is that they aren’t intrinsic qualities of machine learning. We can solve them with better infrastructure—no ML research breakthroughs needed.</p><p>As the MLOps ecosystem matures, new tools will continue to abstract away these parts of infrastructure and nullify the costs that prohibit teams from using ML in production. If you want to accelerate the proliferation of machine learning, consider contributing to any of the many open source MLOps projects—<a href="https://github.com/cortexlabs/cortex" target="_blank">like this one</a>.</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.cortex.dev/post/building-an-open-source-mlops-platform</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039872</guid>
            <pubDate>Mon, 09 Nov 2020 21:04:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Developers Love Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25039826">thread link</a>) | @ibraheemdev
<br/>
November 9, 2020 | https://ibraheem.ca/posts/why-devs-love-rust | <a href="https://web.archive.org/web/*/https://ibraheem.ca/posts/why-devs-love-rust">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Rust has been getting a lot of media attention recently. It seems like a "X written in Rust" post makes the front page of hackernews every other day. Rust has been <a href="https://insights.stackoverflow.com/survey/2020#technology-most-loved-dreaded-and-wanted-languages">voted the most loved language</a> for five years running, and it <a href="https://octoverse.github.com/#fastest-growing-languages">grew in use on Github</a> by <strong>235%</strong> from 2018 to 2019. Large companies such as Mozilla, Apple, Amazon, Facebook, Google, Twitter, and Microsoft have began adopting it in their codebases. So, why do so many people love Rust?</p>
<p>Rust was built to solve many of the hassles associated with other popular languages. Let's look at a couple of examples:</p>
<h4 id="memory-safety"><a href="#memory-safety" aria-label="memory safety permalink"></a><strong>Memory Safety</strong></h4>
<p>Rust focuses on speed and safety. It balances speed and safety through many ‘zero-cost abstractions’. This means that in Rust, abstractions cost as little as possible in order to make them work. The ownership system is a prime example of a zero cost abstraction. All of the analysis we’ll talk about in this section is done at compile time. You do not pay any run-time cost for any of these features.</p>
<p>To track the ownership of each value: a value can only be used at most once, after which the compiler refuses to use it again.</p>
<p>For example, the following code:</p>
<div data-language="rust"><pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> original <span>=</span> String<span>::</span><span>from</span><span>(</span><span>"hello"</span><span>)</span><span>;</span>
    <span>takes_ownership</span><span>(</span>original<span>)</span><span>;</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> original<span>)</span>
<span>}</span> 

<span>fn</span> <span>takes_ownership</span><span>(</span>other<span>:</span> String<span>)</span> <span>{</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> other<span>)</span><span>;</span>
<span>}</span> </code></pre></div>
<p>Yields an error:</p>
<div data-language="rust"><pre><code>error<span>[</span>E0382<span>]</span><span>:</span> borrow of moved value<span>:</span> `original`
 <span>-</span><span>-&gt;</span> src<span>/</span>main<span>.</span>rs<span>:</span><span>4</span><span>:</span><span>20</span>
<span>3</span> <span>|</span>   <span>takes_ownership</span><span>(</span>original<span>)</span><span>;</span>
  <span>|</span>                     <span>-</span> value moved here
<span>4</span> <span>|</span>   <span>println!</span><span>(</span><span>"{}"</span><span>,</span> original<span>)</span>
  <span>|</span>                    <span>^</span> value borrowed here after mov</code></pre></div>
<p>In the above code, the ownership of <code>original</code> was moved to the <code>take_ownership</code> function. Because the ownership was moved, Rust now cleans up the memory of <code>original</code>. Now, the compiler prevents you from using <code>original</code>. </p>
<p>Rust's ownership model guarantees, at compile time, that your application will be safe from dereferencing null or dangling pointers This prevents the dreaded double-free regularly encountered in C or C++, along with many other memory related issues.</p>
<p>In Rust, functions can <em>borrow</em> ownership of a value. Rust tracks borrowed ownership with the borrow checker. We can modify the example above to borrow <code>original</code>, instead of taking ownership:</p>
<div data-language="rust"><pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> original <span>=</span> String<span>::</span><span>from</span><span>(</span><span>"hello"</span><span>)</span><span>;</span>
    <span>borrow_ownership</span><span>(</span><span>&amp;</span>original<span>)</span><span>;</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> original<span>)</span>
<span>}</span> 

<span>fn</span> <span>borrow_ownership</span><span>(</span>other<span>:</span> <span>&amp;</span>String<span>)</span> <span>{</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> other<span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>Now the code compiles, because the ownership of <code>original</code> stays in the main function. Instead of owning the resource, the function borrows ownership. We call the &amp;T type a ‘reference’. A binding that borrows something does not deallocate the resource when it goes out of scope. This means that after the borrow, we can use our original bindings again.</p>
<p>Rust memory safety comes at the cost of complexity. New developers often complain that getting a program to compile can be quite difficult. It’s pretty common for newcomers to the Rust community to get stuck "fighting the borrow checker". As <a href="https://news.ycombinator.com/item?id=23437202#unv_23437831">Rust learner</a> explained:</p>
<blockquote>
<p>"It's hard but I love it. Dealing with the compiler felt like being the novice in an old kung fu movie who spends day after day being tortured by his new master (rustc) for no apparent reason until one day it clicks and he realizes that he knows kung fu."</p>
</blockquote>
<p>Fighting the borrow checker can be frustrating, but trust me, it's worth it. Rust is often compared to Haskell and Scala in the sense that if your code compiles, you can sleep at night without having to worry about runtime errors. This is even more true after looking at the memory safety Rust enforces through its ownership model.</p>
<p>Rust also has a second language hidden inside it that doesn’t enforce memory safety guarantees: it’s called <em>unsafe Rust</em>. Wrapping code with the <code>unsafe</code> block effectively tells the compiler to shut up, because you know what you are doing. Doing so gives you <em>unsafe superpowers</em>. For example, you can dereference a raw pointer:</p>
<div data-language="go"><pre><code>let mut num <span>=</span> <span>5</span><span>;</span>

let r1 <span>=</span> <span>&amp;</span>num as <span>*</span><span>const</span> i32<span>;</span>
let r2 <span>=</span> <span>&amp;</span>mut num as <span>*</span>mut i32<span>;</span>

unsafe <span>{</span>
  <span>println</span><span>!</span><span>(</span><span>"r1 is: {}"</span><span>,</span> <span>*</span>r1<span>)</span><span>;</span>
  <span>println</span><span>!</span><span>(</span><span>"r2 is: {}"</span><span>,</span> <span>*</span>r2<span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>If you can't do something in safe Rust, you can implement it yourself with <code>unsafe</code>. However, <code>unsafe</code> should be used with caution. Abusing it can have unwanted consequences. Because of this, Rust forces you to explicitly mark code as unsafe. You cannot use an unsafe function in a safe block. Many developers even opt to mark there entire project with <code>![forbid(unsafe_code)]</code>.</p>
<h4 id="rust-vs-dynamic-languages"><a href="#rust-vs-dynamic-languages" aria-label="rust vs dynamic languages permalink"></a><strong>Rust vs. Dynamic Languages</strong></h4>
<p>Developers coming from dynamically typed languages will find it hard to argue the benefits of static typing. Static type definitions are even being added to many popular dynamic languages, such as javascript's <a href="https://www.typescriptlang.org/">typescript</a>, python's <a href="https://github.com/python/mypy">type hints</a>, and ruby's <a href="https://github.com/ruby/rbs">rbs</a>. Static languages are generally considered more "scalable" and better for larger codebases as the compiler does much of the work for you. Let's look at an example:</p>
<div data-language="ruby"><pre><code><span>def</span> <span><span>silly</span></span><span>(</span>a<span>)</span>
  <span>if</span> a <span>&gt;</span> <span>0</span>
    puts <span>'hello'</span>
  <span>else</span>
    print a <span>+</span> <span>'3'</span>
  <span>end</span>
<span>end</span></code></pre></div>
<p>The code above prints 'hello', right? Let's test it out:</p>

<p>But, when you pass a negative number:</p>
<div data-language="ruby"><pre><code>$ silly<span>(</span><span>-</span><span>1</span><span>)</span>
<span>=</span><span>&gt;</span> <span>TypeError</span> <span>(</span><span>String</span> can't be coerced into <span>Integer</span><span>)</span></code></pre></div>
<p>You get a <code>TypeError</code> at runtime. </p>
<p>A simple mistake like this can cause runtime errors that can be hard to debug without comprehensive test coverage. Since Rust is statically typed, all type errors will be caught at compile time, and this problem never occurs.</p>
<p>Static typing also results in compiled code that executes faster as the compiler knows the exact data types that are in use, and therefore can produce optimized machine code.</p>
<p>The points in this section apply to pretty much all strongly typed languages. Now let's look at some of the things Rust does differently than other statically typed languages.</p>
<h4 id="no-nulls"><a href="#no-nulls" aria-label="no nulls permalink"></a><strong>No Nulls</strong></h4>
<p>Most languages have a concept of null. Any value can either be what you expect, or nothing at all. If you accidentally miss a null check, you code can blow up at runtime. Tony Hoare, the inventor of null references had <a href="https://qconlondon.com/london-2009/qconlondon.com/london-2009/speaker/Tony+Hoare.html">this to say</a> about the concept:</p>
<blockquote>
<p>I call it my billion-dollar mistake. It was the invention of the null reference in 1965. At that time, I was designing the first comprehensive type system for references in an object oriented language (ALGOL W). My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler. But I couldn't resist the temptation to put in a null reference, simply because it was so easy to implement. This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years</p>
</blockquote>
<p>Rust, unlike most other languages, does not have a concept of null. It does not exist! If <code>x = 1</code>, then x <em>is</em> an integer, and will <em>always</em> be an integer.</p>
<p>Rust expresses optional values with an type called <code>Option</code>: </p>
<div data-language="rust"><pre><code><span>pub</span> <span>enum</span> Option<span>&lt;</span>T<span>&gt;</span> <span>{</span>
    None<span>,</span>
    <span>Some</span><span>(</span>T<span>)</span><span>,</span>
<span>}</span></code></pre></div>
<p>An <code>Option</code> is either something, or nothing. This union is expressed succinctly with Rust enum's, which can hold values. You can pattern match on an option enum to access the underlying value:</p>
<div data-language="rust"><pre><code><span>match</span> x <span>{</span>
  None <span>=&gt;</span> <span>handle_none</span><span>(</span><span>)</span><span>,</span>
  <span>Some</span><span>(</span>value<span>)</span> <span>=&gt;</span> <span>return</span> value
<span>}</span></code></pre></div>
<p>But what happens if you forget to check for <code>None</code>? Doesn't this pose the same problems as null? Nope! Rust solves this problem my enforcing exhaustive pattern matching. This means that this code, which does not check for <code>None</code>:</p>
<div data-language="rust"><pre><code><span>match</span> x <span>{</span>
  <span>Some</span><span>(</span>value<span>)</span> <span>=&gt;</span> <span>println!</span><span>(</span><span>"{}"</span><span>,</span> value<span>)</span>
<span>}</span></code></pre></div>
<p>Will not compile:</p>
<div data-language="rust"><pre><code>error<span>[</span>E0004<span>]</span><span>:</span> non<span>-</span>exhaustive patterns<span>:</span> `None` not covered
<span>-</span><span>-&gt;</span> src<span>/</span>main<span>.</span>rs<span>:</span><span>6</span><span>:</span><span>11</span>
  <span>|</span>
<span>6</span> <span>|</span>  <span>match</span> x <span>{</span>
  <span>|</span>  <span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span> pattern `None` not covered
  <span>|</span>
  <span>=</span> help<span>:</span> ensure that all possible cases are being handled<span>,</span> 
    possibly by adding wildcards or more <span>match</span> arms</code></pre></div>
<p>In Rust, the code above would never make it to production, and clients would never experience the error because the compiler is so strict. Also note how detailed the error message is, telling you the exact location, problem, and potential solution to the error.</p>
<h4 id="rust-vs-statically-typed-languages"><a href="#rust-vs-statically-typed-languages" aria-label="rust vs statically typed languages permalink"></a><strong>Rust vs. Statically Typed Languages</strong></h4>
<p>Rust does its best to get out of the developer's way when it comes to static typing. Rust has a very smart type inference engine. It looks not only at the type of the value expression during its initialization but also at how the variable is used afterwards to infer its type. However, Rust's use of type inference does not decrease its ability to provide detailed error messages at compile time. Let's see how that type inference works. </p>
<p>We can start by initializing a integer:</p>

<p>Because of the annotation, the compiler knows that elem is of type u8. Now we can create a mutable vector (a growable array):</p>
<div data-language="rust"><pre><code><span>let</span> <span>mut</span> vec <span>=</span> Vec<span>::</span><span>new</span><span>(</span><span>)</span><span>;</span></code></pre></div>
<p>At this point the compiler doesn't know the exact type of the vector. It just knows that it's a vector of something (<code>Vec&lt;_&gt;</code>). But once we insert the element into the vector</p>

<p>Aha! Now the compiler knows that <code>vec</code> is a vector of u8's (<code>Vec&lt;u8&gt;</code>)</p>
<p>No type annotation of variables was needed, the compiler is happy and so is the programmer!</p>
<h4 id="rust-vs-garbage-collected-languages"><a href="#rust-vs-garbage-collected-languages" aria-label="rust vs garbage collected languages permalink"></a><strong>Rust vs. Garbage Collected Languages</strong></h4>
<p>Garbage collection is an automatic memory management system that looks for unused variables and frees their memory. It is a concept employed by many widely used languages, such as Java, Ruby, and Python. However, garbage collection can introduce performance issues at scale.</p>
<p>For example, <a href="https://discord.com/">Discord</a> used Golang, a garbage collected language, for keeping track of which channels and messages a user read. They began experiencing latency and CPU spikes consistently every 2 minutes. This is because Go will force a garbage collection run every 2 minutes, scanning the entire LRU cache to determine which memory needed to be handled by GC.</p>
<p>Here is a before and after of them switching from Go, to Rust. Go is purple, Rust is blue.</p>
<p><img src="https://ibraheem.ca/media/rustvsgo-discord.png"></p>
<p>Read the full post here: <a href="https://blog.discord.com/why-discord-is-switching-from-go-to-rust-a190bbca2b1f">Why Discord is Switching from Go to Rust</a></p>
<p>Why is Rust so much better? Rust is blazingly fast and memory-efficient without needing a garbage collector, due to its ownership model. Here is a simple example:</p>

<p>Thanks to Rust's ownership tracking, the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ibraheem.ca/posts/why-devs-love-rust">https://ibraheem.ca/posts/why-devs-love-rust</a></em></p>]]>
            </description>
            <link>https://ibraheem.ca/posts/why-devs-love-rust</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039826</guid>
            <pubDate>Mon, 09 Nov 2020 20:59:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Bad Parts, part 2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25039758">thread link</a>) | @anuragsoni
<br/>
November 9, 2020 | https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2 | <a href="https://web.archive.org/web/*/https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><i>See a typo? Have a suggestion?
<a target="_blank" rel="nofollow" href="https://github.com/snoyberg/snoyman.com/edit/master/content/posts/haskell-bad-parts-2.md">Edit this page on Github</a>
</i>
</p>

<p>If you didn’t see it, please check out <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1">part 1 of this series</a> to understand the purpose of this. Now, for more bad parts!</p>
<h2>Partial functions (in general)</h2>
<p>Laziness very likely belongs in this list. My favorite part of criticizing laziness is how quickly people jump to defend it based on edge cases. So let’s be a bit more nuanced before I later get far <em>less</em> nuanced. Laziness is <strong>obviously</strong> a good thing. Strictness is <strong>obviously</strong> a good thing. They also both suck. It depends on context and purpose. Each of them introduce different kinds of issues. The real question is: what’s a more sensible default? We’ll get to that another time.</p>
<p>I called this section partial functions. Am I having a senior moment? Maybe, but I intentionally started with laziness. In a strict language, function calls can result in exceptions being thrown, segfaulting occurring, or panicking. (And if I write a “Rust: The Bad Parts”, believe me, I’ll be mentioning panicking.) The fact that a function <em>acts</em> like it can successfully perform something, but in fact fails in a predictable way (like failing a <code>HashMap</code> lookup), it should be reflected at the type level. If not, ya dun goofed.</p>
<p>Also, if you have a language that doesn’t let you reflect this information at the type level: ya dun goofed.</p>
<p>Partial functions are the antithesis of this concept. They allow you to say “yeah dude, I can <em>totally</em> give you the first value in an empty list.” Partial functions are like politicians: you can tell they’re lying because their lips are moving. (“But Michael,” you say. “Functions don’t have lips!” Whatever, I’m waxing poetical.)</p>
<p>Alright, so plenty of languages screw this up. Haskell tells those languages “hold my beer.”</p>
<p><img src="https://www.snoyman.com/static/images/holdmybeer.jpg"></p><p>Haskell screws up partial functions way, way worse than other languages:</p>
<ol>
<li>It promotes a whole bunch of them in the standard libraries and <code>Prelude</code>.</li>
<li>Some libraries, like <code>vector</code> (I’m getting to you, don’t worry) make it <em>really</em> confusing by providing an <code>index</code> and <code>unsafeIndex</code> function. Hint: <code>index</code> isn’t really safe, it’s just less unsafe.</li>
<li>There’s no obvious way to search for usages of these partial functions.</li>
<li>And, by far, the worst…</li>
</ol>
<h3>Values are partial too!</h3>
<p>Only in a lazy language does this exist. You call a function. You get a result. You continue working. In any other non-lazy language, that means you have a value. If I have a <code>u32</code> in Rust, I actually have a <code>u32</code> in Rust. Null pointers in languages like C and Java somewhat muddy this situation, but at least primitive types are really there if they say they’re there.</p>
<p>No, not Haskell. <code>x :: Int</code> may in fact not exist. It’s a lie. <code>let x = head [] :: [Int]</code> is a box waiting to explode. And you find out <em>much</em> later. And it’s even worse than that. <code>let alice = Person { name = "Alice", age = someAge }</code> may give you a valid <code>Person</code> value. You can evaluate it. But Cthulhu help you if you evaluate <code>age alice</code>. Maybe, just maybe, <code>someAge</code> is a bottom value. Boom! You’ve smuggled a dirty bomb out.</p>
<p>I’m not advocating for removing laziness in Haskell. In fact I’m not really advocating for much of anything in this series. I’m just complaining, because I like complaining.</p>
<p>But <em>if</em> I was to advocate some changes:</p>
<ul>
<li>Deprecate partial functions</li>
<li>Introduce a naming scheme for partial functions to be more obvious</li>
<li>Introduce a compiler warning to note partial function use (with a pragma to turn off specific usages)</li>
<li>Warn by default on partial pattern matches</li>
<li>Advocate strict data fields by default</li>
</ul>
<h3>But ackshualllly, infinite loops</h3>
<p>Someone’s gonna say it. So I’ll say it. Yes, without major language changes, you can’t prevent partial functions. You can’t even detect them, unless Turing was wrong (and I have my suspicions.) But Haskell community, please, please learn this lesson:</p>
<p><strong>DON’T LET THE PERFECT BE THE ENEMY OF THE GOOD</strong></p>
<p>We can get rid of many of the most common partial functions trivially. We can detect many common cases by looking for partial pattern matches and usage of <code>throw</code> (again, horribly named function). “But we can’t get everything” doesn’t mean “don’t try to get something.”</p>
<h2>Hubris</h2>
<p>Given what I just said, we Haskellers have a lot of hubris. Each time you say “if it compiles it works,” a thunk dies and collapses into a blackhole. We’ve got plenty of messes in Haskell that don’t sufficiently protect us from ourselves. The compiler can only do as good a job as our coding standards and our libraries allow.</p>
<p>“But Haskell’s at least better than languages like PHP.” I mean, obviously I agree with this, or I’d be writing PHP. But since I’m being ridiculously hyperbolic here, let me make a ridiculous claim:</p>
<blockquote>
<p><strong>PHP is better than Haskell, since at least you don’t get a false sense of security</strong></p>
<p><em>- Michael Snoyman, totally 100% what he actually believes, you should totally quote this out of context</em></p>
</blockquote>
<p>I’ve said this so many times. So I’ll say it again. Using a great language with safety features is one tiny piece of the puzzle.</p>
<ul>
<li>Did you get the software requirements right?</li>
<li>Did you leverage the type system to prevent the bugs you’re trying to prevent?</li>
<li>Do your underlying libraries have bugs?</li>
<li>Did you find a way to implement a function with correct types but incorrect semantics?</li>
<li>Did you host the thing on a dinky server sitting under your desk and forget that you have power outages on a daily basis?</li>
<li>Did you forget to write a single test case?</li>
<li>Do your test cases actually test anything meaningful?</li>
</ul>
<p>There are <em>so many ways</em> for software to fail outside the purview of the type system. We’ve got to stop thinking that somehow Haskell (or, for that matter, Rust, Scala, and other strongly typed languages) are some kind of panacea. Seriously: the PHP people at least know their languages won’t protect them from anything. We should bring some of that humility back to Haskell.</p>
<p>Haskell provides me tools to help prevent certain classes of bugs, so I can spend more of my time catching a bunch of other bugs that I’m absolutely going to write. Because I’m dumb. And we need to remember: we’re all dumb.</p>
<h2>More partial functions!</h2>
<p>You know what’s worse than partial functions? Insidiously partial functions. We’ve all been screaming about <code>head</code> and <code>tail</code> for years. My hackles rise every time I see a <code>read</code> instead of <code>readMaybe</code>. I can’t remember the last time I saw the <code>!!</code> operator in production code.</p>
<p>But there are plenty of other functions that are just as dangerous, if not more so. More dangerous because they aren’t well known to be partial. They are commonly used. People don’t understand why they’re dangerous. And they fail only in edge cases that people aren’t thinking about.</p>
<p>Exhibit A: I present <code>decodeUtf8</code>. (Thanks <a href="https://twitter.com/kerckhove_ts/status/1321390954172063745?s=20">Syd</a>.)</p>
<p>Go ahead, search your codebase. Be dismayed that you’ve found it present.</p>
<p>What’s wrong with <code>decodeUtf8</code>? As we established last time, character encoding crap breaks stuff in production. UTF-8 works about 99% of the time, especially for people in Western countries. You’ll probably forget to even test for it. And that function looks so benign: <code>decodeUtf8 :: ByteString -&gt; Text</code>.</p>
<p><strong>DO NOT BE FOOLED</strong></p>
<p>This function is a ticking time bomb. Use <code>decodeUtf8'</code> (yes, it’s named that badly, just like <code>foldl'</code>) and explicitly handle error cases. Or use I/O functions that explicitly handle UTF-8 decoding errors and throw a runtime exception.</p>
<p>“I can’t believe Michael still thinks runtime exceptions are a good idea.” I’ll get to that another time. I don’t really believe they’re a good idea. I believe they are omnipresent, better than bottom values, and our least-bad-option.</p>
<h2>Law-abiding type classes</h2>
<p>Now I’ve truly lost it. What in tarnation could be wrong with law-abiding type classes? They’re good, right? Yes, they are! The section heading is complete clickbait. Haha, fooled you!</p>
<p>There’s a concept in the Haskell community that all type classes should be law-abiding. I’ve gone to the really bad extreme opposing this in the past with early versions of <code>classy-prelude</code>. In my defense: it was an experiment. But it was a bad idea. I’ve mostly come around to the idea of type classes being lawful. (Also, the original namespacing issues that led to <code>classy-prelude</code> really point out a much bigger bad part of Haskell, which I’ll get to later. Stay tuned! Hint: Rust beat us again.)</p>
<p>Oh, right. Speaking of Rust: they do <em>not</em> believe in law-abiding type classes. There are plenty of type classes over there (though they call them <code>trait</code>s) that are completely ad-hoc. I’m looking at you, <code>FromIterator</code>. This is Very, Very Bad of course. Or so my Haskell instincts tell me. And yet, it makes code Really, Really Good. So now I’m just confused.</p>
<p>Basically: I think we need much more nuanced on this in the Haskell community. I’m leaning towards my <em>very</em> original instincts having been spot on. So:</p>
<ul>
<li>Law abiding type classes: great</li>
<li>Flippantly non-law-abiding type classes ala the original <code>classy-prelude</code>: bad</li>
<li>“You know what I meant” typeclasses like <code>ToContent</code> in Yesod: also great</li>
</ul>
<p>This isn’t exactly in line with a “bad part” of Haskell. Up until now I’ve been giving a nuanced reflection on my journeys in Haskell. Let me try something better then. Ahem.</p>
<p><strong>DON’T LECTURE ME ON LAW ABIDING TYPE CLASSES AND FLAGRANTLY VIOLATE LAWS</strong></p>
<p>I’m staring at you, <code>Eq Double</code>. No, you cannot do equality on a <code>Double</code>. (And thanks again to Syd for this idea.) Rust, again, Got It Right. See <code>PartialEq</code> vs <code>Eq</code>. Floating point values do not allow for total equality. This makes things like <code>Map Double x</code> dangerous. Like, super dangerous. Though maybe not as dangerous as <code>HashMap Double x</code>, which deserves its own rant later.</p>
<p>So come down from your high horses. We don’t have law abiding type classes. We have “if I close my eyes and pretend enough then maybe I have law abiding type classes.”</p>
<h2>Unused import warnings</h2>
<p>Haskell has a dumb set of default warnings enabled. (“I think you mean GHC, one implementation of Haskell, not Haskell the language itself.” Uh-huh.) How can we <em>not</em> generate a warning for a partial pattern match? Come on! ADTs and pattern matching is <em>the</em> killer feature to first expose people to. And it’s a total lie: the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2">https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2</a></em></p>]]>
            </description>
            <link>https://www.snoyman.com/blog/2020/11/haskell-bad-parts-2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039758</guid>
            <pubDate>Mon, 09 Nov 2020 20:54:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Statusly - Automate slack DND when you join a zoom meeting/gCal event]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25039692">thread link</a>) | @statusly
<br/>
November 9, 2020 | https://www.statusly.app/why-statusly?ref=hn | <a href="https://web.archive.org/web/*/https://www.statusly.app/why-statusly?ref=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.statusly.app/why-statusly?ref=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039692</guid>
            <pubDate>Mon, 09 Nov 2020 20:48:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmark Godot with Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25039494">thread link</a>) | @todsacerdoti
<br/>
November 9, 2020 | https://blog.extrawurst.org/general/gamedev/rust/2020/11/07/godot-rust-benchmark.html | <a href="https://web.archive.org/web/*/https://blog.extrawurst.org/general/gamedev/rust/2020/11/07/godot-rust-benchmark.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I recently started looking into using Rust and the <a href="https://godotengine.org/">Godot</a> Game Engine for developing games. A very quick experiment recently was to compare performance of GDScript, Visual scripting and Rust for the same task.</p>



<p>It is simple: Let us just draw a ton of lines to have a lot of traffic between our code and the engine:</p>

<p><img src="http://extrawurst.github.io/assets/godot-rust-benchmark/result.png" alt="res"></p>

<p>In fact it is so many lines that we end up with a filled circle. Nothing beautiful, this is just a benchmark afterall 👌</p>



<p>Let us look at the contenders:</p>
<ul>
  <li>gdscript</li>
  <li>visual script</li>
  <li>gdnative (rust)</li>
</ul>

<p><strong>GDScript</strong> is the official scripting language shipping with Godot.</p>

<p><strong>Visual Script</strong> is the official node based way to visually script in Godot (think Unreal Blueprint or Unity Bolt)</p>

<p><strong>GDNative</strong> is the official C-Api to access Godot from escentially any language. We are using <a href="https://github.com/godot-rust/godot-rust">Godot-Rust</a> to be able to compile shared libraries from Rust code to interface with Godot.</p>

<hr>

<p>The entire test with all three options can be found on github: <a href="https://github.com/extrawurst/godot-rust-benchmark">extrawurst/godot-rust-benchmark</a></p>

<p>Rerun it for yourself :)</p>

<h2 id="gdscript">GDScript</h2>

<p>Let’s start with the official way of doing things in Godot - using GDScript:</p>

<div><div><pre><code><span>extends</span> <span>CanvasItem</span>

<span># how many lines to draw? (this can be adjusted from the editor UI)</span>
<span>export</span> <span>var</span> <span>cnt</span> <span>=</span> <span>6000</span>
<span># this is the center point</span>
<span>export</span> <span>var</span> <span>start</span> <span>=</span> <span>Vector2</span><span>(</span><span>250</span><span>,</span><span>250</span><span>)</span>
<span># radius (line length)</span>
<span>export</span> <span>var</span> <span>rad</span> <span>=</span> <span>200</span>

<span>func</span> <span>_draw</span><span>():</span>
	<span># lets measure the runtime</span>
	<span>var</span> <span>startTime</span> <span>=</span> <span>OS</span><span>.</span><span>get_ticks_usec</span><span>()</span>

	<span>var</span> <span>cntf</span> <span>=</span> <span>float</span><span>(</span><span>cnt</span><span>)</span>
	<span>for</span> <span>n</span> <span>in</span> <span>range</span><span>(</span><span>cnt</span><span>):</span>
		<span>var</span> <span>x</span> <span>=</span> <span>sin</span><span>(</span><span>n</span><span>/</span><span>cntf</span> <span>*</span> <span>360.0</span><span>)</span><span>*</span><span>rad</span>
		<span>var</span> <span>y</span> <span>=</span> <span>cos</span><span>(</span><span>n</span><span>/</span><span>cntf</span> <span>*</span> <span>360.0</span><span>)</span><span>*</span><span>rad</span>
		<span>draw_line</span><span>(</span>
			<span>start</span><span>,</span> 
			<span>start</span><span>+</span><span>Vector2</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>),</span> 
			<span>Color</span><span>(</span><span>255</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>),</span> 
			<span>1</span><span>,</span>
			<span>false</span><span>)</span>
	
	<span>print</span><span>(</span><span>"bench: "</span> <span>+</span> <span>String</span><span>(</span><span>OS</span><span>.</span><span>get_ticks_usec</span><span>()</span> <span>-</span> <span>startTime</span><span>))</span>

<span>func</span> <span>_process</span><span>(</span><span>_delta</span><span>):</span>
	<span>update</span><span>()</span>
</code></pre></div></div>

<h2 id="visual-script">Visual Script</h2>

<p>The following screenshot shows the same logic in a visual node based way:</p>

<p><img src="http://extrawurst.github.io/assets/godot-rust-benchmark/visualscript.png" alt="vs"></p>

<p>We immediately see how this is more verbose but at least it is possible and it even just crashed once on me 🙈</p>

<h2 id="gdnative-rust">GDNative (Rust)</h2>

<p>We are using <a href="https://github.com/godot-rust/godot-rust">Godot-Rust</a> for this.</p>

<div><div><pre><code><span>#[export]</span>
<span>fn</span> <span>_</span><span>draw</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>owner</span><span>:</span> <span>&amp;</span><span>CanvasItem</span><span>)</span> <span>{</span>
	<span>let</span> <span>start_time</span> <span>=</span> <span>OS</span><span>::</span><span>godot_singleton</span><span>()</span><span>.get_ticks_usec</span><span>();</span>

	<span>let</span> <span>cntf</span> <span>=</span> <span>self</span><span>.cnt</span> <span>as</span> <span>f32</span><span>;</span>

	<span>for</span> <span>n</span> <span>in</span> <span>0</span><span>..</span><span>self</span><span>.cnt</span> <span>{</span>
		<span>let</span> <span>x</span> <span>=</span> <span>f32</span><span>::</span><span>sin</span><span>(</span><span>n</span> <span>as</span> <span>f32</span> <span>/</span> <span>cntf</span> <span>*</span> <span>360.0</span><span>)</span> <span>*</span> <span>self</span><span>.rad</span><span>;</span>
		<span>let</span> <span>y</span> <span>=</span> <span>f32</span><span>::</span><span>cos</span><span>(</span><span>n</span> <span>as</span> <span>f32</span> <span>/</span> <span>cntf</span> <span>*</span> <span>360.0</span><span>)</span> <span>*</span> <span>self</span><span>.rad</span><span>;</span>
		<span>let</span> <span>target</span> <span>=</span> <span>Vector2</span><span>::</span><span>new</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span> <span>+</span> <span>self</span><span>.start</span><span>;</span>

		<span>owner</span><span>.draw_line</span><span>(</span>
			<span>self</span><span>.start</span><span>,</span> 
			<span>target</span><span>,</span> 
			<span>Color</span><span>::</span><span>rgb</span><span>(</span><span>0.0</span><span>,</span> <span>0.0</span><span>,</span> <span>1.0</span><span>),</span> 
			<span>1.0</span><span>,</span> 
			<span>false</span><span>)</span>
	<span>}</span>

	<span>godot_print!</span><span>(</span>
		<span>"bench: {}"</span><span>,</span>
		<span>OS</span><span>::</span><span>godot_singleton</span><span>()</span><span>.get_ticks_usec</span><span>()</span> <span>-</span> <span>start_time</span>
	<span>);</span>
<span>}</span>
</code></pre></div></div>



<p>I am not going to further comment on the ergonomics of either language. I really did this for two reasons: 1) can we do all we need in the visual script and 2) how does performance compare between the alternatives</p>

<p>Here are the timings:</p>

<table>
  <thead>
    <tr>
      <th>type</th>
      <th>usecs</th>
      <th>slowdown</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>gdnative (rust)</td>
      <td>~980 usec</td>
      <td>-</td>
    </tr>
    <tr>
      <td>gdscript</td>
      <td>~5112 usec</td>
      <td>5x</td>
    </tr>
    <tr>
      <td>visual script</td>
      <td>~7099 usec</td>
      <td>7x</td>
    </tr>
  </tbody>
</table>

<p><sub><sup>(executed on a macbook 2016 3,3 GHz i7, 16 GB Ram, Intel Iris 550 and Godot 3.2.3, avg. over 10 runs)</sup></sub></p>

<p>On twitter people noted that this might change with Godot 4.0 and the support of type checking in gdscript. This could be interesting to measure once 4.0 is released.</p>

<p>For now my conclusion is:</p>

<ul>
  <li>GDScript is easy and quick to learn</li>
  <li>Visual Scripting in Godot works although it feels a little instable</li>
  <li>Godot-Rust is a clear alternative to write entire Godot games in</li>
</ul>

<p>Of course point 3) is limited to people coming with a Rust background otherwise the Rust part in it is a clear challenge to learn first.</p>

      </div></div>]]>
            </description>
            <link>https://blog.extrawurst.org/general/gamedev/rust/2020/11/07/godot-rust-benchmark.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039494</guid>
            <pubDate>Mon, 09 Nov 2020 20:29:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The election of the doge]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25039470">thread link</a>) | @flannery
<br/>
November 9, 2020 | https://generalist.academy/2020/11/06/the-election-of-the-doge/ | <a href="https://web.archive.org/web/*/https://generalist.academy/2020/11/06/the-election-of-the-doge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4574">
	
		<p>
By  on <a href="https://generalist.academy/2020/11/06/the-election-of-the-doge/" title="7:00 am" rel="bookmark"><time datetime="2020-11-06T07:00:00+13:00">November 6, 2020</time></a>	• 
	</p>
	<section>

<p>The ruler of Medieval Venice was chosen by an exceptionally complex ten-step process of alternating random lots and elections.</p>



<div><figure><img loading="lazy" data-attachment-id="4580" data-permalink="https://generalist.academy/kms3898/" data-orig-file="https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg" data-orig-size="2043,1200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;Statens Museum for Kunst&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Canaletto (1697-1768), Dogen og det store raad forsamlede i Sala del consiglio maggior i Dogepaladset, About 1763&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;Public Domain (CC0)&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;kms3898&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="kms3898" data-image-description="" data-medium-file="https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=300" data-large-file="https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=656" src="https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=1024" alt="Grand Council" width="768" height="451" srcset="https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=1024 1024w, https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=768 768w, https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=1536 1536w, https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=150 150w, https://thegeneralistacademy.files.wordpress.com/2020/11/grandcouncil.jpg?w=300 300w" sizes="(max-width: 768px) 100vw, 768px"><figcaption><a href="https://commons.wikimedia.org/wiki/File:Canaletto_-_The_Doge_and_Grand_Council_in_Sala_del_Maggior_Consiglio_-_KMS3898_-_Statens_Museum_for_Kunst.jpg">Canaletto</a>, Public domain, via Wikimedia Commons</figcaption></figure></div>



<p>A few weeks ago I wrote about modern <a href="https://generalist.academy/2020/10/17/electoral-fairness/">democratic electoral systems</a>, and a couple of days ago I wrote about the complexities of the <a href="https://generalist.academy/2020/11/04/the-unpopular-president/">American Electoral College</a>. Today I wanted to go even further back, to the Medieval Venetian Republic. There, the selection of a new leader – the doge – was one of the more complex and baffling electoral processes in history. And even so, though this be madness, yet there is method in’t.</p>



<p>The Great Council of Venice was a large legislative body made up of a relatively small number of noble families. Obviously, everyone wanted to be the doge, but the council was very keen to avoid behind-the-scenes bribery, dirty deals, intrigue, and extended and contentious campaigns. To achieve this, the election of the doge went through multiple steps, all designed to reduce power consolidation.</p>



<p>First, thirty members of the Great Council were chosen at random. Then nine of those thirty were chosen, again randomly. Those nine members picked the next set: forty people from the Great Council. And those forty? Twelve, randomly picked from their number, moved on to the next step. Those twelve chose twenty-five; those twenty-five were randomly pared down to just nine. Having fun yet?</p>



<p>This set of nine members chose forty-five more; eleven were picked – again at random – from those forty-five. The eleven chose forty-one members. Those forty-one (finally!) voted for the doge. </p>



<p>There were some additional checks against skulduggery. Each noble family couldn’t have more than one member in each group, and members couldn’t vote for their own relatives. Every time a set of members voted for the next group, more than a simple majority was required: around three quarters of the voting group had to agree. (For the final election, just 25 of the 41 had to agree.)</p>



<p>To recap, this is the process:<br>Great Council &gt; 30 &gt; 9 &lt; 40 &gt; 12 &lt; 25 &gt; 9 &lt; 45 &gt; 11 &lt; 41 &gt; 1.</p>



<p>Because of this complexity, the chances of rigging or buying the election were greatly reduced, minority concerns were not buried by the majority, but neither was the majority tyrannized by the minority. Today we only use this kind of random process in jury selection and citizen’s assemblies.</p>



<p>[Thanks to Alistair S. for suggesting this topic.]</p>



<ul><li><a href="https://en.wikipedia.org/wiki/Doge_of_Venice">Doge of Venice</a></li><li><a href="https://en.wikipedia.org/wiki/Sortition">Sortition</a></li><li><a href="https://doi.org/10.1007/s10602-019-09290-6">How the Republic of Venice chose its doge: Lot-based elections and supermajority rule</a></li></ul>
		<p>Categories: <a href="https://generalist.academy/category/places/europe/" rel="category tag">Europe</a> <a href="https://generalist.academy/category/history/" rel="category tag">History</a> <a href="https://generalist.academy/category/history/medieval-history/" rel="category tag">Medieval history</a> <a href="https://generalist.academy/category/places/" rel="category tag">Places</a> <a href="https://generalist.academy/category/politics-law/" rel="category tag">Politics &amp; law</a>		</p>
	<div>
		<p><img alt="" src="https://0.gravatar.com/avatar/f7eb82f9df252be8cad1a3993809331d?s=100&amp;d=https%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D100&amp;r=G" height="100" width="100"></p><h3>The Generalist</h3>
		<p>I live in Auckland, New Zealand, and am curious about most things.</p>
	</div>
	</section>
</article></div>]]>
            </description>
            <link>https://generalist.academy/2020/11/06/the-election-of-the-doge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039470</guid>
            <pubDate>Mon, 09 Nov 2020 20:27:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Canada Is 2nd Place]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25039402">thread link</a>) | @Kortaggio
<br/>
November 9, 2020 | https://billmei.net/blog/canada | <a href="https://web.archive.org/web/*/https://billmei.net/blog/canada">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      
      
        <p><img src="https://d33wubrfki0l68.cloudfront.net/6f6580be6496271f0228cb98a1db81f2e403a0c5/df9b6/assets/blog/img/canada--main.jpg" alt="Canada is second place"></p>
      
      <p>We’ll always be in the shadow of our neighbour, the United States; but that’s okay, because mediocrity is what makes Canada awesome.</p>

<p>Our healthcare is worse than the UK’s. TIFF is not as prestigious as the Golden Globes. We are the Shopify to your Amazon, the BlackBerry to your Apple. The landmass spans three oceans and yet still is only the second largest. We have less oil than Texas. Vancouver real estate is not as expensive as San Francisco. The most talented people in the world apply to immigrate here, after they were rejected by the USA.</p>

<p>Canadians don’t desire to be the first, the best, or the greatest. We’re pretty okay with being number two. We’re so unremarkable that we rarely make international news, and that’s fine because most Canadians don’t want that spotlight anyway.</p>

<p>Canadian history is a list of things we helped French and British people accomplish.</p>

<p>Our winter doesn’t stop Napoleons, it just stops your car batteries in the morning.</p>

<p><a href="https://medium.com/conversations-with-tyler/tyler-cowen-margaret-atwood-writer-author-poetry-handmaids-tale-b3ddd258cf81" target="_blank" rel="noopener">Canada is really big</a>. So you can’t make generic statements that apply to all Canadians. You are guaranteed to find someone whose experience contradicts what I’ve written here. Perhaps the only thing that unites Canadians is we tell ourselves at least we’re not American. Canada doesn’t have a strong national identity, or a unique marketing angle.</p>

<p>Canada is the generic store brand of countries.</p>

<p>In an era where technology <a href="http://www.paulgraham.com/re.html" target="_blank" rel="noopener">pulls apart</a> the <a href="https://billmei.net/books/average-is-over/">tails</a>, Canada remains refreshingly average. The best part of a country is also its <a href="https://markmanson.net/5-life-lessons-5-years-traveling-world" target="_blank" rel="noopener">worst part</a>, and the worst part about Canada is that it has no best part.</p>

<p>The lack of any single dominating force is what makes Canada so amazingly diverse. You can just be you, and don’t need to conform to a peer group, because everyone around you doesn’t work for just one industry, or likes just one type of media, or participates in just one cultural bubble. It’s a place where I feel safe to be mediocre; I don’t feel like a failure for not curing cancer or inventing AI or doing rocket science.</p>

<p>No matter how much I like to believe, the truth is that I’ll probably live a normal, unremarkable life that people will forget about once I’m gone. Canada accepts your inherent worth as a person, and doesn’t demand that you achieve, consume, or do something special to deserve your dignity. Canada is a wonderful place to live despite being second place and this reminds you that it’s fine not to be first place. You are valuable because you are you.</p>

<p>Canada is mediocre, and so am I. That’s why I love you, Canada. 🇨🇦</p>

<p><em>I only publish half of my writing publicly. The rest are posted exclusively on my private email list: <a href="https://billmei.net/email">billmei.net/email</a> (Subscribing is free, no spam ever, and you can safely unsubscribe anytime)</em></p>

      <small>
  
  <span>Image credit: Jp Valery</span>
  
  <time datetime="2020-09-28T00:00:00+00:00">Published September 2020</time>
</small>

    </article></div>]]>
            </description>
            <link>https://billmei.net/blog/canada</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039402</guid>
            <pubDate>Mon, 09 Nov 2020 20:20:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye USA]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25039397">thread link</a>) | @polote
<br/>
November 9, 2020 | https://larrysalibra.com/goodbye-usa/ | <a href="https://web.archive.org/web/*/https://larrysalibra.com/goodbye-usa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://larrysalibra.com/content/images/size/w300/2020/11/IMG_1166.jpeg 300w,
                            https://larrysalibra.com/content/images/size/w600/2020/11/IMG_1166.jpeg 600w,
                            https://larrysalibra.com/content/images/size/w1000/2020/11/IMG_1166.jpeg 1000w,
                            https://larrysalibra.com/content/images/size/w2000/2020/11/IMG_1166.jpeg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://larrysalibra.com/content/images/size/w2000/2020/11/IMG_1166.jpeg" alt="Goodbye USA">
</figure>
<section>
<div>
<p>A few weeks ago, when I was trying to open an account at a financial institution here in Hong Kong, someone noticed I was born in the USA and my account was denied.</p><p>They wrote “I regret to inform you at this time we are unable to accept bank wire deposits/withdrawals from US citizens. For more information, please refer to our article: Restricted nationalities and countries.” While this is a common experience for Americans living abroad, one I’ve experienced many times before, it was a mistake, a mistake that reminded me to write this blog post.</p><p>A few days ago, I received a rather passive-aggressive email from one of my banks asking me to “let us know about your tax connection to the United States” with the threat of closing my account if I don’t. Another common experience for Americans living abroad, another mistake and another reminder to write this post.</p><figure><img src="https://larrysalibra.com/content/images/2020/11/Screen-Shot-2020-10-22-at-5.52.02-PM.png" alt=""></figure><p>Tomorrow, Americans will vote to choose one of two candidates no one really likes. I’m not allowed to vote this time around because two years ago, I finally rid myself of the burden that is American citizenship.</p><h2 id="a-hard-story-to-tell">A hard story to tell</h2><p>I’ve tried to write this blog post a number of times over the past two years. I’ve written entire drafts of this post from scratch more than once and never published them, unhappy with the tone or the content or the narrative or worried about the reaction of people I’ve never met on the internet. Perhaps it was the years of brainwashing…I mean, “<a href="https://en.wikipedia.org/wiki/Civic_education_in_the_United_States">civic education</a>”…in US public schools that has scared my psyche and made me afraid of what the tribe will do when it finds out I’ve deserted them. Having to say the "Pledge of Allegiance" every day during one's childhood before he knows what the words "pledge" or "allegiance" even mean really does a job on one's mind.</p><p>I want to tell my story because I hope that it will benefit others on their journey towards personal freedom just the stories of others benefited me.</p><p>Our story starts about a year ago, in October 2019.</p><p>It's 2am on a Saturday morning in Hong Kong and I can't sleep. My body thinks it's still in Paris after two weeks in Europe. One year ago today, I also couldn't sleep but for a different reason. I was tossing and turning from stress the night before what I thought was going to be the biggest decision of my life: to give up US citizenship.</p><p>After over 11 years living outside of the USA, I had made an appointment on October 12, 2018, at the US Consulate in Hong Kong to go through the process known as "expatriation" or "renouncing US citizenship."</p><p>This was the second appointment in the process. The first had been a few weeks prior, on August 31, 2018. You see, the United States wants you to believe that giving up US citizenship is a Big Deal, and in many ways it is! You lose a whole bunch of rights granted by citizenship such as no longer being able live or work in the country unless you get a visa. In this day and age of passports, visas and borders, (<a href="https://www.nationalgeographic.com/travel/features/a-history-of-the-passport/">it didn't used to be like this</a>! travel used to be free as in freedom!) if you didn't have another citizenship, you could become "stateless" with nowhere to go and no way to get past borders to get there. To someone like me who was born and raised in suburban Ohio, this felt like a Big Deal.</p><p>What they don’t tell you, is that you’re also freed from a number of coercive obligations you never agreed to that other countries don’t impose on their citizens by opting-out of US citizenship. They tell you it's all pain with no gain.</p><p>To drive home the Big Dealness of the decision, the State Department made me make two appointments at the consulate to make sure I got their point. And I had to make the appointments well in advance as they were fully booked for months. I wasn’t the only American in Hong Kong trying to exit.</p><p>At the first appointment, a nice vice consul named Rachel took me in to a tiny interview room complete with an American flag in the nondescript Garden Road compound. Our interview began with Rachel hitting her head on the phone on the wall quite hard as she was sitting down and me asking her with a bit of a shock, “OMG, are you okay?!?!" After a minute or so of rubbing her head and grimacing, she was fine and we started with our interview.</p><p>She roughly followed a script that is specified in the <a href="https://fam.state.gov/fam/07fam/07fam1260.html">US State Department's Foreign Affairs Manual</a>. She asked me questions about myself and my decision. Where was I from? (Ohio) How long have I lived abroad? (Since May, 2007) Where does my family live? (My parents live in the US and my brother lives in Bulgaria). Did I have another citizenship and passport? (Yes, Italian) Why did I want to give up US citizenship? (It's complicated, but I didn't feel American anymore and when visiting the US anymore I felt like a tourist).</p><p>After the questions she started reading me a list of what came off as warnings and disclaimers to make sure I knew what I was getting myself into:</p><ul><li>Any children I had wouldn't become US citizens</li><li>Might not be able to travel to the US again</li><li>Wouldn't be able to live or work in the US an appropriate visa</li><li>I would still have to file for and pay taxes that I owe</li><li>If I didn't have another citizenship I could be come stateless</li></ul><p>She then instructed me to take a couple of weeks for a "period of reflection" (this is required according to State Department regulations) and handed me a packet of papers to review listing the consequences giving up my blue passport and outlining the tax implications.</p><p>Where better to go to reflect and get some clarity on my decision to exit the US than to visit a country struggling with its own exit decision, the United Kingdom? So I headed off to the UK for a short vacation followed by a work trip in London.</p><p>By the time I made my first August appointment, I'd already made the decision - I'd been thinking about it for years and had done a ton of research and due diligence. I'd read a lot about other people's experiences and thinking. I was particularly inspired by bitcoin investor Roger Ver's story and Balajis Srinivasan's talk on <a href="https://www.youtube.com/watch?v=cOubCHLXT6A">Voice vs Exit</a>.</p><p>I was most concerned about losing the right to live and work in the US - it seems so many people want this right and that they're willing to go through great pain and inconvenience to get it. However, I hadn't ever used this right in the almost 20 years of my adult life. I’d always competed on the global market without the benefit of “work authorization” protecting me from competition of “aliens.” As life long entrepreneur and a strong advocate of remote work, I didn't ever see myself wanting to sign up for some office job in the States. But would I want to live there?</p><h2 id="a-tourist-in-my-own-country">A tourist in my own country</h2><p>In 2016, I flew to California and rented a car to do some due diligence on the country I was thinking of leaving. I spent a month driving across the US and back, taking in the sites and visiting places I thought I might like to live. The natural beauty of America and her parks is breathtaking. While it is amazing to visit and even vacation for a few weeks, it wasn’t someplace I'd want to live. New York and Chicago were my favorite cities, but cold climate and snow is a turn off as is the crumbling infrastructure and confiscatory tax rates.</p><p>A number of tech friends moved to Austin for the low tax and warm weather, so I stopped there for a few days. After over a decade in Asia, Austin hardly seems big enough to even be called a city. My impression was that it is a bunch of suburban sprawl with some bigger buildings in the middle. And I much prefer being on islands surrounded by water instead of landlocked.</p><figure><img src="https://larrysalibra.com/content/images/2020/11/IMG_5406.jpeg" alt=""></figure><p>In June of 2018, I took a vacation to America’s only state that is “a bunch of islands surrounded by water,” Hawaii. I had found memories of visiting the Aloha state as a child and wanted to make sure that I wasn't missing out on some future destiny where Larry becomes a Hawaiian like George Clooney in <em>The Descendants</em>. The nature was nice, but the poverty, crime and remoteness from everywhere made it not very attractive as a future home.</p><p>I'd discussed the decision with family and friends. Friends ranged from very unhappy to mildly supportive to downright enthusiastic. My brother, also an entrepreneur who has lived outside of the States for more than a decade, was understanding of the challenges the USA imposes on its entrepreneurs abroad and very supportive. My parents were skeptical that it was the right decision. They'd lived their whole lives in the USA and grown up on stories of World War II valor and of their grandparents who had struggled to immigrate to the United States for a better life. They shared their views with me but never gave me any pressure and let me make my own decision.</p><h2 id="the-oath">The oath</h2><p>October 12, 2018, my second appointment in the renunciation process, quickly arrived. I couldn’t really sleep the night before. I was nervous about both the appointment and a <a href="https://blog.blockstack.org/a-path-to-decentralization/">big work announcement</a>. Lots of things were changing.</p><p>In the morning, I woke up and took a taxi to the US consulate for my appointment. Here’s a picture of me before the appointment. You can see the stress in my face.</p><figure><img src="https://larrysalibra.com/content/images/2020/11/IMG_8562.jpeg" alt=""></figure><p>After entering the consulate and going through security, the first step of the appointment was paying the fee: US$2,350. You can’t free yourself from the Land of the Free without having the cash money to buy your freedom. Think of the renunciation fee as an emancipation fee, a lot of money, but a small price to pay for freedom.</p><figure><img src="https://larrysalibra.com/content/images/2020/11/https---blogs-images.forbes.com-robertwood.jpg" alt=""></figure><p>The actual renunciation ceremony was sort of an out-of-body blur. I felt like I was watching myself in the little room with the American flag renouncing my allegiance (which of course the US education system forces children who don’t know what the word “allegiance” means to “pledge”) to the USA.</p><p>The consular official told me that they would take my US passport and hold on to it until the State Department approved my renunciation and return it to me canceled along with my Certificate of Loss of Nationality (CLN) at some later date. He advised that if I needed to travel to the US I might be able to borrow the passport for a trip if the …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://larrysalibra.com/goodbye-usa/">https://larrysalibra.com/goodbye-usa/</a></em></p>]]>
            </description>
            <link>https://larrysalibra.com/goodbye-usa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039397</guid>
            <pubDate>Mon, 09 Nov 2020 20:19:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Recalculate a Spreadsheet]]>
            </title>
            <description>
<![CDATA[
Score 289 | Comments 72 (<a href="https://news.ycombinator.com/item?id=25039393">thread link</a>) | @todsacerdoti
<br/>
November 9, 2020 | https://lord.io/blog/2020/spreadsheets/ | <a href="https://web.archive.org/web/*/https://lord.io/blog/2020/spreadsheets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Let’s say I’m ordering burritos for my two friends while they quar up in Jersey City, and want to calculate the total price of my order:</p>
<p><img alt="screenshot of spreadsheet; burrito price is listed as $7, burrito price w ship as burrito price plus $3, num burritos is 2, and total is num burritos times burrito price w ship, for a total of $20" src="https://lord.io/images/2020/anchors_0.png"></p>
<p>It’s a little confusing to follow the flow of data in a spreadsheet when it’s written like that, so I hope you don’t mind this equivalent diagram that represents it as a graph:</p>
<p><img alt="the previous spreadsheet represented as a graph, with arrows from one cell to another replacing the spreadsheet cell references" src="https://lord.io/images/2020/anchors_1.png"></p>
<p>We’re rounding the cost of an El Farolito super vegi burrito to $8, so assuming the per-burrito delivery toll remains at just $2 per burrito, it looks like the total for our two burritos will be $20.</p>
<p>Oh no, I completely forgot! One of my friends loves to wolf down multiple burritos at a time, so I actually want to place an order for three burritos. If I update <code>Num Burritos</code>, a naïve spreadsheet engine might recompute the entire document, recalculating first the cells with no inputs, and then recalculating any cell whose inputs are ready until we’ve finished every cell. In this case, we’d first calculate <code>Burrito Price</code> and <code>Num Burritos</code>, then <code>Burrito Price w Ship</code>, and then a new final <code>Total</code> of $30.</p>
<p><img alt="same as previous graph, but num burritos is updated to 3, and every cell is tagged as &quot;recalc&quot;" src="https://lord.io/images/2020/anchors_2.png"></p>
<p>This simple strategy of recalculating the whole document may sound wasteful, but it’s actually already <em>better</em> than VisiCalc, the first spreadsheet software ever made, and the first so-called “killer app”, responsible for popularizing the Apple II. VisiCalc would repeatedly recalculate cells from left-to-right and top-to-bottom, sweeping over them again and again until none of them changed. Despite this “interesting” algorithm, VisiCalc remained the dominant spreadsheet software for four years. Its reign ended in 1983, when Lotus 1-2-3 swept the market with “natural-order recalculation”, <a href="https://aresluna.org/attached/computerhistory/articles/spreadsheets/tenyearsofrowsandcolumns">as described by Tracy Robnett Licklider in Byte Magazine</a>:</p>
<blockquote>
<p>Lotus 1-2-3 exploited natural-order recalculation, although it also supported VisiCalc’s row- and column-order modes. Natural-order recalculation maintained a cell dependency list and recalculated a cell before recalculating cells that depended on it.</p>
</blockquote>
<p>Lotus 1-2-3 implemented the “recalculate everything” strategy we’ve shown above, and for the first decade of spreadsheets, that was as good as it got. Yes, we recalculate every cell in the document, but at least we only recalculate every cell once.</p>
<h2>but what about “burrito price w ship”</h2>
<p>Great point, header 2. In my three burrito example there’s no reason to recompute <code>Burrito Price w Ship</code>, because changing the number of burritos we order can’t possibly influence the per-burrito price. In 1989, one of Lotus’ competitors realized this, and created SuperCalc5, presumably naming it after the theory of super burritos at the core of this algorithm. SuperCalc5 recalculated “only cells dependent on changed cells”, which would make updating the burrito count look more like this:</p>
<p><img alt="same as prior graph, with burrito count updated from 2 to 3, but now only the two affected cells &quot;num burritos&quot; and &quot;total&quot; are tagged as recalc" src="https://lord.io/images/2020/anchors_3.png"></p>
<p>By only updating a cell when one of its inputs changes, we can avoid recalculating <code>Burrito Price w Ship</code>. In this case, it saves just a single addition, but on larger spreadsheets it can save quite a bit of time! Unfortunately, we now have another problem. Let’s say my friends now want meat burritos, which cost a dollar more, and simultaneously El Farolito adds a $2 fee paid per-order, regardless of how many burritos you order. Before any formula outputs are recalculated, our graph might look like this:</p>
<p><img alt="same as prior graph (after burrito count update finished calculation), but now burrito price is being updated from $8 to $9, and simultaneously total is updated from &quot;burrito price w ship * num burritos&quot; to &quot;burrito price w ship * num burritos + $2 fee&quot;" src="https://lord.io/images/2020/anchors_4.png"></p>
<p>Since there are two updated cells here, we have a problem. Should we recalculate <code>Burrito Price</code> first, or <code>Total</code>? Ideally, we first calculate <code>Burrito Price</code>, notice that its output has changed, then recalculate <code>Burrito Price w Ship</code>, and finally recalculate <code>Total</code>. However, if we instead recalculate <code>Total</code> first, we’ll have to recalculate it a second time once the new $9 burrito price propagates down. If we don’t calculate cells in the right order, this algorithm isn’t better than recalculating the whole document. In some cases, it’s as slow as VisiCalc!</p>
<p>Clearly, it’s important for us to figure out the right order to update our cells. Broadly, there are two solutions to this problem: dirty marking and topological sorting.</p>
<p>This first solution involves marking all cells downstream from an edit as dirty. For instance, when we update <code>Burrito Price</code>, we would mark the downstream cells <code>Burrito Price w Ship</code> and <code>Total</code> as dirty, even before doing any recalculations:</p>
<p><img alt="same as prior graph with the two updates, but now three nodes are tagged as dirty: &quot;burrito price&quot;, &quot;burrito price w ship&quot;, and &quot;total&quot;. would also like to apologize for the rather confusing image alt text so far; it's really hard to write these for graph diagrams!! if you are a screen reader user and have advice on better ways to do this, would love to hear from you." src="https://lord.io/images/2020/anchors_5.png"></p>
<p>Then, in a loop, we find a dirty cell that has no dirty inputs, and recalculate it. When there are no dirty cells left, we’re done! This solves our ordering problem. There’s one downside though — if a cell is recalculated and we find its new output to be the same as its previous output, we’ll still recalculate downstream cells! A little bit of extra logic can avoid actually running the formula trouble in this case, but we unfortunately still waste time marking and unmarking a lot of cells as dirty.</p>
<p>The second solution is topological sorting. If a cell has no inputs, we mark its height as 0. If a cell has inputs, we mark its height as the maximum of the heights of its inputs, plus one. This guarantees all cells have a greater height than any of their inputs, so we just keep track of all cells with a changed input, always choosing the cell with the lowest height to recalculate first:</p>
<p><img alt="same as prior graph with the two updates, but instead of dirty tags, now every node has a height tag. &quot;burrito price&quot; and &quot;num burritos&quot;, the two cells with no in-nodes, have height 0. &quot;burrito price w ship&quot; has height 1. &quot;total&quot; has height 2." src="https://lord.io/images/2020/anchors_6.png"></p>
<p>In our double-update example, <code>Burrito Price</code> and <code>Total</code> would be initially added to the recalculation heap. <code>Burrito Price</code> has lesser height, and would be recalculated first. Since its output changes, we then would add <code>Burrito Price w Ship</code> to the recalculation heap, and since it too has less height than <code>Total</code>, it would be recalculated before we finally recalculate <code>Total</code>.</p>
<p>This has a big advantage over the first solution: no cell is ever marked dirty unless one of its inputs actually change. However, it requires we keep all cells pending recalculation in sorted order. If we use a heap, this results in an <code>O(n log n)</code> slowdown, so in the worst case, asymptotically slower than Lotus 1-2-3’s strategy of recalculating everything.</p>
<p>Modern-day Excel uses <a href="https://docs.microsoft.com/en-us/office/client-developer/excel/excel-recalculation">a combination of dirty marking and topological sorting</a>, which you can read more about in their docs.</p>
<h2>demand-driven complications</h2>
<p>We’ve now more or less reached the algorithms used in modern-day spreadsheet recalculation. Unfortunately, I suspect there is basically no business case to be made for ever improving it further. The few people with the problem “my Excel spreadsheet is too slow” have already written enough Excel formulas that migration to any other platform is impossible. Fortunately, I have no understanding of business, and so we’re going to look at further improvements anyway.</p>
<p>Beyond caching, one of the cool aspects of a spreadsheet-style computation graph is we can only calculate the cells that we’re interested in. This is sometimes called lazy computation, or demand-driven computation. As a more concrete example, here’s a slightly expanded burrito spreadsheet graph. This example is the same as before, but we’ve added what is best described as “salsa calculations”. Each burrito contains 40 grams of salsa, and we perform a quick multiplication to know how much salsa is in our entire order. In this case, since our order has three burritos, there’s a total of 120 grams of salsa in our entire order.</p>
<p><img alt="a new graph. similar structure to the old graph, but there are two new nodes: &quot;salsa per burrito&quot;, which is set to the constant &quot;40 grams&quot;, and &quot;salsa in order&quot;, which is &quot;salsa per burrito&quot; times &quot;num burritos&quot;" src="https://lord.io/images/2020/anchors_7.png"></p>
<p>Of course, astute readers will have spotted the problem here already: knowing the total weight of salsa in an order is a pretty useless measurement. Who cares that it’s 120 grams? What am I supposed to do with this information?? Unfortunately, a regular spreadsheet would waste cycles calculating <code>Salsa In Order</code>, even if we don’t want it recalculated most of the time.</p>
<p>This is where demand-driven recalculation can help. If we could somehow specify that we’re only interested in the output of <code>Total</code>, we could only recompute that cell and its dependencies, and skip touching <code>Salsa In Order</code> and <code>Salsa Per Burrito</code>. Let’s call <code>Total</code> an <em>observed</em> cell, since we’re trying to look at its output. We can also call both <code>Total</code> and its three dependencies <em>necessary</em> cells, since they’re necessary to compute some observed cell. <code>Salsa In Order</code> and <code>Salsa Per Burrito</code> would be aptly described as <em>unnecessary</em>.</p>
<p>Some folks on the Rust team created the <a href="https://github.com/salsa-rs/salsa">Salsa</a> framework to solve this problem, clearly naming it after the unnecessary salsa calculations their computers were wasting cycles on. Salsa is really cool, and I’m sure <a href="https://www.youtube.com/watch?v=i_IhACacPRY">they can explain</a> how it works better than I can. Very roughly, they use revision numbers to track whether a cell needs recalculation. Any mutation to a formula or input increments the global revision number, and every cell tracks two revisions: <code>verified_at</code> to track the revision its output was last brought up-to-date, and <code>changed_at</code> to track the revision its output last actually changed.</p>
<p><img alt="our new graph, but now there's a title of &quot;current revision: R6&quot;. each cell is tagged with a change revision and verified at revision. all change revisions are R1, except &quot;salsa per burrito&quot;, which is R6. all verified at revisions are R6, except &quot;salsa in order&quot;, which is R1." src="https://lord.io/images/2020/anchors_8.png"></p>
<p>When the user indicates they’d like a fresh value for <code>Total</code>, we’d first recursively recalculate any cell necessary to <code>Total</code>, skipping cells if their <code>last_updated</code> revision is equal to the global revision. Once the dependencies of <code>Total</code> are up-to-date, we only rerun the actual formula in <code>Total</code> if either <code>Burrito Price w Ship</code> or <code>Num Burrito</code> have a <code>changed_at</code> revision greater than the <code>verified_at</code> revision of <code>Total</code>. This is great for Salsa’s purposes in the rust-analyzer, where simplicity is important and each cell takes a significant amount of time to compute. However, we can see the disadvantages in our burrito graph above — if <code>Salsa Per Burrito</code> constantly changes, our global revision number will frequently tick up. This will make each observation of <code>Total</code> walk the three cells necessary to it, even though none of those cells have actually changed. No formulas will be recalculated, but if the graph is large, repeatedly walking all of a cell’s dependencies could get expensive.</p>
<h2>faster demand-driven solutions</h2>
<p>Instead of inventing new algorithms for demand-driven spreadsheets, what if we instead draw from the two classical spreadsheet algorithms mentioned earlier: dirty marking and topological sorting? As you might imagine, a demand-driven model complicates both of these, but both are still viable.</p>
<p>Let’s first look at dirty marking. As before, when we change a cell’s formula, we mark all downstream cells as …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lord.io/blog/2020/spreadsheets/">https://lord.io/blog/2020/spreadsheets/</a></em></p>]]>
            </description>
            <link>https://lord.io/blog/2020/spreadsheets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039393</guid>
            <pubDate>Mon, 09 Nov 2020 20:19:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn how to dive into a new codebase (Front end vs. back end)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25039359">thread link</a>) | @morchen
<br/>
November 9, 2020 | https://swimm.io/blog/2020-08-23-top-down-vs-bottom-up-how-to-deep-dive-into-a-codebase/ | <a href="https://web.archive.org/web/*/https://swimm.io/blog/2020-08-23-top-down-vs-bottom-up-how-to-deep-dive-into-a-codebase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-v-f94c7cca=""> <!----> <div data-v-0cf44990="" data-v-f94c7cca=""><div><p>It’s not impossible to cruise through a programming task on a new codebase and actually complete it without understanding its logic, purpose, or context. Yet there are really only a couple of main approaches to sailing into uncharted waters and coming out the other end alive.</p>
<p>I find it helpful to imagine piecing together a puzzle; we can always start by tackling a dominant piece and working our way from it or rather study the big picture before getting started. Should the approach be the same with a 26-piece-puzzle or a 5K-piece puzzle? Do we write (automation or behavioral) tests, learn the business logic and draw diagrams or rely on conversations with colleagues first?</p>
<blockquote><p lang="en" dir="ltr">Read the documentation? Nobody has time for that!<a href="https://twitter.com/hashtag/100DaysOfCode?src=hash&amp;ref_src=twsrc%5Etfw">#100DaysOfCode</a> <a href="https://twitter.com/hashtag/CodeNewbie?src=hash&amp;ref_src=twsrc%5Etfw">#CodeNewbie</a> <a href="https://twitter.com/hashtag/programming?src=hash&amp;ref_src=twsrc%5Etfw">#programming</a> <a href="https://t.co/aOXy2uJCeU">pic.twitter.com/aOXy2uJCeU</a></p>— Danny Thompson (@DThompsonDev) <a href="https://twitter.com/DThompsonDev/status/1296059274553106432?ref_src=twsrc%5Etfw">August 19, 2020</a></blockquote> 
<p>Whether you are contributing to a new open source project or need to dive into a new repo for work, the approach you opt for will impact your success rate or your teams’. It’s important to cherry-pick the right steps at the right time. Below I list some tips and quick wins I learned along the way for getting into a new repository.</p>
<h3>Bridging the Gap: Top-Down vs Bottom-Up</h3>
<p>Where would you start, if you just arrived at a new team and you were tasked with a backlog issue, for example fixing a bug, creating a button on screen or adding an integration somewhere?</p>
<p><strong>The bottom-up approach</strong>, means trying to get right to the code lines that handle the task at hand. For example, looking for a unique string to pinpoint the specific code area closest to the feature or problem you’re looking to tackle. This approach can lead you to quickly solve the issue at hand. On the other hand, you may unknowingly implement components that have already been implemented, or not understand the impact of your changes on other parts of the codebase.</p>
<p><strong>With top-down</strong>, we look for the larger picture - starting off with modules, , understanding each module’s responsibility, and understanding the main logic. But there are levels of Top-down. For example, you may have a micro-top-down process looking into a specific module (like the module responsible for DB access), or you might have a higher up module - such as the entire backend. The cons of doing an exaggerated top down on a monolithic codebase, is that it’s, plainly speaking, inefficient. It’s easy to hit the end of your exploration capacity and lose sight of the bigger picture when you’re not being hands-on.</p>
<p>While both approaches have merit, they are two extreme ends on the same continuum that are especially problematic for first-timers facing a daunting monolithic codebase. The truth is probably somewhere in the middle (as always). Otherwise, these relatively tempting dichotomous approaches will prove stressful and ineffective when facing delivery.</p>
<p><br>
<strong>Rules of thumbs I try to follow when approaching my first task on a new codebase:</strong></p>
<h3>Get super specific context [Readme, tests and context].</h3>
<p>Even if I want to get to know a very specific code area to complete a task on a repo, I’ll first get some general understanding by looking at the codebase’s Readme files and docs, and even try to look at recent bug-fixes and breakage points to understand the logic. Run the tests and make sure all the frameworks are working and suites are running without errors before starting the task at hand. For a better understanding of the code area, start writing your own tests. If part of a team, I would ask my team lead or mentor which modules and components my first task touches upon.</p>
<h3>Big Picture Components.</h3>
<p>There are some things you should really understand before tackling the task itself. If you’re not sure, ask your team leader / mentor. Why are you writing this code? Why is this important and what’s the objective? What modules will your code interact with? Get a good overview as part of your onboarding but without aimlessly parsing through the codebase. Essentially, this means - start to look for the big picture of the components.</p>
<h3>Quick History Check or Git Extras.</h3>
<p>We love to get frustrated with legacy code, but we also have to learn why some code came to be like that and why it’s still there. Check busy areas of the code through commit messages (look at <a href="https://github.com/tj/git-extras">Git Extras</a> and specifically git effort command to see the number of commit files with the most activity). Another thing is understanding: What libraries and utilities do I need to know? What has already been implemented?</p>
<p>
                <iframe src="https://player.vimeo.com/video/45506445" frameborder="0" allowfullscreen="">
                </iframe>
            </p>
<h3>Check for Interdependencies and Interfaces.</h3>
<p><strong>You can ask: “If I change X, what other modules do I need to change accordingly?”.</strong></p>
<p>At <a href="http://swimm.io/">Swimm</a> for example, users create and run Unit files within the CLI. Users can then collaborate and document information from the repo to highlight different areas of the codebase for other users. We gave a new engineer on our team a task - to save the name of the author of such a Unit upon its creation. This appears to be a super-simple and focused task. Nevertheless, he needed to learn that we have another area that makes sure that what we save in the database is in a certain format so that we don’t send information from our clients (that we do not save by design).</p>
<p>The developer that received this task had to understand the interaction of three different areas - how to save the Unit’s author name (the CLI) without saving client information to the database (DB interaction), and display it in the front end (front end).</p>
<h3>High Exposure = Patterns and Structure.</h3>
<p>Once you’ve explored several areas and functionalities, even poorly documented legacy code, you're bound to start making sense of the mess. You’ll find patterns, see how the code is organized, and gain an understanding of how the different components are connected and inevitably the codebase as a whole. <a href="https://selftaughtcoders.com/how-to-quickly-and-effectively-read-other-peoples-code/">This has to do with high quantity exposure</a> and the way our brain can make up for missing pieces of data. In her new book, <a href="https://www.amazon.com/Badass-Making-Awesome-Kathy-Sierra/dp/1491919019">Badass: Making Users Awesome</a>, Kathy Sierra states:</p>
<blockquote>
<p><strong>“after enough exposure with feedback, your brain [begins] detecting patterns and underlying structures, without your conscious awareness.”</strong></p>
</blockquote>
<h3>Frontend vs Backend: Dive In Like You’re the Captain</h3>
<p>So far I described some high-level tips to apply for any module or code snippet you have to tackle. Yet, there are some tips that better apply to frontend or backend code, as I describe below.</p>
<p><strong>Frontend tips:</strong></p>
<blockquote><div lang="en" dir="ltr"><p>After spending 80 hours on the frontend...</p><p>"Whew! I almost died. Ok let me knock out the API. Gimme 2 hours"</p></div>— Angie Jones (@techgirl1908) <a href="https://twitter.com/techgirl1908/status/1296922565076635648?ref_src=twsrc%5Etfw">August 21, 2020</a></blockquote> 
<ul>
<li>Before you start looking at the code - <strong>interact with it</strong>! Sign up and become a regular user. Try to imagine how each event or action happens in the backend. Play more with the app /website to see how all the changes you will make look and feel constantly. This will also help you consider what your code might affect.</li>
<li><strong>Try to reuse existing components</strong> as much as possible. Be sure to ask your mentor or team lead if there are components you will find helpful in your first task(s).</li>
<li><strong>Try the “friends and family test”.</strong> See how they experience and learn from their user-logic.</li>
</ul>
<p><strong>Backend tips:</strong></p>
<ul>
<li><strong>Research the dependencies</strong>, the functions and main features you must deal with in the backend. Do some frontend investigating as well. It will help you understand how the changes you make in the backend might affect the user’s experience. You’ll need this along the way.</li>
<li><strong>Find all places in the frontend</strong> that interact with your backend code. See if the behavior makes sense before and after your changes.</li>
<li><strong>Skim some areas on git</strong> and <a href="https://github.com/islomar/your-code-as-a-crime-scene">Treat your Code as a Crime Scene</a>. Understand the areas that you touch upon, and look at the code history. Using <a href="https://github.com/tj/git-extras/blob/master/Commands.md">git extra’s commands</a> is a good place to start.</li>
<li><strong>Read the existing</strong> <a href="https://dev.to/perigk/how-to-get-familiar-with-a-new-codebase-i9f">automation tests</a>.</li>
</ul>
<p>
                <iframe type="text/html" src="https://www.youtube.com/embed/qJ_hplxTYJw?autoplay=false" frameborder="0" allowfullscreen="">
                </iframe>
            </p>
<h3>Summarizing thoughts:</h3>
<blockquote>
<p>Experts are not what they know, but what they do</p>
</blockquote>
<p>- <a href="https://medium.com/building-winning-products/kathy-sierra-on-designing-for-badass-ba92cd5fad96">Kathy Sierra on Designing for Badass</a></p>
<ul>
<li>
<p><strong>Write code that others simply get.</strong> That means that your problem solving approach and line of thought are clearly reflected in the code.</p>
</li>
<li>
<p><strong><a href="https://www.forbes.com/sites/forbesproductgroup/2018/03/05/five-critical-steps-to-successful-codebase-on-boarding/#42a08d83e176">Talk to your colleagues</a>.</strong> Successful codebase-onboarding may be heavily influenced by good communication, remote or not, by mentoring or pairing programs, the quality of the tasks you receive, and learning more about the company culture and the people you work with.</p>
</li>
<li>
<p><strong>While onboarding new codebases</strong> <a href="https://swimm.io/blog/2020-07-29-on-the-verge-of-a-new-codebase-5-smart-moves-to-make-when-starting-a-new-job/">we have a rare opportunity to show immediate value</a> to the team by contributing to missing documentation. Once you start to become an expert on a specific area you’ll grow more attentive to missing documentation and you'll have reached the level of Ultimate Onboardee if you’re able to add steps to <a href="http://read.me/"></a>Readme files or deprecated documents.</p>
<p>***</p>
<p>Omer Rosenbaum, is Swimm’s Co-Founder and Chief Technology Officer. Cyber training expert and Founder of Checkpoint Security Academy. Author of <a href="https://data.cyber.org.il/networks/networks.pdf">Computer Networks (in Hebrew)</a>. Visit My <a href="https://www.youtube.com/watch?v=79jlgESHzKQ&amp;list=PL9lx0DXCC4BMS7dB7vsrKI5wzFyVIk2Kg">YouTube Channel</a>.</p>
</li>
</ul>
</div></div> </section></div>]]>
            </description>
            <link>https://swimm.io/blog/2020-08-23-top-down-vs-bottom-up-how-to-deep-dive-into-a-codebase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039359</guid>
            <pubDate>Mon, 09 Nov 2020 20:17:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Connect your on-premises databases to Kubernetes in the cloud]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25039310">thread link</a>) | @alexellisuk
<br/>
November 9, 2020 | https://inlets.dev/blog/2020/11/06/hybrid-cloud-with-inlets.html | <a href="https://web.archive.org/web/*/https://inlets.dev/blog/2020/11/06/hybrid-cloud-with-inlets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Learn how to connect private on-premises services to the public cloud with inlets</p>

<h2 id="what-is-hybrid-cloud-anyway">What is “hybrid cloud” anyway?</h2>

<p>Before we get started, let’s have a clear idea what “hybrid cloud” is all about.</p>

<blockquote>
  <p>“<strong>Hybrid Cloud</strong> is a composition of a public cloud and a private environment, such as a private cloud or on-premises resources, offering the benefits of multiple deployment models. … For example, an organization may store sensitive client data in house on a private cloud application, but interconnect that application to services provided on a public cloud as a software service.” – <a href="https://en.wikipedia.org/wiki/Cloud_computing#Hybrid_cloud">Wikipedia</a></p>
</blockquote>

<p>A hybrid cloud strategy can give a huge benefit for your business by moving workloads to a public cloud, leveraging the flexibility and robustness of managed services, while keeping sensitive data on a private cloud or local data center.</p>

<p>In this post, we’ll demonstrate how you can bring your on-premises services or databases into a Kubernetes cluster running on a public cloud.</p>

<p>This model applies for different use-cases:</p>
<ul>
  <li>perhaps you are in the middle of a digital transformation where some parts of the architecture is deployed on a public cloud, but they still need to integrate with some legacy services</li>
  <li>you have some sensitive data to be kept in a private data center due to data residency regulation</li>
</ul>

<h2 id="tutorial">Tutorial</h2>

<p>You’ll need:</p>
<ul>
  <li>A Kubernetes cluster running on a public cloud (e.g. GKE, AKS, EKS, DOKS, …)</li>
  <li><code>kubectl</code>, configured to connect to the cluster</li>
  <li>A domain and access to your DNS admin panel to create a sub-domain</li>
  <li>A service, like a database, running locally</li>
  <li>An inlets PRO license, start <a href="https://docs.google.com/forms/d/e/1FAIpQLScfNQr1o_Ctu_6vbMoTJ0xwZKZ3Hszu9C-8GJGWw1Fnebzz-g/viewform?usp=sf_link">a 14-day free trial</a>.</li>
</ul>

<p>As an example, we will connect a WordPress instance running in the cloud with a MySQL server running locally. Still, this solution is perfectly applicable to other databases or services like e.g. an Oracle database, a MinIO cluster or a RabbitMQ service.</p>

<p><img src="https://inlets.dev/images/2020-11-06-hybrid-cloud-with-inlets/mysql-wordpress.png" alt="hybrid-mysql-wordpress"></p>

<blockquote>
  <p>Picture above: our target architecture, a WordPress in the cloud connecting to a MySQL on-prem via inlets PRO</p>
</blockquote>

<h3 id="create-the-inlets-pro-exit-server">Create the inlets PRO exit server</h3>

<p>Before we start an inlets-pro exit service, create a Kubernetes secret with a token:</p>

<div><div><pre><code>kubectl create secret generic inlets-token <span>--from-literal</span><span>=</span><span>token</span><span>=</span>&lt;a random token&gt;
</code></pre></div></div>

<p>First, start an inlets-pro exit server pod and make it public with a LoadBalancer service:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>apps/v1</span>
<span>kind</span><span>:</span> <span>Deployment</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>inlets-pro-server</span>
<span>spec</span><span>:</span>
  <span>replicas</span><span>:</span> <span>1</span>
  <span>selector</span><span>:</span>
    <span>matchLabels</span><span>:</span>
      <span>app</span><span>:</span> <span>inlets-pro-server</span>
  <span>template</span><span>:</span>
    <span>metadata</span><span>:</span>
      <span>labels</span><span>:</span>
        <span>app</span><span>:</span> <span>inlets-pro-server</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>inlets-pro</span>
          <span>image</span><span>:</span> <span>inlets/inlets-pro:0.7.2</span>
          <span>imagePullPolicy</span><span>:</span> <span>IfNotPresent</span>
          <span>command</span><span>:</span> <span>[</span> <span>"</span><span>inlets-pro"</span> <span>]</span>
          <span>args</span><span>:</span>
            <span>-</span> <span>"</span><span>server"</span>
            <span>-</span> <span>"</span><span>--auto-tls"</span>
            <span>-</span> <span>"</span><span>--common-name=inlets.example.com"</span>
            <span>-</span> <span>"</span><span>--token-from=/etc/inlets/token"</span>
          <span>volumeMounts</span><span>:</span>
            <span>-</span> <span>name</span><span>:</span> <span>temp-volume</span>
              <span>mountPath</span><span>:</span> <span>/tmp</span>
            <span>-</span> <span>name</span><span>:</span> <span>inlets-token</span>
              <span>mountPath</span><span>:</span> <span>/etc/inlets</span>
              <span>readOnly</span><span>:</span> <span>true</span>   
      <span>volumes</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>temp-volume</span>
          <span>emptyDir</span><span>:</span> <span>{}</span>        
        <span>-</span> <span>name</span><span>:</span> <span>inlets-token</span>
          <span>secret</span><span>:</span>
            <span>secretName</span><span>:</span> <span>inlets-token</span>
</code></pre></div></div>

<p>After applying this on the cluster, a exit server pod is available with:</p>

<ul>
  <li><code>auto-tls</code> enabled, meaning a TLS certificate for the <code>common-name</code> is automatically generated</li>
  <li>the default control port 8123</li>
  <li>the token available in the previously created secret</li>
</ul>

<p>Now expose the exit server with a LoadBalancer service:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>v1</span>
<span>kind</span><span>:</span> <span>Service</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>inlets-pro-server</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>inlets-pro-server</span>
<span>spec</span><span>:</span>
  <span>type</span><span>:</span> <span>LoadBalancer</span>
  <span>ports</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> <span>control</span>
      <span>port</span><span>:</span> <span>8123</span>
      <span>targetPort</span><span>:</span> <span>8123</span>
  <span>selector</span><span>:</span>
    <span>app</span><span>:</span> <span>inlets-pro-server</span>
</code></pre></div></div>

<blockquote>
  <p>Instead of using a LoadBalancer service, a Kubernetes Ingress can also be used here, especially when bringing multiple services into your cluster.</p>
</blockquote>

<p>As you can see, we’ll only expose the control port 8123 to the outside world.
This is actually a good thing, as our database will only reachable from within our Kubernetes cluster, making it more secure.</p>

<p>Wait a little bit until the load balancer is created, grab it’s public IP address and point your domain (remember the common-name) to it.</p>

<div><div><pre><code><span>$ </span>kubectl get service inlets-pro-server
NAME                TYPE           CLUSTER-IP       EXTERNAL-IP       PORT<span>(</span>S<span>)</span>          AGE
inlets-pro-server   LoadBalancer   192.168.197.17   185.136.232.105   8123:31981/TCP   8m11s
</code></pre></div></div>

<blockquote>
  <p>TIP: Some cloud providers honor the <code>loadBalancerSourceRanges</code> field in the Service spec, which allows you to provide a list of IP CIDR blocks allowed to connect to the load balancer. By creating firewall rules, only connections coming from your on-prem data center are allowed.</p>
</blockquote>

<h3 id="start-the-inlets-pro-client">Start the inlets-pro client</h3>

<p>Now that the server part of the tunnel is running, it is time to start the client in our private data center.
Let’s say we have a MySQL instance available with an internal IP address <code>10.1.0.50</code>, start the inlets-pro client:</p>

<div><div><pre><code><span>$ </span>inlets-pro client <span>--license-file</span> ~/inlets-license <span>--port</span> 3306 <span>--url</span> wss://inlets.example.com:8123/connect <span>--upstream</span> 10.1.0.50 <span>--token</span> &lt;your token&gt; 
2020/11/05 13:23:21 Welcome to inlets-pro! Client version 0.7.2
2020/11/05 13:23:21 Licensed to: Johan Siebens &lt;xxxx@gmail.com&gt;, expires: xxx day<span>(</span>s<span>)</span>
2020/11/05 13:23:21 Upstream server: 10.1.0.50, <span>for </span>ports: 3306
inlets-pro client. Copyright Alex Ellis, OpenFaaS Ltd 2020
INFO[2020/11/05 13:23:21] Connecting to proxy                           <span>url</span><span>=</span><span>"wss://inlets.example.com:8123/connect"</span>
</code></pre></div></div>

<p>Perfect! Now the client made the connection, port 3306 of the server pod in our public cloud is accepting connection and will tunnel traffic to the MySQL instance.</p>

<h3 id="create-a-mysql-service">Create a MySQL service</h3>

<p>When we deploy WordPress, we could configure it to connect directly to the inlets-pro server pod, but it is better to create Kubernetes Service:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>v1</span>
<span>kind</span><span>:</span> <span>Service</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>mysql</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>mysql</span>
<span>spec</span><span>:</span>
  <span>ports</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> <span>mysql</span>
      <span>port</span><span>:</span> <span>3306</span>
      <span>targetPort</span><span>:</span> <span>3306</span>
  <span>selector</span><span>:</span>
    <span>app</span><span>:</span> <span>inlets-pro-server</span>
</code></pre></div></div>

<p>The set of Pods targeted by this Service is determined by the same selector as the previous service, but this time it is a service of type ClusterIP, making it only accessible from inside the cluster.</p>

<h3 id="deploy-wordpress">Deploy WordPress</h3>

<p>The only thing left for our example is deploying a WordPress instance, connecting to the MySQL database via the inlets-pro tunnel:</p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>apps/v1</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>wordpress</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>wordpress</span>
<span>spec</span><span>:</span>
  <span>selector</span><span>:</span>
    <span>matchLabels</span><span>:</span>
      <span>app</span><span>:</span> <span>wordpress</span>
  <span>template</span><span>:</span>
    <span>metadata</span><span>:</span>
      <span>labels</span><span>:</span>
        <span>app</span><span>:</span> <span>wordpress</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span>-</span> <span>image</span><span>:</span> <span>wordpress</span>
        <span>name</span><span>:</span> <span>wordpress</span>
        <span>env</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>WORDPRESS_DB_HOST</span>
          <span>value</span><span>:</span> <span>mysql</span>
        <span>ports</span><span>:</span>
        <span>-</span> <span>containerPort</span><span>:</span> <span>80</span>
          <span>name</span><span>:</span> <span>wordpress</span>
</code></pre></div></div>

<blockquote>
  <p>note: this WordPress is not production-ready as it is missing the required volumes for the content</p>
</blockquote>

<p>Mission accomplished! Our WordPress application, running in a public cloud environments is using the MySQL server located in the private data center.</p>

<h2 id="wrapping-up">Wrapping up</h2>

<p>This tutorial gives us a short introduction on how inlets PRO can help us to build a hybrid cloud between existing servers and public cloud.
As a cheaper, easier alternative to a data-center uplink or managed product like AWS Direct Connect or Azure Express Route it is a very lightweight, but powerful, tool to bring your on-prem services to a cloud workload.</p>

<p>For the example we chose WordPress, but the same technique can be applied to any other applications that use TCP traffic.</p>

<ul>
  <li>Resource heavy ETL processes on the cloud, combining multiple data sources like private legacy databases and event streams in the public cloud.</li>
  <li>Data migrations from and to on-prem databases</li>
  <li>Connect your new application to legacy service during a digital transformation</li>
  <li>Keep your LDAP side on-premises in Active Directory and connect to a SaaS IDP product like Auth0. That way anyone can log into a website using their corporate identity without having to migrate Active Directory to the cloud.</li>
</ul>

<p>Further resources:</p>

<ul>
  <li><a href="https://docs.inlets.dev/">Read tutorials and documentation for inlets PRO and OSS</a></li>
  <li><a href="https://inlets.dev/">Kick the tires with free 14-day trial of inlets PRO</a></li>
  <li><a href="https://twitter.com/inletsdev/">Follow @inletsdev on Twitter</a></li>
</ul>

        </div></div>]]>
            </description>
            <link>https://inlets.dev/blog/2020/11/06/hybrid-cloud-with-inlets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039310</guid>
            <pubDate>Mon, 09 Nov 2020 20:13:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Play Dots and Boxes Against AlphaZero in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25039225">thread link</a>) | @carlosaguayo
<br/>
November 9, 2020 | https://carlos-aguayo.github.io/alphazero/ | <a href="https://web.archive.org/web/*/https://carlos-aguayo.github.io/alphazero/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <h4>About</h4>
              <p>WebApp that implements AlphaZero, an exciting and novel Reinforcement Learning Algorithm, used to beat world-champions in games like Go and Chess. In this WebApp, AlphaZero was trained to play the <a href="https://en.wikipedia.org/wiki/Dots_and_Boxes">Dots and Boxes game</a>. This WebApp was written for this <a href="https://towardsdatascience.com/alphazero-a-novel-reinforcement-learning-algorithm-deployed-in-javascript-56018503ad18">Medium blog post</a>.</p>
            </div></div>]]>
            </description>
            <link>https://carlos-aguayo.github.io/alphazero/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039225</guid>
            <pubDate>Mon, 09 Nov 2020 20:04:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nginx conf snippet for blocking bad bots]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25039051">thread link</a>) | @rogue_man_coder
<br/>
November 9, 2020 | https://www.michaellapan.com/blocking-bad-bots | <a href="https://web.archive.org/web/*/https://www.michaellapan.com/blocking-bad-bots">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-1a93d359="" data-v-0291b861=""> <p>A co-worker of mine recently brought up an issue to me where one of our clients were exceeding their monthly ShipperHQ api quota. The wordpress site in question was exceeding their 10k api limit from ShipperHQ for 2 months in a row. The combined traffic and sales from the site did not justify hitting 10k api calls monthly. This is where I came in to see if there was a deeper issue.</p> <p>My first steps were to identify when the api call was sent to ShipperHQ on the site. After some navigating though some pages and keeping an eye on the network tab. I determined the call was being sent out when visiting the checkout.</p> <p>With that known it was time to see where the hits were coming from.</p> <ol><li><p>My first though was to check if the shopping checkout was indexed somewhere on google. A quick google dork later <code>site:site-url inurl:checkout</code> I had found that there were a few entries for the shopping checkout url on google. We removed them and edited the robots.txt</p></li> <li><p>Ensured ShipperHQ was not on the cart page.</p></li> <li><p>lastly, after analyzing the logs I had found a large number of bots that did not respect the robots.txt. Becuase of this they were adding items to carts and navigating to the checkout as they crawled the site. This is where I believed the majortity of the ShipperHQ api hits were coming from. Now its time to block these bots entirly from the site.</p></li></ol> <h4>Nginx Config</h4> <p>To block these malicious bots from crawling the site you can do the following in your nginx conf. While this isnt perfect, as the person with the crawler can change the user_agent. It will atleast get the majortity of them</p> <p>If you need to find the user_agent just go to your nginx access.log and it will show it there. Copy and past it to this list (+restart nginx) and it will start blocking.</p> <p>Specifically for nginx we send back http code 444 for any matching user agents. Code 444 is</p> <blockquote><p>CONNECTION CLOSED WITHOUT RESPONSE</p></blockquote> <pre><code>  if ($http_user_agent ~* (360Spider|80legs.com|Abonti|AcoonBot|Acunetix|adbeat_bot|AddThis.com|adidxbot|ADmantX|AhrefsBot|AngloINFO|Antelope|BaiduSpider|BeetleBot|billigerbot|binlar|bitlybot|BlackWidow|BLP_bbot|BoardReader|Bolt\ 0|BOT\ for\ JCE|Bot\ mailto\:craftbot@yahoo\.com|casper|CazoodleBot|CCBot|checkprivacy|ChinaClaw|chromeframe|Clerkbot|Cliqzbot|clshttp|CommonCrawler|comodo|CPython|crawler4j|Crawlera|CRAZYWEBCRAWLER|Curious|Custo|CWS_proxy|Default\ Browser\ 0|diavol|DigExt|Digincore|DIIbot|discobot|DISCo|DoCoMo|DotBot|Download\ Demon|DTS.Agent|EasouSpider|eCatch|ecxi|EirGrabber|Elmer|EmailCollector|EmailSiphon|EmailWolf|Exabot|ExaleadCloudView|ExpertSearchSpider|ExpertSearch|Express\ WebPictures|ExtractorPro|extract|EyeNetIE|Ezooms|F2S|FastSeek|feedfinder|FeedlyBot|FHscan|finbot|Flamingo_SearchEngine|FlappyBot|FlashGet|flicky|Flipboard|g00g1e|Genieo|genieo|GetRight|GetWeb\!|GigablastOpenSource|GozaikBot|Go\!Zilla|Go\-Ahead\-Got\-It|GrabNet|grab|Grafula|GrapeshotCrawler|GTB5|GT\:\:WWW|harvest|heritrix|HMView|HomePageBot|HTTP\:\:Lite|HTTrack|HubSpot|ia_archiver|icarus6|IDBot|id\-search|IlseBot|Image\ Stripper|Image\ Sucker|Indigonet|Indy\ Library|integromedb|InterGET|InternetSeer\.com|Internet\ Ninja|IRLbot|ISC\ Systems\ iRc\ Search\ 2\.1|jakarta|Java|JetCar|JobdiggerSpider|JOC\ Web\ Spider|Jooblebot|kanagawa|KINGSpider|kmccrew|larbin|LeechFTP|libwww|Lingewoud|LinkChecker|linkdexbot|LinksCrawler|LinksManager\.com_bot|linkwalker|LinqiaRSSBot|LivelapBot|ltx71|LubbersBot|lwp\-trivial|Mail.RU_Bot|masscan|Mass\ Downloader|maverick|Maxthon$|Mediatoolkitbot|MegaIndex|MegaIndex|megaindex|MFC_Tear_Sample|Microsoft\ URL\ Control|microsoft\.url|MIDown\ tool|miner|Missigua\ Locator|Mister\ PiX|mj12bot|Mozilla.*Indy|Mozilla.*NEWT|MSFrontPage|msnbot|Navroad|NearSite|NetAnts|netEstate|NetSpider|NetZIP|Net\ Vampire|NextGenSearchBot|nutch|Octopus|Offline\ Explorer|Offline\ Navigator|OpenindexSpider|OpenWebSpider|OrangeBot|Owlin|PageGrabber|PagesInventory|panopta|panscient\.com|Papa\ Foto|pavuk|pcBrowser|PECL\:\:HTTP|PeoplePal|Photon|PHPCrawl|planetwork|PleaseCrawl|PNAMAIN.EXE|PodcastPartyBot|prijsbest|proximic|psbot|purebot|pycurl|QuerySeekerSpider|R6_CommentReader|R6_FeedFetcher|RealDownload|ReGet|Riddler|Rippers\ 0|rogerbot|RSSingBot|rv\:1.9.1|RyzeCrawler|SafeSearch|SBIder|Scrapy|Scrapy|SeaMonkey$|search.goo.ne.jp|SearchmetricsBot|search_robot|SemrushBot|Semrush|SentiBot|SEOkicks|SeznamBot|ShowyouBot|SightupBot|SISTRIX|sitecheck\.internetseer\.com|siteexplorer.info|SiteSnagger|skygrid|Slackbot|Slurp|SmartDownload|Snoopy|Sogou|Sosospider|spaumbot|Steeler|sucker|SuperBot|Superfeedr|SuperHTTP|SurdotlyBot|Surfbot|tAkeOut|Teleport\ Pro|TinEye-bot|TinEye|Toata\ dragostea\ mea\ pentru\ diavola|Toplistbot|trendictionbot|TurnitinBot|turnit|URI\:\:Fetch|urllib|Vagabondo|Vagabondo|vikspider|VoidEYE|VoilaBot|WBSearchBot|webalta|WebAuto|WebBandit|WebCollage|WebCopier|WebFetch|WebGo\ IS|WebLeacher|WebReaper|WebSauger|Website\ eXtractor|Website\ Quester|WebStripper|WebWhacker|WebZIP|Web\ Image\ Collector|Web\ Sucker|Wells\ Search\ II|WEP\ Search|WeSEE|Wget|Widow|WinInet|woobot|woopingbot|worldwebheritage.org|Wotbox|WPScan|WWWOFFLE|WWW\-Mechanize|Xaldon\ WebSpider|XoviBot|yacybot|YandexBot|Yandex|YisouSpider|zermelo|Zeus|zh-CN|ZmEu|ZumBot|ZyBorg) ) {
      return 444;
  }
</code></pre> <h4>Wordpress modification</h4> <p>If your are unable to modify your nginx conf. Another option would be to have shipping calculation on a different page.</p> <p>Or, using jQuery, to only load the ShipperHQ calculations after the shipping address is filled out.</p></div></div>]]>
            </description>
            <link>https://www.michaellapan.com/blocking-bad-bots</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039051</guid>
            <pubDate>Mon, 09 Nov 2020 19:48:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does consciousness even make sense?]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25039045">thread link</a>) | @algoholix
<br/>
November 9, 2020 | http://niklasbuehler.com/blog/consciousness.html | <a href="https://web.archive.org/web/*/http://niklasbuehler.com/blog/consciousness.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<header>

<span><a href="http://niklasbuehler.com/">Home</a> / <a href="http://niklasbuehler.com/rss.xml">RSS</a> / <a href="http://niklasbuehler.com/contact.html">Contact me</a></span>
</header>
<p><em>08.11.2020</em></p>
<!--
## How does consciousness even make sense?
<a id='1604845992' href='/log/#1604845992'>#1604845992 2020 Nov 08, 15:33</a>
-->
<p>I don’t think the current state of “artificial intelligence” really has proven that it earns the great title of <em>intelligence</em>, as I believe it’s all still just a sophisticated application of statistics on large amounts of data. I prefer the title “machine learning”, as in my opinion that describes the process of adjusting the parameters of statistical methods based on the given data adequately.</p>
<p>I’m not even sure if intelligence and consciousness can be simulated by a computer. Because if they could, then the speed of execution surely wouldn’t matter to that fact, right? And if speed didn’t matter, one could just as well represent the (deterministic!) calculations of a finite computer on a piece of paper or by arranging some stones on a large field. Granted, it’d be somewhat slower than a modern computer and the paper would have to be sufficiently large, but in the end flipping bits, drawing on paper, and moving rocks in a systematic way is just the same when it comes to representing computation. So that’d mean if we arranged a bunch of stones on a large field in a certain pattern and then used some fancy (but deterministic) rules to move them around, we’d create consciousness?! I can’t really believe that’s true.</p>
<p><em>But how is a human brain any different??</em> In the end it’s also just biological wires exchanging electricity (+ some chemistry added to the process)…<br>
I can’t really grasp that. Do my thoughts make sense? Where’s the flaw?</p>
<hr>
<h3 id="join-the-discussion-on-hacker-news">Join the discussion on Hacker News</h3>
<p>There’s an interesting discussion about this text on <a href="https://news.ycombinator.com/item?id=25039045">Hacker News</a>.</p>

<hr>

<h3>Want to leave a comment?</h3>
<p>
If you want to give me some feedback or share your opinion, please contact me via <a href="mailto:hi@niklasbuehler.com?subject=Comment%20on%20Blog:%20consciousness" target="_blank">email</a>.
</p>

<hr>

<p>
<span>© Niklas Bühler, 2020</span>
<span><a href="http://niklasbuehler.com/rss.xml">RSS</a> / <a href="http://niklasbuehler.com/contact.html">Contact me</a></span>
</p>



</div>]]>
            </description>
            <link>http://niklasbuehler.com/blog/consciousness.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25039045</guid>
            <pubDate>Mon, 09 Nov 2020 19:48:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I wrote every day for 365 days]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25038739">thread link</a>) | @patwalls
<br/>
November 9, 2020 | https://patwalls.com/365-blog-posts-in-365-days | <a href="https://web.archive.org/web/*/https://patwalls.com/365-blog-posts-in-365-days">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://patwalls.com/365-blog-posts-in-365-days</link>
            <guid isPermaLink="false">hacker-news-small-sites-25038739</guid>
            <pubDate>Mon, 09 Nov 2020 19:28:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Security Maturity Roadmap [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25038422">thread link</a>) | @sciurus
<br/>
November 9, 2020 | https://summitroute.com/downloads/aws_security_maturity_roadmap-Summit_Route.pdf | <a href="https://web.archive.org/web/*/https://summitroute.com/downloads/aws_security_maturity_roadmap-Summit_Route.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://summitroute.com/downloads/aws_security_maturity_roadmap-Summit_Route.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25038422</guid>
            <pubDate>Mon, 09 Nov 2020 19:07:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Contemplating Becoming a Monk]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25038254">thread link</a>) | @laybak
<br/>
November 9, 2020 | https://knowledgeartist.org/article/becoming-a-monk | <a href="https://web.archive.org/web/*/https://knowledgeartist.org/article/becoming-a-monk">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>I contemplated becoming a Buddhist monk. </span></p> <p><span>For a period of time, I was feeling unmotivated. Depressed, perhaps. It seemed like nothing I did would matter. What's the point of doing anything? </span></p> <p><span>Leaving behind worldly attachments seemed appealing. It was a romantic idea I entertained. </span></p> <p><span>Well, I didn't end up becoming a monk. At least not yet. This post documents my thinking through the decision. And my renewed passion for life.</span></p>  <p><h3><span>Teachings that Resonated</span></h3></p> <p><span>Much of Buddhist teachings rings true to me. Freeing oneself from suffering. Attaining a calm mind through spiritual practice. Living a peaceful life. </span></p> <p><span>It resonated both on a conceptual and a visceral level. And I don't know how much of that came from hearing about it over time from my Buddhist mom.</span></p> <p><span>I could always use more concentration. I could always use more </span> <a href="https://en.wikipedia.org/wiki/Noble_Eightfold_Path" target="_blank"><span>mindfulness</span></a> <span>.</span></p>  <p><h3><span>Leaving It All Behind</span></h3></p> <p><span>The life of a Buddhist monk would be simple. It would be a journey towards enlightenment. </span></p> <p><span>It would mean letting go of my ego and desires. My hopes and dreams. My worries and anxiety. All of it. </span></p> <p><span>It would mean walking away from my possessions and wealth. My comfortable urban lifestyle. My family and friends. </span></p> <p><span>I would be at peace. </span></p>  <p><h3><span>Testing the Idea</span></h3></p> <p><span>But of course, I wasn't going to just take the plunge without validating it in a low-risk way. After all, I had </span> <a href="https://knowledgeartist.org/article/about-me" target="_blank"><span>front-loaded my retirement</span></a> <span> before I started working full-time.</span></p> <p><span>There was only so much I could learn about the Buddhist way of life from reading about it. To validate the idea, I visited several temples. Including a stay at </span> <a href="https://en.wikipedia.org/wiki/Baegyangsa" target="_blank"><span>Baekyangsa</span></a> <span>.</span></p> <p><span>﻿</span> <a href="https://en.wikipedia.org/wiki/Baegyangsa" target="_blank"><span>﻿</span></a> <span>In the process, I spoke with many monks about their experience. I learned a lot more about Buddhist practice. And got to eat some exquisite temple food. 😋</span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/jeong-kwan-mushroom.png"></p>   <p><h3><span>Calming Routines</span></h3></p> <p><span>The routines at a temple didn't seem too far from what I was used to. Over the years, several friends had remarked that I "lived like a monk" anyway.</span></p> <p><span>Waking up at 4 AM was a bit early. But it was doable. And I quite enjoyed the tranquility that the early mornings afforded. I didn't mind the chores. In fact, it felt good to take responsibility to help maintain the temple.</span></p> <p><span>What was the most powerful though, was the morning practice. In a dark room dimly lit with candles, we meditated. We performed prostrations. We chanted in unison. Simple acts, but they moved my soul. </span></p>  <p><h3><span>Conversations With a Young Monk</span></h3></p> <p><span>At one of the temples, I met a young monk around my age. He went to college in New Zealand and was fluent in English. </span></p> <p><span>Having a common language and cultural understanding made him extra relatable. Our conversations were a valuable resource for learning about practicing Buddhism in a modern context.</span></p> <p><span>For him, Buddhist practice was not about strictly following the teachings and the scripture. It was the cultivation of the mind that he was after.</span></p> <p><span>That resonated. It also made the idea of becoming a monk more personal. I could totally see myself becoming more like this guy.</span></p> <p><span>And fun fact, I brought up the </span> <a href="https://www.simulation-argument.com/" target="_blank"><span>simulation argument</span></a> <span> and he too thought that it was likely we are living in a simulation. </span></p>  <p><h3><span>Material Possessions </span></h3></p> <p><span>Having adopted a minimalist lifestyle, living an austere life would not be a big issue. </span></p> <p><span>I didn't own much stuff to begin with. I owned (and still do) a total of five shirts (two of which are identical). And most of my material belongings fit inside a backpack.</span></p> <p><span>I might smuggle in my </span> <a href="https://knowledgeartist.org/article/croissant-way-of-life" target="_blank"><span>morning croissant</span></a> <span> once in a while. But I would be OK for the most part. </span></p>  <p><h3><span>Holding Onto Relationships</span></h3></p> <p><span>But one aspect of life that I have chosen not to leave behind was my earthly relationships.</span></p> <p><span>Some of my happiest moments were with people I loved. Even plain rice tasted better when shared with loved ones. I also remembered how reading Tim Urban's "</span> <a href="https://waitbutwhy.com/2015/12/the-tail-end.html" target="_blank"><span>The Tail End</span></a> <span>" brought me to tears.</span></p> <p><span>I cherished the relationships in my life. And I refused to give them up. </span></p> <p><span>[🚨 Spoiler Alert] In a way, I felt like </span> <a href="https://youtu.be/cH-HT9WCtiQ?t=453" target="_blank"><span>Aang (in Avatar) when he was trying to open his seventh chakra</span></a> <span> to get into the all-powerful Avatar State at will. The chakra was blocked by his earthly attachment. In Aang's case, it was Katara, his lover. For him, the decision was clear: </span> <em>"Why would I choose cosmic energy over Katara?"</em> <span> ﻿</span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/aang-chakra.png"></p>  <p><h3><span>More Fully Participating in Life</span></h3></p> <p><span>I thought about it some more. It became clear to me that I did not want to sit out on life. I did not wish to retreat, to disengage, to let go.</span></p> <p><span>Instead, I wanted to fully embrace life. All the pleasure and pain that it brings, in all its intensity. I wanted to feel the fiery passions. Taste the full spectrum of flavours. Experience the alternate states of consciousness.</span></p> <p><span>Unsuppressed. Unbounded.</span></p> <p><span>I wanted to not just understand timeless abstract principles. But to fully act out my role in my lifetime.</span></p>  <p><h3><span>Creating My Own Meaning</span></h3></p> <p><span>My purpose in life is to feel. It is to create. It is to acquire wisdom and share it. </span></p> <p><span>I want to serve others through my creations. Each day is a challenge I have to overcome, on my never-ending path to mastery. </span></p> <p><span>I would rather live to become a village elder. Loved by the tribe. Scarred by his experiences in life. Respected for wisdom and contributions. That archetype appeals to me more.</span></p> <p><span>There will be gains and losses. Ups and downs. Moments of pure joy. And misery and suffering. </span></p> <p><span>So be it.</span></p>        


          
            
            <p><em>Each week, I send out a newsletter where I share my learnings on product, automation, productivity, and other learnings.</em></p>
            <p><em>Enter your email below to subscribe.</em></p>

            
          
        </div></div>]]>
            </description>
            <link>https://knowledgeartist.org/article/becoming-a-monk</link>
            <guid isPermaLink="false">hacker-news-small-sites-25038254</guid>
            <pubDate>Mon, 09 Nov 2020 18:55:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boost Visual Accessibility by Auto Flipping Text Color Based on Background Color]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25038248">thread link</a>) | @karenying7
<br/>
November 9, 2020 | https://www.blog.karenying.com/posts/boost-visual-accessibility-by-auto-flipping-text-color | <a href="https://web.archive.org/web/*/https://www.blog.karenying.com/posts/boost-visual-accessibility-by-auto-flipping-text-color">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <a href="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d43b4/boost-visual-accessibility-by-changing-your-text-color.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/8ac56/boost-visual-accessibility-by-changing-your-text-color.webp 240w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d3be9/boost-visual-accessibility-by-changing-your-text-color.webp 480w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/e46b2/boost-visual-accessibility-by-changing-your-text-color.webp 960w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/ccc09/boost-visual-accessibility-by-changing-your-text-color.webp 1202w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/8ff5a/boost-visual-accessibility-by-changing-your-text-color.png 240w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/e85cb/boost-visual-accessibility-by-changing-your-text-color.png 480w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d9199/boost-visual-accessibility-by-changing-your-text-color.png 960w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d43b4/boost-visual-accessibility-by-changing-your-text-color.png 1202w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d9199/boost-visual-accessibility-by-changing-your-text-color.png" alt="gradient.png" title="gradient.png" loading="lazy">
      </picture>
  </a>
    </span><em><a href="http://gradient-png.netlify.app/" target="_blank">gradient.png</a></em></p>
<p><strong>If you’re only looking for implementation, <a href="#implementation">skip ahead</a>.</strong></p>
<p>Often times, an app, website, or diagram will write text over a colored background. If the text is white, and the background is light colored, then it’s always hard to read. Visual accessibility is becoming an increasingly hot topic. In this post, we’ll quantify this contrast between two colors, define a standard for the minimum allowed contrast, and implement a way to dynamically change text color based on background color!</p>
<h2 id="wcag-and-contrast-ratio"><a href="#wcag-and-contrast-ratio" aria-label="wcag and contrast ratio permalink"></a>WCAG and Contrast Ratio</h2>
<p>The <a href="https://www.w3.org/WAI/standards-guidelines/wcag/" target="_blank">Web Content Accessibility Guidelines</a> (WCAG) aims to provide a set of standards for developers around the world — to make web content more accessible to people with disabilities.</p>
<p>Perhaps the most obvious applications of the WCAG are in visual accessibility. In this post we’ll dive into the world of color contrast, specifically looking at scenarios where you would want to dynamically change text color based on the background color to increase readability.</p>
<p>In order to understand the motivation behind this, we have to first understand how to quantify the contrast between two colors.</p>
<h3 id="mathematical-representation-of-colors"><a href="#mathematical-representation-of-colors" aria-label="mathematical representation of colors permalink"></a>Mathematical Representation of Colors</h3>
<p>A crash course:</p>
<ul>
<li>
<p>Each color can be represented as a triplet of red, green, and blue values, with values between 0 and 255 — this is the <a href="https://en.wikipedia.org/wiki/RGB_color_space" target="_blank">RGB color space</a></p>
<ul>
<li>Red is <code>(255, 0, 0)</code>, green is <code>(0, 255, 0)</code>, blue is <code>(0, 0, 255)</code></li>
<li>Eggplant purple is equal parts red and blue so it’s <code>(128, 0, 128)</code></li>
</ul>
</li>
<li>
<p>To digitize this RGB triplet, we have <a href="https://en.wikipedia.org/wiki/Web_colors#Hex_triplet" target="_blank">HTML (Hex) color codes</a> which HTML/CSS uses</p>
<ul>
<li>Hex codes are just the concatenation of RGB values in hexadecimal, often preceded by a <code>#</code></li>
<li>Red = <code>#ff0000</code>, green = <code>#00ff00</code>, blue = <code>#0000ff</code>, eggplant purple = <code>#800080</code></li>
</ul>
</li>
<li>Hex codes only represent the RGB color space. There are many other color spaces such as <a href="https://en.wikipedia.org/wiki/HSL_and_HSV" target="_blank">HSL/HSV/HSB</a>, <a href="https://en.wikipedia.org/wiki/CIELAB_color_space" target="_blank">CIELAB</a>, and <a href="https://en.wikipedia.org/wiki/CMYK_color_model" target="_blank">CMYK</a>. Each serve different purposes but we’ll be focusing on RGB for this post.</li>
</ul>
<h3 id="luminance"><a href="#luminance" aria-label="luminance permalink"></a>Luminance</h3>
<p>Now that we have a way to quantify colors, we can talk about <a href="https://en.wikipedia.org/wiki/Relative_luminance" target="_blank">luminance</a>, the preceived brightness of a color. This is the L value in the HSL color space. The mathematical model for <a href="https://planetcalc.com/7779/" target="_blank">calculating luminance</a> is rather convoluted so I’ll be glazing over it. All we need to know is that</p>
<ul>
<li>it can be derived from an RGB triplet — it’s roughly a weighted average of the three values</li>
<li>can be represented as a percentage, or as a value from 0 - 1 (what we’ll be using)</li>
<li>white is 1, black is 0</li>
</ul>
<h3 id="contrast-ratio"><a href="#contrast-ratio" aria-label="contrast ratio permalink"></a>Contrast Ratio</h3>
<p>The final piece is to calculate the <a href="https://webaim.org/articles/contrast/" target="_blank">contrast ratio</a> between two colors, namely between a text color and its background color here.</p>
<p>The formula is just the quotient between the brighter color’s luminance (the bigger number) and the dark color’s luminance (the smaller number):</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>ratio</mtext><mo>=</mo><mfrac><mrow><mi>l</mi><mi>u</mi><mi>m</mi><mo stretchy="false">(</mo><mrow><mtext mathvariant="bold">brighter</mtext><mtext>&nbsp;color)</mtext></mrow><mo>+</mo><mn>0.05</mn></mrow><mrow><mi>l</mi><mi>u</mi><mi>m</mi><mo stretchy="false">(</mo><mrow><mtext mathvariant="bold">darker</mtext><mtext>&nbsp;color</mtext></mrow><mo stretchy="false">)</mo><mo>+</mo><mn>0.05</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">\textrm{ratio} = \frac{lum(\textrm{\textbf{brighter} color)} + 0.05}{lum(\textrm{\textbf{darker} color}) + 0.05}</annotation></semantics></math></span></span></span></p><p>The contrast ratio of any two colors ranges between 1 (two of the same colors) to 21 (black and white).</p>
<p><strong>The WCAG requires a contrast ratio of at least 4.5.</strong></p>
<p>There are three exceptions to the above rule:</p>
<ul>
<li><strong>Large text</strong>: larger text is easier to read. Thus the required ratio is at least 3.0 for bigger text.</li>
<li><strong>Incidental</strong>: text that is for decorative/design purposes, not really meant to be read</li>
<li><strong>Logos</strong></li>
</ul>
<h4 id="examples"><a href="#examples" aria-label="examples permalink"></a>Examples</h4>
<ul>
<li>Contrast ratio of <strong>12.98</strong> (good job Karen)</li>
<li><span>Contrast ratio of <b>4.77</b> (I could do better for links)</span></li>
<li><span>Contrast ratio of <b>4.54</b> (barely passable by WCAG standards)</span></li>
<li><span>Contrast ratio of <b>1.61</b> (terrible)</span></li>
<li><span>Contrast ratio of <b>1.15</b> (brb my eyes are crying)</span></li>
</ul>
<h2 id="use-cases"><a href="#use-cases" aria-label="use cases permalink"></a>Use Cases</h2>
<p>Before we get started coding, let’s run through a couple of examples of where you would want to dynamically changed the text color based on its background color.</p>
<h3 id="facebook-messenger"><a href="#facebook-messenger" aria-label="facebook messenger permalink"></a>Facebook Messenger</h3>
<p>Messenger is what spurred this post. Facebook lets you change the chat default color from the typical blue to a variety of different options. This theme color the background color of all the messages <em>you</em> send. The messages you receive are typically with a dark gray background.</p>
<p><span><span>
      <a href="https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/f6386/fb-blue.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/8ac56/fb-blue.webp 240w,
https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/d3be9/fb-blue.webp 480w,
https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/7dbce/fb-blue.webp 686w" sizes="(max-width: 686px) 100vw, 686px" type="image/webp">
        <source srcset="https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/8ff5a/fb-blue.png 240w,
https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/e85cb/fb-blue.png 480w,
https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/f6386/fb-blue.png 686w" sizes="(max-width: 686px) 100vw, 686px" type="image/png">
        <img src="https://www.blog.karenying.com/static/a8f769be03dbd5ce10de3aaa45a70b46/f6386/fb-blue.png" alt="Facebook Messenger blue" title="Facebook Messenger blue" loading="lazy">
      </picture>
  </a>
    </span></span><br><em>Default Messenger blue</em></p>
<p><span><span>
      <a href="https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/6c745/fb-palette.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/8ac56/fb-palette.webp 240w,
https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/d3be9/fb-palette.webp 480w,
https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/f0cd5/fb-palette.webp 893w" sizes="(max-width: 893px) 100vw, 893px" type="image/webp">
        <source srcset="https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/8ff5a/fb-palette.png 240w,
https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/e85cb/fb-palette.png 480w,
https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/6c745/fb-palette.png 893w" sizes="(max-width: 893px) 100vw, 893px" type="image/png">
        <img src="https://www.blog.karenying.com/static/d49276e5ec176aedd3bc5ed0ceb03fe2/6c745/fb-palette.png" alt="Facebook Messenger palette" title="Facebook Messenger palette" loading="lazy">
      </picture>
  </a>
    </span></span><br> <em>Messenger solid palette. They change this up pretty often. Gradient options are also available 😍</em></p>
<p>However, regardless of what color you pick, the text color is infuriatingly white.</p>
<p><span><span>
      <a href="https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/91e7e/fb-yellow.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/8ac56/fb-yellow.webp 240w,
https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/d3be9/fb-yellow.webp 480w,
https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/f686e/fb-yellow.webp 692w" sizes="(max-width: 692px) 100vw, 692px" type="image/webp">
        <source srcset="https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/8ff5a/fb-yellow.png 240w,
https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/e85cb/fb-yellow.png 480w,
https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/91e7e/fb-yellow.png 692w" sizes="(max-width: 692px) 100vw, 692px" type="image/png">
        <img src="https://www.blog.karenying.com/static/f7dbc143cde958ed091a7992aa0e58da/91e7e/fb-yellow.png" alt="Facebook Messenger yellow" title="Facebook Messenger yellow" loading="lazy">
      </picture>
  </a>
    </span></span><br> <em>Yellow theme in a group chat</em></p>
<p>Remember this example from before? <span>Contrast ratio of <b>1.61</b> (terrible)</span> 🙁</p>
<h3 id="gradientpng"><a href="#gradientpng" aria-label="gradientpng permalink"></a>gradient.png</h3>
<p>I made a gradient generating <a href="http://gradient-png.netlify.app/" target="_blank">app</a> a while back. The app lets you choose colors for a gradient, displaying the hex codes on the current colors.</p>
<p><span>
      <a href="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d43b4/boost-visual-accessibility-by-changing-your-text-color.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/8ac56/boost-visual-accessibility-by-changing-your-text-color.webp 240w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d3be9/boost-visual-accessibility-by-changing-your-text-color.webp 480w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/e46b2/boost-visual-accessibility-by-changing-your-text-color.webp 960w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/ccc09/boost-visual-accessibility-by-changing-your-text-color.webp 1202w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/8ff5a/boost-visual-accessibility-by-changing-your-text-color.png 240w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/e85cb/boost-visual-accessibility-by-changing-your-text-color.png 480w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d9199/boost-visual-accessibility-by-changing-your-text-color.png 960w,
https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d43b4/boost-visual-accessibility-by-changing-your-text-color.png 1202w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://www.blog.karenying.com/static/56417ad67026c9015db7e7d117a45a6f/d9199/boost-visual-accessibility-by-changing-your-text-color.png" alt="gradient.png" title="gradient.png" loading="lazy">
      </picture>
  </a>
    </span><em>Imperfect implementation for <a href="http://gradient-png.netlify.app/" target="_blank">gradient.png</a></em></p>
<p>I calculated luminance for the colors and choose dark text if the luminance was below 50%. However, I didn’t apply the contrast ratio formula, so this is an imperfect implementation. Still better than nothing though?</p>
<h3 id="charts-and-diagrams"><a href="#charts-and-diagrams" aria-label="charts and diagrams permalink"></a>Charts and Diagrams</h3>
<p><img src="https://d2mvzyuse3lwjc.cloudfront.net/doc/en/UserGuide/images/Bar_Of_Pie_Chart/Bar_Of_Pie_Chart.png?v=83483" alt="Pie chart"><em>Rando pie chart I found <a href="https://www.originlab.com/doc/Origin-Help/Bar-Of-Pie" target="_blank">online</a></em></p>
<p>This concept might be most useful when you’re displaying data with different colors, and you want to write text over each section.</p>
<h2 id="implementation"><a href="#implementation" aria-label="implementation permalink"></a>Implementation</h2>
<h3 id="-1-prereqs"><a href="#-1-prereqs" aria-label=" 1 prereqs permalink"></a>-1. Prereqs</h3>
<p>This tutorial assumes you have some knowledge of JavaScript and React. All good? Let’s get started 👍🏼</p>
<h3 id="0-getting-started"><a href="#0-getting-started" aria-label="0 getting started permalink"></a>0. Getting Started</h3>
<p>We’ll use <a href="https://create-react-app.dev/docs/getting-started/" target="_blank">Create React App</a> to create, bundle, and run the project:</p>
<div data-language="bash"><pre><code>$ npx create-react-app dyn-change-text-color
$ <span>cd</span> dyn-change-text-color
$ <span>npm</span> start</code></pre></div>
<h3 id="1-colorbox-component"><a href="#1-colorbox-component" aria-label="1 colorbox component permalink"></a>1. ColorBox Component</h3>
<p>We’re going to create a <code>ColorBox</code> component which takes a hex code string as a prop. For consistency sake, we will always store hex codes variables without the pound sign, only adding it when necessary for CSS/HTML. The hex code prop will determine the background color of the component.</p>
<p>Create a new file called <code>ColorBox.js</code>:</p>

<div data-language="jsx"><pre><code><span>import</span> <span>'./ColorBox.css'</span><span>;</span>

<span>const</span> <span>ColorBox</span> <span>=</span> <span>(</span><span><span>{</span> backgroundHex <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span>
      <span>className</span><span><span>=</span><span>'</span>colorbox-container<span>'</span></span>
      <span>style</span><span><span>=</span><span>{</span><span>{</span> backgroundColor<span>:</span> <span><span>`</span><span>#</span><span><span>${</span>backgroundHex<span>}</span></span><span>`</span></span> <span>}</span><span>}</span></span>
    <span>&gt;</span></span><span>
      </span><span>{</span><span><span>`</span><span>#</span><span><span>${</span>backgroundHex<span>}</span></span><span>`</span></span><span>}</span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span><span>;</span>

<span>export</span> <span>default</span> ColorBox<span>;</span></code></pre></div>
<p>Here we use inline styling to dynamically change the background color based on the component’s prop. We also render the hex code as text in the component.</p>
<p>Let’s import <code>ColorBox</code> to <code>App.js</code> and pass in black as the <code>backgroundHex</code> prop:</p>

<div data-language="jsx"><pre><code><span>function</span> <span>App</span><span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span> <span>className</span><span><span>=</span><span>'</span>App<span>'</span></span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span><span>ColorBox</span></span> <span>backgroundHex</span><span><span>=</span><span>'</span>2a2b2e<span>'</span></span> <span>/&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>Add some styling:</p>

<div data-language="css"><pre><code><span>.colorbox-container</span> <span>{</span>
  <span>display</span><span>:</span> flex<span>;</span>
  <span>align-items</span><span>:</span> center<span>;</span>
  <span>justify-content</span><span>:</span> center<span>;</span>
  <span>height</span><span>:</span> 70px<span>;</span>
  <span>width</span><span>:</span> 200px<span>;</span>
  <span>border-radius</span><span>:</span> 5px<span>;</span>
  <span>padding</span><span>:</span> 20px<span>;</span>
  <span>text-align</span><span>:</span> center<span>;</span>
<span>}</span></code></pre></div>
<p>If we run the app, we should see:</p>
<p><span><span>
      <a href="https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/7527b/colorbox-1.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/8ac56/colorbox-1.webp 240w,
https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/d3be9/colorbox-1.webp 480w,
https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/20eb0/colorbox-1.webp 754w" sizes="(max-width: 754px) 100vw, 754px" type="image/webp">
        <source srcset="https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/8ff5a/colorbox-1.png 240w,
https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/e85cb/colorbox-1.png 480w,
https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/7527b/colorbox-1.png 754w" sizes="(max-width: 754px) 100vw, 754px" type="image/png">
        <img src="https://www.blog.karenying.com/static/539ba39070de853652df053dcd90deef/7527b/colorbox-1.png" alt="ColorBox" title="ColorBox" loading="lazy">
      </picture>
  </a>
    </span></span><br><em><code>ColorBox</code> component with black as <code>backgroundHex</code> prop. Terrible contrast ratio with default black text</em></p>
<h3 id="2-so-oop-much-modularization"><a href="#2-so-oop-much-modularization" aria-label="2 so oop much modularization permalink"></a>2. So OOP, Much Modularization</h3>
<h4 id="21-templates"><a href="#21-templates" aria-label="21 templates permalink"></a>2.1 Templates</h4>
<p>To better organize our code, we’re gonna create a <code>Color</code> class as well as some helper methods. Let’s set these up:</p>

<div data-language="js"><pre><code><span>import</span> <span>{</span> textColors<span>,</span> contrastRatioPair<span>,</span> getLuminance <span>}</span> <span>from</span> <span>'./helper'</span><span>;</span>

<span>export</span> <span>default</span> <span>class</span> <span>Color</span> <span>{</span>
  
  <span>constructor</span><span>(</span><span>hex</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span>hex <span>=</span> hex<span>;</span>
  <span>}</span>

  
  <span>get</span> <span>luminance</span><span>(</span><span>)</span> <span>{</span><span>}</span>

  
  <span>contrastRatioWith</span><span>(</span><span>hex2</span><span>)</span> <span>{</span><span>}</span>

  
  <span>get</span> <span>textColor</span><span>(</span><span>)</span> <span>{</span><span>}</span>
<span>}</span></code></pre></div>

<div data-language="js"><pre><code><span>export</span> <span>const</span> textColors <span>=</span> <span>{</span>
  <span>BLACK</span><span>:</span> <span>'000000'</span><span>,</span>
  <span>WHITE</span><span>:</span> <span>'ffffff'</span><span>,</span>
<span>}</span><span>;</span>


<span>export</span> <span>function</span> <span>contrastRatioPair</span><span>(</span><span>hex1<span>,</span> hex2</span><span>)</span> <span>{</span><span>}</span>


<span>function</span> <span>hexToRGB</span><span>(</span><span>hex</span><span>)</span> <span>{</span><span>}</span>


<span>export</span> <span>function</span> <span>getLuminance</span><span>(</span><span>hex</span><span>)</span> <span>{</span><span>}</span></code></pre></div>
<p>Great, now we can start filling out these functions.</p>
<h4 id="22-luminance"><a href="#22-luminance" aria-label="22 luminance permalink"></a>2.2. Luminance</h4>
<p>As mentioned before, the luminance calculation is a bit messy. We need to first convert our 6 bit hex string to RGB values. To do so, we splice the string, and parse the substrings from hex to decimal:</p>

<div data-language="js"><pre><code>
<span>function</span> <span>hexToDecimal</span><span>(</span><span>hex_string</span><span>)</span> <span>{</span>
  <span>return</span> <span>parseInt</span><span>(</span>hex_string<span>,</span> <span>16</span><span>)</span><span>;</span>
<span>}</span>


<span>function</span> <span>hexToRGB</span><span>(</span><span>hex</span><span>)</span> <span>{</span>
  <span>const</span> r <span>=</span> <span>hexToDecimal</span><span>(</span>hex<span>.</span><span>substring</span><span>(</span><span>0</span><span>,</span> <span>2</span><span>)</span><span>)</span><span>;</span>
  <span>const</span> g <span>=</span> <span>hexToDecimal</span><span>(</span>hex<span>.</span><span>substring</span><span>(</span><span>2</span><span>,</span> <span>4</span><span>)</span><span>)</span><span>;</span>
  <span>const</span> b <span>=</span> <span>hexToDecimal</span><span>(</span>hex<span>.</span><span>substring</span><span>(</span><span>4</span><span>,</span> <span>6</span><span>)</span><span>)</span><span>;</span>

  <span>return</span> <span>{</span> r<span>,</span> g<span>,</span> b <span>}</span><span>;</span>
<span>}</span></code></pre></div>
<p>We can then call <code>hexToRGB</code> in our luminance calculation. If you want to read more about exactly how to calculate, you can check out this <a href="https://planetcalc.com/7779/" target="_blank">calculator</a> or <a href="https://en.wikipedia.org/wiki/Relative_luminance" target="_blank">Wikipedia</a>. But if you just wanna trust me on this one, here’s the gross code:</p>

<div data-language="js"><pre><code>
<span>export</span> <span>function</span> <span>getLuminance</span><span>(</span><span>hex</span><span>)</span> <span>{</span>
  <span>const</span> rgb <span>=</span> <span>hexToRGB</span><span>(</span>hex<span>)</span><span>;</span>

  <span>for</span> <span>(</span><span>const</span> key <span>in</span> rgb<span>)</span> <span>{</span>
    <span>let</span> c <span>=</span> rgb<span>[</span>key<span>]</span><span>;</span>
    c <span>/=</span> <span>255</span><span>;</span>

    c <span>=</span> c <span>&gt;</span> <span>0.03928</span> <span>?</span> Math<span>.</span><span>pow</span><span>(</span><span>(</span>c <span>+</span> <span>0.055</span><span>)</span> <span>/</span> <span>1.055</span><span>,</span> <span>2.4</span><span>)</span> <span>:</span> <span>(</span>c <span>/=</span> <span>12.92</span><span>)</span><span>;</span>

    rgb<span>[</span>key<span>]</span> <span>=</span> c<span>;</span>
  <span>}</span>

  <span>return</span> <span>0.2126</span> <span>*</span> rgb<span>.</span>r <span>+</span> <span>0.7152</span> <span>*</span> rgb<span>.</span>g <span>+</span> <span>0.0722</span> <span>*</span> rgb<span>.</span>b<span>;</span>
<span>}</span></code></pre></div>
<h4 id="23-contrast-ratio"><a href="#23-contrast-ratio" aria-label="23 contrast ratio permalink"></a>2.3. Contrast Ratio</h4>
<p>With our luminance function done, we can call it to calculate the contrast ratio between two colors with our division formula from before:</p>

<div data-language="js"><pre><code>
<span>export</span> <span>function</span> <span>contrastRatioPair</span><span>(</span><span>hex1<span>,</span> hex2</span><span>)</span> <span>{</span>
  <span>const</span> lum1 <span>=</span> <span>getLuminance</span><span>(</span>hex1<span>)</span><span>;</span>
  <span>const</span> lum2 <span>=</span> <span>getLuminance</span><span>(</span>hex2<span>)</span><span>;</span>

  <span>return</span> <span>(</span>Math<span>.</span><span>max</span><span>(</span>lum1<span>,</span> lum2<span>)</span> <span>+</span> <span>0.05</span><span>)</span> <span>/</span> <span>(</span>Math<span>.</span><span>min</span><span>(</span>lum1<span>,</span> lum2<span>)</span> <span>+</span> <span>0.05</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<h4 id="24-filling-out-colorjs"><a href="#24-filling-out-colorjs" aria-label="24 filling out colorjs permalink"></a>2.4. Filling out <code>Color.js</code></h4>
<p>We can now fill out the methods of the <code>Color</code> class with our helper methods:</p>

<div data-language="js"><pre><code>  
  <span>get</span> <span>luminance</span><span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>getLuminance</span><span>(</span><span>this</span><span>.</span>hex<span>)</span><span>;</span>
  <span>}</span>

  
  <span>contrastRatioWith</span><span>(</span><span>hex2</span><span>)</span> <span>{</span>
    <span>return</span> <span>contrastRatioPair</span><span>(</span><span>this</span><span>.</span>hex<span>,</span> hex2<span>)</span><span>;</span>
  <span>}</span>

  
  <span>get</span> <span>textColor</span><span>(</span><span>)</span> <span>{</span>
    <span>const</span> <span>{</span> <span>BLACK</span><span>,</span> <span>WHITE</span> <span>}</span> <span>=</span> textColors<span>;</span>

    <span>return</span> <span>this</span><span>.</span><span>contrastRatioWith</span><span>(</span><span>BLACK</span><span>)</span> <span>&gt;</span> <span>this</span><span>.</span><span>contrastRatioWith</span><span>(</span><span>WHITE</span><span>)</span>
      <span>?</span> <span>BLACK</span>
      <span>:</span> <span>WHITE</span><span>;</span>
  <span>}</span></code></pre></div>
<p><code>textColor</code> computes the contrast ratio of the current color with black and white, and returns the color (black or white) that yields the highest contrast ratio.</p>
<h3 id="3-pulling-it-all-together"><a href="#3-pulling-it-all-together" aria-label="3 pulling it all together permalink"></a>3. Pulling it all Together</h3>
<p>Now we can turn back to our <code>ColorBox</code> component.</p>
<p>All we need to do is create a new <code>Color</code> object with the <code>backgroundHex</code> prop and call its appropriate properties/methods:</p>

<div data-language="jsx"><pre><code><span>const</span> backgroundColor <span>=</span> <span>new</span> <span>Color</span><span>(</span>backgroundHex<span>)</span><span>;</span>
<span>const</span> <span>{</span> textColor <span>}</span> <span>=</span> backgroundColor<span>;</span></code></pre></div>
<p>Then we can set the <code>color</code> CSS property of the div as <code>textColor</code>. I also added a couple of lines to display the current contrast ratio:</p>

<div data-language="jsx"><pre><code>  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span>
      <span>className</span><span><span>=</span><span>'</span>colorbox-container<span>'</span></span>
      <span>style</span><span><span>=</span><span>{</span><span>{</span> backgroundColor<span>:</span> <span><span>`</span><span>#</span><span><span>${</span>backgroundHex<span>}</span></span><span>`</span></span><span>,</span> color<span>:</span> <span><span>`</span><span>#</span><span><span>${</span>textColor<span>}</span></span><span>`</span></span> <span>}</span><span>}</span></span>
    <span>&gt;</span></span><span>
      </span><span>{</span><span><span>`</span><span>#</span><span><span>${</span>backgroundHex<span>}</span></span><span>`</span></span><span>}</span><span>
      </span><span><span><span>&lt;</span>br</span> <span>/&gt;</span></span><span>
      </span><span>{</span><span><span>`</span><span>Contrast ratio: </span><span><span>${</span>backgroundColor
        <span>.</span><span>contrastRatioWith</span><span>(</span>textColor<span>)</span>
        <span>.</span><span>toFixed</span><span>(</span><span>2</span><span>)</span><span>}</span></span><span>`</span></span><span>}</span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre></div>
<p>Now if you check out the app, it should look like this:</p>
<p><span><span>
      <a href="https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/8ae3e/colorbox-2.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/8ac56/colorbox-2.webp 240w,
https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/d3be9/colorbox-2.webp 480w,
https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/b5834/colorbox-2.webp 756w" sizes="(max-width: 756px) 100vw, 756px" type="image/webp">
        <source srcset="https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/8ff5a/colorbox-2.png 240w,
https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/e85cb/colorbox-2.png 480w,
https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/8ae3e/colorbox-2.png 756w" sizes="(max-width: 756px) 100vw, 756px" type="image/png">
        <img src="https://www.blog.karenying.com/static/60068a87c2a2002a02f7ec090c19bf53/8ae3e/colorbox-2.png" alt="ColorBox" title="ColorBox" loading="lazy">
      </picture>
  </a>
    </span></span><br><em>The …</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.blog.karenying.com/posts/boost-visual-accessibility-by-auto-flipping-text-color">https://www.blog.karenying.com/posts/boost-visual-accessibility-by-auto-flipping-text-color</a></em></p>]]>
            </description>
            <link>https://www.blog.karenying.com/posts/boost-visual-accessibility-by-auto-flipping-text-color</link>
            <guid isPermaLink="false">hacker-news-small-sites-25038248</guid>
            <pubDate>Mon, 09 Nov 2020 18:55:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[API with NestJS #17. Offset and keyset pagination with PostgreSQL and TypeORM]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25038192">thread link</a>) | @mwanago
<br/>
November 9, 2020 | https://wanago.io/2020/11/09/api-nestjs-offset-keyset-pagination-postgresql-typeorm/ | <a href="https://web.archive.org/web/*/https://wanago.io/2020/11/09/api-nestjs-offset-keyset-pagination-postgresql-typeorm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><article id="post-3395"><div><div> <p><time datetime="2020-11-09"> November 9, 2020 </time></p><ul><li>1. <a href="https://wanago.io/2020/05/11/nestjs-api-controllers-routing-module/" title="API with NestJS #1. Controllers, routing and the module structure">API with NestJS #1. Controllers, routing and the module structure</a></li><li>2. <a href="https://wanago.io/2020/05/18/api-nestjs-postgresql-typeorm/" title="API with NestJS #2. Setting up a PostgreSQL database with TypeORM">API with NestJS #2. Setting up a PostgreSQL database with TypeORM</a></li><li>3. <a href="https://wanago.io/2020/05/25/api-nestjs-authenticating-users-bcrypt-passport-jwt-cookies/" title="API with NestJS #3. Authenticating users with bcrypt, Passport, JWT, and cookies">API with NestJS #3. Authenticating users with bcrypt, Passport, JWT, and cookies</a></li><li>4. <a href="https://wanago.io/2020/06/01/api-nestjs-error-handling-validation/" title="API with NestJS #4. Error handling and data validation">API with NestJS #4. Error handling and data validation</a></li><li>5. <a href="https://wanago.io/2020/06/08/api-nestjs-serializing-response-interceptors/" title="API with NestJS #5. Serializing the response with interceptors">API with NestJS #5. Serializing the response with interceptors</a></li><li>6. <a href="https://wanago.io/2020/06/15/api-with-nestjs-6-looking-into-dependency-injection-and-modules/" title="API with NestJS #6. Looking into dependency injection and modules">API with NestJS #6. Looking into dependency injection and modules</a></li><li>7. <a href="https://wanago.io/2020/06/22/api-nestjs-relationships-postgres-typeorm/" title="API with NestJS #7. Creating relationships with Postgres and TypeORM">API with NestJS #7. Creating relationships with Postgres and TypeORM</a></li><li>8. <a href="https://wanago.io/2020/07/06/api-nestjs-unit-tests/" title="API with NestJS #8. Writing unit tests">API with NestJS #8. Writing unit tests</a></li><li>9. <a href="https://wanago.io/2020/07/13/api-nestjs-testing-services-controllers-integration-tests/" title="API with NestJS #9. Testing services and controllers with integration tests">API with NestJS #9. Testing services and controllers with integration tests</a></li><li>10. <a href="https://wanago.io/2020/08/03/api-nestjs-uploading-public-files-to-amazon-s3/" title="API with NestJS #10. Uploading public files to Amazon S3">API with NestJS #10. Uploading public files to Amazon S3</a></li><li>11. <a href="https://wanago.io/2020/08/10/api-nestjs-private-files-amazon-s3/" title="API with NestJS #11. Managing private files with Amazon S3">API with NestJS #11. Managing private files with Amazon S3</a></li><li>12. <a href="https://wanago.io/2020/09/07/api-nestjs-elasticsearch/" title="API with NestJS #12. Introduction to Elasticsearch">API with NestJS #12. Introduction to Elasticsearch</a></li><li>13. <a href="https://wanago.io/2020/09/21/api-nestjs-refresh-tokens-jwt/" title="API with NestJS #13. Implementing refresh tokens using JWT">API with NestJS #13. Implementing refresh tokens using JWT</a></li><li>14. <a href="https://wanago.io/2020/10/19/nestjs-performance-postgres-database-indexes/" title="API with NestJS #14. Improving performance of our Postgres database with indexes">API with NestJS #14. Improving performance of our Postgres database with indexes</a></li><li>15. <a href="https://wanago.io/2020/10/26/api-nestjs-transactions-postgresql-typeorm/" title="API with NestJS #15. Defining transactions with PostgreSQL and TypeORM">API with NestJS #15. Defining transactions with PostgreSQL and TypeORM</a></li><li>16. <a href="https://wanago.io/2020/11/02/api-nestjs-array-data-type-postgresql-typeorm/" title="API with NestJS #16. Using the array data type with PostgreSQL and TypeORM">API with NestJS #16. Using the array data type with PostgreSQL and TypeORM</a></li><li>17. API with NestJS #17. Offset and keyset pagination with PostgreSQL and TypeORM</li></ul><p>As our database grows, so do the results of our queries. Returning a lot of data in our API might not be the best approach performance-wise. Dividing our content into multiple pages and solutions like infinite scrolling have been around for quite some time. In this article, we explore ways of implementing pagination and point out their pros and cons.</p><p>You can find all of the code from this series in <a href="https://github.com/mwanago/nestjs-typescript">this repository</a>.</p><h2>Offset and Limit</h2><p>Let’s start with the following, straightforward query:</p><div id="crayon-5fae0a5d87685022050039" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>SELECT</span><span> </span>*<span> </span><span>FROM</span><span> </span>post</p><p><span>ORDER</span><span> </span><span>BY</span><span> </span>id<span> </span><span>ASC</span></p></div></td></tr></tbody></table></div></div><p>The above returns all of the records from the <span id="crayon-5fae0a5d8768d062965654"><span><span>post</span></span></span> table. To be sure about the order of the results, we sort them by id.</p><p>The first step in implementing pagination would be to limit the number of results. We can do that using the <span id="crayon-5fae0a5d8768f814071593"><span><span>LIMIT</span></span></span> statement.</p><div id="crayon-5fae0a5d87692258340509" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>SELECT</span><span> </span>*<span> </span><span>FROM</span><span> </span>post</p><p><span>ORDER</span><span> </span><span>BY</span><span> </span>id<span> </span><span>ASC</span></p><p><span>LIMIT</span><span> </span>10</p></div></td></tr></tbody></table></div></div><p>Now, instead of getting all of the posts, we get just the first ten of them. This results in getting elements with ids from 1 to 10.</p><p>To have fully functional pagination, we need to specify the starting point of our query. To do that, we can use the <span id="crayon-5fae0a5d87694275513468"><span><span>OFFSET</span></span></span> keyword. With it, we can say how many rows we want to skip.</p><div id="crayon-5fae0a5d87697749180522" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>SELECT</span><span> </span>*<span> </span><span>FROM</span><span> </span>post</p><p><span>ORDER</span><span> </span><span>BY</span><span> </span>id<span> </span><span>ASC</span></p><p><span>OFFSET</span><span> </span>10</p><p><span>LIMIT</span><span> </span>10</p></div></td></tr></tbody></table></div></div><p>We omit the first ten posts with the above while still getting just ten posts as a result. This gives us elements with ids from 11 to 20.</p><p>If we would like to change the way we order elements while paginating, we need to modify our <span id="crayon-5fae0a5d87699919923694"><span><span>ORDER </span><span>BY</span></span></span> clause.</p><h3>Implementing offset and limit with TypeORM</h3><p>We want the users to provide the offset and the limit through query params. To implement this, let’s use the knowledge we’ve gained in previous parts of this series. This includes the usage of the <span id="crayon-5fae0a5d8769b180466160"><span><span>class</span><span>-</span><span>validator</span></span></span> and the <span id="crayon-5fae0a5d8769d343452497"><span><span>class</span><span>-</span><span>transformer</span></span></span>.</p><div id="crayon-5fae0a5d8769f216044352" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>import</span><span> </span><span>{</span><span> </span><span>IsNumber</span><span>,</span><span> </span><span>Min</span><span>,</span><span> </span><span>IsOptional</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'class-validator'</span><span>;</span></p><p><span>import</span><span> </span><span>{</span><span> </span><span>Type</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'class-transformer'</span><span>;</span></p><p><span>export</span><span> </span><span>class</span><span> </span><span>PaginationParams</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsOptional</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Type</span><span>(</span><span>(</span><span>)</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>Number</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsNumber</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Min</span><span>(</span><span>0</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>offset</span><span>?</span><span>:</span><span> </span><span>number</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsOptional</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Type</span><span>(</span><span>(</span><span>)</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>Number</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsNumber</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Min</span><span>(</span><span>1</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>limit</span><span>?</span><span>:</span><span> </span><span>number</span><span>;</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><p>We can now use the <span id="crayon-5fae0a5d876a1391249188"><span><span>@</span><span>Query</span><span>(</span><span>)</span></span></span> decorator to inject the above parameters into our controller.</p><div id="crayon-5fae0a5d876a3904639621" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p></div></td><td><div><p><span>import</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>Controller</span><span>,</span></p><p><span>&nbsp;&nbsp;</span><span>Get</span><span>,</span></p><p><span>&nbsp;&nbsp;</span><span>UseInterceptors</span><span>,</span></p><p><span>&nbsp;&nbsp;</span><span>ClassSerializerInterceptor</span><span>,</span></p><p><span>&nbsp;&nbsp;</span><span>Query</span><span>,</span></p><p><span>}</span><span> </span><span>from</span><span> </span><span>'@nestjs/common'</span><span>;</span></p><p><span>import </span><span>PostsService </span><span>from</span><span> </span><span>'./posts.service'</span><span>;</span></p><p><span>import</span><span> </span><span>{</span><span> </span><span>PaginationParams</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'../utils/types/paginationParams'</span><span>;</span></p><p><span>@</span><span>Controller</span><span>(</span><span>'posts'</span><span>)</span></p><p><span>@</span><span>UseInterceptors</span><span>(</span><span>ClassSerializerInterceptor</span><span>)</span></p><p><span>export</span><span> </span><span>default</span><span> </span><span>class</span><span> </span><span>PostsController</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>constructor</span><span>(</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>private</span><span> </span><span>readonly </span><span>postsService</span><span>:</span><span> </span><span>PostsService</span></p><p><span>&nbsp;&nbsp;</span><span>)</span><span> </span><span>{</span><span>}</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Get</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>async </span><span>getPosts</span><span>(</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>@</span><span>Query</span><span>(</span><span>'search'</span><span>)</span><span> </span><span>search</span><span>:</span><span> </span><span>string</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>@</span><span>Query</span><span>(</span><span>)</span><span> </span><span>{</span><span> </span><span>offset</span><span>,</span><span> </span><span>limit</span><span> </span><span>}</span><span>:</span><span> </span><span>PaginationParams</span></p><p><span>&nbsp;&nbsp;</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>if</span><span> </span><span>(</span><span>search</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>this</span><span>.</span><span>postsService</span><span>.</span><span>searchForPosts</span><span>(</span><span>search</span><span>,</span><span> </span><span>offset</span><span>,</span><span> </span><span>limit</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>this</span><span>.</span><span>postsService</span><span>.</span><span>getAllPosts</span><span>(</span><span>offset</span><span>,</span><span> </span><span>limit</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;</span><span>// ...</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><p>Implementing offset-based pagination is very easy with TypeORM. Aside from returning an array of posts, we also want to return a number of them. Thanks to that, our frontend can estimate the number of pages available.</p><p>Although we could use the <span id="crayon-5fae0a5d876a5136177191"><span><span>postsRepository</span><span>.</span><span>count</span><span>(</span><span>)</span></span></span> and <span id="crayon-5fae0a5d876a7385402521"><span><span>postsRepository</span><span>.</span><span>find</span><span>(</span><span>)</span></span></span> methods separately, this would result in making two queries to the database. We can improve that by using <span id="crayon-5fae0a5d876ab432160896"><span><span>postsRepository</span><span>.</span><span>findAndCount</span></span></span>.</p><div id="crayon-5fae0a5d876ad836403912" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>async </span><span>getAllPosts</span><span>(</span><span>offset</span><span>?</span><span>:</span><span> </span><span>number</span><span>,</span><span> </span><span>limit</span><span>?</span><span>:</span><span> </span><span>number</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> </span><span>[</span><span>items</span><span>,</span><span> </span><span>count</span><span>]</span><span> </span><span>=</span><span> </span><span>await </span><span>this</span><span>.</span><span>postsRepository</span><span>.</span><span>findAndCount</span><span>(</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>relations</span><span>:</span><span> </span><span>[</span><span>'author'</span><span>]</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>order</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>id</span><span>:</span><span> </span><span>'ASC'</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>skip</span><span>:</span><span> </span><span>offset</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>take</span><span>:</span><span> </span><span>limit</span></p><p><span>&nbsp;&nbsp;</span><span>}</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>return</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>items</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>count</span></p><p><span>&nbsp;&nbsp;</span><span>}</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><h3>Implementing offset and limit with Elasticsearch</h3><p>In <a href="https://wanago.io/2020/09/07/api-nestjs-elasticsearch/">one of the previous parts of this series</a>, we’ve integrated our posts with Elasticsearch. Fortunately, it is effortless to add the offset-based pagination to it. We need to pass the additional <span id="crayon-5fae0a5d876af585611642"><span><span>offset</span></span></span> and <span id="crayon-5fae0a5d876b1582916924"><span><span>size</span></span></span> parameters.</p><div id="crayon-5fae0a5d876b3343966109" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p></div></td><td><div><p><span>async </span><span>search</span><span>(</span><span>text</span><span>:</span><span> </span><span>string</span><span>,</span><span> </span><span>offset</span><span>?</span><span>:</span><span> </span><span>number</span><span>,</span><span> </span><span>limit</span><span>?</span><span>:</span><span> </span><span>number</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> </span><span>{</span><span> </span><span>body</span><span> </span><span>}</span><span> </span><span>=</span><span> </span><span>await </span><span>this</span><span>.</span><span>elasticsearchService</span><span>.</span><span>search</span><span>&lt;</span><span>PostSearchResult</span><span>&gt;</span><span>(</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>index</span><span>:</span><span> </span><span>this</span><span>.</span><span>index</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>from</span><span>:</span><span> </span><span>offset</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>size</span><span>:</span><span> </span><span>limit</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>body</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>query</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>multi_match</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>query</span><span>:</span><span> </span><span>text</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>fields</span><span>:</span><span> </span><span>[</span><span>'title'</span><span>,</span><span> </span><span>'paragraphs'</span><span>]</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>sort</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>id</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>order</span><span>:</span><span> </span><span>'asc'</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;</span><span>}</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> </span><span>count</span><span> </span><span>=</span><span> </span><span>body</span><span>.</span><span>hits</span><span>.</span><span>total</span><span>.</span><span>value</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> </span><span>hits</span><span> </span><span>=</span><span> </span><span>body</span><span>.</span><span>hits</span><span>.</span><span>hits</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> </span><span>results</span><span> </span><span>=</span><span> </span><span>hits</span><span>.</span><span>map</span><span>(</span><span>(</span><span>item</span><span>)</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>item</span><span>.</span><span>_source</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>return</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>count</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>results</span></p><p><span>&nbsp;&nbsp;</span><span>}</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><h3>Disadvantages</h3><p>The solution with offset and limit seems to be the most widely used. Unfortunately, its performance might fall short of our expectations.</p><p>An essential thing to keep in mind is that the database still needs to compute the rows skipped by the <span id="crayon-5fae0a5d876b5872625941"><span><span>OFFSET</span></span></span>. First, the database sorts all of the rows according to our <span id="crayon-5fae0a5d876b7875979790"><span><span>ORDER </span><span>BY</span></span></span> clause. Then, Postgres drops the number of rows specified in the <span id="crayon-5fae0a5d876b9663351751"><span><span>OFFSET</span></span></span>. This might require quite a bit of work.</p><p>Aside from the performance, another important thing to consider is consistency. We want an element to appear in the results exactly once. Let’s imagine the following situation:</p><ol><li>one user fetches page number one with posts</li><li>meanwhile, the second user creates a new post – after sorting, it ends up on page number one</li><li>the first user fetches the second page</li></ol><p>The last element of the first page is now again seen on the second page because of the above. What’s even worse, the user missed the element that has been added to the first page.</p><h3>Advantages</h3><p>While the offset approach has its cons, it is still common. Due to its simplicity, it is straightforward to implement. Also, it is easy to change the column that we use for sorting, including the usage of multiple columns. Because of that, it is a viable solution in many cases. Especially if the offset is expected not to be big, and the result inconsistencies are acceptable.</p><h2>Keyset pagination</h2><p>While the offset-based pagination can be useful, its performance might not be the best. Sometimes we might want to avoid it.</p><p>One of the ways to do so is to implement keyset pagination. Instead of using the <span id="crayon-5fae0a5d876bb574955228"><span><span>OFFSET</span></span></span> clause, we use the <span id="crayon-5fae0a5d876bd582481924"><span><span>WHERE</span></span></span> command to select the data we haven’t fetched yet.</p><p>Let’s start with a simple query:</p><div id="crayon-5fae0a5d876bf185206021" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>SELECT</span><span> </span><span>*</span><span> </span><span>FROM </span><span>post</span></p><p><span>ORDER </span><span>BY </span><span>id </span><span>ASC</span></p><p><span>LIMIT</span><span> </span><span>10</span></p></div></td></tr></tbody></table></div></div><p>The above query gets us the first ten posts. Let’s assume that the id of the last post was&nbsp;<strong>20</strong>. With this assumption, we can run this query:</p><div id="crayon-5fae0a5d876c1524274213" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>SELECT</span><span> </span><span>*</span><span> </span><span>FROM </span><span>post</span></p><p><span>WHERE </span><span>id</span><span> </span><span>&gt;</span><span> </span><span>20</span></p><p><span>ORDER </span><span>BY </span><span>id </span><span>ASC</span></p><p><span>LIMIT</span><span> </span><span>10</span></p></div></td></tr></tbody></table></div></div><p>The above query gets us ten posts with id bigger than 20. Now, we can take the last post and rerun the query, changing the id. Doing that creates us simple and efficient pagination mechanism.</p><p>This exposes the biggest drawback of the keyset pagination, though. To get a page, we need to know the last element of the previous set of results. This makes traversing multiple pages at once impossible.</p><p>Fortunately, most of the time, the users got straight to the next page. To cover all of the cases, we can implement both the offset-based approach and the keyset pagination.</p><p>If we would like to change the column that we order our elements by, we need to change both the <span id="crayon-5fae0a5d876c3483158102"><span><span>ORDER </span><span>BY</span></span></span> and <span id="crayon-5fae0a5d876c6003224388"><span><span>WHERE</span></span></span> clauses.</p><h3>Implementing keyset pagination with TypeORM</h3><p>Adding keyset pagination is not difficult with TypeORM. First, let’s add another query parameter called <span id="crayon-5fae0a5d876c8758068407"><span><span>startId</span></span></span>&nbsp;to our <span id="crayon-5fae0a5d876ca183148067"><span><span>PaginationParams</span></span></span>.</p><div id="crayon-5fae0a5d876cc422222851" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p></div></td><td><div><p><span>import</span><span> </span><span>{</span><span> </span><span>IsNumber</span><span>,</span><span> </span><span>Min</span><span>,</span><span> </span><span>IsOptional</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'class-validator'</span><span>;</span></p><p><span>import</span><span> </span><span>{</span><span> </span><span>Type</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'class-transformer'</span><span>;</span></p><p><span>export</span><span> </span><span>class</span><span> </span><span>PaginationParams</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsOptional</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Type</span><span>(</span><span>(</span><span>)</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>Number</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsNumber</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Min</span><span>(</span><span>1</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>startId</span><span>?</span><span>:</span><span> </span><span>number</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsOptional</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Type</span><span>(</span><span>(</span><span>)</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>Number</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsNumber</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Min</span><span>(</span><span>0</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>offset</span><span>?</span><span>:</span><span> </span><span>number</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsOptional</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Type</span><span>(</span><span>(</span><span>)</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>Number</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>IsNumber</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>@</span><span>Min</span><span>(</span><span>1</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>limit</span><span>?</span><span>:</span><span> </span><span>number</span><span>;</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><p>Along the way, we will face a small issue with the count of our elements. The <span id="crayon-5fae0a5d876ce386610868"><span><span>postsRepository</span><span>.</span><span>findAndCount</span></span></span> with a <span id="crayon-5fae0a5d876d0604656805"><span><span>WHERE</span></span></span> clause will return only the number of matching posts. We need to count them separately.</p><div id="crayon-5fae0a5d876d2124735725" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p></div></td><td><div><p><span>async </span><span>getAllPosts</span><span>(</span><span>offset</span><span>?</span><span>:</span><span> </span><span>number</span><span>,</span><span> </span><span>limit</span><span>?</span><span>:</span><span> </span><span>number</span><span>,</span><span> </span><span>startId</span><span>?</span><span>:</span><span> </span><span>number</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> where:</span><span> </span><span>FindManyOptions</span><span>&lt;</span><span>Post</span><span>&gt;</span><span>[</span><span>'where'</span><span>]</span><span> </span><span>=</span><span> </span><span>{</span><span>}</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>let </span><span>separateCount</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>if</span><span> </span><span>(</span><span>startId</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>where</span><span>.</span><span>id</span><span> </span><span>=</span><span> </span><span>MoreThan</span><span>(</span><span>startId</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>separateCount</span><span> </span><span>=</span><span> </span><span>await </span><span>this</span><span>.</span><span>postsRepository</span><span>.</span><span>count</span><span>(</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> </span><span>[</span><span>items</span><span>,</span><span> </span><span>count</span><span>]</span><span> </span><span>=</span><span> </span><span>await </span><span>this</span><span>.</span><span>postsRepository</span><span>.</span><span>findAndCount</span><span>(</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>where</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>relations</span><span>:</span><span> </span><span>[</span><span>'author'</span><span>]</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>order</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>id</span><span>:</span><span> </span><span>'ASC'</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>skip</span><span>:</span><span> </span><span>offset</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>take</span><span>:</span><span> </span><span>limit</span></p><p><span>&nbsp;&nbsp;</span><span>}</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>return</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>items</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>count</span><span>:</span><span> </span><span>startId</span><span> </span><span>?</span><span> </span><span>separateCount</span><span> </span><span>:</span><span> </span><span>count</span></p><p><span>&nbsp;&nbsp;</span><span>}</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><h3>Implementing keyset pagination with Elasticsearch</h3><p>We can also achieve the above result with Elasticsearch by adding the id of a post to our query.</p><p>In this very simple example, we separately count the matching posts. If you feel like using other pagination approaches due to performance reasons, Elasticsearch has <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html">other built-in methods of pagination</a>.</p><div id="crayon-5fae0a5d876d4207477620" data-settings=" no-popup minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="show"></td><td><div><p><span>async </span><span>count</span><span>(</span><span>query</span><span>:</span><span> </span><span>string</span><span>,</span><span> </span><span>fields</span><span>:</span><span> </span><span>string</span><span>[</span><span>]</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>const</span><span> </span><span>{</span><span> </span><span>body</span><span> </span><span>}</span><span> </span><span>=</span><span> </span><span>await </span><span>this</span><span>.</span><span>elasticsearchService</span><span>.</span><span>count</span><span>&lt;</span><span>PostCountResult</span><span>&gt;</span><span>(</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>index</span><span>:</span><span> </span><span>this</span><span>.</span><span>index</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>body</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>query</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>multi_match</span><span>:</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>query</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>fields</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;…</span></p></div></td></tr></tbody></table></div></div></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wanago.io/2020/11/09/api-nestjs-offset-keyset-pagination-postgresql-typeorm/">https://wanago.io/2020/11/09/api-nestjs-offset-keyset-pagination-postgresql-typeorm/</a></em></p>]]>
            </description>
            <link>https://wanago.io/2020/11/09/api-nestjs-offset-keyset-pagination-postgresql-typeorm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25038192</guid>
            <pubDate>Mon, 09 Nov 2020 18:51:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A hidden gem in sound symmetry]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25037784">thread link</a>) | @gbh444g
<br/>
November 9, 2020 | https://soundshader.github.io/hn/acf/index.html | <a href="https://web.archive.org/web/*/https://soundshader.github.io/hn/acf/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<blockquote>
  <p><em><a href="https://pages.mtu.edu/~suits/autocorrelation.html">Autocorrelation</a> is used to compare a signal with a time-delayed version of itself. If a signal is periodic, then the signal will be perfectly correlated with a version of itself if the time-delay is an integer number of periods. That fact, along with related experiments, has implicated autocorrelation as a potentially important part of signal processing in human hearing.</em></p>
</blockquote>

<p>ACF is a simple method to visualize music that produces surprisingly good results. Perhaps the most unexpected property of ACF is that it accurately transfers the subjective “harmony level” from music to images. It’s almost an unreasonable property, if you think about it. Images below are ACF height maps in polar coordinates.</p>

<table>
  <thead>
    <tr>
      <th>Female vocal</th>
      <th>David Parsons</th>
      <th>Piano</th>
      <th>Bird</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="https://soundshader.github.io/pics/song-2.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/bowl-3.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/piano-p.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/bird-2.jpg" alt=""></td>
    </tr>
  </tbody>
</table>

<p>More examples: <a href="https://soundshader.github.io/gallery/">soundshader.github.io/gallery</a> (beware of large images).</p>

<p>Live demo: <a href="https://soundshader.github.io/">soundshader.github.io</a></p>



<p>Contrary to what you might think, our ears don’t seem to rely on an FFT-like process to extract isolated frequencies. Instead, our ears detect periodic parts in the signal, although in most cases those periodic parts closely match the FFT frequencies. There is a simple <a href="https://auditoryneuroscience.com/pitch/missing-fundamental-stimuli">experiment</a> that proves this point:</p>

<p><img src="https://auditoryneuroscience.com/sites/default/files/missingFundamental2.png" alt=""></p>

<p>As can be clearly seen on the FFT image, the A signal is a pure sinusoidal tone, while B is a mix of tones. Despite each tone in B is higher than A, our ears perceive B as a lower tone. If we plot both waveforms, we’ll see that A has about 9 peaks in a 20 ms window, while B has only 5. The definition of “peak” is moot, but it doesn’t stop our ears from counting them and using the “number of peaks per second” as a proxy to the tone height.</p>

<p>ACF detects those peaks. ACF sees that there are 5 equally spaced time shifts where <code>B[t] * B[t + shift]</code> reaches the maximum, so on the ACF output we’ll see those 5 peaks.</p>

<blockquote>
  <p>Given that I’ve shamelessly stolen the experiment’s illustration above, I feel obligated to recommend the book where the illustration came from: <a href="https://auditoryneuroscience.com/book-preview">Auditory Neuroscience</a>.</p>
</blockquote>

<p>One downside of ACF is that it drops the phase component of the input signal, and thus ACF is not reversible. This means that images that only render ACF, lose about 50% of the information from the sound and those 50% are important, e.g. dropping the phase from recorded speech makes that speech indiscernible. Real world sounds, such as voice, heavily use nuanced amplitude and phase modulation. ACF captures the former, but ignores the latter.</p>



<p>ACF of a sound sample <code>X[0..N-1]</code> can be computed with two FFTs:</p>

<div><div><pre><code>S = |FFT[X]|^2
ACF[X] = FFT[S]
</code></pre></div></div>

<p>And thus ACF contains exactly the same information as the spectral density <code>S</code> (the well known spectrogram).</p>

<blockquote>
  <p>If you’re familiar with the ACF definition, you’ll notice that I should’ve used the inverse FFT in the last step. There is no mistake. The inverse FFT can be computed as <code>FFT[X*]*</code>, where <code>X*</code> is complex conjugate, but since <code>S[i]</code> is real-valued (and positive, in fact), the conjugate has no effect on it, and since ACF is also real valued in this case, the second conjugate has no effect either.</p>
</blockquote>

<p>ACF is a periodic and even function and so it can be naturally rendered in polar coordinates. In most cases, ACF has a very elaborate structure. Below are some examples, where red = ACF &gt; 0 and blue = ACF &lt; 0.</p>

<table>
  <thead>
    <tr>
      <th>conventional music</th>
      <th>a bird song</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="https://soundshader.github.io/pics/acf-c-1.jpg" alt=""></td>
      <td><img src="https://soundshader.github.io/pics/acf-c-3.jpg" alt=""></td>
    </tr>
  </tbody>
</table>

<p>Looking at the first example, we can tell that there are 5 prominent peaks in a 20 ms sound sample, which corresponds to 250 Hz. This means that our ears would necesserarily perceive this sound as a 250 Hz tone, regardless of what its spectrogram says. If it was a pure 250 Hz tone, we’d see perfectly round shapes of the <code>r = cos(250Hz * t)</code> line, but it’s not the case here: we see that the 5 peaks are modulated with small wavelets: there is one big wavelet in the middle (which consists of 3 smaller wavelets) and 4 smaller wavelets. Our ears would hear the big wavelet as the 2nd harmonic of the 250 Hz tone (i.e. it would be a 500 Hz tone with a smaller amplitude) and the 4 small wavelets as the 5th harmonic (1000 Hz) at barely discernible volume. In addition to that, the 500 Hz harmonic is also modulated by the 3 tiny wavelets, which means we’d hear a 1500 Hz tone, almost inaudible. We can say all this without even looking at the spectrogram or hearing the sound.</p>



<p>Music is a temporal ornament. There are many types of ornaments, e.g. the 17 types of wallpaper tesselations, but few of them look like music. However there is one particular type of ornament that resembles music a lot - I mean those “mandala” images. I don’t know how and why those are produced, but I noticed a connection between those images and music:</p>

<ul>
  <li>The 1st obvious observation is that a mandala is drawn in polar coordinates and is <code>2*PI</code> periodic. Sound is periodic too, so I thought the two facts are related.</li>
  <li>The 2nd observation is that patterns on those images evolve over the radial axis. Ans so is music is a sequence of evolving sound patterns.</li>
  <li>The 3rd observation is that a <code>2*PI</code> periodic function trivially corresponds to a set of frequencies. We usually use FFT to extract the frequencies and another FFT to restore the <code>2*PI</code> periodic function. Thus, a single radial slice of a mandala could encode a set of frequencies. If this is correct, a mandala is effectively an old school vinyl disk.</li>
</ul>

<p>Putting these observations together we naturally arrive with the ACF idea.</p>



<p>Open an issue on github or shoot me a email at ssgh@aikh.org</p>



<p>AGPLv3</p>


      
    </div></div>]]>
            </description>
            <link>https://soundshader.github.io/hn/acf/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037784</guid>
            <pubDate>Mon, 09 Nov 2020 18:19:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is it Pokemon or Big Data? (2016)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25037755">thread link</a>) | @boogies
<br/>
November 9, 2020 | https://pixelastic.github.io/pokemonorbigdata/ | <a href="https://web.archive.org/web/*/https://pixelastic.github.io/pokemonorbigdata/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    
    
    
    
    
    
    
    
    <p>
      Made by <a href="https://twitter.com/pixelastic/">@pixelastic</a>, 
      inspired by <a href="https://docs.google.com/forms/d/1kckcq_uv8dk9-W5rIdtqRwCHN4Uh209ELPUjTEZJDxc/viewform">this google form</a>.
    </p>
  


</div>]]>
            </description>
            <link>https://pixelastic.github.io/pokemonorbigdata/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037755</guid>
            <pubDate>Mon, 09 Nov 2020 18:17:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Illustrated Guide to Superlearning]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25037740">thread link</a>) | @prostoalex
<br/>
November 9, 2020 | https://www.khstats.com/blog/sl/superlearning/ | <a href="https://web.archive.org/web/*/https://www.khstats.com/blog/sl/superlearning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      


<blockquote>
<p>Why use <em>one</em> machine learning algorithm when you could use all of them?! This post contains a step-by-step walkthrough of how to build a superlearner prediction algorithm in <code>R</code>.</p>
</blockquote>


<title>
HTML Image as link
</title>


<p><img alt="cheatsheet" src="https://www.khstats.com/img/Superlearning.jpg" width="100%&quot;"></p><figcaption>
<strong><em>A Visual Guide…</em></strong> Over the winter, I read <a href="https://www.springer.com/gp/book/9781441997814"><em>Targeted Learning</em></a> by Mark van der Laan and Sherri Rose. This “visual guide” I made for <em>Chapter 3: Superlearning</em> by Rose, van der Laan, and Eric Polley is a condensed version of the following tutorial. It is available as an <a href="https://github.com/hoffmakl/CI-visual-guides/blob/master/visual-guides/Superlearner.pdf">8.5x11" pdf on Github</a>, should you wish to print it out for reference (or desk decor).
</figcaption>



<div id="supercuts-of-superlearning">

<ul>
<li><p><strong>Superlearning</strong> is a technique for prediction that involves <strong>combining many individual statistical algorithms</strong> (commonly called “data-adaptive” or “machine learning” algorithms) to <strong>create a new, single prediction algorithm</strong> that is expected to <strong>perform at least as well as any of the individual algorithms</strong>.</p></li>
<li><p>The superlearner algorithm “decides” how to combine, or weight, the individual algorithms based upon how well each one <strong>minimizes a specified loss function</strong>, for example, the mean squared error (MSE). This is done using cross-validation to avoid overfitting.</p></li>
<li><p>The motivation for this type of “ensembling” is that <strong>a mix of multiple algorithms may be more optimal for a given data set than any single algorithm</strong>. For example, a tree based model averaged with a linear model (e.g.&nbsp;random forests and LASSO) could smooth some of the model’s edges to improve predictive performance.</p></li>
<li><p>Superlearning is also called stacking, stacked generalizations, and weighted ensembling by different specializations within the realms of statistics and data science.</p></li>
</ul>
<p><img src="https://www.khstats.com/img/spiderman_meme.jpg"></p>
</div>
<div id="superlearning-step-by-step">

<p>First I’ll go through the algorithm one step at a time using a simulated data set.</p>
<div id="initial-set-up-load-libraries-set-seed-simulate-data">
<h2>Initial set-up: Load libraries, set seed, simulate data</h2>
<p>For simplicity I’ll show the concept of superlearning using only four variables (AKA features or predictors) to predict a continuous outcome. Let’s first simulate a continuous outcome, <code>y</code>, and four potential predictors, <code>x1</code>, <code>x2</code>, <code>x3</code>, and <code>x4</code>.</p>
<pre><code>library(tidyverse)
library(knitr)
set.seed(7)</code></pre>
<pre><code>n &lt;- 5000
obs &lt;- tibble(
  id = 1:n,
  x1 = rnorm(n),
  x2 = rbinom(n, 1, plogis(10*x1)),
  x3 = rbinom(n, 1, plogis(x1*x2 + .5*x2)),
  x4 = rnorm(n, mean=x1*x2, sd=.5*x3),
  y = x1 + x2 + x2*x3 + sin(x4)
)
kable(head(obs), digits=3, caption = "Simulated data set")</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-2">Table 1: </span>Simulated data set</caption>
<thead>
<tr>
<th>id</th>
<th>x1</th>
<th>x2</th>
<th>x3</th>
<th>x4</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2.287</td>
<td>1</td>
<td>1</td>
<td>1.385</td>
<td>5.270</td>
</tr>
<tr>
<td>2</td>
<td>-1.197</td>
<td>0</td>
<td>0</td>
<td>0.000</td>
<td>-1.197</td>
</tr>
<tr>
<td>3</td>
<td>-0.694</td>
<td>0</td>
<td>0</td>
<td>0.000</td>
<td>-0.694</td>
</tr>
<tr>
<td>4</td>
<td>-0.412</td>
<td>0</td>
<td>1</td>
<td>-0.541</td>
<td>-0.928</td>
</tr>
<tr>
<td>5</td>
<td>-0.971</td>
<td>0</td>
<td>0</td>
<td>0.000</td>
<td>-0.971</td>
</tr>
<tr>
<td>6</td>
<td>-0.947</td>
<td>0</td>
<td>1</td>
<td>-0.160</td>
<td>-1.107</td>
</tr>
</tbody>
</table>


<h2>
<strong>Step 1: Split data into K folds
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step1.png">
The superlearner algorithm relies on K-fold cross-validation (CV) to avoid overfitting. We will start this process by splitting the data into 10 folds. The easiest way to do this is by creating indices for each CV fold.</p>
<pre><code>k &lt;- 10 # 10 fold cv
cv_index &lt;- sample(rep(1:k, each = n/k)) # create indices for each CV fold. We need each fold K to contain n (all the rows of our data set) divided by k rows. in our example this is 5000/10 = 500 rows in each fold</code></pre>


<h2>
<strong>Step 2: Fit base learners for first CV-fold
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step2.png"></p>
<p>Recall that in K-fold CV, each fold serves as the validation set one time. In this first round of CV, we will train all of our base learners on all the CV folds (k = 1,2,…,9) <em>except</em> for the very last one: <code>cv_index == 10</code>.</p>
<p>The individual algorithms or <strong>base learners</strong> that we’ll use here are three linear regressions with differently specified parameters:</p>
<ol>
<li><p><strong>Learner A</strong>: <span>\(Y=\beta_0 + \beta_1 X_2 + \beta_2 X_4 + \epsilon\)</span></p></li>
<li><p><strong>Learner B</strong>: <span>\(Y=\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_3 + \beta_4 sin(X_4) + \epsilon\)</span></p></li>
<li><p><strong>Learner C</strong>: <span>\(Y=\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \beta_4 X_1 X_2 + \beta_5 X_1 X_3 + \beta_6 X_2 X_3 + \beta_7 X_1 X_2 X_3 + \epsilon\)</span></p></li>
</ol>
<pre><code>cv_train_1 &lt;- obs[-which(cv_index == 10),] # make a data set that contains all observations except those in k=1
fit_1a &lt;- glm(y ~ x2 + x4, data=cv_train_1) # fit the first linear regression on that training data
fit_1b &lt;- glm(y ~ x1 + x2 + x1*x3 + sin(x4), data=cv_train_1) # second LR fit on the training data
fit_1c &lt;- glm(y ~ x1*x2*x3, data=cv_train_1) # and the third LR</code></pre>
<p>I am <em>only</em> using the linear regressions so that code for running more complicated regressions does not take away from understanding the general superlearning algorithm.</p>
<p>Superlearning actually works best if you use a diverse set, or <strong>superlearner library</strong>, of base learners. For example, instead of three linear regressions, we could use a least absolute shrinkage estimator (LASSO), random forest, and multivariate adaptive splines (MARS). Any parametric or non-parametric supervised machine learning algorithm can be included as a base learner.</p>


<h2>
<strong>Step 3: Obtain predictions for first CV-fold
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step3.png"></p>
<p>We can then get use our validation data, <code>cv_index == 10</code>, to obtain our first set of cross-validated predictions.</p>
<pre><code>cv_valid_1 &lt;- obs[which(cv_index == 10),] # make a data set that only contains observations except in k=10
pred_1a &lt;- predict(fit_1a, newdata = cv_valid_1) # use that data set as the validation for all the models in the SL library
pred_1b &lt;- predict(fit_1b, newdata = cv_valid_1) 
pred_1c &lt;- predict(fit_1c, newdata = cv_valid_1)</code></pre>
<p>Since we have 5000 <code>obs</code>ervations, that gives us three vectors of length 500: a set of predictions for each of our Learners A, B, and C.</p>
<pre><code>length(pred_1a) # double check we only have n/k predictions ...we do :-)</code></pre>
<pre><code>## [1] 500</code></pre>
<pre><code>knitr::kable(head(cbind(pred_1a, pred_1b, pred_1c)), digits= 2, caption = "First CV round of predictions") </code></pre>
<table>
<caption><span id="tab:unnamed-chunk-6">Table 2: </span>First CV round of predictions</caption>
<thead>
<tr>
<th>pred_1a</th>
<th>pred_1b</th>
<th>pred_1c</th>
</tr>
</thead>
<tbody>
<tr>
<td>-1.39</td>
<td>-0.77</td>
<td>-0.40</td>
</tr>
<tr>
<td>-1.27</td>
<td>-0.34</td>
<td>-0.11</td>
</tr>
<tr>
<td>2.16</td>
<td>1.32</td>
<td>1.10</td>
</tr>
<tr>
<td>4.27</td>
<td>4.26</td>
<td>3.98</td>
</tr>
<tr>
<td>3.31</td>
<td>3.98</td>
<td>3.78</td>
</tr>
<tr>
<td>2.29</td>
<td>2.42</td>
<td>2.83</td>
</tr>
</tbody>
</table>


<h2>
<strong>Step 4: Obtain CV predictions for entire data set
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step4.png"></p>
<p>We’ll want to get those predictions for <em>every</em> fold. So, using your favorite <code>for</code> loop, <code>apply</code> statement, or <code>map</code>ping function, fit the base learners and obtain predictions for each of them, so that there are 1000 predictions – one for every point in <code>obs</code>ervations.</p>
<p>The way I chose to code this was to make a generic function that combines Step 2 (base learners fit to the training data) and Step 3 (predictions on the validation data), then use <code>map_dfr()</code> from the <code>purrr</code> package to repeat over all 10 CV folds. I saved the results in a new data frame called <code>cv_preds</code>.</p>
<pre><code>cv_folds &lt;- as.list(1:k)
names(cv_folds) &lt;- paste0("fold",1:k)

get_preds &lt;- function(fold){   # function that does the same procedure as step 2 and 3 for any CV fold
  cv_train &lt;- obs[-which(cv_index == fold),]  # make a training data set that contains all data except fold k
  fit_a &lt;- glm(y ~ x2 + x4, data=cv_train)  # fit all the base learners to that data
  fit_b &lt;- glm(y ~ x1 + x2 + x1*x3 + sin(x4), data=cv_train)
  fit_c &lt;- glm(y ~ x1*x2*x3, data=cv_train)
  cv_valid &lt;- obs[which(cv_index == fold),]  # make a validation data set that only contains data from fold k
  pred_a &lt;- predict(fit_a, newdata = cv_valid)  # obtain predictions from all the base learners for that validation data
  pred_b &lt;- predict(fit_b, newdata = cv_valid)
  pred_c &lt;- predict(fit_c, newdata = cv_valid)
  return(data.frame("obs_id" = cv_valid$id, "cv_fold" = fold, pred_a, pred_b, pred_c))  # save the predictions and the ids of the observations in a data frame
}

cv_preds &lt;- purrr::map_dfr(cv_folds, ~get_preds(fold = .x)) # map_dfr loops through every fold (1:k) and binds the rows of the listed results together

cv_preds %&gt;% arrange(obs_id) %&gt;% head() %&gt;% kable(digits=2, caption = "All CV predictions for all three base learners") </code></pre>
<table>
<caption><span id="tab:unnamed-chunk-7">Table 3: </span>All CV predictions for all three base learners</caption>
<thead>
<tr>
<th></th>
<th>obs_id</th>
<th>cv_fold</th>
<th>pred_a</th>
<th>pred_b</th>
<th>pred_c</th>
</tr>
</thead>
<tbody>
<tr>
<td>1…1</td>
<td>1</td>
<td>4</td>
<td>3.73</td>
<td>5.42</td>
<td>5.28</td>
</tr>
<tr>
<td>1…2</td>
<td>2</td>
<td>8</td>
<td>-0.77</td>
<td>-1.19</td>
<td>-1.20</td>
</tr>
<tr>
<td>1…3</td>
<td>3</td>
<td>2</td>
<td>-0.78</td>
<td>-0.81</td>
<td>-0.69</td>
</tr>
<tr>
<td>1…4</td>
<td>4</td>
<td>10</td>
<td>-1.39</td>
<td>-0.77</td>
<td>-0.40</td>
</tr>
<tr>
<td>1…5</td>
<td>5</td>
<td>6</td>
<td>-0.78</td>
<td>-1.01</td>
<td>-0.97</td>
</tr>
<tr>
<td>1…6</td>
<td>6</td>
<td>7</td>
<td>-0.96</td>
<td>-1.04</td>
<td>-0.94</td>
</tr>
</tbody>
</table>


<h2>
<strong>Step 5: Choose and compute loss function of interest via metalearner
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step5.png"></p>
<blockquote>
<p>This is the key step of the superlearner algorithm: we will use a new learner, a <strong>metalearner</strong>, to take information from all of the base learners and create that new algorithm.</p>
</blockquote>
<p>Now that we have cross-validated predictions for every observation in the data set, we want to merge those CV predictions back into our main data set…</p>
<pre><code>obs_preds &lt;- 
  full_join(obs, cv_preds, by=c("id" = "obs_id"))</code></pre>
<p>…so that we can minimize a final loss function of interest between the true outcome and each CV prediction. This is how we’re going to optimize our overall prediction algorithm: we want to make sure we’re “losing the least” in the way we combine our base learners’ predictions to ultimately make final predictions. We can do this efficiently by choosing a new learner, a metalearner, which reflects the final loss function of interest.</p>
<p>For simplicity, we’ll use another linear regression as our metalearner. Using a linear regression as a metalearner will minimize the Cross-Validated Mean Squared Error (CV-MSE) when combining the base learner predictions. Note that we could use a variety of parametric or non-parametric regressions to minimize the CV-MSE.</p>
<p>No matter what metalearner we choose, the predictors will always be the cross-validated predictions from each base learner, and the outcome will always be the true outcome, <code>y</code>.</p>
<pre><code>sl_fit &lt;- glm(y ~ pred_a + pred_b + pred_c, data = obs_preds)
kable(broom::tidy(sl_fit), digits=3, caption = "Metalearner regression coefficients") </code></pre>
<table>
<caption><span id="tab:unnamed-chunk-9">Table 4: </span>Metalearner regression coefficients</caption>
<thead>
<tr>
<th>term</th>
<th>estimate</th>
<th>std.error</th>
<th>statistic</th>
<th>p.value</th>
</tr>
</thead>
<tbody>
<tr>
<td>(Intercept)</td>
<td>-0.003</td>
<td>0.002</td>
<td>-1.447</td>
<td>0.148</td>
</tr>
<tr>
<td>pred_a</td>
<td>-0.017</td>
<td>0.004</td>
<td>-4.739</td>
<td>0.000</td>
</tr>
<tr>
<td>pred_b</td>
<td>0.854</td>
<td>0.007</td>
<td>128.241</td>
<td>0.000</td>
</tr>
<tr>
<td>pred_c</td>
<td>0.165</td>
<td>0.005</td>
<td>30.103</td>
<td>0.000</td>
</tr>
</tbody>
</table>
<p>This metalearner provides us with the coefficients, or weights, to apply to each of the base learners. In other words, if we have a set of predictions from Learner A, B, and C, we can obtain our best possible predictions by starting with an intercept of -0.003, then adding -0.017 <span>\(\times\)</span> predictions from Learner A, 0.854 <span>\(\times\)</span> predictions from Learner B, and 0.165 <span>\(\times\)</span> predictions from Learner C.</p>
<p><em>For more information on the metalearning step, check out the <a href="#appendix">Appendix</a>.</em></p>


<h2>
<strong>Step 6: Fit base learners on entire data set
</strong></h2><p><img src="https://www.khstats.com/img/sl_steps/step6.png"></p>
<p>After we fit the metalearner, we officially have our superlearner algorithm, so it’s time to input data and …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.khstats.com/blog/sl/superlearning/">https://www.khstats.com/blog/sl/superlearning/</a></em></p>]]>
            </description>
            <link>https://www.khstats.com/blog/sl/superlearning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037740</guid>
            <pubDate>Mon, 09 Nov 2020 18:16:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust emit=asm Can Be Misleading]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25037663">thread link</a>) | @todsacerdoti
<br/>
November 9, 2020 | https://siliconsprawl.com/2020/11/09/rust-emit-asm.html | <a href="https://web.archive.org/web/*/https://siliconsprawl.com/2020/11/09/rust-emit-asm.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="the-short-version">The short version</h2>

<p>Cargo builds like:</p>
<div><div><pre><code><span>$ RUSTFLAGS</span><span>=</span><span>"--emit asm"</span> cargo build <span>--release</span>
<span>$ </span>cargo rustc <span>--release</span> <span>--</span> <span>--emit</span> asm
</code></pre></div></div>

<p>Do not always output assembly equivalent to the machine code you’d get from:</p>


<p>Possibly <code>rustc --emit=asm</code> has some uses, like examining a single file with
no external dependencies, but it’s not useful for my normal case of wanting
to look at the asm for an arbitrary release build.</p>

<h2 id="the-long-version">The long version</h2>

<p><a href="https://siliconsprawl.com/2020/11/06/simd-ray-tracer.html">Previously</a> I rewrote my ray tracer
to use <code>crossbeam::scope</code> and <code>crossbeam::queue</code> instead of rayon. Internally
rayon leans heavily on <code>crossbeam::deque</code> for its work-stealing implementation, so
my expectation was that this change would be neutral or a slight improvement, 
depending on how good of a job the compiler had been doing to condense
rayon’s abstractions.</p>

<p>Instead it was a ~15% regression.</p>

<h3 id="looking-at-the-asm-pt-1">Looking at the asm, pt. 1</h3>

<p>The asm output appeared sane. I saw no expensive indirection, calls, etc. -
things were getting properly inlined and optimized.</p>

<h3 id="understanding-rayon">Understanding rayon</h3>

<p>I first questioned my understanding of rayon and spent some time digging
through its guts. It’s well-engineered, and it’s impressive that clang’s able
to condense all of its abstractions down into basically no overhead - but I also
didn’t see anything fundamentally novel or surprising going on that would give it a significant performance edge. The
splitting/work assignment portion of the vec codepath looked like it would
lead to slightly more even partitioning than my hand-built crossbeam method,
but not by a lot, and definitely not by 15%. So that was bust. I did notice that
crossbeam needed to heap allocate the closure I was using for my thread body,
so perhaps that caused some additional overhead, but it should have been
negligible.</p>

<h3 id="cpu-profiling">CPU profiling</h3>

<p>At this point I dumped both versions into Instruments and did some basic CPU
profiling. rayon’s a bit annoying to poke around in because you end up with
extremely deep stacks of <code>join</code> frames, but nothing really stood out. The
crossbeam version was simply slower with no major red flags.</p>

<h3 id="more-in-depth-cpu-profiling">More in-depth CPU profiling</h3>

<p>I’d been looking for an excuse to try <a href="https://software.intel.com/content/www/us/en/develop/tools/vtune-profiler.html">Intel
VTune</a>
for awhile, but since it’s only supported on Windows and Linux and is best
run on bare-metal, it had always been slightly too much effort to stand up
for smaller projects. It seemed warranted for this one! I had an existing
Windows bootcamp partition, so figured I’d see just how much hassle it was to
get everything working in that before I dusted off something to run Linux.</p>

<p>Sidebar: turns out Rust on Windows is… really nice. I’m not a Windows dev. There are
things I admire about the ecosystem (like a good first-party
debugger and some decent OS APIs), but apart from some Java way back in high
school I’ve never even tried to compile software on a Windows machine. It
always looked like a nightmare for C/C++ projects - I’m familiar enough with
the code side of cross-platform support, but as for actually
building things… I think cmake can spit out a Visual Studio project? And I
keep hearing about WSL? So I went in with significant trepidation. Turns out
it took all of ten minutes to install the VS C++ tools, rustup, a rust
toolchain, vtune, and get everything building and working together. Pretty
impressive.</p>

<p>VTune itself is a complex beast. Most (all?) of the data in it is stuff you
could get out of <code>perf</code>, but the collection and workflow is streamlined - it
does a good job of keeping track of previous runs, grouping them in a way so
you don’t lose anything, surfacing useful information based on top-level
categories (eg. “I want to look at memory access”), and providing a 
diff view between runs. It looks particularly useful for guiding iterative optimization
and refinement. It’s a bit less useful when I’m comparing the
performance of two fairly different programs, because many of the stack
traces are unique to either the rayon or crossbeam version, so “you have 100%
more of these rayon stack traces in this run” is not helpful. Looking through
the data I saw that I was getting flagged on uarch perf, retiring
instructions maybe 5% worse in the crossbeam version. Thinking that could be
stalling waiting on memory, I ran a memory access profile and saw:</p>

<p><img src="https://siliconsprawl.com/assets/images/rrt/vtune_macc.png" alt=""></p>

<p>Crossbeam version is on the left, rayon version is on the right. Okay, 3s
runtime difference - that’s commensurate with the perf regression I’m seeing.
Interesting, we’re memory bound twice as frequently. That’s strange because
our memory access pattern should be pretty similar. We’re doing over twice as
many stores. We’re doing some additional loads. We’re…</p>

<p>Wait.</p>

<p>We’re doing over twice as many stores?! That doesn’t make sense.</p>

<h3 id="replacing-crossbeamscope">Replacing crossbeam::scope</h3>

<p>Perhaps heap allocating the closures was more expensive than I thought, or
had bad knock-on effects. It’s a long shot, but the whole point of side
projects is following some of those random tangents. I set about eliminating
<code>crossbeam::scope</code> and using <code>std::thread</code> directly instead. This was a quick
and dirty test: the entire point of <code>scope</code> is to create an abstraction that
communicates to the borrow checker that threads we’ve spun off have been
joined, otherwise it doesn’t know when a thread’s borrow is guaranteed to
have ended and requires that data references from a thread’s closure are all
static lifetime. In this case I’m manually joining the threads, so I can do a
transmute to placate the compiler. Don’t ship code like this, it defeats the
purpose of using Rust in the first place - you’d have a better experience
with C++. But it can be really handy to circumvent these sorts of checks when
doing quick prototyping/performance analysis to decide if it’s worth the time
to build out a safe abstraction. I would welcome a “just build this without
the borrow checker” mode for cases like this, though I’m probably in the
minority and I don’t expect that would be an easy feature to add.</p>

<p>My testing code looked roughly like this:</p>
<div><div><pre><code><span>let</span> <span>pixels</span> <span>=</span> <span>unsafe</span> <span>{</span> 
    <span>mem</span><span>::</span><span>transmute</span><span>::</span><span>&lt;&amp;</span><span>mut</span> <span>[</span><span>V3</span><span>],</span> <span>&amp;</span><span>'static</span> <span>mut</span> <span>[</span><span>V3</span><span>]</span><span>&gt;</span><span>(</span><span>pixels</span><span>)</span>
<span>};</span>
<span>let</span> <span>handle</span> <span>=</span> <span>std</span><span>::</span><span>thread</span><span>::</span><span>spawn</span><span>(</span><span>move</span> <span>||</span> <span>{</span>
    <span>// code that uses &amp;pixels</span>
<span>});</span>
<span>handle</span><span>.join</span><span>()</span><span>.unwrap</span><span>();</span>
</code></pre></div></div>

<p>As expected, no significant performance gains were had.</p>

<h3 id="looking-at-the-asm-pt-2">Looking at the asm, pt. 2…</h3>

<p>Something isn’t adding up so I want to look at the assembly again, but I’d like to
clearly distinguish between my unchanged business logic and the
rayon/crossbeam coordination code. The majority of my business logic is
behind a single function named <code>cast</code>; adding <code>#[inline(never)]</code> to that single ray processing function
should give me a nice seam between rayon and my business logic.</p>

<p>Build, run and the rayon version slows down… in fact it runs exactly as slow as the crossbeam
version.</p>

<p>I try adding <code>#[inline(always)]</code> to the <code>cast</code> function in the crossbeam
version, and lo and behold it speeds up to match the original rayon version,
my regression disappears.</p>

<p>But, how’s that possible? The <em>first</em> thing I did was look at inlining. Maybe
my quick once-over missed it, maybe I misread and this whole circuitous path
is all my fault?</p>

<p>I generated assembly output for both the inlined and noninlined versions of the crossbeam ray tracer:</p>
<div><div><pre><code><span>$ </span>rg ecl_rt4cast inline.s 
21293:	.asciz	<span>"_ZN6ecl_rt4cast17hc1100eade04dff75E"</span>
<span>$ </span>rg ecl_rt4cast noinline.s 
21293:	.asciz	<span>"_ZN6ecl_rt4cast17hc1100eade04dff75E"</span>
</code></pre></div></div>

<p>I’m building release with symbols, so that string is expected. But neither
version, not even the non-inlined version, is making calls to <code>cast()</code>.
Curious.</p>
<div><div><pre><code><span>$ </span><span>wc</span> <span>-l</span> inline.s 
203969 inline.s
<span>$ </span><span>wc</span> <span>-l</span> noinline.s 
203969 noinline.s
</code></pre></div></div>

<p>Now I feel like I’m being gaslighted. These are the exact same length. A diff
shows that the only changes are some arbitrary IDs in debug info. I have a
difficult relationship with optimizing compilers, so my first thought is maybe
clang’s being clang again and I should go validate the binaries instead…</p>

<div><div><pre><code><span>$ </span>objdump <span>-d</span> ecl_rt_inline | rg ecl_rt4cast
&lt;no output&gt;
<span>$ </span>objdump <span>-d</span> ecl_rt_noinline | rg ecl_rt4cast
0000000100003190 __ZN6ecl_rt4cast17hc1100eade04dff75E:
100003299: e9 af 01 00 00              	jmp	431 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x2bd&gt;
1000034a2: eb 1f                       	jmp	31 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x333&gt;
1000034c6: 74 38                       	je	56 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x370&gt;
1000034e5: 0f 82 f5 00 00 00           	jb	245 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x450&gt;
1000034ee: 72 1d                       	jb	29 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x37d&gt;
1000034f0: e9 eb 00 00 00              	jmp	235 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x450&gt;
100003503: 0f 83 d7 00 00 00           	jae	215 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x450&gt;
100003515: 0f 87 16 03 00 00           	ja	790 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x6a1&gt;
10000351e: 0f 82 1f 03 00 00           	jb	799 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x6b3&gt;
100003527: 0f 82 2b 03 00 00           	jb	811 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x6c8&gt;
100003530: 0f 82 37 03 00 00           	jb	823 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x6dd&gt;
100003539: 0f 82 40 03 00 00           	jb	832 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x6ef&gt;
100003590: 0f 84 1a ff ff ff           	je	<span>-230</span> &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x320&gt;
1000035db: e9 d0 fe ff ff              	jmp	<span>-304</span> &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x320&gt;
10000360a: 0f 86 a1 01 00 00           	jbe	417 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x621&gt;
100003637: 0f 87 57 02 00 00           	ja	599 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x704&gt;
100003668: 0f 86 3d 02 00 00           	jbe	573 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x71b&gt;
100003682: 0f 84 41 01 00 00           	je	321 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x639&gt;
100003707: 0f 85 93 fb ff ff           	jne	<span>-1133</span> &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x110&gt;
10000371a: 0f 86 9f 01 00 00           	jbe	415 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x72f&gt;
100003723: 0f 86 a8 01 00 00           	jbe	424 &lt;__ZN6ecl_rt4cast17hc1100eade04dff75E+0x741&gt;
10000372c: 0f 86 b1 01 00 00           	jbe	433 &lt;_…</code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://siliconsprawl.com/2020/11/09/rust-emit-asm.html">https://siliconsprawl.com/2020/11/09/rust-emit-asm.html</a></em></p>]]>
            </description>
            <link>https://siliconsprawl.com/2020/11/09/rust-emit-asm.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037663</guid>
            <pubDate>Mon, 09 Nov 2020 18:09:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Journalist vs. Facebook]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25037615">thread link</a>) | @leoschwartz
<br/>
November 9, 2020 | https://restofworld.org/2020/the-journalist-vs-facebook/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/the-journalist-vs-facebook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Maria Ressa has a cheerful way of making apocalyptic pronouncements. “The world as we knew it is rubble,” she says over a Zoom call from Manila. “Facts are debatable, we have alternate realities — the White House will say we have alternate realities.”</p>



<p>Ressa is the CEO of Rappler, a prominent digital news outlet in the Philippines. Over the past few years, she has watched from the front row as the internet helped demolish civil discourse and fracture society’s shared sense of reality. In 2016, Ressa witnessed a flood of digital disinformation help elect Rodrigo Duterte, the firebrand populist who as president launched a “war on drugs” that has killed thousands of Filipinos. That year, the same trends helped put in office U.S. President Donald Trump and push the United Kingdom to leave the European Union.</p>



<p>During Duterte’s 2016 campaign, Rappler analyzed fraudulent social media networks that promoted the president and attacked his opponents, drawing on Ressa’s experience mapping terrorist organizations as an investigative reporter in the 1990s and 2000s.</p>



<p>Over the following four years, Ressa became not only a chronicler of the government’s falsehoods but a target of them. Through intimidation and lawsuits, the Duterte administration has <a href="https://www.nytimes.com/2020/05/05/world/asia/philippines-abs-cbn-duterte.html">worked to muzzle</a> a number of independent media organizations in the Philippines. Ressa has been singled out: She and her company were charged with a series of spurious crimes, including tax evasion, all of which she has denied. In June, she and a former colleague <a href="https://www.nytimes.com/2020/06/14/business/maria-ressa-verdict-philippines-rappler.html">were convicted</a> of cyberlibel, a charge that stemmed from an article Rappler published in 2012. Ressa is now out on bail pending an appeal but could ultimately face years in prison.&nbsp;</p>



<p>Rather than silence her, these attacks have only given Ressa a bigger platform. Named a <em>Time </em>magazine <a href="https://time.com/5793800/maria-ressa-the-guardians-100-women-of-the-year/">person of the year</a> in 2019, she has become a global symbol of press freedom and an avatar of courage in the face of rising authoritarianism. As her profile has grown, so, too, has her mission. Today, Ressa’s focus has shifted away from Duterte, whom she sees as only the symptom of a larger problem: Facebook.</p>



<p>Ressa is one of the founding members of the <a href="https://www.theverge.com/interface/2020/9/29/21472092/real-facebook-oversight-board-stunt-activism-limitations">Real Facebook Oversight Board</a>, a group of academics, journalists, and activists formed as a tongue-in-cheek counterpoint to the company’s actual <a href="https://about.fb.com/news/2020/05/welcoming-the-oversight-board/">Oversight Board</a>, launched in May. That board was designed to function as a “Supreme Court” of sorts, with the power to decide if the company’s content-moderation decisions “were made in accordance with Facebook’s stated values and policies.” Ressa contends that those values and policies are<em> themselves</em> the problem, and says that Facebook’s persistent failure to effectively combat disinformation and hate speech poses an existential threat to democracy around the world.</p>



<p>“We’re fighting huge powers. Duterte, Zuckerberg,” she says. “Who would have thought you would have put the two of them in the same breath, but that’s what I’ve been living with for the last four years.”</p>



<p>Rappler began as a Facebook page in 2011 and launched as a stand-alone website the following year. Ressa says she was initially enthusiastic about the power of “social media for good.” Rappler even partnered with Facebook’s Internet.org initiative, which gives consumers in developing countries free access to certain websites. The program was instrumental in getting millions of Filipinos online, and <a href="https://nymag.com/intelligencer/2018/09/how-facebooks-free-internet-helped-elect-a-dictator.html">also on Facebook</a>: Today, nearly all internet users in the country have a Facebook account. It was the 2016 presidential election in the Philippines that eventually changed Ressa’s mind about the social network. “When the problems began, we were the first to feel it,” she says.&nbsp;</p>



<p>Rappler identified dozens of Facebook accounts that were creating and spreading disinformation in support of Duterte. Some posted fictionalized accounts of terrorist attacks and murders supposedly committed by drug addicts, which fed into the newly elected president’s law-and-order agenda. Ressa alerted Facebook, but she says it failed to take action. So <a href="https://www.rappler.com/nation/propaganda-war-weaponizing-internet">Rappler exposed the accounts</a> in a series of articles, instantly making the site a target of the same troll armies it was reporting on. (Facebook says it removes any content that violates its rules.)</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/h_3.01374802-40x60.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/h_3.01374802-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/h_3.01374802-400x601.jpg 400w, https://restofworld.org/wp-content/uploads/2020/11/h_3.01374802-600x902.jpg 600w, https://restofworld.org/wp-content/uploads/2020/11/h_3.01374802-1000x1503.jpg 1000w, " sizes="(max-width: 640px) 100vw, 300px" alt="“The platform itself is biased against facts. It’s really biased against journalism,” said Maria Ressa.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Tania/Contrasto/Redux</span>
			</figcaption>
		</figure>


<p>Since 2016, Ressa has become increasingly convinced that Facebook needs to profoundly change how it’s designed and governed. She believes the platform’s algorithms and content-moderation policies are inherently prejudiced against reasoned debate based on settled truths. “The platform itself is biased against facts. It’s really biased against journalism,” she says. “Social media platforms have atomized meaning to meaninglessness. They have completely deconstructed context.”</p>



<p>Her opinions are backed by a growing body of academic research, which shows that social media sites often <a href="https://jonahberger.com/wp-content/uploads/2013/02/ViralityB.pdf">reward emotional messages over rational analysis</a>, funnel users toward <a href="https://www.scientificamerican.com/article/biases-make-people-vulnerable-to-misinformation-spread-by-social-media/">content that reinforces their</a> preexisting beliefs, and<a href="https://science.sciencemag.org/content/359/6380/1146"> spread lies more rapidly and widely than they do the truth</a>.</p>



<p>Ressa says one of Facebook’s most alarming shortcomings is its reluctance to moderate <a href="https://restofworld.org/2020/in-the-philippines-fake-news-can-get-you-killed/?utm_medium=Social&amp;utm_source=Twitter#Echobox=1603977263">disinformation posted by governments and politicians</a>. The company has justified its restraint by arguing that statements from public figures should remain online for public scrutiny. Although Facebook has removed state-backed propaganda in some instances, Ressa, along with other activists, say that these actions frequently amount to too little, too late. They say Facebook’s inaction has allowed propaganda and disinformation to spread unchecked, overwhelming and delegitimizing the news media.</p>



<p>“What we saw [in the Philippines] was that news organizations were being pushed to the periphery, and the center of the conversation was being taken over by the pro-government, state-sponsored disinformation,” Ressa says.</p>



<p>Without checks and balances on social media, Ressa says, authoritarian governments like Duterte’s can impose their own narratives — that drug addicts and communists run the country, and that journalists like Ressa are criminals and conspirators.</p>



<p>Ressa, who speaks in long, rapid-fire monologues, apologizes throughout her interview for her anger. “It’s very emotional for me,” she says. “I have real skin in the game. If they don’t fix this, this is how the government will normalize the possibility of jailing me. I could go to jail because [Facebook] refuses to address these problems that they created.”</p>



<p>The idea for the Real Facebook Oversight Board began taking shape last year, after Ressa met with Carole Cadwalladr, the journalist who, in 2018, first reported that political consulting firm <a href="https://www.theguardian.com/news/series/cambridge-analytica-files">Cambridge Analytica had harvested Facebook data</a> from millions of users. Since then, a number of high-profile academics and activists have joined the project, including Harvard professor Shoshana Zuboff, who wrote the best-selling book <em>The Age of Surveillance Capitalism</em>, as well as former Estonian President Thomas Hendrik Ilves and NAACP President Derrick Johnson.</p>



<p>The board was created to force Facebook into taking responsibility for the damage it has caused. The group <a href="https://www.axios.com/facebook-critics-take-on-its-oversight-board-06c496a2-355f-4a10-a8b4-d8f9b041a611.html">plans</a> to “use stunts, viral video, celebrity endorsement, and skillful media management” to put a spotlight on the threats social media companies pose to democracy. Ressa says she hasn’t fully discounted Facebook’s ability to do the right thing. “They just need to get off their butts and fix it before it is completely broken,” she says.</p>



<p>Ressa is still processing her evolution from journalism to activism, but she says she sees an obvious connection between the two, especially in an environment where facts are under constant attack. “Journalism is activism when it is a battle for truth,” she says. “This is a time when anyone living in a democracy, if you care about democracy, you have to sit there and answer the same question I was forced to answer four years ago, which is: What are you willing to sacrifice for the truth?”</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/the-journalist-vs-facebook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037615</guid>
            <pubDate>Mon, 09 Nov 2020 18:06:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Work faster and safer on untested code with Overcommitting]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25037561">thread link</a>) | @nicoespeon
<br/>
November 9, 2020 | https://understandlegacycode.com/blog/work-faster-safer-untested-code-overcommitting/ | <a href="https://web.archive.org/web/*/https://understandlegacycode.com/blog/work-faster-safer-untested-code-overcommitting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><undefined>
  <a href="https://understandlegacycode.com/static/2c60e52fc6710a2397962652219eef72/b8ccf/overcommitting-preview.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Comic that recaps the content of this post" title="" src="https://understandlegacycode.com/static/2c60e52fc6710a2397962652219eef72/799d3/overcommitting-preview.png" srcset="https://understandlegacycode.com/static/2c60e52fc6710a2397962652219eef72/00d96/overcommitting-preview.png 148w,https://understandlegacycode.com/static/2c60e52fc6710a2397962652219eef72/0b23c/overcommitting-preview.png 295w,https://understandlegacycode.com/static/2c60e52fc6710a2397962652219eef72/799d3/overcommitting-preview.png 590w,https://understandlegacycode.com/static/2c60e52fc6710a2397962652219eef72/b8ccf/overcommitting-preview.png 750w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p><em>Get this comic in SVG + high-res PNG by subscribing to my weekly newsletter at the bottom of this post 👇</em></p><hr><p>I’m sure you’ve got into this paradox:</p><ul><li>People tell you to write tests <em>before</em> you refactor, so you know if you break something</li><li>But the code is so messy that you need to refactor it <em>before</em> you can write tests</li></ul><p>It sounds like a <a href="https://en.wikipedia.org/wiki/Chicken_or_the_egg">chicken-and-egg problem</a>. Where do you even start?</p><p>Well, usually you don’t have the luxury to wait until you find out. You estimated this issue would take 2 days and now this estimation has turned into a commitment. So you fall back to what you know to do: changing the code, trying not to do any mistake, and testing manually a few common scenarios to verify everything is still working.</p><p>If that’s you, I have a technique for you that will preserve your speed and make your changes safer. Mastering it will make you go faster when things are blurry. You’ll be a <a href="https://fr.wikipedia.org/wiki/Speedrun">speedrunner</a> through the maze of Legacy Code.</p><p><img src="https://understandlegacycode.com/acdf66f62dec2dd5d4b3659e6ca43245/speedrun.gif" alt="Mario speedrun"></p><p>If you’re versioning your code, you already have the tool you need. If you’re not, I suggest <a href="https://git-scm.com/downloads">you install git</a>, run <code>git init</code> in your source code repository, commit everything, and start from here.</p><h2 id="how-overcommitting-can-help"><a href="#how-overcommitting-can-help" aria-label="how overcommitting can help permalink"></a>How overcommitting can help</h2><p>Among all the benefits of source code version control, one is to save the state of your code at different moments of the development. This is what you do when you commit. It allows you to go back to a previous state (commit) if needed.</p><p>Commits are like checkpoints. When the game is particularly difficult, having more checkpoints helps.</p><p>When you realize you did something wrong, commits allow you to go back to a state where things were still working, so you can revisit your changes or try again.</p><p>When you don’t have automated tests, the feedback loop is notoriously longer. You won’t know if you break something until a few minutes, maybe even hours. If you commit as you use to do, you’ll lose dozen of minutes of code, if I’m being optimistic.</p><p>But if you were committing every minute or so, you would have many more checkpoints to start from. You’d be able to find out precisely when things got sour, and start from here!</p><p><strong>Overcommitting allows you to work safely.</strong></p><h2 id="what-does-it-look-like"><a href="#what-does-it-look-like" aria-label="what does it look like permalink"></a>What does it look like</h2><p>When change is risky, think about committing often. Then, commit even more than that!</p><p>You need to commit absurdly frequently. If it feels stupidly frequent, you’re doing it right.</p><p>You’re not used to committing that often. So you need to deliberately push yourself out of your habits to build a new one.</p><p>As you can’t both think carefully about the code and think carefully about committing, I recommend you use a timer. 2 minutes is a good chunk to get started. In my experience, developers commit way less often than that.</p><ol><li>Start a 2 minutes timer.</li><li>When it rings, commit what you have.</li><li>Repeat.</li></ol><p>It’s designed to be a short loop. You must repeat this again and again during your whole coding session.</p><p><strong>Don’t bother with the commit message yet.</strong> That will feel wrong, but that’s normal. You can’t come up with a good name if you commit everything you have every 2 minutes (or you’d be very lucky). The goal is to do safe changes for the moment, focus on that.</p><p>If you’re worried commits won’t pass the review, I advise you to take 5min at the end of each hour to <a href="http://gitready.com/advanced/2009/02/10/squashing-commits-with-rebase.html">squash your commits together</a> and give them more appropriate messages. You should have ~30 small commits to rebase, which shouldn’t take long.</p><h2 id="why-does-it-work"><a href="#why-does-it-work" aria-label="why does it work permalink"></a>Why does it work?</h2><p>The obvious reason is that you create much, much more checkpoints. It makes it easier to detect the exact moment a bug was introduced. You waste less time debugging when you realize there’s a problem.</p><p>Because you don’t focus on the commit message while you’re committing, it preserves your speed. The time is taking care of telling you to commit. When it rings, you just do that and move on.</p><p>But there’s more, and it has to do with safety.</p><p>J. B. Rainsberger told me this recently: <em>why do we have breaks on a car?</em></p><p>Most people will tell you that’s so you can stop. The truth is: <strong>that’s so you can go fast</strong>! If there were no breaks, you would drive slowly and carefully because you can’t react promptly to what’s around the corner. Breaks give you the power to go faster because you can react to obstacles.</p><p>If you have automated tests, you’ll refactor the code more because you know it’s safe to do it. If you don’t have them, you’ll not feel comfortable changing the code and try to work around as much as you can, usually making things worse.</p><p>Sometimes, refactoring the code is necessary so you can add some tests. Sometimes also, you don’t know how to test this code but you still have to change it before tomorrow. In these cases, overcommit will bring you enough safety so you can work faster!</p><p>Finally, the time you’d have saved would be wisely re-invested in writing the automated tests you’re missing!</p><p><strong>Don’t forget to grab your Overcommitting Comic!</strong></p></div></div>]]>
            </description>
            <link>https://understandlegacycode.com/blog/work-faster-safer-untested-code-overcommitting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037561</guid>
            <pubDate>Mon, 09 Nov 2020 18:01:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This Month in Rust GameDev #15 – October 2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25037471">thread link</a>) | @ozkriff
<br/>
November 9, 2020 | https://rust-gamedev.github.io/posts/newsletter-015 | <a href="https://web.archive.org/web/*/https://rust-gamedev.github.io/posts/newsletter-015">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
            
    <article itemscope="" itemtype="http://schema.org/BlogPosting">
        

        <div itemprop="articleBody">
            <p>Welcome to the 15th issue of the Rust GameDev Workgroup's
monthly newsletter.
<a href="https://rust-lang.org/">Rust</a> is a systems language pursuing the trifecta:
safety, concurrency, and speed.
These goals are well-aligned with game development.
We hope to build an inviting ecosystem for anyone wishing
to use Rust in their development process!
Want to get involved? <a href="https://github.com/rust-gamedev/wg#join-the-fun">Join the Rust GameDev working group!</a></p>
<p>You can follow the newsletter creation process
by watching <a href="https://github.com/rust-gamedev/rust-gamedev.github.io/issues?q=label%3Acoordination">the coordination issues</a>.
Want something mentioned in the next newsletter?
<a href="https://github.com/rust-gamedev/rust-gamedev.github.io">Send us a pull request</a>.
Feel free to send PRs about your own projects!</p>
<p>Table of contents:</p>
<ul>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-015/#annual-survey-from-the-rust-gamedev-wg">Annual Survey from the Rust GameDev WG</a></li>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-015/#game-updates">Game Updates</a></li>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-015/#learning-material-updates">Learning Material Updates</a></li>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-015/#library-tooling-updates">Library &amp; Tooling Updates</a></li>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-015/#popular-workgroup-issues-in-github">Popular Workgroup Issues in Github</a></li>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-015/#requests-for-contribution">Requests for Contribution</a></li>
</ul>
<!--
Ideal section structure is:

```
### [Title]

![image/GIF description](image link)
_image caption_

A paragraph or two with a summary and [useful links].

_Discussions:
[/r/rust](https://reddit.com/r/rust/todo),
[twitter](https://twitter.com/todo/status/123456)_

[Title]: https://first.link
[useful links]: https://other.link
```

If needed, a section can be split into subsections with a "------" delimiter.
-->
<h2 id="annual-survey-from-the-rust-gamedev-wg"><a href="https://surveymonkey.com/r/F2JYRFF">Annual Survey from the Rust GameDev WG</a>&nbsp;
</h2>
<p>As we did <a href="https://rust-gamedev.github.io/posts/survey-01">last year</a>, we are once again running
a Rust Game Development Ecosystem Survey. It'll only take 10 minutes,
and your responses help us better understand the state of our ecosystem
and where we should try to focus our collective efforts.</p>
<h2 id="game-updates">Game Updates&nbsp;
</h2>
<h3 id="veloren"><a href="https://veloren.net/">Veloren</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-015/veloren_clouds.jpeg" alt="Landscape">
<em>Endless mountains to explore</em></p>
<p><a href="https://veloren.net/">Veloren</a> is an open world, open-source voxel RPG inspired by Dwarf
Fortress and Cube World.</p>
<p>In October, lots of work was done on the UI, and a buff system. There was an
overhaul done to the staff item that gives it new primary and secondary attacks.
There has also been work done on the axe and bow. The cloud system was
overhauled and brought a cheaper way to compute the 3D noise that the system uses.
The skill bar was overhauled to implement a new design that could handle the new
buff system. This was also the first overhaul in over a year. A SFX system is in
the works to allow effects to be mapped to blocks, for sounds like crickets or
birds.</p>
<p>You can read more about some specific topics from October:</p>
<ul>
<li><a href="https://veloren.net/devblog-88#gemu">Modelling Process</a></li>
<li><a href="https://veloren.net/devblog-89#staff-overhaul-by-sam">Staff Overhaul</a></li>
<li><a href="https://veloren.net/devblog-89#new-skillbar-and-buffs-visuals-pfau">New Skillbar and Buffs Visuals</a></li>
<li><a href="https://veloren.net/devblog-90#cloud-improvements-by-zesterer">Cloud Improvements</a></li>
<li><a href="https://veloren.net/devblog-91#buffs-by-sam">Buffs</a></li>
<li><a href="https://veloren.net/devblog-91#alignment-and-hostility-by-adam">Alignment and Hostility</a></li>
<li><a href="https://veloren.net/devblog-91#fixing-ci-by-xmac94x">Fixing CI</a></li>
</ul>
<p>October's full weekly devlogs: "This Week In Veloren...":
<a href="https://veloren.net/devblog-88">#88</a>,
<a href="https://veloren.net/devblog-89">#89</a>,
<a href="https://veloren.net/devblog-90">#90</a>,
<a href="https://veloren.net/devblog-91">#91</a>.</p>
<p>In November, Veloren will release 0.8. Veloren will also be speaking at
MiniDebConf on November 22nd.</p>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-015/veloren_wolves.jpeg" alt="Healing sceptre">
<em>Team hunt</em></p>
<h3 id="crate-before-attack"><a href="https://cratebeforeattack.com/">Crate Before Attack</a>&nbsp;
</h3>
<p><a href="https://cratebeforeattack.com/"><img src="https://rust-gamedev.github.io/posts/newsletter-015/crate-before-attack.gif" alt="Leaderboard Histogram"></a>
<em>Interactive Histogram with Race Results</em></p>
<p><a href="https://cratebeforeattack.com/">Crate Before Attack</a> by <a href="https://twitter.com/CrateAttack">koalefant (@CrateAttack)</a>
is a skill-based multiplayer game where frogs fight and race using their sticky
tongues as grappling hooks.</p>
<p>A <a href="https://cratebeforeattack.com/play">browser build</a> can be played online.</p>
<p>Changes since the last update:</p>
<ul>
<li>Added a global leaderboard that visualizes Race and Training results in an
interactive histogram.</li>
<li>Tweaked frogs physics to make them more bouncy, added an option that would
keep tongue connected as long as a key is being pressed.</li>
<li><a href="https://youtu.be/j87I8akUTkc">Online Ghosts</a> were added. One can now compete with real
players instead of AI when playing Race mode.</li>
<li>Improved load-times: level graphics is now quantized with an 8-bit palette,
signed distance fields that are used for collisions are now generated offline.
Downloads are cached in an IndexedDB, so subsequent starts are even faster.</li>
<li>Multiple bugs were fixed.</li>
</ul>
<p>More details are in <a href="https://cratebeforeattack.com/posts/20201001-september-update">September</a> and
<a href="https://cratebeforeattack.com/posts/20201029-october-update">October</a> DevLog entries and in
<a href="https://www.youtube.com/channel/UC_xMilPTLuuE5iLs1Ml9zow">YouTube-channel</a>.</p>
<h3 id="egregoria"><a href="https://github.com/Uriopass/Egregoria">Egregoria</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-015/egregoria.jpg" alt="Egregoria roads at night"></p>
<p><a href="https://github.com/Uriopass/Egregoria">Egregoria</a>'s objective is to become a granular society simulation,
filled with fully autonomous agents interacting with their world in real-time.</p>
<p>The <a href="http://douady.paris/blog/egregoria_6.html">6th devlog</a> was published. Updates include:</p>
<ul>
<li>Island generation.</li>
<li>Day/night cycle.</li>
<li>Human AI via utility systems.</li>
<li>Specs to <a href="https://github.com/amethyst/legion">legion 0.3</a> port.</li>
</ul>
<p>See also <a href="https://www.youtube.com/watch?v=mfvAuvC-XLg">the recent video</a> showcasing very basic AI.</p>
<p>Join <a href="https://discord.gg/CAaZhUJ">Egregoria's Discord server</a>.</p>
<p><em>Discussions:
<a href="https://reddit.com/r/rust_gamedev/comments/jkcllc/egregoria_devblog_6">/r/rust_gamedev</a></em></p>
<h3 id="a-b-street"><a href="https://abstreet.org/">A/B Street</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-015/abstreet.png" alt="A/B Street on the web"></p>
<p><a href="https://abstreet.org/">A/B Street</a> is a traffic simulation game exploring how small changes
to roads affect cyclists, transit users, pedestrians, and drivers. Any city
with OpenStreetMap coverage can be used!</p>
<p>Some of this month's updates:</p>
<ul>
<li><a href="http://abstreet.s3-website.us-east-2.amazonaws.com/dev/">web version</a> launched, powered by <code>winit</code>, <code>glow</code>, and other
dependencies having support for WebAssembly;</li>
<li>an <a href="http://abstreet.s3-website.us-east-2.amazonaws.com/osm_demo/">OpenStreetMap viewer</a> with 100 cities imported;</li>
<li>"thought bubbles" for cars looking for parking, by <a href="https://github.com/michaelkirk">Michael</a>;</li>
<li>slow portions of a trip highlighted in the info panel, by <a href="https://github.com/NoSuchThingAsRandom/">Sam</a>;</li>
</ul>
<h3 id="worship-the-sun">Worship The Sun&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-015/worship-sun.jpg" alt="Worship The Sun">
<em>One of the many unique and confounding puzzles in the game</em></p>
<p>Worship The Sun is a dark, mysterious 2D puzzle-platform game with computer
science themes. It introduces the player to a rich language of puzzle elements
and challenges them to solve difficult puzzles that require experimentation,
comprehension, and internalisation of the game's mechanics.</p>
<p>The game is built using a custom engine that sits on top of <a href="https://github.com/amethyst/legion">legion</a>,
<a href="https://github.com/gfx-rs/wgpu">wgpu</a>, and a handful of other crates. It features dynamic lighting, a
flexible particle system, bespoke collision behaviour, and a Vim-inspired level
editor. The majority of game assets are hand drawn in <a href="https://procreate.art/">Procreate</a>
and painstakingly animated.</p>
<p>The game is a few months into development with a release target of late 2021.
You can read about how swimming was added to the game in <a href="https://tuzz.tech/blog/taking-the-plunge">GameDev Note 1:
Taking the Plunge</a> which contains a sneak peek at some of the levels.
For updates and possible playtesting opportunities, follow
<a href="https://twitter.com/chrispatuzzo">@chrispatuzzo</a> and a <a href="https://reddit.com/r/WorshipTheSunGame">/r/WorshipTheSunGame</a> subreddit.</p>
<h3 id="garden"><a href="https://www.cyberplant.xyz/">Garden</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-015/garden_scaled_1.png" alt="Garden">
<em>A couple of trees growing and basking in the sun</em></p>
<p><a href="https://www.cyberplant.xyz/">Garden</a> is a procedural tree-growing, strategical ecosystem-restoration
and biological simulation game with an infinite amount of plant species where
every leaf is simulated, and the natural resources are scarce.
Every specimen is unique, as the plants grow by responding to the live changes in
the environment.
The player has to balance many complex mechanics to sustain life and go
forward in the game.
The game and the custom engine are developed in Rust with an OpenGL backend.</p>
<p>Garden developers (temporary name) are preparing for a demo release in a couple
of months by tying everything together into a coherent experience.
The game is also continually optimized to run on less powerful GPUs,
so that everyone can enjoy it.</p>
<p>Some of the <a href="https://cyberplant.xyz/posts/october_2020">updates from the October devlog</a>:</p>
<ul>
<li>Near-infinite variety of plant species
achieved through treating branch segments as Markov chains
(enabling different growth speeds and probabilities
for other segment types' growth from one another)
and simulating photosynthesis as an electrical circuit
(enabling sugar storage in the form of root vegetables, for example).</li>
<li>Concrete brick destruction mechanics were implemented.
Dust particles for the animation that appears upon breaking,
as well as the debris, were also added to the game.</li>
<li>Saving and loading are almost complete.</li>
<li>A watering can was added.</li>
<li>Smoother soil and debris outlines.</li>
</ul>
<p>Follow the developers <a href="https://twitter.com/logicsoup">@logicsoup</a> and <a href="https://twitter.com/epcc10">@epcc10</a> on Twitter for more updates.</p>
<h3 id="akigi"><a href="https://akigi.com/">Akigi</a>&nbsp;
</h3>
<p><a href="https://akigi.com/">Akigi</a> is a WIP online multiplayer game.</p>
<p>In October, more progress was made on the editor tool for placing entity spawn
points. Work was started on prototyping the hunting skill. Functionality was
added to allow focusing for TextAreas in the user interface. Improvements were
made to the engine's asset management code to make it more generalized.</p>
<p>Full devlogs:
<a href="https://devjournal.akigi.com/october-2020/087-2020-10-04.html">#087</a>,
<a href="https://devjournal.akigi.com/october-2020/088-2020-10-11.html">#088</a>,
<a href="https://devjournal.akigi.com/october-2020/089-2020-10-18.html">#089</a>,
<a href="https://devjournal.akigi.com/october-2020/090-2020-10-25.html">#090</a>.</p>
<h3 id="sun-prison"><a href="https://github.com/ropewalker/sun_prison">Sun Prison</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-015/sun_prison.gif" alt="Sun Prison gameplay"></p>
<p><a href="https://github.com/ropewalker/sun_prison">Sun Prison</a> by <a href="https://twitter.com/dmitrywithouti">Dima Lazarev</a> is a WIP turn-based
meditation on Rubik's cube, <a href="https://github.com/ropewalker/bevy_sokoban">Sokoban</a>, and roguelikes, being
implemented with <a href="https://bevyengine.org/">Bevy engine</a>.
The game is in the very early stages of development,
but it is already possible to <a href="https://twitter.com/dmitrywithouti/status/1309025584039768064">get lost in the dark</a>
or to be <a href="https://twitter.com/dmitrywithouti/status/1309982656260648960">eaten by zombies</a>.</p>
<p>Follow <a href="https://twitter.com/dmitrywithouti">@dmitrywithouti</a> on Twitter for updates.</p>
<h3 id="camp-misty"><a href="https://github.com/ReeCocho/camp-misty">Camp Misty</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-015/camp-misty.PNG" alt="Camp Misty Title Screen"></p>
<p><a href="https://github.com/ReeCocho/camp-misty">Camp Misty</a> is an asymmetric
multiplayer game played on the command line. The game is played with two
people. One of the players is a helpless victim searching for car parts. If
they find all of the parts, they can repair their car and escape the camp. The
other player is a ruthless killer who is trying to hunt down the victim.</p>
<p>The game was created as a learning exercise in about two weeks by
<a href="https://github.com/ReeCocho">@ReeCocho</a>, with contributions from the many helpful members of <a href="https://reddit.com/r/rust">/r/rust</a>.</p>
<h3 id="antorum-online"><a href="https://ratwizard.dev/dev-log/antorum">Antorum Online</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-015/antorum-online-10-29-2020.jpg" alt="A small marketplace area with a few merchants"></p>
<p>Antorum Online is a micro-multiplayer online role-playing game by <a href="https://twitter.com/dooskington">@dooskington</a>.
The game server is written in Rust, and the current "official" client is being
developed in Unity. The server can be self-hosted, and the network protocol is
open, so even custom clients that adhere to the protocol can connect and play.</p>
<p>Two more devlogs were published this month, regarding work done to implement
shops, character creation, and a few other features:</p>
<ul>
<li><a href="https://ratwizard.dev/dev-log/antorum/21">21: Belmart, Shops, And Bartering</a></li>
<li><a href="https://ratwizard.dev/dev-log/antorum/22">22: Character Creation And Customization</a></li>
</ul>
<h3 id="the-honor-sagas"><a href="https://khonsulabs.itch.io/honorsagas">The Honor Sagas</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-015/honor.png" alt="game's banner"></p>
<p><a href="https://khonsulabs.itch.io/honorsagas">The Honor Sagas</a> is an early-in-development 2d MMORPG project.
October was the first month of development, and <a href="https://twitter.com/ectonDev">@ectonDev</a> wrote
<a href="https://khonsulabs.itch.io/honorsagas/devlog/192252/the-honor-sagas-devtober-postmortem">a postmortem</a> of the progress made while participating
in <a href="https://itch.io/jam/devtober-2020">#Devtober</a>.</p>
<h3 id="project-yawc">Project YAWC&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-015/yawc.png" alt="An in-progress game of Project YAWC."></p>
<p>Project YAWC is a turn-based strategy game in the style of Advance Wars in
development by junkmail. October saw the release of Alpha 3, including
dynamically generated info cards and minor networking changes. For inquiries or
if you are interested in playtesting, contact projectyawc(at)gmail.com.</p>
<h3 id="power-kick"><a href="https://kakoeimon.itch.io/power-kick">Power Kick</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-015/power-kick-shot.png" alt="Power Kick"></p>
<p><a href="https://kakoeimon.itch.io/power-kick">Power Kick</a> is a one screen platform game inspired by similar old arcade games
like Bubble Bobble and SnowBros.
Your task is to hit the enemies till they get dizzy and then kick them out of
their misery to proceed to the next stage. The kicked enemies will hit the
colliding enemies with a possibility to create a chain reaction
(similar to the pushed snowball in SnowBros).</p>
<p>The game has 20 stages and in stage 10 and 20 you will face a helicopter boss.</p>
<p>Can be played solo on the web through WebAssembly or up to two players
in the downloadable version:
the first player with the keyboard and the second one with a joypad.</p>
<p>The development took around two weeks thanks to <a href="https://github.com/not-fl3/macroquad">macroquad</a> and <a href="https://crates.io/crates/hecs">hecs</a>.</p>
<h3 id="rymd"><a href="https://profan.itch.io/rymd">rymd</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-015/rymd_2020_11_05.gif" alt="rymd animated combat"></p>
<p><a href="https://profan.itch.io/rymd">rymd</a> by <a href="https://twitter.com/_profan">@_profan</a> is a space shooter prototype made with <a href="https://github.com/not-fl3/macroquad">macroquad</a>.
Intended as a test platform for trying out rust for prototyping games and
particularly for game AI programming purposes.</p>
<p>Development started at the end of October, recent additions include:</p>
<ul>
<li>Basic enemy AI behaviour mostly based on steering behaviours.</li>
<li>Possibly the world's most nauseating physics-driven camera.</li>
<li>Too many particles.</li>
</ul>
<h3 id="pglowrpg"><a href="https://github.com/roalyr/pglowrpg">pGLOWrpg</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-015/pglowrpg.gif" alt="walking through a forest"></p>
<p>The <a href="https://twitter.com/pglowrpg">@pGLOWrpg</a> (Procedurally Generated Living …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rust-gamedev.github.io/posts/newsletter-015">https://rust-gamedev.github.io/posts/newsletter-015</a></em></p>]]>
            </description>
            <link>https://rust-gamedev.github.io/posts/newsletter-015</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037471</guid>
            <pubDate>Mon, 09 Nov 2020 17:54:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manager Advice: Prepare to Be Scrutinized]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25037454">thread link</a>) | @hackitup7
<br/>
November 9, 2020 | https://staysaasy.com/management/2020/09/18/management-scrutiny.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/09/18/management-scrutiny.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>One of the weird things that people don’t tell you about management is the degree to which people will sometimes scrutinize your behavior.</p>

<p>This is completely opposite to how most human interactions work. Generally speaking people overestimate how much attention others are paying to them. It’s easy to be embarrassed if your voice cracks while meeting someone new, if you say something silly in front of your in-laws, or if you have spaghetti sauce on your shirt. In most cases nobody notices because their own life is being pumped into their brain in stereo.</p>

<p>But this isn’t always true. People actually <em>do</em> scrutinize the behavior of people who have some measure of control over their careers (such as the CEO) carefully, and in some cases will even document what they say for a rainy day. This pattern becomes more extreme as titles and organizations grow, to the point where the job of a Fortune 500 CEO almost overlaps with Broadway theater.</p>

<p>The reasons for this are obvious. People aren’t paying attention out of any sort of expectation of wisdom – but when someone has an impact on your job, it’s rational and reasonable to analyze them to help your career. However, I find that few new managers are aware of this phenomenon, which can have far-ranging consequences.</p>

<h2 id="the-awkward-lunch">The Awkward Lunch</h2>

<p>I remember the first time that I learned this lesson. I was eating lunch with my team as we lightly discussed our upcoming customer conference, and made a quick, dismissive offhand comment about how I felt that one of our marketing teams, led by Steve, was going in circles and wasting time on trivial details. This was 100% wrong – you should never “otherize” other teams – but I didn’t say anything particularly incendiary or critical. Nobody made any mention and I certainly forgot what I had said almost immediately.</p>

<p>Two weeks later, a member of my team offered out of the blue to handle an upcoming planning meeting with Steve’s group. I was confused – why was she making this offer? “Well, you mentioned that you thought that Steve had a tendency to waste time, and I know that you’re presenting at that conference in a week so you’re probably busy. I figured I could help cover a meeting with a team you don’t like.”</p>

<p>A team I don’t like? Where did that come from?! I dimly recalled the lunch in which I had made that comment, and realized that the offhand comment which I had immediately deleted from my mind had stuck with my lunchmates. With a growing sense of dread, I also realized that versions of this situation had probably been happening without my realizing it.</p>

<h2 id="managing-under-a-microscope">Managing Under a Microscope</h2>

<p>Advice that I had received earlier in my career, especially after becoming a new manager: assume that someone might remember everything you say or do. For extra fun, also expect that about 10% of the juiciest details that get remembered will be at least somewhat inaccurate.</p>

<p>Since it can be jarring to realize that your team is watching you a little bit more closely than you might like, I try to convey the general advice below to first time managers on my team:</p>

<ul>
  <li>Treat everything that you say like an email – assume that it may live on in someone’s memory for a long time after you say it.</li>
  <li>Be intentional in how you operate or communicate, as some people (particularly your team) may emulate some of your patterns. If you are really harsh when you communicate with other teams, they’ll tend to be harsher as well. If you’re extremely accommodating, they’ll also tend to be more accommodating.</li>
  <li>Build the mental muscle of being less reactive to stressful situations. Try not to visibly frown or look skeptical unless you really mean to express that emotion as people will likely pick up on it. This is true even if you’re stressed because you’re thinking about how your corgi Mr. Snuffles is sick, and your bad mood has nothing to do with work.</li>
  <li>Be extra vigilant not to say things that could be misconstrued as disrespectful or offensive.</li>
  <li>Don’t get wasted at your company’s holiday party, or at other types of events. While I find that most people will give you a pass, it’s really easy to start rumors after hours.</li>
</ul>

<p>There is no way to stop people from scrutinizing – it’s human nature mixed with rational behavior. But if you’re intentional in your actions, you should at least be able to avoid putting your foot in your mouth by saying something dumb at lunch.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/09/18/management-scrutiny.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037454</guid>
            <pubDate>Mon, 09 Nov 2020 17:52:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Git]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25037365">thread link</a>) | @jerodsanto
<br/>
November 9, 2020 | https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Every now and then I get questions on how to work with git in a smooth way when developing, bug-fixing or extending curl – or how I do it. After all, I <a href="https://daniel.haxx.se/blog/2020/10/26/working-open-source/" data-type="post" data-id="14901">work on open source full time</a> which means I have very frequent interactions with git (and GitHub). Simply put, I work with git all day long. Ordinary days, I issue git commands several hundred times.</p>



<p>I have a very simple approach and way of working with git in curl. This is how it works.</p>



<h2>command line</h2>



<p>I use git almost exclusively from the command line in a terminal. To help me see which branch I’m working in, I have this little bash helper script.</p>



<pre>brname () {
  a=$(<code>git rev-parse --abbrev-ref HEAD 2&gt;/dev/null</code>)
  if [ -n "$a" ]; then
    echo " [$a]"
  else
    echo ""
  fi
}
PS1="\u@\h:\w\$(brname)$ "</pre>



<p>That gives me a prompt that shows username, host name, the current working directory and the current checked out git branch.</p>



<p>In addition: I use Debian’s <a href="https://salsa.debian.org/debian/bash-completion/-/blob/master/README.md">bash command line completion</a> for git which is also really handy. It allows me to use tab to complete things like git commands and branch names. </p>



<h2>git config</h2>



<p>I of course also have my customized <code>~/.gitconfig</code> file to provide me with some convenient aliases and settings. My most commonly used git aliases are:</p>


<pre title="">st = status --short -uno
ci = commit
ca = commit --amend
caa = commit -a --amend
br = branch
co = checkout
df = diff
lg = log -p --pretty=fuller --abbrev-commit
lgg = log --pretty=fuller --abbrev-commit --stat
up = pull --rebase
latest = log @^{/RELEASE-NOTES:.synced}..
</pre>


<p>The ‘latest’ one is for listing all changes done to curl since the most recent RELEASE-NOTES “sync”. The others should hopefully be rather self-explanatory.</p>



<p>The config also sets <code>gpgsign = true</code>, enables mailmap and a few other things.</p>



<h2>master is clean and working</h2>



<p>The main curl development is done in the single <a href="https://github.com/curl/curl">curl/curl</a> git repository (primarily hosted on GitHub). We keep the master branch the bleeding edge development tree and we work hard to always keep that working and functional. We do our releases off the master branch when that day comes (every eight weeks) and we provide “<a href="https://curl.haxx.se/snapshots/">daily snapshots</a>” from that branch, put together – yeah – daily.</p>



<p>When merging fixes and features into master, we avoid merge commits and use rebases and fast-forward as much as possible. This makes the branch very easy to browse, understand and work with – as it is 100% linear.</p>



<h2>Work on a fix or feature</h2>



<p>When I start something new, like work on a bug or trying out someone’s patch or similar, I first create a local branch off master and work in that. That is, I don’t work directly in the master branch. Branches are easy and quick to do and there’s no reason to shy away from having loads of them!</p>



<p>I typically name the branch prefixed with my GitHub user name, so that when I push them to the server it is noticeable who is the creator (and I can use the same branch name locally as I do remotely).</p>



<pre>$ git checkout -b bagder/my-new-stuff-or-bugfix</pre>



<p>Once I’ve reached somewhere, I commit to the branch. It can then end up one or more commits before I consider myself “done for now” with what I was set out to do.</p>



<p>I try not to leave the tree with any uncommitted changes – like if I take off for the day or even just leave for food or an extended break. This puts the repository in a state that allows me to easily switch over to another branch  when I get back – should I feel the need to. Plus, it’s better to commit and explain the change <em>before</em> the break rather than having to recall the details again when coming back.</p>



<h2>Never stash</h2>



<p>“git stash” is therefore not a command I ever use. I rather create a new branch and commit the (temporary?) work in there as a potential new line of work.</p>



<h2>Show it off and get reviews</h2>



<p>Yes I am the lead developer of the project but I still maintain the same work flow as everyone else. All changes, except the most minuscule ones, are done as pull requests on GitHub.</p>



<p>When I’m happy with the functionality in my local branch. When the bug seems to be fixed or the feature seems to be doing what it’s supposed to do and the test suite runs fine locally.</p>



<p>I then clean up the commit series with “<code>git rebase -i</code>” (or if it is a single commit I can instead use just “<code>git commit --amend</code>“).</p>



<p>The commit series should be a set of logical changes that are related to this change and not any more than necessary, but kept separate if they are separate. Each commit also gets its own proper commit message. Unrelated changes should be split out into its own separate branch and subsequent separate pull request.</p>



<pre>git push origin bagder/my-new-stuff-or-bugfix</pre>



<h2>Make the push a pull request</h2>



<p>On GitHub, I then make the newly pushed branch into a <a href="https://github.com/curl/curl/pulls">pull request</a> (aka “a PR”). It will then become visible in the list of pull requests on the site for the curl source repository, it will be announced in the #curl IRC channel and everyone who follows the repository on GitHub will be notified accordingly.</p>



<p>Perhaps most importantly, a pull request kicks of a flood of CI jobs that will build and test the code in numerous different combinations and on several platforms, and the results of those tests will trickle in over the coming hours. When I write this, we have around 90 different CI jobs – per pull request – and something like 8 different code analyzers will scrutinize the change to see if there’s any obvious flaws in there.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png"><img loading="lazy" width="2686" height="1510" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png" alt=""></a><figcaption>CI jobs per platform over time. Graph snapped on November 5, 2020</figcaption></figure>



<h2>A branch in the actual curl/curl repo</h2>



<p>Most contributors who would work on curl would not do like me and make the branch in the curl repository itself, but would rather do them in their own forked version instead. The difference isn’t that big and I <em>could</em> of course also do it that way.</p>



<h2>After push, switch branch</h2>



<p>As it will take some time to get the full CI results from the PR to come in (generally a few hours), I switch over to the next branch with work on my agenda. On a normal work-day I can easily move over ten different branches, polish them and submit updates in their respective pull-requests.</p>



<p>I can go back to the&nbsp;master branch again with ‘<code>git checkout master</code>‘ and there I can “<code>git pull</code>” to get everything from upstream – like when my fellow developers have pushed stuff in the mean time.</p>



<h2>PR comments or CI alerts</h2>



<p>If a reviewer or a CI job find a mistake in one of my PRs, that becomes visible on GitHub and I get to work to handle it. To either fix the bug or discuss with the reviewer what the better approach might be.</p>



<p>Unfortunately, flaky CI jobs is a part of life so very often there ends up one or two red markers in the list of CI jobs that can be ignored as the test failures in them are there due to problems in the setup and not because of actual mistakes in the PR…</p>



<p>To get back to my branch for that PR again, I “<code>git checkout bagder/my-new-stuff-or-bugfix</code>“, and fix the issues.</p>



<p>I normally start out by doing follow-up commits that repair the immediate mistake and push them on the branch:</p>



<pre>git push origin <code>bagder/my-new-stuff-or-bugfix</code></pre>



<p>If the number of fixup commits gets large, or if the follow-up fixes aren’t small, I usually end up doing a squash to reduce the number of commits into a smaller, simpler set, and then force-push them to the branch.</p>



<p>The reason for that is to make the patch series easy to review, read and understand. When a commit series has too many commits that changes the previous commits, it becomes hard to review.</p>



<h2>Ripe to merge?</h2>



<p>When the pull request is ripe for merging (independently of who authored it), I switch over to the master branch again and I merge the pull request’s commits into it. In special cases I cherry-pick specific commits from the branch instead. When all the stuff has been yanked into master properly that should be there, I push the changes to the remote.</p>



<p>Usually, and especially if the pull request wasn’t done by me, I also go over the commit messages and polish them somewhat before I push everything. Commit messages should follow our style and mention not only which PR that it closes but also which issue it fixes and properly give credit to the bug reporter and all the helpers – using the right syntax so that our automatic tools can pick them up correctly!</p>



<p>As already mentioned above, I merge fast-forward or rebased into master. No merge commits.</p>



<h2>Never merge with GitHub!</h2>



<p>There’s a button GitHub that says “rebase and merge” that could theoretically be used for merging pull requests. I <em>never</em> use that (and if I could, I’d disable/hide it). The reasons are simply:</p>



<ol><li>I don’t feel that I have the proper control of the commit message(s)</li><li>I can’t select to squash a subset of the commits, only all or nothing</li><li>I often want to cleanup the author parts too before push, which the UI doesn’t allow</li></ol>



<p>The downside with not using the merge button is that the message in the  PR says “closed by [hash]” instead of “merged in…” which causes confusion to a fair amount of users who don’t realize it means that it actually means the same thing! I consider this is a (long-standing) GitHub UX flaw.</p>



<h2>Post merge</h2>



<p>If the branch has nothing to be kept around more, I delete the local branch again with “<code>git branch -d [name]</code>” and I remove it remotely too since it was completely merged there’s no reason to keep the work version left.</p>



<p>At any given point in time, I have some 20-30 different local branches alive using this approach so things I work on over time all live in their own branches and also submissions from various people that haven’t been merged into master yet exist in branches of various maturity levels. Out of those local branches, the number of concurrent pull requests I have in progress can be somewhere between just a few up to ten, twelve something.</p>



<h2>RELEASE-NOTES</h2>



<p>Not strictly related, but in order to keep interested people informed about what’s happening in the tree, we sync the <a href="https://github.com/curl/curl/blob/master/RELEASE-NOTES">RELEASE-NOTES</a> file every once in a while. Maybe every 5-7 days or so. It …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037365</guid>
            <pubDate>Mon, 09 Nov 2020 17:46:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lox: A word that hasn't changed sound or meaning in 8k years]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25037325">thread link</a>) | @fanf2
<br/>
November 9, 2020 | http://m.nautil.us/blog/-the-english-word-that-hasnt-changed-in-sound-or-meaning-in-8000-years | <a href="https://web.archive.org/web/*/http://m.nautil.us/blog/-the-english-word-that-hasnt-changed-in-sound-or-meaning-in-8000-years">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			

			<figure data-alt=""><img src="http://static.nautil.us/16021_16b2399ccd1419de9e098d7abf025eb6.jpg" width="733" alt=""><figcaption><span><i>The word</i> lox <i>was one of the clues that eventually led linguists to discover who the Proto-Indo-Europeans were, and where they lived.</i></span><span>Photograph by Helen Cook / Flickr</span></figcaption></figure><p><span>O</span>ne of my favorite words is <i>lox</i>,” says Gregory Guy, a professor of linguistics at New York University. There is hardly a more quintessential New York food than a lox bagel—a century-old popular appetizing store, Russ &amp; Daughters, <a href="https://www.eater.com/2014/6/30/6201785/the-classic-bagel-and-salmon-sandwich-at-russ-daughters-in-new-york" target="_blank">calls</a> it “The Classic.” But Guy, who has lived in the city for the past 18 years, is passionate about lox for a different reason. “The pronunciation in the Proto-Indo-European was probably ‘lox,’ and that’s exactly how it is pronounced in modern English,” he says. “Then, it meant salmon, and now it specifically means ‘smoked salmon.’ It’s really cool that that word hasn’t changed its pronunciation at all in 8,000 years and still refers to a particular fish.”</p><p>How scholars have traced the word’s pronunciation over thousands of years is also really cool. The story goes back to Thomas Young, also known as “The Last Person Who Knew Everything.” The 18th-century British polymath came up with the wave theory of light, first described astigmatism, and played a key role in deciphering the Rosetta Stone. Like some people before him, Young noticed eerie similarities between Indic and European languages. He went further, analyzing 400 languages spread across continents and millennia and proved that the overlap between some of them was too extensive to be an accident. A single coincidence meant nothing, but each additional one increased the chance of an underlying connection. In 1813, Young declared that all those languages belong to one family. He named it “Indo-European.”</p><p>Today, roughly half the world’s population speaks an Indo-European language. That family includes 440 languages spoken across the globe, including English. The word <i>yoga</i>, for example, which comes from Sanskrit, the language of ancient India, is a distant relative of the English word <i>yoke</i>. The nature of this relationship puzzled historical linguists for two centuries.</p><p>In modern English, well over half of all words are borrowed from other languages. To trace how language changes over time, linguists developed an ingenious toolkit. “Some parts of vocabulary are more stable and don’t change as much. The linguistic term [for these words] is ‘a core vocabulary.’ These are numbers, colors, family relations like ‘mother,’ ‘father,’ ‘sister,’ ‘brother,’ and basic verbs like ‘walk’ and ‘see,’ says Guy. “If you look at words of that sort in different languages, it becomes fairly clear which ones are related and which ones are not. For example, take the English word for number <i>two</i>, which is <i>dva</i> in Russian and <i>deux</i> in French, or the word <i>night</i>, which is <i>nacht</i> in German and <i>noch</i> in Russian.”</p><blockquote><p>“The sounds that change across time are unpredictable, and differ from language to language, and some may not happen to change at all.”</p> </blockquote><p>Analyzing the patterns of change that words undergo, moving from one language to another, showed how to unwind these changes and identify the possible originals. “Reconstructed vocabulary of Indo-European is based on a comparison of descendant languages,” explains Guy. “You collect words that mean more or less the same thing in all the languages, and if they look like each other in terms of their pronunciation, then it’s a good candidate for a descendant from a common ancestor.” The English word <i>honey</i> is <i>madhu</i> in Sanskrit and <i>myod</i> in Russian. Sanskrit and Russian haven’t shared a common ancestor since Indo-European, so these words had to come from the same source. (There are also the words <i>mead</i> in English, <i>met</i> in German and <i>mjød</i> in Danish that refer to an alcoholic drink made from honey.)<br></p><p>After discovering a word that might have existed in the Indo-European, linguists compared how its pronunciations changed from language to language. For example, sound [k] changes to [h] from Latin to Germanic, and the Latin word <i>casa</i> transforms into the English <i>house </i>while&nbsp;the French word <i>cœur</i> transforms into the English <i>heart</i>.*&nbsp;With hints like that, linguists could undo the sound changes and trace the original pronunciation. In several thousand years, most words change beyond recognition, like the word <i>wheel</i>, which initially might have sounded “kʷékʷlos.” But there were some remarkable exceptions—like the timeless <i>lox</i>.</p><p>The <a href="https://upload.wikimedia.org/wikipedia/commons/4/4f/IndoEuropeanTree.svg" target="_blank">family tree</a> of the Indo-European languages sprawls across Eurasia, including such different species as English and Tocharian B, an extinct language once spoken on the territory of Xinjiang in modern China. In Tocharian B, the word for “fish/salmon” is <i>laks</i>, similar to German <i>lachs</i>, and Icelandic <i>lax</i>—the only ancestor all these languages share is the Proto-Indo-European. In Russian, Czech, Croatian, Macedonian, and Latvian, the [k] sound changed to [s,] resulting in the word <i>losos</i>. </p><div id="inpagesub">
	<p>Get the <span>Nautilus</span> newsletter</p>
<p>
	The newest and most popular articles delivered right to your inbox!
</p>
			<!-- Begin MailChimp Signup Form -->
			




</div><p>This kind of millennia-long semantic consistency also appears in other words. For example, the Indo-European <i>porkos</i>, similar to modern English <i>pork</i>, meant a young pig. “What is interesting about the word <i>lox</i> is that it simply happened to consist of sounds that didn’t undergo changes in English and several other daughter languages descended from Proto-Indo-European,” says Guy. “The sounds that change across time are unpredictable, and differ from language to language, and some may not happen to change at all.”</p><p>The word <i>lox</i> was one of the clues that eventually led linguists to discover who the Proto-Indo-Europeans were, and where they lived. The fact that those distantly related Indo-European languages had almost the same pronunciation of a single word meant that the word—and the concept behind it—had most likely existed in the Proto-Indo-European language. “If they had a word for it, they must have lived in a place where there was salmon,” explains Guy. “Salmon is a fish that lives in the ocean, reproduces in fresh water and swims up to rivers to lay eggs and mate. There are only a few places on the planet where that happens.”</p><p>In reconstructed Indo-European, there were words for <i>bear</i>, <i>honey</i>, <i>oak tree</i>, and <i>snow</i>, and, which is also important, no words for <i>palm tree</i>, <i>elephant</i>, <i>lion</i>, or <i>zebra</i>. Based on evidence like that, linguists reconstructed what their homeland was. The only possible geographic location turned out to be in a narrow band between Eastern Europe and the Black Sea where animals, trees, and insects matched the ancient Indo-European words.</p><p>In the 1950s, archaeological discoveries backed up this theory with remnants of an ancient culture that existed in that region from 6,000 to 8,000 years ago. Those people used to build kurgans, burial mountains, that archaeologists excavated to study cultural remains. In that process, scholars not only learned more about the Proto-Indo-Europeans but also why they were able to migrate across Europe and Asia.</p><p>In turned out that, in the past, the grassy plains of steppe that run from Western China to the Black Sea had large herds of wild horses. Early humans hunted them for food, but the Proto-Indo-Europeans were probably the first people who <a href="https://www.pnas.org/content/pnas/109/21/8202.full.pdf" target="_blank">domesticated</a> the ancestors of modern-day domestic horses. That brought them an enormous advantage, allowing them to move a lot faster than any other human group. Then, they adopted—or, less likely, invented—wheeled vehicles and attached these to horses. “That’s probably the moment when they suddenly managed to expand into the Middle East, into India, and across Europe,” says Guy. “Within the next thousands of years, they expanded like no other human group that we know about in history. Because [now] they had mobility, which nobody else had.”</p><p>In his book <i>The Power of Babel</i>, Columbia University linguist John McWhorter wrote, “Everything about a language is eternally and inherently changeable, not just the slang and the occasional cultural destination, but the very sound and meaning of basic words, and the word order and grammar.” It’s nice to know, though, that some words never change—<i>lox</i> being one of the most surprising.</p><p><i>Sevindj Nurkiyazova is a journalist from Kyrgyzstan. Follow her on Medium&nbsp;<a href="https://medium.com/@calempir" target="_blank">@calempir</a>.</i></p><p><i>*This sentence was changed so as not to imply that Germanic languages descend from Latin ones.</i></p><p><i>This classic Facts So Romantic&nbsp;post was originally&nbsp;published in May 2019.</i></p>

		</div></div>]]>
            </description>
            <link>http://m.nautil.us/blog/-the-english-word-that-hasnt-changed-in-sound-or-meaning-in-8000-years</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037325</guid>
            <pubDate>Mon, 09 Nov 2020 17:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Rust Is the Future of Game Development]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 236 (<a href="https://news.ycombinator.com/item?id=25037147">thread link</a>) | @adamnemecek
<br/>
November 9, 2020 | https://thefuntastic.com/blog/why-rust-is-the-future-game-dev? | <a href="https://web.archive.org/web/*/https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-10b1bd0a="" data-v-2ae295f5=""><p><em>Rust, not related to the video game also called Rust, is a promising systems programming language with novel features ideally suited for game development. Exposure and awareness within the game developer community, however, remains limited. In this post, I provide a gentle introduction to Rust and attempt to justify its place on your radar.</em></p>
<h2 id="a-short-history-lesson">A Short History Lesson</h2>
<p>What is Rust, and where did it come from? In <a href="https://www.youtube.com/watch?v=HiWkMFE8uRE" target="_blank" rel="nofollow noopener noreferrer">this fantastic talk</a>, James Munns gives us a detailed oral history. Way back around 2010, Mozilla was frustrated by the state of development in Firefox, a massive software project  written mostly in C++. Despite best practices and an abundance of engineering talent, writing high-performance, parallelised, and memory-safe code, at that scale of complexity, remained fraught and error-prone.</p>
<p>Bear in mind, this predates the advent of C++11 (aka the 2011 edition) which heralded efforts to somewhat modernise the language. Even so, manual memory manipulation is easy to get wrong, and <a href="https://msrc-blog.microsoft.com/2019/07/18/we-need-a-safer-systems-programming-language/" target="_blank" rel="nofollow noopener noreferrer">research</a> from <a href="https://www.zdnet.com/article/chrome-70-of-all-security-bugs-are-memory-safety-issues/" target="_blank" rel="nofollow noopener noreferrer">multiple vendors</a> describes this category of error as responsible for 70% of security vulnerabilities. </p>
<p>Into this context steps Graydon Hoare, a Mozilla employee, introducing <a href="https://en.wikipedia.org/wiki/Rust_(programming_language)#History" target="_blank" rel="nofollow noopener noreferrer">a potential solution</a> to the roadblock: Rust, the hobby language he'd been tinkering with since 2006. In 2012, Mozilla would formally announce Servo, an experimental research project to re-imagine a browser engine built with memory safety and concurrency as first principles. And alongside it, Rust, the companion language to make it all possible.</p>
<p>These early days of Rust are described as a Cambrian explosion of ideas and wild experimentation. Concepts were liberally stolen from other languages, from C++ to OCaml, Haskell, Erlang, ML, C#, Ruby and more, reflecting the diverse pool of engineers working on the language at the time. Still, most in the industry, while admiring the optimism in taking such an ambitious moon shot, <a href="http://dtrace.org/blogs/bmc/2018/09/18/falling-in-love-with-rust/" target="_blank" rel="nofollow noopener noreferrer">remained pessimistic</a> about the prospects of success. </p>
<p>2015 saw a major milestone, with the release of Rust v1.0. Perhaps as significant as the feature list, was the number of failed experiments left behind on the cutting room floor, the team unafraid to pare down the language to its quintessential elements. This was also the first time stability guarantees would be offered, a quality notoriously absent before. </p>
<p>Soon after, in 2016, Firefox <a href="https://hacks.mozilla.org/2016/07/shipping-rust-in-firefox/" target="_blank" rel="nofollow noopener noreferrer">shipped its first production Rust code</a>. The industry and community started to take notice, and Rust began its impressive, and as yet unbroken, <del>four</del> <a href="https://stackoverflow.blog/2020/01/20/what-is-rust-and-why-is-it-so-popular/" target="_blank" rel="nofollow noopener noreferrer">five year streak</a> as Stack Overflow's most beloved language. [<em>Thank you James Munns for pointing out it's now actually five years</em>]. </p>
<p>Right from the outset, Rust set out with a clear focus on   building an inclusive community. They, in turn, have contributed to Rust's impressive technical aptitude, but have also fostered a sense of reverence and fondness not often witnessed in other languages. Are they crazy zealots or onto something?</p>
<h2 id="why-rust">Why Rust?</h2>
<blockquote>
<p><em>The performance of C++ with the convenience of C#</em></p>
</blockquote>
<p>This was the first time Rust hijacked my attention. C++ enjoys a long-standing ubiquity, in part, due to its ability to express zero cost abstractions. As explained by Bjarne Stroustrup, the creator of C++:</p>
<blockquote>
<p><em>What you don't use, you don't pay for. And further: What you do use, you couldn't hand code any better.</em></p>
</blockquote>
<p>It's easy to spot the relevancy to games. Making frame-rate while simulating entire worlds is a daunting performance challenge. Indeed, C++ underpins the bulk of game engines. There simply is <a href="https://www.youtube.com/watch?v=ltCgzYcpFUI" target="_blank" rel="nofollow noopener noreferrer">no other industrial language</a> that offers the same speed and low-level control, whilst writing programs in the large. </p>
<p>C++, however, suffers from the weight of its legacy. The accumulation of features over 40 years makes for a complex and intricate language. In the last decade modernisation of the standard has done well to uplift it from its C roots, but the experienced programmer must build up an arcane lore of which features are blessed, and which machinery is dangerous. As Stroustrup again describes:  </p>
<blockquote>
<p>Within C++, there is a much smaller and cleaner language struggling to get out.   </p>
</blockquote>
<p>This makes the language daunting and difficult to approach for beginners. In <a href="https://boats.gitlab.io/blog/post/zero-cost-abstractions/" target="_blank" rel="nofollow noopener noreferrer">this blog post</a>, Rust contributor <em>withoutboats</em> defines an import quality about abstraction:  </p>
<blockquote>
<p>A zero cost abstraction, like all abstractions, must actually offer a better experience than the alternative.</p>
</blockquote>
<p>So yes, of course, C++ offers a better time than your own hand wrought assembly. However, this is making the subtle point that it's competing against a secondary force: a more expensive abstraction that justifies its cost by being more comfortable and convenient.</p>
<p>We see this writ large in the rise of popular game engines that eschew the complexity of C++, the most notable being Unity. End users write code in C#, a more forgiving and ergonomic language, creating a boon in developer productivity and a reduction in iteration time.  </p>
<p><img src="https://thefuntastic.com/blog/2020-10-Unity-Interest.png" title="Unity interest over time in search trends"></p>
<p>In large codebases though, near the edge of the performance envelope, this trade-off begins to bite. The garbage collector eliminates an entire category of errors by removing responsibility for memory management from the end-user. However as its workload grows, so do periodic performance spikes antithetical to smooth gameplay.  </p>
<p><img src="https://thefuntastic.com/blog/2020-11-GC-spikes.png" title="Unity interest over time in search trends"></p>
<p>The experienced developer can still create a performant experience, however, this demands plugging the leaks in the abstraction. They must build a mental model of the machinery behind the curtain, a collection of arcane wisdom that bans many of the original conveniences, lest they disturb the garbage collector. </p>
<p>So development teams face a choice. Better resourced AAA studios generally choose Unreal or in-house engine tech built on C++, able to absorb the overhead for long term gain. Less resourced studios optimise for time to market, choosing Unity, or one of the many other accessible game making tools (Godot, Haxe, Game Maker, etc.). They often postpone performance concerns until after business eligibility is secured.   </p>
<p>Rust, however, for the first time, promises a third way. A world where it's possible to write zero cost abstractions without sacrificing higher-order elegance. </p>
<h3 id="ownership-based-memory">Ownership based memory</h3>
<p>To understand Rust's special sauce, we're going have to talk about ownership and how it handles memory. This is only a simple sketch, but <a href="http://intorust.com/tutorial/ownership/" target="_blank" rel="nofollow noopener noreferrer">in-depth resources</a> exist for the curious. </p>
<p>Writing optimised code is often about taking the way we, as humans, naturally think of an idea or algorithm, and instead expressing it in terms that favour the computer. This act often harms the legibility and understanding of a program, which makes it much harder for us, the humans, to reason about its correctness. </p>
<p>In a manually managed language, like C, the hapless programmer is left responsible for the machinations of the machine. They must take great care to ensure data is appropriately loaded into memory before operation, and then responsibly disposed of afterwards. A difficult dance in which missteps either cause dramatic crashes or else subtle and hard to detect vulnerabilities. But these are the very same tools that allow careful users to tune performance.  </p>
<p>At the other end of the spectrum, garbage collection promises the programmer it will automatically deal with the problem on their behalf. They are now free to express code naturally, but in doing so, it ties hands behind their back. They no longer have, at least not without indirection, the levers needed to wring out maximal performance.</p>
<p>Rust begins from a different premise. Rather than hiding this complexity, it accepts that computers are hard for humans, and instead tries to save us from the dangerous bits. Users can still tune the machine, but with less rope to wrap around their necks. </p>
<p>In the same way that static typing exists, very clever people have figured out how to make the compiler eliminate a whole category of memory and concurrency errors. To achieve this, Rust makes a bargain with the developer: </p>
<blockquote>
<p>"I'm going to keep track of the lifetime of every piece of memory in your program for you. This way, I can detect the moment you're no longer using it and safely free it on your behalf. But in return, I'm going to need you to follow <a href="https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html" target="_blank" rel="nofollow noopener noreferrer">strict rules</a> about the ownership of that memory. If you try to use it outside of the scope that owns it, my humourless friend here, the borrow checker, is going to make sure you don't hurt yourself."</p>
</blockquote>
<p>However, like static typing, this lunch isn't free. Rust is known to have a steep learning curve, "fighting the borrow checker" becomes a right of passage. It takes time to learn this new paradigm. Ownership makes some familiar patterns difficult or impossible and demands new ones be learnt in their place. Perhaps we should revise our earlier statement as: "The performance of C++ with the <del>convenience</del> safety of C#"</p>
<h2 id="unpacking-rusts-popularity">Unpacking Rust's Popularity</h2>
<p>Early adopters have a selfish reason to extol the virtues of their chosen technology, as widespread adoption enhances the return on their risky investment. In this respect, while interest is high but opportunities for real-world exposure are limited, is it possible that Rust is cresting a wave of unearned hype? <a href="https://matklad.github.io/2020/09/20/why-not-rust.html" target="_blank" rel="nofollow noopener noreferrer">Not every javascript or python developer</a> interested in the language, for example, has a use case that merits the additional complexity.</p>
<p>To a developer standing on the shores of 2010, <code>git</code>, a new version control system with a steep learning curve, may have seemed like a risky investment. But, in the ensuing world of Github, it's hard to argue the effort was wasted, even if some workloads (i.e. large games) still require alternatives.</p>
<p>In a similar vein, how can we qualify Rust's popularity as a meaningful signal? Ultimately, we will only know by the volume of mud we've dug through in the trenches, and admittedly, it is far too early to collect this data for games. </p>
<p>In other industries, though, early reports of Rust are effusive. <a href="https://medium.com/the-innovation/how-microsoft-is-adopting-rust-e0f8816566ba" target="_blank" rel="nofollow noopener noreferrer">Mircosoft</a>, <a href="https://developers.libra.org/docs/community/coding-guidelines" target="_blank" rel="nofollow noopener noreferrer">Facebook</a>, <a href="https://aws.amazon.com/blogs/opensource/aws-sponsorship-of-the-rust-project/" target="_blank" rel="nofollow noopener noreferrer">Amazon</a>, <a href="https://www.wired.com/2016/03/epic-story-dropboxs-exodus-amazon-cloud-empire/" target="_blank" rel="nofollow noopener noreferrer">Dropbox</a>, <a href="https://blog.cloudflare.com/tag/rust/" target="_blank" rel="nofollow noopener noreferrer">Cloudflare</a> all have Rust deployed in production. The <a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=Linux-Kernel-Rust-Path-LPC2020" target="_blank" rel="nofollow noopener noreferrer">Linux Kernel</a> and <a href="https://www.chromium.org/Home/chromium-security/memory-safety/rust-and-c-interoperability" target="_blank" rel="nofollow noopener noreferrer">Chrom…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?">https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?</a></em></p>]]>
            </description>
            <link>https://thefuntastic.com/blog/why-rust-is-the-future-game-dev?</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037147</guid>
            <pubDate>Mon, 09 Nov 2020 17:27:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Peeking Inside the Black Box: Explaining Artificial Intelligence Models]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25037136">thread link</a>) | @asafg6
<br/>
November 9, 2020 | https://www.turtle-techies.com/peeking-inside-the-black-box/ | <a href="https://web.archive.org/web/*/https://www.turtle-techies.com/peeking-inside-the-black-box/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h4>Explaining Artificial Intelligence models</h4><p><h5>2020-11-08</h5></p></div><div><div itemprop="articleBody"><h2 id="a-brief-introduction">A Brief Introduction <a href="#a-brief-introduction"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>We live in the age of data and new technologies.
More and more, Artificial Intelligence is coming to our lives, from the image processing after a picture is shot in our phones to the recommendation algorithm in most content places.
And the number of companies that want to introduce some AI process to their workflow increases by the minute.</p><p>Soon, AI systems will be diagnosing illnesses, granting mortgages, etc.
But then doubts arise.
A lot of those AI systems will be black box systems, most likely Neural Networks or Ensembles.
Basically a lot of automatic learned equations and parameters that are going to tell everybody if they are fit to buy a house, or if they have this or that illness.<br>But can we really trust these systems? They have been proven wrong in the past, showing incredible and unexpected
<a href="https://metro.co.uk/2017/07/13/racist-soap-dispensers-dont-work-for-black-people-6775909/" target="_blank">biases</a>.</p><p>Here is why the trend is moving towards making AI fair and understandable.
There are great initiatives like
<a href="https://www.fast.ai/" target="_blank">fast.ai</a> that focus on unbiased AI, but here we are going to use some of the latest framework to <strong>explain existing models</strong>.<br>Whether you have an AI pipeline in your company or you are learning how to use the latest Neural Network models, this tutorial will explain you a bit more about what is going on inside that process.</p><h2 id="anchor">Anchor <a href="#anchor"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>There are plenty of papers researching XAI (eXplainable Artificial Intelligence), but there are not so many frameworks that can currently take an existing model and explain its internal processes.
This kind of <em>post-hoc explanation</em> is very interesting because it does not have to reimplement and retrain the existing pipelines, but rather can work as a new addition to those pipelines.</p><p>In this article we will explain
<a href="https://github.com/marcotcr/anchor" target="_blank">Anchor</a>, a state-of-the-art library programmed in Python which has proven efficiency and is considered the rival to beat when developing new algorithms.
Anchor is an open-source library that learns a model-agnostic model (this is, it works with any kind of machine learning algorithm).
This model generates a set of rules (or anchors, hence the name) that classify and explain each particular example. Anchor can work with a variety of data, from text to images or tabular.
In this article, we will explain how to use it on a tabular database.</p><h2 id="installing-anchor">Installing Anchor <a href="#installing-anchor"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>To install Anchor, we will need Python 3.7 or greater. To install the package from
<a href="https://pypi.org/" target="_blank">PyPI</a> just type:</p><p>Or clone their repository and install the package:</p><div><pre><code data-lang="Bash">
git clone https://github.com/marcotcr/anchor.git
python setup.py install

</code></pre></div><h2 id="installing-additional-elements">Installing Additional Elements <a href="#installing-additional-elements"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>First step will be to choose our database and to train our model. In this article we will use the very well known
<a href="https://archive.ics.uci.edu/ml/datasets/iris" target="_blank">iris database</a> that we can find packaged inside
<a href="https://scikit-learn.org/stable/" target="_blank">Scikit Learn</a>.</p><p>This is a flower database with 150 registers of different iris flowers. Each register measures both sepal and petal lengths in centimeters, and the target class is the type of iris (setosa, versicolor or virginica).</p><p>To install Scikit-Learn type in the terminal:</p><p>To train a model, we will use one of the best Python libraries out there:
<a href="https://xgboost.readthedocs.io/en/latest/" target="_blank">XGBoost</a>.</p><p>This will train a tree ensemble that grants a great accuracy.
Again, to install it type:</p><h2 id="training-our-model">Training our model <a href="#training-our-model"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>Now we are ready to train our model.
The first step will be to import everything we need:</p><div><pre><code data-lang="Python">
<span>import</span> xgboost <span>as</span> xgb

<span>from</span> sklearn <span>import</span> datasets
<span>from</span> sklearn.model_selection <span>import</span> train_test_split

<span>from</span> anchor <span>import</span> anchor_tabular

</code></pre></div><p>Here we have imported:</p><ul><li>The library to train our model (xgboost)</li><li>The datasets</li><li>A function to automatically generate the train and the test sets to properly validate the model</li><li>Anchor</li></ul><p>Next step will be to load the database:</p><div><pre><code data-lang="Python">
iris <span>=</span> datasets<span>.</span>load_iris()

X_train, X_test, y_train, y_test <span>=</span> train_test_split(iris<span>.</span>data, iris<span>.</span>target, test_size<span>=</span><span>0.3</span>, random_state<span>=</span><span>42</span>)

</code></pre></div><p>In this step, we load the iris dataset from the scikit package.<br>In this format, <code>iris.data</code> contains a series of <code>numpy</code> arrays with the features of the 150 registers, and <code>iris.target</code> contains an array of the prediction (as integers).
Then, we split the data in train and test sets.
This way, we have a random 70% of the database that will be used to train the model, and the 30% remaining that we will use to test the score.
We will also use it later to get some registers unknown to the model that we will be able to classify and explain.</p><p>Now it is time to train the model:</p><div><pre><code data-lang="Python">
xgb_model <span>=</span> xgb<span>.</span>XGBClassifier(random_state<span>=</span><span>42</span>)
xgb_model<span>.</span>fit(X_train, y_train)

</code></pre></div><p>The library <code>XGBoost</code> implements a
<a href="https://en.wikipedia.org/wiki/Gradient_boosting" target="_blank">Gradient Boosting</a> algorithm.<br>What it does is to generate an ensemble of weak models that combine to generate a strong classifier.</p><p>This is typically done by training very shallow decision trees with random sets of data so that they are different from each other.
When they combine by
<a href="https://en.wikipedia.org/wiki/Boosting_%28machine_learning%29" target="_blank">boosting</a> they generate a very powerful model.</p><p>This is a classification problem, so we use a Classifier (not a Regressor).</p><blockquote><p>For this database we can leave the default parameters as is.<br>For other databases, you might need to fine-tune the model.
You can get all you need from the
<a href="https://xgboost.readthedocs.io/en/latest/python/python_api.html" target="_blank">docs</a>.</p></blockquote><p>The model is trained just with the train data. Let’s see how it performs:</p><div><pre><code data-lang="Python">
<span>print</span>(xgb_model<span>.</span>score(X_test, y_test)) <span># 0.98</span>

</code></pre></div><p>If everything is correct, the score should be <code>0.98</code> or higher, given the randomness of some parts of the algorithm.</p><p>Impressive, but this will not tell us <strong>why a particular register is classified in some way</strong>.<br>For this, we will need to apply Anchor.</p><h2 id="applying-anchor-to-our-model">Applying Anchor to our model <a href="#applying-anchor-to-our-model"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>The first step will be to create the <code>explainer</code>.
This is the element that will take the model and explain the registers:</p><div><pre><code data-lang="Python">
explainer <span>=</span> anchor_tabular<span>.</span>AnchorTabularExplainer(class_names<span>=</span>iris<span>.</span>target_names,
                                                    feature_names<span>=</span>iris<span>.</span>feature_names,
                                                    train_data<span>=</span>X_train)

</code></pre></div><p>The <code>explainer</code> takes three parameters:</p><ul><li>The name of each feature</li><li>The name of each class value</li><li>The same data we have used to train the model.</li></ul><p>Note that we are not giving any data from our test set, the explainer does not use that to train.
This way, the explainer doesn’t know the test data, just like the model.</p><p>Let’s take the register with index 30 (at random) from out test data.<br>Pass it through our model:</p><div><pre><code data-lang="Python">
idx <span>=</span> <span>30</span>
np<span>.</span>random<span>.</span>seed(<span>1</span>)
<span>print</span>(<span>'Prediction: '</span>, explainer<span>.</span>class_names[xgb_model<span>.</span>predict(X_test[idx]<span>.</span>reshape(<span>1</span>, <span>-</span><span>1</span>))[<span>0</span>]])

</code></pre></div><pre><code>
Prediction:  setosa

</code></pre><p>Our <code>xgb_model</code> predicts that it will be a <code>setosa</code> output, but why?</p><p>Let’s generate the explanation:</p><div><pre><code data-lang="Python">
exp <span>=</span> explainer<span>.</span>explain_instance(X_test[idx], xgb_model<span>.</span>predict, threshold<span>=</span><span>0.95</span>)

</code></pre></div><p>Here is where the magic happens.<br>We pass the explainer the register we want to explain and the <code>predict</code> function from our model.
This is the good thing about Anchor: as long as the <code>predict</code> function can take a numpy array and return an integer as a prediction, it will work with absolutely any model out there! Even with custom ones you can program.
Note that there is a <code>threshold</code> parameter.
This means that the predictions for the explanation it has generated will hold at least 95% of the time.
But how to show that explanation?</p><p>With this code:</p><div><pre><code data-lang="Python">
<span>print</span>(<span>'Anchor: </span><span>%s</span><span>'</span> <span>%</span> (<span>' AND '</span><span>.</span>join(exp<span>.</span>names())))
<span>print</span>(<span>'Precision: </span><span>%.2f</span><span>'</span> <span>%</span> exp<span>.</span>precision())
<span>print</span>(<span>'Coverage: </span><span>%.2f</span><span>'</span> <span>%</span> exp<span>.</span>coverage())

</code></pre></div><pre><code>
Anchor: 1.70 &lt; petal length (cm) &lt;= 5.10 AND petal width (cm) &lt;= 1.30 AND sepal length (cm) &gt; 5.80
Precision: 1.00
Coverage: 0.06

</code></pre><p>Here we are.
Now we know that our register is a <code>setosa</code> because its petal length is smaller than 1.7 and so on.
We also know that 100% of the registers that match this rule are <code>setosa</code> and that 6% of the training registers match this rule.
With this, we have not only explained what is happening in the model, but also how confident we are in these rules.</p><h2 id="what-is-an-anchor">What is an Anchor <a href="#what-is-an-anchor"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>All right, so now we have a rule or <em>anchor</em> that can explain the registry.<br>But how are they computed? Well, the deep mathematics of the anchor are a bit complicated, but the gist of it is as follows.<br>First, the system determines a probability for a certain <em>anchor</em> to get its precision.<br>Then, using a
<a href="https://en.wikipedia.org/wiki/Greedy_algorithm" target="_blank">greedy algorithm</a>, it starts adding features, values and splits (such as [<code>petal length (cm)</code>, <code>1.7</code>, <code>&lt;</code>]) and computing the best next addition.<br>The system keeps searching the best <em>anchor</em> according to the precision threshold, so that it returns the <strong>shortest</strong> anchor for the specified threshold.
It is not very explainable if the rule has 70 features, is it?<br>The nitty gritty part of the search is more complex, but if you want to have a look feel free to check the original
<a href="https://homes.cs.washington.edu/~marcotcr/aaai18.pdf" target="_blank">article</a>, where everything is explained.</p><h2 id="closing-words">Closing words <a href="#closing-words"><svg height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></h2><p>In these days where AI is taking over more and more functions and processes, it is very easy to just let it decide for us without knowing why.
But there are aspects in life too important to just blindly trust a machine.
With Anchor, we have a library that is easy to add to any machine learning pipeline where the trust of each answer is as important as the answer itself.</p></div></div></div>]]>
            </description>
            <link>https://www.turtle-techies.com/peeking-inside-the-black-box/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037136</guid>
            <pubDate>Mon, 09 Nov 2020 17:27:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[18th Century England Had No Police]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25037076">thread link</a>) | @willbobaggins
<br/>
November 9, 2020 | https://narrativespodcast.com/2020/11/09/narratives-podcast-episode-15-economics-law-and-the-future-with-david-friedman/ | <a href="https://web.archive.org/web/*/https://narrativespodcast.com/2020/11/09/narratives-podcast-episode-15-economics-law-and-the-future-with-david-friedman/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1924">

                    
                    <div>
                        
<p>This week on the podcast, we have David Friedman. David holds a PhD in physics from the University of Chicago, he is chiefly known for his scholarly contributions to economics and law. He is the author of five books of non‐​fiction as well as three novels. We discuss the future, legal systems very different from our own, how technology drives progress, and what the future might look like.&nbsp;</p>



<figure></figure>
                                            </div>

                </article></div>]]>
            </description>
            <link>https://narrativespodcast.com/2020/11/09/narratives-podcast-episode-15-economics-law-and-the-future-with-david-friedman/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037076</guid>
            <pubDate>Mon, 09 Nov 2020 17:21:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Canadian government pledges to connect 98% of Canadians via High-Speed Internet]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25037074">thread link</a>) | @aDfbrtVt
<br/>
November 9, 2020 | https://www.cbc.ca/news/politics/broadband-internet-1.5794901 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/broadband-internet-1.5794901">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The Liberal government is promising to spend more than a billion dollars to connect most Canadian to high-speed internet by 2026.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4962390.1546282434!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/broadband-expansion.jpg"></p></div><figcaption>The Liberal government has been promising to do something to approve broadband internet service in rural areas.<!-- --> <!-- -->(Toby Talbot/Associated Press)</figcaption></figure><p><span><p>After some pandemic-related delays, the Liberal government says it's now&nbsp;on track to connect 98 per cent of Canadians to high-speed internet by 2026.</p>  <p>The announcement comes as more Canadians find themselves living online while stuck at home due to COVID-19 restrictions.</p>  <p>Prime Minister Justin Trudeau and a handful of cabinet ministers&nbsp;held a news conference in Ottawa to launch the $1.75 billion universal broadband fund — a program unveiled in the federal government's 2019 budget and highlighted on the campaign trail and in&nbsp;September's throne speech. Most of the money&nbsp;was&nbsp;announced in last year's budget.</p>  <p>"We were ready to go&nbsp;in March&nbsp;with the new Universal Broadband Fund and then the pandemic hit,"&nbsp;Rural Economic Development Minister Maryam Monsef told reporters.</p>  <p>The prime minister said the government is now on track to connect&nbsp;98 per cent of Canadians&nbsp;to high-speed&nbsp;by 2026 — an increase over&nbsp;the previously promised 95 per cent benchmark — and to link up&nbsp;the rest by 2030.</p>  <p>"These are ambitious targets&nbsp;and we're ready to meet them,"&nbsp;Trudeau said.</p>  <p><em><strong>WATCH |&nbsp;Trudeau announces a large investment in broadband services for rural Canadians</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="Trudeau announces a large investment in broadband services for rural Canadians"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/573/747/ftr%20TRUDEAU%20broadband_frame_0.jpg" alt=""></p></div></div></div><span>Prime Minister Justin Trudeau spoke with reporters during a media briefing in Ottawa on Monday.<!-- --> <!-- -->2:47</span></span></span></p>  <p>About&nbsp;$150 million from the fund will be freed up to fund projects aimed at getting communities connected by next fall.</p>  <p>Senior officials with the department of&nbsp;Innovation, Science and Economic Development&nbsp;said applications will be reviewed on an ongoing basis until Jan. 15, 2021, with a goal of having projects completed by mid-November, 2021.</p>  <p>Deciding who gets upgraded connectivity first will depend on the service providers applying, they said.</p>  <p>Josh Tabish is&nbsp;corporate communications manager at the Canadian Internet Registration Authority, the not-for-profit agency that manages the .ca internet domain. He said he's hoping&nbsp;that a&nbsp;rapid build will bring relief to many Canadians over the next year.</p>    <p>"In terms of action, I think&nbsp;this is great news for Canadians who are stuck at home suffering from slow, crappy internet," he said.&nbsp;</p>  <p>But Tabish also said he hopes the government will look at need when deciding which projects should get approval first.&nbsp;His group has been working to identify the&nbsp;communities that&nbsp;have the slowest&nbsp;rates in Canada.</p>  <p>"What we really want to see happen is communities who are suffering with slow, sluggish connectivity get those upgrades first," he said.</p>  <p>The prime minister said the government also&nbsp;has reached a $600 million agreement with Telesat for satellite capacity to improve broadband service in remote areas and in the North.</p>    <p>"Good reliable internet isn't a luxury. It's a basic service," he said.</p>  <p>"Now more than ever, a video chat cutting out during a meeting or a connection that's too slow to upload a school assignment — that's not just a hassle, that's a barrier."</p>  <h2>Tories call out timelines</h2>  <p>The Opposition Conservatives criticized the government's timelines, arguing Canadians need better access now more than ever.</p>  <p>"This is absolutely unacceptable and a slap in the face to the nearly one million Canadians who don't have internet access at home, much less a reliable cell phone signal," said MP John Nater, Conservative critic&nbsp;for rural economic development.</p>  <p>"For months, Canada's Conservatives have been demanding concrete action to connect Canadians.&nbsp;We will continue to advocate for lower cell phone prices and for real improvements to broadband internet services, so that Canadians living in rural and remote areas have consistent access to these essential services."</p>  <p>The&nbsp;CRTC <a href="https://www.cbc.ca/news/politics/crtc-internet-essential-service-1.3906664">declared</a> broadband internet a basic telecommunications service in 2016.&nbsp;But its data suggest&nbsp;just&nbsp;<a href="https://crtc.gc.ca/eng/internet/internet.htm">40.8 per cent of rural Canadian households have access to </a>download speeds of&nbsp;at least 50 megabits per second (Mbps) and upload speeds of&nbsp;10 Mbps.</p>  <p>The government said those speeds will allow Canadians to work and learn online and access telehealth services.</p>  <p><em><strong>WATCH | Rural Canadians react to today's announcement</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="Liberals promise to connect 98% of Canadians by 2030"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/732/431/politics_THURTON_broadband_money_7000kbps_1280x720_1817544259879.jpg" alt=""></p></div></div></div><span>After some pandemic-related delays, the Liberal government says it's now on track to connect 98 per cent of Canadians to high-speed internet by 2026. The announcement comes as more Canadians find themselves living online while stuck at home due to COVID-19 restrictions.<!-- --> <!-- -->1:47</span></span></span></p>  </span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/broadband-internet-1.5794901</link>
            <guid isPermaLink="false">hacker-news-small-sites-25037074</guid>
            <pubDate>Mon, 09 Nov 2020 17:21:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Converting Utzoo-Wiseman Usenet Tapes to PostgreSQL Back End Using Python]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25036780">thread link</a>) | @kxrm
<br/>
November 9, 2020 | https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/ | <a href="https://web.archive.org/web/*/https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="content" role="main" itemprop="mainEntityOfPage" itemscope="itemscope" itemtype="http://schema.org/Blog"> <article id="post-4678" itemscope="itemscope" itemtype="http://schema.org/BlogPosting" itemprop="blogPost"><div> <!-- .entry-header --><div itemprop="articleBody"><p>Recently, I came across a resource that allowed me to download the entire collection of UTZOO NetNews Archive of the earliest USENET posts. These were essentially the earliest available discussions posted to the Internet by people working at various Universities who were already connected to the Internet. There were approximately 2.1 million posts in these archives created between Feb 1981 and June of 1991. This article describes the journey of converting those tapes into fully searchable PostgreSQL database and later also into the <a href="https://usenetarchives.com/groups.php?c=utzoo" target="_blank" rel="noopener noreferrer">usenetarchives.com</a> website.</p><p>Until 2001, these early Usenet discussions were considered being lost, but miraculously <a href="https://en.wikipedia.org/wiki/Henry_Spencer" target="_blank" rel="noopener noreferrer">Henry Spencer</a> from the University of Toronto, Department of Zoology was backing it up onto magnetic tapes and kept them stored for all these years (apparently at a great cost).</p><p><a href="https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15.png"><img loading="lazy" src="https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15.png" alt="" width="325" height="259" srcset="https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15.png 1282w, https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15-300x239.png 300w, https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15-768x613.png 768w, https://www.joe0.com/wp-content/uploads/2019/02/2019-02-17_9-14-15-1024x817.png 1024w" sizes="(max-width: 325px) 100vw, 325px"></a>H. Spencer had altogether 141 of these magnetic tapes, but there were of no use, so eventually, him and a couple of motivated people such as David Wiseman (who dragged 141 tapes back and forth in his a pickup truck), Lance Bailey, Bruce Jones, Bob Webber, Brewster Kahle, and Sue Thielen; embarked on a process of converting all of these tapes into the regular format, accessible to everyone.</p><p>And that’s the copy I downloaded. What a treasure, right?</p><p>Well, not so fast, once I unzipped the data, I realized that the TGZ format contains literally millions of small text files (each post in its own file). While it was certainly nice to have, it wasn’t something that I or anyone else could read. Certainly not in a forum like discussion format. It wasn’t obvious which post is the one that starts the discussion or which ones are the replies to the thread. And forget about searching through these files, that was utterly not possible. Just to put things into perspective, it took me over 5 hours to un-tar the archives.</p><p>That said, it didn’t take long for me to decide to develop a Python-based converter that would allow me to convert the entire collection from millions of flat files into a fully searchable PostgreSQL database. The following post talks about the process and also includes the Python code of the solution released as open source.</p><p>The UTZOO Usenet archive can be downloaded here:</p><ul><li>http://www.skrenta.com/rt/utzoo-usenet/</li><li>http://shiftleft.com/mirrors/utzoo-usenet/</li><li>https://ipfs.io/ipfs/QmTo7fRxpXwxv6Uw4TAAtyLWEmvugKaggrHSKNBTRHzWcA/</li><li>Or using this torrent: <a href="https://www.joe0.com/wp-content/uploads/2020/10/utzoo-wiseman-usenet-archive_archive.zip">utzoo-wiseman-usenet-archive_archive</a></li></ul><p>Once downloaded you’ll see that archive contains 161 x TAR Archive files. It looks like this:</p><p><a href="https://www.joe0.com/wp-content/uploads/2019/02/img_5c69574363b87.png"><img loading="lazy" src="https://www.joe0.com/wp-content/uploads/2019/02/img_5c69574363b87.png" alt="" width="596" height="531" srcset="https://www.joe0.com/wp-content/uploads/2019/02/img_5c69574363b87.png 832w, https://www.joe0.com/wp-content/uploads/2019/02/img_5c69574363b87-300x268.png 300w, https://www.joe0.com/wp-content/uploads/2019/02/img_5c69574363b87-768x685.png 768w" sizes="(max-width: 596px) 100vw, 596px"></a></p><p>So, I grabbed a copy of the 7-Zip archiver from <a href="https://www.7-zip.org/">https://www.7-zip.org</a> and started decompressing the files.</p><p>I ended up with over <strong>2,104,828</strong>&nbsp;flat text files in <strong>56,988</strong> folders, which was the entire copy of Henry Spencer’s Usenet archive.</p><p>For those who like numbers, here is each Utzoo tape along with its size, number of files and folders:</p><p id="MLqhONH"><img loading="lazy" width="602" height="2294" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e6e422f3ee.png" alt="" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e6e422f3ee.png 602w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e6e422f3ee-79x300.png 79w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e6e422f3ee-269x1024.png 269w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e6e422f3ee-403x1536.png 403w" sizes="(max-width: 602px) 100vw, 602px"></p><h3>File Issues</h3><p>While examining the extract, I realized that Magnetic Tape 118 is uncompressed in \utzoo-wiseman-usenet-archive\news118f1 folder, named tape118, so I had rename it to tape118.tar and extracted it manually, only to realize it’s a copy of files which I already have. Someone creating the original archive forgotten to remove that file. There are 3 files in these folders that need to have.tar extension added and decompressed as well:</p><ul><li>\utzoo-wiseman-usenet-archive\news118f1\tape118</li><li>\utzoo-wiseman-usenet-archive\news120f1\tape120</li><li>\utzoo-wiseman-usenet-archive\news121f1\tape121</li></ul><p>If you opened one of the folders and navigated down to one of the many subfolders, you’d find a file that contained the message. For example, going into&nbsp;\utzoo-wiseman-usenet-archive\news006f1\b15\net\aviation folder, I was now apparently in the <strong>net.aviation</strong> Usenet group. But the only way to find out was to open one of the files and look at the content. Here I highlighted what it looked like.&nbsp;As you can see, each file seems to consist of a header, then a single empty line and the body of the message:</p><p id="RYYsysr"><a href="https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c.png"><img loading="lazy" src="https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c.png" alt="" width="1110" height="759" srcset="https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c.png 1110w, https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c-300x205.png 300w, https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c-768x525.png 768w, https://www.joe0.com/wp-content/uploads/2019/02/img_5c6967453ae2c-1024x700.png 1024w" sizes="(max-width: 1110px) 100vw, 1110px"></a></p><p>So, I decided to build a Python parser, that went through all these files reading the header portion of each message and grouping all unique results together, giving me all the possible headers such as (From, Subject, Newsgroup, etc.). I found that there were about 79 x different types of headers. So it appeared that not all messages adhered to the same basic structure. Going through the headers, all had the standard set that was common across all posts.</p><p>Once I had the common field, I’ve created a Postgres database called ‘utzoo’</p><pre>create database utzoo;</pre><p>And a new schema called all_messages</p><pre>create schema all_messages;


</pre><p>The above database and schema were the pre-requisites. Everything else, like table creation, inserting the posts, etc. is part of the Python script and fully automated.</p><p>In terms of table creation, the script automatically creates 5 tables for each detected newsgroup:</p><ul><li>headers – parsed headers</li><li>references – references for each message</li><li>body – text of the message</li><li>from – who posted the message</li><li>subjects – list of unique subject lines</li></ul><p>This is what the script auto-creates for each unique Group name:</p><pre>create table all_messages.<strong>GroupName_headers</strong>
(
    id         bigserial not null
        constraint GroupName_headers_pk primary key,
    dateparsed timestamp,
    subj_id    bigint,
    ref        smallint,
    msg_id     text,
    msg_from   bigint,
    enc        text,
    contype    text,
    processed  timestamp default CURRENT_TIMESTAMP
);
alter table all_messages.GroupName_headers
    owner to postgres;


create table all_messages.<strong>GroupName_refs</strong>
(
    id      bigint,
    ref_msg text default null
);
alter table all_messages.GroupName_refs
    owner to postgres;

create table all_messages.<strong>GroupName_body</strong>
(
    id   bigint primary key,
    data text default null
);
alter table all_messages.GroupName_body
    owner to postgres;

create table all_messages.<strong>GroupName_from</strong>
(
    id   serial not null
        constraint GroupName_from_pk primary key,
    data text
);
alter table all_messages.GroupName_from
    owner to postgres;

create table all_messages.<strong>GroupName_subjects</strong>
(
    id      serial not null
        constraint GroupName_subjects_pk primary key,
    subject text
);
alter table all_messages.GroupName_subjects
    owner to postgres;</pre><p>Those will be the tables where the Python parser will dump all the data and make sure posts are properly lined up between tables.</p><p>The python script also creates indexes to make the inserting and later reading of the posts faster:</p><pre>create unique index GroupName_headers_uiidx on all_messages.GroupName_headers(id);
create unique index GroupName_headers_umidx on all_messages.GroupName_headers(msg_id);
create unique index GroupName_body_idx on all_messages.GroupName_body(id);; 
create unique index GroupName_from_idx on all_messages.GroupName_from(data);
create unique index GroupName_subjects_idx on all_messages.GroupName_subjects(subject);

</pre><p>Once created, the structure per group looks like this:</p><p id="kdsmyQE"><img loading="lazy" width="362" height="703" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3e7d98df4.png" alt="" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3e7d98df4.png 362w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3e7d98df4-154x300.png 154w" sizes="(max-width: 362px) 100vw, 362px"></p><p>The following screenshot explains how it’s all wired up. I didn’t do any hardcoded relationships, but you can change the script if you want that.</p><p id="THgecCD"><img loading="lazy" width="601" height="496" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e40111a6ef.png" alt="" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e40111a6ef.png 601w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e40111a6ef-300x248.png 300w" sizes="(max-width: 601px) 100vw, 601px"></p><p>The date is an integral part of each message and I had to do some data conversion massaging in Python to get the proper date, as dates were coming in a variety of formats. I’ve tried various libraries but dateutil.parser.parse standard date and time library for Python did the best job.</p><p>However, I still needed to account for various labelling of data fields in the headers, so if data wasn’t found in the ‘date’ header, I had to look into other header parts such as ‘NNTP-Posting-Date’, ‘X-Article-Creation-Date’,&nbsp;‘Posted’,&nbsp;or ‘Received’ fields.</p><p>Well and then it was all about creating a Python parser, start the PostgreSQL, point it to an archive directory, and wait :)</p><p>At the bottom of this article is the code of the Python solution. It’s about 1,000 lines, and it took altogether about 1 day to create and test it. The script is smart enough to keep the track of where it started, so if it needs to be interrupted, it’ll know where to continue from to get the job done.</p><p>The source code is available on GitHub as open-source under MIT license:</p><p><a href="https://github.com/JozefJarosciak/python_mbox_parser/blob/master/utzoo2postgres.py" target="_blank" rel="noopener noreferrer">https://github.com/JozefJarosciak/python_mbox_parser/blob/master/utzoo2postgres.py</a></p><p>The final solution artifact is called ‘<strong>utzoo2postgres.py</strong>‘ , and it was tested on Python 3.8.</p><p>Open the script and define the path to un-tared Utzoo archive directories.</p><p>Examples:</p><pre># for Windows
positionFilePath = "E:\\Usenet\\Utzoo\\"
# for linux:
# positionFilePath = "/Usenet/Utzoo/"</pre><p>Also, define the particulars of your PostgreSQL database:</p><pre>db_connection = psycopg2.connect(host="localhost", user="", password="", port="5432", database="utzoo")</pre><p>And then just execute the script!</p><pre>python 3 utzoo2postgres.py</pre><p><em>Note: In case you need to stop the program and run it later, the script is smart to resume from the last spot it was processing.</em></p><p>The script will process all Utzoo Archive messages in about 6 hours (depending on the speed of your machine).</p><p>Screenshot from processing:</p><p id="UwdOjId"><img loading="lazy" width="713" height="585" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7dc52b05827.png" alt="" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7dc52b05827.png 713w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7dc52b05827-300x246.png 300w" sizes="(max-width: 713px) 100vw, 713px"></p><p>Here is a screenshot of the database after only a couple of minutes of conversion:</p><p id="JQYnVLo"><img loading="lazy" width="432" height="642" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3dc6ce1c7.png" alt="" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3dc6ce1c7.png 432w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e3dc6ce1c7-202x300.png 202w" sizes="(max-width: 432px) 100vw, 432px"></p><p>As you can see, the conversion utility produces a database with 5 tables per group where messages are linked to each other through auto-created indexes.</p><p id="kdsmyQE">Let’s say we want to look up all discussions in the<strong> net.physics</strong> discussions; and sort them out by the number of replies.</p><p>This is how you can do that:</p><p id="ymEaJie"><a href="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b.png"><img loading="lazy" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b.png" alt="" width="1198" height="625" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b.png 1198w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b-300x157.png 300w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b-1024x534.png 1024w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e48cfddb5b-768x401.png 768w" sizes="(max-width: 1198px) 100vw, 1198px"></a></p><p>Now, we can look up a particular discussion by the ID. For example, we want the ID: 1648 from the screenshot above, the discussion with the subject: “<strong>Question on FTL and quantum mechanics</strong>“. That’s not so hard either:</p><p id="rcwUUqq"><a href="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d.png"><img loading="lazy" src="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d.png" alt="" width="1697" height="847" srcset="https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d.png 1697w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d-300x150.png 300w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d-1024x511.png 1024w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d-768x383.png 768w, https://www.joe0.com/wp-content/uploads/2020/10/img_5f7e49dfdfd6d-1536x767.png 1536w" sizes="(max-width: 1697px) 100vw, 1697px"></a></p><p>It’s nice to have a database full of posts, but it’s hardly usable that way. I needed something that would allow me to easily access these posts.</p><p>So, once everything was done, I built a PHP script around this code and registered <a href="http://usenetarchives.com/" target="_blank" rel="noopener noreferrer">https://usenetarchives.com</a> to make all these archives available online, in an easy to read and search (forum-like) web site.</p><p>The PHP code is not part of this article, but you can head over to <a href="https://usenetarchives.com/groups.php?c=utzoo" target="_blank" rel="noopener noreferrer"><strong>https://usenetarchives.…</strong></a></p></div></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/">https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/</a></em></p>]]>
            </description>
            <link>https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25036780</guid>
            <pubDate>Mon, 09 Nov 2020 16:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Towards a Lightweight Jamstack]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25036750">thread link</a>) | @phacks
<br/>
November 9, 2020 | https://orbit.love/blog/towards-a-lightweight-jamstack | <a href="https://web.archive.org/web/*/https://orbit.love/blog/towards-a-lightweight-jamstack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><em>Note: this article is an edited transcript of my talk of the same name at the Jamstack Berlin meetup. You can watch the video <a href="https://youtu.be/taOyVmLgym4">here</a>.</em><br></p><p>Jamstack is thriving. There is a plethora of languages, frameworks, libraries, and services that allow you to take full advantage of static websites while being able to leverage the JavaScript and Serverless ecosystems to build rich, dynamic, and whimsical experiences.</p><p>This often comes at a cost—as most Jamstack frameworks are based on JavaScript frameworks (NextJS and Gatsby on React, NuxtJS, and Gridsome on Vue), <a href="https://timkadlec.com/remembers/2020-04-21-the-cost-of-javascript-frameworks/">the JavaScript tax</a> takes a toll on performance, and, ultimately, on your users.</p><p>This article aims to give directions to curb that JS tax—whether by optimizing your existing JavaScript-framework-based website or by going for an alternative: Eleventy.</p><p>But first, let’s take a trip down memory lane to understand how we got where we are today.</p><h2>From Jekyll to Gatsby</h2><p>The Static/Jamstack ecosystem has evolved <em>a lot</em> over the past decade. This evolution has had a deep impact on the way we conceive websites and on the way our users experience them.</p><p>We’re going to cover three major steps through that journey from the (fictional) point of view of a casual discussion between a server and a user.</p><p>Our user will try and access a website, and our server will give her what she needs to <em>view</em> and <em>interact</em> with it. Those two important steps (the user can see the content, the user can interact with it) will be denoted with associated red badges, highlighting the moment in the conversation when they become possible.</p><p>Buckle up! We’re going all the way back to 2008.</p><h3><br>Pure Static (e.g. Jekyll)</h3><p><a href="https://jekyllrb.com/">Jekyll</a>, created in 2008, has long been the most popular Static Site Generator. Following the “<a href="http://www.aaronsw.com/weblog/000404">bake, don’t fry</a>” adage, it pre-computed all the pages of the website to have them readily available for its visitors.</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/4da9af4b2075d28a8d8e43004d0da1dfa53663ad-1876x802.png" alt="A discussion goes like this. User: “hey could you pass me that index.html file you got there?”. Server: “sure thing here you go”. User: “thanks”"></p><p>It’s straightforward. Simple. No shenanigans. The desired page is served immediately to the user, and it is immediately available to view and interact with. Should she navigate to another page, her browser would fetch it in the same way it did the first.</p><p>As years went by, however, the user experience this solution provided somehow lagged behind what users got used to with mobile applications. Transitions, offline-mode, all the bells and whistles of the mobile revolution were nowhere to be found.</p><p>JavaScript frameworks, Angular, React and Vue among them, offered a new proposition that was to bring native-like experiences to the web, bringing us to our next stop: Client-Side Rendered websites.</p><h3><br>Client-Side Rendering (e.g. React, Vue)</h3><p>To make websites feel native-like, the solution offered by new JavaScript frameworks circa 2015 was to embed a JS-based engine that would create and update the HTML markup and associated styles dynamically. The upfront price to download, parse, and execute that engine would supposedly be offset by faster subsequent navigation and a richer user experience.</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/b6ac711b81b742038bfa1d6503e6768a046c83dd-1872x1150.png" alt="Discussion goes like this. User: “oooh this new online publication looks cool can i see it?”. Server: “you know what why don’t you take all the raw materials and figure it out yourself”. User: “ wow rude but ok”. User computes the page for a moment. User: “ it works!”"></p><p>The major shift that happened with that evolution is that <strong>the cost of building web pages passed from the server to the user’s browser</strong>. This cost is indicated in the discussion with the gear icon, during which the screen is mostly blank or showing a loading indicator.<br></p><p>As a result, the performance of Client-Side Rendered websites depend widely on the specs of the device of the user, as JavaScript is CPU-intensive. The following video, by <a href="https://joshwcomeau.com/">Josh Comeau</a>, shows a 28 seconds difference (!) in load time for the Washington Post between an iPhone and a $100 Xiaomi Redmi 8.</p><h3>Server-Side Rendering (e.g. Next.js, Nuxt.js)</h3><p>A few years after this paradigm was introduced, these issues lead the pendulum to swing back towards the server, with the introduction of Server-Side Rendering.</p><p>Server-Side Rendering was introduced to fix one of the most annoying aspects of Client-Side Rendering: that the content the user came for would not be visible until after the (usually large) JavaScript code is downloaded, parsed, and executed. Those seconds can be <a href="https://www.thinkwithgoogle.com/marketing-strategies/app-and-mobile/mobile-page-speed-new-industry-benchmarks/">the difference between the visitor staying or leaving the website</a>.</p><p>Frameworks like Next.js and Nuxt.js appeared to try and bring the server back to its original role: building web pages. The approach would be different from Jekyll’s, though: in the Server-Side Rendering paradigm, the server acts as a web browser and renders the page using JavaScript—not Ruby.<br></p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/515d9fcb7a96cf4f41c6c090977e5fbbb0cec9cc-1716x1364.png" alt="Discussion goes like this. User: “i heard they worked on performance on this publication”. Server: “they did! here it is: i’m building the page very quicky…”. Server computes the page for a moment. Server: “and now send you the raw materials to build it yourself BUT now you have a nice picture of the finished page to look at meanwhile!”. Server: “and now send you the raw materials to build it yourself BUT now you have a nice picture of the finished page to look at meanwhile!”. User: “sweet! i can see the content first…”. User computes the page for a moment. User: “and now click around!”"></p><p><br>This approach leverages the power of the server to show the content to the visitor immediately. However, as interactivity still relies on client-side JavaScript, a delay is being introduced between the <em>availability</em> of the content and its <em>readiness</em>. From the point of view of the visitor, this can induce <em>rage clicks</em>: clicking on a button or a link has no effect for several seconds, as illustrated below.</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/46db90282489daeae289e6307f4dab205b1b79d4-800x445.gif" alt="An animated gif showing two pages loading (one resembling AirBnB, the other Amazon). The pages look like they are ready, and a fictional user clicks on them for around 20 seconds until it has an effect. The fictional user gets annoyed, then angry, then despaired at the situation."></p><p><em>Source: Addy Osmany, <a href="https://medium.com/@addyosmani/the-cost-of-javascript-in-2018-7d8950fbb5d4">The Cost Of JavaScript in 2018</a></em>​</p><p>There would be much more to say on the topic, as some of the frameworks have additional optimizations (prerendering, link-prefetching…), but we already covered enough ground to know that JavaScript has an impact on the user experience for Jamstack websites. This impact has been dubbed the <em>JavaScript tax</em>.</p><h2>Curbing the JavaScript tax</h2><p>Without entering into more details, we can follow the simple approximation that the less JavaScript is used, the lower the tax will be. Shipping less JavaScript then becomes a powerful approach to enhance the performance of our websites.</p><p>What if we could remove it altogether?</p><h3>Removing the JavaScript of JavaScript frameworks</h3><p><a href="http://nextjs.org/">Next.js</a> and <a href="https://www.gatsbyjs.com/">Gatsby</a> are two popular Server-Side Rendered JavaScript frameworks used on many Jamstack websites. They both use React as the underlying JS library to manage state and UI.</p><p>For this section, I’ll take <a href="https://phacks.dev/">my personal blog</a> as an example. I chose to build it with Gatsby, as I wanted to learn more about how it worked and could leverage my React experience to ship it quickly.</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/1a51c0e83d712f7944362eea3142c9f42e60e64f-2756x1164.png" alt="A screenshot of my personal blog"></p><p>The Developer Experience was a delight and I’m overall pretty happy with it, but something felt <em>off</em>. My blog is pretty basic: an index of all the articles, a page for each, and a few other pages here and there. Yet it was powered by the same technology that powers Facebook, AirBnB and many other extremely complex websites: React. Any overengineering questions put aside, I still required any reader to download, parse, and execute React for <em>no benefits at all</em>. There are no smart widgets or complex UI to justify React. Only text and images.</p><p>My (outstanding) developer experience had an impact on my reader’s user experience. <a href="https://twitter.com/getify/status/1139625725504512003">There is no such thing as trickle-down UX</a>.</p><p>Well, it turns out that there <em>is</em> a way to get the best of both worlds. If, like my blog, your Gatsby website does not require React (or any other JavaScript) to run, you can <em>disable it</em>. The <a href="https://github.com/itmayziii/gatsby-plugin-no-javascript">Gatsby Plugin No Javascript</a> community plugin will let you enjoy the DX of Gatsby without taking a toll on user experience. A <a href="https://github.com/vercel/next.js/pull/11949">similar (experimental) plugin</a> also exists for Next.js.</p><p>Of course, not every website is as simple as my blog—that would be pretty boring. A lot of Gatsby and Next.js websites out there rely on React for their user experience: pretty animations, shopping carts, newsletter sign-ups, and the likes. Is there something we can do on those websites to make them lighter?</p><h3>(P)react</h3><p>When React is required for a website to run properly, we can’t just get rid of JavaScript. What we can do, however, is look for ways to reduce its footprint.</p><p><a href="https://preactjs.com/">Preact</a> is an alternative to React that has the same functionality, the same modern API, for a tenth of its size. The Preact team managed to drastically reduce the footprint by dropping support for some old browsers and legacy React APIs.</p><p>Although there are some slight differences (<a href="https://preactjs.com/guide/v10/differences-to-react#main-differences">see the list</a>), Preact can be used instead of React for many websites without any impact on the end-user, and barely any on the developers.</p><p>We switched from React to Preact on the Orbit app without issues and shaved off half of our JavaScript footprint in the process. If you’d like to try, there are plugins for <a href="https://www.gatsbyjs.org/packages/gatsby-plugin-preact/">Gatsby</a> and <a href="https://github.com/vercel/next.js/tree/canary/examples/using-preact">Next.js</a>, and <a href="https://preactjs.com/guide/v10/switching-to-preact">a guide for switching manually</a>.</p><p>Now, say you are in a situation where you have to create a brand new website. You want to use the Jamstack because you’re convinced of the benefits. You want to be mindful of the user experience, also because you’re convinced of the benefits. Say the website you want to create is similar to this very one, <a href="https://orbit.love/">orbit.love</a>.</p><p>What would you choose for a Lightweight Jamstack? What <em>did I</em> choose for a Lightweight Jamstack?</p><h3>Building orbit.love with Tailwind, Eleventy, and Alpine.js</h3><p>The Orbit website does not have a complex UI—interactivity is limited to a mobile nav menu, modals, and sign-ups for our newsletter and early access. I knew from the get-go that reaching out to (P)react would be heavy handed, so I looked for lightweight alternatives.</p><p>I went for the following: TailwindCSS, for styling, Eleventy, for the static site generation, and Alpine.js, for interactivity.</p><p><a href="http://11ty.dev/">Eleventy</a> is a JavaScript-based Static Site Generator that, despite being written in JavaScript, shares a lot more with Jekyll than with Gatsby. Indeed, Eleventy (also known as 11ty) <em>does not ship any JavaScript by default</em>. You are free to add any, of course, but it does not force you to use any library or framework.</p><p>Not having to use a JavaScript framework also meant that HTML, not JSX or Vue components, is now front and center in the code you write. This helped me avoid the usual traps when writing React: the infamous <a href="https://www.chillybin.com.sg/would-you-like-another-bowl-of-div-soup/#:~:text=What%20is%20Soup%3F,to%20make%20your%20eyes%20bleed.">div soup</a>, inaccessible components, or non-semantic tags.</p><p><a href="https://tailwindcss.com/">TailwindCSS</a> is a utility-first CSS framework, which means that instead of writing CSS for your components (class="navbar__mobile"), you combine utility classes that each do one specific thing (class="flex flex-row justify-center w-full").</p><p>I find this approach incredibly productive once you learn the grammar, and it makes for a resilient CSS architecture at the admitted cost of some duplication in your code. What makes it a great match with Eleventy is that you rarely, if ever, leave your HTML components when writing code. It helps me focus on the task at hand by …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://orbit.love/blog/towards-a-lightweight-jamstack">https://orbit.love/blog/towards-a-lightweight-jamstack</a></em></p>]]>
            </description>
            <link>https://orbit.love/blog/towards-a-lightweight-jamstack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25036750</guid>
            <pubDate>Mon, 09 Nov 2020 16:54:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to build successful Machine Learning teams]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25036630">thread link</a>) | @benkoller
<br/>
November 9, 2020 | https://blog.maiot.io/MLOps-Learning-from-history/ | <a href="https://web.archive.org/web/*/https://blog.maiot.io/MLOps-Learning-from-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-content">
    <div id="blogpost">
        <p>TL;DR: Running successful ML teams and projects requires cross-functional collaboration within the executing team.</p>

<p>That sentence alone does not help anyone. It feels unsubstantiated, and someone playing bullshit bingo might luck out just on that one sentence - and yet, itâ€™s true. Why? Because itâ€™s taking the main driver behind the DevOps revolution in software development and applies it to Machine Learning.</p>

<p>If youâ€™re familiar with what DevOps stands for, where it came from and why itâ€™s such a game-changer, feel free to skip to <a href="#a-better-way">the conclusion</a>.</p>

<p>For everyone else, a quick refresher.</p>

<h2 id="why-did-software-people-come-up-with-devops">Why did â€œsoftware peopleâ€� come up with DevOps?</h2>
<p>Flashback to the 2000s (sorry if this triggers PTSD for my fellow Ops guys out there). Software Development is a barren wasteland. Developers write code until it works on their computer, send an email to QA and Ops to please do their thing now. Nobody knows who the people in QA are, all they are doing is complaining about bugs that canâ€™t be reproduced. Ops are the angry guys from the basement, and somehow they get mad just because code sometimes SEGFAULTs, but it canâ€™t have been a fault on our side, it never SEGFAULTs on my machine.</p>

<p>This is not a healthy way to run a business. The late 2000s were full of stories of companies that failed, simply because their internal software development process was too slow to keep up with the market.</p>

<p>Meet â€œDevOpsâ€�: A new and revolutionary way of dealing with software development. What if we could deliver our software more often, and faster, to our customers? And what if it broke less in production? What if our Devs, QA, and Ops could be happier at work? And, what if we would build up less technical debt along the way?</p>

<h2 id="but-how">But, how?</h2>

<p>How, you ask? Let developers, testers, AND operators work in unison, together, and own the entire process, rather than separate them into silos!
From an orbital perspective, software development can be roughly broken down into a handful of stages:</p>

<ul>
  <li>Coding</li>
  <li>Building / Packaging</li>
  <li>Testing</li>
  <li>Deployment</li>
  <li>Monitoring</li>
</ul>

<p>Allowing teams to own the entire process, rather than just a single aspect, created a deeper understanding of all software lifecycle aspects across the functions in a team. Suddenly, everyone was a part of the development team. Testers had to be able to understand and write code because tests had to be automated. Ops guys built abstractions to the underlying hardware so that others could run software independently. Developers had to acknowledge that software is only done when being exposed successfully to customers.</p>

<p>Yes, there are many ways to mess this up. You might say itâ€™s even impossible to get it right. These ideas have spawned many closely related methodologies and team designs (e.g. SREs at Google, Netflixâ€™s Platform Engineering team, etc. pp.). But evidence confirms: getting all lifecycle functions to work (more) cross-functional will leave you better off than in a siloed environment.</p>

<h2 id="a-pessimistic-look-at-the-state-of-machine-learning-teams">A pessimistic look at the state of Machine Learning teams</h2>
<p>Obviously, Iâ€™m trying to go somewhere with this. Machine Learning as a discipline is exactly where software development was in the early 2000s: just before the dawn of DevOps. Unless youâ€™re in some hotshot startup, you own all data, and every one of your engineers is a core contributor to Kubeflow, your reality will look a bit bleak:</p>

<ul>
  <li>ML teams have little to no influence over the data they get. The data might be owned by a different team, or worse, a customer.</li>
  <li>There is no close communication between ML and data owners.</li>
  <li>Schemas and feature quality changes.</li>
  <li>The delivery of data is not standardized.</li>
  <li>ML teams have to run their own infrastructure. Support from your Platform team ended at â€œHere, I created an AWS IAM account for youâ€�.</li>
  <li>Nobody in your ML team has prior experience as a Software Developer.</li>
</ul>

<h2 id="a-better-way">A better way</h2>
<p>Nothing Iâ€™m about to say should sound like a revelation. Iâ€™ll paint the picture by using an example: A team running the search engine on an e-commerce platform. They need engineers with an understanding of high-performance processing, databases, and API design. They will need to be able to rely on the upstream product data staying consistent. They need to understand how their search engine is used in the frontend, and what performance metrics they need to be able to provide. They need to own the APIs used by downstream teams, e.g. the Frontend or your mobile app. Abstracted, they need to get</p>

<ul>
  <li>The right cross-functional resources/skills</li>
  <li>Structured upstream data as input</li>
  <li>Clear business requirements</li>
  <li>Full ownership of their service</li>
</ul>

<p>The same applies to Machine Learning teams if theyâ€™re supposed to be successful:</p>

<h3 id="skills">Skills</h3>
<p>Your team will be responsible for preprocessing input data it receives, training ML models, evaluating fulfillment of business criteria, and delivering results to downstream stakeholders. Therefore, the skills your team will need are:</p>

<ul>
  <li>Software Engineering to write performant standardized preprocessing code and to expose results as a service</li>
  <li>Operations/SRE to build reproducible ML pipelines and reliable model serving services, both with potentially high resource demand</li>
  <li>Machine Learning to build performant models</li>
  <li>Data Science to evaluate input data and output results</li>
</ul>

<h3 id="upstream-input">Upstream input</h3>

<p>Data needs to be reliable if a team is supposed to generate value from it. The team and the upstream data provider need to agree on the frequency of data provision, data format, and data quality. The easiest and best agreement can be found in code, e.g. through data ingestion pipelines with strong data validation built-in, but it can be beneficial later on to establish a feature store for your Machine Learning team. Horizontally aligned Data Operations teams can help if more than one team is reliant on similar data.</p>

<h3 id="business-objectives">Business objectives</h3>
<p>Surprisingly many projects fail due to muddy business objectives. Business stakeholders and the ML team need to come together and thoroughly define what the business is trying to achieve, and how it affects the model performance indicators. At a minimum, the business and the team need to answer these questions:</p>

<ul>
  <li>How to deal with false-positives, false-negatives?</li>
  <li>Do predictions need to be real-time, or is batch inference fine?</li>
  <li>What biases need to be accounted for?</li>
  <li>Which downstream services need to consume model results?</li>
</ul>

<h3 id="ownership">Ownership</h3>
<p>Probably the most controversial point in this blogpost concerns ownership. After transitioning multiple teams across companies towards full ownership of their software development lifecycle Iâ€™m a firm believer in the approach. Teams need to be responsible for providing the actual value, not just the artifact itself. It drives healthy decision-making (e.g. how big can the final model be, how much resources can it use), and it breeds a deeper understanding of the actual needs of downstream consumers. After all, if the served model does not create a positive impact on someone downstream, the efforts of the team should have been applied elsewhere.</p>

<h2 id="what-now">What now?</h2>
<p>Your teams are now cross-functional, and everyone is eager to jump to work. But what now? How does the work of a successful ML team look like in production? We got you covered on that front, too - check out our blog post on the <a href="https://blog.maiot.io/12-factors-of-ml-in-production/">12 factors of reproducible Machine Learning in production</a>.</p>


    </div>
</section><section id="blog-signup">
    <hr>
    <div>
        <div>
            <p>If you want to keep in touch with the latest blog posts, please subscribe to our <a href="https://blog.maiot.io/feed.xml" target="_blank">RSS Feed </a></p>
        </div>
    </div>
</section></div>]]>
            </description>
            <link>https://blog.maiot.io/MLOps-Learning-from-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25036630</guid>
            <pubDate>Mon, 09 Nov 2020 16:43:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Astronomy Picture of the Day]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25036130">thread link</a>) | @jayass
<br/>
November 9, 2020 | https://misspellede.com/us/cosmos/ | <a href="https://web.archive.org/web/*/https://misspellede.com/us/cosmos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <section>
                    <article>
            <a href="https://misspellede.com/us/comet-atlas-and-orions-belt/">
                <img loading="lazy" src="https://apod.nasa.gov/apod/image/2011/C2020M3Orion_CharlesBracken1024.jpg" alt="Comet ATLAS and Orion's Belt">
            </a>
            
        </article>
                                <article>
            <a href="https://misspellede.com/us/in-green-company-aurora-over-norway/">
                <img loading="lazy" src="https://apod.nasa.gov/apod/image/2011/greencompany_rive_960.jpg" alt="In Green Company: Aurora over Norway">
            </a>
            
        </article>
                    <article>
            <a href="https://misspellede.com/us/martian-moon-phobos-from-mars-express/">
                <img loading="lazy" src="https://apod.nasa.gov/apod/image/2011/phoboslimb_marsexpress_960.jpg" alt="Martian Moon Phobos from Mars Express">
            </a>
            
        </article>
                    <article>
            <a href="https://misspellede.com/us/the-hercules-cluster-of-galaxies/">
                <img loading="lazy" src="https://apod.nasa.gov/apod/image/2011/Abell2151_Howard_Trottier_2020_FFTelescope1024.jpg" alt="The Hercules Cluster of Galaxies">
            </a>
            
        </article>
                    <article>
            <a href="https://misspellede.com/us/moon-over-iss/">
                <img loading="lazy" src="https://apod.nasa.gov/apod/image/2011/ISSlunartransit110320closeup1024.jpg" alt="Moon over ISS">
            </a>
            <div>
                <p><a href="https://misspellede.com/us/cosmos/">cosmos</a>
                <a href="https://misspellede.com/us/moon-over-iss/">Moon over ISS</a></p><p>Derek Demeter • 2020-11-06</p>
                <p>Completing one orbit of our fair planet in 90 minutes the International Space Station can easily be spotted by eye as a very bright star moving throug...</p>
                <p><a href="https://misspellede.com/us/moon-over-iss/">Continue reading <i></i></a>
            </p></div>
        </article>
                    <article>
            <a href="https://misspellede.com/us/north-of-orions-belt/">
                <img loading="lazy" src="https://apod.nasa.gov/apod/image/2011/M78_LDN1622_BarnardsLoop_SEP27_28_Oct15_final1024.jpg" alt="North of Orion's Belt">
            </a>
            <div>
                <p><a href="https://misspellede.com/us/cosmos/">cosmos</a>
                <a href="https://misspellede.com/us/north-of-orions-belt/">North of Orion's Belt</a></p><p>Terry Hancock • 2020-11-05</p>
                <p>Bright stars, interstellar clouds of dust and glowing nebulae fill this cosmic scene, a skyscape just north of Orion's belt. Close to the plane of our...</p>
                <p><a href="https://misspellede.com/us/north-of-orions-belt/">Continue reading <i></i></a>
            </p></div>
        </article>
                    <article>
            <a href="https://misspellede.com/us/fifty-gravitational-wave-events-illustrated/">
                <img loading="lazy" src="https://apod.nasa.gov/apod/image/2011/GWaveSources2020Oct_LigoVIrgo_960.jpg" alt="Fifty Gravitational Wave Events Illustrated">
            </a>
            
        </article>
                    <article>
            <a href="https://misspellede.com/us/tagging-bennu-the-movie/">
                <img loading="lazy" src="https://www.youtube.com/embed/F6Tkb8syTK8?rel=0" alt="Tagging Bennu: The Movie">
            </a>
            
        </article>
                    <article>
            <a href="https://misspellede.com/us/half-sun-with-prominence/">
                <img loading="lazy" src="https://apod.nasa.gov/apod/image/2011/HalfSunProm_Colacurcio_960.jpg" alt="Half Sun with Prominence">
            </a>
            <div>
                <p><a href="https://misspellede.com/us/cosmos/">cosmos</a>
                <a href="https://misspellede.com/us/half-sun-with-prominence/">Half Sun with Prominence</a></p><p>Rainee Colacurcio • 2020-11-02</p>
                <p>What's happening to the Sun? Clearly, the Sun's lower half is hidden behind a thick cloud.  Averaging over the entire Earth, clouds block the Sun abou...</p>
                <p><a href="https://misspellede.com/us/half-sun-with-prominence/">Continue reading <i></i></a>
            </p></div>
        </article>
                    <article>
            <a href="https://misspellede.com/us/in-the-center-of-the-trifid-nebula/">
                <img loading="lazy" src="https://apod.nasa.gov/apod/image/2011/Trifid_HubbleGendler_960.jpg" alt="In the Center of the Trifid Nebula">
            </a>
            
        </article>
                    </section>
            
                    </div></div>]]>
            </description>
            <link>https://misspellede.com/us/cosmos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25036130</guid>
            <pubDate>Mon, 09 Nov 2020 16:01:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Europe enforces IM-Services to store encryption master key for government access]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25036061">thread link</a>) | @lilatentakel
<br/>
November 9, 2020 | https://fm4.orf.at/stories/3008930/ | <a href="https://web.archive.org/web/*/https://fm4.orf.at/stories/3008930/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="ss-storyText" role="article">
     
     <p><strong>Im EU-Ministerrat wurde binnen fünf Tagen eine Resolution beschlussfertig gemacht, die Plattformbetreiber wie WhatsApp, Signal und Co. künftig dazu verpflichtet, Generalschlüssel zur Überwachbarkeit von E2E-verschlüsselten Chats und Messages anzulegen.</strong></p>
     



     


     <p>Von <a href="http://fm4.orf.at/tags/erichmoechel">Erich Moechel</a></p><p>Der Terroranschlag in Wien wird im EU-Ministerrat dazu benützt, um ein Verbot sicherer Verschlüsselung für Services wie WhatsApp, Signal und viele andere im Schnellsiedeverfahren durchzusetzen. Das geht aus einem mit 6. November datierten internen Dokument der deutschen Ratspräsidentschaft an die Delegationen der Mitgliedsstaaten im Rat hervor, das ORF.at vorliegt.</p><p>Das sollte nun unter den „weiteren Schritten gegen den Terrorismus“ zu verstehen sein, die Frankreichs Präsident Emmanuel Macron mit Bundeskanzler Sebastian Kurz (ÖVP) im Rahmen einer Videokonferenz zu Wochenbeginn besprechen will. Der Beschluss ist bereits so weit akkordiert, dass er in der Videotagung der Innen- und Justizminister Anfang Dezember ohne weitere Diskussion verabschiedet werden kann.</p><div><p><img src="https://tubestatic.orf.at/static/images/site/tube/20201145/eu_ministerrat_cover.5944853.jpg" alt="Text" title="© EU Ministerrat" width="800" height="560"></p><p>EU Ministerrat</p><p>Rechts sind die Ratsarbeitsgruppen aufgelistet, an die dieser Text erging, dessen erste revidierte Fassung offenbar am Freitag fertig wurde. Wie im Ministerrat üblich, wurde das Dokument als „limite“ klassifiziert. Da es aus diesem Grund abseits des Rats nirgendwo für die Öffentlichkeit einsehbar ist, wird es hier zur Verfügung gestellt: <a href="https://files.orf.at/vietnam2/files/fm4/202045/783284_fh_st12143-re01en20_783284.pdf">[PDF]</a></p></div><h2>Analogien zur Vorratsdatenspeicherung</h2><p>Aus dem ursprünglich für Anfang kommender Woche geplanten Besuch Macrons wurde pandemiebedingt eine Videokonferenz „zur Bekämpfung des islamistischen Terrorismus“. Weiters steht ein Besuch des EU-Ratspräsidenten Charles Michel in Wien für Montag an, der ebenfalls mit Bundeskanzler Kurz Gespräche führen wird. Zudem empfängt Europaministerin Karoline Edtstadler (ÖVP) den französischen Europastaatssekretär Clement Beaune im Bundeskanzleramt. Alleine um Kondolenzbezeugungen geht es dabei natürlich nicht.</p><p>Mittlerweile wird zwar immer klarer, dass offenbar haarsträubende Ermittlungsfehler im BVT den Anschlag erst ermöglicht hatten und nicht fehlende digitale Überwachungsbefugnisse. Ob irgendein solcher Zusammenhang zur Tat besteht, ist allerdings unerheblich. In Brüssel wird so ein Anlass seit 25 Jahren mit schnöder Regelmäßigkeit dafür missbraucht, längst geplante Überwachungsvorhaben durchzusetzen. Auf diese Weise wurde die fünf Jahre lang in der EU umstrittene Vorratsdatenspeicherung nach den Zugsanschlägen in Madrid (2004) und London durch Islamisten (2005) durch den Ministerrat und das Parlament geschleust.</p><div><p><img src="https://tubestatic.orf.at/static/images/site/tube/20201145/ohne-titel-2.5944858.jpg" alt="Text" title="© EU Ministerrat" width="800" height="360"></p><p>EU Ministerrat</p><p>An den letzten Änderungen (fett und unterstrichen) sieht man, welche Formulierungen von einzelnen Mitgliedsstaaten in den Text reklamiert worden waren. Zuletzt eingefügt wurden „Terrorismus“ und eine unscheinbare Änderung im Wording. Statt der in allen Dokumenten seit 1995 üblichen Strafverfolger („law enforcement“) ist nun konsequent von „competent authorities“ die Rede. Wer damit gemeint ist, steht weiter unten.</p></div><h2>Verabschiedung ohne weitere Diskussionen</h2><p>Diese Resolution des Ministerrats ist laut Dokument - da wird um allfällige letzte Einwände gebeten -  nicht nur fast fertig ausformuliert. Sie ist im Rat offenbar auch bereits fertig abgestimmt. Am 19. November soll sie dann in der Ratsarbeitsgruppe zur Kooperation im nationalen Sicherheitsbereich (COSI) verabschiedet werden, am 25. ist die Vorlage im Rat der ständigen Vertreter der EU-Mitgliedsstaaten (COREPER) geplant. Dort hat der Ratsbeschluss bereits den Status eines I-Items, damit kann er ohne weitere Diskussion passieren.</p><p>In einer für Anfang Dezember geplanten virtuellen Sitzung des Rats der Innen- und Justizminister soll der Beschluss dann abgefeiert werden. Was folgen wird, ist klar, nämlich ein Auftrag des Ministerrats an die EU-Kommission, einen Entwurf für eine Verordnung zu erstellen, die dann das übliche Prozedere durch Parlament und Rat durchlaufen wird. Angesichts der offenbaren Einstimmigkeit wäre es im Ministerrat allerdings möglich, die geplante Regulation in ihrem Kern auch ohne Mitwirkung des Parlaments durchzuziehen. Auch das hat es in Zusammenhang mit Überwachung schon gegeben. So wurde der berühmte Beschluss im Fischereiausschuss des Rats von 1995 zur Überwachbarkeit der damals neuen GSM-Netze als A-Item (beschlossene Sache) durchgezogen, von dem das EU-Parlament erst nach seinem Inkrafttreten 1996 Kenntnis erhielt.</p><div><p><img src="https://tubestatic.orf.at/static/images/site/tube/20201145/ohne-titel-1.5944852.jpg" alt="Text" title="© Public | FiveEyes" width="1280" height="255"></p><p>Public | FiveEyes</p><p>Diese Passage sieht dem EU-Ministerratsbeschluss zwar zum Verwechseln ähnlich, stammt jedoch nicht aus Europa. <a href="https://www.justice.gov/opa/pr/international-statement-end-end-encryption-and-public-safety">Sie findet sich vielmehr in einer Resolution der Innen- und Justizminister</a> aus den „Five Eyes“-Staaten, datiert mit 11. Oktober. Die Spionageallianz ist neben Europol und diversen europäischen Diensten eine der treibenden Kräfte, auf die der aktuelle Ministerratsbeschluss zurückzuführen ist.</p></div><h2>Treibende Kräfte im Hintergrund</h2><p>Frankreich treibt das ursprünglich von Großbritannien angestoßene Vorgehen gegen sichere Verschlüsselung auf Plattformen wie WhatsApp bereits das ganze Jahr auf EU-Ebene voran. Der Boden dafür wurde seit 2015 in einer ganze Serie von Kampagnen vorbereitet, die abwechselnd von Europol und FBI bzw. den Diensten der „Five Eyes“-Spionageallianz samt den dafür zuständigen Ministern gefahren wurden. Erst Anfang Oktober hatten die Innenminister dieser fünf Staaten - Großbritannien, USA, Australien, Neuseeland und Kanada - die Internetkonzerne erneut aufgefordert, ihre IT-Netze mit Hintertüren für die Strafverfolger auszustatten.</p><p>Sekundiert wurden sie dabei von ihren Amtskollegen in Japan und in Indien. Warum sich die Geheimdienstallianz so auffällig um die bedauernswerten Strafverfolger jahrelang öffentlich gesorgt hat, ist eigentlich selbsterklärend. Sie sind die übrigen „competent authorities“ die ebenfalls Zugang erhalten werden.</p><h2>„Competent authorities“ lassen grüßen</h2><p>Laut weiteren Informationen, die ORF.at vorliegen, soll die Überwachungsmethode „Exceptional Access“ gewählt werden, das geht indirekt bereits aus diesem  nicht technischen Resolutionstext hervor. Unter acht möglichen Modellvorschlägen, die allesamt aus technischen Szenarien verschiedener Geheimdienste stammen, wurde jener aus dem britischen „National Cyber Security Center“ (NCSC) ausgewählt. Das NCSC ist eine Abteilung des britischen Militärgeheimdienstes GCHQ. Plattformbetreiber wie WhatsApp, Signal und Co, die alle E2E-Verschlüsselung benützen, sollen verpflichtet werden, zusätzlich Generalschlüssel anzulegen und diese zu hinterlegen.</p><div><p><img src="https://tubestatic.orf.at/static/images/site/tube/20200939/eu_ministerrat_diskussionspapier_ea.5941753.jpg" alt="Skizzen aus Dokumenten" title="© EU-Ministerrat" width="800" height="409"></p><p>EU-Ministerrat</p><p>Hier wird ein Nachschlüssel für Dritte in den Verschlüsselungsprozess zweier Chatteilnehmer geschmuggelt, es ist die Methode „Exceptional Access“ des GCHQ. Mit sicherer Verschlüsselung hat diese wie alle anderen in diesem Dokument enthaltenen Varianten nichts zu tun, es sind einfach nur verschiedene Arten von „Man in the middle“ -Angriffen auf sichere Kommunikation. Die Studie wurde im Auftrag der deutschen Ratspräsidentschaft erstellt und im August <a href="https://www.politico.eu/wp-content/uploads/2020/09/SKM_C45820090717470-1_new.pdf">vom Fachmagazin Politico</a> veröffentlicht.</p></div><p>Das nämlich sind die „competent authorities“: GCHQ, DGSE, BND usw., deren Staubsaugermethoden an den Glasfasern wegen zunehmender Transportverschlüsselung immer weniger verarbeitbare Daten einbringen. Um diese drohende Datenarmut abzuwenden, wurden jetzt Generalschlüssel verlangt - und wie es aussieht, wird das im Rat auch bewilligt. Dann kann das BVT, das es nicht einmal schafft, einen Terroristen auszuschalten, der von zwei anderen Diensten zweimal auf dem Silbertablett serviert wird, künftig auch in Chatverläufen wochenlang nicht ermitteln.</p>
     
     



   </div></div>]]>
            </description>
            <link>https://fm4.orf.at/stories/3008930/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25036061</guid>
            <pubDate>Mon, 09 Nov 2020 15:56:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Separating User Database and Authorization from Apps with Istio and FusionAuth]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25035985">thread link</a>) | @mooreds
<br/>
November 9, 2020 | https://reachablegames.com/oidc-fusionauth-istio/ | <a href="https://web.archive.org/web/*/https://reachablegames.com/oidc-fusionauth-istio/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://reachablegames.com/content/images/size/w300/2020/11/security.jpg 300w,
                            https://reachablegames.com/content/images/size/w600/2020/11/security.jpg 600w,
                            https://reachablegames.com/content/images/size/w1000/2020/11/security.jpg 1000w,
                            https://reachablegames.com/content/images/size/w2000/2020/11/security.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://reachablegames.com/content/images/size/w2000/2020/11/security.jpg" alt="Separating your User Database and Authorization from Applications with Istio and FusionAuth">
            </figure>

            <section>
                <div>
                    <p>Kubernetes is a tremendously powerful cluster management system. &nbsp;There are many pluggable technologies to choose from that exhibit the features you desire, which is great because you have options--but also comes with the down-side that the likelihood someone else has done exactly what you are trying to do is slim. &nbsp;Eventually, there will be some consolidation as developers gather around the best solutions, but for the moment, there are lots of interesting projects to choose from (and not a ton of great examples for certain configs). Today, I'm sharing a slightly challenging setup and hoping it helps the community.</p><p>I am using Istio as my L7 ingress and routing controller, which is based on Envoy. &nbsp;It is a highly scalable L7 proxy with excellent performance characteristics and relatively mature feature set. When it came time to implement a basic <code>/admin</code> route on a project, I came up with the list of features that I wanted to achieve. &nbsp;My desired config:</p><ul><li>Applications should not have access to user passwords or necessarily email</li><li>Applications should not re-implement role-based access control (RBAC) security, as every application will need it</li><li>Users should be able to login without creating yet another username/password to remember, but support it if they prefer</li><li>Users should be able to self-register, password reset if necessary, and manage what remote authentications are associated with their account without needing support (Google keyword CIAM)</li><li>Application Admins should be able to edit the role of users, either explicitly or by group permissions, with a visual interface for non-technical people to control access</li><li>K8s Ops should be able to change what RBAC rules protect individual routes to applications without a redeploy</li><li>Fully self-hosted, to limit external dependencies and have auditable security around user data</li></ul><p>The simplest way to get started is to follow the excellent walkthrough on <a href="https://www.blog.jetstack.io/blog/istio-oidc/">Jetstack.io</a> that explains in reasonably good detail how to cover your whole ingress with JWT handling. &nbsp;I won't go over all that detail here. &nbsp;Instead, I will present the exact YAML manifests necessary to directly deploy a working config, as well as show screenshots of relevant bits in FusionAuth of exactly how to configure the application so it communicates properly with these manifests.</p><h3 id="why-fusionauth">Why FusionAuth?</h3><p>I usually try out two or three alternative technologies before settling into one I like. Although I did start with KeyCloak, it felt a little unpolished and left a lot to be desired when it came to explaining how to configure it if the terminology wasn't familiar (eg. people who aren't security professionals). &nbsp;I studied several other options and it came down to Gluu or FusionAuth. &nbsp;The main deciding factor for me in favor of FusionAuth was the amount of documentation and tutorials (with much appreciated touches of humor). &nbsp;There is also a clear effort made by the developers to provide official docker images and Kubernetes examples that show real world use. &nbsp;I have been remarkably satisfied with this decision.</p><h3 id="quick-architecture-overview">Quick Architecture Overview</h3><p>Ok, so let's talk about the architecture of how this works together. &nbsp;Like any other traffic using Istio, a request will come into an application by following the routing rules of a <code>VirtualService</code> to a <code>Service</code>, then to a Deployment's <code>Pod</code>. &nbsp;To use the Istio security features, this pod needs to have the Sidecar Proxy running, otherwise the rules don't do anything. (This is unfortunate, as it has been my experience that the sidecar can cause connectivity issues with certain workloads, so just be aware it can cause side effects and you may need to explicitly create and configure the <code>Sidecar</code> for this namespace). The easiest way to get this working is to enable automatic sidecar proxy injection on a new <code>Namespace</code> and deploy the application there. &nbsp;By declaring a <code>RequestAuthentication</code> rule, we configure Istio to refuse any traffic that doesn't have a validly signed Json Web Token (JWT). &nbsp;And by declaring an <code>AuthorizationPolicy</code> rule, we configure Istio to accept or deny traffic by matching specific HTTP paths or user roles, etc. &nbsp;That's great! &nbsp;Right?</p><p>Well, Istio isn't quite mature enough to speak Open ID Connect. &nbsp;It's only smart enough to expect a validly decoded JWT and do some simple pattern matching against its contents. &nbsp;When those rules fail, you just get <code>RBAC: access denied</code> as a response to your request. &nbsp;There's no redirection logic to send the browser to the auth server login page. &nbsp;So, let's teach it to do that with a simple <code>EnvoyFilter</code> rule that is injected on <code>SIDECAR_INBOUND</code>. This lets us target specific applications to protect only the routes we care about without impacting anything else. </p><p>A few critical details: <code>RequestAuthentication</code> only accepts a &nbsp;JWT that is signed with an RSA key, because HMAC is a symmetrical key and anyone who can decode it can also sign it. &nbsp;This means it needs to know where to get the public RSA key, which is supplied in the <code>issuer</code> field. &nbsp;Assuming this checks out, Istio then looks at any <code>AuthorizationPolicy</code> rules and either <code>ALLOW</code> or <code>DENY</code> traffic based on matching or non-matching details. &nbsp;In this case, I have provided a basic rule that allows anyone who has been verified to have an account with this application, and further restrict the <code>/admin/</code> path to accounts that have the <code>admin</code> role. &nbsp;Should anything go wrong, Istio just says <code>RBAC: access denied</code> . &nbsp;To diagnose, just delete these rules and try hitting the endpoint to see what errors pop up. &nbsp;If these rules are removed and you are still getting Unauthorized messages, it's oauth2-proxy refusing the user--check the config and logging to see why.</p><p>Here's the YAML we've all been waiting for. &nbsp;This fully describes a working config where the <code>VirtualService</code> is in the default namespace but everything else is in <code>auth</code> just to keep it away from everything else. &nbsp;The application is hosted at <code>https://auth-example.reachablegames.com</code>. &nbsp;Certain difficult and undocumented details that cause problems if not configured properly have been commented below--please pay attention before changing or simplifying things.</p><pre><code># create namespace where applications can have sidecar injection
apiVersion: v1
kind: Namespace
metadata:
  labels:
    app: auth
    istio-injection: enabled
  name: auth
---
# This rule makes sure the JWT is decoded and passed through to the web server as HTTP_PAYLOAD base64 encoded.
apiVersion: security.istio.io/v1beta1
kind: RequestAuthentication
metadata:
  name: auth-example
  namespace: auth
spec:
  selector:
    matchLabels:
      app: auth-example
  jwtRules:
  - issuer: "https://fusionauth.reachablegames.com"
    # this passes the full bearer token as the "authorization" header
    forwardOriginalToken: true        
    # this passes just the decoded JWT as "payload" header
    outputPayloadToHeader: "payload"  
---
# This rule verifies the user is an authenticated user (requestPrincipals) and also authorized (request.auth.claims)
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: auth-example
  namespace: auth
spec:
  selector:
    matchLabels:
      app: auth-example
  action: ALLOW
  rules:
  - from:  # limit admin path to users with admin role
    - source:
        requestPrincipals: ["*"]
    to:
    - operation:
        paths: ["/admin/*"]
    when:
    - key: request.auth.claims[roles]
      values: ["admin"]
  - from:  # allow anyone who is authorized to access the site to access anything other than /admin
    - source:
        requestPrincipals: ["*"]
    to:
    - operation:
        notPaths: ["/admin/*"]
---
# This intercepts and sends the traffic directly to the oauth2-proxy if there isn't a JWT cookie in the header.
apiVersion: networking.istio.io/v1alpha3
kind: EnvoyFilter
metadata:
  name: auth-example
  namespace: auth
spec:
  workloadSelector:
    labels:
      app: auth-example
  configPatches:
  - applyTo: HTTP_FILTER
    match:
      context: SIDECAR_INBOUND
      listener:
        portNumber: 80
        filterChain:
          filter:
            name: envoy.http_connection_manager
            subFilter:
              name: envoy.filters.http.jwt_authn
    patch:
      operation: INSERT_BEFORE
      value:
        name: envoy.filters.http.ext_authz
        typed_config:
          "@type": type.googleapis.com/envoy.config.filter.http.ext_authz.v2.ExtAuthz
          http_service:
            server_uri: # Note, this absolutely must be the FQDN for the service.  Does not work as a shortname.
              uri: http://auth-example-oauthproxy.auth.svc.cluster.local:8081
              cluster: outbound|8081||auth-example-oauthproxy.auth.svc.cluster.local
              timeout: 10s
            authorizationRequest:
              allowedHeaders:
                patterns:
                - exact: cookie
            authorizationResponse:
              allowedUpstreamHeaders:
                patterns:
                - exact: authorization
---
# Critical: spell out the FQDN because this VirtualService is in "default" but the Service is in "auth"
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: auth-example
  namespace: default
  labels:
    app: auth-example
spec:
  hosts:
  - "auth-example.reachablegames.com"
  gateways:
  - istio-gw
  http:
  - route:
    - destination:
        host: auth-example.auth.svc.cluster.local  # this refers to a Service with name="auth-example"
        port:
          number: 80
---
# Sends traffic to the auth-example deployment pods, which is our application we are trying to secure
apiVersion: v1
kind: Service
metadata:
  name: auth-example
  namespace: auth
  labels:
    app: auth-example
spec:
  ports:
  - port: 80
    name: http-web
    targetPort: http-web
    protocol: TCP
  selector:
    app: auth-example  # send traffic to the auth-example pods
  sessionAffinity: None
  type: ClusterIP
---
# Sends …</code></pre></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reachablegames.com/oidc-fusionauth-istio/">https://reachablegames.com/oidc-fusionauth-istio/</a></em></p>]]>
            </description>
            <link>https://reachablegames.com/oidc-fusionauth-istio/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035985</guid>
            <pubDate>Mon, 09 Nov 2020 15:51:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Art of the Seed Pitch]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035887">thread link</a>) | @paraj
<br/>
November 9, 2020 | https://parajmathur.com/2020/10/24/art-of-seed-pitch/ | <a href="https://web.archive.org/web/*/https://parajmathur.com/2020/10/24/art-of-seed-pitch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<figure><img data-attachment-id="71" data-permalink="https://parajmathur.com/2020/10/24/art-of-seed-pitch/coach-speaking-before-audience/" data-orig-file="https://parajvc.files.wordpress.com/2020/10/the-seed-pitch-graphic.jpg" data-orig-size="8000,5000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Coach speaking before audience. Mentor presenting charts and reports, Employees meeting at business training, seminar or conference. Vector illustration for presentation, lecture, education concept&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Coach speaking before audience&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Coach speaking before audience" data-image-description="" data-medium-file="https://parajvc.files.wordpress.com/2020/10/the-seed-pitch-graphic.jpg?w=300" data-large-file="https://parajvc.files.wordpress.com/2020/10/the-seed-pitch-graphic.jpg?w=1024" src="https://parajvc.files.wordpress.com/2020/10/the-seed-pitch-graphic.jpg?w=1024" alt="Designed by pch.vector / Freepik" title="Designed by pch.vector / Freepik" srcset="https://parajvc.files.wordpress.com/2020/10/the-seed-pitch-graphic.jpg?w=1024 1024w, https://parajvc.files.wordpress.com/2020/10/the-seed-pitch-graphic.jpg?w=2048 2048w, https://parajvc.files.wordpress.com/2020/10/the-seed-pitch-graphic.jpg?w=150 150w, https://parajvc.files.wordpress.com/2020/10/the-seed-pitch-graphic.jpg?w=300 300w, https://parajvc.files.wordpress.com/2020/10/the-seed-pitch-graphic.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I meet 20+ seed and pre-seed founders every week. Every founder has a unique presentation style. Some like to go through the deck slide by slide. Others prefer a more dynamic conversation without a deck. After studying hundreds of pitches, the most effective and efficient pitches follow this framework — Founder-Product-Market-Fit.</p>



<p><amp-fit-text layout="fixed-height" min-font-size="6" max-font-size="72" height="80"><strong>Founder – why you are the right team to invest in</strong></amp-fit-text></p>



<p>A pre-seed/seed investment is mostly a bet on the founding team and their ability to move fast, execute, learn, and overcome adversity. Because this is potentially the beginning of a 10+ year relationship (hopefully), start your pitch by talking about you and the team. Tell your story. Highlight your professional accomplishments, industry and functional areas of expertise, and any unique insights you have about the problem you are solving. In this segment, some founders rely on logos (Stanford, Google, McKinsey), others rely on pedigree and experience (X years leading B2B Sales teams), and some on results and exits. The main goal is to help the investor understand why you are the right person to bet on, right now.</p>



<p><strong>Product –&nbsp; your solution to an existing problem</strong></p>



<p>After convincing the investor that you have done other cool things <em>before this</em>, the next step is showing that you can do <strong><em>this. </em></strong>To do that, you need to answer two questions. First, is it even possible to build this solution? Second, can <strong>you</strong> build this? If the answer to either of those is no, it might be hard to raise money for your idea. Otherwise, this is the perfect time to talk about the specifics of your product. What it does. How it works. How it solves the problem. How much of it have you built so far. This last part is important because it reflects your ability to move fast and execute. If you started the company in 2018, and it’s 2020, and you don’t have an MVP yet, it raises red flags. If you can convince the investor that your product truly solves the problem and you have made meaningful progress towards putting this product in the hands of the customers, this section is successful.</p>



<p><strong>Market – customers care about your solution</strong></p>



<p>If the (all too) recent demise of Quibi proves anything, it is that building a cool new product isn’t enough to attract customers. As a result, you need to first highlight the segments that face the problem you have set out to solve. It’s okay if it’s not a precisely defined market, it’s helpful to show your thinking around how you are slicing and dicing the market and how you are creating your ideal customer profile (VCs will use this in their internal market sizing).&nbsp; Once you show target customers, the next step is to show your progress in reaching them, and their ability and willingness to pay for your solution. The best way to do this is revenue. If you are really early you can use a combo: show how much the problem costs them in dollars and time, and how much you found they are willing to pay through customer interviews. You want the investor to walk away from this segment thinking that you understand the customer profile, their needs and wants, have a strategy for how to reach them, a preliminary understanding of how much the solution is worth to them, and how much traction you have so far with your early adopters.</p>



<p><strong>Fit – okay so you did it once but can you do it again, and again?</strong></p>



<p>Once I hit a full court basketball shot. Is the NBA calling? No, I have never been able to do it again. To succeed as a startup founder you need to sell your product to a customer. Then do it again. Then do it a million more times, atleast. The final key piece of the puzzle is discussing how you can repeatedly get customers to use and pay for your product. In VC-speak this is your go to market strategy. Walk through your process for acquiring customers and how you can repeat it, even if it is not ironclad. If you have a few different channels, mention them all and then highlight your favorite one and why you like it. The secret to sticking the landing here, is to show that you have figured out a way to repeatedly get customers.</p>



<p>By the end of this pitch, ideally, you showcase your founder highlight reel, prove you can build a product that actually solves a problem, demonstrate that customers care about it enough to pay for it, and that you can do it again, and again, and again. Thinking through your pitch in this format will help you modify your pitch for any situation, from the elevator pitch, to a 30 min intro call, to an hour long partner meeting.</p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-10-24T21:23:16-04:00">October 24, 2020</time><time datetime="2020-10-26T09:40:30-04:00">October 26, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://parajmathur.com/2020/10/24/art-of-seed-pitch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035887</guid>
            <pubDate>Mon, 09 Nov 2020 15:43:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oneapi.jl – Native Julia Support for Intel GPUs]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25035875">thread link</a>) | @KenoFischer
<br/>
November 9, 2020 | https://juliagpu.org/2020-11-05-oneapi_0.1/ | <a href="https://web.archive.org/web/*/https://juliagpu.org/2020-11-05-oneapi_0.1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="main"><i data-feather="calendar"></i><time datetime="2020-11-05">Nov 5, 2020</time><br><i data-feather="edit-2"></i>Tim Besard<p>We’re proud to announce the first version of oneAPI.jl, a Julia package for programming
accelerators with the <a href="https://www.oneapi.com/">oneAPI programming model</a>. It is currently
available for select Intel GPUs, including common integrated ones, and offers a similar
experience to CUDA.jl.</p><p>The initial version of this package, v0.1, consists of three key components:</p><ul><li>wrappers for the oneAPI Level Zero interfaces;</li><li>a compiler for Julia source code to SPIR-V IR;</li><li>and an array interface for convenient data-parallel programming.</li></ul><p>In this post, I’ll briefly describe each of these. But first, some essentials.</p><h2 id="installation">Installation</h2><p>oneAPI.jl is currently only supported on 64-bit Linux, using a sufficiently recent kernel,
and requires Julia 1.5. Furthermore, it currently only supports a limited set of Intel GPUs:
Gen9 (Skylake, Kaby Lake, Coffee Lake), Gen11 (Ice Lake), and Gen12 (Tiger Lake).</p><p>If your Intel CPU has an integrated GPU supported by oneAPI, you can just go ahead and
install the oneAPI.jl package:</p><pre><code>pkg&gt; add oneAPI
</code></pre><p>That’s right, no additional drivers required! oneAPI.jl ships its own copy of the <a href="https://github.com/intel/compute-runtime">Intel
Compute Runtime</a>, which works out of the box on
any (sufficiently recent) Linux kernel. The initial download, powered by Julia’s artifact
subsystem, might take a while to complete. After that, you can import the package and start
using its functionality:</p><pre><code>julia&gt; using oneAPI

julia&gt; oneAPI.versioninfo()
Binary dependencies:
- NEO_jll: 20.42.18209+0
- libigc_jll: 1.0.5186+0
- gmmlib_jll: 20.3.2+0
- SPIRV_LLVM_Translator_jll: 9.0.0+1
- SPIRV_Tools_jll: 2020.2.0+1

Toolchain:
- Julia: 1.5.2
- LLVM: 9.0.1

1 driver:
- 00007fee-06cb-0a10-1642-ca9f01000000 (v1.0.0, API v1.0.0)

1 device:
- Intel(R) Graphics Gen9
</code></pre><h2 id="the-onearray-type">The <code>oneArray</code> type</h2><p>Similar to CUDA.jl’s <code>CuArray</code> type, oneAPI.jl provides an array abstraction that you can
use to easily perform data parallel operations on your GPU:</p><pre><code>julia&gt; a = oneArray(zeros(2,3))
2×3 oneArray{Float64,2}:
 0.0  0.0  0.0
 0.0  0.0  0.0

julia&gt; a .+ 1
2×3 oneArray{Float64,2}:
 1.0  1.0  1.0
 1.0  1.0  1.0

julia&gt; sum(ans; dims=2)
2×1 oneArray{Float64,2}:
 3.0
 3.0
</code></pre><p>This functionality builds on the <a href="https://github.com/JuliaGPU/GPUArrays.jl/">GPUArrays.jl</a>
package, which means that a lot of operations are supported out of the box. Some are still
missing, of course, and we haven’t carefully optimized for performance either.</p><h2 id="kernel-programming">Kernel programming</h2><p>The above array operations are made possible by a compiler that transforms Julia source code
into SPIR-V IR for use with oneAPI. Most of this work is part of
<a href="https://github.com/JuliaGPU/GPUCompiler.jl">GPUCompiler.jl</a>. In oneAPI.jl, we use this
compiler to provide a kernel programming model:</p><pre><code>julia&gt; function vadd(a, b, c)
           i = get_global_id()
           @inbounds c[i] = a[i] + b[i]
           return
       end

julia&gt; a = oneArray(rand(10));

julia&gt; b = oneArray(rand(10));

julia&gt; c = similar(a);

julia&gt; @oneapi items=10 vadd(a, b, c)

julia&gt; @test Array(a) .+ Array(b) == Array(c)
Test Passed
</code></pre><p>Again, the <code>@oneapi</code> macro resembles <code>@cuda</code> from CUDA.jl. One of the differences with the
CUDA stack is that we use OpenCL-style built-ins, like <code>get_global_id</code> instead of
<code>threadIdx</code> and <code>barrier</code> instead of <code>sync_threads</code>. Other familiar functionality, e.g. to
reflect on the compiler, is available as well:</p><pre><code>julia&gt; @device_code_spirv @oneapi vadd(a, b, c)
; CompilerJob of kernel vadd(oneDeviceArray{Float64,1,1},
;                            oneDeviceArray{Float64,1,1},
;                            oneDeviceArray{Float64,1,1})
; for GPUCompiler.SPIRVCompilerTarget

; SPIR-V
; Version: 1.0
; Generator: Khronos LLVM/SPIR-V Translator; 14
; Bound: 46
; Schema: 0
               OpCapability Addresses
               OpCapability Linkage
               OpCapability Kernel
               OpCapability Float64
               OpCapability Int64
               OpCapability Int8
          %1 = OpExtInstImport "OpenCL.std"
               OpMemoryModel Physical64 OpenCL
               OpEntryPoint Kernel
               ...
               OpReturn
               OpFunctionEnd
</code></pre><h2 id="level-zero-wrappers">Level Zero wrappers</h2><p>To interface with the oneAPI driver, we use the <a href="https://github.com/oneapi-src/level-zero">Level Zero
API</a>. Wrappers for this API is available under the
<code>oneL0</code> submodule of oneAPI.jl:</p><pre><code>julia&gt; using oneAPI.oneL0

julia&gt; drv = first(drivers())
ZeDriver(00000000-0000-0000-1642-ca9f01000000, version 1.0.0)

julia&gt; dev = first(devices(drv))
ZeDevice(GPU, vendor 0x8086, device 0x1912): Intel(R) Graphics Gen9
</code></pre><p>This is a low-level interface, and importing this submodule should not be required for the
vast majority of users. It is only useful when you want to perform very specific operations,
like submitting an certain operations to the command queue, working with events, etc. In
that case, you should refer to the <a href="https://spec.oneapi.com/level-zero/latest/index.html">upstream
specification</a>; The wrappers in the
<code>oneL0</code> module closely mimic the C APIs.</p><h2 id="status">Status</h2><p>Version 0.1 of oneAPI.jl forms a solid base for future oneAPI developments in Julia. Thanks
to the continued effort of generalizing the Julia GPU support in packages like GPUArrays.jl
and GPUCompiler.jl, this initial version is already much more usable than early versions of
CUDA.jl or AMDGPU.jl ever were.</p><p>That said, there are crucial parts missing. For one, oneAPI.jl does not integrate with any
of the vendor libraries like oneMKL or oneDNN. That means several important operations, e.g.
matrix-matrix multiplication, will be slow. Hardware support is also limited, and the
package currently only works on Linux.</p><p>If you want to contribute to oneAPI.jl, or run into problems, check out the GitHub
repository at <a href="https://github.com/JuliaGPU/oneAPI.jl">JuliaGPU/oneAPI.jl</a>. For questions,
please use the <a href="https://discourse.julialang.org/c/domain/gpu">Julia Discourse forum</a> under
the GPU domain and/or in the #gpu channel of the <a href="https://julialang.org/community/">Julia
Slack</a>.</p></main></div></div>]]>
            </description>
            <link>https://juliagpu.org/2020-11-05-oneapi_0.1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035875</guid>
            <pubDate>Mon, 09 Nov 2020 15:42:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Architecture Playbook]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 46 (<a href="https://news.ycombinator.com/item?id=25035752">thread link</a>) | @yarapavan
<br/>
November 9, 2020 | https://nocomplexity.com/documents/arplaybook/index.html | <a href="https://web.archive.org/web/*/https://nocomplexity.com/documents/arplaybook/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>
        
          By Maikel Mardjan<br>
        
            © Copyright 2018,2019, 2020 BM-Support.org. Created by Maikel Mardjan. This work is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License (cc-by-sa).<br>
      </p>
  </div></div>]]>
            </description>
            <link>https://nocomplexity.com/documents/arplaybook/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035752</guid>
            <pubDate>Mon, 09 Nov 2020 15:31:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SC20: Supercomputing Virtual Conference Now Live]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035671">thread link</a>) | @ArtWomb
<br/>
November 9, 2020 | https://www.eventscribe.net/2020/SC20/index.asp? | <a href="https://web.archive.org/web/*/https://www.eventscribe.net/2020/SC20/index.asp?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>This session is not in your schedule.</p>
					</div></div>]]>
            </description>
            <link>https://www.eventscribe.net/2020/SC20/index.asp?</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035671</guid>
            <pubDate>Mon, 09 Nov 2020 15:23:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start with “No”]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035670">thread link</a>) | @jerodsanto
<br/>
November 9, 2020 | https://www.dylanpaulus.com/start-with-no/ | <a href="https://web.archive.org/web/*/https://www.dylanpaulus.com/start-with-no/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><section><div><blockquote>
<p>Our default response to any idea that comes up should be: “Interesting. Maybe some day.” In other words, a very soft “no” that leaves all our options open. We don’t put it in a backlog. We give it space so we can learn whether it’s really important and what it might entail.</p>
</blockquote>

<p>Story time. At a previous employer I had a boss who I thought was pretty tough. Not to me, but our users. No matter the request his response was always the same, "No." Eventually, we implemented around 40% of the requests, but the constant rejection of these requests stuck with me. Now that I lead a team I notice myself using the same mindset. "No" isn't negative, and it's not dismissive. "No" is a way of protecting the team, the project, and the users.</p>
<h3 id="No"><a href="#No" aria-label="No permalink"></a>No?</h3>
<p>There is a natural progression to projects that looks something like this. First, the honeymoon phase. The pastures are green; the project has no technical debt and every feature is a great idea. As we add functionality our user base grows. If we're lucky enough to get traction we move to phase two, the monolith. Our application now handles a bunch of use-cases. It does your taxes, picks up your dog's poop, and reminds you to call your mom. Only power users can fully grasp the purpose of the application. The technical debt is increasing with every new feature added. Finally, we get to the last phase. The application has become so bloated that it's hard to develop new features. New users aren't willing to learn the ins-and-outs of the product. A new startup comes around with a trimmed down version of your application. It's so easy to use! Around this time users are jumping ship.</p>
<figure>
    <span>
      <span></span>
  <picture>
        <source srcset="https://www.dylanpaulus.com/static/2c6a45f0b16beb2d0378247e433e93e4/c85cb/feature-graph.webp 300w,
https://www.dylanpaulus.com/static/2c6a45f0b16beb2d0378247e433e93e4/b0a15/feature-graph.webp 500w" sizes="(max-width: 500px) 100vw, 500px" type="image/webp">
        <source srcset="https://www.dylanpaulus.com/static/2c6a45f0b16beb2d0378247e433e93e4/f93b5/feature-graph.jpg 300w,
https://www.dylanpaulus.com/static/2c6a45f0b16beb2d0378247e433e93e4/41099/feature-graph.jpg 500w" sizes="(max-width: 500px) 100vw, 500px" type="image/jpeg">
        <img src="https://www.dylanpaulus.com/static/2c6a45f0b16beb2d0378247e433e93e4/41099/feature-graph.jpg" alt="Diagram showing a product's lifecycle" title="Diagram showing a product's lifecycle" loading="lazy">
      </picture>
    </span>
    <figcaption>Diagram showing a product's lifecycle</figcaption>
  </figure>
<p>Saying "no" is a buffer in our development process. It gives us, the developer, time to think of an optimal solution. Could a feature being asked for be solved in a way that satisfies multiple feature requests? Is there some domain logic we have yet to understand? Does the feature really make sense in <em>this</em> application? All these questions help reduce the lifecycle described above. It reduces feature churn by keeping the application simple, and by solving issues the users actually have.</p>
<p>Be mindful of how features interacts within your application. Nothing comes without a cost--especially in software development.</p>
<h3 id="No-1"><a href="#No-1" aria-label="No 1 permalink"></a>No.</h3>
<p>"No" is a way of protecting people--the users and the development team. There is a gradient of experience when it comes to using your application. Users will be complete beginners, and others will be power users. As a product owner we need to balance these two extremes. If the application is too power-user-centric, then it's harder for new users to grok. When the application is too hand-holding, power users become frustrated. Saying "no" to one extreme is a way of keeping the scales balanced. But, be mindful of what you say "no" to. Some features may be vital to the application's success. This is part of the art.</p>
<p>"No" gives time to find the optimal solution to a problem. Users ask for a solution to <strong>X</strong> and suggest implementing <strong>Y</strong>, but what they really need is <strong>K</strong>. Feature requests give us an opportunity to improve processes and workflows. Our user's are domain experts, but are prone to do things they way they've "always done them". We can come in and find ways to simplify. Ask the user, "do we really need this step?" or "Could the system handle that instead of a person?" Once code is written and users get accustomed to the feature, it's really hard to change. Do this step upfront.</p>
<p>"No" keeps the development team doing meaningful work. Spending a sprint or two implementing a feature nobody uses or finds frustrating is demoralizing. Think about the workflow before writing any code. Question the feature and the users. Does the application need this? Could we implement it in a simple way? Reduce code churn; reduce developer churn.</p>
<h3 id="No-2"><a href="#No-2" aria-label="No 2 permalink"></a>No!</h3>
<p>Work needs to get done. At some point you need to say "yes", but instead of taking on every task, you get to be mindful on what to prioritize. You get to take on the tasks that add the most business value and delight users. Use "no" as a tool.</p></div></section></section></div>]]>
            </description>
            <link>https://www.dylanpaulus.com/start-with-no/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035670</guid>
            <pubDate>Mon, 09 Nov 2020 15:23:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are Airlines Ready to Transport Vaccines?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035662">thread link</a>) | @ilamont
<br/>
November 9, 2020 | https://airlineweekly.com/are-airlines-ready-to-transport-vaccines/ | <a href="https://web.archive.org/web/*/https://airlineweekly.com/are-airlines-ready-to-transport-vaccines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><article id="main-article" itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><div><p>The answer is “maybe.” The International Air Transport Association (IATA) <a href="https://www.iata.org/en/pressroom/pr/2020-09-09-01/">says</a> the airline industry could be ready to air ship billions of doses of Covid-19 vaccines, when they’re ready to be administered, but only if governments around the world coordinate now on transport policies.</p><p>The logistical challenge of transporting billions of vaccines is enormous. First, the sheer capacity required. IATA estimates that 8,000 cargo-only Boeing 747s would be needed to carry enough doses for the world’s 7.6 billion people. It’s almost needless to say that there aren’t 8,000 B747 freighters (given that Boeing only built just under 1,600 B747s of all types in the 50 years since the aircraft launched).</p><p>Most air freight is carried not by freighters but in the belly holds of passenger aircraft. Since the pandemic started, airlines have slashed international routes, resulting in a cargo capacity crunch just as cargo demand and profits started to rise. Many airlines, including United, American, <a href="https://airlineweekly.com/cargo-buoys-turkish-airlines/">Turkish</a>, Emirates, and others, have operated special cargo-only flights since the pandemic begin, converting passenger cabins to temporary cargo holds (and in fact, cargo led to rare profits in the industry for <a href="https://airlineweekly.com/cargo-fuels-korean-asiana-profits/">Korean and Asiana</a>). Global air freight capacity was down 31% in July, the latest month for which data are available, from 2019, <a href="https://www.iata.org/en/pressroom/pr/2020-08-31-01/">IATA said</a>. </p><p>A second challenge is maintaining the “cold chain,” or keeping the vaccines cool from manufacture to delivery. It’s not a matter of life and death if the cold chain fails for a shipment of fresh fruit. It could be if a shipment of vaccines is exposed to high temperatures, during land transport to the airport, on the tarmac, or even at the delivery airport if the shipment is held up by customs. Early in the pandemic, reports that personal protective equipment was stalled on tarmacs raised outrage, even though most of the equipment survived. Vaccines would not survive days on the tarmac, the industry warns. Freight industry analysts have said the cold chain already is stretched and could further imperil the safe transport of vaccines.</p><p>And speaking of safety, airlines transporting vaccines will be charged with the safety of what will arguably be the world’s most valuable commodity. Security at all points of the logistics chain needs to be strengthened and can’t be solely airlines’ responsibility, IATA said.</p><p>The good news is that airlines have parked thousands of aircraft — including hundreds of large widebodies — that can be pressed into vaccine-transport duty. But it takes time to return aircraft parked in the desert to service. And it takes employees to return those aircraft to service and to fly them, just as airlines around the world are in the process of furloughing tens of thousands of workers. </p><p>None of this is insurmountable, IATA argues. Governments need to act and coordinate on security, mandating cargo flights, and loosening some quarantine and travel restrictions to allow flight crews more flexibility to operate cargo flights. But the time to act is now, not when vaccines are ready for distribution. “If borders remain closed, travel curtailed, fleets grounded and employees furloughed, the capacity to deliver life-saving vaccines will be very much compromised,” said IATA Director General Alexandre de Juniac. &nbsp;&nbsp;</p><p><a href="https://airlineweekly.com/subscribe/">Subscribe Now to Airline Weekly</a></p></div></div> </article></div></div></div></div></div>]]>
            </description>
            <link>https://airlineweekly.com/are-airlines-ready-to-transport-vaccines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035662</guid>
            <pubDate>Mon, 09 Nov 2020 15:22:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I don't care what Elon Musk thinks anymore]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 66 (<a href="https://news.ycombinator.com/item?id=25035658">thread link</a>) | @avthar
<br/>
November 9, 2020 | https://avthar.com/blog/dont-outsource-thinking | <a href="https://web.archive.org/web/*/https://avthar.com/blog/dont-outsource-thinking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-f18334b57a4385ee2a76"><div><p><em>This blog originally appeared in my </em><a href="https://avthar.substack.com/"><em>weekly newsletter</em></a><em>, where I share ideas I’m reflecting upon, experiments I’m trying and lessons I’ve learned, all to help you level up your own life. To get posts like this straight to your inbox, </em><a href="https://avthar.substack.com/"><em>subscribe here</em></a><em>.</em></p><p>—</p><p>Youtube recommended to me&nbsp;<a href="https://www.youtube.com/watch?v=vVnDE8wSrVo">what Elon Musk would work on if he was 22 years old today</a>. The video has almost 3 million views. In the past, I would’ve immediately watched the whole video, gotten inspired by what Elon thought were industries important to the future of humanity and then spent a ton of time working on that and telling everyone about it. All because Elon Musk thought it was important.&nbsp;</p><p><strong>This is outsourcing your thinking</strong>. This trick served me well in highschool and throughout college, but it’s not sustainable for long term success and happiness.&nbsp;</p><p>There are two problems with outsourcing your thinking. Continuing with the example of past me, there are things I’m already interested in, have&nbsp;<a href="https://nav.al/specific-knowledge">specific knowledge</a>&nbsp;about or possess a competitive advantage in, that won’t be mentioned on Elon’s list. Consequently, the first problem is that I will look down on those things as less meaningful and important and not pursue them, despite my better suitability and chances of success in those areas.</p><p>The second problem with outsourcing your thinking is that once the novelty of the problem fades away, I’d be faced with navigating difficulty, naysayers and the friction of creating something new, without an internal compass to guide me toward the correct paths to take. Put simply, Elon Musk isn’t there to talk me through what he thinks the path forward to be. This all stems from the issue that I pursued something, not because I had interest in that thing, actually enjoyed it or thought it was important, but because Elon Musk (or whoever else) thought it was important to work on. And I followed his thinking, rather than thinking for myself.</p><p>The reason this is important is because most success in business is having&nbsp;<strong>product-market-founder fit</strong>, not just about working on what’s world changing or hot. It’s about building a product that solves a burning problem for the right market and&nbsp;<strong>being the right person, with the right intuition</strong>&nbsp;to bring that product to market, operate that company and delight those customers. Even if you’re working on an important problem, if you don’t have conviction that comes from your own mental models, you’ll get burned when chaos hits. Just ask all the crypto ‘experts’ of 2016/17.&nbsp;<strong>It’s better to build something that’s an expression of yourself, rather than something others think is smart.</strong></p><p>Outsourcing your thinking is a manifestation of the error of trusting others more than we trust ourselves.&nbsp;<a href="https://avthar.com/blog/jw-curation">Josh Waitzkin</a>&nbsp;talks about how this phenomenon of outsourcing your thinking happens all the time in the investing world:</p><blockquote><p>“<em>If you take investors, there might be an investment, which one from the outside we think is objectively good. But it really isn't objectively good. It has to fit into one's portfolio of investments in a way that emerges from one's own mental models. Otherwise, it is not a form of self expression. Then, when you enter volatility, you're not gonna know what to do with it.</em>” -&nbsp;<a href="https://avthar.com/blog/jw-curation">Josh Waitzkin</a></p></blockquote><p>Elon Musk is a placeholder for anyone telling you what you should do or think. That could be entrepreneurs or VCs you idolize or maybe your parents (especially true if you’re brown). The reality is that you should not care what Elon Musk or anyone else says is important, you should decide for yourself what you should work on, based on following your own curiosity and interest.&nbsp;<strong>Do the hard work of experimenting, exploring and thinking for yourself. Don’t outsource your thinking.</strong></p><p><a href="https://avthar.substack.com/"><em>Subscribe here</em></a><em> to get posts like this straight to your inbox, </em></p></div></div></div>]]>
            </description>
            <link>https://avthar.com/blog/dont-outsource-thinking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035658</guid>
            <pubDate>Mon, 09 Nov 2020 15:21:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dying for movies: Suicide highlights labour issues in Canada's VFX sector]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035628">thread link</a>) | @alibarber
<br/>
November 9, 2020 | https://montreal.ctvnews.ca/mobile/dying-for-movies-suicide-highlights-labour-issues-in-canada-s-visual-effects-sector-1.5175793 | <a href="https://web.archive.org/web/*/https://montreal.ctvnews.ca/mobile/dying-for-movies-suicide-highlights-labour-issues-in-canada-s-visual-effects-sector-1.5175793">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>MONTREAL -- 
	Last April, Malcolm Angell, a 46-year-old New Zealander who moved to Montreal to work in the city's famed visual effects industry, was taken to hospital after attempting suicide.</p>
<p>
	He was back at work two days later at Montreal-based visual effects studio Mill Film, according to his brother, Ivan. A month later -- shortly after learning his mother had a brain tumour and didn't have long to live -- Angell tried to kill himself again. This time he died.</p>
<p>
	Angell's former colleagues allege the work environment at Mill Film was toxic. They say 80-hour workweeks were common, and that Angell was regularly humiliated by his bosses. Ivan says he's certain his brother would have quit -- were it not for a clause in Angell's contract requiring he pay a $35,000 penalty.</p>
<p>
	The story told by Angell's colleagues is not uncommon in Canada's visual effects and animation sectors, according to industry insiders. Long overtime hours, often unpaid, are seen as normal, they say. And employees in these industries are vulnerable -- particularly foreign workers -- who toil on short-term contracts and are afraid to speak up out of fear of not getting hired again.</p>
<p>
	For Vanessa Kelly, a former animator and union organizer in Vancouver's animation industry, Angell's suicide is a sign that something is deeply wrong with the visual effects sector. She said similar issues exist in animation and within video game companies across Canada.</p>
<p>
	"These are movies. Why are people dying for movies?" said Kelly, general director of the Art Babbitt Appreciation Society, which is trying to organize animators in Vancouver.</p>
<p>
	Angell had nearly 20 years experience in film, and got his start working on set during the production of The Lord of The Rings. In August 2019, he moved to Montreal to work in the city's visual effects industry -- one of the largest in the world. Colleagues and friends say it was not long before the job started to get to him.</p>
<p>
	The Canadian Press spoke to three of Angell's former colleagues, who painted a picture of a workplace where Angell was under extreme pressure and where bosses yelled at him during meetings. Complaints to human resources and to senior mangers, they said, went nowhere.</p>
<p>
	The Canadian Press has agreed not to identify those workers because they fear repercussions. All three said people in the industry who speak out against work conditions are frequently blacklisted.</p>
<p>
	"Work kinda sucks," Angell wrote in an email to a friend in New York City in early September 2019. By November, in an email to the same friend, he said he was doing the work of two people. A planned trip to New Zealand for a wedding in February, 2020, was cancelled, his brother Ivan said in a recent interview, because Angell couldn't get the time off work.</p>
<p>
	Ivan Angell said friends noticed a change in his brother by December. The man who was described in an obituary as a "superfriend" who was always smiling, had become a "shadow of himself," he said.</p>
<p>
	Julia Neville, with the International Alliance of Theatrical Stage Employees, said fears of being blacklisted for speaking out in the visual effects industry are legitimate. Visual effects artists are precarious workers, Neville said, because their contracts are typically for one project at a time. "There's always that underlying insecurity," she said. Foreign workers, such as Angell, are "particularly vulnerable."</p>
<p>
	"They can't just cross the street and work for another visual effects house -- their whole ability to work in Canada is tied to a specific employer," Neville said. Much of the film industry is unionized, while the large majority of visual effects artists are not, she explained. Long hours and unpaid overtime "are very common," she said, adding that unfair labour practices are frequent in other entertainment sectors, such as animation, reality television and in commercials.</p>
<p>
	Neville said visual effects companies try to underbid each other for work on projects produced by major movie studios. "That pressure is exerted downward onto the worker," she said. "What ends up happening is there's never enough time allotted to accomplish what you need done."</p>
<p>
	Angell's former colleagues said he was under extreme pressure to complete his part in the movie "Bios," starring Tom Hanks. They said Angell and the team he oversaw had been told by his bosses at Mill Film to finish additional work but hadn't been given more time or money to get it done.</p>
<p>
	Another element that tied Angell to his employer was his contract, a copy of which The Canadian Press viewed. The contract included a clause stating he was liable to pay Mill Film a $35,000 indemnity should he leave in the middle of a project.</p>
<p>
	The indemnity clause identified Angell as a "key member" of the team and indicated that the company would be contractually committing Angell's services to its client. The contract said that for "certain very exceptional and serious" reasons the company could decide to waive the indemnification clause.</p>
<p>
	Adelle Blackett, a law professor at McGill University and labour law expert, said that clause "is deeply disturbing." Quebec's labour standards require employers to provide working conditions that "safeguard employees' dignity, health and well-being," she wrote in an email. "An employee working in conditions of freedom must be able to terminate an employment contract with only minimally necessary restrictions."</p>
<p>
	Technicolor, Mill Film's parent company, did not make anyone available to speak on the record. In an emailed statement, the company said Angell's death was a "traumatic and tragic event for his family, friends and for our team. We mourn his passing and continue to express our deepest condolences to his family."</p>
<p>
	The company said it has introduced a new program aimed at supporting employee mental health since Angell's death -- due to the "severity and isolating nature of the pandemic." Another program has been launched encouraging employees to "call out" inappropriate behaviour, the company said.</p>
<p>
	"Technicolor has had longstanding and robust anti-harassment policies in place in Canada. This specifically includes broad anti-bullying and related anti-retaliation policies, among others," it said. The company said it takes complaints seriously and that it didn't receive any formal complaints about Angell's treatment at Mill Film.</p>
<p>
	Kelly -- who quit animation work in 2017 to pursue a science degree -- said unpaid overtime is common. "In animation and (visual effects) we have major skilled labour shortages," she said, adding that companies often don't have the budget to hire more people. "We have to fill in those gaps with overtime and they don't want to pay us for it."</p>
<p>
	Kelly said she got involved with union organizing after working on a project as a storyboard artist. She said her workload suddenly doubled but her deadline remained the same. The work -- which required hours of unpaid overtime -- damaged her wrist and her eyesight, she said.</p>
<p>
	"My physical body was being harmed, my mental capacity was being harmed and my relationships were being harmed. And I looked around and I said, what is this for? A PBS show for children?"</p>
<p>
	For many workers in animation, the job is a part of their identity, Kelly said. "People don't do this because they just want a job, they do this because they have a skill and a passion.</p>
<p>
	"They eat, live and breathe this." But behind the scenes, she said, "there's blood on the screen."</p>

<p>
	<em>-- this report by The Canadian Press was first published Nov. 5, 2020.</em></p>
                                              </div></div>]]>
            </description>
            <link>https://montreal.ctvnews.ca/mobile/dying-for-movies-suicide-highlights-labour-issues-in-canada-s-visual-effects-sector-1.5175793</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035628</guid>
            <pubDate>Mon, 09 Nov 2020 15:19:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to price your SaaS product]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035529">thread link</a>) | @moeamaya
<br/>
November 9, 2020 | https://www.lennyrachitsky.com/p/saas-pricing-strategy | <a href="https://web.archive.org/web/*/https://www.lennyrachitsky.com/p/saas-pricing-strategy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>👋 Hello, I’m&nbsp;<a href="https://twitter.com/lennysan">Lenny</a>&nbsp;and welcome to a ✨&nbsp;<strong>once-a-month-free-edition&nbsp;</strong>✨ of my newsletter. Each week I humbly tackle reader questions about product, growth, working with humans, and anything else that’s stressing them out at the office.</em></p><p><em>If you’re not a paid subscriber, here’s what you missed this month:</em></p><ol><li><p><em><a href="https://www.lennyrachitsky.com/p/moving-from-ic-product-manager-to">Moving from IC product manager to manager of product managers</a></em></p></li><li><p><em><a href="https://www.lennyrachitsky.com/p/top-5-most-interesting-things-about">Top 5 most interesting things about Booking.com's early growth strategy</a></em></p></li><li><p><em><a href="https://www.lennyrachitsky.com/p/the-most-important-bottom-up-saas">The most important bottom-up SaaS metrics to track (and how to best visualize them)</a></em></p></li></ol><blockquote><h2>Q: I'm building a SaaS product and don't know where to start when pricing it. How should I approach my pricing strategy?</h2></blockquote><p>When this question came in, I took to Twitter to find the smartest person in the world on SaaS pricing…</p><p>Many suggestions came though but one name came up again and again: <a href="https://twitter.com/Patticus">@Patticus</a>, aka Patrick Campbell.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F225c2988-0cd8-431b-b69b-a8e7dd1de832_2400x1350.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F225c2988-0cd8-431b-b69b-a8e7dd1de832_2400x1350.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/225c2988-0cd8-431b-b69b-a8e7dd1de832_2400x1350.png&quot;,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:657394,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I cold DM’d Patrick and asked him if he’d be up for writing a guest post. He instantly agreed 🙌🙌🙌</p><p>For those that don’t know Patrick, he is CEO of <a href="https://www.profitwell.com/">ProfitWell</a>, and generally regarded guru on anything SaaS. Unrelated to this post, I started using ProfitWell a couple of months back to track my newsletter metrics, and the amount of insight you get into your subscription business is unreal. AND IT’S FREE.  If you’re running a SaaS business,  definitely <a href="https://www.profitwell.com/">check it out.</a> This is not a sponsored post — I just love the product.</p><p><em>🚨 <strong>Bonus</strong>: Patrick Campbell is doing a live AMA at 5pm PT today (10/27) in our subscriber-only Slack group. Ask Patrick any question you have about pricing your product live!</em></p><p>With that out of the way, let’s dive in!</p><p>—</p><p><em>by Patrick Campbell</em></p><p>Pricing is one of those topics that sits at the nexus of uncomfortable and long-term, which means companies often don’t think about it for far too long. Even when they eventually figure it out, they don’t touch it again for years.</p><p><strong>The most successful companies optimize monetization in some manner every quarter</strong>. You may be thinking, “they change their price every 3 months!?” No, and that's the first lesson of monetization: pricing goes so much further than the actual price. Let me explain.</p><p>If we go to a thirty thousand foot view, you have to think about what you're actually doing with pricing. No matter the business you're in — non-profit, retail, SaaS, DTC, B2B, whatever — you've created some sort of value. You attach a unit of measurement to the value you created: your price. Put simply, your price is the exchange rate on the value you're creating in the world.</p><p>But price doesn’t live in a vacuum. Everything in your business — from sales and marketing to product and finance — is used to drive someone to buy the product at the price you're offering. Dozens of aspects of your business influence your price, and how effectively it converts customers:</p><ol><li><p><strong>The segment and vertical you are targeting</strong>: You can go upmarket to customers who have higher willingness to pay, shift to a vertical that sees more value in your offering, or even change the ideal customer profile entirely.</p></li><li><p><strong>Your product, positioning, and packaging</strong>: You can come out with new features, move features to different tiers, pull features out and make them add-ons, change up your value propositions, etc.</p></li><li><p><strong>Your price</strong>: You can move your price up or down, which will impact conversion obviously, but will also impact the perception of your brand.</p></li></ol><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F637dba83-56b6-434f-906e-330f363cbde7_1600x900.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F637dba83-56b6-434f-906e-330f363cbde7_1600x900.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/637dba83-56b6-434f-906e-330f363cbde7_1600x900.png&quot;,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>These are not the only axes when it comes to pricing, but the point is anything that influences the value of your product is involved in pricing and monetization. Cool – I've now given you a college lecture worthy of a tweed blazer, so let's dig into where you should start.</p><p><strong>In the beginning, the actual number you're charging isn't that important. </strong></p><p>There are some exceptions, but for the most part, you should first be figuring out the range you're in: a $10 product, $100 product, $1k product, etc. Don't waste time debating $500 vs. $505, because this doesn't matter as much until you have a stronger foundation beneath you.</p><p>What matters much more is two other questions:</p><ol><li><p>Your <strong>value metric</strong></p></li><li><p>Your ideal <strong>customer profiles and segments</strong></p></li></ol><p>These two elements are the foundation of your monetization and pricing strategy. Let’s explore them individually.</p><h3>Step 1: Determine your Value Metric</h3><p>A “value metric” is essentially what you charge for. For example: per seat, per 1,000 visits, per CPA, per GB used, per transaction, etc. <strong>If you get everything else wrong in pricing, but you get your value metric right, you'll do ok</strong>. It's that important. Partly because it bakes lower churn and higher expansion revenue into your monetization.</p><p>Pricing based on a value metric (vs. a tiered monthly fee) is important because it allows you to make sure you're not charging a large customer the same as you'd charge a small customer.</p><p>If you remember back to your high school or college economics class, the professor put a point on a demand curve for the perfect price and said “the revenue a firm gets is the area under that point.” The problem here is — what about all that other area under the curve? <strong>You’re missing out on that revenue by charging a flat monthly fee.&nbsp;</strong></p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F971baee8-62bc-4007-8a62-b2179faef927_1600x900.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F971baee8-62bc-4007-8a62-b2179faef927_1600x900.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/971baee8-62bc-4007-8a62-b2179faef927_1600x900.png&quot;,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>“Good, better, best” pricing is a bit more advantageous, because you end up with three points on our trusty demand curve, and thus more revenue potential. You see this in a lot of retail products who are constrained by being physical goods — the car with the basic package vs. the car with the stereo and sunroof vs. the car with everything. In software, it’s thankfully dying out, but you’ll still see it with mass-market products:&nbsp; Netflix, Adobe Creative Cloud, etc.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F24c3c7aa-aab8-40d1-9d5b-147b44cc2669_1600x900.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F24c3c7aa-aab8-40d1-9d5b-147b44cc2669_1600x900.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/24c3c7aa-aab8-40d1-9d5b-147b44cc2669_1600x900.png&quot;,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>A value metric however allows you to have essentially infinite price points — maximizing your revenue potential. In practice, you’ll never show infinite price points on your pricing page, sales deck, or mobile conversion page, but you may have a customer come in at a certain level and then grow.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6d0315d-e46a-4f3e-b03e-3bc46c2609d5_1600x900.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6d0315d-e46a-4f3e-b03e-3bc46c2609d5_1600x900.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e6d0315d-e46a-4f3e-b03e-3bc46c2609d5_1600x900.png&quot;,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>Value metrics also bake growth directly into how you charge because as usage or the amount of value received goes up (and those are not the same thing), the customer pays more. If they end up using or consuming less, they pay less (and thus avoid churning). This is why companies using value metrics are typically growing at <a href="https://www.profitwell.com/recur/all/outcome-based-value-metrics-for-growth">double the rate with half the churn and 2x the expansion revenue</a> when compared to companies that charge a flat fee or where the only difference between their pricing tiers are features.&nbsp;</p><h4><strong>How to determine your value metric</strong></h4><p>To determine your value metric, think about the <em>ideal essence of value</em> for your product&nbsp;— what value are you directly providing your customer? </p><p>In B2B, it's likely going to be money saved, revenue gained, time saved, etc. In DTC, it may be the joy you bring them, fitness achieved, increased efficiency, etc. Obviously, we can't measure all of these, but if you can, <em>and</em> your customer trusts your measurement (meaning you say you saved them $100 and they agree you saved them $100), that’s your value metric.</p><p>As an example, the perfect value metric for ProfitWell Retain (our churn recovery product) is how much churn we recover for you. We can measure this, and our customers agree to the measurement, so we can charge on that axis. Other pure value metric products include <a href="https://mainstreet.us/">MainStreet</a>, which handles government paperwork to automatically get you back tax credits — you pay a percentage of the money saved.&nbsp;</p><p>Most of you won't have a pure value metric, so the next step is to find a proxy for that metric. Take for example <a href="https://www.hubspot.com/">HubSpot</a>’s marketing product. Their pure value metric is the amount of revenue their tool drives for your business. This is hard to measure and hard for the customer to agree to in terms of what percentage of credit HubSpot deserves for revenue from a blog post. Proxies for HubSpot are things like the number of contacts, number of visits, number of users, etc.&nbsp;</p><p>To find the right proxy metric, you want to come up with 5-10 proxies and then talk to your customers and prospects. You’ll typically find 1-2 of these pricing metrics will be most preferred amongst your target customers. You then want to make sure those 1-2 also make sense from a growth perspective. Your larger customers should be using/getting more of the metric, whereas your smaller customers should be using/getting less of the metric. You also want to make sure the metric encourages retention.</p><p>When we look at HubSpot, if they were to primarily price on “number of seats”, folks could share a login and HubSpot wouldn’t make much more money on large customers vs. small. Ironically they wouldn’t get as many people invested into HubSpot, because there’d be friction to adding additional seats. Instead, if they give unlimited seats and price based on “number of contacts” there’s minimal friction to getting as many people into HubSpot as possible to do activities (e.g. blog posts, email campaigns, landing pages, etc.)&nbsp;that then produce contacts.</p><p>The result: HubSpot’s marketing product’s value metric is “contacts”, which ensures growth is baked directly into how they make money. The usage drives the metric, which therein drives revenue. Most importantly customers small, medium, and large are all paying at the point they see value and then can grow.</p><p>Some other examples:</p><ol><li><p><a href="https://wistia.com/">Wistia</a> charges by the number of videos or channels you use/have</p></li><li><p><a href="https://zapier.com/">Zapier</a> invented the concept of zap (connection of software) and charge based on time to connect</p></li><li><p><a href="https://www.bbc.com/news/technology-29551380">Theater in Barcelona charged based on the number of laughs</a></p></li><li><p><a href="https://www.husqvarna.com/">Husqvarna</a> charges based on time for lawn care products vs. making you buy them</p></li><li><p><a href="https://www.rolls-roycemotorcars.com/en_US/home.html">Rolls Royce</a> charges per mile for airplane engines. They own the engines on the plane you own and do all the maintenance. Cool model.</p></li><li><p><a href="https://www.freshpatch.com/">Fresh Patch</a> charges based on the amount of grass you want per month for your dog — yes they deliver grass to you monthly</p></li></ol><p>As a side note, you should stop pricing based on seats for products where each seat doesn’t provide a unique experience. For instance, in a CRM if I log in to the AE sitting next to me’s account, I can’t really do my work because I’m only seeing their leads and accounts. Conversely, if I log in to our marketing manager’s …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lennyrachitsky.com/p/saas-pricing-strategy">https://www.lennyrachitsky.com/p/saas-pricing-strategy</a></em></p>]]>
            </description>
            <link>https://www.lennyrachitsky.com/p/saas-pricing-strategy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035529</guid>
            <pubDate>Mon, 09 Nov 2020 15:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aaron Swartz would have been 34 years old today]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035500">thread link</a>) | @paulcarroty
<br/>
November 9, 2020 | https://www.aaronswartzday.org/remembering-aaron-in-2020/ | <a href="https://web.archive.org/web/*/https://www.aaronswartzday.org/remembering-aaron-in-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><em><strong>This year’s <a href="https://www.aaronswartzday.org/invitation/">Aaron Swartz Day and International Hackathon</a> will take place online from 10am-5pm PST on November 14, 2020. </strong></em></p>
<p><strong>It’s free and </strong><span data-key="1936"><em data-slate-leaf="true"><strong data-slate-leaf="true">livestreamed on our </strong></em></span><a href="https://www.youtube.com/channel/UCAX6qlJGN1g1EAXtRoZVN7w" data-key="1937"><span data-key="1938"><em data-slate-leaf="true"><strong data-slate-leaf="true">YouTube</strong></em></span></a><span data-key="1939"><em data-slate-leaf="true"><strong data-slate-leaf="true"> and </strong></em></span><a href="https://www.facebook.com/AaronSwartzDay/" data-key="1940"><span data-key="1941"><em data-slate-leaf="true"><strong data-slate-leaf="true">Facebook</strong></em></span></a><span data-key="1942"><em data-slate-leaf="true"><strong data-slate-leaf="true"> channels. </strong></em></span></p>
<p><em><strong><a href="https://www.eventbrite.com/e/aaron-swartz-day-and-international-hackathon-2020-tickets-128384147441">Register on Eventbrite</a> to have the streaming links emailed to you in the morning on Saturday, November 14. You can also just check our <a href="https://twitter.com/aaronswartzday">@AaronSwartzDay </a>Twitter or look on our home page here at <a href="http://aaronswartzday.org/">aaronswartzday.org</a> on that morning.<br>
</strong></em></p>
<p><a href="https://www.aaronswartzday.org/wp-content/uploads/2014/11/Aaron.png"><img loading="lazy" src="https://www.aaronswartzday.org/wp-content/uploads/2014/11/Aaron.png" alt="" width="566" height="443" srcset="https://www.aaronswartzday.org/wp-content/uploads/2014/11/Aaron.png 566w, https://www.aaronswartzday.org/wp-content/uploads/2014/11/Aaron-300x234.png 300w" sizes="(max-width: 566px) 100vw, 566px"></a></p>
<p>Today would have been Aaron’s 34th birthday, but instead we mourn our friend and wonder what could have been, had he not taken his own life seven years ago after being terrorized by a career-driven prosecutor and U.S. Attorney who decided to just make shit up, make an example out of Aaron, impress their bosses and further their own careers.</p>
<p>As it turns out though, <strong><a href="https://www.aaronswartzday.org/aaron-swartz-was-authorized/">Aaron’s downloading wasn’t even illegal</a></strong>, as he was a Harvard Ethics Fellow at the time and Harvard and MIT had contractual agreements allowing Aaron to access those materials en masse.</p>
<p>But all this didn’t come to light until it was too late.</p>
<p>Aaron was careful not to tell his friends too much about his case for fear he would involve them in the quagmire. In truth, we wouldn’t have minded doing anything we could to help him, but we didn’t realize he needed help, and that his grand jury’s runaway train had gone so far off the rails.</p>
<p>We should have known though, as Grand Juries are <strong><a href="https://www.releasechelsea.com/faq/e/">a dangerous, outdated practice</a></strong> that <strong><a href="https://www.releasechelsea.com/faq/h/">give prosecutors unlimited power</a></strong>, making it easy to manipulate the way that witnesses and evidence are presented to the Grand Jury and convince jurors of almost anything. These kinds of proceedings also often violate <strong><a href="https://www.releasechelsea.com/faq/i/">the subject and witness’ constitutional rights</a></strong> in different ways. For these reasons, most civilized countries have transitioned away from them<strong> <a href="https://www.releasechelsea.com/faq/j/">in favor of preliminary hearings</a></strong>.</p>
<p>We learned many other lessons from his case, after the smoke had cleared. We learned that Aaron’s Grand Jury prosecutor, Assistant U.S. Attorney Stephen Heymann, and the U.S. Attorney in charge of his case, Carmen Ortiz, were so obsessed with trying to make names for themselves, they were&nbsp; willing to fabricate charges and evidence in order get indictments that would otherwise be unachievable.</p>
<p>As Dan Purcell explained:</p>
<blockquote><p>“Steve Heymann did what bureaucrats and functionaries often choose to do. He wanted make a big case to justify his existence and justify his budget. The casualties be damned…</p>
<p>Our bottom line was going to be that Aaron had done only what MIT permitted him to do. He hadn’t gained unauthorized access to anything. He had gained access to JSTOR with full authorization from MIT. Just like anyone in the jury pool, anyone reading Boing Boing, or anyone in the country could have done.</p>
<p>We hoped that the jury would understand that and would acquit Aaron, and it quickly became obvious to us that there really wasn’t going to be opportunity to resolve the case short of trial because Steve Heymann was unreasonable.”</p></blockquote>
<p>We also learned that MIT was more concerned with their own reputation than standing up for the truth or protecting Aaron. In fact, we learned that MIT decided to <em>assist the government with its case</em> <em>against Aaron</em>, rather than helping him by pressuring to Feds to drop the case, even after JSTOR had made it clear it did not wish to prosecute.</p>
<p>We know all this because <strong><a href="https://www.aaronswartzday.org/kevin-poulsen-2014/">Kevin Poulsen explained to us how he had to sue the Department of Homeland Security</a></strong> to get access to documents in <strong><a href="http://swartzfiles.com/">Aaron’s FBI file</a></strong>, and that <strong><a href="https://boingboing.net/2013/07/18/mit-blocking-release-of-aaron.html">MIT blocked their release</a></strong> – intervening as a third party – and demanding to get a chance to further redact them before they were released to Kevin – and the Judge granted their request! Only time will tell what MIT was so worried about, but its behavior suggests that there may have been some kind of cover-up&nbsp; regarding its involvement in Aaron’s case.</p>
<p>Most recently, thanks to Property of the People’s Ryan Shapiro, we learned that <strong><a href="https://www.aaronswartzday.org/jan11rawthought/#Aarondocs">Aaron had an erroneous code in his FBI record</a></strong>&nbsp; that meant “International Terrorism involving Al Qaeda” – deriving from his sending a single email to the University of Pittsburg, which might explain why the FBI was so suspicious of him during his case.</p>
<p>There are still many pieces of the puzzle missing, but we won’t stop trying to put it all together. We hope you will join us on November 14th to honor him and learn about his projects and ideas that are still bearing fruit to this day, such as <strong><a href="https://securedrop.org/">SecureDrop</a></strong>, <strong><a href="https://openlibrary.org/">Open Library</a></strong>, and the <strong><a href="https://www.aaronswartzday.org/psp/">Aaron Swartz Day Police Surveillance Project</a></strong>.</p>
<p>Until then, we will continue to come together to help each other and share information, knowledge and resources, and to try to make things better in our world.</p>
<p>Please email us at aaronswartzday at gmail.com or <strong><a href="https://twitter.com/aaronswartzday">DM us on Twitter</a></strong> if you would like to contribute a project to the hackathon – or want to be on the hackathon or speaker Jitsi calls<strong>. </strong></p>
<p>We hope to see you on November 14th!</p>
<h4><strong><em>&nbsp;<a href="https://www.aaronswartzday.org/howl-for-aaron-swartz/">Howl For Aaron Swartz</a> (by Brewster Kahle)</em></strong></h4>
<h5>Howl for Aaron Swartz</h5>
<p><em>Written by Brewster Kahle, shortly after Aaron’s Death, on January 11, 2013.<br>
</em></p>
<p>Howl for Aaron Swartz<br>
New ways to create culture<br>
Smashed by lawsuits and bullying<br>
Laws that paint most of us criminal</p>
<p>Inspiring young leaders<br>
Sharing everything<br>
Living open source lives<br>
Inspiring communities selflessly</p>
<p>Organizing, preserving<br>
Sharing, promoting<br>
Then crushed by government<br>
Crushed by politicians, for a modest fee<br>
Crushed by corporate spreadsheet outsourced business development</p>
<p>New ways<br>
New communities<br>
Then infiltrated, baited<br>
Set-up, arrested</p>
<p>Celebrating public spaces<br>
Learning, trying, exploring<br>
Targeted by corporate security snipers<br>
Ending up in databases<br>
Ending up in prison</p>
<p>Traps set by those that promised change<br>
Surveillance, wide-eyes, watching everyone now<br>
Government surveillance that cannot be discussed or questioned<br>
Corporate surveillance that is accepted with a click</p>
<p>Terrorists here, Terrorists there<br>
More guns in schools to promote more guns, business<br>
Rendition, torture<br>
Manning, solitary, power</p>
<p>Open minds<br>
Open source<br>
Open eyes<br>
Open society</p>
<p>Public access to the public domain<br>
Now closed out of our devices<br>
Closed out of owning books<br>
Hands off<br>
Do not open<br>
Criminal prosecution</p>
<p>Traps designed by the silicon wizards<br>
With remarkable abilities to self-justify<br>
Traps sprung by a generation<br>
That vowed not to repeat<br>
COINTELPRO and dirty tricks and Democratic National Conventions</p>
<p>Government-produced malware so sophisticated<br>
That career engineers go home each night thinking what?<br>
Saying what to their families and friends?</p>
<p>Debt for school<br>
Debt for houses<br>
Debt for life<br>
Credit scores, treadmills, with chains</p>
<p>Inspiring and optimistic explorers navigating a sea of traps set by us<br>
I see traps ensnare our inspiring generation<br>
Leaders and discoverers finding new ways and getting crushed for it</p>

	</div></div>]]>
            </description>
            <link>https://www.aaronswartzday.org/remembering-aaron-in-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035500</guid>
            <pubDate>Mon, 09 Nov 2020 15:07:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elixir Flavoured Erlang: Erlang to Elixir Transpiler]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035483">thread link</a>) | @marianoguerra
<br/>
November 9, 2020 | http://marianoguerra.org/posts/elixir-flavoured-erlang-an-erlang-to-elixir-transpiler/ | <a href="https://web.archive.org/web/*/http://marianoguerra.org/posts/elixir-flavoured-erlang-an-erlang-to-elixir-transpiler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Last year I was invited to <a href="https://en.elixirconf.la/">ElixirConf Latin America in Colombia</a> to give a talk,
I proposed to also give a tutorial about <a href="https://riak-core-lite.github.io/">Riak Core</a>
and they said that it should be in Elixir, so I started looking into Elixir to
translate my Riak Core material to it.</p><p>This year I was invited to give another talk about languages on the Erlang virtual machine at <a href="https://www.codebeambr.com/">Code BEAM Brasil 2020</a> and I thought it would be a good idea
to continue working on it and maybe announce it at the talk.</p><p>To measure progress I built some scripts that would transpile the Erlang
standard library to Elixir and then try compiling the resulting modules with
the Elixir compiler, I would pick one compiler error, fix it and try again.</p><p>With this short feedback loop and a counter that told me how many modules
compiled successful it was just a matter of finding errors and fixing them.
At the beginning each fix would remove lot of compiler errors and some times
surface new ones, after a while each error was a weird corner case and progress
slowed.</p><p>Some days before the talk I managed to transpile all of Erlang/OTP and 91% of
the Elixir translations compiled successfully.</p><p>The result is of course <a href="https://github.com/marianoguerra/efe">Elixir Flavoured Erlang</a>, but
as a side effect I have Erlang/OTP in Elixir, so I decided to publish it too.</p><p>The objective of this repository is to allow Elixir programmers to read Erlang
code for projects they use, most of the code compiles but I can't ensure that
it behaves identically to the original source.</p><p>While writing the readme of efe I needed some example that wasn't OTP so I
decided to also transpile a widely used project on Erlang and Elixir: the <a href="https://github.com/marianoguerra/otp.ex/tree/main/cowboy/src">Cowboy web server</a></p><div id="the-match-operator-in-elixir">
<h2>The ^ match operator in Elixir</h2>
<p>In Elixir variable bindings by default rebind to the new value, if they are
already bound and you want to pattern match on the current value you have to
add the <em>^</em> operator in front:</p>
<pre><a name="rest_code_fd61af65dfe74189aeb889ef8462540c-1"></a><span>iex</span><span>(</span><span>1</span><span>)</span><span>&gt;</span> <span>a</span> <span>=</span> <span>1</span>
<a name="rest_code_fd61af65dfe74189aeb889ef8462540c-2"></a><span>1</span>
<a name="rest_code_fd61af65dfe74189aeb889ef8462540c-3"></a><span>iex</span><span>(</span><span>2</span><span>)</span><span>&gt;</span> <span>a</span> <span>=</span> <span>2</span>
<a name="rest_code_fd61af65dfe74189aeb889ef8462540c-4"></a><span>2</span>
<a name="rest_code_fd61af65dfe74189aeb889ef8462540c-5"></a><span>iex</span><span>(</span><span>3</span><span>)</span><span>&gt;</span> <span>a</span>
<a name="rest_code_fd61af65dfe74189aeb889ef8462540c-6"></a><span>2</span>
<a name="rest_code_fd61af65dfe74189aeb889ef8462540c-7"></a><span>iex</span><span>(</span><span>4</span><span>)</span><span>&gt;</span> <span>^</span><span>a</span> <span>=</span> <span>3</span>
<a name="rest_code_fd61af65dfe74189aeb889ef8462540c-8"></a><span>**</span> <span>(</span><span>MatchError</span><span>)</span> <span>no</span> <span>match</span> <span>of</span> <span>right</span> <span>hand</span> <span>side</span> <span>value</span><span>:</span> <span>3</span>
</pre>
<p>In Erlang variables are bound once and then always pattern match, the easy
part of the translation is that I know that when a variable is bound and in
match position I have to add the <em>^</em>, the thing is that I can't add the <em>^</em>
on the first binding and I have to know where variables are in match position.</p>
<p>For this I do <a href="https://github.com/marianoguerra/efe/blob/main/src/efe_var_ann.erl">a pass on the Erlang Abstract Syntax Tree and I add annotations
on variables</a> to know if it's already bound and if it's in match possition, the
pretty printer in the second pass checks those annotations to know if it has
to add the <em>^</em> or not.</p>
</div><div id="why-some-modules-don-t-compile">
<h2>Why some modules don't compile?</h2>
<p>Here's a list of reasons why the remaining modules don't compile after being
transpiled.</p>
<div id="for-comprehensions-must-start-with-a-generator">
<h3>For comprehensions must start with a generator</h3>
<p>There's a weird trick in Erlang where you can generate an empty list if a
condition is false or a list with one item if a condition is true by having a
list comprehension that has no generator but has a filter.</p>
<p>I've been told that it's an artifact of how list comprehensions used to be
translated to other code in the past.</p>
<pre><a name="rest_code_2bdc186984394a22b651c88739f592c2-1"></a><span>1</span><span>&gt;</span> <span>[</span><span>ok</span> <span>||</span> <span>true</span><span>].</span>
<a name="rest_code_2bdc186984394a22b651c88739f592c2-2"></a><span>[</span><span>ok</span><span>]</span>
<a name="rest_code_2bdc186984394a22b651c88739f592c2-3"></a>
<a name="rest_code_2bdc186984394a22b651c88739f592c2-4"></a><span>2</span><span>&gt;</span> <span>[</span><span>ok</span> <span>||</span> <span>false</span><span>].</span>
<a name="rest_code_2bdc186984394a22b651c88739f592c2-5"></a><span>[]</span>
</pre>
<p>The fact is that it's valid Erlang and is used in some places in the standard library.</p>
<p>For simple cases in efe I insert a dummy generator:</p>
<pre><a name="rest_code_0369c5665dce49749f10a1cf9ea48854-1"></a><span>for</span> <span>_</span> <span>&lt;-</span> <span>[</span><span>:EFE_DUMMY_GEN</span><span>],</span> <span>true</span> <span>do</span>
<a name="rest_code_0369c5665dce49749f10a1cf9ea48854-2"></a>    <span>:ok</span>
<a name="rest_code_0369c5665dce49749f10a1cf9ea48854-3"></a><span>end</span>
<a name="rest_code_0369c5665dce49749f10a1cf9ea48854-4"></a>
<a name="rest_code_0369c5665dce49749f10a1cf9ea48854-5"></a><span>for</span> <span>_</span> <span>&lt;-</span> <span>[</span><span>:EFE_DUMMY_GEN</span><span>],</span> <span>false</span> <span>do</span>
<a name="rest_code_0369c5665dce49749f10a1cf9ea48854-6"></a>    <span>:ok</span>
<a name="rest_code_0369c5665dce49749f10a1cf9ea48854-7"></a><span>end</span>
</pre>
<p>For more advanced cases with many filters I have to analyze if inserting a
generator at the beginning doesn't change the result, that's why some cases are
left as is.</p>
</div>
<div id="erlang-records-dont-evaluate-default-expressions-elixir-defrecord-do">
<h3>Erlang records don’t evaluate default expressions, Elixir defrecord do</h3>
<p><a href="http://erlang.org/doc/reference_manual/records.html">Erlang records</a> are not
part of the language, they are expanded by the <a href="http://erlang.org/doc/man/epp.html">Erlang Preprocessor</a>.</p>
<p>What the preprocessor does is to insert the default values "as is" on the places
where a record is created, this means that if the default is a function call it
won't be evaluated during definition, there will be a function call for each
instantiation of the record.</p>
<p>Elixir has <a href="https://hexdocs.pm/elixir/master/Record.html">a module to deal with Erlang Records</a> using macros, the thing is that Elixir will evaluate the defaults when they are defined,
this means that if the call doesn't return a constant the behavior won't be the same.
If the call returns a value that can't be represented as a constant in the code it won't compile either.</p>
<p>Another issue is if the function being called is declared after the record is
defined, it will fail with an error saying that the function doesn't exit.</p>
<p>There could be a solution here by creating another module that tries to emulate
the way default values behave in Erlang (they behave as "quoted" expressions)
but I don't know so much about Elixir macros to know how to do it.</p>
</div>
<div id="named-lambda-functions">
<h3>Named lambda functions</h3>
<p>In Erlang <a href="https://erlang.org/doc/reference_manual/expressions.html#fun-expressions">lambda functions can have names to allow recursion</a>, in Elixir this is not supported, there's
no way to automatically change the code in a local/simple way, it's easy to
change the code by hand so I decided to transpile it as if Elixir supported
named lambda functions and get a compiler error.</p>
</div>
<div id="expressions-in-bitstrings">
<h3>Expressions in bitstrings</h3>
<p>In Elixir <a href="https://elixir-lang.org/getting-started/binaries-strings-and-char-lists.html#bitstrings">size in bitstring expects an integer or a variable as argument</a>, Erlang allows any expression there, it's easy to fix by hand by extracting the expression into a variable and putting the variable there, it could be doable but for now I just leave the expression in place and get a compiler error.</p>
</div>
<div id="variable-defined-inside-scope-and-used-outside">
<h3>Variable defined inside scope and used outside</h3>
<p>In Erlang variables introduced within the if, case or receive expressions are implicitly exported from the bodies, this means this works:</p>
<pre><a name="rest_code_6cfc4681f2944f1785c8eee1cdfb7414-1"></a><span>case</span> <span>1</span> <span>of</span> <span>A</span> <span>-&gt;</span> <span>ok</span> <span>end</span><span>,</span> <span>A</span><span>.</span>
<a name="rest_code_6cfc4681f2944f1785c8eee1cdfb7414-2"></a><span>% or this</span>
<a name="rest_code_6cfc4681f2944f1785c8eee1cdfb7414-3"></a><span>case</span> <span>1</span> <span>of</span> <span>1</span> <span>-&gt;</span> <span>B</span> <span>=</span> <span>2</span> <span>end</span><span>,</span> <span>B</span><span>.</span>
</pre>
<p>Elixir has more strict scoping rules and that is not allowed, this is highly discouraged in Erlang but used in some places in the standard library.</p>
</div>
</div><div id="corner-cases-all-the-way-down">
<h2>Corner cases all the way down</h2>
<p>Here's a list of small differences that I had to fix.</p>
<div id="erlang-vs-elixir-imports">
<h3>Erlang vs Elixir imports</h3>
<p>In Erlang you can import functions from a module in multiple imports and they "add up".</p>
<p>In Elixir later imports for the same module "shadow" previous ones.</p>
<p>The solution is to group imports for the same module and emit only one import
per module.</p>
<p>In Erlang you can import a function more than once, in Elixir it's a compiler
error, the solution is to deduplicate function imports.</p>
</div>

<div id="lowercase-variables-that-become-keywords">
<h3>Lowercase variables that become keywords</h3>
<p>Erlang variables start with uppercase, Elixir variables with lowercase, this
means in Erlang variable names can't clash with language keywords but the lowercase
versions can, that's why I have to <a href="https://github.com/marianoguerra/efe/blob/main/src/efe_pp.erl#L1738">check if the variable is a keyword</a> and add a suffix to them.</p>
</div>
<div id="local-calls-and-kernel-autoimports">
<h3>Local calls and Kernel autoimports</h3>
<p>Elixir auto import functions from the <a href="https://hexdocs.pm/elixir/Kernel.html">Kernel</a> module
that may clash with local functions in the current Erlang module, for this case I have to <a href="https://github.com/marianoguerra/efe/blob/21ac93fb9eecfb8b164787d0e9935dae6ba7119e/src/efe_pp.erl#L1838">detect Kernel functions and macros</a> that are also local functions and add an expression to avoid auto importing them, like this:</p>
<pre><a name="rest_code_004b69f2fa9941fe83cdf5cee61ad893-1"></a><span>import</span> <span>Kernel</span><span>,</span> <span>except</span><span>:</span> <span>[</span><span>to_string</span><span>:</span> <span>1</span><span>,</span> <span>send</span><span>:</span> <span>2</span><span>]</span>
</pre>
</div>
<div id="private-on-load-function">
<h3>Private on_load function</h3>
<p>Erlang allows to define a private function to be run when the module loads,
Elixir only allowed public functions, this has been reported and fixed in
Elixir but not yet released.</p>
</div>
<div id="function-capture-calls-with-dynamic-values">
<h3>Function capture/calls with dynamic values</h3>
<p>In Erlang the syntax to pass a reference to a function is uniform for constants
and variables:</p>
<pre><a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-1"></a><span>fun</span> <span>calls</span><span>/</span><span>3</span>
<a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-2"></a><span>fun</span> <span>cornercases</span><span>:</span><span>calls</span><span>/</span><span>3</span>
<a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-3"></a><span>fun</span> <span>M</span><span>:</span><span>F</span><span>/</span><span>Arity</span>
<a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-4"></a><span>fun</span> <span>M</span><span>:</span><span>calls</span><span>/</span><span>3</span>
<a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-5"></a><span>fun</span> <span>M</span><span>:</span><span>F</span><span>/</span><span>3</span>
<a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-6"></a><span>fun</span> <span>cornercases</span><span>:</span><span>F</span><span>/</span><span>Arity</span>
<a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-7"></a><span>fun</span> <span>cornercases</span><span>:</span><span>calls</span><span>/</span><span>Arity</span>
<a name="rest_code_9c91d656991a4f0a99b43d0cbba79657-8"></a><span>fun</span> <span>M</span><span>:</span><span>calls</span><span>/</span><span>Arity</span><span>}</span>
</pre>
<p>In Elixir I had to special case when any part is a variable.</p>
<pre><a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-1"></a><span>&amp;</span><span>calls</span><span>/</span><span>3</span>
<a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-2"></a><span>&amp;</span><span>:cornercases</span><span>.</span><span>calls</span><span>/</span><span>3</span>
<a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-3"></a><span>Function</span><span>.</span><span>capture</span><span>(</span><span>m</span><span>,</span> <span>f</span><span>,</span> <span>arity</span><span>)</span>
<a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-4"></a><span>Function</span><span>.</span><span>capture</span><span>(</span><span>m</span><span>,</span> <span>:calls</span><span>,</span> <span>3</span><span>)</span>
<a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-5"></a><span>Function</span><span>.</span><span>capture</span><span>(</span><span>m</span><span>,</span> <span>f</span><span>,</span> <span>3</span><span>)</span>
<a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-6"></a><span>Function</span><span>.</span><span>capture</span><span>(</span><span>:cornercases</span><span>,</span> <span>f</span><span>,</span> <span>arity</span><span>)</span>
<a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-7"></a><span>Function</span><span>.</span><span>capture</span><span>(</span><span>:cornercases</span><span>,</span> <span>:calls</span><span>,</span> <span>arity</span><span>)</span>
<a name="rest_code_8a20e56ef08c4fb8b32a4bfaca4a1070-8"></a><span>Function</span><span>.</span><span>capture</span><span>(</span><span>m</span><span>,</span> <span>:calls</span><span>,</span> <span>arity</span><span>)</span>
</pre>
<p>Something similar happens with function calls:</p>
<pre><a name="rest_code_9183c2e1ec3c4a6ca42e5c6e94251da2-1"></a><span>M</span> <span>=</span> <span>erlang</span>
<a name="rest_code_9183c2e1ec3c4a6ca42e5c6e94251da2-2"></a><span>F</span> <span>=</span> <span>max</span>
<a name="rest_code_9183c2e1ec3c4a6ca42e5c6e94251da2-3"></a><span>M</span><span>:</span><span>max</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<a name="rest_code_9183c2e1ec3c4a6ca42e5c6e94251da2-4"></a><span>M</span><span>:</span><span>F</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<a name="rest_code_9183c2e1ec3c4a6ca42e5c6e94251da2-5"></a><span>erlang</span><span>:</span><span>F</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<a name="rest_code_9183c2e1ec3c4a6ca42e5c6e94251da2-6"></a><span>erlang</span><span>:</span><span>max</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<a name="rest_code_9183c2e1ec3c4a6ca42e5c6e94251da2-7"></a><span>max</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
</pre>
<p>vs</p>
<pre><a name="rest_code_40785744968a44b196ab0dffde38b6c8-1"></a><span>m</span> <span>=</span> <span>:erlang</span>
<a name="rest_code_40785744968a44b196ab0dffde38b6c8-2"></a><span>f</span> <span>=</span> <span>:max</span>
<a name="rest_code_40785744968a44b196ab0dffde38b6c8-3"></a><span>m</span><span>.</span><span>max</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<a name="rest_code_40785744968a44b196ab0dffde38b6c8-4"></a><span>apply</span><span>(</span><span>m</span><span>,</span> <span>f</span><span>,</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>])</span>
<a name="rest_code_40785744968a44b196ab0dffde38b6c8-5"></a><span>apply</span><span>(</span><span>:erlang</span><span>,</span> <span>f</span><span>,</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>])</span>
<a name="rest_code_40785744968a44b196ab0dffde38b6c8-6"></a><span>:erlang</span><span>.</span><span>max</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<a name="rest_code_40785744968a44b196ab0dffde38b6c8-7"></a><span>max</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
</pre>
</div>
<div id="binary-operators">
<h3>Binary operators</h3>
<p>In Erlang <a href="http://erlang.org/doc/reference_manual/expressions.html#arithmetic-expressions">binary operators</a> are builtin.</p>
<p>In Elixir they are macros from the <a href="https://hexdocs.pm/elixir/Bitwise.html">Bitwise</a> module.</p>
<p>The fix was easy, just use the module.</p>
</div>
<div id="call-expressions">
<h3>Call Expressions</h3>
<p>In Erlang there's no extra syntax to call a function that is the result of an
expression:</p>
<pre><a name="rest_code_6b808e85e84a4da6aa619e274c1eb8ba-1"></a><span>fun</span> <span>()</span> <span>-&gt;</span> <span>ok</span> <span>end</span><span>().</span>
<a name="rest_code_6b808e85e84a4da6aa619e274c1eb8ba-2"></a><span>% or</span>
<a name="rest_code_6b808e85e84a4da6aa619e274c1eb8ba-3"></a><span>(</span><span>return_fn</span><span>())().</span>
</pre>
<p>In Elixir it has to be wrapped in parenthesis and a dot added before the call:</p>
<pre><a name="rest_code_a7611ce6437f4112b8095f769d3914e5-1"></a><span>(</span><span>fn</span> <span>()</span> <span>-&gt;</span> <span>:ok</span> <span>end</span><span>)</span><span>.</span><span>()</span>
<a name="rest_code_a7611ce6437f4112b8095f769d3914e5-2"></a><span># or</span>
<a name="rest_code_a7611ce6437f4112b8095f769d3914e5-3"></a><span>(</span><span>return_fn</span><span>())</span><span>.</span><span>()</span>
</pre>
</div>
<div id="weird-function-names">
<h3>Weird function names</h3>
<p>In Erlang to declare or call function names whose names are not valid identifiers
the name has to be in single quotes:</p>
<pre><a name="rest_code_e525dfbd2faa468dab783017a1e1faf2-1"></a><span>'substring-after'</span><span>()</span> <span>-&gt;</span>
<a name="rest_code_e525dfbd2faa468dab783017a1e1faf2-2"></a>    <span>wxMenu</span><span>:</span><span>'Destroy'</span><span>(</span><span>A</span><span>,</span> <span>B</span><span>).</span>
</pre>
<p>In Elixir the declaration is different from the call.</p>
<pre><a name="rest_code_511d8c2441144a3f847e5f7b9b36594f-1"></a><span>def</span> <span>unquote</span><span>(</span><span>:"substring-after"</span><span>)()</span> <span>do</span>
<a name="rest_code_511d8c2441144a3f847e5f7b9b36594f-2"></a>    <span>:wxMenu</span><span>.</span><span>'Destroy'</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span>
<a name="rest_code_511d8c2441144a3f847e5f7b9b36594f-3"></a><span>end</span>
</pre>
<p>When the function is a keyword in Elixir the declaration is the same but a
local call must be prefixed with the module to be valid syntax:</p>
<pre><a name="rest_code_5db18959ea2c451fbc16653aa3c92d9d-1"></a><span>keyword_methods</span><span>()</span> <span>-&gt;</span>
<a name="rest_code_5db18959ea2c451fbc16653aa3c92d9d-2"></a>    <span>{</span><span>nil</span><span>(),</span> <span>in</span><span>()}.</span>
<a name="rest_code_5db18959ea2c451fbc16653aa3c92d9d-3"></a>
<a name="rest_code_5db18959ea2c451fbc16653aa3c92d9d-4"></a><span>nil</span><span>()</span> <span>-&gt;</span> <span>nil</span><span>.</span>
<a name="rest_code_5db18959ea2c451fbc16653aa3c92d9d-5"></a><span>in</span><span>()</span> <span>-&gt;</span> <span>in</span><span>.</span>
</pre>
<p>vs</p>
<pre><a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-1"></a><span>def</span> <span>keyword_methods</span><span>()</span> <span>do</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-2"></a>    <span>{</span><span>__MODULE__</span><span>.</span><span>nil</span><span>(),</span> <span>__MODULE__</span><span>.</span><span>in</span><span>()}</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-3"></a><span>end</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-4"></a>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-5"></a><span>def</span> <span>unquote</span><span>(</span><span>:nil</span><span>)()</span> <span>do</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-6"></a>    <span>nil</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-7"></a><span>end</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-8"></a>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-9"></a><span>def</span> <span>unquote</span><span>(</span><span>:in</span><span>)()</span> <span>do</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-10"></a>    <span>:in</span>
<a name="rest_code_2b8527328040454ea27b6cc1c8ac541c-11"></a><span>end</span>
</pre>
</div>
<div id="erlang-non-short-circuit-boolean-operators">
<h3>Erlang non short circuit boolean operators</h3>
<p>For historical reasons Erlang's boolean operators <em>and</em> and <em>or</em> do not short
circuit, this means they evaluate both sides before evaluating itself, for short
circuit versions the newer and recommended <em>andalso</em> and <em>orelse</em> operators
exist. Still the old versions are used in some places.</p>
<p>Elixir only has short circuit versions, to solve this I replace calls to those
operators to the functions in the Erlang module that do the same, since I need
to force the evaluation of both sides and function calls evaluate the arguments
before calling it does what I need.</p>
<pre><a name="rest_code_afb80f254e8f4854ba75cc53416f3fb5-1"></a><span>o_and</span><span>(</span><span>A</span><span>,</span> <span>B</span><span>)</span> <span>-&gt;</span> <span>A</span> <span>and</span> <span>B</span><span>.</span>
<a name="rest_code_afb80f254e8f4854ba75cc53416f3fb5-2"></a><span>o_or</span><span>(</span><span>A</span><span>,</span> <span>B</span><span>)</span>  <span>-&gt;</span> <span>A</span> <span>or</span> <span>B</span><span>.</span>
<a name="rest_code_afb80f254e8f4854ba75cc53416f3fb5-3"></a><span>o_xor</span><span>(</span><span>A</span><span>,</span> <span>B</span><span>)</span> <span>-&gt;</span> <span>A</span> <span>xor</span> <span>B</span><span>.</span>
</pre>
<p>vs</p>
<pre><a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-1"></a><span>def</span> <span>o_and</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>do</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-2"></a>  <span>:erlang</span><span>.</span><span>and</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-3"></a><span>end</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-4"></a>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-5"></a><span>def</span> <span>o_or</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>do</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-6"></a>  <span>:erlang</span><span>.</span><span>or</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-7"></a><span>end</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-8"></a>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-9"></a><span>def</span> <span>o_xor</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>do</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-10"></a>  <span>:erlang</span><span>.</span><span>xor</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span>
<a name="rest_code_c615e15c0ee24d6ea1a26a0cdf7c4f43-11"></a><span>end</span>
</pre>
<p>The problem is in guards, where only a subset of functions can be used, in
Erlang since <em>and</em> and <em>or</em> are operators they are allowed, but in Elixir the
function calls are not, only in this case I replace the non short circuit
version for the short circuit ones since …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://marianoguerra.org/posts/elixir-flavoured-erlang-an-erlang-to-elixir-transpiler/">http://marianoguerra.org/posts/elixir-flavoured-erlang-an-erlang-to-elixir-transpiler/</a></em></p>]]>
            </description>
            <link>http://marianoguerra.org/posts/elixir-flavoured-erlang-an-erlang-to-elixir-transpiler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035483</guid>
            <pubDate>Mon, 09 Nov 2020 15:05:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is there so much surprise around Trump's approach to losing the US Election]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035356">thread link</a>) | @twords
<br/>
November 9, 2020 | https://twords.com/view-article/thgwigmore-Why-is-there-so-much-surprise-around-Trump-s-approach-to-losing-the-US-Election-2020- | <a href="https://web.archive.org/web/*/https://twords.com/view-article/thgwigmore-Why-is-there-so-much-surprise-around-Trump-s-approach-to-losing-the-US-Election-2020-">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="root"><div><div><div><div><div><header><div><p><a tag="[object Object]" href="https://twords.com/"><img src="https://twords.com/static/media/inverse_cropped.0601fa81.svg"></a></p><div><div><div></div></div></div><div><p><a tag="[object Object]" href="https://twords.com/authentication/login">Login</a></p></div></div></header></div><div class="page"><div><div><p><a href="https://twords.com/#" data-rb-event-key="/" role="button"></a><a href="https://twords.com/">Home</a></p></div><div><p><a href="https://twords.com/#" data-rb-event-key="/trending" role="button"></a><a href="https://twords.com/trending">Trending</a></p></div><div><p><a href="https://twords.com/#" data-rb-event-key="/my-feed" role="button"></a><a href="https://twords.com/my-feed">My Feed</a></p></div></div><div><nav><a href="https://twords.com/"></a></nav></div><div><div><a href="https://twords.com/view-article/null"><div><p>Continue reading...</p></div></a></div><div></div></div><div><div><p><h3>Latest Articles</h3></p><div><div><p><span>Loading..</span></p></div><p><span>Loading...</span></p></div></div></div></div><div><nav><div><p><a tag="[object Object]" href="https://twords.com/about-us">About Us</a></p></div><div><p><a tag="[object Object]" href="https://twords.com/contact-us">Contact Us</a></p></div><div><p><a tag="[object Object]" href="https://twords.com/faq">FAQ</a></p></div><div><div><p><a href="https://twitter.com/official_twords">Twitter</a></p></div></div></nav></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://twords.com/view-article/thgwigmore-Why-is-there-so-much-surprise-around-Trump-s-approach-to-losing-the-US-Election-2020-</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035356</guid>
            <pubDate>Mon, 09 Nov 2020 14:52:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vulnerabilities Discovered in Tcl Android TVs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035350">thread link</a>) | @moviuro
<br/>
November 9, 2020 | https://sick.codes/extraordinary-vulnerabilities-discovered-in-tcl-android-tvs-now-worlds-3rd-largest-tv-manufacturer/ | <a href="https://web.archive.org/web/*/https://sick.codes/extraordinary-vulnerabilities-discovered-in-tcl-android-tvs-now-worlds-3rd-largest-tv-manufacturer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                
<p>The following piece is the culmination of a three-month long investigation into Smart TVs running Android. Having lived through this research experience, I can wholeheartedly say that there were multiple moments that I, and another security researcher that I met along the way, couldn’t believe what was happening. On multiple occasions I found myself feeling as though, “you couldn’t even make this up…”</p>



<p>I’m a security researcher, a freelance developer, and a hacker.</p>



<p>Please follow me on Twitter <a href="https://twitter.com/sickcodes" target="_blank" rel="noreferrer noopener">@sickcodes</a> here: <a href="https://twitter.com/sickcodes" target="_blank" rel="noreferrer noopener">https://twitter.com/sickcodes</a></p>



<p>The second researcher in this story is John Jackson: <a href="https://twitter.com/johnjhacking" target="_blank" rel="noreferrer noopener">https://twitter.com/johnjhacking</a>, an Application Security Engineer with Shutterstock, and a hacker.</p>



<p>We met about half way through this, and I have included his experience too.</p>



<h2>Initial Research</h2>



<p>Near the end of September, while conducting research into low-end Android boxes, I came across a number of serious flaws in the way in which these devices were being designed.</p>



<p>Without delving into the nuances of each device, all of the Smart TV products are Android based.</p>



<p>There are four types of TV products in the TV market:</p>



<ol><li>TV Sticks</li><li>TV Boxes</li><li>Smart TVs</li><li>Android TVs</li></ol>



<p>All of them are ARM based single board computers (SBCs). Most of the dies are 32bit, some are 64bit, but all of them are like a little Raspberry Pi competitor, focusing on GPU performance through the small, but powerful, Mali GPUs.</p>



<p>Some of the products that I investigated were “factory-flawed” and deliberately insecure.</p>



<h2>First Blood</h2>



<p>On 2020-09-20, I discovered some ridiculous security shortfalls in the TV Sticks.</p>



<p><em>NOTE: TCL does not make TV sticks that are vulnerable. Only TCL Android TVs are affected. The following vulnerabilities refer to other products that I was testing at the time before finding the TCL vulnerability that is discussed in depth after the nmap scaps below.</em></p>



<p>Each stick that I tested had at least one of the following major security flaws.</p>



<ul><li>Port 22 open and allowing SSH access as root:root out of the box</li><li>Port 5555 open and allowing unauthenticated android (adb) as root:root out of the box</li><li>Rooted device, with world-executable su binaries in multiple locations</li><li>Open WiFi network with adb and ssh daemons running</li></ul>



<p>In effect, if you had a thousand of these devices, you could worm through all of them, taking advantage of the dual WiFi, plain-text WAN router credentials, and the ability to then hop from the TV stick, to the router, MITM the router, search for more vulnerable devices from the larger, more powerful router, and truly “surf the internet”.</p>



<p><strong>Proof of Concept</strong></p>



<pre># connect to the device's open WiFi network without any password
adb connect 192.168.1.1
adb shell
su
whoami
# root</pre>



<p>Having witnessed how dismal the security was on these devices, or lack thereof, my plan was to write a really big proof of concept, in the form of an actual shell based worm, that would hop between the 4 or 5 TV sticks that I had.</p>



<p>Speaking to an associate about my idea, we ended up chatting about real Android TVs.</p>



<p>Suddenly, I thought, “If these sticks are the same, just little Rockchip &amp; Amlogic CPUs, then what is so special about Smart TVs?”</p>



<p>Since I don’t actually have an Android Television to test, I asked my friend what type of Smart TV does he have and is it running Android?</p>



<p>His answer was, “TCL and not sure.”</p>



<p>I hadn’t really heard much about TCL, but it turns out TCL is a huge Chinese electronics manufacturing company.</p>



<p>TCL has been growing their global market share, at a remarkable rate.</p>



<p>According to a Forbes article, they only launched in the United States in 2013 and sales began on Amazon: <a href="https://www.forbes.com/sites/sethporges/2016/11/14/how-a-no-name-chinese-tv-brand-came-to-dominate-the-amazon-charts/?sh=15fd0d52f096" target="_blank" rel="noreferrer noopener">https://www.forbes.com/sites/sethporges/2016/11/14/how-a-no-name-chinese-tv-brand-came-to-dominate-the-amazon-charts/?sh=15fd0d52f096</a></p>



<div><figure><img loading="lazy" width="928" height="545" src="https://sick.codes/wp-content/uploads/2020/11/tv-market-share-2008-2020.png" alt="TV market share 2008 2020" srcset="https://sick.codes/wp-content/uploads/2020/11/tv-market-share-2008-2020.png 928w, https://sick.codes/wp-content/uploads/2020/11/tv-market-share-2008-2020-300x176.png 300w, https://sick.codes/wp-content/uploads/2020/11/tv-market-share-2008-2020-768x451.png 768w, https://sick.codes/wp-content/uploads/2020/11/tv-market-share-2008-2020-750x440.png 750w" sizes="(max-width: 928px) 100vw, 928px"><figcaption>TV market share 2008 to 2020</figcaption></figure></div>



<p>With their Amazon success, TCL began targeting other large markets.</p>



<p>The key point here is that they aren’t Samsung or LG, but they ARE selling millions of TV sets…</p>



<p>We did a remote desktop session and I ran a trivial nmap scan on the TV to see what it was running out of the box.</p>



<p>Here is the nmap scan:</p>



<pre>Starting Nmap 7.91 ( https://nmap.org ) at 2020-10-16 21:55 UTC
…
Scanning 10.0.0.117 [65535 ports]
Discovered open port 6550/tcp on 10.0.0.117
Discovered open port 8012/tcp on 10.0.0.117
Discovered open port 6466/tcp on 10.0.0.117
Discovered open port 8009/tcp on 10.0.0.117
Discovered open port 9000/tcp on 10.0.0.117
Discovered open port 8443/tcp on 10.0.0.117
Discovered open port 10101/tcp on 10.0.0.117
Discovered open port 46211/tcp on 10.0.0.117
Discovered open port 7989/tcp on 10.0.0.117
Discovered open port 6467/tcp on 10.0.0.117
Discovered open port 6559/tcp on 10.0.0.117
Discovered open port 6553/tcp on 10.0.0.117
Discovered open port 4332/tcp on 10.0.0.117
Discovered open port 8008/tcp on 10.0.0.117
Completed SYN Stealth Scan at 21:56, 20.40s elapsed (65535 total ports)
Initiating Service scan at 21:56
Scanning 14 services on 10.0.0.117
…
Completed Service scan at 21:58, 156.41s elapsed (14 services on 1 host)
Not shown: 65521 closed ports</pre>



<p>If you nmap your Android mobile phone, you will generally find 0 open TCP ports.</p>



<p><strong>Zero.</strong></p>



<p>So why does a TV need so many open ports?</p>



<p>While there are some reasons why TVs should have open ports, some of the above services warranted much deeper investigation.</p>



<p>Since I was in a remote desktop session, I just entered all the URLs manually into his web browser.</p>



<pre>http://10.0.0.117:6550
http://10.0.0.117:8012
http://10.0.0.117:6466
http://10.0.0.117:8009
http://10.0.0.117:9000
http://10.0.0.117:8443
http://10.0.0.117:10101
http://10.0.0.117:46211
http://10.0.0.117:7989
http://10.0.0.117:6467
http://10.0.0.117:6559
http://10.0.0.117:6553
http://10.0.0.117:4332
http://10.0.0.117:8008</pre>



<p>I also tested the https:// editions:</p>



<pre>https://10.0.0.117:6550
https://10.0.0.117:8012
https://10.0.0.117:6466
https://10.0.0.117:8009
https://10.0.0.117:9000
https://10.0.0.117:8443
https://10.0.0.117:10101
https://10.0.0.117:46211
https://10.0.0.117:7989
https://10.0.0.117:6467
https://10.0.0.117:6559
https://10.0.0.117:6553
https://10.0.0.117:4332
https://10.0.0.117:8008</pre>



<p>Some of the pages were blank white pages. This can indicate an API endpoint.</p>



<p>Some of the pages just hang the browser.</p>



<p>Then the rest of the nmap scan came through…</p>



<pre>PORT STATE SERVICE VERSION
4332/tcp open getty-focus?
6466/tcp open ssl/unknown
| ssl-cert: Subject: commonName=atvremote/BeyondTV2/BeyondTV/BeyondTV2/unknown
| Subject Alternative Name: email:<a href="https://sick.codes/cdn-cgi/l/email-protection" data-cfemail="5b3a353f2934323f762f2d76293e36342f3e76282e2b2b34292f1b3c34343c373e75383436">[email&nbsp;protected]</a>
| Issuer: commonName=atvremote/BeyondTV2/BeyondTV/BeyondTV2/unknown
| Public Key type: rsa
| Public Key bits: 2048
| Signature Algorithm: sha256WithRSAEncryption
…
6467/tcp open tcpwrapped
6550/tcp open fg-sysupdate?
| fingerprint-strings:
| NULL:
|_ Version 4
6553/tcp open unknown
6559/tcp open unknown
| fingerprint-strings:
| GenericLines:
…
7989/tcp open unknown
| fingerprint-strings:
| FourOhFourRequest:
| HTTP/1.1 404 Not Found
| Content-Type: text/plain
| Date: Fri, 16 Oct 2020 10:57:17 GMT
| Accept-Ranges: bytes
| Connection: keep-alive
| Content-Length: 26
| Error 404, file not found.
| GenericLines:
| HTTP/1.1 400 Bad Request
| Content-Type: text/plain
| Date: Fri, 16 Oct 2020 10:56:27 GMT
| Connection: keep-alive
| Content-Length: 56
| REQUEST: Syntax error. Usage: GET /example/file.html
| SIPOptions:
| HTTP/1.1 404 Not Found
| Content-Type: text/plain
| Date: Fri, 16 Oct 2020 10:57:37 GMT
| Accept-Ranges: bytes
| Connection: keep-alive
| Content-Length: 26
|_ Error 404, file not found.
8008/tcp open http?
|_http-title: Site doesn\'t have a title (text/html).
8009/tcp open ssl/castv2 Ninja Sphere Chromecast driver
|_ajp-methods: Failed to get a valid response for the OPTION request
8012/tcp open unknown
8443/tcp open ssl/https-alt\?
|_http-title: Site doesn\'t have a title (text/html).
| ssl-cert: Subject: commonName=/organizationName=Google Inc/stateOrProvinceName=Washington/countryName=US
| Issuer: commonName=TCL TV BeyondTV Realtek RTD2851 Cast ICA/organizationName=Google Inc/stateOrProvinceName=Washington/countryName=US
9000/tcp open ssl/cslistener?
10101/tcp open ssl/ezmeeting-2?
46211/tcp open tcpwrapped</pre>



<p>Port 7989 was showing a 404 error, yet when I visit 10.0.0.117:7989 in the browser, an error is shown.</p>



<p>http://10.0.0.117:7989 did not return a page in the browser.</p>



<div><figure><img loading="lazy" width="1007" height="664" src="https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure.png" alt="TCL directory file structure" srcset="https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure.png 1007w, https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-300x198.png 300w, https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-768x506.png 768w, https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-750x495.png 750w" sizes="(max-width: 1007px) 100vw, 1007px"><figcaption>TCL directory file structure</figcaption></figure></div>



<p>What kind of special web server doesn’t show an index page, but shows deeper pages?</p>



<p>I had recently done research on an IoT device that was serving CGI scripts from the / directory, so the first page I thought to test was init.rc</p>



<p><em>http://10.0.0.117:7989/init.rc</em></p>



<p>403 Forbidden.</p>



<p>Yikes.</p>



<p>This means that the file is exists but we are not authorized to view it.</p>



<p>Naturally, I tested some other Android directories:</p>



<p><em>http://10.0.0.117:7989/sdcard</em></p>



<figure><img loading="lazy" width="916" height="691" src="https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-vulnerability.png" alt="TCL directory file structure vulnerability" srcset="https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-vulnerability.png 916w, https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-vulnerability-300x226.png 300w, https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-vulnerability-768x579.png 768w, https://sick.codes/wp-content/uploads/2020/11/tcl-directory-file-structure-vulnerability-750x566.png 750w" sizes="(max-width: 916px) 100vw, 916px"><figcaption>TCL directory file structure vulnerability</figcaption></figure>



<p>If you work with computers, no matter whether it be mobile apps, web apps, websites, back-end, front-end, upend…</p>



<p>Ask yourself this question right now:</p>



<figure><blockquote><p><em>When in the history of your career…</em><br><em>Have you ever needed to serve the entire filesystem…</em><br><em>over http?</em></p></blockquote></figure>



<p>This becomes a really import question because this custom vendor firmware is currently installed in millions of TCL Android TVs around the world.</p>



<p>My friend who was actually on the phone to me while we were doing the remote desktop, was fairly surprised.</p>



<p>“Why can we see all the files in the TV?”</p>



<p>Port 7989 is not on the list of standard TCP/UDP ports by the Internet Assigned Numbers Authority (IANA), https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.txt</p>



<p>This means, without scanning all 65,535 ports, most scanners will skip that port.</p>



<p>Secondly, the actual root page is blank.</p>



<p>So in order to scan more than 1 page per port, port scan times will exponentially increase…</p>



<p>Curiously, I checked the IANA list for other …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sick.codes/extraordinary-vulnerabilities-discovered-in-tcl-android-tvs-now-worlds-3rd-largest-tv-manufacturer/">https://sick.codes/extraordinary-vulnerabilities-discovered-in-tcl-android-tvs-now-worlds-3rd-largest-tv-manufacturer/</a></em></p>]]>
            </description>
            <link>https://sick.codes/extraordinary-vulnerabilities-discovered-in-tcl-android-tvs-now-worlds-3rd-largest-tv-manufacturer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035350</guid>
            <pubDate>Mon, 09 Nov 2020 14:52:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A US Visa in 937 Days]]>
            </title>
            <description>
<![CDATA[
Score 296 | Comments 144 (<a href="https://news.ycombinator.com/item?id=25035307">thread link</a>) | @caution
<br/>
November 9, 2020 | https://daniel.haxx.se/blog/2020/11/09/a-us-visa-in-937-days/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/09/a-us-visa-in-937-days/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Here’s the complete timeline of events. From my first denial to travel to the US until I eventually received a tourist visa. And then I can’t go anyway.</p>



<h2>December 5-11, 2016</h2>



<p>I spent a week on Hawaii with Mozilla – my employer at the time. This was my 12th visit to the US over a period of 19 years. I went there on ESTA, the visa waiver program Swedish citizens can use. I’ve used it many times, there was nothing special this time. The typical procedure with ESTA is that we apply online: fill in a form, pay a 14 USD fee and get a confirmation within a few days that we’re good to go.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/hawaii-2016.jpg"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/hawaii-2016.jpg" alt="" width="558" height="414"></a><figcaption>I took this photo at the hotel we stayed at during the Mozilla all-hands on Hawaii 2016.</figcaption></figure>



<h2>June 26, 2017</h2>



<p>In the early morning one day by the check-in counter at Arlanda airport in Sweden, I was refused to board my flight. Completely unexpected and out of the blue! I thought I was going to San Francisco via London with British Airways, but instead I had to turn around and go back home – slightly shocked. According to the lady behind the counter there was “something wrong with my ESTA”. I used the same ESTA and passport as I used just fine back in December 2016. They’re made to last two years and it had not expired.</p>



<figure><a href="https://twitter.com/bagder/status/879198063998513152"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-06-Twitter-Publish.png" alt="" width="553" height="199"></a><figcaption>Tweeted by me, minutes after being stopped at Arlanda.</figcaption></figure>



<p>People engaged by Mozilla to help us out could not figure out or get answers about what the problem was (questions and investigations were attempted both in the US and in Sweden), so we put our hopes on that it was a human mistake somewhere and decided to just try again next time.</p>



<h2>April 3, 2018</h2>



<p>I missed the following meeting (in December 2017) for other reasons but in the summer of 2018 another Mozilla all-hands meeting was coming up (in Texas, USA this time) so I went ahead and applied for a new ESTA in good time before the event – as I was a bit afraid there was going to be problems. I was right and I got denied ESTA very quickly. “Travel Not Authorized”.</p>



<figure><img loading="lazy" src="https://daniel.haxx.se/media/ESTA-travel-not-authorized.png" alt="" width="642" height="458"><figcaption>Rejected from the ESTA program.</figcaption></figure>



<h2>Day 0 – April 17, 2018</h2>



<p><strong>Gaaah</strong>. It meant it was no mistake last year, they actually mean this. I switched approach and instead applied for a tourist visa. I paid 160 USD, filled in a ridiculous amount of information about me and my past travels over the last 15 years and I visited the US embassy for an in-person interview and fingerprinting.</p>



<figure><img loading="lazy" src="https://daniel.haxx.se/media/Administrative-Processing.png" alt="" width="577" height="289"></figure>



<p>This is day 0 in the <a href="https://daniel.haxx.se/blog/2018/07/28/administrative-purgatory/" data-type="post" data-id="11076">visa process</a>, 296 days after I was first stopped at Arlanda.</p>



<h2>Day 90 – July 2018</h2>



<p>I missed the all-hands meeting in San Francisco when I didn’t get the visa in time.</p>



<h2>Day 240 – December 2018</h2>



<p>I <a href="https://daniel.haxx.se/blog/2018/11/18/im-leaving-mozilla/">quit Mozilla</a>, so I then had no more reasons to go to their company all-hands…</p>



<h2>Day 365 – April 2019</h2>



<p><a href="https://daniel.haxx.se/blog/2019/04/17/one-year-in-still-no-visa/" data-type="post" data-id="12216">A year passed</a>. “someone is working on it” the embassy email person claimed when I asked about progress.</p>



<h2>Day 651- January 28, 2020</h2>



<p>I emailed the embassy to query about the process</p>



<figure><img loading="lazy" src="https://daniel.haxx.se/media/651-days-email.png" alt="" width="611" height="166"><figcaption>Screenshotted email</figcaption></figure>



<p>The reply came back quickly:</p>



<blockquote><p>Dear Sir, </p><p>All applications are processed in the most expeditious manner possible. While we understand your frustration, we are required to follow immigration law regarding visa issuances. This process cannot be expedited or circumvented. Rest assured that we will contact you as soon as the administrative processing is concluded.</p></blockquote>



<h2>Day 730 – April 2020</h2>



<p><a href="https://daniel.haxx.se/blog/2020/04/17/two-years-in/" data-type="post" data-id="13456">Another year had passed</a> and I had given up all hope. Now it turned into a betting game and science project. How long can they actually drag out this process without saying either yes or no?</p>



<h2>Day 871 – September 3, 2020</h2>



<p>A friend of mine, a US citizen, contacted his Congressman – <a href="https://en.wikipedia.org/wiki/Gerry_Connolly">Gerry Connolly</a> – about my situation and asked for help. His office then subsequently sent a question to the US embassy in Stockholm asking about my case. While the response that arrived on September 17 was rather negative…</p>



<pre>your case is currently undergoing necessary administrative processing and regrettably it is not possible to predict when this processing will be completed.</pre>



<p>… I think the following turn of events indicates it had an effect. It unclogged something.</p>



<h2>Day 889 – September 22, 2020</h2>



<p>After 889 days since my interview on the embassy (only five days after the answer to the congressman), the embassy contacted me over email. <em> For the first time since that April day in 2018.</em></p>



<pre>Your visa application is still in administrative processing. However, we regret to inform you that because you have missed your travel plans, we will require updated travel plans from you.</pre>



<p>My travel plans – that had been out of date for the last 800 days or so – suddenly needed to be updated! As I was already so long into this process and since I feared that giving up now would force me back to square one if I would stop now and re-attempt this again at a later time, I decided to arrange myself some updated travel plans. After all, I work for an American company and I have a friend or two there.</p>



<h2>Day 900 – October 2, 2020</h2>



<p>I replied to the call for travel plan details with an official invitation letter attached, inviting me to go visit my colleagues at <a href="https://www.wolfssl.com/">wolfSSL</a> signed by our CEO, Larry. I really want to do this at some point, as I’ve never met most of them so it wasn’t a made up reason. I could possibly even get some other friends to invite me to get the process going but I figured this invite should be enough to keep the ball rolling.</p>



<h2>Day 910 – October 13, 2020</h2>



<p>I got another email. Now at 910 days since the interview. The embassy asked for my passport “for further processing”.</p>



<h2>Day 913 – October 16, 2020</h2>



<p>I posted my passport to the US embassy in Stockholm. I also ordered and paid for “return postage” as instructed so that they would ship it back to me in a safe way.</p>



<h2>Day 934 – November 6, 2020</h2>



<p>At 10:30 in the morning my phone lit up and showed me a text telling me that there’s an incoming parcel being delivered to me, shipped from “the Embassy of the United State” (bonus points for the typo).</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/embassy-text.png"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/embassy-text.png" alt="" width="496" height="211"></a></figure>



<h2>Day 937 – November 9, 2020</h2>



<p>I received my passport. Inside, there’s a US visa that is valid for ten years, until November 2030.</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/VISA.jpg"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/VISA.jpg" alt="" width="441" height="221"></a><figcaption>The upper left corner of the visa page in my passport…</figcaption></figure></div>



<p>As a bonus, the visa also comes with a NIE (National Interest<br>Exception) that allows me a single entry to the US during the PP (Presidential Proclamations) – which is restricting travels to the US from the European Schengen zone. In other words: I am actually allowed to travel right away!</p>



<p>The timing is fascinating. The last time I was in the US, Trump hadn’t taken office yet and I get the approved visa in my hands just days after Biden has been announced as the next president of the US.</p>



<h2>Will I travel?</h2>



<p>Covid-19 is still over us and there’s no end in sight of the pandemic. I will of course not travel to the US or any other country until it can be deemed safe and sensible.</p>



<p>When the pandemic is under control and traveling becomes viable, I am sure there will be opportunities. Hopefully the situation will improve before the visa expires.</p>



<h2>Thanks to</h2>



<p>All my family and friends, in the US and elsewhere who have supported me and cheered me up through this entire process. Thanks for keeping inviting me to fun things in the US even though I’ve not been able to participate. Thanks for pushing for events to get organized outside of the US! I’m sorry I’ve missed social gatherings, a friend’s marriage and several conference speaking opportunities. Thanks for all the moral support throughout this long journey of madness.</p>



<p>A special thanks go to David (you know who you are) for contacting Gerry Connolly’s office. I honestly think this was the key event that finally made things move in this process.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/09/a-us-visa-in-937-days/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035307</guid>
            <pubDate>Mon, 09 Nov 2020 14:47:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Kafka – 8 things to check before going live]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25035239">thread link</a>) | @ariskk
<br/>
November 9, 2020 | https://ariskk.com/kafka-8-things | <a href="https://web.archive.org/web/*/https://ariskk.com/kafka-8-things">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><span>
      <span></span>
  <img alt="A Kafka System" title="A Kafka System" src="https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/18e3b/kafka-system.jpg" srcset="https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/46946/kafka-system.jpg 240w,https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/55489/kafka-system.jpg 480w,https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/18e3b/kafka-system.jpg 960w,https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/60e21/kafka-system.jpg 1440w,https://ariskk.com/static/89caf78b2f29f9e66a1780486740f932/198e7/kafka-system.jpg 1485w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><p>Apache Kafka is a beautiful system. It scales well, it is stable and it provides phenomenal system architecture flexibility.
After 5 years of running production Kafka clusters, I have collected a list of tips and pitfalls. Some of them were learnt the hard way.
If you work in a small team rolling out Kafka to production, those might prove useful.
The article assume familiarity with basic Kafka concepts, such as brokers, topics, producers and consumers.
What is more, the following points should be valid for up to Kafka 2.6.0.
Without further ado.</p><h3>1. Key all the messages!</h3><p>Kafka topics consist of a (configurable) number of partitions.
If the partition number is not provided by the user, <code>KafkaProducer</code>
chooses the partition for the message using the <code>key</code> in the <code>ProducerRecord</code> instance passed to it.</p><p>Check out the default <a href="https://github.com/apache/kafka/blob/2.6.0/clients/src/main/java/org/apache/kafka/clients/producer/internals/DefaultPartitioner.java#L65">implementation</a>:
It checks if the key is <code>null</code>, and if it isn't it, computes a <code>murmur2</code> hash modulo the number of partitions.
This is consistent; it will yield the same result for messages sharing the same key.
If the key is <code>null</code> though, it uses a <a href="https://github.com/apache/kafka/blob/2.6.0/clients/src/main/java/org/apache/kafka/clients/producer/internals/StickyPartitionCache.java#L60">sticky partitioner</a>
that chooses a partition randomly at every batch.
In practical terms, if no key is passed, the producer will choose the partition randomly.</p><p>This has important implications because <strong>Kafka only provides delivery ordering guarantees within a partition</strong>.
Messages in the same partition will be delivered in the order they were committed.
Messages in different partitions will be delivered in non-deterministic order.
If the messages have any form of <strong>causal relationship</strong> between them, and they are <strong>not</strong> in the same partition,
then any downstream consumer will have to collect all messages for a key before processing them, else causal consistency might be violated; whatever <em>all</em> means in the context of
an infinite stream.</p><p>As a simple example to illustrate the above, think of a simple event like the following:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>case class EmailSubscription(</span></p><p><span>2</span><span>  email: Email,</span></p><p><span>3</span><span>  active: Boolean,</span></p><p><span>4</span><span>  createdOn: DateTime</span></p><p><span>5</span><span>)</span></p><p><span>6</span><span></span></p><p><span>7</span><span>def storeToDB(sub: EmailSubscription) = ???</span></p><p><span>8</span><span>val events: Stream[EmailSubscription] = ???</span></p></pre></div><p>If emails arrive in causal order, then we can map the events statelessly:</p><p>If per-email causal order is not guaranteed though, we need to maintain enough state to know
if the event we see is indeed the latest. Else if the order is reversed, we might send an email to a user who
has unsubscribed.
For example:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>events</span></p><p><span>2</span><span>  .groupMapReduce(_.email)(identity)(</span></p><p><span>3</span><span>    (e1, e2) =&gt; if (e1.createdOn.isAtfer(e2.createdOn)) e1 else e2</span></p><p><span>4</span><span>  )</span></p><p><span>5</span><span>    .values</span></p><p><span>6</span><span>    .map(storeToDB)</span></p></pre></div><p>If we key messages using <code>email</code>, then Kafka will deliver all messages for a single email in the order they were inserted.
Our consumer can be completely stateless; it can fetch messages from Kafka and store them to a datastore.
If the key is <code>null</code> (none provided), our stateless consuer will happily store a message from the past.
To mitigate that, at the very minimum we need to maintain the latest <code>createdOn</code> date for every email.
Relying on wall clocks for causality <a href="https://github.com/aphyr/distsys-class#clocks">is a very bad idea</a>.</p><p>Assuming per key ordering can be guaranteed, downstream reducer bounds can be reduced from a <code>Semilattice</code> to a <code>Semigroup</code>.
In practical terms, by taking advantage of this property we can drop the commutativity requirement which unlocks easier implementations.
If designing reducers for Kafka consumers sounds interesting, let me know and I will write about it.</p><h3>2. Ensure all producers are using the same partitioner</h3><p>Providing a key is not enough. Partitioners (ie the function f: (key) =&gt; partition) are configurable.
Kafka provides a few and users can roll out their own. Do <strong>NOT</strong> assume all producers are using the same partitioner.</p><p>In a complex system where Go services, Python services, Spark and other wild animals all share the same Kafka cluster, all sorts of different implementations might exist.
If different services are pushing data to the same topics, an integration test would be very useful.
If things go wrong, delivery to consumers will be non-deterministic and debugging it can be pure hell.</p><h3>3. Topic versioning</h3><p>The beauty of Kafka is that data can be reprocessed as many times as needed.
This forgives a lot of errors. To illustrate this one, let's assume the same dummy model:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>case class EmailSubscription(</span></p><p><span>2</span><span>  email: Email,</span></p><p><span>3</span><span>  active: Boolean,</span></p><p><span>4</span><span>  createdOn: DateTime</span></p><p><span>5</span><span>)</span></p></pre></div><p>Let's now assume messages are serialized to <code>json</code> before being pushed to Kafka.
Due to a json serialization bug, the following is pushed to the <code>emailsubscriptions</code> topic:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>{</span></p><p><span>2</span><span>  "email": {</span></p><p><span>3</span><span>    "value": "aris@aris.com"</span></p><p><span>4</span><span>  },</span></p><p><span>5</span><span>  "active": false,</span></p><p><span>6</span><span>  "createdOn": 1600000000</span></p><p><span>7</span><span>}</span></p></pre></div><p>Instead of the expected:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>{</span></p><p><span>2</span><span>  "email": "aris@aris.com",</span></p><p><span>3</span><span>  "active": false,</span></p><p><span>4</span><span>  "createdOn": 1600000000</span></p><p><span>5</span><span>}</span></p></pre></div><p>Downstream consumers try to deserialize the message and fail. What can be done?</p><p>One solution would be to create a custom deserializer for those buggy instances and to add it to all the consumers.
That's non trivial and error prone code; useful just for this instance.</p><p>Another solution would be to implement a consumer that would read from <code>emailsubscriptions-1</code>, fix the issue, and write to <code>emailsubscriptions-2</code>.
Once the offsets of the two topics are identical, producers and consumers can switch from <code>emailsubscriptions-1</code> to <code>emailsubscriptions-2</code> without having to update any code.
What's great about this is that those migrations can fail with no major consequences. If <code>emailsubscriptions-2</code> is no good, we can run again and produce <code>emailsubscriptions-3</code> and so on.
This trick also works for non-trivial schema changes, migrations and other data enrichments.
Avro and Profobuf can help in some cases, but bugs will occur and requirements will evolve in unpredictable ways.
In any case, "fixing" a topic's data by reading from it and publishing to it is rarely a good idea.
Topics should be immutable and versioning them can help in many situations where a topic's content have been corrupted.</p><h3>4. Treat ZooKeeper like royalty</h3><p>Up until at least 2.6.0, Kafka relies on ZooKeeper.
Losing connection to ZooKeeper means no ISRs (In-Sync-Replicas, more on that later), no partition leader election and eventually the brokers shut down.
Thankfully <a href="https://twitter.com/fpjunqueira?lang=en">@fpjunqueira</a> and his team who created ZooKeeper are real pros, and that won't happen without reason.
In fact, ZooKeeper is one of the most reliable distributed systems (that I have seen at least).</p><p>The two following mess ups have occurred though:</p><ol><li>Due to a bug in the provisioning Ansible script, 2/3rds of a cluster ended up in the same availability zone, with sequential IPs (that usually means in the same rack on AWS).
They all disappeared at the same time. No consensus, hell broke loose.</li><li>A QA environment ran for long enough for all nodes to run out of disk space (ZooKeeper creates backup snapshots of the transaction log over time and someone/something external has to deal with deleting them).
At the same time. Bringing this env back to life required editing znodes manually, and still data was lost.</li></ol><p>To clean up older transaction log snapshots in ZooKeeper 3.4.x, ZooKeeper provides the following tool:</p><div data-language=""><pre data-linenumber="true"><p><span>1</span><span>java -cp zookeeper-3.4.x.jar:lib/*:conf org.apache.zookeeper.server.PurgeTxnLog \</span></p><p><span>2</span><span>  /var/lib/zookeeper /var/lib/zookeeper -n 5</span></p></pre></div><p>Ideally on a cron.</p><p>Those are just two examples. A lot more can go wrong. Because of the consequences of failure, proper JMX metric monitoring and real time log aggregation,
all hooked up to a form of PagerDuty, are very highly recommended.</p><h3>5. Unclean elections and minimum ISRs</h3><p>This is essentially a trade off between availability and durability. Let's start with unclean elections.</p><p>Let's assume we have a topic with a single partition and a single replica. Data is happily flowing in.
If the replica is "in-sync" (aka identical to the leader and in the ISR set in ZooKeeper),
then if the leader partition becomes unavailable (eg the broker crashes) then the replica can pick up, accept writes and continue with no downtime.
If the replica lags behind though, the leader will remove it from the ISRs in ZooKeeper. If then the leader goes down, there are two options:</p><ol><li>The lagging replica picks up, accepts writes and whatever excess writes the old leader had are <em>lost</em>. Essentially, the replica gets elected as leader without being in-sync. This is the "unclean" part.</li><li>The partition becomes unavailable and new writes are rejected.</li></ol><p>It entirely depends on the kind of data the topic holds. If the topic holds system metrics,
then maybe the most recent data is more valuable and thus losing some older writes might be acceptable.
If the topic contains bank transactions, going down until a human intervenes might be a better option.
This is a broker level config that can be overridden per topic.</p><p>The second part of this equation is <code>min.insync.replicas</code>, which represents the minimum number of replicas that have to be in-sync for a write to go through.
This is configurable at the broker level, topic level and even at the producer level (ie <code>acks</code>). Same considerations as above,
if the topic holds payments, having just 1 replica with all the data might be risky.</p><p>Legendary distributed systems researcher Kyle Kingsbury, aka Aphyr, did an <a href="https://aphyr.com/posts/293-call-me-maybe-kafka">excellent analysis on Kafka's replication mechanism</a> some 7 years ago.
If you wish to dig deeper into this trade off, reading Aphyr's piece is very highly recommeneded. As far as I understand, the basic trade offs discussed still hold true today.</p><h3>6. Memory Maps</h3><p>Kafka uses a LOT of those. Running out of them leads to a fatal runtime exception that will kill the broker.
If the OS defaults are used, it is extremely likely that those will be reached as soon as the cluster has a few tens of thousand segments per broker.
What's worse is that in a well balanced cluster where brokers hold similar numbers of partitions, those failures will occur roughly at the same time.
Let's look a bit closer:</p><p><code>vm.max_map_count</code>: is the maximum number of memory map areas a process can have.</p><p>From the linux kernel <a href="https://www.kernel.org/doc/html/latest/admin-guide/sysctl/vm.html?highlight=max_map_count#max-map-count">docs</a>:</p><blockquote><p>max_map_count:<br>
<!-- -->This file contains the maximum number of memory map areas a process
may have. Memory map areas are used as a side-effect of …</p></blockquote></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ariskk.com/kafka-8-things">https://ariskk.com/kafka-8-things</a></em></p>]]>
            </description>
            <link>https://ariskk.com/kafka-8-things</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035239</guid>
            <pubDate>Mon, 09 Nov 2020 14:39:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Physicists develop an efficient modem for the future quantum internet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035235">thread link</a>) | @rbanffy
<br/>
November 9, 2020 | https://www.mpq.mpg.de/modem-quantum-internet | <a href="https://web.archive.org/web/*/https://www.mpq.mpg.de/modem-quantum-internet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  
  <p>Physicists at the Max Planck Institute of Quantum Optics have developed the basic technology for a new "quantum modem". It will allow users to connect to a future quantum internet that is based on the existing fibre optic network infrastructure.</p>
  

  

  <p>The first quantum revolution brought about semiconductor electronics, the laser and finally the internet. The coming, second quantum revolution promises spy-proof communication, extremely precise quantum sensors and quantum computers for previously unsolvable computing tasks. But this revolution is still in its infancy. A central research object is the interface between local quantum devices and light quanta that enable the remote transmission of highly sensitive quantum information. The Otto-Hahn group "Quantum Networks" at the Max-Planck-Institute of Quantum Optics in Garching is researching such a "quantum modem". The team has now achieved a first breakthrough in a relatively simple but highly efficient technology that can be integrated into existing fibre optic networks. The work is published this week in "Physical Review X".</p>
  
  
<figure data-description="The Garching quantum modem: The crystal disk with the quantum bits of erbium atoms (arrows) is in the middle, the back and forth reflected infrared light is indicated by the red disks." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          The Garching quantum modem: The crystal disk with the quantum bits of erbium atoms (arrows) is in the middle, the back and forth reflected infrared light is indicated by the red disks.
        </p>
        <p>
           Christoph Hohmann (MCQST)
        </p>
    </figcaption>
</figure>


<p>The Corona pandemic is a daily reminder of how important the internet has become. The World Wide Web, once a by-product of basic physical research, has radically changed our culture. Could a quantum internet become the next major innovation out of physics?</p>
<p>It is still too early to answer that question, but basic research is already working on the quantum internet. Many applications will be more specialised and less sensual than video conferencing, but the importance of absolutely spy-proof long-distance communication is understandable to everyone. "In the future, a quantum internet could be used to connect quantum computers located in different places," Andreas Reiserer says, "which would considerably increase their computing power!” The physicist heads the independent Otto-Hahn research group "Quantum Networks" at the Max-Planck-Institute of Quantum Optics in Garching.</p>
<p>A quantum internet is thus essentially about the global networking of new technologies that make a much more consequent use of quantum physics than ever before. However, this requires suitable interfaces for the extremely sensitive quantum information. This is an enormous technical challenge, which is why such interfaces are a central focus of fundamental research. They must ensure that stationary quantum bits - qubits for short - interact efficiently with "flying" qubits for long-distance communication without destroying the quantum information. Stationary qubits will be located in local devices, for example as the memory or processor of a quantum computer. Flying qubits are typically light quanta, photons, that transport the quantum information through the air, a vacuum of space or through fibre optic networks.</p>
<h2>Delicate connection between quantum bits</h2>
<p>The "quantum modem" is designed to efficiently establish a connection between flying and stationary qubits. For this purpose, the team around doctoral student Benjamin Merkel has developed a new technology and has just demonstrated its basic functionality. Its crucial advantage is that it could be integrated into the existing telecommunications fibre-optic network. This would be the fastest way to advance a functioning long-distance networking of quantum technologies.</p>
<p>For this system to work, the photons sent or received by the modem as quantum information carriers must be matched precisely to the infrared wavelength of the laser light used for telecommunications. This means that the modem must have qubits at rest that can react precisely to these infrared photons with a quantum leap. Only in this way the sensitive quantum information can be transmitted directly between the qubits at rest and the flying qubits.&nbsp;</p>
<p>Extensive research by the Garching-based group showed that the element erbium is best suited for this purpose. Its Electrons can perform a perfectly matching quantum leap. Unfortunately, the erbium atoms are very reluctant to make this quantum leap. Therefore,&nbsp; they must be fixated in anenvironment that forces them to react more quickly. To solve this problem, the erbium atoms and the infrared photons are locked up in a suitable space for as long as possible. "You can think of it as a party, which should stimulate the best possible communication between, let’s say, ten guests," Reiserer explains. The size of the space is crucial here. "In a football stadium the guests would get lost, a telephone box in turn would &nbsp;be too small," the physicist continues, "but a living room would do just fine.”</p>
<p>The party, however, would quickly be over because the photons travel at the speed of light and are therefore highly volatile and always tempted to leave. This is why the Garching quantum modem uses a tiny mirror cabinet as a "living room" Thereto,the team packed the atoms into a transparent crystal made of an yttrium silicate compound, which is five times thinner than a human hair. This crystal, in turn, is placed like a sandwich spread between two almost perfect mirrors. To eliminate the heat wobbling of the atoms, which is destructive to quantum information, the entire ensemble is cooled to minus 271 °C.</p>
<h2>Photon ping-pong in the mirror cabinet</h2>

<figure data-description="Approximately in the centre of the picture, the &quot;mirror cabinet&quot; can be seen from outside, which creates the connection between flying and stationary qubits." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Approximately in the centre of the picture, the "mirror cabinet" can be seen from outside, which creates the connection between flying and stationary qubits.
        </p>
    </figcaption>
</figure>


<p>The photons trapped between the mirrors are reflected back and forth through the crystal like ping-pong balls. They pass the erbium atoms so often so that &nbsp;the atoms have enough time to react with a quantum leap. Compared to a situation without a mirror cabinet, this happens much more efficiently and almost sixty times faster. Since the mirrors, despite their perfection, are also slightly permeable to the photons, the modem can connect to the network.</p>
<p>"We are very happy about this success," Reiserer says. As a next step, he wants to improve the experiment such that individual erbium atoms can be addressed as qubits via laser light. This is not only an important step towards a usable quantum modem. Erbium atoms as qubits in a crystal may even serve directly as a quantum processor, which is the central part of a quantum computer. This would make the modem easily compatible with such quantum terminals.</p>
<p>With such an elegant solution, comparatively simply constructed "quantum repeaters" would also become possible. Every hundred kilometres, the devices would have to compensate the increasing losses of quantum information transported by photons in the fibre-optic network. Such “quantum repeaters” are also the focus of international research. "Although such a device based on our technology would cost about a hundred thousand euros, widespread use would not be unrealistic," Reiserer says.</p>
<p>The Garching quantum modem is still purely fundamental research. But it has the potential to advance the technical realisation of a quantum internet.</p>
<p>&nbsp;(RW/MPQ)</p>
  
</div></div>]]>
            </description>
            <link>https://www.mpq.mpg.de/modem-quantum-internet</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035235</guid>
            <pubDate>Mon, 09 Nov 2020 14:39:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I ended up with 1k GitHub repos while testing the GitHub API with CATS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035195">thread link</a>) | @ludovicianul
<br/>
November 9, 2020 | https://ludovicianul.github.io/2020/10/05/github-api-testing/ | <a href="https://web.archive.org/web/*/https://ludovicianul.github.io/2020/10/05/github-api-testing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>05 Oct 2020</span></p>
<p><span><strong>!!! WARNING !!! If you choose to run the steps in this article, please note that you will end up with a significant number of dummy GitHub repos under your username. Over 1k in my case.
There is a script at the end of the article that you can use to delete them. Be careful not to delete your real repos though!</strong></span></p>

<p><img src="https://github.com/ludovicianul/ludovicianul.github.io/raw/master/images/github_repos.png" alt="Repos"></p>


<p>Building good APIs is hard. There are plenty of resources out there with plenty of good advice on how to achieve this. While some of the things are a must, like following the <a href="https://cheatsheetseries.owasp.org/cheatsheets/REST_Security_Cheat_Sheet.html">OWASP REST Security Practices</a>,
some others might be debatable, based on preference, “like using <code>snake_case</code> or <code>camelCase</code> for naming JSON objects”. (I plan to write a more detailed article in the next weeks on what I consider good practices.)
As the number of APIs usually grows significantly, even when dealing with simple systems, it’s very important to have quick ways to make sure the APIs are meeting good practices consistently.</p>

<p>I’ve shown in a <a href="https://ludovicianul.github.io/2020/09/09/cats/">previous article</a> how easy it is to use a tool like <a href="https://github.com/Endava/cats">CATS</a> to quickly verify OpenAPI endpoints 
while covering a significant number of tests cases. But that was a purely didactic showcase using the OpenAPI demo <code>petstore</code> app. Which was obviously not built as a production ready service.
Today I’ll pick a real-life API, specifically the GitHub API, which recently published <a href="https://github.com/github/rest-api-description/blob/main/descriptions/ghes-2.22/ghes-2.22.yaml">their OpenAPI specs</a>.</p>

<p>I’ve downloaded the 2.22 version and saved the file locally as <code>github.yml</code>. Before we start, we need to <a href="https://github.com/settings/tokens/new">create an access token</a> in order to be able to call the APIs. Make sure it has proper scopes for repo creation (and deletion when using the script at the end of the article).
Also, as the API is quite rich (the file has 59k lines), I’ve only selected the <code>/user/repos</code> path for this showcase. You’ll see that there are plenty of findings only using this endpoint.</p>

<p>You can run <code>CATS</code> as a blackbox testing tool and incrementally add minimal bits of context until you end up with consistent issues or a green suite.</p>

<p>As shown in the <a href="https://ludovicianul.github.io/2020/09/09/cats/">previous article</a>, running <a href="https://github.com/Endava/cats">CATS</a> is quite simple:</p>

<div><div><pre><code>./cats.jar <span>--contract</span><span>=</span>github.yml <span>--server</span><span>=</span>https://api.github.com <span>--paths</span><span>=</span><span>"/user/repos"</span> <span>--headers</span><span>=</span>headers_github.yml
</code></pre></div></div>

<p>With the <code>headers_github.yml</code> having the following content:</p>

<div><div><pre><code><span>all</span><span>:</span>
  <span>Authorization</span><span>:</span> <span>token XXXXXXXXXXXXX</span>
</code></pre></div></div>

<p>Let’s see what we get on a first run:</p>

<p><img src="https://github.com/ludovicianul/ludovicianul.github.io/raw/master/images/first_run_github.png" alt="First Run"></p>

<p>We have <code>42 warnings</code> and <code>156 errors</code>. Let’s go through the errors first. Looking at the result of <code>Test 118</code> we see that a request failed due to the name of the repository not being unique. 
Indeed, <code>CATS</code>, for each Fuzzer, preserves an initial payload that will be used to fuzz each of the request fields. This means that we need a way to force <code>CATS</code> to send unique names for the <code>name</code> field. Noted!</p>

<p><img src="https://github.com/ludovicianul/ludovicianul.github.io/raw/master/images/test_118_github.png" alt="Test 118"></p>

<p><code>Test 426</code> says that <code>If you specify visibility or affiliation, you cannot specify type.</code>. Let’s note this down also.</p>

<p><img src="https://github.com/ludovicianul/ludovicianul.github.io/raw/master/images/test_426_github.png" alt="Test 426"></p>

<p>Considering the above 2 problems are reported consistently, let’s give it another go with a <a href="https://github.com/Endava/cats#reference-data-file">Reference Data File</a>.
This is the <code>refData_github.yml</code> file that will be used:</p>

<div><div><pre><code><span>/user/repos</span><span>:</span>
  <span>name</span><span>:</span> <span>"</span><span>T(org.apache.commons.lang3.RandomStringUtils).random(5,true,true)"</span>
  <span>type</span><span>:</span> <span>"</span><span>cats_remove_field"</span>
</code></pre></div></div>

<p><code>CATS</code> supports <a href="https://github.com/Endava/cats#dynamic-values-in-configuration-files">dynamic values in properties values</a> via the <a href="https://docs.spring.io/spring-framework/docs/3.0.x/reference/expressions.html">Spring Expression Language</a>.
Using the above <code>refData</code> file, <code>CATS</code> will now generate a new random <code>name</code> everytime it will execute a request to the GitHub API.
Also, using the <code>cats_remove_field</code> value, <code>CATS</code> will remove this field from all requests before sending them to the endpoint. More details on this feature <a href="https://github.com/Endava/cats#removing-fields">here</a>.</p>

<p>Running <code>CATS</code> again:</p>

<div><div><pre><code>./cats.jar <span>--contract</span><span>=</span>github.yml <span>--server</span><span>=</span>https://api.github.com <span>--paths</span><span>=</span><span>"/user/repos"</span> <span>--headers</span><span>=</span>headers_github.yml <span>--refData</span><span>=</span>refData_github.yml
</code></pre></div></div>

<p>We now get <code>17 warnings</code> and <code>90 errors</code>. Again, looking though the tests failures/warnings there are some tests which are failing due to the fact the <code>since</code> and <code>before</code> are not sent in ISO8061 timestamp format (more on this inconsistency in the <a href="#Findings">Findings</a> section).</p>

<p><img src="https://github.com/ludovicianul/ludovicianul.github.io/raw/master/images/second_run_github.png" alt="Second Run"></p>

<p>We’ll now update the <code>refData</code> file to look as follows:</p>

<div><div><pre><code><span>/user/repos</span><span>:</span>
  <span>before</span><span>:</span> <span>"</span><span>T(java.time.Instant).now().toString()"</span>
  <span>since</span><span>:</span> <span>"</span><span>T(java.time.Instant).now().minusSeconds(86400).toString()"</span>
  <span>name</span><span>:</span> <span>"</span><span>T(org.apache.commons.lang3.RandomStringUtils).random(5,true,false)"</span>
  <span>type</span><span>:</span> <span>"</span><span>cats_remove_field"</span>
</code></pre></div></div>

<p>and run <code>CATS</code> again:</p>

<div><div><pre><code>./cats.jar <span>--contract</span><span>=</span>github.yml <span>--server</span><span>=</span>https://api.github.com <span>--paths</span><span>=</span><span>"/user/repos"</span> <span>--headers</span><span>=</span>headers_github.yml <span>--refData</span><span>=</span>refData_github.yml
</code></pre></div></div>

<p><img src="https://github.com/ludovicianul/ludovicianul.github.io/raw/master/images/third_run_github.png" alt="Third Run"></p>

<p>We now get <code>5 warnings</code> and <code>83 errors</code>. Looking through the errors and warnings, there is a significant amount which I consider legit issues while some are debatable points, depending on preference/standards being followed. 
Let’s go through the findings.</p>


<h2 id="invalid-values-for-boolean-fields-implicitly-converted-to-false">Invalid values for boolean fields implicitly converted to false</h2>
<p>One of the Fuzzers that <code>CATS</code> has is the <code>BooleanFieldsFuzzer</code>. 
This Fuzzer works on the assumption that if you send an invalid value into a <code>boolean</code> field, the service should return a validation error.
Obviously, the GitHub API does not do this, but is rather silently converting the value to <code>false</code>. It’s true this is a consistent behaviour, applying for all boolean fields like <code>auto_init</code>, <code>allow_merge_commits</code>, etc, but I would personally choose to return a validation error in these cases.</p>

<p>This is in contradiction with the <a href="https://cheatsheetseries.owasp.org/cheatsheets/REST_Security_Cheat_Sheet.html#input-validation">OWASP recommendation</a> around strong input validation and data type enforcing.</p>

<h2 id="invalid-values-for-enumerated-fields-implicitly-converted-to-the-default-value-">Invalid values for enumerated fields implicitly converted to the default value (?)</h2>
<p>The <code>InvalidValuesInEnumsFieldsFuzzer</code> will send invalid values in enum fields. It expects a validation error in return. 
The GitHub API does not seem to reject invalid values, but rather convert them to a default value and respond successfully to the request.</p>

<p>This is in contradiction with the <a href="https://cheatsheetseries.owasp.org/cheatsheets/REST_Security_Cheat_Sheet.html#input-validation">OWASP recommendation</a> around strong input validation and data type enforcing.</p>

<h2 id="integer-fields-accepting-decimal-or-large-negative-or-positive-values">Integer fields accepting decimal or large negative or positive values</h2>
<p>The <code>DecimalValuesInIntegerFieldsFuzzer</code> expects an error when it sends a <code>decimal</code> value inside an <code>integer</code> field. The GitHub API seems to accept these invalid values in the <code>team_id</code> field without returning any error, but rather resulting in a successful processing of the request.
Same applies for <code>ExtremePositiveValueInIntegerFieldsFuzzer</code> and <code>ExtremeNegativeValueIntegerFieldsFuzzer</code> which will send values such as <code>9223372036854775807</code> or <code>-9223372036854775808</code> in the <code>team_id</code> field.
Strings also seem to be accepted in the <code>team_id</code> field.</p>

<p>This is in contradiction with the <a href="https://cheatsheetseries.owasp.org/cheatsheets/REST_Security_Cheat_Sheet.html#input-validation">OWASP recommendation</a> around strong input validation and data type enforcing.</p>

<h2 id="accepts-unsupported-or-dummy-content-type-headers">Accepts unsupported or dummy Content-Type headers</h2>
<p>The GitHub API seems to successfully accept and process requests containing unsupported (according to the OpenAPI contract) <code>Content-Type</code> headers such as: <code>image/gif</code>, <code>multipart/related</code>, etc. or dummy ones such as <code>application/cats</code>.</p>

<p>This is in contradiction with the <a href="https://cheatsheetseries.owasp.org/cheatsheets/REST_Security_Cheat_Sheet.html#validate-content-types">OWASP recommendation</a> around validation around content types.</p>


<p>The GitHub API does not reject requests that contain duplicate headers. The HTTP standard itself allows duplicate headers for specific cases, but allowing duplicate headers might lead to hidden bugs.</p>

<h2 id="spaces-are-not-trimmed-from-values">Spaces are not trimmed from values</h2>
<p>If the request fields are prefixed or trailed with spaces, they are rejected as invalid values. For example sending a <code>Haskell</code> space-prefixed value in the <code>gitignore_template</code> will cause the service to return an error.
Although this is inconsistent with the fact that if you trail or prefix the <code>since</code> and <code>before</code> fields with spaces, the values get trimmed successfully and converted to dates.
As a common approach I think that services should consistently trim spaces by default (maybe with some business-driven special cases) for all request fields and perform the validation after.</p>

<h2 id="accepting-new-fields-in-the-request">Accepting new fields in the request</h2>
<p>The GitHub API seems to allow injection of new json fields inside the requests. The <code>NewFieldsFuzzer</code> adds a new <code>catsField</code> inside a request, but GitHub API accepts it as valid.
This is again in contradiction with the <a href="https://cheatsheetseries.owasp.org/cheatsheets/REST_Security_Cheat_Sheet.html#input-validation">OWASP recommendation</a> which suggests rejecting unexpected content.</p>

<h2 id="doesnt-make-proper-use-of-enumerated-values">Doesn’t make proper use of enumerated values</h2>
<p>There are cases when it makes sense to use enums rather than free text. Some examples are the <code>gitignore_template</code> field or the <code>license_template</code> field, which are rejecting invalid values. They are obviously having a pre-defined list of values, but do not enforce this in any way in the contract.
Having them listed as enums will also make it easier to understand what are all supported templates for example.</p>


<p>There are 2 fields called <code>since</code> and <code>before</code> which seem to actually be a <code>date-time</code>, although in the OpenAPI contract they are only marked as <code>string</code> without any additional <code>format</code> information. In the description of the fields it states that this is actually an ISO date, but it will also be good to leverage <a href="https://swagger.io/docs/specification/data-models/data-types/">the features of OpenAPI</a> and mark them accordingly.</p>

<p><img src="https://github.com/ludovicianul/ludovicianul.github.io/raw/master/images/date_time_github.png" alt="Date-Time Error"></p>

<h2 id="mismatch-of-validation-between-front-end-driven-calls-and-direct-api-calls">Mismatch of validation between front-end driven calls and direct API calls</h2>
<p>The <code>homepage</code> field seems to accept any values when doing a direct API call, but when you try to set this from the UI, you will get an error saying that you need to enter a valid URL.</p>

<p><img src="https://github.com/ludovicianul/ludovicianul.github.io/raw/master/images/ui_error_github.png" alt="Validation Error from the UI"></p>

<p>Having the same level of validation for backend and frontend is another good practice for making sure you don’t end up with inconsistent data.</p>


<p>There are some other failures which might seem debatable or not applicable:</p>
<ul>
  <li><code>description</code> accepts very large strings (50k characters sent by CATS), although the GitHub API doesn’t actually have constraint information in the contract; again this is not necessarily a problem, but it’s important for the contract to enforce constraints</li>
  <li>The <code>RecommendedHeadersFuzzer</code> expects a <code>CorrelationId/TraceId</code> to be defined in the headers, but this being a public API, it’s not actually applicable</li>
  <li>The <code>CheckSecurityHeadersFuzzer</code> expects a <code>Cache-Control: no-store</code> as per the OWASP recommendations, but the endpoint does not operate critical data, so allowing caching of the information is fine</li>
</ul>


<p><strong>Before proceeding, please be careful to not delete your real repos</strong>.
This is the script I’ve used to delete the repos. …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ludovicianul.github.io/2020/10/05/github-api-testing/">https://ludovicianul.github.io/2020/10/05/github-api-testing/</a></em></p>]]>
            </description>
            <link>https://ludovicianul.github.io/2020/10/05/github-api-testing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035195</guid>
            <pubDate>Mon, 09 Nov 2020 14:34:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finding passwords in the public Gists feed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035158">thread link</a>) | @passflow
<br/>
November 9, 2020 | https://gistsecrets.io/home | <a href="https://web.archive.org/web/*/https://gistsecrets.io/home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <div>
      <p><a href="https://gistsecrets.io/home">
        <img src="https://gistsecrets.io/images/header.svg" alt="GistSecrets.io">
      </a></p><div>
        <p><a href="https://gistsecrets.io/about">About</a></p>
        <p><a href="https://twitter.com/intent/tweet?text=Alert%20people%20who%20may%20have%20saved%20their%20plaintext%20passwords%20with:%20https://gistsecrets.io">Tweet</a></p>
        <p><a href="https://www.linkedin.com/in/florian-overfelt">LinkedIn</a></p>
        <p><a href="https://www.buymeacoffee.com/floverfelt">Donate</a></p>
      </div>
    </div>
    <div>
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
    </div>

    
    <div>
      <p><a href="https://gistsecrets.io/home">
        <span>Â©</span><img src="https://gistsecrets.io/images/header.svg" alt="GistSecrets.io">
      </a>
    </p></div>
  
</div>]]>
            </description>
            <link>https://gistsecrets.io/home</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035158</guid>
            <pubDate>Mon, 09 Nov 2020 14:31:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cowboys and Villagers. Simple Thoughts on Hiring]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035124">thread link</a>) | @etherio
<br/>
November 9, 2020 | https://devinfee.com/cowboys-villagers-6b3e0740f56e | <a href="https://web.archive.org/web/*/https://devinfee.com/cowboys-villagers-6b3e0740f56e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="e53f">Simple Thoughts on Hiring</h2><div><div><div><p><a href="https://medium.com/@dfee?source=post_page-----6b3e0740f56e--------------------------------" rel="noopener"><img alt="Devin Fee" src="https://miro.medium.com/fit/c/96/96/1*eQw2G_FuHx8Ta00xEvlJEg.png" width="48" height="48"></a></p></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3360/1*KfFjWyfbhqsxEpsYt3kS1A.jpeg" width="1680" height="1050" srcset="https://miro.medium.com/max/552/1*KfFjWyfbhqsxEpsYt3kS1A.jpeg 276w, https://miro.medium.com/max/1104/1*KfFjWyfbhqsxEpsYt3kS1A.jpeg 552w, https://miro.medium.com/max/1280/1*KfFjWyfbhqsxEpsYt3kS1A.jpeg 640w, https://miro.medium.com/max/1400/1*KfFjWyfbhqsxEpsYt3kS1A.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*KfFjWyfbhqsxEpsYt3kS1A.jpeg?q=20"></p></div></div></div></figure><p id="113b">Your first hires were probably mistakes. Mine were disasters; they demonstrated humanity’s fascinating ability to self-implode. Hiring is hard.</p><p id="3694">You’ll probably begin by hiring people who look like you. Not demographically (right?), but people who share the same traits you share: hard working, perfectionist, and maybe even unforgiving. Or, you’ve hired people you want to be friends with — people you’d enjoy going to a concert with or perhaps carrying on a different type of relationship with (i.e. platonic).</p><p id="1a3b">So while I was digging a bit deeper into <a href="https://www.saastr.com/" rel="noopener">SaaStr</a> this evening I came across an interesting discussion between Sarah Lacey and <a href="https://www.slack.com/" rel="noopener">Slack’s</a> CEO, Stewart Butterfield. Slack is a team of 40 year-old plus employees. Slack doesn’t screen for age, but the company does focus on building a village. Not a frat. How many times do we as builders have to learn these lessons?</p><figure><div></div></figure><p id="a15f">This clip highlights the struggle of managing towards a culture with balance and purpose. Sarah discusses with Stewart the work / life balance at <a href="https://www.techcrunch.com/" rel="noopener">TechCrunch</a> with grueling hours and punishing schedules. This thought is then juxtaposed against <a href="https://www.pandodaily.com/" rel="noopener">PandoDaily</a>, where she takes the marathon approach of business building.</p><p id="38c1">These two conclude by discussing the design of a business foundation that is mature and respectful: hallmark traits of a dependability and resilience.</p><p id="14b8">Deviating from the narrative they’ve laid, my experience in hiring and development of employees leads to my understanding that short-term benefits of bringing on cowboys — my way or the highway folk — comes at the cost of any long term benefits. The rapidity of responsibility delegation is only matched by the rate at which they hand it back on their way out. Cowboys don’t stick around; they’re cowboys!</p><p id="8017">Following from that philosophy, there are two hiring questions I fall back on during the candidate screening process:</p><ul><li id="1a87">what do <strong>you</strong> want out of this experience?</li><li id="358e">what resources do <strong>you</strong> need to call on to be successful?</li></ul><p id="9a58">The first question is about alignment and fit. If my needs (as a hiring manager) and your desires are aligned, we can do business today and work in a common direction. If there is a mismatch here and yet I advance the candidate down the hiring-pipeline, I ought to soul-search about what I’m trying to accomplish. I (read: you) need a reality check.</p><p id="0b3c">The second question — really a topic for another day — should help you determine whether the candidate has been there before or whether they’re just a <a href="https://en.wikipedia.org/wiki/Peter_principle" rel="noopener">Peter principle</a> candidate.</p><p id="23a2">Building a village in your business is about hiring function-focused staff who are able to provide excellence and depth for today’s needs. The villagers take pride in their work and stay firmly focused on improving themselves and the village. They demonstrate ownership and long-term buy-in. They often idolize the cowboy, but realize those dreamy nights spent under the stars are often spent alone.</p><p id="ceff">Remember, you’re also a villager. Yes you, the founder, the exec, the CEO. It is up to you to as mayor to bring in good citizens. More good citizens will follow.</p><p id="6d6a">Or don’t. Develop organizations that lack the fundamentals of dependability and resilience. Your villagers and best talent will exit alongside the cowboys. They’ll just be headed in separate directions.</p><p id="3355"><em>Originally published on October 7th, 2015.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://devinfee.com/cowboys-villagers-6b3e0740f56e</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035124</guid>
            <pubDate>Mon, 09 Nov 2020 14:28:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prometheus Pushgateways – Everything You Need to Know]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035108">thread link</a>) | @botayhard
<br/>
November 9, 2020 | https://www.metricfire.com/blog/prometheus-pushgateways-everything-you-need-to-know/ | <a href="https://web.archive.org/web/*/https://www.metricfire.com/blog/prometheus-pushgateways-everything-you-need-to-know/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
          

    

          <h2 id="Intro">Intro</h2>
<p>You have your MetricFire Prometheus instance(s) scraping your scraping targets for every scrape_interval time period, and that is all fine and dandy. But, what if some of your applications do not live long enough to be discovered and scraped by Prometheus? For example if you are using Kubernetes service discovery, and your pods do not live enough to be picked up? Then the typical pull model of Prometheus does not fit anymore because Prometheus cannot find or scrape all of the targets. Some kind of solution is needed.</p>
<p>This is where <a href="https://github.com/prometheus/pushgateway">Prometheus Pushgateways</a> come in. You can send metrics data to the Pushgateway from your short-lived scripts, then the metrics will be eventually ingested by Prometheus. This article on MetricFire’s blog will tell you everything that you need to know so that you can quickly start using Pushgateways. Everything below has been tested for the version 1.2.0 of Prometheus Pushgateway.</p>
<p>To follow along with the blog on your own Prometheus instance, try setting up the MetricFire hosted Prometheus. You can <a href="https://metricfire.com/trial-demo">sign on to our free trial</a>, and get all of the benefits of Prometheus and Grafana with none of the hassle of installation.</p>

<h2 id="Basic-Usage">Basic Usage</h2>
<h3 id="Running-a-Pushgateway">Running a Pushgateway</h3>
<p>The first and most important question - what do I actually need to run a Prometheus Pushgateway? The software is written in Go, so it is distributed as a self-contained binary that you can run on any of Go’s supported operating systems and architecture. If it is most convenient for you, then you can go to the github page for <a href="https://github.com/prometheus/pushgateway/releases">Prometheus Pushgateway releases</a>, and download those binaries there. Here is a handy bash script to download, extract, and run the specified version:</p>

<pre><code>#!/bin/bash
VERSION="1.2.0"
wget "https://github.com/prometheus/pushgateway/releases/download/v${VERSION}/pushgateway-${VERSION}.linux-amd64.tar.gz"
tar xvzf "pushgateway-${VERSION}.linux-amd64.tar.gz" "pushgateway-${VERSION}.linux-amd64/pushgateway"
rm -f "pushgateway-${VERSION}.linux-amd64.tar.gz"
mv "pushgateway-${VERSION}.linux-amd64/pushgateway" ./
rmdir "pushgateway-${VERSION}.linux-amd64"</code></pre>

<p>Obviously, you ought to change the operating system and architecture in this snippet if it is different on your machine. This will give you a binary pushgateway in your current working directory. You can use it to start your own Pushgateway.</p>
<p>If you would rather use a container then there are premade Docker images already waiting for you in the Docker hub. A simple:</p>

<pre><code>docker run -it -p 9091:9091 --rm prom/pushgateway&nbsp;</code></pre>
<p>‍&nbsp;</p>
<p>will give you a Pushgateway container that gets deleted automatically on shutdown on localhost:9091:</p>
<p>‍&nbsp;</p>
<p><img src="https://cdn.buttercms.com/JDQRJvG4RAyraAGXExUR" alt="undefined"></p>

<p>Finally, let’s talk about Kubernetes. <a href="https://helm.sh/">Helm</a> is the ubiquitous package manager for Kubernetes that we will use. It has a nice chart for Pushgateway that you can install with the following command:</p>

<pre><code>helm install stable/prometheus-pushgateway</code></pre>

<p>By default, the chart will create a Service that is also listening on port 9091. You can find the reference list of all of the options <a href="https://hub.helm.sh/charts/stable/prometheus-pushgateway">here</a>. What’s more, the chart even integrates with the <a href="https://github.com/coreos/prometheus-operator">Prometheus Operator</a>. What this integration means is that if you add serviceMonitor.enabled to that chart, then your Pushgateway will be automatically scraped by Prometheus. This is a huge topic in itself, and it is more related to Kubernetes than Pushgateways, so we will skip it in this article. Feel free to explore the links above to learn more about it.</p>
<p>The default options given by Pushgateway should work well in most of the cases. Here they are with the explanation of each of them:</p>
<ul>
<li><em>--web.listen-address=:9091</em>, IP (optional) and port pair on which to listen for requests;</li>
<li><em>--web.telemetry-path=/metrics</em>, Path under which the metrics (both user-sent and internal ones) of the Pushgateway will be exposed;</li>
<li><em>--web.external-url=</em>, URL on which this Pushgateway is externally available. Useful if you expose it via some domain name;</li>
<li><em>--web.route-prefix=</em>, if specified then uses this as a prefix for all of the routes. Defaults to <em>--web.external-url</em>’s prefix;</li>
<li><em>--web.enable-lifecycle</em>, if specified then lets you shutdown the Pushgateway via the <a href="https://github.com/prometheus/pushgateway#management-api">API</a>;</li>
<li><em>--web.enable-admin-api</em>, if specified then enables the Admin API. It lets you perform certain destructive actions. More on that in the following sections;</li>
<li><em>--persistence.file=</em>, if specified then Pushgateway writes its state to this file every <em>--persistence.interval</em> time period;</li>
<li><em>--persistence.interval=5m</em>, how often the state should be written to the previously specified file;</li>
<li><em>--push.disable-consistency-check</em>, if specified then the metrics are not checked for correctness at ingestion time. Should not be specified in the absolute majority of cases;</li>
<li><em>--log.level=info</em>, one of: <em>debug</em>, <em>info</em>, <em>warn</em>, <em>error</em>. Only prints messages with levels higher than that;</li>
<li><em>--log.format=logfmt</em>, possible values: <em>logfmt</em>, <em>json</em>. Specify <em>json</em> if you want structured logs that could be used with, for example, <a href="https://www.elastic.co/">Elasticsearch</a>.</li>
</ul>
<p>‍&nbsp;</p>
<h3 id="Sending-Metrics">Sending Metrics</h3>
<p>Now we have a Pushgateway up and running. However, how do you send your own metrics to it from your ephemeral batch jobs? There are two ways:</p>
<ol>
<li>You can use a program which can do web requests, or&nbsp;</li>
<li>You can use a client library.</li>
</ol>
<p>‍</p>
<p>The former is more applicable in the cases where your batch job is written in a language such as Powershell or Bash.</p>
<p>With Powershell you can use the canonical <em>Invoke-WebRequest</em> which sends a web request to the given URL and given data. To send metrics data to a Pushgateway on Windows Powershell you can use this snippet:</p>
<p>‍&nbsp;</p>
<pre><code>$metrics = "
# TYPE some_metric 
gaugesome_metric 42
# TYPE awesomeness_total counter
# HELP awesomeness_total How awesome is this article.
awesomeness_total 99999999
"Invoke-WebRequest-Uri "http://localhost:9091/metrics/job/metricfire/instance/article" -Body $metrics -Method Post</code></pre>

<p>Running the above snippet will give you the following result in the user interface at <em>localhost:9091</em>:</p>
<p>‍&nbsp;</p>
<p><img src="https://cdn.buttercms.com/YajDBBbnS2aFgKJ2oSVG" alt="undefined"></p>

<p>Consequently, the <em>/metrics</em> end-point now has the following data:</p>
<p>‍&nbsp;&nbsp;</p>
<p><img src="https://cdn.buttercms.com/4DkYcx6mSSODkC8kgQNo" alt="undefined"></p>
<p>&nbsp;&nbsp;‍</p>

<p><img src="https://cdn.buttercms.com/fFsMQLDLSgiuaZuumava" alt="undefined"></p>



<p>As you can see, there are two labels, job and instance. If Prometheus can't find them, it will attach them by itself if the configuration value <em>honor_labels</em> is <em>true</em>. In the snippet above they have been added to the metrics data via the URL that we have used to make the request.</p>
<p>For Linux and other Unix(-like) operating systems we can use the widespread cURL to do this request. The following snippet achieves the same result as the previous one:</p>
<p>‍&nbsp;</p>
<pre><code>cat &lt;&lt;EOF | curl --data-binary @- http://localhost:9091/metrics/job/metricfire/instance/article
# TYPE some_metric gauge
some_metric 42
# TYPE awesomeness_total counter
# HELP awesomeness_total How awesome is this article.
awesomeness_total 
99999999
EOF</code></pre>

<p>The labels specified in the URL are used for grouping metrics together. This enables them to be easily deleted later on because we can refer to small groups of metrics together.</p>
<p>In the case where your job or other labels contain a slash (/) character, then you will need to do extra work. You can find more information <a href="https://github.com/prometheus/pushgateway#url">here</a>.</p>
<p>The only needed label that is necessary to pass metrics via the URL is the <em>job</em> label. Also, note that any of the labels passed via the URL will overwrite whatever labels that the metrics passed via the body might have. If you have any doubts then you can always push some example metrics and check what is being exposed to Prometheus by checking the /metrics (or some other path, if you have it changed via <em>--web.telemetry-path</em>): <a href="http://localhost:9091/metrics">http://localhost:9091/metrics</a>.&nbsp;</p>
<p>If everything succeeds then you will get a response with 200 HTTP status code. If you have disabled the consistency check then you might get a 202 HTTP status code, which means that your metrics have been queued for inclusion into the next scrape, and that they haven’t been checked yet. The actual scraping might fail if you’ve pushed some invalid metrics. For example, if you have pushed them with different types, even if you have written the name exactly the same.&nbsp;</p>
<p>Finally, a 400 HTTP status code means that you’ve pushed some invalid metrics and they have been rejected. In such a case, the HTTP response indicates what is wrong. For example: pushed metrics are invalid or inconsistent with existing metrics: <em>pushed metrics are invalid or inconsistent with existing metrics: collected metric "some_metric" { label:&lt;name:"instance" value:"article" &gt; label:&lt;name:"job" value:"metricfire" &gt; label:&lt;name:"label" value:"test" &gt; gauge:&lt;value:12345 &gt; } was collected before with the same name and label values</em>.</p>
<p>This means that the same metric has been defined twice in one request. It is invalid to redefine the metric’s value in the same request or scrape.</p>


<p>&nbsp; ‍&nbsp;</p>
<h3 id="Scraping-Metrics">Scraping Metrics</h3>
<p>The configuration that you might have is highly variable depending on the different service discovery mechanism(-s) that you have at your disposal. Explore the different configuration options available <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config">here</a>. The simplest option is to statically define a Pushgateway target from which to scrape metrics:</p>
<p>‍&nbsp;</p>
<pre><code>scrape_configs:
- job_name: pushgateway
  honor_labels: false
  static_configs:
  - targets: ['localhost:9091']
    labels:
      pushgateway_instance: metricfire</code></pre>

<p>This will make your Prometheus scrape a Pushgateway instance at <em>localhost:9091</em> if you are running a Pushgateway locally. Another thing to consider is enabling the <em>honor_labels</em> parameter. Having it enabled means that Prometheus would opt to choose whatever comes from the Pushgateway instead of what Prometheus is trying to attach when it tries to add certain reserved labels or labels which have you specified in the scraping configuration. For example, if you had a metric in your Pushgateway <em>awesomeness{pushgateway_instance=”notmetricfire”}</em> then it would use the value <em>notmetricfire</em> for that label instead of <em>metricfire</em> as defined in the scraping configuration that you can see in the code snippet above. Without it, the original label will be renamed to <em>exported_pushgateway_instance</em> which would have the value <em>notmetricfire</em>.</p>
<p>Enabling <em>honor_label</em> is useful in cases where you want to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.metricfire.com/blog/prometheus-pushgateways-everything-you-need-to-know/">https://www.metricfire.com/blog/prometheus-pushgateways-everything-you-need-to-know/</a></em></p>]]>
            </description>
            <link>https://www.metricfire.com/blog/prometheus-pushgateways-everything-you-need-to-know/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035108</guid>
            <pubDate>Mon, 09 Nov 2020 14:27:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at S&P 500's real excess return over Treasuries over long time horizons]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25035020">thread link</a>) | @fa
<br/>
November 9, 2020 | https://fasiha.github.io/post/excess-returns/ | <a href="https://web.archive.org/web/*/https://fasiha.github.io/post/excess-returns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><figure><img src="https://fasiha.github.io/post/excess-returns/The_Monitor_and_Merrimac.jpg"></figure>  <ul>
    <li><a href="https://fasiha.github.io/">Blog</a></li>
    <li><a href="https://fasiha.github.io/#contact">Contact</a></li>
    <li><a href="https://fasiha.github.io/atom.xml">Feed</a></li>
  </ul><p><em>Updated on Sun, 08 Nov 2020 03:01:01 GMT, tagged with ‘finance’.</em></p><p>Imagine. It's 1871. A promising young American has just entered the workforce and makes it a point to buy $100 of the S&amp;P 500 index every month, with dividends reinvested, over a forty year career. It's now 1911. Our American, about to retire, stops these monthly purchases and asks, "What is the real return I achieved in excess of risk-free Treasuries over my forty-year investing horizon?"</p>
<p><strong><em>Answer: 3.8%.</em></strong></p>
<blockquote>
<p>You want details, I got details. You can read the <a href="https://github.com/fasiha/shiller-heat/blob/8cac0574702320ffc41302c8392b4929855ed321/shiller.ts#L121-L125">code</a> or the <a href="https://drive.google.com/file/d/1jzBiJ4OAIDo35Nom0U6a655TJAnqeoMf/view?usp=sharing">spreadsheet</a> (start at cell W5), but I use Robert Shiller's <a href="http://www.econ.yale.edu/~shiller/data.htm">online dataset</a>. It contains monthly numbers for the S&amp;P 500 index's price (dollars per share), dividends (dollars per month), CPI (consumer price index, to discount inflation), and 10-year Treasury yields, all starting in 1871. I assume you invested $1 at the beginning of each month at the real CPI-adjusted price of the stock index, reinvesting the dividends that accrued over the previous month. After 480 such buying sessions, I calculate the internal rate of return (XIRR) by assuming the entire portfolio was liquidated, which is just an accounting choice to answer the question, "what real return did the S&amp;P 500 yield over this forty year horizon after monthly dollar cost averaging".</p>
<p>I then do a similar exercise with Treasuries: every month I assume you put that real $1 into a savings account-like vehicle that pays interest monthly at the same rate as the 10-year T-note's (CPI-adjusted). XIRR again computes the internal rate of return, over the same time horizon. <em>Excess</em> return is just the S&amp;P's real return minus the Treasuries' real return, and is expressed in a percentage just like any rate of return.</p>
</blockquote>
<p>Imagine now that every year after 1871, we can find one such promising young American to join the work force and to do the same thing: monthly-dollar-cost average into the S&amp;P 500 index for forty years.</p>
<p>Seven years later, the investor who began dollar-cost averaging in 1878 and asks in 1918 what their real excess rate of return was, gets a shocking number.</p>
<p><strong><em>0.3%.</em></strong></p>
<p>This investor retiring in 1918; the next one retiring in 1919, and 1920, and on, up to 1924: each of these see an excess real rate of return between <strong><em>-1.3%</em></strong> and <strong><em>0.3%</em></strong>. In 1925, the retiree who began in 1885, sees a <strong><em>0.8%</em></strong> excess real return, and only after them does each successive year's retiree see a nice positive excess real return.</p>
<p>The graph below plots this time series: the excess real return each year's retiree saw, from 1911 to 2020. Thanks to Plotly, it's interactive so you can click, tap, zoom, pan, pinch, etc. You can see it starts out at the 3.8% mentioned above, drops to -1.3% in the early 1920s, and wanders between -2.4% and 6.6%, as each year's retiree does a bit better or worse than the previous year's. The <em>median</em> excess real return for all our retirees: 1.6%.</p>

<p>From 1925 to 1981, each retiree saw a positive real excess return.</p>
<p>Then, from 1981 to 2013, thirty-one retirees during this thirty-three year interval saw negative excess real returns over forty years of monthly dollar-cost averaging. (There was a brief blip into positive territory during 1999 and 2000, i.e., the Tech Bubble.) That's a whole generation: a parent and their child could both have seen zero real excess return, over a career's worth of investing.</p>
<p>As I'm writing this, in late 2020, I see this year's retiree is looking back on 3.1% real excess return of the S&amp;P 500 over Treasuries, over forty years of monthly dollar-cost averaging. I'm about fifteen years into my career. You might be thirty-five years into yours, or just three years. We don't yet know what the graph will look like for us when we retire, in five, twenty-five, and thirty-seven years hence—but seeing this graph, with its plateaus and gyrations, and imagining at each point a retiree looking back on <em>a lifetime</em> of following solid retirement advice, gives me pause: so many of them were <em>unrewarded</em> for investing in stocks—they could have just bought Treasuries and relaxed.</p>
<p>I'm caricaturing retirement conventional wisdom a little bit—although its simplest tenet is to buy and hold a diversified basket of equities and reap its risk premium over the long-term, we haven't simulated a glide path to bonds, or explored any alternatives. Nevertheless, for me personally, answering this simple question about equities' excess real returns following this commonly-recommended strategy was very illuminating, because it makes me feel that retirement savings is less of a solved topic than I thought.</p>
<p><strong>Postscript</strong> A friend recently asked me, "What should I invest in for my newborn's college fund?" Although the universe of assets worth considering is much larger than just S&amp;P 500 ETF vs a money market fund, the above analysis can apply: what is the excess real return of the S&amp;P 500 over Treasuries over all <em>twenty</em> year horizons of monthly dollar-cost averaging, with dividends reinvested?</p>
<p>That's the graph below (along with several other horizons).</p>

<p>Answer: it ranges from between 10.4% to -10% annualized rate of return, with a <em>median</em> of 2.4%. If we imagine an annual series of parent–investors adopting this strategy, the first's child turning twenty in 1891, this median means that half of them saw excess returns greater than 2.4% and half of them less. Do these returns justify putting your child's college fund in the S&amp;P 500? I would feel sufficiently uneasy about this and seek to explore other options.</p>
<blockquote>
<p><strong>Footnote</strong> Earlier versions of this post were circulated in February 2019, and again in March 2020 which led to finding and fixing a bug in the calculation. The <a href="https://drive.google.com/file/d/1jzBiJ4OAIDo35Nom0U6a655TJAnqeoMf/view?usp=sharing">Google Sheets version</a> of Shiller's dataset includes calculations for a single data point. I also sought some feedback from the readers of <a href="https://money.stackexchange.com/q/121010">Personal Finance Stack Exchange</a>.</p>
</blockquote>
<p>(Banner: a crop from "The Monitor and Merrimac: The First Fight Between Ironclads", chromolithograph by Louis Prang &amp; Co., 1886. <a href="https://commons.wikimedia.org/wiki/File:The_Monitor_and_Merrimac.jpg">Wikimedia</a>)</p>


<p>
<small>Previous: <a href="https://fasiha.github.io/post/risk-for-kids-and-grownups/">Learning about risk, for kids and grownups</a><br></small>
</p>
</div>]]>
            </description>
            <link>https://fasiha.github.io/post/excess-returns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25035020</guid>
            <pubDate>Mon, 09 Nov 2020 14:19:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tiny CI System]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25034823">thread link</a>) | @yule
<br/>
November 9, 2020 | https://www.0chris.com/tiny-ci-system.html | <a href="https://web.archive.org/web/*/https://www.0chris.com/tiny-ci-system.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<p>2020-11-08</p>
<p>This is a little demonstration of how little you need to host your own git
repositories and have a modest <a href="https://en.wikipedia.org/wiki/Continuous_integration">Continuous Integration</a>
system for them. All you need is a unixy
server you can ssh into, but arguably you can try this out locally as well.
We will use Redis at one point to queue tasks, but
strictly speaking this can be achieved without additional software. To keep things
simple this will only work with one repository, since this is only describing a
pattern.</p>
<p>The source code to all of that follows below can be found <a href="https://git.sr.ht/%7Estchris/tiny-ci">here</a>.</p>
<h2>Hosting bare git repositories</h2>
<p>Assuming you can ssh into a server and create a directory, this is all you need
to create a shareable git repository:</p>
<pre><code>$ git init --bare
</code></pre>
<p>Ideally you are using a distinct user for it (named <code>git</code>) and have it set to
use <code>git-shell</code> as its default shell. By convention bare repositories are stored
in directories which end in <code>.git</code>. You can now clone this repository from your
machine with:</p>
<pre><code>$ git clone ssh://git@host.example.com/~git/repo.git
</code></pre>
<h2>post-receive hooks</h2>
<p>A <a href="https://git-scm.com/docs/githooks#post-receive">post-receive hook</a> is an executable which can do some work as soon as something new was pushed to the repository. We will use an executable shell script which needs to go inside the <code>hooks</code> directory of the (bare) repository on the server side.</p>
<p>Now the most trivial thing to do would be to do the actual work in here, but this would block the <code>git push</code> on the client side, so we just want to enqueue a new job, return a handle and exit. If what you do takes only a short amount of time, you can stop here. Alternatively you can use this repository for deployments only, by defining it as a separate remote. But the goal here is to have tests run on every push, so we will split the job creation from the actual run.</p>
<p>This is where Redis comes into play for the job queueing. We will assume redis is installed and running and we will use redis-cli to access it from the script. We will use two data structures: a list of jobs waiting to be executed, referenced by a UUID we will generate and a hash where we can store the git revision and the state associated to a given job, as well as its output.</p>
<p>Note that git is passing three arguments to the script via stdin: the old revision before the push, the new revision and the current ref.</p>
<pre><code>#!/bin/bash
while read -r _ newrev ref
do
	id=$(uuid)
	echo "Starting CI job $id"
	redis-cli hset "$id" rev "$newrev" &gt;/dev/null
	redis-cli hset "$id" ref "$ref" &gt;/dev/null
	redis-cli lpush jobs "$id" &gt;/dev/null
done
</code></pre>
<h2>Defining build jobs</h2>
<p>By convention our system will run whatever is in an executable script named <code>ci.sh</code>. The drawback is that this only works with trusted systems and access to the repository needs to be guarded to prevent random code execution. The big advantage is that we don't need to come up with a job definition DSL or cumbersome file format.</p>
<p>Our convention will also be that the script will be passed one argument: the name of the git ref, so we can decide what to do based on the branch we are on.</p>
<p>Let's just put this into a file named <code>ci.sh</code>:</p>
<pre><code>#!/usr/bin/env bash

# the git ref gets passed in as the only argument
ref="$1"

# pretend we're running tests
echo "running tests"

# only deploy if we're on the main branch
[[ "$ref" == "refs/heads/main" ]] &amp;&amp; echo "Deploying"
</code></pre>
<h2>The build runner</h2>
<p>Now that jobs are queued the last piece missing is a job runner. We will make use of Redis' <a href="https://redis.io/commands/blpop">BLPOP command</a> to block until the jobs list has a new job for us. That job id will give us the revision we need to check out and will allow us to write back the output and status of the job.</p>
<p>Note that, as discussed, this assumes a repository called <code>test</code> is already checked out right next to the script.</p>
<p>tiny-ci.sh</p>
<pre><code>#!/usr/bin/env bash

# ./runner.sh is supposed to run on the server where your git repository lives

# the logic in here will run in an infinite loop:
# * (block and) wait for a job
# * run it
while :
do

# Announce that we're waiting
echo "Job runner waiting"

# We are using https://redis.io/commands/blpop to block until we have a new
# message on the "jobs" list. We use `tail` to get the last line because the
# output of BLPOP is of the form "list-that-got-an-element\nelement"
jobid=$(redis-cli blpop jobs 0 | tail -n 1)

# The message we received will have the job uuid
echo "Running job $jobid"

# Get the git revision we're supposed to check out
rev=$(redis-cli hget "${jobid}" "rev")
echo Checking out revision "$rev"

# Get the git ref
ref=$(redis-cli hget "${jobid}" "ref")

# Prepare the repository (hardcoded path) by getting that commit
cd test || exit; git fetch &amp;&amp; git reset --hard "$rev";

# Actually runs the job and saves the output
if ! output=$(./ci.sh "$ref" 2&gt;&amp;1);
then
    status="failed";
else
    status="success";
fi;

# Update the result status
redis-cli hset "${jobid}" "status" $status;

# Update the job output
redis-cli hset "${jobid}" "output" "$output";

echo "Job ${jobid} done"

done
</code></pre>
<h2>Running it</h2>
<p>Summing up:</p>
<ul>
<li>there's a bare git repository somewhere, called <code>test.git</code></li>
<li>we can clone the empty repo (or create a new one and add the respective remote)</li>
<li>on the server hosting the git repository we clone <code>test.git</code> into <code>test</code> and place <code>tiny-ci.sh</code> next to it</li>
<li>we run builds by starting <code>tiny-ci.sh</code> on the server hosting the repository</li>
</ul>
<p>Now if we <code>git push</code> a new commit to the <code>main</code> branch with the <code>ci.sh</code> file from above, the output will return the job id</p>
<pre><code>Enumerating objects: 5, done.
...
remote: Starting CI job dab82634-21cc-11eb-b3b3-9b8767dff47c
</code></pre>
<h2>Checking build status</h2>
<p>Knowing a job uuid, the easiest way to get the status
of a build is by using the <code>--csv</code> style output of the <a href="https://redis.io/commands/hgetall">HGETALL</a> command of redis.</p>
<pre><code>$ ssh example.com redis-cli --csv hgetall $JOB_UUID
"rev","f0706ea18a22031f84619b1161c8fbdb0dcd6850","ref","refs/heads/master","status","success","output","running tests\nDeploying"
</code></pre>
<h2>Possible further improvements</h2>
<ul>
<li>
<p><strong>multi-repo support</strong></p>
<p>This would mean changes to the <code>post-receive</code> hook to put jobs in a list named <code>job-${REPONAME}</code> and then have the worker also react based on that. Notice how <code>redis-cli blpop</code> takes several lists to watch and will also return the name of the list.</p>
</li>
<li>
<p><strong>job cleanup</strong></p>
<p>Creating a key for every job pollutes the redis database unnecesarily. Enqueuing the job could be done via <a href="https://redis.io/commands/setex">SETEX</a> so that the keys go away after one hour / one day / one week. The purpose of Redis here is short term storage and not long-term archival of job results</p>
</li>
<li>
<p><strong>more workers</strong></p>
<p>Scaling to multiple workers on the same machine would need different working folders (and some process isolation depending on the tasks run in there). Scaling to multiple machines would need access to a central redis instance for job distribution.</p>
</li>
<li>
<p><strong>worker isolation / sandboxing</strong></p>
<p>For more complex tasks some kind of process and file-system isolation is necessary. The worker could spin up VMs or Docker containers. The build system used on <a href="https://builds.sr.ht/">builds.sr.ht</a> for instance uses a <a href="https://man.sr.ht/builds.sr.ht/installation.md#security-model">Docker container run as an unprivileged user in a KVM qemu machine</a>.</p>
</li>
<li>
<p><strong>timestamps</strong></p>
<p>For convenience you would definitely want timestamps for every operation. This also allows to list queries like "the last five jobs" or to do maintenance on job results based on their time.</p>
</li>
<li>
<p><strong>notifications</strong></p>
<p>Any CI system will have some form of notifications and the simplest form would be to do something in the script, right at the end. But this covers only the success case, so a better approach would be to create a notification queue and have a notification worker react on that.</p>
</li>
</ul>
<p><a href="https://lobste.rs/s/fbc6wl/tiny_ci_system">Discuss on lobste.rs</a></p>


<ul>
  
</ul>

    </div></div>]]>
            </description>
            <link>https://www.0chris.com/tiny-ci-system.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034823</guid>
            <pubDate>Mon, 09 Nov 2020 13:56:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Free Features]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 83 (<a href="https://news.ycombinator.com/item?id=25034809">thread link</a>) | @alangibson
<br/>
November 9, 2020 | https://landshark.io/2020/11/09/no-free-features.html | <a href="https://web.archive.org/web/*/https://landshark.io/2020/11/09/no-free-features.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p><a href="https://news.ycombinator.com/item?id=25032105">This thread recently hit the top of Hacker news</a>.</p>

<blockquote>
  <p>No More Free Work from Marak: Pay Me or Fork This</p>

  <p>Respectfully, I am no longer going to support Fortune 500s
( and other smaller sized companies ) with my free work.</p>
</blockquote>

<p>The gist is that Marak, who’s on the brink of homelessness after his apartment building caught fire, is no longer interested in doing unpaid work for businesses using his <a href="https://github.com/Marak/faker.js">faker.js</a> project. He seems to be getting a lot of support from the open source developer community.</p>

<h2 id="unpaid-interns">Unpaid Interns</h2>

<p>The foundational principle of open source is “fix your problem, then give the world a copy of the solution.” So let’s get one thing straight: <em>open source developers are not volunteering to fix your problem.</em> They are fixing their own problems, then letting you use the solution too because it costs them nothing. That near-zero cost of replicating software is why open source works.</p>

<p>Because of this, I don’t think developers claiming to do open source should expect compensation for features that they need for themselves. But developing a new feature that they don’t need is something different entirely. In IT we call that a Change Request, and CRs come with a fee to cover them. ‘Near-zero cost’ doesn’t apply anymore because now they’re taking on a lot of work they otherwise wouldn’t have done.</p>

<p>Not recognizing this difference has led to a situation where for-profit entities are using open-source devs as unpaid interns. Well it’s worse really: at least interns get resume filler.</p>

<h2 id="no-more-free-features">No More Free Features</h2>

<p>I look forward to a day when asking anyone to do unpaid labor is considered unethical by our industry. That goes for feature requests on open source projects, on unpaid internships, and on unpaid ‘take home’ interview assignments.</p>

<p>Requesting work in an economic context without offering compensation in some form is morally indefensible. It’s wrong because unpaid labor is wrong. It’s wrong because presuming on anyone’s helpful nature is wrong. We shouldn’t be using bounties to move our change requests to the head of the line because we shouldn’t even be making requests without a bounty attached.</p>

<p>(<a href="https://news.ycombinator.com/item?id=25034809">Official Hacker News discussion thread</a>)</p>

</div></div>]]>
            </description>
            <link>https://landshark.io/2020/11/09/no-free-features.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034809</guid>
            <pubDate>Mon, 09 Nov 2020 13:55:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JIT Compiler of PCRE2]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25034716">thread link</a>) | @elvis70
<br/>
November 9, 2020 | https://zherczeg.github.io/sljit/pcre2_jit.html | <a href="https://web.archive.org/web/*/https://zherczeg.github.io/sljit/pcre2_jit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://zherczeg.github.io/sljit/pcre2_jit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034716</guid>
            <pubDate>Mon, 09 Nov 2020 13:46:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why you should care about privacy (even if no one else around you does)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25034710">thread link</a>) | @betaman0
<br/>
November 9, 2020 | https://www.cupwire.com/why-you-should-care/ | <a href="https://web.archive.org/web/*/https://www.cupwire.com/why-you-should-care/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>There's a pattern I've noticed over the last couple years that goes something like this. </p><ul><li>Person has a personal revelation or their curiosity is piqued and are interested in privacy</li><li>Person reads articles and researches ways to become more private after learning how companies are abusing our data</li><li>Person finds an online forum, such as Reddit, and ends up sprinting down the rabbit hole of alternatives, fixes, and 'get private quick' actions</li><li>Person does too much, too fast and becomes burnt out</li><li>Person questions if it's all worth it because it's hard and no one else around them is doing it so why should they</li><li>Person goes back to old, comfortable habits</li></ul><p>It happens like clockwork and you can always tell what stage the person is at after talking to them for a moment or two. &nbsp;But, there's a specific step I want to hone in on for this post. &nbsp;The "no one else around me is doing it, so why should I bother" part.</p><p>Usually, this mentality comes during or directly after they try to change their daily habits, both IRL and online, all at once and become overwhelmed. They changed all of their passwords, email service, web browser, downloaded Signal, deleted Facebook and SnapChat, went and registered for a PO box, and shredded their credit cards all in the same week and are trying to cold turkey their way into privacy.</p><p>After spending hours of their time and a chunk of cash, they're sitting there wondering if it's all worth it. Their brain begins to cast doubt on their actions and look for justifications to drop everything and go back to how it was. &nbsp;Mom and dad are out living their life happily even though they use Facebook, Windows, and Chrome. &nbsp;Your best friend runs a successful local shop and uses Google for everything. &nbsp;Heck, even your younger sister is all over social media and signs up for every contest known to man, yet, her life doesn't seem any different than yours when you've gone through all of this work to become more private. </p><p>So why care about privacy when everyone around you doesn't? &nbsp;</p><p>Here's four reasons why you should care and why it's important you do.</p><h2 id="you-have-to-normalize-it">You have to normalize it</h2><p>Headlines about privacy and data abuse are at an all-time high but we still see the same arguments show up time after time.</p><div><p>“I have nothing to hide” <br>“They already know everything about me” <br>“I like Facebook and Google” </p><p>These statements don't always come from a place of ignorance. People, generally, know that Facebook and Google collects their data. &nbsp;Maybe not to the extent that they do, but people know they're giving up information to use their services. Often time, these comments come from a place of disinterest or general skepticism. </p></div><p>There's a perception that if you're concerned about privacy, you're trying to hide something or you bear a tin foil hat and shout conspiracies on the corner. Basically, being private is currently seen as "not normal". &nbsp;</p><p>Some of this is self inflicted, with privacy enthusiasts jokingly calling themselves paranoid, weirdos, or nut jobs. &nbsp;It may seem like it's all in good fun but over time, it begins to reinforce that these beliefs and habits are atypical when they aren't.</p><p>When we look at someone wearing a coat, we don't suddenly wonder what they're hiding. &nbsp;We think "oh, that person must be cold". Same thing with masks. Wearing a mask? &nbsp;You must either be sick or doing your part to prevent the spread of a global pandemic that's killed over 215,000 people in the US <em>cough</em>wearyourmask<em>cough</em>. The point is that it's no longer seen as odd to walk around everywhere with a medical grade mask on your face. It's been normalized. </p><p>This is the point we need to get privacy to and we do it by taking these actions ourselves. &nbsp;You might tell 10 people to use Signal and maybe one person does. Even though the other nine aren't using it, you've planted a seed in their mind. Next time one of their other friends or family member mentions downloading Signal, they'll remember that you mentioned it a while back and will start to think "is this something I should be checking out?" </p><p>One we individually begin to normalize these actions, behaviors, and services, <a href="https://en.wikipedia.org/wiki/Social_proof">social proof</a> will take over.</p><p>And why do you have to take a stand and do you part to help normalize it? Because...</p><h2 id="most-people-won-t-do-it-alone">Most people won't do it alone</h2><p>We are creatures of habit and it almost always takes some sort of external force to get us to change our ways. That could be as simple as stepping on the scale one day and going “holy crap, I didn’t realize I put on so much weight” or as serious as a near-death experience that forces us to quit drinking and appreciate the small things in life. It could also be as simple as a close friend or family member asking you to download a messenger app or explaining to you why Facebook is bad. </p><p>Chances are you didn’t just wake up one day and think “I should care about my privacy.” You probably read an article, saw a documentary, had a chat with a friend, or were a victim of some sort of data abuse. Your friends won’t just wake up one day and start using Signal either. You have to guide them to it.</p><p>This doesn't mean monologue for 15 straight minutes of borderline conspiracy at them. &nbsp;Nobody, including &nbsp;yourself, enjoys someone preaching or talking at them. You also don't always need ultimatums either. &nbsp;I know those are somewhat popular in the privacy community (ex: talk to me on Signal or don't talk to me at all) but that can easily backfire. Telling family and friends that you found an awesome new messager that's better than regular texting and you want to try it out with them is much more effective because...</p><h2 id="most-people-will-humor-you">Most People Will Humor You</h2><p>More often than not, your friends and family value you and respect your values even if they don’t share them. Your friends may not humor you if you ask them to delete Facebook, but if you ask them to switch to a user-friendly app like Signal or Wire or ask them to use an encrypted email provider like ProtonMail, they'll probably take you up on the offer. </p><p>Friends and family are, generally, willing to jump into their app store of choice and download an app to try it out. People do it all the time for random games, apps that autotune your voice, or ones that make your head look like an alien. As long as you aren't asking them to set up a server or some complex onboarding process, most people will download an app, jump through a two or three step registration, and test it out for you.</p><p>They may only use these apps with youand that's perfectly fine. It opens the door for you to explain to them why you want to use these apps, how it benefits them, and why they should get their friends and family to use them as well.</p><h2 id="herd-immunity">Herd Immunity</h2><p>The reason why every company harvests so much data is because there's so much value in it thanks to the large amount of people who willingly give it up. &nbsp;Names, addresses, email accounts, usernames, social media accounts, SSN, birthdays, where they're born, pictures of themselves, kids, and friends, browsing history, shopping habits, location data, etc. </p><p>Because there's so much data on so many people, it becomes valuable. Not just monetary value in terms of buying/selling data either. It makes advertising better and more targeted, its <a href="https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did">predictions more accurate</a>, and <a href="https://en.wikipedia.org/wiki/Facebook%E2%80%93Cambridge_Analytica_data_scandal">mass manipulation more damaging.</a></p><p>But what happens when people start to use services where Google can't read your messages and email or see your search history? Or ones where Facebook can't see every thought, opinion, or stance you have? Or use cash so every bank and retailer can't see each and every purchase you make?</p><p>What happens is that the data becomes less accurate, which lowers the value. And when the value reaches a specific threshold, it becomes worthless and the company will have to shift its efforts to something that makes them money or they die. It's a win for you because you've made the choice to use privacy respecting services but it also is a win for those who can't or don't want to switch because the company drops the collection due to being a low return on investment.</p><p>Even by yourself, you're ever so slightly lowering the amount of data they have, the accuracy of their data, and the value their data has. &nbsp;But the wonderful thing is, you aren't alone. &nbsp;There are millions of people who have taken steps to regain their privacy and the movement is growing every day. &nbsp;You may not personally know anyone who has taken any privacy focused steps, but the world is slowly moving that way. </p><p>ProtonMail hit <a href="https://www.inverse.com/article/49041-protonmail-ceo-andy-yen-interview">5 million active users a couple years back</a>. Facebook is <a href="https://www.businessinsider.com/facebook-decline-2-million-daily-users-us-canada-q3-earnings-2020-10">down 2 million users in the US and Canada.</a> Signal is <a href="https://time.com/5893114/signal-app-privacy/">growing by leaps and bounds</a>. DuckDuckGo is <a href="https://duckduckgo.com/traffic">consistently seeing increases in traffic every month.</a></p><p>Privacy is slowly building a wall that big tech and others can't get around. &nbsp;You aren't alone in this. &nbsp;Millions of individual people have taken a stance and made a change. &nbsp;You don't have to do everything all at once. &nbsp;Rome wasn't built in a day and neither is your privacy. &nbsp;Take the steps, even if no one else you know currently is, because not only are you making the world better for yourself, you're making better for everyone.</p><hr><p><em>This post was based on the post from <a href="https://write.as/thenewoil/why-you-yes-you-reading-this-need-to-take-the-lead-in-privacy-and-security">TheNewOil</a>.</em></p><p><em>Want to join the discussion? &nbsp;Check out this post, and others, over at the <a href="https://www.reddit.com/r/cupwire">CupWire subreddit</a> and leave a comment.</em></p>
  </div></div>]]>
            </description>
            <link>https://www.cupwire.com/why-you-should-care/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034710</guid>
            <pubDate>Mon, 09 Nov 2020 13:45:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Writing Is About Logic, Not Words]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25034706">thread link</a>) | @anacleto
<br/>
November 9, 2020 | https://pulseasync.com/operators/share-written-ideas/ | <a href="https://web.archive.org/web/*/https://pulseasync.com/operators/share-written-ideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article"><p>Today it's almost obvious to state that good written communication creates a business advantage.</p>
<p>I've probably read more articles on written communication in the workplace in the last two months than over the last 10 years. </p>
<p>Most of these essays gave tips on how to become better writers.</p>
<p>I couldn't help but notice that many (if not all) of them questioned the same thing: the prose.</p>
<p>Everyone advised to keep sentences short and to the point, use active voice and not passive&nbsp;voice, use fewer commas and more periods, avoid acronyms, etc.</p>
<p>Let's be clear: none of these are mistaken or wrong by any means. But this made me realize how huge the misconceptions are on what good business writing actually means.</p>
<p>In fact, what separates most people from good writing has very little to do with style, grammar, local sentences structure, word selection, or even content per se.&nbsp;</p>
<p>Most people can't write well because they don't know how to control the logical sequence in which they present their ideas.</p>
<p>And that is the single most important act necessary to clear writing.</p>
<p>In this essay we're going to dig into how you can effectively share written ideas in a way that value time and effort for others.</p>
<hr>
<h2 id="understanding-how-we-think"><a href="#understanding-how-we-think" aria-label="understanding how we think permalink"></a>Understanding How We Think</h2>
<p>Writing an idea is always the result of two macro-steps. First, decide the point that we want want to make, and then put into words.</p>
<p>To understand how we can effectively share written ideas, we need to understand first how we formulate them in the first place.</p>
<p>Deciding the point you want to make is the result of a 5-step process.</p>
<ul>
<li><em>Unbundling</em> a concept</li>
<li><em>Noticing</em> something</li>
<li><em>Articulating</em>/<em>Developing</em> an idea</li>
<li><em>Re-Bundling</em>&nbsp;</li>
<li><em>Reframing</em></li>
</ul>
<p><img src="https://pulseasync.com/assets/generate-idea-thinking-process.png" alt="State diagram to share the 5-step process one use to generate an idea."></p>
<h3 id="unbundling-a-concept"><a href="#unbundling-a-concept" aria-label="unbundling a concept permalink"></a>Unbundling A Concept</h3>
<p>Every idea begins with an unbundling process. Unbundling is an act of exploration that leads to the decoupling of all the individual items of a certain subject.</p>
<p>Unbundling something doesn't imply a deep understanding of it. It's more a perception of full awareness.</p>
<p>In fact, you might not even know how every individual piece works, but you know they all exist in separate forms. No hidden parts.</p>
<h3 id="noticing-something"><a href="#noticing-something" aria-label="noticing something permalink"></a>Noticing Something</h3>
<p>Unbundling enhances our ability to observe, and this can lead us to noticing something. This can be a pattern, an insight, a novelty, or even a minor detail.</p>
<p>If <em>unbundling</em> is the flint, <em>noticing</em> is the spark that really makes the fire.</p>
<h3 id="articulatingdeveloping-an-idea"><a href="#articulatingdeveloping-an-idea" aria-label="articulatingdeveloping an idea permalink"></a>Articulating/Developing An Idea</h3>
<p>Only when we notice something can we start developing an idea. That's where the creative part begins. That's where you try to develop your initial cue into a fully formed idea.&nbsp;</p>
<p>For instance, if you noticed that something was unnecessary or too complicated, you might run a simplification process. If you noticed something was missing, you go through an addition or reinforcement process.</p>
<h3 id="re-bundling-and-reframing"><a href="#re-bundling-and-reframing" aria-label="re bundling and reframing permalink"></a>Re-bundling And Reframing</h3>
<p>Once you finish including your idea, you go through re-bundling. This is a reconstruction process. This is where you try to recompose a world that now contemplates your newly inserted idea.&nbsp;</p>
<p>Bundling is a fundamental part because it's where you can verify if the your new world still holds up. If not, that's a signal you need to put more work in the articulation phase or what you noticed didn't lead to anything meaningful at all.</p>
<p>If at the end of the re-bundling process your world does hold up, you go through a reframing process.</p>
<p>On paper, this seems to be a very logical and clear process, but in reality it's much more complicated as you constantly repeat these steps of of unbundling, editing your idea, and re-bundling until you find a viable path.</p>
<p><img src="https://pulseasync.com/assets/generate-idea-complexity.png" alt="The complex process of idea generation"></p>
<p>Now that you have an idea, you need to decide how to put it into words that you can share with others.</p>
<h2 id="understanding-how-we-write"><a href="#understanding-how-we-write" aria-label="understanding how we write permalink"></a>Understanding How We Write</h2>
<p>From a broader point, the single goal of writing is to get some information into someone's head.</p>
<p>Think about it. It's almost a simulation act.</p>
<p>You need to reproduce your reader's thinking process using your brain. And know how to build up your information in a way that feels logical and makes sense to them.</p>
<p>This process has very little to do with what you went through when you came up with the idea in the first place. In fact, forcing the reader through the exact same original path you took will have the opposite effect and create more confusion.</p>
<p>Here's how it often goes:</p>
<ol>
<li>You have an idea <em>x</em></li>
<li>You write down a set of words <em>m</em> that lead you to <em>x</em></li>
<li>Because of the pre-existing narrative that led you to the idea, you associate <em>m -&gt; x</em></li>
<li>When you proofread it, you mentally get it. Not because <em>m -&gt; x</em> but because of all the pre-existing associations.</li>
</ol>
<p>This is how most people write. And it's exactly why most people's writing sucks.</p>
<p>Not because they use too many passive forms or weak verbs (that doesn't help either), but because they aren't able to write from the reader's perspective. Most writings lacks the basic logical order and structure.</p>
<h2 id="what-is-good-business-writing"><a href="#what-is-good-business-writing" aria-label="what is good business writing permalink"></a>What is Good Business Writing</h2>
<p>Good business writing is a combination of two things:</p>
<ul>
<li>Information Context</li>
<li>Information Resolution</li>
</ul>
<h3 id="how-to-build-context-the-scqa-framework"><a href="#how-to-build-context-the-scqa-framework" aria-label="how to build context the scqa framework permalink"></a>How to build Context: The SCQA Framework</h3>
<p>Context is the "<em>you're here</em>" red arrow that you can see on almost any maps. Good information context helps the reader set the frame to understand what they're about to read next.</p>
<p>Shared context helps the participants make judgments calls using the same pair of lenses.</p>
<p>A lack of a shared understanding on the basic principles can easily result in a partial understanding or conflict on what follows.</p>
<p>What's the best way to build information context?</p>
<p>Barbara Minto, a McKinsey consultant in the 70s, solved this problem with what she called the <em>SCQA framework</em>.</p>
<p>She named this framework the <em>Situation — Complication — Question — Answer</em> framework. You can unpack more on this topic in her book “The Pyramid Principle”.</p>
<p>According to Minto, context is the result of these four sub-ingredients:</p>
<ol>
<li>Situation,</li>
<li>A Complication,</li>
<li>A Question,</li>
<li>... and an Answer.</li>
</ol>
<p>The <strong>Situation</strong> is a non-controversial statement on a subject that you know the reader will agree because it's something he already knows. By summarizing what he already knows, the situation establishes the relevance of the questions that your document is going to answer.&nbsp;</p>
<p>The <strong>Complication</strong> describes an alteration of a stable situation. Keep in mind, this alteration is purely fact-based. The Situation-Complication combination should lead the reader to an immediate question.</p>
<p>The <strong>Question</strong> represents an intuitive response to the complication. The best Situation-Complication scenario makes the question sound totally superfluous to state. The best questions aren't posed, they emerge.</p>
<p>The <strong>Answer</strong> is the summary of your main idea. Beware, it's the solution, not the explanation of it. Good answers are typically represented by 3/4 bullet points. No more.</p>
<p>If you squint at it, you realise that the SCQA framework turned out initial schema upside down.</p>
<p>Ideas comes up in a bottom-up fashion, but they need to be told top-down.</p>
<p>This is not how we think. But it's how we should write.</p>
<p><img src="https://pulseasync.com/assets/scqa-reversed-thinking-frmework.png" alt="SCQA reversed thinking framework"></p>
<p>Another interesting benefit of building information context using the SCQA framework is that once you've gotten the initial part out of the way, you can focus all your energy on making and supporting the case for why it's true.</p>
<h3 id="how-to-increase-resolution-whyhow-dialogues"><a href="#how-to-increase-resolution-whyhow-dialogues" aria-label="how to increase resolution whyhow dialogues permalink"></a>How to increase Resolution: Why/How Dialogues</h3>
<p>Ensuring you and your reader are in the same place before you lead him through your thinking is a necessary but non-sufficient condition. </p>
<p>Once he's aware of the gist of your main idea (Answer), you need to argue and support it. That's when you need to focus on information resolution.</p>
<p>Think of <em>information resolution</em> as the density level of details that you're able to provide to the reader. The bolder the answer, the higher resolution levels it requires.</p>
<p>If you gloss over key important passages, people will not follow your thinking and might have a partial understanding of the message.</p>
<p>How do you increase information resolution?</p>
<p>You support your initial <em>Answer</em> using the form of Why/How dialogues. Making an initial statement that the reader doesn't know will automatically raise a logical question in his mind. <em>How is that possible?</em> <em>Why do you say that?</em> In your following answers, you're likely to tell him other details he doesn't know and this will raise further questions that you're going to answer. And so on.</p>
<p>The author will continue to write, raising and answering questions, until he reaches a point at which he judges the reader will have no more logical questions.</p>
<p>The vertical relationship of a why/how dialogue helps capture the reader's attention. It permits you, as an author, to establish an inner dialog that will pull him with great interest through your reasoning. The reader will be forced to respond logically to your ideas.</p>
<p>As you can see we've not made a full circle. We're now in the (previously discussed) unbundling part.</p>
<h2 id="examples-of-good-business-writing"><a href="#examples-of-good-business-writing" aria-label="examples of good business writing permalink"></a>Examples of Good Business Writing</h2>
<p>Armed with our SCQA framework and the Why/How vertical development, let's look at the skeleton of some real examples.</p>

<p>It's one of the most common examples. common examples. A salesperson, after speaking with a customers, irrupts in the #product or #engineering Slack channels requesting the implementation of a given feature.</p>
<p>If you've been in this position, here's how you can Minto-ize an internal feature request for your product:</p>
<blockquote>
<p><em>Situation:</em>
We have never allowed customers to customize XYZ in order to keep complexity low.</p>
<p><em>Complication:</em>
However, competitor X has now shipped such a customization feature, and we’ve been losing deals because of that.</p>
<p><em>Questions:</em>
We now need to decide whether we want to allow some kind of customization as well.</p>
<p><em>Answer:</em>
[...]</p>
</blockquote>

<p>Directives are the most common internal memo. Executives write them to request something of someone.</p>
<blockquote>
<p><em>Situation:</em>&nbsp;
As you know we're repositioning product <em>x</em> for mid-sized enterprise. We need to teach you how to see <em>x</em> for organizations between 100 and 200 employees.</p>
<p><em>Complication:</em>
We've never sold to this type of customer before. Hence, we need to construct a new customer profile from scratch</p>
<p><em>Questions:</em> (How can we do the profile?)</p>
<p><em>Answer:</em>
We're going to host:</p>
<ol>
<li>A …</li></ol></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pulseasync.com/operators/share-written-ideas/">https://pulseasync.com/operators/share-written-ideas/</a></em></p>]]>
            </description>
            <link>https://pulseasync.com/operators/share-written-ideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034706</guid>
            <pubDate>Mon, 09 Nov 2020 13:44:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practical Introduction to Quantum Computing: Qubits to Quantum ML and Beyond]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25034692">thread link</a>) | @blopeur
<br/>
November 9, 2020 | https://indico.cern.ch/event/970903/ | <a href="https://web.archive.org/web/*/https://indico.cern.ch/event/970903/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div itemprop="description">
        <p><strong>*** The webcast is now over - The recording link is posted at the bottom of this page ***</strong></p>

<p><strong>General description of the course</strong></p>

<p><span><span>Quantum computing is one the most promising new trends in information processing. In this course, we will introduce from scratch the basic concepts of the quantum circuit model (qubits, gates and measures) and use them to study some of the most important quantum algorithms and protocols, including those that can be implemented with a few qubits (BB84, quantum teleportation, superdense coding...) as well as those that require multi-qubit systems (Deutsch-Jozsa, Grover, Shor..). We will also cover some of the most recent applications of quantum computing in the fields of optimization and simulation (with special emphasis on the use of quantum annealing, the quantum approximate optimization algorithm and the variational quantum eigensolver) and quantum machine learning (for instance, through the use of quantum support vector machines and quantum variational classifiers). We will also give examples of how these techniques can be used in chemistry simulations and high energy physics problems.</span></span></p>

<p><span><span>The focus of the course will be on the practical aspects of quantum computing and on the implementation of algorithms in quantum simulators and actual quantum computers (as the ones available on the IBM Quantum Experience and D-Wave Leap). No previous knowledge of quantum physics is required and, from the mathematical point of view, only a good command of basic linear algebra is assumed. Some familiarity with the python programming language would be helpful, but is not required either.&nbsp;</span></span></p>

<p>====</p>

<p><strong>Lecture 1: Introduction</strong></p>

<p><strong><span><span>What is quantum computing? Applications of quantum computing. Hardware and software for quantum computing. Elements of the quantum circuit model. Introduction to the IBM Quantum Experience</span></span></strong></p>

<p>===</p>

<p><strong>Biography of the speaker</strong></p>

<p><span><span>Elías F. Combarro holds degrees&nbsp;from the University of Oviedo (Spain) in both Mathematics (1997, award for second highest grades in the country) and Computer Science (2002, award for highest grades in the country). After some research stays at the Novosibirsk State University (Russia), he obtained a Ph.D. in Mathematics (Oviedo, 2001) with a dissertation on the properties of some computable predicates under the supervision of Prof. Andrey Morozov. Since 2009, Elías F. Combarro has been an associate professor at the Computer Science Department of the University of Oviedo. He has published more than 50 research papers in international&nbsp;journals on topics such as Computability Theory, Machine Learning, Fuzzy Measures and Computational Algebra. His current research focuses on the application Quantum Computing to algebraic, optimization and machine learning problems. From July 2020 he has been a Cooperation Associate at CERN openlab.</span></span></p>


    </div>
</div></div>]]>
            </description>
            <link>https://indico.cern.ch/event/970903/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034692</guid>
            <pubDate>Mon, 09 Nov 2020 13:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using “Virtio-Fs” on a Unikernel]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25034668">thread link</a>) | @ingve
<br/>
November 9, 2020 | https://www.qemu.org/2020/11/03/osv-virtio-fs/ | <a href="https://web.archive.org/web/*/https://www.qemu.org/2020/11/03/osv-virtio-fs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
		<div>
			<!-- Main -->
	<section>
		<header>
			
			<p>03 Nov 2020 — by Fotis Xenakis</p>
		</header>
		<p>This article provides an overview of <a href="https://virtio-fs.gitlab.io/">virtio-fs</a>,
a novel way for sharing the host file system with guests and
<a href="https://github.com/cloudius-systems/osv">OSv</a>, a specialized, lightweight
operating system (unikernel) for the cloud, as well as how these two fit
together.</p>

<h2 id="virtio-fs">virtio-fs</h2>

<p>Virtio-fs is a new host-guest shared filesystem, purpose-built for local file
system semantics and performance. To that end, it takes full advantage of the
host’s and the guest’s colocation on the same physical machine, unlike
network-based efforts, like virtio-9p.</p>

<p>As the name suggests, virtio-fs builds on virtio for providing an efficient
transport: it is included in the (currently draft, to become v1.2) virtio
<a href="https://github.com/oasis-tcs/virtio-spec">specification</a> as a new device. The
protocol used by the device is a slightly extended version of
<a href="https://github.com/libfuse/libfuse">FUSE</a>, providing a solid foundation for
all file system operations native on Linux. Implementation-wise, on the QEMU
side, it takes the approach of splitting between the guest interface (handled
by QEMU) and the host file system interface (the device “backend”). The latter
is handled by virtiofsd (“virtio-fs daemon”), running as a separate process,
utilizing the
<a href="https://www.qemu.org/docs/master/interop/vhost-user.html">vhost-user</a> protocol
to communicate with QEMU.</p>

<p>One prominent performance feature of virtio-fs is the DAX (Direct Access)
window. It’s a shared memory window between the host and the guest, exposed as
device memory (a PCI BAR) to the second. Upon request, the host (QEMU) maps file contents to the window for the guest to access directly. This bears performance
gains due to taking VMEXITs out of the read/write data path and bypassing the
guest page cache on Linux, while not counting against the VM’s memory (since
it’s just device memory, managed on the host).</p>

<p><img src="https://gitlab.com/virtio-fs/virtio-fs.gitlab.io/-/raw/master/architecture.svg" alt="virtio-fs DAX architecture"></p>

<p>Virtio-fs is under active development, with its community focussing on a pair of
device implementation in QEMU and device driver in Linux. Both components are
already available upstream in their initial iterations, while upstreaming
continues further e.g. with DAX window support.</p>

<h2 id="osv">OSv</h2>

<p>OSv is a <a href="https://en.wikipedia.org/wiki/Unikernel">unikernel</a> (framework). The
two defining characteristics of a unikernel are:</p>

<ul>
  <li><strong>Application-specialized</strong>: a unikernel is an executable machine image,
consisting of an application and supporting code (drivers, memory management,
runtime etc.) linked together, running in a single address space (typically
in guest “kernel mode”).</li>
  <li><strong>Library OS</strong>: each unikernel only contains the functionality mandated by its
application in terms of non-application code, i.e. no unused drivers, or even
whole subsystems (e.g. networking, if the application doesn’t use the
network).</li>
</ul>

<p>OSv in particular strives for binary compatibility with Linux, using a <a href="https://github.com/cloudius-systems/osv/wiki/Dynamic-Linker">dynamic
linker</a>. This means
that applications built for Linux should run as OSv unikernels without requiring
modifications or even rebuilding, at least most of the time. Of course, not the
whole Linux ABI is supported, with system calls like <code>fork()</code> and relatives
missing by design in all unikernels, which lack the notion of a process. Despite
this limitation, OSv is quite full featured, with full SMP support, virtual
memory, a virtual file system (and many filesystem implementations, including
ZFS) as well as a mature networking stack, based on the FreeBSD sources.</p>

<p>At this point, one is sure to wonder “Why bother with unikernels?”. The problem
they were originally
<a href="http://unikernel.org/files/2013-asplos-mirage.pdf">introduced</a> to solve is the
bloated software stack in modern cloud computing. Running general-purpose
operating systems as guests, typically for a single application/service, on top
of a hypervisor which already takes care of isolation and provides a standard
device model means duplication, as well as loss of efficiency. This is were
unikernels come in, trying to be just enough to support a single application
and as light-weight as possible, based on the assumption that they are executing
inside a VM. Below is an illustration of the comparison between
general-purpose OS, unikernels and containers (as another approach to the same
problem, for completeness).</p>

<p><img src="https://www.qemu.org/screenshots/2020-11-04-unikernel-vs-gpos.svg" alt="Unikernels vs GPOS vs containers"></p>

<h2 id="osv-meet-virtio-fs">OSv, meet virtio-fs</h2>

<p>As is apparent e.g. from the container world, it is very common for applications
running in isolated environments (such as containers, or unikernels even more
so) to require host file system access. Whereas containers sharing the host
kernel thus have an obvious, controlled path to the host file system, with
unikernels this has been more complex: all solutions were somewhat heavyweight,
requiring a network link or indirection through network protocols. Virtio-fs
then provided a significantly more attractive route: straight-forward mapping of
fs operations (via FUSE), reusing the existing virtio transport and decent
performance without high memory overhead.</p>

<p>The OSv community quickly identified the opportunity and came up with a
read-only implementation on its side, when executing under QEMU. This emphasized
being lightweight complexity-wise, while catering to many of its applications’
requirements (they are stateless, think e.g. serverless). Notably, it includes
support for the DAX window (even before that’s merged in upstream QEMU),
providing <a href="https://github.com/foxeng/diploma">excellent performance</a>, directly
rivalling that of its local (non-shared) counterparts such as ZFS and ROFS (an
OSv-specific read-only file system).</p>

<p>One central point is OSv’s support for booting from virtio-fs: this enables
deploying a modified version or a whole new application <strong>without rebuilding</strong>
the image, just by adjusting its root file system contents on the host. Last,
owing to the DAX window practically providing low-overhead access to the host’s
page cache, scalability is also expected to excel, with it being a common
concern due to the potentially high density of unikernels per host.</p>

<p>For example, to build the <code>cli</code> OSv image, bootable from virtio-fs, using the
core OSv <a href="https://github.com/cloudius-systems/osv#building-osv-kernel-and-creating-images">build
system</a>:</p>
<div><div><pre><code>scripts/build fs=virtiofs export=all image=cli
</code></pre></div></div>
<p>This results in a minimal image (just the initramfs), while the root fs contents
are placed in a directory on the host (<code>build/export</code> here, by default).</p>

<p><a href="https://github.com/cloudius-systems/osv#running-osv">Running</a> the above image
is just a step away (may want to use the virtio-fs development version of
<a href="https://gitlab.com/virtio-fs/qemu/-/tree/virtio-fs-dev">QEMU</a>, e.g. for DAX
window support):</p>
<div><div><pre><code>scripts/run.py --virtio-fs-tag=myfs --virtio-fs-dir=$(pwd)/build/export
</code></pre></div></div>
<p>This orchestrates running both virtiofsd and QEMU, using the contents of
<code>build/export</code> as the root file system. Any changes to this directory, directly
from the host will be visible in the guest without re-running the previous build
step.</p>

<h2 id="conclusion">Conclusion</h2>

<p>OSv has gained a prominent new feature, powered by virtio-fs and its QEMU
implementation. This allows efficient, lightweight and performant access to the
host’s file system, thanks to the native virtio transport, usage of the FUSE
protocol and the DAX window architecture. In turn, it enables use cases like
rapid unikernel reconfiguration.</p>

		<ul>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/storage/index.html">storage</a></li>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/virtio-fs/index.html">virtio-fs</a></li>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/unikernel/index.html">unikernel</a></li>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/osv/index.html">OSv</a></li>
		
		</ul>
	</section>

		</div>
	</div></div>]]>
            </description>
            <link>https://www.qemu.org/2020/11/03/osv-virtio-fs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034668</guid>
            <pubDate>Mon, 09 Nov 2020 13:40:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Which FinTech Investment Trends Are Popular and Why?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25034472">thread link</a>) | @cpepper
<br/>
November 9, 2020 | https://codeandpepper.com/fintech-investment-trends/ | <a href="https://web.archive.org/web/*/https://codeandpepper.com/fintech-investment-trends/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
<p>In business, good enough is often not enough. Many people are turning away from incumbent financial institutions because traditional banking can’t provide the level of services they are actively seeking. Meanwhile, FinTech startups introduce innovative service offerings almost every month. Investors keep their eyes open, they don’t want to miss a potential unicorn. Here’s a list of important FinTech investment trends to watch – maybe they’ll bring another industry star.</p>



<figure><ul><li><figure><amp-img width="864" height="450" src="https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why.jpg" alt="" data-id="14569" data-full-url="https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why.jpg" data-link="https://codeandpepper.com/?attachment_id=14569" srcset="https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why.jpg 864w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why-300x156.jpg 300w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why-768x400.jpg 768w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why-361x188.jpg 361w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why-192x100.jpg 192w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why-720x375.jpg 720w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why-432x225.jpg 432w" sizes="(max-width: 864px) 100vw, 864px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="864" height="450" src="https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why.jpg" alt="" srcset="https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why.jpg 864w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why-300x156.jpg 300w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why-768x400.jpg 768w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why-361x188.jpg 361w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why-192x100.jpg 192w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why-720x375.jpg 720w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why-432x225.jpg 432w" sizes="(max-width: 864px) 100vw, 864px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzQ1MCcgd2lkdGg9Jzg2NCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></figure></li></ul></figure>







<p>First, let’s take a look at the foundations of the industry. Phenomenons like <a href="https://codeandpepper.com/services/open-banking">open banking</a> or <a href="https://codeandpepper.com/services/insurance-insurtech-software-development">InsurTech</a> took both the financial sector and social media by storm. These new digital services are what people want and need in their daily activities. Being relevant is exactly what drives the growth of FinTech companies. Trends like Big Data improve customer relationships and give people personalized experience, expanding brands’ market reach.</p>



<p>The stakes are high. <a href="https://www.marketdataforecast.com/market-reports/fintech-market" target="_blank" rel="noreferrer noopener nofollow">According to Market Data Forecast</a>, the global financial technology market will reach the value of $305 billion by 2025. That’s a big pie and everyone wants their share. Tech solutions have the potential to improve the customer experience. They are also well-positioned for the application’s future growth. Companies like <a href="https://www.fintechmagazine.com/digital-payments/klarna-how-can-we-enrich-customer-experience">Klarna</a>, a FinTech payments giant, look for customer relationships to enhance the business. Especially now, when people stay at home and buy from home. Even more than before the pandemic. The market values such an approach – Klarna is currently worth over $10.5 billion.</p>



<p>How does it translate into FinTech sectors? The pandemic <a href="https://sifted.eu/articles/fintech-funding-data-corona" target="_blank" rel="noreferrer noopener nofollow">collapse of early 2020</a> will not slow down macro trends. <a href="https://pitchbook.com/news/reports/q2-2020-emerging-tech-research-fintech?utm_medium=nl-na&amp;utm_source=reports&amp;utm_campaign=q2-2020-emerging-tech-research-fintech" target="_blank" rel="noreferrer noopener nofollow">According to PitchBook</a>, European investors are confident that long-term tendencies will “broadly favor” the sector. Which trends and companies are getting traction and why?</p>



<h2 id="h-top-fintech-investment-trends">Top FinTech investment trends</h2>



<p>Traditional banking has much to think about. The trends below clearly show there’s no turning back from innovation. Consumers think that security and convenience brought by new financial products have changed their lives for the better. The mobile is the wallet, the social impact of satisfied customers is big. This is how it looks in practice.</p>



<h3 id="h-insurtech-is-on-the-rise">InsurTech is on the rise</h3>



<p>Four trends are shaping the <a href="https://codeandpepper.com/insurtech-industry-guide/">InsurTech</a> industry:</p>



<ul><li>human agents are replaced with artificial intelligence (AI) and machine learning</li><li>Big Data intelligence and Internet of Things (IoT) increase customer retention</li><li>increased use of blockchain help in better risk assessment</li><li>digital ecosystems drive revenue</li></ul>



<p>Companies in this sector vary dramatically. Investors pour their money in companies like <a href="https://www.threatinformer.com/" target="_blank" rel="noreferrer noopener nofollow">ThreatInformer</a>, a next level InsurTech providing risk intelligence to the industry. Such data-driven solutions are especially important in a world ruled by access to information. The startup combines threat data, security assessments, and environmental factors to help clients estimate insurance risks. On the other hand, we have more “traditional” InsurTech startups, like <a href="https://www.homelyfe.com/" target="_blank" rel="noreferrer noopener nofollow">Homelyfe</a>. The app lets users manage their policies in one place.</p>



<h3 id="h-online-payment-processing-still-challenging-traditional-banking">Online payment processing still challenging traditional banking</h3>



<p>There are many online payment processing platforms, yet investors still believe in them. They don’t seem to be afraid of market saturation. Many apps have unique features, targeting nations or even local problems. To the point, where traditional financial institutions can’t efficiently compete.</p>



<p>Companies like <a rel="noreferrer noopener nofollow" href="https://stripe.com/" target="_blank">Stripe</a>, <a rel="noreferrer noopener nofollow" href="https://www.adyen.com/" target="_blank">Adyen</a>, or the previously mentioned Klarna, help people manage their payments on-the-go. Investing in these companies means tapping into people’s spending potential. It also gives managers insights into customer behaviours, invaluable in doing business.</p>



<div><figure><amp-img width="864" height="450" src="https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2.jpg" alt="" srcset="https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2.jpg 864w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2-300x156.jpg 300w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2-768x400.jpg 768w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2-361x188.jpg 361w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2-192x100.jpg 192w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2-720x375.jpg 720w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2-432x225.jpg 432w" sizes="(max-width: 864px) 100vw, 864px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="864" height="450" src="https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2.jpg" alt="" srcset="https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2.jpg 864w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2-300x156.jpg 300w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2-768x400.jpg 768w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2-361x188.jpg 361w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2-192x100.jpg 192w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2-720x375.jpg 720w, https://codeandpepper.com/wp-content/uploads/2020/10/Which-FinTech-Investment-Trends-are-Popular-and-Why_2-432x225.jpg 432w" sizes="(max-width: 864px) 100vw, 864px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzQ1MCcgd2lkdGg9Jzg2NCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></figure></div>



<h3 id="h-peer-to-peer-lending-solutions-as-a-future-proof-fintech-investment">Peer-to-peer lending solutions as a future-proof FinTech investment</h3>



<p>One of the most powerful tools used by traditional banks is lending. However, their monopoly in that domain has been broken. FinTech loans are among the most interesting financial products in the eyes of investors. Not everyone is eligible for a bank loan but there are plenty of people with even small capital who will gladly help in time of need.</p>



<p>Connecting individuals or entrepreneurs with potential lenders is a social, financial, and technological phenomenon. Brands like <a href="https://www.lu.com/" target="_blank" rel="noreferrer noopener nofollow">Lufax</a>, <a href="https://www.prosper.com/" target="_blank" rel="noreferrer noopener nofollow">Prosper</a> or <a href="https://www.commonbond.co/" target="_blank" rel="noreferrer noopener nofollow">CommonBond</a> grow by making their offers tailored to specific groups. The latter thrives because it has an offer addressed exclusively to students – a demographic notorious for having money problems. Peer-to-peer payment solutions engage users and support communities, making them a perfect remedy for the times of uncertainty.</p>



<h3 id="h-fintech-investments-come-to-the-unbanked">FinTech investments come to the unbanked</h3>



<p>According to <a href="https://globalfindex.worldbank.org/" target="_blank" rel="noreferrer noopener nofollow">The World Bank report</a>, 1.7 billion people across the world don’t have access to any formal financial system. 60% of them simply don’t have enough money, 30% never felt like they needed a bank, 26% think of banking accounts as too expensive.</p>



<p>At the same time, there is a growing number of startups serving those who are considered too poor by traditional banking. <a href="https://www.planet-fintech.com/file/163178/" target="_blank" rel="noreferrer noopener nofollow">FinTech investments</a> are now made not only in the USA or London, the European FinTech capital. Latin America, Africa, Southeast Asia are full of companies that bring money to those who have very little. Companies like <a href="https://www.lenddo.com/" target="_blank" rel="noreferrer noopener nofollow">Lenddo</a> or <a href="https://www.ayannah.com/" target="_blank" rel="noreferrer noopener nofollow">Ayannah</a> efficiently activate people in emerging markets.</p>



<h3 id="h-bigger-investments-in-cybersecurity-solutions">Bigger investments in cybersecurity solutions</h3>



<p>Traditional financial institutions are shifting from making their own FinTech products into buying the existing ones. In fact, <a href="https://www.businessinsider.com/1-in-5-european-banks-would-buy-fintech-startups-2016-6?IR=T" target="_blank" rel="noreferrer noopener nofollow">one in five European banks would buy a FinTech startup</a>. Security, for some companies in the middle of the to-do list, is a must for big banks. That’s why the banking sector will look for solutions with an established security track record. Or at least those which can be easily turned into safe application.</p>



<h3 id="h-active-search-for-apps-with-potential-for-ecosystem-building">Active search for apps with potential for ecosystem building</h3>



<p>To effectively compete and meet customers’ expectations, many business owners decide to cooperate with various industries. Creating an <a href="https://codeandpepper.com/innovations-improving-fintech-customer-experience/">ecosystem of mutually beneficial applications</a>, drives added value for users. It also attracts investors. The more companies can offer, the more users they can attract and the more value they have in the eyes of people who want to invest.</p>



<p>The future of FinTech investment lies in applications that are platforms, not just solutions. Think of WeChat, the Chinese behemoth. It launched in 2011, allowing to send text and voice messages to family and friends. Local email market penetration was low, forcing the app owners to innovate. By 2015, <a href="https://www.wsj.com/articles/BL-CJB-28569" target="_blank" rel="noreferrer noopener nofollow">90% of Chinese Internet users were browsing the net on mobile</a>. Today, WeChat serves as a platform to pay for utilities, use city services, order movie tickets, and much more. You can pay for products and services, even support a favorite charity.</p>



<p>WeChat is for China what Facebook Messenger, Instagram, and Apple Pay are for the West. And much more. According to <a href="https://go.appannie.com/rs/071-QED-284/images/2001_State_of_Mobile_2020_Main_EN.pdf" target="_blank" rel="noreferrer noopener nofollow">an AppAnnie report</a>, the average number of installed mobile apps in 2020 is 40. At the same time, <a href="https://www.forbes.com/sites/blakemorgan/2019/05/02/when-it-comes-to-customer-engagement-loyalty-matters-at-citi/#6ca973fe7fb6" target="_blank" rel="noreferrer noopener nofollow">Citi reported</a> that 83% of consumers and 94% of millennials are more likely to participate in a loyalty program if it’s accessible on mobile.</p>



<p>Conclusions? The future digital economy will most likely favour cooperation between the FinTech industry and 3rd party apps. A feature-rich ecosystem is valuable for users and it brings revenue.</p>



<h2 id="h-fintech-investment-trends-are-clear">FinTech investment trends are clear</h2>



<p>If good enough is not enough, do more! FinTech investment trends are coming into focus, especially in the light of the COVID-19 pandemic. There are detailed guides on how to invest, written for example by <a href="https://www.investors.com/news/technology/fintech-companies-to-buy-and-watch" target="_blank" rel="noreferrer noopener nofollow">Investor’s Business Daily</a>. None of them, however, can prepare you for what really needs to be done.</p>



<p>Users’ trust is built on reliability. Outsourcing FinTech software development can save time and money, helping you build an app fit for the future. Financial products are valued for design, performance, and integrations. Need a boost for growth potential? <a href="https://codeandpepper.com/services/api-development/">Create a platform, not a solution</a>.</p>
          </div></div>]]>
            </description>
            <link>https://codeandpepper.com/fintech-investment-trends/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034472</guid>
            <pubDate>Mon, 09 Nov 2020 13:20:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benefits of an integrated eCommerce marketing platform]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25034333">thread link</a>) | @xxlcloudinc
<br/>
November 9, 2020 | https://codecoda.com/en/blog/entry/6-benefits-of-an-integrated-ecommerce-marketing-platform | <a href="https://web.archive.org/web/*/https://codecoda.com/en/blog/entry/6-benefits-of-an-integrated-ecommerce-marketing-platform">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description">
<p>Few technological advancements and innovations have affected the world of commerce as deeply as <strong>the advent of eCommerce</strong>. One cannot overstress the profound ease of doing business online, especially in an increasingly mobile-friendly digital era. In turn, this development has motivated brands and businesses to adapt their marketing strategies accordingly. Inevitably, many seem to have come to <em>the data-driven conclusion that an integrated eCommerce marketing platform is both necessary and lucrative.</em> </p>
<p>The most fundamental benefit of such a platform should be immediately obvious in this context. An <em>ever-growing, vast, tech-savvy, often international audience</em> should allure any brand or business. However, tapping into such a sizeable audience entails a notable practical burden, unprecedented for many. Fortunately, such platforms tackle this burden by <strong><a href="https://codecoda.com/en/blog/entry/ecommerce-guide-from-idea-to-a-working-online-solution">providing tailor-made solutions</a></strong> to each of the challenges at hand. However, to analyze such solutions in-depth, one would need to carefully examine <strong>the emerging challenges alongside the benefits such platforms offer</strong>.</p>
<h2>The benefits of an integrated eCommerce marketing platform</h2>
<p>Arguably, the most fundamental challenge that comes with such a volume of transactions is strictly practical; <strong>handling and processing transactions themselves</strong>. Concurrently, the need to handle back-end jobs remains, while their scope and intensity only increase. Furthermore, <em>such a volume of data can hamper marketing efforts due to fragmented data, and thus inhibit sales and growth.</em> To consolidate such challenges, one could identify them as the following core issues; </p>
<ul>
<li>Miscommunication between incoming orders and internal accounting systems </li>
<li>Siloed data which can hamper team/department cohesion   </li>
<li>Mismanagement of potential leads and engagement opportunities </li>
<li>Time mismanagement </li>
<li>Worse customer experience and service </li>
</ul>
<p>By definition, all of the aforementioned factors can have a visible adverse effect on any brand or business. <strong>Increased strain</strong>, especially for the less prepared, can range from mildly disorganizing to borderline catastrophic. Therefore, an integrated <strong><a href="https://codecoda.com/en/blog/entry/best-ecommerce-platforms-2020">eCommerce marketing platform</a></strong> can be an invaluable asset towards tackling these challenges and ensuring growth, simply because such platforms strive to tackle those same challenges. Most significantly, <em>they aim to let brands and businesses streamline their operations</em>, optimizing their time, and ultimately delivering a concise, enticing customer experience.</p>
<div>
<blockquote>
<p>If you do build a great experience, customers tell each other about that. Word of mouth is very powerful.</p>
</blockquote>

</div>
<p>The exact benefits of an integrated eCommerce marketing platform can be numerous and worth exploring individually and in-depth. In the interest of time and consolidated information, however, one should safely distill them down to <strong>6 key benefits</strong>.</p>
<div><div data-appear-animation="fadeInUpShorter" data-appear-animation-delay="200"><div><h4>Eliminating human errors and duplicate data entries</h4><div><p>The very first challenge of sustaining a vast ERP system for eCommerce ventures lies, expectedly, in <strong>human error</strong>. Processing large quantities of orders manually lends itself to oversights and mistakes such as the following;</p></div><ul>
<li>Duplicate data entries</li>
<li>Transposed numbers</li>
<li>Wrong or misspelled data entries</li>
<li>Lost orders</li>
</ul><p>While such mistakes may not incur immediately visible damage, their effect and quantity <em>only scale with size</em>. As one’s backlog expands, the room for such errors naturally increases as employees struggle to manage the added strain. Furthermore, potential mismanagement of data and orders can deteriorate brand loyalty and jeopardize growth in the context of eCommerce. Online avenues and retail sites offer public, visible customer reviews as a testament of quality – which can conversely amplify even the slightest imperfection.<br>As such, an integrated eCommerce marketing platform can overcome this challenge by <strong>automating data entry</strong>. It can process any volume of orders with the same efficiency and swiftness while providing a <em>nearly error-free process</em>. While it may not be absolutely infallible, as no software solutions truly are, it can certainly offer more confidence than manual data entry.</p>
</div></div><div data-appear-animation="fadeInUpShorter" data-appear-animation-delay="200"><div><h4>Automated order cycles and timely data updates</h4><div><p>By the same token, manual order cycles and data updates also offer room for error. Moreover, they become increasingly inefficient in terms of time investment on a scale. On both accounts, manually updating data can be <strong>inefficient, error-prone, and needlessly time-consuming</strong>. An integrated eCommerce marketing platform can address both through similar yet distinct functionalities.</p><p><b>An integrated eCommerce marketing platform can automate order cycles</b><br>Traditionally, sizeable volumes of orders may require manual management, <strong>exporting and importing them into back-end accounting systems</strong>. The massive potential volume of eCommerce orders can encumber employees regarding this task, slowing down order processing speed and shipping. In response, such platforms can automate this process and enable seamless data entry.</p><p><b>An integrated eCommerce marketing platform can update customer and inventory data in a timely manner</b><br>Similarly, manual data updates can present a challenge and entail errors. One needs to <em>update inventory after each incoming order, and customer data changes fairly regularly</em>. Needless to say, errors on either front can damage operations and one’s image. Furthermore, both of those processes can demand unreasonable effort and precious time that one could invest elsewhere. As such, these solutions address this challenge by automating data updates; <strong>bi-directional integration</strong> can keep inventory and customer data synchronized and up-to-date.</p></div>
</div></div><div data-appear-animation="fadeInUpShorter" data-appear-animation-delay="200"><div><h4>Data integration and customer segmentation</h4><div><p>Moreover, still on the subject of data management and analysis, <strong><a href="https://codecoda.com/en/blog/entry/things-to-consider-when-choosing-an-ecommerce-solution">data integration</a></strong> is an irreplaceable asset. <strong>Siloed data</strong> inaccessible by specific employees or departments can hamper internal cooperation and thus jeopardize the final customer experience. Additionally, fragmented data can prevent <strong>proper lead analysis</strong>, which can, in turn, lead to multiple shortcomings;</p></div><ul>
<li>Poor lead acquisition and profitability analysis</li>
<li>Disjointed marketing efforts</li>
<li>Lower ROI across marketing and sales endeavors</li>
</ul><p>An integrated platform can address such challenges by providing <strong>centralized, cross-channel data</strong> accessible by multiple devices. Additionally, it offers powerful insights into <strong>customer behavior, interaction history, and specific touchpoints</strong>. Thus, brands and businesses can use such data to segment customers according to their demographics and other characteristics, behavior, and profitability. In turn, they can provide highly personalized marketing campaigns and purchase funnels, <em>which yield significantly better results.</em></p>
</div></div><div data-appear-animation="fadeInUpShorter" data-appear-animation-delay="200"><div><h4>Improved customer experience and customer service</h4><div><p>With the aforementioned benefits of consolidated data and optimized internal cooperation, another benefit of an integrated eCommerce marketing platform lies in <strong>customer satisfaction</strong>. In the digital age, customers expect a seamless experience and impeccable customer support. A consolidated, detailed database can facilitate both to a significant degree. </p><p>In terms of customer service, <strong>swift access to customer interaction history</strong> and past inquiries can expedite the process. Common and frequent inquiries can be identified more easily, and the appropriate agents for each incoming communication can be notified more effectively. By the same token, such a trove of valuable, actionable data can significantly <strong>improve customer experience</strong>. Consider the following data-driven initiatives;</p></div><ul>
<li>Optimal lead acquisition and conversion through well-timed communication </li>
<li>An increased volume of user-generated content, such as public comments and reviews, through post-purchase requests </li>
<li>More engagement and loyalty incentives, such as tailored content, loyalty points programs, and referrals </li>
</ul><p>An integrated eCommerce marketing platform can facilitate the above, and more, to <strong>holistically improve operations</strong>. In turn, such efforts can unclog the back-end of any brand or business, and by extension, improve the customers’ final experience.</p>
</div></div>
<div data-appear-animation="fadeInUpShorter" data-appear-animation-delay="200"><div><h4>Reduced operational costs</h4><p>Furthermore, <strong>automated accounting processes</strong> can help reduce operational costs. Eliminating human error can be beneficial by itself, as outlined above, <em>but it also has the byproduct of reducing labor costs</em>. As such, fewer employees and administrators need to take up the burden of manual data entry and management.<br>Simultaneously, outside of accounting automation, <strong>data-driven choices can reduce marketing costs</strong> as well. With more data in hand to inform focused marketing decisions, one can reduce the costs of misplaced or mismanaged marketing efforts.</p>
</div></div>
<div data-appear-animation="fadeInUpShorter" data-appear-animation-delay="200"><div><h4>Time efficiency</h4><div><p>Lastly, the data, automation, and overall operational efficiency that an integrated eCommerce marketing platform can offer can only conclude with <strong>time efficiency</strong>. Time is a vital, valuable resource that can dictate growth rates and even sustainability. From reducing the administrative burden of accounting to streamlining data entry and collection, automation can indeed streamline one’s time investments.</p><p>In turn, time saved from redundant, automatable tasks can be invested in more productive activities, such as <strong>producing high-converting marketing content</strong>. Lead analysis can highlight the most valuable marketing platforms, content types, and lead generation strategies for one’s intended audience – <em>equally time-intensive but arguably far more productive tasks to focus on.</em></p></div>
</div></div>

</div>
<h2>Beyond an integrated eCommerce marketing platform: business software solutions</h2>
<p>Finally, it is equally noteworthy that <strong>further business software options</strong> also exist. As long as one can guarantee integration, such options are not mutually exclusive; rather, they can function as complementary assets. <strong>Customer relationship management (CRM)</strong> software is likely among the most prominent holistic solutions, but various business software solutions can handle different vital tasks; </p>
<ul>
<li>Word and spreadsheet processing software </li>
<li>Asset management software </li>
<li>Accounting, billing, and payroll software </li>
<li>Internal communication software </li>
</ul>
<p>All …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codecoda.com/en/blog/entry/6-benefits-of-an-integrated-ecommerce-marketing-platform">https://codecoda.com/en/blog/entry/6-benefits-of-an-integrated-ecommerce-marketing-platform</a></em></p>]]>
            </description>
            <link>https://codecoda.com/en/blog/entry/6-benefits-of-an-integrated-ecommerce-marketing-platform</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034333</guid>
            <pubDate>Mon, 09 Nov 2020 13:04:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Engineering Manager Event Loop (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25034254">thread link</a>) | @mooreds
<br/>
November 9, 2020 | https://www.chriseigner.com/engineering-manager-event-loop/ | <a href="https://web.archive.org/web/*/https://www.chriseigner.com/engineering-manager-event-loop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
	<article>
		<div>

			<section>
				<div><p>In prepping for a new Engineering Manager role I'll be starting in the next several weeks, I stumbled on a great video featuring <a href="https://twitter.com/dloft">David Loftesness</a> (former Director of Eng at Twitter, now at eero) talking about the transition from Engineer to Manager.</p>
<p>I liked this matrix enough that I turned it into a downloadable PDF for other folks.</p>
<p><img src="https://s3-us-west-2.amazonaws.com/chris-eigner-site/2018/10/Screen-Shot-2018-10-24-at-5.37.09-PM.png" alt="Screen-Shot-2018-10-24-at-5.37.09-PM"></p>
<p><a href="https://www.dropbox.com/s/b35bm43aecdb9cu/Engineering%20Manager%20Event%20Loop.pdf?dl=0">Click the link to download</a></p>
<p>Source: <a href="https://www.youtube.com/watch?v=qaHEy1I2M5Q">https://www.youtube.com/watch?v=qaHEy1I2M5Q</a></p>
</div>
			</section>

			<section>

				

				

				

						

			</section>


			<section>
				<a id="show-disqus">Show Comments</a>
			    
			</section>

            <section>
                <form method="post" action="/subscribe/">
    

    
    
    


</form>


                <p>Get the latest posts delivered right to your inbox.</p>
            </section>

			


		</div>
	</article>
</div></div>]]>
            </description>
            <link>https://www.chriseigner.com/engineering-manager-event-loop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034254</guid>
            <pubDate>Mon, 09 Nov 2020 12:57:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Cyrillic orthography for the Polish language]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25034182">thread link</a>) | @keiferski
<br/>
November 9, 2020 | http://steen.free.fr/cyrpol/index.html | <a href="https://web.archive.org/web/*/http://steen.free.fr/cyrpol/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<!---------------- Header ------------------->





<!---------------- Body ------------------->



<p><small><i>See also: </i> <a href="http://steen.free.fr/interslavic/index.html">Interslavic</a>, <a href="http://steen.free.fr/wenedyk/index.html">Wenedyk</a>, <a href="http://steen.free.fr/poilschi/index.html">Poilschi</a></small></p>

<a name="introduction"></a>

<h2>Ortografia cyrylicka dla języka polskiego</h2>
<h2>A Cyrillic orthography for the Polish language</h2>

<p><big>E</big>ver wondered what Polish would look like if it were written in Cyrillic? Perhaps you have. Or not. In any case, I have. That's what happens when you spend half of your life working on language projects that one way or another are related to Polish or the Slavic languages in general. Toying around with Polish, Slavic, as well as with several Slavic orthographies, it is hard not to think about the possibilities of a Cyrillic orthography for Polish.</p>

<p>Many people have argued that Cyrillic would be unsuitable for Polish. I disagree with that opinion. Granted, Polish phonology differs from that of the other Slavic languages in several ways, but these two facts remain: Polish is a completely Slavic language by any standard, and Cyrillic, unlike the Latin alphabet, was made especially to fit Cyrillic phonology, and therefore is perfectly suited for it. Therefore, I am convinced that Polish and Cyrillic are a perfect match. Much more so, in fact, than Polish and the Latin alphabet. Latin orthographies of Slavic languages always have one of the following two disadvantages: either they are full of diacritical marks, or they look horribly like English or another Western language. Slovene manages best, but still has <b>š</b>, <b>ž</b> and <b>č</b>. Other languages have more of those babies. Polish orthography has managed to avoid hačeks, but has a whole bunch of other diacritics instead: <b>ą</b>, <b>ę</b>, <b>ł</b>, <b>ż</b>, <b>ć</b>, <b>ń</b>, <b>ó</b>, <b>ś</b>, <b>ź</b>. Besides, Polish in addition tends to favour digraphs like <b>sz</b> and <b>ie</b>, so Polish words tend to be appear longer than they actually are.</p>

<p>Now, I am quite fond of Polish orthography, and therefore my Cyrillic orthography of Polish should by no means be treated as a serious proposal to replace Polish orthography. If anyone would ever make such a proposal, I would be the first to stand up against it. This project, therefore, is primarily a thought experiment, my answer to the question if such an orthography would be possible at all.</p>

<p>The idea, by the way, is not new at all. If we have to believe Wikipedia, Russia's czar Nikolay I intended to cyrillify Polish in the mid-19th century as a means for russification, although at last nothing came of his plans. Here is a sample:</p>

<table><tbody><tr><td>
<div><p>Поврóтъ Таты, <i>пр̌езъ А. Мицкевича</i></p><p>
Пóйдзьце о дзятки, пóйдзьце вшистке разэм<br>
За място, подъ слупъ на взгóрэкъ,<br>
Тамъ пр̌едъ цудовнымъ клęкнийце образэмъ,<br>
Побожне змóвце пацёрэкъ.</p><p>
Тато не враца ранки и вечоры<br>
Вэ Лзах го чекамъ и трводзэ;<br>
Розлялы р̌еки, пэлнэ звер̌а боры,<br>
И пэлно збóйцóвъ на дродзэ;-</p></div>
</td><td>
<div><p>Слышąцъ то дзятки бегнą вшистке разэмъ<br>
За място подъ слупъ на взгóрэкъ,<br>
Тамъ пр̌едъ цудовнымъ клęкая̨ образемъ,<br>
И зачиная̨ пацёрэкъ.</p><p>
Цалуя̨ земę, потэмъ въ Имę Ойца,<br>
Сына и Духа свęтэго,<br>
Бąдзь похвалёна пр̌енайсьвęтша Трóйца<br>
Тэразъ и часу вшелькего.</p><p>
(...)</p></div></td></tr></tbody></table>

<p>A few pecularities in this text deserve our attention:
</p><ul>
<li>the use of the letter <b>р̌</b> for Polish <b>rz</b>;
</li><li>the hard sign <b>ъ</b> at the end of many words (a feature common in prerevolutionary Russian);
</li><li>the fact that Polish <b>ó</b> remains untouched;
</li><li>this orthography inherits the Polish ogonek and adds it to Cyrillic letters;
</li><li>the use of <b>ць</b> and <b>дзь</b> where Polish has <b>ć</b> and <b>dź</b>, a feature also present in contemporary Belarusian.
</li></ul>

<p>My own Cyrillic orthography for Polish is largely based on the same premises, but there are a few differences as well, which I will describe below. By the way, it should be noted that the transcription quoted above is not the only attempt at a Cyrillic alphabet for Polish. Several people have played with the idea, seriously or less seriously. An interesting example is <a href="http://varpho.livejournal.com/2006/11/17/">Jusowica (Юсовица)</a>, created by Szymon Pawlas.</p>

<hr>

<p><big>T</big>he biggest problem related with the Cyrillisation of Polish are sounds that do not exist in other languages, nor do they correspond closely with anything else that exist in them: the nasal vowels <b>ą</b> and <b>ę</b>. The 19th century Russian solution is in fact a pretty funny one: it simply teleports the ogonek to Cyrillic, thus producing four characters that have never seen before in Cyrillic: <b>а̨</b>, <b>э̨</b>, <b>я̨</b> and <b>е̨</b> (the latter two representing <b>ją</b> and <b>ję</b> respectively). A funny solution indeed! And an unnecessary one to that, because Old Church Slavonic has precisely four Cyrillic characters for exactly these four sounds: <b>ѫ</b>, <b>ѧ</b>, <b>ѭ</b> and <b>ѩ</b>. True, they are uncommon, because the only living Slavic language that preserved these sounds is Polish, a language that happens to be written in Latin alphabet. But since these letters are around, why shouldn't we simply use them? After all, they exist, and are indefinitely more Cyrillic than Cyrillic letters with ogoneks beneath them. Besides, the choice for <b>а̨</b> and <b>я̨</b> is equally unlogical as the Polish letter <b>ą</b> itself, since it is pronounced as nasalised <b>o</b>; it is not for nothing that the Latin transcription of Old Church Slavonic uses <b>ǫ</b>.</p>

<p>Another specifically Polish letter is the <b>ó</b>, pronounced as [u] (its Czech equivalent is <b>ů</b>). The transcription mentioned above conveniently keeps it. But why would we? It has no pronunciation of its own; the only thing that distinguishes it from <b>u</b> is that it alternates with <b>o</b>. Incidentally, mixing up those two is the most common spelling mistake in Polish. As far as I am concerned, there is no reason to keep it. Since <i>miasto</i> alternates with <i>mieście</i> (and not with <i>miæście</i> or something), why can't <i>grud</i> alternate with <i>grodzie</i>? So let's be bold and use <b>у</b> instead.</p>

<p>The characters <b>ć</b> and <b>dź</b> could of course be rendered like Belarusian (and in a way, Polish) does, by using <b>ць</b> and <b>дзь</b>, but I'd much prefer <b>ть</b> and <b>дь</b>. Etymologically speaking, this is more correct; after all <b>ć/dź</b> are the softened equivalents of <b>t/d</b>, not of <b>c/dz</b>. Sequences like <b>ti</b> and <b>di</b> are rare in Polish and occur only in foreign words. In these rare cases, we could write <i>радио</i> and <i>тиара</i> (a Pole will know that they are to be read as <i>radio</i> and <i>tiara</i> and not like <i>radzio</i> or <i>ciara</i>). Or, if we want to be really sure that the <b>t</b> will not be softened in these cases, we could use the hard sign and write <i>радъио</i> and <i>тъиара</i>.<br>
Using <b>ть</b>/<b>дь</b> instead of <b>ць</b>/<b>дзь</b> has one more advantage: now at least will not have to worry about the sequence <b>cja</b>, which is unambiguously rendered as <b>ця</b>.</p>

<p>Same goes for the digraphy <b>rz</b>, which in Polish is pronounced like <b>ż</b>. Another common source of spelling errors. Yet, I wouldn't propose transcribing it to <b>ж</b>, for the same etymological reasons: <b>rz</b> comes from softened <b>r</b>, while <b>ż</b> comes from softened <b>g</b>. The fact that it sounds very different does not change that fact. Therefore, we simply use <b>рь</b> (and not this weird creation from the 19th century, <b>р̌</b>). Just like <b>ti</b> and <b>di</b>, <b>ri</b> is a rare sequence in Polish that occurs only in foreign words, so I propose the same solution for it as well.</p>

<p>And then we have the letter <b>e</b>. Because in Polish palatalising <b>e</b> is way more numerous than its non-palatalising equivalent, we will use Cyrillic <b>e</b> for the former (usually rendered as <b>je</b> or <b>ie</b>) and <b>э</b> for the latter. This is also what the 19th century version does.</p>

<p>The choice for other Cyrillic letters is merely a matter of picking an option. For example, how do we represent <b>i</b> and <b>y</b>? Do we follow the Russian model and pick <b>и/ы</b> or do we prefer the Ukrainian model and pick <b>і/и</b>? Both are possible, but I've decided to follow the Russian model. Also, when preceded by <b>cz</b>, <b>sz</b> or <b>ż</b> we write <b>и</b> instead of <b>ы</b> – just like Russian does. Again, a matter of etymology.</p>

<p>So, let's see now what Cyrylica Polska looks like.</p>

<a name="alphabet"><hr></a><h2>Alphabet</h2>

<p><big>C</big>yrylica Polska has 37 letters. Exactly the same as the 33 letters of the Russian alphabet, with four additional characters for the nasals:</p>

<p><p><b><span size="+1">А Б В Г Д Е Ë Ж З И Й К Л М Н О П Р С Т У Ф Х Ц Ч Ш Щ Ъ Ы Ь Э Ю Я Ѧ Ѫ Ѩ Ѭ</span></b></p></p>

<a name="vowels"><hr></a><h2>Vowels</h2>

<p><big>E</big>very vowel has a hardening and a softening version. Both can occur in two possitions: either it follows a consonant, or it doesn't (in that case it is either word-initial or after another vowel). In Polish orthography, when a softening vowel follows a consonant, it is preceded by <b>i</b>, unless the consonant in question is inherently soft. In other positions this vowel is preceded by <b>j</b>. The only exceptions are <b>i</b>, which is softening by definition, and <b>y</b>, which is never softening. <br>
Just like <b>i</b> and <b>y</b> form a pair, in Cyrillic all vowels come in pairs, as you can see in the table below:</p>

<p><table><colgroup><col><col><col><col>
</colgroup><tbody><tr><th colspan="2">Latin</th><th colspan="2">Cyrylica</th></tr>
<tr><th> <i>hard</i> </th><th> <i>soft</i> </th><th> <i>hard</i> </th><th> <i>soft</i> </th></tr>
<tr><td>	a	</td><td>	ia/ja		</td><td>	а	</td><td>	я	</td></tr>
<tr><td>	e	</td><td>	ie/je		</td><td>	э	</td><td>	е	</td></tr>
<tr><td>	y	</td><td>	i		</td><td>	ы	</td><td>	и	</td></tr>
<tr><td>	o	</td><td>	io/jo		</td><td>	о	</td><td>	ë	</td></tr>
<tr><td>	ó<br>u	</td><td>	ió/jó<br>iu/ju	</td><td>	у	</td><td>	ю	</td></tr>
<tr><td>	ą	</td><td>	ią/ją		</td><td>	ѫ	</td><td>	ѭ	</td></tr>
<tr><td>	ę	</td><td>	ię/ję		</td><td>	ѧ	</td><td>	ѩ	</td></tr>
</tbody></table></p>

<a name="consonants"><hr></a><h2>Consonants</h2>

<p><big>N</big>ow that the question of palatalised vs. non-palalalised consonant has been resolved by the vowels that follow them, the consonants have suddenly become very simple to handle. Here goes:</p>

<p><table><tbody><tr><td>
<table><colgroup><col width="40%"><col width="60%">
</colgroup><tbody><tr><th>Latin</th><th>Cyrylica</th></tr>
<tr><td>	p		</td><td>	п	</td></tr>
<tr><td>	b		</td><td>	б	</td></tr>
<tr><td>	f		</td><td>	ф	</td></tr>
<tr><td>	w		</td><td>	в	</td></tr>
<tr><td>	t, ć		</td><td>	т	</td></tr>
<tr><td>	d, dź		</td><td>	д	</td></tr>
<tr><td>	s, ś		</td><td>	с	</td></tr>
<tr><td>	z, ź		</td><td>	з	</td></tr>
<tr><td>	k		</td><td>	к	</td></tr>
<tr><td>	g		</td><td>	г	</td></tr>
<tr><td>	ch<br>h		</td><td>	х	</td></tr>
</tbody></table>
</td><td>
<table><colgroup><col width="40%"><col width="60%">
</colgroup><tbody><tr><th>Latin</th><th>Cyrylica</th></tr>
<tr><td>	sz		</td><td>	ш	</td></tr>
<tr><td>	ż		</td><td>	ж	</td></tr>
<tr><td>	cz		</td><td>	ч	</td></tr>
<tr><td>	szcz		</td><td>	щ	</td></tr>
<tr><td>	c		</td><td>	ц	</td></tr>
<tr><td>	m		</td><td>	м	</td></tr>
<tr><td>	n		</td><td>	н	</td></tr>
<tr><td>	ł, l		</td><td>	л	</td></tr>
<tr><td>	r, rz		</td><td>	р	</td></tr>
<tr><td>	j		</td><td>	й	</td></tr>
<tr><td>	ь		</td><td>	soft sign	</td></tr>
<tr><td>	ъ		</td><td>	hard sign	</td></tr>
</tbody></table>
</td></tr></tbody></table></p>

<p>A few notes:
</p><ul>
<li>Most consonants can be soft (palatalised) or hard. Whether a Cyrillic <b>д</b> should be read as <b>d</b> or <b>dź</b> is decided by the consonant that follows it: <b>дэ</b> should be read as <b>de</b>, <b>де</b> should be read as <b>dzie</b>.
</li><li>If a soft consonant is not followed by a vowel, i.e. when it is word- or syllable-final, it is followed by the soft sign: <b>bat</b> becomes <b>бат</b>, <b>bać</b> becomes <b>бать</b>.
</li><li>In reality, the soft sign will occur only after <b>т</b>, <b>д</b>, <b>н</b>, <b>л</b>, and <b>р</b>. However, in a few cases it can be placed after another consonant as well, although that wouldn't affect pronunciation. For example, take these two Polish cities: Kraków and Wrocław. When declined, the former has a hard <b>w</b>, the latter a soft <b>w</b>, and so their genitives are <i>Krakowa</i> and <i>Wrocławia</i> respectively. In Cyrillic, we could easily write <b>Вроцлавь</b> for "Wrocław", to make this fact predictable.
</li><li>Most consonant clusers as palatalised as a whole, and only in a few cases consonants in such a cluster are palatalised individually. Therefore, <b>śmiałość</b> is written <b>смялость</b>, and not <b>сьмялосьть</b>.
</li><li>The consonant clusters <b>śr</b> and <b>źr</b> (historically from <i>ser-/zer- &gt; srze-/zrze-</i>, in some dialects <i>st…</i></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://steen.free.fr/cyrpol/index.html">http://steen.free.fr/cyrpol/index.html</a></em></p>]]>
            </description>
            <link>http://steen.free.fr/cyrpol/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034182</guid>
            <pubDate>Mon, 09 Nov 2020 12:49:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing Maslow's Hierarchy of Needs (1999) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25034104">thread link</a>) | @throw0101a
<br/>
November 9, 2020 | https://www.miqols.org/howb/wp-content/uploads/2016/06/Hagerty-M._Maslows-Needs-Hierarchy-Natl-QOL_1998.pdf | <a href="https://web.archive.org/web/*/https://www.miqols.org/howb/wp-content/uploads/2016/06/Hagerty-M._Maslows-Needs-Hierarchy-Natl-QOL_1998.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.miqols.org/howb/wp-content/uploads/2016/06/Hagerty-M._Maslows-Needs-Hierarchy-Natl-QOL_1998.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034104</guid>
            <pubDate>Mon, 09 Nov 2020 12:39:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Urgency Illusion: How to stay present when big things happen in the world]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25034043">thread link</a>) | @LeonW
<br/>
November 9, 2020 | https://leowid.com/the-urgency-illusion-how-to-stay-present-when-big-things-happen-in-the-world/ | <a href="https://web.archive.org/web/*/https://leowid.com/the-urgency-illusion-how-to-stay-present-when-big-things-happen-in-the-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <header>    
                
            </header>

            <section>
            <div>
                <div><p>Last week I felt way more on edge than usual. There were new lockdown restrictions here in Austria due to COVID, the US elections kept me checking the news every few minutes and a terrorist attack shook up the country. My belly was tight and the world felt gray. Quickly, I felt preoccupied with so many things at once.</p>
<p>My experience is that when events like these happen, I can feel an urge to drop everything and somehow get involved and do things related to these events. Or to fall into apathy. Some of that feels good, yet often the intention it’s coming from is one of my underlying fear, anger, hatred, or sadness. I witness this in others often too. The more I reflect on this, the more it becomes clear to me that this is usually a dead-end. The more helpful way forward seems to be to attend to my emotions and state of being first, before I’m doing anything with it.</p>
<p>Hard, yet simple. Especially when so much is coming at us all at once.</p>
<h2>Being touched, but not led astray</h2>
<p>My friend Matthias told me recently on a hike through the forest, how he spent some time meditating on the terrorist attacks. His intention was to see the causes and conditions that led to it, casting a net as wide as possible. To me, this was a great example of letting ourselves be touched by current events, but not led astray. I would illustrate it like this:</p>
<p><img loading="lazy" src="https://leowid.com/wp-content/uploads/2020/11/ideas-8.jpg" alt="" width="2157" height="1668" srcset="https://leowid.com/wp-content/uploads/2020/11/ideas-8.jpg 2157w, https://leowid.com/wp-content/uploads/2020/11/ideas-8-300x232.jpg 300w, https://leowid.com/wp-content/uploads/2020/11/ideas-8-1024x792.jpg 1024w, https://leowid.com/wp-content/uploads/2020/11/ideas-8-768x594.jpg 768w, https://leowid.com/wp-content/uploads/2020/11/ideas-8-1536x1188.jpg 1536w, https://leowid.com/wp-content/uploads/2020/11/ideas-8-2048x1584.jpg 2048w" sizes="(max-width: 2157px) 100vw, 2157px"></p>
<p>The patterns I see the most and know well from myself, that I believe aren’t very helpful are two extreme reactions to current events:</p>
<ul>
<li><strong>apathy or “I don’t care…”</strong>: I simply carry on with my life, pretending that nothing happened or ignoring any major current events that have shaken up the world. This tends to keep me focused, but also makes my work and attention kind of lifeless, apathetic, and overall feel disconnected from my own intentions and dreams.</li>
<li><strong>flooded or “OMG, drop everything &amp; let’s do something!”</strong>: Here I have such a strong reaction that I want to take to the streets immediately, express my anger, hurt, sadness, and pain in the hopes that it will improve the situation. I feel reactive and righteous that I’m doing something about the situation.</li>
</ul>
<p>I believe that neither of these reactions helps us create the life and world that we ultimately want to see. And I think there’s a middle way, that uses the wisdom of both of these more extreme directions:</p>
<ul>
<li><strong>Care</strong>: When there is a major external event after we’ve gotten to safety, whether it’s from disease, attack, or something else, we first need care. By care, I mean our ability to tend to the emotional and inner states that have been evoked from the event. Tending to our anger, hurt, pain, feeling our sadness, tears, and frustration. This can take some time and the more support we have to feel through these elements of life, the more enjoyable this part can be for us.</li>
<li><strong>Integration with the life you want</strong>: Once the big emotions have settled, we can turn our attention to integration and meaning-making. What does it mean that we have experienced this? How does this connect with our bigger intention of living the life we want? An example from my own life is that through plenty of reflection on the coronavirus crisis and the amount of physical distancing and disconnection has birthed a new idea of a product to help us reconnect in a meaningful way, even when we’re not in the same room together. I’ve deeply enjoyed working on this the last weeks, it doesn’t feel reactive, yet it seems to be aligned with what is happening in the wider world and my dream of creating more presence and aliveness for myself and the people I meet.</li>
</ul>
<h2>Letting the urgency illusion pass and acting with power</h2>
<p>As the urgency illusion passes, there comes a window for all of us where we can be present to what happened and at the same time have enough space inside for ourselves and our dreams. This is the sweet spot, where we can make useful sense of ourselves and the world around us.</p>
<p>If you’re stuck along the journey towards integration right now, here’re some questions that you might find helpful to journal with:</p>
<ul>
<li><strong>Care-questions</strong>: What needs to be tended to on the inside? How are you doing? What level of care would support you the most right now?</li>
<li><strong>Integration-questions</strong>: What are the 3 most important values for you to live into in this life? Where is the overlap between those and what happened in the world? How can you move forward in integrity with what happened, without throwing everything overboard?</li>
</ul>
<p>From there, see which actions naturally arise for you as you give yourself space and time to let everything integrate.</p>
<p>Whatever you’re going through, keep going, sending love and care your way!</p>
</div>
            </div>
        </section><section>
                <div>
                    <p><img data-src="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg" data-srcset="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg 400w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-300x300.jpg 300w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-150x150.jpg 150w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-180x180.jpg 180w" data-sizes="(max-width: 100px) 100vw, 100px" alt="" src="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg" srcset="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg 400w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-300x300.jpg 300w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-150x150.jpg 150w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-180x180.jpg 180w">
                        <span>Leo Widrich</span>
                        <span>Leo Widrich coaches extraordinary people. In his previous life, he co-founded Buffer, a $20m+ revenue software company. He also lived in Buddhist monasteries for close to two years, trained as a trauma therapist and now lives in Vienna near the forest. He tweets <a href="https://twitter.com/LeoWid">@leowid</a>. To learn about working with him, <a href="https://leowid.com/working-with-me/">go here</a>.</span>
                    </p>
                </div>
            </section><section>
        <div>
            <div><h3>Receive my most vulnerable and powerful lessons from meeting life.</h3><p>Add your details below for my weekly newsletter.</p></div>
        </div>
    </section>
        </div></div>]]>
            </description>
            <link>https://leowid.com/the-urgency-illusion-how-to-stay-present-when-big-things-happen-in-the-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034043</guid>
            <pubDate>Mon, 09 Nov 2020 12:29:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When remote work doesn't cut it]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25034037">thread link</a>) | @FlyingSnake
<br/>
November 9, 2020 | https://samkhawase.com/blog/remote-work/ | <a href="https://web.archive.org/web/*/https://samkhawase.com/blog/remote-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>The COVID-19 crisis, while disrupting the global world unlike anything before, has opened up an unexpected window to remote work. Nearly all major<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>tech<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> giants<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> have<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> allowed their workers to do home office. Many people are considering this as a sign of the advent of <strong>Work 2.0</strong>, where physical offices spaces will be irrelevant, and people can work from their cozy dens. There are however significant challenges in adoption of generalized remote work and things will be back as usual once the COVID-19 ends.</p>
<p>The <strong>challenges surrounding remote work outweigh it’s promises</strong>. Not every company is a FAANG, and companies will struggle to transition given their limited resources.</p>
<h2 id="regulations">Regulations</h2>
<p>The most significant hurdle in hiring a global remote team is <strong>regulation</strong>. Labor regulations are wildly different amongst countries, and could be cumbersome for some companies. Some major hurdles include:</p>
<ul>
<li>
<p><strong>Payroll taxes</strong>, retirement bonuses: Germany has rentenversicherung, sozialversicherung whereas USA has 401k contributions. Can a German company afford to <strong>setup payroll</strong> taxes for a remote workers hired from India, Chile or US? Or will it lead to worker abuse through <strong>laissez-faire abuse</strong> through freelance contracts?</p>
</li>
<li>
<p><strong>Notice periods</strong>: Europeans (on average) have 3 months notice period while US Americans have 2 weeks. How would a US company deal with it? On top of that, several countries have <strong>protection against unlawful termination</strong>, and how can a Slovakian employee avail that benefit against a German company?</p>
</li>
<li>
<p><strong>IP protection</strong>: It’s hard to <strong>protect IP</strong> if employees are not in the same jurisdiction. A company operation from Czechia would find it hard to settle trade disputes with a remote worker from South Africa. Another example is of <strong>TISAX compliance</strong> that is required for specialized hardware projects for Automotive industries. Remote work fails to make a dent in this situation.</p>
</li>
</ul>
<h2 id="hardware-cant-remote">Hardware can’t remote</h2>
<p>Patio11’s law<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> states that the <strong>economy is much bigger than you think</strong>. There are companies which have widely different business models and they often have a hardware related product. My <a href="https://www.salonlab-server.de/en-GB/">current project</a> is an IoT device that talks to an iPad app. The <strong>hardware team</strong> needs <strong>specialized tools</strong> to work on the IoT device, and these tools can’t be moved to home office. Remote work is a strict no-no for such products.</p>
<h2 id="swim-against-the-tide">Swim against the tide</h2>
<p>The biggest hurdle employees face in remote/home offices is <strong>lack of focus and direction</strong>. Humans have evolved over thousands of years to collaborate based on interpersonal cues, and a video call simply does not have the same effect. Humans need <strong>feedback</strong> and <strong>constructive communication</strong> whereas isolation kills the spirit. People who are new to remote work often feel <strong>rudderless</strong> because <strong>self discipline is hard</strong> when there’s no structure. I’m doing remote work on-and-off since 2018, and it took me a lot of discipline to get productive. The simple fact is that remote work is not natural, and not suited for all work streams in a typical company. Add to it the fact that many <strong>families</strong> simply don’t have space to work from home, and on top of that there might be kids around.</p>
<p>Remote work might be one of the few positive outcomes of the COVID-19 crisis but unless we tend to it carefully, we’ll end up creating a unhappy and unproductive workspace.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://www.wsj.com/articles/facebook-to-shift-permanently-toward-more-remote-work-after-coronavirus-11590081300">https://www.wsj.com/articles/facebook-to-shift-permanently-toward-more-remote-work-after-coronavirus-11590081300</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://www.cnbc.com/2020/08/07/atlassian-tells-employees-they-can-work-from-home-indefinitely.html">https://www.cnbc.com/2020/08/07/atlassian-tells-employees-they-can-work-from-home-indefinitely.html</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p><a href="https://www.wsj.com/articles/google-to-keep-employees-home-until-summer-2021-amid-coronavirus-pandemic-11595854201">https://www.wsj.com/articles/google-to-keep-employees-home-until-summer-2021-amid-coronavirus-pandemic-11595854201</a> <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p><a href="https://www.buzzfeednews.com/article/alexkantrowitz/twitter-will-allow-employees-to-work-at-home-forever">https://www.buzzfeednews.com/article/alexkantrowitz/twitter-will-allow-employees-to-work-at-home-forever</a> <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p><a href="https://secondbreakfast.co/patio11-s-law">https://secondbreakfast.co/patio11-s-law</a> <a href="#fnref:5" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

            </div></div>]]>
            </description>
            <link>https://samkhawase.com/blog/remote-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034037</guid>
            <pubDate>Mon, 09 Nov 2020 12:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Free Typography Logo Maker]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25034017">thread link</a>) | @hosshams
<br/>
November 9, 2020 | https://formito.com/tools/logo | <a href="https://web.archive.org/web/*/https://formito.com/tools/logo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://formito.com/tools/logo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25034017</guid>
            <pubDate>Mon, 09 Nov 2020 12:25:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenBSD Router Guide]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25033925">thread link</a>) | @upofadown
<br/>
November 9, 2020 | https://www.unixsheikh.com/tutorials/openbsd-router-guide/ | <a href="https://web.archive.org/web/*/https://www.unixsheikh.com/tutorials/openbsd-router-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<table>
    <tbody><tr>
        <td><img src="https://www.unixsheikh.com/includes/img/openbsd-icon.png" alt="OpenBSD icon"></td>
        <td>
            
            <h4>Network segmenting firewall, DHCP, DNS with Unbound, domain blocking and much more<br>
                <span>OpenBSD: 6.8 · Published: 2020-11-05 · Updated: 2020-11-12 · Version: 1.4.1</span>
            </h4>
        </td>
    </tr>
</tbody></table>

<h2>Introduction</h2>

<div><p>In this guide we're going to take a look at how we can use cheap and "low end" hardware to build an amazing OpenBSD router with firewalling capabilities, segmented local area networks, DNS with domain blocking, DHCP and more.</p><p>We will use a setup in which the router segments the local area network (LAN) into three separate networks, one for the grown-ups in the house, one for the children, and one for public facing servers, such as a private web server or mail server. We will also look at how we can use DNS to block out ads, porn, and other websites on the Internet. The OpenBSD router can also be used on small to mid-size offices.</p></div>

<p>Table of contents</p>
<ul>
    <li><a href="#why-a-firewall">Why a firewall?</a></li>
    <li><a href="#the-hardware">The hardware</a></li>
    <li><a href="#why-openbsd">Why OpenBSD?</a></li>
    <li><a href="#the-network">The network</a>
    <ul>
        <li><a href="#setting-up-the-network">Setting up the network</a></li>
    </ul>
    </li>
    <li><a href="#dhcp">DHCP</a></li>
    <li><a href="#a-packet-filtering-firewall">PF - A packet filtering firewall</a>
    <ul>
        <li><a href="#pf-setup">PF setup</a></li>
        <li><a href="#clarifications">Clarifications</a></li>
        <li><a href="#pf-domain-name-resolution">Domain name or hostname resolution</a></li>
        <li><a href="#the-ruleset">The ruleset</a>
            <ul>
                <li><a href="#whitelist">The children's whitelist</a>
                    <ul>
                        <li><a href="#persistent-table">Using a persistent table</a></li>
                    </ul>
                </li>
            </ul>
        </li>
        <li><a href="#loading-ruleset">Loading the rules</a></li>
        <li><a href="#logging">Logging and monitoring</a></li>
    </ul>
    </li>
    <li><a href="#domain-name-service">DNS</a>
    <ul>
        <li><a href="#unbound">I present to you, Unbound</a></li>
        <li><a href="#blocking-with-dns">Blocking with DNS</a>
            <ul>
                <li><a href="#nxdomain">NXDOMAIN vs redirecting</a></li>
            </ul>
        </li>
        <li><a href="#doh">The problem with DNS over HTTPS (DoH)</a></li>
        <li><a href="#unbound-setup">Setting up Unbound</a>
            <ul>
                <li><a href="#basic-settings">Basic settings</a></li>
                <li><a href="#lets-block-some-domains">Let's block some domains!</a></li>
            </ul>
        </li>
        <li><a href="#dns-security">DNS security</a>
            <ul>
                <li><a href="#dns-hijacking">DNS hijacking</a>
                    <ul>
                        <li><a href="#dns-hijacking-prevention">DNS hijacking prevention</a></li>
                    </ul>
                </li>
                <li><a href="#dns-spoofing">DNS spoofing</a>
                    <ul>
                        <li><a href="#dns-spoofing-prevention">DNS spoofing prevention</a></li>
                    </ul>
                </li>
            </ul>
        </li>
    </ul>
    </li>
    <li><a href="#appendix">Appendix</a>
        <ul>
            <li><a href="#inspecting-doh">Inspecting DNS over HTTPS (DoH)</a></li>
            <li><a href="#blocking-doh">Blocking DNS over HTTPS (DoH)</a></li>
            <li><a href="#dhcp-domain">Adding the domain-name option to DHCP and using a FQDM</a></li>
            <li><a href="#recommended-reading">Recommended reading</a></li>
            <li><a href="#how-to-contribute">How to contribute to the guide?</a></li>
            <li><a href="#todo">TODO</a></li>
        </ul>
    </li>
</ul>

<h2 id="why-a-firewall">Why a firewall?</h2>
<p>Almost no matter how you connect to the Internet from your home or office, you need a real firewall between you and the modem or router that your ISP has provided you with.</p>
<p>Very rarely do consumer-grade modems or routers get firmware updates and they are often vulnerable to <a href="https://en.wikipedia.org/wiki/Home_router#Security">network attacks</a> that turns these devices into <a href="https://en.wikipedia.org/wiki/Botnet">botnets</a>, such like the <a href="https://en.wikipedia.org/wiki/Mirai_(malware)">Mirai malware</a>. Many consumer-grade modems and routers is to blame for some of the largest <a href="https://en.wikipedia.org/wiki/Distributed_denial_of_service_attack">distributed denial of service (DDoS) attacks</a>.</p>
<p>A firewall between you and your ISP modem or router cannot protect your modem or router device against attacks, but it can protect your computers and devices on the inside of the network, and it can help you monitor and control the traffic that comes and goes to and from your local network.</p>
<p>Without a firewall between your local network and the ISP modem or router you could basically consider this an open door policy, like leaving the door to your house wide open, because you cannot trust the equipment from your ISP.</p>
<p>It is always a really good idea to put a real firewall between your local network and the Internet, and with OpenBSD you get an very solid solution.</p>

<p><b>NOTE:</b><br>Currently this guide only deals with IPv4 as most people still don't use IPv6 and many ISPs also still only use IPv4, but IPv6 is planned for a future update of the guide.</p>

<h2 id="the-hardware">The hardware</h2>
<p>You don't have to buy expensive hardware to get an effective router and firewall for your house or office. Even with cheap and "low end" hardware you can get a very solid solution.</p>
<p>I have build multiple solutions with the <a href="https://www.asrock.com/mb/Intel/Q1900DC-ITX/">ASRock Q1900DC-ITX</a> motherboard that comes with an Intel Quad-Core Celeron processor.</p>
<p><img src="https://www.unixsheikh.com/includes/img/asrock-q1900dc-itx.png" alt="ASRock Q1900DC-ITX motherboard"></p>
<p>I'll admit, it's a pretty "crappy" motherboard, but it gets the job done and I have several builds that have run very solid for many years on gigabit networks with full saturation and the firewall, DNS, etc. working "overtime" and the CPU hardly breaks a sweat.</p>
<p>The ASRock Q1900DC-ITX motherboard has the advantage that it comes with a DC-In Jack that is compatible with a 9~19V power adapter, making it very power saving. Unfortunately the ASRock Q1900DC-ITX motherboard is no longer made, but I'm just using it as an example, I have used several other cheap boards as well.</p>
<p><b>NOTE:</b><br>Most of the current ASRock J-series can be used. Search for any J-series board on Amazon and a list will show up on recent hardware. Such as <a href="https://www.amazon.com/ASRock-Motherboard-Mini-DDR3-Q1900B-ITX/">ASRock Q1900B-ITX</a>, <a href="https://www.amazon.com/ASRock-J5005-ITX-Quad-Core-Processor-Motherboards/">ASRock J5005-ITX</a> and <a href="https://www.amazon.com/ASRock-Motherboard-CPU-Combo-J3355M/">ASRock J3335M</a> (These are not affiliate links!). Many other low power brands from other motherboard producers can be uses as well.</p>
<p>I have also used the ASRock Q1900-ITX (it doesn't come with the DC-In Jack) combined with a PicoPSU.</p>
<p><img src="https://www.unixsheikh.com/includes/img/picopsu.png" alt="PicoPSU power supply"></p>
<p>You can find different brands and versions of the PicoPSU, some are better quality than others. I have two different brands, the original and a cheaper knockoff, both performs very well and they save quite a bit of power contrary to running with a normal power supply.</p>
<p>Last, I am using a cheap Intel knockoff quad port NIC found on Ebay like this one:</p>
<p><img src="https://www.unixsheikh.com/includes/img/intel-quad-nic.png" alt="Intel Quad NIC"></p>
<p>I know it is better to use quality hardware, especially on a network that you care about, but this tutorial is about how you can get away with using fairly cheep hardware and still get an extremely useful product that will continue to serve you well for many years - at least that is my experience.</p>
<p>I recommend that you look for a low power mini ITX board with hardware <a href="https://www.openbsd.org/amd64.html">supported by OpenBSD</a>, such as an Intel Celeron or Intel i3 processor. These boards are typically cheap, less power hungry, and they don't take up much space. I don't recommend using the Intel Atom CPU if you have a gigabit network as they usually choke because they can't handle the amount of traffic, but your mileage may vary.</p>
<p>You might also need a couple of cheap gigabit switches for the segmented local network, at least if you have more than one computer you want to connect to the same LAN :)</p>

<h2 id="why-openbsd">Why OpenBSD?</h2>
<p>In truth, you can get a similar setup with one of the other <a href="https://en.wikipedia.org/wiki/Comparison_of_BSD_operating_systems">BSD flavors</a> or one of the many different <a href="https://en.wikipedia.org/wiki/Linux_distribution">Linux distribution</a>, but <a href="https://www.openbsd.org/">OpenBSD</a> is specifically very well suited and designed for this kind of task. Not only does it come with all the needed software in the base install, but it also has significantly better security and tons of improved mitigations already build-in into the operating system. I <a href="https://www.unixsheikh.com/articles/openbsd-is-fantastic.html">highly recommend</a> OpenBSD over any other operating system for this kind of task.</p>
<p>This guide is not going to show you how to install OpenBSD. If you haven't done that before I recommend you spin up some kind of virtual machine or see if you have some unused and supported hardware laying around you can play with. OpenBSD is one of the easiest and quickest operating systems to install. Don't be afraid of the non-gui approach, once you have tried it you will really appreciate the simplicity. Use the default settings when in doubt.</p>
<p>Before you endeavor on this journey make sure to reference the OpenBSD documentation! Not only is everything very well documented, but you will most likely find all the answers you need right there. Read the <a href="https://www.openbsd.org/faq/index.html">OpenBSD FAQ</a> and take a look at the different <a href="https://man.openbsd.org/">manual pages</a> for the software we're going to use.</p>
<p>Another really useful place to find general information about OpenBSD is the <a href="https://marc.info/?l=openbsd-misc">OpenBSD mailing list archives</a>. Also make sure to stay up to date with relevant information by subscribing to the <a href="https://www.openbsd.org/mail.html">Announcements and security advisories</a> mailing list.</p>
<p>Last, but not least, please consider <a href="https://www.openbsd.org/donations.html">supporting OpenBSD</a>! Even if you don't use OpenBSD on a daily basis, but perhaps make use of <a href="https://www.openssh.com/">OpenSSH</a> on Linux, then you're really using software from the OpenBSD project. Consider making a small, but steady donation to support the further development of all the great software the OpenBSD developers make!</p>

<h2 id="the-network">The network</h2>
<p>A router is basically a device that regulate network traffic between two or more separate networks. The router will ensure that network traffic intended for the local network doesn't run out into the wild on the Internet, and traffic on the Internet, that is not intended for your local network, stays on the Internet.</p>
<p><b>NOTE:</b><br>A router is sometimes also referred to as a gateway, which generally is alright, but in truth a real gateway joins dissimilar systems, while a router joins similar networks. An example of a gateway would be a device that joins a PC network with a telecommunications network.</p>
<p>In this tutorial we're building a router and we have 4 networks of the same type to work with. One is the Internet and the other three are the internally segmented local area networks (LANs). Some people prefer to work with virtual LANs, but in this tutorial we're going to use the quad port NIC from the illustration above. You can achieve the same result by using multiple one port NICs if you prefer that, you just have to make sure that you have enough room and free PCI slots on the motherboard. You can also use the Ethernet port on the motherboard itself, but it depends on the driver and support for the device. I have had no problems using the Realtek PCI gigabit Ethernet controller that normally comes with many motherboards even though I recommend Intel over Realtek.</p>
<p>Of course you don't have to segment the network into several parts if you don't need that, and it will be very easy to change the settings from this guide, but I have decided to use this approach in order to show you how you can protect your children by segmenting their network into a separate LAN that not only gets ad and porn blocking using DNS blocking (all the segments gets that), but you can even whitelist the parts of the Internet you want them to have access to. The last part about whitelisting is difficult and generally not recommended unless your children requires only very limited access, but it is doable with some work, and the guide is going to show you one way you can do that.</p>
<p>This is an illustration of the network we're going to setup:</p>
<pre><code>
                       Internet
                          |
                    xxx.xxx.xxx.xxx
                    ISP Modem (WAN)
                      10.24.0.23
                          |
                       OpenBSD
                      10.24.0.50
                  (router/firewall)
  …</code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.unixsheikh.com/tutorials/openbsd-router-guide/">https://www.unixsheikh.com/tutorials/openbsd-router-guide/</a></em></p>]]>
            </description>
            <link>https://www.unixsheikh.com/tutorials/openbsd-router-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033925</guid>
            <pubDate>Mon, 09 Nov 2020 12:13:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pfizer and BioNTech Announce Vaccine Candidate Against Covid-19 Achieved Success]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033852">thread link</a>) | @doener
<br/>
November 9, 2020 | https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-announce-vaccine-candidate-against-covid-19?mobile=1 | <a href="https://web.archive.org/web/*/https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-announce-vaccine-candidate-against-covid-19?mobile=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="article">

  <div>
                <ul type="disc"><li><em>Vaccine candidate was found to be more than 90% effective in preventing COVID-19 in participants without evidence of prior SARS-CoV-2 infection in the first interim efficacy analysis</em></li><li><em>Analysis evaluated</em><em> 94 confirmed cases of COVID-19 in trial participants </em></li><li><em>Study enrolled 43,538 participants, with 42% having diverse backgrounds, and no serious safety concerns have been observed; safety and additional efficacy data continue to be collected </em></li><li><em>Submission for Emergency Use Authorization (EUA) to the U.S. Food and Drug Administration (FDA) planned soon after the required safety milestone is achieved, which is currently expected to occur in the third week of November </em></li><li><em>Clinical trial to continue through to final analysis at 164 confirmed cases in order to collect further data and characterize the vaccine candidate’s performance against other study endpoints</em></li></ul><p><strong>NEW YORK and MAINZ, GERMANY, November 9, 2020</strong> — <a href="https://www.globenewswire.com/Tracker?data=PJ8PG63hVRh2bkt5smgOlFAGa-RXpa2iRwzAO6IqH_YcfyX-R7Tdk96PAniX7YGQoMAdF-jDHoeL-YX46MLSDw==" rel="nofollow" target="_blank"><u>Pfizer Inc.</u></a> (NYSE: PFE) and <a href="https://www.globenewswire.com/Tracker?data=XfaLG8yfG5HYcb1T5NR2xBQd-D3R4PCcCCpFaLX9rM23piCwE-K7u65TmqKeemgOsm9Iwv7SBS6CLe_lhfQmFA==" rel="nofollow" target="_blank"><u>BioNTech SE</u></a> (Nasdaq: BNTX) today announced their mRNA-based vaccine candidate, BNT162b2, against SARS-CoV-2 has demonstrated evidence of efficacy against COVID-19 in participants without prior evidence of SARS-CoV-2 infection, based on the first interim efficacy analysis conducted on November 8, 2020 by an external, independent Data Monitoring Committee (DMC) from the Phase 3 clinical study. After discussion with the FDA, the companies recently elected to drop the 32-case interim analysis and conduct the first interim analysis at a minimum of 62 cases. Upon the conclusion of those discussions, the evaluable case count reached 94 and the DMC performed its first analysis on all cases. </p>  <p>The case split between vaccinated individuals and those who received the placebo indicates a vaccine efficacy rate above 90%, at seven days after the second dose. This means that protection is achieved 28 days after the initiation of the vaccination, which consists of a 2-dose schedule. As the study continues, the final vaccine efficacy percentage may vary. The DMC has not reported any serious safety concerns and recommends that the study continues to collect additional safety and efficacy data as planned. The data will be discussed with regulatory authorities worldwide. </p>  <p>“Today is a great day for science and humanity. The first set of results from our Phase 3 COVID-19 vaccine trial provides the initial&nbsp;evidence of our vaccine’s ability to prevent COVID-19,” said <strong>Dr. Albert Bourla, Pfizer Chairman and CEO.</strong> “We are reaching this critical milestone in our vaccine development program at a time when the world needs it most with infection rates setting new records, hospitals nearing over-capacity and economies struggling to reopen. With today’s news, we are a significant step closer to providing people around the world with a much-needed breakthrough to help bring an end to this global health crisis. We look forward to sharing additional efficacy and safety data generated from thousands of participants in the coming weeks.”</p>  <p>“I want to thank the thousands of people who volunteered to participate in the clinical trial, our academic collaborators and investigators at the study sites, and our colleagues and collaborators around the world who are dedicating their time to this crucial endeavor,” added <strong>Bourla.</strong> “We could not have come this far without the tremendous commitment of everyone involved.”</p>  <p>“The first interim analysis of our global Phase 3 study provides evidence that a vaccine may effectively prevent COVID-19. This is a victory for innovation, science and a global collaborative effort,” said <strong>Prof. Ugur Sahin, BioNTech Co-founder and CEO.</strong> “When we embarked on this journey 10 months ago this is what we aspired to achieve. Especially today, while we are all in the midst of a second wave and many of us in lockdown, we appreciate even more how important this milestone is on our path towards ending this pandemic and for all of us to regain a sense of normality. We will continue to collect further data as the trial continues to enroll for a final analysis planned when a total of 164 confirmed COVID-19 cases have accrued. I would like to thank everyone who has contributed to make this important achievement possible.”</p>  <p>The Phase 3 clinical trial of BNT162b2 began on July 27 and has enrolled 43,538 participants to date, 38,955 of whom have received a second dose of the vaccine candidate as of November 8, 2020. Approximately 42% of global participants and 30% of U.S. participants have racially and ethnically diverse backgrounds. The trial is continuing to enroll and is expected to continue through the final analysis when a total of 164 confirmed COVID-19 cases have accrued. The study also will evaluate the potential for the vaccine candidate to provide protection against COVID-19 in those who have had prior exposure to SARS-CoV-2, as well as vaccine prevention against severe COVID-19 disease. In addition to the primary efficacy endpoints evaluating confirmed COVID-19 cases accruing from seven days after the second dose, the final analysis now will include, with the approval of the FDA, new secondary endpoints evaluating efficacy based on cases accruing 14 days after the second dose as well. The companies believe that the addition of these secondary endpoints will help align data across all COVID-19 vaccine studies and allow for cross-trial learnings and comparisons between these novel vaccine platforms. The companies have posted an updated version of the study protocol at <a href="https://www.globenewswire.com/Tracker?data=bE4RvEXc3amHdJ0LinFQkPyUCRxShL94rKlQWnVIuOebbWs0t_t1F1qSmc0deSfk8TsQTmqiZHqgYUA4_HoIG8cgZ-MTBQVX5ZbQ89L9eImlSxNuQzgmZ36Fp4CVqIu8sjS4aT-HPEktSLWmEhtRsQ==" rel="nofollow" target="_blank"><u>https://www.pfizer.com/science/coronavirus</u></a>. </p>  <p>Pfizer and BioNTech are continuing to accumulate safety data and currently estimate that a median of two months of safety data following the second (and final) dose of the vaccine candidate – the amount of safety data specified by the FDA in its guidance for potential Emergency Use Authorization – will be available by the third week of November. Additionally, participants will continue to be monitored for long-term protection and safety for an additional two years after their second dose.</p>  <p>Along with the efficacy data generated from the clinical trial, Pfizer and BioNTech are working to prepare the necessary safety and manufacturing data to submit to the FDA to demonstrate the safety and quality of the vaccine product produced. Based on supply projections, we expect to supply globally up to 50 million vaccine doses in 2020 and manufacture up to 1.3 billion doses in 2021. Pfizer and BioNTech plan to submit data from the full Phase 3 trial for scientific peer-review publication.</p>  <p><strong>About Pfizer: Breakthroughs That Change Patients’ Lives</strong></p>  <p>At Pfizer, we apply science and our global resources to bring therapies to people that extend and significantly improve their lives. We strive to set the standard for quality, safety and value in the discovery, development and manufacture of health care products, including innovative medicines and vaccines. Every day, Pfizer colleagues work across developed and emerging markets to advance wellness, prevention, treatments and cures that challenge the most feared diseases of our time. Consistent with our responsibility as one of the world's premier innovative biopharmaceutical companies, we collaborate with health care providers, governments and local communities to support and expand access to reliable, affordable health care around the world. For more than 150 years, we have worked to make a difference for all who rely on us. We routinely post information that may be important to investors on our website at <u><a href="https://www.globenewswire.com/Tracker?data=4FbrwG1rPf9jwYvPniD1rUMbj6s_Wqek0iGxXtCmV7zUg7CMpYiSUA1zc-r5E0Nf_ZNaQlSWnZ5e8_mFWG8XYA==" rel="nofollow" target="_blank">www.Pfizer.com</a></u>. In addition, to learn more, please visit us on <u><a href="https://www.globenewswire.com/Tracker?data=4FbrwG1rPf9jwYvPniD1rf9AtACzzG5su0IsLCtDLy0Q4vyLC1u2a07goDfiO7HGejXmxyveSXGtjTX9Jbf1aw==" rel="nofollow" target="_blank">www.Pfizer.com</a></u> and follow us on Twitter at <a href="https://www.globenewswire.com/Tracker?data=nZQmHBaz29Df7F7-i_Dx5Ci9JAIKZm1fs38JsJ0UDRndZf2WfVJLut17r7ky8GafcpFUih6abC7JiIHrL1K6Bw==" rel="nofollow" target="_blank"><u>@Pfizer</u></a> and <a href="https://www.globenewswire.com/Tracker?data=nZQmHBaz29Df7F7-i_Dx5EIUSI0zr1bjnR6DBf-Egt2of100u8SheiSFC3c0Qbr_yoniSSHE2UwRTyWYI9JOS5L8WV3tP6hHSIv-ym0XDP0=" rel="nofollow" target="_blank"><u>@Pfizer News</u></a>, <a href="https://www.globenewswire.com/Tracker?data=UH05W4ZxYdmUeMyOlJKhJmRsqWd0fvhHaFnVv0fo-CIWUdkF6HDUEv2p868nekUmyUYROhkLqSYY41Pcuq02MsL4ZoYkXD237abwsIit60U=" rel="nofollow" target="_blank"><u>LinkedIn</u></a>, <a href="https://www.globenewswire.com/Tracker?data=ir8lky4stO2XkFLpjU_Ut0YeVDly5-CLV1tWNdWEYeM0oZHykh1Sm3s7CRgIHdfPWelsTpFq7j2P9dXmnvMVig==" rel="nofollow" target="_blank"><u>YouTube</u></a> and like us on Facebook at <a href="https://www.globenewswire.com/Tracker?data=LTOch18I9XnaHE4qzjVzrNxzuXYwnNH0v4XrrVbCqgnXUaKX5nOdqwvgTZru4193lMFjeY16tudZKniE9EdlpQSPhDWRORO-8flQBehdsh8=" rel="nofollow" target="_blank"><u>Facebook.com/Pfizer</u></a>.</p>  <p><strong>Pfizer Disclosure Notice</strong></p>  <p>The information contained in this release is as of November 9, 2020. Pfizer assumes no obligation to update forward-looking statements contained in this release as the result of new information or future events or developments.</p>  <p>This release contains forward-looking information about Pfizer’s efforts to combat COVID-19, the collaboration between BioNTech and Pfizer to develop a potential COVID-19 vaccine, the BNT162 mRNA vaccine program, and modRNA candidate BNT162b2 (including qualitative assessments of available data, potential benefits, expectations for clinical trials, anticipated timing of clinical trial readouts and regulatory submissions and anticipated manufacturing, distribution and supply), that involves substantial risks and uncertainties that could cause actual results to differ materially from those expressed or implied by such statements. Risks and uncertainties include, among other things, the uncertainties inherent in research and development, including the ability to meet anticipated clinical endpoints, commencement and/or completion dates for clinical trials, regulatory submission dates, regulatory approval dates and/or launch dates, as well as risks associated with preliminary and interim data, (including the Phase 3 interim data that is the subject of this release), including the possibility of unfavorable new preclinical or clinical trial data and further analyses of existing preclinical or clinical trial data; the risk that clinical trial data are subject to differing interpretations and assessments, including during the peer review/publication process, in the scientific community generally, and by regulatory authorities; whether and when data from the BNT162 mRNA vaccine program will be published in scientific journal publications and, if so, when and with what modifications; whether regulatory authorities will be satisfied with the design of and results from these and future preclinical and clinical studies; whether and when any biologics license and/or emergency use authorization applications may be filed in any jurisdictions for BNT162b2 or any other potential vaccine candidates; whether and when any such applications may be approved by regulatory authorities, which will depend on myriad factors, including making …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-announce-vaccine-candidate-against-covid-19?mobile=1">https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-announce-vaccine-candidate-against-covid-19?mobile=1</a></em></p>]]>
            </description>
            <link>https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-announce-vaccine-candidate-against-covid-19?mobile=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033852</guid>
            <pubDate>Mon, 09 Nov 2020 11:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Knowledge Is The Real Wealth]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033771">thread link</a>) | @ozres1
<br/>
November 9, 2020 | https://ruizhidong.com/why-knowledge-is-ultimately-more-important-than-money/ | <a href="https://web.archive.org/web/*/https://ruizhidong.com/why-knowledge-is-ultimately-more-important-than-money/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<hr><p>The real source of wealth is not money. Money is abundant and plentiful. Fiat can be printed at will. It’s a means to an end.</p><p>Knowledge that advances civilization on the other hand is <em>scarce</em>. Great thinkers like Newton enable progress.</p><p>Consider for a moment what $1 million would have bought you 500 years ago… 100 years ago… today…</p><p>and 100 years into the future.</p><p>Being a John Rockefeller 100 years ago wouldn’t have gotten you an iPhone no matter how much money you spent.</p><p>The problem isn’t one of having enough money to organize labour and resources.</p><p><strong>The bigger problem is in <em>knowing</em> what to do. </strong></p><p>This has been the real bottleneck in unleashing human potential. Until now.</p><p><a href="https://giphy.com/gifs/5VKbvrjxpVJCM" target="_blank" rel="noopener">via GIPHY</a></p><p>AI and the advancement of thinking tools to assist in research, development and general decision making will greatly alleviate this strain and enable greater productivity.</p><div><div><div><figure><img data-attachment-id="1647" data-permalink="https://ruizhidong.com/why-knowledge-is-ultimately-more-important-than-money/naval-ravikant/" data-orig-file="https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant.jpg" data-orig-size="250,250" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="naval-ravikant" data-image-description="" data-medium-file="https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant.jpg" data-large-file="https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant.jpg" width="250" height="250" src="https://cdn.shortpixel.ai/spai/q_lossless+ret_img/https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant.jpg" data-spai-eager="1" alt="" srcset="https://cdn.shortpixel.ai/spai/q_lossless+ret_img/https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant.jpg 250w, https://cdn.shortpixel.ai/spai/q_lossless+ret_img/https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant-150x150.jpg 150w, https://cdn.shortpixel.ai/spai/q_lossless+ret_img/https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant-80x80.jpg 80w" loading="lazy" sizes="(max-width: 250px) 100vw, 250px" data-old-src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjUwIDI1MCIgd2lkdGg9IjI1MCIgaGVpZ2h0PSIyNTAiIGRhdGEtdT0iaHR0cHMlM0ElMkYlMkZydWl6aGlkb25nLmNvbSUyRndwLWNvbnRlbnQlMkZ1cGxvYWRzJTJGMjAyMCUyRjExJTJGbmF2YWwtcmF2aWthbnQuanBnIiBkYXRhLXc9IjI1MCIgZGF0YS1oPSIyNTAiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PC9zdmc+" data-lazy-src="https://ruizhidong.com/wp-content/uploads/2020/11/naval-ravikant.jpg?is-pending-load=1"><figcaption>Naval Ravikant</figcaption></figure></div><blockquote><p>Society, business, &amp; money are downstream of technology, which is itself downstream of science. Science applied is the engine of humanity. <br></p><p>Corollary: Applied Scientists are the most powerful people in the world. This will be more obvious in the coming years.</p><cite>— Naval Ravikant</cite></blockquote><hr></div></div><hr><h3>An example using an isolated island</h3><figure><p><span><iframe width="900" height="507" src="https://www.youtube.com/embed/9EdnEOWA9w4?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p></figure>
</div></div>]]>
            </description>
            <link>https://ruizhidong.com/why-knowledge-is-ultimately-more-important-than-money/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033771</guid>
            <pubDate>Mon, 09 Nov 2020 11:45:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA['It was crazy,' says California kayaker who was engulfed in a whale's mouth]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033732">thread link</a>) | @pseudolus
<br/>
November 9, 2020 | https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5790998/it-was-crazy-says-california-kayaker-who-was-engulfed-in-a-whale-s-mouth-1.5791001 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5790998/it-was-crazy-says-california-kayaker-who-was-engulfed-in-a-whale-s-mouth-1.5791001">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Julie McSorley&nbsp;says she&nbsp;learned an important lesson after she and her friend were nearly swallowed by a humpback: "Whales need their space."</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5791307.1604607440!/fileImage/httpImage/image.jpeg_gen/derivatives/16x9_780/whale.jpeg"></p></div><figcaption>Sam Mcmillan of Atuscadero, Calif., was out snapping photos of humpback whales in San Luis Obispo Bay when he saw one whale breach the surface directly under a pair of kayakers. <!-- --> <!-- -->(Sam McMillan Photography)</figcaption></figure><p><span><div><div role="button" tabindex="0" title="'It was crazy,' says California kayaker who was engulfed in a whale's mouth"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/425/375/AsItHappens-podcast-640x360.jpg" alt=""></p><p><span>As It Happens</span><span>6:28</span><span>'It was crazy,' says California kayaker who was engulfed in a whale's mouth</span></p></div></div></div></span></p><p><span><p>Julie McSorley&nbsp;says she&nbsp;learned an important lesson after she and her friend ended up in a humpback's mouth:&nbsp;"Whales need their space."</p>  <p>McSorley and Liz Cottriel were kayaking together in California's San Luis Obispo Bay on Monday morning,&nbsp;watching the whales feed on silverfish, when one of the massive sea creatures surfaced beneath them, toppling their kayak and knocking them into the water.&nbsp;</p>  <p>Videos and photos from&nbsp;other kayakers and paddlers appear&nbsp;to show the women and their kayak&nbsp;being momentarily engulfed in the whale's mouth — though the two friends&nbsp;say it all happened too fast for them to be sure.&nbsp;</p>  <p>"It's definitely woke me up to the realization that, you know, our place is not in the feeding zone of whales," McSorley&nbsp;told <em>As It Happens</em> host Carol Off.&nbsp;</p>  <p>"We didn't think we were that close, but we definitely were right in the area that we shouldn't have been — so I've learned my lesson, big time."</p>  <ul>   <li><strong><em>The following video&nbsp;contains strong language:</em></strong></li>  </ul>  <p><span><span><iframe src="https://www.youtube.com/embed/3X2C46--2lY" frameborder="no" title="YouTube content" allowfullscreen=""></iframe></span></span></p>  <hr>  <p>Humpback&nbsp;whales have been active lately in Luis Obispo Bay near Avila Beach,&nbsp;drawing kayakers and paddlers to the area to watch them feed.</p>  <p>McSorley had already been out to watch them once, so when her friend came to town for a visit, she asked her if she wanted to go.</p>  <p>"Her reaction was, 'No, I don't like the ocean. I'm scared of sharks. I'm scared of anything I can't see in the water.' And I so ignorantly told her, 'Oh, they're never going to dump you over. The kayaks are very stable. I've never had an issue,'" McSorley said.</p>  <p>"And so she reluctantly came with me just to have a new experience."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5791324.1604608023!/fileImage/httpImage/image.jpeg_gen/derivatives/original_300/kayaking.jpeg 300w,https://i.cbc.ca/1.5791324.1604608023!/fileImage/httpImage/image.jpeg_gen/derivatives/original_460/kayaking.jpeg 460w,https://i.cbc.ca/1.5791324.1604608023!/fileImage/httpImage/image.jpeg_gen/derivatives/original_620/kayaking.jpeg 620w,https://i.cbc.ca/1.5791324.1604608023!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/kayaking.jpeg 780w,https://i.cbc.ca/1.5791324.1604608023!/fileImage/httpImage/image.jpeg_gen/derivatives/original_1180/kayaking.jpeg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5791324.1604608023!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/kayaking.jpeg"></p></div><figcaption>This photo by Sam Mcmillan of Atuscadero, Calif., shows Liz Cottriel, right, and Julie McSorley, left, kayaking in California’s San Luis Obispo Bay.<!-- --> <!-- -->(Sam McMillan Photography)</figcaption></figure></span></p>  <p>For the first hour or so, the friends followed a pair of humpbacks as they fed. They would spot the swarms of fish — or "bait balls" — at a distance, watch the whales&nbsp;surface for a munch, wait a few minutes, and then move to the place the whales had just been.</p>  <p>They were sitting peacefully in their&nbsp;kayak waiting to see where the next bait ball&nbsp;would show up, when the little fish suddenly appeared all around them.&nbsp;</p>  <p>"So I knew it was going to be very close, but again, I'd seen whales breach right next kayaks before. So my mind was like, this is going to be, you know, super cool," McSorley said.</p>  <p>"And then all of a sudden the boat lifted up and we were dumped in the water very, very quickly."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5791316.1604608039!/fileImage/httpImage/image.jpeg_gen/derivatives/original_300/whale.jpeg 300w,https://i.cbc.ca/1.5791316.1604608039!/fileImage/httpImage/image.jpeg_gen/derivatives/original_460/whale.jpeg 460w,https://i.cbc.ca/1.5791316.1604608039!/fileImage/httpImage/image.jpeg_gen/derivatives/original_620/whale.jpeg 620w,https://i.cbc.ca/1.5791316.1604608039!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/whale.jpeg 780w,https://i.cbc.ca/1.5791316.1604608039!/fileImage/httpImage/image.jpeg_gen/derivatives/original_1180/whale.jpeg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5791316.1604608039!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/whale.jpeg"></p></div><figcaption>This shot by Sam Mcmillan of Atuscadero, Calif., shows a kayak paddle sticking out of the whale's mouth after it surfaced between Cottriel and McSorley. <!-- --> <!-- -->(Sam McMillan Photography)</figcaption></figure></span></p>  <p>Cottriel could see the inside of the whale's mouth coming down on them, but mistook it at the time for its belly. Panicked and confused,&nbsp;she threw up her hand to stop it.&nbsp;</p>  <p>"I'm thinking to myself, 'I'm going to&nbsp;push. Like, I'm going to push a whale out of the way. It was the weirdest thought. I'm thinking, 'I'm dead. I'm dead.' I thought it was going&nbsp;land on me," Cottriel&nbsp;<a href="https://kmph.com/news/local/kayakers-get-knocked-over-by-humpback-whales-at-avila-beach">told the local Fox News affiliate</a>.</p>  <p>"Next thing I know, I'm under water."</p>  <p>McSorley says it all happened so fast that the only thing she remembers is feeling the boat rise, and then finding herself beneath the surface.&nbsp;</p>  <p>"Once we were in the water, we didn't know where we were — if we were under the whale, if we were sucked down with the whales," she said.</p>  <p>"So both of us ... ended up popping up right next to the kayak and next to each other. It was crazy."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5791336.1604612953!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/liz-cottriel-and-julie-mcsorley.jpg 300w,https://i.cbc.ca/1.5791336.1604612953!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/liz-cottriel-and-julie-mcsorley.jpg 460w,https://i.cbc.ca/1.5791336.1604612953!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/liz-cottriel-and-julie-mcsorley.jpg 620w,https://i.cbc.ca/1.5791336.1604612953!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/liz-cottriel-and-julie-mcsorley.jpg 780w,https://i.cbc.ca/1.5791336.1604612953!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/liz-cottriel-and-julie-mcsorley.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5791336.1604612953!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/liz-cottriel-and-julie-mcsorley.jpg"></p></div><figcaption>Cottriel, left, and McSorley, right.<!-- --> <!-- -->(Submitted by Julie McSorley and Liz Cottriel)</figcaption></figure></span></p>  <p>Sam Mcmillan&nbsp;was nearby&nbsp;taking photos of the whales at the time. He told <em>As It Happens</em> that he just knew he was going to get a good shot&nbsp;when he saw the size of the bait ball.&nbsp;</p>  <p>But it wasn't until he heard people shouting "Are you OK?" that he realized there were two&nbsp;people and a kayak mixed in with the fish and the whale.</p>  <p>"I&nbsp;checked on Julie and Liz to make sure they were OK, but it wasn't until I got home and saw the photos that I had taken, where you can see that they were right in the whale's mouth, that I realized just what had happened," he said.&nbsp;</p>  <p>McSorley&nbsp;says she and Cottriel didn't realize it either, until other kayakers came to their rescue.</p>  <p>"They were telling us, 'You were in the mouth, you were in the whale's&nbsp;mouth!"&nbsp;McSorley said. "But we didn't have any idea at that time. And it didn't really hit us until we watched the video later."</p>    <p>McSorley, meanwhile, says she won't be kayaking again&nbsp;when the whales are out unless she can keep a football field's distance from the creatures.</p>  <p>"I'll definitely kayak in the ocean by dolphins and otters and seals and all the others," she said. "But I think the whales need their space."</p>  <hr>  <p><em>Written by Sheena Goodyear. Interview produced by Sarah Cooper.&nbsp;</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5790998/it-was-crazy-says-california-kayaker-who-was-engulfed-in-a-whale-s-mouth-1.5791001</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033732</guid>
            <pubDate>Mon, 09 Nov 2020 11:40:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Extract full news article content from any RSS feed using Extract API]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033704">thread link</a>) | @imshashank
<br/>
November 9, 2020 | https://pipfeed.com/2020/11/09/tutorial-extract-full-news-article-content-from-any-rss-feed-using-extract-api/ | <a href="https://web.archive.org/web/*/https://pipfeed.com/2020/11/09/tutorial-extract-full-news-article-content-from-any-rss-feed-using-extract-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div itemprop="articleBody"><p>Learn how to extract all fields from any RSS feed or given a list of URLs. For this example, we will be using Medium’s RSS feed. The code will be in python but can easily be adapted for other languages.</p><p>Lets start by importing the packages. We will be using “feedparser” to extract Medium Rss feed.</p><pre><code lang="bash">pip install feedparser
pip install requests</code></pre><p>Let’s begin by first extracting links from the RSS feed. For this example, we will be extracting the articles from “Towards Data Science”. “Towards Data Science” is one of the leading blogs when it comes to Data Science, Machine Learning &amp; Artificial Intelligence.</p><pre><code lang="python">import feedparser

NewsFeed = feedparser.parse("https://towardsdatascience.com/feed")
print("Total entries found in feed: "+ str(len(NewsFeed.entries)) +"\n")
i =0
for entry in NewsFeed.entries:
print(str(i) + ": Got url: " + entry.link)
i = i +1</code></pre><p>We are able to extract the links, now we want to extract the entire content, summary, metadata and other details for each news article in the feed.</p><p>To extract we will be using Pipfeed’s extract API: <a href="https://promptapi.com/marketplace/description/pipfeed-api" rel="nofollow noopener external noreferrer" target="_blank" data-wpel-link="external">https://promptapi.com/marketplace/description/pipfeed-api</a> You can get a free API key from prompt API.</p><pre><code lang="python">import requests

url = "https://api.promptapi.com/pipfeed"

payload = "https://towardsdatascience.com/topic-model-evaluation-3c43e2308526"
headers= {
  "apikey": "YOUR_API_KEY"
}

response = requests.request("POST", url, headers=headers, data = payload)

status_code = response.status_code
result = response.text
print(result)</code></pre><p>The above code will extract the given URL and return all the fields. Below is the response we get for the above code. DO NOT forget to replace the API key with your own API keys generated from prompt API.</p><p>“Summary” &amp; “predictedCategories” are generated using Pipfeed’s AI models. Rest of the fields are extracted from the article HTML itself.</p><pre><code lang="json">{
"publishedAt": "2020-11-09T05:15:23.001Z",
"title": "Topic Model Evaluation",
"authors": [
"Giri Rabindranath"
],
"description": "Evaluation is the key to understanding topic models - This article explains what topic model evaluation is, why it's important and how to do it",
"language": "en",
"url": "https://towardsdatascience.com/topic-model-evaluation-3c43e2308526",
"mainImage": "https://miro.medium.com/max/1200/1*wvlqQPpOHFK7xQ1XOhe6xg.jpeg",
"category": "machine-learning",
"categories": null,
"predictedCategories": [
"machine-learning",
"data-science",
"programming"
],
"tags": [],
"keywords": [
"coherence",
"evaluation",
"human",
"model",
"models",
"topic",
"topics",
"way",
"word",
"words"
],
"summary": "In this article, we\u2019ll look at topic model evaluation, what it is and how to do it.\nWhat is topic model evaluation?\nTopic model evaluation is the process of assessing how well a topic model does what it is designed for.\nThis is why topic model evaluation matters.\nHow to evaluate topic models \u2014 RecapThis article has hopefully made one thing clear \u2014 topic model evaluation isn\u2019t easy!",
"images": [
"https://miro.medium.com/fit/c/140/140/1*74Yrxu8s4sOtTECtixv9Fg.jpeg",
"https://miro.medium.com/max/60/1*<a href="https://pipfeed.com/cdn-cgi/l/email-protection" data-cfemail="246c72746d7e6a17714e6a536e61137e67415e407c706564165c0a4e544143">[email&nbsp;protected]</a>?q=20",
"https://miro.medium.com/fit/c/140/140/0*l_zfjU9IKMa47tfy",
"https://miro.medium.com/fit/c/56/56/2*b2y5uCYazQ9FgiUQEUHT6Q.jpeg",
"https://miro.medium.com/max/60/1*mpyrgqwMjfclV2oN1U2VIA.jpeg?q=20",
"https://miro.medium.com/max/698/1*E4oPMmq5jTKuStZJuyDGpw.jpeg",
"https://miro.medium.com/max/12032/1*wvlqQPpOHFK7xQ1XOhe6xg.jpeg",
"https://miro.medium.com/max/60/1*_MXaw5BKgIsm8J3dOUNHMg.jpeg?q=20",
"https://miro.medium.com/max/224/1*AGyTPCaRzVqL77kFwUwHKg.png",
"https://miro.medium.com/max/270/1*W_RAPQ62h0em559zluJLdQ.png",
"https://miro.medium.com/max/60/1*E4oPMmq5jTKuStZJuyDGpw.jpeg?q=20",
"https://miro.medium.com/max/1200/1*wvlqQPpOHFK7xQ1XOhe6xg.jpeg",
"https://miro.medium.com/max/60/0*aP8H1qpRN_OR1x5r?q=20",
"https://miro.medium.com/max/60/0*NIpOoYo9iHt4lMbg?q=20",
"https://miro.medium.com/max/60/0*l_zfjU9IKMa47tfy?q=20",
"https://miro.medium.com/max/270/1*Crl55Tm6yDNMoucPo1tvDg.png",
"https://miro.medium.com/max/784/1*_MXaw5BKgIsm8J3dOUNHMg.jpeg",
"https://miro.medium.com/fit/c/140/140/1*FTG-junI6KJzojC_xRVNXg.png",
"https://miro.medium.com/max/60/0*fG5RLd48iOZezB_y.jpeg?q=20",
"https://miro.medium.com/fit/c/140/140/0*NIpOoYo9iHt4lMbg",
"https://miro.medium.com/fit/c/140/140/1*<a href="https://pipfeed.com/cdn-cgi/l/email-protection" data-cfemail="9cd4caccd5c6d2afc9f6d2ebd6d9abc6dff9e6f8c4c8dddcaee4b2f6ecf9fb">[email&nbsp;protected]</a>",
"https://miro.medium.com/max/60/1*wvlqQPpOHFK7xQ1XOhe6xg.jpeg?q=20",
"https://miro.medium.com/fit/c/140/140/1*mpyrgqwMjfclV2oN1U2VIA.jpeg",
"https://miro.medium.com/fit/c/140/140/0*fG5RLd48iOZezB_y.jpeg",
"https://miro.medium.com/fit/c/140/140/0*aP8H1qpRN_OR1x5r",
"https://miro.medium.com/max/60/1*74Yrxu8s4sOtTECtixv9Fg.jpeg?q=20",
"https://miro.medium.com/max/60/1*FTG-junI6KJzojC_xRVNXg.png?q=20"
],
"blogName": null,
"blogLogoUrl": null,
"html": "&lt;div class=\"page\" id=\"readability-page-1\"&gt;&lt;section&gt;&lt;div&gt;&lt;div&gt;&lt;h2 id=\"ef6b\"&gt;DATA SCIENCE EXPLAINED&lt;/h2&gt;&lt;h2 id=\"e375\"&gt;Here\u2019s what you need to know about evaluating topic models&lt;/h2&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;a rel=\"noopener\" href=\"https://medium.com/@g_rabi?source=post_page-----3c43e2308526--------------------------------\"&gt;&lt;div&gt;&lt;p&gt;&lt;img height=\"28\" width=\"28\" src=\"https://miro.medium.com/fit/c/56/56/2*b2y5uCYazQ9FgiUQEUHT6Q.jpeg\" alt=\"Giri Rabindranath\"&gt;&lt;/p&gt;&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;p id=\"8bff\"&gt;&lt;em&gt;Topic models are widely used for analyzing unstructured text data, but they provide no guidance on the quality of topics produced. Evaluation is the key to understanding topic models. In this article, we\u2019ll look at what topic model evaluation is, why it\u2019s important and how to do it.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;/section&gt;&lt;section&gt;&lt;div&gt;&lt;div&gt;&lt;h2 id=\"324c\"&gt;Contents&lt;/h2&gt;&lt;ul&gt;&lt;li id=\"dd12\"&gt;&lt;a rel=\"noopener\" href=\"#f0ce\"&gt;&lt;em&gt;What is topic model evaluation&lt;/em&gt;&lt;/a&gt;?&lt;/li&gt;&lt;li id=\"ceba\"&gt;&lt;a rel=\"noopener\" href=\"#d1ae\"&gt;&lt;em&gt;How to evaluate topic models&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id=\"ea5d\"&gt;&lt;a rel=\"noopener\" href=\"#2932\"&gt;&lt;em&gt;Evaluating topic models \u2014 Human judgment&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id=\"6275\"&gt;&lt;a rel=\"noopener\" href=\"#9b50\"&gt;&lt;em&gt;Evaluating topic models \u2014 Quantitative metrics&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id=\"ea38\"&gt;&lt;a rel=\"noopener\" href=\"#19ff\"&gt;&lt;em&gt;Calculating coherence using Gensim in Python&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id=\"95a3\"&gt;&lt;a rel=\"noopener\" href=\"#1756\"&gt;&lt;em&gt;Limitations of coherence&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id=\"251a\"&gt;&lt;a rel=\"noopener\" href=\"#63c4\"&gt;&lt;em&gt;How to evaluate topic models \u2014 Recap&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&lt;li id=\"e448\"&gt;&lt;a rel=\"noopener\" href=\"#31aa\"&gt;&lt;em&gt;Conclusion&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p id=\"6f84\"&gt;Topic modeling is a branch of &lt;a rel=\"noopener nofollow\" href=\"https://highdemandskills.com/natural-language-processing-explained-simply/\"&gt;natural language processing&lt;/a&gt; that\u2019s used for exploring text data. It works by identifying key themes \u2014 or topics \u2014 based on the words or phrases in the data that have a similar meaning. Its versatility and ease-of-use have led to a variety of applications.&lt;/p&gt;&lt;p id=\"3772\"&gt;Be&lt;span id=\"rmm\"&gt;i&lt;/span&gt;ng a form of unsupervised learning, topic modeling is useful when annotated or labeled data isn\u2019t available. This is helpful, as the majority of emerging text data isn\u2019t labeled, and labeling is time-consuming and expensive to do.&lt;/p&gt;&lt;p id=\"030c\"&gt;For an easy-to-follow, intuitive explanation of topic modeling and its applications, see &lt;a rel=\"noopener nofollow\" href=\"https://highdemandskills.com/topic-modeling-intuitive/\"&gt;this article&lt;/a&gt;.&lt;/p&gt;&lt;p id=\"fb4a\"&gt;One of the shortcomings of topic modeling is that there\u2019s no guidance about the quality of topics produced. If you want to learn about how meaningful the topics are, you\u2019ll need to evaluate the topic model.&lt;/p&gt;&lt;p id=\"b937\"&gt;In this article, we\u2019ll look at topic model evaluation, what it is and how to do it. It\u2019s an important part of the topic modeling process that sometimes gets overlooked. For a topic model to be truly useful, some sort of evaluation is needed to understand how relevant the topics are for the purpose of the model.&lt;/p&gt;&lt;p id=\"b85d\"&gt;Topic model evaluation is the process of assessing how well a topic model does what it is designed for.&lt;/p&gt;&lt;p id=\"44ee\"&gt;When you run a topic model, you usually do it with a specific purpose in mind. It may be for document classification, to explore a set of unstructured texts, or some other analysis. As with any model, if you wish to know how effective it is at doing what it\u2019s designed for, you\u2019ll need to evaluate it. This is why topic model evaluation matters.&lt;/p&gt;&lt;p id=\"e9c9\"&gt;Evaluating a topic model can help you decide if the model has captured the internal structure of a corpus (a collection of text documents). This can be particularly useful in tasks like e-discovery, where the effectiveness of a topic model can have implications for legal proceedings or other important matters.&lt;/p&gt;&lt;p id=\"a51a\"&gt;More generally, topic model evaluation can help you answer questions like:&lt;/p&gt;&lt;ul&gt;&lt;li id=\"b7ef\"&gt;Are the identified topics understandable?&lt;/li&gt;&lt;li id=\"1d2d\"&gt;Are the topics coherent?&lt;/li&gt;&lt;li id=\"325e\"&gt;Does the topic model serve the purpose it is being used for?&lt;/li&gt;&lt;/ul&gt;&lt;p id=\"da03\"&gt;Without some form of evaluation, you won\u2019t know how well your topic model is performing or if it\u2019s being used properly.&lt;/p&gt;&lt;p id=\"c559\"&gt;Evaluating a topic model isn\u2019t always easy, however.&lt;/p&gt;&lt;p id=\"3adc\"&gt;If a topic model is used for a measurable task, such as classification, then its effectiveness is relatively straightforward to calculate (eg. measure the proportion of successful classifications). But if the model is used for a more qualitative task, such as exploring the semantic themes in an unstructured corpus, then evaluation is more difficult.&lt;/p&gt;&lt;p id=\"ff58\"&gt;In this article, we\u2019ll focus on evaluating topic models that do not have clearly measurable outcomes. These include topic models used for document exploration, content recommendation and e-discovery, amongst other use cases.&lt;/p&gt;&lt;p id=\"dc38\"&gt;E…</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pipfeed.com/2020/11/09/tutorial-extract-full-news-article-content-from-any-rss-feed-using-extract-api/">https://pipfeed.com/2020/11/09/tutorial-extract-full-news-article-content-from-any-rss-feed-using-extract-api/</a></em></p>]]>
            </description>
            <link>https://pipfeed.com/2020/11/09/tutorial-extract-full-news-article-content-from-any-rss-feed-using-extract-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033704</guid>
            <pubDate>Mon, 09 Nov 2020 11:36:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Representation Learning with Autoencoder]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033673">thread link</a>) | @patrycjaneptune
<br/>
November 9, 2020 | https://neptune.ai/blog/understanding-representation-learning-with-autoencoder-everything-you-need-to-know-about-representation-and-feature-learning | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/understanding-representation-learning-with-autoencoder-everything-you-need-to-know-about-representation-and-feature-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p>Machine learning is a subfield of Artificial Intelligence, where we try to build intelligent systems that have the function and behavior of our brain. Through ML, we try to build machines that can compute, extract patterns, automate routine tasks, diagnose biological anomalies, and prove scientific theories and hypotheses.</p>



<p>Because machine learning is a subset of AI, it doesn’t rely on hard-coded algorithms to find its way to the core solution, but it strengthens AI with the idea that it can extract knowledge from given information, and finds its way to the core idea without being hardcoded.&nbsp;</p>



<blockquote><p><strong>With the advent of machine learning, we can now design algorithms that can “tackle problems involving knowledge of the real world and make decisions that appear subjective.”</strong> </p><p>(Ian Goodfellow, “Deep Learning”)</p></blockquote>



<p>Data plays a key role in all machine learning problems.</p>



<p>Why is it so important?&nbsp;</p>



<p>Data is a discrete arrangement of information that offers a continuous series of events. In this arrangement, the whole patterns of representation are hidden. If a machine can extract patterns that represent a particular event, we can say that the machine has learned that information, and if new data or information is fed into it then it can provide appropriate solutions and predictions.</p>






<h2>Representation Learning</h2>



<p>Imagine an engineer designing an ML algorithm to predict malignant cells based on brain scans. To design the algorithm, the engineer has to rely heavily on patient data, because that’s where all the answers are.&nbsp;</p>



<p>Each observation or feature in that data describes the attributes of the patient. The machine learning algorithm that predicts the outcome has to learn how each feature correlates with the different outcomes: benign or malignant.</p>



<p>So in case of any noise or discrepancies in the data, the outcome can be totally different, which is the problem with most machine learning algorithms. Most machine learning algorithms have a superficial understanding of the data.&nbsp;</p>



<p>So what is the solution?</p>



<p><strong>Provide the machine with a more abstract representation of the data.&nbsp;</strong></p>



<p>For many tasks, it is impossible to know what features should be extracted. Alan Turing and his colleagues deciphering the enigma code observed the patterns that were regularly appearing in the messages. This is where the<a href="https://opensource.com/article/17/9/representation-learning" target="_blank" rel="noreferrer noopener nofollow"> idea of representation learning </a>truly comes into view.&nbsp;</p>



<p>In representation learning, the machine is provided with data and it learns the representation by itself. It’s a method of finding a representation of the data – the features, the distance function, the similarity function– that dictates how the predictive model will perform.&nbsp;</p>



<p>Representation learning works by reducing high-dimensional data into low-dimensional data, making it easier to find patterns, anomalies, and also giving us a better understanding of the behavior of the data altogether.&nbsp;</p>



<p>It also reduces the complexity of the data, so the anomalies and noise are reduced. This reduction in noise can be very useful for supervised learning algorithms.&nbsp;</p>






<h3><strong>Invariance and disentangling</strong></h3>



<p>The problem with representation learning is that it’s very difficult to get representations that can solve a given problem. Luckily, deep learning and deep neural networks started to prove very much goal-oriented and efficient.&nbsp;</p>



<p>The idea that deep neural networks can build complex concepts out of simple concepts lies at the core of deep learning [Ian Goodfellow, “Deep learning”].&nbsp;</p>



<p><strong>So where does the idea of representation learning fit in?</strong></p>



<p>People try to understand the success of deep learning. The two main conclusions are<a href="https://opensource.com/article/17/9/representation-learning" target="_blank" rel="noreferrer noopener nofollow"> <strong>representation learning </strong></a>and<strong> optimization</strong>.&nbsp;</p>



<p>Deep learning is often seen as a black box, where a finite number of functions are used to find parameters that yield good generalization. This is achieved by optimization where the algorithm tries to correct itself by evaluating the model output with the ground truth.&nbsp;</p>



<hr>



<p><strong><sup>EDITOR’S NOTE<br></sup></strong>Check also: <a href="https://neptune.ai/blog/the-ultimate-guide-to-evaluation-and-selection-of-models-in-machine-learning" target="_blank" rel="noreferrer noopener nofollow">The Ultimate Guide to Evaluation and Selection of Models in Machine Learning</a></p>



<hr>



<p>This process is done until the optimization function reaches a minimum point called the global minima. Most deep learning networks are heavily over-parameterized and suggest that they may overfit – where the algorithm performs well on training data but fails to perform well in new data. Recent work suggests that this is related to properties of the loss landscape, and to the implicit regularization performed by stochastic gradient descent (SGD), but the overall output is still noisy [Zhang et al., 2017].</p>



<p>Representation learning, on the other hand, focuses on the properties of the representation learned by the layers of the network (the activations) while remaining largely agnostic to the particular optimization process used [Emergence of Invariance and Disentanglement in Deep Representations, 2018].&nbsp;</p>



<p>Two major factors that usually occur in any data distribution are <strong>variance</strong> and <strong>entanglement</strong>. These two factors need to be eliminated to get a good representation from the data. Variance in the data can also be considered the sensitivity, and these sensitivities can turn the outcome upside down. Any model that we build has to be robust to variance, i.e. it has to be invariant because this can greatly harm the outcome of a deep learning model.</p>



<p>Entanglement is the way a vector in the data is connected or correlated to other vectors in the data. These connections make the data very complex and hard to decipher. What we are supposed to do is look for variables where the relationship is simple. It’s an easy way to transform high dimensional data into low dimensional data, or to transform high-dimensional data in a way that can be easily separated.&nbsp;</p>



<p>From the previous section, we learned that the ability of representation learning is that it learns abstract patterns that make sense to the data, while deep learning is often ascribed the ability of deep networks to learn representations that are invariant (insensitive) to nuisance such as translations, rotations, occlusions, and also “disentangled”,&nbsp;or separating factors in the high-dimensional space of data [Bengio, 2009]. But it is still important to learn to simplify a complex arrangement of data by creating models that are invariant and untangled.</p>



<blockquote><p>“If neither the architecture nor the loss function explicitly enforce invariance and disentangling, how can these properties emerge consistently in deep networks trained by simple generic optimization?”</p></blockquote>



<p>It turns out that we can answer this question by showing two things:&nbsp;</p>



<ol><li>Using classical notions of statistical decision and information theory, we show that invariance in a deep neural network is equivalent to the minimum of the representation it computes, and can be achieved by <strong>stacking layers</strong> and injecting noise in the computation, under realistic and empirically validated assumptions.</li><li>Using an Information Decomposition of the empirical loss, we show that overfitting can be reduced by <strong>limiting the information content stored in the weights</strong>. [Emergence of Invariance and Disentanglement in Deep Representations, 2018].</li></ol>






<h3><strong>The Information Bottleneck</strong></h3>



<p>Information Bottleneck (IB) was introduced by Tishby et al. (1999). It was introduced with a hypothesis that it can extract relevant information by compressing the amount of information that can traverse the full network, forcing a learned compression of the input data.&nbsp;</p>



<p>This compressed representation not only reduces dimensions but along with it reduces the complexity of the data as well [Deep Learning and the Information Bottleneck Principle, Tishby 2015]. The idea is that a network rids noisy input data of extraneous details as if by squeezing the information through a bottleneck, leaving only the features most relevant to general concepts.&nbsp;</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/neptune.ai/wp-content/uploads/information-bottleneck.png?resize=512%2C384&amp;ssl=1" alt="information bottleneck" width="512" height="384" srcset="https://i1.wp.com/neptune.ai/wp-content/uploads/information-bottleneck.png?resize=1024%2C768&amp;ssl=1 1024w, https://i1.wp.com/neptune.ai/wp-content/uploads/information-bottleneck.png?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/neptune.ai/wp-content/uploads/information-bottleneck.png?resize=768%2C576&amp;ssl=1 768w, https://i1.wp.com/neptune.ai/wp-content/uploads/information-bottleneck.png?resize=1536%2C1152&amp;ssl=1 1536w, https://i1.wp.com/neptune.ai/wp-content/uploads/information-bottleneck.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1"></figure></div>



<p>Tishby’s findings have the AI community buzzing. “I believe that the information bottleneck idea could be very important in future deep neural network research”, said Alex Alemi of Google Research, who has already developed new approximation methods for applying an information bottleneck analysis to large deep neural networks. The bottleneck could serve “not only as a theoretical tool for understanding why our neural networks work as well as they do currently but also as a tool for constructing new objectives and architectures of networks,” Alemi said.</p>






<h3><strong>Latent variables</strong></h3>



<p>A latent variable is a random variable that cannot be observed directly, but it lays the foundation of how the data is distributed. Latent variables also give us a low-level representation of high-dimensional data. They give us an abstract representation of how the data is distributed.&nbsp;</p>



<div><figure><img loading="lazy" width="495" height="200" src="https://i0.wp.com/neptune.ai/wp-content/uploads/latent-variables.png?resize=495%2C200&amp;ssl=1" alt="latent variables" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/latent-variables.png?w=495&amp;ssl=1 495w, https://i0.wp.com/neptune.ai/wp-content/uploads/latent-variables.png?resize=300%2C121&amp;ssl=1 300w" sizes="(max-width: 495px) 100vw, 495px" data-recalc-dims="1"></figure></div>



<p>So why do we need latent variables?</p>



<p>All machine learning has a definite problem of learning complicated probability distribution <em>p(x)</em>. And these distributions are <strong>constrained</strong>, with only a limited set of high-dimensional data points <em>x</em> drawn from this distribution.&nbsp;</p>



<p>For example, to learn the probability distribution over images of cats we need to define a <strong>distribution that</strong> can model complex correlations between all pixels which form each image. Modelling this distribution directly is a tedious and challenging task, even unfeasible infinite time. Instead of modelling <em>p(x) </em>directly, we can introduce an (unobserved) latent variable z and define a conditional distribution <em>p(x | z)</em> for the data, which is called a likelihood. In probabilistic terms, <em>z</em> can be interpreted as a continuous random variable. For the example of cat images, z could contain a hidden representation of the type of cat, its color, or shape.</p>



<p>Having z, we can further introduce a<strong> prior distribution</strong> <em>p(z</em>) over the latent variables to compute the joint distribution over observed and latent variables <em>p(x,z) = p(x|z)p(z)</em>.&nbsp;</p>



<p>To obtain the data distribution <em>p(x) </em>we need to marginalize over the latent variables.&nbsp;</p>



<div><figure><img src="https://latex.codecogs.com/gif.latex?%5Cdpi%7B120%7D%20%5Clarge%20p%28x%29%20%3D%20%5Cint%20p%28x%2Cz%29dz%20%3D%20%5Cint%20p%28x%7Cz%29p%28z%29dz" alt="" title="This is the rendered form of the equation. You can not edit this directly. Right click will give you the option to save the image, and in most browsers you can drag the image onto your desktop or another program."></figure></div>



<p>Prior to that we can compute <strong>posterior …</strong></p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/understanding-representation-learning-with-autoencoder-everything-you-need-to-know-about-representation-and-feature-learning">https://neptune.ai/blog/understanding-representation-learning-with-autoencoder-everything-you-need-to-know-about-representation-and-feature-learning</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/understanding-representation-learning-with-autoencoder-everything-you-need-to-know-about-representation-and-feature-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033673</guid>
            <pubDate>Mon, 09 Nov 2020 11:32:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief History of Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033660">thread link</a>) | @JKooll
<br/>
November 9, 2020 | https://bestproductsreviews.com.au/a-brief-history-of-python/ | <a href="https://web.archive.org/web/*/https://bestproductsreviews.com.au/a-brief-history-of-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><ul><li><a data-class="popup" data-network="facebook" href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fbestproductsreviews.com.au%2Fa-brief-history-of-python%2F" target="_blank" rel="nofollow"><span></span> </a></li><li><a data-class="popup" data-network="twitter" href="https://twitter.com/intent/tweet?text=A%20Brief%20History%20of%20Python&amp;url=https%3A%2F%2Fbestproductsreviews.com.au%2Fa-brief-history-of-python%2F" target="_blank" rel="nofollow"><span></span> </a></li><li><a data-class="popup" data-network="google-plus" href="https://plus.google.com/share?url=https%3A%2F%2Fbestproductsreviews.com.au%2Fa-brief-history-of-python%2F" target="_blank" rel="nofollow"><span></span> </a></li><li><a data-class="popup" data-network="pinterest" href="https://pinterest.com/pin/create/button/?url=https%3A%2F%2Fbestproductsreviews.com.au%2Fa-brief-history-of-python%2F&amp;description=Python+is+my+favourite+language%2C+concise%2C+beautiful%2C+and+easy+to+use.%26nbsp%3BTwo+days+ago%2C+I+was+very+excited+to+promote+the+benefits+of+Python+to+my+friends.+After+listening+to+it%2C+my+friend+asked+me%3A+Okay%2C+I+admit+that+Python+is+good%2C+but+why+is+it+called+Python%3F+I%27m+not+sure%3A+Well%2C+it+seems+to+be+the+name+of+a+TV+show.+The+friend+asked+again%3A+Is+Guido+you+mentioned+as+an+American%3F%26nbsp%3B%28Guido+von+Rossum%2C+author+of+Python%29+I%27m+not+sure+again%3A+he+switched+from+Google+to+work+in+Dropbox%2C+but+his+name+is+Dutch+%28with+a+von+in+the+middle%29.&amp;media=https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06121511-82e43957fefe4c13ac06bd02a5e9d97a.png" target="_blank" rel="nofollow"><span></span> </a></li><li><a data-class="popup" data-network="fintel" href="https://fintel.io/share?url=https%3A%2F%2Fbestproductsreviews.com.au%2Fa-brief-history-of-python%2F" target="_blank" rel="nofollow"><span></span></a></li></ul>
<p><a href="https://bestproductsreviews.com.au/awesome-python-books/">Python</a> is my favourite language, concise, beautiful, and easy to use.&nbsp;Two days ago, I was very excited to promote the benefits of Python to my friends.</p>
<p>After listening to it, my friend asked me: Okay, I admit that Python is good, but why is it called Python?</p>
<p>I’m not sure: Well, it seems to be the name of a TV show.</p>
<p>The friend asked again: Is Guido you mentioned as an American?&nbsp;(Guido von Rossum, author of Python)</p>
<p>I’m not sure again: he switched from Google to work in Dropbox, but his name is Dutch (with a von in the middle).</p>
<p>So, I spent some time investigating the history of Python later.&nbsp;This is good learning.&nbsp;I have seen the source of many functions in Python and the design philosophy of Python, such as which functions are leftover from history, which functions are repetitive, how to add functions… Moreover, Python is also a successful case of the open-source movement.&nbsp;From the history of Python, we can get a glimpse of the concepts and achievements of open source development.</p>
<h2>The origin of Python</h2>
<p>The author of Python, Guido von Rossum, is indeed Dutch.&nbsp;In 1982, Guido received a master’s degree in mathematics and computer science from the University of Amsterdam.&nbsp;However, although he can be regarded as a mathematician, he enjoys the fun of computers even more.&nbsp;In his words, although he possesses both mathematics and computer qualifications, he always tends to do computer-related work and is keen to do any programming-related work.</p>
<div><figure><img width="400" height="600" src="https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06100633-c2ce8755002945df846b5dad1dc25cdd.jpg" alt="python, Best Products Reviews - Tita" srcset="https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06100633-c2ce8755002945df846b5dad1dc25cdd.jpg 400w, https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06100633-c2ce8755002945df846b5dad1dc25cdd-200x300.jpg 200w" sizes="(max-width: 400px) 100vw, 400px" title="A Brief History of Python 2" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20400%20600'%3E%3C/svg%3E" data-lazy-srcset="https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06100633-c2ce8755002945df846b5dad1dc25cdd.jpg 400w, https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06100633-c2ce8755002945df846b5dad1dc25cdd-200x300.jpg 200w" data-lazy-src="https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06100633-c2ce8755002945df846b5dad1dc25cdd.jpg"><figcaption>Guido von Rossum</figcaption></figure></div>
<p>At that time, he was exposed to and used languages ​​such as Pascal, C, Fortran, etc.&nbsp;The basic design principle of these languages ​​is to make machines run faster.&nbsp;In the 1980s, although IBM and Apple had set off a wave of personal computers, the configuration of these personal computers was very low (in today’s view).&nbsp;For example, in the early Macintosh, only 8MHz CPU frequency and 128KB RAM, a large array can fill the memory.&nbsp;The core of all compilers is to optimize so that the program can run.&nbsp;In order to increase efficiency, language also forces programmers to think like computers so that they can write programs that are more in line with machine tastes.&nbsp;In that era, programmers could not wait to squeeze every inch of computer power with their hands.&nbsp;Some people even think that C language pointers are a waste of memory.&nbsp;As for dynamic typing, automatic memory management, object-oriented… Don’t think about it, it will paralyze your computer.</p>
<p>However, this way of thinking makes Guido feel distressed.&nbsp;Guido knows how to write a function in C language, but the whole writing process takes a lot of time (even if he already knows exactly how to implement it).&nbsp;His other option is the shell.&nbsp;Bourne Shell has long existed as an interpreter for UNIX systems.&nbsp;UNIX administrators often use shells to write simple scripts to perform some system maintenance tasks, such as regular backups, file system management, and so on.&nbsp;The shell can be like glue, connecting many functions under UNIX together.&nbsp;Many programs with hundreds of lines in the C language can be completed in just a few lines in the shell.&nbsp;However, the essence of the shell is to invoke commands.&nbsp;It is not a real language.&nbsp;For example, the shell has no numeric data types, and addition operations are very complicated.&nbsp;In short, the shell cannot fully mobilize the computer’s functions.</p>
<p>(For shell, you can refer to&nbsp;<a aria-label=" (opens in a new tab)" href="https://amzn.to/3khj35T" target="_blank" rel="noreferrer noopener nofollow">How Linux Works</a>&nbsp;and&nbsp;<a label=" (opens in a new tab)" href="https://amzn.to/35cJzJK" target="_blank" rel="noreferrer noopener nofollow">The Linux Command Line</a>&nbsp;)</p>
<p>Guido hopes that there is a language that can fully call the computer’s functional interfaces like C language, and can be easily programmed like a shell.&nbsp;ABC language gave Guido hope.&nbsp;ABC was developed by CWI (&nbsp;Centrum Wiskunde &amp; Informatica, Institute of Mathematics and Computers) in the&nbsp;Netherlands.&nbsp;Guido works at CWI and participated in the development of the ABC language.&nbsp;ABC language is for the purpose of teaching.&nbsp;Unlike most languages ​​at the time, the goal of ABC language was to&nbsp;“make users feel better.&nbsp;”&nbsp;ABC language hopes to make the language&nbsp;easy to read, easy to use, easy to remember, easy to learn&nbsp;and to stimulate people’s interest in learning programming.&nbsp;For example, the following is an ABC program from Wikipedia, this program is used to count the total number of words that appear in the text:</p>
<pre><code>HOW TO RETURN words document:
   PUT {} IN collection
   FOR line IN document:
      FOR word IN split line:
         IF word not.in collection:
            INSERT word IN collection
   RETURN collection</code></pre>
<p>HOW TO is used to define a function.&nbsp;A Python programmer should easily understand this program.&nbsp;ABC language uses colons (:) and indentation to indicate program blocks (C language uses {} to indicate program blocks).&nbsp;There is no semicolon at the end of the line.&nbsp;There are no parentheses () in the for and if structures.&nbsp;If you change HOW TO to def, change the PUT line to collection = [] and change the INSERT line to collection.append(word), this is almost a standard Python function.&nbsp;The above function reads like a natural text.</p>
<p>Despite having good readability and ease of use, the ABC language did not become popular in the end.&nbsp;At that time, the ABC language compiler needed a relatively high-end computer to run.&nbsp;The users of these computers are usually proficient in computers, and they consider the efficiency of the program more than the difficulty of learning.&nbsp;In addition to hardware difficulties, the design of the ABC language also has some fatal problems:</p>
<ul><li><strong>Poor scalability</strong>.&nbsp;The ABC language is not a modular language.&nbsp;If you want to add features to the ABC language, such as graphical support, you must change many places.</li><li><strong>Cannot directly perform IO</strong>.&nbsp;The ABC language cannot directly manipulate the file system.&nbsp;Although you can import data through methods such as text streaming, ABC cannot read and write files directly.&nbsp;The difficulty of input and output is fatal to computer languages.&nbsp;Can you imagine a sports car that can’t open the door?</li><li><strong>Over-renovation</strong>.&nbsp;ABC uses natural language to express the meaning of the program, such as HOW TO in the program above.&nbsp;However, for programmers, they are more accustomed to using the function or define to define a function.&nbsp;Similarly, programmers are also used to assigning variables with the equal sign (=).&nbsp;Although this makes the ABC language special, it actually increases the difficulty of learning for programmers (most programmers master more than one language).</li><li><strong>Difficult to spread</strong>.&nbsp;The ABC compiler is large and must be stored on tape.&nbsp;When Guido was visiting, he had to have a large tape to install the ABC compiler for others.&nbsp;In this way, ABC language is difficult to spread quickly.</li></ul>
<div><figure><img width="469" height="666" src="https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06111717-51622dbe8fbb4e54ae64f834584180c0.gif" alt="python, Best Products Reviews - Tita" title="A Brief History of Python 3" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20469%20666'%3E%3C/svg%3E"></figure></div>
<p>In 1989, in order to pass the Christmas holiday, Guido began to write a compiler/interpreter for the Python language.&nbsp;Python comes from Guido’s beloved TV series Monty Python’s Flying Circus (BBC 1960s-70s indoor sitcoms, based on British life at the time).&nbsp;He hopes that this new language called Python can realize his idea (a language between C and shell, with comprehensive functions, easy to learn, easy to use, and extensible).&nbsp;As a language design lover, Guido has already had (not very successful) attempts to design languages.&nbsp;This time, it was just a pure hacking behavior.</p>
<h2>The birth of Python</h2>
<p>In 1991, the first Python compiler (also an interpreter) was born.&nbsp;It is implemented in C language and can call C library (.so file).&nbsp;From its birth, Python has: classes, functions, exception handling, core data types including lists and dictionaries, and module-based Expand the system.</p>
<div><figure><img width="348" height="96" src="https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06121511-82e43957fefe4c13ac06bd02a5e9d97a.png" alt="python, Best Products Reviews - Tita" srcset="https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06121511-82e43957fefe4c13ac06bd02a5e9d97a.png 348w, https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06121511-82e43957fefe4c13ac06bd02a5e9d97a-300x83.png 300w" sizes="(max-width: 348px) 100vw, 348px" title="A Brief History of Python 4" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20348%2096'%3E%3C/svg%3E" data-lazy-srcset="https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06121511-82e43957fefe4c13ac06bd02a5e9d97a.png 348w, https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06121511-82e43957fefe4c13ac06bd02a5e9d97a-300x83.png 300w" data-lazy-src="https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06121511-82e43957fefe4c13ac06bd02a5e9d97a.png"><figcaption>The original Python logo: Designed by Guido’s brother Just von Rossum</figcaption></figure></div>
<p>A lot of Python syntax comes from C, but it is strongly influenced by the ABC language.&nbsp;Some regulations from the ABC language are still controversial today, such as mandatory indentation.&nbsp;However, these provisions allow Python syntax&nbsp;content&nbsp;easy to read&nbsp;.&nbsp;On the other hand, Python cleverly chooses to obey some conventions (especially the conventions of the C language).&nbsp;For example, use the equal sign to assign values ​​and use def to define functions.&nbsp;Guido believes that if something is established on “common sense”, there is no need to over-entangle it.</p>
<p>Python has been particularly concerned&nbsp;with&nbsp;extensibility&nbsp;from the beginning.&nbsp;Python can be extended on multiple levels.&nbsp;At a high level, you can import .py files.&nbsp;At the bottom, you can reference C language libraries.&nbsp;Python programmers can quickly use Python to write .py files as extension modules.&nbsp;But when performance is an important factor to consider, Python programmers can go deep into the bottom layer, write C programs, compile them into .so files and import them into Python.&nbsp;Python is like using steel to build a house, first prescribe a big frame.&nbsp;The programmer can expand or change quite freely under this framework.</p>
<p>The original Python was developed entirely by Guido himself.&nbsp;Python is welcomed by Guido colleagues.&nbsp;They quickly gave feedback on usage opinions and participated in the improvement of Python.&nbsp;Guido and some colleagues form the core team of Python.&nbsp;They spend most of their free time hacking Python (including work time because they use Python for work).&nbsp;Subsequently, Python expanded beyond CWI.&nbsp;Python hides many details on the machine level and hands them to the compiler for processing, and highlights the logic of programming thinking.&nbsp;Python programmers can spend more time thinking about the logic of the program, rather than the specific implementation details (Guido has a T-shirt that says: Life is short, I use Python).&nbsp;This feature has attracted the majority of programmers.&nbsp;Python became popular.</p>
<p>We had to pause our Python time and take a look at the computer overview at this time.&nbsp;In the early 1990s, personal computers began to enter ordinary households.&nbsp;Intel released the 486 processor, and Windows released a series of window systems starting with Window 3.0.&nbsp;The performance of the computer is greatly improved.&nbsp;Programmers began to pay attention to the ease of use of computers (such as graphical interfaces).</p>
<div><figure><img width="640" height="480" src="https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06121437-2bed48b285d746c2a147d1d63cc05483.png" alt="python, Best Products Reviews - Tita" srcset="https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06121437-2bed48b285d746c2a147d1d63cc05483.png 640w, https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06121437-2bed48b285d746c2a147d1d63cc05483-300x225.png 300w" sizes="(max-width: 640px) 100vw, 640px" title="A Brief History of Python 5" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20640%20480'%3E%3C/svg%3E" data-lazy-srcset="https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06121437-2bed48b285d746c2a147d1d63cc05483.png 640w, https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06121437-2bed48b285d746c2a147d1d63cc05483-300x225.png 300w" data-lazy-src="https://bestproductsreviews.com.au/wp-content/uploads/2020/11/06121437-2bed48b285d746c2a147d1d63cc05483.png"><figcaption>Win…</figcaption></figure></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bestproductsreviews.com.au/a-brief-history-of-python/">https://bestproductsreviews.com.au/a-brief-history-of-python/</a></em></p>]]>
            </description>
            <link>https://bestproductsreviews.com.au/a-brief-history-of-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033660</guid>
            <pubDate>Mon, 09 Nov 2020 11:30:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Train Your Own Object Detector Using TensorFlow Object Detection API]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033619">thread link</a>) | @patrycjaneptune
<br/>
November 9, 2020 | https://neptune.ai/blog/how-to-train-your-own-object-detector-using-tensorflow-object-detection-api | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/how-to-train-your-own-object-detector-using-tensorflow-object-detection-api">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p>Object detection is a computer vision task that has recently been influenced by the progress made in Machine Learning.&nbsp;</p>



<p>In the past, creating a custom object detector looked like a time-consuming and challenging task. Now, with tools like <a href="https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/index.html" target="_blank" rel="noreferrer noopener nofollow">TensorFlow Object Detection API</a>, we can create reliable models quickly and with ease.</p>



<div><figure><img loading="lazy" src="https://i2.wp.com/neptune.ai/wp-content/uploads/object-detection-tensorflow.png?resize=769%2C385&amp;ssl=1" alt="object detection tensorflow" width="769" height="385" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/object-detection-tensorflow.png?w=1025&amp;ssl=1 1025w, https://i2.wp.com/neptune.ai/wp-content/uploads/object-detection-tensorflow.png?resize=300%2C150&amp;ssl=1 300w, https://i2.wp.com/neptune.ai/wp-content/uploads/object-detection-tensorflow.png?resize=768%2C384&amp;ssl=1 768w" sizes="(max-width: 769px) 100vw, 769px" data-recalc-dims="1"></figure></div>



<p><em>Object Detection task solved by TensorFlow | Source: <a href="https://blog.tensorflow.org/2020/07/tensorflow-2-meets-object-detection-api.html" target="_blank" rel="noreferrer noopener nofollow">TensorFlow 2 meets the Object Detection API</a></em></p>



<p>In this article we will focus on the second generation of the TensorFlow Object Detection API, which:</p>



<ul><li>supports TensorFlow 2,&nbsp;&nbsp;</li><li>lets you employ state of the art model architectures for object detection,&nbsp;</li><li>gives you a simple way to configure models.</li></ul>



<p>If you’re interested to know all of the features available in TensorFlow 2 and its API, you can find them in the <a href="https://blog.tensorflow.org/2020/07/tensorflow-2-meets-object-detection-api.html" target="_blank" rel="noreferrer noopener nofollow">official announcement from Google</a>.</p>



<p><strong>After reading this article, you should be able to create your own custom object detector.&nbsp;</strong></p>



<p>We’ll be using the <a href="https://ai.googleblog.com/2020/04/efficientdet-towards-scalable-and.html" target="_blank" rel="noreferrer noopener nofollow">EfficientDet based model</a> as an example, but you will also learn how to use <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md" target="_blank" rel="noreferrer noopener nofollow">any architecture</a> of your choice to get a model up and running. Stay tuned! Your own object detector is just around the corner.</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/neptune.ai/wp-content/uploads/object-detection-api.jpg?resize=768%2C512&amp;ssl=1" alt="object detection api" width="768" height="512" srcset="https://i1.wp.com/neptune.ai/wp-content/uploads/object-detection-api.jpg?resize=1024%2C682&amp;ssl=1 1024w, https://i1.wp.com/neptune.ai/wp-content/uploads/object-detection-api.jpg?resize=300%2C200&amp;ssl=1 300w, https://i1.wp.com/neptune.ai/wp-content/uploads/object-detection-api.jpg?resize=768%2C512&amp;ssl=1 768w, https://i1.wp.com/neptune.ai/wp-content/uploads/object-detection-api.jpg?w=1351&amp;ssl=1 1351w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1"></figure></div>



<p><em>Output example for a model trained using TF Object Detection API. | Source: <a href="https://github.com/tensorflow/models/tree/master/research/object_detection" target="_blank" rel="noreferrer noopener nofollow">Official TF Object Detection API GitHub page</a></em></p>






<h2>Before you start</h2>



<p>Let me briefly talk about the prerequisites that are essential to proceed towards your own object detector:&nbsp;</p>



<ul><li>You should have Python installed on your computer. In case you need to install it, I recommend <a href="https://docs.anaconda.com/anaconda/install/" target="_blank" rel="noreferrer noopener nofollow">following this official guide by Anaconda</a>.</li><li>If your computer has a CUDA-enabled GPU (a GPU made by NVIDIA), then a few relevant libraries are needed in order to support GPU-based training. In case you need to enable GPU support, check the <a href="https://docs.nvidia.com/cuda/archive/10.1/index.html#installation-guides" target="_blank" rel="noreferrer noopener nofollow">guidelines</a> on NVIDIA’s website. Your goal is to install the latest version of both the CUDA Toolkit, and cuDNN for your operating system.</li></ul>






<h2>Installation and setup</h2>



<p>Let’s first make sure that we have everything needed to start working with the TensorFlow Object Detection API. I’ll go over the entire setup process, and explain every step to get things working.</p>



<p>If you’ve already worked with the TF API, you can still have a quick glance over this part, just to make sure that we’re following the same direction.&nbsp;</p>



<p>But if it is your first time installing Tensorflow Object detection API, I would highly recommend completing all of the steps in this section. Let’s jump in!</p>



<hr>



<p><strong><span><span><sup>EDITOR’S NOTE</sup><br></span></span></strong><a href="https://neptune.ai/integrations/tensorflow" target="_blank" rel="noreferrer noopener nofollow">Did you know that you can use TensorFlow for training deep learning models and Neptune for experiment tracking?</a></p>



<hr>



<h3><strong>1. Creating a project directory</strong></h3>



<p>Under a path of your choice, create a new folder. Name it <code>Tensorflow</code>.</p>



<h3><strong>2. Creating a new virtual environment </strong></h3>



<ul><li>Open a <em>Terminal </em>window<em> </em>and use the <code>cd</code> command to navigate to the <code>Tensorflow</code> folder created in step 1.</li></ul>



<ul><li>Create a new virtual environment using the <code>venv</code> library:</li></ul>



<p>If you already have <code>venv</code> installed on your machine (or you prefer managing environments with another tool like <em><a href="https://www.anaconda.com/" target="_blank" rel="noreferrer noopener nofollow">Anaconda</a></em>), then proceed directly to new environment creation.&nbsp;</p>



<p>In case you don’t know what <code>venv</code> is or don’t have it installed, you can do it by typing the following command in your <em>Terminal</em> window:</p>



<pre>pip install venv                                                         
</pre>



<p>In order to create a new environment using <code>venv</code>, type the following command in your <em>Terminal</em> window:</p>



<pre>python -m venv tf2_api_env 
</pre>



<p>Once executed, a new virtual environment named <code>tf2_api_env</code> will be created by <code>venv</code>.</p>



<ul><li>Activate newly created virtual environment:</li></ul>



<p>In order to activate the virtual environment that we’ve just created, you first need to make sure that your current working directory is <code>Tensorflow</code>. You can check your current working directory by typing and executing the following command in your <em>Terminal</em> window:</p>



<pre>pwd 
</pre>



<p>In order to activate your virtual environment, run the following command from you <em>Terminal</em> window:</p>



<pre>source tf2_api_env/bin/activate</pre>



<p>If you see the name of your environment at the beginning of the command line within your <em>Terminal</em> window, then you are all set. It should look like this:</p>



<div><figure><img loading="lazy" width="731" height="485" src="https://i0.wp.com/neptune.ai/wp-content/uploads/virtual-environment-activation.png?resize=731%2C485&amp;ssl=1" alt="virtual environment activation" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/virtual-environment-activation.png?w=731&amp;ssl=1 731w, https://i0.wp.com/neptune.ai/wp-content/uploads/virtual-environment-activation.png?resize=300%2C199&amp;ssl=1 300w" sizes="(max-width: 731px) 100vw, 731px" data-recalc-dims="1"></figure></div>



<p><em>Successful virtual environment activation in the Terminal window</em></p>



<ul><li>Install core library</li></ul>



<p>It’s time to install TensorFlow in our environment. Make sure that your environment is activated, and do the installation by executing the following command:</p>



<pre>pip install tensorflow==<span>2.</span>* 
</pre>



<p><strong>NOTE: </strong>as I’m writing this article, the latest TensorFlow version is 2.3. You can use this version, but it’s not a requirement. Everything we do in this guide is compatible with 2.3, and it might also work with later updates. It’s up to you to try. In case of any problems, you can always downgrade to 2.3 and move on.</p>



<h3><strong>3. Download and extract TensorFlow Model Garden</strong></h3>



<p>Model Garden is an official TensorFlow repository on <a href="http://github.com/" target="_blank" rel="noreferrer noopener nofollow">github.com</a>. In this step we want to clone this repo to our local machine.</p>



<ul><li>Make sure that within your <em>Terminal </em>window you’re located in the <code>Tensorflow</code> directory.</li></ul>



<ul><li>In your web browser, go to <a href="https://github.com/tensorflow/models" target="_blank" rel="noreferrer noopener nofollow">Model Garden Repo</a> and click on the <em>Code</em> button in order to select a cloning method that’s best for you (the options are HTTPS, SSH or GitHub CLI).</li></ul>



<div><figure><img loading="lazy" width="1024" height="645" src="https://i2.wp.com/neptune.ai/wp-content/uploads/cloning-method.png?resize=1024%2C645&amp;ssl=1" alt="cloning metod" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/cloning-method.png?resize=1024%2C645&amp;ssl=1 1024w, https://i2.wp.com/neptune.ai/wp-content/uploads/cloning-method.png?resize=300%2C189&amp;ssl=1 300w, https://i2.wp.com/neptune.ai/wp-content/uploads/cloning-method.png?resize=768%2C484&amp;ssl=1 768w, https://i2.wp.com/neptune.ai/wp-content/uploads/cloning-method.png?w=1372&amp;ssl=1 1372w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure></div>



<p><em>Selecting a cloning method for an official Model Garder Tensorflow repo</em></p>



<ul><li>Once you select the cloning method, clone the repo to your local <code>Tensorflow</code> directory. In case you need extra help with cloning, check <a href="https://docs.github.com/en/enterprise/2.13/user/articles/cloning-a-repository" target="_blank" rel="noreferrer noopener nofollow">this official GitHub guide</a>.</li></ul>



<p>By now you should have the following structure under the <code>Tensorflow</code> directory:</p>



<pre>Tensorflow/
└─ tf2_api_env/
   ├─ bin/
   ├─ include/
   └── …
└─ models/
   ├─ community/
   ├─ official/
   ├─ orbit/
   └── …
</pre>



<h3><strong>4. Download, install and compile Protobuf</strong></h3>



<p>By default, the TensorFlow Object Detection API uses Protobuf to configure model and training parameters, so we need this library to move on.</p>



<ul><li>Go to the <a href="https://github.com/protocolbuffers/protobuf/releases" target="_blank" rel="noreferrer noopener nofollow">official protoc release page</a> and download an archive for the latest protobuf version compatible with your operation system and processor architecture.&nbsp;</li></ul>



<p>For example, I’m using <em>Ubuntu</em>. My CPU is <em>AMD64</em> (64-bit processor). As I’m writing this article, the latest protoc version is <em>3.13.0</em>. Given all of that information, I am downloading <em>protoc-3.13.0-linux-x86_64.zip</em> file from the official protoc release page.</p>



<ul><li>In the <code>Tensorflow</code> project directory, create a new folder called <code>protoc</code>. Extract the content of the downloaded archive to the <code>Tensorflow/protoc</code> directory.&nbsp;</li></ul>



<p>Now your <code>Tensorflow</code> directory structure should look like this:</p>



<pre>Tensorflow/
└─ protoc/
   ├─ bin/
   ├─ include/
   ├─ readme.txt
└─ tf2_api_env/
   ├─ bin/
   ├─ include/
   └── …
└─ models/
   ├─ community/
   ├─ official/
   ├─ orbit/
   └── …
</pre>



<ul><li>Compile all proto files</li></ul>



<p>Make sure that in your <em>Terminal </em>window, you’re located in the <code>Tensorflow</code> directory. To compile proto files, execute this command:</p>



<pre>protoc/bin/protoc models/research/object_detection/protos/*.proto
--python_out=.
</pre>



<h3><strong>5. Install COCO API</strong></h3>



<p>COCO API is a dependency that does not go directly with the Object Detection API. You should install it separately. Manual installation of COCO API introduces a few new features (e.g. set of popular <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/evaluation_protocols.md" target="_blank" rel="noreferrer noopener nofollow">detection or/and segmentation metrics</a> becomes available for model evaluation). Installation goes as follows:</p>



<p>If you’re using Windows:</p>



<ul><li>Make sure that within your <em>Terminal </em>window you’re located in the <code>Tensorflow</code> directory. Run the following commands one by one:</li></ul>



<pre>pip install cython
pip install git+https://github.com/philferriere/cocoapi.git
</pre>



<p>If you’re using Linux:</p>



<ul><li>Make sure that within your <em>Terminal </em>window you’re located in the <code>Tensorflow</code> directory. Run the following commands one by one:</li></ul>



<pre>pip install cython
git clone https://github.com/cocodataset/cocoapi.git
cd cocoapi/PythonAPI
make
cp -r pycocotools ./models/research/
</pre>



<p>By the end of this step, your <code>Tensorflow</code> directory structure should look like this:</p>



<pre>Tensorflow/
└─ cocoapi/
   ├─ common/
   ├─ LuaAPI/
   └── …
└─ protoc/
   ├─ bin/
   ├─ include/
   ├─ readme.txt
└─ tf2_api_env/
   ├─ bin/
   ├─ include/
   └── …
└─ models/
   ├─ community/
   ├─ official/
   ├─ orbit/
   └── …
</pre>



<h3><strong>6. Object Detection API installation</strong></h3>



<p>This is the final step of our Installation and Setup block! We’re going to install the Object Detection API itself. You do this by installing the <em>object_detection</em> package. Here’s how:</p>



<ul><li>Make sure that within your <em>Terminal </em>window you’re located in the <code>Tensorflow</code> directory.</li></ul>



<ul><li>Change the current working directory from <code>Tensorflow</code> to <code>Tensorflow/models/research</code> using the <code>cd</code> command</li></ul>



<ul><li>Run the following commands one by one in your <em>Terminal </em>window:</li></ul>



<pre>cp object_detection/packages/tf2/setup.py .
python -m pip install .
</pre>



<p><strong>NOTE: </strong>the<strong> </strong>second command might give you an error. No worries at all. Just run it one more time until you see a completed installation.</p>



<ul><li>Test if your installation is successful by running the following command from <code>Tensorflow/models/research</code> directory in your <em>Terminal </em>window:</li></ul>



<pre>python object_detection/builders/model_builder_tf2_test.py</pre>



<p>Once tests are finished, you will see a message printed out in your <em>Terminal </em>window. If all 20 tests were run and the status for them is “OK” (some might be skipped, that’s perfectly fine), then you are all set with the installation!&nbsp;</p>



<div><figure><img loading="lazy" width="498" height="225" src="https://i1.wp.com/neptune.ai/wp-content/uploads/congratulations.gif?resize=498%2C225&amp;ssl=1" alt="congratulations" data-recalc-dims="1"></figure></div>



<p>That was a lot of work, so congratulations! Well done!</p>






<h2>Data preparation</h2>



<p>When you finish all installation steps, you need to think about the data that you’ll feed into your custom object detection model later.&nbsp;</p>



<p>Models based on the TensorFlow object detection API need a special format for all input data, called <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord" target="_blank" rel="noreferrer noopener nofollow"><em>TFRecord</em></a>. We’ll talk about how to transform your data into the <em>TFRecord </em>format (to get a better sense of what the <em>TFRecord </em>format is, I highly recommend reading <a href="https://medium.com/mostly-ai/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564" target="_blank" rel="noreferrer noopener nofollow">this article</a>), but first let’s talk about a few assumptions about your data availability and its annotations. Specifically, we assume that:</p>



<ul><li>You already <strong>have data (images) collected</strong> for model training, validation and testing,</li><li>Your <strong>i…</strong></li></ul></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/how-to-train-your-own-object-detector-using-tensorflow-object-detection-api">https://neptune.ai/blog/how-to-train-your-own-object-detector-using-tensorflow-object-detection-api</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/how-to-train-your-own-object-detector-using-tensorflow-object-detection-api</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033619</guid>
            <pubDate>Mon, 09 Nov 2020 11:24:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Useful Values / Guiding Principles from Ethics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033563">thread link</a>) | @hunglee2
<br/>
November 9, 2020 | https://lowercaseopinions.com/useful-values | <a href="https://web.archive.org/web/*/https://lowercaseopinions.com/useful-values">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>What we value is foundational to how we approach our lives, how we prioritise our time, and how we interact with one another. In society, in companies, in communities like families and friendship groups.</p>

<p>Our values already exist: in every group, there’s a set of shared or overlapping values. Perhaps you value being demonstratively affectionate to one another: your group chat is likely kind words, animal gifs, wishing each other luck and good vibes on stressful days, or arranging karaoke dates so you can sweetly serenade one another. Maybe you value learning, and that manifests through book recommendations, DMing each other links to thought-provoking articles, attending salons and watching documentaries together.</p>

<p>Often these values shift as the group changes, and as you change the group that you’re in. I find myself leaning harder into some of my values with a particular group of friends, and a different set with my family or my coworkers.</p>

<p>In companies, it’s fundamental that we’re able to talk coherently about what we value, especially if we want to preserve some of this sense of belonging as we scale. Culture is the manifestation of values, it’s the glue that binds us; to reinforce and steer this, we need to have a clear, shared understanding of what’s important to us all in how we work together.</p>

<p>A company’s mission, or a team’s mission, establishes what problem space is addressed; values and culture become the <em>how</em> underlying the business strategy to achieve the company’s mission.</p>

<p>I think it’s really interesting to observe the language that we use when talking about company values. People refer to “the right behaviours” or being a “good” employee. We’ve borrowed the language of ethics - and I don’t think this is a coincidence at all.</p>

<p>In fact, there are three frameworks in ethics that have striking parallels to how we set out what’s good or right in a company or business. One of these lends itself exceptionally well to framing company values.</p>



<p>Before we dive into my weird Good-Place-esque rundown of metaethics as applied to companies, I want to explore a little bit what makes a good set of values.</p>

<p>There’s a trope that every startup should have five pithy values that can be neatly painted onto the wall (and then a couple of pages explaining what each of them actually means!). And that is often the endpoint - something polished by a copywriter that gets thrown onto t-shirts or notebooks or painted on a wall back when a physical office felt important.</p>

<p>But often we miss a step. We get the polished pithy phrases, but don’t draw them from the right place. This process of understanding and surfacing what your team values has to be <em>descriptive</em>. It’s a weird, difficult, fun, generative, iterative journey of discovery. You’ll find the intrinsic qualities that you deem valuable in the people you all want to work with (smart, considerate), and the extrinsic qualities that you value in how you interact with one another (straightforward, open to early feedback).</p>

<p>This discovery process is so important to building a healthy and meaningful company culture. Values are so, so important - they’re what the culture is built on, they’re what bring us joy and meaning every day. But we dismiss them because so often they do end up just being a set of catchy but empty phrases painted on a wall.</p>

<p>I have two examples of pithy phrases masquerading as values which just aren’t useful:</p>

<p><em>Get shit done.</em>
This one baffles me because it provides no direction. What shit should I be getting done? What’s the best way to get it done? At what point is my shit done enough? Especially in the context of a company, where I get paid to do a job - my side of the employment contract is about getting shit done! You can tell me to value doing shit as much as you like, but this adds zero value when you consider that, contractually, as soon as I stop getting shit done, you’ll stop paying me!</p>

<p><em>Don’t be evil.</em>
I have a bunch of issues with this as a thing to value. Firstly, how are we defining evil? Secondly, can I do evil without being evil? What if it’s unintentional? Thirdly, is not being evil enough, or should I strive to be good? And if so, what is good? I used to say “be good, have fun” when I dropped my kid off at school in the mornings, but I’ve switched to “have fun, learn something” because it feels more directionally useful. I think “be good” sometimes reads as “don’t get told off”, and I’ve definitely been told off for doing what was right.</p>

<p>Honestly compared to these, if you’re going to paint something on your wall, I’d actually favour “live, laugh, love”. It’s more like a useful value statement than either of these - it’s clear that love and laughter are states to optimise for, which can at least guide the behaviours we choose. Tell me to “live, laugh, love” and my constraints are tighter than “don’t be evil”. Plus there’s already a bunch of wall decals on etsy!</p>



<p>Our values affect how we go about achieving things and interacting with others. They capture the quirks, traits and essences of the things that make your company and your community who they are.  For me, useful values have two properties: they are opinionated, and they guide behaviour.</p>

<p>The things that <em>you in particular</em> value have to take a perspective and a point of view. And it needs to be a meaningful point of view - where you can envisage a world where many very reasonable people take a conflicting point of view.</p>

<p>You know you have pinpointed genuinely useful values if you can use them to make decisions about what you do and how you do it. Particularly in high stress or difficult situations: for instance, how you approach interpersonal conflict or even conflicting priorities.</p>

<p>Both “don’t be evil” and “get shit done” fail on both counts - I can’t imagine anyone pasting the opposite on an office wall, and I can’t imagine solving a problem by using either. They are about as generic as you can be. Likewise “integrity” is not especially meaningful as a value; what would it mean to be a reasonable person who holds a value that’s contradictory to that?</p>

<p>“Move fast”, on the other hand, is absolutely meaningful. Depending on the context, you could choose to move fast; to be cautious; to take thoughtful and deliberate action; to prioritise perfection over speed. “Build to last” would take an opposing point of view, but be meaningful - as would “excellence always”. None of these three stances are objectively better than the others, which is great! Pick one and you now have a value that not only takes a perspective, but also influences how you work.</p>



<p>Our values delineate what we encourage and praise, and what is frowned upon or even punished. They set out what is right and what is wrong within the company. Values layer over the top of the ethical and moral norms of the society where you operate - like, the laws and regulatory principles and business governance.</p>

<p>When we internalise values as a sort of ethical system, it makes a lot of sense to adopt an ethics framework in order to establish how we want to think about values. Ethical <em>systems</em> concern themselves less with what specific acts are moral or immoral, and more with how we systematically determine this. So I want to focus less on what specific things we value, and more on how we frame values.</p>

<p>I’ll briefly outline three approaches to ethics from the western philosophical canon, and how the combination of the three gives us a strong framework for thinking about right and wrong in a company.</p>

<h2 id="categorical-imperatives-and-the-law">Categorical imperatives and the law</h2>

<p>One approach to ethics is through the <a href="https://plato.stanford.edu/entries/kant-moral/#CatHypImp">categorical imperative</a>: ethics should be a system of commands which are always, unconditionally, universally the correct and right way to act.</p>

<p><em>“Act only according to that maxim whereby you can, at the same time, will that it should become a universal law.”</em> Judaism and Christianity’s Ten Commandments take the form of categorical imperatives.</p>

<p>There are no exceptions to the imperative. If, as a collective, we set out that lying is wrong, then it is not ever permissible for anyone to lie. This is super clear cut, which appeals to those who like simplicity! But humans are messy. The workplace is ambiguous, the decisions we make in our jobs are nuanced. There are a lot of behaviours that are context-dependent, or require a trade-off. So the universal commandment approach can’t capture the delightful quirks of one company over another - they are adopted by everyone.</p>

<p>But there is something useful in considering this approach. Let’s assume that there is a subset of actions which are either good or bad, based on whether everyone should do it, or everyone should not do it. In a company context, this approach is really useful in two places: the first is laws, regulation and governance. For example, it is never acceptable to commit fraud. The second is process and policies. For example, in our company, it is never acceptable to bully or harass others.</p>

<p>I referenced “don’t be evil” earlier, and for me that falls into the categorical imperative category, as does “only hire the best”. But there’s a whole layer of nuance beneath these that we need to unpick to determine what they mean within a particular company - “the best” is subjective, we characterise it through traits that we deem valuable, and those just won’t apply to everyone.</p>

<h2 id="utilitarianism-and-stakeholder-benefit">Utilitarianism and stakeholder benefit</h2>

<p><em>“It is the greatest happiness of the greatest number that is the measure of right and wrong.”</em></p>

<p>A second approach to ethics is <a href="https://plato.stanford.edu/entries/bentham/#PaiPle">utilitarianism</a> - where an act is good based entirely on its <em>consequences</em> and which way they swing happiness. In the context of a company, the clearest parallel is where a lot of what you do - the goals you set - optimise for stakeholder benefit (which includes profit and user happiness).</p>

<p>One of the difficulties with utilitarianism is that it is entirely based on consequences, intention has no role to play at all. This theory of ethics would judge someone’s actions good if …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lowercaseopinions.com/useful-values">https://lowercaseopinions.com/useful-values</a></em></p>]]>
            </description>
            <link>https://lowercaseopinions.com/useful-values</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033563</guid>
            <pubDate>Mon, 09 Nov 2020 11:13:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hand-drawn animated tram ride (web experiment)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033545">thread link</a>) | @parisianka
<br/>
November 9, 2020 | https://alexanderperrin.com.au/paper/shorttrip/ | <a href="https://web.archive.org/web/*/https://alexanderperrin.com.au/paper/shorttrip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="credits">
<div>
<p>
<strong>Short Trip - Alexander Perrin, 2017</strong>
</p>
<p>Hold left or right to move.</p>
<p>Read more about the project
<a href="http://alexanderperrin.com.au/portfolio/short-trip/" target="_blank">here.</a>
</p>
<p>Thank you to
<a href="https://twitter.com/domwillmott" target="_blank">Dom Willmott</a> for
<br>audio support.</p>
<p>If you would like to support Short Trip, you're welcome (but not obliged) to make a contribution
<a href="https://paypal.me/alexanderperrin">here.</a>
</p>
<p>Quality Mode:
<span id="default-button">Default</span>
<span id="eco-button">Eco</span>
</p>
<p>Sound:
<span id="mute-off">On</span>
<span id="mute-on">Off</span>
</p>
</div>
</div></div>]]>
            </description>
            <link>https://alexanderperrin.com.au/paper/shorttrip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033545</guid>
            <pubDate>Mon, 09 Nov 2020 11:10:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Instantly refactor your Python code in Vim]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033399">thread link</a>) | @brendanator
<br/>
November 9, 2020 | https://sourcery.ai/blog/sourcery-vim/ | <a href="https://web.archive.org/web/*/https://sourcery.ai/blog/sourcery-vim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <span></span>
  <img alt="Sourcery and Vim" title="Sourcery and Vim" src="https://sourcery.ai/static/d9a1fa03d905634aaaa161e3752f8ff2/5a190/sourcery-vim.png" srcset="https://sourcery.ai/static/d9a1fa03d905634aaaa161e3752f8ff2/772e8/sourcery-vim.png 200w,
https://sourcery.ai/static/d9a1fa03d905634aaaa161e3752f8ff2/e17e5/sourcery-vim.png 400w,
https://sourcery.ai/static/d9a1fa03d905634aaaa161e3752f8ff2/5a190/sourcery-vim.png 800w,
https://sourcery.ai/static/d9a1fa03d905634aaaa161e3752f8ff2/c1b63/sourcery-vim.png 1200w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
    </span></p>
<p>We're delighted to announce that Sourcery is now available in Vim 🎉.</p>
<p>This means you can use all of the great features of Sourcery directly in Vim:</p>
<ul>
<li><em>Instant refactoring suggestions</em>.  We're the only tool that will refactor your code for you! As you edit, Sourcery will analyse your code and suggest improvements which you can preview and then apply with a single command.</li>
<li><em>We don't break your code</em>.  Sourcery uses extensive static analysis to ensure that its refactorings don't change the existing functionality - backed up by testing on open source repositories.</li>
<li><em>Code Quality Metrics</em>.  View the quality of any function and be shown warnings when the quality drops below a threshold.</li>
</ul>
<h2>Installation</h2>
<p>Sourcery uses the the excellent coc.nvim LSP plugin to provide its functionality. There are complete installation instruction on our <a href="https://github.com/sourcery-ai/sourcery/wiki/Vim-Usage#installation">wiki</a>.</p>
<h2>Sourcery in Action</h2>
<p>Here's a Sourcery refactoring suggestion shown using <code>:call CocAction('doHover')</code></p>
<p><span>
      <span></span>
  <img alt="Suggested diff" title="Suggested diff" src="https://sourcery.ai/static/f0507d4539c1878b600f5c8bd406049a/5a190/suggestion.png" srcset="https://sourcery.ai/static/f0507d4539c1878b600f5c8bd406049a/772e8/suggestion.png 200w,
https://sourcery.ai/static/f0507d4539c1878b600f5c8bd406049a/e17e5/suggestion.png 400w,
https://sourcery.ai/static/f0507d4539c1878b600f5c8bd406049a/5a190/suggestion.png 800w,
https://sourcery.ai/static/f0507d4539c1878b600f5c8bd406049a/764be/suggestion.png 806w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
    </span></p>
<p>Run <code>:CocFix</code> to view the options to fix:</p>
<p><span>
      <span></span>
  <img alt="Options to fix" title="Options to fix" src="https://sourcery.ai/static/ad7d66732663b341ba56f3785d4252bc/5a190/fix-options.png" srcset="https://sourcery.ai/static/ad7d66732663b341ba56f3785d4252bc/772e8/fix-options.png 200w,
https://sourcery.ai/static/ad7d66732663b341ba56f3785d4252bc/e17e5/fix-options.png 400w,
https://sourcery.ai/static/ad7d66732663b341ba56f3785d4252bc/5a190/fix-options.png 800w,
https://sourcery.ai/static/ad7d66732663b341ba56f3785d4252bc/e1031/fix-options.png 803w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
    </span></p>
<p>Press <code>1</code> and your code is instantly refactored:</p>
<p><span>
      <span></span>
  <img alt="Refactored code" title="Refactored code" src="https://sourcery.ai/static/cc000aacc919619f5f31baaa3cfb7d35/5a190/refactored.png" srcset="https://sourcery.ai/static/cc000aacc919619f5f31baaa3cfb7d35/772e8/refactored.png 200w,
https://sourcery.ai/static/cc000aacc919619f5f31baaa3cfb7d35/e17e5/refactored.png 400w,
https://sourcery.ai/static/cc000aacc919619f5f31baaa3cfb7d35/5a190/refactored.png 800w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
    </span></p>
<h2>Documentation</h2>
<p>Check out our <a href="https://github.com/sourcery-ai/sourcery/wiki/Vim-Usage">wiki</a> for more usage instructions and configuration options.</p>
<h2>Thanks</h2>
<p>Thanks to <a href="https://github.com/marcoaaguiar">Marco Aguiar</a> for working out how to use Sourcery in Vim 🙏!</p></div></div>]]>
            </description>
            <link>https://sourcery.ai/blog/sourcery-vim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033399</guid>
            <pubDate>Mon, 09 Nov 2020 10:44:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The power of HTTP headers and examples]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25033398">thread link</a>) | @loweisz
<br/>
November 9, 2020 | https://www.lorenzweiss.de/the_power_of_http_headers_with_four_examples/ | <a href="https://web.archive.org/web/*/https://www.lorenzweiss.de/the_power_of_http_headers_with_four_examples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Almost everything in the web is sent with <strong>http</strong> and even non-developers have seen it when using the internet as keyword
inside urls or links.</p>
<p>Http stands for <strong>Hypertext Transfer Protocol</strong> and gives us the ability to transfer hypertext between a browser and a server.
This is a great technology that has been around almost since the invention of the web and is constantly evolving and
<a href="https://en.wikipedia.org/wiki/HTTP/2">offering more and more great features</a></p>

<p>As a developer you probably heard of http headers, at least in the moment you heard about the CORS policy.
This is a problem you must have heard about when developing websites.
But what exactly are http headers and what other ways are there to use them?</p>
<p>Let us first find out what they do and how you could use them. </p>
<p>When a browser requests a resource, for example a page of this blog, it asks the server with a request.
This request looks something like this: </p>
<div data-language="js"><pre><code><span>fetch</span><span>(</span><span>"https://www.lorenzweiss.de/race_conditions_explained/"</span><span>,</span> <span>{</span>
  credentials<span>:</span> <span>"include"</span><span>,</span>
  headers<span>:</span> <span>{</span>
    accept<span>:</span>
      <span>"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3"</span><span>,</span>
    <span>"accept-language"</span><span>:</span> <span>"en,en-US;q=0.9,de-DE;q=0.8,de;q=0.7"</span><span>,</span>
    <span>"cache-control"</span><span>:</span> <span>"max-age=0"</span><span>,</span>
    <span>"sec-fetch-mode"</span><span>:</span> <span>"navigate"</span><span>,</span>
    <span>"sec-fetch-site"</span><span>:</span> <span>"same-origin"</span><span>,</span>
    <span>"sec-fetch-user"</span><span>:</span> <span>"?1"</span><span>,</span>
    <span>"upgrade-insecure-requests"</span><span>:</span> <span>"1"</span><span>,</span>
  <span>}</span><span>,</span>
  referrerPolicy<span>:</span> <span>"no-referrer-when-downgrade"</span><span>,</span>
  body<span>:</span> <span>null</span><span>,</span>
  method<span>:</span> <span>"GET"</span><span>,</span>
  mode<span>:</span> <span>"cors"</span><span>,</span>
<span>}</span><span>)</span><span>;</span></code></pre></div>
<p>So you can see the URL or location of the resource, some information about the request and also a lot of headers with some information about the request.
This is how your browser tells the server some more information about the request. For example what kind of data type it accepts or
how the client is handling the cache.</p>
<p>After sending the request, the server replies, and it also sets some headers in the reply, which could look like this: </p>
<div data-language="text"><pre><code>:authority: www.lorenzweiss.de
:method: GET
:path: /race_conditions_explained/
:scheme: https
accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3
accept-encoding: gzip, deflate, br
accept-language: en,en-US;q=0.9,de-DE;q=0.8,de;q=0.7
cache-control: max-age=0
cookie: _ga=GA1.2.1173972759.1584812492; _gid=GA1.2.2076192721.1594044231
sec-fetch-mode: navigate
sec-fetch-site: same-origin
sec-fetch-user: ?1
upgrade-insecure-requests: 1
user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36</code></pre></div>
<p>There is also some information that the server wants to tell the browser what to do with the resource, for example
if there are cookies, it must be determined which encoding was used, etc</p>
<p>Basically, in the http-context the headers for the communication of the browser and the server are used to extend the simple
Requests for resources. You could see it as the sheet of paper that is added on top of a package that you oder from an online store,
giving you more information about the context and the resource that you ordered.
Most of the headers have quite good defaults which you don't need to think of, but there are some headers that
can get quite important, like CORS headers. But there are so much more headers that you might never heard of which are very useful
and good to know how to use. </p>

<p>Do not worry, this article will not deal with CORS headers. The following http headers are those that are rarely used, but
can be really powerful and helpful to significantly improve the communication between a server and the browser. </p>
<p>So let's dig into it. Here are some headers that you can set and that are very useful and practical.</p>
<h2 id="if-range"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/If-Range">If-Range</a><a href="#if-range" aria-label="if range permalink"></a></h2>
<h3>What and why?</h3>
<p>Imagine you start downloading a large resource, such as a video, an image, etc., and stop in between because of connection problems.
With <code>If-Range</code> you can tell the server if the representation is unchanged, to send the part(s) that are requested in Range.
Which means only the parts that were missing and not again the whole thing.</p>
<p>This can be very helpful when dealing with large resources and often bad connections as with mobile devices.
Because the resource can be downloaded in parts even if the connection is interrupted in between. </p>
<h4>How to use</h4>
<p>It can either be used with a date when the resources were last modified, or with an <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag">ETag</a>, which is a key to help if the resources was invalidated</p>
<div data-language="text"><pre><code>If-Range: &lt;day-name&gt;, &lt;day&gt; &lt;month&gt; &lt;year&gt; &lt;hour&gt;:&lt;minute&gt;:&lt;second&gt; GMT
If-Range: &lt;etag&gt;</code></pre></div>
<h4>Example</h4>
<div data-language="text"><pre><code>If-Range: Wed, 21 Oct 2015 07:28:00 GMT </code></pre></div>
<h2 id="vary"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Vary">Vary</a><a href="#vary" aria-label="vary permalink"></a></h2>
<p><code>Vary</code> Comes from a time when the web or http was used for a variety of things and not just for web pages.<br>
It is based on the idea of using http to exchange information in many different formats.
How does it do that? Well, it tells the server in which header to find the information, how to present the information. </p>
<p>Nowadays it can be really helpful if you have different resources for different customers, for example
mobile, tablet or desktop.
Imagine three different images for the same resource are stored on the server, depending on the device.
Then you can simply use the <code>Vary</code> header to tell the server to check the device and then decide which image size to send. </p>
<h4>Example</h4>
<p>For the example with the device dependent images, you can simply pass the 'user agent' to tell the server
that it should check the user-agent for device information. </p>

<h4>How to use</h4>

<p>Just enter the header, the server must check before deciding which resource to send.</p>
<h2 id="content-disposition"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Content-Disposition">Content-Disposition</a><a href="#content-disposition" aria-label="content disposition permalink"></a></h2>
<p>If we go back to the example of a request to a server, for example to load this website, it is clear to the browser,
that it must <strong>display</strong> the resource of the answer.
But it can also be the case that the server sends a resource that the browser should automatically download to the user's computer,
like a picture or pdf etc.
A server can tell the browser what the browser should do with the attached resource via the <code>Content Disposition</code> header.</p>
<h4>Example</h4>
<p>With defining the <code>Content-disposition</code> to <code>attachment</code> the browser knows that this is a resource to download instead of just
show. </p>
<div data-language="text"><pre><code>Content-Disposition: attachment; filename="data.pdf"</code></pre></div>
<h4>How to use</h4>
<p>You can define the header as <code>inline</code> or <code>attachment</code>, where `inline is always the default.  </p>
<div data-language="text"><pre><code>Content-Disposition: &lt;inline | attachment&gt;</code></pre></div>
<h2 id="feature-policy"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Feature-Policy">Feature-Policy</a><a href="#feature-policy" aria-label="feature policy permalink"></a></h2>
<p>This is a fairly new header and therefore only supported by modern browsers (sorry to all IE users). However
I want to mention this anyway because I think it can be really helpful for some use cases.<br>
Basically, the <code>feature-policy tells the browser which features or apis the browser should provide to the document and its</code>iframes` to be used. </p>
<p>For example, it can ban all scripts or iframes etc. within this website to allow sensitive apis like the camera or microphone.</p>
<h4>How to use</h4>
<div data-language="text"><pre><code>Feature-Policy: &lt;directive&gt; &lt;allowlist&gt;</code></pre></div>
<p>The <code>directive</code> is the name of the feature. You can see the full <a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Feature-Policy#Directives">list of features here</a>
The <code>allowlist</code> defines the origins which are allowed to use the directive.</p>
<h3>Example</h3>
<p>Suppose we want our website to use neither the microphone nor the camera. With this header the
document or a contained iframe cannot access these functions.</p>
<div data-language="text"><pre><code>Feature-Policy: microphone 'none'; camera 'none'</code></pre></div>
<h3>More Headers:</h3>
<p>Here are some more headers that are worth mentioning: </p>
<ul>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Upgrade-Insecure-Requests">Upgrade-Insecure-Requests</a></li>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Age">Age</a></li>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Trailer">Trailer</a></li>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Location">Location</a></li>
</ul>
<h2 id="conclusion">Conclusion<a href="#conclusion" aria-label="conclusion permalink"></a></h2>
<p>Https headers are great and also very useful! But sometimes they can be quite complex, and it's really hard to get an overview of what headers are available and what benefits they bring.
Also when developing a website, especially in the frontend, you don't come in contact with them too often, except maybe with the CORS headers.
But I think that this missed some possibilities. http headers represent the communication between the server and the
customers much better, and we all know that communication is the key to a good relationship.</p>
<p>I hope I could shed some light on the darkness of http headers for you. In case I missed a good and helpful header,
please do not hesitate to send me a mail or contact me in any way.</p></div></div>]]>
            </description>
            <link>https://www.lorenzweiss.de/the_power_of_http_headers_with_four_examples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033398</guid>
            <pubDate>Mon, 09 Nov 2020 10:44:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Message from the Center for Presidential Transition]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033361">thread link</a>) | @scapecast
<br/>
November 9, 2020 | https://presidentialtransition.org/publications/message-from-the-center-advisory-board/ | <a href="https://web.archive.org/web/*/https://presidentialtransition.org/publications/message-from-the-center-advisory-board/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<article id="post-8006" role="article">
    <h3>A MESSAGE FROM THE CENTER FOR PRESIDENTIAL TRANSITION ADVISORY BOARD</h3>
    <p>
      November 8, 2020    </p>
    

    
<p>&nbsp;<strong>November 8, 2020&nbsp;</strong></p>



<p>The Partnership for Public Service’s Center for Presidential Transition is the nation’s premier nonpartisan source of information and resources designed to help presidential candidates and their teams lay the groundwork for a new administration or for a president’s second term. The Center has been active in transition activities on a bipartisan basis for four cycles.&nbsp;</p>



<p>We congratulate Vice President Joe Biden and Senator Kamala Harris on their successful and historic campaign for the White House. In our role we have observed the seriousness with which they have taken the transition planning process. They embraced transition planning early, recruited a seasoned and disciplined team and resourced their transition effort commensurate with the challenges that President-elect Biden will face on January 20. While there will be legal disputes requiring adjudication, the outcome is sufficiently clear that the transition process must now begin.&nbsp;</p>



<p>As candidate Biden becomes President-elect Biden, he and his transition team will quickly shift from campaigning to governing. To build an effective government ready to address the urgent needs of our great country, the new president will have to recruit 4,000 political appointees, including 1,250 who require Senate confirmation; prepare a $4.7 trillion budget; implement a strong policy agenda; and assume leadership of a workforce of 2 million civilian employees and 2 million active duty and reserve troops.&nbsp;</p>



<p>We want to also applaud the two other key stakeholders necessary for a successful transition – the White House staff and the career officials throughout the federal government with responsibility for transition planning under the Presidential Transition Act. The White House staff took implementation of the Presidential Transition Act seriously, met every statutory milestone and worked closely with the career officials responsible for transition planning. The career federal officials with responsibility for transition planning, led by the GSA, did exactly what one would expect from highly qualified, experienced career officials – they planned and prepared methodically for either eventuality – a Trump re-election or a Biden win.&nbsp;</p>



<p>Now the real challenge begins. We urge the Trump administration to immediately begin the post-election transition process and the Biden team to take full advantage of the resources available under the Presidential Transition Act. This was a hard-fought campaign, but history is replete with examples of presidents who emerged from such campaigns to graciously assist their successors. “Your success now is our country’s success,” George H.W. Bush wrote in 1993 to the incoming president who involuntarily retired him, “I am rooting hard for you.”&nbsp;</p>



<p><strong>Josh Bolten</strong>, White House Chief of Staff and Director of the Office of Management and Budget, George W. Bush Administration (Republican)&nbsp;</p>



<p><strong>Michael Leavitt</strong>, Secretary of Health and Human Services and Administrator, Environmental Protection Agency, George W. Bush Administration, Governor of Utah (Republican)&nbsp;</p>



<p><strong>Thomas F. (Mack) McLarty</strong>, White House Chief of Staff, Clinton Administration (Democrat)&nbsp;</p>



<p><strong>Penny S. Pritzker, </strong>Secretary of Commerce, Obama Administration (Democrat)&nbsp;</p>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content -->
                
    </article></div>

</div></div>]]>
            </description>
            <link>https://presidentialtransition.org/publications/message-from-the-center-advisory-board/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033361</guid>
            <pubDate>Mon, 09 Nov 2020 10:38:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero-Days in Desktop Web Browsers]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25033290">thread link</a>) | @svenfaw
<br/>
November 9, 2020 | https://www.radsix.com/dashboard1/ | <a href="https://web.archive.org/web/*/https://www.radsix.com/dashboard1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.radsix.com/dashboard1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033290</guid>
            <pubDate>Mon, 09 Nov 2020 10:24:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Biden-Harris plan to create union jobs by tackling the climate crisis]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033253">thread link</a>) | @_Microft
<br/>
November 9, 2020 | https://buildbackbetter.com/priorities/climate-change/ | <a href="https://web.archive.org/web/*/https://buildbackbetter.com/priorities/climate-change/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	

		<section id="content">

	  
<div data-module="">
  <div>
	<div>
	  <p>From coastal towns to rural farms to urban centers, climate change poses an existential threat — not just to our environment, but to our health, our communities, our national security, and our economic well-being. It also damages our communities with storms that wreak havoc on our towns and cities and our homes and schools. It puts our national security at risk by leading to regional instability that will require U.S military-supported relief activities and could make areas more vulnerable to terrorist activities.</p>
	</div>
  </div>
</div>

<div data-module="" id="climate-change-2" data-new-section="false" data-id="climate-change-2">
  <div>
	<div>
	  <div>
	   <p>The current COVID-19 pandemic reminds us how profoundly the energy and environmental policy decisions of the past have failed communities — allowing systemic shocks, persistent stressors, and pandemics to disproportionately impact communities of color and low-income communities.</p>
<p>At this moment of profound crisis, we have the opportunity to build a more resilient, sustainable economy — one that will put the United States on an irreversible path to achieve net-zero emissions, economy-wide, by no later than 2050. Biden is working to seize that opportunity and, in the process, create millions of good-paying jobs that provide workers with the choice to join a union and bargain collectively with their employers.</p>
<p>President-elect Biden is leading the world to address the climate emergency and leading through the power of example. Biden knows how to stand with America’s allies, stand up to adversaries, and level with any world leader about what must be done. He will not only recommit the United States to the Paris Agreement on climate change – he will go much further than that. He is working to lead an effort to get every major country to ramp up the ambition of their domestic climate targets.</p>
	  </div>
	</div>
  </div>
</div>

<!-- .module.block-quote -->

<div data-module="" id="climate-change-4" data-new-section="false" data-id="climate-change-4">
  <div>
	<div>
	  <div>
	   <p>President-elect Biden will ensure that — coming out of this profound public health and economic crisis, and facing the persistent climate crisis — we are never caught flat-footed again. He is working to launch a national effort aimed at creating the jobs we need to build modern, sustainable infrastructure now and deliver an equitable clean energy future.</p>
<p>The current coronavirus crisis destroyed millions of American jobs, including hundreds of thousands in clean energy. It has exacerbated historic environmental injustices. Biden will immediately invest in engines of sustainable job creation — new industries and re-invigorated regional economies spurred by innovation from our national labs and universities; commercialized into new and better products that can be manufactured and built by American workers; and put together using feedstocks, materials, and parts supplied by small businesses, family farms, and job creators all across our country.</p>
<p>President-elect Biden is working to make far-reaching investments in:</p>
<ul>
<li><strong>Infrastructure:</strong> Create millions of good, union jobs rebuilding America’s crumbling infrastructure – from roads and bridges to green spaces and water systems to electricity grids and universal broadband – to lay a new foundation for sustainable growth, compete in the global economy, withstand the impacts of climate change, and improve public health, including access to clean air and clean water.</li>
<li><strong>Auto Industry:</strong> Create 1 million new jobs in the American auto industry, domestic auto supply chains, and auto infrastructure, from parts to materials to electric vehicle charging stations, positioning American auto workers and manufacturers to win the 21st century; and invest in U.S. auto workers to ensure their jobs are good jobs with a choice to join a union.</li>
<li><strong>Transit:</strong> Provide every American city with 100,000 or more residents with high-quality, zero-emissions public transportation options through flexible federal investments with strong labor protections that create good, union jobs and meet the needs of these cities — ranging from light rail networks to improving existing transit and bus lines to installing infrastructure for pedestrians and bicyclists.</li>
<li><strong>Power Sector:</strong> Move ambitiously to generate clean, American-made electricity to achieve a carbon pollution-free power sector by 2035. This will enable us to meet the existential threat of climate change while creating millions of jobs with a choice to join a union.</li>
<li><strong>Buildings:</strong> Upgrade 4 million buildings and weatherize 2 million homes over 4 years, creating at least 1 million good-paying jobs with a choice to join a union; and also spur the building retrofit and efficient-appliance manufacturing supply chain by funding direct cash rebates and low-cost financing to upgrade and electrify home appliances and install more efficient windows, which will cut residential energy bills.</li>
<li><strong>Housing:</strong> Spur the construction of 1.5 million sustainable homes and housing units.</li>
<li><strong>Innovation:</strong> Drive dramatic cost reductions in critical clean energy technologies, including battery storage, negative emissions technologies, the next generation of building materials, renewable hydrogen, and advanced nuclear – and rapidly commercialize them, ensuring that those new technologies are made in America.</li>
<li><strong>Agriculture and Conservation:</strong> Create jobs in climate-smart agriculture, resilience, and conservation, including 250,000 jobs plugging abandoned oil and natural gas wells and reclaiming abandoned coal, hardrock, and uranium mines — providing good work with a choice to join or continue membership in a union in hardhit communities, including rural communities, reducing leakage of toxics, and preventing local environmental damage.</li>
<li><strong>Environmental Justice:</strong> Ensure that environmental justice is a key consideration in where, how, and with whom we build — creating good, union, middle-class jobs in communities left behind, righting wrongs in communities that bear the brunt of pollution, and lifting up the best ideas from across our great nation — rural, urban, and tribal.</li>
</ul>
	  </div>
	</div>
  </div>
</div>



	</section>

  </article></div>]]>
            </description>
            <link>https://buildbackbetter.com/priorities/climate-change/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033253</guid>
            <pubDate>Mon, 09 Nov 2020 10:17:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Rust Is the Future of Game Development]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25033247">thread link</a>) | @TheFuntastic
<br/>
November 9, 2020 | https://thefuntastic.com/blog/why-rust-is-the-future-game-dev | <a href="https://web.archive.org/web/*/https://thefuntastic.com/blog/why-rust-is-the-future-game-dev">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-10b1bd0a="" data-v-2ae295f5=""><p><em>Rust, not related to the video game also called Rust, is a promising systems programming language with novel features ideally suited for game development. Exposure and awareness within the game developer community, however, remains limited. In this post, I provide a gentle introduction to Rust and attempt to justify its place on your radar.</em></p>
<h2 id="a-short-history-lesson">A Short History Lesson</h2>
<p>What is Rust, and where did it come from? In <a href="https://www.youtube.com/watch?v=HiWkMFE8uRE" target="_blank" rel="nofollow noopener noreferrer">this fantastic talk</a>, James Munns gives us a detailed oral history. Way back around 2010, Mozilla was frustrated by the state of development in Firefox, a massive software project  written mostly in C++. Despite best practices and an abundance of engineering talent, writing high-performance, parallelised, and memory-safe code, at that scale of complexity, remained fraught and error-prone.</p>
<p>Bear in mind, this predates the advent of C++11 (aka the 2011 edition) which heralded efforts to somewhat modernise the language. Even so, manual memory manipulation is easy to get wrong, and <a href="https://msrc-blog.microsoft.com/2019/07/18/we-need-a-safer-systems-programming-language/" target="_blank" rel="nofollow noopener noreferrer">research</a> from <a href="https://www.zdnet.com/article/chrome-70-of-all-security-bugs-are-memory-safety-issues/" target="_blank" rel="nofollow noopener noreferrer">multiple vendors</a> describes this category of error as responsible for 70% of security vulnerabilities. </p>
<p>Into this context steps Graydon Hoare, a Mozilla employee, introducing <a href="https://en.wikipedia.org/wiki/Rust_(programming_language)#History" target="_blank" rel="nofollow noopener noreferrer">a potential solution</a> to the roadblock: Rust, the hobby language he'd been tinkering with since 2006. In 2012, Mozilla would formally announce Servo, an experimental research project to re-imagine a browser engine built with memory safety and concurrency as first principles. And alongside it, Rust, the companion language to make it all possible.</p>
<p>These early days of Rust are described as a Cambrian explosion of ideas and wild experimentation. Concepts were liberally stolen from other languages, from C++ to OCaml, Haskell, Erlang, ML, C#, Ruby and more, reflecting the diverse pool of engineers working on the language at the time. Still, most in the industry, while admiring the optimism in taking such an ambitious moon shot, <a href="http://dtrace.org/blogs/bmc/2018/09/18/falling-in-love-with-rust/" target="_blank" rel="nofollow noopener noreferrer">remained pessimistic</a> about the prospects of success. </p>
<p>2015 saw a major milestone, with the release of Rust v1.0. Perhaps as significant as the feature list, was the number of failed experiments left behind on the cutting room floor, the team unafraid to pare down the language to its quintessential elements. This was also the first time stability guarantees would be offered, a quality notoriously absent before. </p>
<p>Soon after, in 2016, Firefox <a href="https://hacks.mozilla.org/2016/07/shipping-rust-in-firefox/" target="_blank" rel="nofollow noopener noreferrer">shipped its first production Rust code</a>. The industry and community started to take notice, and Rust began its impressive, and as yet unbroken, <del>four</del> <a href="https://stackoverflow.blog/2020/01/20/what-is-rust-and-why-is-it-so-popular/" target="_blank" rel="nofollow noopener noreferrer">five year streak</a> as Stack Overflow's most beloved language. [<em>Thank you James Munns for pointing out it's now actually five years</em>]. </p>
<p>Right from the outset, Rust set out with a clear focus on   building an inclusive community. They, in turn, have contributed to Rust's impressive technical aptitude, but have also fostered a sense of reverence and fondness not often witnessed in other languages. Are they crazy zealots or onto something?</p>
<h2 id="why-rust">Why Rust?</h2>
<blockquote>
<p><em>The performance of C++ with the convenience of C#</em></p>
</blockquote>
<p>This was the first time Rust hijacked my attention. C++ enjoys a long-standing ubiquity, in part, due to its ability to express zero cost abstractions. As explained by Bjarne Stroustrup, the creator of C++:</p>
<blockquote>
<p><em>What you don't use, you don't pay for. And further: What you do use, you couldn't hand code any better.</em></p>
</blockquote>
<p>It's easy to spot the relevancy to games. Making frame-rate while simulating entire worlds is a daunting performance challenge. Indeed, C++ underpins the bulk of game engines. There simply is <a href="https://www.youtube.com/watch?v=ltCgzYcpFUI" target="_blank" rel="nofollow noopener noreferrer">no other industrial language</a> that offers the same speed and low-level control, whilst writing programs in the large. </p>
<p>C++, however, suffers from the weight of its legacy. The accumulation of features over 40 years makes for a complex and intricate language. In the last decade modernisation of the standard has done well to uplift it from its C roots, but the experienced programmer must build up an arcane lore of which features are blessed, and which machinery is dangerous. As Stroustrup again describes:  </p>
<blockquote>
<p>Within C++, there is a much smaller and cleaner language struggling to get out.   </p>
</blockquote>
<p>This makes the language daunting and difficult to approach for beginners. In <a href="https://boats.gitlab.io/blog/post/zero-cost-abstractions/" target="_blank" rel="nofollow noopener noreferrer">this blog post</a>, Rust contributor <em>withoutboats</em> defines an import quality about abstraction:  </p>
<blockquote>
<p>A zero cost abstraction, like all abstractions, must actually offer a better experience than the alternative.</p>
</blockquote>
<p>So yes, of course, C++ offers a better time than your own hand wrought assembly. However, this is making the subtle point that it's competing against a secondary force: a more expensive abstraction that justifies its cost by being more comfortable and convenient.</p>
<p>We see this writ large in the rise of popular game engines that eschew the complexity of C++, the most notable being Unity. End users write code in C#, a more forgiving and ergonomic language, creating a boon in developer productivity and a reduction in iteration time.  </p>
<p><img src="https://thefuntastic.com/blog/2020-10-Unity-Interest.png" title="Unity interest over time in search trends"></p>
<p>In large codebases though, near the edge of the performance envelope, this trade-off begins to bite. The garbage collector eliminates an entire category of errors by removing responsibility for memory management from the end-user. However as its workload grows, so do periodic performance spikes antithetical to smooth gameplay.  </p>
<p><img src="https://thefuntastic.com/blog/2020-11-GC-spikes.png" title="Unity interest over time in search trends"></p>
<p>The experienced developer can still create a performant experience, however, this demands plugging the leaks in the abstraction. They must build a mental model of the machinery behind the curtain, a collection of arcane wisdom that bans many of the original conveniences, lest they disturb the garbage collector. </p>
<p>So development teams face a choice. Better resourced AAA studios generally choose Unreal or in-house engine tech built on C++, able to absorb the overhead for long term gain. Less resourced studios optimise for time to market, choosing Unity, or one of the many other accessible game making tools (Godot, Haxe, Game Maker, etc.). They often postpone performance concerns until after business eligibility is secured.   </p>
<p>Rust, however, for the first time, promises a third way. A world where it's possible to write zero cost abstractions without sacrificing higher-order elegance. </p>
<h3 id="ownership-based-memory">Ownership based memory</h3>
<p>To understand Rust's special sauce, we're going have to talk about ownership and how it handles memory. This is only a simple sketch, but <a href="http://intorust.com/tutorial/ownership/" target="_blank" rel="nofollow noopener noreferrer">in-depth resources</a> exist for the curious. </p>
<p>Writing optimised code is often about taking the way we, as humans, naturally think of an idea or algorithm, and instead expressing it in terms that favour the computer. This act often harms the legibility and understanding of a program, which makes it much harder for us, the humans, to reason about its correctness. </p>
<p>In a manually managed language, like C, the hapless programmer is left responsible for the machinations of the machine. They must take great care to ensure data is appropriately loaded into memory before operation, and then responsibly disposed of afterwards. A difficult dance in which missteps either cause dramatic crashes or else subtle and hard to detect vulnerabilities. But these are the very same tools that allow careful users to tune performance.  </p>
<p>At the other end of the spectrum, garbage collection promises the programmer it will automatically deal with the problem on their behalf. They are now free to express code naturally, but in doing so, it ties hands behind their back. They no longer have, at least not without indirection, the levers needed to wring out maximal performance.</p>
<p>Rust begins from a different premise. Rather than hiding this complexity, it accepts that computers are hard for humans, and instead tries to save us from the dangerous bits. Users can still tune the machine, but with less rope to wrap around their necks. </p>
<p>In the same way that static typing exists, very clever people have figured out how to make the compiler eliminate a whole category of memory and concurrency errors. To achieve this, Rust makes a bargain with the developer: </p>
<blockquote>
<p>"I'm going to keep track of the lifetime of every piece of memory in your program for you. This way, I can detect the moment you're no longer using it and safely free it on your behalf. But in return, I'm going to need you to follow <a href="https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html" target="_blank" rel="nofollow noopener noreferrer">strict rules</a> about the ownership of that memory. If you try to use it outside of the scope that owns it, my humourless friend here, the borrow checker, is going to make sure you don't hurt yourself."</p>
</blockquote>
<p>However, like static typing, this lunch isn't free. Rust is known to have a steep learning curve, "fighting the borrow checker" becomes a right of passage. It takes time to learn this new paradigm. Ownership makes some familiar patterns difficult or impossible and demands new ones be learnt in their place. Perhaps we should revise our earlier statement as: "The performance of C++ with the <del>convenience</del> safety of C#"</p>
<h2 id="unpacking-rusts-popularity">Unpacking Rust's Popularity</h2>
<p>Early adopters have a selfish reason to extol the virtues of their chosen technology, as widespread adoption enhances the return on their risky investment. In this respect, while interest is high but opportunities for real-world exposure are limited, is it possible that Rust is cresting a wave of unearned hype? <a href="https://matklad.github.io/2020/09/20/why-not-rust.html" target="_blank" rel="nofollow noopener noreferrer">Not every javascript or python developer</a> interested in the language, for example, has a use case that merits the additional complexity.</p>
<p>To a developer standing on the shores of 2010, <code>git</code>, a new version control system with a steep learning curve, may have seemed like a risky investment. But, in the ensuing world of Github, it's hard to argue the effort was wasted, even if some workloads (i.e. large games) still require alternatives.</p>
<p>In a similar vein, how can we qualify Rust's popularity as a meaningful signal? Ultimately, we will only know by the volume of mud we've dug through in the trenches, and admittedly, it is far too early to collect this data for games. </p>
<p>In other industries, though, early reports of Rust are effusive. <a href="https://medium.com/the-innovation/how-microsoft-is-adopting-rust-e0f8816566ba" target="_blank" rel="nofollow noopener noreferrer">Mircosoft</a>, <a href="https://developers.libra.org/docs/community/coding-guidelines" target="_blank" rel="nofollow noopener noreferrer">Facebook</a>, <a href="https://aws.amazon.com/blogs/opensource/aws-sponsorship-of-the-rust-project/" target="_blank" rel="nofollow noopener noreferrer">Amazon</a>, <a href="https://www.wired.com/2016/03/epic-story-dropboxs-exodus-amazon-cloud-empire/" target="_blank" rel="nofollow noopener noreferrer">Dropbox</a>, <a href="https://blog.cloudflare.com/tag/rust/" target="_blank" rel="nofollow noopener noreferrer">Cloudflare</a> all have Rust deployed in production. The <a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=Linux-Kernel-Rust-Path-LPC2020" target="_blank" rel="nofollow noopener noreferrer">Linux Kernel</a> and <a href="https://www.chromium.org/Home/chromium-security/memory-safety/rust-and-c-interoperability" target="_blank" rel="nofollow noopener noreferrer">Chrom…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thefuntastic.com/blog/why-rust-is-the-future-game-dev">https://thefuntastic.com/blog/why-rust-is-the-future-game-dev</a></em></p>]]>
            </description>
            <link>https://thefuntastic.com/blog/why-rust-is-the-future-game-dev</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033247</guid>
            <pubDate>Mon, 09 Nov 2020 10:16:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Continued fractions and the square root of 3]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033224">thread link</a>) | @ColinWright
<br/>
November 9, 2020 | https://www.flyingcoloursmaths.co.uk/continued-fractions-and-the-square-root-of-3/ | <a href="https://web.archive.org/web/*/https://www.flyingcoloursmaths.co.uk/continued-fractions-and-the-square-root-of-3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>I’m a Big Fan of both <span data-cites="standupmaths">@standupmaths</span> and <span data-cites="sparksmaths">@sparksmaths</span>, two mathematicians who fight the good fight.</p>
<p>I was interested to see Ben <a href="https://www.youtube.com/watch?v=qknGhrmBZvA&amp;feature=youtu.be">tackling the square root of 3</a> using the ‘long division’ method. It’s a method I’ve tried hard to love. It’s a method I just can’t bring myself to do or recommend. <span data-cites="colinthemathmo">@colinthemathmo</span> has an explainer <a href="https://www.solipsys.co.uk/new/SquareRootByLongDivision.html?RSS">here</a>, probably as nice an explainer as the method permits.</p>
<p>I have two alternative methods for finding the square root of three.</p>
<p>The first, Ben alludes to in the video: use the binomial expansion. My instinct is to find a number $3k^2$ (where $k$ is an integer) that’s fairly close to an even power of 10 - for example, $108 = 3(6^2)$.</p>
<p>Now you can apply the binomial expansion: $6\sqrt{3} = \left( 10^2 +8\right)^{1/2} = 10 + \frac{1}{2}\left(\frac{1}{10}\right)(8) + \frac{-1}{8}\left(\frac{1}{1000}\right)(64) + \dots$. This will converge pretty quickly, at least one decimal digit per term, but the divisions quickly become cumbersome and if you’re going to use fractions continually, you may as well…</p>
<p>… use continued fractions. Or a matrix version thereof.</p>
<p>Like Ben, I’m going to skip the derivation and jump straight to the method: the key matrix is $\mathbf {M}_n =  \mattwotwo{1}{1}{2}{3}^n$ - for a large value of $n$.</p>
<p>Applying this matrix to $\mattwotwo{0}{1}{1}{1}$ gives a two-by-two matrix in which the bottom-right element divided by the bottom-left one is a good approximation to $\sqrt{3}$. Perhaps more simply, this is just the sum of the bottom row of $\bb M$ divided by its bottom right element.</p>
<p>And we can be clever about calculating $\mathbf M_n$: repeatedly squaring the matrix gives us answers that approach $\sqrt{3}$ quite rapidly - although the multiplications can get big quite quickly.</p>
<p>The approximation from $\bb M_1$ is $\frac{5}{3}$, which is not a bad starting point.</p>
<p>From $\bb M_2$, it’s $\frac{19}{11} \approx 1.727$, which is not at all far from the true answer.</p>
<p>Squaring $\bb M_2$ gives $\bb M_4$, and the approximation from there is $\frac{265}{153}$ - the numbers are already getting big, but we’re within $2.5\times 10^{-5}$ of the true answer.</p>
<p>Squaring $\bb M_4$ gives $\bb M_8$, where numbers are in the ten-thousands; the estimate is now $\frac{51409}{29681}$, which is around $6\times10^{-10}$ away from $\sqrt{3}$.</p>
<p>The operations here are not <em>trivial</em><a href="#footnote_0_8385" id="identifier_0_8385" title="hush, sensei">1</a>, but they’re more tedious than difficult. Multiplying and adding large numbers is typically easier than long division – and in fact, multiplying repeatedly by $\bb M_1$ is not all that hard, even with big numbers (I believe each extra matrix gives roughly one decimal place of accuracy).</p>
<p>You’re left with one big division to do at the end, which <em>is</em> a bit more difficult than the other sums – but it’s just one division!</p>
<p>Now, Sir Isaac may not have had continued fractions available to him - but the maths involved here is certainly achievable on quill and parchment. I’m definitely not saying this is the method Ben should have used in the video (I mean, the whole point was to do it an absurd and 17th-century way), but figured it was a nice method to share.</p>
<div>
                        <p><a href="https://www.flyingcoloursmaths.co.uk/author/admin/"><img alt="" src="https://secure.gravatar.com/avatar/2882d12afb7b20f6db30d794567b21a1?s=80&amp;d=mm&amp;r=pg" srcset="https://secure.gravatar.com/avatar/2882d12afb7b20f6db30d794567b21a1?s=160&amp;d=mm&amp;r=pg 2x" height="80" width="80" loading="lazy"></a></p><h2>Colin</h2>
                        <p>Colin is a Weymouth maths tutor, author of several Maths For Dummies books and A-level maths guides. He started Flying Colours Maths in 2008.

He lives with an espresso pot and nothing to prove.</p></div>

<ol><li id="footnote_0_8385">hush, sensei [<a href="#identifier_0_8385">↩</a>]</li></ol>					</div></div>]]>
            </description>
            <link>https://www.flyingcoloursmaths.co.uk/continued-fractions-and-the-square-root-of-3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033224</guid>
            <pubDate>Mon, 09 Nov 2020 10:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leaky academia: digital intimacy and open secrets in times of Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033222">thread link</a>) | @tokai
<br/>
November 9, 2020 | https://www.identitiesjournal.com/the-viral-condition-virtual-symposium/leaky-academia-digital-intimacy-and-open-secrets-in-times-of-covid-19 | <a href="https://web.archive.org/web/*/https://www.identitiesjournal.com/the-viral-condition-virtual-symposium/leaky-academia-digital-intimacy-and-open-secrets-in-times-of-covid-19">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><em>Nanna Bonde Thylstrup, <span>Copenhagen Business School, Denmark;</span>&nbsp;Zeerak&nbsp;Waseem, University of Sheffield, UK;&nbsp;and Daniela Agostinho, University of Copenhagen, Denmark</em></p><p><em>Within the context of academia, much like in other sectors of society, the ongoing pandemic has exposed inequalities that we here describe as 'open secrets'. The disclosure of such open secrets, or 'hidden truths' that were never hidden to begin with, is being facilitated through the digitally networked spaces that bring us together more than ever. Engaging with the 'viral condition' foregrounded by this virtual symposium, this essay thinks through how the virality of digital media is currently intersecting with the unfolding viral pandemic. As we find ourselves connecting in new ways, we suggest that it is time to consider the challenges posed by digital networks, the troubled intimacies they generate, and their potential to forge alliances and solidarities amidst stark and growing inequality.&nbsp;</em>&nbsp;</p><div><p>COVID-19 turned the familiar humdrum of the academic year upside down, abruptly putting a stop to everyday routines and demanding new practices. The effects of COVID-19 have been brutal across society: unemployment rates have skyrocketed, economies have gone to shambles, and hundreds of thousands have died and will continue to die and fall ill from this disease.</p><p>&nbsp;Many writers before us have pointed out how the unfolding pandemic has magnified existing inequalities, laying bare realities that were there all along. Such inequalities have also become highly visible in digitally-enabled academia, as higher education institutions have rushed to respond to the spread of the virus.</p><p>&nbsp;Across privileged Scandinavia, from where we write, professors retreated to spacious summerhouses away from urban centres, quietly enjoying their sudden liberation from academic reproductive labour, tedious meetings and departmental obligations. Some even enjoyed a surge in productivity or used their time to catch up on their reading lists. Others seized the chance to add a COVID-19 grant to their already extensive grant collection. Beyond Scandinavia, journal submissions from male authors went up (Flaherty 2020). Executive branches of academia saw new opportunities in the sudden shift to online teaching, framing the analogue-to-digital conversion as a positive disruptive force (Kandri 2020). Tech companies strongly encouraged this embrace and gained new strongholds in the educational sector, fueling disaster capitalism on campus (Turiano 2020). From this perspective, COVID-19 was not only experienced as a social tragedy, but also as an opportunity for retreat, advancement and profit.</p><p>&nbsp;Meanwhile, with their work rhythms, social lives and study habits upended, students struggle to keep afloat in small and shared accommodations. A massive pre-existing mental health crisis among the student population suddenly hits the headlines (Pedersen 2020). Without a systemic response in place, some universities reacted with quickly improvised tips on how to keep a routine and promises of a mindfulness app (Munk 2020), offering technological fixes in lieux of politically-informed responses. Feminist, anti-racist and critical disability communities quickly came together to perform the unpaid and academically unrecognised labour of gathering best practices for online teaching (Davidson 2020; Hamraie 2020; Wernimont 2020). Yet, as student and teacher frustration with online instruction accumulates over time, the already devalued labour performed by critical digital pedagogy is even more frowned upon than before the pandemic. Moreover, the socio-political critiques that underlie this body of scholarship are evacuated by utilitarian uptakes, disregarding the critique of sexism, racism and ableism in academia in favour of uncritical implementation of digital technologies. Meanwhile, the divide between tenured faculty and short-term employees is widening (Zahneiss 2020). Researchers on temporary contracts witness their working hours and job prospects disappear like grains of sand in a precarious hourglass, while universities avoid committing to contract extensions or even use the opportunity to fire temporary employees (Collini 2020). Fieldwork stalls. And journal submissions by women drop (Wiegand et al. 2020; Andersen et al. 2020).</p><p>&nbsp;Within the context of academia, much like in other sectors of society, the ongoing pandemic has exposed inequalities that we here describe as 'open secrets'. The disclosure of such open secrets, or 'hidden truths' that were never hidden to begin with, is being facilitated through the digitally networked spaces that bring us together more than ever. Engaging with the 'viral condition' foregrounded by this virtual symposium, this essay thinks through how the virality of digital media is currently intersecting with the unfolding viral pandemic. As we find ourselves connecting in new ways, we suggest that it is time to consider the challenges posed by digital networks, the troubled intimacies they generate, and their potential to forge alliances and solidarities amidst stark and growing inequality.</p><p>&nbsp;<strong>Leaky conditions – ‘hidden’ truths</strong><br>As we practice containment – stuck in rooms, apartments, buildings, cities and countries – we also experience new modes of intimacy. Through the porous digital networks that bind us, we leak into each others’ homes and lives. We screenshot and close-examine colleagues’ bookshelves and domestic backgrounds. We observe meeting participants who, forgetting they are on screen, fill dishwashers, pick noses or go to the restroom. We leak into rooms and backyards of students while our children, partners, parents and pets photobomb our lectures. We even leak into our own field of vision, our tired faces – normally out of sight – staring back at us on screen.</p><p>&nbsp;These new digital intimacies (Wiehn 2020) are not reserved for close friends and colleagues. We also leak into wider communities and data aggregates through video conferencing platforms, contact tracing apps and new higher-ed platforms. Professors conducting online classes about China in one end of the world leak into Chinese censorship apparatuses through Zoom (@letahong 2020). Researchers developing contact tracing apps in the health sector find themselves entangled in regimes of surveillance and policing (Amnesty 2020). And the rushed adoption of digital technologies in the classroom sediments infrastructures that create new value flows between big tech and higher education (Walsh 2020). Academia’s apparently contained spaces, previously upheld by physical walls and normative epistemological boundaries between the public and private spheres, now turn into intimate membranes that leak through digital networks.</p><p>&nbsp;Digital intimacies have given rise to a string of viral stories about digital transgressions: people unwittingly broadcasting their toilet visits and intimate affairs to department meetings and online classes (Vincent 2020; Smith 2020; Feldman 2020). And in turn, the racialised and sexualised abuse that occurs offline now leak into once safe spaces. Rather than merely exposing flawed privacy settings or digital illiteracy, these stories, in which the boundaries between public and private dissolve, tend to confirm the inherently porous nature of digital technologies. The leakiness of digital technologies is not accidental or anecdotal; it is built into the digital networks that bind us. Rather than premised on sealed infrastructures that shield and protect, digital technologies are meant to leak at all times (Agostinho and Thylstrup 2019; Chun 2016). Crucially, this leaky nature not only exposes domestic intimacies to the wider world; it also enables and upholds the economic model of surveillance capitalism, as it allows for massive and continuous data flows across platforms.</p><p>&nbsp;Exhausted by lockdowns and fatigued by digital screens, many of us long to return to more contained spaces: meeting rooms, classrooms, hallways and canteens that will allow us to maintain the (imagined) boundaries between public and private and navigate safe and unsafe spaces physically. But this longing for contained spaces also reveals a conservative nostalgia for spaces where privilege can thrive without being confronted by precarity and vulnerability. A space where the pre-existing inequalities are less dramatically seen and felt. Where academia’s dirty secrets can be thrown back into the closet.</p><p>&nbsp;Here we draw on queer theorist Eve Sedgwick and her landmark book <em>Epistemology of the Closet</em> (1990), where she challenges the binary ‘secrecy/disclosure’ that forms the backbone of modern society. Following Michel Foucault, Sedgwick examines sexuality (its secrecy and disclosure) as the structure of modern ways of knowing. She suggests that modern power is premised on the knowledge and withholding of secrets, or as she puts it, modern power is organized around the figure of the closet. The closet here functions as a contained space: what it contains (what is closeted) and what it spills or leaks (the act of outing) structures the modern organisation of knowledge, what is supposed to be known and what is supposed to remain unknown. As Claire Hemmings puts it, the 'closet is the open secret through which difference and inequality are both obscured and played out in front of our eyes in plain sight' (Hemmings 2020).</p><p>&nbsp;The closet of society’s open secrets has been further challenged by the intersection of the pandemic with digital connectivity. Within academia, the shared (if unequally felt) condition of COVID-19 and the unprecedented intimacy of digital media laid bare the 'hidden' truths of academic inequality, both locally and globally. We use scare quotes around 'hidden' to emphasise how these inequalities were never actually <em>hidden</em>. Instead they were hiding in plain sight, but only the privileged could afford to look away: the unequal distribution of reproductive labour, falling along gendered and racialised lines; the previous exclusion …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.identitiesjournal.com/the-viral-condition-virtual-symposium/leaky-academia-digital-intimacy-and-open-secrets-in-times-of-covid-19">https://www.identitiesjournal.com/the-viral-condition-virtual-symposium/leaky-academia-digital-intimacy-and-open-secrets-in-times-of-covid-19</a></em></p>]]>
            </description>
            <link>https://www.identitiesjournal.com/the-viral-condition-virtual-symposium/leaky-academia-digital-intimacy-and-open-secrets-in-times-of-covid-19</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033222</guid>
            <pubDate>Mon, 09 Nov 2020 10:10:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Think Piece on Privacy and Big Data]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25033030">thread link</a>) | @Rohitha_Perera
<br/>
November 9, 2020 | https://talk.hyvor.com/blog/privacy-and-big-data/ | <a href="https://web.archive.org/web/*/https://talk.hyvor.com/blog/privacy-and-big-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span></span>
<span>118</span>
</p>
<p>The majority of us in the present and in the immediate future <a href="https://www.beyondtrust.com/blog/entry/exactis-data-breach-paving-road-data-dystopia-us-gdpr">will face the issue of Privacy</a>. Consider this basic thought, which may sound like science fiction, but is actually quite present today: Thanks to the devices we wear now, <a href="https://www.beyondtrust.com/blog/entry/exactis-data-breach-paving-road-data-dystopia-us-gdpr">the harvesting of our biometric data</a> is a possibility. It is this thought process that led to this think piece on privacy and big data.</p>
<p>Corporations can get to know us far better than we know ourselves. They can then not just predict our feelings but also manipulate our feelings. Monitoring of our biometrics can make episodes like that of Cambridge Analytica’s data hacks prehistoric in comparison. </p>
<p>Remember that <a href="https://www.cheatsheet.com/money-career/heres-much-google-facebook-really-think-youre-worth.html/">you are worth quite a bit of money to the social channels </a>you use. The podcast detailing the <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9IY09mTE41Mg&amp;ep=14&amp;episode=MjM0YjM1OTgtZTQ1Mi00NGZhLTkzYjUtMTQxMGJjZTY1NGE4">Congressional Antitrust Investigation on Tech Monopolies: Google, Facebook, Amazon, and Apple</a> gives a serious look at how powerful these big data companies are. The scale is astronomical. Amazon captures 70% of all retails in the United States. They literally have seven times the revenue of their next largest competitor. </p>
<p>Now imagine their cloud computing capabilities. Take stock of the number of iPhones that are there. We know that what you share on social media, and the information that you surrender is a Big Data Issue; and, consider the number of search results Google controls. There’s information about you being harvested. You should know how your information is being used. </p>
<h2>Some Background</h2>
<p>We hear of how <a href="https://www.theguardian.com/us-news/2018/mar/22/steve-bannon-on-cambridge-analytica-facebook-data-is-for-sale-all-over-the-world">Steve Bannon used Facebook</a> to change politics and change culture. Facebook data, algorithms and narratives were his key weapons. These tools were used by the <a href="https://www.reuters.com/article/us-facebook-cambridge-analytica-kogan-idUSKBN1GX2F6">Cambridge Analytica team to identify the dark triad</a> — Narcissism, Machiavellianism and Psychopathy — in people. We now know about the Russian interference in American politics. We know how data had been manipulated to channel the latent proclivities of racism and anti-Semitism within America to divide it. </p>
<p>The same podcast makes mention of a great knowledge-infused book, which is Shoshana Zuboff’s <a href="https://youtu.be/QL4bz3QXWEo">The Age of Surveillance Capitalism</a>. In this book, Zuboff details the rise of a new form of power which will forever change our lives. By collecting behavioral data from their users, corporations have amassed an incomprehensibly large and detailed picture of our personal lives. They use this data to expand their corporate power and profitability. This, of course, has tremendous consequences for our privacy, but also for our political system.</p>
<figure><img src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/big-5-personality.jpg" alt="" data-src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/big-5-personality.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>Surveillance Capitalism talks of <a href="https://www.simplypsychology.org/big-five-personality.html">The Five Factor Personality Test</a>, which helps companies like Facebook infer our political proclivities and sexuality. This is based on the predictive signals based on the punctuation we use on a Facebook status. </figcaption></figure>
<p>Surveillance Capitalism is where it universally claims our private human experience as their free source of raw material. They take the rich predictive signals in our behavior and convert it into data. We hear of <a href="https://arstechnica.com/information-technology/2017/05/facebook-helped-advertisers-target-teens-who-feel-worthless/#:~:text=Leaked%202017%20document%20reveals%20FB,exploit%20teens'%20words%2C%20images.&amp;text=Facebook's%20secretive%20advertising%20practices%20became,of%20the%20company's%20Australian%20office.">Facebook executives who promote&nbsp;advertising campaigns that exploit Facebook users’ emotional states</a>. Facebook’s algorithms can determine, and&nbsp;allow&nbsp;advertisers to pinpoint, “moments when young people need a confidence boost.”&nbsp;97% of Facebook’s revenue comes from its online targeted advertising markets. These are wholly-owned and operated in this surveillance capitalist economic logic. </p>
<p>Readers of Cathy O’Neil’s Weapons of Math Destruction will be compelled to believe the potential dangers of big data. O’Neil, a mathematician, analyses how the use of big data and algorithms in a variety of fields. These include insurance, advertising, education, and policing. They can lead to decisions that harm the poor, reinforce racism, and amplify inequality. Mathematicians and statisticians were for a very long time studying our desires, movements, and spending power. This is the Big Data economy we are living in. </p>
<h2>Trust is Important </h2>
<p>Consumers are more conscious of their data privacy than ever. A recent <a href="https://tealium.com/resource/whitepaper/how-brands-can-prioritize-privacy-in-the-age-of-data/">Tealium study</a> on consumer data privacy found that 97% of consumers surveyed said they are somewhat or very concerned about protecting their data. <a href="https://www.accenture.com/t20171220T024439Z__w__/us-en/_acnmedia/PDF-68/Accenture-Global-Anthem-POV.pdf#zoom=50">Research by Accenture</a>&nbsp;shows that&nbsp;88% of<strong> </strong>consumers say companies that provide personalized experiences without compromising their trust are more appealing and can relate to their needs better than others.</p>
<p>We are focusing on Facebook on this particular blog post to quite a degree since it is the one singular social medium that is growing exponentially. One of the ways in which Facebook garners your data is with you revealing your data and your intentions via the act of publishing status updates and even commenting. You see, the act of commenting fulfills just one touchpoint in the process of these tech giants harvesting of data. Facebook built&nbsp;<a rel="noreferrer noopener" href="https://developers.facebook.com/docs/plugins/comments/" target="_blank">comments plugin</a>&nbsp;to allow users to leave comments on websites, blogs and forums through their Facebook accounts. It was expected to provide high-quality conversations over the internet but instead ended up spamming popular sites.</p>
<p>If you do use the Facebook Comments plugin, remember that your comments are a valuable content asset that shouldn’t be subject to <a href="https://ducttapemarketing.com/how-and-why-i-use-the-facebook-comments-plugin/">Facebook’s Terms of Service</a>, which basically says they can do whatever they want with them. An increasing amount of spam raises questions about how well the policy of malicious content online is going on. There are many misleading and offensive comments, usually attracting and persuading users towards a specific link to click it. These comments are often repetitive and can easily be identified as spam.</p>
<p>According to an estimation by&nbsp;<a href="https://www.similartech.com/technologies/facebook-comments">Similartech</a>&nbsp;more than 360,000 unique domains have installed Facebook Comments plugin. It is still not clear why and how the spam filters of Facebook failed to filter spam comments. <a href="https://www.similartech.com/technologies/facebook-comments">In 2015</a>, one of the security firms, Symantec reported scammers had been trying to affect the comments sections of Facebook to spread malware. </p>
<p>For more than two years now, Facebook has been working on its content-moderation efforts and the spamming in Facebook Comment boxes shows that problematic content still finds its way to escape the loopholes. Moreover, <a href="https://www-dailymail-co-uk.cdn.ampproject.org/v/s/www.dailymail.co.uk/sciencetech/article-2525227/amp/Facebook-tracks-type-DONT-post-update-comment.html?amp_js_v=a6&amp;amp_gsa=1&amp;usqp=mq331AQFKAGwASA%3D#aoh=16034519192504&amp;referrer=https%3A%2F%2Fwww.google.com&amp;amp_tf=From%20%251%24s&amp;ampshare=https%3A%2F%2Fwww.dailymail.co.uk%2Fsciencetech%2Farticle-2525227%2FFacebook-tracks-type-DONT-post-update-comment.html">Facebook can track what </a><a href="https://www-dailymail-co-uk.cdn.ampproject.org/v/s/www.dailymail.co.uk/sciencetech/article-2525227/amp/Facebook-tracks-type-DONT-post-update-comment.html?usqp=mq331AQFKAGwASA%3D&amp;amp_js_v=0.1#aoh=16034519192504&amp;referrer=https%3A%2F%2Fwww.google.com&amp;amp_tf=From%20%251%24s&amp;ampshare=https%3A%2F%2Fwww.dailymail.co.uk%2Fsciencetech%2Farticle-2525227%2FFacebook-tracks-type-DONT-post-update-comment.html">you</a><a href="https://www-dailymail-co-uk.cdn.ampproject.org/v/s/www.dailymail.co.uk/sciencetech/article-2525227/amp/Facebook-tracks-type-DONT-post-update-comment.html?amp_js_v=a6&amp;amp_gsa=1&amp;usqp=mq331AQFKAGwASA%3D#aoh=16034519192504&amp;referrer=https%3A%2F%2Fwww.google.com&amp;amp_tf=From%20%251%24s&amp;ampshare=https%3A%2F%2Fwww.dailymail.co.uk%2Fsciencetech%2Farticle-2525227%2FFacebook-tracks-type-DONT-post-update-comment.html"> type</a>, even if you never post it.&nbsp;Data scientists can determine that a status or comment has been typed by tracking code in the HTML form element of each page.</p>
<h2>Read The Terms and Conditions</h2>
<p>We live in a world where the concept of privacy already seems outdated. But that is largely because we’ve decided not to inquire about what happens when we trade it for convenience. The more connected you, and billions of others, are to Facebook, the more money Facebook makes by selling your personal information, and the more powerful it becomes.</p>
<p>The terms of service state,&nbsp;<em>We use the data we have — for example, about the connections you make, the choices and settings you select, and what you share and do on and off our Products — to personalize your experience.</em></p>
<figure><img loading="lazy" width="746" height="634" src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg" alt="" srcset="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg 746w, https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC-300x255.jpg 300w" sizes="(max-width: 746px) 100vw, 746px" data-srcset="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg 746w, https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC-300x255.jpg 300w" data-src="https://talk.hyvor.com/blog/wp-content/uploads/2020/10/DcrJMbSW0AAxJXC.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><a href="https://qz.com/1266835/facebooks-terms-of-service-translated-so-you-understand-your-data-and-privacy-settings/">Be wary of nebulous terms and promises</a></figcaption></figure>
<p>Basically, this means that Facebook uses every bit of personal information it can, collected&nbsp;<a href="https://www.consumerreports.org/privacy/how-facebook-tracks-you-even-when-youre-not-on-facebook/">both on and off Facebook</a>, to entice advertisers. The better the company knows you through the personal information you share with your friends and family, the more likely they are to be able to sell you stuff you want.</p>
<h2>Choose The Right to Privacy</h2>
<p>Big data is big business and value is created from customer insight. But, where is the moral line? What happens when companies cross that line? What if consumers could flip the equation to offer their data directly to the companies they trust? The future could be customer-monetized data.</p>
<p>We are the authors of our own destruction here since we don’t choose to be aware. If you participate in Facebook, should you not have some semblance of an expectation of privacy. The former Federal Trade Commission Chairperson Jon Leibowitz publicly stated, “We all agree that consumers don’t read privacy policies.”</p>
<p><a href="https://talk.hyvor.com/docs/gdpr">Ensure you choose privacy</a> and are aware of how technology plans on using your data. The only solution is being non-participatory. The solution is choosing not to be part of a pernicious agenda that can be defined as Surveillance Capitalism. </p>
<div><div><div><h4>
Need a privacy-focused commenting platform for your website?
</h4>

</div></div></div> </div></div>]]>
            </description>
            <link>https://talk.hyvor.com/blog/privacy-and-big-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25033030</guid>
            <pubDate>Mon, 09 Nov 2020 09:37:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pijul: Towards 1.0]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 107 (<a href="https://news.ycombinator.com/item?id=25032956">thread link</a>) | @lelf
<br/>
November 9, 2020 | https://pijul.org/posts/2020-11-07-towards-1.0/ | <a href="https://web.archive.org/web/*/https://pijul.org/posts/2020-11-07-towards-1.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
                We are looking for <strong>VC funding</strong>. If you are interested in helping us build the future of collaboration (for code and other documents), shoot us an email at <a href="mailto:contact@pijul.org">contact@pijul.org</a>.
                
            </p>


<p>Saturday, November 7, 2020</p>
<p>After fixing the performance and scalability problems, we’re on our way to getting a stable Pijul. In this post, I explain what I’ve been up to in the recent months.</p>
<h2 id="context">Context</h2>
<p>Pijul has always been advertised as a research project, trying to implement a theory of patches that would be sound and fast. This is an ambitious goal, and became even more ambitious than initially envisioned.</p>
<p>One of the hardest challenges is that source code is by essence stateful, which makes it much harder to iterate over algorithm designs, like normal research projecst need to. For example, in order to get from our last published version to our current design, we have gone through many different variants, and there wasn’t much to publish.</p>
<p>Moreover, the UX aspect is what matters most in the end, and testing it on a real world project is the only way to get it there. However, unlike in a compiler, where bootstrapping is done one step at a time, and previous versions are always available to compile your current one, a version control system has the additional problem that the previous versions might not always be easily accessible if there is a bug.</p>
<p>One of the criticisms I’ve heard since I realised that better datastructures were possible is that I was “working secretely”. I certainly understand this feeling, but this is based on a misunderstanding of how research works. When I first had the idea that I’m explaining in this post, I realised that a complete rewrite would be needed. But for a very long time, almost nothing other than unusable, unreadable prototypes happened.</p>
<p>Back then, there wasn’t much to show, since it wasn’t even clear that the basic datastructure would work. And even when they started working at a large enough scale, it took me quite a bit of testing on large repositories before they started actually working.</p>
<p>This also implies that there wasn’t much to show for quite a while, since the new algorithm wasn’t usable until very recently, and any repository started before now would have become obsolete in a matter of days.</p>
<p>There were also <a href="#a-personal-note">persoprofessional reasons</a> for this silence, described at the end of this post.</p>

<p>Pijul depends on two other projects I’ve started.</p>
<h3 id="sanakirja">Sanakirja</h3>
<p>One of these projects is Sanakirja, which is “just” a key-value store, but has the extra feature that databases can be cloned efficiently. I would have loved to just use an existing library, but there just isn’t any that has this cloning feature. However, the scope of Sanakirja is still quite modest, it does one thing and does it well. Obviously, it took some time to find the memory-management bugs, but I have good confidence that this is now done.</p>
<p>In previous releases of Pijul, databases were implemented with a single mmapped file containing the binary representation of B Trees. Despite their lower writing performance (compared to alternatives such as <em>Log-structured merge-trees</em>), and the complexity of the code for deletions, B Trees are very well suited to this use case: indeed, since they are trees, reference-counting the nodes is enough to implement efficient clones.</p>
<p>One of the remaining issues was that in order to grow the database, we needed to un-mmapped the file, grow it, and mmap it again. Since applying a single change in Pijul must be an atomic operation, we needed to cancel the transaction when that happened, and restart it with a bigger file.</p>
<p>Another issue is that I wanted the next libpijul to compile on platforms that don’t have mmap, such as WASM. However, if reallocating an mmapped file has a very low complexity (even though it does have a non-zero cost in terms of system calls), reallocating a chunk of memory often requires copying everything. This completely defeats the point of the algorithms in Pijul, which rely on a particular representation of the datastructures on the disk.</p>
<p>The main innovation in Sanakirja 0.13 is to use a vector of memory blocks (either in memory or mmapped from a file), of exponentially-increasing size. The overhead is just one extra indirection, the complexity of adding items is the same (since the operation of creating an extra block is $O(1)$). The exponentially-increasing sizes mean that the allocated memory is always at least half-full.</p>
<h3 id="thrussh">Thrussh</h3>
<p>The other one is Thrussh. That library implements the SSH protocol, and tries to handle a number of key formats. The former is a surprisingly easy goal, and keeping up with Tokio versions has historically been the hardest bit, while the latter is the most horrendous hydra-like task, with new heads and legacy formats showing up every time you think you’re done.</p>
<h2 id="how-repositories-used-to-work-and-still-do-to-some-extent">How repositories used to work (and still do, to some extent)</h2>
<p>Old-style repositories represented a single file by a directed graph $G = (V, E)$ of lines, where each vertex $v\in V$ represented a line, and an edge from $u \in V$ to $v\in V$, labelled by some change (also called patch) number $c$, could be read as “according to change $c$, line $u$ comes before $v$”.</p>
<p>This means that changes could introduce vertices and lines, as in the following example, where a line $D$ is introduced between $A$ and $B$:</p>
<p><img src="https://pijul.org/img/repos-line-add.svg">
</p>
<p>Here, the thick line represents the change from the file containing the lines $A$, $B$, $C$ to the file with the new line $D$.
An important feature to note is that <strong>vertices are uniquely identified</strong>, by the hash of the change that introduced them, along with a position in that change. This means that two lines with the same content, introduced by different changes, will be different. It also means that a lines keeps its identity, even if the change is applied in a totally different context.</p>
<p>Moreover, this system is append-only, in the sense that <em>deletions</em> are handled by a more sophisticated labelling of the edges. In the example above, if we want to delete line $D$, we just need to make a change mapping the edge introduced by $c_0$ to a deleted edge, which we label by the name $c_1$ of the change that introduces it:</p>
<p><img src="https://pijul.org/img/repos-line-del.svg">
</p>
<p>From now on, we call the full edges <strong>alive</strong>, and the dashed ones <strong>dead</strong>.</p>
<p>We have just described the two basic kinds of actions in Pijul. There are no other. One kind adds vertices to the graph, along with “alive” edges around them, and the other kind maps an existing edge label onto a different one.
In order to fully described the system, I also need to mention that the edge labels are given by two parameters: their status (alive, deleted, and a few others related to multiple files and technical details explained below) and the change that introduced them.</p>
<h3 id="dependencies">Dependencies</h3>
<p>This scheme allows to defines dependencies between changes:</p>
<ul>
<li>
<p>If a change $c$ adds a vertex, we must have its <em>“context”</em>, i.e. the lines before and after it, hence the changes that introduced these lines are in the dependencies of $c$.</p>
</li>
<li>
<p>If a change $c$ deletes a vertex, or in other words maps an existing edge introduced by a change $d$, then $c$ must depend on $d$.</p>
</li>
</ul>
<p>Of course, this is just the minimal set of dependencies needed to make sense of the text edits. Hooks and scripts may add extra language-dependent dependencies based on semantics.</p>
<h3 id="are-edge-labels-minimal">Are edge labels minimal?</h3>
<p>Our goals is to find the smallest possible system, both for reasons of mathematical aesthetics (why store useless stuff?) and the other one for performance. Therefore, one immediate question comes to mind: why even keep the change number on the edges?</p>
<p>In order to answer that question, suppose we don’t keep the labels, meaning that the maps happen between statuses only. Then, consider the following two situations:</p>
<ul>
<li>
<p><strong>Change inverses</strong></p>
<p>The first issue happens when two authors delete a line in parallel, and one of the authors reverts their change. Applying these changes yields the following diagram, where the two deletions get merged into one, and the inverse applies to both:</p>
 <p><img src="https://pijul.org/img/inverse2.svg">
 </p>
<p>However, this is not what we expect, since one of the authors explicitly reverted the deletion, while the other performed the same deletion in parallel.
By keeping the labels, this is what we get instead:</p>
 <p><img src="https://pijul.org/img/inverse3.svg">
 </p>
</li>
<li>
<p><strong>Missing contexts</strong></p>
<p>For the sake of clarity, in the rest of this post, we name two users Alice (with pronouns “she/her”) and Bob (with pronouns “he/his”).</p>
<p>This situation, where Alice writes something in the middle of a paragraph $p$, while Bob deletes $p$ in parallel.
One issue here, is that the situation is not symmetric: when Bob applies Alice’s change, he can tell immediately that something is wrong, because the context of Alice’s edits is labelled as deleted in his repository.</p>
 <p><img src="https://pijul.org/img/known-vertices1.svg">
 </p>
<p>However, Alice’s situation is different: indeed, consider the case where instead of deleting $p$ <em>in parallel</em> of her changes, Bob deleted $p$ after applying Alice’s change. The edges deleted are exactly the same, but this is not a conflict, as shown in the following diagram:</p>
 <p><img src="https://pijul.org/img/known-vertices2.svg">
 </p>
<p>The situation is further complicated by the fact that this system doesn’t behave symmetrically with the contexts above and below the new line. Indeed, if Bob deleted the <em>down context</em> of the line (i.e. if he deleted line $C$) instead of the <em>up context</em> (line $B$), Alice could detect the conflict, since in that case, $C$ would have both an alive and a dead edge pointing to it ($C$ is called a “zombie vertex” internally), as shown in the following diagram:</p>
 <p><img src="https://pijul.org/img/known-vertices0.svg">
 </p>
<p>Keeping the change identifiers on each edge allows us to solve this. In Pijul 0.12, Bob would add the labels of all the edges around the deleted lines to the dependencies of his change. Then, Alice can tell whether Bob knows of her change before applying it. The changes are conflict if and only if Bob doesn’t know of the new lines.</p>
<p>However, this behaviour was counter-intuitive, <a href="https://discourse.pijul.org/t/why-these-patches-dont-commute/449">as noted by @tae</a>.</p>
<p>A finer analysis of what dependencies are led to a different behaviour in the new Pijul. Changes now have two different sets of …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pijul.org/posts/2020-11-07-towards-1.0/">https://pijul.org/posts/2020-11-07-towards-1.0/</a></em></p>]]>
            </description>
            <link>https://pijul.org/posts/2020-11-07-towards-1.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032956</guid>
            <pubDate>Mon, 09 Nov 2020 09:24:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is how I Git]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25032951">thread link</a>) | @stargrave
<br/>
November 9, 2020 | https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Every now and then I get questions on how to work with git in a smooth way when developing, bug-fixing or extending curl – or how I do it. After all, I <a href="https://daniel.haxx.se/blog/2020/10/26/working-open-source/" data-type="post" data-id="14901">work on open source full time</a> which means I have very frequent interactions with git (and GitHub). Simply put, I work with git all day long. Ordinary days, I issue git commands several hundred times.</p>



<p>I have a very simple approach and way of working with git in curl. This is how it works.</p>



<h2>command line</h2>



<p>I use git almost exclusively from the command line in a terminal. To help me see which branch I’m working in, I have this little bash helper script.</p>



<pre>brname () {
  a=$(<code>git rev-parse --abbrev-ref HEAD 2&gt;/dev/null</code>)
  if [ -n "$a" ]; then
    echo " [$a]"
  else
    echo ""
  fi
}
PS1="\u@\h:\w\$(brname)$ "</pre>



<p>That gives me a prompt that shows username, host name, the current working directory and the current checked out git branch.</p>



<p>In addition: I use Debian’s <a href="https://salsa.debian.org/debian/bash-completion/-/blob/master/README.md">bash command line completion</a> for git which is also really handy. It allows me to use tab to complete things like git commands and branch names. </p>



<h2>git config</h2>



<p>I of course also have my customized <code>~/.gitconfig</code> file to provide me with some convenient aliases and settings. My most commonly used git aliases are:</p>


<pre title="">st = status --short -uno
ci = commit
ca = commit --amend
caa = commit -a --amend
br = branch
co = checkout
df = diff
lg = log -p --pretty=fuller --abbrev-commit
lgg = log --pretty=fuller --abbrev-commit --stat
up = pull --rebase
latest = log @^{/RELEASE-NOTES:.synced}..
</pre>


<p>The ‘latest’ one is for listing all changes done to curl since the most recent RELEASE-NOTES “sync”. The others should hopefully be rather self-explanatory.</p>



<p>The config also sets <code>gpgsign = true</code>, enables mailmap and a few other things.</p>



<h2>master is clean and working</h2>



<p>The main curl development is done in the single <a href="https://github.com/curl/curl">curl/curl</a> git repository (primarily hosted on GitHub). We keep the master branch the bleeding edge development tree and we work hard to always keep that working and functional. We do our releases off the master branch when that day comes (every eight weeks) and we provide “<a href="https://curl.haxx.se/snapshots/">daily snapshots</a>” from that branch, put together – yeah – daily.</p>



<p>When merging fixes and features into master, we avoid merge commits and use rebases and fast-forward as much as possible. This makes the branch very easy to browse, understand and work with – as it is 100% linear.</p>



<h2>Work on a fix or feature</h2>



<p>When I start something new, like work on a bug or trying out someone’s patch or similar, I first create a local branch off master and work in that. That is, I don’t work directly in the master branch. Branches are easy and quick to do and there’s no reason to shy away from having loads of them!</p>



<p>I typically name the branch prefixed with my GitHub user name, so that when I push them to the server it is noticeable who is the creator (and I can use the same branch name locally as I do remotely).</p>



<pre>$ git checkout -b bagder/my-new-stuff-or-bugfix</pre>



<p>Once I’ve reached somewhere, I commit to the branch. It can then end up one or more commits before I consider myself “done for now” with what I was set out to do.</p>



<p>I try not to leave the tree with any uncommitted changes – like if I take off for the day or even just leave for food or an extended break. This puts the repository in a state that allows me to easily switch over to another branch  when I get back – should I feel the need to. Plus, it’s better to commit and explain the change <em>before</em> the break rather than having to recall the details again when coming back.</p>



<h2>Never stash</h2>



<p>“git stash” is therefore not a command I ever use. I rather create a new branch and commit the (temporary?) work in there as a potential new line of work.</p>



<h2>Show it off and get reviews</h2>



<p>Yes I am the lead developer of the project but I still maintain the same work flow as everyone else. All changes, except the most minuscule ones, are done as pull requests on GitHub.</p>



<p>When I’m happy with the functionality in my local branch. When the bug seems to be fixed or the feature seems to be doing what it’s supposed to do and the test suite runs fine locally.</p>



<p>I then clean up the commit series with “<code>git rebase -i</code>” (or if it is a single commit I can instead use just “<code>git commit --amend</code>“).</p>



<p>The commit series should be a set of logical changes that are related to this change and not any more than necessary, but kept separate if they are separate. Each commit also gets its own proper commit message. Unrelated changes should be split out into its own separate branch and subsequent separate pull request.</p>



<pre>git push origin bagder/my-new-stuff-or-bugfix</pre>



<h2>Make the push a pull request</h2>



<p>On GitHub, I then make the newly pushed branch into a <a href="https://github.com/curl/curl/pulls">pull request</a> (aka “a PR”). It will then become visible in the list of pull requests on the site for the curl source repository, it will be announced in the #curl IRC channel and everyone who follows the repository on GitHub will be notified accordingly.</p>



<p>Perhaps most importantly, a pull request kicks of a flood of CI jobs that will build and test the code in numerous different combinations and on several platforms, and the results of those tests will trickle in over the coming hours. When I write this, we have around 90 different CI jobs – per pull request – and something like 8 different code analyzers will scrutinize the change to see if there’s any obvious flaws in there.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png"><img loading="lazy" width="2686" height="1510" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png" alt=""></a><figcaption>CI jobs per platform over time. Graph snapped on November 5, 2020</figcaption></figure>



<h2>A branch in the actual curl/curl repo</h2>



<p>Most contributors who would work on curl would not do like me and make the branch in the curl repository itself, but would rather do them in their own forked version instead. The difference isn’t that big and I <em>could</em> of course also do it that way.</p>



<h2>After push, switch branch</h2>



<p>As it will take some time to get the full CI results from the PR to come in (generally a few hours), I switch over to the next branch with work on my agenda. On a normal work-day I can easily move over ten different branches, polish them and submit updates in their respective pull-requests.</p>



<p>I can go back to the&nbsp;master branch again with ‘<code>git checkout master</code>‘ and there I can “<code>git pull</code>” to get everything from upstream – like when my fellow developers have pushed stuff in the mean time.</p>



<h2>PR comments or CI alerts</h2>



<p>If a reviewer or a CI job find a mistake in one of my PRs, that becomes visible on GitHub and I get to work to handle it. To either fix the bug or discuss with the reviewer what the better approach might be.</p>



<p>Unfortunately, flaky CI jobs is a part of life so very often there ends up one or two red markers in the list of CI jobs that can be ignored as the test failures in them are there due to problems in the setup and not because of actual mistakes in the PR…</p>



<p>To get back to my branch for that PR again, I “<code>git checkout bagder/my-new-stuff-or-bugfix</code>“, and fix the issues.</p>



<p>I normally start out by doing follow-up commits that repair the immediate mistake and push them on the branch:</p>



<pre>git push origin <code>bagder/my-new-stuff-or-bugfix</code></pre>



<p>If the number of fixup commits gets large, or if the follow-up fixes aren’t small, I usually end up doing a squash to reduce the number of commits into a smaller, simpler set, and then force-push them to the branch.</p>



<p>The reason for that is to make the patch series easy to review, read and understand. When a commit series has too many commits that changes the previous commits, it becomes hard to review.</p>



<h2>Ripe to merge?</h2>



<p>When the pull request is ripe for merging (independently of who authored it), I switch over to the master branch again and I merge the pull request’s commits into it. In special cases I cherry-pick specific commits from the branch instead. When all the stuff has been yanked into master properly that should be there, I push the changes to the remote.</p>



<p>Usually, and especially if the pull request wasn’t done by me, I also go over the commit messages and polish them somewhat before I push everything. Commit messages should follow our style and mention not only which PR that it closes but also which issue it fixes and properly give credit to the bug reporter and all the helpers – using the right syntax so that our automatic tools can pick them up correctly!</p>



<p>As already mentioned above, I merge fast-forward or rebased into master. No merge commits.</p>



<h2>Never merge with GitHub!</h2>



<p>There’s a button GitHub that says “rebase and merge” that could theoretically be used for merging pull requests. I <em>never</em> use that (and if I could, I’d disable/hide it). The reasons are simply:</p>



<ol><li>I don’t feel that I have the proper control of the commit message(s)</li><li>I can’t select to squash a subset of the commits, only all or nothing</li><li>I often want to cleanup the author parts too before push, which the UI doesn’t allow</li></ol>



<p>The downside with not using the merge button is that the message in the  PR says “closed by [hash]” instead of “merged in…” which causes confusion to a fair amount of users who don’t realize it means that it actually means the same thing! I consider this is a (long-standing) GitHub UX flaw.</p>



<h2>Post merge</h2>



<p>If the branch has nothing to be kept around more, I delete the local branch again with “<code>git branch -d [name]</code>” and I remove it remotely too since it was completely merged there’s no reason to keep the work version left.</p>



<p>At any given point in time, I have some 20-30 different local branches alive using this approach so things I work on over time all live in their own branches and also submissions from various people that haven’t been merged into master yet exist in branches of various maturity levels. Out of those local branches, the number of concurrent pull requests I have in progress can be somewhere between just a few up to ten, twelve something.</p>



<h2>RELEASE-NOTES</h2>



<p>Not strictly related, but in order to keep interested people informed about what’s happening in the tree, we sync the <a href="https://github.com/curl/curl/blob/master/RELEASE-NOTES">RELEASE-NOTES</a> file every once in a while. Maybe every 5-7 days or so. It …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032951</guid>
            <pubDate>Mon, 09 Nov 2020 09:23:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Beauty of Python's ExitStack (2015)]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25032924">thread link</a>) | @polm23
<br/>
November 9, 2020 | https://www.rath.org/on-the-beauty-of-pythons-exitstack.html | <a href="https://web.archive.org/web/*/https://www.rath.org/on-the-beauty-of-pythons-exitstack.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I believe Python's <a href="http://docs.python.org/3/library/contextlib.html#contextlib.ExitStack">ExitStack</a> feature does not get the recognition
it deserves. I think part of the reason for this is that its
documentation is somewhere deep down in the (already obscure)
<a href="http://docs.python.org/3/library/contextlib.html">contextlib</a> module because formally ExitStack is just one of many
available context managers for Python's <a href="http://docs.python.org/3/reference/compound_stmts.html#the-with-statement">with statement</a>. But
ExitStack deserves far more prominent notice than that. This post will
hopefully help with that.</p>
<p>So what makes ExitStack so important? In short, it's the best way to
handle allocation and release of external resources in Python.</p>
<div id="the-problem">
<h2>The Problem</h2>
<p>The main challenge with external resources is that you have to release
them when you don't need them anymore -- and in particular you must
not forget to do so in all the alternate execution paths that may be
entered in case of error conditions.</p>
<p>Most languages implement error conditions as "exceptions" that can be
"caught" and handled (Python, Java, C++), or as special return values
that you need to check to determine if an error occured (C, Rust,
Go). Typically, code that needs to acquire and release external
resources then looks like this:</p>
<div><pre><span></span><span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>()</span>
<span>try</span><span>:</span>
    <span># do stuff with res1</span>
    <span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>()</span>
    <span>try</span><span>:</span>
        <span># do stuff with res1 and res2</span>
    <span>finally</span><span>:</span>
        <span>release_resource</span><span>(</span><span>res2</span><span>)</span>
<span>finally</span><span>:</span>
   <span>release_resource</span><span>(</span><span>res1</span><span>)</span>
</pre></div>
<p>or, if the language doesn't have exceptions:</p>
<div><pre><span></span><span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>();</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>-</span><span>1</span><span>)</span> <span>{</span>
   <span>retval</span> <span>=</span> <span>-</span><span>1</span><span>;</span>
   <span>goto</span> <span>error_out1</span><span>;</span>
<span>}</span>
<span>// do stuff with res1</span>
<span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>();</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>-</span><span>1</span><span>)</span> <span>{</span>
   <span>retval</span> <span>=</span> <span>-</span><span>2</span><span>;</span>
   <span>goto</span> <span>error_out2</span><span>;</span>
<span>}</span>
<span>// do stuff with res1 and res2</span>
<span>retval</span> <span>=</span> <span>0</span><span>;</span> <span>// ok</span>

<span>error_out2</span><span>:</span>
  <span>release_resource</span><span>(</span><span>res2</span><span>);</span>
<span>error_out1</span><span>:</span>
  <span>release_resource</span><span>(</span><span>res1</span><span>);</span>
<span>return</span> <span>retval</span><span>;</span>
</pre></div>
<p>This approach has three big problems:</p>
<ol>
<li>The cleanup code is far away from the allocation code.</li>
<li>When the number of resources increases, indentation levels (or jump
labels) accumulate, making things hard to read.</li>
<li>Managing a dynamic number of resources this way is impossible.</li>
</ol>
<p>In Python, some of these issues can be alleviated by using the
<tt>with</tt> statement:</p>
<div><pre><span></span> <span>@contextlib.contextmanager</span>
 <span>def</span> <span>my_resource</span><span>(</span><span>id_</span><span>):</span>
     <span>res</span> <span>=</span> <span>acquire_resource</span><span>(</span><span>id_</span><span>)</span>
     <span>try</span><span>:</span>
         <span>yield</span> <span>res</span>
     <span>finally</span><span>:</span>
         <span>release_source</span><span>(</span><span>res</span><span>)</span>

<span>with</span> <span>my_resource</span><span>(</span><span>RES_ONE</span><span>)</span> <span>as</span> <span>res1</span><span>,</span> \
   <span>my_resource</span><span>(</span><span>RES_TWO</span><span>)</span> <span>as</span> <span>res2</span><span>:</span>
    <span># do stuff with res1</span>
    <span># do stuff with res1 and res2</span>
</pre></div>
<p>However, this solution is far from optimal: you need to implement
resource-specific context managers (note that in the above example we
silently assumed that both resources can be acquired by the same
function), you can get rid of extra indentation only if you allocate
all the resources at the same time and live with an ugly continuation
line (no parenthesis allowed in this context), and you still need to
know the number of required resources ahead of time.</p>
<p>Over in the world of exception-less programming languages (no pun
intended), <a href="http://www.golang.org/">Go</a> has developed a different remedy: the <a href="http://golang.org/ref/spec#Defer_statement">defer statement</a>
defers execution of an expression until the enclosing
function returns. Using <tt>defer</tt>, the above example can be written
as:</p>
<div><pre><span></span><span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>()</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>NULL</span><span>)</span> <span>{</span>
    <span>return</span> <span>-</span><span>1</span>
<span>}</span>
<span>defer</span> <span>release_resource</span><span>(</span><span>res1</span><span>)</span>
<span>// do stuff with res1</span>
<span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>()</span>
<span>if</span><span>(</span><span>res</span> <span>==</span> <span>NULL</span><span>)</span> <span>{</span>
    <span>return</span> <span>-</span><span>2</span>
<span>}</span>
<span>defer</span> <span>release_resource</span><span>(</span><span>res2</span><span>)</span>
<span>// do stuff with res1 and res2</span>
<span>return</span> <span>0</span>
</pre></div>
<p>This is pretty nice: allocation and cleanup are kept close together,
no extra indentation or jump labels are required, and converting this
to a loop that dynamically acquires multiple resources would be
straightforward. But there are still some drawbacks:</p>
<ul>
<li>To control when exactly a group of resources is getting released you
have to factor out into separate functions all parts of code that
access the respective resources.</li>
<li>You cannot "cancel" a deferred expression, so there is no way to
e.g. return a resource to the caller if no error occured.</li>
<li>There is no way to handle errors from the cleanup functions.</li>
<li><tt>defer</tt> is available in Go, but not in Python.</li>
</ul>
</div>
<div id="exitstack-to-the-rescue">
<h2>ExitStack to the rescue</h2>
<p><a href="http://docs.python.org/3/library/contextlib.html#contextlib.ExitStack">ExitStack</a> fixes all of the above issues, and adds some benefits on
top of it. An ExitStack is (as the name suggests) a stack of clean-up
functions. Adding a callback to the stack is the equivalent of calling
Go's <tt>defer</tt> statement. However, clean-up functions are not executed
when the function returns, but when execution leaves the <tt>with</tt>
block - and until then, the stack can also be emptied again.</p>
<p>Finally, clean-up functions itself may raise exceptions without
affecting execution of other clean-up functions. Even if multiple
clean-ups raise exceptions, you are will get a usable stacktrace.</p>
<p>Here's how to acquire multiple resources:</p>
<div><pre><span></span><span>with</span> <span>ExitStack</span><span>()</span> <span>as</span> <span>cm</span><span>:</span>
    <span>res1</span> <span>=</span> <span>acquire_resource_one</span><span>()</span>
    <span>cm</span><span>.</span><span>callback</span><span>(</span><span>release_resource</span><span>,</span> <span>res1</span><span>)</span>
    <span># do stuff with res1</span>
    <span>res2</span> <span>=</span> <span>acquire_resource_two</span><span>()</span>
    <span>cm</span><span>.</span><span>callback</span><span>(</span><span>release_resource</span><span>,</span> <span>res2</span><span>)</span>
    <span># do stuff with res1 and res2</span>
</pre></div>
<p>Note that</p>
<ul>
<li>acquisition and release are close to each other</li>
<li>there's no extra indentation,</li>
<li>the pattern and it easily scales up to many resources (including a
dynamic number that's acquired in a loop)</li>
</ul>
<p>If there already is a context manager for your resource, there's also
a shortcut function:</p>
<div><pre><span></span><span>with</span> <span>ExitStack</span><span>()</span> <span>as</span> <span>cm</span><span>:</span>
    <span>res1</span> <span>=</span> <span>cm</span><span>.</span><span>enter</span><span>(</span><span>open</span><span>(</span><span>'first_file'</span><span>,</span> <span>'r'</span><span>))</span>
    <span># do stuff with res1</span>
    <span>res2</span> <span>=</span> <span>cm</span><span>.</span><span>enter</span><span>(</span><span>open</span><span>(</span><span>'second_file'</span><span>,</span> <span>'r'</span><span>))</span>
    <span># do stuff with res1 and res2</span>
</pre></div>
<p>To open a bunch of files and return them to the caller (without
leaking already opened files if a subsequent open fails):</p>
<div><pre><span></span><span>def</span> <span>open_files</span><span>(</span><span>filelist</span><span>):</span>
    <span>fhs</span> <span>=</span> <span>[]</span>
    <span>with</span> <span>ExitStack</span><span>()</span> <span>as</span> <span>cm</span><span>:</span>
        <span>for</span> <span>name</span> <span>in</span> <span>filelist</span><span>:</span>
            <span>fhs</span><span>.</span><span>append</span><span>(</span><span>cm</span><span>.</span><span>enter</span><span>(</span><span>open</span><span>(</span><span>name</span><span>,</span> <span>'r'</span><span>)))</span>
        <span>cm</span><span>.</span><span>pop_all</span><span>()</span>
        <span>return</span> <span>fhs</span>
</pre></div>
<p>Disclaimer: the <a href="https://bugs.python.org/issue13585">original idea for ExitStack</a> came from me.</p>
</div>
</div></div>]]>
            </description>
            <link>https://www.rath.org/on-the-beauty-of-pythons-exitstack.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032924</guid>
            <pubDate>Mon, 09 Nov 2020 09:19:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programmatically perform personalized sales out-reach to Fortune 500 companies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25032865">thread link</a>) | @nubela
<br/>
November 9, 2020 | https://nubela.co/blog/send-personalized-emails-to-decision-makers-scrape-linkedin-company-profile/ | <a href="https://web.archive.org/web/*/https://nubela.co/blog/send-personalized-emails-to-decision-makers-scrape-linkedin-company-profile/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://accountgram-production.sfo2.cdn.digitaloceanspaces.com/nubelaco_ghost/2020/11/TLC_How_I_sent_personalized_emails_with_25_follow-ups_to_decision_makers_of_200_Fortune_500_companies_light_bg.png 300w,
                            https://accountgram-production.sfo2.cdn.digitaloceanspaces.com/nubelaco_ghost/2020/11/TLC_How_I_sent_personalized_emails_with_25_follow-ups_to_decision_makers_of_200_Fortune_500_companies_light_bg.png 600w,
                            https://accountgram-production.sfo2.cdn.digitaloceanspaces.com/nubelaco_ghost/2020/11/TLC_How_I_sent_personalized_emails_with_25_follow-ups_to_decision_makers_of_200_Fortune_500_companies_light_bg.png 1000w,
                            https://accountgram-production.sfo2.cdn.digitaloceanspaces.com/nubelaco_ghost/2020/11/TLC_How_I_sent_personalized_emails_with_25_follow-ups_to_decision_makers_of_200_Fortune_500_companies_light_bg.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://accountgram-production.sfo2.cdn.digitaloceanspaces.com/nubelaco_ghost/2020/11/TLC_How_I_sent_personalized_emails_with_25_follow-ups_to_decision_makers_of_200_Fortune_500_companies_light_bg.png" alt="How to programmatically send personalized emails to 200 decision makers of Fortune 500 companies (with code samples)">
</figure>
<section>
<div>
<h2 id="i-want-to-close-bigger-deals-by-reaching-decision-makers-directly">I want to close bigger deals by reaching decision-makers directly</h2><p>I am the founder of Nubela. I lead sales for Proxycurl, and I do this alone. So it is vital that whatever I do is leveraged and effective. Luckily, I can code.<br>I figured that general emails do not get to decision-makers in large(r) companies, and I want to move up the value chain. I want to close bigger deals. I think I can achieve that by reaching decision-makers directly and with emails personalized with a unique problem-solution statement for their company. To say, I want to do what other sales reps are doing and more.<br>To be very specific, I want to reach 200 decision-makers at a single burst. I want to send 25 personalized follow-ups per decision-maker.<br>In this blog post, I will share how I accomplished this with code.</p><h2 id="getting-a-list-of-companies-with-crunchbase-pro">Getting a list of companies with Crunchbase Pro</h2><p>I want to target larger companies that have the budget to purchase Proxycurl to build data-driven products. In particular, I have shortlisted companies that belong to the likes of sales automation tools, job boards, and talent sourcing companies to be our target market. Crunchbase Pro is excellent for building a list like such.</p><p>With Crunchbase Pro, I started a Company Search for a list of companies that</p><ol><li>matched Proxycurl's target industries</li><li>have revenues that are more than 5+M per annum</li></ol><p>Then, I exported the search results into a CSV file, ensuring that I have a column of data that includes the company's Linkedin Profile.</p><p>Once I have the list, I want to enrich the data with company names and their corresponding corporate website. This is the Python script I used to enrich data for the list of companies I had exported from Crunchbase Pro:</p><pre><code>async def get_company(company_profile_url: str):
    api_endpoint = f'{PROXYCURL_HOST}/api/linkedin/company'
    header_dic = {'Authorization': 'Bearer ' + PROXYCURL_API_KEY}

    for _ in range(RETRY_COUNT):
        try:
            async with httpx.AsyncClient() as client:
                r = await client.get(api_endpoint,
                                     params={'url': company_profile_url},
                                     headers=header_dic,
                                     timeout=PROXYCURL_XHR_DEFAULT_TIMEOUT)
                assert r.status_code == 200
                return r.json()
        except:
            continue

    return None


async def enrich_companies(lis):
    for profile_url in lis:
        coy = await get_company(profile_url)
        if coy is None:
            return None
        website = coy.get('website', None)
        coy_name = coy.get('name', None)

        # todo - (task for reader) save `website` and `coy_name` in a file
</code></pre>
<h2 id="find-decision-makers-with-proxycurl-api">Find decision makers with Proxycurl API</h2><p>Now that I have companies, I need decision-makers. Decision-makers in this exercise mean people in the roles of CEO, COO, CTO, and VP of Product.</p><p>To accomplish this, I will search for them on Google. For example, if I want to find the Linkedin profile of the CEO of Cognism, I will enter the following search phrase in Google:</p><blockquote>linkedin.com/in ceo cognism</blockquote><p>Chances are, the correct profile will be in the search result. I will then repeat the query with different roles till I have a list of profiles. And it works.</p><p>To perform Google searches at scale, I will use Proxycurl's <a href="https://nubela.co/proxycurl/docs#crawling-other-pages">"Crawling other pages" endpoint</a>. This is how I programmatically make Google Search queries with Proxycurl:</p><pre><code>async def google_search_async(search_term, retry_count=5) -&gt; List[str]:
    """
    Perform a Google Search via Overlord and return a list of results in terms of URLs in the first page.
    """
    for _ in range(retry_count):
        try:
            search_url = f"https://www.google.com/search?q={quote(search_term)}"
            payload = {'url': search_url,
                       "type": 'xhr',
                       }

            async with httpx.AsyncClient() as client:
                r = await client.post(f"{OVERLORD_ENDPOINT}/message",
                                      auth=(OVERLORD_USERNAME,
                                            OVERLORD_PASSWD),
                                      json=payload,
                                      timeout=PROXYCURL_XHR_DEFAULT_TIMEOUT)
                if r.status_code != 200:
                    print(
                        f"Google search failed with {r.status_code}, retrying.")
                assert r.status_code == 200

            html_src = r.json()['data']
            soup = BeautifulSoup(html_src, features="html.parser")
            result_lis = soup.select(".g a[ping]")
            href_lis = []
            for result in result_lis:
                href = result['href']
                if '//webcache.googleusercontent.com/search' in href:
                    continue
                if 'https://translate.google.com/translate' in href:
                    continue
                href_lis += [href]
            if len(href_lis) == 0:
                continue
            return href_lis
        except:
            traceback.print_exc()
            continue
    raise Exception
</code></pre>
<p>However, my computer is not smart enough to understand when a CEO is the same as "Chief Executive Officer." Or that "Engineering Head" and "Chief Engineering" are very much alike. For that, I have an algorithm which I call <code>is_string_similar()</code>. You can find the algorithm to check if two strings are similar <a href="https://giki.wiki/@nubela/Software-Engineering/similar-string">here</a>.</p><p>Once I have a list of Linkedin profiles, I need to ensure that:</p><ol><li>The profile's current employment belongs to the company that I am googling for (Google gets this wrong sometimes)</li><li>The profile's current role at the company matches the decision making roles.</li></ol><p>To perform the checks above, I will:</p><ol><li>Enrich the Linkedin profiles with <a href="https://nubela.co/proxycurl/docs#linkedin-person-profile-endpoint">Proxycurl's Person Profile Endpoint</a> to get the profile's list of experiences.</li><li>Verify that his/her active employment matches up.</li></ol><p>This is how I accomplish the above in Python code:</p><pre><code>async def get_person_profile(profile_url):
    api_endpoint = f'{PROXYCURL_HOST}/api/v2/linkedin'
    header_dic = {'Authorization': 'Bearer ' + PROXYCURL_API_KEY}

    for _ in range(RETRY_COUNT):
        try:
            async with httpx.AsyncClient() as client:
                r = await client.get(api_endpoint,
                                     params={'url': profile_url},
                                     headers=header_dic,
                                     timeout=PROXYCURL_XHR_DEFAULT_TIMEOUT)
                if r.status_code == 404:
                    return None
                assert r.status_code == 200
                return r.json()
        except:
            continue

    print(f"{profile_url} retried {RETRY_COUNT} times but still failing")
    return None


async def google_search_async(search_term, retry_count=3) -&gt; List[str]:
    """
    Perform a Google Search via Overlord and return a list of results in terms of URLs in the first page.
    """
    for _ in range(retry_count):
        try:
            search_url = f"https://www.google.com/search?q={quote(search_term)}"
            payload = {'url': search_url,
                       "type": 'xhr',
                       }

            async with httpx.AsyncClient() as client:
                r = await client.post(f"{OVERLORD_ENDPOINT}/message",
                                      auth=(OVERLORD_USERNAME,
                                            OVERLORD_PASSWD),
                                      json=payload,
                                      timeout=PROXYCURL_XHR_DEFAULT_TIMEOUT)
                if r.status_code != 200:
                    print(
                        f"Google search failed with {r.status_code}, retrying.")
                assert r.status_code == 200

            html_src = r.json()['data']
            soup = BeautifulSoup(html_src, features="html.parser")
            result_lis = soup.select(".g a[ping]")
            href_lis = []
            for result in result_lis:
                href = result['href']
                if '//webcache.googleusercontent.com/search' in href:
                    continue
                if 'https://translate.google.com/translate' in href:
                    continue
                href_lis += [href]
            return href_lis
        except:
            traceback.print_exc()
            continue
    raise Exception


async def find_people_in_roles(coy_name: str, li_coy_profile_url: str = None) -&gt; List[str]:
    MAX_WORKERS = 10
    ROLES = ['ceo',
             'cto',
             'coo',
             'vp engineering'
             ]

    def does_role_match(role: str, person_profile: Dict) -&gt; bool:
        for exp in person_profile['experiences']:
            if not (exp['ends_at'] is None and util.is_string_similar(coy_name, exp['company'])):
                continue

            if not util.is_string_similar(role, exp['title']):
                continue

            return True
        return False

    async def search_li_profile(role: str) -&gt; List[str]:
        url_result_lis = await google_search_async(f"linkedin.com/in {role} {coy_name}", retry_count=RETRY_COUNT)
        profile_url_lis = list(filter(lambda x: 'linkedin.com/in' in x,
                                      url_result_lis))
        return (role, profile_url_lis)

    print("Performing google search for Linkedin profiles")
    tasks = [search_li_profile(role) for role in ROLES]
    search_results = await asyncio.gather(*tasks)

    profile_url_lis = []
    for _, profile_lis in search_results:
        for profile_url in profile_lis:
            if profile_url not in profile_url_lis:
                profile_url_lis += [profile_url]
    print(f"Total of {len(profile_url_lis)} profiles to query")

    profile_dic = {}
    working_lis = []
    for idx, profile_url in enumerate(profile_url_lis):
        working_lis += [profile_url]

        if (idx &gt; 0 and len(working_lis) &gt; 0 and idx % MAX_WORKERS == 0) or idx == (len(profile_url_lis) - 1):
            print(f"Working on {len(working_lis)} profiles..")
            tasks = …</code></pre></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nubela.co/blog/send-personalized-emails-to-decision-makers-scrape-linkedin-company-profile/">https://nubela.co/blog/send-personalized-emails-to-decision-makers-scrape-linkedin-company-profile/</a></em></p>]]>
            </description>
            <link>https://nubela.co/blog/send-personalized-emails-to-decision-makers-scrape-linkedin-company-profile/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032865</guid>
            <pubDate>Mon, 09 Nov 2020 09:12:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Loop Software (2013)]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25032563">thread link</a>) | @netgusto
<br/>
November 9, 2020 | https://marak.com/blog/2013-05-13-time-loop-software | <a href="https://web.archive.org/web/*/https://marak.com/blog/2013-05-13-time-loop-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<p>What if it were possible to write software capable of time travel? What if we could write software that was able to retrieve results from a computation solved sometime in the near future? What would this software look like? What problems could be solved?</p>
<p><a href="https://en.wikipedia.org/wiki/Novikov_self-consistency_principle#Time_loop_logic">Time loop logic</a> is a hypothetical system of computation that exploits the <a href="https://en.wikipedia.org/wiki/Novikov_self-consistency_principle">Novikov self-consistency principle</a>. In this system the computer is able to send the result of a computation backwards through time and rely upon the self-consistency principle to force the sent result to be correct. This futuristic concept might seem impossible now but I'd imagine trying to explain nuclear fission to a 3rd century blacksmith would seem equally impossible.</p>
<h2 id="writing-time-loop-software">Writing time loop software</h2>
<p>Building on the concept of time loop logic we are able to implement theoretical programming constructs to help better understand the concept of time travel in software. In the following examples we demonstrate what a time loop logic program might look like.</p>
<h3 id="an-event-loop">An event loop</h3>
<p>In the follow examples we'll be using the JavaScript programing language. JavaScript provides a single thread of execution for code to run in. The JavaScript virtual machine is constantly running an event loop. Each tick of this event loop represents a single cycle of code execution. Once this cycle is completed the next tick in the event loop will occur. In the popular <a href="https://nodejs.org/">Node.js</a> framework <a href="https://nodejs.org/api/process.html#process_process_nexttick_callback">an API is provided</a> to defer the execution of a block of code until the nextTick of the event loop occurs.</p>
<h4 id="node-js-process-nexttick-example">node.js process.nextTick() example</h4>
<pre><code><span><span>function</span> <span>foo</span>(<span></span>) </span>{
  <span>console</span>.log(<span>'foo'</span>);
}

process.nextTick(foo);
<span>console</span>.log(<span>'bar'</span>);
</code></pre><p>This will output:</p>
<pre><code><span>bar
</span><span>foo</span>
</code></pre><p>The same effect of <code>process.nextTick</code> can also be achieved using JavaScript's setTimeout command</p>
<pre><code>setTimeout<span>(<span>foo</span>, <span>0</span>)</span>
</code></pre><h4 id="node-js-process-prevtick-example">node.js process.prevTick() example</h4>
<p>Now let's imagine that instead of deferring a line of code until the next tick of the event loop we could instead push that code <em>backwards</em> to the <em>previous</em> tick of the event loop.</p>
<pre><code><span><span>function</span> <span>foo</span>(<span></span>) </span>{
  <span>console</span>.log(<span>'foo'</span>);
}

<span>console</span>.log(<span>'bar'</span>);
process.prevTick(foo);
</code></pre><p>Outputs:</p>
<pre><code><span>foo</span>
bar
</code></pre><p>The same effect of <code>process.prevTick</code> can also be achieved using setTimeout with a negative value</p>
<pre><code>setTimeout<span>(<span>foo</span>, <span>-1</span>)</span>
</code></pre><p>Since all we are doing is logging a simple string to the console, this is a contrived example. However; building on the concept of <code>process.prevTick</code> we can begin to implement more complex time loop programs.</p>
<h2 id="brute-force-cracking-with-time-loops">Brute force cracking with time loops</h2>
<p>Let's assume a simple <a href="https://en.wikipedia.org/wiki/Brute-force_search">brute-force search</a> password cracking scenario. Imagine there is a login function which expects a password. We have access to a very large word dictionary in which our cracking software will sequentially attempt logins using every word in the dictionary as a password until a match is found.</p>
<p>Here is the code for our brute-force program</p>
<p><em>Note: It's important to remember that Novikov's self-consistency principle guarantees that the sequence of events generating the paradox in the following code has zero probability.</em></p>


<h2 id="prime-factors-with-time-loops">Prime Factors with time loops</h2>
<p>Using time-loop logic  prime factors can be calculated in polynomial time.</p>


<h2 id="zero-lag-instant-communication">Zero-lag / Instant Communication</h2>
<p>The theoretical application of time-loop logic is endless. Imagine a time-loop based communication protocol. This would mean zero millisecond latency. Imagine gaming, video broadcasting, and file sharing with instantaneous transfer and zero lag. Through exploiting self-consistency we know that data will be sent in the immediate future ( since the data has begun transferring from the source ) and that eventually the transmission will arrive at it's destination. As long as the data will eventually be received, we are able to send the result back from the future into the immediate present, removing the notion of latency or lag.</p>
<h2 id="time-loop-logic-and-novikov-s-self-consistency-principle">Time Loop Logic and Novikov's Self-Consistency Principle</h2>
<p>How is it actually possible to program a time loop? Based on the self-consistency principle and continuing advancements in quantum entanglement these types of mind-bending constructs are not very far away. It's very possible we'll see this type of software actively being developed within the next hundred years.</p>
<p>Time loop logic was first written about by <a href="https://en.wikipedia.org/wiki/Hans_Moravec">Hans Moravec</a> who is best known for his work in robotics and artificial intelligence at Carnegie Mellon University. You can find Hans' original paper from 1991, "Time Travel and Computing", here: <a href="https://frc.ri.cmu.edu/~hpm/project.archive/general.articles/1991/TempComp.html">https://frc.ri.cmu.edu/~hpm/project.archive/general.articles/1991/TempComp.html</a>. I recommend reading the entire paper.</p>
<p>What we know from <a href="https://en.wikipedia.org/wiki/Closed_timelike_curve#General_relativity">general relativity</a> is that at a quantum level backwards time-travel is mathematically possible in certain solutions containing <a href="https://en.wikipedia.org/wiki/Closed_timelike_curve">closed timelike curves</a>. A closed timelike curve is a <a href="https://en.wikipedia.org/wiki/World_line">world-line</a> in a <a href="https://en.wikipedia.org/wiki/Lorentzian_manifold#Lorentzian_manifold">Lorentzian manifold</a>. </p>
<p>Closed timelike curves ( CTCs ) pose a problem for physicists. The existence of CTCs introduces the notion of time travel being possible. If time travel is possible, we have now introduced the notion of <a href="https://en.wikipedia.org/wiki/Grandfather_paradox">time travel paradoxes</a> which can violate <a href="https://en.wikipedia.org/wiki/Causality_(physics)">causality</a>. Since it's generally accepted that we cannot violate causality in our universe we must be able to explain how closed time-like curves can exist.</p>
<p>In his self-consistency principle Novikov asserts that if an event exists that would give rise to a paradox, or to any "change" to the past whatsoever, then the probability of that event is zero. In short, it says that it is impossible to create time travel paradoxes. You can find the original paper here: <a href="http://authors.library.caltech.edu/3737">http://authors.library.caltech.edu/3737</a>. I recommend starting with reading the <a href="https://en.wikipedia.org/wiki/Novikov_self-consistency_principle#History_of_the_principle">history of the principle</a>.</p>

<p>In order for time loop logic to return an answer instantaneously, we <em>must</em> ensure that the problem will run long enough into the future to <em>actually</em> calculate the result. If a problem takes sixty seconds to solve, the program must run for at least sixty seconds. Time-loop logic does <em>not</em> violate causality. We are able to retrieve the answer instantly because we have committed to spending sixty seconds in the future calculating the answer and sending it back.</p>
<p>This turns debugging time-loop logic into somewhat of an impossibility. Any bugs in a time loop indicate that sometime in the future a problem has occurred. <strong>This event may or may not be related to software.</strong> </p>
<p>Imagine a computer that utilized a time loop to brute force crack passwords ( as our code posted above did). I turn the machine on and request it cracks the password. The program doesn't work. Frustrated, I turn off the machine and complain to my co-worker Josh.</p>
<p>Josh turns on the machine and requests the password. The software works instantly cracking the password in under 1ms.</p>
<p>Bewildered, I ask Josh why the machine worked for him but not for me.</p>
<p>Josh replies, "It's actually quite simple. Using that computer it's going to take approximately 400 hours to brute force the password. After that 400 hours the CPU must recursively return the cracked password back in time until it reaches right now. I was able to get the answer instantly because I have decided to not turn this computer off for another 399 hours and 59 minutes. Simply put, you turned off the computer too quickly"</p>
<p><em>The consequences of unplugging the computer</em></p>
</div></div></div>]]>
            </description>
            <link>https://marak.com/blog/2013-05-13-time-loop-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032563</guid>
            <pubDate>Mon, 09 Nov 2020 08:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Productivity vs. Privacy]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25032481">thread link</a>) | @jessems
<br/>
November 9, 2020 | https://jessems.com/productivity-vs-privacy | <a href="https://web.archive.org/web/*/https://jessems.com/productivity-vs-privacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>In recent years there's been a steady growth in privacy focused companies. Some examples that have reached large-scale adoption are <a href="https://protonmail.com/">ProtonMail</a>, <a href="https://signal.com/">Signal</a>, and <a href="https://duckduckgo.com/">DuckDuckGo</a>. These are companies that have put privacy front and center to their value proposition and can be considered <em>privacy-preserving products</em>. I've come to beleive a goal of preserving user privacy is often inherently in tension with the goal of advancing user productivity.</p><p>What these services have in common is that they promise their users a higher degree of privacy relative to their competitors. Instead of the usual encryption in transit (protection from eavesdroppers) and encryption at rest (protection against unauthorized users), services like Signal and ProtonMail enable their users to hide data from anyone except the intended recipient, which — crucially — includes the service providers themselves.</p><p>This category of encryption is known as end-to-end encryption (e2e) and has found adopters in anyone from principled libertarians to journalists and human rights activitists whose lives may depend on their conversations remaining unwiretapped.</p><h2>Early privacy-preserving software was too difficult to use</h2><p>The canonical implementation of e2e for email is known as Pretty Good Privacy (PGP) and its reference implementation is GPG. GPG never reached mass adoption and there seems to be a myriad of reasons for that. The most salient reason, however, seems to be that to this day, it continues to be difficult to use. As the founder of Signal, Moxie Marlinspike <a href="https://moxie.org/2015/02/24/gpg-and-me.html">explains</a>, the spirit behind GPG was the following:</p><blockquote><p>Instead of developing opinionated software with a simple interface, GPG was written to be as powerful and flexible as possible.</p></blockquote><p>Powerful, flexible software written by nerds, unfortunately also tends to be prohibitively complex for normal users. Combined with the fact that <a href="https://signal.org/blog/the-ecosystem-is-moving/">decentralized technology seems unable to quickly adapt to change</a>, the result has been a clunky solution that has, quite frankly, stayed clunky. With no feasible privacy-preserving alternative <!-- -->[1]<!-- -->, non-privacy preserving email providers became the norm.</p><h2>Surveillance capitalist companies will not encrypt your data, because they rely on being able to read it</h2><p>One such email provider, Gmail by Google, gained millions of users by offering a free plan. Their initial monetization strategy was scanning your emails and serving you personalized ads. Although they've stopped personalizing the ads, they're still scanning your email's contents to serve you a better experience across their services. Similarly, Facebook tracks what you do to shape your experience and keep you glued (they would say 'engaged') to their platform.</p><p>What unites platforms like Google and Facebook, is described by Professor Shoshana Zuboff as “<a href="https://en.wikipedia.org/wiki/Surveillance_capitalism">surveillance capitalism</a>”. The business model of surveillance capitalist companies is to harvest personal data about you to build a model that predicts your behavior. These prediction models are packaged and sold as advertisement opportunities to companies eager to buy your attention. You might be the user, but you're not the customer — the advertisers are.</p><p>It should come as no surprise then, that none of these platforms has shipped with end-to-end encryption by default. Doing so would go against the incentives that undergird their very business model. Their ability to predict your behavior, and sell ads based on those predictions, hinges on their ability to harvest your data.</p><h2>Data is also collected to improve the service</h2><p>A company like Google has other business models of course. Google Workspace, aimed at businesses, is a collection of collaboration and productivity tools. This ranges from Google Docs, to chat, to video conferencing, and more. By offering this as a paid service, Google exposes itself to a different incentive, one where the customer and the user are now one and the same.</p><p>Even if you're both the user and the customer, your data is still being harvested. This data might not feed into personalized ads (because that’s no longer the primary business model) but rather into improving your experience. But as a business user, when does your experience improve? And as a service provider, how do you know what improves the experience?</p><h2>Improvements are productivity gains</h2><p>There's an inclination to think of improvements as things that help you do the thing you want to do quicker, better and/or with less frustration. We can go one step further and borrow some of the thinking used in economics and treat productivity simply as the ratio between outputs (salaries and corporate profits) and inputs (hours worked). Productivity increases if inputs can be decreased (for equal outputs) or outputs can be increased (for equal inputs). What's more, we would expect this quantity to improve along with advances in technology.</p><p>How does technology lead to increases in productivity? One obvious way is by making us more efficient. If some new technology saves us time doing a certain task (decreased input), all other things being equal, we’ll end up seeing those gains reflected in our outputs.</p><h2>Productivity gains are discovered, not planned</h2><p>What exactly are the things that increase efficiency? Here's where it gets tricky. In the realm of knowledge work, we don't always know where the gains will come from — that is, before they are made. We are still discovering new ways in which we can be more productive and especially so in the domain of collaborative productivity. An illustrative example of how productivity gains are discovered comes from Kevin A. Kwok's description of Figma's road to success.</p><p>In "Why Figma Wins", <a href="https://kwokchain.com/2020/06/19/why-figma-wins/">Kwok details</a> how the product team discovered a way to enable more efficient collaboration in the design process. That this potential existed wasn't at all  obvious to even those within the scene. While Sketch had broken new ground with their vector based design tool geared towards product designers, Figma took it to another level by taking many of the same (dare I say revolutionary) UX patterns and offering them in a web-native, multiplayer web application.</p><blockquote><p>The core insight of Figma is that design is larger than just designers. Design is all of the conversations between designers and PMs about what to build. It is the mocks and prototypes and the feedback on them. It is the handoff of specs and assets to engineers and how easy it is for them to implement them.</p></blockquote><p>As Kevin explains, Figma brought together the disparate disciplines that are involved in a design process into a synced browser window for everybody. This helped democratize design and remove a lot of friction that had existed before.</p><p>Not only did Figma push the frontier of productivity into new territory, it wasn’t obvious beforehand what that territory would look like. The lesson is that productivity improvements are won through a process of <em>discovery</em>. Kevin explains:</p><blockquote><p>As disciplines evolve, they figure out the social norms needed to operate better, build tools that can be shared across the industry, and invent abstractions that allow offloading more and more of the workload. They learn how to collaborate better, not just with each other but with all the other functions as well.</p></blockquote><p>Although there's some inherent uncertainty about what the productivity gains will look like (and where to look for them), there's no uncertainty about whether they will be made at all. If one thing can be counted on, it's the tech industry's relentless march towards higher productivity. The big tech platforms know this and don't shy away from investing heavily in innovation (discovery) in that direction.</p><h2>Productivity gains are unlocked by harvesting data</h2><p>Although there is some inherent tension between preserving privacy vs. allowing for a multiplayer mode like Figma, we can find even stronger tensions when it comes to harvesting data in favor of productivity gains.</p><p>A search feature relies on indexing your data. A recommendation feature relies on mining your browsing history. An autocomplete feature relies on what you (or other users) typed before.</p><p>All these potential features which are made possible through harvesting your user data are not available to privacy-preserving products. The user data isn't readable to them — and that's the whole point.</p><p>This creates a trade-off from the user's perspective. Whatever your particular motivation might be, as soon as you opt for a privacy-preserving service you're opting for a service that is not able to read your data, and by extension, not able to harvest it. Because the harvesting of data is what is driving many of the improvements in productivity, in choosing to preserve user privacy, these services are forgoing their ability to provide additional gains in productivity.</p><p>Historically, as we saw with the origins of GPG, there has always been additional friction involved in replicating a workflow in a privacy-preserving manner. Although using e2e services such as Signal and ProtonMail has become nearly frictionless, they lack many features their non-privacy preserving counterparts offer.</p><h2>The productivity gap between privacy-preserving and non-preserving services</h2><p>If you compare the productivity gains between privacy-preserving and non-preserving products from the perspective of the user, it's hard not to arrive at the conclusion that there’s a gap between the two — and it appears to be growing.</p><p>There is perhaps no better example of a feature which hinges on the ability to read user data than search. Although ProtonMail is reminiscent of Gmail in many ways, one area where it falls short is the absence of any ability to  search the contents of your emails. Search only works if the provider of such functionality can scan and index your content. It works even better if the provider is able to harvest search queries and use those to build predictive models (e.g. autocomplete and smart suggestions). These are features which make Gmail users more productive but aren't available to ProtonMail users <!-- -->[3]<!-- -->.</p><p>The absence of search might not be a dealbreaker for a …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jessems.com/productivity-vs-privacy">https://jessems.com/productivity-vs-privacy</a></em></p>]]>
            </description>
            <link>https://jessems.com/productivity-vs-privacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032481</guid>
            <pubDate>Mon, 09 Nov 2020 08:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Does laser cutting count as woodworking?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25032259">thread link</a>) | @Mimowork
<br/>
November 8, 2020 | https://www.mimowork.com/news/Can%20laser%20cutting%20be%20considered%20as%20woodworking.html | <a href="https://web.archive.org/web/*/https://www.mimowork.com/news/Can%20laser%20cutting%20be%20considered%20as%20woodworking.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>If you clicked on this, you must be interested in woodworking and maybe you also have one of those confusions:&nbsp;</span><strong>Does laser cutting count as woodworking?</strong></p><p><strong><strong><img src="https://www.mimowork.com/data/upload/ueditor/20201102/5f9f6ed9121ab.jpg" title="Does laser cutting count as woodworking?cid=6" alt="Does laser cutting count as woodworking?cid=6" width="700" height=""></strong></strong></p><p><span>Some may say woodworking is all about skilled manual labor, however, some may say technology has progressed, and sometimes manual labor is unnecessary.</span></p><p><span>Here are some thoughts we would want to share with you:</span></p><h2><span>1. Wood is the medium</span></h2><p><span>As with any industry, there are changing trends and evolving technology. The definition of handmade is becoming blurry.</span></p><p><span>For example, like the difference between forging and milling, both use metal as a medium but get the same result. Therefore, no matter what you want to do, engraving, cutting, labeling, and no matter what you want to use, a circular saw, table saw, jigsaw, or a laser cutting machine, it is just different pathways to achieve the same goal.</span></p><p><img src="https://www.mimowork.com/data/upload/ueditor/20201102/5f9f9d1607475.jpg" title="Does laser cutting count as woodworking?cid=6" alt="Does laser cutting count as woodworking?cid=6" width="700" height=""></p><h2><span>2. Skill is the key</span></h2><p><span>We can reach an agreement that the idea of “skill” is more based on how much someone put themselves into a project. So if someone uses a 3D printer to print out an “artworks” he/she downloaded, then it should not really be praised as craftsmanship, regardless of how fancy it would be.</span></p><p><a href="https://www.mimowork.com/flatbed-laser-cutting-machine/desktop-laser-engraver-70.html" target="_blank"><span>CNC laser cutting</span></a><span>&nbsp;is a different skill set. A considerable part of the wooden creation is from the skill and ability in operating the CNC laser cutting system.</span></p><p><span>Therefore, as long as you put the time in your woodworking, whatever is learning how to run a CNC laser cutting machine or using a jigsaw, even without the design work, just takes a certain amount of skill that should be appreciated.</span></p><p><span><img src="https://www.mimowork.com/data/upload/ueditor/20201102/5f9f9d83cfc6a.jpg" title="Does laser cutting count as woodworking?cid=6" alt="Does laser cutting count as woodworking?cid=6" width="700" height=""></span></p><h2>3. Technology is a tool</h2><p><span>Some musicians faced criticism for their use of synthesizers or electronic devices. Witnessing the success of Giorgio Moroder, Pink Floyd, etc, still and all, some people felt this was unskilled or unmusical.</span></p><p><span>Same idea with woodworking. Using CNC does not mean that the user lays a board down and CNC will give you a completed piece of work. It is just a tool to shorten your working hours and realize your creativity. There are more high-tech productivity tools yet to come. As tools evolve, unique and brand-new ways to express your artworks will also evolve.</span></p><p><span>Fortunately, the art world now is including “digital art” as a respected and well-developed genre.</span></p><p><img src="https://www.mimowork.com/data/upload/ueditor/20201102/5f9f9ea5567e2.jpg" title="Does laser cutting count as woodworking?cid=6" alt="Does laser cutting count as woodworking?cid=6" width="700" height=""></p><p><img src="https://www.mimowork.com/data/upload/ueditor/20201102/5f9f9ed0187eb.jpg" title="Does laser cutting count as woodworking?cid=6" alt="Does laser cutting count as woodworking?cid=6" width="700" height=""></p><p><span>If you have an idea to create, then you are already miles ahead of most people. Do not let anyone ever dull your sparkle!</span></p></div></div>]]>
            </description>
            <link>https://www.mimowork.com/news/Can%20laser%20cutting%20be%20considered%20as%20woodworking.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032259</guid>
            <pubDate>Mon, 09 Nov 2020 07:41:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Structured Concurrency]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25032133">thread link</a>) | @ingve
<br/>
November 8, 2020 | https://ericniebler.com/2020/11/08/structured-concurrency/ | <a href="https://web.archive.org/web/*/https://ericniebler.com/2020/11/08/structured-concurrency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>TL;DR: <strong>“Structured concurrency” refers to a way to structure async computations so that child operations are guaranteed to complete before their parents, just the way a function is guaranteed to complete before its caller.</strong> This sounds simple and boring, but in C++ it’s anything but. Structured concurrency — most notably, C++20 coroutines — has profound implications for the correctness and the simplicity of async architecture. It brings the <a href="https://docs.microsoft.com/en-us/cpp/cpp/welcome-back-to-cpp-modern-cpp?view=msvc-160">Modern C++ style</a> to our async programs by making async lifetimes correspond to ordinary C++ lexical scopes, eliminating the need for reference counting to manage object lifetime.</p>
<h2>Structured Programming and C++</h2>
<p>Back in the 1950’s, the nascent computing industry discovered structured programming: that high-level programming languages with lexical scopes, control structures, and subroutines resulted in programs that were far easier to read, write, and maintain than programming at the assembly level with test-and-jump instructions and <code>goto</code>. The advance was such a quantum leap that nobody talks about structured programming anymore; it’s just “programming”.</p>
<p>C++, more so than any other language, leverages structured programming to the hilt. The semantics of object lifetime mirror — and are tied to — the strict nesting of scopes; i.e., the <em>structure</em> of your code. Function activations nest, scopes nest, and object lifetimes nest. Objects’ lifetimes end with a scope’s closing curly brace, and objects are destroyed in the reverse order of their construction to preserve the strict nesting.</p>
<p>The Modern C++ programming style is built on this structured foundation. Objects have <em>value semantics</em> — they behave like the ints — and resources are cleaned up in destructors deterministically, which guarantees structurally that resources aren’t used after their lifetimes have ended. This is <em>very</em> important.</p>
<p>When we abandon this strict nesting of scopes and lifetimes — say, when we reference count an object on the heap, or when we use the singleton pattern — we are fighting against the strengths of the language rather than working with them.</p>
<h2>The Trouble With Threads</h2>
<p>Writing correct programs in the presence of concurrency is far more difficult than in single-threaded code. There are lots of reasons for this. One reason is that threads, like singletons and dynamically allocated objects, scoff at your puny nested scopes. Although you can use the Modern C++ style <em>within</em> a thread, when logic and lifetimes are scattered across threads, the hierarchical structure of your program is lost. The tools we use to manage complexity in single-threaded code — in particular, nested lifetimes tied to nested scopes — simply don’t translate to async code.</p>
<p>To see what I mean, let’s look at what happens when we take a simple synchronous function and make it asynchronous.</p>
<pre>void computeResult(State &amp; s);

int doThing() {
  State s;
  computeResult(s);
  return s.result;
}
</pre>
<p><code>doThing()</code> is simple enough. It declares some local state, calls a helper, then returns some result. Now imagine that we want to make both functions async, maybe because they take too long. No problem, let’s use Boost futures, which support continuation chaining:</p>
<pre>boost::future&lt;void&gt; computeResult(State &amp; s);

boost::future&lt;int&gt; doThing() {
  State s;
  auto fut = computeResult(s);
  return fut.then(
    [&amp;](auto&amp;&amp;) { return s.result; }); // OOPS
}
</pre>
<p>If you’ve programmed with futures before, you’re probably screaming, <em>“Nooooo!”</em> The <code>.then()</code> on the last line queues up some work to run after <code>computeResult()</code> completes. <code>doThing()</code> then returns the resulting future. The trouble is, when <code>doThing()</code> returns, the lifetime of the <code>State</code> object ends, <em>and the continuation is still referencing it</em>. That is now a dangling reference, and will likely cause a crash.</p>
<p>What has gone wrong? Futures let us compute with results that aren’t available yet, and the Boost flavor lets us chain continuations. But the continuation is a separate function with a separate scope. We often need to share data across those separate scopes. No more tidy nested scopes, no more nested lifetimes. We have to manage the lifetime of the state manually, something like this:</p>
<pre>boost::future&lt;void&gt;
computeResult(shared_ptr&lt;State&gt; s); // addref
                                    // the state

boost::future&lt;int&gt; doThing() {
  auto s = std::make_shared&lt;State&gt;();
  auto fut = computeResult(s);
  return fut.then(
    [s](auto&amp;&amp;) { return s.result; }); // addref
                                       // the state
}
</pre>
<p>Since both async operations refer to the state, they both need to share responsibility to keep it alive.</p>
<p>Another way to think about this is: <em>what is the lifetime of this asynchronous computation?</em> It starts when <code>doThing()</code> is called, but it doesn’t end until the continuation — the lambda passed to <code>future.then()</code> — returns. <em>There is no lexical scope that corresponds to that lifetime.</em> And that is the source of our woes.</p>
<h2>Unstructured Concurrency</h2>
<p>The story gets more complicated yet when we consider executors. Executors are handles to executions contexts that let you schedule work onto, say, a thread or thread pool. Many codebases have some notion of an executor, and some let you schedule things with a delay or with some other policy. This lets us do cool things, like move a computation from an IO thread pool to a CPU thread pool, or retry an async operation with a delay. Handy, but like <code>goto</code> it is a very low-level control structure that tends to obfuscate rather than clarify.</p>
<p>For instance, I recently came across an algorithm that uses executors and callbacks (called Listeners here) that retries the async allocation of some resource. Below is a greatly abridged version. It is described after the break.</p>
<pre>// This is a continuation that gets invoked when
// the async operation completes:
struct Manager::Listener : ListenerInterface {
  shared_ptr&lt;Manager&gt; manager_;
  executor executor_;
  size_t retriesCount_;

  void onSucceeded() override {
    /* ...yay, allocation succeeded... */
  }
  void onFailed() override {
    // When the allocation fails, post a retry
    // to the executor with a delay
    auto alloc = [manager = manager_]() {
      manager-&gt;allocate();
    };
    // Run "alloc" at some point in the future:
    executor_.execute_after(
      alloc, 10ms * (1 &lt;&lt; retriesCount_));
  }
};

// Try asynchronously allocating some resource
// with the above class as a continuation
void Manager::allocate() {
  // Have we already tried too many times?
  if (retriesCount_ &gt; kMaxRetries) {
    /* ...notify any observers that we failed */
    return;
  }

  // Try once more:
  ++retriesCount_;
  allocator_.doAllocate(
    make_shared&lt;Listener&gt;(
      shared_from_this(),
      executor_,
      retriesCount_));
}
</pre>
<p>The <code>allocate()</code> member function first checks to see if the operation has already been retried too many times. If not it calls a helper <code>doAllocate()</code> function, passing in a callback to be notified on either success or failure. On failure, the handler posts deferred work to the executor, which will call <code>allocate()</code> back, thus retrying the allocation with a delay.</p>
<p>This is a heavily stateful and rather circuitous async algorithm. The logic spans many functions and several objects, and the control and data flow is not obvious. Note the intricate ref-counting dance necessary to keep the objects alive. Posting the work to an executor makes it even harder. Executors in this code have no notion of continuations, so errors that happen during task execution have nowhere to go. The <code>allocate()</code> function can’t signal an error by throwing an exception if it wants any part of the program to be able to recover from the error. Error handling must be done manually and out-of-band. Ditto if we wanted to support cancellation.</p>
<p>This is <strong>unstructured concurrency</strong>: we queue up async operations in an <em>ad hoc</em> fashion; we chain dependent work, use continuations or “strand” executors to enforce sequential consistency; and we use strong and weak reference counts to keep data alive until we are certain it’s no longer needed. There is no formal notion of task A being a child of task B, no way to enforce that child tasks complete before their parents, and no one place in the code that we can point to and say, “Here is the algorithm.”</p>
<blockquote>
<p><strong>If you don’t mind the analogy, the hops through the executor are a bit like <code>goto</code> statements that are non-local in both time and space: “Jump to this point in the program, <em>X</em> milliseconds from now, on this particular thread.”</strong></p>
</blockquote>
<p>That non-local discontinuity makes it hard to reason about correctness and efficiency. Scale unstructured concurrency up to whole programs handling lots of concurrent real-time events, and the incidental complexity of manually handling out-of-band asynchronous control and data flow, controlling concurrent access to shared state, and managing object lifetime becomes overwhelming.</p>
<h2>Structured Concurrency</h2>
<p>Recall that in the early days of computing, unstructured programming styles rapidly gave way to structured styles. With the addition of coroutines to C++, we are seeing a similar phase shift happening today to our asynchronous code. If we were to rewrite the above retry algorithm in terms of coroutines (using Lewis Baker’s popular <a href="https://github.com/lewissbaker/cppcoro">cppcoro</a> library), it might look something like this:</p>
<pre>// Try asynchronously allocating some resource
// with retry:
cppcoro::task&lt;&gt; Manager::allocate() {
  // Retry the allocation up to kMaxRetries
  // times:
  for (int retriesCount = 1;
       retriesCount &lt;= kMaxRetries;
       ++retriesCount) {
    try {
      co_await allocator_.doAllocate();
      co_return; // success!
    } catch (...) {}

    // Oops, it failed. Yield the thread for a
    // bit and then retry:
    co_await scheduler_.schedule_after(
      10ms * (1 &lt;&lt; retriesCount));
  }

  // Error, too many retries
  throw std::runtime_error(
    "Resource allocation retry count exceeded.");
}
</pre>
<blockquote>
<p>Aside: This replaces the <code>executor_</code> with a <code>scheduler_</code> that implements cppcoro’s <a href="https://github.com/lewissbaker/cppcoro#delayedscheduler-concept">DelayedScheduler</a> concept.</p>
</blockquote>
<p>Let’s …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ericniebler.com/2020/11/08/structured-concurrency/">https://ericniebler.com/2020/11/08/structured-concurrency/</a></em></p>]]>
            </description>
            <link>https://ericniebler.com/2020/11/08/structured-concurrency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032133</guid>
            <pubDate>Mon, 09 Nov 2020 07:15:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Choose a Programming Language Guide 2021]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25032086">thread link</a>) | @kmhmubin
<br/>
November 8, 2020 | https://mubinsodyssey.com/how-to-choose-a-programming-language-guide-2021 | <a href="https://web.archive.org/web/*/https://mubinsodyssey.com/how-to-choose-a-programming-language-guide-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>With the blessing of the Internet, people can learn anything anytime, anywhere without any hassle. Programming Language is one of the examples. Nowadays, not only students but also general people learn programming language as hobbies or to make a career on it as programming could be fun and buy you a Lamborghini at the same time. No kidding, As of Nov 1, 2020, the average annual pay for a <a target="_blank" href="https://www.ziprecruiter.com/Salaries/Software-Developer-Salary">Software Developer in the United States is $86,523 a year</a>. Don’t worry, and you don’t need talent, just passion; you can earn too.</p>
<p>However, Choosing a programming language is challenging when you’re getting started. Whenever you search about it, they lead to new recommend blogs, articles, or youtube videos, which could be very confusing. It's not only you; almost everyone faces this common problem. Even I was confused when I started my computer engineering degree.</p>
<p><strong>Table of content</strong></p>
<ul>
<li><p><a href="#no-more-confusion">No More Confusion</a></p>
</li>
<li><p><a href="#choose-a-development-field">Choose A Development Field</a></p>
</li>
<li><p><a href="#choose-a-programming-language">Choose A Programming Language</a></p>
</li>
<li><p><a href="#work-on-projects">Work On Projects</a></p>
</li>
<li><p><a href="#what’s-next">What’s Next</a></p>
</li>
</ul>
<p>Don’t worry. This article will help you to pick the best language for what you want to learn and become. To learn without any stress, follow the steps below.</p>
<h2 id="no-more-confusion"><strong>No More Confusion</strong>😕</h2>
<p>Every time you search on google or watch videos, you would be like, WTF??!! So, in short, just to let you know,</p>
<p>Python is king!😎</p>
<p>Java is down!😪</p>
<p>C++ is hard!🤐</p>
<p>Javascript is boss!😎</p>
<p>PHP is no more! 😰</p>
<p><img src="https://media.giphy.com/media/5t9wJjyHAOxvnxcPNk/giphy.gif" alt="confused"></p>
<p>All these languages make you confused?!! Forget what you have read before about this and make your mind and head clear now.</p>

<h2 id="choose-a-development-field"><strong>Choose A Development Field</strong> ⛏️</h2>
<p>Make your mind about which field you want to work with to be less confused. There are many fields such as,</p>
<ul>
<li>Web Development</li>
<li>Mobile App Development</li>
<li>Desktop App Development</li>
<li>Machine Learning</li>
<li>Security (Software / Network)</li>
</ul>
<p>And many more. Just Pick one of them. Let me explain a little bit to understand those fields.</p>
<p>💠 <strong>Web Development</strong> </p>
<p>Web development is the building and maintenance of websites; it’s the work that happens behind the scenes to make a website look great, work fast, and perform well with a seamless user experience.</p>
<p>💠 <strong>Mobile App Development</strong></p>
<p>Mobile app development is creating software intended to run on mobile devices and optimized to take advantage of those products' unique features and hardware.</p>
<p>💠 <strong>Desktop App Development</strong></p>
<p>Desktop Applications are run stand alone on the user’s laptops and systems. The term used for these applications desktop differs from mobile applications, which are in the trend. The key features of desktop applications are the high efficiency of the application, and these are highly customized as per user requirements and flexibility.</p>
<p>💠 <strong>Machine Learning</strong></p>
<p>Machine learning is an application of artificial intelligence (AI) that provides systems the ability to learn and improve from experience without being explicitly programmed automatically. Machine learning focuses on developing computer programs that can access data and use them to learn for themselves.</p>
<p>💠 <strong> Software Security</strong></p>
<p>Software security is an idea implemented to protect software against malicious attacks and other hacker risks so that the software continues to function correctly under such potential risks. Security is necessary to provide integrity, authentication, and availability.</p>
<p>💠 <strong> Network Security</strong></p>
<p>Network security is a broad term that covers a multitude of technologies, devices, and processes. In its simplest term, it is a set of rules and configurations designed to protect the integrity, confidentiality, and accessibility of computer networks and data using both software and hardware technologies.</p>

<h2 id="choose-a-programming-language"><strong>Choose A Programming Language</strong>🛠️</h2>
<p>Choose a language based on the platform. Why, if you ask? It will help you to learn faster, and you can become more productive. Now the main problem, There’s a lot of programming languages. Wikipedia has a list of over <a target="_blank" href="https://en.wikipedia.org/wiki/List_of_programming_languages">700 programming languages</a>.</p>
<p><img src="https://media.giphy.com/media/3o6YglDndxKdCNw7q8/giphy.gif" alt="what"></p>
<p>Wait. WHAT!! 😲</p>
<p>Are you kidding me? How can I choose a programming language over 700 languages?</p>
<p>Hold your horse, man. Don’t worry.</p>
<p>Before that, Check out this gem.</p>
<p><img src="https://i.imgur.com/7iR9fH4.jpg" alt="programmic joke"></p>
<p>I will give you a better explanation. Don’t get confused after seeing the list. We don’t need to know about it anyway. I will provide a good summary of programming language that can use for personal work or company work.</p>
<p>🔷 <strong><a target="_blank" href="https://www.java.com/en/">Java</a></strong></p>
<p>Popularity: Very high</p>
<p>Ease of Learning: Moderate to Difficult</p>
<p>Use Cases: General Use and Specialty</p>
<ul>
<li>Web applications</li>
<li>Mobile</li>
<li>Embedded systems</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://www.cprogramming.com/">C</a></strong></p>
<p>Popularity: Medium</p>
<p>Ease of Learning: Moderate</p>
<p>Use Cases: General Use and Specialty</p>
<ul>
<li>Embedded systems</li>
<li>Hardware drivers</li>
<li>Local Applications</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://python.org/">Python</a></strong></p>
<p>Popularity: Very High</p>
<p>Ease of Learning: Easy to Moderate</p>
<p>Use Cases: General Use and Specialty</p>
<ul>
<li>Web Applications</li>
<li>Artificial Intelligence</li>
<li>Machine Learning</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://isocpp.org/">C++</a></strong></p>
<p>Popularity: High</p>
<p>Ease of Learning: Difficult</p>
<p>Use Cases: General Use, Specialty</p>
<ul>
<li>Local Applications</li>
<li>Web Services</li>
<li>Proprietary Services</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://docs.microsoft.com/en-us/dotnet/csharp/">C#(Sharp)</a></strong></p>
<p>Popularity: High</p>
<p>Ease of Learning: Moderate</p>
<p>Use Cases: General Use</p>
<ul>
<li>Web Applications</li>
<li>Local Applications</li>
<li>Services/Microservices</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://www.w3schools.com/">HTML</a></strong></p>
<p>Popularity: High</p>
<p>Ease of Learning: Easy</p>
<p>Use Cases: Web Sites and Application</p>
<ul>
<li>Web Development</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/JavaScript">Java Script</a></strong></p>
<p>Popularity: Very High</p>
<p>Ease of Learning: Moderate</p>
<p>Use Cases: General Use</p>
<ul>
<li>Local Applications</li>
<li>Web Applications</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://www.php.net/">PHP</a></strong></p>
<p>Popularity: High</p>
<p>Ease of Learning: Easy</p>
<p>Use Cases: General Use</p>
<ul>
<li>Web Applications</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://www.mysql.com/">SQL</a></strong></p>
<p>Popularity: Very High</p>
<p>Ease of Learning: Easy to Moderate</p>
<p>Use Cases: Specialty</p>
<ul>
<li>Database Queries</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/ProgrammingWithObjectiveC/Introduction/Introduction.html">Objective-C</a></strong></p>
<p>Popularity: High</p>
<p>Ease of Learning: Difficult</p>
<p>Use Cases: Mobile Applications</p>
<ul>
<li>Apple iOS devices: iPhone, iPad</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://www.ruby-lang.org/en/">Ruby</a></strong></p>
<p>Popularity: High</p>
<p>Ease of Learning: Easy to Moderate</p>
<p>Use Cases: General</p>
<ul>
<li>Web Applications</li>
<li>Scripting</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://developer.apple.com/swift/">Swift</a></strong></p>
<p>Popularity: Medium</p>
<p>Ease of Learning: Moderate to Difficult</p>
<p>Use Cases: Apple Mobile and Desktop applications</p>
<ul>
<li>MacBook</li>
<li>iPhone</li>
<li>iPad</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://golang.org/">GO</a></strong></p>
<p>Popularity: Low</p>
<p>Ease of Learning: Moderate</p>
<p>Use Cases: General</p>
<ul>
<li>Web Applications</li>
<li>Local Applications</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://www.perl.org/">Perl</a></strong></p>
<p>Popularity: High</p>
<p>Ease of Learning: Easy to Moderate</p>
<p>Use Cases: General</p>
<ul>
<li><p>Local Applications</p>
</li>
<li><p>Web Applications</p>
</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://dart.dev/">Dart</a></strong></p>
<p>Popularity: Niche</p>
<p>Ease of Learning: Moderate</p>
<p>Use Cases: General</p>
<ul>
<li>Web Applications</li>
<li>Mobile Applications</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://kotlinlang.org/">Kotlin</a></strong></p>
<p>Popularity: Medium</p>
<p>Ease of Learning: Moderate</p>
<p>Use Cases: Mobile Development</p>
<ul>
<li>Android Applications</li>
</ul>
<p>🔷 <strong><a target="_blank" href="https://visualstudio.microsoft.com/vs/features/net-development/">Visual Basic .NET</a></strong></p>
<p>Popularity: Low</p>
<p>Ease of Learning: Moderate</p>
<p>Use Cases: General Use</p>
<ul>
<li>Web Applications</li>
<li>Local Applications</li>
</ul>
<p><img src="http://carlcheo.com/wp-content/uploads/2014/12/which-programming-language-should-i-learn-first-infographic.png">
<em>Image Credit: <a href="http://carlcheo.com/" target="_blank">Carlcheo.com</a> </em></p>
<p>Choose only one. Start from the very basic and practice every day for at least 2 hours. And try to solve problems.</p>

<h2 id="work-on-projects">Work On Projects🗄️</h2>
<p>After choosing a project or where you want to work, choose a language. And after that, <strong>Start working on small projects</strong>. Like building a simple calculator. Little by little, go from small to big projects. Projects will help you to understand what is lacking. Challenge yourself to create new things.</p>
<p>Best things to do, Build 30 things in 30 days of the challenge.</p>
<p><strong>#build30thingschallenge #mubinsodyssey</strong> on Twitter with us.</p>
<p>Here some project Ideas, if you don’t have for yourself. I would say work on the common and small projects first, then go for your ones. It will be more productive and efficient for you.</p>
<ul>
<li>Guess The Number</li>
<li>Rock, Paper, Scissors Game</li>
<li>Password Generator</li>
<li>Dice Rolling Simulator</li>
<li>Hangman Game</li>
<li>Digital Cloak</li>
<li>Word Counter Tool</li>
<li>Percentage Calculator</li>
<li>Height &amp; Weight Converter Calculator</li>
<li>Temperature Conversion tool</li>
<li>Restaurant Bill Management System</li>
<li>ATM Management System</li>
<li>Movie Ticket Booking System</li>
<li>Attendance Management System</li>
<li>Tic Tac Toe Game</li>
<li>Banking System</li>
<li>Library Management System</li>
<li>Student Report Card Generator</li>
<li>Contact Management system</li>
<li>Pacman Game</li>
<li>Personal Diary management system</li>
<li>Quiz Game</li>
<li>Typing Tutor</li>
</ul>
<p>And many more. Just google small projects.</p>

<h2 id="whats-next">What’s Next ⏭</h2>
<p>After that, chose one of the below options that suit best for you.</p>
<ul>
<li>Apply for a job; which will help you to get real-world experiences in the programming world</li>
<li>Freelancing; which will introduce you to other programmers where you can enrich your programming knowledge</li>
<li>Startup; It will develop your own idea.</li>
</ul>
<p>Here some best websites you can search for your desired jobs.</p>
<ul>
<li><a target="_blank" href="https://jobs.github.com/positions?description=&amp;location=Remote">Github</a></li>
<li><a target="_blank" href="https://stackoverflow.com/jobs">Stack overflow</a></li>
<li><a target="_blank" href="https://jsremotely.com/">JSRemotely</a></li>
<li><a target="_blank" href="https://authenticjobs.com/">Authentic Jobs</a></li>
<li><a target="_blank" href="https://www.indeed.com/">Indeed</a></li>
<li><a target="_blank" href="https://jobbatical.com/explore">Jobbatical</a></li>
<li><a target="_blank" href="https://weworkremotely.com/">We work remotely</a></li>
<li><a target="_blank" href="https://bigcloud.io/">Bigcloud</a></li>
<li><a target="_blank" href="https://remoteok.io/">Remote Ok</a></li>
<li><a target="_blank" href="https://www.androidjobs.io/">AndroidJobs</a></li>
<li><a target="_blank" href="https://landing.jobs/">Landing Jobs</a></li>
<li><a target="_blank" href="https://ai-jobs.net/">Ai-jobs</a></li>
<li><a target="_blank" href="https://www.toptal.com/">Toptal</a></li>
<li><a target="_blank" href="https://www.upwork.com/">Upwork</a></li>
<li><a target="_blank" href="http://www.guru.com/">Guru</a></li>
<li><a target="_blank" href="https://www.freelancer.com/">Freelancer</a></li>
<li><a target="_blank" href="https://www.fiverr.com/">Fiverr</a></li>
</ul>

<hr>
<p>🚩👉 If it was useful to you, please Like/Share to reach others as well. Please hit the <strong><em>Subscribe</em></strong> button at the top of the page to get an email notification on my latest posts.</p>
<p>I talk about web development and UI design on <strong>Twitter</strong> <a target="_blank" href="https://twitter.com/kmhmubin">@kmhmubin</a>, come to talk with me there!</p>
<p>The cover image is an improvisation on top of the work from <a target="_blank" href="https://www.freepik.com/vectors/arrow">Freepik</a>.</p>
</div></div>]]>
            </description>
            <link>https://mubinsodyssey.com/how-to-choose-a-programming-language-guide-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25032086</guid>
            <pubDate>Mon, 09 Nov 2020 07:01:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I'm going to experiment by being Blind and Alone for 24 Hours]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25031774">thread link</a>) | @Osiris30
<br/>
November 8, 2020 | https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/ | <a href="https://web.archive.org/web/*/https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-896">

	
	<!-- .entry-header -->


			<div>

			
<figure><img data-attachment-id="901" data-permalink="https://dormin.org/bird-box/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg" data-orig-size="2000,1050" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="bird-box" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=300" data-large-file="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=760" src="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=1024" alt="" srcset="https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=1024 1024w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=150 150w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=300 300w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg?w=768 768w, https://dorminorg.files.wordpress.com/2020/11/bird-box.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>For 24 hours I will be blind and alone in my apartment. I eventually want to try being blind for a week, but I’ll need seven days with no other obligations, and I won’t have that for a while. For now, I’ll suffice with a smaller-scale experiments with a few extra provisions for added difficulty.</p>







<ol type="1"><li>I must leave my blindfold on for 24 hours.<ul><li>If I remove the blindfold, I have failed the experiment</li><li>If the blindfold falls off or I can get partial sight, I have failed the experiment.</li><li>I am only allowed to readjust my blindfold if I can see light.</li></ul></li><li>I must not be in contact with any other people for 24 hours.<ul><li>I cannot answer my phone or any other messaging system.</li><li>I cannot receive in-person visitors.</li><li>If someone knocks at the door, I cannot answer verbally or physically.</li></ul></li><li>I will set an alarm for 24 hours. I cannot set any other alarms or use any other means to ascertain the time.<ul><li>It is up to me to keep my phone charged so the alarm goes off.</li></ul></li><li>I cannot leave my apartment.</li></ol>











<p>I have no good reason. I just want to see if I am capable of doing it and what will happen. Some things I’m curious about:</p>



<ul><li>Do I have the willpower to get through the experiment?</li><li>Will I become disoriented from losing all sense of time?</li><li>Will I be able to stave off boredom with podcasts, audiobooks, and music on my phone?</li><li>Will I enter some sort of meditative state due to a lack of sensory input?</li><li><a href="https://www.discovermagazine.com/the-sciences/scientists-made-people-wear-blindfolds-for-4-days-the-resulting-hallucinations-were-incredible">Will I hallucinate</a>?</li><li>Will my non-sight senses heighten?</li><li>Will I hurt myself by falling or banging into something?</li><li>Will I sleep?</li><li>Will I eat? Is consuming caffeine a good idea (for entertainment) or a bad idea (energy with no direction)?</li><li>Will this experience make me more interested in being blind for a week? Or less?</li></ul>



<figure><img src="https://digitalimpact.io/wp-content/uploads/2014/08/Blind.png" alt="Modern CEOs Are Blindfolded - Digital Impact"></figure>







<p>Attempt One started at 10:30 AM and failed at 1:13 PM. I purposefully took off my blindfold because I was worried that my multiple failures to input my Iphone’s password had resulted in a permanent lock or data wipe. But the password screen was just locked for a minute and all was well.</p>



<p>Given that I failed in the early afternoon, I considered restarting the experiment on another day in the morning. But I had already carved out a 24 hour period when I wouldn’t do any work or be disturbed, and it might have been a week or two longer before I got that opportunity again.</p>



<p>So I checked my messages, briefly went on Reddit, and then restarted.</p>



<div><figure><img data-attachment-id="903" data-permalink="https://dormin.org/t86752/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg" data-orig-size="521,610" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;CSA Images \/ CSA Images&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Blindfolded Woman&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;\u00a9 CSA Images \/ CSA Images&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;T86752&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="T86752" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=256" data-large-file="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=521" src="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=521" alt="" srcset="https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg 521w, https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=128 128w, https://dorminorg.files.wordpress.com/2020/11/blindfold-2.jpg?w=256 256w" sizes="(max-width: 521px) 100vw, 521px"></figure></div>







<p>Attempt Two was successful. I put on my blindfold at 1:23 PM on Thursday, November 5, 2020. I removed it at 1:28 PM on Friday, November 6.</p>



<p>It was an… interesting experience. I don’t recommend it, but I’m glad I did it. I’m not sure where to begin in describing it, especially since I couldn’t take notes, and part of the challenge was being confused. But I’ll do my best to break down the experience.</p>



<div><figure><img src="https://cdn.shopify.com/s/files/1/0818/3417/products/Les_Sublimes_Cashmere_Scarf_Dark_Blue_packshot_2048x.jpg?v=1539973736" alt="Large Cashmere Scarf in Dark Blue | Les Sublimes" width="427" height="427"></figure></div>



<h2><strong><span>Blindfold</span></strong></h2>



<p>To simulate blindness, I used a dark blue scarf as a blindfold. One layer wasn’t quite dark enough, so I folded it in half for extra light defense.</p>



<p>With the blindfold securely on, my vision was the same whether my eyes were open or closed. I kept my eyes closed 99.9% of the time since it was usually more comfortable and helped limit light. I occasionally opened my eyes to check the brightness level and to… I guess you could call it <em>stretch my eyelids.</em> They don’t feel good if you leave them closed for too long.</p>



<p>I couldn’t get a perfect scarf seal around my eyes, so sometimes when I tilted my head back while sitting I noticed a little light come into the bottom of my vision. To limit this, I often pinched the scarf around my nose in that position. But many/most blind people can see some light anyway, so I don’t think this was a significant violation of the experiment.</p>



<p>My eyes got quite dry under the scarf, so I applied moisturizer to this lids and sockets four or five times. I wanted to use eyedrops too, but there was no way to do so without failing the experiment.</p>



<figure><img loading="lazy" data-attachment-id="906" data-permalink="https://dormin.org/image/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/image.jpeg" data-orig-size="225,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=225" data-large-file="https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=225" src="https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=225" alt="BLACK N BLACK - #blackouttuesday ✊🏻✊🏼✊🏽✊🏾✊🏿 | Facebook" width="786" height="786" srcset="https://dorminorg.files.wordpress.com/2020/11/image.jpeg 225w, https://dorminorg.files.wordpress.com/2020/11/image.jpeg?w=150 150w" sizes="(max-width: 786px) 100vw, 786px"></figure>



<h2><strong><span>Blindness</span></strong></h2>



<p>Initially, everything was black, but as the day went on and the sun went down, I could tell it was nighttime even through two layers of scarf and my eyelids. I’m not sure if I could tell because my eyes had adjusted to become extremely sensitive to light, or if there were other subtle signals (ie. noises, air temperature, circadian rhythms, etc.) which my body picked up on. As evidence of the latter, I could not see any difference between the tv being on or off, nor the refrigerator being opened or closed, even when I was sitting right in front of either.</p>



<p>What I saw depended on how I applied my focus. If I did focus on my vision, I’d see the typical blackness you get from closing your eyes, but it was never perfectly black nor uniform; there was always some odd movement and occasional coloring (whiteness, pale blue, or sometimes red). The most common distortions were a swirling or flowing whiteness, sort of like cream in coffee. I hoped that being blindfolded for so long would make the distortions more extreme, but for the most part it looked no different than what you’d see if you closed your eyes right now for ten minutes.</p>



<p>There was one exception. It must have been about 20+ hours into the experiment, and my eyes were itching, so I rubbed both of them at the same time over the scarf. If you rub your closed eyes and focus on your sight any time you can see some weird stuff, but this was far more extreme than usual. I remember my entire vision filling up with white bubbles which then broke and briefly returned to black. Then white lightning bolt shapes stretched across my sight, expanded to make my vision purely white, and then slowly faded back to black. The strangest thing about it was the <em>brightness</em>. I literally felt like I was staring into lights despite being blindfolded in a dark room. Unfortunately, it only lasted about 30 seconds, but my heart was racing.</p>



<p>More notable than what I saw was what I didn’t see. By default, I was lost in thought and I focused on nothing. In such a state, I didn’t even register my vision or notice the darkness. I <em>think</em> this made my imagination and mental visualization more acute. On occasion, I’d be deep in thought and I’d get the <em>brightness</em> sensation again because I’d be mentally picturing something so vividly that the inevitable return to darkness felt like shutting off the lights in my brain. I’ll explain more about this in the <strong>Three Phases</strong> section.</p>



<p>Sadly, I did not hallucinate, or at least not as far as I could tell.</p>



<figure><img src="https://i1.wp.com/www.intelligentliving.co/wp-content/uploads/2014/07/sloth-sleeping.jpg?fit=1024%2C698&amp;ssl=1" alt="Fighting Bacteria With Sloth Fur"></figure>



<h2><strong><span>Energy</span></strong></h2>



<p>This was the most surprising aspect of the experiment.</p>



<p>I read that <a href="https://abcnews.go.com/Health/story?id=117902&amp;page=1#:~:text=Without%20light%20cues%20that%20the,as%20a%20result%2C%20researchers%20say.">blind people have trouble getting to sleep</a> because they don’t access any/enough light for their circadian rhythms. I seem to have the exact opposite problem. Without light, my body always thinks it’s time to sleep and has trouble doing anything else. Throughout most of the experiment, I felt extremely lethargic, lazy, and had to fight to stay awake.</p>



<p>I started my first failed experiment attempt at 10:30 AM. I had gotten 7.5 solid hours of sleep, I hadn’t done anything tiring the previous day, and I generally felt fine. Then I put on my blindfold, and within thirty minutes I was nodding off. I semi-slept for two hours before deciding to get an energy drink to get myself out of the funk. That worked, but as soon as it wore off, I was back in semi-sleep mode.</p>



<p>Even when I was firmly awake, I generally felt weak and lethargic. Movement around the apartment was annoying of course, but made so much more difficult by my energy levels. I ended up lying perfectly still in my comfy computer chair with my feet on a table 95% of the time. That is, when I wasn’t lying in bed.</p>



<p>On the other hand, when I removed my blindfold after 24 hours, I experienced a <em>burst</em> of energy. Seriously, it was like I had downed a double shot of espresso. It was like a switch had been flicked. The haziness and cobwebs were gone in an instant, and I felt the energy coursing through my body. I guess light has a big impact on me.</p>



<div><figure><img data-attachment-id="908" data-permalink="https://dormin.org/blind-man-2/" data-orig-file="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg" data-orig-size="615,479" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1604789422&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="blind-man-2" data-image-description="" data-medium-file="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=300" data-large-file="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=615" src="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=615" alt="" srcset="https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg 615w, https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=150 150w, https://dorminorg.files.wordpress.com/2020/11/blind-man-2.jpg?w=300 300w" sizes="(max-width: 615px) 100vw, 615px"></figure></div>



<h2><strong><span>Movement</span></strong></h2>



<p>I moved exactly how you’d expect… clumsily.</p>



<p>For the most part, I slowly walked around my apartment with a hand out to feel for walls and edges. Sometimes I’d get lazy and crawl just so it was easier. I know my apartment well enough that it wasn’t hard to get around, but every once in awhile I’d lose track of where I was and would be left slowly swinging my arm around searching for anything. It’s not a pleasant sensation.</p>



<p>Before the experiment, I had planned to pace around for fun, or maybe even do some exercise with the free time. But the confusion and especially the lethargy stopped all that. I just sat in my chair and didn’t move unless I needed to get a drink, go to the bathroom, or sleep.</p>



<p>I kind of wish I had done the experiment in an unfamiliar environment to add to the movement challenge, but oh well.</p>



<div><figure><img src="https://secure.img1-fg.wfcdn.com/im/99629273/compr-r85/1167/116715839/dual-flush-elongated-one-piece-toilet-seat-included.jpg" alt="DeerValley Dual-Flush Elongated One-Piece Toilet (Seat Included) &amp; Reviews  | Wayfair" width="729" height="729"></figure></div>



<h2><strong><span>Necessities</span></strong></h2>



<p>For food, I ate a big lunch at 10 AM before the experiment and then munched on dark chocolate throughout the night. I felt the heavy lethargy well before the lack of calories was an issue. I probably should have put some prepackaged meals in my fridge to eat, but I was worried about making a mess and not being able to clean up. Do I want ants? Because that’s how I get ants.</p>



<p>For drinks, I could manage to get to the kitchen and fill a cup with water when I needed to. I never took a full cup back to my chair just in case I knocked it over (clean up would be a nightmare). I also had some diet coke to serve as entertainment and put a little caffeine in me.</p>



<p>For the bathroom, I (a man) peed sitting down. I’m not ashamed to admit it.</p>



<div><figure><img src="https://imgaz2.staticbg.com/thumb/large/oaupload/banggood/images/F2/09/b934b522-e3e3-491d-b758-d0b92c259f0c.jpg" alt="Novel surreal melting distorted wall clock surrealist salvador dali style  wall clock amazing home decoration gift Sale - Banggood.com" width="802" height="801"></figure></div>



<h2><strong><span>Time</span></strong></h2>



<p>As part of the experiment, I never knew what time it was. This was intended to confuse me throughout the 24 hours, and it did, but it may have helped too. With no sense of time, it was easy to sit back and not think about it. Time drifted by and I existed. That was that.</p>



<p>I actually did ask Siri for the time once… it was late in the experiment, and it felt like I had put on the blindfold forever ago. As you’d expect, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/">https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/</a></em></p>]]>
            </description>
            <link>https://dormin.org/2020/11/08/the-blind-alone-and-confused-for-24-hours-challenge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031774</guid>
            <pubDate>Mon, 09 Nov 2020 05:39:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Postgres Constraints]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25031762">thread link</a>) | @mkfeuhrer
<br/>
November 8, 2020 | https://www.mohitkhare.com/blog/postgres-constraints | <a href="https://web.archive.org/web/*/https://www.mohitkhare.com/blog/postgres-constraints">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-70187a8e=""><div data-v-70187a8e=""><div data-v-70187a8e=""><div data-v-70187a8e=""><div data-v-70187a8e=""><p data-v-70187a8e="">Postgres Constraints</p> <div data-v-70187a8e=""><div data-v-70187a8e=""><div data-v-70187a8e=""><div data-v-70187a8e=""><a href="https://www.mohitkhare.com/categories/postgres" data-v-70187a8e=""><p>Postgres</p></a></div><div data-v-70187a8e=""><a href="https://www.mohitkhare.com/categories/programming" data-v-70187a8e=""><p>Programming</p></a></div></div> <p><span data-v-70187a8e="">7 Nov 2020</span></p></div></div></div> <div data-v-70187a8e=""><p><img data-src="/_nuxt/63ad73275483584243aebc1fd69ef658-784.webp" data-loading="data:image/webp;base64,UklGRgoBAABXRUJQVlA4IP4AAAAwBgCdASooABQAPrVUpE2nJKOiJWmY4BaJYwDJYQAKoFAB7kBcIIWHmJt9ZaBV40LzWjUry2QaaEQAAP74lTicra5rKSznYhK/eFaS4dVB+7QvzV2yPYbWUlxMrpz05N73X3b6B6rHrST5Ka3bHoSksnKFvvArong89ZLtdBEtzVjIcV2PqpFTYYGj9zusV8MytzLt/d9q7IjLLhrcMbost2qo1PBIeZoDGl3dsVjSoUlQSgG9dwBUUWxA0LtwTDYea8YtLezljE0O4N5NIQNKZ0fYH9TLqtNX6K92xjciU4hWo570XkAqdyf7mR+6BTuqoojNjOCbhcwgIuAAAA==" alt="Postgres Constraints" data-v-f2b60aba="" src="https://www.mohitkhare.com/_nuxt/63ad73275483584243aebc1fd69ef658-784.webp"></p></div></div></div> <div data-v-1bfa12aa="" data-v-70187a8e=""><p data-v-1bfa12aa="">Get latest articles directly in your inbox</p> <div data-v-1bfa12aa=""><form action="https://usetaski.us18.list-manage.com/subscribe/post?u=2974614c11e6abca644007be7&amp;id=3b5ecce493" method="post" name="mc-embedded-subscribe-form" target="_blank" novalidate="" data-v-1bfa12aa=""><div data-v-1bfa12aa=""> </div></form></div></div>  <div data-v-5c76b055="" data-v-70187a8e=""><p data-v-5c76b055="">Liked the content? Do support :)</p> <div data-v-5c76b055=""><p><a href="https://www.paypal.me/mkfeuhrer" aria-label="Paypal - Mohit Khare" data-v-5c76b055=""><img src="https://www.mohitkhare.com/_nuxt/5021b7226315080e2ba0e37576a90ee6-320.png" alt="Paypal - Mohit Khare" width="125px" data-v-5c76b055=""></a></p> <p><a target="_blank" href="https://www.buymeacoffee.com/chHAzigTb" aria-label="Buy me a coffee - Mohit Khare" data-v-5c76b055=""><img src="https://www.mohitkhare.com/_nuxt/img/7c718ef.svg" width="175px" alt="Buy me a coffee" data-v-5c76b055=""></a></p></div></div>  <div data-v-70187a8e=""></div></div> <div data-v-70187a8e=""><div data-v-3d6db495="" data-v-70187a8e=""><p data-v-3d6db495="">Explore more</p> <div data-v-3d6db495=""><div data-v-3d6db495=""><div data-v-423c8b1c="" data-v-3d6db495=""><div data-v-423c8b1c=""><div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/personal-okrs" data-v-423c8b1c=""><p><img data-src="/_nuxt/58c006b0de508ad0918f13aae4a9fd4d-613.png" data-loading="data:image/png;base64,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" alt="Personal OKRs for Success" data-v-f2b60aba="" src="https://www.mohitkhare.com/_nuxt/58c006b0de508ad0918f13aae4a9fd4d-613.png"></p></a></div> <div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/personal-okrs" data-v-423c8b1c=""><p data-v-423c8b1c="">Personal OKRs for Success</p></a></div></div></div><div data-v-423c8b1c="" data-v-3d6db495=""><div data-v-423c8b1c=""><div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/making-decisions-the-right-way" data-v-423c8b1c=""><p><img data-src="/_nuxt/e988377883f08d1ca218d809e931f11e-1000.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAAACXBIWXMAAAsTAAALEwEAmpwYAAAFEElEQVRYw+2W+1NUZRjH959ouLUTlwCBENIihL1x2cvZPec9e/bsBSIGAUVNblNc1AVxOexZlkYmIsxLTeOAEBREXJRRB9AxDaSZRCWgZtRJCsvCJiYVdpees8usdGfj0i+888yZ95x93/fzPN/3eZ93eTqi6n8x3gZ4A7wB3gCvO5jRIVZHmLnOeoK1yKJVGHW4SUda/hvbY7CeYGiCTVHty39BnBYcS6sqnKEzaw3mFKYx40mBcjBc1suPN0bgatKsX+uIDQRDEFZWmnZHhI8FookQ6pyfcHt8Dq2u0ePMmoANhNmAM1rSqkvM78fwiS2oJ0zZH6Ya4UvZEAVOMCkwgGD0y0635YERS8lKEVGVLd5bFyYYV+DnY6iBazc/Otl21lvU4htXEoVrcZNaeUiDHVjmli8DjMx6Zblpk6RsC94XhrWGCr9SUQPRRHfPuUbrkfPe4hY/UTdfdCJGW/K8av9zGIVY/cojhhxWk9bcpN1fhErb+cJBb6I5RDRBUNdDibN+4kF+wueBqia/uI+9pAP+WH9kQl+AlE4uWs4Z+3cwSVpLknbc3IQ1+gran5I0BsWPEdS1CDQaQo5uQkOBykafbS1eog4f8UCUbMBfbkjI05LVOnzFYA2qzpQWDDwrqAhVpCYV74nRjsgVY1HUUJBqJBQf8lfU8wWp4r1Zgl2NkUnN/mIKCgu3zauRXFq8Mjs2XS/bryer6sOlg2Lp5It0c7DwTHDyxWfkx7235r2UQdC16Qm5GfE7aGRZzeME6mmQNUtR+GmEtH2zZFyoaQoTtgdIOvkJnb7basMRCfJAHQWRV/M4waJ4JVTKdKzocrSy118yHCf/IEzc8rSgxSfusn8SG0kjkoWDvvwywvOkRFvSsJLhaKw7QFa/FWsLjT/qFVMblHgjQMps1iLS4lHx8gCsQZYMZWlnhHCnMM+AFxfFi7JiZaRiX0M4zobjiLKuCdh5FbIvY2WZ4hwS1aThr2WpaU2ymrudFMZMYY7Ww/vRs0tCS1TRpMVAmvGk8uajXeUF7xDSg3rSQpOWdfgjwBhIViExDn022fBmtzKhDPxYh/t40Wgl8+3Uj6e7hjGJ0aBeLBcpatZlTlc8AUMoME2PzK75i2mFzK6n62MqxZKyiuKCEwsLC3du3QMGWIraAgOQtAKUx5PLKcz0z2w9WgKGoWrFIZhJqyqRrALMuSILVRcWpVUM/ASmUZpgg/t6RxacrbqyNVlQCq7AgLrDnRf7R7s6ruTufJtSmNyuL0XowRBnPHdY4O+BovcvXbgxOX53ZGiixvyh0/2DGYY3tDiT/Upt66kLfT1XSwrfLc4/Mfd43gW+fWv6k44rR+q6e7uG4dVut8Nz5qdf8nIalInlIKEbCXlAyitI+SEw8JIHUcNXYNRWt9tt3DSHw7Hg4BbtaLsE7sMqX09OTX834yLNzj68/8PPi8N+34Bqs9nn5mzQvz56e9f2OlpZmUpxpwD0A3zhnqOv5x7bnfnW8JUJHqQG8DNTD39/7wFMmJ+3AR7mu3x3N6DYnN9dPDcVOrbF8U/8cAVwb3omXWeVifbD1jBlp0DIh78+evTw8YOZWZjFSS0XHTAZG50uO5aSOLhzRY5nf0Jy2P8Y65+bzck+03PVZGw63nDatbJbI3jlQV68ml0/8eXdv1RvJc3OqeNw++FSi3Pb6QTvvWN9U9/cX3Wqm23/G3l4kDtuZdaz8WzztqXqr1v7DeOTH/N/KPjZAAAAAElFTkSuQmCC" alt="Making Decisions: The right way" data-v-f2b60aba="" src="https://www.mohitkhare.com/_nuxt/e988377883f08d1ca218d809e931f11e-1000.png"></p></a></div> <div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/making-decisions-the-right-way" data-v-423c8b1c=""><p data-v-423c8b1c="">Making Decisions: The right way</p></a></div></div></div><div data-v-423c8b1c="" data-v-3d6db495=""><div data-v-423c8b1c=""><div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/productivity-chrome-extensions" data-v-423c8b1c=""><p><img data-src="/_nuxt/755f7f3a578954e44f3b07ab0c6debea-800.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEEUlEQVRYw+1WW0hbSRgOFNanug+CVXxYlWi9BrO1+BBpC6XQy1OfFJaCpcIKuwuLUGhrK4oYtcULWu9RXBcvVbNGI6s16x2lrZfE1tbGKxVtjTG9JEZNTs45/TzT1ZgYm9K+FM73MJlz8s985/vnn29GcNwNhISECIXCqKiotbU1lmUZhmG/GgKemCfmiXni7484ODhY+DkEBQUFBASIRKJvSRwZGRkdHX3iUCBALBbHxMTodLpdYpPJ9MFtINiRWCqV0jSt1+vfugb+tVqtNTU18/PzZNjW1lZERISHh4enp+fRQ4EAhIWHh2OIfbYEBQUF+KEo6pC02Gw2tE1NTXNzc+TN9va2RCLx9fX19/f/yQ4BTggMDPTz84uNjcWQfcT5+fl7xNxbBhnY2qStFub/Nw7EZDBaBDIcyCMAWZsHgcjdl+o9Ym78pnr0nfT2+h8Jhuu/GR/8bds0H6gYme/q6hoZGRkeHh4cHBwYGOjv7+/u7iaRbhXXJ2KLBa3h0cDrsxKdRPz+4inDhZMrkgh9+i2aYWknYijIyMiQyWS1tbXV1dUlJSWFhYV9fX1fUNWEmKZs26ztZtu18Wjh/K+/P6jvHZHnmTv8TP/8QOnbaS7UQXFbm0Iul3d2dv7LAepHR0ehG/QKhWJ8fBz9hxw0Go1LYpZhV94vn+68eC/tTHFl3+n7T+IrplZexLHPBdSbVJsTMbZHXV1dRUVFcXFxeXl5aWkpOtDd0NCA5OODWltb6+vrlUrl1NQUvmBHG00fTKwzrZ2rvXBZcelGsyLqT+WlrIf6Z+dZjYB6LXUmRqqxtCqVCuLa29uheGlpqbe3t6enp6OjA4uNztDQEOSiFBYWFpxtZ19VX1feEBWJr7Yl/FKXK1MlsE+PmB8fpTbUNONIjPiioqL09HTCmpmZqdVqoRJpSE1NzcvLq6qqyuWQmJiIT3Sp2EpZ0b4yLMX/dSUs9+czMtFzlYfpvx+NCyVcVVPOxJhOrVajhT5S2KQzMTEBrRCKxZ6ennZlEnuKGXZH1zuzQfa4UT50x/Iixax/xMUwztsJa5yTk1NWVoaXEJeVlZWcnIw6T0tLq6ysRIXjMSUlpaWlZXc3OhIjG8SJ8PcOPXEDZIYzDxsHC7fZGhsb7Q0EqaM47DoJwlDtmIrYhZWDy+2EpXLTMpubm4lXE5MyGAxw/42NDXTW19ctHEBpNBqJ+ZOzYYUDzMuROC4uDpnJzs6+6xrIKlYkKSlpeXl51yw1avXY2NhLrXZ2dha7FuuNzurqKjb04uIi+jMzM4ifnJzEquOkcShsAZzd29v72KHw8fHx8vLCjQA69o23m8jZwO1t/IBUh4aGhn0OONRwCcGRbH8eO0z6pbcD/rLHE/PEPDFP7DY+Aj8diF6OEZ/ZAAAAAElFTkSuQmCC" alt="Boost Productivity with Chrome Extensions" data-v-f2b60aba="" src="https://www.mohitkhare.com/_nuxt/755f7f3a578954e44f3b07ab0c6debea-800.png"></p></a></div> <div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/productivity-chrome-extensions" data-v-423c8b1c=""><p data-v-423c8b1c="">Boost Productivity with Chrome Extensions</p></a></div></div></div><div data-v-423c8b1c="" data-v-3d6db495=""><div data-v-423c8b1c=""><div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/reading-101" data-v-423c8b1c=""><p><img data-src="/_nuxt/8aca56b2b6f66cbaa13ebd461ec75744-800.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEnklEQVRYw2NQJwJoaGioqKgYGBi8evXq//////79+08xYBi1eNTiUYtHLR61mBSL1UBAHYRgNqmpo7BpYrGGhromEGioa6iraaipaoDt0gSywfaBgDpISklJSU9Pn5oW5yaFH10z+ci62Tsa3TdPzlnVm7mmLuT0jOqTS8tWNiXNyLE4syh/SYH1smKLgiC9h0+pZ3FHXfH36zt/Pjz9ZGHYw93997Z1PVxT9v/m7v+3Z96dl763wfz/pe6bU4KfLwmfnmN15+ELuMVfv379TDT4+uXLf1TnMtTlxz/cPuH5rik3eiwvrap5cmz13b1z359Z/f9s591pQQfr9b9syzzUYLO/xaY1wfD+45cQbT9+/DA0NOTl5RURERHGC4AKgMqA6eP79+/IocXgZSydZ8na4CV6fGLUoaU9hxe2XVjZfmp+2erm6EBdbk9NzjAj3iwrjjADTjdj+Wcv38AtNjMzAxoqIyMjJSUlKSkJJyEAwpaWlgYqEBUVNTc3R7c4z9/4Up/nwQUNq2f2zmvK3D2t6OzcnFkFbuUR1jEu+iFutllh7ulWvBuq7Upjne4/fo6s+e/fv7/B4C8YAMUhIj9//vwHBt++ffsKBkAGehz3tDf8un902YS60sTA1qzA3oKgzmyfJQ2xVzb171vY3lWWOrkutzlQ/vai2O6CgLsPnkK0/fr1a+eOnQcPHLh06dKVK1d27dp16tSpLVu2nDhx4vLly3fv3j1y+PDBgweAAYMzcXXWFtzfPWtpX8W66U3HVk04smrSrgWdG6ZUnlw77eGFo6e3LS2NdKryEDnW6dSc5nrv0TOINqAPaqpr2traent7p06dWlVVNW/evKysrEkTJ65bt+7AgQP9/f09PT1fgGkKRy5gKMlOfHz99I1jW/ZtWLRgWs/8KV2bl82+fHjzrWMbH53c8P/9vYV1sdE6DO7qnHYGSi9evUYLaiD48+cPMHgh4j9//QJygWxgaEMYOH3s7Wyxc/PKFZv3lNS0FFXUFpZVlpZXNtTXzZkxae+m5TfP7r+yoX+SN2uoIY+dvhrcYiB48+bNx48fgX56BwZAm4ABC0xBnz59ArJfv34NjFqg+LOnT58/f44Z5gwtFbmfr2y7c/Xc60e3vz+5+uPp1Z9Pr/x8cvHr/TNf7526tGf5zAj1+V4Msea8trqqL2EWAz164fz5M6dP37xx4/atW+fOnj1//vzt27dfvHhx/Pjx+/fvQ2IayLhw4QKQDXQiWpgzNNeU/X937+nlI/du3Xj/8NLHm4ffXj/66vbxN7f2v7+99+r2abOi1FttGNItWd2NlJ6/fI2qH2EQRBDkpj9/IGxIOscZ1K21pf/f3vl45/SHO2dfXT/x+e6pz/fOfLp3+uv9ky+v7F/Snr26yrPJnfdsiUF5tOWDJy+Q7UB2BKnlKIOPp1tNaX5pflZZfmZxTjqIUQBiA1FJboa3o5Wvg0mkg0ahn5m3k+mz5y+pVlYrKipJSklLScsAkbSMLIQB48ooKqsoKqsqqGhIyClp6+hTt1rU0MQNINUikFJXUwWWty9fjjZ9Ri0etXjU4lGL6W8xAIU/JG106R/JAAAAAElFTkSuQmCC" alt="Improving Reading 101" data-v-f2b60aba="" src="https://www.mohitkhare.com/_nuxt/8aca56b2b6f66cbaa13ebd461ec75744-800.png"></p></a></div> <div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/reading-101" data-v-423c8b1c=""><p data-v-423c8b1c="">Improving Reading 101</p></a></div></div></div><div data-v-423c8b1c="" data-v-3d6db495=""><div data-v-423c8b1c=""><div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/transactions-postgres-golang" data-v-423c8b1c=""><p><img data-src="/_nuxt/7d79089f0176c12135db8901018a0f3b-800.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAAACXBIWXMAAAsTAAALEwEAmpwYAAAE8klEQVRYw+1W6U/bZRxv4F8giEAMJBhgkAnJwjLfmMzEbS9MFuWFJm4sgEOQTWRcy4CBAoVSekEvrq4ctqWFFhgttJylXHITbgQ55CwDFghYQPBDf66rBZnHErOknzTf3/P7Pk/7+d5PSe5/Ax4eHm5ubj4+Pmtra8fHx0dHR8f/GSQrsZXYSmwlfvOI8aMXXgUvLy8c8/X1XV1dfW3Erq6ubxvh4OAA+ZYRhMbJycnZ2RkLR0dHKD09PfV6vYkY8rd/AkvigIAAkUgkFBaJxeLS0pIyiUQslpQUF+PD5/F5XE5p6Q/FJSeIiIiYm5t7bR6zWCw8nunXdLrWZm1rW1t7b3dXQ1OzVqttam4pq1Q2NzWu609SW1xcPDk5icXh4SFkZ2dnUFBQWFhY6LnAgeDg4JSUFAunSTQafd+wl5RO/ySOc/lLSjRTnMCWXAmh3ojMThaobqWWXotgJaRlra2uiMTiiYkJfGd/fx8yPz+fRCLZ2tqSzoWNjQ0kSsRgMJhHi8ThcAd6u28/5nsGsfxCc77hPPUOZngH0n3uMr0DaZHsqg8eFNyMYTc2aBQKxdjYGL5D2L6+vt5pRFtbW0dHBxaQWLe3t2PR1dVlUgKDg4OWHnO5XJ1O5/+Q6x3E+Cg6L0feFpervBFbcDGYdjWSz6rQRfGVHz9g6bTNcrncnHhjY2NkZGRpaWlvb29lZWVxcRHNtru7iwKEcnx8HK9Qwj5UhnlV/kHM5nCG+nsDk/Pc79Cux+QnPVFHcqsfFdS+81laNO9pSpHmHrvmi1jq0vxMmVRGhNrkcXZ2NplMzsjISE1NjYuLY7PZFAoFKZAZwePxaDRaenp6+L1woVBoScxksXaeb4Qm0i/ezb4WnfcVvdwnmB7Dr3n3FuXz70vDmfKo3NqEdDqOikRiorgI4s3NzYaGBrVa3d3drao9QX19vVKlQkbqNRqEuq6urrKqSqNWz8zMIDyWVc1gMPDIYPKu3Od9GMn7lltzPU4A+gt3qJdCmJSy1gKZUiB4gjNFRUXmVY2wM5lMKpUqlUorKysLCwtz+XxoYA3W+Nn4+HiqEfPzC6ebkEShZOJRIZN++pDnG8ZP5pVJlC0hDMV7QTT32xkx+Wp5jYZKow8MDJSXlyNzJo9nZ2fhYktLi0qlgtPT09OQRHFNTU3By76+PlRPY2Mjts4gzsw8If555qfYFFoYWUDOzMrIkzBlWr9QllcgLYGvSM0RJqZSJicnkDaCmPAYNFFRUfAMsUWaq6urcQBTAU6j45FppP9xUhIkjDOZ+5IYoSDMGRwckMukFYpKgbDoUSb/cjjX72tOxHeM4f4f9cYBguFFhNpkOywgxiGhMbzAnhEHBwfYwuvpefmSGIdMqt3t52RuyaUwzvsReYmZ7M1nekJvQbyzs4PC3tra2t7eXl5exit6CTToHEhUE7Yg0VpotjNmNRFqHAU3JJzYN/wqFEmv3mfejGaVycoPjXqiuJA883bq6ekZGhpCmw4PD2OBKQFlf3//6OgocozUQkKPVyI7Z8xqk8eEN78szNeqNRg78OMkpMbd06E+H0dG/OUl4e/vjzbHBCC/QFpaWlZWFlJAp9MxENKMwCuuhIWFBfNr0QLmpr/SOJKLiwvuWoc/g7iV7e3tiS1cyXZ2dhj0pyffv78Wcb3/P/9ArP8yrcRWYivxG0f8O49FUp+RTJP8AAAAAElFTkSuQmCC" alt="Transactions on Postgres with Golang" data-v-f2b60aba="" src="https://www.mohitkhare.com/_nuxt/7d79089f0176c12135db8901018a0f3b-800.png"></p></a></div> <div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/transactions-postgres-golang" data-v-423c8b1c=""><p data-v-423c8b1c="">Transactions on Postgres with Golang</p></a></div></div></div><div data-v-423c8b1c="" data-v-3d6db495=""><div data-v-423c8b1c=""><div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/productivity-in-vscode" data-v-423c8b1c=""><p><img data-src="/_nuxt/f2694ea112a372daa3fcf90c076889fc-800.png" data-loading="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAoCAIAAAADnC86AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEiUlEQVRYw+1WSUwbZxSeQntp1KoHxBJUBCpKIeQAUqscorRVlaKqt1YcKvWAWhSpBzZFIKoACkLBZjNpIRKrTezYgCEoFAqBIlybTQaMHfadmMVgA8YYXC94mX7MUMcMiNI2l6r+NHrzzz8z//e+997/Zoj3L4CIiIjw8PDo6OitrS2SJF0uF/mvQXiJvcReYi/xf48Yi179K0RFReGxmJgYnU7nJoZ1XBhOp5NJHBYWFhQUdPksYD6QuhUcHOzv7x8ZGbm9vf3KFMfHxzc0NHC53NqT4PJ4IgFfLOQ/qq2t4fJEdXWpqakrKyt4BwpgFQpFcnJyenp62rnAAykpKRwOhyGaKCsrw8lut3vO0orW9x1jBqebSSgUzs/PY3B4eAhbXV1NEISvry9xLnx8fGBRKDabzTNaRFFREU5Wq81uP87HIeWEQr17q/DXm5UzqTJL56IJMwKBYH5hAQPad61W29PTI5VKe3t7ZTKZlIJEIsEYFuPfKEgoDA0NMRUXFxe7FcMbh/PII+nc1o0CybXsXz7lzsX+bIltMhhIUlwnnKMU015bLJbNzU3U+eLiIlKgo2A0GtVqNSzmURCwGK+uruJhZo5p4nK5tmJ420Gt2PJcE53b9V5mxwe5HXHi1din5s+fGHROsrH+mJiO/OjoaE5OTmJiIlYoLCxksVjl5eWIP9I5Ozvb2dnJ4/GQR8xnZGSoVCp3qI6JSzgcnD6qnL50T5n2TFMhWwy/2xqY3nqzSDLyYueB0vah0Hir8QQx/f7S0lJbW1tXV9fIyEh/f39fX9/k5CQI6GjPzMzAs46OjpaWFqVSabVamYqLKMUv9OYvRcv+7IkQliLkh/bvBUOavaPgsIYtMULjJ2KD1kk2nVQMPkgsKCioqqrKy8srLS1FuUDlwMCAWCyuqakRiUTNzc1yuRx+MOS+DDXpdNxpVL2T2ReYP3mZ/fzhoI6+nSu3XBMYb9QbNj2I6SWQS0hB+bS3t8NOTEwgwt3d3dC9vLyMW1AMJ2DHxsZO736CQ4X6m+pB4rv66/c7vxIuvJmjejtX9W2z2mp35its4bXG6yLDhoOpeHh4OCkpqaSkBMGEbiQV9Gw2u6mpCdXO5/MrKipQBFlZWRifoZjO8Rc/ST97IFvV/+5wkbefqt/IHvXNVn5cOf11q/7Ko/2Yx7uexO6WaTab7X8C61ooWCkcHByYTCYzBUaTOBHqA7PNbHPQOwpH2rP11zKVr9+Vv/vj0tXHppBK/doh+eQk8Wn8rVb6ch+7aCAm1Ov3pVoiffCt/IUrfFNyzz5m6kTHnevV9Gq6c6Gfub8k9qPjKB8PBzS32zZUW7i20Z1rwaNzoTOggej1+r29vbW1tX0KCOz6+jqCvLOzo6egpnDGdsI2ON2rGWD0app4d3cXpYtiRmOanp4eHx9H9YIJg6mpKY1Gg3a2sbGBMeocDjGJ4+LiUJnYiOxTYLHcBwsZSUhIgLKLh/r8x4jQ0NCAgIDAc4EPs5+fH/4FGN9j1ym4Jz3pz/SAwOf9n/2BeH/2vMReYi/x/474D5XblxQw5EkNAAAAAElFTkSuQmCC" alt="Improve your productivity with VS Code" data-v-f2b60aba="" src="https://www.mohitkhare.com/_nuxt/f2694ea112a372daa3fcf90c076889fc-800.png"></p></a></div> <div data-v-423c8b1c=""><a href="https://www.mohitkhare.com/blog/productivity-in-vscode" data-v-423c8b1c=""><p data-v-423c8b1c="">Improve your productivity with VS Code</p></a></div></div></div></div></div></div> <div data-v-70187a8e=""><div data-v-39a855d9="" data-v-70187a8e=""><p data-v-39a855d9="">
    Liked the content? <br data-v-39a855d9="">
    Support me
  </p> <div data-v-39a855d9=""><p><a href="https://www.paypal.me/mkfeuhrer" aria-label="Paypal - Mohit Khare" data-v-39a855d9=""><img src="https://www.mohitkhare.com/_nuxt/5021b7226315080e2ba0e37576a90ee6-320.png" alt="Paypal - Mohit Khare" width="100px" data-v-39a855d9=""></a></p> <p><a target="_blank" href="https://www.buymeacoffee.com/chHAzigTb" aria-label="Buy me a coffee - Mohit Khare" data-v-39a855d9=""><img src="https://www.mohitkhare.com/_nuxt/img/7c718ef.svg" width="150px" alt="Buy me a coffee" data-v-39a855d9=""></a></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.mohitkhare.com/blog/postgres-constraints</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031762</guid>
            <pubDate>Mon, 09 Nov 2020 05:35:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nix(OS) Thoughts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25031754">thread link</a>) | @one-punch
<br/>
November 8, 2020 | https://blog.knightsofthelambdacalcul.us/posts/2020-06-20-nix-nixos-thoughts/ | <a href="https://web.archive.org/web/*/https://blog.knightsofthelambdacalcul.us/posts/2020-06-20-nix-nixos-thoughts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>This post is relatively scatterbrained, and if you’re familiar with Nix, there’s
not any explicitly new ground to tread here. However, I have enjoyed my
experience with NixOS so much that I felt compelled to write this post, although
there’s already a plethora of posts drilling the same points.</p>
<p>From time to time, I find software that immediately seems to <strong>click</strong> with me,
and I start integrating it almost irreversibly into my workflow, to the point
where it’s difficult to think outside of its scope. Emacs is one of these: when
I began using it, I started integrating most of my software into Emacs, be it
IRC or RSS.</p>
<p>My recent experience with NixOS, though not my first (more on that later), was
like this. As of today, my two laptops and my server all run NixOS, and they all
use the same configuration – just with different things enabled/disabled across
different machines. From both the perspective of a system administrator and the
perspective as someone with a <em>meticulous</em> set of dotfiles, this is one of the
best decisions I’ve ever made.</p>
<h2 id="the-bad-parts">The bad parts</h2>
<p>Figured I’d get this out of the way first, as doing Nix-everything hasn’t been
<em>entirely</em> painless. Namely, some of the things I find notable are:</p>
<ul>
<li>Doing things “the normal way” is either ill-advised or impossible – in
general, a lot of system-level things can <em>only</em> be accomplished declaratively
(through Nix) via mutability</li>
<li>Running binaries from the internet is a pain because they don’t know where to
find shared libraries – a workaround for this is, oddly enough, using the
Steam runtime (packaged as <code>steam-run</code>)</li>
<li>The Nix language is syntactically very ugly and has a very distinct learning
curve – this was lessened by personal Haskell knowledge, which helped me
understand its overall paradigm</li>
<li>The documentation oftentimes is bad or nonexistent – you will often find
yourself reading packages’ Nix expressions to understand exactly how they work</li>
</ul>
<p>The most notable of these is the lack of documentation. Much of my configuration
would be extremely difficult had I not just loaded up <code>nix repl</code> and played
around with things in <code>builtins</code> and <code>pkgs.lib</code>. The Nix language itself is
extremely obtuse if you have no FP knowledge, and while efforts such as
<a href="https://nixos.org/nixos/nix-pills/">Nix Pills</a> have <em>helped</em>, it’s not even close to enough, in my opinion.</p>
<h2 id="first-impressions">First impressions</h2>
<p>My first experience with NixOS was in early 2017, as I was doing Haskell
development at the time and had heard Nix was a good build system as an
alternative or complement to Cabal, which is a <strong>garbage fire</strong> of a tool. At this
time, <code>home-manager</code> did not exist, and most of my dots were managed
traditionally via GNU Stow or just not at all. I did things as I always had –
installing packages with the package manager on the command-line, and stowing
my dotfiles – all of which was done in an imperative fashion.</p>
<p>NixOS is terrible at being a “traditional Linux” like this. I ended up with a
mess of declarative/imperative work, none of which was reproducible, which is
one of the promises of Nix as a whole – and my system was cluttered with trash.
I hated NixOS for this reason, and didn’t return to it for a long time.</p>
<p>I would later learn that the more you buy into NixOS’s declarative model, the
more utopian it becomes.</p>
<h2 id="second-attempt-and-thoughts-on-home-manager">Second attempt, and thoughts on <code>home-manager</code></h2>
<p>Recently, I got a new laptop – a Lenovo ThinkPad T495. I opted to try NixOS
again on the merit that I saw people talking about a tool caled <code>home-manager</code>,
which after reading up on it, appeared to alleviate my former problems of doing
the majority of things imperatively. Additionally, I was armed with more
knowledge of functional programming as a whole, meaning I was better able to
(ab)use the Nix expression language.</p>
<p><a href="https://github.com/rycee/home-manager"><code>home-manager</code></a> is a tool for managing a user’s environment with Nix – this
means what would be traditionally known as “dotfiles” (even though they aren’t
actually “dots” here) can now be encoded and managed with Nix. It also means I
am able to rollback my dots, which I’ve never explicitly needed to do, but is
nice should I accidentally/intentionally break something.</p>
<p>I set up my new NixOS system with <code>home-manager</code> immediately and avoided using
<code>nix-env -iA</code> (imperative package management) at all costs. With my FP
knowledge, the Nix expression language came very naturally to me – it felt like
an uglier, simpler version of ML (perhaps this feel comes from the <code>let... in</code>
convention). While encoding my configs, I began to find tricks here and there to
add abstraction to my configurations – writing functions, making variables,
even in forms of configuration that formerly didn’t support this kind of work.</p>
<p>As a former fan of programmable window managers like xmonad and dwm, forced off
them by Wayland’s promises of no screen tearing (which it absolutely fulfills),
I realized that with Nix, <em>everything was like xmonad</em>. I could configure things
with the power of nearly a full programming language, FP knowledge in hand. This
was the first thing that really caused me to love Nix.</p>
<p>Additionally, I do CTFs, and for these challenges you often have to have
esoteric software that you’re unlikely to touch again. Nix solves this problem
very well by allowing creation of a temporary environment – just run
<code>nix-shell -p &lt;package&gt;</code> and you’re dropped into an environment with the package
available. This avoids cluttering your system with random trash.</p>
<h2 id="reproducibility">Reproducibility</h2>
<p>As a test, I took my old laptop (which ran Void Linux), and decided to slap my
NixOS configuration onto it. I had to do some modularization such that I
wouldn’t copy system-specific settings (such as partition layout), but after
that, my mind was <em>absolutely blown</em>.</p>
<p>With a proper declarative configuration, I was up and running with all my
software, dotfiles, and all on a brand new system in less than an hour, even
with some software compiled from source. It felt somehow utopian – the promise
that NixOS made of reproducible configurations was made. As someone who puts far
too much work into their dotfiles, this was what I had been looking for all
along – the <em>ultimate</em> dotfile manager.</p>
<h2 id="nixos-on-the-server">NixOS on the server</h2>
<p>Recently, I switched from a Raspberry Pi 4 running Alpine to a PCEngines APU2,
namely because it’s x86, has AES-NI, is quad-core, and is overall <em>faster</em>. I’ve
noticed significant improvements with Nextcloud, namely, after moving to it.</p>
<p>In my opinion, server settings are where NixOS shines the most! When setting up
the server, I was able to merely take my existing configuration, disable the
graphical session in my system-specific settings, and deploy it – instant user
account, instant shell configuration, et cetera. Setting up services was a
breeze as well: for example, here’s the entirety of a configuration to set up
Nextcloud over an nginx reverse proxy with HTTPS (unmodularized, but
modularization is pretty trivial):</p>
<div><pre><code data-lang="nix">{ config<span>,</span> pkgs<span>,</span> lib<span>,</span> <span>.</span><span>.</span><span>.</span> }:
<span>with</span> lib; {
  services<span>.</span>nextcloud <span>=</span> {
    enable <span>=</span> <span>true</span>;
    hostName <span>=</span> <span>"</span><span>c</span><span>l</span><span>o</span><span>u</span><span>d</span><span>.</span><span>q</span><span>t</span><span>p</span><span>2</span><span>t</span><span>.</span><span>c</span><span>l</span><span>u</span><span>b</span><span>"</span>;

    nginx<span>.</span>enable <span>=</span> nginxCfg<span>.</span>enable;
    https <span>=</span> nginxCfg<span>.</span>ssl;
    maxUploadSize <span>=</span> <span>"</span><span>5</span><span>G</span><span>"</span>;

    config <span>=</span> {
      dbtype <span>=</span> <span>"</span><span>p</span><span>g</span><span>s</span><span>q</span><span>l</span><span>"</span>;
      dbuser <span>=</span> <span>"</span><span>n</span><span>e</span><span>x</span><span>t</span><span>c</span><span>l</span><span>o</span><span>u</span><span>d</span><span>"</span>;
      dbhost <span>=</span> <span>"</span><span>/</span><span>r</span><span>u</span><span>n</span><span>/</span><span>p</span><span>o</span><span>s</span><span>t</span><span>g</span><span>r</span><span>e</span><span>s</span><span>q</span><span>l</span><span>"</span>;
      dbname <span>=</span> <span>"</span><span>n</span><span>e</span><span>x</span><span>t</span><span>c</span><span>l</span><span>o</span><span>u</span><span>d</span><span>"</span>;
      dbpassFile <span>=</span> <span>"</span><span>/</span><span>e</span><span>t</span><span>c</span><span>/</span><span>n</span><span>e</span><span>x</span><span>t</span><span>c</span><span>l</span><span>o</span><span>u</span><span>d</span><span>-</span><span>d</span><span>b</span><span>-</span><span>p</span><span>a</span><span>s</span><span>s</span><span>"</span>;

      adminuser <span>=</span> <span>"</span><span>h</span><span>a</span><span>z</span><span>e</span><span>l</span><span>"</span>;
      adminpassFile <span>=</span> <span>"</span><span>/</span><span>e</span><span>t</span><span>c</span><span>/</span><span>n</span><span>e</span><span>x</span><span>t</span><span>c</span><span>l</span><span>o</span><span>u</span><span>d</span><span>-</span><span>p</span><span>a</span><span>s</span><span>s</span><span>"</span>;
    };
  };

  services<span>.</span>postgresql <span>=</span> {
    enable <span>=</span> <span>true</span>;
    ensureDatabases <span>=</span> [ <span>"</span><span>n</span><span>e</span><span>x</span><span>t</span><span>c</span><span>l</span><span>o</span><span>u</span><span>d</span><span>"</span> ];
    ensureUsers <span>=</span> [
      { name <span>=</span> <span>"</span><span>n</span><span>e</span><span>x</span><span>t</span><span>c</span><span>l</span><span>o</span><span>u</span><span>d</span><span>"</span>;
        ensurePermissions<span>.</span><span>"</span><span>D</span><span>A</span><span>T</span><span>A</span><span>B</span><span>A</span><span>S</span><span>E</span><span> </span><span>n</span><span>e</span><span>x</span><span>t</span><span>c</span><span>l</span><span>o</span><span>u</span><span>d</span><span>"</span> <span>=</span> <span>"</span><span>A</span><span>L</span><span>L</span><span> </span><span>P</span><span>R</span><span>I</span><span>V</span><span>I</span><span>L</span><span>E</span><span>G</span><span>E</span><span>S</span><span>"</span>;
      }
    ];
  };

  systemd<span>.</span>services<span>.</span><span>"</span><span>n</span><span>e</span><span>x</span><span>t</span><span>c</span><span>l</span><span>o</span><span>u</span><span>d</span><span>-</span><span>s</span><span>e</span><span>t</span><span>u</span><span>p</span><span>"</span> <span>=</span> {
    requires <span>=</span> [ <span>"</span><span>p</span><span>o</span><span>s</span><span>t</span><span>g</span><span>r</span><span>e</span><span>s</span><span>q</span><span>l</span><span>.</span><span>s</span><span>e</span><span>r</span><span>v</span><span>i</span><span>c</span><span>e</span><span>"</span> ];
    after <span>=</span> [ <span>"</span><span>p</span><span>o</span><span>s</span><span>t</span><span>g</span><span>r</span><span>e</span><span>s</span><span>q</span><span>l</span><span>.</span><span>s</span><span>e</span><span>r</span><span>v</span><span>i</span><span>c</span><span>e</span><span>"</span> ];
  };

  services<span>.</span>nginx<span>.</span>virtualHosts<span>.</span><span>"</span><span>c</span><span>l</span><span>o</span><span>u</span><span>d</span><span>.</span><span>q</span><span>t</span><span>p</span><span>2</span><span>t</span><span>.</span><span>c</span><span>l</span><span>u</span><span>b</span><span>"</span> <span>=</span> {
    forceSSL <span>=</span> <span>true</span>;
    enableACME <span>=</span> <span>true</span>;
  };
}
</code></pre></div><p>Merely writing this expression was enough to create a fully functional Nextcloud
instance. I never had to touch the actual Postgres prompt, I never had to touch
<code>occ</code> – just enabling this module immediately got everything up and running. It
even automatically fetched HTTPS certificates for me via LetsEncrypt, and
automatically created the required database.</p>
<p>This approach applies to the majority of services under Nix – even the
derivations I had to write myself (for example, for <a href="https://git.qtp2t.club/hazel/perihelion">my webring manager</a>) were far
easier with Nix than without. Everything was unified under one language!</p>
<p>Furthermore, the fact that my desktop and server run the same dotfiles, just
with different things enabled/disabled, means that I can have an instant
environment akin to my “production” server (if you can call it that).</p>
<h2 id="nix-as-a-build-system">Nix as a build system</h2>
<p>Nix at its fundamental level is just a way to create reproducible builds, and
NixOS is its application at an extreme level. It makes sense, then, that Nix
makes a good system for reproducible builds. While none of the projects I work
on truly <em>need</em> to be reproducible, it’s nice to not have my system cluttered
with garbage – I can have libraries or entire compilers only available in the
context of one project.</p>
<p>Notable tools that complement Nix here are:</p>
<ul>
<li><a href="https://direnv.net/">direnv</a>, which allows to have an environment specific to a directory – this
allows being dropped into a Nix shell without an explicit step</li>
<li><a href="https://github.com/target/lorri">lorri</a>, which is a replacement for <code>nix-shell</code> with tight <code>direnv</code> integration</li>
<li><a href="https://github.com/nmattia/niv">niv</a>, which is useful for pinning the entirety of Nixpkgs to a certain commit</li>
</ul>
<p>My workflow/setup for Nix-based projects is something like this:</p>
<ul>
<li>
<p>Run <code>lorri init</code> to create an environment and <code>direnv allow</code> to use it</p>
</li>
<li>
<p>Run <code>niv init</code> to pin Nixpkgs, and switch the branch to NixOS 20.03</p>
</li>
<li>
<p>Write a <code>shell.nix</code>. For a Racket project, for example, it would look like:</p>
<div><pre><code data-lang="nix">  <span>let</span>
    sources <span>=</span> <span>import</span> <span>./nix/sources.nix</span>;
    pkgs <span>=</span> <span>import</span> sources<span>.</span>nixpkgs {};
  <span>in</span>
  pkgs<span>.</span>mkShell {
    buildInputs <span>=</span> <span>with</span> pkgs; [
      racket
    ];
  }
</code></pre></div><p>This automatically pulls the Racket interpreter, regardless of whether the
target system has Racket installed. This is a simplistic example – more
complex projects would have more complex dependencies. Regardless, with
<code>direnv</code>,</p>
</li>
<li>
<p>Work on the project! As dependencies flow in, add them to <code>shell.ni…</code></p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.knightsofthelambdacalcul.us/posts/2020-06-20-nix-nixos-thoughts/">https://blog.knightsofthelambdacalcul.us/posts/2020-06-20-nix-nixos-thoughts/</a></em></p>]]>
            </description>
            <link>https://blog.knightsofthelambdacalcul.us/posts/2020-06-20-nix-nixos-thoughts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031754</guid>
            <pubDate>Mon, 09 Nov 2020 05:33:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monitoring a grain dryer remotely]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25031661">thread link</a>) | @vaillancourtmax
<br/>
November 8, 2020 | https://maximevaillancourt.com/blog/monitoring-a-grain-dryer-via-the-internet | <a href="https://web.archive.org/web/*/https://maximevaillancourt.com/blog/monitoring-a-grain-dryer-via-the-internet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <p>A relative of mine called a few months ago: “Hey, I have a grain dryer that I’d like to monitor from my phone. Is that something you could set up in time for harvest season?”</p>

<p>I have no idea how grain dryers work, especially not Internet-enabled grain dryers — because <em>of course</em> that’s a thing — but I figured I’d give it a shot anyway.</p>

<p>For context, a grain dryer is literally a combination of a huge furnace and fans that, you guessed it, dries harvested grain for optimal (lack of) moisture.</p>

<div>
<p><img alt="A GSI grain dryer next to a grain silo." src="https://d33wubrfki0l68.cloudfront.net/5a21714733e72c8597435c3ac8150c2fdf955de6/5cfa4/assets/dryer/gsi-1220.jpg">
</p>

</div>

<p>Such dryers typically have an embedded computer running some version of Windows and a touchscreen display that allows monitoring and controlling the dryer’s temperature, timers, and other parameters to get the perfect output.</p>

<div>
<p><img alt="A GSI grain dryer's control panel." src="https://d33wubrfki0l68.cloudfront.net/1b66a66084b20383b3d61ebe1da9a9aa038dd8f7/cccbd/assets/dryer/controller.png">
</p>
<p>
  A GSI grain dryer's control panel. Image © <a href="https://www.grainsystems.com/master/products/conditioning/watchdog-technology.html">GSI</a>
</p>
</div>

<p>However, because these things run for hours at a time, and because agriculture workers during harvest season usually end up in a sleep-deprived state that lasts for multiple weeks, having the ability to monitor these grain dryers remotely lets workers get more precious sleep time (instead of having to walk/drive up to the grain dryer to see if everything’s okay in the middle of the night).</p>

<p>The desired outcome is to monitor the grain dryer remotely using the web interface:</p>

<div>
<p><img alt="An iPhone with the grain dryer's web monitoring interface open in the browser." src="https://d33wubrfki0l68.cloudfront.net/2ec442d267d87ac17aa3ace20b6c0a536e74fcc5/89508/assets/dryer/web-ui.jpg">
</p>
<p>
  The web interface to monitor the grain dryer's current state. Image © <a href="https://www.grainsystems.com/content/dam/Brands/GSI/Brochures/Conditioning/gs013_Modular-TSeries-Dryers-2017_7.pdf/_jcr_content/renditions/original">GSI</a>
</p>
</div>

<p>It’s now harvest season 2020, so I connected a grain dryer to the Internet yesterday. It was fun (and weird) and I learned a few things. Here’s how we did it.</p>

<h3 id="what-youll-need">What you’ll need</h3>

<ul>
  <li>A GSI grain dryer with a <a href="https://www.grainsystems.com/master/products/conditioning/watchdog-technology.html">Watchdog module</a> installed (I was lucky that the dryer already had this module installed)</li>
  <li>A cellular modem (we purchased a <a href="https://www.netgear.com/home/products/mobile-broadband/lte-modems/LB1120.aspx">Netgear LB1120</a>)</li>
  <li>A cellular data plan with a public static IP (we went with Telus, a Canadian cellular carrier, and needed to open a business account to get access to a public static IP for 15$/month per month on top of the base data plan)</li>
  <li>A laptop with an Ethernet port</li>
  <li>A few Ethernet cables</li>
</ul>

<h3 id="topology">Topology</h3>

<p>Here’s how the network topology looks like:</p>

<div><div><pre><code>                   (via public static IP)
                        +----------+
         +--------------&gt; Internet &lt;--------------+
         |              +----------+              |
 +-------v--------+                       +-------v-------+
 | Cellular modem |                       | Mobile device |
 +-------^--------+                       +---------------+
         |
+--------v----------+
|    Grain dryer    |
| (Watchdog module) |
+-------------------+
</code></pre></div></div>

<p>Essentially, we’ll expose the grain dryer’s web interface to the Internet via a public static IP using a cellular modem. Once it’s exposed, the operator will be able to navigate to that static IP from their mobile device to access the grain dryer’s web interface.</p>

<h3 id="subscribing-for-a-data-plan-and-a-static-ip">Subscribing for a data plan and a static IP</h3>

<p>I called various cellular carriers here in Canada to learn more about their data-only plans and the possibility of adding a public static IP option to the plan: the only carrier that seemed like they knew what they were talking about was Telus. Others either didn’t offer the public static IP option, or didn’t know what I was talking about.</p>

<p>With that, we went ahead and signed up for a business account at Telus (required to get access to the public static IP option), bought a SIM card, and a data-only plan for the modem.</p>

<h3 id="setting-up-the-cellular-modem">Setting up the cellular modem</h3>

<p>First up, we need to make sure we’re able to connect to the nearest cellular tower to connect to the Internet. The Netgear LB1120 is fairly easy to set up on paper: pop a SIM card in there and we’re done, right? Well, for our use case, not quite. There are a few things to do to set it up to use the static IP assigned to the data plan from the cellular carrier. More importantly, the modem needs to be set up in “bridge” mode (instead of “router” mode) to act as a simple bridge (rather than a router) to connect it directly to the grain dryer.</p>

<div>
<p><img alt="Laptop, modem, cables, and various manuals spread out on concrete." src="https://d33wubrfki0l68.cloudfront.net/d011a2ceee600cafd7f0ee676b393623f84bbef4/f13bd/assets/dryer/setup-modem.jpg">
</p>
<p>
  On-premise setup to configure the modem and the dryer. That's my trusty ThinkPad X220.
</p>
</div>

<p>Days before arriving on the premises, <a href="https://community.netgear.com/t5/Mobile-Routers-Hotspots-Modems/LB1120-Bridge-Mode-No-Connectivity/m-p/1404666#M3431">I read online that the firmware that ships out of the box is broken</a>: “bridge” mode doesn’t function at all, and an update is required to fix it. This made me a bit nervous because I didn’t have the modem with me, and wasn’t sure if I was going to be able to get the update to work properly. Thankfully, upon inserting the SIM card, turning the modem on, plugging it into the computer via an Ethernet cable, and accessing the modem’s setup interface at <code>http://192.168.5.1</code>, the modem’s web UI suggests downloading the latest firmware over the air. Neat!</p>

<p>From what I read, you must use a firmware more recent than <code>NTG9X07C_12.09.05.27</code> to make sure “bridge” mode works fine. In our case, we updated to <code>NTG9X07C_12.09.05.30</code>, so we’re good.</p>

<div>
<p><img alt="Updating the modem's firmware over the air." src="https://d33wubrfki0l68.cloudfront.net/7d6dd2d298b3cf861f6144dc01dc774b85ac9ff3/a036b/assets/dryer/firmware-update.jpg">
</p>
<p>
  Updating the modem's firmware over the air.
</p>
</div>

<p>Once the update completes and the modem reboots, we can go in the settings and change the operation mode to “bridge”:</p>

<div>
<p><img alt="Changing the modem's operation mode to Bridge mode." src="https://d33wubrfki0l68.cloudfront.net/34c50316b7c48bdcf08962a436d697d2ff1b9c27/a56a3/assets/dryer/bridge-mode.png">
</p>
<p>
  Changing the modem's operation mode to Bridge mode. Image © <a href="https://kb.netgear.com/31163/How-to-change-4G-LTE-Modem-from-router-mode-to-bridge-mode">Netgear</a>
</p>
</div>

<p>Doing so “turns off the router function of the device and assigns the network IP address directly to the attached host”, which is exactly what we need to connect the modem directly to the dryer’s Watchdog module. Save and let the modem reboot.</p>

<p>Now, the SIM is in the modem, which has the latest firmware and is in “bridge” mode, but there’s one last thing to fix: the cellular carrier is assigning a dynamic IP to the modem, which isn’t what we want: we should be getting the static IP for the data plan we’re paying for. To resolve this issue, we need to tweak the modem’s access point name (APN).</p>

<p>I got stuck on this issue for around 30 minutes before remembering that APNs are a thing and that I could possibly tweak it in the modem settings. I’m glad I remembered!</p>

<p>By default, the modem auto-detects the APN from the cellular carrier. For most cases, this works fine, but in this particular case, we want to use a different APN that allows us to use the static IP assigned to our data plan. APN settings vary by cellular carrier, and I ended up searching for Telus’ APN settings while on premise. I found <a href="https://usatcorp.com/faqs/common-access-point-names-apn-carrier/">USAT Corp’s website to include various APN settings</a>, so I highly recommend trying those values out for your particular cellular carrier.</p>

<p>In our specific case, we needed to use the following settings to be able to get the static IP assigned to the modem:</p>

<ul>
  <li>Access point name (APN): <code>staticipeast.telus.com</code> (we’re on the east coast)</li>
  <li>Authentication: None</li>
  <li>Packet data profile (PDP): IPv4</li>
</ul>

<div>
<p><img alt="Configuring the APN to use the static IP assigned to the account." src="https://d33wubrfki0l68.cloudfront.net/a9161e0b08165d260829bf6fd22337043b63bffa/40217/assets/dryer/apn-settings.png">
</p>
<p>
  In the modem settings, we need to configure a new APN to ask the cellular carrier to assign the account's static IP to the modem.
</p>
</div>

<p>The LB1120 has a setting to automatically connect to the Internet upon booting: I recommend turning this on to have it connect automatically in the case of a power failure.</p>

<p>Let’s reboot the modem one more time. At this point, the modem should be using the static IP assigned to your data plan by the cellular carrier.</p>

<div>
<p><img alt="Signal is equivalent to 2 bars out of 5." src="https://d33wubrfki0l68.cloudfront.net/5c248b8917f0fe46445757c0dee3636422b25f1b/b2044/assets/dryer/2-bars.jpg">
</p>
<p>
  The Netgear LB1120 cellular modem, all set up and ready to go. Even though it sits at 2 bars out of 5, it's plenty for the low throughput use case of reading data from a dryer.
</p>
</div>

<p>A tip to know if the modem is configured correctly: with the computer (device A) connected to the modem via Ethernet, use another device (device B) to access the expected static IP address (I used my smartphone). On device A, serve something (anything) on port 80 (I did <code>sudo python -m SimpleHTTPServer 80</code>), and see if you get that on device B when visiting the static IP address. If you do, then the modem is all set up and ready to go. If not, something’s wrong (invalid APN, incorrect data plan, no public static IP configured by the cellular carrier, some sort of NAT that prevents direct access, etc.).</p>

<p>Now that the modem is configured properly, let’s move on to configuring the grain dryer itself.</p>

<h3 id="configuring-the-dryer">Configuring the dryer</h3>

<p>The process to configure the dryer is fairly similar to configuring the modem: we essentially connect the dryer to the laptop via Ethernet to configure it via a web interface. But first, let’s look inside the dryer’s computer compartment.</p>

<p>It all peels up like an onion: the outermost layer is the protective door to prevent water and debris from hitting switches and the touchscreen, and the middle layer is the computer and touchscreen itself along with a PLC. The Watchdog module is fixed inside the box itself.</p>

<div>
<p><img alt="The dryer's computer and PLC internals exposed." src="https://d33wubrfki0l68.cloudfront.net/a74f45dc1610d35fecb4981dae16685049b56b5c/11a3d/assets/dryer/onion.jpg">
</p>
<p>
  The dryer's PLC. The Watchdog module is not pictured (it's fixed on the right).
</p>
</div>

<p>When looking inside the box, the Watchdog module is fixed inside and connected to the rest of the PLC via an RS232 serial port. There are two Ethernet ports: one WAN port (the one on the left in the picture), and a LAN port (the one on the right).</p>

<div>
<p><img alt="The Watchdog module fixed inside the computer compartment of the dryer." src="https://d33wubrfki0l68.cloudfront.net/e3234c6b71810bcce6c0ab3b7e561fee69d4a57e/1e608/assets/dryer/watchdog-module.jpg">
</p>
<p>
  The Watchdog module. The WAN port is directly connected to the modem.
</p>
</div>

<p>To configure the dryer’s network settings, we need to connect the Watchdog’s LAN port to the computer via Ethernet and access the web interface at <code>http://10.0.0.1/setup</code>. On this screen, you’ll need to click “Configure”, which will bring up the possibility to use DHCP or a static IP address. In our case, we select the “static IP” option.</p>

<div>
<p><img alt="The Watchdog network configuration screen, to configure the static IP address used to connect to the dryer." src="https://d33wubrfki0l68.cloudfront.net/2ceb582c1539a2d312fde85322f070fa42c21e38/ea792/assets/dryer/network-setup.png">
</p>
<p>
  Configuring the network settings on the grain dryer.
</p>
</div>

<p>On the next screen, we fill out the following fields:</p>

<ul>
  <li>Static IP address</li>
  <li>Subnet mask</li>
  <li>Gateway</li>
  <li>DNS1</li>
  <li>DNS2</li>
</ul>

<p>Assuming that the static IP address provided by the cellular carrier is <code>241.2.31.59</code>, we’d fill out the fields as such:</p>

<ul>
  <li>Static IP address: <code>241.2.31.59</code> (static IP from the cellular carrier)</li>
  <li>Subnet mask: <code>255.255.255.0</code> (pretty standard stuff)</li>
  <li>Gateway: <code>241.2.31.1</code> (same as static IP, but last component is <code>1</code>)</li>
  <li>DNS1: <code>241.2.31.1</code> (we use the gateway as the DNS provider)</li>
  <li>DNS2: <code>8.8.8.8</code> (this is Google DNS, because why not)</li>
</ul>

<p>Once that’s done, save the network configuration, and turn off the grain dryer.</p>

<p>You may now connect the modem to the Watchdog module’s WAN port (as pictured a few paragraphs above).</p>

<p>Now, the moment of truth: turn on the dryer. You may …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://maximevaillancourt.com/blog/monitoring-a-grain-dryer-via-the-internet">https://maximevaillancourt.com/blog/monitoring-a-grain-dryer-via-the-internet</a></em></p>]]>
            </description>
            <link>https://maximevaillancourt.com/blog/monitoring-a-grain-dryer-via-the-internet</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031661</guid>
            <pubDate>Mon, 09 Nov 2020 05:12:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4 Billion USD ICO From 2017: Clues Emerging, Finally]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25031582">thread link</a>) | @npguy
<br/>
November 8, 2020 | https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/ | <a href="https://web.archive.org/web/*/https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Travelers aboard a luxury TransAtlantic cruise have shared pictures that many in the crypto community believe could provide clues on the missing 4 billion dollars raised during the EOS ICO. </p>



<p>DoubleSpend’s own analysis based on the size of the box show that it could very well contain the amount in USDs that was raised in the year-long ICO.</p>
<div><p><a href="https://twitter.com/share?url=https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/&amp;text=Object%20Floating%20In%20Atlantic%20Ocean%20Could%20Contain%20EOS%E2%80%99%20ICO%20Funds%3A%20Sources" title="Share on Twitter" target="_blank" rel="nofollow noopener noreferrer" data-postid="409" data-social-network="Twitter" data-social-action="Tweet" data-social-target="https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/"><span><span><svg version="1.1" xmlns="http://www.w3.org/2000/svg" width="29.71875" height="32" viewBox="0 0 951 1024"><path d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"></path></svg></span><span>Tweet</span></span><span>0</span></a></p></div>		</div></div>]]>
            </description>
            <link>https://doublespend.io/2020/10/28/breaking-object-floating-in-atlantic-could-be-carrying-funds-raised-in-eos-ico/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031582</guid>
            <pubDate>Mon, 09 Nov 2020 04:55:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Strategies to working remotely and smashing goals]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25031490">thread link</a>) | @veebuv
<br/>
November 8, 2020 | https://www.remoteworkly.co/blog/22-tips-to-working-remotely-and-smash-your-goals | <a href="https://web.archive.org/web/*/https://www.remoteworkly.co/blog/22-tips-to-working-remotely-and-smash-your-goals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="45d72c63-4641-3f9f-f271-8df897413c12"><p>Alright the future of work is here to stay and we all need to prepare for the best remote work practices. Regardless of what happens, work has changed forever, people will go back to the office surely, but the dynamic will now be a hybrid mode.<br>‍</p><p>So learning how to work remotely will be a skill in your arsenal that might just propel you to your next career promotion. If you've asked yourself the question "how to work from home" - you've reached the right place.<br>‍</p><h4>1) Create a routine</h4><p>If you want to succeed working from home or working remotely this is a must, which is why it's the top position. You need to build a system that builds a body clock. I used to get into the zone when I got onto the train and grabbed by morning coffee at my office, when I couldn't do this anymore I spiraled. This was until I started building an atomic habit again, micro habits that signal the mind for whats about to happen next. Nowadays my trigger is early morning juice, similarly so, build a routine. Get out of bed, go to the gym, have a process.<br>‍</p><h4>2) Have your creative work space</h4><p>Separate your living, from your office space. Even if it means working from a coffee shop. You need to keep your area of comfort for leisure and work for work. This is an important work tip as separation of concerns as well as "environments" make a significant difference to motivation. Pretty much the same reason people go to libraries when they can read at home</p><p>‍</p><h4>3) Set time boundaries</h4><p>Its very easy to be sucked into 24 hour work when working from home. One of the keys to working remotely is creating time boundaries. Employers may feel like you're available to message after work hours. In addition you might get FOMO from all the slack notifications. Fight the urge, set your boundaries. 80% of 130 people I spoke to said they were constantly fatigued from working from home. This is a very important tip amongst other work from home tips and tricks. Stay disciplined to time<br>‍</p><h4>4) Leave home</h4><p>How to be productive working from home ? Leave your home. Ironic - I know but cabin fever can creep into you. As humans we need social interaction and movement. Step away from your home, go for a walk, meet a friend or better yet exercise. This will stimulate both your body muscles as well as your brain. Feeling fresh air graze your face makes a big difference, especially when you're glued to your screen<br>‍</p><h4>5) Plan meetings with work colleagues</h4><p>We've been remote for nearly 1.5 years now and I always advice social meetings for working remotely. Catch up with any team-mate in the same city as you and make it a monthly if not weekly thing. Building bonds with people in real life not only helps you create long lasting relationships, but also helps you connect deeper with another person. 70% of communication is non - verbal, which you miss out over zoom calls.<br>‍</p><h4>6) Reduce distractions</h4><p>"Minimise the number of distractions you have in your office" - simple yet sage advice for working remotely. We've got a concentration span of 12 seconds, with slack messages going off every moment combined with our innate nature of not wanting to miss out on important conversations leads us to doing absolutely no work at all. I encourage you to embrace an async first work culture, tools like <a href="http://remoteworkly.co/">remoteworkly.co</a> help with async video meetings or even loom for screen recording.<br>‍</p><h4>7) Have no meeting Wednesdays</h4><p>Meets really hurt productivity. 72% of managers say meetings are a complete waste and 60% of employees think they will work better without meetings. This is the same reason Zoom fatigue is becoming a big issue, because you need to have your camera on and focus the entire time. Try encourage a culture where you have certain days with no meetings. Any conversation that needs to happen can occur in an asynchronous way, weather thats via tools like <a href="http://remoteworkly.co/">remoteworkly.co</a> or vidyard. If you're reporting bugs, use feedback tools like bugheard or <a href="http://remoteworkly.co/show">remoteworkly.co/show</a></p><h4><br>8)Avoid unwanted meetings with conversation bloat</h4><p>Focus on getting work done, try set a decorum where you can leave meetings you're not needed in anymore. Teams that embrace the concept of async communication will win. This will reduce anxiety within teams, improve culture and make sure the meetings that do happen are purely focused on value and outcome. This can be done using tools like <a href="http://remoteworkly.co/">remoteworkly.co</a> for async meetings and startups or even voice notes like recordify</p><h4><br>9)Start with the toughest task</h4><p>There's a science behind this but it works. We often think starting with easy tasks gives us the feeling of accomplishment and builds up momentum. There is some truth to this, however by the time you reach the tough/long task to complete you're left drained of energy and delay it to tomorrow, which never comes. Start with the toughest tasks, its the best way to be productive working from home<br>‍</p><h4>10)Over communicate</h4><p>There will be obvious disconnect between you and your team mates when you're remote. That is the nature of VoIP communication. So make sure you overcommunicate. This does not mean to spam people with 100 messages, but rather use video and tools that capture as much data as possible for you to make it easier for the other person to understand what you're doing without having to reach back to you."</p><h4><br>11)Leverage asynchronous communication</h4><p>My favorite tip in my list of remote work best practices. I strongly believe async communication is the way of the future. Leverage using async communication whenever and wherever possible without organizing impromptu/time blocking calls. There's several tools out there that let you take full advantage of async communication, <a href="http://remoteworkly.co/">remoteworkly</a>, <a href="http://loom.com/">loom</a>, <a href="http://vidyard.com/">vidyard</a>, <a href="http://marker.io/">marker</a> (for website feedback), <a href="http://remoteworkly.co/show">remoteworkly</a> (for QA feedback), <a href="http://trello.com/">trello</a>, <a href="http://asana.com/">asana<br>‍</a></p><h4>12)Use productivity hacks like pomodoro</h4><p>The pomodoro technique is one of the best productivity tips I came across. Its an old technique that lets you cut down your work into an investment reward balance. This builds another atomic habit loop where you learn to enjoy difficult tasks in anticipation of the reward. Your day is broken down into 25 minute work chunks of pure focus with 5 minute breaks, do this 4 times and then take a 20 minute break, rinse and repeat. Checkout timechi.com</p><h4><br>13)Share your project progress</h4><p>The easiest way to start working when you're feeling down or demotivated is by sharing your progress. Social accountability plays a big role in human motivation, something about putting our reputation at risk that kicks us in the behind. In addition, sharing your progress becomes a incredible feedback cycle, where you encourage others with your progress or cause them to reach out to you and motivate you to push faster. Lastly, having progress updates is a great way to look back and see how far you come, consequentially motivating you to work better</p><h4><br>14)Avoid jumping on impromptu phonecalls</h4><p>This rolls back to my earlier point about async conversations, Paul Graham mentioned that one of the downfalls of remote work is impromptu meetings where a large number of incredible ideas are usually generated is being robbed from todays workforce. Yes this is true, but on the flip side, most of the inefficiencies in working from an office came from these "tap on the shoulder" interruptions. I no longer pick up calls unless the message following up says "this is urgent", your concentration is sacred in 2020. Protect it at all costs.</p><h4><br>15)Set clear expectations for each day</h4><p>Employing a daily manifest of long term goals, short term goals, micro tasks as well as schedule has been a game changer in working remote. You almost get to "grade" each day in terms of the success you wanted to achieve and what you did achieve. This lets you work out what is the most effective work from home schedule for you. Each week, analyze the good days and bad days, pick up patterns that lead to bad days and those that lead to good days and optimize to focus on the good patterns.</p><h4><br>16Share with video whenever you can</h4><p>To prevent the feeling of isolation, use video software whenever you can. <a href="http://loom.com/">Loom</a> is a great place to begin, or even zoom for work meetings. I know it can be daunting at times, but it provides a great path to building deeper and more meaningful relationships with teams. PS - when you're chatting, look into the camera and not your screen. Makes double the impact</p><h4><br>17) Ask for one on one checkins</h4><p>Do NOT cancel your one on ones with your team mates, they're more important than every given there is no face to face relationship with your direct supervisor or subordinate. Use a template with a clear structure to find out how your team is doing, how things can be done better. This builds trust and encourages them to keep motivated even when people feel disconnected.<br>‍</p><h4>18) Bond with your team beyond work, get to learn about their family</h4><p>Use tools like <a href="http://donut.com/">donut</a> to encourage your team members to learn about each other. This is vital for new employees who don't have a chance to meet new people given you're restricted to a computer, donut runs introduction meetings between people. Encouraging that communication between new colleagues is a great way to improve team bond, morale and company culture</p><h4><br>19) Exercise</h4><p>Yes, do it. As human's we're not made to be seat potatoes. Despite how tasty potatoes are, you can't aspire to be one. Get out, hit the gym and exercise. The endorphins release as well as adrenaline rush you get post exercise is fundamental for peak performance. You won't find one successful person who doesn't preach for a daily exercise schedule</p><h4><br>20) Use noise filtering software</h4><p>Working at home with kids or even a dog can be very disturbing and sometimes embarrassing. Even though everyone is working remote, the noise of a grinder in the background whilst you're delivering your Q4 results can be quite distractive. Use tools like <a href="http://krisp.ai/">krisp</a> that magically cut out background noise and give you the confidence that regardless of who's speaking at the back, your colleagues won't be able to hear it.<br>‍</p><h4>21) Check in with 5 of your friends</h4><p>I assure you many of your friends will be …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.remoteworkly.co/blog/22-tips-to-working-remotely-and-smash-your-goals">https://www.remoteworkly.co/blog/22-tips-to-working-remotely-and-smash-your-goals</a></em></p>]]>
            </description>
            <link>https://www.remoteworkly.co/blog/22-tips-to-working-remotely-and-smash-your-goals</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031490</guid>
            <pubDate>Mon, 09 Nov 2020 04:34:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start with pen and paper]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25031483">thread link</a>) | @sethetter
<br/>
November 8, 2020 | https://sethetter.com/posts/start-with-pen-and-paper/ | <a href="https://web.archive.org/web/*/https://sethetter.com/posts/start-with-pen-and-paper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            


<article>
    
    <section>
        <p>tl;dr — If you feel unfocused, grab a pen and paper and start writing your thoughts down.</p>
<p>Is there a question you are stuck on? A ambiguous goal you're trying to accomplish? Maybe a task you know you need to do but from which you keep getting distracted?</p>
<p><strong>Nothing will provide focus like pen and paper.</strong></p>
<p>It's all too easy these days to have a clear intention only to be sidetracked by the whirlpool of apps and services clawing for our attention on our devices.</p>
<p>It helps to take the time to groom our notification settings for importance and timeliness, but a digital device that we can use to complete nearly any task will never stand up to pen and paper in terms of it's ability to provide focus.</p>
<p>My thoughts are a constant whirlwind, I'm certainly more distractible than most, and interacting with nearly any online service only fuels that fire. So how can I get anything done if I'm unable to control my focus?</p>
<p><strong>Pen and paper.</strong> Whenever I catch myself stuck in the whirlpool, feeling not-great because I <em>know</em> I'm not doing what I want to be doing, or what I should be doing, I step away, grab pen and paper, and start writing.</p>
<p>The simple act of writing can focus my thoughts and attention in a way that nothing else can. Free from distractions, just a canvas to pour my thoughts into, and turn them into something with a sense of direction and purpose.</p>
<p>Writing is like a superpower to me. If there's any task I want to accomplish, the first step is always to write it down. Anytime I need to recenter myself on that task, I simply return to paper.</p>
<p>Throughout my life I've found that the simplest solutions are often the most powerful. So far I've found no simpler solution to start tackling any problem than to simply write it down, and then keep on writing.</p>

    </section>
</article>


        </div></div>]]>
            </description>
            <link>https://sethetter.com/posts/start-with-pen-and-paper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031483</guid>
            <pubDate>Mon, 09 Nov 2020 04:33:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cool Machine Learning Books]]>
            </title>
            <description>
<![CDATA[
Score 242 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25031455">thread link</a>) | @ridddle
<br/>
November 8, 2020 | http://matpalm.com/blog/cool_machine_learning_books/ | <a href="https://web.archive.org/web/*/http://matpalm.com/blog/cool_machine_learning_books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
  <p>awhile ago i posted
   <a href="http://matpalm.com/blog/2010/08/06/my-list-of-cool-machine-learning-books/">my list of cool machine learning books</a>,
   but it's been awhile so it's probably time to update it...
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/mml.jpg"></p>
<p><b><a href="https://mml-book.github.io/">Mathematics for Machine Learning</a>
   by Marc Peter Deisenroth, A. Aldo Faisal &amp; Cheng Soon Ong.</b>
</p>
<p>this is my personal favorite book on the general math required for machine learning,
   the way things are described really resonate with me.
   available as a free pdf but i got a paper copy to support the authors after reading the
   first half.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/laalfd.jpg"></p>
<p><b><a href="http://math.mit.edu/~gs/learningfromdata/">Linear Algebra and Learning from Data</a>
   by Gilbert Strang.</b>
</p>
<p>this is gilbert's most recent work. it's really great, he's such a good teacher, and
   <a href="https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/">his freely available lectures</a>
   are even better. it's a shorter text than his other classic intro below with
   more of a focus on how things are connected to modern machine learning techniques.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/itla.jpg"></p>
<p><b><a href="https://math.mit.edu/~gs/linearalgebra/">Introduction to Linear Algebra</a>
   by Gilbert Strang.</b>
</p>
<p>this was my favorite linear algebra book for a long time before his 'learning from
   data' came out. this is a larger book with a more comprehensive view of linear algebra.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/ts.jpg"></p>
<p><b><a href="https://greenteapress.com/wp/think-stats-2e/">Think Stats: Probability and Statistics for Programmers</a> by Allen Downey.</b>
</p>
<p>this book focuses on practical computation methods for probability and statistics.
   i got a lot out of working through this one.
   it's all in python and available for free.
   ( exciting update! as part of writing this post i've discovered there's a new edition
   to read!)
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/dbda.jpg"></p>
<p><b><a href="https://sites.google.com/site/doingbayesiandataanalysis/">Doing Bayesian Data Analysis</a>
   by John Kruscgke</b>
</p>
<p>on the bayesian side of things this is the book i've most enjoyed working through.
   i've only got the first edition which was R and
   <a href="https://en.wikipedia.org/wiki/OpenBUGS">BUGS</a> but i see
   the second edition is R,
   <a href="http://mcmc-jags.sourceforge.net/">JAGS</a> and
   <a href="https://mc-stan.org/">Stan</a>.
   it'd be fun i'm sure to work through it doing
   everything in <a href="https://github.com/pyro-ppl/numpyro">numpyro</a>. i might do that in all
   my free time. haha. "free time" hahaha. sob.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/eosl.jpg"></p>
<p><b><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning</a>
   by Hastie, Tibshirani and Friedman</b>
</p>
<p>this is still one of the most amazing fundamental machine learning books i've ever had.
   in fact i've purchased this book <em>twice</em> and given it away both times :/ i might buy another
   copy some time soon, even though it's been freely available to download for ages. an
   amazing piece of work.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/pgm.jpg"></p>
<p><b>
   <a href="https://mitpress.mit.edu/books/probabilistic-graphical-models">Probabilistic Graphical Models</a>
   by Daphne Koller &amp; Nir Friedman</b>
</p>
<p>this is an epic textbook that i'd love to understand better. i've read a couple of sections in
   detail but not the entire tome yet.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/praml.jpg"></p>
<p><b>
   <a href="https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/">Pattern Recognition and Machine Learning</a>
   by Christopher Bishop</b>
</p>
<p>this is probably the best overall machine learning text book i've ever read. such a beautiful book
   and <a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">the pdf is FREE FOR DOWNLOAD!!!</a>
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/mlapp.jpg"></p>
<p><b><a href="https://mitpress.mit.edu/books/machine-learning-1">Machine Learning: A Probabilistic Perspective</a> by Kevin Murphy</b>
</p>
<p>this is my second favorite general theory text on machine learning.
   i got kevin to sign my copy when he was passing my desk once but
   someone borrowed it and never gave it back :(
   so if you see a copy with my name on the spine let me know!
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/homl.jpg"></p>
<p><b><a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</a> by Aurélien Géron</b>
</p>
<p>this is the book i point most people to when they are interested in getting up
   to speed with modern applied machine learning without too much concern for the
   theory. it's very up to date (as much as a book can be) with the latest libraries
   and, most importantly, provides a good overview of not just neural stuff but fundamental
   <a href="https://scikit-learn.org/stable/">scikit-learn</a> as well.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/mle.jpg"></p>
<p><b><a href="http://www.mlebook.com/wiki/doku.php">Machine Learning Engineering</a> by Andriy Burkov</b>
</p>
<p>a great book focussing on the operations side of running a machine learning system. i'm a bit
   under half way through the free online version and very likely to buy a physical copy to finish
   it and support the author. great stuff and, in many ways, a more impactful book than any of
   the theory books here.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/itdm.jpg"></p>
<p><b><a href="https://www-users.cs.umn.edu/~kumar001/dmbook/index.php">Introduction to Data Mining</a>
   by Pang-Ning Tan, Michael Steinbach &amp; Vipin Kumar</b>
</p>
<p>this is another one that was also on my list from ten years ago and though it's section
   on neural networks is a bit of chuckle these days there is still a bunch of really
   great fundamental stuff in this book. very practical and easy to digest. i also see there's
   a second edition now. i reckon this would compliment the "hands on" book above very well.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/salp.jpg"></p>
<p><b><a href="https://web.stanford.edu/~jurafsky/slp3/">Speech and Language Processing</a>
   by Dan Jurafsky &amp; James Martin</b>
</p>
<p>still the best overview of NLP there is (IMHO). can't wait to read the 3rd edition which
   apparently will cover more modern stuff (e.g. transformers) but until then, for the
   love of god though, please don't be one of those "this entire book is
   irrelevant now! just fine tune BERT" people :/
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/no.jpg"></p>
<p><b><a href="https://link.springer.com/book/10.1007/978-0-387-40065-5">Numerical Optimization</a>
   by Jorge NocedalStephen J. Wright</b>
</p>
<p>this book is super hard core and maybe more an operations
   research book than machine learning. though i've not read it cover to cover the
   couple of bits i've worked through really taught me a lot. i'd love to understand
   the stuff in this text better; it's so so fundamental to machine learning (and more)
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/dl.jpg"></p>
<p><b><a href="https://www.deeplearningbook.org/">Deep Learning</a>
   by Ian Goodfellow</b>
</p>
<p>writing a book specifically on deep learning is very dangerous since things move so fast but
   if anyone can do it, ian can... i think ian's approach to explaining neural networks
   from the ground up is one of my favorites. i got the first edition hardback but it's free to
   download from the website.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/pr.jpg"></p>
<p><b><a href="https://mitpress.mit.edu/books/probabilistic-robotics">Probabilistic Robotics</a>
   by Sebastian Thrun, Wolfram Burgard and Dieter Fox</b>
</p>
<p>when i first joined a robotics group i bought a stack of ML/robotics books and this
   was by far the best. it's good intro stuff, and maybe already dated in places given
   it's age (the 2006 edition i have) but i still got a bunch from it.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/tml.jpg"></p>
<p><b><a href="https://www.oreilly.com/library/view/tinyml/9781492052036/">TinyML</a>
   by Pete Warden &amp; Daniel Situnayake</b>
</p>
<p>this was a super super fun book to tech review! neural networks on microcontrollers?!?
   yes please!
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/ec.jpg"></p>
<p><b><a href="https://www.wiley.com/en-us/Evolutionary+Computation%3A+Toward+a+New+Philosophy+of+Machine+Intelligence%2C+3rd+Edition-p-9780471669517">Evolutionary Computation</a> by David Fogel</b>
</p>
<p>this is still by favorite book on evolutionary algorithms; i've had this for a loooong
   time now. i still feel like evolutionary approaches are due for a big big comeback
   any time soon....
</p>
<hr>


<h2>in the mail...</h2>
<p>the good thing about writing a list is you get people telling you cool ones you've missed :)
</p>
<p>the top three i've chosen (that are in the mail) are...
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/ciis.jpg"></p>
<p><b><a href="http://bayes.cs.ucla.edu/PRIMER/">Causal Inference in Statistics</a> by
   Judea Pearl, Madelyn Glymour &amp; Nicholas P. Jewell</b>
</p>
<p>recommended by <a href="https://twitter.com/animesh_garg">animesh</a> who quite rightly points out
   the lack of causality in machine learning books in the books above.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/itiala.jpg"></p>
<p><b><a href="https://www.cambridge.org/au/academic/subjects/computer-science/pattern-recognition-and-machine-learning/information-theory-inference-and-learning-algorithms?format=HB&amp;isbn=9780521642989">Information Theory, Inference and Learning Algorithms</a> by David MacKay</b>
</p>
<p>i've seen this book mentioned a number of times and was most recently recommended by
   my colleague <a href="https://twitter.com/danesherbs">dane</a> so it's time to get it.
</p>
<hr>
   <p><img src="http://matpalm.com/blog/imgs/2020/mlb/bmlpa.jpg"></p>
<p><b><a href="https://www.oreilly.com/library/view/building-machine-learning/9781492045106/">Building Machine Learning Powered Applications</a> by Emmanuel Ameisen</b>
</p>
<p>a number of people i worked with have enjoyed this. first recommended by another
   colleague <a href="https://twitter.com/davidcolls">dave</a>.
   looks to be on the practical side rather than the theory but that's ok some times :)
</p>

  </div></div>]]>
            </description>
            <link>http://matpalm.com/blog/cool_machine_learning_books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031455</guid>
            <pubDate>Mon, 09 Nov 2020 04:26:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does the event loop work in JavaScript? [video]]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25031384">thread link</a>) | @krayonatan
<br/>
November 8, 2020 | https://yonatankra.com/how-does-the-event-loop-work/ | <a href="https://web.archive.org/web/*/https://yonatankra.com/how-does-the-event-loop-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="primary"><main id="main" role="main"><article id="post-599"><div><!-- .entry-meta --><div> <p><span><span>Estimated Reading Time: </span> <span>&lt; 1</span> <span>minute</span></span></p><figure><p><span><iframe width="640" height="360" data-src="https://www.youtube.com/embed/Nqx3rtv_dko?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p><figcaption>The event loop and your code talk from WarsawJS</figcaption></figure><p>On august 2020 I spoke at <a rel="noreferrer noopener" href="https://warsawjs.com/" data-type="URL" data-id="https://warsawjs.com/" target="_blank">WarsawJS</a>, explaining about the event loop and how it works.  I hope you will enjoy this talk.</p><p>If you prefer to read – <a href="https://yonatankra.com/the-event-loop-and-your-code/" data-type="post" data-id="299">here’s the blog post this talk is based on</a>.</p><p id="jp-relatedposts"><h3><em>Related</em></h3></p></div><!-- .entry-content --><!-- .entry-footer --></div></article><!-- #post-## --><p><h3>Enjoyed the article?</h3><h4>Sign up to my newsletter to enjoy more content:</h4></p>  <nav role="navigation" aria-label="Posts"><h2>Post navigation</h2></nav><!-- #comments --></main><!-- #main --></div></div>]]>
            </description>
            <link>https://yonatankra.com/how-does-the-event-loop-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031384</guid>
            <pubDate>Mon, 09 Nov 2020 04:12:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The choice of ML modeling library does not matter]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25031356">thread link</a>) | @chmaynard
<br/>
November 8, 2020 | https://www.shreya-shankar.com/modeling-libraries/ | <a href="https://web.archive.org/web/*/https://www.shreya-shankar.com/modeling-libraries/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When building the first machine learning pipelines for my company, I agonized over which modeling libraries to include in our stack. What would most model developers want to use? I felt strongly about scikit-learn and PyTorch, but what would be the consequences of imposing my opinions on ML frameworks on our company’s infrastructure? Which modeling library would “win” in the long-term? What if I wrote modeling code in a DSL that would become obsolete in a few years?</p>
<p>In 2016, I took an introductory deep learning class with assignments all in Tensorflow; my most recent deep learning course was completely conducted in PyTorch. Four years later, <a href="https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/">it seems like all ML researchers I know use PyTorch</a>. The few who don’t use PyTorch use TF 1.0, with the “some day I’ll switch to TF 2.0 or PyTorch” mantra. What happened?</p>
<p>Over several months, I realized that <strong>the choice of library does not matter, as modeling is just a tiny step in the machine learning pipeline.</strong> Other steps are equally, if not more, challenging to maintain: for example, <a href="https://www.oracle.com/technetwork/middleware/oedq/successful-data-migration-wp-1555708.pdf">it is much harder to migrate data pipeline code</a> than rewrite basic TF modeling code in PyTorch. I’ve written models in TensorFlow, PyTorch, XGBoost, scikit-learn, and LightGBM for different tasks for my company. I’ve even written non-Python models in Scala. When I iterate on machine learning pipelines for a prediction task, I avoid changing the model architectures as much as possible since <a href="https://www.shreya-shankar.com/making-ml-work/">I’d rather change parts of the pipeline I understand better</a>, like data ingestion and better featurization. My company’s pull requests show that people hardly touch their modeling code compared to pipeline code. What matters is having the infrastructure to “plug and play” ML model trainers and predictors, since there is almost never one programming library that meets all needs. </p>
<p>Some would point to the trends of researchers overwhelmingly preferring PyTorch and JAX and argue that a winner here actually does matter, because researchers turn into data scientists at companies, these data scientists build models, and the models will get productionized and used “forever.” But as a field, we’re still struggling with productionizing models, aligning their outputs with human incentives, iterating on these systems, and trusting these pipelines. For any ML practitioners outside “big tech,” their biggest problems are model pipelines and value alignment between customers, themselves, and machines. After all, these are essential to product development. Even if we built frameworks for these central problems, the modeling library still won’t matter because <a href="https://softwareengineering.stackexchange.com/a/390687">multiple software frameworks for a problem can happily coexist</a>. People are smart and can easily learn a different framework — the fact that there was such a large, rapid <a href="https://www.quora.com/Why-are-people-shifting-from-TensorFlow-to-PyTorch">transition from TensorFlow to PyTorch</a> within a few years proves that developers will find the best tool for their job. It matters more that they have the correct foundation for software they build.</p>
<p>Additionally, business considerations can override the choice of framework or even build new frameworks, particularly in startups. My company’s codebase for a particular ML problem has experienced something in this vein: first, I wrote experimental code in my DSLs of choice to “solve” the problem. Then when we had to build a product, I <a href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/">rewrote</a> the pipeline. Then when we pivoted slightly, I <a href="https://refactoring.com/">refactored</a> the pipeline to produce the live ML product we’re regularly releasing today. As I gained more clarity on the current version of the product and how other stakeholders (technical or nontechnical) might interact with it, I realized these business considerations drove pipeline development more than the modeling libraries or my opinions on other DSLs.</p>
<p>So the horse race of modeling libraries is misleading, and the most challenging problems in “real-world” ML right now revolve around business values, productionization, miniaturization, and pipelining for repeated training and inference. But since <a href="https://www.cs.princeton.edu/courses/archive/fall09/cos109/06langs.pdf">programming languages</a> and infrastructure <a href="https://www.forbes.com/sites/oracle/2015/05/20/javas-20-years-of-innovation">drive innovation in software</a>, it’s still worth thinking about the evolution of modeling libraries. In <a href="https://www.amazon.com/Mythical-Man-Month-Software-Engineering-Anniversary/dp/0201835959">The Mythical Man-Month: Essays on Software Engineering</a>, Fred Brooks introduces the concept of the <em><a href="https://en.wikipedia.org/wiki/Second-system_effect">second-system effect</a></em> to be “the tendency of small, elegant, and successful systems to be succeeded by over-engineered, bloated systems, due to inflated expectations and overconfidence.” Famous examples include the IBM System/360 operating system (which succeeded the IBM 700/7000 series from the 1950s), and the Multics operating system (which succeeded Compatible Time-Sharing System from the late 1960s). </p>
<p>I consider TF 1.0 a success: it accelerated a lot of deep learning research, was fairly narrow and thoughtful in scope, and spearheaded innovation in the hardware vertical with XLA compilation, TPUs, and more. But over time, as hundreds of TensorFlow engineers tried to address the software’s limitations and turn TensorFlow into a machine learning library for everybody, it suffered from the second-system effect and became TF 2.0, a machine learning library for nobody (possibly except for Google). One set of problems they tried to address is “making models work in production settings:” TFX is a great example of an <a href="https://blog.tensorflow.org/2020/09/brief-history-of-tensorflow-extended-tfx.html">overhyped</a> and <a href="https://pypistats.org/packages/tfx">underused</a> TF 2.0 tool. Compare the PyPI stats with <a href="https://pypistats.org/packages/kfp">Kubeflow</a>’s for context; TFX built their framework to fit nicely with Kubeflow and Kubeflow users still don’t want to use TFX. This is not to say the problems with production ML aren’t real; rather, it seems TFX currently isn’t <em>the</em> solution to many of these incredibly challenging problems. Having tutorials doesn’t help if the <a href="https://neptune.ai/blog/deep-dive-into-ml-models-in-production-using-tfx-and-kubeflow">UX is counterintuitive and engineers need to become professional error log parsers</a> to become proficient with the tool.</p>
<p>All this being said about my criticism for the TensorFlow UX, I actually use TF 2.0 at work — mainly out of laziness. The Spark to TFRecord to TFData to TF model pipeline is <a href="https://github.com/tensorflow/ecosystem/tree/master/spark/spark-tensorflow-connector">partially</a> <a href="https://docs.databricks.com/applications/machine-learning/load-data/tfrecords-save-load.html">documented</a>, whereas the Spark to TFRecord to something to PyTorch model pipeline is only <a href="https://github.com/uber/petastorm">barely</a> <a href="https://databricks.com/blog/2020/06/16/simplify-data-conversion-from-apache-spark-to-tensorflow-and-pytorch.html">documented</a>. But the DSL for my models is hardly something I think about on a day-to-day basis, since most of my problems aren’t “how quickly can I code up a transformer or convnet architecture from scratch.” People in this industry rarely build things from scratch. Software products are built on the <a href="https://effectivesoftwaredesign.com/2014/11/02/the-minimum-viable-product-and-incremental-software-development/">principle of incrementality</a>; code and features accumulate over time. </p>
<p>So my answer to my original question is that it’s not worth worrying about which modeling library will “win” in the long run, because <strong>multiple libraries can win if they each do something important</strong>, such as championing the dataflow paradigm or easy autodifferentiation. If you’re an engineer, don’t build your pipelines around a specific modeling library. If you’re a researcher or data scientist, don’t worry about learning all the modeling libraries or whatever libraries the company’s job description mentions. Software history indicates that the modeling framework bloat is inevitable, and for as long as these libraries’ biggest priorities are to compete with each other, they will all converge to the same solutions to mission-critical modeling problems — <a href="https://ai.googleblog.com/2017/10/eager-execution-imperative-define-by.html">eager execution</a>, ease of <a href="https://www.tensorflow.org/tutorials/quickstart/beginner">building a model from scratch</a>, ability to <a href="https://pytorch-lightning.readthedocs.io/en/latest/loggers.html">nicely view loss curves</a>, and more. But these are only a fraction of most “real-world” machine learning problems, and you, as a machine learning practitioner, at the end of the day aren’t hired only for your expertise in training a model once; you’re hired to make a machine learning system consistently deliver value to an end user.</p>
<p><em>Thanks to <a href="https://people.eecs.berkeley.edu/~pathakr/">Reese Pathak</a>, <a href="https://www.linkedin.com/in/jayant-bhambhani-31b71821/">Jay Bhambhani</a> and <a href="https://twitter.com/debnilsur">Debnil Sur</a> for their feedback on multiple drafts.</em></p></div></div>]]>
            </description>
            <link>https://www.shreya-shankar.com/modeling-libraries/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031356</guid>
            <pubDate>Mon, 09 Nov 2020 04:04:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 The Biden-Harris plan to beat Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25031354">thread link</a>) | @hkhn
<br/>
November 8, 2020 | https://buildbackbetter.com/priorities/covid-19/ | <a href="https://web.archive.org/web/*/https://buildbackbetter.com/priorities/covid-19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	

		<section id="content">

	  
<div data-module="">
  <div>
	<div>
	  <p><span>The American people deserve an urgent, robust, and professional response to the growing public health and economic crisis caused by the coronavirus (COVID-19) outbreak. President-elect Biden believes that the federal government must act swiftly and aggressively to help protect and support our families, small businesses, first responders, and caregivers essential to help us face this challenge, those who are most vulnerable to health and economic impacts, and our broader communities – not to blame others or bail out corporations. </span></p>
	</div>
  </div>
</div>

<div data-module="" id="covid-19-2" data-new-section="false" data-id="covid-19-2">
  <div>
	<div>
	  <div>
	   <p>The Biden-Harris administration will always:</p>
<ul>
<li><strong>Listen to science</strong></li>
<li><strong>Ensure public health decisions are informed by public health professionals</strong></li>
<li><strong>Promote trust, transparency, common purpose, and accountability in our government</strong></li>
</ul>
<p>President-elect Biden and Vice President-elect Harris have a seven-point plan to beat COVID-19.</p>
<p><strong>Ensure all Americans have access to regular, reliable, and free testing.</strong></p>
<ul>
<li>Double the number of drive-through testing sites.</li>
<li>Invest in next-generation testing, including at home tests and instant tests, so we can scale up our testing capacity by orders of magnitude.</li>
<li>Stand up a Pandemic Testing Board like Roosevelt’s War Production Board. It’s how we produced tanks, planes, uniforms, and supplies in record time, and it’s how we will produce and distribute tens of millions of tests.</li>
<li>Establish a U.S. Public Health Jobs Corps to mobilize at least 100,000 Americans across the country with support from trusted local organizations in communities most at risk to perform culturally competent approaches to contact tracing and protecting at-risk populations.</li>
</ul>
<p><strong>Fix personal protective equipment (PPE) problems for good.</strong></p>
<p>President-elect Joe Biden is taking responsibility and giving states, cities, tribes, and territories the critical supplies they need.</p>
<ul>
<li>Fully use the Defense Production Act to ramp up production of masks, face shields, and other PPE so that the national supply of personal protective equipment exceeds demand and our stores and stockpiles — especially in hard-hit areas that serve disproportionately vulnerable populations — are fully replenished.</li>
<li>Build immediately toward a future, flexible American-sourced and manufactured capability to ensure we are not dependent on other countries in a crisis.</li>
</ul>
<p><strong>Provide clear, consistent, evidence-based guidance for how communities should navigate the pandemic – and the resources for schools, small businesses, and families to make it through.</strong></p>
<ul>
<li>Social distancing is not a light switch. It is a dial. President-elect Biden will direct the CDC to provide specific evidence-based guidance for how to turn the dial up or down relative to the level of risk and degree of viral spread in a community, including when to open or close certain businesses, bars, restaurants, and other spaces; when to open or close schools, and what steps they need to take to make classrooms and facilities safe; appropriate restrictions on size of gatherings; when to issue stay-at-home restrictions.</li>
<li>Establish a renewable fund for state and local governments to help prevent budget shortfalls, which may cause states to face steep cuts to teachers and first responders.</li>
<li>Call on Congress to pass an emergency package to ensure schools have the additional resources they need to adapt effectively to COVID-19.</li>
<li>Provide a “restart package” that helps small businesses cover the costs of operating safely, including things like plexiglass and PPE.</li>
</ul>
	  </div>
	</div>
  </div>
</div>

<!-- .module.block-quote -->

<div data-module="" id="covid-19-4" data-new-section="false" data-id="covid-19-4">
  <div>
	<div>
	  <div>
	   <p><strong>Plan for the effective, equitable distribution of treatments and vaccines — because development isn’t enough if they aren’t effectively distributed.</strong></p>
<ul>
<li>Invest $25 billion in a vaccine manufacturing and distribution plan that will guarantee it gets to every American, cost-free.</li>
<li>Ensure that politics plays no role in determining the safety and efficacy of any vaccine. The following 3 principles will guide the Biden-Harris administration: Put scientists in charge of all decisions on safety and efficacy; publicly release clinical data for any vaccine the FDA approves; and authorize career staff to write a written report for public review and permit them to appear before Congress and speak publicly uncensored.</li>
<li>Ensure everyone — not just the wealthy and well-connected — in America receives the protection and care they deserve, and consumers are not price gouged as new drugs and therapies come to market.</li>
</ul>
<p><strong>Protect older Americans and others at high risk.</strong></p>
<p>President-elect Biden understands that older Americans and others at high-risk are most vulnerable to COVID-19.</p>
<ul>
<li>Establish a COVID-19 Racial and Ethnic Disparities Task Force, as proposed by Vice President-elect Harris, to provide recommendations and oversight on disparities in the public health and economic response. At the end of this health crisis, it will transition to a permanent Infectious Disease Racial Disparities Task Force.</li>
<li>Create the Nationwide Pandemic Dashboard that Americans can check in real-time to help them gauge whether local transmission is actively occurring in their zip codes. This information is critical to helping all individuals, but especially older Americans and others at high risk, understand what level of precaution to take.</li>
</ul>
<p><strong>Rebuild and expand defenses to predict, prevent, and mitigate pandemic threats, including those coming from China.</strong></p>
<ul>
<li>Immediately restore the White House National Security Council Directorate for Global Health Security and Biodefense, originally established by the Obama-Biden administration.</li>
<li>Immediately restore our relationship with the World Health Organization, which — while not perfect — is essential to coordinating a global response during a pandemic.</li>
<li>Re-launch and strengthen U.S. Agency for International Development’s pathogen-tracking program called PREDICT.</li>
<li>Expand the number of CDC’s deployed disease detectives so we have eyes and ears on the ground, including rebuilding the office in Beijing.</li>
</ul>
<p><strong>Implement mask mandates nationwide by working with governors and mayors and by asking the American people to do what they do best: step up in a time of crisis.</strong></p>
<p>Experts agree that tens of thousands of lives can be saved if Americans wear masks. President-elect Biden will continue to call on:</p>
<ul>
<li>Every American to wear a mask when they are around people outside their household.</li>
<li>Every Governor to make that mandatory in their state.</li>
<li>Local authorities to also make it mandatory to buttress their state orders.</li>
</ul>
<p>Once we succeed in getting beyond this pandemic, we must ensure that the millions of Americans who suffer long-term side effects from COVID don’t face higher premiums or denial of health insurance because of this new pre-existing condition. The Biden-Harris Administration will work to ensure that the protections for those with pre-existing conditions that were won with Obamacare are protected. And, they will work to lower health care costs and expand access to quality, affordable health care through a Medicare-like public option.</p>
	  </div>
	</div>
  </div>
</div>



	</section>

  </article></div>]]>
            </description>
            <link>https://buildbackbetter.com/priorities/covid-19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031354</guid>
            <pubDate>Mon, 09 Nov 2020 04:04:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A fun website that simulates fluid]]>
            </title>
            <description>
<![CDATA[
Score 309 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25031304">thread link</a>) | @svikashk
<br/>
November 8, 2020 | https://paveldogreat.github.io/WebGL-Fluid-Simulation/ | <a href="https://web.archive.org/web/*/https://paveldogreat.github.io/WebGL-Fluid-Simulation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <p>Try Fluid Simulation app!</p>
                        <p><a id="apple_link" target="_blank">
                                <img alt="Download on the App Store" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/app_badge.png">
                            </a>
                            <a id="google_link" target="_blank">
                                <img alt="Get it on Google Play" src="https://paveldogreat.github.io/WebGL-Fluid-Simulation/gp_badge.png">
                            </a>
                        </p>
                    </div></div>]]>
            </description>
            <link>https://paveldogreat.github.io/WebGL-Fluid-Simulation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031304</guid>
            <pubDate>Mon, 09 Nov 2020 03:54:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Where were you when the US election was called? A map of the stars]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25031179">thread link</a>) | @juanre
<br/>
November 8, 2020 | https://greaterskies.com/free-map/harris-2020 | <a href="https://web.archive.org/web/*/https://greaterskies.com/free-map/harris-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-21cede04=""><div><h2>About your star map</h2> <p>It is an accurate image of the sky as seen from a particular place and time, including thousands of stars, the Moon, the Sun and the planets.</p> <p>We have been making these maps since 2006, and are proud to make the very best available.  You can learn more about them
      <a href="https://greaterskies.com/star-map/" target="_blank">here</a>.</p> <p>We really hope you will love it!</p> <p>The GreaterSkies team</p></div></div></div>]]>
            </description>
            <link>https://greaterskies.com/free-map/harris-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031179</guid>
            <pubDate>Mon, 09 Nov 2020 03:25:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SSH Tunneling Basics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25031064">thread link</a>) | @bswamina
<br/>
November 8, 2020 | https://www.polarsparc.com/xhtml/SSH-Tunnel.html | <a href="https://web.archive.org/web/*/https://www.polarsparc.com/xhtml/SSH-Tunnel.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <br>
    
    <br>
    
    
    <hr> 
    <p>Overview</p>
    <p>In networking, a <span>Tunnel</span> is used to encapsulate a communication protocol that is not supported
        by the network inside a protocol that is supported by the network.</p>
    <p>The following are some of terms used in this article:</p>
    <table id="col2-table">
      <thead>
        <tr>
          <th>Term</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><span>SSH</span></td>
          <td>short for <span>S</span>ecure <span>SH</span>ell is a protocol that sets
            up an encrypted connection between two nodes over an unsecured network using a Client-Server architecture</td>
        </tr>
        <tr>
          <td><span>SSH Server</span></td>
          <td>a server that listens on the TCP port <span>22</span> for incoming SSH client
            requests, then authenticates those client requests, and provides a command prompt</td>
        </tr>
        <tr>
          <td><span>SSH Client</span></td>
          <td>a client used to connect to the remote SSH Server on a specific network node</td>
        </tr>
        <tr>
          <td><span>SSH Tunnel</span></td>
          <td>a method of encapsulating and transmitting arbitrary networking data over an encrypted SSH
            connection between a client node and a server node</td>
        </tr>
        <tr>
          <td><span>SSH Port Forwarding</span></td>
          <td>another name for <span>SSH Tunnel</span></td>
        </tr>
      </tbody>
    </table>
    <div id="para-div">
      <p>So, why do we need <span>tunneling</span> ??? The following are some of the reasons:</p>
      <ul id="blue-sqr-ul">
        <li>
          <p>To allow access to legacy applications or unsecure services such as IMAP, POP3, VNC, etc</p>
        </li>
        <li>
          <p>To implement a virtual private network (<span>VPN</span>)</p>
        </li>
        <li>
          <p>To allow access to services behind a firewall</p>
        </li>
      </ul>
    </div>
    <div id="para-div">
      <p>There are <span>3</span> types of <span>SSH Tunnel</span> options as listed below:</p>
      <ol id="blue-ol">
        <li>
          <p><span>Local</span> Port Forwarding</p>
        </li>
        <li>
          <p><span>Remote</span> Port Forwarding</p>
        </li>
        <li>
          <p><span>Dynamic</span> Port Forwarding</p>
        </li>
      </ol>
    </div>
    <p>We will discuss and demonstrate each of the above options in the following sections.</p>
    <p>Setup</p>
    <p>The setup will be on a Ubuntu 20.04 LTS based Linux desktop. For the demonstrations, we will create an environment with
        3 virtual machines running on the hypervisor <span>VirtualBox</span>.</p>
    <p>The following diagram illustrates the environment setup:</p>
    <div id="img-outer-div"> <p><img src="https://www.polarsparc.com/xhtml/images/ssh-tunnel-2.png" alt="Environment"></p><p>Environment</p>
    </div>
    <br>
    <div id="para-div">
      <p>The following are some of the highlights of the 3 virtual machines:</p>
      <ul id="blue-sqr-ul">
        <li>
          <p><span>vm-1</span> :: 1 vCPU, 2GB RAM, 20GB storage, Ubuntu 20.04 OS, and uses a single virtual network
            interface with <span>NAT</span> networking (<span>10.0.2.15</span>)</p>
        </li>
        <li>
          <p><span>vm-2</span> :: 1 vCPU, 2GB RAM, 20GB storage, Ubuntu 20.04 OS, and uses a single virtual network
            interface with <span>Host-only</span> networking (<span>192.168.56.104</span>)</p>
        </li>
        <li>
          <p><span>vm-3</span> :: 1 vCPU, 2GB RAM, 20GB storage, Ubuntu 20.04 OS, and uses a two separate virtual
            network interfaces - one with <span>NAT</span> networking (<span>10.0.2.4</span>) and the
            other with <span>Host-only</span> networking (<span>192.168.56.103</span>)</p>
        </li>
      </ul>
    </div>
    <p>Open a Terminal window in each of the 3 virtual machines <span>vm-1</span> thru <span>vm-3</span>
        and install <span>Python Flask</span>, <span>Net Tools</span>, and <span>SSH Server
        </span> by executing the following command:</p>
    <p>$ sudo apt install python3-flask net-tools openssh-server -y</p>
    <p>The following would be a typical output:</p>
    <div id="out-div">
      <h4>Output.1</h4>
      <pre>Reading package lists... Done
Building dependency tree       
Reading state information... Done
The following additional packages will be installed:
  javascript-common libjs-jquery ncurses-term openssh-sftp-server python3-itsdangerous python3-jinja2 python3-markupsafe
  python3-openssl python3-pyinotify python3-werkzeug ssh-import-id
Suggested packages:
  apache2 | lighttpd | httpd molly-guard monkeysphere ssh-askpass python-flask-doc python-jinja2-doc python-openssl-doc
  python3-openssl-dbg python-pyinotify-doc ipython3 python-werkzeug-doc python3-lxml python3-termcolor python3-watchdog
The following NEW packages will be installed:
  javascript-common libjs-jquery ncurses-term net-tools openssh-server openssh-sftp-server python3-flask python3-itsdangerous
  python3-jinja2 python3-markupsafe python3-openssl python3-pyinotify python3-werkzeug ssh-import-id
0 upgraded, 14 newly installed, 0 to remove and 0 not upgraded.
Need to get 1,478 kB of archives.
After this operation, 9,096 kB of additional disk space will be used.
Get:1 http://us.archive.ubuntu.com/ubuntu focal/main amd64 javascript-common all 11 [6,066 B]
Get:2 http://us.archive.ubuntu.com/ubuntu focal/main amd64 libjs-jquery all 3.3.1~dfsg-3 [329 kB]
Get:3 http://us.archive.ubuntu.com/ubuntu focal/main amd64 ncurses-term all 6.2-0ubuntu2 [249 kB]
Get:4 http://us.archive.ubuntu.com/ubuntu focal/main amd64 net-tools amd64 1.60+git20180626.aebd88e-1ubuntu1 [196 kB]
Get:5 http://us.archive.ubuntu.com/ubuntu focal-updates/main amd64 openssh-sftp-server amd64 1:8.2p1-4ubuntu0.1 [51.5 kB]
Get:6 http://us.archive.ubuntu.com/ubuntu focal-updates/main amd64 openssh-server amd64 1:8.2p1-4ubuntu0.1 [377 kB]
Get:7 http://us.archive.ubuntu.com/ubuntu focal/main amd64 python3-itsdangerous all 1.1.0-1 [14.6 kB]
Get:9 http://us.archive.ubuntu.com/ubuntu focal/main amd64 python3-markupsafe amd64 1.1.0-1build2 [13.9 kB]
Get:9 http://us.archive.ubuntu.com/ubuntu focal/main amd64 python3-jinja2 all 2.10.1-2 [95.5 kB]
Get:10 http://us.archive.ubuntu.com/ubuntu focal/main amd64 python3-werkzeug all 0.16.1+dfsg1-2 [183 kB]
Get:11 http://us.archive.ubuntu.com/ubuntu focal/main amd64 python3-flask all 1.1.1-2 [80.3 kB]
Get:12 http://us.archive.ubuntu.com/ubuntu focal/main amd64 python3-openssl all 19.0.0-1build1 [43.3 kB]
Get:13 http://us.archive.ubuntu.com/ubuntu focal/main amd64 python3-pyinotify all 0.9.6-1.2ubuntu1 [24.8 kB]
Get:14 http://us.archive.ubuntu.com/ubuntu focal/main amd64 ssh-import-id all 5.10-0ubuntu1 [10.0 kB]
Fetched 1,478 kB in 0s (5,095 kB/s)  
Preconfiguring packages ...
Selecting previously unselected package javascript-common.
(Reading database ... 192970 files and directories currently installed.)
Preparing to unpack .../00-javascript-common_11_all.deb ...
Unpacking javascript-common (11) ...
Selecting previously unselected package libjs-jquery.
Preparing to unpack .../01-libjs-jquery_3.3.1~dfsg-3_all.deb ...
Unpacking libjs-jquery (3.3.1~dfsg-3) ...
Selecting previously unselected package ncurses-term.
Preparing to unpack .../02-ncurses-term_6.2-0ubuntu2_all.deb ...
Unpacking ncurses-term (6.2-0ubuntu2) ...
Preparing to unpack .../net-tools_1.60+git20180626.aebd88e-1ubuntu1_amd64.deb ...
Unpacking net-tools (1.60+git20180626.aebd88e-1ubuntu1) ...
Selecting previously unselected package openssh-sftp-server.
Preparing to unpack .../03-openssh-sftp-server_1%3a8.2p1-4ubuntu0.1_amd64.deb ...
Unpacking openssh-sftp-server (1:8.2p1-4ubuntu0.1) ...
Selecting previously unselected package openssh-server.
Preparing to unpack .../04-openssh-server_1%3a8.2p1-4ubuntu0.1_amd64.deb ...
Unpacking openssh-server (1:8.2p1-4ubuntu0.1) ...
Selecting previously unselected package python3-itsdangerous.
Preparing to unpack .../05-python3-itsdangerous_1.1.0-1_all.deb ...
Unpacking python3-itsdangerous (1.1.0-1) ...
Selecting previously unselected package python3-markupsafe.
Preparing to unpack .../06-python3-markupsafe_1.1.0-1build2_amd64.deb ...
Unpacking python3-markupsafe (1.1.0-1build2) ...
Selecting previously unselected package python3-jinja2.
Preparing to unpack .../07-python3-jinja2_2.10.1-2_all.deb ...
Unpacking python3-jinja2 (2.10.1-2) ...
Selecting previously unselected package python3-werkzeug.
Preparing to unpack .../08-python3-werkzeug_0.16.1+dfsg1-2_all.deb ...
Unpacking python3-werkzeug (0.16.1+dfsg1-2) ...
Selecting previously unselected package python3-flask.
Preparing to unpack .../09-python3-flask_1.1.1-2_all.deb ...
Unpacking python3-flask (1.1.1-2) ...
Selecting previously unselected package python3-openssl.
Preparing to unpack .../10-python3-openssl_19.0.0-1build1_all.deb ...
Unpacking python3-openssl (19.0.0-1build1) ...
Selecting previously unselected package python3-pyinotify.
Preparing to unpack .../11-python3-pyinotify_0.9.6-1.2ubuntu1_all.deb ...
Unpacking python3-pyinotify (0.9.6-1.2ubuntu1) ...
Selecting previously unselected package ssh-import-id.
Preparing to unpack .../12-ssh-import-id_5.10-0ubuntu1_all.deb ...
Unpacking ssh-import-id (5.10-0ubuntu1) ...
Setting up javascript-common (11) ...
Setting up net-tools (1.60+git20180626.aebd88e-1ubuntu1) ...
Setting up openssh-sftp-server (1:8.2p1-4ubuntu0.1) ...
Setting up openssh-server (1:8.2p1-4ubuntu0.1) ...
Creating config file /etc/ssh/sshd_config with new version
Creating SSH2 RSA key; this may take some time ...
3072 SHA256:OVmIaDeM2PCBtB6O5tddPIC3q4nuZVdqfcs/7A3QM5A root@vm-3 (RSA)
Creating SSH2 ECDSA key; this may take some time ...
256 SHA256:qDrGgauXE9LwZ6S1j4fjbY0LIPyrL+YSU8iq+PbR7jM root@vm-3 (ECDSA)
Creating SSH2 ED25519 key; this may take some time ...
256 SHA256:WBk+gqOXD47VoAJrw+JeZLxQlzBWdaKFRxi5xfPAkYg root@vm-3 (ED25519)
Created symlink /etc/systemd/system/sshd.service â†’ /lib/systemd/system/ssh.service.
Created symlink /etc/systemd/system/multi-user.target.wants/ssh.service â†’ /lib/systemd/system/ssh.service.
rescue-ssh.target is a disabled or a static unit, not starting it.
Setting up python3-openssl (19.0.0-1build1) ...
Setting up ssh-import-id (5.10-0ubuntu1) ...
Attempting to convert /etc/ssh/ssh_import_id
Setting up python3-pyinotify (0.9.6-1.2ubuntu1) ...
Setting up python3-itsdangerous (1.1.0-1) ...
Setting up python3-markupsafe (1.1.0-1build2) ...
Setting up python3-jinja2 (2.10.1-2) ...
Setting up libjs-jquery (3.3.1~dfsg-3) ...
Setting up ncurses-term (6.2-0ubuntu2) ...
Setting up python3-werkzeug (0.16.1+dfsg1-2) ...
Setting up python3-flask (1.1.1-2) ...
Processing triggers for systemd (245.4-4ubuntu3.3) ...
Processing triggers for man-db (2.9.1-1) ...
Processing triggers for ufw (0.36-6) ...</pre>
    </div>
    <p>Local Port Forwarding</p>
    <p>Assuming <span>vm-3</span> is hosting a useful web application on <span>10.0.2.4</span>, it is
        *ONLY* accessible within the <span>10.0.2.x</span> network. What if a client on the <span>
        vm-2</span> wants to access the web application ???</p>
    <p>In this situation, one could use Local Port Forwarding SSH Tunnel option to allow the client <span>vm-2</span>
        running on <span>192.168.56.104</span> to access the web application server running on the
        <span>10.0.2.x</span> network.</p>
    <p>The following is the code for the simple <span>Python</span> based web application:</p>
    <fieldset id="sc-fieldset"> <legend>Web.py</legend>
      <pre>import sys
from datetime import datetime
from flask …</pre></fieldset></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.polarsparc.com/xhtml/SSH-Tunnel.html">https://www.polarsparc.com/xhtml/SSH-Tunnel.html</a></em></p>]]>
            </description>
            <link>https://www.polarsparc.com/xhtml/SSH-Tunnel.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25031064</guid>
            <pubDate>Mon, 09 Nov 2020 03:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Program Development in Limbo for Inferno OS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25030961">thread link</a>) | @marttt
<br/>
November 8, 2020 | https://seh.dev/limbo-intro/ | <a href="https://web.archive.org/web/*/https://seh.dev/limbo-intro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    <div>
<h2 id="motivation">Motivation</h2>
<p>Resources covering software development under Inferno are fairly scarce.</p>
<p>As such, this post aims to provide a start-to-finish demonstration of program development in Limbo inside Inferno.</p>
<h2 id="introduction">Introduction</h2>
<p>This post assumes you’re using Inferno, specifically <a href="https://code.9front.org/hg/purgatorio/">purgatorio</a>, hosted under <code>linux/amd64</code> or similar.</p>
<p>It’s also possible to use Inferno under Docker as per the <code>INSTALL</code> file.</p>
<p>Other platforms are supported, but steps may differ here or there.</p>
<p>The rune <code>$</code> indicates a unix shell command under <code>bash</code>, probably.</p>
<p>The rune <code>;</code> or <code>%</code> indicates a command to be run from inside Inferno.</p>
<p>The final source from this post: <a href="https://github.com/henesy/socketh-limbo">https://github.com/henesy/socketh-limbo</a></p>
<p>This post will be an implementation of <a href="https://github.com/henesy/SocketH">SocketH</a> which was originally written in Go and has a few other implementations:</p>
<ul>
<li><a href="https://github.com/henesy/socketh-myr">https://github.com/henesy/socketh-myr</a></li>
<li><a href="https://github.com/henesy/SocketS">https://github.com/henesy/SocketS</a></li>
</ul>
<p>The original code isn’t great, but it gives a target for what we want to create.</p>
<h2 id="getting-started">Getting started</h2>
<p>Many, if not all, of these development steps prior to <em>running</em> the final Dis bytecode can be done from outside of Inferno.</p>
<p>The limbo compiler can be called as <code>limbo</code> and with the right workflow development may be more pleasant.</p>
<p>This post assumes:</p>
<ul>
<li>Development occurs inside of Inferno for the purpose of consistency</li>
<li>Some knowledge about imperative, C-like, language programming</li>
<li>Some knowledge about how unix-like systems work</li>
<li>Some knowledge about how C-like compiler and linker flows work</li>
<li>Knowledge about how to interact with a unix-like shell</li>
<li>Vague knowledge about Inferno, such as the fact Inferno exists ☺</li>
</ul>
<h3 id="build-inferno">Build Inferno</h3>
<p>Steps provided are targeted for <code>linux/amd64</code> as a host for Inferno.</p>
<p>The official <a href="https://bitbucket.org/inferno-os/inferno-os/">Inferno</a> tree is hosted over <a href="https://git-scm.com/">Git</a>.</p>
<p>The <a href="https://code.9front.org/hg/purgatorio/">purgatorio</a> fork is hosted by the 9front project over <a href="https://www.mercurial-scm.org/">Mercurial</a>.</p>
<p>Cloning:</p>
<div><pre><code data-lang="text">$ hg clone https://code.9front.org/hg/purgatorio
destination directory: purgatorio
requesting all changes
adding changesets
adding manifests
adding file changes
added 86 changesets with 10904 changes to 10545 files
new changesets 78950db8e089:749c484c1b9c
updating to branch default
9584 files updated, 0 files merged, 0 files removed, 0 files unresolved
$ cd purgatorio/
$ ls
acme                     FreeBSD  libdynld     libprefab      mkfile       scripts
AIX                      icons    libfreetype  libsec         mkfiles      services
appl                     include  libinterp    libtk          module       Solaris
bitbucket-pipelines.yml  Inferno  libkern      limbo          NetBSD       tools
CHANGES                  INSTALL  libkeyring   Linux          NOTICE       usr
dis                      Irix     liblogfs     locale         Nt           utils
doc                      keydb    libmath      MacOSX         OpenBSD
Dockerfile               lib      libmemdraw   makemk-AIX.sh  os
DragonFly                lib9     libmemlayer  makemk.sh      Plan9
emu                      libbio   libmp        man            POSTINSTALL
fonts                    libdraw  libnandfs    mkconfig       README.md
$
</code></pre></div><p><strong>Read the</strong> <code>INSTALL</code> <strong>file!</strong></p>
<p>Update our <code>$HOME/.profile</code> to reflect the Inferno install, adapt this to your directories:</p>
<div><pre><code data-lang="text">export EMU='-g1280x960 -c1'
export INFERNO=$HOME/repos/purgatorio
export PATH=$PATH:$INFERNO/Linux/386/bin
</code></pre></div><p>Reload our shell currently in the purgatorio root tree:</p>
<div><pre><code data-lang="text">$ source $HOME/.profile
$
</code></pre></div><p>Update the <code>mkconfig</code> file to reflect our environment, adapt this as needed:</p>
<div><pre><code data-lang="text">ROOT=$HOME/repos/purgatorio

TKSTYLE=std

CONF=emu

SYSHOST=Linux		# build system OS type (Hp, Inferno, Irix, Linux, MacOSX, Nt, Plan9, Solaris)
SYSTARG=$SYSHOST	# target system OS type (Hp, Inferno, Irix, Linux, Nt, Plan9, Solaris)

OBJTYPE=386

OBJDIR=$SYSTARG/$OBJTYPE

&lt;$ROOT/mkfiles/mkhost-$SYSHOST			# variables appropriate for host system
&lt;$ROOT/mkfiles/mkfile-$SYSTARG-$OBJTYPE	# variables used to build target object type
</code></pre></div><p>Enable multi-arch support on debian-based distributions if on amd64 (64-bit) as Inferno is 32-bit only:</p>
<div><pre><code data-lang="text">$ dpkg --add-architecture i386
$ apt-get update
</code></pre></div><p>Install dependencies required to compile Inferno, this example shows dependencies for debian-based (Ubuntu) distributions:</p>
<div><pre><code data-lang="text">$ apt install libc6-dev-i386 libxext6:i386 libx11-dev:i386 libxext-dev:i386 libfontconfig1-dev:i386
…
$
</code></pre></div><p>Build <code>mk</code> which will be used to bootstrap the rest of the process:</p>
<p>Build and install Inferno!</p>
<div><pre><code data-lang="text">$ mk mkdirs
…
$ mk clean
…
$ mk install
…
$
</code></pre></div><h3 id="start-inferno">Start Inferno</h3>
<p>A graphical environment should appear.</p>
<p>You can make the gui window for Inferno larger by passing in a different size to <code>emu</code> as per <a href="http://man.postnix.pw/purgatorio/1/emu">the manual</a>:</p>
<div><pre><code data-lang="text">-gXsizexYsize
	Define screen width and height in pixels.  The default
	values are 640x480 and the minimum values are 64x48.
	Values smaller than the minimum or greater than the
	available display size are ignored.
</code></pre></div><p>thus:</p>
<p>and so forth.</p>
<p>Some programs can be found under the start menu in the bottom left corner decorated with the <a href="https://seh.dev/limbo-intro/vitanuova.com/">Vita Nuova</a> logo:</p>
<p><img src="http://www.vitanuova.com/images/vitanuova.jpg" alt="Vita Nuova’s logo"></p>
<p>The <code>Shell</code> entry in the start menu will provide a shell-interpreter window from which further commands can be run inside Inferno.</p>
<h3 id="preparation">Preparation</h3>
<div><pre><code data-lang="text">% cd $home/appl
% os git clone https://github.com/henesy/socketh-limbo
% cd socketh-limbo
% lc
.git/     LICENSE   README.md
% touch .gitignore socketh.b
% acme socketh.b
</code></pre></div><p><code>.gitignore</code>:</p>
<p>Limbo ‘libraries’, known as ‘modules’, and ‘programs’ are one and the same in terms of semantics, bar ‘libraries’ having module <code>.m</code> files which are similar to header <code>.h</code> files in C.</p>
<p>As such, the boilerplate for most Limbo programs is very similar. We can initialize our main file as follows.</p>
<p><code>socketh.b</code>:</p>
<div><pre><code data-lang="c">implement SocketH;

include <span>"sys.m"</span>;
	<span>sys</span>: Sys;

include <span>"draw.m"</span>;
include <span>"arg.m"</span>;

<span>SocketH</span>: module {
	<span>init</span>: fn(<span>nil</span>: ref Draw<span>-&gt;</span>Context, <span>argv</span>: list of string);
};


<span># An implementation of the SocketH chat protocol
</span><span></span>init(<span>nil</span>: ref Draw<span>-&gt;</span>Context, <span>argv</span>: list of string) {
	sys <span>=</span> load Sys Sys<span>-&gt;</span>PATH;
	<span>arg</span> :<span>=</span> load Arg Arg<span>-&gt;</span>PATH;
	<span>if</span>(arg <span>==</span> nil)
		raise <span>"could not load arg"</span>;



	exit;
}
</code></pre></div><p>We can break this down a bit.</p>
<p><code>implement</code> declares a module by name.</p>
<p>A module definition must be provided indicating exported functions from the module:</p>
<div><pre><code data-lang="text">SocketH: module {
	init: fn(nil: ref Draw-&gt;Context, argv: list of string);
};
</code></pre></div><p>Note how a variable name of <code>nil</code> is used to drop assignment of a value.</p>
<p>The <code>init</code> function is special in shell-loaded Limbo programs and its signature <em>must</em> match what the shell expects the init function interface to be.</p>
<p>Functionally, <code>init</code> is equivalent to <code>main</code> in most other languages.</p>
<p><code>include</code> imports an external module’s definitions into our scope.</p>
<p><code>load</code> performs the dynamic loading of a module at runtime.</p>
<p><code>exit</code> performs the dynamic un-loading of a module at runtime.</p>
<p><code>raise</code> will throw an exception with a given string as its content.</p>
<p>We refer to names inside a module using the <code>-&gt;</code> operator.</p>
<p>We can jointly assign and declare in one step using the <code>:=</code> operator.</p>
<p>Curly braces are optional.</p>
<p>Semicolons are not.</p>
<p>Note the absence of a reserved <code>main</code> module. This is due to each <code>.dis</code> file, potentially an independent module, being theoretically loadable in its own right. A reserved name would cause significant issues with namespaces ☺.</p>
<h3 id="setting-up-a-workflow">Setting up a workflow</h3>
<p>Compiling our program should be as straightforward as running the Limbo compiler against our source file:</p>
<div><pre><code data-lang="text">% limbo socketh.b
% lc
.git/		LICENSE		socketh.b
.gitignore	README.md	socketh.dis
% socketh.dis
%
</code></pre></div><p>This program does nothing right now, but that’s fine.</p>
<p>Note how we can omit the <code>./</code> when running <code>.dis</code> programs.</p>
<p>Calling the limbo compiler each time is a bit of a pain, and if we start using commandline flags this will become tedious to type.</p>
<p>In acme, we could type the text we want to run in a tag or window and middle-click said text to run the compilation (or more!) on-demand. In Inferno, acme comes with a <code>Limbo</code> command in the default window tag, but that only works for one file.</p>
<p>We can simplify this process by writing a <s>makefile</s> <a href="http://doc.cat-v.org/bell_labs/mk/">mkfile</a>!</p>
<p><code>mkfile</code>:</p>
<div><pre><code data-lang="text">&lt;/mkconfig

DISBIN = /dis

TARG = socketh.dis

&lt;/mkfiles/mkdis
</code></pre></div><p>Mk semantics are similar to make with some changes.</p>
<p>How mk will behave inside Inferno using the <code>mkdis</code> mkfile as the trailing import:</p>
<ul>
<li>Mk can import outside mkfiles using the <code>&lt;</code> operator</li>
<li><code>mk</code> will call <code>mk all</code> which resolves to the <code>all</code> (default) target</li>
<li><code>mk install</code> calls the <code>all</code> target and copies the <code>TARG</code> file(s) to the <code>DISBIN</code> destination directory</li>
<li><code>mk clean</code> removes files such as <code>.dis</code> and <code>.sbl</code> from the working directory</li>
<li><code>mk nuke</code> calls the <code>clean</code> target as well as delete the ‘target’ files such as the <code>/dis/socketh</code> binary if the <code>install</code> target has been called</li>
</ul>
<p>A demonstration:</p>
<div><pre><code data-lang="text">% lc
.git/		LICENSE		mkfile
.gitignore	README.md	socketh.b
% mk
limbo -I/module -gw socketh.b
socketh.b:15: warning: argument argv not referenced
% lc
.git/		LICENSE		mkfile		socketh.dis
.gitignore	README.md	socketh.b	socketh.sbl
% mk install
rm -f /dis/socketh.dis &amp;&amp; cp socketh.dis /dis/socketh.dis
% mk clean
rm -f *.dis *.sbl
% whatis socketh
/dis/socketh.dis
% mk nuke
rm -f *.dis *.sbl
cd /dis; rm -f socketh.dis
% whatis socketh.dis
socketh.dis: not found
% lc
.git/		LICENSE		mkfile
.gitignore	README.md	socketh.b
%
</code></pre></div><p>Note the Limbo compiler flags being passed by default now for the <code>all</code> target.</p>
<p>At this point, I usually add <code>mk clean &amp;&amp; mk</code> to my acme tag and run that for multi-file or more complex Limbo programs. This flow is very similar to how I do development under Plan 9.</p>
<h3 id="common-patterns">Common patterns</h3>
<h4 id="commandline-flags">Commandline flags</h4>
<p>We can use <a href="https://seh.dev/limbo-intro/man.postnix.pw/purgatorio/2/arg">arg(2)</a> to process commandline flags:</p>
<div><pre><code data-lang="c"><span>…</span>

<span>chatty</span>: <span>int</span>	<span>=</span> <span>0</span>;	<span>#</span> Verbose debug output


<span># An implementation of the SocketH chat protocol
</span><span></span>init(<span>nil</span>: ref Draw<span>-&gt;</span>Context, <span>argv</span>: list of string) {
	sys <span>=</span> load Sys Sys<span>-&gt;</span>PATH;
	<span>arg</span> :<span>=</span> load Arg Arg<span>-&gt;</span>PATH;
	<span>if</span>(arg <span>==</span> nil)
		raise <span>"could not load arg"</span>;

	<span>addr</span>: string <span>=</span> <span>"tcp!*!9090"</span>;

	arg<span>-&gt;</span>init(argv);
	arg<span>-&gt;</span>setusage(<span>"socketh [-D] [-a addr]"</span>);

	<span>while</span>((<span>c</span> :<span>=</span> arg<span>-&gt;</span>opt()) <span>!=</span> <span>0</span>)
		<span>case</span> c {
		<span>'D'</span> <span>=&gt;</span>
			chatty<span>++</span>;

		<span>'a'</span> <span>=&gt;</span>
			addr <span>=</span> arg<span>-&gt;</span>earg();

		<span>*</span> <span>=&gt;</span>
			arg<span>-&gt;</span>usage();
		}

	argv <span>=</span> arg<span>-&gt;</span>argv();



	exit;
}
</code></pre></div><p>We can see how these flags are parsed and how these functions act:</p>
<div><pre><code data-lang="text">% mk
mk: 'all' is up to date
% socketh -h
usage: socketh [-D] [-a addr]
% socketh -D
% socketh -a
usage: socketh [-D] [-a addr]
% socketh -a -D
% socketh -D -a
usage: socketh [-D] [-a …</code></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://seh.dev/limbo-intro/">https://seh.dev/limbo-intro/</a></em></p>]]>
            </description>
            <link>https://seh.dev/limbo-intro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030961</guid>
            <pubDate>Mon, 09 Nov 2020 02:43:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Attention Is My Most Valuable Asset for Productivity as a Software Developer]]>
            </title>
            <description>
<![CDATA[
Score 630 | Comments 246 (<a href="https://news.ycombinator.com/item?id=25030938">thread link</a>) | @zwbetz
<br/>
November 8, 2020 | https://zwbetz.com/attention-is-my-most-valuable-asset-for-productivity-as-a-software-developer/ | <a href="https://web.archive.org/web/*/https://zwbetz.com/attention-is-my-most-valuable-asset-for-productivity-as-a-software-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
      <div>
        <div>
          <div>
            
  
  
  <p>
    
    
    
    <strong>Published: </strong>2020-11-08

    
    
      
      
        • <strong>Lastmod: </strong>2020-11-12

      
    
    
    
    
      <br>
      <span>
        <strong>Tags: </strong>
        
          
          
          
        
          
          
          
        
          
          
          
        
        <a href="https://zwbetz.com/tags/life/">life</a> • <a href="https://zwbetz.com/tags/attention/">attention</a> • <a href="https://zwbetz.com/tags/productivity/">productivity</a>
      
    </span>
  </p>
  
  
  
  

<p><em><strong>Note:</strong> This article has made the rounds on <a href="https://news.ycombinator.com/item?id=25030938">Hacker News</a> and <a href="https://www.reddit.com/r/programming/comments/jrlxbh/attention_is_my_most_valuable_asset_for/">Reddit</a>. The comments have been fun to read, and while I won’t address them all, I will say this… What I hope readers take away, is to realize just how interrupted and distraction-ridden their day may be, and that it doesn’t have to be that way, that you can improve it. Given that, these methods to guard your attention have worked for me, with “me” being the key word. So, take what’s useful for you, and discard the rest. Enjoy.</em></p>
<p>Like a tightly written function, I prefer to exit early if no work should be done. So, if you disagree with these definitions and assumptions, now’s a good time to stop reading.</p>
<ul>
<li><strong>Sustainable productivity:</strong> The maximum rate of quality work output, without loss to the wellbeing of the developer</li>
<li><strong>Quality work:</strong> Software that meets requirements, is valuable to users, is maintainable, and is as bug free as possible</li>
<li><strong>Attention:</strong> The limited mental capacity to focus on a task</li>
<li>Sustainable productivity is desired</li>
<li>Attention is essential to sustainable productivity</li>
</ul>
<p>My high-level workflow looks something like this: identify the problem to solve; think on the problem and let ideas percolate; research, discuss, and experiment with these ideas; implement and test the solution; deliver and maintain the solution.</p>
<p>This cycle could repeat many times in a day. Or I could spend days stuck on a single cycle step. Every step in this cycle requires attention. The more attention I can devote, the more cycles I can complete, and the more productive I am.</p>
<p>How long you can focus on a task varies by person. Some people are very good at it out of the box, some people, not so much. Regardless of the hand you were dealt, I believe that focus (the act of devoting your attention) is a skill, and like any skill, can be improved with practice.</p>
<p>So, how can you increase your attention reserves? The most bang for your buck is to organize your outside world in such a way that it’s distraction free as possible. Once you do that, you’ll have more time to practice, and therefore more time to get better.</p>
<p><strong>Build physical strength.</strong> The damage done by sitting 8+ hours a day is underrated. You need a way to offset this damage, especially if you plan to work in this field for decades. Opinions abound on this topic, but I personally prefer deadlifts. There are few movements more primal than picking a heavy object off the ground and standing up with it. You can <a href="https://www.youtube.com/watch?v=wYREQkVtvEc">learn correct technique in little time</a>. I most like deadlifts because you can do them safely, at high weights, into old age. I also like the hand, back, and hip strength they give, to make it that much harder for sitting damage to have its way with you.</p>
<p><strong>Make my place of work boring and tidy.</strong> My office is a spare bedroom. The walls are blank. There’s no tv. There’s a desk, chair, laptop, laptop stand, keyboard, mouse, and mouse pad. There’s a window, which lets enough light in so that I don’t feel like I’m missing a beautiful day, but not too much light to cause screen glare. If I need to work with paper, it’s immediately filed somewhere when done.</p>
<p><strong>Make my smart phone dumb.</strong> My phone has all notifications disabled, except for calls and text messages. Well, and National Hurricane Center alerts, since I live in Louisiana. Unless you’re my wife, you know that I don’t respond to text messages immediately, that’s just how it is. I disabled my social media accounts some time ago. But if you have them, turning off notifications should help curve the urge to compulsively check them.</p>
<p><strong>Be an OS minimalist.</strong> Apps I use less commonly are a keypress combo away. Given this, my dock has only the apps I use on a daily basis:</p>
<ul>
<li>File system explorer</li>
<li>Internet browser</li>
<li>Terminal</li>
<li>Text editor for front-end code and notes</li>
<li>IDE for back-end code</li>
<li>IDE for database</li>
<li>Visual file differ for version control</li>
<li>Email client</li>
<li>Instant message client</li>
</ul>
<p>My desktop alternates between clean and dirty states. Files I’m currently working with live on the desktop. Then they’re filed away into sensible folders when done.</p>
<p><strong>Organize my browser bookmarks.</strong> When I read something useful that I may need to reference later, I file it under a general archive folder. Then more specific items get their own folders. Frequently accessed links are visible on my bookmarks bar under their own folder.</p>
<p><strong>Minimize meetings.</strong> Look, I know some things make sense to discuss face to face, or voice to voice. But if they don’t, then you don’t need a meeting. An email or instant message will suffice.</p>
<p><strong>Finally, use the <a href="https://en.wikipedia.org/wiki/Time_management#The_Eisenhower_Method">The Eisenhower Method</a> to categorize my tasks.</strong> Imagine a grid of 4 quadrants:</p>
<ul>
<li>Important and Urgent</li>
<li>Important and Not Urgent</li>
<li>Not Important and Urgent</li>
<li>Not Important and Not Urgent</li>
</ul>
<p>Important and Urgent tasks have to be dealt with. For me, these are usually major production issues.</p>
<p>Important and Not Urgent tasks should absorb the bulk of your time. For me, this is the plain old development work of implementing features, fixing bugs, and making existing code more maintainable and performant. Also included are building relationships with others and planning ahead.</p>
<p>Not Important and Urgent tasks are nasty attention thieves. They shout out to you in immediacy, but offer little value in return. You know what these are for you. For me, these are most often lazily asked questions, where the asker did not do their due diligence, and expects a top-notch answer immediately. Also included are last-minute meetings, and over-talkative coworkers.</p>
<p>Not Important and Not Urgent tasks are usually not known to your users. Take internal documentation updates as an example. Thing is, they’re an investment in yourself, which means a more productive future “you”. So don’t forget to show them some love in your spare moments.</p>
<p><strong>Further reading.</strong> If you don’t know who Cal Newport is, you’re missing out. He has a whole blog dedicated to this type of thing, and has written books such as <em>Deep Work</em> and <em>Digital Minimalism</em>. Here are some of my favorite articles by him:</p>
<ul>
<li><a href="https://www.calnewport.com/blog/2009/02/04/have-we-lost-our-tolerance-for-a-little-boredom/">Have We Lost Our Tolerance For a Little Boredom?</a></li>
<li><a href="https://www.calnewport.com/blog/2010/06/10/is-allowing-your-child-to-study-while-on-facebook-morally-equivalent-to-drinking-while-pregnant/">Is Allowing Your Child to Study While on Facebook Morally Irresponsible?</a></li>
<li><a href="https://www.calnewport.com/blog/2008/04/07/monday-master-class-how-to-reduce-stress-and-get-more-done-by-building-an-autopilot-schedule/">Monday Master Class: How to Reduce Stress and Get More Done By Building an Autopilot Schedule</a></li>
<li><a href="https://www.calnewport.com/blog/2009/11/24/are-passions-serendipitously-discovered-or-painstakingly-constructed/">Are Passions Serendipitously Discovered or Painstakingly Constructed?</a></li>
<li><a href="https://www.calnewport.com/blog/2018/06/08/jerry-seinfelds-closed-door/">Jerry Seinfeld’s Closed Door</a></li>
</ul>



  
  
  

  
  




          </div>
        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://zwbetz.com/attention-is-my-most-valuable-asset-for-productivity-as-a-software-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030938</guid>
            <pubDate>Mon, 09 Nov 2020 02:39:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Windows 10 Installer Dystopia]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25030752">thread link</a>) | @brenns10
<br/>
November 8, 2020 | https://brennan.io/2020/11/08/windows-10-nightmare-edition/ | <a href="https://web.archive.org/web/*/https://brennan.io/2020/11/08/windows-10-nightmare-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  
<p><em>Stephen Brennan • 08 November 2020</em></p><p>A few days ago I had the displeasure of helping a friend reinstall Windows on
their laptop, which had previously contained Ubuntu. The reason for their switch
isn’t that important – although I helpfully suggested keeping Linux, it was
their machine and their decision. I didn’t expect the process to be particularly
difficult. After all, I work on operating systems for a living now, so I didn’t
expect any trouble. But to my surprise, I encountered a nearly dystopian
situation before I even got to the desktop.</p>

<p>I started the process by creating a bootable USB from the ISO downloaded from
Microsoft’s <a href="https://www.microsoft.com/en-us/software-download/windows10ISO">download page</a>. It feels weird writing that, but yes, the ISO
seems to be freely, easily downloaded. No product key was required to download,
or even install. The USB creation process was not easy (Microsoft suggests using
Windows to create the bootable USB, a chicken-and-egg problem if ever there was
one). It seems that the standard <code>dd</code> process used by every Linux vendor does
not work here – instead you need to get the correct magic incantations of
partition types and filesystems, and then copy files from the ISO file into the
USB. I ended up falling back to a tool called <a href="https://github.com/slacka/WoeUSB">WoeUSB</a> to do this process,
after three failed manual attempts.</p>

<p>The real fun started after I (finally) successfully booted from the USB and
started through the installation wizard. Cortana loudly greeted me, telling me
she’d walk me through the installation process using my voice. I must say that,
while I don’t really care to have a voice assistant guide me through OS
installation, I can see it helping a lot of folks out there, if it works
properly (I did not test it). I’m glad that Microsoft is at least trying this
out!</p>

<p>I went through the (impressively quick) installation process, and the laptop
automatically rebooted. It prompted me to connect to the Internet, which I
foolishly did. Directly after connecting to WiFi, the wizard asked me to login
with a Microsoft account!</p>

<p>I chuckled internally. “Classic Microsoft, asking for a silly cloud login just
to use Windows,” I thought. I don’t know my friend’s MS account login, and even
if I did I wouldn’t link their OS account to some cloud account!</p>

<p>I searched for the cancel button, but couldn’t find one. I tried to submit the
form with empty username and password, but that didn’t work. Realizing that I
might be trapped, I got my phone and fired up Google.  Surely, Microsoft
wouldn’t make it <em>impossible</em> to setup a new PC without linking it to their
cloud, right?</p>

<p>I found an <a href="https://helpdeskgeek.com/windows-10/how-to-setup-windows-10-without-a-microsoft-account/">article</a> which said that, by disabling the Internet connection I
had just configured, I could skip the login process. So, I hit the back button
on the installer. The wizard animated for a moment as if it was working, and
then showed me the same login screen. No matter how many times I hit the back
button, the wizard did not let me go back to the Internet configuration page!</p>

<p>“They haven’t got me yet,” I thought. I held down the power button and rebooted
the computer. Certainly on reboot I would restart the process, and could skip
the Internet configuration, right?</p>

<p>The laptop rebooted to a Microsoft Account login page.</p>

<p>So, I did what any self-respecting, conscientious friend would do for a friend:
<strong>I reinstalled Windows all over again.</strong>  This time, during the setup wizard
after the reboot, I skipped configuring an Internet connection. I was greeted
with this page:</p>

<p><img src="https://brennan.io/images/win10-nointernet.png" alt="win10-nointernet"></p>

<p>This, to me, felt kind of chilling. After all, it’s not like I asked not to use
a MS account. All I did was decide not to configure Internet on my first boot,
which has nothing to do with linking a MS account. After all, maybe I just don’t
have Internet access at the moment, or maybe I forgot the WiFi password.  Why
should the installer lecture me about the benefits of a MS account when simply I
did not configure WiFi? It felt obvious that this was a bald-faced statement:
“we know you’re avoiding our login process, and in a few years we’ll get rid of
this loophole too. Welcome to the future!”</p>

<p>I clicked the text (which wasn’t highlighted as a link or as a button) which
said “Continue with limited setup”. This was an odd phrasing, given that none of
the operating system features I’m familiar with (scheduling processes, providing
a unified interface to hardware devices, etc) requires a cloud account.</p>

<p>At this point, I was allowed to create a “local account” for my friend, and
finish the setup. I was presented with a list of preferences, all helpfully
enabled by default:</p>

<p><img src="https://brennan.io/images/win10-privacy.png" alt="win10-privacy"></p>

<p>The irony here is beautiful. Ads “may be less relevant to you”. The only entity
this harms is Microsoft, being able to avertise at you less (within your very
<em>operating system</em>, no less). Why should they bill this as a negative?</p>

<p>After disabling all of the toggles, the desktop loaded for the first time, I
noticed the following at the bottom right:</p>

<p><img src="https://brennan.io/images/win10-edge.png" alt="win10-edge"></p>

<p>I used MS Edge to install Firefox, and closed it out. On reboot, the login
screen contained two advertisements (!!!) for MS Edge. I returned the laptop to
my friend, grateful I didn’t have to use this horror show of an operating
system.</p>

<h2 id="why-does-this-even-matter">Why does this even matter?</h2>

<p>I spend my workday working on operating systems. Don’t get me wrong, I’m new to
the field, and I have a lot to learn. But as far as I know, <strong>there is no
feature in a modern operating system which requires a cloud account login.</strong> (I
would love to be educated if this claim is false, please get in touch!)</p>

<p>I used to spend my career working on machine learning and data analysis. One
thing I remember from my “past life” is that <strong>there’s nothing better than
linking different types of identifiers together.</strong> If Microsoft can track you by
your “Windows installation ID” and also by your “Microsoft Account”, then <em>of
course</em> they want to link those two identifiers together.</p>

<p>More links means more data about you. What applications you run, what sites you
visit, etc. An operating system as at the root of what you trust when you use a
computer. Do you use online banking? Your operating system can read the password
to your bank account, the balances, and more, directly out of memory! I’m not
suggesting that Windows does that – I just want to illustrate the sort of trust
you implicitly use every time you login to your bank account on Windows (or Mac
OS for that matter). But maybe Microsoft just looks at how frequently you login
to your computer, or what sites you’re interested in. What DNS queries does your
OS resolve? What IP addresses have you used in the last 90 days?</p>

<p>All of the data which is obvious to your operating system, can be linked to your
personal identity when you connect it to a cloud account. Don’t get me wrong,
even if you don’t connect it to a cloud account, you still are getting
incredible amounts of telemetry and tracking recording your every move. But why
would you voluntarily give more links and data to Microsoft?</p>

<p>I don’t think most people understand the sort of data they’re giving over to
Microsoft when they login and use Windows. These dark patterns that Microsoft
employs are sickeningly obvious, and really difficult to avoid. Why would I
trust a company that tries to manipulate its customers into such total data
collection, to be responsible with the data it receives?</p>

<p>I can’t imagine how frustrating it must be to be an operating system developer
at Microsoft. I have a lot of respect for the operating system kernel they make.
It seems to be one of the few major non-Unix like kernels out there. It seems
fascinating and I’d love to learn more about it. But it must be frustrating to
see the product of your hard work go out packaged with software capable of
collecting and tracking your users’ every move, and thrown together with an
installer intent on forcing them to submit to this data collection.</p>



<hr>



  
  

  </div></div>]]>
            </description>
            <link>https://brennan.io/2020/11/08/windows-10-nightmare-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030752</guid>
            <pubDate>Mon, 09 Nov 2020 02:02:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Observations from listening and producing 350 startup podcasts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25030613">thread link</a>) | @JollyMerchant
<br/>
November 8, 2020 | https://viralwegrow.com/blog/observations-from-over-350-startup-podcasts/ | <a href="https://web.archive.org/web/*/https://viralwegrow.com/blog/observations-from-over-350-startup-podcasts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        




<main id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://viralwegrow.com/blog/content/images/size/w300/2020/11/istockphoto-165518488-170667a-1.jpg 300w,
                            https://viralwegrow.com/blog/content/images/size/w600/2020/11/istockphoto-165518488-170667a-1.jpg 600w,
                            https://viralwegrow.com/blog/content/images/size/w1000/2020/11/istockphoto-165518488-170667a-1.jpg 1000w,
                            https://viralwegrow.com/blog/content/images/size/w2000/2020/11/istockphoto-165518488-170667a-1.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://viralwegrow.com/blog/content/images/size/w2000/2020/11/istockphoto-165518488-170667a-1.jpg" alt="Observations from listening and producing 350+ startup podcasts">
            </figure>

            <section>
                <div>
                    <div><p>After listening to over 100 Nathan Latka Podcasts, observing 200 Indiehacker podcasts and watching 50 Microconf talks AND recording 80 episodes myself.</p><p>Here's what I've observed:</p><p><strong>SEO</strong><br>Over 70% of founders credited SEO for being their best source of growth. Invest into ASAP and build up that MOAT.</p><p><strong>FB / Social Media</strong><br>Its a hit or miss. Don't waste time curating the perfect Ad or post. Tim Doyle of Eucalyptus shared that his most profitable Ad was not some high quality video but rather a Doge meme.</p><p><strong>Velocity is everything</strong><br>When building companies you NEED to move fast, there is no alternative to it.</p><p><strong>Product</strong><br>Product led growth is the BEST type, its natural and doesn't feel forced.</p><p><strong>Distribution</strong><br>This is probably just as much if not more important than the content or product itself. Build with distribution in mind, articles / SEO or products.</p><p><strong>SLC</strong><br>NO ONE wants to use an MVP - stop using that mindset. Literally no one other than your Mum/Dad will use a "minimum" "viable" thing you build. Its 2020, the whole patchy product cycle doesn't exist. Aim for Simple, Loveable and Complete (or what I call Minimal Product for Impact) Introduce simple features that meet your north star and make sure they're complete.</p><p><strong>Cold Email</strong><br>Learn to master this, its a great skillset to have in building a company and distributing content.</p><p><strong>Feature Validation</strong><br>Before you build a feature, literally build a simple landing page, run some GAds to it for lifetime deals (this doesn't work always, but for some apps).</p><p><strong>Communicate</strong><br>Build every channel possible to communicate with your user as often as possible for as long as possible.</p><p><strong>No CC No Bueno</strong><br>UNTIL someone gives you their CC, you don't have validation. Do not take anything else as validation other than their CC.</p><p><strong>Timeframe</strong><br>Before you start, set a goal to hit, if you don't hit that goal, be quick to reflect. Build more or move on Last but the MOST important.</p><p><strong>Audience</strong><br>Almost 90% of all the "Super successful" founders attributed having a previous built audience as their reason for success. They built this audience through, podcasts, blogs, Youtube, Tiktok or even Newsletters. BUILD. AN. AUDIENCE. You have a higher chance of succeeding with a shit product and a large audience than vice versa For those that are keen.</p><p>All the best peeps!</p></div><p>-Vaibhav<br></p><blockquote><em><strong>Vaibhav</strong></em> has built several startups into Million Dollar businesses serving Millions of customers across the globe via five2one. He's commonly found on stage talking about AI/ML or Product engineering whilst building his 2nd startup cenario.</blockquote>
                </div>
            </section>

                <section>
    <h3>Subscribe to ViralWeGrow</h3>
    <p>Gain a personal advantage with our weekly insights and analysis into the startup hacks world.</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</main>






        

    </div><p><span></span>
        Could not sign up! Invalid sign up link.
    </p></div>]]>
            </description>
            <link>https://viralwegrow.com/blog/observations-from-over-350-startup-podcasts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030613</guid>
            <pubDate>Mon, 09 Nov 2020 01:33:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to easily understand Flexbox CSS – (Part 1)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25030527">thread link</a>) | @alanmontgomery
<br/>
November 8, 2020 | https://blog.alanmontgomery.co.uk/how-to-easily-understand-flexbox-css-part-1 | <a href="https://web.archive.org/web/*/https://blog.alanmontgomery.co.uk/how-to-easily-understand-flexbox-css-part-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1604884175281/Wd5pu-Bw3.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>In this mini-series, I will be taking you through how to use flexbox CSS, in a simple, easy to understand way. You can really empower your projects and websites with the use of flexbox CSS and reduce your lines of code drastically. I have also released a video-based tutorial series over on my <a target="_blank" href="https://bit.ly/alanmontgomerycoding">YouTube</a> so if you'd prefer a video, check that below! Ok... Let's get into it.</p>


<p>Flexbox CSS is a one dimensional layout model/method used for laying out items (HTML elements) in a row or column fashion (horizontal or vertical).</p>
<h2 id="why-flexbox-css">Why Flexbox CSS?</h2>
<p>Long gone are the days of using <code>float</code> and <code>position</code> in CSS to create layouts and responsive layouts. Utilising flexbox allows you to create fully <strong>responsive</strong>, mobile first layouts without needing to write lots of different media queries.</p>
<h2 id="display">Display</h2>
<p>The most important CSS property in flexbox is the <strong>display</strong> property. This is how we define a "flexbox container". Familiar display properties include <em>block</em>, <em>inline</em>, <em>inline-block</em> etc etc. Flex is no different, it can be defined like this:</p>
<pre><code><span>.container</span> {

    <span>display</span>: flex;
}
</code></pre>
<h2 id="container">Container</h2>
<pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"container"</span>&gt;</span>
    <span>&lt;<span>div</span> <span>class</span>=<span>"item"</span>&gt;</span><span>&lt;/<span>div</span>&gt;</span>
    <span>&lt;<span>div</span> <span>class</span>=<span>"item"</span>&gt;</span><span>&lt;/<span>div</span>&gt;</span>
    <span>&lt;<span>div</span> <span>class</span>=<span>"item"</span>&gt;</span><span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>
</code></pre>
<p>Our flex container is typically a block level element, usually like a div for example. Refer to the below image; I have defined a flex container and inside my flex container, I have three more divs.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604881496142/fnYjCju9S.png?auto=format&amp;q=60" alt="Flexbox container / Flex container"></p>
<h2 id="items">Items</h2>
<p>These are called flex items. Each child inside a flex container is referred to as an "item". You can style these individually again, using flexbox CSS if wanted and we'll get into the specifics of this in the next part.
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604881547911/oHOA4hd7z.png?auto=format&amp;q=60" alt="Flexbox items / Flex items"></p>
<h2 id="flex-direction">Flex Direction</h2>
<pre><code><span>.container</span> {

    <span>display</span>: flex;
    <span>flex-direction</span>:
}
</code></pre>
<p>The next important CSS property in terms of flexbox is the <code>flex-direction</code> property. This allows you to specify which direction you want to place the items inside the flex container. There are four values which can be used for the <code>flex-direction</code> property, either in a row or a column (<em>e.g. horizontally or vertically</em>).</p>
<h3 id="row">Row</h3>
<pre><code><span>.container</span> {

    <span>display</span>: flex;
    <span>flex-direction</span>: row;
}
</code></pre>
<p>By default, a flex container will automatically have the flex direction of row. Items inside a row direction flex container will be displayed <em>left to right</em> (LTR), your first item will be the first placed element on the display.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604881578319/WinXtcAhZ.png?auto=format&amp;q=60" alt="Flex direction row"></p>
<h3 id="row-reverse">Row Reverse</h3>
<pre><code><span>.container</span> {

    <span>display</span>: flex;
    <span>flex-direction</span>: row-reverse;
}
</code></pre>
<p>The <code>row-reverse</code> value for <code>flex-direction</code> is similar to the <code>row</code> value, however the items inside a row-reverse direction flex container will be displayed <em>right to left</em> (RTL), so your first item will now become the last for example.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604881606985/r6yklzUvS.png?auto=format&amp;q=60" alt="Flex direction row-reverse"></p>
<h3 id="column-and-column-reverse">Column and Column Reverse</h3>
<pre><code><span>.container</span> {

    <span>display</span>: flex;
    <span>flex-direction</span>: column | column-reverse;
}
</code></pre>
<p>The next type of <code>flex-direction</code> you can specify is in the vertical axis in the form of columns. First of all with the <code>column</code> value, similar to the <code>row</code> value but placed <em>top to bottom</em> (TTB). Alternatively you can use the <code>column-reverse</code> value which again, is similar to <code>row-reverse</code> but displayed <em>bottom to top</em> (BTT).</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604881638561/5U3hUwFeJ.png?auto=format&amp;q=60" alt="Flex direction column and column reverse"></p>
<p>Hope you enjoyed part 1 of my easy to understand flexbox CSS tutorial. It really is that simple to get started using it. In the next part we'll look at some more specific properties we can use to <code>justify-content</code> to space out flex items inside our flex containers!</p>
<p>Please leave a comment and a reaction to this post if you enjoyed it! Also, I have a <strong>YouTube</strong> channel where I'm posting lots of coding tutorials, tips, tricks, reviews and more, would love to see you there:</p>

<p>See you in the next part!</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.alanmontgomery.co.uk/how-to-easily-understand-flexbox-css-part-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030527</guid>
            <pubDate>Mon, 09 Nov 2020 01:12:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big-O]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25030390">thread link</a>) | @dleskosky
<br/>
November 8, 2020 | https://www.danielleskosky.com/big-o/ | <a href="https://web.archive.org/web/*/https://www.danielleskosky.com/big-o/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-label="Big-O"><div>
<div><figure><img loading="lazy" width="2240" height="1260" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/bigO/bigo-banner.png" alt="Big O Banner"></figure></div>


<p>Big-O is pretty important.&nbsp; It is the metric that is used to describe the efficiency of algorithms.&nbsp; Having a thorough understanding of Big-O is crucial for ensuring that algorithms are as efficient as possible.&nbsp; Let’s learn more about this fundamental computer science topic.</p>


<h2>What is Big-O?</h2>


<p>Imagine that there is a ship builder.&nbsp; Her name is Andrea.&nbsp; She makes big ships and small ships for a port city.&nbsp; She can make the small ships pretty quickly, but the bigger ships take longer.&nbsp; The amount of&nbsp;<strong>time</strong> that it takes her to build a ship is proportional to the&nbsp;<strong>size</strong> of the ship.&nbsp;&nbsp;</p>
<p>Andrea is also a pirate.&nbsp; She is known to steal other peoples’ ships.&nbsp; She usually does her pirating in a port town that is 10 days worth of travel by land and 5 days of travel back with the stolen ship, so 15 days round trip.&nbsp; The port town that she pirates from always has the ship size that she is looking for.&nbsp;</p>
<p>If a customer asks Andrea to build a ship, she has two options.&nbsp; She can either build the ship or she could put on her pirate hat and go steal a ship.&nbsp;&nbsp;</p>
<p>So if someone wants Andrea to build a ship for them, which option should Andrea choose?&nbsp; That’s right!&nbsp; It depends.</p>
<ul>
<li><strong>Build the Ship: O(s):</strong>&nbsp; where s is the size of the ship.&nbsp; This is <strong>linear</strong> time.&nbsp; The time that it takes to build the ship increases linearly depending on the size of the ship.&nbsp;</li>
<li><strong>Steal the Ship: O(1):&nbsp;&nbsp;</strong>this is <strong>constant</strong> time.&nbsp; It doesn’t matter how big or small the ship is.&nbsp; It will always take Andrea 15 days to get the ship back to the customer.&nbsp;&nbsp;</li>
</ul>
<p>So Andrea should build the ship if she can get it done in less than 15 days.&nbsp; If the ship is big enough that it would take longer than 15 days to build, then Andrea should go steal the ship.&nbsp;</p>
<p>On a side note, this blog does not condone stealing and Andrea should really rethink her life of crime.</p>
<p>Here is a graph that represents the relationship between linear O(s) and constant O(1) time:</p>


<div><figure><img loading="lazy" width="532" height="484" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/bigO/constant-linear.png" alt="Constant v linear"></figure></div>


<p>There are many more possible runtimes that can occur besides linear and constant.&nbsp; Here is a graph that shows some of the more commonly-used runtimes:</p>


<figure><img loading="lazy" width="1618" height="1130" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/bigO/complexity-chart.png" alt="Complexity Chart"></figure>


<p>The above complexity chart comes from the <a href="https://www.bigocheatsheet.com/" target="_blank" rel="noopener noreferrer">Big-O Cheatsheet</a> website.&nbsp; Definitely a useful resource!</p>


<h2>The Three Cases</h2>


<p>Let’s use quick sort as an example.&nbsp; Quick sort picks a random element as a pivot and then swaps the values so that the elements less than the pivot appear before the elements that are greater than the pivot.&nbsp; Then it uses recursion to further sort the left and right sides.&nbsp; Learn more about quick sort <a href="https://www.geeksforgeeks.org/quick-sort/" target="_blank" rel="noopener noreferrer">here</a>.</p>
<ul>
<li><strong>Best Case:</strong>&nbsp; The best case means that the algorithm is given the most ideal data.&nbsp; If all elements are equal in the array then quick sort will just have to traverse the array once.&nbsp; Traversing an array of <strong>N</strong> elements will give a runtime of&nbsp;<strong>O(N)</strong>.</li>
<li><strong>Worst Case:</strong>&nbsp; The worst case means that the algorithm is given the least ideal data.&nbsp; With quick sort, it could happen that the pivot is repeatedly the biggest element in the array.&nbsp; If this were to happen then instead of the subarray being recursively divided in half each time, the subbarray would only be reduced by one element.&nbsp; This would give a runtime of&nbsp;<strong>O(<b><i>N</i><sup>&nbsp;2</sup></b>)</strong>.</li>
<li><strong>Expected Case:</strong>&nbsp; Typically instead of having a worst case or a best case you are more likely to have an expected case.&nbsp; Sometimes the pivot will be high and sometimes the pivot will be low, but over time they will average each other out.&nbsp; This will give a runtime more close to&nbsp;<strong>O(N log N)</strong>.</li>
</ul>
<p>The best case runtime usually isn’t of too much interest when analyzing an algorithm.&nbsp; The&nbsp;<strong>worst</strong> and&nbsp;<strong>expected&nbsp;</strong>cases are the ones that need to be considered.</p>


<h2>Space Complexity</h2>


<p>Space complexity is used to describe the total amount of memory that an algorithm uses in respect to the input size of the algorithm.&nbsp;&nbsp;</p>
<p>If an algorithm requires an array of size <em>n</em>, this will require O(n) space.&nbsp; If there is a two dimensional array of size&nbsp;<em>n </em>by <em>n, </em>then O(n<sup>2</sup>) space is required.</p>


<h2>Some Useful Big-O Tips</h2>


<p>There are a couple of tips that you should keep in the back of your mind when you are working on finding the Big-O.&nbsp; Here they are:</p>
<ul>
<li><strong>No constants</strong></li>
<li><strong>No non-dominant terms</strong></li>
<li><strong>Consider multiple runtimes</strong></li>
</ul>


<h2>No Constants</h2>


<p>With Big-O time the constants are not taken into consideration.&nbsp;</p>
<blockquote>
<p>Big-O notation doesn’t care about constants because Big-O notation only describes the long-term growth rate of functions, rather than their absolute magnitudes.”&nbsp;&nbsp;</p>
</blockquote>
<p>An algorithm that might seem to be <em>O(2N)</em> is actually only <em>O(N).&nbsp; </em>Here is a <a href="https://stackoverflow.com/questions/22188851/why-is-the-constant-always-dropped-from-big-o-analysis#:~:text=Big%2DO%20notation%20doesn't,rather%20than%20their%20absolute%20magnitudes.&amp;text=A%20function%20whose%20runtime%20is%20n2%20%2F%202%20will%20be,runtime%20is%20just%20n2." target="_blank" rel="noopener noreferrer">Stack Overflow post</a> that does a pretty good job of describing it.&nbsp;</p>
<p>Take a look at some code:</p>

<pre title="">int min = Integer.MAX_VALUE;
int max = Integer.MIN_VALUE;
for (int x : array) {
    if (x &lt; min) {
        min = x;
    }
    if (x &gt; max) {
        max = x;
    }
}
</pre>

<p>The runtime is O(array.length) or O(N).&nbsp;</p>
<p>Let’s take look at some more code:</p>

<pre title="">int min = Integer.MAX_VALUE;
int max = Integer.MIN_VALUE;
for (int x : array) {
    if (x &lt; min) {
        min = x;
    }
}
for (int x : array) {
    if (x &gt; max) {
        max = x;
    }
}
</pre>

<p>Your first intuition might to be assume that because there are two for loops that iterate the length of the array that the runtime must be O(2N).&nbsp; Don’t fall into this trap!&nbsp; The runtime is O(N).&nbsp; Remember to drop the constant!</p>


<h2>No Non-Dominant Terms</h2>


<p>What if you get a runtime like O(<i>N</i><sup>&nbsp;2</sup> + N)?&nbsp; What should we do then?&nbsp; Well, if you were able to deduce that we should drop the non-dominant term, then congratulations!&nbsp;&nbsp;</p>
<p>Consider the runtime O(<i>N</i><sup>&nbsp;2</sup> + <i>N</i><sup>&nbsp;2</sup>).&nbsp; This is the same as O(2<i>N</i><sup>&nbsp;2</sup>).&nbsp; We know that we should not include constants in our runtimes.&nbsp; So if one of the <i>N</i><sup>&nbsp;2</sup> terms is ignored then we can ignore the N in O(<i>N</i><sup>&nbsp;2</sup> + N) as well.&nbsp;&nbsp;</p>
<ul>
<li>O(<i>N</i><sup>&nbsp;2</sup> + N) becomes O(<i>N</i><sup> 2</sup>).</li>
<li>O(N + logN) becomes O(N).</li>
<li>O(5*2<sup>N</sup> + 1000N<sup>100</sup>) becomes O(2<sup>N</sup>).</li>
</ul>


<h2>Consider Multiple Runtimes</h2>


<p>If we had to iterate through two arrays of the same length N then we could say that the runtime was O(N) (remember to drop constants!).&nbsp; However what happens if the arrays are of different lengths?&nbsp;&nbsp;</p>
<p>Take a look at some code:</p>

<pre title="">for (int a : arrA) {
    print(a);
}

for (int b : arrB) {
    print(b);
}
</pre>

<p>We are iterating through two arrays of different lengths.&nbsp; The runtime is O(A + B).&nbsp; Both runtime lengths must be considered!</p>
<p>Let’s take a look at some more code:</p>

<pre title="">for (int a : arrA) {
    for (int b : arrB) {
        print(a + "," + b);
    }
}
</pre>

<p>If the arrays were of equal length we could say that the runtime was O(<i>N</i><sup>&nbsp;2</sup>).&nbsp; However, the arrays are different lengths.&nbsp; This means that for every element of A, arrB will be iterated through.&nbsp; This results in a runtime of <br>O(A * B).</p>


<h2>Thanks!</h2>


<p>Thanks for reading my post.&nbsp; I hope that you found it useful.&nbsp; Once you understand the material presented here, be sure to continue your learning about Big-O.</p>
<p>Here are some topics that you should explore next:</p>
<ul>
<li><a href="https://hackernoon.com/what-does-the-time-complexity-o-log-n-actually-mean-45f94bb5bfbf" target="_blank" rel="noopener noreferrer">Log N Runtimes</a></li>
<li><a href="https://yourbasic.org/algorithms/time-complexity-recursive-functions/" target="_blank" rel="noopener noreferrer">Recursive Runtimes</a></li>
<li><a href="https://yourbasic.org/algorithms/amortized-time-complexity-analysis/" target="_blank" rel="noopener noreferrer">Amortized Time</a></li>
</ul>
<p>Thanks again!</p><!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://www.danielleskosky.com/big-o/"
    dc:identifier="https://www.danielleskosky.com/big-o/"
    dc:title="Big-O"
    trackback:ping="https://www.danielleskosky.com/big-o/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://www.danielleskosky.com/big-o/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030390</guid>
            <pubDate>Mon, 09 Nov 2020 00:35:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mapping the Underground: Supervised Discovery of Cybercrime Supply Chains [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25030329">thread link</a>) | @stjo
<br/>
November 8, 2020 | https://damonmccoy.com/papers/ecrime2019.pdf | <a href="https://web.archive.org/web/*/https://damonmccoy.com/papers/ecrime2019.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>Å”•PíTÃjÜ¿Ì9‚tœ†äWŸë_ûuVÓ#?‹ÒUY'ü{Ä^5t3},5Ý©Å�Â�YÜQŒµ‹;ðR(‘îh¡‡Y]çãS„i‹Ãq5èç´®ÞáîÀæŸ‰ÌpÞàüó_°ZNöÁ
¸xy5~­uH­�ÔÜêU[-x»ºÙú–e©–0ø‘
[¤3N=V´\ûuíjŽGw±t ð[ÏR!ÀKöžÁç÷÷N°�„Ä:Ám9-·¢‘ß´Z¤¾™Õ·Þiê5
«4w¦-&nbsp;.ÞR*Abd…âH@‘òWx­¶¥‹¿ÙB	KDÐ!|GD«e÷)
î2BæÆi
&gt;R 4&nbsp;†Þ·E»Øµ‡½PŠmÀ&nbsp;#eHÓàë-íHÊðjR_dW�]�Ï³²˜ä§](©‚EJ÷<wtÓ€ )!v‘¢_«¨—�œd“�Íi="">Œ‹Ëºø”wÊGH�n	Ñ" S­¡=ÄQUW×Ù(£ì)+³áõ¤èÂö$ü”¤ÊÆ!iÊ—Û#¼Ì&amp;õÐ€0.Àò¤ÅŠò¼—.ÕÀ©‚T'˜“jò‘0ÚQžM®ÆÝàI	nã¨aáe©`AlY§mcÍºq)áÛƒ?‹R	±š¯»v…“v‰ñÀ†ÐÙuqIfPÖq*;Í1�¯
ÂØÓE5¬É±äŸ‘T–m
&gt;/È:…-âS1©5ºl8¬NÉ¯¸ú"/bÌ±Í¶A{h§ù _Ó&gt;8-àòòÓ¢î¸°%)oTÈ¾iGBHe&lt;Ø]\—&lt;¢C¡¢@*\Naª�øZ˜˜„K°µ R›‡)eòT× *kGß‡a•žk$`T¤Ò;E6KDE#~¨u“ðY%°(sb]J§TC£j�I¯3&lt;+Zeâ·mm\Œò““.µdh´])–ìÉ(Ú®”ÃHÚàûýýO[¿õ_½Ýÿ£Ÿ:IŽÈ®f�Í‚¦G[‚{}VU°~ ”]
+pônÀXƒM‰O`¤w3Æy.ÛÕ›¥À�ð=ðýM½©eÜ„G²bSý»S3ðÆ £ƒýx`CV‘{-Û }“ :|œVÆ;`Ó§dþÛÀRÅFè$Ó&gt;eíòg��s&gt;È.;çîV;®‰ü¤H˜
’-z_.à×Î”¾ì	C‰ÊÐ[MN/
¶Ñ$E�u°„n÷j&lt;Îkb%~ÿ4/ëâì!ëp¿“?Aø÷v	¢„3^äú5I¯¢Ø*µe	�î"½Í�Ýy˜Ÿ`]Škl�Ò»U*KµÇ¯7Õäl�k§×p^®Ö˜ò‘»v·ÛJ�6z«ýõÆˆü‚Äf5áË�´
’ÄÒàŽøðaÊÓèmrƒ?º¨FÙ„¼—ßzµÿnKƒhgyú«#î{£ƒ¸@…šŸ‘Î€Qê/&lt;œZìYq~5^ú´.K�*GÚ‹©Ëµ‚{O›BR&nbsp;ÿþ<mƒa8:,#è-�‘<�sˆ «¾¾Ùç!Ù%�°±k="" r‚ú="" ìû“ÅÏ‹y»jÌ6v.ÆÕ¨¸áÙauú­nØì§w¬h£ÿ±ÈÒ†9ób="">ûËÖ{[�GÙ�õÖyÇó�m&lt;ï½Ù�zoþ–þ¾§'o˜ÄM›Õã«¼Us_÷l’'§Ø;-œ¼Íÿ|s/ûGÐ^&gt;äåiVÖÔd’^~LÝ"þª û+Ï¡§êëÍ×
5�à¨ú­,Ð0g3<ulš²-Ûbhag·=©óÑ~yv%«þy.Í»1Ÿ÷™êy–}Í6¶o«“t_»º¼æ#´À¼dòé¨úu÷ »\bÆß“ªhþÝy}Ög\ÚÅrÐ›Úzuc½÷i}@ì€Ñtî‰6¬9ÆÆ¶e="" �w‰`àÈÌ‚žhkg�à?4¾="">fŽŽþ ƒVb…˜Aow›�46Øg�é9ýª›3/î–ˆŽš#¨Rë`iO/¡#!Ò	:Õl½£b(ž¥šüƒ¨iÉÞk�¿¨€³Ë×yq~QCM
´?BŸ³}Q§„_‹€§·7ÌÎ'ÌMg{ù²úŒ©6-±fK]6áÉAMÓ‘+A§æîƒž•¨Ï^1ä9'Âƒ·Ù(¿SÖûu6,Ûåù0'™ô!õß™×„c¶˜&nbsp;±ì†¬žË
¥xì%Þj¬0ÖK¹n¨¹ÕíqCÍ½¡âñ"•\©ÿb÷¿Î‡ŸòºÀ—wÅ/ÛÆ)*FyÕƒz0º5ý`ZÓiCk¾ íƒap­1¸ocøÆ~ð­ç^�³}cîÐzîÈZcî'Šþ&gt;®ý�¦”4¦B.uo�Eß/©Ù1(×T�RDäL5šxýEl8`Z64dXP-Ñd~‹+ñ£[Øh-D¢+SBö¬)YBÉ&nbsp;
¥ÓzÁ-šYÜ£W&nbsp;,ÎGCŒÇÌšÊt&nbsp;AÇÐì°Ùžýÿ—bÏ‰µÒ'2 GB_ê±™õ<o¨n€ÇøÐ0¨ç¾xÝi±.üo-Öt[lœ¹‹;—ùôáq~µmxt7œØl¹Í¸5];¼&h^Ã%s?ÕðËóà%ntþ2ì}5¼=a®_z ófÌøª$}s’af`ª´b="" Žáæ�|yÐð^Ðr«›é="">í†‘@ÏËt_Eƒ0~žî#!º‘ïG+¸£¬žmš ècèÿüè�Q U"‰S’Û0EÑÌúo6*½3Û§ÿT²Ö`“=ïz†zôzÆÓ/QþøKT?þõ�¿Dó�–øäþTÙÇõ§O¿@÷ü/)cpendstream
endobj
180 0 obj
&lt;&lt; /Filter /FlateDecode /S 186 /Length 183 &gt;&gt;
stream
xœc```b`ëd`e`šÁ Æ`620°Xèp09°1p8±L`°~°§œ!¶Œ�çsÜÓsF\azÉæ
,-s\.oìÇtp'GEekxˆ‰‹ëškS¢®wº®Nït]džÑ@|}J8P°ÂõzKxKø0$Å|&nbsp;Ë||Í%�4'ó��}Ž�Ÿ�ÁeÂëƒçüs¾”�,Q˜¤p5îäåÏèäÞHw
endstream
endobj
181 0 obj
&lt;&lt; /Annots [ 191 0 R 192 0 R 193 0 R 194 0 R 195 0 R 196 0 R 197 0 R 198 0 R 199 0 R 200 0 R ] /Contents 182 0 R /MediaBox [ 0 0 612 792 ] /Parent 387 0 R /Resources 203 0 R /Type /Page &gt;&gt;
endobj
182 0 obj
&lt;&lt; /Filter /FlateDecode /Length 4519 &gt;&gt;
stream
xÚ¥Z[“ãÆ­~÷¯˜‡ã*Í©Í»È&lt;ÙY¯ÏÙT¼veÇq¥Ö~è![3©ðâñì¯&gt;MRÎ&amp;©¼Hhô�&gt;&nbsp;éßnü›ÿûÂ¿úÿãý_}DþMyyàG7÷û›8óò4¾Ù…¾—Ñÿ}yóqó½9Ÿ«æp»�âx3-ˆhóSSÚî6È6‡®›òRýa&lt;Ûî·ª·¥´ú¶ê‹ö6H6¿áÇvÏÒ¬Ýßþzÿ§› L¼ Jo¶áÎËòT¦{óü`»¢«N˜(ñ1ä¹~úÍÑTM�¾²òÀ÷ò$Ë±òmšyqº»ÙF�e¡ŒõÓW�FúþñhjÛ™V{ûþÍÎËw~€Î»ÈÃÝ
É!É¥ç/¾­Î{»(¤Yæ¦w2þ÷æ÷'[×Rø¦®Ì¹ëªí×æ£’—ñ7á;šCEtO¦ªUÐkû½(YÎöüÊTaº:ÕSº¹¾Ùwí§µ9Rß‹‚l9É§ÿl’oÍ©mT–ÅÚŒ?-ór3‰¯ŠŽÍC/�I	‚Ðs:°lx““~‡)†ÉèÈ±Œ4PÅ{o!¿'YÁßnópÓv�Rú©©~ƒ¶û›¾²[Œy­Êw;ZYwBä3Mø¼¶¬�·‹ó‹u]MÎ¢$Âœºª&lt;&nbsp;Ö®­š–¥ÿÙº&gt;ý{ëz×¶kÌPµ�QµÓžÎ#qUkŠÊ6…^ãwM?TU®­r¦©!\f2AÇ·÷áøuƒƒy=[Žª+'3_°•j\
ïâV|]Ô^aNž)¼ñQ[õÐê¯«¢¯&lt;29�,Ãš•àù6M6ËéŠBôñr.ÚÉ«Š­Å70£°Ÿ´52m¬ïdêrÝØ7ýÐ™bp¢Hí#º)Aâì2KliûÁ4%[á$JÅ
'ÑnÓÛŒ�q/|¨Øg¶Ì-ñ{WÕX[’Uæk“NÐ‘oq‘L4´Ô,6d¾÷·aBª†‘¿Vƒªe¯êµ®‹
*€‚ö–‚Ýïm1TÝo¢¢Òš33¨PïñÚ|Y•ÞÝÿg©?Yõ Ô¶Ã½¤S	éï`2èKe’Jo…ìÕi„y´)Äi0¿;ÞÍ)ÕáFÊÿ+!´á@»Ü.W¤r*h¥ã‰§Œ#èa3bç&nbsp;i³²÷ÁÆÏÐ"+´žÈ¹í™ÁråìplK¡‡£„ª—;6Û¯¬ädŠcÕðíÊ©ƒéÐ¥G�úR©:tæ|Ü&gt;ñÉÄ0t]Ÿ{J8x´·{2”!nì Þ6ßØß'-½:'Þ8ßMâ½—]ž´æJg¸…ˆh&lt;õRžm~;©y1¦�åê1P+x‹$¦­Ö‡¶«†ãIŠ…Q~UBµöÏRŠ¢/A"pâðK!ääB7Í&nbsp;cM€ãjO4_ÅÞ*&nbsp;“ø{Ë&amp;/Ü¼muÕ…¯Glþ2ö}e´õ,�;é£zw¾¼)$Š$×lú£\œîËÓ¨Nª]sïíg]p!i²l=P¥¨I‡\Ë½üÁ—BðÐ#ùòN8¯®uço¼1ñé¦»x¡t(a&amp;üóJÒ]2&gt;˜N¡@—–0Œå`•3ÂÖÏW’˜og#š�-‘àìðd-T‰­R*ÇbÐjÙ ¬ö¨bS
Ž^FêfdÓÂ&gt;·”ÊÔõóÊIŒ½Ý�5,H.�Íväë�œêÈŠL5,ÔTu]Õ&nbsp;í�”Ùï£šý¾´ïíŠ.®W˜F›ïœ9Ó˜.´9�ë[²ËwÂhÇNšéU‡‰@q2Ÿé|àÓê`üè4¤\Òõ—«hGˆ.ŽU¾q²¡S´ÏÂ«
ï^L("
[›ŠÜXÕg8b¥U'%Rr²¬†ñwkWä/Ñ	éÓ~lX
DÀÄ`Áíç#¸ÍBVêˆ—Ž[öƒÑwï”öw¥hs/D'Ø¯ypŠ¡âðÂƒ°äwp†r£1Â›Û¨Ì÷f;v'4üŸMsÉöKÕ�¢»b·IF1Î¥‡¯×Kñ›¦^š Ê
(èt3dßpe·	àÒÜk£$^J”nã=Ý¾�ö½MÉœÑá‡›˜ó-s~búÍ¢Í;¦¥ÍûUÈGP=ÌcB|ˆw×±ßÖô[³ý€`'žÑ†�Ø]*)‹ñB2c]WÁ¸1·•º¥ˆ6AîIÿYlz¤A@±C"3’
ôÇ¤ƒ;]©yÝÿáYëÛÓ©-«¡ú$ÚK¬²b5ÚÛÎÂg€u6Ý&nbsp;Ù¢Ò¿&amp;'¶œ|0Å#ã�`ó1Œõ„ü«à+%C�¯-QøÀùðCóyQÅï„kä¯?›ÓÉvk“b™YÈ2‹³¡RÈ·�xFþžØ&gt;K½´#te]+»Ä†'C½)£¬T¡BÄDrŠC·¶Œ¢³lN"òÌýÐv–âKHå'û@!�eGc§�©$!LÍ„8¶=Ð&nbsp;6ïXvšùJ¿”í	–�–ÉñesÀgvRAr©køTmlŠÂžiÜ65Ã0ðÏæ™=ïêNÙ°‘öcxF„OÀ ¸3ÒÎO¬ÁTÝ‹Ò{RúùH[å–/mpV&amp;t‡Ïx“QQ…0Î=ÙýBqèµG\&amp;Z=Ð•&nbsp;U’VOtº<a”o�È_vŸØ¹`3�t´,5bpfŸr1˜þÑ“ª7w·‘ûíÉ¯mÜyöy@2�ü�—i*a^Ür+cîÙh=6ŠkÎûaÐ³5º�Ù™Ò¾²>—þX�!¶0v8‚$&amp;'@¬=ß©ÒeÕG¥`2ª”ON·9(‡�5™&nbsp;˜‡¶-û5­VÐé;5ê¥TifE³8ý"©¦`¤¬ŒVß6‚æÓùØ{^išÏ€�hØS�(ø7Z³”6º²�6_B
”‡ixþkV[‚^Zs¦�(Ëp«\¼6-'&gt;
ýM[Kö±œj¸ƒ€b8ý’ƒ®×“Võ÷„ÿcWµ«†”M$§Šâ$ÚM/°˜®¥þO
«á
Ö+îâ$šÌQ+ÓFlg·kgÞ�5â•(Þ`Í�’ýhÒ &amp;3iAEb+À•u�[´c]
Ó6¤ùVØV¯»‹rMÕKu£&lt;ñÉ³&lt;[â‡Pxp�'£ƒ1ç�q:šõvžˆáªk�á¾ã`hè½f÷†±d³•Ä©Þ§sÝ
âLJ.í
š�œXöRÍI”8uÖlv5…rmò®LJì0Œ˜Iš—%)‰"ùõNj?†Ñ¯BI8Jµª/Âí['%ì&nbsp;0lhÂÊüVpÆ©eï»K×O­VãÂÜ†)‚ªw¼gÜ@6öLnžî™x`çvmî–ú&nbsp;K,LJ†×BHQ#¡yŽ,I!Ä€ª�Ã4ÿ©!#&lt;Œ°5çßî„/¸ª÷ŒôX£Íc#¬my°Â",qêÅ	ÅÑdôAWú�‘¦@P4k;¾TÅ$Ÿ²@Iê;çö7óòEã´K)¹WkºâÈ@]FV34ÑÇ¶X›W2”¼µ9¥¬R“;	…E2ô$Nëa{j
¡„‘·À¤Vº|F4k˜•…þ"¼•²¤$OÌ}&gt;[Í&gt;´ãá¨ì©WßÖå‹ZÕq2;­4uC¨³¦2L3H¶¿,8÷‚w¨¼VZÏù"mYu«)Þ
}=?ˆoâ&lt;öòXŸÉÔÐØn¨ØžïB
e‰Xä%&lt;á|ï²w( {×hHª!B,"¨±¿²;éâ0È&gt;™‘ðãt&nbsp;j;ÀŸ².³aKV&lt;Ñ¿ÓF�XÕ�×û`ÆºýÔ¹:â‹	 –;|f²Tü�&gt;ª?†)[bª\ºœô*¢ûÉ‹2.‚7%Ø
Y^½=NîV	qL.a›8ÚEÞ(šw·²&gt;,@§¦„�S5»«˜ìÙ3®
y¤t—»ôü¤Çç©š³Û&lt;×<yù§õhnvbªgb³âó ­ü÷d,iful«í<÷¤gÍ''Ð!Êâi…‚;af¢8á4="" Ûxæ^éx{—ŒbÙÀµÀhzzlØ£¨mß³{–ÈÃum¦…ÛaßàµˆóÁ‘•€2Òqï8w¥Ððîu]vÓenc¢$&9œëÊq«¦$!Š·a¥(9jŒ0ÔÖå”•­òd×Ýð+ëÐ½q$�ˆdê8i¬j‰Õc="">oðmÍ‚ƒÁy~!å†e¼¦^YËFkf½[²®0œ-SëQ¶KIì—W\Šƒ{!§ûƒ^|½}gÓ®¡ÞªX•0Vó	¢ä¡kÐ²­ë©N–³�Dsº™»N*…ÒR†(�Þ®™Ó3C|þpaõ(±÷À\NÁ,íô
�¢Ú0�¦Ôœ/Öº›¨ûÌþgÍ/ŒŽ›øs@§zùjð6�Õ«&amp;æçÛŒßàÂ&lt;—BT¢Ià¨¿ÜíÖ6Z1?¢Ån°çã–‰çêÌo	/mÌ8¸ç§OŠx‘³Î#…Ûƒ*&lt;`‰&gt;ÂUµ†#IþÒy%ùldPxÅÈLëÛFút‰7ìhµf6…TâG#nÈ§@?�X±’4Œ»üÊ)ÿí¸š~šŸŠÈˆÖS²vR&amp;#b~8zÑfrØ¨êÜ“Ìêã	{M÷â`rãþÙ‡&nbsp;Ü Çž…J
žbßnƒ
´…Å£Z1¨&nbsp;~4’ÁJ!ðh´š#ym­Û0‹f%ºŸB"”.
¢´^ˆºÅP¥vtš›-ž3
¤AþE,{2EÇ
¤I¢&gt;¹IóÀ¹W&amp;é�´ôB'Ùt3À$òéX1"Åh½üëKÑÊÔ{6AùnŠPÊæ&nbsp;U¢ Äå
Eü®z™SopqŠ_ä-%"‘ê½žŸV\Íé þpëÇZô4Ò±š��¾‹E�-"›HP¥rùÃ(ùòKþGWÓrôu·vMŠ¶ÄóHD
UšÁ(©ð)â--çŸQprÎÆJ`Í6%ÜYY®7&gt;÷]²cí(F÷=A¶Û’]Ü­+ËNH"û	}úmF°s�Òüà�J§¤ÌwXóš¡AôÏÁ©hÛ«vö2�˜úêË€SSŸóúàx�ª¢0§¼ðÎˆV2'×�Ï¤…X—t¼qG?å»’ÜŽífæ4•ˆ,`Nªùº�ÚÍº*6˜?%}
1\¾…Yê²w»ÉŽ¾š¥XnaGý…åLóÏY#Tßësá"Ý‰!¦…ÿTì­ÈÀ%Ñ"�(þ5ÔôÉgR~vI£
?ªr�Ø_âQ‡wT9~æ/ÞR×®ïâe5Œv›q¨\&gt;ÚiŽ|·Ìkãº’¡‡µGª–Q±'“L­MÝ·B­ø*§5|£"Jœ›‘–”¤ ¸€ÐÊ5Žw
©&lt;‡šá”½_;Ä4ô£û(Á
Z¾–ÈxÍr.g´|Bá*±Ö/~âWžõîÔ&lt;ËŸFD-6±²’&gt;¼—nÈÊŒÃýHKZyÐ’ÚeB_5‰?ïi9þ²*ŠväÄ.:»%gÑ¬%8ÆàÐN‚“�Ä�ÑŽPðÓQO¤†-9ýëIœ8qô™O†1Ì^\’Š³ÉºŽý:ëâgù¯[²[ú¡ûœ‚Ño;¡àJ«	íªéÛCÍ¶Sßä3ÆùÞ�èÓ„›ùY±’#Ò¼õòKñTDH8.PÛ­zÂäû¶Ö÷i’Ç.ÒF7»
"ÏwŸ¬þïe‹�dJýéžÅAH°fa‘Ú³0�üõ‹�¬c`Ó9~¦Zö¹&lt;ÄÕ•\	Uˆ�Ïææ×Ùä)‚_|Jz²{DCç?L¹Üw…¶xRËN„ûÀ
4‡£kOÑî»|o2Ã\”ôUG®?Ùe®—J	‰ÐØäË@öµ»�Hê2=Â¼•Øv-æ’�Fæ#Ü®Iò³ÇÌÆ¶Ûó§–üªÜÈ‹òŒÀ…ò¿„iÙºá]|@‡6‹ïÖ.ÖµÈÆq~ù
gâ/Å±~ç3GAR�&nbsp;ÜÉó¿ó&gt;'ù2gHÑž¼6H
g4ð¯/©msQ«_à­�®:íÄŸRü&nbsp;/–}'
»&lt;£ë¯`(ZÈ¼4ÎÜw0ù.ÛÛ]˜Û4Ê¢môU�õ?Qàù¾Î&amp;Aè¹~ˆüöíÛ‹ñßÞñOjl”¹
endstream
endobj
183 0 obj
&lt;&lt; /Filter /FlateDecode /Length1 1421 /Length2 6662 /Length3 0 /Length 7636 &gt;&gt;
stream
xÚ�uT”m×.-Ž 
ÒCwwJJKwè03À303tw
ˆ4ˆÒ"RJŠ - ¢´€t‡ÿ¨ïû½ÿû�³Ö9ëYkžç¾vÜ{ßûºîá`10P† ì¡÷p´€ˆ&nbsp;°,PUÏØR(,,&amp;(,,
àà0�¡]¡Á3(CÀeÿ—ƒ*
Bc05ã§‡€µ=]�"b@IY)Yaa&nbsp;¨°°ÌßŽ¤,P
äƒõ�Ú8àPE¸û"aŽNhÌ6¹Á&lt;@)þßá@e7(Á�z ´Ô
³#ä
4F€aP´ï¿RpË;¡Ñî²BBÞÞÞ‚ 7” é¨ÈÃô†¡�€FPé…5¼rƒþéLÀ4q‚¡þàÆ´7	bW
Ga"&lt;á(ˆÙh¬¥Ôw‡Âÿ8ëþqàþu6@A‘ÿ¤û+úW"üw0F¸¹ƒà¾0¸#Ðæ
êßÓDû&nbsp;ù� 8ä—#È…ÀÄƒ¼@0W�=Æáwå à=eC Óà_í¡ÀH˜;%ˆ‚¹þjQèWÌ)«Ã!ª77(�üªO
†„‚1Çî+ôg².p„7Üÿ¯…qøÕÄÓ]Èóð„j©ýå‚�ÿ`ŽP4PBXFRR\õB}ÀNB¿Ò›øºCE~Á˜ýÝî@LÐ@˜óø£@^P é	
ôÿß†¯""@ŒÚCapÀ?Ù10ÔáÏ3|$Ìh-ŒážPø×óŸ/[½ ¸«ï?î¿ç+d¦fn&nbsp;lÂ÷§ãÿØTT&gt;@1a&nbsp;€Œ„PDDZ(%%üwì¯2„ÿ‰Õ‚; €2ªÅÓß{ýEî¿ÄÁüw®ûk¡@îHn#,!ÆüˆüSýwÈÿ�á¿²ü¿HþßÝótuýmæþmÿ?Ì 7˜«ï_Òz¢1ÐC`dÿoWsèÑêA!0O·ÿ¶j¡A!(Ã1dÿƒÃP÷`&gt;Pˆ
vúC™?¸é/©¹ÂàP
öënÁD	ÿ—
£/°æþ@axùÛÅÈçßûªÃÁÈ/�‰JHAH$È Œ¡“(fÞþ"AB&nbsp;&gt;¿™„#Ð˜ ¦Ç@&nbsp;	ø5V1&nbsp;…é†rÁLÁé—ñ7."*‚€1Çñ&amp;ú7±wý
ÿ«°'‰ÑäoÊ`
ý{ýû€B}&nbsp;`À§)X.Â¹&gt;¢í´V™Þ[`åÁ—¯±É–½1hÎéçþNº7²5Æ=TBªîfÌ”E�MÐóþ8ö±y›º�®ù�¥Þ»¤²+�?pvðÖÊAÐ9ŽHeÄ.‘í&lt;6d$yh�gÍõÄ|ê2RªKl­zµèªµf%³	t“²¤Ó£)çulâÄ[²°E¿·´!M$GZgzšh™Ž\áÄÃOTÚhÏ|—¬³ÞÏÏ¿ËíëÍÛ/Ðé®‘¬Š¢&nbsp;¥ôÓfÉLé§¥zœ«ÝŒÂâT‘8V-KKf¥}áÅ¹€êíþd-Óòf
¢Í½ñhçñá½æ{,xJôÖ3ãÚ�@ûÝÞúyý›.¡ä"mÛ1ùà”óùí
î&amp;‚%@‡dbÀ€¸^QbÛÁ¢¸ƒÃcÅ~UBâ|:¹Ù¡ŸÖ·ÎFíÊŽ�%¶àrÙŠ�ªÏ‰9±~ÊÝ'^&gt;uG$µQñw�,&nbsp;&amp;Q5dœô­AÓ•Ÿ:�ë†h	nûÊY	Þ?ôiª K7‹Ö•w÷pc8{'¬wC
ñ|Y¿ÅvŸˆmÎ1c­&amp;âéJÀÙŒClºD¨wË\ÕœéDÂ�K*ß¦ô­·s&gt;_ùÐWb£�Ðâ5ïœó"±yâ2=øcðVºBŸÐ×	V«Fž‚4‰ëj¦Ù6ÜÀn»‹iÁw¿û�vÏÜŠx²�ô«ÙÜñÀ~ $ž“'n™&gt;å[x‘@òá�èZÉ2~qV”ÃôU~w�o°c—2yIG4·
Aî}´ß#œúÇ%ÇE}Âc@¿oš]N8$˜9ìõ…VÇá‡9%‹ö*ÊKÿÂ©=ÿZóù�ê`Ý—�Ì
'ô
Q+%?ß›ðá
ÃK&amp;"ÙrÐd‰ŸÎ–¨’pÔ7ÉË¬=wá/òáûf£NÚ82â¹Ä�WQ8Y¸î)œ)Ü[nq«R¹Ÿð­ÃÜXìR7Á�qÖ0Ö[³ÝûBªgÖ4™.¯î"ïí‚’ãÓX×Ð¶w’e…«ùå¼õä´o›2Û6†ÁÉÌø¹(Í@ùÂá{N)E½b¶r­N
ÞG×IÌ�õöGgnÙ±~%1.Ã¤tEâ²_SiÈŽ¥F¢$�	ÃvT$Û©'ch‡/?á…Ê_x|exKÇ•xBñÕ-¸&gt;ÄUÊWØ‘½á{¨œ¦é;Á3×2^Žtañq¾k.oKiG1"[»‡“DÃd!ïéÝ5ï²û†7„ôˆ1;^B�y[ÉL²’Ùz?³;oÈD~Tí1cVýbœ(,è„¼ã¬%A�pU	y–þŽ
ßHrö¤Çm2{9&nbsp;€¦2Fjã�Èß�µs:Ñ“8�k&nbsp;À�l&amp;%/ŸÐXÓ¦Ì„¯µši,õa“‡hÏ’ÕÉ{¯…îÁery�õBPxÖò·ïÜé±µEo&nbsp;
qó
=ÏüŸj–?!Ê'¯üô”¥tÍ½b-B¯œ@Âôƒ'?–b,¬ÛÚ1ÔTÉiH*hÓ²x¬s†eXb$‰¼eõ9Ží²pÓ¯ïÜ¤û�E&gt;š×—ÚVe&amp;ÿ¥ÏÅ&nbsp;p©S®»UÇ‡Sæ&lt;ð!á\IicQÒ×2¯›š!Ù"¼I8o“‘+WÑ\a_qíÚ%§FÌ‡;ÓÈ·‰m,Ýö,�î¾ðmÍfÑJ@8òSÈ¶tæŽì§~–5Õ[ãjâÈkÐ5m/{pB:ƒ±ªti³o–ƒóîO4%¬[…ù�‰XŸÈ‰/‡ºÛ­7Ýßq¿(÷PQ’“pÍÄžÎQq=Š^ø�Lf‘rÖóÈ¥1&nbsp;hUÏ0­Ï&nbsp;1dcöª¶G�^&lt;¦Ó.‰¤}½e,3~QágÇ¼ÕÏÃ8EpwlQ@¦öz;ÏWïhvkæ•�|³Ç&amp;d5§’Œ1€W½
ŸŸ=Å»Ä]ZâMú¶Bs¯ÒUGzŒî†-{¤z¡ÛGw¥ÞBß&gt;É69`o�&amp;¯<k^n¢»r,jÔ³]áðgt¤è(Í´|fû1ª$ö 7‡Â<÷Õ`ÿ—}µçeÓüœõn,}ŸÂËbffé¶="~ÚëðôM:ÄÊK/ðƒ¤Ì''{ÓUÒ|NÃÆðôÔD%Ç.–‹è|kY¯dó&quot;‡Y¢ÈXÕ–€rnlûÙ]\X­Yæª�_'ã¨ËP&nbsp;Uy°²ÆÁR<M‹óç³Ðå­åÅ¨" £ãpæšêÝwn»œiõõ}¶›ÑÅpóð°;ýàÂåœm·%y¯~n?Þ8v›®="">¾.&gt;™«³Ü{FÎÞ730W�·¯F­èýÉè2´?Ä*ô:�rEºgé­ªtN–ç4�õ¹ºäI¶WÞ]¥ŽmA§yì�s’—Z(úRb·^i“7:=ì&lt;)‹ã]áÜ×·,wñ½•¾uwˆ9Y÷˜¦öµ´ßd‹ê&lt;Œ8&amp;J¶g5x:X[éÖ?Ž™G6?üG&amp;ÈP^è
cÇõ.¹{çGm,µ2&nbsp;�ý¼¬2‘¬J¿‹&nbsp;Ii
¬8ž¬.z{nJ+Çö¥Ñr'ß»änÝLÙ›"¨›ôú0s&nbsp;îüî¥ƒ¼Iêyö½T<h®f-×±!ég›.o�égÏæÉž� {@½s"vay;="" *‚ŸÈ™–x‰xŒºÙeÞä-‰�}vù¢:c¶ËÂój|¹¢võÍ+¿¦{¬="" s­¬Ô="" ¸ÆÌÄ¾»ÃŒo:ø³f¯ù÷l#ÂèÓc="">p/á)Šx0qŠº1Äí»S‹jQ3ê\å«pÍyk„÷ÑE?lF¦j¥­R&amp;�Z_ü(?ÐuþÈ½þÃ‡Àž
Z�nÐ5æÖÇ½Sßš!m{j‹–Î]e1e�ÞˆyB¨R\„#ñ£î:K´;¹‰ŽHë{Ž6A*Ü¼êdì•Ò,ˆô½l©gÕSÚOßªCñ×Ÿ€¥R£|gè(fN’³@‹†éúÏ¸™â¯Iò}Žã]Þz@è
¥ÎÀ^{€ÒÇ4‡„¶mþ¯RªäWGˆ×i7u,F™¥î‘ÛÓq…µÁ“`¿œOþäÝæDÖ²/ÂŒJXÒ´…ûpÜÁ"à§*=f:¸f,9„&amp;U]«®á=‘–/‹IµpÈ.âc\_~÷å�½9ñrL;ô34
Ò¶)©:ºÀ�RmurþUWfâ�­¥‡âó`ZŸ<f¡¼´õ‚ ýÏÒ¹5ål¬ŠÙßÎc*Ë�êõc¸(îpêÑxæ]¾‡˜_v7±Ðçm�*ý="" g‰Á="" êób+µèèðÔxÚòhýåÙl�ÿ-ŒaÑ(³ÇrdÙˆfò“'îÏoï‰†¦="" k6};eç¼[ÜŠoé|h¹¦="" Àk:–«yø3·ª2jœÄr‘azùå±¤Ùæ§ãtzlÕùÒtya#æo‘��o(n="©=UÕ!Ý#Õ?L¸GÕ3Ï%—7�n$R/ˆÍWê&quot;Ø¬¹Z(—ÞÚ?JRXÇ6V,wŸ" s_*Šc"o™�l{ÀÆk-÷ôÛÚ®æÉùkÇªËb“ó"¦Àå±íhß¡×edü‹”dùoñÍíxz‹…s="" y†ˆááè²�h©úy×wÂoj¥­ãÃÁ@¥çÂøi!å&á7ˆÒªj¥“¯pd�g‰£Ëmsõjórgãpê="">épÝfù&gt;õp?¤óL/#Úf­¹P±ñˆNèíu›ƒÆ‘ÓôRGLr]žaH~"1yÕõg¿"ÅËÁ—Ãš�)ÙEÇÖð0‚'­¸æ
ýxsU…A(UÁñ,¥ZÓó¶:=Š¡�|Ï¾D;7¬:b©b5¹Ã­æ¢m¾”úÕÚ!pFš%ÆäM;¾ÑŒU�É3Ù˜bþð®aUÄ:gM©ïý3bX7¬GÕ�rRíœpø·/µ&nbsp;…	œä,pöÐ«3E[ïÝŽv¬UKœÝj~q3®åSWì‘0{´ïKpHh%HÃ×RYÁ#¦Ì‚0OJÇ$æîW»Oú'ÜËâ¢ÌÓp÷=õz}Ø¢P“¯ŸôZ®¤Ž¹]Œ¤Wù®2êÛ*ÝÔhºPEwË»’ÌFz#Ÿ�H¥j²Auð%ót#&nbsp;Ÿb'“H‰óUüØucÊ&lt;5Lã2—àï._›/Ö�¾¨›lËïz](¨&lt;ƒÏ"KY8Q«ò„¯²¾žäzÞ�˜8à1&nbsp;:¶\/¶ÏyUÝÿ³BÃø"qü›þ…</f¡¼´õ‚></h®f-×±!ég›.o�égïæéž�></k^n¢»r,jô³]áðgt¤è(í´|fû1ª$ö></yù§õhnvbªgb³âó></a”o�è_vÿø¹`3�t´,5bpfÿr1˜þñ“ª7w·‘ûíé¯müyöy@2�ü�—i*a^ür+cîùh=6škîûað³5º�ù™ò¾²></o¨n€çøð0¨ç¾xýi±.üo-öt[lœ¹‹;—ùôáq~µmxt7œøl¹í¸5];¼&h^ã%s?õðëóà%ntþ2ì}5¼=a®_z></ulš²-ûbhag·=©óñ~yv%«þy.í»1ÿ÷™êy–}í6¶o«“t_»º¼æ#´à¼dòé¨úu÷></mƒa8:,#è-�‘<�sˆ></wtó€></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://damonmccoy.com/papers/ecrime2019.pdf">https://damonmccoy.com/papers/ecrime2019.pdf</a></em></p>]]>
            </description>
            <link>https://damonmccoy.com/papers/ecrime2019.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030329</guid>
            <pubDate>Mon, 09 Nov 2020 00:23:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub Whoami via SSH]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25030301">thread link</a>) | @menduz
<br/>
November 8, 2020 | https://menduz.com/posts/2020.11.08 | <a href="https://web.archive.org/web/*/https://menduz.com/posts/2020.11.08">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>There is a very easy way to know know which Github user is associated with your SSH key.<!--more--> 
Executing <code>ssh -T <a href="https://menduz.com/cdn-cgi/l/email-protection" data-cfemail="e2858b96a2858b968a9780cc818d8f">[email&nbsp;protected]</a></code>, you will receive a greeting with your username.</p>

<div><div><pre><code>❭ ssh <span>-T</span> <a href="https://menduz.com/cdn-cgi/l/email-protection" data-cfemail="3e59574a7e59574a564b5c105d5153">[email&nbsp;protected]</a>
Hi menduz! Youve successfully authenticated, but GitHub does not provide shell access.
</code></pre></div></div>

<p>To extract the username we can run <code>sed</code> over the response.</p>



<h2 id="importing-gpg-keys">Importing GPG keys</h2>

<p>I use my YubiKey to store both my GPG and SSH. But having the SSH working out of the box is way easier than GPG, the last requires the machine to know the public key before it can be used. And it can be either downloaded from a key server, plain .asc files, or like in my case: download it from my Github profile.</p>

<p>To do so, I leverage the <code>https://github.com/{username}.gpg</code> function.</p>

<p>Since we now know the username associated with the SSH in the YubiKey (the previous step), we can get the GPG keys like this:</p>

<div><div><pre><code>❭ <span># this step may require you to touch the YubiKey</span>
❭ <span>username</span><span>=</span><span>$(</span>ssh <span>-T</span> <a href="https://menduz.com/cdn-cgi/l/email-protection" data-cfemail="fb9c928fbb9c928f938e99d5989496">[email&nbsp;protected]</a> 2&gt;&amp;1 | <span>sed</span> <span>'s/^Hi //'</span> | <span>sed</span> <span>'s/\! .*//'</span><span>)</span>
❭ curl <span>--silent</span> <span>"https://github.com/</span><span>${</span><span>username</span><span>}</span><span>.gpg"</span> | gpg <span>--import</span>
</code></pre></div></div>

<p>Check it works running <code>gpg --card-status</code> and search for the email in the “General key info” section, it must match your GPG’s. If it doesn’t show up, make sure you are importing the same keys present in the card.</p>

<div><div><pre><code>❭ gpg <span>--card-status</span> | <span>grep</span> <span>"General key info"</span>
General key info..: pub  ed25519/3ABC123401923E0A 2020-11-08 Agustin Mendez &lt;<a href="https://menduz.com/cdn-cgi/l/email-protection" data-cfemail="720b1d070032171f131b1e5c111d1f">[email&nbsp;protected]</a>&gt;
</code></pre></div></div>

<h2 id="setting-up-git">Setting up Git</h2>

<p>Now that we already have our GPG and SSH working, we must configure Git to use the GPG and the mail.</p>

<p>To do so, the email address from the GPG will be used (which is a requirement for Github).</p>

<div><div><pre><code>
<span># Read email from the --card-status</span>
<span>CARD_MAIL</span><span>=</span><span>$(</span>gpg <span>--card-status</span> | <span>grep</span> <span>-Po</span> <span>--color</span><span>=</span>never <span>"(?&lt;=&lt;).*(?=&gt;)"</span><span>)</span>

<span>if</span> <span>[[</span> <span>$?</span> <span>==</span> 0 <span>]]</span><span>;</span> <span>then
  </span><span>echo</span> <span>"&gt; Using mail: </span><span>${</span><span>CARD_MAIL</span><span>}</span><span>"</span>
  <span>CARD_NAME</span><span>=</span><span>$(</span>gpg <span>--card-status</span> | <span>grep</span> <span>-Po</span> <span>--color</span><span>=</span>never <span>"(?&lt;=[0-9]{4}-[0-9]{2}-[0-9]{2} ).*(?= &lt;</span><span>${</span><span>CARD_MAIL</span><span>}</span><span>)"</span><span>)</span>

  <span>if</span> <span>[[</span> <span>$?</span> <span>!=</span> 0 <span>]]</span><span>;</span> <span>then
    </span><span>echo</span> <span>"&gt; ! Cannot find CARD_NAME."</span>
    <span>echo</span> <span>"&gt; FAILED!"</span>
  <span>else
    </span><span>echo</span> <span>"&gt; Using name: </span><span>${</span><span>CARD_NAME</span><span>}</span><span>"</span>
    <span>KEY_ID</span><span>=</span><span>$(</span>gpg <span>--keyid-format</span> none <span>--list-key</span> <span>"</span><span>${</span><span>CARD_MAIL</span><span>}</span><span>"</span> | <span>grep</span> <span>-Po</span> <span>"[A-F0-9]{40}"</span><span>)</span>
    <span>if</span> <span>[[</span> <span>$?</span> <span>==</span> 0 <span>]]</span><span>;</span> <span>then
      </span><span>echo</span> <span>"&gt; Using key:  </span><span>${</span><span>KEY_ID</span><span>}</span><span>"</span>
      git config <span>--global</span> user.name <span>"</span><span>${</span><span>CARD_NAME</span><span>}</span><span>"</span>
      git config <span>--global</span> user.email <span>"</span><span>${</span><span>CARD_MAIL</span><span>}</span><span>"</span>
      git config <span>--global</span> commit.gpgsign <span>true
      </span>git config <span>--global</span> user.signingkey <span>"</span><span>${</span><span>KEY_ID</span><span>}</span><span>"</span>
      <span># git config --global url."ssh://<a href="https://menduz.com/cdn-cgi/l/email-protection" data-cfemail="2a4d435e6a4d435e425f4804494547">[email&nbsp;protected]</a>/".insteadOf "https://github.com/"</span>

      <span>echo</span> <span>"&gt; SUCCESS!"</span>
    <span>else
      </span><span>echo</span> <span>"&gt; ! Cannot find KEY_ID"</span>
      <span>echo</span> <span>"&gt; FAILED!"</span>
    <span>fi
  fi
else
  </span><span>echo</span> <span>"&gt; ! No known yubikey was detected."</span>
  <span>echo</span> <span>"&gt; FAILED!"</span>
<span>fi</span>
</code></pre></div></div>



<p>Did you know you are sending your identities every time you connect to an ssh server?</p>

<p>Be careful to not leak your keys to every place you want to connect to.</p>

<p>To do so, create an identity for each site you want to connect to and add the following lines to your <code>~/.ssh/config</code> file:</p>

<div><div><pre><code>IdentitiesOnly <span>yes

</span>Host github.com
  IdentityFile ~/.ssh/id_rsa_yubikey.pub
</code></pre></div></div>

<p>To get the public key from your SSH in the YubiKey run:</p>

<div><div><pre><code>ssh-add <span>-L</span> | <span>grep</span> <span>"cardno"</span> <span>&gt;</span> ~/.ssh/id_rsa_yubikey.pub
</code></pre></div></div>

<p>That is part of my https://menduz.com/bootstrap.sh script, used every time I set up a new machine or when I think that my machine was somehow compromised.</p>
 
  </div></div>]]>
            </description>
            <link>https://menduz.com/posts/2020.11.08</link>
            <guid isPermaLink="false">hacker-news-small-sites-25030301</guid>
            <pubDate>Mon, 09 Nov 2020 00:17:07 GMT</pubDate>
        </item>
    </channel>
</rss>
