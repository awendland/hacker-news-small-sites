<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 04 Feb 2021 04:34:20 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 04 Feb 2021 04:34:20 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[UUID Primary Key in Elixir Phoenix with PostgreSQL and Ecto]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25998969">thread link</a>) | @pawurb
<br/>
February 2, 2021 | https://pawelurbanek.com/elixir-phoenix-uuid | <a href="https://web.archive.org/web/*/https://pawelurbanek.com/elixir-phoenix-uuid">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><img title="UUID in PostgreSQL Ecto and Phoenix are presented by sheep Photo by Massimiliano Martini on Unsplash" alt="UUID in PostgreSQL Ecto and Phoenix are presented by sheep Photo by Massimiliano Martini on Unsplash" data-src="https://pawelurbanek.com/assets/phoenix-uuid-berries-5f0a260a1179e9d85a99e145fe21aac830bf6ce4f69f8bbf020559f7daeca581.jpg" src="https://pawelurbanek.com/assets/phoenix-uuid-berries-thumb-0e16f18ada64c57876f3eee963c36f40cace0df97c72189ecb3dca601e5b1521.jpg">
</p>
<br>


<p>UUID also known as GUID is an alternative primary key type for SQL databases. It offers some non-obvious advantages compared to standard integer-based keys. Phoenix provides reliable support for working with UUID using its Ecto PostgreSQL adapter. In this tutorial, we will dive deep into UUIDs with all their cons and pros.</p>
<h2 id="benefits-of-using-uuids-instead-of-integers">Benefits of using UUIDs instead of integers</h2>
<p>UUID is a random string in a predefined format. Sample value looks like that:</p>
<p><code>ccbb63c0-a8cd-47b7-8445-5d85e9c80977</code></p>
<p>UUID is superior to integer-based primary keys in many ways. One caveat might be the size of database indexes, but for non-big-data tables, you shouldn’t notice the difference between integers and UUIDs.</p>


<h3 id="exposing-non-public-information-in-urls">Exposing non-public information in URLs</h3>
<p>A primary key value is usually publicly discoverable in URLs and API network logs. In turn, everyone can roughly estimate the app’s resources, total number, and pace of growth. Do you really want to expose how many users are signing up to your service or how many products you are selling with public URLs like:</p>
<div><div><pre><code>/orders/2234/checkout
/users/287/profile
</code></pre></div></div>
<p>This issue could be mitigated by adding slugs, but these are just duplicated unique keys with additional maintenance required.</p>
<p>Switching to UUID results in URLs that don’t expose any potentially confidential information:</p>
<div><div><pre><code>/orders/cc7a4c8b-1a90-4287-a983-3f6e10bd88d4/checkout
/users/6b6cabb3-e37d-4dd1-ae18-a4eb893b07ae/profile
</code></pre></div></div>
<h3 id="access-scoping-bugs">Access scoping bugs</h3>
<p>Properly scoping access to resources in web apps with non-trivial business logic is hard. It’s possible to ship code like:</p>
<figure><pre><code data-lang="elixir"><span>defmodule</span> <span>YourAppWeb</span><span>.</span><span>InvoiceController</span> <span>do</span>
  <span># ...</span>

  <span>def</span> <span>show</span><span>(</span><span>conn</span><span>,</span> <span>%{</span><span>"</span><span>id"</span> <span>=&gt;</span> <span>id</span><span>})</span> <span>do</span>
    <span>invoice</span> <span>=</span> <span>Repo</span><span>.</span><span>get</span><span>(</span><span>Invoice</span><span>,</span> <span>id</span><span>)</span>

    <span>render</span><span>(</span><span>conn</span><span>,</span> <span>"</span><span>show.html"</span><span>,</span> <span>invoice:</span> <span>invoice</span><span>)</span>
  <span>end</span>
<span>end</span></code></pre></figure>
<p>instead of:</p>
<figure><pre><code data-lang="elixir"><span>defmodule</span> <span>YourAppWeb</span><span>.</span><span>InvoiceController</span> <span>do</span>
  <span># ...</span>

  <span>def</span> <span>show</span><span>(</span><span>conn</span><span>,</span> <span>%{</span><span>"</span><span>id"</span> <span>=&gt;</span> <span>id</span><span>},</span> <span>current_user</span><span>)</span> <span>do</span>
    <span>invoice</span> <span>=</span> <span>Repo</span><span>.</span><span>one</span><span>(</span>
                <span>from</span> <span>a</span> <span>in</span> <span>Invoice</span><span>,</span>
                <span>where:</span> <span>a</span><span>.</span><span>id</span> <span>==</span> <span>^</span><span>id</span> <span>and</span> <span>a</span><span>.</span><span>user_id</span> <span>==</span> <span>^</span><span>current_user</span><span>.</span><span>id</span>
              <span>)</span>

    <span>render</span><span>(</span><span>conn</span><span>,</span> <span>"</span><span>show.html"</span><span>,</span> <span>invoice:</span> <span>invoice</span><span>)</span>
  <span>end</span>
<span>end</span></code></pre></figure>
<p>This example might seem obvious, but in apps with multiple user roles and complex logic for who can access what, it’s not always possible to completely prevent similar mistakes.</p>
<p>If invoice ID was a UUID type in the above example, it would make it impossible for an attacker to sequentially scan integer ID values looking for a security hole. This simple change makes a range of potential security bugs extremely unlikely to exploit.</p>
<p>By no means, I claim that using UUID releases you from the necessity to scope access to resources in your web app. Still, it might save you in case a similar security loophole was discovered in your project.</p>
<h3 id="frontend-independence">Frontend “independence”</h3>
<p>UUID primary keys allow frontend applications to independently generate new objects, together with IDs, without talking to the backend. A unique ID can be created using the JavaScript code, and the chances of collision with already existing objects are negligible.</p>
<p>This approach opens up a whole array of possibilities for frontend developers, e.g., to batch create objects together with their associations without the overhead of API calls.</p>
<h2 id="uuid-formats-in-elixir-ecto">UUID formats in Elixir Ecto</h2>
<p>You can generate UUID with Elixir by running:</p>
<figure><pre><code data-lang="elixir"><span>Ecto</span><span>.</span><span>UUID</span><span>.</span><span>generate</span><span>()</span>
<span># "b436517a-e294-4211-8312-8576933f2db1"</span></code></pre></figure>
<p>Under the hood string format of UUID is converted to binary when interacting with the database layer. To generate a sample binary UUID run:</p>
<figure><pre><code data-lang="elixir"><span>Ecto</span><span>.</span><span>UUID</span><span>.</span><span>bingenerate</span><span>()</span>
<span># &lt;&lt;72, 143, 56, 198, 127, 12, 78, 152, 141, 149, 101, 55, 70, 15, 236, 224&gt;&gt;</span></code></pre></figure>
<p>You can convert one format to another in the following way:</p>
<figure><pre><code data-lang="elixir"><span>Ecto</span><span>.</span><span>UUID</span><span>.</span><span>dump</span><span>(</span><span>"</span><span>b436517a-e294-4211-8312-8576933f2db1"</span><span>)</span>

<span># {:ok, &lt;&lt;180, 54, 81, 122, 226, 148, 66, 17, 131, 18, 133, 118, 147, 63, 45, 177&gt;&gt;}</span>

<span>Ecto</span><span>.</span><span>UUID</span><span>.</span><span>load</span><span>(</span><span>&lt;&lt;</span><span>180</span><span>,</span> <span>54</span><span>,</span> <span>81</span><span>,</span> <span>122</span><span>,</span> <span>226</span><span>,</span> <span>148</span><span>,</span> <span>66</span><span>,</span> <span>17</span><span>,</span> <span>131</span><span>,</span> <span>18</span><span>,</span> <span>133</span><span>,</span> <span>118</span><span>,</span> <span>147</span><span>,</span> <span>63</span><span>,</span> <span>45</span><span>,</span> <span>177</span><span>&gt;&gt;</span><span>)</span>

<span># {:ok, "b436517a-e294-4211-8312-8576933f2db1"}</span></code></pre></figure>
<h2 id="how-to-start-using-uuid-in-elixir-phoenix-apps">How to start using UUID in Elixir Phoenix apps</h2>
<p>First, generate the following migration:</p>
<p><code>priv/repo/migrations/20201217143615_create_users.exs</code></p>
<figure><pre><code data-lang="elixir"><span>defmodule</span> <span>YourApp</span><span>.</span><span>Repo</span><span>.</span><span>Migrations</span><span>.</span><span>CreateUsers</span> <span>do</span>
  <span>use</span> <span>Ecto</span><span>.</span><span>Migration</span>

  <span>def</span> <span>change</span> <span>do</span>
    <span>create</span> <span>table</span><span>(</span><span>:users</span><span>,</span> <span>primary_key:</span> <span>false</span><span>)</span> <span>do</span>
      <span>add</span> <span>:id</span><span>,</span> <span>:uuid</span><span>,</span> <span>primary_key:</span> <span>true</span><span>,</span> <span>null:</span> <span>false</span>

      <span>timestamps</span><span>()</span>
    <span>end</span>
  <span>end</span>
<span>end</span></code></pre></figure>
<p>Don’t forget to run it:</p>
<figure><pre><code data-lang="bash">mix ecto.migrate</code></pre></figure>
<p>Now add the corresponding schema module:</p>
<p><code>lib/your_app/accounts/user.ex</code></p>
<figure><pre><code data-lang="elixir"><span>defmodule</span> <span>YourApp</span><span>.</span><span>Accounts</span><span>.</span><span>User</span> <span>do</span>
  <span>use</span> <span>Ecto</span><span>.</span><span>Schema</span>
  <span>import</span> <span>Ecto</span><span>.</span><span>Changeset</span>

  <span>@primary_key</span> <span>{</span><span>:id</span><span>,</span> <span>Ecto</span><span>.</span><span>UUID</span><span>,</span> <span>autogenerate:</span> <span>true</span><span>}</span>

  <span>schema</span> <span>"</span><span>users"</span> <span>do</span>
    <span>timestamps</span><span>()</span>
  <span>end</span>
<span>end</span></code></pre></figure>
<p>You can use string UUID format when building queries. Just remember always to prefix even the literal values with <code>^</code> because otherwise, you’ll get a somewhat cryptic error:</p>
<figure><pre><code data-lang="elixir"><span># Incorrect</span>

<span>Repo</span><span>.</span><span>one</span><span>(</span>
  <span>from</span> <span>a</span> <span>in</span> <span>Area</span><span>,</span>
  <span>where:</span> <span>a</span><span>.</span><span>id</span> <span>==</span> <span>"</span><span>1e24165e-7f1d-4169-8ebe-869b7d1b7c90"</span>
<span>)</span>

<span># ** (EXIT from #PID&lt;0.470.0&gt;) shell process exited with reason: an exception was raised:</span>
<span># ** (ArgumentError) argument error</span>
<span># (stdlib 3.13.2) :io.put_chars(:standard_io, :unicode</span>

<span>Repo</span><span>.</span><span>one</span><span>(</span>
  <span>from</span> <span>a</span> <span>in</span> <span>Area</span><span>,</span>
  <span>where:</span> <span>a</span><span>.</span><span>id</span> <span>==</span> <span>^</span><span>"</span><span>1e24165e-7f1d-4169-8ebe-869b7d1b7c90"</span>
<span>)</span>

<span># %YourApp.Accounts.User{ ... }</span></code></pre></figure>
<h3 id="generating-uuid-using-postgresql-function">Generating UUID using PostgreSQL function</h3>
<p><code>autogenerate: true</code> configures Ecto to generate random UUID values for newly created objects. Alternatively, you could generate UUIDs at the PostgreSQL level by editing your migration like that:</p>
<figure><pre><code data-lang="elixir"><span>defmodule</span> <span>YourApp</span><span>.</span><span>Repo</span><span>.</span><span>Migrations</span><span>.</span><span>CreateUsers</span> <span>do</span>
  <span>use</span> <span>Ecto</span><span>.</span><span>Migration</span>

  <span>def</span> <span>change</span> <span>do</span>
    <span>execute</span> <span>"</span><span>CREATE EXTENSION IF NOT EXISTS pgcrypto"</span>

    <span>create</span> <span>table</span><span>(</span><span>:users</span><span>,</span> <span>primary_key:</span> <span>false</span><span>)</span> <span>do</span>
      <span>add</span> <span>:id</span><span>,</span> <span>:uuid</span><span>,</span> <span>primary_key:</span> <span>true</span><span>,</span> <span>null:</span> <span>false</span><span>,</span> <span>default:</span> <span>fragment</span><span>(</span><span>"</span><span>gen_random_uuid()"</span><span>)</span>

      <span>timestamps</span><span>()</span>
    <span>end</span>
  <span>end</span>
<span>end</span></code></pre></figure>
<p>If you decide to do it, remember to use the <code>returning</code> option when inserting new objects. Without it, Ecto would not fetch default column values generated by PostgreSQL functions.</p>
<figure><pre><code data-lang="elixir">  <span>def</span> <span>create_user</span><span>(</span><span>attrs</span><span>)</span> <span>do</span>
    <span>%</span><span>User</span><span>{}</span>
    <span>|&gt;</span> <span>User</span><span>.</span><span>changeset</span><span>(</span><span>attrs</span><span>)</span>
    <span>|&gt;</span> <span>Repo</span><span>.</span><span>insert</span><span>(</span><span>returning:</span> <span>[</span><span>:id</span><span>])</span>
  <span>end</span></code></pre></figure>
<p>Let’s have a look at the resulting SQL query with and without <code>returning: [:id]</code> config:</p>
<figure><pre><code data-lang="sql"><span>INSERT</span> <span>INTO</span> <span>"users"</span> <span>(</span><span>"email"</span><span>,</span><span>"inserted_at"</span><span>,</span><span>"updated_at"</span><span>)</span>
  <span>VALUES</span> <span>(</span><span>$</span><span>1</span><span>,</span><span>$</span><span>2</span><span>,</span><span>$</span><span>3</span><span>)</span>
  <span>[</span><span>"<a href="https://pawelurbanek.com/cdn-cgi/l/email-protection" data-cfemail="9afff7fbf3f6daffe2fbf7eaf6ffb4f9f5f7">[email&nbsp;protected]</a>"</span><span>,</span> <span>~</span><span>N</span><span>[</span><span>2021</span><span>-</span><span>01</span><span>-</span><span>14</span> <span>15</span><span>:</span><span>46</span><span>:</span><span>49</span><span>],</span> <span>~</span><span>N</span><span>[</span><span>2021</span><span>-</span><span>01</span><span>-</span><span>14</span> <span>15</span><span>:</span><span>46</span><span>:</span><span>49</span><span>]]</span></code></pre></figure>
<p>Insert query without <code>returning</code> option</p>
<figure><pre><code data-lang="sql"><span>INSERT</span> <span>INTO</span> <span>"users"</span> <span>(</span><span>"email"</span><span>,</span><span>"inserted_at"</span><span>,</span><span>"updated_at"</span><span>)</span>
  <span>VALUES</span> <span>(</span><span>$</span><span>1</span><span>,</span><span>$</span><span>2</span><span>,</span><span>$</span><span>3</span><span>)</span> <span>RETURNING</span> <span>"id"</span>
  <span>[</span><span>"<a href="https://pawelurbanek.com/cdn-cgi/l/email-protection" data-cfemail="8beee6eae2e7cbeef3eae6fbe7eea5e8e4e6">[email&nbsp;protected]</a>"</span><span>,</span> <span>~</span><span>N</span><span>[</span><span>2021</span><span>-</span><span>01</span><span>-</span><span>14</span> <span>15</span><span>:</span><span>46</span><span>:</span><span>49</span><span>],</span> <span>~</span><span>N</span><span>[</span><span>2021</span><span>-</span><span>01</span><span>-</span><span>14</span> <span>15</span><span>:</span><span>46</span><span>:</span><span>49</span><span>]]</span></code></pre></figure>
<p>Insert query with <code>returning</code> option</p>
<h3 id="using-uuid-as-a-default">Using UUID as a default</h3>
<p>If you’re starting a new project and would like all your schemas to leverage UUIDs for primary keys without customizing their migrations, you need to add the following line to your config file.</p>
<p><code>config/config.exs</code></p>
<figure><pre><code data-lang="elixir"><span>config</span> <span>:your_app</span><span>,</span> <span>yourapp</span><span>.</span><span>repo</span><span>,</span> <span>migration_primary_key:</span> <span>[</span><span>type:</span> <span>:uuid</span><span>]</span></code></pre></figure>
<p>If you did not create the project yet, you could use a <code>--binary-id</code> flag to configure it automatically:</p>
<figure><pre><code data-lang="bash">mix phx.new your_app <span>--binary-id</span></code></pre></figure>
<h2 id="how-to-migrate-a-table-from-integer-to-uuid-primary-key">How to migrate a table from integer to UUID primary key?</h2>
<p>Changing the primary key type in the table is not straightforward. You need to start by running a similar migration that will create a new <code>uuid</code> column. Then rename the old <code>id</code> column to <code>integer_id</code>, unset it as the primary key in favor of the new <code>uuid</code> column after renaming it to <code>id</code>.</p>
<figure><pre><code data-lang="elixir"><span>defmodule</span> <span>YourApp</span><span>.</span><span>Repo</span><span>.</span><span>Migrations</span><span>.</span><span>UsersPrimaryKey</span> <span>do</span>
  <span>use</span> <span>Ecto</span><span>.</span><span>Migration</span>

  <span>def</span> <span>up</span>
    <span>alter</span> <span>table</span><span>(</span><span>"</span><span>users"</span><span>)</span> <span>do</span>
      <span>add</span> <span>:uuid</span><span>,</span> <span>:uuid</span><span>,</span> <span>default:</span> <span>fragment</span><span>(</span><span>"</span><span>gen_random_uuid()"</span><span>),</span> <span>null:</span> <span>false</span>
    <span>end</span>

    <span>rename_column</span> <span>table</span><span>(</span><span>"</span><span>users"</span><span>),</span> <span>:id</span><span>,</span> <span>to:</span> <span>:integer_id</span>
    <span>rename_column</span> <span>table</span><span>(</span><span>"</span><span>users"</span><span>),</span> <span>:uuid</span><span>,</span> <span>to:</span> <span>:id</span>

    <span>execute</span> <span>"</span><span>ALTER TABLE users drop constraint users_pkey;"</span>
    <span>execute</span> <span>"</span><span>ALTER TABLE users ADD PRIMARY KEY (id);"</span>

    <span># Optionally you remove auto-incremented</span>
    <span># default value for integer_id column</span>
    <span>execute</span> <span>"</span><span>ALTER TABLE ONLY users ALTER COLUMN integer_id DROP DEFAULT;"</span>

    <span>alter</span> <span>table</span><span>(</span><span>"</span><span>users"</span><span>)</span> <span>do</span>
      <span>modify</span> <span>:integer_id</span><span>,</span> <span>:bigint</span><span>,</span> <span>null:</span> <span>true</span>
    <span>end</span>

    <span>execute</span> <span>"</span><span>DROP SEQUENCE IF EXISTS users_id_seq"</span>
  <span>end</span>

  <span>def</span> <span>down</span> <span>do</span>
    <span>raise</span> <span>Ecto</span><span>.</span><span>MigrationError</span><span>,</span> <span>"</span><span>Irreversible migration"</span>
  <span>end</span>
<span>end</span></code></pre></figure>
<p>I will not detail how to migrate associations because it will differ for every use case. You need to follow the similar steps of adding a new GUID type column and based on the value from the old integer foreign key, you must assign correct UUID keys.</p>
<h2 id="caveats-of-working-with-uuid">Caveats of working with UUID</h2>
<h3 id="binary-logs">Binary logs</h3>
<p>You only need the string format to construct the UUID queries. Unfortunately, currently, Ecto displays the binary format in the logs, so you’ll need to do the manual conversion to work with them. I’ve <a href="https://github.com/elixir-ecto/ecto_sql/pull/292" target="_blank" rel="noopener noreferrer">opened a PR</a> trying to improve it.</p>
<p><img alt="Binary UUID format displayed in Elixir Phoenix logs" title="Binary UUID format displayed in Elixir Phoenix logs" loading="lazy" src="https://pawelurbanek.com/assets/uuid-binary-logs-611dd7b6b8e97ef17a33c1f45402ff8aadb410e0a4bce533f717415717dceb94.png"></p>
<p>Binary UUID format displayed in Phoenix logs</p>
<h3 id="implicit-ordering-issue">Implicit ordering issue</h3>
<p><code>first</code> and <code>last</code> Query.API methods may seem broken when used with UUIDs. By default, they sort objects based on their primary key.</p>
<p>Integer primary keys are generated sequentially. We can assume that the most recently created object will have the highest ID value.</p>
<p>On the contrary, due to UUID’s totally random nature, it is generated in a non-sequential order. PostgreSQL can still sort them using the deterministic algorithm. It means that a single UUID from the table will always have a first place when sorting. Unfortunately, it has nothing to do with when it was generated compared to other UUID values from the same table.</p>
<p>It results in a seemingly buggy behavior of first and last methods. To remediate that, make sure to always explicitly pass the column name by which you want to sort your collection. In most cases, you’ll probably want to use <code>inserted_at</code> instead of <code>id</code>. One catch here is that the <code>inserted_at</code> column is not guaranteed to be unique. To avoid inconsistent results, always make sure to subsort your results by primary key:</p>
<figure><pre><code data-lang="elixir"><span># Without UUIDs</span>

<span>User</span> <span>|&gt;</span> <span>first</span> <span>|&gt;</span> <span>Repo</span><span>.</span><span>one</span>

<span># With UUIDs</span>

<span>User</span> <span>|&gt;</span> <span>first</span><span>([</span><span>:inserted_at</span><span>,</span> <span>:id</span><span>])</span> <span>|&gt;</span> <span>Repo</span><span>.</span><span>one</span></code></pre></figure>
<p>BTW you can check out my <a href="https://github.com/pawurb/ecto_extras" target="_blank" rel="noopener noreferrer">EctoExtras package</a>. It implements a set of simple helper functions that I find missing from the default Ecto implementation. With <code>EctoExtras</code>, the above example could look like that:</p>
<figure><pre><code data-lang="elixir"><span># Without UUIDs</span>

<span>Re…</span></code></pre></figure></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pawelurbanek.com/elixir-phoenix-uuid">https://pawelurbanek.com/elixir-phoenix-uuid</a></em></p>]]>
            </description>
            <link>https://pawelurbanek.com/elixir-phoenix-uuid</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998969</guid>
            <pubDate>Tue, 02 Feb 2021 09:37:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Hosted VPN with WireGuard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25998852">thread link</a>) | @modmodmod
<br/>
February 2, 2021 | https://cri.dev/posts/2021-02-01-5-dollar-easy-self-hosted-vpn-setup/ | <a href="https://web.archive.org/web/*/https://cri.dev/posts/2021-02-01-5-dollar-easy-self-hosted-vpn-setup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>This will take you less than 5 minutes to get a private VPN on your own Ubuntu server.</p>
<p>What you need to get started:</p>
<ul>
<li>a VPS (Ubuntu 20.04 LTS preferrably)</li>
<li>docker and docker-compose installed</li>
</ul>
<h2 id="setting-up-docker-compose"><a href="#setting-up-docker-compose">#</a> Setting up docker-compose</h2>
<p>On the VPS, I suggest to do the following:</p>
<p>Create a folder <code>wireguard/config</code> in your $HOME:</p>
<pre><code>mkdir -p wireguard/config
</code></pre>
<p>Inside the <code>wireguard</code> folder (next to the <code>config</code> folder), create the docker-compose file:</p>
<pre><code>vim docker-compose.yml
</code></pre>
<p>With the following contents:</p>
<pre><code>version: "2.1"
services:
  wireguard:
    image: linuxserver/wireguard
    container_name: wireguard
    cap_add:
      - NET_ADMIN
      - SYS_MODULE
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Europe/Rome
      - SERVERURL=YOUR_IP_OR_DNS_NAME_OF_YOUR_SERVER #optional
      - SERVERPORT=51820
      - PEERS=5
    volumes:
      - /home/YOUR_USERNAME/wireguard/config:/config
      - /lib/modules:/lib/modules
    ports:
      - 51820:51820/udp
    sysctls:
      - net.ipv4.conf.all.src_valid_mark=1
    restart: always
</code></pre>
<p>Simply change the <code>SERVERURL</code> variable, or delete that line if you want to use the server IP.</p>
<p>Additionally, change the location of your wireguard config path in the <code>volumes</code> section. (use <code>pwd</code> to get the current path you are in).</p>
<p><strong>For more info and environment variables, check out the official <a href="https://hub.docker.com/r/linuxserver/wireguard" target="_blank" rel="nofollow noopener external">linuxserver/wireguard doc</a>.</strong></p>
<p>I’ve used <code>restart: always</code> so that WireGuard comes up after a system restart.</p>
<p>Changed <code>PEERS</code> to 5, so that I have 5 configurations available for my devices.</p>
<h2 id="launching-the-container"><a href="#launching-the-container">#</a> Launching the container</h2>
<p>Start the container in the background with</p>
<pre><code>docker-compose up -d
</code></pre>
<p>This will create the needed configurations in the <code>wireguard/config</code> folder.</p>
<p>The structure of your <code>wireguard</code> folder looks something like this</p>
<pre><code>.
├── config
│&nbsp;&nbsp; ├── coredns
│&nbsp;&nbsp; │&nbsp;&nbsp; └── Corefile
│&nbsp;&nbsp; ├── peer1
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── peer1.conf
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── peer1.png
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── privatekey-peer1
│&nbsp;&nbsp; │&nbsp;&nbsp; └── publickey-peer1
.............................
│&nbsp;&nbsp; ├── server
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── privatekey-server
│&nbsp;&nbsp; │&nbsp;&nbsp; └── publickey-server
│&nbsp;&nbsp; ├── templates
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── peer.conf
│&nbsp;&nbsp; │&nbsp;&nbsp; └── server.conf
│&nbsp;&nbsp; └── wg0.conf
└── docker-compose.yml
</code></pre>
<h2 id="firewall-configuration"><a href="#firewall-configuration">#</a> Firewall configuration</h2>
<p>If you’re using <code>ufw</code>, simply enable the port <code>51820</code> so that you can connect to your server from outside:</p>
<pre><code>ufw enable 51820
ufw reload
</code></pre>
<p>If you run <code>sudo ufw status</code> you should see:</p>
<pre><code>Status: active

To                         Action      From
--                         ---      ----
....................................................
51820                      ALLOW       Anywhere
51820 (v6)                 ALLOW       Anywhere (v6)
</code></pre>
<h2 id="connecting-devices"><a href="#connecting-devices">#</a> Connecting devices</h2>
<p>Now you can <code>cat</code> or <code>scp</code> the configurations individually to your devices.</p>
<p>The configurations are located in the <code>config/peerX</code> folder, where <code>X</code> represents the peer number.</p>
<p>E.g. I could <code>cat/scp</code> the configuration in <code>wireguard/config/peer1/peer1.conf</code> and put it in <code>/etc/wireguard/wg0.conf</code> on my host machine.</p>
<p>View the configuration for peer 1 on your server with</p>
<pre><code>cat /home/YOUR_USERNAME/wireguard/config/peer1/peer1.conf
</code></pre>
<p>and place it in <code>/etc/wireguard/wg0.conf</code> on your host machine.</p>
<p>If you want to use <code>scp</code>, you could run the following on your local machine:</p>
<pre><code>scp <a href="https://cri.dev/cdn-cgi/l/email-protection" data-cfemail="da8f899f889a899f888c9f88">[email&nbsp;protected]</a>:/home/YOUR_USERNAME/wireguard/config/peer1/peer1.conf /etc/wireguard/wg0.conf
</code></pre>
<p>To connect to your newly created WireGuard VPN from one of your devices, you’ll need to install <code>wireguard-tools</code>.</p>
<p>E.g. <code>apt install wireguard-tools</code> , <code>pacman -S wireguad-tools</code> based on your distro</p>
<p><a href="https://www.wireguard.com/install/" target="_blank" rel="nofollow noopener external">Here you can find a more detailed explanation</a></p>
<p>Now you can simply run <strong><code>wg-quick up wg0</code></strong> and you’re connected to your VPN.</p>
<p>Test it out by running <code>curl ipinfo.io</code> and inspect the output.</p>
<h2 id="connecting-mobile-device-with-qr-code"><a href="#connecting-mobile-device-with-qr-code">#</a> Connecting mobile device with QR code</h2>
<p>On your mobile device, install the WireGuard client.</p>
<p>Then add a new WireGuard tunnel by creating a new configuration scanning a QR code.</p>
<p>On your VPS run the following to output a QR code on the terminal that you can scan on your mobile device:</p>
<pre><code>docker exec -it wireguard app/show-peer 1
</code></pre>
<h2 id="inspecting-connections"><a href="#inspecting-connections">#</a> Inspecting connections</h2>
<p>If you want to understand who is connected and which profiles are in use, simply run the following on your VPS:</p>
<pre><code>docker exec -it wireguard wg
</code></pre>
<p>This will give you more information about your connections with the following output:</p>
<pre><code>interface: wg0
  public key: (redacted)
  private key: (hidden)
  listening port: 51820

peer: (redacted)
  endpoint: (redacted):51820
  allowed ips: (redacted)/32
  latest handshake: 27 seconds ago
  transfer: 5.04 MiB received, 172.64 MiB sent

...

peer: (redacted)
  allowed ips: (redacted)/32
</code></pre>
<h2 id="conclusion"><a href="#conclusion">#</a> Conclusion</h2>
<p>This was most definitely the easiest way I found to connect computers and mobile devices to your own WireGuard VPN.</p>
<p>Let me know if you had troubles setting it up yourself!</p>
</div></div>]]>
            </description>
            <link>https://cri.dev/posts/2021-02-01-5-dollar-easy-self-hosted-vpn-setup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998852</guid>
            <pubDate>Tue, 02 Feb 2021 09:18:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualisation of Co-Occurring Types with Rust]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25998835">thread link</a>) | @batterylow
<br/>
February 2, 2021 | https://shahinrostami.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/ | <a href="https://web.archive.org/web/*/https://shahinrostami.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<pre>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]</pre>
</div></div>]]>
            </description>
            <link>https://shahinrostami.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998835</guid>
            <pubDate>Tue, 02 Feb 2021 09:15:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Unofficial DynASM Documentation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25998833">thread link</a>) | @lelf
<br/>
February 2, 2021 | https://corsix.github.io/dynasm-doc/index.html | <a href="https://web.archive.org/web/*/https://corsix.github.io/dynasm-doc/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <p>DynASM is a preprocessor and tiny runtime library for creating assemblers and JIT compilers in C or C++.</p>
        <p>DynASM was written for, and is maintained as part of, <a href="http://luajit.org/">LuaJIT</a>. LuaJIT 1 used
           DynASM in a JIT role. LuaJIT 2 doesn't use DymASM in a JIT role, but LuaJIT 2's interpreter is hand-written in assembly,
           and it uses DynASM as a powerful cross-platform assembler.</p>
        <p>To get the latest copy of DymASM, run the following:</p>
        <pre><span>git clone http://luajit.org/git/luajit-2.0.git</span>
<span>cd luajit-2.0/dynasm</span></pre>
        <p>The <a href="http://luajit.org/dynasm.html">official documentation</a> for DynASM is extremely spartan, which can
           make it difficult to get started with DynASM. For using DynASM in a JIT role, this unofficial documentation's
           <strong><a href="https://corsix.github.io/dynasm-doc/tutorial.html">tutorial</a></strong> is recommended as a starting point. Once you're more familiar with DynASM,
           the <strong><a href="https://corsix.github.io/dynasm-doc/reference.html">reference</a></strong> and <strong><a href="https://corsix.github.io/dynasm-doc/instructions.html">instruction listing</a></strong>
           pages are recommended reading for fleshing out your DynASM knowledge.</p>
        <p>Note that DynASM supports the x86, x64, ARM, PowerPC, and MIPS instruction sets, but this unofficial documentation
           only covers x86 and x64.</p>
      </div></div>]]>
            </description>
            <link>https://corsix.github.io/dynasm-doc/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998833</guid>
            <pubDate>Tue, 02 Feb 2021 09:14:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demystifying useEffect's clean-up function]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25998648">thread link</a>) | @rozenmd
<br/>
February 2, 2021 | https://maxrozen.com/demystifying-useeffect-cleanup-function | <a href="https://web.archive.org/web/*/https://maxrozen.com/demystifying-useeffect-cleanup-function">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>When you're starting to write React hooks, it can be hard to understand what's going on with useEffect, particularly if you're trying to translate Hooks to lifecycle methods in class components.</p><p>You read everywhere that you <em>shouldn't</em> compare useEffect to lifecycle methods, but then where do you start?</p><p>Thankfully, not knowing how useEffect's clean-up function works isn't as bad as getting the <a href="https://maxrozen.com/learn-useeffect-dependency-array-react-hooks">dependency array wrong</a>, or passing <a href="https://maxrozen.com/stop-useeffect-running-every-render-with-usecallback">constantly redeclared functions into useEffect</a>.</p><p>That being said though, there are some nifty uses of the clean-up function that you should know about.</p><h2 id="useeffects-clean-up-function-doesnt-just-run-once"><a href="#useeffects-clean-up-function-doesnt-just-run-once" aria-label="demystifying useeffect cleanup function permalink"></a>useEffect's clean-up function doesn't just run once</h2><p>If you take nothing else away from this article, remember this: useEffect's clean-up function doesn't <em>just</em> run on unmount (assuming your dependency array isn't empty).</p><p>See this often overlooked sentence in the <a href="https://reactjs.org/docs/hooks-reference.html#cleaning-up-an-effect">React Hooks API reference</a>:</p><blockquote><p>Additionally, if a component renders multiple times (as they typically do), the previous effect is cleaned up before executing the next effect</p></blockquote><h2 id="so-when-does-clean-up-run"><a href="#so-when-does-clean-up-run" aria-label="demystifying useeffect cleanup function permalink"></a>So when does clean-up run?</h2><p>useEffect's clean-up runs after the next render, before the next useEffect.</p><p>This might mess with your brain a little bit, but check out this example:</p><div><pre data-language="jsx"><p><span>import</span><span> React</span><span>,</span><span> </span><span>{</span><span> useEffect</span><span>,</span><span> useState </span><span>}</span><span> </span><span>from</span><span> </span><span>'react'</span><span>;</span><span></span></p><p><span></span><span>export</span><span> </span><span>default</span><span> </span><span>function</span><span> </span><span>App</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>[</span><span>state</span><span>,</span><span> setState</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>null</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    console</span><span>.</span><span>log</span><span>(</span><span>'I am the effect'</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>      console</span><span>.</span><span>log</span><span>(</span><span>'I run after re-render, but before the next useEffect'</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>}</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>  console</span><span>.</span><span>log</span><span>(</span><span>'I am just part of render'</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>    </span><span>&lt;</span><span>&gt;</span><span></span></p><p><span>      </span><span>&lt;</span><span>button</span><span></span></p><p><span>        </span><span>onClick</span><span>=</span><span>{</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>          </span><span>setState</span><span>(</span><span>'Some v. important state.'</span><span>)</span><span>;</span><span></span></p><p><span>        </span><span>}</span><span>}</span><span></span></p><p><span>      </span><span>&gt;</span><span></span></p><p><span>        Click me</span></p><p><span>      </span><span>&lt;/</span><span>button</span><span>&gt;</span><span></span></p><p><span>      </span><span>&lt;</span><span>p</span><span>&gt;</span><span>state</span><span>:</span><span> </span><span>{</span><span>state</span><span>}</span><span>&lt;/</span><span>p</span><span>&gt;</span><span></span></p><p><span>    </span><span>&lt;/</span><span>&gt;</span><span></span></p><p><span>  </span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div><table><thead><tr><th></th></tr></thead><tbody><tr><td><em>This example is also available as a <a href="https://codesandbox.io/s/useeffect-cleanup-example-1qgw2?file=/src/App.js">CodeSandbox</a>.</em></td></tr></tbody></table><p>When the above component first renders, in the console you see:</p><div><pre><p><span>&gt; I am just part of render</span></p><p><span>&gt; I am the effect</span></p></pre></div><p>If you then click the button (triggering a re-render), the following lines are printed underneath:</p><div><pre><p><span>&gt; I am just part of render</span></p><p><span>&gt; I run after re-render, but before the next useEffect</span></p><p><span>&gt; I am the effect</span></p></pre></div><p>Even though the clean-up function is <em>running</em> in the new render, it still has the old prop values since it was <em>declared</em> in the previous render.</p><p>More concretely:</p><div><pre data-language="jsx"><p><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  console</span><span>.</span><span>log</span><span>(</span><span>'id: '</span><span>,</span><span> id</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    console</span><span>.</span><span>log</span><span>(</span><span>'id: '</span><span>,</span><span> id</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span>;</span><span></span></p><p><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>props</span><span>.</span><span>id</span><span>]</span><span>)</span><span>;</span><span></span></p></pre></div><ul><li><code>id</code> starts as <code>1</code>.</li><li>Component renders, displaying <code>id</code> as <code>1</code> in the UI</li><li>useEffect runs, calling <code>console.log</code> and prints <code>id: 1</code></li><li>Props change, setting <code>id</code> to <code>2</code></li><li>Component re-renders, displaying <code>id</code> as <code>2</code> in the UI</li><li>useEffect clean-up function fires, calling <code>console.log</code> and prints <code>id: 1</code></li><li>useEffect runs, calling <code>console.log</code> and prints <code>id: 2</code></li></ul><h2 id="what-to-actually-use-useeffects-clean-up-functions-for"><a href="#what-to-actually-use-useeffects-clean-up-functions-for" aria-label="demystifying useeffect cleanup function permalink"></a>What to actually use useEffect's clean-up functions for</h2><p>Honestly, it's pretty rare that I find a use for useEffect's clean-up function in my day-to-day work as I don't use subscriptions at work (so I never need to unsubscribe from connections in the clean-up function).</p><p>You <em>can</em> use it to avoid race conditions in async requests, which is pretty nifty.</p><p>From <a href="https://maxrozen.com/race-conditions-fetching-data-react-with-useeffect">Fixing Race Conditions in React with useEffect</a>:</p><div><pre data-language="jsx"><p><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> active </span><span>=</span><span> </span><span>true</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>fetchData</span><span> </span><span>=</span><span> </span><span>async</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>const</span><span> response </span><span>=</span><span> </span><span>await</span><span> </span><span>fetch</span><span>(</span><span>`</span><span>https://swapi.dev/api/people/</span><span>${</span><span>props</span><span>.</span><span>id</span><span>}</span><span>/</span><span>`</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>const</span><span> newData </span><span>=</span><span> </span><span>await</span><span> response</span><span>.</span><span>json</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>if</span><span> </span><span>(</span><span>active</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>setFetchedId</span><span>(</span><span>props</span><span>.</span><span>id</span><span>)</span><span>;</span><span></span></p><p><span>      </span><span>setData</span><span>(</span><span>newData</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span>;</span><span></span></p><p><span>  </span><span>fetchData</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    active </span><span>=</span><span> </span><span>false</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span>;</span><span></span></p><p><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>props</span><span>.</span><span>id</span><span>]</span><span>)</span><span>;</span><span></span></p></pre></div><p>You can also use an AbortController to cancel your requests instead of a boolean flag, see <a href="https://maxrozen.com/race-conditions-fetching-data-react-with-useeffect#useeffect-clean-up-function-with-abortcontroller">the example here</a>.</p><h2 id="dedicated-unmount-hook"><a href="#dedicated-unmount-hook" aria-label="demystifying useeffect cleanup function permalink"></a>Dedicated unmount hook</h2><p>While React doesn't have a dedicated unmount hook, you can always use useEffect's clean-up function with an empty dependency array:</p><div><pre data-language="jsx"><p><span>import</span><span> React</span><span>,</span><span> </span><span>{</span><span> useEffect </span><span>}</span><span> </span><span>from</span><span> </span><span>'react'</span><span>;</span><span></span></p><p><span></span><span>const</span><span> </span><span>SomeComponent</span><span> </span><span>=&gt;</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>     </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>         </span><span>}</span><span></span></p><p><span>     </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span></span></p><p><span> </span><span>}</span><span></span></p></pre></div><p>I'm not sure why you'd want this (nor have I needed this), but it's worth knowing that it's possible.</p></div></div></div>]]>
            </description>
            <link>https://maxrozen.com/demystifying-useeffect-cleanup-function</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998648</guid>
            <pubDate>Tue, 02 Feb 2021 08:47:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Space temple for peace of universe including earth and human safety in space]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25998604">thread link</a>) | @rguiscard
<br/>
February 2, 2021 | https://www.terraspace.jp/press-release/20210201 | <a href="https://web.archive.org/web/*/https://www.terraspace.jp/press-release/20210201">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" dir="ltr"><section id="h.e34255cb8b2199c_36"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.e34255cb8b2199c_39"><div><p><h3 id="h.1e59uzt3hiki" dir="ltr">2021/2/1</h3><h3 id="h.gy12guze6umz" dir="ltr"><span>人工衛星開発のテラスペース、人工衛星による宇宙寺院の開発と打ち上げに向け業務技術提携を実施</span></h3></p></div></div></div></div></div></div></div></div></section><section id="h.e34255cb8b2199c_40"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.e34255cb8b2199c_43"><div><div><p dir="ltr"><span>テラスペース株式会社(本社:京都市左京区、代表取締役:北川貞大、以下、テラスペース)は、世界遺産 京都 醍醐寺 (総本山:京都市伏見区、座主:仲田順和、以下、醍醐寺)と人工衛星による宇宙寺院の開発と打ち上げに向け業務技術 提携を行いました。</span></p><p dir="ltr"><span>テラスペースは、2023年度打ち上げ予定のIoT衛星内の区画を活用し、人工衛星に宇宙寺院の役割も持たせます。今回の 業務技術提携に伴い、人工衛星の開発に加え、醍醐寺と一緒に劫蘊寺実行委員会を発足させ、宇宙寺院の運用と事務局の 業務を行います。</span></p><p dir="ltr"><span>また、醍醐寺などと協力し、携帯電波の届かない山間部の文化財保護にIoT衛星を役立てます。</span></p><p dir="ltr"><span>宇宙寺院は「浄天院劫蘊寺(じょうてんいんごううんじ)」(以下 劫蘊寺)と命名されました。劫蘊寺は、鎮護宇宙を 趣旨とする醍醐寺の法流を汲む寺院になります。地球を含む宇宙全体の平和と、人類の宇宙での活動の安全のための、宇 宙法要が、醍醐寺などで定期的に開催されます。宇宙寺院というのは、文字の通り、宇宙に浮かぶお寺のことで、高度4 00km〜500kmの地球低軌道で運用を行い、約1時間半かけて地球を一周します。宇宙寺院の現在地情報などはスマホア プリで確認できるようになる予定です。</span></p><p dir="ltr"><span>【劫蘊寺公式H P】</span><span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.gounji.space%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGILtSJIOi8Urzit6yGt0xbD46aiw" target="_blank">https://www.gounji.space/</a></span><span> </span></p><p dir="ltr"><span>【醍醐寺公式H P】</span><span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.daigoji.or.jp%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNH4l02j46FSCbTWVrKRySIocBsJhw" target="_blank">https://www.daigoji.or.jp/</a></span></p></div></div></div></div></div></div></div></div></div></section><section id="h.19cb177f5fb6139f_3"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.19cb177f5fb6139f_0"><div><div><p><img src="https://lh5.googleusercontent.com/h3BfIfXXKt5BKFy84lhgBSL0NNJYx_0l1tdP5aL62VoxVw4dnCn7I51aKyuv3euM-kRHr_yRhtHHxB8d40Ac6MU0CzdkJiovnvAlPM_w7dxghHMGJuM=w1280" role="img"></p></div></div></div></div><div><div id="h.19cb177f5fb6139f_8"><div><p dir="ltr"><span>左:テラスペース代表 北川貞大  右:総本山醍醐寺座主 仲田順和猊下</span></p></div></div></div></div></div></div></div></div></section><section id="h.597c5cd814811569_7"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.597c5cd814811569_4"><div><div><p><img src="https://lh4.googleusercontent.com/rKcHFm62T2oHGSzuI0JPX-osxcw97uvzg6Ba6Q5mepLtrNtpMUz-M2wcLU1EL5MrvLT2EOj2jJaguYFa3coJLBkLvJwVRT_2RonqRS9QQzp9nZEb9w=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.19cb177f5fb6139f_13"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.19cb177f5fb6139f_10"><div><div><p dir="ltr"><span>広報担当:今村誠子</span></p><p dir="ltr"><span>TEL: 0774-74-8202</span></p><p dir="ltr"><span>Email: info@terraspace.jp</span></p></div></div></div></div></div></div></div></div></div></section></div></div>]]>
            </description>
            <link>https://www.terraspace.jp/press-release/20210201</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998604</guid>
            <pubDate>Tue, 02 Feb 2021 08:40:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing a Bricked SSD with JTAG]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25998328">thread link</a>) | @drudru11
<br/>
February 1, 2021 | https://fmad.io/blog-ssd-bricked-restore.html | <a href="https://web.archive.org/web/*/https://fmad.io/blog-ssd-bricked-restore.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<p>
				SSD`s are the life blood of our fmadio 10G, 40G, 100G ethernet capture systems. They provide backing storage that well exceeds that of conventional RAM, are super fast and light weight. Thus its prudent to keep the SSD farms in top nick, optimal health, and occasionally perform emergency room brain surgery on them. Unfortunately today is one of those days.
			</p>
			<br>

			<div>                        
				<ul>                            
					<li><img width="60%" src="https://fmad.io/images/blog/20141229_ssd_jtag_close.jpg" alt="ssd connected to jtag"></li>
				</ul>                        
			</div>


		<p>
As with all things, it happened late on a Friday night when I was adding a new feature to the system that wipes all capture data from the system. This is simple button click on the web UI page as our clients data is quite sensitive thus needs to be deleted when the box moves internally or externally. The wipe is implemented using the "Secure Erase" ATA-8 command, you can read all about it <a href="https://ata.wiki.kernel.org/index.php/ATA_Secure_Erase">here</a>. Its essentially a restore-to-factory-setting operation. Meaning after the SecureErase the drive`s internal state is the same as "just left the factory". 
		</p>
		
		<p>
Which is great when it works, but this kind of low level drive formatting is pretty complicated with many (presumably) asynchronous operations going on in parallel... and doing 100 of these operations back to back at high speed is probably something the vendor did not expect (I was testing dammit!). In our case this bricked 6 SSD`s rendering them completely useless causing myself quite the stress as I now have several thousand dollars worth of inventory destroyed!  - not a good day.
</p>


				<p><img width="1024px" src="https://fmad.io/images/blog/money_burn.jpg" alt="fmadio ssd lost"></p><p>
The result is a wall of rather intimidating errors indicating imminent doom with the disk is for all intensive purposes <a href="https://en.wikipedia.org/wiki/Brick_%28electronics%29"><b>BRICKED</b></a>.

<code>

kernel: [18633.754193] ata2.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0
kernel: [18633.754204] ata2.00: irq_stat 0x40000001
kernel: [18633.754206] ata2.00: failed command: READ DMA
kernel: [18633.754209] ata2.00: cmd c8/00:08:00:00:00/00:00:00:00:00/e0 tag 0 dma 4096 in
kernel: [18633.754209]          res 51/04:00:00:00:00/00:00:00:00:00/60 Emask 0x1 (device error)
kernel: [18633.754210] ata2.00: status: { DRDY ERR }
kernel: [18633.754211] ata2.00: error: { ABRT }
kernel: [18633.754515] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.754614] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.759150] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.759215] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.763495] ata2.00: configured for UDMA/133
kernel: [18633.770136] ata2: EH complete
kernel: [18633.770278] ata2.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0
kernel: [18633.770280] ata2.00: irq_stat 0x40000001
kernel: [18633.770281] ata2.00: failed command: READ DMA
kernel: [18633.770284] ata2.00: cmd c8/00:08:00:00:00/00:00:00:00:00/e0 tag 1 dma 4096 in
kernel: [18633.770284]          res 51/04:00:00:00:00/00:00:00:00:00/60 Emask 0x1 (device error)
kernel: [18633.770286] ata2.00: status: { DRDY ERR }
kernel: [18633.770286] ata2.00: error: { ABRT }
kernel: [18633.770572] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.770641] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.775164] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.775210] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.779527] ata2.00: configured for UDMA/133
kernel: [18633.786094] ata2: EH complete
kernel: [18633.786205] ata2.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0
kernel: [18633.786207] ata2.00: irq_stat 0x40000001
kernel: [18633.786208] ata2.00: failed command: READ DMA
</code>


</p><p>
The usual suspects to recover were tried and failed, leaving only a few options.
<br>
</p>

<h5>a) RMA the boards back to the seller<br>
b) Contact vendor support<br>
c) Perform surgery</h5>


<p>
Option a) of RMA`ing the boards was the safest option, tho usually you get some other previously recycled RMA`ed device back. Option b) of contacting the vendor is always such a brutally painful experience. It would likely end up with some random "Customer Support" person with a strange accent... giving the default completely useless response of RMA the device and get a replacement kind of thing... ho hum. Which leaves surgery! Now I usually don't go messing with hardware like this (anymore... :) ) because it takes up quite a bit time. However SSD health and prosperity is directly linked to our profitability thus deemed it a worth while time investment to have a more intimate relationship with our SSD models of choice. 
</p>
<br>

<div><p>
The process starts with a general reconnaissance mission of what pins are accessible, and what those pins are for. First up was finding the UART / serial interface but it was silent and likely disabled by the firmware. Next up was what most likely looked like a JTAG interface and... bingo, full JTAG interface connecting and operating as expected.
</p><p>

 JTAG is a hardware based system debugger that for CPU`s let you control instruction execution and read/write memory anywhere. You can see in the picture below some soldering of header pins was required, that is then wired to a breadboard which is wired to a Raspberry PI.
</p></div>


	<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_jtag.jpg" alt="fmadio ssd with jtag connected"></p><div><p>
Raspberry PI? wtf ? In this case the Raspberry PI was converted into a JTAG debugger using the outstanding software over at <a href="http://openocd.sourceforge.net/">OpenOCD</a>. As "real" JTAG debuggers are quite expensive ranging from $100 - $1000+ making OCD coupled with the PI an excellent low cost alternative. 
</p><p>

At this point you get a small rush as you gain access and poke the device, after which the vastness of having no idea what anything does starts to weigh you down. Then slowly bit by bit, instruction after instruction, string after string you gain some intuition on the memory map, what the code does, how its setup and eventually find something interesting.
</p></div> 

<p>

The first entry point to look for is the classic printf / trace / debug operation which gives you insight into what the software is doing. And eventually managed to track down the code that`s basically

<code>
void trace(char* Message, ...)
{ 
	va_arg list;
	va_start(arglist, Message);

	char buf[1024];
	vsprintf(buf, Message, arglist);

	if (debug_enable)
	{
		fwrite(output, buf, strlen(buf));
	}
}
</code>

which writes out a string to a console to tell the developer on whats going on. Note that the code has to "flatten" the string first before even deciding to output or not, which gives us a nice window to sniff the string with JTAG even if nothing is written to the console. 
</p>


<p>
After sniffing strings for a while and getting a better feel for whats happening noticed that the SSD is receiving commands from the SATA host no problem. But there`s some sort of funkyness going on that causes the SSD to send no response back - kind of a one-way-street. One idea to resolve this is: in theory the security erase operation restores everything back to good health. The question tho, is the device actually processing a security erase request ?  
</p>


<p>
... and using our printf JTAG sniffer... it most certainly is processing the request! But failing miserably due to an incorrect password. You can see the sniffed printf jtag string in the output below. Hint: <i>"&lt;SED&gt; Credential Comparison Failed"</i> ASCIIZ string.
</p>


	<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_security_erase_fail.jpg" alt="fmadio ssd security erase fail"></p><p>
Which makes it clear why the security erase / factory reset failed but more importantly you can track down the offending bit of code from this string. That results in the following snippet of assembler courtesy of the IDA toolset below.
</p> 

<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_security_check.jpg" alt="fmadio ssd security erase password check"></p><p>
To decode that for you its doing a 32 byte long compare against some expected cryptographic hash key. Then the <i>"magic compare"</i> aka instruction <b>CMP R5, #1</b> is testing if the keys matched. Then doing a conditional jump to a printf routine based on that comparison result <b>BLNE sub_80...</b>. And finally  the functions return value is the result of the comparison <b>MOV R0, R5</b>. Nothing particularly fancy going on.
</p> 


<p>
There`s a few ways to go from here. One would be to reverse engineer how the 32B key is generated and create  a general purpose exploit. The other would be to just patch the binary such that it thinks it passed the security check. eg Fake a correct password response. We chose the latter as it only takes a few minutes and all I want is to restore the SSD farm`s health. Patching the binary with JTAG is trivial, console output is shown below.
</p> 


<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_security_erase_patch.jpg" alt="fmadio ssd security erase password fake"></p><div><p>
The above shows disassembling the patched code first, the "before" section. This is to check we overwrite the correct bit of code. Then patch it using the command <b>cpu0 arm mww</b> with the value 0xe3a05001. Then disassemble again "after section" to confirm the patch worked and has the correct instruction. 
</p><p>

In this case we replaced <b>BLNE</b> instruction (print error message to the console) with <b>MOV r5, #1</b> at address 0x8009abe4 (shown in blue). The result of the "magic check" is 0 for fail, 1 for pass and write it to register r5. All we did is ignore the whole comparison and simply override it and say the security check always passes (r5 = 1).
</p></div> 

<p>
...
</p>

<p>
Now its patched, with cpu`s resumed its the moment of truth. Issuing the security erase operation from the host system via hdparm. 
<br>
<code>
$ sudo hdparm --security-erase 1234  /dev/sdb
security_password="1234"

/dev/sdb:
 Issuing SECURITY_ERASE command, password="1234, user=user
$
</code>
<br>
... and it worked! the SSD is back to life, working as normal and running at high speed!  ... with <b>several thousand dollars worth of SSD`s back in business</b> making our 10G, 40G, 100G network capture systems more resilient than ever. Now if the SSD vendor (who shall remain nameless) would fix the dam bug so excessive back-to-back security password/erase does NOT brick the device, life would be so much better. 
</p>


	</div></div>]]>
            </description>
            <link>https://fmad.io/blog-ssd-bricked-restore.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998328</guid>
            <pubDate>Tue, 02 Feb 2021 07:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring FPGA Graphics]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25998154">thread link</a>) | @rbanffy
<br/>
February 1, 2021 | https://projectf.io/posts/fpga-graphics/ | <a href="https://web.archive.org/web/*/https://projectf.io/posts/fpga-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Welcome to <em>Exploring FPGA Graphics</em>. In this series, we explore graphics at the hardware level and get a feel for the power of FPGAs. We start by learning how displays work, before racing the beam with Pong, starfields and sprites, simulating life with bitmaps, drawing lines and triangles, and finally creating simple 3D models. I’ll be writing and revising this series throughout 2020 and 2021.</p>
<p>In this first post, we learn how computer displays work and animate simple shapes with an FPGA.</p>
<p><em>Updated 2021-01-28. Get in touch with <a href="https://twitter.com/WillFlux">@WillFlux</a> or open an <a href="https://github.com/projf/projf-explore/issues">issue on GitHub</a>.</em></p>
<blockquote>
<p>In all beginnings dwells a magic force<br>
<em>Herman Hesse, Stages from <a href="https://en.wikipedia.org/wiki/The_Glass_Bead_Game">The Glass Bead Game</a></em></p>
</blockquote>
<h3 id="series-outline">Series Outline</h3>
<ul>
<li>Exploring FPGA Graphics (this post) - learn how displays work and animate simple shapes</li>
<li><a href="https://projectf.io/posts/fpga-pong/">FPGA Pong</a> - race the beam to create the arcade classic</li>
<li><a href="https://projectf.io/posts/hardware-sprites/">Hardware Sprites</a> - fast, colourful, graphics with minimal resources</li>
<li><a href="https://projectf.io/posts/fpga-ad-astra/">FPGA Ad Astra</a> - demo with hardware sprites and animated starfields</li>
<li><a href="https://projectf.io/posts/framebuffers/">Framebuffers</a> - driving the display from a bitmap in memory</li>
<li><a href="https://projectf.io/posts/life-on-screen/">Life on Screen</a> - the screen comes alive with Conway’s Game of Life</li>
<li><a href="https://projectf.io/posts/lines-and-triangles/">Lines and Triangles</a> - drawing lines and triangles with a framebuffer</li>
</ul>
<p><em>More parts to follow.</em></p>
<h3 id="requirements">Requirements</h3>
<p>For this series, you need an FPGA board with video output. We’ll be working at 640x480, so pretty much any video output will work. It helps to be comfortable with programming your FPGA board and reasonably familiar with Verilog.</p>
<p>We’ll be demoing the designs with two boards:</p>
<ul>
<li><strong><a href="https://docs.icebreaker-fpga.org/hardware/icebreaker/">iCEBreaker</a></strong> (Lattice iCE40) with <strong><a href="https://docs.icebreaker-fpga.org/hardware/pmod/dvi/">12-Bit DVI Pmod</a></strong></li>
<li><strong><a href="https://reference.digilentinc.com/reference/programmable-logic/arty-a7/reference-manual">Digilent Arty A7-35T</a></strong> (Xilinx Artix-7) with <strong><a href="https://reference.digilentinc.com/reference/pmod/pmodvga/reference-manual">Pmod VGA</a></strong></li>
</ul>
<h3 id="source">Source</h3>
<p>The SystemVerilog designs featured in this series are available from the <a href="https://github.com/projf/projf-explore/">projf-explore</a> repo on GitHub. The designs are open source hardware under the permissive MIT licence, but this blog is subject to normal copyright restrictions.</p>
<blockquote>
<p><strong>Quick Aside: SystemVerilog?!</strong><br>
We’ll be using a few choice features from SystemVerilog to make Verilog a little more pleasant (no laughing at the back). If you’re familiar with Verilog, you’ll have no trouble.</p>
</blockquote>
<h2 id="space-and-time">Space and Time</h2>
<p>The screen you’re looking at is a little universe with its own rules of space and time.</p>
<p>Looking at a screen from afar, you see a smooth two-dimensional image. Look more closely, and you see many individual blocks: these are <strong>pixels</strong>, made up of red, green, and blue components. A typical high-definition image is 1920 pixels across and 1080 lines down: over 2 million pixels in total. Even a 640x480 image has over 300,000 pixels. The need to handle so much information so quickly is a big part of the challenge of working with graphics at a hardware level.</p>
<p>A VGA cable has five main signals: red, green, blue, horizontal sync, and vertical sync. There are no addressing signals to tell the screen where to draw pixels; the secret is time, defined by the sync signals. The red, green, and blue wires carry the colour of each pixel in turn. Each pixel lasts a fixed length of time; when the display receives a <strong>horizontal sync</strong>, it starts a new line; when it receives a <strong>vertical sync</strong>, it begins a new frame. Showing many frames in quick succession provides the illusion of a moving image.</p>
<p>The sync signals are part of <strong>blanking</strong> intervals. Originally designed to allow an electron gun to move to the next line or top of the screen, blanking intervals have been retained and repurposed in contemporary displays: HDMI uses them to transmit audio. The blanking interval has three parts: <strong>front porch</strong>, <strong>sync</strong>, and <strong>back porch</strong>.</p>
<p><img src="https://projectf.io/img/posts/fpga-graphics/display-timings.png" alt="Display Timings" title="Display Timings"></p>
<h2 id="display-timings">Display Timings</h2>
<p>In this series, we’re going to use <strong>640x480</strong> as our display resolution. Almost all displays support 640x480, and its low resource requirements make it simple to work with on small FPGAs. All the same principles apply at higher resolutions, such as 1280x720 or 4K.</p>
<p>We’ll use traditional horizontal and vertical timings, based on the original VGA monitor and adapter:</p>
<div><pre><code data-lang="plaintext">    640x480 Timings      HOR    VER
    -------------------------------
    Active Pixels        640    480
    Front Porch           16     10
    Sync Width            96      2
    Back Porch            48     33
    Blanking Total       160     45
    Total Pixels         800    525
    Sync Polarity        neg    neg
</code></pre></div><p><em>Learn more from <a href="https://projectf.io/posts/video-timings-vga-720p-1080p/">Video Timings: VGA, SVGA, 720p, 1080p</a>.</em></p>
<p>Taking blanking into account, we have a total of 800x525 pixels. A typical LCD refreshes 60 times a second, so the number of pixels per second is <code>800 x 525 x 60 = 25,200,000</code>, which equates to a <strong>pixel clock</strong> of 25.2 MHz.</p>
<blockquote>
<p><strong>CAUTION: CRT Monitors</strong><br>
Any modern display, including <a href="https://en.wikipedia.org/wiki/Multisync_monitor">multisync CRTs</a>, should be fine with a 25.2 or 25 MHz pixel clock. Fixed-frequency CRTs, such as the original IBM 85xx series, could be damaged by an out-of-spec signal. Use these designs at your own risk.</p>
</blockquote>
<h2 id="running-to-time">Running to Time</h2>
<p>We’ve decided we need a pixel clock of 25.2 MHz pixel clock, but neither of our demo boards has such a clock. To reach the required frequency, we’re going to use a <strong><a href="https://en.wikipedia.org/wiki/Phase-locked_loop">phase-locked loop</a></strong> (PLL). Almost all FPGAs include one or more PLLs, but there isn’t a standard way to configure them in Verilog, so we have to use vendor-specific designs.</p>
<p>We have provided implementations for Xilinx 7 Series (XC7) and Lattice iCE40; for other FPGAs, you’ll need to consult your vendor documentation. If you can’t reach 25.2 MHz exactly, then 25 MHz or thereabouts should be fine (but see note about CRTs, above). The iCE40 can’t generate 25.2 MHz using the oscillators on iCEBreaker but works fine at 25.125 MHz.</p>
<h3 id="clock-generator-modules">Clock Generator Modules</h3>
<ul>
<li>Xilinx 7 Series: <strong><a href="https://github.com/projf/projf-explore/blob/master/common/xc7/clock_gen.sv">xc7/clock_gen.sv</a></strong></li>
<li>Lattice iCE40: <strong><a href="https://github.com/projf/projf-explore/blob/master/common/ice40/clock_gen.sv">ice40/clock_gen.sv</a></strong></li>
</ul>
<h2 id="display-timings-module">Display Timings Module</h2>
<p>Using our ~25 MHz pixel clock, we can generate timings for our 640x480 display. Creating display timings is straightforward: there’s one counter for horizontal position and one for vertical. We use these counters to decide on the correct time for sync signals.</p>
<p>640x480 display timings generator <strong>[<a href="https://github.com/projf/projf-explore/blob/master/common/display_timings_480p.sv">display_timings_480p.sv</a>]</strong>:</p>
<div><pre><code data-lang="verilog"><span>module</span> display_timings_480p (
    <span>input</span>  <span>wire</span> <span>logic</span> clk_pix,   <span>// pixel clock
</span><span></span>    <span>input</span>  <span>wire</span> <span>logic</span> rst,       <span>// reset
</span><span></span>    <span>output</span>      <span>logic</span> [<span>9</span><span>:</span><span>0</span>] sx,  <span>// horizontal screen position
</span><span></span>    <span>output</span>      <span>logic</span> [<span>9</span><span>:</span><span>0</span>] sy,  <span>// vertical screen position
</span><span></span>    <span>output</span>      <span>logic</span> hsync,     <span>// horizontal sync
</span><span></span>    <span>output</span>      <span>logic</span> vsync,     <span>// vertical sync
</span><span></span>    <span>output</span>      <span>logic</span> de         <span>// data enable (low in blanking interval)
</span><span></span>    );

    <span>// horizontal timings
</span><span></span>    <span>parameter</span> HA_END <span>=</span> <span>639</span>;           <span>// end of active pixels
</span><span></span>    <span>parameter</span> HS_STA <span>=</span> HA_END <span>+</span> <span>16</span>;   <span>// sync starts after front porch
</span><span></span>    <span>parameter</span> HS_END <span>=</span> HS_STA <span>+</span> <span>96</span>;   <span>// sync ends
</span><span></span>    <span>parameter</span> LINE   <span>=</span> <span>799</span>;           <span>// last pixel on line (after back porch)
</span><span></span>
    <span>// vertical timings
</span><span></span>    <span>parameter</span> VA_END <span>=</span> <span>479</span>;           <span>// end of active pixels
</span><span></span>    <span>parameter</span> VS_STA <span>=</span> VA_END <span>+</span> <span>10</span>;   <span>// sync starts after front porch
</span><span></span>    <span>parameter</span> VS_END <span>=</span> VS_STA <span>+</span> <span>2</span>;    <span>// sync ends
</span><span></span>    <span>parameter</span> SCREEN <span>=</span> <span>524</span>;           <span>// last line on screen (after back porch)
</span><span></span>
    <span>always_comb</span> <span>begin</span>
        hsync <span>=</span> <span>~</span>(sx <span>&gt;=</span> HS_STA <span>&amp;&amp;</span> sx <span>&lt;</span> HS_END);  <span>// invert: negative polarity
</span><span></span>        vsync <span>=</span> <span>~</span>(sy <span>&gt;=</span> VS_STA <span>&amp;&amp;</span> sy <span>&lt;</span> VS_END);  <span>// invert: negative polarity
</span><span></span>        de <span>=</span> (sx <span>&lt;=</span> HA_END <span>&amp;&amp;</span> sy <span>&lt;=</span> VA_END);
    <span>end</span>

    <span>// calculate horizontal and vertical screen position
</span><span></span>    <span>always_ff</span> @ (<span>posedge</span> clk_pix) <span>begin</span>
        <span>if</span> (sx <span>==</span> LINE) <span>begin</span>  <span>// last pixel on line?
</span><span></span>            sx <span>&lt;=</span> <span>0</span>;
            sy <span>&lt;=</span> (sy <span>==</span> SCREEN) <span>?</span> <span>0</span> <span>:</span> sy <span>+</span> <span>1</span>;  <span>// last line on screen?
</span><span></span>        <span>end</span> <span>else</span> <span>begin</span>
            sx <span>&lt;=</span> sx <span>+</span> <span>1</span>;
        <span>end</span>
        <span>if</span> (rst) <span>begin</span>
            sx <span>&lt;=</span> <span>0</span>;
            sy <span>&lt;=</span> <span>0</span>;
        <span>end</span>
    <span>end</span>
<span>endmodule</span>
</code></pre></div><p><em>ProTip: The last assignment wins in Verilog, so the reset overrides the existing <code>sx</code> and <code>sy</code>.</em></p>
<p><strong>sx</strong> and <strong>sy</strong> store the horizontal and vertical position; their maximum values are 800 and 525 respectively, so we need 10 bits to hold them (2<sup>10</sup> = 1024). <strong>de</strong> is <em>data enable</em>, which is low during the blanking interval: we use it to decide when to draw pixels.</p>
<p>Display modes vary in the polarity of their sync signals; for traditional 640x480, the polarity is negative for both <strong>hsync</strong> and <strong>vsync</strong>. Negative polarity means the voltage is mostly high, with low voltage indicating a sync signal.</p>
<p>The following simulation shows the vertical sync starting at the 490th line (counting starts at zero):</p>
<p><img src="https://projectf.io/img/posts/fpga-graphics/hsync-vsync-vga.png" alt="Sync Signal Simulation" title="Simulating VGA horizontal &amp; vertical sync signals"></p>
<h2 id="test-benches">Test Benches</h2>
<p>You can exercise the designs with the included test benches (Xilinx only):</p>
<ul>
<li><strong><a href="https://github.com/projf/projf-explore/tree/master/common/xc7/clock_gen_tb.sv">Clock Gen Test Bench</a></strong> (Xilinx 7 Series)</li>
<li><strong><a href="https://github.com/projf/projf-explore/tree/master/common/xc7/display_timings_tb.sv">Display Timings Test Bench</a></strong> (Xilinx 7 Series)</li>
</ul>
<p>Some things to check:</p>
<ul>
<li>What is the pixel clock period?</li>
<li>How long does the pixel clock take to lock?</li>
<li>Does a frame last exactly 1/60th of a second?</li>
<li>How much time does a single line last?</li>
<li>What is the maximum values of <code>sx</code> and <code>sy</code> when <code>de</code> is low?</li>
</ul>
<p><em>You can find instructions for running the simulation in the source <a href="https://github.com/projf/projf-explore/tree/master/fpga-graphics">README</a>.</em></p>
<h2 id="top-display">Top Display</h2>
<p>Now we have our display signals we’re ready to start drawing. To begin, we’re going to keep it simple and draw a coloured square. When the screen x and y coordinates are both less than 32 we draw in orange; otherwise, we use blue. Because our colour output has 4 bits per channel, we can use a single hex digit from 0-F to represent the intensity of red, green, and blue.</p>
<p>There are two versions of this top module, one for each demo board:</p>
<ul>
<li>Xilinx XC7: <strong><a href="https://github.com/projf/projf-explore/blob/master/fpga-graphics/xc7/top_square.sv">xc7/top_square.sv</a></strong></li>
<li>Lattice iCE40: <strong><a href="https://github.com/projf/projf-explore/blob/master/fpga-graphics/ice40/top_square.sv">ice40/top_square.sv</a></strong></li>
</ul>
<h3 id="arty-vga">Arty VGA</h3>
<p>Shown below is the version for Arty A7-35T (XC7) with Pmod VGA:</p>
<div><pre><code data-lang="verilog"><span>module</span> top_square (
    <span>input</span>  <span>wire</span> <span>logic</span> clk_100m,     <span>// 100 MHz clock
</span><span></span>    <span>input</span>  <span>wire</span> <span>logic</span> btn_rst,      <span>// reset button (active low)
</span><span></span>    <span>output</span>      <span>logic</span> vga_hsync,    <span>// horizontal sync
</span><span></span>    <span>output</span>      <span>logic</span> vga_vsync,    <span>// vertical sync
</span><span></span>    <span>output</span>      <span>logic</span> [<span>3</span><span>:</span><span>0</span>] vga_r,  <span>// 4-bit VGA red
</span><span></span>    <span>output</span>      <span>logic</span> [<span>3</span><span>:</span><span>0</span>] vga_g,  <span>// 4-bit VGA green
</span><span></span>    <span>output</span>      <span>logic</span> [<span>3</span><span>:</span><span>0</span>] vga_b   <span>// 4-bit VGA blue
</span><span></span>    );

    <span>// generate pixel clock
</span><span></span>    <span>logic</span> clk_pix;
    <span>logic</span> clk_locked;
    clock_gen clock_640x480 (
       .clk(clk_100m),
       .rst(<span>!</span>btn_rst),  <span>// reset button is active low
</span><span></span>       .clk_pix,
       .clk_locked
    );

    <span>// display timings
</span><span></span>    <span>localparam</span> CORDW <span>=</span> <span>10</span>;  <span>// screen coordinate width in bits
</span><span></span>    <span>logic</span> [CORDW<span>-</span><span>1</span><span>:</span><span>0</span>] sx, sy;
    <span>logic</span> hsync, vsync, de;
    …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://projectf.io/posts/fpga-graphics/">https://projectf.io/posts/fpga-graphics/</a></em></p>]]>
            </description>
            <link>https://projectf.io/posts/fpga-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998154</guid>
            <pubDate>Tue, 02 Feb 2021 07:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Small-time crooks make money by reporting Instagram accounts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25998014">thread link</a>) | @n_kb
<br/>
February 1, 2021 | https://www.mediapart.fr/journal/international/010221/comment-de-petits-escrocs-font-fermer-des-comptes-instagram/ | <a href="https://web.archive.org/web/*/https://www.mediapart.fr/journal/international/010221/comment-de-petits-escrocs-font-fermer-des-comptes-instagram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.mediapart.fr/journal/international/010221/comment-de-petits-escrocs-font-fermer-des-comptes-instagram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998014</guid>
            <pubDate>Tue, 02 Feb 2021 06:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do less and do it better]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25997935">thread link</a>) | @quyleanh
<br/>
February 1, 2021 | https://qmacro.org/2021/02/01/do-less-and-do-it-better/ | <a href="https://web.archive.org/web/*/https://qmacro.org/2021/02/01/do-less-and-do-it-better/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>In 2021 I want to consolidate and improve upon some skills I already have, rather than add more. Here’s what I mean, and how I got inspired.</em></p>

<p>In October last year Samir Talwar <a href="https://twitter.com/SamirTalwar/status/1318904227935227905">tweeted</a> something simple yet profound: “<em>Do less, and do it better</em>”.</p>

<p>In my work and play I discover and start using various tools and technologies. The pace of change in this industry, coupled with the (not unpleasant) demands on what I have to produce, means that I often end up with only a shallow understanding of things. And sometimes these are things I use every day.</p>

<p>The nature of my job as a developer advocate (but I think this extends to development in general), in the context of that fast pace of change, means that there’s always something new to learn, to adopt, and to incorporate into a workflow, process or solution. But that can come at a price - of limited comprehension and mastery.</p>

<p>To explain further, I’m going to stretch a metaphor relating to ploughing a field and sowing seeds.</p>

<p><strong>Ploughing and sowing</strong></p>

<p>As an individual, I sometimes feel as though I’m trying to prepare a large field and plant seeds there using a poorly hand-constructed and inefficient plough made of the wrong sort of wood and bits of string, combined with a seed drill made out of old toilet rolls and sticky tape. Not only that, but I’m trying to plant across the entire field, 50 furrows wide, as I move along.</p>

<p>Needless to say, the ploughing doesn’t go very well, and the seeds are planted imprecisely, sometimes superficially, mostly wastefully, resulting in poor distribution, low growth and high energy expenditure.</p>

<p>But if I were to abandon the idea of going wide, and instead go narrow, focusing on just a handful of furrows, I could afford to take the time to correctly plant each seed, nurturing &amp; watering each one, producing strong plants with deep roots and healthy growth.</p>

<p>I’ve thought this for a while but never got round to doing anything about it. Samir’s tweet has galvanised me into spending some time working out what that means for me.</p>

<p><strong>Consolidating</strong></p>

<p>So this year I’m attempting to “do less, and do it better” by acknowledging the tools I use day in day out, and learn more about them, restricting myself to a narrow set of topics, move a step closer towards mastery in each, and really benefit from everything they have to offer.</p>

<p>Here’s an example from this weekend; I read the entirety of the main README for the excellent fuzzy-finder tool <a href="https://github.com/junegunn/fzf"><code>fzf</code></a>, all 16 pages. That might seem ridiculous to say (16 pages is not a lot) but I’ve used <code>fzf</code> for a year or so and never RTFM’d before. In my defence, I’ve also been constantly and painfully aware that I’ve merely scratched the surface. I’ve now discovered some <code>fzf</code> gems that I can put into practice immediately, and some areas that I need to dig into more.</p>

<p>Likewise for other tools that I use, tools that are not only essential, but which, when mastered, can make my workflows even better. I’m thinking of Vim (I’ve recently started watching my friend and colleague David Kunz’s <a href="https://www.youtube.com/channel/UCFU7a7OMYfcpjtIpu2j47_Q">DevOnDuty</a> series, which I can strongly recommend), <a href="https://github.com/tmux/tmux/wiki"><code>tmux</code></a> (<a href="http://rwxrob.live/">rwxrob</a> is a great practitioner, and I should re-read Brian P. Hogan’s great <a href="https://pragprog.com/titles/bhtmux2/tmux-2/">book on tmux</a> too) and of course the environment and language that ties it all together for me - <a href="https://www.gnu.org/software/bash/">Bash</a>.</p>

<p>The lockdown has afforded me time to read more, and I need to embrace that and work out how I can keep that momentum up. I want to tip the balance over from always having my fingers on the keyboard towards stepping away from the keyboard to read, reflect and consolidate my learning.</p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://qmacro.org/2021/02/01/do-less-and-do-it-better/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997935</guid>
            <pubDate>Tue, 02 Feb 2021 06:22:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Short Writing Is the Future of Writing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25997778">thread link</a>) | @hieunc229
<br/>
February 1, 2021 | https://pigg.in/posts/nC38jbAhLTP-short-writing-is-the-future-of-writing | <a href="https://web.archive.org/web/*/https://pigg.in/posts/nC38jbAhLTP-short-writing-is-the-future-of-writing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="str-vOKpYe5nW" data-connect-field="content"><p>Many claimed longer content rank higher [1] in search results. It should be changed soon. Either be less biased about short writing, or make the length criteria less important.</p><p>Because many of us need the right information, not long content.</p><p>Let’s start with the 2 main target users who search for things.</p><p>The first target enjoys reading. It’s like enjoy a video game, a movie, or a song. They enjoy a good experience, a type of content that opens their imagination. Then sail them through any details the author intended. Those types of content use descriptive paragraphs, transitions, with fancy words. It makes readers feel great.</p><p>The second target is in need to search for a piece of information. They prefer a straightforward and simple answer. Which means minimal, concise sentences, with no fancy words.</p><p>I used to enjoy and have no problem reading long content. But recently, I'd spend 5 seconds scanning relevant headings. Then another minute to find the information, or go back and look for another search result.</p><p>To me, this is a horrible reading habit. I realized my attention span getting shorter.</p><p>As our reading habits changed. We need a better format to diggest information. For example, video content is getting more popular. It required less effort to diggest.</p><p>3 common examples are:</p><ul><li>Medium (a blogging platform) rolled out a new model for short content. They found [2] that readers spend more time on good and short content</li><li>Seth Godin, well-known for finding out what's next for marketing. <a href="https://seths.blog/">His daily posts</a> are in between <a href="https://i.imgur.com/N28JSX3.png">50 to &gt; 300 words</a>.</li><li>Successful products that provide sumarize service: Blinklist (sumarize books service) or <a href="https://trends.vc/">TrendsVC</a> (a newsletter summarize recent trend in many categories), or <a href="https://www.producthunt.com/posts/i-lazy-to-read">I Lazy To Read</a> (summarize any article into 5-sentences)</li></ul><p>That goes with the search results. When someone needs an answer, it should be minimal, concise, and straightforward. It's easier to generate short content anyway.</p><hr><p>[cover photo] credit <a href="https://unsplash.com/photos/SSh9O_-sTzg">Priscilla Du Preez</a></p><p>[1] i.e <a href="https://backlinko.com/search-engine-ranking#:~:text=The%20average%20Google%20first%20page%20result%20contains%201,447%20words">Search engine ranking</a>, or <a href="https://www.sweor.com/seocontentlength#:~:text=The%20average%20content%20length%20for,content%20each%20web%20page%20has">SEO Content Length</a></p><p>[2] <a href="https://help.medium.com/hc/en-us/articles/360036691193-Calculating-earnings-in-the-Partner-Program#:~:text=we%E2%80%99ve%20found%20that%20readers%20will%20end%20up%20spending%20more%20time%20with%20the%20piece">How will shorter pieces perform in this new model?</a></p></div></div>]]>
            </description>
            <link>https://pigg.in/posts/nC38jbAhLTP-short-writing-is-the-future-of-writing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997778</guid>
            <pubDate>Tue, 02 Feb 2021 05:40:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Proportional Pricing Model]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25997510">thread link</a>) | @Windson
<br/>
February 1, 2021 | https://osjobs.net/blog/posts/the-proportional-pricing-model/ | <a href="https://web.archive.org/web/*/https://osjobs.net/blog/posts/the-proportional-pricing-model/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
    <div>

        

        <article data-small-caps="true" data-align="default" data-type="posts" data-toc-num="true">

            

            

            
                
            

            
                

<p><time datetime="2021-02-02T12:38:32+08:00"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M400 64h-48V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H160V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H48C21.49 64 0 85.49 0 112v352c0 26.51 21.49 48 48 48h352c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm-6 400H54a6 6 0 0 1-6-6V160h352v298a6 6 0 0 1-6 6zm-52.849-200.65L198.842 404.519c-4.705 4.667-12.303 4.637-16.971-.068l-75.091-75.699c-4.667-4.705-4.637-12.303.068-16.971l22.719-22.536c4.705-4.667 12.303-4.637 16.97.069l44.104 44.461 111.072-110.181c4.705-4.667 12.303-4.637 16.971.068l22.536 22.718c4.667 4.705 4.636 12.303-.069 16.97z"></path></svg>&nbsp;2021.2.2</time>
    
    
    
        
        
        
            
        
    
    
        
        <span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"></path></svg>&nbsp;1391</span>
    
    
        
        <span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5 0-200-89.5-200-200S145.5 56 256 56s200 89.5 200 200-89.5 200-200 200zm61.8-104.4l-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6 0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"></path></svg>&nbsp;7&nbsp;mins</span>
    
    
    
</p>

            

            <div>
              <p><span>S</span>ix months ago, <a href="https://osjobs.net/co/" target="_blank" rel="noopener">Overseas Rabbit Course</a> started using a new pricing model. After applying the new strategy, revenue from each customer has increased by 2000%. According to this data, the new pricing strategy seems to gain great success. Of course, it would be a danger if we simple inferring the reasons for succeeding from numbers. But after such a large improvement in revenue, I still tend to analyze the reasons behind it.</p>
<h3 id="table-of-contents"><a href="#table-of-contents"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Table of Contents</h3>
<ul>
<li>Previous pricing model</li>
<li>New pricing model</li>
<li>What happened</li>
<li>Streaming media platform subscription</li>
<li>How to fix it</li>
<li>New problems</li>
<li>Summary</li>
</ul>
<h3 id="previous-pricing-model"><a href="#previous-pricing-model"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Previous pricing model</h3>
<p>Overseas Rabbit Course is an interview course for programmers including resume review and mock interview services. The previous pricing model is quite straight forward. It started in April 2018, the day Overseas Rabbit went online. our original pricing model charged a uniform price to each customer for the same course. Customers choose the desired course and pay for it, then we apply the related course for them.</p>
<p><img src="https://cdn.jsdelivr.net/gh/OSJobs/osjobs-info@master/assets/imgs/old%20price.png" alt="Old pricing model"></p>
<p>Just like other service platforms, a common problem for this pricing model is to find the best price to achieve profit maximization, so we adjusted the price in a while. Under the premise that the reduction of price would lead to more customers. However, it doesn’t work that well. Looking back, even though this pricing model is used everywhere but may not be the one we need.</p>
<h3 id="new-pricing-model"><a href="#new-pricing-model"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>New pricing model</h3>
<p>Until June 2020, a customer proposed to use 50% of his monthly salary to pay for our course. It reminds me of another programmer course I have seen before. It is also charged in proportion to the salary. I had doubts about this pricing model at that moment for two reasons:</p>
<ol>
<li>Paying by proportion is much more expensive than a fixed fee. The median salary of Chinese programmers is about 12,000 yuan, and 50% of the salary is almost 10 times more than the original fee. I’m not sure how many customers are willing to pay for it.</li>
<li>Job hunting is a combination of ability and luck. Some customers may take a few months to be successfully recruited. Such uncertainty may cause unstable revenue.</li>
</ol>
<p>However, after we found a customer is willing to pay by proportion. We made some adjustments to the course content and adopted a dynamic charging strategy. <strong>Nowadays, all of our courses are free to join, and we charge 50% of the customer’s salary only after they had been recruited succeed.</strong> I call this pricing strategy Proportional Pricing Model. I believe someone must have discovered it earlier than me and has named it, such as the programmer course I saw before. (Welcome to leave a comment if you found the source. ) Surprisingly, under the new pricing model, there are more customers than before, and we successfully increased our revenue by 20 times recently.</p>
<p><img src="https://cdn.jsdelivr.net/gh/OSJobs/osjobs-info@master/assets/imgs/new%20price.png" alt="New pricing model"></p>
<h3 id="why"><a href="#why"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Why</h3>
<p>I suppose there are some potential factors for the increasing revenue:</p>
<ol>
<li>Consequentialism</li>
<li>Dynamic price</li>
<li>Willingness of payment</li>
<li>Risk estimation</li>
</ol>
<h4 id="consequentialism"><a href="#consequentialism"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Consequentialism</h4>
<p>In the beginning, we thought that customers want to improve the ability for interviewing, but we were wrong. What customers really need is getting a job, <strong>and there is a huge difference between them.</strong> Most people will only judge the quality of the course based on the result after completing it. Under the previous price model, customers will balance between the course cost and interview skills obtained with their criterion. But now, Proportional Pricing Model closely connects the recruitment certainty with our course so customers would balance the course cost with the success of recruitment.</p>
<h4 id="dynamic-price"><a href="#dynamic-price"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Dynamic price</h4>
<ol>
<li>Proportional Pricing Model means the payment varies with the salary level, customers cannot know the actual number they will pay before getting the job which will make them feel less expensive.</li>
<li>Proportional payment is fairer. Higher cost means a higher salary. Customers should expect to pay as much as possible because it means they have a higher salary.</li>
<li>Percentages cannot be directly compared. If setting a fixed fee, such as 6,000 yuan per customer, the customer can directly compare 6,000 yuan with what he/she could purchase, such as books or other courses.&nbsp;</li>
</ol>
<h4 id="willingness-of-payment"><a href="#willingness-of-payment"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Willingness of payment</h4>
<ol>
<li>Everyone likes free products, customers can attend our courses for free until they found a job. Since 60% of our customers are unemployed, they don’t want to pay another bill.</li>
<li><strong>Customers will pay for what they think is worth.</strong> More than one customer has said that they are willing to spend more than 50% of their salary to exchange successful recruitment, which has never happened under the previous strategy.</li>
</ol>
<h4 id="wrong-risk-estimation"><a href="#wrong-risk-estimation"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Wrong risk estimation</h4>
<p>“It’s obvious that” most people will eventually get a job. However, lots of customers will overestimate the risk of unable to find a job when affected by the fear of unemployment.</p>
<h3 id="streaming-media-platform-subscription"><a href="#streaming-media-platform-subscription"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Streaming media platform subscription</h3>
<p>Let me talk about one more example to use Proportional Pricing Model. From Netflix, Youtube to Chinese media platforms like Tencent Video, Mango TV uses a monthly subscription price model. Although they use some strategies to attract customers continuously subscribing, such as 30 days of free trial, continuous monthly discounts, annual discounts, family membership package, there are still several problems:</p>
<h4 id="it-cost-the-platform-a-lot"><a href="#it-cost-the-platform-a-lot"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>It cost the platform a lot</h4>
<p>Usually, customers subscribe to the service because of a certain episode, and they will cancel their subscription after watching it (the first-month cancellation rate of streaming media platform is higher than 40%). Therefore, streaming media platforms need to continuously spend money on producing new content or purchasing copyrights, which would bring a lot of costs.</p>
<h4 id="customer-is-not-happy"><a href="#customer-is-not-happy"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Customer is not happy</h4>
<p>Some platforms want customers to automatically renew so they try different ways to prevent users from canceling, like bad UI, complicated steps, etc. Moreover, no customer feels they could take advantage of the same price.</p>
<ol>
<li>Customers who watch less (like me) will regret that they have spent too much on subscription fees. I hate monthly subscription, even though the monthly subscription price is cheaper than one cup of coffee.</li>
<li>Customer who watches more will not satisfy as well for the following two reasons: 1) Because there are a huge amount of videos, it’s difficult to measure how many videos you need to watch to get the fee back. 2) Mostly, watching videos is just a kind of entertainment. People may feel guilty if they spend too much time on it every month, and it leads to subscription cancellation.</li>
</ol>
<h3 id="how-to-fix-it"><a href="#how-to-fix-it"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>How to fix it</h3>
<p>With Proportional Pricing Model, I propose a new way to fix it:</p>
<ol>
<li>Customers can join streaming media membership for free and they can watch everything from the platform.</li>
<li><strong>The platform will charge the customer only if his/her monthly watching time is top 30% among all customers</strong>. For example, if Youtube has 10 million members, only 3 million customers will be charged every month, 7 million customers can enjoy services for free.</li>
</ol>
<p>The advantages of this scheme are as follows:</p>
<h4 id="dynamic-price-1"><a href="#dynamic-price-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Dynamic price</h4>
<p>Since customers are hard to predict whether they have to pay for this month:</p>
<ol>
<li>Their watching time may unconsciously reach the level of charging.</li>
<li>They are no longer need to decide whether to subscribe to the platform depend on a specific episode.</li>
</ol>
<h4 id="willingness-to-pay"><a href="#willingness-to-pay"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Willingness to pay</h4>
<ol>
<li>Charging everyone a fixed price is unfair. Just like electricity bills, charging everyone the same price bill will cause controversy. Therefore, members are charged based on how long they watched is more reasonable.</li>
<li>Everyone likes free products. who will cancel them when auto-renew is free.</li>
<li>It’s quite interesting to guess whether you need to pay this month. If people don’t have to pay for this month, people would feel like they earned money.</li>
</ol>
<h3 id="new-problems"><a href="#new-problems"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>New problems</h3>
<ol>
<li>In the Proportional Pricing Model, We don’t know how to set the number of percentages, 30% or 50%? Should we use the A/B test or there are other better ways for testing.</li>
<li>It is harder to get the money back, Overseas Rabbit may take several months to get the money from customer. Youtube may fail to charge some of the customers after every month.</li>
</ol>
<h3 id="summary"><a href="#summary"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Summary</h3>
<p>From my point of view, there are two conditions to build the best pricing model</p>
<ol>
<li>Easy to understand, customer willing to pay</li>
<li>Make money when the customer didn’t aware of it</li>
</ol>
<h3 id="last"><a href="#last"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Last</h3>
<ul>
<li>Feel free to email me (contact at osjobs.net) if you have any ideas about this article</li>
<li>Thanks to Mr. Peng and Liu Chang for reviewing this article. Thanks to Mary Ma for helping me translating.</li>
</ul>
            </div>

            
    
    
        
    



        </article>

        

        
    <p><span title="Updated @ 2021-02-02 12:38:32 CST">

<svg xmlns="http://www.w3.org/2000/svg" width="130" height="20"><linearGradient id="b" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"></stop><stop offset="1" stop-opacity=".1"></stop></linearGradient><clipPath id="a"><rect width="130" height="20" rx="3" fill="#fff"></rect></clipPath><g clip-path="url(#a)"><path d="M0 0h55v20H0z"></path><path d="M55 0h75v20H55z"></path><path fill="url(#b)" d="M0 0h130v20H0z"></path></g><g fill="#fff" text-anchor="middle" font-size="110"><text x="285" y="150" fill="#010101" fill-opacity=".3" textLength="450" transform="scale(.1)">updated</text><text x="285" y="140" textLength="450" transform="scale(.1)">updated</text><text x="915" y="150" fill="#010101" fill-opacity=".3" textLength="650" transform="scale(.1)">2021-02-02</text><text x="915" y="140" textLength="650" transform="scale(.1)">2021-02-02</text></g></svg>
        </span></p>



        


        




        
    
    



        
    



        


        


        
    
        
        
    
    
    
    



        


    </div>
</div></div>]]>
            </description>
            <link>https://osjobs.net/blog/posts/the-proportional-pricing-model/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997510</guid>
            <pubDate>Tue, 02 Feb 2021 04:40:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go 1.16 will make system calls through Libc on OpenBSD]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 67 (<a href="https://news.ycombinator.com/item?id=25997506">thread link</a>) | @lladnar
<br/>
February 1, 2021 | https://utcc.utoronto.ca/~cks/space/blog/programming/Go116OpenBSDUsesLibc | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/Go116OpenBSDUsesLibc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Go 1.16 will make system calls through libc on OpenBSD</h2>

	<p><small>February  1, 2021</small></p>
</div><div><p>One of the unusual things about <a href="https://golang.org/">Go</a> is that
it started out with the approach of directly making system calls
on Unix, instead of calling the standard C library functions that
correspond to those system calls. <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoCLibraryAPIIssues">There are reasonably good reasons
for Go to make direct system calls</a> and this
works well on Linux, but other Unixes are different. The official
API for Illumos and Solaris system calls requires you to use their
C library, and OpenBSD wants you to do this as well for security
reasons (for <a href="https://lwn.net/Articles/806776/">OpenBSD system call origin verification</a>). Go has used the C library on
Solaris and Illumos for a long time, but through Go 1.15 it made
direct system calls on OpenBSD and so current released versions of
OpenBSD had a special exemption from their system call origin
verification because of it.</p>

<p>The news of the time interval for Go 1.16 is that this is changing. To
quote from the current draft release notes (which are probably soon to
be the official release notes):</p>

<blockquote><p>On the 64-bit x86 and 64-bit ARM architectures on OpenBSD (the
<code>openbsd/amd64</code> and <code>openbsd/arm64</code> ports), system calls are now
made through <code>libc</code>, instead of directly using the <code>SYSCALL/SVC</code>
instruction. This ensures forward-compatibility with future versions
of OpenBSD. In particular, OpenBSD 6.9 onwards will require system
calls to be made through <code>libc</code> for non-static Go binaries.</p>
</blockquote>

<p>As far as I know, Go programs that look up host names or do a few other
operations are very likely to not be statically linked. You can force
static linking (and you'll normally get it if you cross-build), but it
has some drawbacks for hostname lookups in some configurations and you
can't do some other operations at all.</p>

<p>At one level everything is okay with this situation. OpenBSD 6.9 will
almost certainly include Go 1.16 in its ports collection, since it will
be the only version of Go that works on it, and from there you can build
Go programs that will run fine on 6.9. At another level, any dynamically
linked Go program you have will need to be rebuilt with Go 1.16 before
you can run it on OpenBSD 6.9. Hopefully you have the source code and
can still build it (in what will be a 'modular by default' world in Go
1.16). This is nothing really new for OpenBSD, which has always made it
clear that they don't promise ABI or even API compatibility; you always
need to be prepared to rebuild your programs for new OpenBSD versions,
and perhaps to update them to more secure APIs.</p>

<p>(Statically linked Go programs built by Go 1.15 or earlier will likely
keep working on OpenBSD 6.9, assuming that there are no other ABI
changes that affect them. But you should probably plan to rebuild them
with Go 1.16 just to be sure. I don't know what the situation will be
if you want to create Go binaries that work across a range of OpenBSD
versions.)</p>

<p>As the release notes say, Go 1.16 will make system calls through libc
for all programs, whether they're dynamically linked or statically
linked. Right now OpenBSD only requires this for dynamically linked
programs (well, will require it), but always calling via libc is simpler
than to maintain two sets of system call code. And someday OpenBSD may
do something more elaborate so that making system calls via libc is
required even for statically linked programs.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/Go116OpenBSDUsesLibc</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997506</guid>
            <pubDate>Tue, 02 Feb 2021 04:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Polymorphisation: Improving Rust compilation times through intelligent monomorp [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25997495">thread link</a>) | @todsacerdoti
<br/>
February 1, 2021 | https://davidtw.co/media/masters_dissertation.pdf | <a href="https://web.archive.org/web/*/https://davidtw.co/media/masters_dissertation.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://davidtw.co/media/masters_dissertation.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997495</guid>
            <pubDate>Tue, 02 Feb 2021 04:37:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AlmaLinux Beta: A Community-Driven Replacement for CentOS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25997458">thread link</a>) | @_-david-_
<br/>
February 1, 2021 | https://blog.almalinux.org/introducing-almalinux-beta-a-community-driven-replacement-for-centos/ | <a href="https://web.archive.org/web/*/https://blog.almalinux.org/introducing-almalinux-beta-a-community-driven-replacement-for-centos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div>

                                <p><span>CloudLinux is proud to announce the release of AlmaLinux Beta. We’ve collected community feedback and built our new beta release around what you would expect from an enterprise-level Linux distribution. AlmaLinux is a completely free 1:1 binary compatible fork of Red Hat Enterprise Linux (RHEL) 8, inspired by the community and built by the engineers and talent behind CloudLinux. Visit <a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/">this link</a></span><span>&nbsp;to download Beta images.</span></p>

<p><span>With the Beta release deployed, we’d like to ask the community to be involved and provide feedback. We aim to build a Linux distribution entirely from community contributions and feedback. During AlmaLinux Beta, we ask for assistance in testing, documentation, support and future direction for the operating system. Together, we can build a Linux distribution that fills the gap left by the now unsupported CentOS distribution.</span></p>
<p><span>The AlmaLinux team set up all the necessary infrastructure to make it convenient for our contributors to provide their input. The public repository on </span><a href="https://github.com/AlmaLinux"><span>Github</span></a><span> is where we will finalize the source code for the system, and any additional documentation will be posted on the </span><a href="https://wiki.almalinux.org/"><span>wiki</span></a><span>. We set up the wiki and repository to make it easy for the community to provide as much information and feedback as possible. The AlmaLinux team will review every comment and request, but we ask that only registered contributors </span><a href="https://bugs.almalinux.org/login_page.php"><span>file bug reports</span></a><span> to filter out spam.</span></p>
<p><span>To facilitate communication and help answer some of the common questions you might already have, we will be hosting a live QA webinar with the AlmaLinux team. </span><span>The webinar will take place on February 10, </span><span>5 PM (UTC) / 9 AM (PST). Among the participants present will be Igor Seletskiy, CEO of CloudLinux, and Alexander Vinogradov, Head of Engineering at AlmaLinux.</span></p>
<p><span>You can sign up for our webinar </span><a href="https://blog.almalinux.org/webinars/almalinux-beta-qa-webinar/"><span>here</span></a><span>.</span></p>
<p><span>If you have any questions, comments, feedback or concerns, please feel free to send us your thoughts to </span><a href="https://blog.almalinux.org/cdn-cgi/l/email-protection#2048454c4c4f60414c4d414c494e55580e4f5247"><span><span data-cfemail="85ede0e9e9eac5e4e9e8e4e9ecebf0fdabeaf7e2">[email&nbsp;protected]</span></span></a><span> or send them during the webinar on Twitter with the hashtag #AlmaLinuxBeta.</span></p>
<p><span>CloudLinux and the AlmaLinux team would like to thank the community for their input. This is just the beginning for AlmaLinux, and we look forward to continued improvements and updates for the next generation enterprise-level Linux operating system.</span></p>
<p><span>Thank you for your contribution, input, and support throughout launching AlmaLinux! The infrastructure was the first step, now we need your help to make the next one!</span></p>


<p><strong>Release Notes for AlmaLinux 8 beta</strong></p>
<p><span>The release code name: Purple <a href="https://en.wikipedia.org/wiki/Pallas%27s_cat">Manul</a>.</span></p>
<p><span>CloudLinux is proud to present the beta version of AlmaLinux. After roughly a month and a half from the announcement, here is a 1:1 RHEL binary compatible replacement for your RHEL-based systems.&nbsp;</span></p>
<p><span>This is for the community and by the community, you’re the soul of Linux. Thank you for your interest and suggestions so far, keep them coming.</span></p>
<p><span>Use this version to thoroughly test your workloads and report any unintended features (ie, bugs) you may find, it will help make AlmaLinux better.</span></p>

<h2><span>Installation instructions</span></h2>

<p><span>There are three installation ISO images available:</span></p>
<ul>
<li aria-level="1"><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-boot.iso"><span>AlmaLinux-8.3-beta-1-x86_64-boot.iso</span></a><span> – a single network installation CD image that downloads packages over the Internet.</span></li>
<li aria-level="1"><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-minimal.iso"><span>AlmaLinux-8.3-beta-1-x86_64-minimal.iso</span></a><span> – a minimal self-containing DVD image that makes possible offline installation.</span></li>
<li aria-level="1"><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-dvd1.iso"><span>AlmaLinux-8.3-beta-1-x86_64-dvd1.iso</span></a><span> – a full installation DVD image that contains mostly all AlmaLinux packages. We don’t really recommend using it unless you need to set up and use AlmaLinux on a machine without internet access.</span></li>
</ul>

<p><span>Download a preferable ISO image and verify its checksum. Here is an example for GNU/Linux:</span></p>
<blockquote>
<pre><span># download and import the AlmaLinux public key</span>
<span>$ wget </span><a href="https://repo.almalinux.org/almalinux/RPM-GPG-KEY-AlmaLinux"><span>https://repo.almalinux.org/almalinux/RPM-GPG-KEY-AlmaLinux</span></a>
<span>$ gpg --import RPM-GPG-KEY-AlmaLinux</span>

<span># download a checksums list</span>
<span>$ wget </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/CHECKSUM"><span>https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/CHECKSUM</span>
</a><span>
# verify the checksums list, we are looking for “Good signature”</span>
<span>$ gpg --verify CHECKSUM </span>
<span>gpg: Signature made Thu 28 Jan 2021 11:39:12 PM MSK</span>
<span>gpg:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; using RSA key 51D6647EC21AD6EA</span>
<span>gpg: <strong>Good signature from "AlmaLinux &lt;<a href="https://blog.almalinux.org/cdn-cgi/l/email-protection" data-cfemail="156574767e747270675574797874797c7b606d3b7a6772">[email&nbsp;protected]</a>&gt;"</strong> [unknown]</span>
<span>gpg: WARNING: This key is not certified with a trusted signature!</span>
<span>gpg:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; There is no indication that the signature belongs to the owner.</span>
<span>Primary key fingerprint: 5E9B 8F56 17B5 066C E920&nbsp; 57C3 488F CF7C 3ABB 34F8</span>
<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Subkey fingerprint: E53C F5EF 91CE B0AD 1812&nbsp; ECB8 51D6 647E C21A D6EA</span>

<span># download the network install ISO</span>

<span>$ wget </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-boot.iso"><span>https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-boot.iso</span></a>
<span># calculate the downloaded ISO SHA256 checksum</span>
<span>$ sha256sum AlmaLinux-8.3-beta-1-x86_64-boot.iso </span>
<span>d15be406f417e81382b46a54d87dff01c8ca770c847c18703f19146587b61a1f&nbsp; AlmaLinux-8.3-beta-1-x86_64-boot.iso</span>

<span># compare it with expected checksum, it should be the same</span>
<span>$ cat CHECKSUM | grep -E 'SHA256.*AlmaLinux-8.3-beta-1-x86_64-boot.iso'</span>
<span>SHA256 (AlmaLinux-8.3-beta-1-x86_64-boot.iso) = d15be406f417e81382b46a54d87dff01c8ca770c847c18703f19146587b61a1f</span></pre>
</blockquote>

<p><span>If you decided to use the AlmaLinux-8.3-beta-1-x86_64-boot.iso image, you will need to provide this </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/BaseOS/x86_64/kickstart/"><span>https://repo.almalinux.org/almalinux/8.3-beta/BaseOS/x86_64/kickstart/ </span></a><span>repository as the Installation Source:</span></p>

<p><img loading="lazy" src="http://blog.almalinux.org/wp-content/uploads/2021/02/source-2.png" alt="" width="731" height="507" srcset="https://blog.almalinux.org/wp-content/uploads/2021/02/source-2.png 1053w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-300x208.png 300w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-1024x710.png 1024w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-150x104.png 150w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-768x532.png 768w" sizes="(max-width: 731px) 100vw, 731px"></p>

<p><span>If you are going to install a non-minimal environment, you will need to add the AppStream repository to the additional repositories: </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/AppStream/x86_64/os/"><span>https://repo.almalinux.org/almalinux/8.3-beta/AppStream/x86_64/os/</span></a><span>.</span></p>
<p><span>There are no extra Installation Sources required if you decided to go with AlmaLinux-8.3-beta-1-x86_64-minimal.iso or AlmaLinux-8.3-beta-1-x86_64-dvd1.iso images.</span></p>

<h2><span>How to set up a usb key to install AlmaLinux</span></h2>
<blockquote>
<pre><span>dd if=AlmaLinux-8.3-beta-1-x86_64-boot.iso of=/dev/sdX</span></pre>
</blockquote>
<p><span>Where </span><b>sdX</b><span> is your usb device</span></p>

<h2><span>Known issues</span></h2>
<ul>
<li><span>Our libreport/abrt packages aren’t integrated with the bugs.almalinux.org bug-tracker yet, so a user will have to submit a crash report manually. Issue: </span><a href="https://bugs.almalinux.org/view.php?id=2"><span>almbz#2</span></a><span>.</span></li>
<li><span>The “perl:5.30” module support is incomplete in the beta release, it will be finished in the stable.</span></li>
<li><span>We don’t have the latest “jmc” and “maven” module versions. They will be updated later.</span></li>
<li><span>The “satellite-5-client” module is located in the BaseOS repository instead of the AppStream. Issue: </span><a href="https://bugs.almalinux.org/view.php?id=4"><span>almbz#4</span></a><span>.</span></li>
<li><span>There is no support for Secure Boot in the beta release. Issue: </span><a href="https://bugs.almalinux.org/view.php?id=3"><span>almbz#3</span></a><span>.</span></li>
<li><span>The debuginfo repositories are empty and will be populated in a couple of days after the beta release.</span></li>
</ul>



                             </div>



                            </div></div>]]>
            </description>
            <link>https://blog.almalinux.org/introducing-almalinux-beta-a-community-driven-replacement-for-centos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997458</guid>
            <pubDate>Tue, 02 Feb 2021 04:30:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Journal of Illusion (JOI): open-access journal to promote the study of illusions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25997298">thread link</a>) | @sohkamyung
<br/>
February 1, 2021 | https://journalofillusion.net/index.php/joi/index | <a href="https://web.archive.org/web/*/https://journalofillusion.net/index.php/joi/index">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="customblock-about">
	<div>
		<p><span>About the journal</span></p>
<p>Journal of Illusion (JOI) is an open-access journal that aims at gathering resources to promote the study of illusion. JOI defines an illusion as the perception of an object or phenomenon that is considered to be inconsistent with individual’s or group’s prior knowledge, recognition, or belief as to what the object or phenomenon should be in perception, cognition, and/or physics.&nbsp; Therefore, JOI focuses on perceptual illusions, cognitive illusions (e.g. magic or misunderstanding) or physical illusions (e.g. mirage or the Doppler effect). For perceptual illusions, not only visual illusions but also illusions at various sensory modalities are welcome. Trompe l’oeil as well as illusion artworks are also welcome. <strong><a href="https://journals.openacademia.net/index.php/joi/about">Learn more &gt;&gt;</a></strong></p>
	</div>
</div><div id="customblock-whypublish">
	<div>
		<p><span>Why publish with <strong><em>Journal of Illusion</em></strong>?</span></p>
<p><span>Open Access</span>&nbsp;–&nbsp;<em>Journal of Illusion</em>&nbsp;is free from all access barriers, allowing for the widest possible dissemination of your work.</p>
<p><span>Retain copyright&nbsp;</span>– you are free to disseminate your work, make unlimited copies, and deposit it in any repository.&nbsp;</p>
<p><span>Personal service</span>&nbsp;–&nbsp;<em>Journal of Illusion</em>&nbsp;is published in partnership with <a href="https://openacademia.net/index.html">Open Academia</a>, a Publishing Partner dedicated to giving you excellent service.&nbsp;</p>
<p><span>Self-archiving</span>&nbsp;– you can deposit&nbsp;<em>any</em>&nbsp;version of your manuscript in any required repository or archive, or post it to your personal or institutional website.&nbsp;</p>
<p><strong>Post-publication statistics</strong> – metrics shown with each article make it easy to check how often your paper is being downloaded via the JOI website.</p>
<p><strong>Add supplementary material</strong> – you can make data sets, protocols, very large illustrations, videos, questionnaires etc. available to readers alongside your article, free of charge.&nbsp;</p>
	</div>
</div></div>]]>
            </description>
            <link>https://journalofillusion.net/index.php/joi/index</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997298</guid>
            <pubDate>Tue, 02 Feb 2021 03:58:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The anthem of Russia on YouTube was “privatized” by an American company]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25997296">thread link</a>) | @sjreese
<br/>
February 1, 2021 | https://en.topwar.ru/179591-gimn-rossii-v-youtube-okazalsja-privatizirovan-amerikanskoj-kompaniej.html | <a href="https://web.archive.org/web/*/https://en.topwar.ru/179591-gimn-rossii-v-youtube-okazalsja-privatizirovan-amerikanskoj-kompaniej.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<meta property="og:type" content="article">
<meta property="og:title" content="The anthem of Russia on YouTube was &quot;privatized&quot; by an American company">
<meta property="article:author" content="novosti">
<meta property="article:section" content="Новости">
<meta property="article:tag" content="Новости">
<meta property="article:published_time" content="2021-02-02T06:35:55+0300">
<meta itemprop="datePublished" content="2021-02-02T06:35:55+0300">
<meta itemprop="identifier" content="179591">
<p><a href="https://topwar.ru/uploads/posts/2021-02/1612236802_5.jpg" target="_blank"><img loading="lazy" src="https://topwar.ru/uploads/posts/2021-02/thumbs/1612236802_5.jpg" alt=""></a></p><p>The network is actively discussing a situation that any adequate person perceives as nonsense. The point is that YouTube video hosting users have noticed the following, to put it mildly, oddity. When trying to upload video content with the Russian anthem to their channels, bloggers were faced with warnings that this allegedly violates the copyrights of some American copyright holders. </p><p>Blogger Yuri Khovansky tried to figure out the situation when he was faced with a warning from the video hosting about “controversial content”.</p><p>It turned out that the music of the Russian anthem, written in Soviet times by the composer Alexander Alexandrov, was somehow "privatized" by the American corporation BMI. Bloggers note that now, in order to use the video with the anthem of Russia on your YouTube channel, you must submit an application to the "copyright holder". Phantasmagoria…</p><p>A detailed study of the situation revealed that this is not only the case with the Russian anthem on YouTube. It turned out that a few months ago this video hosting showed a tendency in which Western companies, including those in the music business, submitted data on the "ownership" of a number of Soviet songs, marches, etc. Thus, the American company The Orchard Music "registered rights "to the Soviet musical compositions" Victory Day "and" Holy War ". This was followed by a whole ninth wave of American "privatization" of Soviet cultural heritage on YouTube. The "rights" of American companies were registered in respect of those songs of Soviet performers who had the largest number of streams on the Internet.</p><p>Thus, it should be stated that American video hosting is actually trying to legitimize outright digital raiding or even piracy, while also encouraging it. This is another example of how far the American digital giants have gone, considering themselves the right to dispose of not only user accounts, but also cultural<a href="https://en.topwar.ru/history/" title="история">historical</a> heritage, to which they themselves have nothing to do.
</p></div></div>]]>
            </description>
            <link>https://en.topwar.ru/179591-gimn-rossii-v-youtube-okazalsja-privatizirovan-amerikanskoj-kompaniej.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997296</guid>
            <pubDate>Tue, 02 Feb 2021 03:57:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kafka as a Database? Yes or No]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25997256">thread link</a>) | @matthewhelm
<br/>
February 1, 2021 | https://davidxiang.com/2021/01/10/kafka-as-a-database/ | <a href="https://web.archive.org/web/*/https://davidxiang.com/2021/01/10/kafka-as-a-database/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="penci-post-entry-inner"><p>I recently read through a Hacker News <a href="https://news.ycombinator.com/item?id=25346851" target="_blank" rel="noreferrer noopener nofollow">thread</a> discussing the <a href="https://materialize.com/kafka-is-not-a-database/" target="_blank" rel="noreferrer noopener">article</a> “Kafka Is Not A Database”, by <a href="https://twitter.com/narayanarjun" target="_blank" rel="noreferrer noopener nofollow">Arjun Narayan</a>&nbsp;and&nbsp;<a href="https://twitter.com/frasergeorgew?lang=en" target="_blank" rel="noreferrer noopener nofollow">George Fraser</a>. The opinions behind this topic are fascinating and I enjoyed sifting through comments from both sides of the table. For the purposes of this post, I’ve labeled these two broad groups of thoughts as Team Blue and Team Red.</p><p>Team Blue believes that <a href="https://kafka.apache.org/" target="_blank" rel="noreferrer noopener">Kafka</a>, a popular streaming platform, has the potential to be the source-of-truth for your data—replacing one of the key responsibilities of conventional databases.</p><p>Team Red strongly disagrees.</p><p>The following is high-level summary of these opinions.</p> <h2><strong>Kafka As A Database</strong></h2><h3>TL;DR Streams,Events,Kafka</h3><p>First, a conceptual model of streams:</p><blockquote><p>In&nbsp;<a href="https://en.wikipedia.org/wiki/Computer_science">computer science</a>, a&nbsp;<strong>stream</strong>&nbsp;is a&nbsp;<a href="https://en.wikipedia.org/wiki/Sequence">sequence</a>&nbsp;of&nbsp;<a href="https://en.wikipedia.org/wiki/Data_element">data elements</a>&nbsp;made available over time.&nbsp;A stream can be thought of as items on a&nbsp;<a href="https://en.wikipedia.org/wiki/Conveyor_belt">conveyor belt</a>&nbsp;being processed one at a time rather than in large batches.</p><cite>Wikipedia.org</cite></blockquote><p>Imagine that you’ve hired an invisible assistant. This assistant’s only responsibility is to record everything you do:</p><ol><li>Wakes up @ 8 am</li><li>Brushes teeth @ 8:35 am</li><li>Begins showering @ 8:40 am</li><li>…</li></ol><p>As you go about your day, your assistant meticulously captures your activity and adds new entries into your daily log. This growing log represents a <strong>stream </strong>of your day-to-day activity. The data elements that comprise the stream are known as <strong>events</strong>. Once an event is recorded, it is immutable; the fact that you brushed your teeth at 8:35 am yesterday will never change.</p><p>While your invisible assistant is following you around and <strong>producing</strong> new events to your stream, who is <strong>consuming</strong> them? Anyone who cares! I’m sure your mom would be thrilled to process through your activities and call you if there are any anomalies.</p><p>What about <strong>Kafka</strong>?</p><blockquote><p><strong>Apache Kafka</strong>&nbsp;is an&nbsp;<a href="https://en.wikipedia.org/wiki/Open-source_software" target="_blank" rel="noreferrer noopener nofollow">open-source</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Stream_processing" target="_blank" rel="noreferrer noopener nofollow">stream-processing</a>&nbsp;software platform developed by the&nbsp;<a href="https://en.wikipedia.org/wiki/Apache_Software_Foundation" target="_blank" rel="noreferrer noopener nofollow">Apache Software Foundation</a>, written in&nbsp;<a href="https://en.wikipedia.org/wiki/Scala_(programming_language)" target="_blank" rel="noreferrer noopener">Scala</a>&nbsp;and&nbsp;<a href="https://en.wikipedia.org/wiki/Java_(programming_language)" target="_blank" rel="noreferrer noopener">Java</a>.&nbsp;</p><cite>Wikipedia.org</cite></blockquote><p>Kafka is a platform (large set of software tools) that helps programmers work with streams.</p><h2>Team Blue – Streams Everywhere</h2><p>Team Blue believes that streams are a natural model for both life and computing. Your users produce a stream of clicks, sign-ups, and orders. Your code produces a stream of logs, metrics, and programmatic events. Team Blue believes that the intuitive nature of streams can lead to intuitive software architectures.</p><p>An essential component of any system is the database—a convenient place to read and write whatever you want. How can a stream replace this concept that we are so used to? If streams are a never-ending series of immutable events, then the property of state is the culmination of events up to a certain point in time. For example, the latest state of a database is the culmination of all operations made to that database. In computing, this is referred to as <a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/event-sourcing" target="_blank" rel="noreferrer noopener">Event Sourcing</a>. This paradigm is very different to how many developers are used to thinking about their data.</p><p>Beyond data storage, Team Blue is bullish on the idea of stream-focused architectures in general. Streams work well with microservices, promote loose coupling of systems, and have the potential to create leverage in your software. If you’re thinking about streams, you will inevitably think about Kafka—one of the industry’s leading streaming platforms.</p><p><strong>Can</strong> you use Kafka as a database? Team Blue says yes.</p><p><strong>Should</strong> you use Kafka as a database? That’s up to you.</p><h2>Team Red – You Need Databases</h2><p>On the other side of the table is Team Red who believes that programmers are making a mistake by replacing conventional databases with Kafka.</p><p>Team Red believes that 99% of applications need the features of a conventional database—especially the features handling complex concurrency issues. Many of us use these features and they are critical for the success of our applications. Modern databases are battle-tested and have been iterated on for decades. Team Red believes that the message of “Kafka As A Database” is a dangerous message that leads developers into architectures they’re not equipped to handle.</p><h2>The People On Each Team</h2><p>There is no shortage of influential people who align with Team Blue. One notable engineer is <a href="https://twitter.com/jaykreps" target="_blank" rel="noreferrer noopener">Jay Kreps</a>, CEO of <a href="https://www.confluent.io/blog/okay-store-data-apache-kafka/" target="_blank" rel="noreferrer noopener">Confluent</a>. Confluent is an organization that sells Kafka as a solution to enterprises. There is a direct correlation between using streams and using Kafka; I’m sure Jay has a few extra reasons to be bullish on streams beyond his personal software architecture preferences.</p><p>Another influencer aligned with Team Blue is <a href="https://twitter.com/martinkl" target="_blank" rel="noreferrer noopener">Martin Kleppmann</a>, author of the extremely popular book <a href="https://www.amazon.com/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321" target="_blank" rel="noreferrer noopener">Designing Data-Intensive Applications</a>. Martin Kleppmann is a researcher who loves the idea of streams. His goal is to educate as many programmers as possible. Martin’s only qualm with Team Red’s opinion is the tone of their blog post. In his <a href="https://twitter.com/martinkl/status/1336336852890963977" target="_blank" rel="noreferrer noopener">own words</a>:</p><blockquote><p>Nice blog post [Kafka Is Not A Database] explaining why the “database inside out” approach is not for everyone. <a href="https://twitter.com/narayanarjun">@narayanarjun</a> and <a href="https://twitter.com/frasergeorgew">@frasergeorgew</a> are right —&nbsp;if you need to maintain constraints before events are written (e.g. not selling more items than you have in stock), it’s easier to use a DB and CDC.</p><p>On the other hand, the message is also a bit patronising. It basically says “you’re not clever enough to use an event log correctly — leave database stuff to the experts”. I respectfully disagree: it is good to explore new approaches. Learn about the trade-offs, educate yourself.</p><cite>Martin Kleppmann</cite></blockquote><p>Engineers on Team Red’s side include <a href="https://materialize.com/author/arjun/" target="_blank" rel="noreferrer noopener nofollow">Arjun Narayan</a>&nbsp;and&nbsp;<a href="https://materialize.com/author/george-fraser/" target="_blank" rel="noreferrer noopener nofollow">George Fraser</a>, co-authors of the <a href="https://materialize.com/kafka-is-not-a-database/" target="_blank" rel="noreferrer noopener">article</a> which refutes the idea of “Kafka As A Database.” They have decided to put a large, yellow caution sign in front of Team Blue’s message. Team Red has no issue with Kafka or streams; they have an issue with eager developers throwing out their <a href="https://en.wikipedia.org/wiki/Relational_database#RDBMS" target="_blank" rel="noreferrer noopener">RDMSs</a> and jumping on the stream bandwagon. Their only extra agenda might be to get extra eyeballs on their engineering blogs.</p><h2>Arguments From Team Blue</h2><p>The following points are summaries of topics discussed in Martin Kleppmann’s <a href="https://www.youtube.com/watch?v=fU9hR3kiOK0&amp;t=2089s" target="_blank" rel="noreferrer noopener">video</a>.</p><h3>High Integrity Data – Never Deleted</h3><p>With a database, your information is easily susceptible to being lost. Once your Postgres row is updated, it’s difficult to recover the previous state of that row without introducing custom accountability software. Databases and the records inside them are designed to be mutable. It’s both a great convenience and a great risk. If a table accidentally gets deleted, you might find yourself scrambling to restore your database from a backup. This is particularly painful in production.</p><p>On the other hand, if your data exists as a log of immutable events—and that log happens to be retained forever—the history of your changes never runs the risk of being erased. Accounting is a great example of this—accountants balance their books by only appending new entries to their ledgers. An error in a financial transaction is always fixed by another transaction.</p><p>Team Blue believes that this characteristic can be an asset to software architectures. As a permanent log of events, data will always have its historical context and can easily be audited. Furthermore, the lack of an “eraser” forces programmers and processes to be held highly accountable for their actions.</p><div> <p><span>Trade-Off</span>: </p><p> One concern of storing all your data in a log is that the size of your logs may become unwieldy over time. Do we really care about how a customer changed their email 3 years ago or do we only care about what it is today? Large Kafka logs can also complicate consumers—catching up from offset 0 may not be so easy. Kafka has implemented features like <a href="https://kafka.apache.org/documentation.html#compaction" target="_blank" rel="noopener"> Log Compaction </a> to mitigate this. However, this is yet another complexity for programmers to manage and debug. </p><p> Another trade-off of this architecture is that it can become cumbersome for privacy concerns. There are administrative use-cases (GDPR) when you are required to completely <strong>hard delete</strong> all of your customer’s personal information from your system. This takes additional effort if the data to be deleted is scattered across logs and storage systems.</p></div><h3>Separation Of Concerns – Reading / Writing</h3><p>Team Blue points out that one of the great conveniences of databases is also one of its greatest challenges. The convenience of databases is undeniable—an easy one-stop shop to read and write anything. The drawback to being a one-stop shop is that you can’t be the best at any <strong>one</strong> thing, which becomes problematic as you scale.</p><p>Conventional databases easy conflate reads and writes, two very different styles of operations. As you scale, the access patterns in your software will inevitably force you to optimize for a certain set of operations. If an operation-specific optimization is done in a centralized location, it will likely degrade the performance of other operations in that location. If you optimize reads, you complicate writes—and vice versa.</p><p>One of the first steps in optimizing SQL reads is to begin denormalizing (duplicating) data across various tables. Once your data is duplicated, queries require less joins and respond faster. However, the drawback of denormalization is that it creates additional complications on the write pathway. Programmers need to remember to update and synchronize the duplicated data across multiple tables.</p><p>This pattern grows in complexity as you scale. If denormalization isn’t getting you the required read performance, the usual next step is to introduce a cache in front of your database. A cache is extremely convenient and can be designed to precisely answer the questions your clients are asking. However, as many programmers are intimately aware of, maintaining a cache is never easy. You now to need synchronize writes across network boundaries, worry about distributed transactions, and debug subtle invalidation issues.</p><p>Going back to our make-believe example, my assistant only has <strong>one</strong> responsibility—log my daily activity. One day, I decide that I want to look back in time to see how my activities are categorized. Unfortunately, I can’t ask my assistant this question because it’s too specific; all he knows how to do is produce events. To get insights on my activity, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidxiang.com/2021/01/10/kafka-as-a-database/">https://davidxiang.com/2021/01/10/kafka-as-a-database/</a></em></p>]]>
            </description>
            <link>https://davidxiang.com/2021/01/10/kafka-as-a-database/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997256</guid>
            <pubDate>Tue, 02 Feb 2021 03:47:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Barbarians Past the Gate]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25996935">thread link</a>) | @AngelusNovus
<br/>
February 1, 2021 | https://otherlife.co/barbarians-past-the-gate/ | <a href="https://web.archive.org/web/*/https://otherlife.co/barbarians-past-the-gate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="div_block-73-2180"><div id="inner_content-74-2180"><section id="section-2-306"><div><div id="inner_content-3-306"><p>Legacy institutions are at war with distributed collective intelligence, but the legacy institutions are losing—badly.</p>
<p>2 million full-time “content creators,” outside any professional sanction; the election of Donald Trump against an airtight media consensus certain of its impossibility; mass, hysterical preference falsification due to a normalization of political correctness, with silent mass migration into countless private communities; Big Tech’s capitulation to censorship on all major social platforms; the resilient rise in the price of Bitcoin and a proliferation of <a href="https://forefront.market/ranking">durable social currencies on Ethereum;</a> and most recently, an unprecedented execution of decentralized social intelligence, which minted more than a few millionaires out of thin air, by <a href="https://share.transistor.fm/s/05408a92">a niche internet community hacking the source code of finance capitalism.</a></p>
<p>Most of the essential requirements for a functioning polity—fiat currency, leaders, laws, and shared identity—have been fully decoded and open-sourced in the form of cryptocurrencies, content creators, Smart Contracts, and fandoms. It seems inevitable that our roughly 195 nation states must increasingly give way to thousands of digital micro-polities, as these embryonically political structures grow in economic and psychological power.</p>
<p>The only other defining characteristic of autonomous polities—a monopoly on the use of force—is increasingly obsolete as the payoff to peaceful trade raises the opportunity cost of physical violence. Hence the relative dearth of interstate war since the end of World War II.</p>
<p>If you doubt the claim that “content creators” are budding politicians—whether they know it or not—consider the curious case of Mr. Beast.</p>
<p>The most powerful Youtubers are accidentally rediscovering the nature of Aristocracy, a type of social role we like to think we abolished.</p>
<p>Mr. Beast is a Youtuber who currently enjoys 52 million subscribers and earns somewhere in the ballpark of $20-30 million annually at the age of 22. Jimmy Donaldson built one of the most influential and economically successful Youtube channels through a specific concept: Outrageous and conspicuous acts of generosity. His typical video involves him gifting large sums of money or lavish objects to random people, poor people, or friends.</p>
<p>As true aristocrats have always known, and as contemporary elites have forgotten, lavish generosity towards the needy demonstrates one’s authentic nobility, wins public attention and admiration, and genuinely improves society while increasing the political and economic power of the donor.</p>
<p>The so-called “creator economy” is only a becoming-liquid of the circuit connecting noble traits, admiration, and capital, such that the previously abolished form of Aristocracy re-appears in a distributed and ungovernable format. You could try to govern it, but you would need someone as organically admirable as the target, or else Mr. Beast fans will never even hear about your new law, let alone respect it (especially after they upload themselves full-time to the Mr. Beast VR pod and earn all of their income through Mr. Beast’s branded gaming engine). National law enforcement does not generally excel in the domain of authentic nobility, ergo the new form of distributed Aristocracy will not be put back in the bottle.</p>
<p>I am not suggesting Mr. Beast will become the effective President of a new country within the United States. I am suggesting Mr. Beast will be one of <em>thousands</em> who effectively constitute micro-polities, each one optimizing for different personality types and demographic buckets. Power laws dictate a small minority of creators will enjoy audiences far larger than the rest, but I suspect at least several thousands of creators will operate all-inclusive <em>weltanschauungen</em> for audiences of several thousands. I am pulling these specific numbers out of thin air, but I am directionally confident; I would encourage someone to explore more sophisticated modeling of this question.</p>
<p>If you still doubt that someone like Mr. Beast is an embryonic statesman, you might be impressed to learn about his long-term goal. His stated goal is to create a nation-wide system of homeless shelters and food banks. That’s right, he’s going to build a <a href="https://www.tubefilter.com/2020/11/19/mrbeast-philanthropy-food-bank/">national system of public housing.</a> I see no reason why he cannot succeed, given that he has already proven a business model that turns charismatic philanthropy into attention, admiration, and wealth for himself. Given that the USA Department of Housing and Urban Development doesn’t even try to create housing any more, it is not particularly speculative or sci-fi to suggest that Mr. Beast is on his way to becoming a kind of shadow Secretary of Housing in the United States. It’s there for the taking, it’s his stated goal, and he’s on track to do it. If he falters, it’s hard to imagine that the next generation of creators will also fail to appreciate such historic opportunities in front of them.</p>
<p>Bitcoin feeds directly into content creators becoming governors, not additively but multiplicatively—in a few ways. This means you should watch out for non-linear takeoffs, where things seem to be unfolding gradually, gradually… and then all at once.</p>
<p>First of all, Bitcoin is becoming the leading inflation-hedge asset as the US government engages in unprecedented money printing. Censorship-resistant and inflation-proof money is becoming increasingly accessible, normalized, and trusted at the same time that legacy institutions are doubling down on… censorship and inflation. It’s not inconceivable that eventually the US government needs Bitcoin—and the intellectual/communication services of leading content creators—much more than anyone needs the US government. If the US government’s balance sheet gets worse, and Bitcoin continues to get better, this alone could trigger a non-linear event where all smart money rushes into Bitcoin rapidly, and the US government’s balance sheet collapses with equal rapidity.</p>
<p>Second, most of the leading content creators have hardly even begun utilizing cryptocurrency. They will. Given the mimetic nature of financial value, leading Youtubers could single-handedly increase the price of any given cryptocurrency, simply by promoting it, using it, and whipping their fans into a frenzy.</p>
<p>Just recently Elon Musk put the word “Bitcoin” in his Twitter profile and <a href="https://www.coindesk.com/elon-musk-prompted-bitcoin-price-surge-causes-liquidation-of-387m-in-shorts">the price of Bitcoin immediately rose 15%.</a> If for any reason Bitcoin becomes fashionable among leading creators, the result will be non-linear. The creators would be making themselves even richer, simply by adopting Bitcoin and triggering price increases, so I consider this to be a game-theoretic inevitability (even if many don’t want to take this opportunity at time t1, rising creators who do take this opportunity at time t2 will dominate the others, which means it is hard to imagine a future in which this opportunity is not taken).</p>
<p>Just as we watched the Reddit community Wallstreetbets pump the price of Gamestop on the stock exchange, without a leader, any community with a leader will be all the more capable of such a feat. The Robinhood app was able to halt purchases of Gamestop, but there already exist decentralized crypto exchanges, on which nobody has the power to halt trades. Technically unstoppable versions of the Gamestop pump therefore seem inevitable on decentralized exchanges, meaning communities will eventually have unprecedented power to affect the value of assets by sheer belief and collective will.</p>
<p>There is already a new breed of avant-garde content creators—small compared to Mr. Beast but large enough to be dangerous—investing heavily in crypto assets and infrastructure. Consider Trevor McFedries, creator of the first CGI influencer Lil’ Miquela. He’s minted his own social currency $FWB on the Ethereum blockchain, and its value has been <a href="https://www.coingecko.com/en/coins/friends-with-benefits">rising steadily</a> as the value of his community increases. If he and his community continue to create value inside the community, the value of $FW will continue to rise, and everyone in the community will see their wealth increase in proportion to their $FWB holdings. It is hard to imagine that there will not eventually be a creator as big as Mr. Beast and as crypto-savvy as McFedries, who runs a private digital community with a market cap as great as the GDP of many countries.</p>
<p>The most influential content creators will build cabinets of advisors and shareholders drawn from different domains: A chief technologist drawn from Silicon Valley, a chief financial officer drawn from Wall Street, etc. This is when the political nature of content creators will become unmistakable. These companies will look and feel like small national governments, running a combination of revenue-generating enterprises for profit and philanthropic enterprises for citizen-recruitment, all organized around their own state-sponsored media.</p>
<p>The nation state may well persist, but only as a shell of its former self, and mainly by hitching its wagon to the leading micro-polities. One can imagine a scenario in which Heads of State and leading content creators broker an informal bargain that allow Heads of State to save face on condition they defer to the new power-holders. In the near future, the relationship of the US President and leading American Youtubers may be analogous to the relationship between the Queen of England and Parliament.</p>
<p>Many micro-polities will initially appear to mainstream observers as religious “cults,” driven by “conspiracy theories,” led by charismatic “grifters,” operating massive “pyramid schemes.” Eventually it will be realized that such things have always been the building blocks of nations. As the myth of Romulus attests, the founding of a nation is always a crime—until it’s the law.</p>
</div></div></section></div>

</div></div>]]>
            </description>
            <link>https://otherlife.co/barbarians-past-the-gate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25996935</guid>
            <pubDate>Tue, 02 Feb 2021 02:50:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cracking the top product design interviews]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25996721">thread link</a>) | @nishthadalal
<br/>
February 1, 2021 | https://nishthadalal.com/the-product-design-interview | <a href="https://web.archive.org/web/*/https://nishthadalal.com/the-product-design-interview">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-89ca65980cf20cd29b4a"><div><p>Compiling my learnings, experience, and tactics having been on both sides of the interview process. For every step of the process, I share: </p><ul data-rte-list="default"><li><p>Insights from the hiring panel’s perspective from my experience in building out design teams and designing interview guides</p></li><li><p>Learnings from interviewing with &amp; landing offers from renowned product design orgs</p></li></ul><p>There is no snippet of code that can magically help you crack the product design interview. Ultimately, every design interview is unique as it hinges on the work presented by the candidate. This book will guide you through every step of the interview process, break down what you are being assessed on, and help you walk out of every interview knowing you put your best foot forward.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1610994000314_6568"><p><em>Downloadable guides for companies like Facebook, Airbnb, Spotify and more coming soon. These will be included as extras in the book.</em></p></div></div>]]>
            </description>
            <link>https://nishthadalal.com/the-product-design-interview</link>
            <guid isPermaLink="false">hacker-news-small-sites-25996721</guid>
            <pubDate>Tue, 02 Feb 2021 02:10:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Surprising Security Vulnerability on the Google Search Results Page]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25996667">thread link</a>) | @patelajay285
<br/>
February 1, 2021 | https://ajayp.app/posts/2021/01/a-surprising-security-vulnerability-on-the-google-search-results-page/ | <a href="https://web.archive.org/web/*/https://ajayp.app/posts/2021/01/a-surprising-security-vulnerability-on-the-google-search-results-page/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Back in 2015, I discovered a surprising security vulnerability that allowed you to run malicious JavaScript code on the Google search engine results page, which might be one of the most secure pages on the internet given how much daily traffic it recieves. It wasn’t until <a href="#the-fix">4 years later (or 2019) that they finally closed the case on it</a> and I could share it without breaking my nondisclosure agreement with Google.</p><p>This sounds like a lot like an <a href="https://en.wikipedia.org/wiki/Cross-site_scripting">XSS attack</a>, which you would imagine Google would sanitize for, but it’s not and it’ll soon become clear why as I explain.</p><p>I was on Google searching for something like <em>“text-to-speech javascript libraries”</em>. I went from the Google search results page to clicking the first result, back to the Google search results page, to clicking on the second result, back to the Google search results page, etc. What I noticed was that my speakers kept making a clicking noise, like they were turning on and off—but just for a second.</p><figure><img src="https://media.ajayp.app/posts/2021/01/google-search.png" loading="lazy" width="340"></figure><p>I thought maybe there was some other program running on my computer or that my speakers were busted, but I realized it happened everytime I went to the Google search results page for this query. It also happened everytime I went to the first search results page, which was of a company that had a demo of their text-to-speech solution on it.</p><p>I figured the company’s page was loading their text-to-speech engine, that seemed to use the <a href="https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesis">SpeechSynthesis interface of the WebSpeech API</a>, and that’s why the speakers were turning on. But why were they on the Google page? That seemed like Google was maybe pulling in code on the search results page from the company’s page. That should never happen though, surely Google sanitizes anything that ever gets displayed on their pages from containing HTML or <code>&lt;script&gt;</code> tags.</p><p>This seemed like a plausible attack vector if there was some bug that allowed you to bring arbitrary code on to the Google search results page and a huge one at that.</p><p>I dumped the source code of the search results page and started looking at the HTML around the search result, but it didn’t look like any <code>&lt;script&gt;</code> or HTML tags were making it through. I started looking for instances of the company’s domain and found something like:</p><div><pre><code data-lang="html">&lt;<span>link</span> <span>rel</span><span>=</span><span>"prerender"</span> <span>href</span><span>=</span><span>"https://thecompanyspage.com/example"</span>&gt;
</code></pre></div><p>I was not familiar with <code>rel="prerender"</code> myself in 2015. Indeed, it seemed to be some sort of <a href="https://www.w3.org/TR/2015/WD-resource-hints-20150717/#dfn-prerender">new mechanism for pre-fetching and pre-loading a page</a> to speed up page transistions and load times as an optimization.</p><p>Google seemed to have invented <code>rel="prerender"</code> to prefetch and load the first search result in the background, so that when you clicked on the first search result (as most users do), it would instantly be ready for viewing.</p><p>The <code>rel="prerender"</code> has to execute JavaScript to load dynamic content, but it wasn’t blocking the WebSpeech API from playing audio possibly. Luckily for Google, the pre-rendered content is loaded in its own origin and, therefore, sensitive resources like cookies on the Google page were not at risk from being harvested by attackers like they would be in an XSS attack.</p><p>After learning this, the next step was to prove this out with my own website on Google’s search results page and see what I could make of it.</p><p>I needed a long obscure phrase that I could get the #1 Google search result spot for and that no one would accidently stumble upon so I could keep the vulnerability relatively secret until Google could fix it. I chose the apt phrase “Alphabet Spoke to Me In My Dreams” and purchased the <code>alphabetspoketomeinmydreams.xyz</code> domain name (now expired) that would show up as the first Google search result for the phrase. This was around the time <a href="https://www.nytimes.com/2015/08/11/technology/google-alphabet-restructuring.html">Google restructured into Alphabet Inc</a>.</p><p>The first malicious thing I could think to do was to “vandalize” the Google search results page with one of those “win a prize” scams pretending to be Google to phish their users. I also thought it would be sufficiently creepy to show how you were able to access standard information about the user like their location, ISP, IP address while being prerendered and speak it back to them. I know <a target="_blank" href="https://youtu.be/iZ6bamP8wZk?t=46">Dwight Schrute would be scared of that</a>.</p><figure><div><p><iframe width="560" height="315" src="https://www.youtube.com/embed/1bFlquq0GcY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></div><figcaption><span>Google Search Results Page Proof-of-Concept</span>
JavaScript code executing to play speech synthesis audio on the Google search results page.</figcaption></figure><p>So this looks pretty bad, but you would think that a user might notice if they click on the first result that it was a 3rd-party page causing the audio to play not Google right? Yes, except you can use the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Document/hidden"><code>document.hidden</code> property</a> to detect prerender mode and condition your code so that it only runs in <code>rel="prerender"</code> mode on the Google search engine results page! This creates a pretty robust appearance for impersonation as nothing happens if you go to the page directly.</p><div><pre><code data-lang="javascript"><span>if</span> (<span>document</span>.hidden) {
  <span>// The page is being loaded in rel="prerender", run the WebSpeech API code
</span><span></span>} <span>else</span> {
  <span>// The page is being loaded normally, don't do anything
</span><span></span>}
</code></pre></div><h2 id="chrome-vulnerability">Chrome Vulnerability</h2><p>While testing this, I found that this doesn’t only work on the Google search results page, but it turns out Chrome also “prerenders” the first result of the autocomplete in the URL search bar. Therefore, you can start playing WebSpeech audio without even having a page loaded in the browser frame.</p><figure><div><p><iframe width="560" height="315" src="https://www.youtube.com/embed/pqyOnzGDRlg" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></div><figcaption><span>Google Chrome Proof-of-Concept</span>
JavaScript code executing to play speech synthesis audio in the Chrome browser before any page is loaded in the browser at all when triggered by a user typing in a search into the URL search bar.</figcaption></figure><h2 id="denial-of-service-possibilities">Denial-of-Service Possibilities</h2><p>After testing other APIs, it seemed clear that only the WebSpeech API was making it through to the parent page. Things like <code>alert()</code> boxes were deferred from being visible until the page was actually loaded. But it also seemed clear that, while certain APIs were not available, JavaScript was running unrestricted. What happens if you do an infinite loop on the prerendered page?</p><div><pre><code data-lang="javascript"><span>while</span> (<span>true</span>) {
  <span>// Infinite loop
</span><span></span>}
</code></pre></div><p>Yep, you could “denial of service” the Google search results page from being displayed. This is not an attack on their servers, but rather you lock up the user’s browser so Google’s search results page cannot load.</p><figure><img src="https://media.ajayp.app/posts/2021/01/dos.png" loading="lazy" alt="Google Search Results Page Denial-of-Service" title="Google Search Results Page Denial-of-Service" width="600"><figcaption><span>Google Search Results Page Denial-of-Service</span>
Preventing the Google search results page from even loading by infinite looping in the prerendered page.</figcaption></figure><p>I shared the live example and a locally reproducible example of the vulnerability to Google.</p><h2 id="googles-response">Google’s Response</h2><p>Google’s security team responded promptly and professionally within 24 hours and decided to award a monetary reward for the vulnerability. The Chrome team did not dual-award since Google had already awarded. The Chrome team, however, were responsible for fixing the issue. I was not able to share this bug for quite some time due to the nondisclosure terms of Google’s vulnerability program.</p><h2 id="the-fix">The Fix</h2><p>The bug report and discussion is now public and visible <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=520275">here</a>.</p><p>I was suprised at how long it took to resolve and how difficult the fix seemed to be. It proved very difficult to break this API out from being enabled in the prerender context. In fact, at one point, one of the developers mentioned: <em>“This is currently our oldest &gt;= Medium severity security bug."</em> It was not until 2019 that they finally closed the bug after prerendering support was completely dropped from Chrome, due to it causing headaches like this, and the proof-of-concept could no longer be reproduced.</p><p>So, it seems premature optimization like <code>rel="prerender"</code> being the root of all evil isn’t just true because you might spend time <a href="https://xkcd.com/1691/">optimizing something that isn’t worth it</a>, but also because it likely increases the complexity and surface area for serious security bugs.</p></div></div>]]>
            </description>
            <link>https://ajayp.app/posts/2021/01/a-surprising-security-vulnerability-on-the-google-search-results-page/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25996667</guid>
            <pubDate>Tue, 02 Feb 2021 02:00:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to hire a software engineering contractor]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25996457">thread link</a>) | @muxcmux
<br/>
February 1, 2021 | https://www.tonkata.com/posts/how-to-not-hire-a-software-engineering-contractor/ | <a href="https://web.archive.org/web/*/https://www.tonkata.com/posts/how-to-not-hire-a-software-engineering-contractor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>For almost 4 years now I have been a web development contractor.</p>
<p>To me, a software contracting job is about bringing in extra resources to help
you or your company solve a problem. Something you can’t solve or it’s too
economically disadvantageous to solve by only relying on your current staff.
Kinda like if you had to add a downpipe to your guttering - you probably will
get it done, but chances are it’s gonna take more time, money, and pain than
if you had instead opted for a handyman to do the job.</p>
<p>Needing a contractor automatically implies a few things. First, you actually
have a concrete problem. This might be rolling out a new feature, fixing some
old bugs, or improving an existing user journey - a project in a sense. Whatever
it is - you know exactly (or nearly) what you want. Second, your engineers can’t
be allocated to the task, they have better things to do. Third, you want to
bring someone on board who knows their shit. You are not interested in investing
in their future or growing an in-house team. You just want to get stuff done.
And finally - you have a budget and a time constraint to work with.</p>
<p>So the question is - How the heck do you know if the person you are interviewing
is going to do a job of acceptable quality, on time, and within budget?</p>
<p>Well, how do you work out if the handyman can do your guttering?</p>
<p>I would instinctively ask them about the work they’ve already done. Have they
worked on guttering before? If yes - what kind? Maybe they’ve worked with
plastic pipes or perhaps they prefer old fashioned copper systems? Hell, if the
convo’s going well, I might ask them to show me some of their previous work! Why
stop there - ask them about how they are going to carry the job out? All good
questions, no doubt, and it seems most people will take a similar approach when
looking for a handyman.</p>
<p>So why is it then, when I apply for a software contracting job in your company,
you are asking me to solve a 2sum problem? Why do you insist I implement a
<a href="https://www.youtube.com/watch?v=YQs6IC-vgmo">linked list</a>? How is me inverting
a binary tree helping you decide if I can build your GraphQL API? Does it really
help you work out if I’ll be able to fix that mess of a legacy networking
library your ex-principal engineer left behind if I can convert Roman numerals
to Arabic and back?</p>
<p>No, none of this will help you figure it out. Just like it won’t help you work
out if the handyman can fix your guttering if you ask them to demonstrate to you
how to climb a ladder, drive a screw, or fix a light bulb.</p>
<p>If you need to ask these questions at an interview, then you most certainly
don’t need a contractor. You want permanent employees. What you need is to
grow the organisation and have people you can continuously invest in. You don’t
necessarily have an immediate problem requiring you to bring in extra help. It’s
either that or you just heard FAANGs are hiring this way, so I’mma do it too.</p>
<p>I’m not 22 and definitely not fresh out of gradschool. I <a href="https://www.tonkata.com/work/">have been around for a
while</a> and I know my shit. I’ve seen things and I have no
problem showing you my work or walking you through it. I have no illusions of
being a genius or the best and that’s reflected in my day rate. I’m a contractor
with real world experience. Experience from the same world your paying customers
live in - not the imaginary problems and shitty data structures one.</p>
<p>So please don’t waste my time with your pretend problems and ego scratching.
It’s not a contractor you are after.</p>
</section></div>]]>
            </description>
            <link>https://www.tonkata.com/posts/how-to-not-hire-a-software-engineering-contractor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25996457</guid>
            <pubDate>Tue, 02 Feb 2021 01:23:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “induced demand“ case against YIMBYism is wrong]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25996426">thread link</a>) | @jseliger
<br/>
February 1, 2021 | https://www.slowboring.com/p/induced-demand | <a href="https://web.archive.org/web/*/https://www.slowboring.com/p/induced-demand">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Today I want to talk about an idea that I don’t think has much purchase in real-world politics but seems to loom large both on the internet and in academic circles — the idea that new real estate development activity actually <em>causes gentrification</em> through some kind of induced demand phenomenon. </p><p>Nathan Robinson in his <a href="https://www.currentaffairs.org/2021/01/the-only-thing-worse-than-a-nimby-is-a-yimby">anti-YIMBY screed</a> explores a scenario in which replacing smaller buildings with larger ones increases housing scarcity even while adding units because “we're luring rich people from elsewhere to our city.” He’s doing a thought-experiment, but clearly one he thinks is plausible, while <a href="https://shelterforce.org/2018/11/05/heres-what-we-actually-know-about-market-rate-housing-development-and-displacement/">Amee Chew</a> in a 2018 Shelterforce article states that “numerous studies show that market-rate housing development has price ripple effects on surrounding neighborhoods, driving up rents and increasing the burden on lower-income households.”</p><p>Chew’s studies don’t really say that (more on this later) but the studies do say what I also know from personal experience which is that people living through a gentrification process often <em>say</em> this is what’s going on. This is all exacerbated by the fact that many people, as in this recent Washington Post article about Mt Pleasant, <em>define</em> gentrification as the presence of new-built condos with chain store retail on the ground floor. And it is definitely true that if what you mean by “gentrification” is “new buildings and chain stores” then blocking new buildings and chain stores will block gentrification.</p><p>But the argument here is supposed to be about prices, displacement, and ultimately people’s living standards. </p><p>And the induced demand objection fails on four scores:</p><ul><li><p>It is empirically false, at least most of the time. </p></li><li><p>Accepting its logic would counsel against <em>all</em> efforts to improve quality of life.</p></li><li><p>If it were true, it still wouldn’t follow that new construction is bad.</p></li><li><p>It misconstrues what the YIMBY proposal is in the first place.</p></li></ul><p>As I say, I don’t really believe that people believing in the induced demand argument explains any of the proximate barriers to housing reform. But it does come up a lot online, so I’d like to have a resource for explaining to people what’s wrong with it.</p><h4>The induced demand intuition</h4><p>The WMATA Green Line was extended to Columbia Heights in 1999, which meant that by 2003 a young person such as myself looking for a cheap place to live in a walkable neighborhood with good access to mass transit might pick it blindly off Google Maps and Craigslist as a good place to rent a basement apartment. </p><p>It was actually a fairly dismal neighborhood at the time, largely because the immediate vicinity of the metro station was a bunch of unsightly vacant lots and construction sites. But if you went to the no-longer-extant Columbia Heights Coffee Shop, all the talk among the gentrifiers was “there’s going to be a Target soon.” And, indeed, a few years later the construction sites were transformed into apartment buildings and retail, so if you go today, the immediate environs of the Metro station feature a Giant, a Target, a Best Buy, a Wawa, a Starbucks, and a bunch of other national chains along with some locally owned businesses. Then the slightly less proximate commercial areas either north on 14th Street or over on 11th Street are thriving ecologies of local businesses.     </p><p>There is clearly some kind of flywheel effect whereby the new retail amenities make the neighborhood a better place to live, which attracts more (and more affluent) residents, which in turn makes it a more attractive place to locate your business. </p><p>Now I think it’s obvious that the start of the Columbia Heights flywheel was the opening of the Green Line, especially given the largest context of falling urban crime during this period. The reason you could find white people in a coffee shop talking about how they were looking forward to the Target opening is that the gentrification cycle was already underway. Neighborhoods normally experience an initial hipster phase of gentrification (typified by dive bars, yoga studios, and independent coffee shops) <em>before</em> the major real estate developments and national chains arrive. </p><p>But we can argue intuitions all day — the real question is research.</p><h4>Empirically, more supply lowers prices</h4><p>Back when I wrote <em>The Rent Is Too Damn High</em>, I said that the impact of new development on hyper-local prices was theoretically ambiguous and the important thing was to look at city-wide effects that are not. </p><p>Fortunately, the past few years have seen a good amount of empirical work on this question. And it turns out that in most cases studied, new units reduce prices even on a very local scale. </p><ul><li><p><a href="https://www.dropbox.com/s/oplls6utgf7z6ih/Pennington_JMP.pdf?dl=0">Kate Pennington</a>’s recent study of San Francisco is very precise: “I find that rents fall by 2% for parcels within 100m of new construction. Renters’ risk of being displaced to a lower-income neighborhood falls by 17%. Both effects decay linearly to zero within 1.5km.”</p></li><li><p><a href="https://docs.wixstatic.com/ugd/7fc2bf_ee1737c3c9d4468881bf1434814a6f8f.pdf">Xiaodi Li</a> looked at New York: “For every 10% increase in the housing stock, rents decrease 1% and sales prices also decrease within 500 feet.”</p></li><li><p><a href="https://noahpinion.substack.com/p/the-left-nimby-canon">Brian Asquith, Evan Mast, and Davin Reed</a> look specifically at new market-rate housing in low-income neighborhoods in eleven cities and find: “New buildings decrease nearby rents by 5 to 7 percent relative to locations slightly farther away or developed later, and they increase in-migration from low-income areas.”</p></li></ul><p>There are some more studies along these lines, but I don’t want to inundate you with them because I do agree that the impact is theoretically ambiguous and someday, someone, somewhere will find the opposite result. </p><p>It is striking, though, that induced demand theory doesn’t yet have its Card &amp; Kruger paper that changed the game on the minimum wage. There is no Arin Dube of induced demand theory who’s published a series of rigorous empirical papers demonstrating that there’s something weird in this market. Instead you get this from Chew:</p><blockquote><p>Studies show that market-rate housing development is linked to the mass displacement of neighboring low-income residents (Davidson and Lees&nbsp;<a href="http://journals.sagepub.com/doi/10.1068/a3739">2005</a>,&nbsp;<a href="https://wordpress.clarku.edu/mdavidson/files/2012/02/Davidson-Lees-2010-New-Build-Gentrification.pdf">2010</a>; Pearsall&nbsp;<a href="http://journals.sagepub.com/doi/pdf/10.1068/c08126">2010</a>). Such displacement occurs even when low-income housing is not directly demolished and destroyed to make way for new development—because it operates through indirect and exclusionary means, such as “price shadowing” (Davidson and Lees&nbsp;<a href="http://journals.sagepub.com/doi/10.1068/a3739">2005</a>,&nbsp;<a href="https://wordpress.clarku.edu/mdavidson/files/2012/02/Davidson-Lees-2010-New-Build-Gentrification.pdf">2010</a>). Market-rate housing production causes significant price impacts in surrounding neighborhoods, raising area rents and real estate taxes (Oliva&nbsp;<a href="https://drum.lib.umd.edu/bitstream/handle/1903/4205/umi-umd-4016.pdf;sequence=1">2006</a>; Pearsall&nbsp;<a href="http://journals.sagepub.com/doi/pdf/10.1068/c08126">2010</a>; Zuk and Chapple&nbsp;<a href="http://www.urbandisplacement.org/sites/default/files/images/udp_research_brief_052316.pdf">2016</a>).&nbsp;</p></blockquote><p>So I checked the links.</p><p>The two Davidson and Lees papers are concerned with a definitional question in urban geography. According to them, the traditional meaning of gentrification in the literature is something like “rich people move into old homes and renovate them.” They argue that we should extend the definition to include things like new mixed-use housing and retail developments in underused industrial spaces. They <em>assert</em> but do not demonstrate that “price shadowing” occurs in these cases, and then argue that this sort of phenomenon ought to count as gentrification.</p><p><a href="https://www.urbandisplacement.org/sites/default/files/images/udp_research_brief_052316.pdf">Zuk and Chapple</a> actually say: “At the regional level, both market-rate and subsidized housing reduce displacement pressures, but subsidized housing has over double the impact of market-rate units.”</p><p>Pearsall says that cleaning up brownfields raises prices in nearby Census tracts, which is interesting and raises the question of whether “make people live near toxic waste” is really the affordable housing strategy we want. </p><p>Last we get to Oliva, who at last actually finds induced demand. He looks at the Inner Harbor project in Baltimore which transformed a largely derelict stretch of waterfront into a tourist attraction featuring a convention center, an amazing aquarium, a cool park, and a bunch of hotels and restaurants. Note that in this case promoting economic development was the intended goal of the initiative (Baltimore is poor) and the point of his study is that it was a limited success story — home values did rise, but “this impact has been far more pronounced on the prices of properties located within a short distance from the water even decades after the initial projects on the waterfront were started.”</p><p>This is all good empirical work. But note that I don’t think anyone has ever argued that building an aquarium will reduce housing cost burdens. The Inner Harbor is (by design) a tourist attraction. A couple of weeks ago, I took my kid to the Maryland Zoo in Baltimore, then we drove down to the Inner Harbor, got some takeout from Shake Shack, walked around waterfront, and bought a couple of bottles of water somewhere. This is what a successful tourist attraction is supposed to accomplish — you bring in retail dollars and tax revenue. We’ll come back post-pandemic and see the aquarium. It’s a nice place to visit. And Oliva shows that if you build a nice place to visit in the middle of a city, then the immediately adjacent homes become more desirable. Similarly, per Pearsall, if you clean up a brownfield the adjacent homes become more desirable.</p><p>New infill housing appears to empirically neutralize the induced demand by simultaneously inducing supply. But conceptually there’s a question here — is it bad to make neighborhoods better places to live? </p><h4>Better neighborhoods are better</h4><p>Here’s the problem. Consider the following argument:</p><ol><li><p>Constructing new buildings will bring new retail amenities to the neighborhood.</p></li><li><p>New amenities will make the neighborhood a more attractive place to live.</p></li><li><p>Because the neighborhood is now more attractive, prices will rise.</p></li><li><p>Rising prices will displace some existing residents.</p></li><li><p>Therefore we shouldn’t allow new buildings to be constructed.</p></li></ol><p>In place of (1) you could put all kinds of things:</p><ul><li><p>Constructing a new park</p></li><li><p>Reducing the crime rate</p></li><li><p>Renovating the local high school</p></li><li><p>Improving bus service to downtown</p></li><li><p>Fixing the potholes</p></li></ul><p>In other words, you could imagine this kind of logic becoming an infinite cycle of bad urban policy. Defund police will lead to more murders? Well, that’s good for housing affordability. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.slowboring.com/p/induced-demand">https://www.slowboring.com/p/induced-demand</a></em></p>]]>
            </description>
            <link>https://www.slowboring.com/p/induced-demand</link>
            <guid isPermaLink="false">hacker-news-small-sites-25996426</guid>
            <pubDate>Tue, 02 Feb 2021 01:19:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: View on mobile 2.0 – View any website mobile version from desktop]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25996246">thread link</a>) | @azabraao
<br/>
February 1, 2021 | https://azabraao.me/view-on-mobile | <a href="https://web.archive.org/web/*/https://azabraao.me/view-on-mobile">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://azabraao.me/view-on-mobile</link>
            <guid isPermaLink="false">hacker-news-small-sites-25996246</guid>
            <pubDate>Tue, 02 Feb 2021 00:56:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[So, is Signal good or bad?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25995819">thread link</a>) | @type0
<br/>
February 1, 2021 | https://current.workingdirectory.net/posts/2021/signal/ | <a href="https://web.archive.org/web/*/https://current.workingdirectory.net/posts/2021/signal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">







<div id="pagebody">

<div id="content" role="main">
<p>After <a href="https://arstechnica.com/tech-policy/2021/01/whatsapp-users-must-share-their-data-with-facebook-or-stop-using-the-app/">Facebook updated their Whatsapp privacy
policy</a>,
and a certain rich capitalist who doesn't like Facebook for reasons different
then mine told the world to use Signal, Signal's downloads <a href="https://www.businessinsider.com/whatsapp-facebook-data-signal-download-telegram-encrypted-messaging-2021-1?op=1">went up by
4,200%</a>.</p>

<p>As often happens when something becomes popular, the criticisms start to fly!</p>

<p>For the record, I currently think promoting <a href="https://signal.org/">Signal</a> is
an important tactical strategy for the left. [I also think we should promote
and install federated chat apps like <a href="https://conversations.im/">conversations</a>
and <a href="https://element.io/">element</a> and <a href="https://delta.chat/en/">delta chat</a>
whereever it is possible.]</p>

<p>Here are some of the main criticisms I hear that I think are a distraction:</p>

<ul>
<li><p><strong>Signal forces you to use the Google Play store and Google Services</strong>: This
isn't true any more. You can download <a href="https://signal.org/android/apk/">the apk
directly</a> on a phone without any Google
services and it works great. The app will alert you to new versions.</p>

<p>Don't get me wrong: the Signal network still depends on Google services.
And, we <em>should</em> be avoiding corporate technology and building our own
infrastructure. However, in practice, Signal is an alternative to Whatsapp
and Telegram - which not only use the same corporate services but are
proprietary technology that is fully owned by powerful tech giants. Signal
is still a non-profit organization with a vastly different mission.</p></li>
<li><p><strong>Signal's approach to privacy isn't perfect</strong> (the most common variation on
this theme is that a state actor could monitor your outgoing communications
and the incoming communications of the person you are communicating with and
prove that you are communicating with each other).</p>

<p>This criticism missed what makes Signal so important. The beauty of Signal
is that it addresses the "woops!" moment most privacy activists had when
Snowden's data trove become public: it provides <em>mass</em> privacy to stop
<em>mass</em> surveillance. Prior to 2013, most tech/privacy activists were focused
on the "targeted" individual approach to privacy, working hard to make sure
our tools were as absolutely perfect as possible for the tiny percentage of
people who know they are under surveillance. Very little effort went into
getting them adopted on a mass scale.</p>

<p>Criticizing Signal for not providing perfect privacy misses that fact that
these things often are trade offs.</p>

<p>This trade-off also applies to the first point - dependency on Google
services makes installation far easier for suporting millions of people.</p></li>
</ul>


<p>Here are some criticisms that I think are nuanced:</p>

<ul>
<li><p><strong>Signal is a centralized app</strong>: this criticism often includes examples of
Moxie (Signal's founder) refusing and actively discouraging attempts by
others to write software that interacts with Signal.</p>

<p>Signal is free software, which is a major improvement over most corporate
technology. But since it's entirely controlled by one entity, it can be
shutdown in a heart beat. And, if Signal changes direction, we cannot easily
take the work we have all invested in learning signal and create our own
version that reflects our values.</p>

<p>This problem is in contrast to federated systems like email - where anyone
can run their own email server and apply their own policies. If one email
serveer is shutdown, you can move to another.</p>

<p>I agree with this critique, but I think it's nuanced because of the trade
offs. Having full control over the entire network and all the software
provides a level of reliability and consistency that would not be possible
with a federated protocol. And, we already have three different, fully
viable federated chat protocols (see above). I'd rather have Signal be
Signal and invest our energy on a federated chat system via the existing,
well-developed alternatives.</p>

<p>This opinion is tactical - and could change at any moment. I think there
will come a time when we are going to tell the world to move from Signal to
the best available federated protocol. But I'm not convinced we have a
robust enough federated chat infrastructure to support that move.</p></li>
<li><p><strong>Signal forces you to use your phone number as an identifier</strong>: You can't
get a Signal account without a phone number. And you generally can't get a
phone number without revealing some aspect of your identity. That makes
staying anoymous very difficult. There are reports of a new Signal feature
making it possible to avoid revealing your phone number when communicating
with others, but you would still need a phone number to get an account
because a SMS or phone call confirmation is required.</p></li>
<li><p><strong>Signal isn't getting ahead of the curve on abuse</strong>: There's an interesting
<a href="https://www.platformer.news/p/-the-battle-inside-signal">piece informed by former Signal staff
people</a> about the
management's resistance to getting ahead of the curve when it comes to
abuse. How would signal respond to reports of harrassment? What would signal
do if it recognized facsists movements organizing on its platform? Any mass
platform that is not planning for abuse is going to be in big trouble very
soon.</p></li>
</ul>


<p>These last two are not exactly two sides of the same coin, but they are
related. How Signal manages to balance privacy and protection from abuse will
be the real test as to whether promoting Signal continues to be a useful
strategy for the left.</p>

</div>









</div>



</div></div>]]>
            </description>
            <link>https://current.workingdirectory.net/posts/2021/signal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25995819</guid>
            <pubDate>Mon, 01 Feb 2021 23:56:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Conventions of Safety (2019)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25995786">thread link</a>) | @luu
<br/>
February 1, 2021 | https://ceri.storey.name/posts/2019-08-18-unconventional-safety.html | <a href="https://web.archive.org/web/*/https://ceri.storey.name/posts/2019-08-18-unconventional-safety.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>Thanks to some discussions in my team recently, I’ve been thinking recently about how design conventions can help or harm safety.<!--more--> One place this comes up is in application layout, and what kinds of behaviour we put where.</p>
<p>To my mind, the biggest value in having conventions around service layout is to lower the cost of change. Let’s say we have a component that listens for events from others. In that case, you might have a habit of putting those listeners into a file named <code>listener.rs</code>. If this becomes a habit, you will know to look at the listener file, instead of needing to search for it.</p>
<p>When we write a service then change it rarely afterwards, this habit can be very useful. If you are unfamiliar with a section of the codebase, these kinds of <em>affordances</em> can make life easier. This results in less time sifting through code, and so makes it easier to change.</p>
<p>Another way to lower the cost of change is to have clear roles for each module within it. (And these roles themselves can follow clear patterns). Even then, these roles serve to hide some detail from the rest of the system.</p>
<p>A good interface means that a caller can express intent clearly, and let someone else worry about the details. For example, a database library lets you can pose <em>queries</em> and get results back. Without it, you’d need to know exactly how to turn your application’s data into something the database understands, and vica versa.</p>
<p>A good interface should also make clear what it needs. Let’s say some people in an office want to number documents. We can keep a logbook with the last number used. We can read the previous value we gave out, write down the next number, and use that for our document.</p>
<p>If lots of people want to number documents at the same time, then we encounter a problem. What if two people read then write the same numbers, and have the same number for their documents? People shouldn’t make this mistake, as they’ll notice that someone else is holding the book, and won’t race to write in it before the other has finished. Some people describe this as “common sense”.</p>
<p>Computers don’t have common sense. This is why we need to spell everything out to them in exacting detail. If they have read the last document number, they won’t know to check no-one else has changed it when they write down the new number, either.</p>
<p>So, in a distributed system we can use a centralised lock service to solve this problem. With this, the computer will take the lock, update the number and release the lock. Even then, if the new number routine does not know anything about the lock mechanism, it’s still possible to make the same mistake. A programmer might forget that they need to take the lock to call the new number routine, for example.</p>
<p>So, we have ways to solve this. One is we make the new number routine manage the lock itself. This is fine as long as it controls everything itself, but once we have other routines that use locks involved, then things get more complicated. This is okay if the lock for the new number is only for that new number. But if we share it with other routines, we risk problems like deadlocks.</p>
<p>Another solution is to inform the new number routine that we hold the lock, and have the routine fail if we do not. For example, the lock server may provide a <a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">token</a> the routine can verify. .</p>
<p>The logical conclusion to this is in the rust standard library. The <code>Mutex&lt;T&gt;</code> type holds a value of some type T, and will only permit access via a guard that guarantees we hold the lock.</p>
<p>A big part of designing safe systems is understanding how things go right over the long term. A big part of this is to ensure that it’s easy to do the safe thing, and difficult to do something unsafe.</p>
<p>The example of numbering documents is quite a low stakes task. In a bank though, we need to number payment cards, so we know whose account to charge. Having two cards with the same card number may mean one person can spend another’s money. This is bad for the customer, and leaves the bank liable for the mistake.</p>
<p>Now, these may seem like mistakes that are simple to avoid, but in complex systems, <a href="https://how.complexsystems.fail/">things go wrong all the time</a>. So it’s wise to design assuming that mistakes will happen, both from machines and people. For example, a tired, or rushed developer may not know to hold a lock while calling the new number routine. Having the routine fail in that case will mean that at they discover their mistake quickly.</p>
<p>So we should design our components and interfaces to be safe, and error resistant. And precisely because conventions can be so powerful, we should design them to encourage safe ways of working.</p>
</article></div>]]>
            </description>
            <link>https://ceri.storey.name/posts/2019-08-18-unconventional-safety.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25995786</guid>
            <pubDate>Mon, 01 Feb 2021 23:53:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can the PinePhone replace your Android or iOS device?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25995418">thread link</a>) | @viktork11
<br/>
February 1, 2021 | https://techscoop.xyz/2021/02/01/can-the-pinephone-replace-your-android-or-ios-device/ | <a href="https://web.archive.org/web/*/https://techscoop.xyz/2021/02/01/can-the-pinephone-replace-your-android-or-ios-device/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>One of the most anticipated Linux phones of 2020 is finally available, after months of waiting and anticipation the PinePhone is now available to purchase. Well, sort of… Ok, so its the <a href="https://pine64.com/product/pinephone-community-edition-mobian-limited-edition-linux-smartphone/?v=0446c16e2e66">community edition </a>on pre-order and it won’t ship until Feb but that’s progress. Right?</p>



<p>The new PinePhone is a Linux phone for the developer community, it’s affordable and comes from the guys over at Pine64 who brought us the <a href="https://www.pine64.org/pinebook-pro/">Pinebook Pro</a> laptop. Its open-source and is supported by a vast majority of Linux phone projects.</p>



<p>It’s encouraging to finally see an alternative to Android for fellow Linux partisans who rightly want to have ultimate control over their mobile phone. Let’s be honest here, its a budget phone at heart and it does come with some limitations but the concept of the PinePhone is intriguing.</p>



<p>If you’re a Linux diehard, a security practitioner or just like many others, you’re looking for something more than Android and IOS this may be the handset for you.</p>



<p>The phone comes with the Quad-Core ARM Cortex A53 64-Bit SOC which is standard on the Pine A64 Single Board Computer. Running <a href="https://mobian-project.org/">Mobian</a> Linux with 2GB of LPDDR3 RAM and retails at $149.</p>



<figure><img loading="lazy" src="https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1.png" data-src="https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1.png" alt="PinePhone" width="600" height="600" data-srcset="https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1.png 600w, https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1-300x300.png 300w, https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1-150x150.png 150w" data-sizes="(max-width: 600px) 100vw, 600px" srcset="https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1.png 600w, https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1-300x300.png 300w, https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1-150x150.png 150w"><figcaption>PinePhone</figcaption></figure>



<h2>SPECIFICATIONS</h2>



<ul><li>Allwinner A64 Quad Core SoC with Mali 400 MP2 GPU</li><li>2GB of LPDDR3 RAM</li><li>5.95″ LCD 1440×720, 18:9 aspect ratio (hardened glass)</li><li>Bootable Micro SD</li><li>16GB eMMC</li><li>HD Digital Video Out</li><li>USB Type C (Power, Data and Video Out)</li><li>Quectel EG-25G with worldwide bands</li><li>WiFi: 802.11 b/g/n, single-band, hotspot capable</li><li>Bluetooth: 4.0, A2DP</li><li>GNSS: GPS, GPS-A, GLONASS</li><li>Vibrator</li><li>RGB status LED</li><li>Selfie and Main camera (2/5Mpx respectively)</li><li>Main Camera: Single OV6540, 5MP, 1/4″, LED Flash</li><li>Selfie Camera: Single GC2035, 2MP, f/2.8, 1/5″</li><li>Sensors: accelerator, gyro, proximity, compass, ambient light</li><li>3 External Switches: up down and power</li><li>HW switches: LTE/GNSS, WiFi, Microphone, Speaker, Cameras&nbsp;</li><li>Samsung J7 form-factor 3000mAh battery</li><li>Case is matte black finished plastic</li><li>Headphone Jack</li></ul>



<p>The aim of the new PinePhone is to help create a market for a device like this where a functional affordable Linux phone can support existing projects for end-users, while also helping developers work together to drive support for the community-driven device.</p>



<p>The PinePhone isn’t trying to be the next flagship phone, its objectives are clear, it wants to be a reliable, customisable alternative to mainstream Android and IOS. We have to acknowledge that this phone is aimed at Linux Partisans and Dev’s specifically and isn’t suited to technophobes and users who fear the unknown. If you like the thought of physical kill switches and privacy toggles this may be your time to shine.</p>



<h2>Tech Specifications</h2>



<figure><table><tbody><tr><td>BODY</td><td>Dimensions: 160.5mm x 76.6mm x 9.2mm<br>Weight: 185 grams<br>Build: Plastic with Mobian logo<br>Colour: Black<br>SIM: Micro-SIM</td></tr><tr><td>Display</td><td>Type: HD IPS capacitive touchscreen, 16M colors<br>Size: 5.95 inches<br>Resolution: 1440×720 pixels, 18:9 ratio</td></tr><tr><td>PLATFORM</td><td>OS: Mobian OS build<br>Chipset: Allwinner A64<br>CPU: 64-bit Quad-core 1.2 GHz ARM Cortex A-53<br>GPU: MALI-400MP2</td></tr><tr><td>MEMORY</td><td>Internal Flash Memory: 16GB eMMC<br>System Memory: 2GB LPDDR3 SDRAM<br>Expansion: micro SD Card support SDHC and SDXC, up to 2TB</td></tr><tr><td>CAMERA</td><td>Main Camera: Single 5MP, 1/4″, LED Flash<br>Selfie Camera: Single 2MP, f/2.8, 1/5″</td></tr><tr><td>SOUND</td><td>Loudspeaker: Yes, mono<br>3.5mm jack with mic: Yes, stereo</td></tr><tr><td>COMMUNICATION</td><td>Worldwide, Global LTE bands<br>LTE-FDD: B1/ B2/ B3/ B4/ B5/ B7/ B8/ B12/ B13/ B18/ B19/ B20/ B25/ B26/ B28<br>LTE-TDD: B38/ B39/ B40/ B41<br>WCDMA: B1/ B2/ B4/ B5/ B6/ B8/ B19<br>GSM: 850/900/1800/1900MHz<br>WLAN: Wi-Fi 802.11 b/g/n, single-band, hotspot<br>Bluetooth: 4.0, A2DP<br>GPS: Yes, with A-GPS, GLONASS</td></tr><tr><td>FEATURES</td><td>USB: type C, USB Host, DisplayPort Alternate Mode output<br>Sensors: Accelerometer, gyro, proximity, ambient light, magnetometer(compass)<br>Actuator: Vibrator<br>Privacy Switches: LTE (include GPS), Wifi/BT, Mic, and Camera</td></tr><tr><td>BATTERY</td><td>Removable Li-Po 2750-3000 mAh battery<br>Charging: USB type-C, 15W – 5V 3A Quick Charge, follows USB PD specification</td></tr></tbody></table></figure>



<h2>Who is Pine64</h2>



<p>Pine64 have been selling ARM Linux devices since 2015, they started out originally with Single Board Computers such as the <a href="https://www.pine64.org/devices/single-board-computers/pine-a64/">Pine A64</a>. Much similar to the Well known Raspberry Pi but have now expanded into many other product areas. The guys over at Pine64 sell Laptops, Smartwatches and even Tablets and Server Clusters.</p>



<figure><img loading="lazy" width="600" height="600" src="https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2.png" data-src="https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2.png" alt="" data-srcset="https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2.png 600w, https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2-300x300.png 300w, https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2-150x150.png 150w" data-sizes="(max-width: 600px) 100vw, 600px" srcset="https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2.png 600w, https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2-300x300.png 300w, https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2-150x150.png 150w"></figure>



<h2>PinePhone Editions</h2>



<p>The PinePhone has gone through multiple prototypes before the first public release. BraveHeart began shipping in Jan 2020 and since then we now have the new community edition.</p>



<p>BraveHeart was the first PinePhone to go on sale early Nov 2019 and was sold without an OS installed, it was available direct from the Pine64 website and It sold out in days! The BraveHeart handsets were shipped to early adopters in Jan 2020.</p>



<p>There are some slight differences between BraveHeart and the later models, notably the inability for BraveHeart to connect to external monitors via USB Type-C. Laters models can do this so it’s worth doing your research before purchasing.</p>



<p>Community Editions, the successor the BraveHeart.</p>



<p>The PinePhone Ubports Community Edition was the first handset in the community lineup. It went on sale in May 2020 and came with pre-loaded Ubuntu Touch. This handset had minor hardware revisions and sold out almost instantly.</p>



<p>The second community edition was shipped with PostmarketOS and It went on sale in July 2020. This was the first PinePhone to support video over USB Type-C.</p>



<p>September provided us with a<a href="https://www.omgubuntu.co.uk/2020/08/pinephone-manjaro-community-edition"> </a>Manjaro edition handset, followed by a Plasma Mobile device in December 2020.</p>



<p>All units to date have been similar in style and design.</p>



<h2>Linux Support</h2>



<p>As of writing, there are <a href="https://wiki.pine64.org/index.php?title=PinePhone_Software_Releases">18 operating systems</a> available for the PinePhone. Bear in mind the OS’s are in various stages of the development lifecycle. Many have been written from the ground up for the mobile community such as Ubuntu Touch and Sailfish. A lot of the others are from existing desktop Linux distributions.</p>



<ul id="block-e4f6503d-217f-4c38-80f5-47d13aab6e12"><li>Arch Linux ARM</li><li>Fedora</li><li>Gentoo</li><li>GloDroid</li><li>KDE Neon</li><li>LuneOS</li><li>Maemo Leste</li><li>Manjaro ARM</li><li>Mobian</li><li>Nemo Mobile</li><li>NixOS</li><li>OpenMandriva Lx</li><li>openSUSE</li><li>postmarketOS</li><li>SailfishOS</li><li>SkiffOS</li><li>Sxmo</li><li>Ubuntu Touch</li></ul>



<h2>Where can I buy a PinePhone?</h2>



<p>You can buy a Pinephone&nbsp; Community Edition from the <a href="https://pine64.com/product-category/pinephone/">Pine64 Store</a>. </p>



<p>Note, Community Limited Edition PinePhones are aimed solely for developer and early adopter. More specifically, only intend for these units to find their way into the hands of users with extensive Linux experience.</p>



<h2>PinePhone Summary</h2>



<p>My favourite distro is <a href="https://wiki.mobian-project.org/doku.php?id=intro">Mobian</a> and the desire we have for the success of PinePhone isn’t because its cheap, it’s because is built for a multitude of community-driven OS’s on a secure device that has a real chance to deliver mobile Linux to the community. </p>



<p>Like you, I want an open source mobile phone. But my concerns are that it will only truly stake its market share once there’s a semi polished platform like that of Android.&nbsp;</p>



<p>Linux has so much to offer to the mobile market and challenging the likes of apple and android can only be a good thing.&nbsp;</p>



<p>It’s commendable what Pine64 are trying to achieve, deliver the hardware that mobile distros can develop upon.&nbsp;</p>



<p>But until the PinePhone is more polished and has a fully functioning operating and echo system I worry people will struggle using it as a daily device.&nbsp;</p>



<p>Its early days so be ready for quirks and rough finishes, its not flash and polished yet. </p>



<p>But remember, that’s not why you bought this device. You bought it because like me you found it exciting to be part of something that isn’t mainstream. To hopefully one day free people from the grasp of Android and IOS and deliver them into the tender loving arms of Linux.</p>
		</div></div>]]>
            </description>
            <link>https://techscoop.xyz/2021/02/01/can-the-pinephone-replace-your-android-or-ios-device/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25995418</guid>
            <pubDate>Mon, 01 Feb 2021 23:11:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we reduced our AI labeling cost by 10x]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25995293">thread link</a>) | @antimatter15
<br/>
February 1, 2021 | https://cresta.com/blog/how-we-reduced-our-labeling-cost-by-10x | <a href="https://web.archive.org/web/*/https://cresta.com/blog/how-we-reduced-our-labeling-cost-by-10x">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>At Cresta, we are democratizing expertise for sales and support teams by making every agent an expert. <a href="https://www.cresta.ai/blog/software-that-learns">To distill such expertise into software</a>, we ask top agents to demonstrate, and in turn, help us label best practices. Machine Learning models are then trained for customers to maximize their KPIs. Our models continuously learn what top agents do differently and scale those behaviors across entire teams.</p>
<p>Apart from providing goal-directed suggestions during ongoing live chats which we talked about in our recent <a href="https://cresta.com/blog/action-directed-gpt-2">Action Directed GPT-2 blogpost</a>, another unique feature that Cresta offers is real-time coaching assist. As shown below, Cresta provides personalized coaching at key moments in a live chat, to inculcate the required behaviors for every agent to perform like a top agent.</p>
</div><div><p>The Real-time Coaching and Agent Assist features mentioned above are powered by our Natural Language Understanding (NLU) pipeline, which is responsible for producing models that help us understand and track the state of the conversation as a chat progresses between an agent and a visitor. The 2 most common tasks which our NLU pipeline solves for, are:</p>
<ol>
<li><strong>Intent Classification</strong>: detecting the intent behind each message from both agent and visitor</li>
<li><strong>Chat Driver Classification</strong>: detecting and tracking the main objective behind the visitor reaching out</li>
</ol>
<p>In 2019, as our customer base started to rapidly grow, one of the biggest challenges we faced was the time and effort required to label data required by our NLU Classification pipeline. To scale as a software company, we strive to maximize our speed of developing and iterating on the required models. In this blog post, we share how our classification pipeline evolved over time and how we reduced our labeling cost and efforts by over 10x, while continuously pushing our accuracy benchmarks forward.</p>
<h2>Deep Transfer Learning</h2>
<p>As was the case for most NLP pipelines across the world in 2019, the first big jump in efficiency came with the introduction of Deep Transfer Learning. Transfer learning, in the form of pre-trained language models, has revolutionized the field of NLP, leading to state-of-the-art results on a wide range of tasks. The idea is to first pre-train a model on a large unlabeled dataset using a language modeling objective, and then fine-tune it on a smaller labeled dataset using a supervised task of choice.</p>
<figure id="attachment_19481" aria-describedby="caption-attachment-19481"><a href="https://cresta.com/static/49c936488d40a0a581c63e208c03b817/DeepTransferLearning.svg"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/7dc3d3fbd8815267d9bc196690d81f500c864251/30a8b/static/49c936488d40a0a581c63e208c03b817/deeptransferlearning.svg" alt="deep-transfer-learning" width="1175" height="623"></a><figcaption id="caption-attachment-19481">A loose analogy depicting Deep Transfer Learning with large pre-trained language models</figcaption></figure>
<p>Many practical applications of NLP occur in scenarios where there is a scarcity of labeled data. This is where fine-tuning large pre-trained language models has changed the game completely. These models have shown to be <a href="https://arxiv.org/pdf/1801.06146.pdf" target="_blank" rel="noopener noreferrer" data-token-index="4" data-reactroot="">extremely sample-efficient</a>, capable of achieving good performance on many tasks with only a few hundred labeled samples.</p>
<p>At the start of 2019, with <a href="https://arxiv.org/pdf/1806.08730.pdf" target="_blank" rel="noopener noreferrer" data-token-index="1" data-reactroot="">multi-task learning in NLP</a> increasingly showing <a href="https://www.aclweb.org/anthology/P19-1441.pdf" target="_blank" rel="noopener noreferrer" data-token-index="3" data-reactroot="">great empirical results</a>, we deployed a multi-headed <a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noopener noreferrer" data-token-index="6" data-reactroot="">BERT</a> for all the different tasks in our classification pipeline. As shown in the image below, this enabled us to train all of them together with a shared BERT encoder, maximizing each head’s learning from all the available labeled data. As a result, the final outcome was us reducing the number of labeled samples required per customer while pushing our accuracy benchmarks to previously uncharted regions.</p>
<figure id="attachment_19595" aria-describedby="caption-attachment-19595"><a href="https://cresta.com/static/c32940d6d127c78f2ee15def9fd31c19/MultiTaskModel.svg"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/b06d84f31cd820198db7a8d7d60ec129bdc5da02/572c8/static/c32940d6d127c78f2ee15def9fd31c19/multitaskmodel.svg" alt="MultiTaskModel" width="650" height="544"></a><figcaption id="caption-attachment-19595">Multi-head BERT for multiple NLU classification tasks</figcaption></figure>
<h2>One-vs-all Classification</h2>
<p>Buoyed by the success of the multi-head architecture, we turned our attention to a problem which was proving to be a costly step in our labeling process: handling a <span data-token-index="2" data-reactroot="">growing Label Taxonomy</span>.</p>
<p>For a model to track the state of a conversation using the classifiers described above, not all messages necessarily belong to a class of interest. As depicted in the image below, this meant that the multi-class classifiers which were deployed had a “None” class, to account for any messages that didn’t fall under the existing set of classes of interest. Instead of starting with a minimal set and then iteratively making data-driven additions to the taxonomy for each customer, this multi-class classification problem formulation forced us to spend considerable time upfront determining the granularity and details of the required taxonomy, and carefully defining what constitutes the “None” class – else otherwise, any future iterations on the taxonomy meant re-visiting all the labeled samples under a large “None” class and updating labels as required.</p>
<p>In short, our workflow was highly resistant to any taxonomy changes, which invariably happened as we entered new verticals and iterated with new customers, causing a lot of re-labeling and label quality issues.</p>
<figure id="attachment_19489" aria-describedby="caption-attachment-19489"><a href="https://cresta.com/static/8f33f77cd519328648e22cd7418828c9/Taxonomy.svg"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/ed4f6e9d53dbdc39bfed1638dfa522c57d508b23/39870/static/8f33f77cd519328648e22cd7418828c9/taxonomy.svg" alt="taxonomy" width="1086" height="1107"></a><figcaption id="caption-attachment-19489">“None” class allowing an agent intent classifier to abstain from messages of no interest</figcaption></figure>
<p>To address the above challenge of iterating on a growing label taxonomy, we converted the multi-class classification problem to a <a href="https://www.jmlr.org/papers/volume5/rifkin04a/rifkin04a.pdf" target="_blank" rel="noopener noreferrer" data-token-index="3" data-reactroot="">one-vs-all</a> classification problem using a multi-head architecture. As shown in the image below, each head acted as a binary classifier (True/False) for one of the classes, and a False from all the heads implied the “None” class.</p>
<figure id="attachment_19597" aria-describedby="caption-attachment-19597"><a href="https://cresta.com/static/5f384297bcae22f0b5ff76b621e92618/OneVsAllModel.svg"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/21af77eae2ce7cf1246837df83aa1cf7a2641935/a37a0/static/5f384297bcae22f0b5ff76b621e92618/onevsallmodel.svg" alt="OneVsAllModel" width="650" height="555"></a><figcaption id="caption-attachment-19597">Multi-head BERT for One-vs-all Intent Classification</figcaption></figure>
<p>The above architecture gave us the flexibility of adding more classes as we iterated on the taxonomy required to produce the experience desired by our customers, without having having to re-label our existing dataset each time. This architecture could be used both for a single-task or in a multi-task setting by simply prepending the class name with the task name to create a unique identifier for each head.</p>
<h2>Binary Labeling Interface with Loss Masking</h2>
<p>Data labeling interfaces and best practices, in general, have been an under-researched area – as was touched upon by François Chollet’s recent <a href="https://twitter.com/fchollet/status/1353422914071142400">tweet</a>, which sparked a debate amongst the research community. Our experience while trying to scale Machine Learning for business use-cases, pushed us to consider data curation and labeling as any other research problem we were looking to solve.</p>
<p>Labeling cost has 2 dimensions –&nbsp;the number of labeled samples required and the average time required to “correctly” label a sample. We realized that the effort and cost required to reach a high quality labeled dataset was often turning out to be a costly step requiring multiple quality assurance iterations. With a much more flexible one-vs-all architecture, instead of just looking for ways to reduce the number of labeled samples required by our models, we started iterating on optimizing our labeling interface with the goal of reducing the difficulty of labeling a given sample.</p>
<p>Humans usually have a small attention span, and labeling often can be a very tedious and mundane task. We A/B tested a new labeling interface where labelers would be making a single binary decision at a time, True/False for a pair of (sample, class), determining whether the sample belongs to that class or not.</p>
<figure id="attachment_19479" aria-describedby="caption-attachment-19479"><a href="https://cresta.com/static/659a310e5fce053badfc32f2150dde8e/BinaryLabelingInterface.svg"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/fe846b3dac1d4f4d9fae9261260cd632397cb78a/02ec0/static/659a310e5fce053badfc32f2150dde8e/binarylabelinginterface.svg" alt="binary-labeling-interface" width="650" height="753"></a><figcaption id="caption-attachment-19479">Labeler makes a binary decision and focuses on 1 class at a time with clear labeling guidelines and examples</figcaption></figure>
<p>A labeler could pick a class they wanted to focus on and the interface would present a sample to be labeled in a binary fashion, accompanied by clear labeling guidelines and examples, as shown in the image above. This interface allowed labelers to think about one class at a time, resulting in a lower cognitive load for them, while also allowing us to scale and distribute the labeling tasks more efficiently among the labelers. Our results showed that this interface resulted in ~2x faster labeling, with fewer mistakes made by the labelers.</p>
<p>Integrating the Binary Labeling Interface with our one-vs-all architecture meant we had to solve 1 problem: there was no guarantee that for a given sample, all the classes would be labeled. More explicitly, given the large amount of unlabeled data we usually work with, the design choice of labeling one class per sample meant that it was highly likely that for a given labeled sample in our training set, we would not have a supervision signal for all the heads. To address this, we implemented Loss Masking, where for a given sample we masked the loss for all the heads we didn’t have a label for. As demonstrated in the image below, for each sample, the loss is only applied to heads for which we have a label in the training batch.</p>
<figure id="attachment_19624" aria-describedby="caption-attachment-19624"><a href="https://cresta.com/static/f9db1b2a9ad8afa293ecf0eaf6356e67/LossMasking.svg"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/68b42654328635ee23f9cb533634466d86347fb6/1705a/static/f9db1b2a9ad8afa293ecf0eaf6356e67/lossmasking.svg" alt="LossMasking" width="1180" height="868"></a><figcaption id="caption-attachment-19624">Loss masking to handle sparse labels for different heads</figcaption></figure>
<h2>Active Learning</h2>
<p>Next, we turned our attention towards pushing the boundary around how sample-efficient Deep Transfer Learning could be, by introducing Active Learning in the pipeline. Our goal was to explore what can be achieved both in terms of accuracy and the associated labeling cost when these large pre-trained language models are used in conjunction with Active Learning techniques.</p>
<p>Similar to how humans learn, giving a model the power to interactively query a human to obtain labels at certain data points – i.e. introducing human guidance at various intervals – can dramatically improve the learning process. This is the key idea behind <a href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning)" target="_blank" rel="noopener noreferrer" data-token-index="3" data-reactroot="">Active Learning</a>: that a machine learning algorithm can achieve greater accuracy with fewer training labels if it is allowed to choose the data from which it learns.</p>
<figure id="attachment_19613" aria-describedby="caption-attachment-19613"><a href="https://cresta.com/static/2123331ca4ae632e8022d3d8eb8c5b65/ActiveLearningPlot.svg"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/44b66a594734fd9b8905fa5fccd4e340ec8a1462/32156/static/2123331ca4ae632e8022d3d8eb8c5b65/activelearningplot.svg" alt="ActiveLearningPlot" width="1242" height="352"></a><figcaption id="caption-attachment-19613">As described in the above plot using a toy dataset, choosing the optimal data points to label can dramatically reduce the amount of labeled data the model might need (<a href="http://burrsettles.com/pub/settles.activelearning.pdf">Image credits</a>)</figcaption></figure>
<p>Active Learning is an iterative process, which can be described by the following steps</p>
<ul>
<li><strong>Step 1</strong>: Label a small set of data, instead of investing huge labeling resources and cost upfront</li>
<li><strong>Step 2</strong>: Train a model on the above and then use it to predict outputs on unlabeled data</li>
<li><strong>Step 3</strong>: From the predictions, select data points based on a sampling strategy (for example Uncertainty Sampling – which selects data points the model is most uncertain about) and label those to include in the training dataset</li>
<li><strong>Step 4</strong>: (Back to Step 2) Retrain the model with the updated dataset and repeat the rest of the steps until a satisfactory quality is achieved</li>
</ul>
<h2>Wor…</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cresta.com/blog/how-we-reduced-our-labeling-cost-by-10x">https://cresta.com/blog/how-we-reduced-our-labeling-cost-by-10x</a></em></p>]]>
            </description>
            <link>https://cresta.com/blog/how-we-reduced-our-labeling-cost-by-10x</link>
            <guid isPermaLink="false">hacker-news-small-sites-25995293</guid>
            <pubDate>Mon, 01 Feb 2021 22:57:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Security Adventures Game]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25995146">thread link</a>) | @technion
<br/>
February 1, 2021 | https://mssecurityadventure.com/game.html | <a href="https://web.archive.org/web/*/https://mssecurityadventure.com/game.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mssecurityadventure.com/game.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25995146</guid>
            <pubDate>Mon, 01 Feb 2021 22:43:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Talking Head Anime from a Single Image via Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25994963">thread link</a>) | @Cixelyn
<br/>
February 1, 2021 | https://pkhungurn.github.io/talking-head-anime-2/ | <a href="https://web.archive.org/web/*/https://pkhungurn.github.io/talking-head-anime-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    	<p><span>
	      \(
	      \def\sc#1{\dosc#1\csod}
	      \def\dosc#1#2\csod{{\rm #1{\small #2}}}
	      \)
    	</span></p>
      
      <p>
      <a href="http://pkhungurn.github.io/">Pramook Khungurn</a>
      </p>
      
    </div><div>
					
		

		<p><b>Abstract.</b> I extended the <a href="https://pkhungurn.github.io/talking-head-anime/">animation-from-a-single-image neural network system I created in 2019</a> so that the characters can make more types of facial expressions. While the old system can only open/close the eyes and the mouth, this new version affords more eye/mouth shapes and can control the eyebrows and the irises. They allow a character to show various emotions and give more convincing impression of speech.</p>

		<table>
				<tbody><tr>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/headshot.png">	
						</p>
					</td>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/emotion/00000001.png">	
						</p>
					</td>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/emotion/00000002.png">	
						</p>
					</td>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/emotion/00000003.png">	
						</p>
					</td>
				</tr>
				<tr>
					<td><span size="2">Input <a href="#fn_gibara">[copyright]</a></span></td>
					<td><span size="2">Happy</span></td>
					<td><span size="2">Sad</span></td>
					<td><span size="2">Angry</span></td>
				</tr>
				<tr>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/emotion/00000004.png">	
						</p>
					</td>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/emotion/00000005.png">	
						</p>
					</td>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/emotion/00000006.png">
						</p>
					</td>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/emotion/00000007.png">	
						</p>
					</td>
				</tr>
				<tr>
					<td><span size="2">Disgusted</span></td>
					<td><span size="2">Condescending</span></td>
					<td><span size="2">Uwamedukai <a href="#fn_uwamedukai">[footnote]</a></span></td>
					<td><span size="2">Gangimari-Gao <a href="#fn_gangimari">[footnote]</a></span></td>
				</tr>	
			</tbody></table>			
		

		

		<p>With the new network, I can drive character illustrations with motions authored for 3D models.</p>

		<p>
		<iframe width="560" height="315" src="https://www.youtube.com/embed/mfENtYixnNE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>		
		</p>

		<p>I also created a real-time motion transfer tool that provides more controls over the character's face.</p>

		<p>
			<iframe width="560" height="315" src="https://www.youtube.com/embed/m13MLXNwdfY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
		</p>

		<p>I modified the tool to record my motion and was later able make multiple characters talk and sing with more dynamic lip and face movements.</p>

		<p>
			<iframe width="560" height="315" src="https://www.youtube.com/embed/_O5BEcUz3Bw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
		</p>
			

		
		<h2>1 &nbsp; Motivation</h2>		

		<p>With the goal of making it easier to become a <a href="https://en.wikipedia.org/wiki/Virtual_YouTuber">virtual YouTuber</a> (VTuber), in 2019, I created a <a href="https://pkhungurn.github.io/talking-head-anime">neural network system</a> that can animate the face of any existing anime character, given only an image of it. The system, however, cannot yet be considered practical for becoming a VTuber. The most important shortcoming is that it can only close the eyes and mouth, robbing the character the ability to make most facial expressions. Characters used by professional VTubers, on the other hand, can deform the eyebrows, eyelids, irises, and mouth into various shapes. My goal in this article is to improve my system's expressiveness by increasing the types of movements it can produce.</p>

		<h2>2 &nbsp; Summary of Approach</h2>

		<p>My neural network system takes two inputs. First is a <a href="https://en.wikipedia.org/wiki/Head_shot">head shot</a> of a character looking straight at the viewer, and second is a six-dimensional <i>pose vector</i> that specifies the pose the user wants the character to take. It outputs another image of the same character taking the specified pose. By varying the pose vector over time, the character can be animated. It can perform six types of movements because the pose vector is six-dimensional. However, excluding rotating the face, it can only closes its eyes and mouth.</p>

		<p>The system poses a given character in two steps, each carried out by its own separate subnetwork. The <i>face morpher</i> closes the eyes and the mouth, and the <i>face rotator</i> rotates the face.</p>

		<table>
	            <tbody><tr>
	                <td>
	                    <a href="https://pkhungurn.github.io/talking-head-anime-2/data/overview_two_step_process.png"><img src="https://pkhungurn.github.io/talking-head-anime-2/data/overview_two_step_process.png" width="600"></a>
	                </td>
	            </tr>
	            <tr>
	                <td>
	                    <b>Figure 2.1</b>  
	                    An overview of how the 2019 system poses a character's face. The character is <a href="https://www.youtube.com/channel/UC4YaOt1yT-ZeyB0OmxHgolA/videos">Kizuna AI</a> (© Kizuna AI).
	                </td>
	            </tr>
	        </tbody></table>
	    

	    <p>To increase types of movement, I started by preparing larger datasets. From the <a href="https://pkhungun.github.io/talking-head-anime/index.html#dataset">collection of approximately 8,000 3D models</a> I collected for my last system, I identified 39 common movements of facial parts and generated new datasets containing them. (You can see the list of movements <a href="https://pkhungurn.github.io/talking-head-anime-2/full.html#face-params">here</a>.) The movements encompass all the four movable facial features (eyebrows, eyelids, irises, and mouth) that can be observed in industrial characters. The size of the pose vector increased from 6 to 42 as a result <a href="#fn_pose_vector_length">[footnote]</a>.</p>

	    

	    <p>To deal with larger pose vectors, I propose a new architecture for the face morpher network, the overview of which is depicted in Figure 2.2.</p>

		<table>
	            <tbody><tr>
	                <td>
	                    <a href="https://pkhungurn.github.io/talking-head-anime-2/data/face_morpher_two_steps.png"><img src="https://pkhungurn.github.io/talking-head-anime-2/data/face_morpher_two_steps.png" width="600"></a>
	                </td>
	            </tr>
	            <tr>
	                <td>
	                    <b>Figure 2.2</b> 
	                    An overview of the new face morpher architecture. It morphs the face in two steps: the first morphs the eyebrow, and the second morphs the eyes and the mouth. The character is <a href="https://www.youtube.com/channel/UCp6993wxpyDPHUpavwDFqgg">Tokino Sora</a> (© Tokino Sora Ch.).
	                </td>
	            </tr>
	        </tbody></table>
	    

	    <p>The new face morpher has two subnetworks: the <b>eyebrow morpher</b> and the <b>eye &amp; mouth morpher</b>, with each network deforming the organ(s) in its name. The pose vector is divided into parts that can be fed into the relevant subnetworks.</p>

	    <h3>2.1 &nbsp; Eyebrow Morpher</h3>

	    <p>The eyebrow morpher first segments out the eyebrows with a dedicated subnetwork called the <b>eyebrow segmenter</b>. It then uses another subnetwork called the <b>eyebrow warper</b> to deform eyebrow and then composite the result back to the original image.</p>

	    <table>
	            <tbody><tr>
	                <td>
	                    <a href="https://pkhungurn.github.io/talking-head-anime-2/data/eyebrow_morpher_overview.png"><img src="https://pkhungurn.github.io/talking-head-anime-2/data/eyebrow_morpher_overview.png" width="600"></a>
	                </td>
	            </tr>
	            <tr>
	                <td>
	                    <b>Figure 2.3</b> 
	                    An overview of the architecture of the eyebrow morpher.
	                </td>
	            </tr>
	        </tbody></table>
	    

	    <p>The two networks have similar structures. It contains an encoder-decoder network that turns the input image(s) and the (optional) pose vector into an intermediate feature representation, which is then used to perform several image manipulation steps. I employ three types of image manipulation, each encapsulated into a reusable neural network unit.

	    </p><ol>
	    	<li><b>Partial image change</b>. The feature tensor is used to produce an alpha mask and another image that represents changes to the original image. The mask and the change image are then used to perform <a href="https://en.wikipedia.org/wiki/Alpha_compositing">alpha blending</a> with the input image to partially modify it. I take this step from the ECCV 2018 paper by Pumarola et al., which successfully applies it to alter facial expressions in human photos <a href="#fn_pumarola_2018">[2018]</a>.</li>

	    	<li><b>Combining</b>. The feature tensor is used to produce an alpha mask, which is then used to combine two images through alpha blending.</li>

	    	<li><b>Warping.</b> The feature tensor is transformed into an <b>appearance flow</b>, a map which tells, for each pixel of the output, which input image pixel to copy from <a href="#fn_zhou_2016">[Zhou et al. 2016]</a>. The appearance flow is then used to warp another image as it tells where each pixel should be moved to.</li>
	    </ol>
	    
	    

	   	<p>The eyebrow segmenter does its job with two partial image changes. The eyebrow warper deforms the extracted eyebrows with a warp and a partial image change. It then combines them back to the face image. Their architectures are given in Figure 2.4 and 2.5.</p>

	   	<p>
			<a href="https://pkhungurn.github.io/talking-head-anime-2/data/eyebrow_segmenter.png"><img src="https://pkhungurn.github.io/talking-head-anime-2/data/eyebrow_segmenter.png" width="600"></a><br>
			<b>Figure 2.4</b> Architecture of the eyebrow segmenter.
		</p>

		<p>
			<a href="https://pkhungurn.github.io/talking-head-anime-2/data/eyebrow_warper.png"><img src="https://pkhungurn.github.io/talking-head-anime-2/data/eyebrow_warper.png" width="600"></a><br>
			<b>Figure 2.5</b> Architecture of the eyebrow warper.
		</p>

		<p>During research, I discovered that it was very important to process the eyebrows separately from other facial features. Network architectures that used the same network to morph all facial features blurred the eyebrows after morphing them. By having separate networks morph the eyebrows after segmenting them out, I introduced a strong bias to preserve the eyebrow pixels, yielding crisp results.</p>

		
		<p><b>Figure 2.6</b> The effect of using separate networks to segment, morph, and then composite the eyebrows as proposed above.
		</p>
	
		

		<h3>2.2 &nbsp; Eye &amp; Mouth Morpher</h3>

	    <p>The eye &amp; mouth morpher has a similar architecture to the previous two networks. After passing the input image (the output of the eyebrow morpher) and the relevant part of the pose vector to an encoder-decoder network, it performs the following image manipulation steps:
		</p><ol>
			<li>a warp to deform the mouth and the irises,</li>
			<li>a partial image change to retouch the output of the last step, and</li>
			<li>another partial image change to deform the eyelids.</li>
		</ol>
		

		<p>
			<a href="https://pkhungurn.github.io/talking-head-anime-2/data/eye_and_mouth_morpher.png"><img src="https://pkhungurn.github.io/talking-head-anime-2/data/eye_and_mouth_morpher.png" width="600"></a><br>
			<b>Figure 2.7</b> Architecture of the eye &amp; mouth morpher.
		</p>

		<p>The above rather complicated process was a result of my iterating on the architecture. The first warping step is required to preserve high-frequency details of the irises. If partial image change were used, iris patterns drawn by artists would be lost.</p>

		
		<p><b>Figure 2.8</b> The effect of the first warping step of the eye &amp; mouth morpher on the quality of the irises. The character is <a href="https://www.youtube.com/channel/UCzrw4K7D9Ti3FP8WMTVPImg">Weatheroid Airi</a> (© Weathernews Inc.).
		</p>
	
		

		<p>The last step is necessary to produce artifact-free closed eyelids. If I were to deform the eyelids together with other facial features, they would be covered by the first warping step. I discovered that this led to small lines near the eyes being smeared, and the eyelids would be blemished as a result.</p>

		
		<p><b>Figure 2.9</b> The effect of processing the eyelids with a partial image change in a separate step. Notice the blemish produced by the architecture with warping. It is the result of the network's dragging the eyelid down and thereby smearing the small line inside the ground truth's red box. My proposed architecture simply fills the space with a solid color, yielding an artifact-free image. The character is <a href="https://www.youtube.com/channel/UCyb-cllCkMREr9de-hoiDrg">Yamato Iori</a> (© Appland, Inc.).
		</p>
	
		

		<h2>3 &nbsp; Results</h2>

		<p>I applied my system to 200 images of VTubers and related characters to generate a short video clip for each, and I put all the videos together in the <a href="#eyecatcher">eyecatcher</a>. You can watch the individual videos in the figure below.</p>

		<table>
				<tbody><tr>
					<td>Image being animated</td>
					<td>Video</td>
				</tr>
				<tr>
					<td id="characterImageCell">
						<img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/tsukino_mito/headshot.png">
					</td>
					<td id="characterVideoCell">
						<video muted="" controls="" loop="">
					    <source src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/tsukino_mito/video.mp4" type="video/mp4">
					    </video>
					</td>
				</tr>
				<tr>
					<td colspan="2">
						
					</td>
				</tr>
			</tbody></table>
			<p><b>Figure 3.1</b> Videos of characters being animated by my system.</p>			
				

		

		<p>Below is a selection of characters making the 7 facial expressions shown at the beginning of the article.</p>
	</div><div>

		<p>The above figure demonstrates the versatility of my system. It could handle both male and female characters with very different eye and face shapes. It sensibly deformed the eyes even when partially occluded by hair or seen through translucent glasses. It hallucinates plausible mouth shapes in cases where the input image has a closed mouth while my previous system would just leave the mouth as is.</p>

		<p>Another strengths of my system is its flexibility: I can combine it with any source of pose parameters. I thus use it to create a number of content creation tools and <a href="https://en.wikipedia.org/wiki/Vidding">fanvids</a>.</p>

		<p>First, I created a desktop application that allows the user to manipulate an anime character's facial expression and face rotation by dragging sliders. The resulting image can be saved for later use.</p>

		<p>
			<iframe width="560" height="315" src="https://www.youtube.com/embed/535mjOjpy38" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
		</p>

		<p>Second, I wrote a program that converts motions authored for 3D models into sequences to pose parameters, allowing me use them to drive 2D character illustrations. With this tool, I created 4 music videos.</p>

		<p>
	…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pkhungurn.github.io/talking-head-anime-2/">https://pkhungurn.github.io/talking-head-anime-2/</a></em></p>]]>
            </description>
            <link>https://pkhungurn.github.io/talking-head-anime-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25994963</guid>
            <pubDate>Mon, 01 Feb 2021 22:27:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RISC-V isn't as interesting as you think]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25994836">thread link</a>) | @todsacerdoti
<br/>
February 1, 2021 | https://sporks.space/2021/02/01/risc-v-isnt-as-interesting-as-you-think/ | <a href="https://web.archive.org/web/*/https://sporks.space/2021/02/01/risc-v-isnt-as-interesting-as-you-think/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-47">
	<!-- .entry-header -->

	
		<div>
			
<p><em>I had wrote this before the Unleashed was revealed, so some of the bits on economics have changed. As of writing this, I still stand by my other beliefs. </em>One of the most hyped things in hardware design is RISC-V, the open ISA available without license fees. Many organizations including <a href="https://www.westerndigital.com/company/innovations/risc-v">Western Digital</a> have pledged support for RISC-V, and the open source community has a lot of faith in it, and with <a href="https://www.anandtech.com/show/16080/nvidia-to-acquire-arm-for-40-billion">Nvidia’s recent purchase of Arm</a>, people are concerned. However, I feel these hopes are somewhat misleading, as RISC-V’s openness is less at the benefit of the user and more for CPU vendors.</p>

<p><strong>Royalties</strong>. One of the biggest benefits of RISC-V is not having to pay any royalties for a CPU using it. You might pay SiFive or someone else for a realization of their cores on hard silicon, but that’s for the design, not an abstract implementation of the ISA. Openness here means there’s more profit margin on the tiny chips running washing machines, since they don’t have to pay ARM or Synopsys. While the savings could be passed onto you, the ISA’s openness will never be of concern when the program is on a one-time-programmable ROM.</p>



<p><strong>ISA fragmentation</strong>. RISC-V intentionally defines a small ISA with extensions (for example, multiplication, which actually encompasses divide too… which is even more expensive to implement than multiply, but it’s a package deal). While most larger implementations will implement a common set of extensions, having basic functionality in extensions could make software compatibility for binary distributions harder. This is made worse by RISC-V explicitly encouraging custom instructions for task-specific tweaks on vendor silicon – great for embedded, not so hot for general purpose computers and operating systems supporting them.</p>



<p><strong>Economics</strong>. RISC-V has actively courted embedded, which makes sense as a niche. Much of the hype of RISC-V is hoping for laptop/desktop/server class silicon. This is unlikely, because the economics of embedded are different. ISA doesn’t matter as much in embedded programming (code reuse matters, but it’s not like you’re running arbitrary binaries), whereas user/enterprise focused computing usually lives and dies by binary compatibility (to protect investments in existing applications) and performance gained by things most RISC-V implementations don’t have yet like superscalar execution (To say nothing how these impact implementation complexity and security!).</p>



<p><strong>Openness doesn’t tickle down</strong>. The openness of an ISA doesn’t have much impact on the implementation. A design with restricted signing keys is completely acceptable under their licensing – and is very likely, considering the embedded dominance RISC-V is likely to have. There are no guarantees of openness in ways that impact a user (i.e controlling the root of trust), since a user doesn’t exactly have access to a fab.</p>



<p><strong>Design flaws</strong>. RISC-V seems like it hasn’t learned anything from CPUs designed after 1991. Between some <a href="https://gist.github.com/erincandescent/8a10eeeea1918ee4f9d9982f7618ef68">rookie mistakes</a> like few <a href="https://lobste.rs/s/yqqhxu/llvm_for_m68k_completed_not_merged">addressing modes</a> (register churn, code density) and <a href="https://lobste.rs/s/icegvf/will_risc_v_revolutionize_computing#c_8wbb6t">blowing out the encoding space</a>. However, despite its flaws, it’s poised to take over embedded and possibly beyond anyways – worse truly is better.</p>



<p>Overall, RISC-V will lead in a revolution for nationalist vanity CPUs (think Loongson; no one will run them but for show and perhaps a niche of radical ideologues) , academic projects, and embedded vendors wanting to save on their balance sheets, but it probably won’t affect users or developers.</p>
					</div><!-- .entry-content -->

	
	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://sporks.space/2021/02/01/risc-v-isnt-as-interesting-as-you-think/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25994836</guid>
            <pubDate>Mon, 01 Feb 2021 22:17:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Polyaxon v1.5: Cloud Native Events, Hooks, and Joins]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25994303">thread link</a>) | @plx
<br/>
February 1, 2021 | https://blog.polyaxon.com/polyaxon-v1-5/ | <a href="https://web.archive.org/web/*/https://blog.polyaxon.com/polyaxon-v1-5/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><h2>Joins</h2>
<p>Until now, Polyaxon provided several interfaces for fanning out operations either with a list of parameters using <a href="https://polyaxon.com/docs/automation/mapping/">Mapping</a> or based on a <a href="https://polyaxon.com/docs/automation/optimization-engine/">hyperparameter tuning algorithm</a> supported by the Matrix section.</p>
<p>The <a href="https://polyaxon.com/docs/automation/joins/">Join interface</a> is a new abstraction that allows performing fan-in operations. A typical use-case for such interface is the map-reduce pattern, but it’s also the interface used by Polyaxon to provide performance-based Tensorboards, i.e. starting a Tensorbaord based on a search: <code>{query: metrics.loss:&lt; 0.01, sort: metrics.loss, limit: 10}</code>.</p>
<p>Polyaxon <code>Join</code> is not a replacement to other map-reduce frameworks, rather it provides a very convenient way to collect all; <code>Inputs</code>, <code>Outputs</code>, <code>Lineages</code>, <code>Contexts</code>, <code>Artifacts</code> from upstream runs based on <a href="https://polyaxon.com/docs/core/query-language/">Polyaxon Query Language</a>.</p>
<p>A <code>Join</code> can be used both in an independent operation or in the context of a DAG. And each operation can perform one or multiple joins.</p>
<p>Let’s look at some concrete examples.</p>
<h3>Performance-based Tensorboard</h3>
<p>A performance-based Tensorboard operation allows starting a Tensorboard, dynamically, based on some criteria without prior knowledge of the runs’ ids.</p>
<div data-language="yaml"><pre><code><span>version</span><span>:</span> <span>1.1</span>
<span>kind</span><span>:</span> operation
<span>name</span><span>:</span> compare<span>-</span>top<span>-</span>experiments
<span>joins</span><span>:</span>
<span>-</span> <span>query</span><span>:</span> <span>"metrics.loss:&lt;0.01"</span>
  <span>sort</span><span>:</span> <span>"metrics.loss"</span>
  <span>limit</span><span>:</span> <span>"5"</span>
  <span>params</span><span>:</span>
    <span>tensorboards</span><span>:</span>
      <span>value</span><span>:</span> <span>{</span><span>dirs</span><span>:</span> <span>"{{ artifacts.tensorboard }}"</span><span>}</span>
<span>component</span><span>:</span>
  <span>inputs</span><span>:</span>
  <span>-</span> <span>{</span><span>name</span><span>:</span> tensorboards<span>,</span> <span>type</span><span>:</span> artifacts<span>,</span> <span>toInit</span><span>:</span> <span>true</span><span>}</span>
  <span>run</span><span>:</span>
    <span>kind</span><span>:</span> service
    <span>ports</span><span>:</span>
    <span>-</span> <span>6006</span>
    <span>container</span><span>:</span>
      <span>image</span><span>:</span> tensorflow/tensorflow<span>:</span>2.2.0
      <span>command</span><span>:</span>
      <span>-</span> tensorboard
      <span>args</span><span>:</span>
      <span>-</span> <span>'--logdir={{globals.artifacts_path}}'</span>
      <span>-</span> <span>'--port={{globals.ports[0]}}'</span>
      <span>-</span> <span>'--path_prefix={{globals.base_url}}'</span>
      <span>-</span> <span>'--host=0.0.0.0'</span></code></pre></div>
<p>In this example, Polyaxon will automatically perform a search and collect artifacts logged under the name <code>tensorboard</code>.
Note that using the <code>artifacts</code> prefix, Polyaxon will look in the lineage table, however, if you do not log the lineage using Polyaxon, you can still pass a subpath, e.g. <code>sub-path/in/each/run/in/the/search</code>.</p>
<h3>Map-Reduce</h3>
<p>Joins can be used as an automated process to perform <code>fan-out -&gt; fan-in</code> or <code>map-reduce</code> process.</p>
<div data-language="yaml"><pre><code><span>version</span><span>:</span> <span>1.1</span>
<span>kind</span><span>:</span> component
<span>run</span><span>:</span>
  <span>kind</span><span>:</span> dag
  <span>operations</span><span>:</span>
  <span>-</span> <span>name</span><span>:</span> fan_out
    <span>hubRef</span><span>:</span> <span>"my-component:v1"</span>
    <span>matrix</span><span>:</span>
      <span>kind</span><span>:</span> random
      <span>numRuns</span><span>:</span> <span>20</span>
      <span>params</span><span>:</span>
        <span>learning_rate</span><span>:</span>
          <span>kind</span><span>:</span> linspace
          <span>value</span><span>:</span> 0.001<span>:</span>0.1<span>:</span><span>5</span>
        <span>dropout</span><span>:</span>
          <span>kind</span><span>:</span> choice
          <span>value</span><span>:</span> <span>[</span><span>0.25</span><span>,</span> <span>0.3</span><span>]</span>
        <span>conv_activation</span><span>:</span>
          <span>kind</span><span>:</span> pchoice
          <span>value</span><span>:</span> <span>[</span><span>[</span>relu<span>,</span> <span>0.1</span><span>]</span><span>,</span> <span>[</span>sigmoid<span>,</span> <span>0.8</span><span>]</span><span>]</span>
        <span>epochs</span><span>:</span>
          <span>kind</span><span>:</span> choice
          <span>value</span><span>:</span> <span>[</span><span>5</span><span>,</span> <span>10</span><span>]</span>
  <span>-</span> <span>name</span><span>:</span> fan_in
    <span>params</span><span>:</span>
      <span>matrix_uuid</span><span>:</span>
        <span>ref</span><span>:</span> ops.fan_out
        <span>value</span><span>:</span> globals.uuid
        <span>contextOnly</span><span>:</span> <span>true</span>
    <span>joins</span><span>:</span>
    <span>-</span> <span>query</span><span>:</span> <span>"metrics.accuracy:&gt;0.9, pipeline:{{ matrix_uuid }}"</span>
      <span>sort</span><span>:</span> <span>"-metrics.accuracy"</span>
      <span>params</span><span>:</span>
        <span>uuids</span><span>:</span> <span>{</span><span>value</span><span>:</span> <span>"globals.uuid"</span><span>,</span> <span>contextOnly</span><span>:</span> <span>true</span><span>}</span>
        <span>learning_rates</span><span>:</span> <span>{</span><span>value</span><span>:</span> <span>"inputs.learning_rate"</span><span>,</span> <span>contextOnly</span><span>:</span> <span>true</span><span>}</span>
        <span>accuracies</span><span>:</span> <span>{</span><span>value</span><span>:</span> <span>"outputs.accuracy"</span><span>,</span> <span>contextOnly</span><span>:</span> <span>true</span><span>}</span>
        <span>losses</span><span>:</span> <span>{</span><span>value</span><span>:</span> <span>"outputs.loss"</span><span>,</span> <span>contextOnly</span><span>:</span> <span>true</span><span>}</span>
    <span>component</span><span>:</span>
      <span>run</span><span>:</span>
        <span>kind</span><span>:</span> job
        <span>container</span><span>:</span>
          <span>image</span><span>:</span> image
          <span>command</span><span>:</span> <span>[</span><span>"/bin/bash"</span><span>,</span> <span>"-c"</span><span>]</span>
          <span>args</span><span>:</span> <span>[</span>echo <span>{</span><span>{</span> uuids <span>}</span><span>}</span>; "echo <span>{</span><span>{</span> learning_rates <span>}</span><span>}</span>; "echo <span>{</span><span>{</span> accuracies <span>}</span><span>}</span>; echo <span>{</span><span>{</span> losses <span>}</span><span>}</span>"<span>]</span></code></pre></div>
<p>In the example above, instead of searching the complete project, we restrict the search to a specific subset defined by the pipeline managing the random search algorithm (the same logic can be used for Mapping, grid search, Bayesian optimization, …).</p>
<p>In this example, the reduce operation is not doing anything important, just printing some of the inputs and outputs collected.</p>
<h2>Hooks</h2>
<blockquote>
<p><strong>Note</strong>: Hooks are currently on the commercial version only, but will be available on Polyaxon CE soon</p>
</blockquote>
<p>If you are using Polyaxon, you are already aware that you can provide:</p>
<ul>
<li><a href="https://polyaxon.com/docs/core/specification/init/">init containers</a>: an interface for users to run init containers before the main container containing the logic for training models or processing data.</li>
<li><a href="https://polyaxon.com/docs/core/specification/sidecars/">sidecar containers</a>: specialized containers running as sidecars to the main container.</li>
</ul>
<p><a href="https://polyaxon.com/docs/automation/hooks/">The hooks interface</a> is an extension to complete the lifecycle with a post-done logic.
Typically, hooks, are operations that run after the main logic, to notify external systems, trigger evaluation logic, generate reports, …</p>
<p>Compared to <code>init</code> and <code>sidecars</code> abstractions, we made the decision to run hooks outside of the pod where the main logic is running for several reasons:</p>
<ul>
<li>To allow users to release important resources, e.g. GPU/TPU that might not be needed for running the hook(s).</li>
<li>To make a distinction of what users should be running in such operations, normally we expect that users should use this interface to run recurrent and abstracted logic that depends on an upstream operation, yet applies to most operations with similar characteristics.</li>
</ul>
<p>Users can run full components, with their own <code>init</code> and <code>sidecars</code> in hooks, and can run many hooks per operation following:</p>
<ul>
<li>A trigger.</li>
<li>A set of conditions</li>
<li>And based on the full context of the main operation.</li>
</ul>
<p>All valid hooks will be automatically scheduled to run as soon as the main operation reaches a final status.</p>
<h2>Events</h2>
<p><a href="https://polyaxon.com/docs/automation/events/">Events</a> are the last major addition to the Polyaxonfile specification in this release, users can now run DAGs with full events support.</p>
<p>Most workflow orchestrators support an aggregated upstream condition, e.g. <code>all succeeded</code>, <code>all failed</code>, or <code>all done</code>, basically an orchestrator would schedule an operation or a task only after the upstream is finished. That was also the case for Polyaxon until this release.</p>
<p><code>Events</code> allow starting an operation in response to any event generated by an upstream entity. In this release, the entity is an operation running in the same DAG context. In the future, the entity could be anything from a Git commit, a new S3 blob, to an internal alert, or a new registered model version.</p>
<p>Here’s an example of starting a Tensorboard as soon as a training operation starts running:</p>
<div data-language="yaml"><pre><code><span>version</span><span>:</span> <span>1.1</span>
<span>kind</span><span>:</span> component
<span>name</span><span>:</span> experiment<span>-</span>with<span>-</span>tensorboard
<span>run</span><span>:</span>
  <span>kind</span><span>:</span> dag
  <span>operations</span><span>:</span>
  <span>-</span> <span>name</span><span>:</span> experiment
    <span>pathRef</span><span>:</span> <span>"./experiment.yml"</span>
    <span>params</span><span>:</span>
      <span>learning_rate</span><span>:</span>
        <span>value</span><span>:</span> <span>0.005</span>
      <span>epochs</span><span>:</span>
        <span>value</span><span>:</span> <span>10</span>
  <span>-</span> <span>name</span><span>:</span> tensorboard
    <span>hubRef</span><span>:</span> tensorboard
    <span>termination</span><span>:</span>
      <span>timeout</span><span>:</span> <span>7200</span>
    <span>params</span><span>:</span>
      <span>uuid</span><span>:</span>
        <span>ref</span><span>:</span> ops.experiment
        <span>value</span><span>:</span> globals.uuid
    <span>events</span><span>:</span>
      <span>-</span> <span>ref</span><span>:</span> ops.experiment
        <span>kinds</span><span>:</span> <span>[</span>run_status_running<span>]</span></code></pre></div>
<p>This DAG will schedule two operations, a job for training a DL experiment and a Tensorboard to visualize the outputs of the experiment.
Instead of waiting for the experiment to finish before starting a Tensorboard, or copying the UUID of the job to start the Tensorboard manually, this DAG will schedule the Tensorboard automatically as soon as the training starts running. If the training fails because of some compilation error, the Tensorboard will be marked as skipped.</p>
<h2>Compiler</h2>
<h3>Optimized compilation and context resolution</h3>
<p>This version brings several new heuristics to optimize the process of resolving and converting Polyaxonfiles, from a couple of milliseconds to a second in some cases, which should translate to faster scheduling of operations.</p>
<p>We also consolated the interface for requesting and resolving information from the compiler’s context, as well as moving the context to its own <a href="https://polyaxon.com/docs/core/context/">documentation section</a>.</p>
<h3>Improved init artifacts specification</h3>
<p>This was requested several times, extending the artifacts initializer to allow providing a custom destination path where it should store the artifacts collected:</p>
<div data-language="yaml"><pre><code><span>init</span><span>:</span>
  <span>files</span><span>:</span>
    <span>-</span> file1
    <span>-</span> <span>-</span> file2
      <span>-</span> path/to/store/file2
  <span>dirs</span><span>:</span>
    <span>-</span> dir1
    <span>-</span> <span>-</span> dir2
      <span>-</span> path/to/store/dir2</code></pre></div>
<p><code>file1</code> and <code>dir1</code> are what users were familiar with. <code>file2</code> and <code>dir2</code> are the new capability, the initializer accepts a tuple to specify the path from and the path to.</p>
<h3>Restart with copy improvement</h3>
<p>As a result of the previous enhancement, when a user restarts an operation using the copy mode, the copied information will be initialized automatically under the new run.</p>
<blockquote>
<p><strong>Note</strong>: Restart with copy mode is an advanced feature to allow users to resume training of an experiment with updated code/params/configuration/resources multiple times without mutating the original run.</p>
</blockquote>
<h3>New input type UUID</h3>
<p>Polyaxonfile parser can now validate <code>uuid</code> types properly, users can use this new type instead of <code>str</code> to validate the inputs and fail faster.</p>
<h2>UI</h2>
<h3>Serveral new lineage tabs</h3>
<p>It was always possible to filter all upstream/downstream runs based on another run or all runs that are clones of a specific run. But pulling such information required doing a manual search in the comparison table.</p>
<p>Polyaxon UI now exposes several new lineage tabs to show:</p>
<ul>
<li>Artifacts &amp; Connections requested for a specific run:</li>
</ul>
<p><span>
<a href="https://blog.polyaxon.com/static/62dbd837f4a0476d1bc3f310c1961dac/218ba/feature-1.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature1" title="feature1" src="https://blog.polyaxon.com/static/62dbd837f4a0476d1bc3f310c1961dac/f97d7/feature-1.png" srcset="https://blog.polyaxon.com/static/62dbd837f4a0476d1bc3f310c1961dac/0eb09/feature-1.png 500w, https://blog.polyaxon.com/static/62dbd837f4a0476d1bc3f310c1961dac/1263b/feature-1.png 1000w, https://blog.polyaxon.com/static/62dbd837f4a0476d1bc3f310c1961dac/f97d7/feature-1.png 2000w, https://blog.polyaxon.com/static/62dbd837f4a0476d1bc3f310c1961dac/218ba/feature-1.png 2144w" sizes="(max-width: 2000px) 100vw, 2000px" loading="lazy">
</a>
</span></p>
<ul>
<li>All clones:</li>
</ul>
<p><span>
<a href="https://blog.polyaxon.com/static/690372bb90e36147cb6cb20ed5903858/bcfad/feature-2.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature2" title="feature2" src="https://blog.polyaxon.com/static/690372bb90e36147cb6cb20ed5903858/bcfad/feature-2.png" srcset="https://blog.polyaxon.com/static/690372bb90e36147cb6cb20ed5903858/0eb09/feature-2.png 500w, https://blog.polyaxon.com/static/690372bb90e36147cb6cb20ed5903858/1263b/feature-2.png 1000w, https://blog.polyaxon.com/static/690372bb90e36147cb6cb20ed5903858/bcfad/feature-2.png 1396w" sizes="(max-width: 1396px) 100vw, 1396px" loading="lazy">
</a>
</span></p>
<ul>
<li>Upstream &amp; Downstream edge runs:</li>
</ul>
<p><span>
<a href="https://blog.polyaxon.com/static/ee169824c349d9e08f4b3f85c2414f25/9ddde/feature-3.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature3" title="feature3" src="https://blog.polyaxon.com/static/ee169824c349d9e08f4b3f85c2414f25/f97d7/feature-3.png" srcset="https://blog.polyaxon.com/static/ee169824c349d9e08f4b3f85c2414f25/0eb09/feature-3.png 500w, https://blog.polyaxon.com/static/ee169824c349d9e08f4b3f85c2414f25/1263b/feature-3.png 1000w, https://blog.polyaxon.com/static/ee169824c349d9e08f4b3f85c2414f25/f97d7/feature-3.png 2000w, https://blog.polyaxon.com/static/ee169824c349d9e08f4b3f85c2414f25/9ddde/feature-3.png 2784w" sizes="(max-width: 2000px) 100vw, 2000px" loading="lazy">
</a>
</span></p>
<h3>Improved run’s overview page</h3>
<ul>
<li>Namespace and artifacts store:</li>
</ul>
<p> <span>
<a href="https://blog.polyaxon.com/static/295330902bfdb7d7f9cc543cbba9d739/56508/feature-4.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature4" title="feature4" src="https://blog.polyaxon.com/static/295330902bfdb7d7f9cc543cbba9d739/56508/feature-4.png" srcset="https://blog.polyaxon.com/static/295330902bfdb7d7f9cc543cbba9d739/0eb09/feature-4.png 500w, https://blog.polyaxon.com/static/295330902bfdb7d7f9cc543cbba9d739/1263b/feature-4.png 1000w, https://blog.polyaxon.com/static/295330902bfdb7d7f9cc543cbba9d739/56508/feature-4.png 1696w" sizes="(max-width: 1696px) 100vw, 1696px" loading="lazy">
</a>
</span></p>
<ul>
<li>Better documentation with Readme (the markdown preview has a similar style as the run’s overview page, in both light and dark themes):</li>
</ul>
<p><span>
<a href="https://blog.polyaxon.com/static/1eeb946e75848e39f887fe17d8e35e04/b1b5c/feature-5-1.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature5-1" title="feature5-1" src="https://blog.polyaxon.com/static/1eeb946e75848e39f887fe17d8e35e04/f97d7/feature-5-1.png" srcset="https://blog.polyaxon.com/static/1eeb946e75848e39f887fe17d8e35e04/0eb09/feature-5-1.png 500w, https://blog.polyaxon.com/static/1eeb946e75848e39f887fe17d8e35e04/1263b/feature-5-1.png 1000w, https://blog.polyaxon.com/static/1eeb946e75848e39f887fe17d8e35e04/f97d7/feature-5-1.png 2000w, https://blog.polyaxon.com/static/1eeb946e75848e39f887fe17d8e35e04/b1b5c/feature-5-1.png 2864w" sizes="(max-width: 2000px) 100vw, 2000px" loading="lazy">
</a>
</span></p>
<p><span>
<a href="https://blog.polyaxon.com/static/c23214109d9ab2f01d651ecc7b64e552/b1b5c/feature-5-2.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature5-2" title="feature5-2" src="https://blog.polyaxon.com/static/c23214109d9ab2f01d651ecc7b64e552/f97d7/feature-5-2.png" srcset="https://blog.polyaxon.com/static/c23214109d9ab2f01d651ecc7b64e552/0eb09/feature-5-2.png 500w, https://blog.polyaxon.com/static/c23214109d9ab2f01d651ecc7b64e552/1263b/feature-5-2.png 1000w, https://blog.polyaxon.com/static/c23214109d9ab2f01d651ecc7b64e552/f97d7/feature-5-2.png 2000w, https://blog.polyaxon.com/static/c23214109d9ab2f01d651ecc7b64e552/b1b5c/feature-5-2.png 2864w" sizes="(max-width: 2000px) 100vw, 2000px" loading="lazy">
</a>
</span></p>
<ul>
<li>IO tables with search and pagination:</li>
</ul>
<p> <span>
<a href="https://blog.polyaxon.com/static/933623297bb16a89b97cc6eda7eeb5ff/1fcef/feature-6.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature6" title="feature6" src="https://blog.polyaxon.com/static/933623297bb16a89b97cc6eda7eeb5ff/1fcef/feature-6.png" srcset="https://blog.polyaxon.com/static/933623297bb16a89b97cc6eda7eeb5ff/0eb09/feature-6.png 500w, https://blog.polyaxon.com/static/933623297bb16a89b97cc6eda7eeb5ff/1263b/feature-6.png 1000w, https://blog.polyaxon.com/static/933623297bb16a89b97cc6eda7eeb5ff/1fcef/feature-6.png 1919w" sizes="(max-width: 1919px) 100vw, 1919px" loading="lazy">
</a>
</span></p>
<ul>
<li>Copying of the complete inputs and outputs as JSON objects:</li>
</ul>
<p> <span>
<a href="https://blog.polyaxon.com/static/e72e1847b33220e8eff7acfbfb436b17/1fcef/feature-7.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature7" title="feature7" src="https://blog.polyaxon.com/static/e72e1847b33220e8eff7acfbfb436b17/1fcef/feature-7.png" srcset="https://blog.polyaxon.com/static/e72e1847b33220e8eff7acfbfb436b17/0eb09/feature-7.png 500w, https://blog.polyaxon.com/static/e72e1847b33220e8eff7acfbfb436b17/1263b/feature-7.png 1000w, https://blog.polyaxon.com/static/e72e1847b33220e8eff7acfbfb436b17/1fcef/feature-7.png 1919w" sizes="(max-width: 1919px) 100vw, 1919px" loading="lazy">
</a>
</span></p>
<h3>Wait time</h3>
<p>The dashboard will show a new field <code>wait time</code>, this time represents all phases that come before an operation is scheduled on Kubernetes.
This information is available on the overview page, and on the comparison table. Users can query and sort by the wait time similar to other meta data.</p>
<p> <span>
<a href="https://blog.polyaxon.com/static/53c7baf679e277b03b46e8fe4563bec3/9e144/feature-8.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature8" title="feature8" src="https://blog.polyaxon.com/static/53c7baf679e277b03b46e8fe4563bec3/9e144/feature-8.png" srcset="https://blog.polyaxon.com/static/53c7baf679e277b03b46e8fe4563bec3/9e144/feature-8.png 226w" sizes="(max-width: 226px) 100vw, 226px" loading="lazy">
</a>
</span></p>
<p>By analyzing the wait time of runs filterd by specific queue, you should have more context to optimize and organize your queues.</p>
<h3>Consolidated pipeline overview</h3>
<p>We moved several aspects that provide information about the pipeline into a subsection:</p>
<ul>
<li>Pipeline Concurrency</li>
<li>Children run kinds</li>
<li>Pipeline progress</li>
</ul>
<p> <span>
<a href="https://blog.polyaxon.com/static/182f05b9b4e9b842d005332663455b0b/cfc60/feature-9.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature9" title="feature9" src="https://blog.polyaxon.com/static/182f05b9b4e9b842d005332663455b0b/cfc60/feature-9.png" srcset="https://blog.polyaxon.com/static/182f05b9b4e9b842d005332663455b0b/0eb09/feature-9.png 500w, https://blog.polyaxon.com/static/182f05b9b4e9b842d005332663455b0b/cfc60/feature-9.png 776w" sizes="(max-width: 776px) 100vw, 776px" loading="lazy">
</a>
</span></p>
<h2>Docs</h2>
<p>We published a new section <code>how-tos</code> that should feature short guides on how to use Kubernetes capabilities, as well as answer …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.polyaxon.com/polyaxon-v1-5/">https://blog.polyaxon.com/polyaxon-v1-5/</a></em></p>]]>
            </description>
            <link>https://blog.polyaxon.com/polyaxon-v1-5/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25994303</guid>
            <pubDate>Mon, 01 Feb 2021 21:35:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Changelog Spec]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25994262">thread link</a>) | @haskellandchill
<br/>
February 1, 2021 | https://opticdev.github.io/changelog-spec-demo/ | <a href="https://web.archive.org/web/*/https://opticdev.github.io/changelog-spec-demo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://opticdev.github.io/changelog-spec-demo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25994262</guid>
            <pubDate>Mon, 01 Feb 2021 21:32:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Repl.it __logs]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25994177">thread link</a>) | @agmm
<br/>
February 1, 2021 | https://blog.repl.it/__logs | <a href="https://web.archive.org/web/*/https://blog.repl.it/__logs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blog.repl.it/__logs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25994177</guid>
            <pubDate>Mon, 01 Feb 2021 21:24:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Staircase of the Self: An Illustrated Dive into the Progression of Identity]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25994026">thread link</a>) | @LYeo
<br/>
February 1, 2021 | https://moretothat.com/the-staircase-of-the-self/ | <a href="https://web.archive.org/web/*/https://moretothat.com/the-staircase-of-the-self/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When children copy us, we think it’s cute. When adults copy us, we threaten to sue.</p><p>This odd dynamic shines a light on our relationship with imitation, and the way it morphs over time. When we interact with a child, we operate under the assumption that the child is still learning about her place in the world, so we accept emulation as a prerequisite to her development. It’s not only normal to see the child copying the behavior of adults, it’s something that brings us immense joy to see.</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A01-Kids-and-imitation.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A01-Kids-and-imitation.png" alt="child imitating parents" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A01-Kids-and-imitation.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A01-Kids-and-imitation-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A01-Kids-and-imitation-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A01-Kids-and-imitation-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A01-Kids-and-imitation-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>Psychologist Alfred Adler believed that this imitative behavior is the result of an “inferiority complex” that is universal in childhood. Since all children enter a world inhabited by towering adults, the sheer physical differences between themselves and their parents causes this feeling of inferiority to develop. To alleviate this, the child will emulate the behavior of these lumbering giants, and will learn how to overcome various challenges by copying what they do.</p><p>Another way to look at this is that the sense of self is not strongly cultivated in a child. Most of the child’s connection to her individuality is purely based on sense data – it’s limited to the pang of hunger she feels, the physical warmth she experiences, the discomfort she wants you to resolve.</p><p>But her awareness of who she is as a unique person has been offloaded to the adults. My wife and I will look at <a href="https://moretothat.com/a-letter-to-my-newborn-daughter/" target="_blank" rel="noopener noreferrer">our newborn daughter</a> and say things like, “She seems quite introverted” or “She’s sensitive to people’s energy,” but my daughter (likely) isn’t making any of these character interpretations about herself.</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A02-Wonder-what-she-is-thinking.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A02-Wonder-what-she-is-thinking.png" alt="deep thinker" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A02-Wonder-what-she-is-thinking.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A02-Wonder-what-she-is-thinking-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A02-Wonder-what-she-is-thinking-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A02-Wonder-what-she-is-thinking-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A02-Wonder-what-she-is-thinking-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>This lack of a sense of self is a spiritual goal for many adults, but that’s only because we know how to take care of our basic biological needs. Young children, on the other hand, literally cannot survive without the presence of caretakers, so having no sense of self doesn’t do them any good. The survival of the self is reliant upon interactions with others, so the shaping of their identity depends on who is there to provide for them regularly.</p><p>Imitation is the birthplace of human behavior. There’s no way around this fact, and we all intuitively understand this to be true. However, why is it also intuitive for us to scorn imitation as we age? Why does it become desirable to discard societal norms to become our “authentic selves,” or to escape this sense of self entirely?</p><p>Well, to answer these questions, we’re going to have to take a journey through the stages of one’s identity, and how we internalize it at each level. To do this, I’d like to introduce what I call <span><strong>The Staircase of the Self</strong></span>:</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A03-The-Staircase-of-the-Self.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A03-The-Staircase-of-the-Self.png" alt="the staircase of the self" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A03-The-Staircase-of-the-Self.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A03-The-Staircase-of-the-Self-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A03-The-Staircase-of-the-Self-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A03-The-Staircase-of-the-Self-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A03-The-Staircase-of-the-Self-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>As the diagram indicates, the position of each step is tied to how strongly one identifies with their sense of self, or the feeling of being a distinct individual navigating the world. One thing you’ll notice is that the diagram is symmetrical, so there are two steps occupying the same horizontal position at different points in the journey (e.g. Self-Esteem and Self-Actualization). This is because both these steps embody a similar association with identity, but do so with different lenses. We’re going to go into this in more detail later.</p><p>But for the time being, we’re going to focus on the first two steps, and see what it means to move out of utter dependency, and into a semblance of independence.</p><h3>From Inferiority to Self-Esteem</h3><div><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A04-From-Inferiority-to-Self-Esteem.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A04-From-Inferiority-to-Self-Esteem.png" alt="inferiority to self-esteem" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A04-From-Inferiority-to-Self-Esteem.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A04-From-Inferiority-to-Self-Esteem-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A04-From-Inferiority-to-Self-Esteem-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A04-From-Inferiority-to-Self-Esteem-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A04-From-Inferiority-to-Self-Esteem-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p></div><p>The feeling of inferiority is largely due to an absence of a sense of self, but not in the way monks and meditators view it. This texture of “no self” originates from the helplessness we all experience as infants, and the complete reliance we must have on others to sustain our lives. Our behaviors are driven by fear, this fear lends itself to inferiority, and this inferiority causes us to outsource our identities to whoever we think has the answers.</p><p>So how do we identify the presence of our own unique intellect?</p><p>The feeling of inferiority is certainly not limited to infants, but by viewing this question through the lens of child psychology, we’ll arrive at a pretty good answer.</p><p>Jean Piaget, an influential 20th century psychologist, keenly observed that infants develop their intellect not through social interaction, but by personal action. Piaget initially thought that language was the primary developer of the intellect, but he noticed that an infant’s rapid capacity to interact with her physical surroundings is how she actually learned. Contrary to popular belief, it wasn’t “goo-goo gah-gah”ing with family members that developed her mind, but the way she used her senses to navigate the material world around her.</p><p>Piaget used this observation to propose that intellectual development happens in four distinct stages, each of which progresses from the more concrete (touching and arranging objects) to the more abstract (categorization to verbal reasoning). What makes progression possible is the child’s ability to build a “schema” (aka mental model) of the world, to introduce something foreign to that schema, and then to have the child update that schema to accommodate that foreign thing.</p><p>So for example, let’s say you show a child two glasses of different sizes. One is tall and thin (which holds water), while the other is short and wide (which is empty):</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B01-Glasses-of-water.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B01-Glasses-of-water.png" alt="cups experiment" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B01-Glasses-of-water.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B01-Glasses-of-water-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B01-Glasses-of-water-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B01-Glasses-of-water-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B01-Glasses-of-water-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>Then let’s take the contents of the tall glass and pour it into the short glass:</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B02-Glasses-of-water.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B02-Glasses-of-water.png" alt="pouring big cup into small cup" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B02-Glasses-of-water.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B02-Glasses-of-water-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B02-Glasses-of-water-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B02-Glasses-of-water-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B02-Glasses-of-water-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>If this is the first time the child has seen this, she will believe that the shorter glass now holds less water than the taller one did. Since her existing schema takes differences in height to indicate changes in quantity, she will be unable to understand how both cups contain the same amount of water.</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B03-Glasses-of-water-rev.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B03-Glasses-of-water-rev.png" alt="being surprised at the cup" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B03-Glasses-of-water-rev.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B03-Glasses-of-water-rev-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B03-Glasses-of-water-rev-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B03-Glasses-of-water-rev-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B03-Glasses-of-water-rev-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>The only way for the child to accommodate this new knowledge is for her to take action and try it out herself. It doesn’t matter how much you sit her down and explain the mechanics, the only way for her to update her schema is to break the old one by integrating this foreign reality.</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B04-Glasses-of-water.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B04-Glasses-of-water.png" alt="pouring from small cup to big cup" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B04-Glasses-of-water.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B04-Glasses-of-water-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B04-Glasses-of-water-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B04-Glasses-of-water-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B04-Glasses-of-water-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>Intellectual development is deeply personal, and can only occur when one takes on the experiential challenges required to update their schemas. This is why Piaget called for classrooms where each child’s progress was individually accommodated by the teacher, and learning was more interactive. Agency plays a big role in how we cultivate our intellectual curiosity, as this type of willful action is what allows us to trust our own cognitive capabilities.</p><p>At its core, <span><strong>self-esteem is about having the confidence to solve problems on your own accord</strong></span>. And the way you do this is by regularly facing challenges that stretch the boundaries of your mind, which in turn shatter and update the preexisting models you had of the world. The more you do this, the more you cultivate your sense of judgment, which allows you to shut the door to inferiority.</p><p>This is easier said than done, largely because inferiority is the platform in which existence begins. It’s what you feel when you look to other people’s solutions to solve your personal problems, and this type of emulative behavior is what is required to progress through childhood. But with each challenge we face and resolve, we slowly transcend our reliance on others, and develop our unique lens to view the world through.</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C01-Climbing-to-Self-Esteem.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C01-Climbing-to-Self-Esteem.png" alt="moving up a step" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C01-Climbing-to-Self-Esteem.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C01-Climbing-to-Self-Esteem-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C01-Climbing-to-Self-Esteem-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C01-Climbing-to-Self-Esteem-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C01-Climbing-to-Self-Esteem-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>As you reach the step of self-esteem, the sense of self grows in turn. Confidence is a belief in how strongly your sense of agency is tied to favorable life outcomes, and the greater it is, the more you carve out a space for yourself in this world.</p><p>Self-esteem is invaluable in discovering who you are, but there comes a point where this independence begins to thirst for something greater.</p><p>And it is here where the utility of self-esteem begins to fall apart.</p><h3>From Self-Esteem to Pride</h3><div><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C02-From-Self-Esteem-to-Pride.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C02-From-Self-Esteem-to-Pride.png" alt="self-esteem to pride" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C02-From-Self-Esteem-to-Pride.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C02-From-Self-Esteem-to-Pride-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C02-From-Self-Esteem-to-Pride-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C02-From-Self-Esteem-to-Pride-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C02-From-Self-Esteem-to-Pride-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p></div><blockquote><p><em>All social disturbances and upheavals have their roots in a crisis of individual self-esteem, and the great endeavors in which the masses most readily unite [are] basically a search for pride.</em></p><p>– Bruce Lee</p></blockquote><p>The paradox of self-esteem is that in order to have confidence in yourself, you need to better understand the social context in which you operate in. For example, if you want to be a great manager, you have to be acutely aware of all the dynamics you have with your team members. If you want to be a great entrepreneur, you have to figure out how to build an awesome solution that other people would find helpful.</p><p>This is inevitable because even though life is a single-player game, meaning is ultimately derived <a href="https://moretothat.com/the-meaning-of-life-is-absurd/" target="_blank" rel="noopener noreferrer">on multi-player mode</a>. We can only navigate existence through our own lens, but it’s through the connections we make with other people that gives the journey its purpose.</p><p>Self-esteem is complicated for this very reason. So much of it is tied into <a href="https://moretothat.com/the-omnipresence-of-work/" target="_blank" rel="noopener noreferrer">how useful we are to others</a>, and our confidence grows the more we are rewarded for our actions. This confidence boost leads to a higher attachment to the sense of self, which means that we look to further differentiate ourselves from everyone else.</p><p>And when it comes to differentiation, humanity has used one crude tool to achieve this since the dawn of our existence:</p><p>The desire for status.</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C03-Status-vial.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C03-Status-vial.png" alt="people desiring status" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C03-Status-vial.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C03-Status-vial-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C03-Status-vial-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C03-Status-vial-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C03-Status-vial-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>Any quest for status begins with an attachment to some identity, and then using a strong sense of self to climb up that particular silo. Corporate ladders are a common example of this phenomenon. Academic hierarchies are another. Others are primarily concerned with influence, which can be seen in abundance on social media or any other <a href="https://moretothat.com/pursue-mastery-not-status/" target="_blank" rel="noopener noreferrer">metric-heavy medium</a>.</p><p>The first thing status does is that it changes the nature of confidence. Confidence is no longer gauged by your internal benchmark of progress; it is contingent upon the praise you receive from others. This makes your sense of self fragile, as its condition hinges upon reactions that are not your own. The tide of other people’s opinions never follow any predictable pattern, so you begin to operate from an unstable foundation.</p><p>In order to compensate for this, we introduce the element of pride.</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C06-From-Pride-to-Self-Actualization-rev.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C06-From-Pride-to-Self-Actualization-rev.png" alt="people's opinions vs my pride" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C06-From-Pride-to-Self-Actualization-rev.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C06-From-Pride-to-Self-Actualization-rev-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C06-From-Pride-to-Self-Actualization-rev-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C06-From-Pride-to-Self-Actualization-rev-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C06-From-Pride-to-Self-Actualization-rev-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>Pride is an overcorrection to our fragility in confidence. It’s a staunch attachment to an identity, regardless of what <a href="https://moretothat.com/why-everyone-can-face-the-truth/" target="_blank" rel="noopener noreferrer">may or may not be true</a>. It’s our way of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://moretothat.com/the-staircase-of-the-self/">https://moretothat.com/the-staircase-of-the-self/</a></em></p>]]>
            </description>
            <link>https://moretothat.com/the-staircase-of-the-self/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25994026</guid>
            <pubDate>Mon, 01 Feb 2021 21:12:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Splatoon 2’s Netcode and Matchmaking: An In-Depth Look (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25993639">thread link</a>) | @ignitionmonkey
<br/>
February 1, 2021 | https://oatmealdome.me/blog/splatoon-2s-netcode-an-in-depth-look/ | <a href="https://web.archive.org/web/*/https://oatmealdome.me/blog/splatoon-2s-netcode-an-in-depth-look/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Splatoon 2’s netcode and matchmaking has been criticized for many different reasons. Some of the common complaints are frequent disconnections, low tick rate, lag, and that the netcode uses a peer-to-peer architecture. In this blog post, I will attempt to explain how the netcode works and address some people’s complaints. This post is the culmination of a year’s worth of research and collaboration with others. I hope that you will learn something from it!</p>
<p>If you are allergic to essays, I’ve included a list of key points at the end of the post. I still recommend to try and read the whole thing, however.</p>
<p>(The listing image was taken by <a href="https://steamcommunity.com/sharedfiles/filedetails/?id=1193479292">Ethan</a>. Thank you so much!)</p>
<h3>Need-to-Know</h3>
<p>Let’s go over some basic information first.</p>
<h4>Basic Netcode Terminology</h4>
<p>Please have a look over <a href="https://www.pcgamer.com/netcode-explained/">PCGamer’s excellent netcode overview</a> to review basic information about what netcode is and its associated terminology. I will not be explaining every term or concept here otherwise this post would be a million words long. (As if it wasn’t already that long in the first place…)</p>
<h4>Pia</h4>
<p>At its core, Splatoon 2 uses a library called “pia”. Pia was developed by Nintendo in order to make creating networking features for games easier. It implements network features based on a “peer-to-peer” architecture, unlike the traditional “client-server” architecture. This means that instead of one server having a “one-on-one conversation” between each Nintendo Switch console to exchange information, all of the consoles communicate directly with each other to share information.</p>
<figure><img data-attachment-id="155" data-permalink="https://oatmealdome.me/blog/splatoon-2s-netcode-an-in-depth-look/peer-to-peer/" data-orig-file="https://cdn.oatmealdome.me/wp-content/uploads/2019/05/09210009/Peer-to-peer.png" data-orig-size="620,308" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Peer-to-peer" data-image-description="" data-medium-file="https://cdn.oatmealdome.me/wp-content/uploads/2019/05/09210009/Peer-to-peer-300x149.png" data-large-file="https://cdn.oatmealdome.me/wp-content/uploads/2019/05/09210009/Peer-to-peer.png" src="https://cdn.oatmealdome.me/wp-content/uploads/2019/05/09210009/Peer-to-peer.png" alt="" data-lazy-src="https://cdn.oatmealdome.me/wp-content/uploads/2019/05/09210009/Peer-to-peer.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption> from bitcoinwiki.org, CC BY-SA </figcaption></figure>
<p>However, this doesn’t mean that there isn’t a “master console” similar to what a server would be. Pia assigns one console as the “host” of the session. This is usually the person who opened the session first, and people who join the session are considered to be regular clients. (Contrary to popular belief, it hasn’t been definitively proven that the person at the top of the matchmaking screen is the host of the session.) But how do other people find each other to join sessions?</p>
<h4>NEX</h4>
<p>NEX is a two-part system comprising of a game server and an API used to communicate with the servers. NEX handles matchmaking for peer-to-peer sessions, NAT traversal (helping people behind a firewall or router with getting connected to others), and rankings. Pia has built-in support for NEX’s matchmaking and NAT traversal features, making it easy for developers who are already using pia to implement online play. (NEX actually has its own peer-to-peer networking library independent of pia called VSocket, but Splatoon 2 does not use this. As far as I know, I don’t think any game does…)</p>
<p>NEX actually began its life as <a href="http://www.quazal.com/rendez-vous.htm">Quazal Technologies Inc.’s Rendez-Vous</a>, which started development <a href="https://www.gamasutra.com/view/feature/130572/middleware_postmortem_quazal_.php?page=3">all the way back in 2003</a>. Several games from the 2000s used technology from Quazal to implement multiplayer features. <a href="https://www.gamesindustry.biz/articles/quazal-ubisoft-deal-latter-to-employ-former-s-multiplayer-middleware">Ubisoft later acquired Quazal Technologies in 2010</a>. Rendez-Vous lives on to at least 2015, as <a href="https://jpboivin.me/wp/">Ubisoft Montreal continues to add features to the library</a>.</p>
<p>As for NEX, it appears Nintendo must have either bought or licensed Rendez-Vous from Quazal. They then proceeded to make various changes to the library and rebrand it as NEX.</p>
<h4>“Libraries”?</h4>
<p>In the previous sections, I referred to pia and NEX as “libraries”. If you don’t know, a library is a set of code meant to be shared between different programs. You might see where I’m going with this…</p>
<p>Pia and NEX are actually used by multiple games on the 3DS, Wii U, and Switch. They were not built specifically for Splatoon 2. Here’s a selection of software that uses them:</p>
<p><strong>3DS</strong></p>
<ul><li>Friends service (NEX)</li></ul>
<p><strong>Wii U</strong></p>
<ul><li>Splatoon</li><li>Mario Kart 8</li><li>Friends service (NEX)</li></ul>
<p><strong>Switch</strong></p>
<ul><li>Splatoon 2 (yes, this means that Splatoon 2’s netcode is an evolution of Splatoon 1’s)</li><li>Mario Kart 8 Deluxe</li><li>ARMS</li><li>Nintendo Entertainment System – Nintendo Switch Online</li></ul>
<p>As you can see, it’s all first party software. This isn’t an exhaustive list – I’m less familiar with 3DS games, though pia is definitely available for 3DS. Nintendo <em>does</em> provide the libraries to third-party developers but I haven’t seen any third-party games using pia or NEX yet.</p>
<h3>Splatoon 2</h3>
<p>Now that we know the basics, let’s apply our knowledge to Splatoon 2!</p>
<h4>Clones</h4>
<p>Splatoon 2’s netcode is built entirely using a feature of pia called “clones”. A clone is created by a console, and other consoles can “subscribe” to the clone. If the owning console makes changes to the clone, the subscribing consoles are notified of any changes. For example, a clone can be made using a variable called “X”. If the owning console changes X to 5, then all of the subscribers will be notified that the value of X was changed to 5. Splatoon 2 does not use any other method of data synchronization other than clones, though pia supports sending messages directly between consoles without using clones.</p>
<p>There are three types of clones:</p>
<ul><li>Unreliable – changing the clone will cause a notification to be sent to subscribing consoles, but the notification may or may not arrive at the subscribers because of packet loss</li><li>Reliable – a notification will be sent to subscribing consoles, with more being sent if they are not received, guaranteeing synchronization</li><li>Event – clone synchronization is guaranteed, and any data changes in rapid succession are guaranteed to be processed in the order that they were made</li></ul>
<p>Here are some examples of where the various clone types are used:</p>
<ul><li>Unreliable – player position, as the game can interpolate (guess) where the player is heading towards based off their current speed and position if there is data loss</li><li>Reliable – basic player information like their name and equipment, as this information is required to be synchronized between consoles, but the order in which it is received does not matter</li><li>Event – a boss Salmonid spawning in Salmon Run, as other consoles need to know that this happened and the order in which bosses spawn in</li></ul>
<p>In addition, clones have various “access permissions” that can be set:</p>
<ul><li>Send – values can be only set and sent to subscribers with an associated Receive clone</li><li>Receive – values can be only received from an associated Send clone</li><li>Sequential – all consoles can set the values, though because of this an Event clone cannot also be a Sequential clone (impossible to preserve the order of values set)</li><li>Atomic – all consoles can set the values, but only one console can set the value at a time</li></ul>
<p>To keep synchronization, each console starts up a “clone clock”. For Splatoon 2, this clock goes up 120 units per second and continues until the session closes. (For the nerds, an integer overflow wouldn’t happen for a very, very long time. It would be over a year before it overflows assuming that the data type is an unsigned integer.) If the clocks become out of sync, the clocks are resynchronized. This can occur if, for example, there is a sudden spike in CPU load and the game can’t keep up with its refresh rate. This clock value is also occasionally used as a “seed” for the random number generator (RNG), which is used in various in-game actions that involve randomness. </p>
<h4>Tick rate</h4>
<p>The tick rate situation in Splatoon 2 is complicated and marred with controversy. The controversy part mainly comes from <a href="https://web.archive.org/web/20170801024252/https://octo.im/2017/07/31/splatoon-2-online-multiplayer-analysis/">a post by Oliver Brammer</a>, who published an article saying that Splatoon 2 runs at 15.75Hz. This isn’t entirely true.</p>
<p>To start off, the game ticks at 60Hz. (Fun fact – when the game enters the plaza and halves the frame rate, it accomplishes this by lowering the entire tick rate of the game to 30Hz.) Each tick, the game tells pia to send packets, receive packets, and process any events. This means that the netcode also processes at 60Hz. <em>However</em>, Nintendo set a configuration flag that says clone data should only be sent every 4 ticks. This means that the tick rate for sending data is artificially constrained to 15Hz. Normal processing of packets occurs at 60Hz, so receiving and processing clone data runs at “normal speed”.</p>
<p><strong>What does this 15Hz send rate mean?</strong></p>
<p>The pia library will combine packets during the 4 tick waiting period into one big packet at the end. (This coalescing of data explains why Oliver Brammer found an increase of average packet size compared to Splatoon 1.) This waiting period also means that data may arrive at minimum 4 ticks later. However, remember that event clones will always be processed in the order that they occur. Event clones are used for things like player damage, inking the map, and bullet spawning. <em>This may mitigate some of the effects caused by the lower tick rate.</em></p>
<p><strong>Why is Nintendo artificially constraining the tick rate?</strong></p>
<p>This is likely for bandwidth reasons, as Oliver Brammer stated. According to his data, there was a 45% reduction in bandwidth going from Splatoon 1 to Splatoon 2. It could also be for stability reasons. By using less data, it can allow players with less capable Internet connections to be able to play online. This is especially beneficial for mobile hotspots.</p>
<p><strong>How does this compare to Splatoon 1?</strong></p>
<p>Unfortunately, it’s very hard to analyze Splatoon 1’s netcode. Nintendo made it easy for me to analyze Splatoon 2 since they accidentally left debugging information for many versions. Splatoon 1, on the other hand, is essentially a black box. I have found a configuration setting that may be similar to the “waiting period” setting in Splatoon 2, but I have been unable to confirm this. In addition, Splatoon 1 uses a very old version of pia, and there have been several major changes to the library since (mostly relating to how packets are serialized). It would be unfair to do a “direct” comparison between Splatoon 1 and Splatoon 2.</p>
<p>However, I do want to say that I believe Oliver Brammer’s claim that Splatoon 1 had trouble keeping up at 25Hz is incorrect. The fluctuation in data size could be there for other reasons. For example, the waiting period may be set lower, causing clone data to not be coalesced as often. This would result in lower overall packet sizes and data to be sent much more frequently.</p>
<h4>Disconnects</h4>
<p>The game has three …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oatmealdome.me/blog/splatoon-2s-netcode-an-in-depth-look/">https://oatmealdome.me/blog/splatoon-2s-netcode-an-in-depth-look/</a></em></p>]]>
            </description>
            <link>https://oatmealdome.me/blog/splatoon-2s-netcode-an-in-depth-look/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25993639</guid>
            <pubDate>Mon, 01 Feb 2021 20:44:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Estimates, Design and the Payoff Line]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25993563">thread link</a>) | @nvader
<br/>
February 1, 2021 | https://danverbraganza.com/writings/estimates-design-and-the-payoff-line | <a href="https://web.archive.org/web/*/https://danverbraganza.com/writings/estimates-design-and-the-payoff-line">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" itemscope="" itemtype="http://schema.org/BlogPosting" itemid="estimates-design-and-the-payoff-line">
        
        
        <p itemprop="about"><i>How inaccuracies in estimation lead to a systematic undervaluing of the importance of Design</i></p>
        <p>
        by  on <i itemprop="datePublished">2021-01-31</i></p>
        <p><span itemprop="articleBody">
          <p>In Martin Fowler's
<a href="https://www.martinfowler.com/bliki/DesignStaminaHypothesis.html">DesignStaminaHypothesis</a>,
he asks the question of when is it worth the time to design properly, and when
it is acceptable to take on tech debt by neglecting design. By neglecting design
and long-term thinking, you're able to take an individual product or feature to
market much faster, but you slow down your overall rate of delivery for the
whole project. The article is great and I encourage you to read it.</p>

<p>From the article, I've reproduced the following graph, with one addition.</p>

<p>Mark calls out the design payoff line, below which you can achieve a faster
delivery by taking on technical debt, but above which technical debt hurts in
the long run. I want to point out how errors in estimation, or driving to
deadlines, can hurt this process.</p>

<figure>
<img src="https://danverbraganza.com/assets/design-hypothesis-annotated.png" title="An annotated graph of cumulative functionality delivered with respect to time">
<figcaption>
Fig. 1: An annotated graph of cumulative functionality delivered with respect to time
</figcaption>
</figure>

<p>I've added two lines to this graph. There's an estimated delivery time, and an
actual one. If we are able to deliver the project on the estimated schedule,
then it apparently makes sense to skip the in-depth design work, since the
amount of cumulative features shipped is higher with the blue line than the red.
However, in this example, if the actual delivery date slips, then you would have
been better off investing in design. At the actual delivery time, the amount of
features shipped by the red line is more than the blue.</p>

<p>The core rub here is that given any estimate of delivery, we should expect the
mean value of the actual delivery to be later than that!<sup id="fnref:0"><a href="#fn:0">1</a></sup> Delivery dates are
dominated by their right tail. Consider that a project can never be delivered
earlier than its start date, but it <em>can</em> be prolonged indefinitely.</p>

<p>This seems like an extreme claim, but my experience bears it out. If it were not
true, we would expect to see at least half of all projects to be delivered
earlier than their deadline. In fact it would need to be the overwhelming
majority delivered ahead of schedule, to make up for the rare but extreme
outliers that miss their estimates. In practice, however, work expands to fill
the time available even in cases where the project is running well.</p>

<p>This means that an attempt to rationally decide whether a project can skip
design and incurr tech debt based on an estimate has a systemic risk. This risk
can blow up and hurt you in two ways. Not only is the project itself now
delayed, but the entire codebase is worse off than if you had chosen a slower
approach. If this project happened to be part of a larger coordinated schedule
that is also time-constrained, well now your problems have only just begun.</p>

<p>I recommend that the next time you feel pressured to incur under-design tech
debt because of a deadline or a low estimate, model out the scenario of what
happens if the actual delivery time slips. If that scenario is unacceptable, it
is worth your while to push back against incurring tech debt.</p>

<p>Remember, slow is smooth, and smooth is fast.</p>

<p>Have a comment? I'd love to hear your thoughts at <a href="https://news.ycombinator.com/item?id=25993563">this thread on Hacker News</a></p>


        </span></p><section>
	  <h4>Other articles you may like</h4>
          <ul>
	    
            <li>
              <b><a href="https://danverbraganza.com/writings/software-names-to-avoid">Names to avoid in Software Engineering</a></b>
	      An incomplete list of poor names for libraries, modules, projects and teams
            </li>
            
            <li>
              <b><a href="https://danverbraganza.com/writings/distributed-circuit-breakers-at-hipmunk">Distributed Circuit Breakers at Hipmunk</a></b>
	      How we implemented Circuit Breakers at Hipmunk to automatically deal with third party outages.
            </li>
            
            <li>
              <b><a href="https://danverbraganza.com/writings/misapplying-lazy-recursive-defaultdict">Misapplying LazyRecursiveDefaultDict</a></b>
	      A cautionary tale of how I misapplied the wrong software tool to a problem, and what I've learned from it.
            </li>
            
          </ul>
	</section>
	
	
	<section>
	This article was filed under:
	<p><span>Software Engineering</span> 
	</p>
	</section>
	
      </div></div>]]>
            </description>
            <link>https://danverbraganza.com/writings/estimates-design-and-the-payoff-line</link>
            <guid isPermaLink="false">hacker-news-small-sites-25993563</guid>
            <pubDate>Mon, 01 Feb 2021 20:39:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Esoteric Programming Languages – The Obscure and Unconventional]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25993381">thread link</a>) | @azhenley
<br/>
February 1, 2021 | https://thecodebytes.com/esoteric-programming-languages/ | <a href="https://web.archive.org/web/*/https://thecodebytes.com/esoteric-programming-languages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article id="post-863"><header> <img width="1280" height="800" src="https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280.png" alt="Esoteric Programming Languages" loading="lazy" srcset="https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280.png 1280w, https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280-300x188.png 300w, https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280-1024x640.png 1024w, https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280-768x480.png 768w" sizes="(max-width: 1280px) 100vw, 1280px" data-srcset="https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280.png 1280w, https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280-300x188.png 300w, https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280-1024x640.png 1024w, https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280-768x480.png 768w" data-src="https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></header><section><h2>Introduction</h2> We all know that programming languages can be incredibly useful tools. However, what if there were languages that were not created to be used? Ones that test the boundaries of programming language design and cause even the most experienced programmers to bang their heads against the wall trying to build a simple program? Enter esoteric programming languages.<h2>What Are Esoteric Programming Languages?</h2> Most programming languages are designed for the purpose of widespread use and productivity. However, Esoteric programming languages (esolang) are a segment of programming languages that are not built for usability, but rather for entertainment, artistic intent, or to prove a concept. The word "esoteric" is <a href="https://www.etymonline.com/word/esoteric" target="_blank" rel="noopener noreferrer">derived from the Greek word "esoterikos"</a>, which means “belonging to an inner circle”. Esoteric languages are not intended to be widely understood.<h2>The Purpose of Esoteric Languages</h2> The first-ever esoteric programming language was <a href="http://catb.org/~esr/intercal/" target="_blank" rel="noopener noreferrer">INTERCAL</a>. A parody created by <a href="https://en.wikipedia.org/wiki/Don_Woods_(programmer)" target="_blank" rel="noopener noreferrer">Don Woods</a> and James M. Lyon in 1972 that mimicked popular languages at the time, such as <a href="https://stackoverflow.blog/2020/04/20/brush-up-your-cobol-why-is-a-60-year-old-language-suddenly-in-demand/">COBOL.</a> The idea was later revived in 1993 when Wouter van Oortmerssen designed <a href="http://strlen.com/false-language/" target="_blank" rel="noopener noreferrer">FALSE</a>. The concept was to build a powerful, tiny implementation (compiler executable of 1024 bytes) programming language with an obfuscated syntax that was disorienting to its users. From here, more recognizable names such as <a href="https://esolangs.org/wiki/Brainfuck" target="_blank" rel="noopener noreferrer">brainfuck</a> and <a href="https://esolangs.org/wiki/Befunge" target="_blank" rel="noopener noreferrer">Befunge</a> began to emerge and the concept of esoteric languages began to take shape as a concept.  As previously stated, esoteric languages have four main purposes. To act as a proof of concept, for competitive sport, display an artistic process and simply for entertainment. To better grasp these ideas, let's look into each of them with an example language.<h3>Proof of Concept (Brainfuck)</h3> The first purpose of esoteric languages we are going to look at is proof of concept. A language that was able to present a proof of concept to the computer science community was <a href="https://esolangs.org/wiki/Brainfuck" target="_blank" rel="noopener noreferrer">Brainfuck.</a> A minimalist programming language that contains an astonishing eight characters in total while still proving to be <a href="https://medium.com/@evinsellin/what-exactly-is-turing-completeness-a08cc36b26e2" target="_blank" rel="noopener noreferrer">Turing-complete</a>. The language should not be used for practical projects due to its complexity at scale (as the name suggests). However, it is interesting to see that a programming language can have its utilities with such a small amount of primitives. Here is an example of the language:  <h3>Competitive (Malbolge)</h3> Esoteric languages can also be viewed in a competitive context, such as Malbolge. Languages like Malbolge were created with the sole intent to be exceptionally incomprehensible and difficult to use. Achieved through self-modification, non-intuitive operators and encryption, Malbolge is one of the hardest programming languages to learn. It also very well could be the first of its kind for this purpose in mind. The competition revolving around Malbolge is contained within the premise of the language. That anyone able to make a useful program with Malbolge deserves bragging rights. Here's a sample of how difficult the language is to use.  <h3>Artistic (Shakespeare)</h3> The third purpose of esolang's are for artistic purposes. A popular example of this is the <a href="http://shakespearelang.com/" target="_blank" rel="noopener noreferrer">Shakespeare language</a>. A unique programming language that is meant to resemble the writing from Shakespearean plays. The language is unique, as it redefines the entire programming paradigm. Instead of focusing on producing an intended result, the goal is to make the code itself look more elegant. If only all our code looked as clean as this!  <h3>Entertainment (COW)</h3> Finally, some esoteric programming languages are simply meant to be entertaining.&nbsp; Such as the <a href="https://esolangs.org/wiki/COW" target="_blank" rel="noopener noreferrer">COW language by Sean Heber</a>. As a derivative of the Brainfuck language mentioned above, COW only has 12 primitive. All of which are different capitalizations of the word 'moo'. It's hard to imagine why someone would go through so much effort to create this language. In a way, this comical language really does grasp what programming is all about: incredibly frustrating, a little silly and most importantly, fun.  <h2>The Interesting Thing About Esoteric Languages</h2> So that's pretty much all you need to know about esoteric programming languages. In a strange way, they are like the 'conceptual art' of the programming world. Unconventional and weird, but often thought-provoking and fascinating. Esoteric languages break the recycled formula that most conventional languages follow. Making me believe that these languages could one day be the key to new applications of programming.  Although, if nothing else, they are fascinating designs to look at. Which remain untouched over years, without the over looming necessity to stay 'current' like the majority of popular languages today. Allowing them to only become more interesting with age.  You can check out a full list of esoteric programming languages, <a href="https://esolangs.org/wiki/Language_list" target="_blank" rel="noopener noreferrer">here.</a> If you have anything to add, I would love to hear it in the comment section below!  If you are a programmer that is interested in making passive income, <a href="https://thecodebytes.com/make-passive-income-programming-5-incomes-for-software-developers/">check out this</a>.  Most of the insights I gathered from this post were from <a href="https://esolangs.org/wiki/Main_Page" target="_blank" rel="noopener noreferrer">esolangs.org</a> and <a href="https://morr.cc/esolangs/esolangs.pdf" target="_blank" rel="noopener noreferrer">Esoteric Programming Languages by Sebastian Morr</a>.  Happy coding everyone!  &nbsp;</section></article></div></div>]]>
            </description>
            <link>https://thecodebytes.com/esoteric-programming-languages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25993381</guid>
            <pubDate>Mon, 01 Feb 2021 20:27:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weights and Biases raises $45m to build better tools for ML practitioners]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25993297">thread link</a>) | @shcheklein
<br/>
February 1, 2021 | https://wandb.ai/wandb/news/reports/Weights-and-Biases-raises-45m-to-build-better-tools-for-ML-practitioners--Vmlldzo0NDExMTE | <a href="https://web.archive.org/web/*/https://wandb.ai/wandb/news/reports/Weights-and-Biases-raises-45m-to-build-better-tools-for-ML-practitioners--Vmlldzo0NDExMTE">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://wandb.ai/wandb/news/reports/Weights-and-Biases-raises-45m-to-build-better-tools-for-ML-practitioners--Vmlldzo0NDExMTE</link>
            <guid isPermaLink="false">hacker-news-small-sites-25993297</guid>
            <pubDate>Mon, 01 Feb 2021 20:21:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XRP Pump and Dump]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25993128">thread link</a>) | @yuzugit
<br/>
February 1, 2021 | https://yuzu.dev/2021-02-01/xrp-pump-dump | <a href="https://web.archive.org/web/*/https://yuzu.dev/2021-02-01/xrp-pump-dump">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  <p><span>Written by</span>
    
        Benjamin Robert
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2021-02-01 00:00:00 +0000">February 01, 2021</time>
    
  </p>

  
  

  

<p><a href="https://en.wikipedia.org/wiki/Ripple_(payment_protocol)"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAJcAAAB9CAMAAACYngGvAAAAaVBMVEX///8AAADx8fH7+/vs7OzMzMxqamr09PQGBgbf39/o6Og2NjbZ2dmsrKzj4+NHR0eZmZl1dXVdXV1kZGS4uLjAwMArKytNTU1/f3/S0tJYWFimpqYhISHGxsYwMDAbGxsTExONjY09PT0abePRAAAEsUlEQVR4nO1bx2KrQAykYzDNNjHNSRz//0c+E/LikhFoQbtcPFfaoJltWq31biPUlinU8Pu+Zfnwws4QrR1Fy7KaFYlhWs1wsdmsRMyFtDbN/+tYykA7rwMt4gAs5V4zrf2YiAOIiLkaWbkBFNF/vCuBxA4aeWERk+fbImh+fVJCETfR3xuTM5RSEy0o4vlPtHpkMLB6ItbCb2X45ugT3VyF4qzCCn3oE4g4AJt/L90qXdxBQBEHRPCBSpgXjJZNRqtHckSPtJJShtBbH6O0THQX7A7iERk2v5THXGx5oiXeI/qAEZOR0oHRmhJxAO7HZMyPLc+IVo8Ymj93FrNycvTiY8x9PsKtcikxB7fEkX7rGTE0f77M/C6M1qen8o4YvqNSescTPOitnC3igGwLpZzfKnF3umVa/gYPm38uMQ9bfoYAGZZS+QdHXpbPelkm110QHcS8f7S8C7SEolOviKFZL7NbUQabkLKU+DWt+v/9wsE/qmb+EId9US+Nu2il1k30OAsHjxhLydeAaNYLRBwQwt89cd8bn2DABWZNHpaSN9omWMQl49mNGFTiwvFYBi2fi9CihrbHxAsEThO1Yus+B67a7XTisRQ+FSyfX/4CL5DtYMy+If4Z4eU7XiLbBfWVsMAPSKc7HJyusrcFMrFXwHZo2wdBEQfghV+Punz8mFPinLwtuAy9J0ZErMdHnfpNDz+t4fLzJ1pa8qKUlGyMNpMlIMzPhL6cKN4HYGKnMblNZNRY0dKZc6c2dBjR0srqCqK/nEChm5Zlvc2g9aafFjmK05AcqcfgdnASSuDU6XX8PWJypPmDevFMXgkRT8yAlaEURTLNLFBIuQnC6cg5xhVtZ8juAG7c7dHS4rLvYnNux/D8sr6PW1WXvtCCRwKu12PtIL3wwgsvvKAXcVOmXdelZWN2ukUj9ovndfih8Fdm56UtTtxs23S9sbscnxkG5RqkvA5WWjxg0xkPGpV4e9bTwIL2DiXcAoQ4mlPTU8ue7A2J+aayqu1xMpIG4C9pb9Bfbu2pJicGBJq1xFvLDMzfNOYgUrXWDSeNGYFobrS+I6aNWAwrXNk4axrMce3hDzbbvKqqfDs2OB21pFFw8dU3tsV7EjthGDpx8j4yQh01SIlLSK/Yp895GyclBwRxYg3REncJSkm4CZFPP01v8iohw5bPffIJH+6K2+eZNTkYuEB5YiMZbyOPlRsr08KVTVOaNLiKSYwYLhxl1M4RhQRCUuJqA96BATzKi5i/gZZnbr3iTd6zADFs+Zb9PJZysceI02v8PCqxl0p3MCwkcLxTO4yCzwktitgSy08QW2J+X+hAHT4eN1tKueN0OGIzieGTpPM2qrH539emJUhM+nirUHchfxwYr4cVI6bjlLIAMT1nlBdLWWqIVg8cMXYiClduSFSy4Igx0z2YlkxKBkeMRQyL+CVCy7K+5kqJoyVFiyI2GTHdtGYS009rFjG85JOlRREbWYxiWvIpeFzbRhIzE60eShEzFa0eChHDtDottCyr4xIzS4tNzDQtJjGst05aFLEHP69Bi0FsHVqTxBS7OUGMdk2YlpntTDypKtamNUIM0zKyk/kNPIMp/gEDuTul11+UXgAAAABJRU5ErkJggg==" alt="XRP"></a></p>

<p>This week-end, as I was looking at the dogecoin situation, my attention got droven to a new cryptocurrency I didn’t know so far: XRP. I am pretty new to investment and cryptocurrency. Actually, I earnt one bitcoin in 2013 by playing online poker and I sold it for around $300 when the price got “high”. That gives you a pretty good view of my trading skill (for those you don’t know, here’s the current value of one bitcoin: <a href="https://coinmarketcap.com/currencies/bitcoin/">check how much I didn’t win</a>. However I was in the mood to trade a bit but didn’t want to join the $DOGE hype. After a quick research, I discover $XRP from <a href="https://en.wikipedia.org/wiki/Ripple_(payment_protocol)">Ripple</a> and assume that it was a good time to invest in that. By the time I’ve bought (Saturday, 02/30/2021), value was at 0.28€.</p>

<p><img src="https://raw.githubusercontent.com/yuzugit/yuzugit.github.io/master/img/boughtTime.png" alt="What and invest!"></p>


<p>Rumours started to spread all over the web that r/wallstreetbets guys or other groups were going to pump XRP a lot, like what happened with $GME (if you are not familiar with this, check out this article <a href="https://time.com/5933242/gamestop-stock-gme/">on Time.com</a>). During the Sunday, 31, the value started to increase a lot, up to 0,40 in the morning (+61,14%). I started to wonder “Is it a good time to sell?”. Afraid to see the whole bitcoin situation happening again (even if they were no actual factors prouving that) and having invested a really small amount of money, I decided to wait and check out the telegram group and r/xrp.</p>

<p><img src="https://raw.githubusercontent.com/yuzugit/yuzugit.github.io/master/img/xrpValueSunday.jpg" alt="Stonks"></p>


<p>What I saw in the telegram group was really strange. More than 120k of people were on XRP telegram channel, sending memes, asking to “GO TO THE MOON” and “BUY AND HOLD”. Most of them didn’t have a telegram avatar. The hype was getting really strong for a value explosion of XRP, some people prediction $1, others even $4 to $5. I started to look around some books, article and youtube channel during that day and I learnt about “pump and dump” (as said earlier, really new into trading and finance).</p>

<p><img src="https://raw.githubusercontent.com/yuzugit/yuzugit.github.io/master/img/pumpanddump.png" alt="Pump and Dump"></p>

<p><a href="https://en.wikipedia.org/wiki/Pump_and_dump">P&amp;D or Pump and Dump</a> is a model where you manipulate investors (in that case small retail ones) to “pump” a value (meaning pushing a lot of people to invest) via false informations to make profit from the same value you bought before the pump. The “dump” part reflecting the side where big investors sell all of their shares, causing the value to decrease quickly. As in thoses cases, a lot of investors are inexperienced and small, they probably going to panique and sell too before the value crash too much.</p>

<p>In the XRP case, it happen around 0.62 (I speak in euros, it was around .7 in dollars). A lot of people had the false information that a group in germany were going to push the value beyond $1 are people kept buying at 0.5/0.6. Causing them to loose a lot of money during the dump. I was in the telegram group and I don’t know how much is true but people talk about the month rent they invested, life saving and stuff like that. I know and a lot of people who start trading for fun over nights or week-end knows that you must only invest money that you are “confortable” to loose but the call is hard to resist for some.</p>

<p>When I’m writing this article, the value droped -15,90% and still droping. Worthing 0.32€. I didn’t manage the risk a lot and I had the chance to purchase low, before the drop, and to be not too greedy to make a good profit.</p>


<p>Why am I saying all this? Just to say “hey a lot of people got fucked, a small amount of people got rich. I got okay.”. A trying to stay okay is my advice for small investors. The hardest part is to manage risk. You always want to go bigger and try to “reach the moon” and that’s sometimes how you crash into an asteroid (okay that metaphor is wierd). People make fun of me when I tell them I sold a bitcoin for $300 but the point is, I made money off that investment. Sure I could made a lot more and more talented or experienced people have the skills to do that but, to me, the important part is not to loose money. I’ve invested €300 dollars on XRP and still have €300 invested. Maybe they will worth 200 in a couple of weeks/months, maybe they will worth 400. I don’t care that much as I have returned my investment and I can no follow the trends without fear or need. I know it seems like a pretty basic stuff and you can say “okay all that story to tell something as simple as that” but I believe that it’s a game that can make you really passionate and appeal to your lowest instincts. It’s important to stay humble and logical. To know what you are risking. To not only think of the screenshot you will send to your friends saying “hey, I’ve made x10 on that one.”.</p>

<p>Remember that this game is tricky, that some people with a lot of means and money can turn your “big opportunity” into a big loss. Don’t listen too blindly to people that promise you the world or the moon. You invest in something (a currency, a company value, anything), you should be sure that it worth the stock price. But again, I’m just a guy that makes video games.</p>

</div>




    </div></div>]]>
            </description>
            <link>https://yuzu.dev/2021-02-01/xrp-pump-dump</link>
            <guid isPermaLink="false">hacker-news-small-sites-25993128</guid>
            <pubDate>Mon, 01 Feb 2021 20:10:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decred 1.6 implements Lightning, cryptocurrency mix and decentralized treasury]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25992908">thread link</a>) | @GE56x
<br/>
February 1, 2021 | https://www.explica.co/decred-updates-its-code-and-integrates-the-lightning-network/ | <a href="https://web.archive.org/web/*/https://www.explica.co/decred-updates-its-code-and-integrates-the-lightning-network/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			



<p>The Decred team announced a few days ago the release of version 1.6 of their software.  It is one of the technological updates that qualify as one of the most important of the project to date, in which the Lightning Network (LN) is integrated into its platform.</p>
<p>Under the name Decrediton, the new version is announced on Decred’s official website.  There it is explained that the new code is already complete, waiting for the next activation.  It will be launched through a consensus vote that will take place when enough stakeholders have updated to the new version.  In that sense, version 1.6 version is now available for download.</p>








<p>New features added to the network with this update include LN integration.  The team highlights the properties of this second-layer micro-payment network, by facilitating<strong> the instant sending of transactions off the blockchain, with low fees.</strong> It is a compatibility that “brings great benefits for scalability and user privacy,” says the publication.</p>
<p>Additionally, in terms of privacy, Decrediton incorporates CoinShuffle ++, a protocol for mixing P2P coins that allows creating CoinJoin transactions, those that use jumps and mixes in order to obfuscate exit addresses.  With that, <strong>the ability to send private transactions on the network is added,</strong> as it is possible for users to mix their cryptocurrencies with those of others.</p>
<p>Once mixed up, tracing the coins back to the original wallet will not be feasible, as explained in the post.  This optional privacy feature had only been available on Decred for more technical users since August 2019.</p>

<p>On the other hand, the new version also supports the use of a new form of VSP (voting service provider), now identified as VSPD.  Its use facilitates <strong>purchase of voting tickets</strong> with mixed cryptocurrencies, which will not be tied to a single address.  “There is no need to register an account with an email address and there is no redemption script to support,” they say.</p>
<p><img loading="lazy" width="700" height="368" alt="" srcset="https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred.jpg 700w, https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred-300x158.jpg 300w, https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred-560x294.jpg 560w" data-lazy-sizes="(max-width: 700px) 100vw, 700px" src="https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred.jpg"><img loading="lazy" width="700" height="368" src="https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred.jpg" alt="" srcset="https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred.jpg 700w, https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred-300x158.jpg 300w, https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred-560x294.jpg 560w" sizes="(max-width: 700px) 100vw, 700px">The new software version implements Lightning, cryptocurrency mix and decentralized treasury.  Source: Decred.org</p>
<p>VSPs had already been implemented in June 2020 at Decred.  As CriptoNoticias reported at the time, the main objective of this implementation is <strong>provide users with greater privacy.</strong> However, until now it was only tested as a custom client tool, not suitable for everyday use.</p>
<h2 id="h-avances-en-la-descentralizaci-n-de-la-tesorer-a-de-decred">Advances in the decentralization of Decred’s Treasury</h2>
<p>With the release of version v1.6, the project takes a new step in the <strong>decentralization process of its treasury.</strong> Decrediton delivers a higher level of participation to its community of stakeholders, the people who vote to decide on changes to the consensus rules and governance, as well as on treasury and policy issues of the blockchain platform.</p>
<p>“When the code is activated (after the community completes the update), all Decred stakeholders will have the power to veto or approve all expenses from the treasury,” the team says on its website.</p>

<p>In 2018, the project gave the community the power to vote on how treasury funds are spent with the launch of Politeia, its off-chain proposal system.  But now, if the new voting system is approved, stakeholders <strong>they will be able to review the movements every month</strong> to vote for approval or rejection, through your wallet.  The aim of this process is to give greater transparency to treasury spending and to eliminate the risk of theft of funds, increasing security levels.</p>
<p>The Decred project was born more than three years ago as a proposal based on community participation.  It uses a hybrid mining algorithm between Proof of Work (PoW) and Proof of Stake (POS).  At the time of writing this article, the price of the network’s native cryptocurrency, DCR, is USD 67.88, with a rise of 27% in the last 7 days in Live Coin Watch data.</p>




<!-- AI CONTENT END 1 -->
		</div></div>]]>
            </description>
            <link>https://www.explica.co/decred-updates-its-code-and-integrates-the-lightning-network/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992908</guid>
            <pubDate>Mon, 01 Feb 2021 19:55:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Craig Hunter Exits Sony Pictures TV to Join YouTube]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25992825">thread link</a>) | @sodrick
<br/>
February 1, 2021 | https://relayvibe.co/craig-hunter-is-leaving-sony-pictures-tv | <a href="https://web.archive.org/web/*/https://relayvibe.co/craig-hunter-is-leaving-sony-pictures-tv">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1651">
	
		<div>
<figure>
<img src="https://i1.wp.com/relayvibes.co/wp-content/uploads/2021/02/Craig-Hunter-Is-Leaving-Sony-Pictures-TV.jpg?resize=678%2C381&amp;ssl=1" alt="Craig Hunter Is Leaving Sony Pictures TV" title="">
</figure>

<div><p><a href="https://relayvibes.co/tag/Youtube">Youtube</a> has added to its system the Director of Kids Networks at <a href="https://relayvibes.co/tag/sonypicturestelevision">Sony Pictures Television</a>, <a href="https://relayvibes.co/tag/craighunter">Craig Hunter</a>. He will head( as the global head) the YouTube Originals Preschool Content.</p>
<p>Hunter is currently in London, he is leaving planning to leave for Unites States, LA to be precise, this summer. This is a newly created role and as the Global head of Preschool Content, he will be reporting to Nadine Zylstra, Head of Family Learning and Impact for YouTube Originals.</p>
<p>All preschool content that falls around the kids and families vertical covering scripted and unscripted programming will be under his management.</p>
<p>Zylstra commended Craig in a statement as highly skilled and experienced international content specialist in kids and family space. “His experience and creative background will help lead us in our commitment to invest in the future of quality kids, family and educational programming — as part of the $100 million commitment to original content that we announced.”</p>
<p>Spent almost 9 years with Sony Pictures, Hunter has been managing Sony Pictures Television’s kids’ linear and VOD brands, content acquisitions, commissioning, programming and strategy all around the UK. He was also in charge for the Pop brand. Hunter, who is a Bachelor of Arts (Hons) in graphic design and advertising from Buckinghamshire New University, started his career with Disney after which he moved on to work at BBC Studios. Later he went to Nickelodeon where he spent more than 6<a href="https://finance.yahoo.com/finance/news/youtube-hires-sony-pictures-tv-173131614.html#:~:text=Variety-,YouTube%20Hires%20Sony%20Pictures%20TV%20Exec%20Craig,Head%20Preschool%20Kids'%20Original%20Content&amp;text=YouTube%20tapped%20veteran%20executive%20Craig,the%20internet%20platform's%20originals%20team." target="_blank" rel="noopener"> years</a> .</p>

</div>

	</div><div id="text-13">			<p><img loading="lazy" src="https://i0.wp.com/relayvibes.co/wp-content/uploads/2020/08/ad-300x250-mh-magazine-3.png?resize=300%2C250" alt="" width="300" height="250" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/relayvibes.co/wp-content/uploads/2020/08/ad-300x250-mh-magazine-3.png?resize=300%2C250&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
		</div></article></div>]]>
            </description>
            <link>https://relayvibe.co/craig-hunter-is-leaving-sony-pictures-tv</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992825</guid>
            <pubDate>Mon, 01 Feb 2021 19:50:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Killing Containers at Scale]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25992627">thread link</a>) | @amasad
<br/>
February 1, 2021 | https://blog.repl.it/killing-containers-at-scale | <a href="https://web.archive.org/web/*/https://blog.repl.it/killing-containers-at-scale">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>To make it so that anyone with a web browser can code on Replit, our backend infrastructures runs on preemptible VMs. That means the computer running your code can shutdown at any time! We've made it really fast for repls to reconnect when that happens. Despite our best efforts, though, people had been seeing repls stuck connecting for a long time. After some profiling and digging into the Docker source code, we found and fixed the problem. Our session connection error rate dropped from 3% to under 0.5% and our 99th percentile session boot time dropped from 2 minutes to 15 seconds.</p>
<p>There were many different causes of stuck repls, varying from: unhealthy machines, race conditions that lead to deadlock, and slow container shutdowns. This post focuses how we fixed the last cause, slow container shutdowns. Slow container shutdowns affected nearly everyone using the platform and would cause a repl to be inaccesible for up to a minute.</p>
<h3 id="replit-architecture">Replit Architecture</h3>
<p>Before going in depth on fixing slow container shutdowns, you'll need some knowledge of Replit's architecture.</p>
<p>When you open a repl, the browser opens a websocket connection to a Docker container running on a preemptible VM. Each of the VMs run something we call <code>conman</code>, which is short for container manager.</p>
<p>We must ensure that there is only a single container per repl at anytime. The container is used to facilitate multiplayer features, so its important that every user in the repl connects to the same container.</p>
<p>When a machine that hosts these Docker containers shuts down, we have to wait for each container to be destroyed before they can be started again on some other machine. Since we use preemptible instances, this process happens frequently.</p>
<p>Below you can see the typical flow when trying to access a repl on a mid-shutdown instance.</p>
<p><img src="https://blog.repl.it/images/destroying-stuck-repls/simplified_arch.png" alt="Simplified diagram of repl.it conman architecture"></p>
<ol>
<li>A user opens their repl which opens the IDE and attempts to connect to the backend evaluation server via a WebSocket.</li>
<li>The request hits a load balancer which selects a conman instance to proxy to based on CPU usage.</li>
<li>A healthy, living conman gets the request. Conman notices that the request is for a container that is living on a different conman and proxies the request there.</li>
<li>Sadly this conman is shutting down and rejects the WebSocket connection!</li>
</ol>
<p>Requests will continue to fail until either:</p>
<ol>
<li>The docker container is shut down and the repl container entry in the global store is removed.</li>
<li>Conman finishes shutting down and is no longer accessible. In this case, the first conman will remove the old repl container entry and start a new container.</li>
</ol>
<h3 id="slow-container-shutdowns">Slow Container Shutdowns</h3>
<p>Our preemptible VMs are given 30 seconds to cleanly shutdown before they are forcibly terminated. After some investigation, we found that we rarely finished shutting down within those 30 seconds. This prompted us to dig further and instrument the machine shutdown routine.</p>
<p>After adding some more logging and metrics around machine shutdowns, it became clear that calls to <code>docker kill</code> were taking much longer than expected. <code>docker kill</code> usually took a few milliseconds to kill a repl container during normal operation, but we spent 20+ seconds killing 100-200 containers at the same time during shutdown.</p>
<p>Docker offers two ways to stop a container: <code>docker stop</code> and <code>docker kill</code>. Docker stop sends a <code>SIGTERM</code> signal to the container and gives it a grace period to gracefully shutdown. If the container doesn't shutdown within the grace period, the container is sent <code>SIGKILL</code>. We don't care about gracefully shutting down the container and would rather shut it down as quickly as possible. <code>docker kill</code> sends <code>SIGKILL</code> which should kill the container immediately. For some reason, the theory did not match reality, <code>docker kill</code> shouldn't be taking on the order of seconds to <code>SIGKILL</code> the container. There must be something else going on.</p>
<p>To dig into this, here is a script which will create 200 docker containers and time how long it takes to kill them at the same time.</p>
<pre><code><span>#!/bin/bash
</span>
COUNT=200
<span>echo</span> <span>"Starting <span>$COUNT</span> containers..."</span>
<span>for</span> i <span>in</span> $(seq 1 <span>$COUNT</span>); <span>do</span>
    <span>printf</span> .
    docker run -d --name <span>test</span>-<span>$i</span> nginx &gt; /dev/null 2&gt;&amp;1
<span>done</span>

<span>echo</span> -e <span>"\nKilling <span>$COUNT</span> containers..."</span>
time $(docker <span>kill</span> $(docker container ls -a --filter <span>"name=test"</span> --format <span>"{{.ID}}"</span>) &gt; /dev/null 2&gt;&amp;1)

<span>echo</span> -e <span>"\nCleaning up..."</span>
docker rm $(docker container ls -a --filter <span>"name=test"</span> --format <span>"{{.ID}}"</span>) &gt; /dev/null 2&gt;&amp;1</code></pre>
<p>Running this on the same kind of VM we run in production, a GCE n1-highmem-4 instance, yields:</p>
<pre><code>Starting 200 containers...
................................&lt;trimmed&gt;
Killing 200 containers...

real    0m37.732s
user    0m0.135s
sys     0m0.081s

Cleaning up...</code></pre><p>This confirmed our suspicions that something is going in inside the Docker runtime which causes shutdowns to be so slow. Time to dig into Docker itself...</p>
<p>Docker daemon has an option to <a href="https://docs.docker.com/config/daemon/#enable-debugging">enable debug logging</a>. These logs let us peak into what what's happening inside of dockerd and each entry has a timestamp so it might provide some insight into where all this time is being spent.</p>
<p>With debug logging enabled, let's rerun the script and look at dockerd's logs. This will output a lot of log messages since we are dealing with 200 container, so I've hand-selected portions of the logs that are of interest.</p>
<pre><code>2020-12-04T04:30:53.084Z    dockerd    Calling GET /v1.40/containers/json?all=1&amp;filters=%7B%22name%22%3A%7B%22test%22%3Atrue%7D%7D
2020-12-04T04:30:53.084Z    dockerd    Calling HEAD /_ping
2020-12-04T04:30:53.468Z    dockerd    Calling POST /v1.40/containers/33f7bdc9a123/kill?signal=KILL
2020-12-04T04:30:53.468Z    dockerd    Sending kill signal 9 to container 33f7bdc9a1239a3e1625ddb607a7d39ae00ea9f0fba84fc2cbca239d73c7b85c
2020-12-04T04:30:53.468Z    dockerd    Calling POST /v1.40/containers/2bfc4bf27ce9/kill?signal=KILL
2020-12-04T04:30:53.468Z    dockerd    Sending kill signal 9 to container 2bfc4bf27ce93b1cd690d010df329c505d51e0ae3e8d55c888b199ce0585056b
2020-12-04T04:30:53.468Z    dockerd    Calling POST /v1.40/containers/bef1570e5655/kill?signal=KILL
2020-12-04T04:30:53.468Z    dockerd    Sending kill signal 9 to container bef1570e5655f902cb262ab4cac4a873a27915639e96fe44a4381df9c11575d0
...</code></pre><p>Here we can see the requests to kill each container, and that <code>SIGKILL</code>is sent almost immediately to each container.</p>
<p>Heres some log entries seen around 30 seconds after executing <code>docker kill</code>:</p>
<pre><code>...
2020-12-04T04:31:32.308Z    dockerd    Releasing addresses for endpoint test-1's interface on network bridge
2020-12-04T04:31:32.308Z    dockerd    ReleaseAddress(LocalDefault/172.17.0.0/16, 172.17.0.2)
2020-12-04T04:31:32.308Z    dockerd    Released address PoolID:LocalDefault/172.17.0.0/16, Address:172.17.0.2 Sequence:App: ipam/default/data, ID: LocalDefault/172.17.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65529, Sequence: (0xfa000000, 1)-&gt;(0x0, 2046)-&gt;(0x1, 1)-&gt;end Curr:202
2020-12-04T04:31:32.308Z    dockerd    Releasing addresses for endpoint test-5's interface on network bridge
2020-12-04T04:31:32.308Z    dockerd    ReleaseAddress(LocalDefault/172.17.0.0/16, 172.17.0.6)
2020-12-04T04:31:32.308Z    dockerd    Released address PoolID:LocalDefault/172.17.0.0/16, Address:172.17.0.6 Sequence:App: ipam/default/data, ID: LocalDefault/172.17.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65530, Sequence: (0xda000000, 1)-&gt;(0x0, 2046)-&gt;(0x1, 1)-&gt;end Curr:202
2020-12-04T04:31:32.308Z    dockerd    Releasing addresses for endpoint test-3's interface on network bridge
2020-12-04T04:31:32.308Z    dockerd    ReleaseAddress(LocalDefault/172.17.0.0/16, 172.17.0.4)
2020-12-04T04:31:32.308Z    dockerd    Released address PoolID:LocalDefault/172.17.0.0/16, Address:172.17.0.4 Sequence:App: ipam/default/data, ID: LocalDefault/172.17.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65531, Sequence: (0xd8000000, 1)-&gt;(0x0, 2046)-&gt;(0x1, 1)-&gt;end Curr:202
2020-12-04T04:31:32.308Z    dockerd    Releasing addresses for endpoint test-2's interface on network bridge
2020-12-04T04:31:32.308Z    dockerd    ReleaseAddress(LocalDefault/172.17.0.0/16, 172.17.0.3)
2020-12-04T04:31:32.308Z    dockerd    Released address PoolID:LocalDefault/172.17.0.0/16, Address:172.17.0.3 Sequence:App: ipam/default/data, ID: LocalDefault/172.17.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65532, Sequence: (0xd0000000, 1)-&gt;(0x0, 2046)-&gt;(0x1, 1)-&gt;end Curr:202</code></pre><p>These logs don't give us a full picture of everything dockerd is doing, but this makes it seem like dockerd might be spending a lot of time releasing network addresses.</p>
<p>At this point in my adventure, I decided it was time to start digging into docker engine's source code and build my own version of dockerd with some extra logging.</p>
<p>I started out by looking for the codepath that handles container kill requests. I added some extra log messages with timings of different spans and eventually I found out where all this time was being spent:</p>
<p><code>SIGKILL</code> is sent to the container and then before responding to the HTTP request, the engine waits for the container to no longer be running (<a href="https://github.com/docker/engine/blob/ab373df1125b6002603456fd7f554ef370389ad9/daemon/kill.go#L174">source</a>)</p>
<pre><code>    &lt;-container.Wait(context.Background(), containerpkg.WaitConditionNotRunning)</code></pre><p>The <code>container.Wait</code> function returns a channel which receives the exit code and any error from the container. Unfortunately, to get the exit code and error, a lock on the interal container struct must be acquired. (<a href="https://github.com/docker/engine/blob/ab373df1125b6002603456fd7f554ef370389ad9/container/state.go#L212-L233">source</a>)</p>
<pre><code>  ...

    <span>go</span> <span><span>func</span><span>()</span></span> {
        <span>select</span> {
        <span>case</span> &lt;-ctx.Done():
            
            resultC &lt;- StateStatus{
                exitCode: <span>-1</span>,
                err:      ctx.Err(),
            }
            <span>return</span>
        <span>case</span> &lt;-waitStop:
        <span>case</span> &lt;-waitRemove:
        }

        s.Lock() 
        result := StateStatus{
            exitCode: s.ExitCode(),
            err:      s.Err(),
        }
        s.Unlock()

        resultC &lt;- result
    }()

    <span>return</span> resultC

  ...</code></pre>
<p>As it turns out, this container lock is held while cleaning up network resources and the <code>s.Lock()</code> above ends up waiting for a long time. This happens inside <a href="https://github.com/docker/engine/blob/ab373df1125b6002603456fd7f554ef370389ad9/daemon/monitor.go#L27-L103"><code>handleContainerExit</code></a>. The container lock is held for the duration of the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.repl.it/killing-containers-at-scale">https://blog.repl.it/killing-containers-at-scale</a></em></p>]]>
            </description>
            <link>https://blog.repl.it/killing-containers-at-scale</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992627</guid>
            <pubDate>Mon, 01 Feb 2021 19:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast Incremental Builds with Speculation and Cancellation]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25992590">thread link</a>) | @stuhood
<br/>
February 1, 2021 | https://blog.pantsbuild.org/fast-incremental-builds-speculation-cancellation/ | <a href="https://web.archive.org/web/*/https://blog.pantsbuild.org/fast-incremental-builds-speculation-cancellation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<!--kg-card-begin: html--><!--kg-card-end: html--><!--kg-card-begin: markdown-->
<p>Because they decouple your iteration time from the total size of your codebase, fast incremental re-builds are critical in large codebases and monorepos. As discussed in <a href="https://blog.pantsbuild.org/dependency-inference/">our post about dependency inference</a>, having fine-grained dependency information reduces the amount of work that is invalidated after an edit by ignoring irrelevant changes.</p>
<p>But modern build tools are also able to avoid wasted work when a file that your build depends on <em>has</em> (maybe!) changed. And thanks to its deep support for cancellation and side-effect free execution model, <a href="https://www.pantsbuild.org/">Pants</a> is able to further reduce re-build latency by speculatively re-executing work!</p>

<p>In many cases while building your code, files will change in ways that don’t actually affect the outcome of the build. Common examples are cases like changing comments in compiled or code-generated languages (Java and Protobuf, for example), or touching files on disk without actually editing their contents. In these cases, avoiding running the dependent compiles or other logic is a significant benefit.</p>
<p>Pants uses SHA256 hashing and deep equality to determine whether <code>@rules</code> (used to write <a href="https://www.pantsbuild.org/docs/rules-api-concepts">build logic in Pants</a>) and processes need to re-run, but because build processes should always be deterministic, we can more quickly provide incremental results in these cases. To do so, Pants supports what the <a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems.pdf">Build Systems à la Carte</a> paper calls “early cutoff”.</p>
<p>Early cutoff (also known as “cleaning”) is implemented in Pants by deciding whether to re-run an <code>@rule</code> (after a file that it depends on -- likely indirectly -- has changed on disk) by comparing a record of previous “generation” values for each dependency <code>@rule</code> to up-to-date generation values. This generation value is incremented each time the previous output value of a <code>@rule</code> is not identical to its new output value: it acts as a very memory efficient record of which versions of its dependencies an <code>@rule</code> used. When the generation values of all of an <code>@rule</code>s dependencies are equal to those from its previous run, we know that it does not need to re-run, and that its previous output value is still valid. When <code>@rule</code>s are cleaned this way, it’s very likely that their dependents in the graph will be cleaned as well, which “cuts off” the need to run any <code>@rule</code> logic, dramatically reducing runtime.</p>
<p>Pants’ dependency inference (for Python; elsewhere soon!) also presents a really useful case for early cutoff. Dependency inference extracts import statements from the content of individual files, but while editing your code, the vast majority of your edits to files will be to non-import statements. This means that the dependency inference <code>@rule</code>s will very frequently trigger early cutoff!</p>

<p>But the combination of dependency inference and cleaning is interesting for another reason: because the dependencies of your code fundamentally drive “which” <code>@rule</code> logic needs to run (“what do I need to compile before compiling this module?”, “which files need to be in the sandbox for this test?”, etc), the output of the dependency inference <code>@rule</code>s will very frequently be a <a href="https://en.wikipedia.org/wiki/Data_dependency">data dependency</a> of other <code>@rule</code> logic … and dependency inference represents a very fundamental data dependency!</p>
<p>Neil Mitchell’s <a href="https://neilmitchell.blogspot.com/2020/11/data-types-for-build-system-dependencies.html">excellent blog post on the topic of dependencies in build systems</a> introduces a particularly costly example of ignoring a data dependency: a computed “is_optimized” flag might fundamentally affect which (and how much!) work needs to be done in a build. If between two builds, the computed value of <code>is_optimized</code> changes from <code>True</code> to <code>False</code> (potentially representing an order of magnitude difference in runtime), it’s particularly critical that a user does not need to wait for the stale result before the updated result is computed.</p>
<p>Pants’ monadic plugin API allows <code>@rule</code> authors to write natural, seemingly imperative code. But as described in Mitchell’s post, the existence of data dependencies between <code>@rule</code> outputs in a monadic build system would suggest that Pants needs to be careful to clean a graph of <code>@rule</code>s in the order that dependencies were originally requested in. And dependency inference is no exception: in the build after an import statement has been removed from your code, Pants must not force you to wait for that removed dependency to be rebuilt!</p>
<p>But this is potentially problematic: data dependencies are costly because they force ordering. Dependency inference requires parsing the AST of your code to extract import statements: a data dependency between extracting the imports of a file and running a test in that file (for example), implies that while cleaning the <code>@rule</code> graph after that file has changed, we should not start running the test until after we’ve finished extracting imports. And as mentioned before, the imports of your test file are much less likely to have changed than its other content, meaning that an infrequently changing output blocks computing the key result of your build: whether your test passed!</p>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><!--kg-card-end: html--><!--kg-card-begin: markdown--><p>This represents an interesting challenge: is it possible for Pants to preserve the excellent usability properties of dependency inference (avoiding needing to maintain redundant, potentially-stale copies of your import statements in both your code and in <code>BUILD</code> files), without forcing the running of a test to wait for import parsing? Yes, we can: via speculative execution!</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown-->
<p><a href="https://en.wikipedia.org/wiki/Speculative_execution">Speculative execution</a> (aka “speculation”) is a technique used (somewhat infamously: more on that later) in CPUs, but which is also employed when sending RPCs in distributed systems (where it might be referred to as using <a href="https://blog.acolyer.org/2015/01/15/the-tail-at-scale/">hedged requests</a>).</p>
<p>Applying speculative execution to reducing the cost of data dependencies means applying prior knowledge about the likelihood that a data-dependency will have a particular output value to decide to eagerly launch a data-dependent task with the predicted input <em>before</em> its data-dependency has completed. Concretely: it means being able to launch the extraction of imports <em>and</em> the running of the test <em>in parallel</em>!</p>
<p>And so: Pants uses its record of the generation values of the previous build to <a href="https://github.com/pantsbuild/pants/pull/11308">clean the <code>@rule</code> graph speculatively</a>, sidestepping the data dependency in incremental rebuilds!</p>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><!--kg-card-end: html--><!--kg-card-begin: markdown-->
<p>To ensure correctness, safe speculation requires that speculated work never has side-effects (which is where speculation in CPUs <a href="https://en.wikipedia.org/wiki/Speculative_execution#Security_vulnerabilities">went astray</a>). And reducing speculation’s costs requires the ability to quickly and cleanly cancel speculated work when you determine that your guesses were incorrect.</p>
<p>Fortunately, both purity (the absence of side-effects) and interruptibility are already fundamental to the architecture of Pants 2.0!</p>
<h2 id="pure">Pure</h2>
<p>Pants’ <code>@rule</code> API was designed from the ground up to be side-effect free. With the exception of specially classified “Goal” rules (which “finalize” the run from an end user’s perspective), <code>@rule</code>s are intended to be <a href="https://en.wikipedia.org/wiki/Pure_function">pure</a> coroutines.</p>
<p><code>@rule</code>s consume specialized APIs that present <a href="https://www.pantsbuild.org/v2.2/docs/rules-api-file-system">an atomic, read-only view of the filesystem</a>, and precise tracking of <code>@rule</code> dependencies (down to the level of syscalls to expand symlinks, etc) ensures that -- although the filesystem might look like a global static -- the relevant <code>@rule</code>s can be restarted in cases where files change during a run to preserve atomicity guarantees.</p>
<p>Build tools <a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems.pdf">“excel”</a> at running processes: your typechecker, compiler, code generator, test, etc. But most processes that run during your build produce outputs, and ensuring that these outputs are not observable side-effects is an interesting challenge! To isolate processes, Pants fundamentally operates on content-addressable collections of files (known as <code>Snapshots</code>, and implemented using the Bazel <a href="https://github.com/bazelbuild/remote-apis/blob/9e72daff42c941baaf43a4c370e2607a984c58a7/build/bazel/remote/execution/v2/remote_execution.proto#L819-L857">Remote APIs</a>) rather than on filesystem state. This means that process inputs and outputs are always immutable values, and never references into a mutable store like the filesystem.</p>
<p>Rather than writing out the results of processes into a shared mutable working directory as is common in many build tools, Pants stores all process inputs and outputs in a database (backed locally by <a href="https://symas.com/lmdb/">LMDB</a>, and remotely by a Remote API <a href="https://github.com/bazelbuild/remote-apis/blob/9e72daff42c941baaf43a4c370e2607a984c58a7/build/bazel/remote/execution/v2/remote_execution.proto#L185-L257">CAS</a> instance), and executes processes inside of chroots. Only the final results that a user directly requested via a high level “goal” (<code>fmt</code>, <code>test</code>, <code>package</code>, etc) are actually materialized as a visible side-effect in their workspace.</p>
<p>This fundamental isolation is critical to speculation, because it means that Pants can always spawn multiple copies of processes, without worrying that they will collide or otherwise observe one-another’s results!</p>
<h2 id="interruptible">Interruptible</h2>
<p>Being free of side-effects eliminates one common challenge of providing interruptibility: there is no need to “clean up” after canceled processes, because their execution could not affect any mutable resources in ways that might need to be reverted. But the other requirement is ensuring that you don’t waste CPU time on those trees as they fall in that unobserved forest: and cancelling work once you’ve launched it can be, in-and-of-itself, tricky.</p>
<p>Native threads in all common operating systems are eager: once you’ve launched them they run to completion, killing them without their cooperation is a <a href="https://unix.stackexchange.com/questions/403988/how-to-kill-an-individual-thread-under-a-process-in-linux">risky proposition</a>, and getting their cooperation at a fine-grained level would require peppering your code with “<code>is_it_time_to_give_up()</code>?” checks.</p>
<p>Luckily, the core of Pants is written in Rust, and -- rather than using native threads -- uses <a href="https://tokio.rs/">tokio</a> to support running thousands of lightweight user-space tasks. Due to their <a href="https://rust-lang.github.io/async-book/02_execution/02_future.html">pull-based/lazy</a> design, Rust Futures (which back its excellent <code>async/await</code> feature) are inherently cancellable: with <a href="https://docs.rs/tokio/1.0.1/tokio/fn.spawn.html">rare</a> and <a href="https://docs.rs/tokio/1.0.1/tokio/process/index.html#droppingcancellation">well-noted</a> exceptions, dropping a <code>Future</code> value recursively cancels all associated work at its next <code>await</code>.</p>
<p>And because we use tokio to spawn processes, receive UNIX signals, interact with the filesystem, communicate with remote servers, etc, this deep support for cancellation pervades Pants’ APIs, and continuously minimizes the overhead of speculation.</p>
<p>Another very visible feature enabled by inherent support for cancellation is getting the expected behavior when a user running Pants …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.pantsbuild.org/fast-incremental-builds-speculation-cancellation/">https://blog.pantsbuild.org/fast-incremental-builds-speculation-cancellation/</a></em></p>]]>
            </description>
            <link>https://blog.pantsbuild.org/fast-incremental-builds-speculation-cancellation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992590</guid>
            <pubDate>Mon, 01 Feb 2021 19:30:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disinformation: The Game of Belief is now a War]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25992531">thread link</a>) | @ztratar
<br/>
February 1, 2021 | https://www.zachtratar.com/Disinformation-The-Game-of-Belief-is-now-a-War.html#.YBhVpHdKjUI | <a href="https://web.archive.org/web/*/https://www.zachtratar.com/Disinformation-The-Game-of-Belief-is-now-a-War.html#.YBhVpHdKjUI">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>A mass hijacking of our minds is currently underway. Perhaps you’ve felt it for a while now.</p>

<p>Underlying facts seem increasingly rare, “the truth” is debated back and forth without progress, and people’s behaviors continuously bend towards the irrational. It’s all so weirdly ironic — aren’t we supposed to be living in the so-called “Information Age”?</p>

<p>What the heck happened?</p>

<p>Well, we’re all human &amp; sometimes believe in things that aren’t true. It’s a complicated psychological weakness — after all, “what is truth” is a hard question! As we seek truth as individuals, we’re lucky that most of our personal misjudgments are unique and relatively harmless. At scale, however, people have learned our psychology becomes predictable. And exploitable.</p>

<p>Individuals and organizations — especially the media, political parties and politicians — above all seek to increase their power and status. Thus, in their communication, their primary goal is not to tell the truth or describe reality, but instead to win the game they are playing. This incentive leads them to build their audience by engaging in disinformation campaigns and “<em>Narrative Warfare”</em> tactics<em>.</em> They create stories &amp; perceptions — some real, some fake — to manipulate our emotions and align us with <em>their</em> narrative &amp; <em>their</em> goals.</p>

<p>Information, reality, and truth… none of them really matter as long as we end up joining their side and reinforcing their power.</p>

<p>Although mass manipulation is a trend throughout all of history, it turns out that giving everyone smartphones and instant access to every other human <em>changes everything</em>. The internet is jet fuel. Through Facebook and online media, disinformation now spreads to millions within minutes, is targeted to the specific people who will believe it, and evolves social groups to purge skeptics.</p>

<p>Over time, these attacks on our information ecosystem turn many people into fact-resistant conspiracy theorists and radicals — their identity and daily thoughts become dominated by a tribal battles they believe they are fighting. Once enough people radicalize, Politicians need their votes and are forced to radicalize as well to get elected. Finally, the cycle completes: once in power, politicians opt to accelerate Narrative Warfare to reinforce their power instead of summoning the courage to lead. This is what we have seen play out in the US over the past decade and it’s a downward spiral we must reverse. It threatens the core foundations of successful democracy: empathy, collaboration, useful debate, and truthful speech.</p>

<p>Unfortunately, <a href="https://www.zachtratar.com/voter-fraud-debunk.html#.YBcYCelKjUI">I’ve met these politicians</a> and observed these social patterns. From 2008 to 2010 I founded a political polling company and learned how political parties didn’t just want your data — they wanted to know who your family was, how to convince you of things, and which buttons to push. I got out of politics. Then, from 2011 to 2014 I was the first employee at a well-funded social media startup. We walked into the office every day desiring to “create community”, and even though some of us were educated in psychology, we were totally naive. No where in our heads did we imagine the acceleration of misinformation and disinformation at scale. While we only reached millions of people, Facebook successfully spread to billions and doubled-down on exploitable technologies.</p>

<p>So now we’re all living in manipulated realities, attacking each other on a daily basis, and often resorting to conspiratorial thinking. To get out of this, we all have a responsibility to grow wiser to “truth”, mitigate tribalism and take back control of our minds.</p>

<p>First, let’s start by better understanding the war we’re in.</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ol>
  <li>Complexity of Truth</li>
  <li>Psychology of Truth</li>
  <li>Group Dynamics of Truth</li>
  <li>Societal Truth</li>
  <li>The Game of Belief</li>
  <li>Narrative Warfare</li>
  <li>Technological Acceleration</li>
  <li>What Next?</li>
</ol>

<h2 id="complexity-of-truth">Complexity of Truth</h2>

<p>We attempt to determine truth as individuals by making judgements, and these judgements are all based on information we encounter in various forms (e.g. school, books, facebook posts, conversations, etc.</p>

<p>Truth is complex and tricky, though — philosophers call its study “<a href="https://plato.stanford.edu/entries/epistemology/">epistemology</a>,” which roughly translates to “the reason of knowledge and understanding”.</p>

<blockquote>
  <p>“Any fool can know. The point is to understand”</p>

  <p><span><em>-</em> Albert Einstein</span></p>
</blockquote>

<p>To know “the truth” you need not only good information, but all of the context required to create a full understanding. Without context, you are viewing only one piece to a larger puzzle. Most communication — especially short-form communication on the internet — is missing substantial context, which leads to misinterpretation.</p>

<p>Ask yourself two questions:</p>

<ul>
  <li>How often are your words on the internet fully understood and interpreted correctly by other people?</li>
  <li>How often do you think, when you’re reading the news, you’re getting robust context?</li>
</ul>

<p>The more complex a topic — like hedge fund market dynamics — the more context is necessary to create a full understanding. Since civilization is advanced, the problems of the world are all quite complex, and people need to spend the extra care to gather context. With some topics, such as “building a growing economy”, the complexity is so staggeringly high that no single human can ever understand the entire problem. Literally <em>no one knows the full truth.</em></p>

<blockquote><p lang="en" dir="ltr">History of epistemology:<br>300 BC: you can't know anything.<br>600: some stuff you can.<br>1600: no, not even that.<br>1800: what about this?<br>2000: no.</p>— Existential Comics (@existentialcoms) <a href="https://twitter.com/existentialcoms/status/857396828110675968?ref_src=twsrc%5Etfw">April 27, 2017</a></blockquote>


<p>Even if you understand complexity and have “done your research”, when are you done? There are always “unknown unknowns” — context and perspectives out there that you didn’t even know you had to research in the first place. How unfair!</p>

<p>Thus, “the full truth” is never fully attainable by anyone. Nevertheless, at some point we accept the reality we perceive, make judgements, and take action anyways. There’s no other option — we must try to seek our personal truth over time. As is said “the Truth will set you free,” so we must learn to wade through the complexity and our manage our personal biases.</p>

<div>

  <p><strong>Example:</strong> Recently GameStop has been in the news for it’s skyrocketing stock after a historic short squeeze, led by regular retail traders from Reddit, drove hedge funds to lose billions of dollars. Robinhood and other brokers limited $GME trading, and there was a massive backlash against the apps. The narrative? Robinhood was obeying orders from Billionaire Hedge Funds and the system was rigged. Both Ted Cruz and <a href="https://twitter.com/AOC/status/1354830697459032066">AOC</a> seem to agree with that narrative.
Context that came out later:</p>

  <ul>
    <li>Robinhood faced a liquidity crunch and <a href="https://www.businessinsider.com/robinhood-ceo-defends-gamestop-amc-nokia-trading-restrictions-2021-1">proactively borrowed several hundred million dollars</a>. They then limited trading so they could afford financial settlement with acceptable risk. <a href="https://www.foxbusiness.com/markets/robinhood-ceo-refutes-conspiracy-theory-hedge-funds-prompted-gamestop-trading-halt">It wasn’t that they wanted to help Billionaires</a>, but instead survive as a business.</li>
    <li>Regular retail traders were the loud voices in the news, but other <a href="https://www.wsj.com/articles/gamestop-frenzy-puts-spotlight-on-trading-giant-citadel-securities-11612089000">hedge funds aligned with them to exploit the stock</a>. This wasn’t as clean as “Wall Street vs Main Street,” as many wanted to believe.</li>
  </ul>

</div>

<h2 id="psychology-of-truth">Psychology of Truth</h2>

<p>We all have our flaws. Unfortunately — you and I — we’re absolutely terrible at determining what is real from what isn’t.</p>

<p>Some of our psychological vulnerabilities:</p>

<ul>
  <li><strong>Confirmation Bias</strong>: Once we make judgements, we stick with them, and any information that appears to support our worldview will be welcomed instantly — even if it’s a stretch. Evidence to the contrary is ignored, and even causes us, on average, to irrationally <a href="https://www.newyorker.com/magazine/2017/02/27/why-facts-dont-change-our-minds">dig into their own beliefs</a> instead of question them.</li>
  <li><strong>Self-gain</strong>: We look for information to help us increase our status. We share information we think others will like, because then they’ll like us.</li>
  <li><strong>Entertainment</strong>: The more sensationalist and crazy sounding the news, the more we are likely to engage with it, talk about it, and share it.</li>
  <li><strong>Fear</strong>: If something makes us fearful, most people will first <em>assume it is true</em> to hedge risk. After all, if it’s not true then there’s nothing to worry about!</li>
  <li><strong>Lack of Time &amp;</strong> <strong>Laziness</strong>: It’s a luxury to have time to do your own research. Even if you have the time, do you want to read a 5 sentence summary or a 10 page paper? Short content captures attention more easily, but leaves no room for nuance or context. This is best shown by the fact that we only read headlines — <a href="https://www.chicagotribune.com/business/blue-sky/ct-share-this-link-without-reading-it-ap-bsi-20160618-story.html">59% of all social media shares happen without reading the article</a>.</li>
  <li><strong>Repetition Reinforcement:</strong> if we hear something multiple times, we are more likely to believe it. This was the core propaganda technique of the Nazi party.</li>
  <li><strong>Incorrect Focus</strong>: Too much information about the wrong thing distracts us. If others talk about a single aspect of a topic, we naturally assume other aspects are less meaningful. This happens in science, for example, where the topics discussed are only those which are well funded.</li>
  <li><strong>Hero Effect:</strong> We are inclined to believe powerful people are out to get us. We actively want to be a protagonist against a planned, well-executing group of powerful, evil people. For example, <a href="https://www.pewresearch.org/fact-tank/2020/07/24/a-look-at-the-americans-who-believe-there-is-some-truth-to-the-conspiracy-theory-that-covid-19-was-planned/ft_20-07-15_conspiracies_new_01/">40-50% of less educated Americans think COVID was intentionally planned by powerful people.</a></li>
  <li><strong>Short Working Memory:</strong> To hold nuanced views we have to be able to hold multiple topics in working, short-term memory. But when we are bombarded with hyper-active amounts of information, nothing stays in working memory long enough to create nuanced views.</li>
</ul>

<p>And that’s just to name a few! There are hundreds more, such as <a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases">this list of 100+ cognitive biases</a>.</p>

<p>For most of us, what we believe is more predicated on our psychological vulnerabilities rather than what is true and real. This is why the scientific method was so revolutionary — it’s a framework for determining truth without requiring trust, faith, or belief in other people.</p>

<p>We all suck at determining truth.</p>

<h2 id="group-dynamics-of-truth">Group Dynamics of Truth</h2>

<p>Things get really chaotic once you move beyond the individual psychological level and into groups. From a very young age, we all seek to be accepted as part of an in-group — a community. It’s hard-wired into us.</p>

<p>In …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.zachtratar.com/Disinformation-The-Game-of-Belief-is-now-a-War.html#.YBhVpHdKjUI">https://www.zachtratar.com/Disinformation-The-Game-of-Belief-is-now-a-War.html#.YBhVpHdKjUI</a></em></p>]]>
            </description>
            <link>https://www.zachtratar.com/Disinformation-The-Game-of-Belief-is-now-a-War.html#.YBhVpHdKjUI</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992531</guid>
            <pubDate>Mon, 01 Feb 2021 19:25:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unbroken Enigma Message]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25992462">thread link</a>) | @akakievich
<br/>
February 1, 2021 | https://enigma.hoerenberg.com/index.php?cat=Unbroken | <a href="https://web.archive.org/web/*/https://enigma.hoerenberg.com/index.php?cat=Unbroken">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://enigma.hoerenberg.com/index.php?cat=Unbroken</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992462</guid>
            <pubDate>Mon, 01 Feb 2021 19:20:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we develop FDA-compliant machine learning algorithms]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 34 (<a href="https://news.ycombinator.com/item?id=25992363">thread link</a>) | @yshrestha
<br/>
February 1, 2021 | https://innolitics.com/articles/machine-learning-development-for-medical-devices/ | <a href="https://web.archive.org/web/*/https://innolitics.com/articles/machine-learning-development-for-medical-devices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    
    <p>
      by Grace Adams and Yujan Shrestha on January 26, 2021
    </p>
    
    <p>Want to know how we develop safe, effective, and FDA compliant machine learning algorithms? This article describes how we develop machine learning algorithms, points out common pitfalls, and makes documentation recommendations.</p>

<p>When developing a machine learning or AI algorithm, it’s easy to become overly focused on making the best model possible. While model performance is important, to incorporate the model into a commercial medical device, you’ll need to be able to demonstrate to the FDA that the model is safe and effective. Therefore, it’s critical to thoroughly document the algorithm’s development lineage in your design history file. The process outlined in this article will help you do this. We’ve used it to develop AI algorithms within a recently 510(k)-cleared class-II medical device for one of our clients.</p>

<p>The FDA released its <a href="https://www.fda.gov/media/145022/download"><em>Artificial Intelligence/Machine Learning (AI/ML)-Based Software as a Medical Device (SaMD) Action Plan</em></a> in January of 2021. In it, they discuss upcoming changes to their approach for regulating ML-based medical devices. The exact details aren’t public, but we suspect following a consistent development process will be part of it.</p>
      <h2 id="focus-on-process-documentation">
        
        
          Focus on process documentation <a href="#focus-on-process-documentation">🔗</a>
        
        
      </h2>

<p>Our AI development process includes generating reports that detail the input data, model performance, and model selection process. These reports streamline model development by helping developers recognize and correct some of the most common pitfalls in algorithm development, thereby increasing confidence in the AI/ML algorithm’s safety and efficacy. As a convenient side effect, these reports are a powerful tool when designing a QMS suitable for AI and navigating the FDA clearance process.</p>
    
      <h3 id="some-common-pitfalls-we-have-identified-are">
        
        
          Some common pitfalls we have identified are: <a href="#some-common-pitfalls-we-have-identified-are">🔗</a>
        
        
      </h3>

<ul>
  <li>Laser-focus on chasing higher accuracy metrics and forgetting about the business, clinical, and regulatory context</li>
  <li>Errors in data import and preprocessing</li>
  <li>Clinically unrealistic data augmentation</li>
  <li>Algorithm performance metrics—such as the Dice score—are not a perfect proxy to clinical performance but are treated as such</li>
  <li>Data leakage or improper training/validation splits leads to undetectable overfitting and a false sense of stellar algorithm performance</li>
  <li>Using data that was acquired with non-clinical (research) protocols that are too different from the device’s intended use thereby leading to regulatory risk. <sup><a href="#acknowledgments">1</a></sup></li>
  <li>Not being aware of sampling bias in the data thereby leading to regulatory risk. For example, certain age groups may be underrepresented or certain scanner vendors may be overrepresented. <sup><a href="#acknowledgments">1</a></sup></li>
</ul>
    
      <h3 id="these-pitfalls-can-be-mitigated-by-the-following-reports">
        
        
          These pitfalls can be mitigated by the following reports: <a href="#these-pitfalls-can-be-mitigated-by-the-following-reports">🔗</a>
        
        
      </h3>

<ul>
  <li>Input Verification Report</li>
  <li>Data Augmentation Quality Assurance Report</li>
  <li>Model Performance Report</li>
  <li>Model Comparison Report</li>
</ul>
    
      <h3 id="input-verification-report">
        
        
          Input Verification Report <a href="#input-verification-report">🔗</a>
        
        
      </h3>

<p>The input verification report should visualize the dataset as close to the model training step as possible. A common source of error can be simple data processing errors. This report is also an excellent way to verify the quality of the data. If the input data is not very accurate to start with, it will be hard to train an accurate model. In other words, “garbage in equals garbage out.”</p>

<p><a href="http://innolitics.com/innolitics.github.io.downloads/2021-01-26-machine-learning-development-for-medical-devices/Input_Verification_Report.pdf">Click here to view an example</a></p>
    
      <h3 id="data-augmentation-quality-assurance-qa-report">
        
        
          Data Augmentation Quality Assurance (QA) Report <a href="#data-augmentation-quality-assurance-qa-report">🔗</a>
        
        
      </h3>

<p>Data augmentation is a powerful technique that effectively increases the size of your dataset, reducing the risk of overfitting and increasing accuracy. However, going overboard with data augmentation techniques could distort the images beyond realistic boundaries. The data augmentation QA report takes a random sample of the dataset and produces several augmentations of that image and its annotations. This report allows you to confirm the augmented images are still clinically valid and that the annotations—such as segmentations and fiducial markers—are augmented properly.</p>

<p><a href="http://innolitics.com/innolitics.github.io.downloads/2021-01-26-machine-learning-development-for-medical-devices/Data_Augmentation_QA_Report.pdf">Click here to view an example</a></p>
    
      <h3 id="model-performance-report">
        
        
          Model Performance Report <a href="#model-performance-report">🔗</a>
        
        
      </h3>

<p>The model performance report can vary greatly depending on the problem. However, there are four essential properties that this report should have:</p>

<ol>
  <li>Training graphs: These graphs should show how the accuracy and loss metrics develop from epoch to epoch for the training and validation set. They can help you determine if the model converges, when it begins to overfit, and the likelihood of data leakage.</li>
  <li>Statistics table: This table shows any relevant information for the model, such as the training set accuracy at the end of the last training epoch, the validation set accuracy, and the number of parameters in the model.</li>
  <li>Model Architecture: Information about the structure of the model itself. Tensorflow has a built-in function for visualizing this quickly.</li>
  <li>Visualized Inference: This portion of the report will look a lot like the input verification report for the validation set, but it will also include both the human and AI annotations. We place the worst performers at the top of the report to help focus analysis and subsequent iteration.</li>
</ol>

<p><a href="http://innolitics.com/innolitics.github.io.downloads/2021-01-26-machine-learning-development-for-medical-devices/Model_Output_Verification_Report.pdf">Click here to view an example</a></p>
    
      <h3 id="model-comparison-report">
        
        
          Model Comparison Report <a href="#model-comparison-report">🔗</a>
        
        
      </h3>

<p>During the development of any ML model, there are likely to be hundreds of models trained, each with different hyperparameters, data augmentations, or even different architecture configurations. Additionally, model improvements are likely to be made in the post-market phase as more data is acquired and newer ML techniques are discovered. Therefore, it is essential to have a way to compare multiple models so that you can empirically determine which model performs better. The model comparison report includes the training graphs for each of the models, a statistics table for easy model comparison, and the inferences from each of the models on the same validation dataset. Visualizing all of the different models’ inferences is particularly important since the loss function alone is not the full story. For example, a model with worse metrics could be because it is actually finding more human annotation errors than the others.</p>

<p><a href="http://innolitics.com/innolitics.github.io.downloads/2021-01-26-machine-learning-development-for-medical-devices/Models_Comparison_Report.pdf">Click here to view an example</a></p>
    
      <h2 id="the-process">
        
        
          The Process <a href="#the-process">🔗</a>
        
        
      </h2>

<p>The process we have developed is rooted in the idea that good machine learning practices will lead to algorithms that will generalize to a real clinical setting and thus be safe and reliable. Here I’ll use an example project, segmenting the lungs in chest x-rays, to go step-by-step through our development process. I’ll be detailing the use of the four reports and pointing out common sources of errors along the way.</p>
    
      <h2 id="step-1-problem-definition">
        
        
          Step 1: Problem definition <a href="#step-1-problem-definition">🔗</a>
        
        
      </h2>

<p>When beginning any project, it is vital to understand the goals and limitations. We work closely with our clients to make sure that we can meet all their requirements. Some important considerations are:</p>

<ul>
  <li>Speed: Should this run on an embedded device? Should inference be possible without a GPU? How many concurrent inferences are necessary and on what hardware?</li>
  <li>Accuracy: What accuracy do we think is necessary for a clinically useful model? If an algorithm suggests a segmentation for the physician to edit, the minimum accuracy threshold is probably lower than if the algorithm’s segmentations are used directly for diagnosis. A risk analysis coupled with a literature review can help determine this threshold.</li>
  <li>Development budget: Where should we be on the 80/20 rule? Each .9% added to the accuracy target will scale the cost exponentially. Should we use off the shelf architectures or something more customized? How fast do we need to develop the model? Is this a feasibility study, or do we need to observe more rigorous medical device design controls?</li>
</ul>

<p><em>Example: For the Lung Segmentation problem, it doesn’t need to run on an embedded device and should always have access to a GPU. The goal is to make the model as accurate as possible, but there will usually be several inferences running concurrently. Ideally, the model will be as small as possible without sacrificing accuracy, as inferences time is related to model size. The budget and timeline are limited, so existing architecture implementations are preferred.</em></p>
    
      <h2 id="step-2-get-data">
        
        
          Step 2: Get data <a href="#step-2-get-data">🔗</a>
        
        
      </h2>

<p>The data used to train and test the model is an essential part of ML development. If a client already has a dataset ready to go, that’s great! But if not, we are happy to connect them with tools and services for image annotation as needed.</p>

<p><em>Example: I chose to go with a dataset from Kaggle, a machine learning hub where users can find and publish datasets and other resources to advance the data science field. Link to the dataset I used: https://www.kaggle.com/nikhilpandey360/chest-xray-masks-and-labels</em></p>
    
      <h2 id="step-3-data-partition-strategy">
        
        
          Step 3: Data partition strategy <a href="#step-3-data-partition-strategy">🔗</a>
        
        
      </h2>

<p>Once we have a dataset, there are several data processing steps to get it into a form readily consumable by ML. Usually, this involves splitting the dataset into training, validation, and test sets.</p>

<p>First, we work with our client to set aside a test set. The test set should be reasonably representative of the data commonly seen in clinical scenarios. It will not be used at all during model training. Instead, we will use it to see how well the algorithm performs on unseen data. It will also be the “acceptance criteria” used for the final deliverable and to verify the validity of incremental changes in future versions of the model.</p>

<p>After setting aside the test set, we split the remaining data into …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://innolitics.com/articles/machine-learning-development-for-medical-devices/">https://innolitics.com/articles/machine-learning-development-for-medical-devices/</a></em></p>]]>
            </description>
            <link>https://innolitics.com/articles/machine-learning-development-for-medical-devices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992363</guid>
            <pubDate>Mon, 01 Feb 2021 19:14:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Docker Images the Proper Way]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25992209">thread link</a>) | @dreamy_borg
<br/>
February 1, 2021 | https://martinheinz.dev/blog/42 | <a href="https://web.archive.org/web/*/https://martinheinz.dev/blog/42">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://martinheinz.dev/blog/42</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992209</guid>
            <pubDate>Mon, 01 Feb 2021 19:05:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Global]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25991988">thread link</a>) | @tosh
<br/>
February 1, 2021 | https://blog.repl.it/global | <a href="https://web.archive.org/web/*/https://blog.repl.it/global">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>We had the idea for Replit in Jordan, launched as a startup in New York, and incorporated as a company in San Mateo. The US gave us the infrastructure, the capital, and network to launch our business, and for that we're forever grateful. However, to us, the internet is a <a href="https://www.eff.org/cyberspace-independence">new country</a> and we want to make our citizenship official and our commitment real. We're joining our global community of hackers, students, teachers, and entrepreneurs and becoming a global company and service. Starting today:</p>
<ul>
<li>Our first two non-US compute regions are up --  Mumbai, India and London, England -- making us a global service</li>
<li>We're hiring worldwide making us a globally distributed company</li>
</ul>
<h2 id="global-routing">Global routing</h2>
<p>Previously, Replit has been operating out of a single datacenter in
the United States. When you start a repl, or join multiplayer, all
of your traffic had to make it to our one datacenter.</p>
<p>While that's not a significant issue if you live nearby, for our
friends all over the world it means every time you type a letter,
you had to cross an ocean at least twice! That means you could see
latencies as high as 300ms for each keystroke in the terminal! Now, when you create
a repl, it lives in the datacenter closest to you. Instead of
everyone having to cross the ocean multiple times, you can feel even
closer than your own computer! And if you have friends far away, things
will feel better too. Instead of connecting to a datacenter that is
far away, you'll connect to the datacenter closest to you, and
we'll deliver your bits as quickly as possible,
so you don't have to travel the world all on your own.</p>
<p>If you lived in India prior to our new data center, you saw significant delay in actions like running your code:</p>
<p><img src="https://blog.repl.it/images/global/before.gif" alt="before latency"></p>
<p>This is what you'll see today:</p>
<p><img src="https://blog.repl.it/images/global/after.gif" alt="after latency"></p>
<p>With these changes coding with friends and coworkers from all
over the world will feel closer than ever, and we're only just
getting started! We've made it super easy for us to ship to even
more countries, datacenters, and devices around the world. Before you
know it you might even be able to have a Replit data center in your
own home!</p>
<p><a href="https://blog.repl.it/killing-containers-at-scale">Read more</a> about our infrastructure and challenges with running a globally distributed multiplayer service.</p>

<p>Because we're still a highly collaborative small team and we haven't perfected the art of asynchronous we require employees to overlap with PST working hours for four hours a day. Otherwise you can be wherever you want in the world. </p>
<p><a href="https://repl.it/careers">Apply here</a>.</p>

	</div></div>]]>
            </description>
            <link>https://blog.repl.it/global</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991988</guid>
            <pubDate>Mon, 01 Feb 2021 18:51:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weblorg: A Static HTML Generator for Emacs and Org-Mode]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25991966">thread link</a>) | @clarete
<br/>
February 1, 2021 | https://emacs.love/weblorg/posts/v0-1-1-we-re-live.html | <a href="https://web.archive.org/web/*/https://emacs.love/weblorg/posts/v0-1-1-we-re-live.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-2">
<p>
With weblorg, one can first automate the process of finding Org-Mode
files, parsing them and feeding them into a template and then
rendering the final output into an HTML file.  Without further ado,
that's how one would do it in Emacs-Lisp:
</p>

<div>
<pre>(<span>require</span> '<span>weblorg</span>)

(weblorg-route
 <span>:name</span> <span>"posts"</span>
 <span>:input-pattern</span> <span>"./posts/*.org"</span>
 <span>:template</span> <span>"post.html"</span>
 <span>:output</span> <span>"./posts/{{ slug }}.html"</span>
 <span>:url</span> <span>"/posts/{{ slug }}.html"</span>)

(weblorg-export)
</pre>
</div>

<p>
That is enough to tell weblorg to find all Org-Mode files within the
directory posts and render them with the template <code>post.html</code>.
</p>

<p>
If you don't want to flex your design skills while spinning up a new
website or blog, worry not. A lean but mean theme is shipped by
default with weblorg.  To allow users to easily copy static assets
from a theme, one can use the following:
</p>

<div>
<pre>
(weblorg-copy-static
 <span>:output</span> <span>"static/{{ file }}"</span>
 <span>:url</span> <span>"/static/{{ file }}"</span>)
</pre>
</div>

<p>
Check out the <a href="https://emacs.love/weblorg/doc/index.html">Documentation</a> with a full article on how to setup a
new website and more.
</p>
</div></div>]]>
            </description>
            <link>https://emacs.love/weblorg/posts/v0-1-1-we-re-live.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991966</guid>
            <pubDate>Mon, 01 Feb 2021 18:50:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Full Transcript – Elon Musk vs. Vlad Tenev on Clubhouse]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25991946">thread link</a>) | @powerandr
<br/>
February 1, 2021 | https://www.mrhack.io/blog/elon-musk-vlad-tenev-robinhood-ceo-full-transcript/ | <a href="https://web.archive.org/web/*/https://www.mrhack.io/blog/elon-musk-vlad-tenev-robinhood-ceo-full-transcript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><iframe src="https://www.youtube.com/embed/1L8mI0i4XSA" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p><strong>Vlad Tenev: </strong>… It’s actually a couple of companies. So there’s an introducing broker dealer called “RobinHood Financial”. And that basically is the app that, you know and love. It processes trades. You’re a customer of of Robinhood Financial. Then there’s a clearing broker dealer, Robinhood Securities, that clears and settles the trades. And then we have Robinhood Crypto, which is our crypto business, of which all of these are kind of different entities that are differently operated.</p>
<p>So basically Wednesday of last week, we just had, you know, unprecedented volume, unprecedented load on the system. A lot of these so-called meme stocks were going viral on social media and people or people were joining Robinhood. And there was a lot of net by activity on them, as you guys all know. And Robinhood at this time, I think was number one on the App Store and pretty close, if not number one on on Google Play as well.</p>
<p>So just unprecedented activity. And so Thursday morning, so I’m sleeping. But at three thirty a.m. Pacific, our operations team receives a file from the NSCC, which is the National Securities Clearing Corporation. So basically, as a broker, as a clearing broker, and this is where Robinhood Securities comes in, we have to put up money to the NSCC, based on some factors, including things like the volatility of the trading activity, concentration into certain securities. And this is this is the equities business. So it’s based on stock trading and not options trading or anything else.</p>
<p>So they gave us a file with the deposit and the the request was around three billion dollars, which is about an order of magnitude more than what it typically is.</p>
<p><strong>Elon Musk:</strong> So why is this kind of like this seems like like it sounds like this is an unprecedented increase in demand for capital. What formula that they use to calculate that?</p>
<p><strong>Vlad Tenev:</strong> Well, yeah, and just to give context, Robinhood, up until that point, has raised a little bit around two billion dollars in total venture capital.</p>
<p>Up until now. So it’s a big number, like three billion dollars. This is a large number. So basically, the and you know, the details are we don’t have the full details. It’s a little bit of an opaque formula, but there’s a component called the VAR of it, which is value at risk. And that’s based on kind of some fairly quantitative things, although it’s not it’s not fully transparent. So there are ways to reverse engineer it, but it’s not kind of publicly shared.</p>
<p>And then there’s a special component, which is discretionary. So that’s that kind of acts as a multiplier and basically…</p>
<p><strong>Elon Musk:</strong> discretionary discretionary meaning, like it’s just their opinion.</p>
<p><strong>Vlad Tenev:</strong> Yeah, it’s it’s a little bit I mean, I’m sure there’s there’s definitely more more than just their opinion, but basically…</p>
<p><strong>Elon Musk:</strong> I mean, I guess what they’ve gone through, everyone wants to know whatever it was like, did something maybe shady go down here? Like, it just seems weird that you get a sudden ten billion dollar demand, you know, three billion or even more. Sorry, how much?</p>
<p><strong>Vlad Tenev:</strong> Yeah, it was three billion</p>
<p><strong>Elon Musk:</strong> up two to three billion around. You know, just suddenly out of nowhere and what does</p>
<p><strong>Vlad Tenev:</strong> I wouldn’t I wouldn’t I wouldn’t impute shadiness to it or anything like that. And actually, you know, the NSCC was reasonable subsequent to this. And they’ve been they’ve been they worked with us to actually lower it. So it was unprecedented activity. You know, we don’t I don’t have the full context about, you know, what was what was going on in what’s going on in the in that is key to make these calculations.</p>
<p>But, yeah, essentially…</p>
<p><strong>Elon Musk:</strong> if anyone holding you hostage right now…</p>
<p><strong>Vlad Tenev: </strong>But no, I’m OK. Yeah. Thanks for asking. But anyway, so this was this was obviously nerve wracking and I actually was asleep at this point. You know, the operations team was was fielding this had at three o’clock and then, you know, we got back, we put our heads together, you know, chief operating officer basically said, look, let’s call up the higher ups at the NSCC and kind of figure out what’s going on.</p>
<p>Maybe there’s some way we can work with them. And basically, there was another call and they lowered it to something like one point four billion dollars from three. So we were making some progress reports and then but still high number and then. We basically proposed. Well, let’s let’s explain how we plan to let’s explain how we’ll manage risk in these symbols throughout the day. We proposed marking these volatile stocks that were kind of driving, driving the activity position, closing only.</p>
<p>And then at about an hour before the market closed, market opened. So 5:30 or 5 in the morning, they came back and they said, OK, the charges or the deposit. Seven hundred million, which we then deposited and paid promptly and then everything was fine. So that essentially explains why we had to we had to mark these symbols. Position closing only. And also why we didn’t want to we knew this was a bad outcome for customers.</p>
<p>You know, part of what’s been really difficult is Robinhood stands for democratizing access to stocks. And we want we want to give people the access. So that’s been very, very challenging. But we had no choice in this case. We had to conform to our regulatory capital requirements. And so the team did did what they could to make sure we were available for customers.</p>
<p><strong>Elon Musk:</strong> Who controls the success of this organization, this Clearing House?</p>
<p><strong>Vlad Tenev:</strong> You know, it’s a it’s a consortium, it’s not it’s not quite a government agency, you know, I don’t really know the details of of all of that.</p>
<p><strong>Elon Musk: </strong>OK.</p>
<p><strong>Vlad Tenev: </strong>But, you know, and to be fair, we were we were I think there was legitimate sort of turmoil in the markets, like these are unprecedented events with these meme stocks. And, you know, there was a lot of activity. So there probably is. So some amount of extra risk in the system that warrants higher, higher requirements. So it’s not entirely unreasonable, but we do operational processes to make sure that customers that had positions could sell their open positions because obviously restricting someone we got a lot of questions about.</p>
<p>OK, you had to restrict buying. Why didn’t you also restrict selling? The fact of the matter is, people get really pissed off if they’re holding stock and they want to sell it and they can’t. So I think that’s that’s categorically worse. So and lots of other brokers, I think we’re in the same situation. Robinhood was in the news. But you you sort of heard this industry wide. Right. Other brokers basically restricted the same exact activity.</p>
<p><strong>Elon Musk: </strong>All right, so it sounds like this association should cozy up and they basically have a gun to your head, either the head of this money or else. And so because I mean, basically what people are wondering is like, did you sell down the river or do you have no choice? If you had no choice, that’s understandable. But then we got to find out why you had no choice. And who are the people that are saying you have no choice?</p>
<p><strong>Vlad Tenev: </strong>Yeah, I think that’s where we have to comply with these requirements. Financial institutions have requirements. You know, the the formula behind these requirements. I think it would obviously be ideal if there was a little bit more transparency so we could plan better around that, you know, but to be fair, we were able to open and serve our customers. And, you know, twenty four hours later, our team raised over a billion dollars in capital, so that when we when we did open, when we do open tomorrow morning, we’ll be able to kind of relax the stringent position limits that we put on these securities on Friday.</p>
<p><strong>Elon Musk: </strong>Will there be any limits?</p>
<p><strong>Vlad Tenev: </strong>Well, I think there’s always going to be some theoretical limit, like we don’t have infinite capital and on Friday there were limits. So there’s always there’s always going to have to be some limit. I think the question is, you know, will the limits be high enough to the point where, you know, some they won’t impact ninety nine point nine plus percent of customers. So, you know, if someone were to deposit one hundred billion dollars and and decide to trade in one stock like that, that wouldn’t be possible.</p>
<p><strong>Elon Musk: </strong>All right. All right. Well, I guess people really want to know if you had no choice, then you had no choice, that is the situation. And then that’s understandable. But then whoever put that gun to your head. Should you be willing to ask for public.</p>
<p><strong>Vlad Tenev: </strong>Yeah, listen, and, yeah, I know there’s this crisis. This is unprecedented times, and to be fair to those guys, I’ve been they’ve been reasonable. So we are I think the one thing that is maybe not clear to people is Robinhood is a participant in the financial system. So we have to work with all of these counter parties. So we do get a lot of questions about, you know, why do you work with market makers? Why do you work with clearing houses? Vertically integrating and getting. It is hard enough to introducing a clearing broker dealer? Not too many people have done that. But the financial system that allows customers to trade shares is sort of a complex web of multiple parties. And, you know, it’s hard to think.</p>
<p>Everyone says it could be better, it could be improved. It’s it’s just the necessity of of trading equities in the US that you have to do all these things.</p>
<p><strong>Elon Musk: </strong>To what degree are you beholden to Citadel? I mean, like basically said it was unhappy than I thought then what happened?</p>
<p><strong>Vlad Tenev: </strong>Yes, there was a rumor that Citadel or other market makers kind of pressured us into doing this, and now that’s just false. Market makers execute our trades, they execute trades off of every broker dealer.</p>
<p>And this was this was a clearing house. This was a clearing house decision. And it was just based on the capital requirements. So Citadel and other market makers weren’t involved in that.</p>
<p><strong>Elon Musk: </strong>But …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mrhack.io/blog/elon-musk-vlad-tenev-robinhood-ceo-full-transcript/">https://www.mrhack.io/blog/elon-musk-vlad-tenev-robinhood-ceo-full-transcript/</a></em></p>]]>
            </description>
            <link>https://www.mrhack.io/blog/elon-musk-vlad-tenev-robinhood-ceo-full-transcript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991946</guid>
            <pubDate>Mon, 01 Feb 2021 18:49:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Defining a Custom Class Constructor in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25991832">thread link</a>) | @sethdandridge
<br/>
February 1, 2021 | https://sethdandridge.com/blog/defining-a-custom-class-constructor-in-python | <a href="https://web.archive.org/web/*/https://sethdandridge.com/blog/defining-a-custom-class-constructor-in-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Python gives you tremendous visibility into its internal workings. The degree to which you can pop open the hood and modify what’s happening at runtime is powerful and terrifying. The author of the venerable Flask web framework Armin Ronacher gave a fantastic talk on this topic called <a href="https://www.youtube.com/watch?v=qCGofLIzX6g">How Python was Shaped by Leaky Internals</a>.</p>

<p>One way to take advantage of these leaky internals is by overwriting the built-in class constructor. Whenever you define a class, the function <code>__build_class__</code> is called behind the scenes. <code>__build_class__</code> is passed the class code (which is actually, suprisingly, a function) and the class name as arguments. The result of executing <code>__build_class__</code> is your class being created in the appropriate namespace. I’m <a href="https://www.pythoninsight.com/2019/03/what-happens-when-a-class-is-created/">simplifying</a>, but bear with me.</p>



<p>To see this in action, let’s define a simple class called <code>Dog</code> and observe <code>__build_class__</code> do its job.</p>

<figure><pre><code data-lang="python"><span>class</span> <span>Dog</span><span>:</span>
  <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
    <span>print</span><span>(</span><span>'bark bark'</span><span>)</span>

<span>dog</span> <span>=</span> <span>Dog</span><span>()</span>
<span>#&gt; bark bark</span></code></pre></figure>

<p>Now let’s define a custom build class function to see a bit of what’s happening under the hood.</p>

<figure><pre><code data-lang="python"><span>def</span> <span>custom_build_class</span><span>(</span><span>*</span><span>args</span><span>):</span>
  <span>print</span><span>(</span><span>args</span><span>)</span>

<span>__builtins__</span><span>.</span><span>__build_class__</span> <span>=</span> <span>custom_build_class</span>

<span>class</span> <span>Dog</span><span>:</span>
  <span>pass</span>
<span>#&gt; (&lt;function Dog at 0x10f6ff6a8&gt;, 'Dog')</span></code></pre></figure>

<p>You can see the two arguments that are passed to <code>__build_class__</code> are the <code>Dog</code> function (the code of the <code>Dog</code> class) and the name of the class, <code>'Dog'</code>. Because we don’t ever call the “real” <code>__build_class__</code>, the class is never defined in the namespace. Curiously, however, accessing the variable <code>Dog</code> doesn’t throw <code>NameError</code>. Instead, it’s just<code>None</code>.</p>

<figure><pre><code data-lang="python"><span>print</span><span>(</span><span>Dog</span><span>)</span>
<span>#&gt; None</span></code></pre></figure>

<p>Not sure why this is—evidently there’s something outside of <code>__build_class__</code> that’s modifying the namespace. Worth further investigation.</p>


<p>Now let’s redefine the built-in class constructor so that no matter what class you define, the <code>__build_class__</code> function assigns the code for <code>Dog</code> to that class name instead of the code of the class you’re defining.</p>

<figure><pre><code data-lang="python"><span>class</span> <span>Dog</span><span>:</span>
  <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
    <span>print</span><span>(</span><span>'woof woof'</span><span>)</span>

<span>def</span> <span>custom_build_class</span><span>(</span><span>*</span><span>args</span><span>):</span>
  <span>return</span> <span>Dog</span>

<span>__builtins__</span><span>.</span><span>__build_class__</span> <span>=</span> <span>custom_build_class</span>

<span>class</span> <span>Cat</span><span>:</span>
  <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
    <span>print</span><span>(</span><span>'meow meow'</span><span>)</span>

<span>cat</span> <span>=</span> <span>Cat</span><span>()</span>
<span>#&gt; bark bark
</span>
<span>print</span><span>(</span><span>type</span><span>(</span><span>cat</span><span>))</span>
<span>#&gt; &lt;class '__main__.Dog'&gt;</span></code></pre></figure>

<p>Chaos reigns!</p>



<p>Aside from impressing your friends and coworkers with verboten Python magic, why would you ever want to do any of this? I actually can’t think of a legitimate reason. Perhaps you need a hook that registers every class upon its creation? However, this case would probably be better served with a metaclass. If you can think of a legitimate real-world scenario for overriding <code>__build_class__</code>, let me know.</p>

<p>This is the second in a series of blog entries I’m calling “baby snakes”, bits of Python arcana aimed at intermediate and advanced Python developers. For a similar exercise in Python’s built-in abuse, see <a href="https://sethdandridge.com/blog/redefining-pythons-print-function">Redefining Python’s Print() Function</a> and check back soon for even more!</p>


  </div></div>]]>
            </description>
            <link>https://sethdandridge.com/blog/defining-a-custom-class-constructor-in-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991832</guid>
            <pubDate>Mon, 01 Feb 2021 18:41:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Identifying Linear Relationships Between Variables in Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25991608">thread link</a>) | @danielmp1202
<br/>
February 1, 2021 | https://www.narrativetext.co/the-linear-model/identifying-linear-relationships-between-variables-in-machine-learning | <a href="https://web.archive.org/web/*/https://www.narrativetext.co/the-linear-model/identifying-linear-relationships-between-variables-in-machine-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img src="https://www.narrativetext.co/assets/application/160x160/img3.jpg" alt="Image Description"></p><h2>Join our private community in Slack</h2>
          <p>
            Keep up to date by participating in this global community of data
            scientists. We talk about data science use cases, we share notebooks,
            we participate in data science competitions, we help each other,
            and we share new ML techniques and much more!
          </p>
        </div></div>]]>
            </description>
            <link>https://www.narrativetext.co/the-linear-model/identifying-linear-relationships-between-variables-in-machine-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991608</guid>
            <pubDate>Mon, 01 Feb 2021 18:26:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Expresso: A faster, drop-in replacement for the ExpressJS router]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25991516">thread link</a>) | @newtang
<br/>
February 1, 2021 | https://blog.jonnew.com/posts/express-router-part-2-expresso | <a href="https://web.archive.org/web/*/https://blog.jonnew.com/posts/express-router-part-2-expresso">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><a href="https://blog.jonnew.com/posts/express-router-part-1">In my previous post</a>, I noted that the default router for Express, an extremely popular Node module, hasn’t seen any substantial optimization in years. So, I was curious if I could make a faster, drop-in replacement router, and in early summer of 2020, I broke ground on this project. In the ensuing months, I made incremental progress, and I’m thrilled to share that the <a href="https://www.npmjs.com/package/expresso-router">first public version of Expresso is now available</a>!</p>



<p>My goals were to make Expresso faster than the default Express router, reasonably backwards compatible, throw helpful errors on problematic setup, and finally, to allow routes to be added in an order-independent manner. Let’s walk through these!</p>

<h3 id="speed">Speed</h3>

<p>I tweaked <a href="https://github.com/delvedor/router-benchmark">router-benchmark</a> to include Expresso, and I included the results in my API doc. For static routes Expresso wins hands down, at least according to my quick and dirty local testing environment.</p>

<div><div><pre><code>
<span>====================</span>
 expresso benchmark
<span>====================</span>
short static: 8,375,979 ops/sec
static with same radix: 8,533,307 ops/sec
long static: 7,822,262 ops/sec

<span>=================================</span>
 default express router benchmark
<span>=================================</span>
short static: 1,676,429 ops/sec
static with same radix: 1,590,129 ops/sec
long static: 829,426 ops/sec

</code></pre></div></div>

<p>For parameterized routes (ie <code>/api/v1/:user</code>), Expresso-router is again faster, but the difference isn’t as stark.</p>

<div><div><pre><code><span>====================</span>
 expresso benchmark
<span>====================</span>
dynamic route: 928,018 ops/sec
mixed static dynamic: 765,725 ops/sec

<span>=================================</span>
 default express router benchmark
<span>=================================</span>
dynamic route: 743,979 ops/sec
mixed static dynamic: 613,461 ops/sec
</code></pre></div></div>

<p>The truth is, I’m certain I left some optimization on the table, particularly for parameterized routes, but I was getting anxious to share this with the public. Also, I want to point out that the default express router can get slower as more routes are added. For example, if it has 100 routes, it would run through all of them until it found a match. Expresso-router utilizes a tree for parameterized routes, so it scales much more efficiently.</p>

<h3 id="backwards-compatible">Backwards compatible</h3>

<p>The <a href="https://github.com/newtang/expresso/blob/HEAD/API.md#api-1">API for Expresso is basically identical to the default Express router</a> . However, there are a few missing features like wildcards, and support for parameters in the <code>use</code> function. I have <a href="https://github.com/newtang/expresso/issues">issues</a> filed for several of these, and some <a href="https://github.com/newtang/expresso/blob/HEAD/API.md#migration">additional details in the Migration section</a>.</p>

<h3 id="errors">Errors</h3>

<p>If possible, it’s preferable to make the right thing easy to do, and make the wrong thing, like a source of common mistakes, something destructive, or a suboptimal decision, more difficult. Expresso tries to warn users about common mistakes on setup, but <a href="https://github.com/newtang/expresso/blob/HEAD/API.md#config">allows some optional, explicit overrides in the constructor</a>. Here’s a couple examples.</p>

<figure><pre><code data-lang="javascript"><span>const</span> <span>router</span> <span>=</span> <span>expresso</span><span>();</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/api</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/api</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span> <span>//throws exception for duplicate route</span></code></pre></figure>

<figure><pre><code data-lang="javascript"><span>const</span> <span>router</span> <span>=</span> <span>expresso</span><span>();</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/id/:id</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/id/:value</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span> <span>//throws exception for duplicate route</span></code></pre></figure>

<figure><pre><code data-lang="javascript"><span>const</span> <span>router</span> <span>=</span> <span>expresso</span><span>({</span><span>allowDuplicatePaths</span><span>:</span> <span>true</span><span>});</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/api</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/api</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span>

<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/id/:id</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/id/:value</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span></code></pre></figure>

<p>Although these compact examples might look a little silly or improbable, these errors are more likely to manifest themselves if the routes are distributed across multiple files.</p>

<h3 id="order-independence">Order Independence</h3>

<p>Order independence is a big feature for Expresso. In the default Express router, this situation was possible:</p>

<figure><pre><code data-lang="javascript"><span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/api/v1/:user</span><span>'</span><span>,</span> <span>(</span><span>req</span><span>,</span> <span>res</span><span>)</span> <span>=&gt;</span> <span>{</span><span>res</span><span>.</span><span>send</span><span>(</span><span>req</span><span>.</span><span>params</span><span>.</span><span>user</span><span>)});</span>

<span>// will never get called in default Express router, but will get called in Expresso </span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/api/v1/settings</span><span>'</span><span>,</span> <span>(</span><span>req</span><span>,</span> <span>res</span><span>)</span> <span>=&gt;</span> <span>{</span><span>res</span><span>.</span><span>send</span><span>(</span><span>'</span><span>settings</span><span>'</span><span>)});</span></code></pre></figure>

<p>In the above example, a GET request to <code>/api/v1/settings</code> will never trigger the second route in the default Express router because the first one would match even though it’s less specific. However, with Expresso, this is no longer a concern. Routes are order independent, and Expresso will check the most specific route first.</p>

<h3 id="conclusion">Conclusion</h3>

<p>Naively, this project took a little longer than I intended. There were a lot of details to get right, and there’s some interesting features the default Express router has that are easy to overlook. For example, it handles all HEAD and OPTIONS requests, and carefully adjusts the <code>url</code> and <code>baseUrl</code> properties on the <code>req</code> object when multiple routers are used. A lot of these I discovered while going through the default router’s tests to maximize backwards compatibility where I could.</p>

<p>Because it took longer than estimated, I have some mild regret taking on this project. It wasn’t particularly distinct from my <a href="https://mapbox.com/">day job</a>, so I started to lose a little bit of momentum towards the end. I’ll probably be reinvigorated to add missing features if someone finds Expresso useful.</p>


          </div></div>]]>
            </description>
            <link>https://blog.jonnew.com/posts/express-router-part-2-expresso</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991516</guid>
            <pubDate>Mon, 01 Feb 2021 18:18:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Browser plugin that adds extra features to Metrc]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25991509">thread link</a>) | @nosmokewhereiam
<br/>
February 1, 2021 | https://www.gosellout.com/metrc-toolkit | <a href="https://web.archive.org/web/*/https://www.gosellout.com/metrc-toolkit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.gosellout.com/metrc-toolkit</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991509</guid>
            <pubDate>Mon, 01 Feb 2021 18:18:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything You Hate About Clubhouse Is Why It Will Win]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25991386">thread link</a>) | @swyx
<br/>
February 1, 2021 | https://www.swyx.io/clubhouse-hate/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/clubhouse-hate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>You can listen to <a href="https://share.transistor.fm/s/6719542d">an audio version of this essay here</a>.</em></p>
<p>Trust me, I <em>tried</em> to make the Clubhouse bear case.</p>
<p>The original title of this post was "Everything Clubhouse Did Right — and Why It Will Fail Anyway". The exercise forced me to list the reasons why it wasn't worth $1 billion - why live conference calls are inferior to existing formats like podcasts and Discord.</p>
<p>When I was done, I went for a walk to think about it. By the time I came back, I had done a complete 180. (Note - <em>this was even before I heard about the Elon event</em>)</p>
<p>I <em>still</em> dislike the Clubhouse experience. I wouldn't recommend it to you. But all the reasons I dislike it are the same reasons it will work:</p>
<ul>
  <li><strong>Clubhouse is exclusive</strong>. You have hoops to jump and gates to open every step of the way. It's iOS only. Invite only. Requires your phone number for no goddamn reason. And once you're through <em>all of that</em> you gain the privilege of being in the voiceless audience hoping senpai will notice your raised hand and puffed up bio.</li>
  <li><strong>Clubhouse is ephemeral</strong>. Conversations aren't recorded. Your work doesn't compound and isn't searchable. This is <em>horrible</em> for ROI on your time as a content creator.</li>
  <li><strong>Clubhouse is live-only</strong>. If all the convos are happening in Pacific Time and you live in Europe, tough luck. If you came in halfway and have no idea what was said, tough luck. The only way to be fully involved is to turn on mobile notifications and track scheduled chats. Causing more — not less — distraction and work for you.</li>
  <li><strong>Clubhouse enhances existing privilege</strong>. Because automated recommendations aren't possible, Clubhouse mostly relies on a Twitter-like follow graph. To gain a following you mostly already have to be famous off-platform or well-connected to people who will bring you up on stage ("second-degree famous"). Choosing a <a href="https://www.eugenewei.com/blog/2019/2/19/status-as-a-service">Status as a Service</a> model (Twitter) over a <a href="https://www.eugenewei.com/blog/2020/8/3/tiktok-and-the-sorting-hat">Sorting Hat</a> model (TikTok) sacrifices discovery for establishment.</li>
  <li><strong>Clubhouse is a terrible listening experience</strong>. There's no audience chat or polling. Obnoxious speakers can dominate the conversation. <a href="https://twitter.com/wongmjane/status/1355817942093496320?s=20">Trolls</a> and <a href="https://www.dailydot.com/unclick/tiffany-haddish-bullies-doctor-on-clubhouse-covid/">harassment</a> abound. You can't play at 2x or rewind an important part. Podcasts were trending towards better audio and editing, Clubhouse regresses to shitty phone mics with feedback and connection issues. Signal is scarce, noise is rampant.</li>
</ul>
<p>In my original write up I listed the many better offerings in every dimension. Want to listen to interviews with great audio and show notes? Podcasts. Want ultrascalable livestreaming? Twitch. Want livestreamed audio with recording and submitted questions? <a href="https://twitter.com/N8Elliott/status/1355203379392176131?s=20">Capiche</a>. Want to do an audio webinar? Use Zoom with the camera off. Want voice with text chat? Discord. Just want a Clubhouse clone with less friction? <a href="https://twitter.com/TwitterSpaces">Twitter Spaces</a>.</p>
<p>When I was done listing the alternatives, I knew I had made a mistake. They checked more boxes on a feature comparison basis. But social media doesn't work like that. I was trying to be logical in a <em>socio</em>-logical domain.</p>
<p>I had conclusively <em>PROVED</em>, with my big brain and fancy words, how profoundly inferior Clubhouse was. No compounding creator should prefer it, and no self respecting listener should enjoy it, compared to alternatives.</p>
<p>But the majority of people don't work like that:</p>
<ul>
  <li>Some people are turned off by exclusivity and friction. But <em>most people</em> take it as social proof of something cool.</li>
  <li>Some creators are turned off by ephemerality. But <em>more people</em> will start trying precisely because it's easy and doesn't matter. The Elon Musks and Vlad Tenevs of the world will be less guarded, despite clearly knowing anything they say will be recorded, because <em><a href="https://en.wikipedia.org/wiki/The_medium_is_the_message">the medium is the message</a></em>.</li>
  <li>Some people are turned off by demands on their time. But <em>most people</em> leave mobile notifications on and the live nature of chats creates some of the most urgent notifications you'll get on your phone, second only to a call from your mother. The synchronicity creates an <em>event</em> — a clear Before and After where you can excitedly gossip and feel superior to people out of the loop. This is a rarity in an everything-async world.</li>
  <li>Some people are turned off by stacked decks. But <em>most people</em> just want to follow celebrities and experts and aren't interested in the challenging, messy work of finding people on the way up.</li>
  <li>Some people are turned off by the listening experience. But Clubhouse is <a href="https://www.swyx.io/good-enough/">Good Enough</a>, especially if content is created sooner and in bigger quantity than available anywhere else.</li>
</ul>
<p>Clubhouse should've died <a href="https://www.theverge.com/interface/2020/7/8/21316172/clubhouse-content-moderation-taylor-lorenz-harassment-abuse">in July when the VC and Media abuse cases erupted</a>. Instead it came back stronger than ever, standing at <a href="https://web.archive.org/web/20210131175202/https://www.businessinsider.com/why-the-hype-about-1-billion-clubhouse-not-so-crazy-2021-1">2 million weekly active users</a>. <strong>If any of these negatives mattered</strong>, the app should have seen extreme churn. Instead, <a href="https://a16z.com/2021/01/24/investing-in-clubhouse/">Andrew Chen</a>, <a href="https://twitter.com/rrhoover/status/1353393250552270850">Ryan Hoover</a>, and <a href="https://twitter.com/shl/status/1353406140495798272">Sahil Lavingia</a> — who do this for a living and have insider knowledge of metrics — value it above $1 billion dollars, six months after it was <a href="https://www.forbes.com/sites/alexkonrad/2020/05/15/andreessen-horowitz-wins-vc-sweepstakes-to-back-clubhouse-voice-app/?sh=5b8466d56f2a">valued at $100 million</a>.</p>
<p><strong>People. Aren't. Churning.</strong> No matter how much you may hate the app — usage is going <em>up</em>. This is scary and worth taking note. Clubhouse is already showing signs of successful expansion in Asia (read: non-English Clubhouses).</p>
<p>Instagram had 30 million MAUs when Facebook bought it for $1 billion. Whatsapp had 450m for $19 billion. By Whatsapp metrics, Clubhouse is wildly overvalued (lets say it has 10m MAU right now). But audio isn't text. <a href="https://alexdanco.com/2019/10/17/the-audio-revolution/">Alex Danco says</a> that texting is a cold medium, while audio is the hottest medium of all. He was mildly wrong — podcasting is still kinda lukewarm — but <strong><em>live, ephemeral</em></strong> audio is so hot you will literally drop everything and stay up late and ignore your partner to go listen to Elon.</p>
<p>Worse is better. The exact reasons you hate Clubhouse — the kind of thing that drives you to read an article like this to the end — are the exact same reasons it is going to win.</p>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/clubhouse-hate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991386</guid>
            <pubDate>Mon, 01 Feb 2021 18:08:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AlmaLinux Beta: A Community-Driven Replacement for CentOS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25991329">thread link</a>) | @jaboutboul
<br/>
February 1, 2021 | https://blog.almalinux.org/introducing-almalinux-beta-a-community-driven-replacement-for-centos/ | <a href="https://web.archive.org/web/*/https://blog.almalinux.org/introducing-almalinux-beta-a-community-driven-replacement-for-centos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div>

                                <p><span>CloudLinux is proud to announce the release of AlmaLinux Beta. We’ve collected community feedback and built our new beta release around what you would expect from an enterprise-level Linux distribution. AlmaLinux is a completely free 1:1 binary compatible fork of Red Hat Enterprise Linux (RHEL) 8, inspired by the community and built by the engineers and talent behind CloudLinux. Visit <a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/">this link</a></span><span>&nbsp;to download Beta images.</span></p>

<p><span>With the Beta release deployed, we’d like to ask the community to be involved and provide feedback. We aim to build a Linux distribution entirely from community contributions and feedback. During AlmaLinux Beta, we ask for assistance in testing, documentation, support and future direction for the operating system. Together, we can build a Linux distribution that fills the gap left by the now unsupported CentOS distribution.</span></p>
<p><span>The AlmaLinux team set up all the necessary infrastructure to make it convenient for our contributors to provide their input. The public repository on </span><a href="https://github.com/AlmaLinux"><span>Github</span></a><span> is where we will finalize the source code for the system, and any additional documentation will be posted on the </span><a href="https://wiki.almalinux.org/"><span>wiki</span></a><span>. We set up the wiki and repository to make it easy for the community to provide as much information and feedback as possible. The AlmaLinux team will review every comment and request, but we ask that only registered contributors </span><a href="https://bugs.almalinux.org/login_page.php"><span>file bug reports</span></a><span> to filter out spam.</span></p>
<p><span>To facilitate communication and help answer some of the common questions you might already have, we will be hosting a live QA webinar with the AlmaLinux team. </span><span>The webinar will take place on February 10, </span><span>5 PM (UTC) / 9 AM (PST). Among the participants present will be Igor Seletskiy, CEO of CloudLinux, and Alexander Vinogradov, Head of Engineering at AlmaLinux.</span></p>
<p><span>You can sign up for our webinar </span><a href="https://blog.almalinux.org/webinars/almalinux-beta-qa-webinar/"><span>here</span></a><span>.</span></p>
<p><span>If you have any questions, comments, feedback or concerns, please feel free to send us your thoughts to </span><a href="https://blog.almalinux.org/cdn-cgi/l/email-protection#2048454c4c4f60414c4d414c494e55580e4f5247"><span><span data-cfemail="85ede0e9e9eac5e4e9e8e4e9ecebf0fdabeaf7e2">[email&nbsp;protected]</span></span></a><span> or send them during the webinar on Twitter with the hashtag #AlmaLinuxBeta.</span></p>
<p><span>CloudLinux and the AlmaLinux team would like to thank the community for their input. This is just the beginning for AlmaLinux, and we look forward to continued improvements and updates for the next generation enterprise-level Linux operating system.</span></p>
<p><span>Thank you for your contribution, input, and support throughout launching AlmaLinux! The infrastructure was the first step, now we need your help to make the next one!</span></p>


<p><strong>Release Notes for AlmaLinux 8 beta</strong></p>
<p><span>The release code name: Purple <a href="https://en.wikipedia.org/wiki/Pallas%27s_cat">Manul</a>.</span></p>
<p><span>CloudLinux is proud to present the beta version of AlmaLinux. After roughly a month and a half from the announcement, here is a 1:1 RHEL binary compatible replacement for your RHEL-based systems.&nbsp;</span></p>
<p><span>This is for the community and by the community, you’re the soul of Linux. Thank you for your interest and suggestions so far, keep them coming.</span></p>
<p><span>Use this version to thoroughly test your workloads and report any unintended features (ie, bugs) you may find, it will help make AlmaLinux better.</span></p>

<h2><span>Installation instructions</span></h2>

<p><span>There are three installation ISO images available:</span></p>
<ul>
<li aria-level="1"><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-boot.iso"><span>AlmaLinux-8.3-beta-1-x86_64-boot.iso</span></a><span> – a single network installation CD image that downloads packages over the Internet.</span></li>
<li aria-level="1"><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-minimal.iso"><span>AlmaLinux-8.3-beta-1-x86_64-minimal.iso</span></a><span> – a minimal self-containing DVD image that makes possible offline installation.</span></li>
<li aria-level="1"><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-dvd1.iso"><span>AlmaLinux-8.3-beta-1-x86_64-dvd1.iso</span></a><span> – a full installation DVD image that contains mostly all AlmaLinux packages. We don’t really recommend using it unless you need to set up and use AlmaLinux on a machine without internet access.</span></li>
</ul>

<p><span>Download a preferable ISO image and verify its checksum. Here is an example for GNU/Linux:</span></p>
<blockquote>
<pre><span># download and import the AlmaLinux public key</span>
<span>$ wget </span><a href="https://repo.almalinux.org/almalinux/RPM-GPG-KEY-AlmaLinux"><span>https://repo.almalinux.org/almalinux/RPM-GPG-KEY-AlmaLinux</span></a>
<span>$ gpg --import RPM-GPG-KEY-AlmaLinux</span>

<span># download a checksums list</span>
<span>$ wget </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/CHECKSUM"><span>https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/CHECKSUM</span>
</a><span>
# verify the checksums list, we are looking for “Good signature”</span>
<span>$ gpg --verify CHECKSUM </span>
<span>gpg: Signature made Thu 28 Jan 2021 11:39:12 PM MSK</span>
<span>gpg:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; using RSA key 51D6647EC21AD6EA</span>
<span>gpg: <strong>Good signature from "AlmaLinux &lt;<a href="https://blog.almalinux.org/cdn-cgi/l/email-protection" data-cfemail="156574767e747270675574797874797c7b606d3b7a6772">[email&nbsp;protected]</a>&gt;"</strong> [unknown]</span>
<span>gpg: WARNING: This key is not certified with a trusted signature!</span>
<span>gpg:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; There is no indication that the signature belongs to the owner.</span>
<span>Primary key fingerprint: 5E9B 8F56 17B5 066C E920&nbsp; 57C3 488F CF7C 3ABB 34F8</span>
<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Subkey fingerprint: E53C F5EF 91CE B0AD 1812&nbsp; ECB8 51D6 647E C21A D6EA</span>

<span># download the network install ISO</span>

<span>$ wget </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-boot.iso"><span>https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-boot.iso</span></a>
<span># calculate the downloaded ISO SHA256 checksum</span>
<span>$ sha256sum AlmaLinux-8.3-beta-1-x86_64-boot.iso </span>
<span>d15be406f417e81382b46a54d87dff01c8ca770c847c18703f19146587b61a1f&nbsp; AlmaLinux-8.3-beta-1-x86_64-boot.iso</span>

<span># compare it with expected checksum, it should be the same</span>
<span>$ cat CHECKSUM | grep -E 'SHA256.*AlmaLinux-8.3-beta-1-x86_64-boot.iso'</span>
<span>SHA256 (AlmaLinux-8.3-beta-1-x86_64-boot.iso) = d15be406f417e81382b46a54d87dff01c8ca770c847c18703f19146587b61a1f</span></pre>
</blockquote>

<p><span>If you decided to use the AlmaLinux-8.3-beta-1-x86_64-boot.iso image, you will need to provide this </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/BaseOS/x86_64/kickstart/"><span>https://repo.almalinux.org/almalinux/8.3-beta/BaseOS/x86_64/kickstart/ </span></a><span>repository as the Installation Source:</span></p>

<p><img loading="lazy" src="http://blog.almalinux.org/wp-content/uploads/2021/02/source-2.png" alt="" width="731" height="507" srcset="https://blog.almalinux.org/wp-content/uploads/2021/02/source-2.png 1053w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-300x208.png 300w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-1024x710.png 1024w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-150x104.png 150w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-768x532.png 768w" sizes="(max-width: 731px) 100vw, 731px"></p>

<p><span>If you are going to install a non-minimal environment, you will need to add the AppStream repository to the additional repositories: </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/AppStream/x86_64/os/"><span>https://repo.almalinux.org/almalinux/8.3-beta/AppStream/x86_64/os/</span></a><span>.</span></p>
<p><span>There are no extra Installation Sources required if you decided to go with AlmaLinux-8.3-beta-1-x86_64-minimal.iso or AlmaLinux-8.3-beta-1-x86_64-dvd1.iso images.</span></p>

<h2><span>How to set up a usb key to install AlmaLinux</span></h2>
<blockquote>
<pre><span>dd if=AlmaLinux-8.3-beta-1-x86_64-boot.iso of=/dev/sdX</span></pre>
</blockquote>
<p><span>Where </span><b>sdX</b><span> is your usb device</span></p>

<h2><span>Known issues</span></h2>
<ul>
<li><span>Our libreport/abrt packages aren’t integrated with the bugs.almalinux.org bug-tracker yet, so a user will have to submit a crash report manually. Issue: </span><a href="https://bugs.almalinux.org/view.php?id=2"><span>almbz#2</span></a><span>.</span></li>
<li><span>The “perl:5.30” module support is incomplete in the beta release, it will be finished in the stable.</span></li>
<li><span>We don’t have the latest “jmc” and “maven” module versions. They will be updated later.</span></li>
<li><span>The “satellite-5-client” module is located in the BaseOS repository instead of the AppStream. Issue: </span><a href="https://bugs.almalinux.org/view.php?id=4"><span>almbz#4</span></a><span>.</span></li>
<li><span>There is no support for Secure Boot in the beta release. Issue: </span><a href="https://bugs.almalinux.org/view.php?id=3"><span>almbz#3</span></a><span>.</span></li>
<li><span>The debuginfo repositories are empty and will be populated in a couple of days after the beta release.</span></li>
</ul>



                             </div>



                            </div></div>]]>
            </description>
            <link>https://blog.almalinux.org/introducing-almalinux-beta-a-community-driven-replacement-for-centos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991329</guid>
            <pubDate>Mon, 01 Feb 2021 18:05:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A financial insider's take on GameStonk]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25991180">thread link</a>) | @davidd8
<br/>
February 1, 2021 | https://www.davidexmachina.com/2021/02/cant-stonk-wont-stonk-game-stonk.html | <a href="https://web.archive.org/web/*/https://www.davidexmachina.com/2021/02/cant-stonk-wont-stonk-game-stonk.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.davidexmachina.com/2021/02/cant-stonk-wont-stonk-game-stonk.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991180</guid>
            <pubDate>Mon, 01 Feb 2021 17:54:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Argo Workflows v3.0]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25991077">thread link</a>) | @dnsmichi
<br/>
February 1, 2021 | https://blog.argoproj.io/argo-workflows-v3-0-4d0b69f15a6e | <a href="https://web.archive.org/web/*/https://blog.argoproj.io/argo-workflows-v3-0-4d0b69f15a6e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p id="3ed4">We’re incredibly proud of how far <a href="https://github.com/argoproj/argo" rel="noopener"><strong>Argo Workflows</strong></a> has come since its <a rel="noopener" href="https://blog.argoproj.io/introducing-argo-a-container-native-workflow-engine-for-kubernetes-55c0b4b76fac"><strong>inception</strong></a> three years ago!</p><ul><li id="01a4">17th Oct 2017 — first commit</li><li id="947c">6th Feb 2018 — v2.0 rewritten in Go</li><li id="dcbd">2nd Sep 2019 — first 1,000 stars</li><li id="9355">17th Apr 2020 — <a href="https://www.cncf.io/blog/2020/04/07/toc-welcomes-argo-into-the-cncf-incubator/" rel="noopener">became a CNCF incubator project</a></li><li id="5b9b">22nd Jan 2021 — 373 contributors, 2k commits, 7.3k stars, 1.3k forks, 5.2k Slack members</li></ul><p id="0265">With this all behind us — we’re round to announce <strong>Argo Workflows v3.0.</strong></p><h2 id="aaf7">What is Argo Workflows?</h2><p id="7875"><strong>Argo Workflows</strong> is a cloud-native workflow engine that can run 10,000s of concurrent workflows, each with 1,000s of steps.</p><h2 id="29df">What can I use it for?</h2><ul><li id="5678">Machine Learning</li><li id="46b6">ETL, Data Analytics &amp; Data Science</li><li id="061c">Data processing pipelines</li><li id="b4d2">Batch processing</li><li id="bce1">Serverless</li><li id="084c">CI/CD</li></ul><h2 id="1f24">Who uses Argo?</h2><p id="d00f">Argo is used to “discover new physics” at CERN, for 3D rendering at CoreWeave (on a 1,000 node cluster with 6,000 GPUs), and in Intuit’s Machine Learning and Data Processing platforms. Argo Workflows is actively used in production by well over <a href="https://github.com/argoproj/argo/blob/master/USERS.md" rel="noopener">100 organizations</a>, including <strong>Adobe, Alibaba Cloud, BlackRock, Capital One, Data Dog, Datastax, Google, GitHub, IBM, Intuit, NVIDIA, SAP, New Relic, and RedHat.</strong></p><h2 id="6abc">Why would I use Argo?</h2><p id="bc11">When we asked our users who were using tools like Kubeflow, Apache Airflow, AWS Batch, AWS Lambda, KNative, TektonCD, and <a href="https://blog.kintohub.com/how-do-we-ditch-jenkins-for-argo-1c0b4df5dab0" rel="noopener">Jenkins</a> why they also use Argo, they said<strong> they love that it is cloud-native, simple, fast, scales, and cost-effective.</strong></p><h2 id="aa48">Big new features every release</h2><p id="d3b3">In the last 12 months, every release has had major new features:</p><ul><li id="34ce"><a rel="noopener" href="https://blog.argoproj.io/whats-coming-up-in-argo-workflows-v2-12-3899bae53562">v2.12: reports and metrics, SSO+RBAC</a></li><li id="9317"><a rel="noopener" href="https://blog.argoproj.io/argo-workflows-v2-11-a8b6189bf60e">v2.11: webhooks, memorization</a></li><li id="7fdb"><a rel="noopener" href="https://blog.argoproj.io/argo-workflows-v2-10-d20beeee5df3">v2.10: Java and Python SDKs, semaphores, and mutexes</a></li><li id="acc8"><a rel="noopener" href="https://blog.argoproj.io/argo-workflows-v2-9-47b9c2b5f456">v2.9: single-sign-on, Windows support, workflow template ref</a></li><li id="3ff0"><a rel="noopener" href="https://blog.argoproj.io/whats-new-in-argo-workflow-v2-8-5356ee1d4f7f">v2.8: cluster workflow templates</a></li><li id="ab13"><a rel="noopener" href="https://blog.argoproj.io/argo-workflows-v2-7-6ace8c210798">v2.7: submittable workflow templates, Prometheus metrics</a></li><li id="50f0"><a href="https://github.com/argoproj/argo/releases/tag/v2.6.0" rel="noopener">v2.6: Gomodules, filtering labels</a></li><li id="20d1"><a rel="noopener" href="https://blog.argoproj.io/argo-workflows-v2-5-released-ce7553bfd84c">v2.5: API server, the workflow archive, cron workflows</a></li></ul><ul><li id="ed9f">Major upgrade (20k new lines of code) to the user interface with many new features and much more robust</li><li id="1469">Brand new APIs for Argo Events</li><li id="04b7">Controller High-Availability</li><li id="54c8">Key-only artifacts make it easier to perform map-reduce operations</li><li id="0dd0">Moving the repository</li><li id="6230">Go modules support</li></ul><h2 id="cca4">Argo Events API and UI</h2><p id="19ec">Argo Workflows v3.0 comes with a new UI that now also supports Argo Events! The UI is also more robust and reliable.</p><ul><li id="0c4a">New API endpoints for Argo Events</li><li id="d65d">New event-flow page</li><li id="379d">Create, edit, and view log event sources and sensors in the UI</li><li id="ff13">Embeddable widgets</li><li id="9cb9">New workflow log viewer</li><li id="5094">Configurable “Get Help” button</li><li id="d657">More configurable link buttons (e.g. for linking into your logging facility)</li><li id="1e6f">Seamless reconnection on network errors</li><li id="9264">Refactored code to use more robust React functional components</li></ul><p id="f8ca">The<strong> event-flow page</strong> allows users to understand how event sources and sensors are connected together, as well as linking in the workflows created by triggers, and displaying animations whenever a message is seen.</p><figure><p><img alt="Image for post" src="https://miro.medium.com/proxy/1*qi3-DdjCLGEa3V86YhCZyQ.png"></p><figcaption>Event-flow</figcaption></figure><p id="3b26">You can <strong>create and update event sources and sensors</strong> directly in the user interface using the same visual language we use for workflows:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1334/1*CnLN8MIMQoofSlpAaDSGfg.png" width="667" height="274" srcset="https://miro.medium.com/max/552/1*CnLN8MIMQoofSlpAaDSGfg.png 276w, https://miro.medium.com/max/1104/1*CnLN8MIMQoofSlpAaDSGfg.png 552w, https://miro.medium.com/max/1280/1*CnLN8MIMQoofSlpAaDSGfg.png 640w, https://miro.medium.com/max/1334/1*CnLN8MIMQoofSlpAaDSGfg.png 667w" sizes="667px" data-old-src="https://miro.medium.com/max/60/1*CnLN8MIMQoofSlpAaDSGfg.png?q=20"></p></div></div><figcaption>Event Sources</figcaption></figure><p id="3435">We’ve added some simple <strong>widgets </strong>you can use to embed the status and progress of a workflow or the latest workflow created by a workflow template or cron workflow:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1238/1*7iql7XVD9v9-1_-UfjO4LA.png" width="619" height="721" srcset="https://miro.medium.com/max/552/1*7iql7XVD9v9-1_-UfjO4LA.png 276w, https://miro.medium.com/max/1104/1*7iql7XVD9v9-1_-UfjO4LA.png 552w, https://miro.medium.com/max/1238/1*7iql7XVD9v9-1_-UfjO4LA.png 619w" sizes="619px" data-old-src="https://miro.medium.com/max/52/1*7iql7XVD9v9-1_-UfjO4LA.png?q=20"></p></div></div><figcaption>Widgets</figcaption></figure><p id="f0ac">Rather than editing your workflow by hand, you can also <strong>submit from a template</strong>:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1150/1*3c0kAYITJpSt4A4FtbvRsA.png" width="575" height="237" srcset="https://miro.medium.com/max/552/1*3c0kAYITJpSt4A4FtbvRsA.png 276w, https://miro.medium.com/max/1104/1*3c0kAYITJpSt4A4FtbvRsA.png 552w, https://miro.medium.com/max/1150/1*3c0kAYITJpSt4A4FtbvRsA.png 575w" sizes="575px" data-old-src="https://miro.medium.com/max/60/1*3c0kAYITJpSt4A4FtbvRsA.png?q=20"></p></div></div><figcaption>Workflow Creator</figcaption></figure><p id="b213">The log viewer has been updated to allow you to view the init and wait containers easier (helping debug artifact issues). It also allows you to <strong>tail the whole workflow</strong>:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1626/1*aDmxHb6qK0YXPFDqN-bnlQ.png" width="813" height="736" srcset="https://miro.medium.com/max/552/1*aDmxHb6qK0YXPFDqN-bnlQ.png 276w, https://miro.medium.com/max/1104/1*aDmxHb6qK0YXPFDqN-bnlQ.png 552w, https://miro.medium.com/max/1280/1*aDmxHb6qK0YXPFDqN-bnlQ.png 640w, https://miro.medium.com/max/1400/1*aDmxHb6qK0YXPFDqN-bnlQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*aDmxHb6qK0YXPFDqN-bnlQ.png?q=20"></p></div></div></div><figcaption>Log Viewer</figcaption></figure><p id="e514">If you want to try it yourself, you can take a look around the <a href="https://workflows.apps.argoproj.io/" rel="noopener"><strong>test environment</strong></a><strong>.</strong></p><p id="ed2e">We have an extensive demo video you can watch online from January’s community meeting (starts at 41m):</p><figure><div></div></figure><h2 id="a0d4">Controller High-Availability</h2><p id="c675">The v3.0 release introduces a hot-standby workflow controller feature for high availability and quick recovery by leveraging the Kubernetes leader election feature. The default install enables leader election and one has a pod, which is the leader. Whenever a controller pod crashes, Kubernetes will restart it. To reduce startup time, you can now run two pods. The second pod will be on hot-standby and take over immediately if the leader dies.</p><pre><span id="43b2">kubectl scale deployment/workflow-controller --replicas=2 </span></pre><h2 id="5b79">Key-Only Artifacts</h2><p id="f857">Argo Workflows v3.0 introduces a default artifact repository reference and key-only artifacts, two new features that work together.</p><ul><li id="83b6">Users can configure a default artifact repository for their namespace rather than having to define it explicitly for each workflow.</li><li id="98bd">Workflow specifications do not need to provide non-key fields (e.g. bucket, username/password secret key). They can use just the key (hence “key-only”), and the non-key fields will be inherited from the artifact repository.</li><li id="e292">Users can specify the key to reference artifacts globally without using parameterized inputs and outputs.</li><li id="fc9b">Easier to specify fan-in artifact patterns, simplifying map-reduce style workflows.</li></ul><p id="c415">As a consequence, we no longer need to replicate non-key elements in manifests, reducing the disk-space needed for workflows.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1766/1*jqBXCrmex2GmJYj_ZlTwZQ.png" width="883" height="483" srcset="https://miro.medium.com/max/552/1*jqBXCrmex2GmJYj_ZlTwZQ.png 276w, https://miro.medium.com/max/1104/1*jqBXCrmex2GmJYj_ZlTwZQ.png 552w, https://miro.medium.com/max/1280/1*jqBXCrmex2GmJYj_ZlTwZQ.png 640w, https://miro.medium.com/max/1400/1*jqBXCrmex2GmJYj_ZlTwZQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*jqBXCrmex2GmJYj_ZlTwZQ.png?q=20"></p></div></div></div></figure><h2 id="424c">New Repository Location</h2><p id="ab61">We’ll be renaming the Argo workflow repository to <code>argo-workflows</code>rather than <code>argo</code>. The new name makes it clear that this is the repo for Argo Workflows and not the overall Argo Project.</p><p id="d21a">Github automatically forwards when a repository is renamed, so users should not be significantly impacted.</p><h2 id="1ebd">Go Modules + Go Client v1.19</h2><p id="7eba">In 2020, we migrated to Go modules. Unfortunately, migrating to Go modules is a breaking change and we never completed the work, and it was still not possible to <code>go get github.com/argoproj/argo</code> without some hackery. Release v3 will fix this.</p><h2 id="e08b">v2.12 Long-term Support</h2><p id="2529">We plan to provide long-term support for v2.12. There will be bug fixes, but no new features, for 6+ months.</p><p id="a9d3">What we expect to back-port:</p><ul><li id="0ce7">Bug fixes.</li><li id="a583">Changes to complete features new in v1.12 (e.g SSO+RBAC).</li></ul><p id="57d1">We don’t plan to back-port:</p><ul><li id="b6e9">UI bug fixes that are based on refactoring that is unique to v3.0. But you can run the v3.0 UI with the v2.12 controller.</li><li id="5658">New features.</li></ul><p id="295a">Argo Workflows v3.1 will contain enhancement to make it easier to write fan-out-fan-in workflows using artifacts, and well as conditional artifacts.</p><p id="f19c">Nothing as big as this is the work of one person, so beyond the core team, we must recognize these major contributors:</p><ul><li id="5fcb">Daisuke Taniwaki — Preferred Networks</li><li id="0754">Yuan Tang — Ant Group</li><li id="79bc">Mark White</li><li id="1c43">Daniel Herman</li><li id="3e99">Sam Elder — Keblotix</li><li id="25af">Michael Crenshaw — Colaberry/CCRi</li><li id="1d3f">Xianlu Bird — Aliyun</li><li id="d18e">Peter Salanik — CoreWeave</li><li id="e8b9">J.P. Zivalich — Pipekit</li><li id="30d6">Niklas Hansson — Sandvik CODE</li><li id="f435">Antoine Dao — Pollination</li><li id="8eca">Clemens Lange — CERN</li><li id="ba08">Vaibhav Page — Blackrock</li><li id="c4e7">Sumit Nagal — Intuit</li><li id="2139">David Breitgand — IBM</li></ul></div></div></div>]]>
            </description>
            <link>https://blog.argoproj.io/argo-workflows-v3-0-4d0b69f15a6e</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991077</guid>
            <pubDate>Mon, 01 Feb 2021 17:47:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why shorter food supply chains aren’t necessarily better]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25991044">thread link</a>) | @finphil
<br/>
February 1, 2021 | https://nuadox.com/post/641939640543232000/short-food-supply-chains-conversation | <a href="https://web.archive.org/web/*/https://nuadox.com/post/641939640543232000/short-food-supply-chains-conversation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="641939640543232000">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/641939640543232000/short-food-supply-chains-conversation"><h2>Let’s talk logistics: Why shorter food supply chains aren’t necessarily better</h2></a>
                                <figure data-orig-height="853" data-orig-width="1280"><img src="https://64.media.tumblr.com/3b6d3de257c70ad7108584d25c3ed612/e23af1d6cf07b765-fe/s1280x1920/5b2470073c2a32381da64c12642abe9e83d58676.png" data-orig-height="853" data-orig-width="1280" width="1280" height="853" alt="image"></figure><p><b>- By Richard Gray , Horizon -</b></p><p>

Fears over supermarket shortages during the early stages of the Covid-19 pandemic <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Feit.europa.eu%2Fnews-events%2Fnews%2Feit-food-report-reveals-impact-covid-19-pandemic-european-food-behaviours&amp;t=Y2VlMjFiMWI3Yjc2YjJkNjUwY2QyYTZmNDUxZGQwZDRjZjQxYjY4NixZZVNEMG1LMQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612413273">led many people to buy their food from local producers</a>, raising the prospect of a transformation in the way people get their food in the future. But while eating locally and shorter supply chains are <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fec.europa.eu%2Feip%2Fagriculture%2Fsites%2Fagri-eip%2Ffiles%2Feip-agri_brochure_short_food_supply_chains_2019_en_web.pdf&amp;t=ZjMzMWZkODZiMWVjNGUyNGUzZTllMWFmMDdlMTBmYjFlODY4ZDExMyxZZVNEMG1LMQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612413273">often viewed as a more sustainable alternative to our global food system</a>, the reality is much more complicated, explains Dr Tessa Avermaete, a bioeconomist at the Katholieke Universiteit Leuven in Belgium.

<br></p><p><b>What has the pandemic revealed about the way Europe gets its food?</b></p><p>On the consumer side there were really only a few problems with supplies in Europe. In Belgium, for example, we had some issues with yeast because suddenly everyone was at home and started baking. There were also some issues with <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.cbi.eu%2Fnews%2Fbittersweet-impact-covid-19-cocoa-chocolate-market&amp;t=Njc1OGY4YjBlYmMzYjUxMzQ2YjE1Zjk4ZWYxOGRlMTVkN2Q4NDM0MixZZVNEMG1LMQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612413273">chocolate due to the cacao supply</a> and a specific type of <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.euronews.com%2F2020%2F12%2F20%2Fgreek-olive-harvest-hit-as-pandemic-leads-to-labour-shortage&amp;t=OGVmYzk1YjkxNmY0Zjg1MjU5MTU4ZjE0ODg1ZTM5MjA1NjZjZmNkOCxZZVNEMG1LMQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612413273">olives</a>. Not really things you need for a healthy diet.&nbsp;</p><p>What I think the Covid-19 crisis has shown is that actually the food supply chains are very robust. No one in Europe really went hungry because of Covid-19. But some farmers in Europe have suffered, particularly if they are exporting. In the potato sector, those exporting to China, for example, had tonnes of potatoes left. It has shown that we need to think about what happens when food supply chains are disrupted.</p><p><b>What have been the solutions to that?</b></p><p>One thing that people have talked a lot about is <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwww.fao.org%2Fdocuments%2Fcard%2Fen%2Fc%2Fcb1020en%2F&amp;t=NDA4YjkzODY1MDk0YjkxOGE1M2UwYTY5NDIyZDU3OGE4NTY0MzlkYixZZVNEMG1LMQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612413273">shorter supply chains</a>. Certainly, during the pandemic many more people have been finding they have a local farmer or supplier out there they can buy from. This can be good for the local economy and be a way of getting healthy food. But we have to be honest – it is only a tiny part of the overall market. And it is quite likely that people will go back to their normal retailer once the crisis is over. But what I like is that it has started to get people thinking more about where their food comes from. When you look at the food system it is actually quite complex.</p><p><b>Is buying local always more sustainable than buying from big retailers? </b></p><p>It’s easy to think that doing things locally is the right solution because it might on the surface seem to have a lower (environmental) footprint and reduce the risk of disruption. But not everything can be grown everywhere. There are some regions that have the right kind of fertile land needed for arable crops while others are better suited as pasture for livestock. Some land is suitable for soy but can’t be used to grow apple trees on. It makes sense to use your land in the way it is best suited for, and this is what our global food supply chains have allowed us to do.</p><p>We did some calculations at our university that if we tried to produce the livestock we consume in Belgium completely locally, then we would need double the land we have today just to produce fodder for the animals. In many cases it is more sustainable to produce food somewhere else and import it than grow it locally. Growing something in a heated greenhouse at a local farm can require more energy than growing it somewhere with more suitable climate and importing it by boat. The same applies with water - if it is too dry where you live, it can take a lot of extra water from the environment to grow some crops.</p><p>Bad weather conditions and plant diseases, or political disruption and wars could also prevent food from being produced locally at certain times. Global trade has given us some resilience to these.&nbsp;&nbsp;</p><p><b>Do local food networks have any advantages?</b></p><p>During the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fcordis.europa.eu%2Fproject%2Fid%2F613532&amp;t=MDNjMTMzY2MyMzIwOWY1MDRlZTEwZGRhM2U0NTIzY2NjNTk5ZjFkMCxZZVNEMG1LMQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612413273">TRANSMANGO project</a> (to assess the vulnerability and resilience of Europe’s food systems) we looked at how certain <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs12571-018-0860-x&amp;t=ZmE0N2QwODBlMzI3OWU2ZDU0MTVkZTQ2ZGVkMjUzOGNhNzA1Mjc4MyxZZVNEMG1LMQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612413273">alternative food networks contribute to food security</a>. These are things like small organic farms, farmers markets, local deliveries and community supported agriculture. They have a really important social factor because they can bring together communities. But in terms of overall food availability their contribution is limited. And we also saw that many of these alternative food networks are only accessible to people in middle and high socioeconomic classes. They don’t reach out to people in the lower classes.</p><p><b>Are there other disadvantages?</b></p><p>There is also an important issue when it comes to food processing. With a lot of these initiatives you get unprocessed food – people have to do a lot of preparation to be able to then eat it. That ability to prepare food is just as important as the availability itself as you can only eat food if you know how to prepare it properly.&nbsp;Unless you know this, you are going to be food insecure.</p><p><b>What do you mean by being ‘food insecure’?</b></p><p>It’s about food availability, but also it’s about nutritional value. If we look at a global level, we produce enough calories to feed the world. But if you look in terms of fruit and vegetables, there is still a lack. So, the problem is that we don’t have enough to feed the world in a healthy way. But that’s just one side of the story – there are so many people who are overweight and the health costs that go together with that are huge. Here in Europe it is an area that needs far more attention than malnutrition.</p><p><b>Are there any problems you see coming in the future?&nbsp;</b></p><p>One of the biggest challenges at the moment is the need for policies that strengthen the position of the farmer and simultaneously reduce the environmental impact of the sector. We need governments that take action based on scientific evidence, not based on beliefs or driven by electoral concerns. I have no doubt that Europe has smart and ambitious farmers, but they need to be incentivised to take actions that contribute to a more sustainable, future-proof food system. Local food networks have a part to play, but I hope we don’t lose sight of how important big producers are for food security too.</p><p><i>The research in this article was funded by the EU.</i></p><p><i> This post&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fhorizon-magazine.eu%2Farticle%2Fqa-why-shorter-isn-t-necessarily-better-when-it-comes-food-supply-chains.html&amp;t=MWNiMDdmM2Y3MjVjM2JmYzc2YjUyY2FiZmQ2NGFiMGQ3NTUxNDY1NyxZZVNEMG1LMQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612413273">Q&amp;A: Why shorter isn’t necessarily better when it comes to food supply chains</a>&nbsp;was originally published on&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fhorizon-magazine.eu%2F&amp;t=ZjUwMzE0ZWYzMWQ3OTRkOWVkMTMyMjdmZTAzMDliNTg3Y2QwZDMyMixZZVNEMG1LMQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612413273">Horizon: the EU Research &amp; Innovation magazine | European Commission</a>&nbsp;under a Creative Commons license.</i></p><p>–</p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/632440031725912064/food-waste-and-cities">Food waste: Cities can make the difference</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/food">food</a>
                                    
                                        <a href="https://nuadox.com/tagged/supply-chain">supply chain</a>
                                    
                                        <a href="https://nuadox.com/tagged/logistics">logistics</a>
                                    
                                        <a href="https://nuadox.com/tagged/agriculture">agriculture</a>
                                    
                                        <a href="https://nuadox.com/tagged/sustainability">sustainability</a>
                                    
                                        <a href="https://nuadox.com/tagged/nutrition">nutrition</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                        <a href="https://nuadox.com/tagged/featured">featured</a>
                                    
                                        <a href="https://nuadox.com/tagged/economics">economics</a>
                                    
                                        <a href="https://nuadox.com/tagged/retail">retail</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/641939640543232000/short-food-supply-chains-conversation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991044</guid>
            <pubDate>Mon, 01 Feb 2021 17:45:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cult of Best Practice]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25990929">thread link</a>) | @zdw
<br/>
February 1, 2021 | https://domk.website/blog/2021-01-31-cult-of-best-practise.html | <a href="https://web.archive.org/web/*/https://domk.website/blog/2021-01-31-cult-of-best-practise.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p><time datetime="2021-01-31">31 Jan 2021</time>
    /
    <span>~7 min</span>
  </p>
  


<p>Best practices are, despite the name, not universally good.</p>

<p>Many best practices in programming don’t meet the definition. They spread not based on merit or evidence but thanks to authority bias and social utility. As they spread, they lose nuance. As they lose nuance, they become easier to evangelise. Combined with lack of experience, they can lead to cult-like behaviour.</p>

<p>Think of an engineering team that got obsessed with a best practice, like test-driven development or writing user stories, to the point of detriment. Many developers have fallen into that trap, myself included.</p>

<p>Why can best practices be harmful? Why do we like following them? When and how do they go wrong? To answer these questions, we need to understand where they come from and how they spread in the context of programming.</p>

<h2 id="impostor-best-practices">Impostor Best Practices</h2>

<p>The main reason some programming best practices are harmful is that they are not real best practices.</p>

<p>Look at the official definition: “A best practice is a method or technique that has been generally accepted as superior to any alternatives because it produces results that are superior to those achieved by other means […]”. <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> The key parts of the definition are “generally accepted” and “superior to any alternatives”.</p>

<p>The problem with many programming best practices is that they <em>pretend</em> to conform to that definition, but they do not.</p>

<p>Some best practices aren’t generally accepted. They come from different, less reliable sources of authority. It could be a prominent individual or a specific community who present something as widely accepted when it’s their own experience or opinion.</p>

<p>We might have a proponent of object-oriented programming saying that it is an accepted best practice, but not everyone agrees. If the proponent is respected and followed in the programming community, many people will put a lot of weight on their opinion, but that doesn’t make it generally accepted. There are different competing paradigms each with their pros and cons.</p>

<p>Some best practices are not superior in outcomes. They claim they are, but objectively there are equivalent alternatives. For example, is functional programming superior to object-oriented? We can’t say one is better than the other, even though they are both presented as a best practice by some.</p>

<p>The problem with superiority is that most programming best practices aren’t evidence-based. Programming is too young, fast-changing and complex to have done the research to establish the evidence for something consistently producing better outcomes. We work in the world of opinions, feelings and anecdotal evidence.</p>

<p>Some best practices are also very volatile. Fast-moving languages and frameworks declare something best practice and supersede it a year later. That isn’t inherently wrong, but it’s a sign of how fast our understanding of best can evolve, while best practices are expected to be time-tested. <sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<p>However, not all best practices in programming are impostors. There are time-tested, generally accepted, and superior practices. For example, the general idea of automated testing now meets that definition.</p>

<p>Nor are all impostor best practices bad. Not being universally accepted can mean they aren’t universally accepted <em>yet</em>. Not being superior in general might be a scope problem, and the practice is superior in specific situations.</p>

<p>However, these cases need to be interpreted with nuance, which brings us to the next problem.</p>

<h2 id="lost-in-translation">Lost In Translation</h2>

<p>Good best practices are <em>simple and universal</em>. Many programming best practices tackle complex issues that require nuance and context — but that nuance and context get lost as the best practice spreads.</p>

<p>Consider this example: someone, through a lot of trial and error, found a good way to tackle a problem. Because of the learning process, they understand the nuances in how and when to apply it.</p>

<p>The solution works for them and they start sharing their lessons as best practice. This gets picked up by people who skipped the learning and went straight to applying it, missing out on some nuance. Those people share it again. A new cohort of people picks it up. They misunderstand it more and share it again.</p>

<p>Soon, all understanding of why the practice works is lost. People are parroting it as a simplified, absolute catchphrase. “Always write the tests before the implementation”. <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup></p>

<p>The complexity can increase over time too. An idea that was originally simple that required a lot of nuanced interpretation is made increasingly complex by people who miss the point.</p>

<p>Take the example of “agile”. Originally a set of 12 principles, it has been turned into monstrous frameworks that oppose those principles by consultancies that sell organisational transformation.</p>

<p>Once all nuance is lost, the conditions are perfect for the idea to spread. It originated from someone with respect, experience, and authority. The simplicity makes it sound easy. People who don’t understand it sell it as a panacea. As a result, people can learn about it quickly and start evangelising. Despite its merit-based origin, it has become a social phenomenon.</p>



<p>The social aspect of how best practices spread helps us answer the next question — why do we like following them?</p>

<p>When we lack the experience and confidence to form our own opinions, we defer to the next best thing: an authority. This is a well-known cognitive bias. <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup></p>

<p>Thanks to the authority bias, best practices have a social utility. They give us something that people are biased to believe that we can lean on. There are many examples of this utility:</p>

<ul>
  <li>A way to hedge our bets. If we are wrong, we can defend ourselves by saying that we just followed best practices. How could someone blame us?</li>
  <li>A way to mimic the best. If someone we see as an authority does something, it’s natural for us to try to learn and copy what they do.</li>
  <li>A virtue-signalling mechanism. If something is “the best”, we naturally want to signal to everyone that we also do what is best.</li>
  <li>A way to fit in. If everyone around us considers something “the best”, we would be hard-pressed to go against our peers.</li>
</ul>

<h2 id="the-cult">The Cult</h2>

<p>Because of the social nature of best practices, it’s easy for herd mentality to kick in.</p>

<p>Imagine a team of inexperienced developers with no one seasoned to lean on. They can’t make all decisions in an informed way — following best practices is the next best option.</p>

<p>They struggle with something, and they search for a solution. They come across a simple-looking practice that addresses their problem, supported by someone prominent. Is your code buggy and unreliable? Write more tests. Is your code hard to test? Adopt test-driven development! <sup id="fnref:3:1" role="doc-noteref"><a href="#fn:3">3</a></sup></p>

<p>Once a solution like that is found, everyone is motivated by the authority and social utility of it. It gets adopted ad absurdum. All nuance is lost. Soon you have a team that insists that every ticket is written as a user story, or that every class has to have tests because it’s <em>best practice</em>.</p>

<h2 id="way-out">Way Out</h2>

<p>It might seem obvious that adopting something obsessively is a bad idea, but many teams out there operate exactly like that.</p>

<p>The way out of the cult starts with understanding what the commonly presented best practices are — a social phenomenon.</p>

<p>Once we realise that, the first step is understanding where they come from and what problem they solve — understand their origins and the subtleties of applying them successfully. <sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup></p>

<p>The next step is to make our own mistakes and learn from them. Break the rules and understand what happens when we don’t follow a particular practice. Follow it to its logical conclusion and see what happens then. <sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup></p>

<p>The trial and error learning involved gives us knowledge much deeper than what we would gain by following the rules.</p>

<p>Having made our own mistakes, the third and final step is to form our own opinions and speak up.</p>

<p>If we’ve understood where a best practice comes from, and we’ve tried what happens when we don’t follow it, we should have the confidence to make and defend our own opinions about it. We can help the rest of our team see the full picture and break the cult.</p>

<p>Going against the flow like that can be hard. Convincing the rest of a team that something they believe in isn’t what it promised to be, requires skill and patience. Telling them won’t be enough. You need to take them on the same learning journey you went on. That’s how you make progress.</p>

<p>To short-circuit that learning process and prevent best practice cults from forming in the first place, you need to have enough senior engineers on your teams. Each team needs to have someone who is experienced and confident enough to become a trusted authority for their colleagues. Someone who can make informed decisions and bring the necessary nuance.</p>

<p>We need to encourage open-mindedness and independent thinking. We need to scrutinise best practices and understand them in depth. That’s how we stop the cult.</p>

<hr>



</article></div>]]>
            </description>
            <link>https://domk.website/blog/2021-01-31-cult-of-best-practise.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990929</guid>
            <pubDate>Mon, 01 Feb 2021 17:37:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pip has dropped support for Python 2]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 49 (<a href="https://news.ycombinator.com/item?id=25990891">thread link</a>) | @feross
<br/>
February 1, 2021 | https://pip.pypa.io/en/stable/news/#id4 | <a href="https://web.archive.org/web/*/https://pip.pypa.io/en/stable/news/#id4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<li><p><strong>PROCESS</strong> Version numbers are now simply <code><span>X.Y</span></code> where the leading <code><span>1</span></code>
has been dropped.</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> Dropped support for Python 3.1.</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> Removed the bundle support which was deprecated in
1.4. (#1806)</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> File lists generated by <cite>pip show -f</cite> are now
rooted at the location reported by show, rather than one (unstated)
directory lower. (#1933)</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> The ability to install files over the FTP protocol
was accidentally lost in pip 1.5 and it has now been decided to not restore
that ability.</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> PEP 440 is now fully implemented, this means that
in some cases versions will sort differently or version specifiers will be
interpreted differently than previously. The common cases should all function
similarly to before.</p></li>
<li><p><strong>DEPRECATION</strong> <code><span>pip</span> <span>install</span> <span>--download-cache</span></code> and
<code><span>pip</span> <span>wheel</span> <span>--download-cache</span></code> command line flags have been deprecated and
the functionality removed. Since pip now automatically configures and uses
it’s internal HTTP cache which supplants the <code><span>--download-cache</span></code> the
existing options have been made non functional but will still be accepted
until their removal in pip v8.0. For more information please see
<a href="https://pip.pypa.io/en/stable/reference/pip_install.html#caching">https://pip.pypa.io/en/stable/reference/pip_install.html#caching</a></p></li>
<li><p><strong>DEPRECATION</strong> <code><span>pip</span> <span>install</span> <span>--build</span></code> and <code><span>pip</span> <span>install</span> <span>--no-clean</span></code> are now
<em>NOT</em> deprecated.  This reverses the deprecation that occurred in v1.5.3.
(#906)</p></li>
<li><p><strong>DEPRECATION</strong> Implicitly accessing URLs which point to an origin which is
not a secure origin, instead requiring an opt-in for each host using the new
<code><span>--trusted-host</span></code> flag (<code><span>pip</span> <span>install</span> <span>--trusted-host</span> <span>example.com</span> <span>foo</span></code>).</p></li>
<li><p>Allow the new <code><span>--trusted-host</span></code> flag to also disable TLS verification for
a particular hostname.</p></li>
<li><p>Added a <code><span>--user</span></code> flag to <code><span>pip</span> <span>freeze</span></code> and <code><span>pip</span> <span>list</span></code> to check the
user site directory only.</p></li>
<li><p>Silence byte compile errors when installation succeed. (#1873)</p></li>
<li><p>Added a virtualenv-specific configuration file. (#1364)</p></li>
<li><p>Added site-wide configuration files. (1978)</p></li>
<li><p>Added an automatic check to warn if there is an updated version of pip
available. (#2049)</p></li>
<li><p><cite>wsgiref</cite> and <cite>argparse</cite> (for &gt;py26) are now excluded from <cite>pip list</cite> and
<cite>pip freeze</cite>. (#1606, #1369)</p></li>
<li><p>Add <code><span>--client-cert</span></code> option for SSL client certificates. (#1424)</p></li>
<li><p><cite>pip show --files</cite> was broken for wheel installs. (#1635, #1484)</p></li>
<li><p>install_lib should take precedence when reading distutils config.
(#1642, #1641)</p></li>
<li><p>Send <cite>Accept-Encoding: identity</cite> when downloading files in an attempt to
convince some servers who double compress the downloaded file to stop doing
so. (#1688)</p></li>
<li><p>Stop breaking when given pip commands in uppercase (#1559, #1725)</p></li>
<li><p>pip no longer adds duplicate logging consumers, so it won’t create duplicate
output when being called multiple times. (#1618, #1723)</p></li>
<li><p><cite>pip wheel</cite> now returns an error code if any wheels fail to build. (#1769)</p></li>
<li><p><cite>pip wheel</cite> wasn’t building wheels for dependencies of editable requirements.
(#1775)</p></li>
<li><p>Allow the use of <code><span>--no-use-wheel</span></code> within a requirements file. (#1859)</p></li>
<li><p>Attempt to locate system TLS certificates to use instead of the included
CA Bundle if possible. (#1680, #1866)</p></li>
<li><p>Allow use of Zip64 extension in Wheels and other zip files. (#1319, #1868)</p></li>
<li><p>Properly handle an index or --find-links target which has a &lt;base&gt; without a
href attribute. (#1101, #1869)</p></li>
<li><p>Properly handle extras when a project is installed via Wheel. (#1885, #1896)</p></li>
<li><p>Added support to respect proxies in <code><span>pip</span> <span>search</span></code>.
(#1180, #932, #1104, #1902)</p></li>
<li><p><cite>pip install --download</cite> works with vcs links. (#798, #1060, #1926)</p></li>
<li><p>Disabled warning about insecure index host when using localhost. Based off of
Guy Rozendorn’s work in #1718. (#1456, #1967)</p></li>
<li><p>Allow the use of OS standard user configuration files instead of ones simply
based around <code><span>$HOME</span></code>. (#2021)</p></li>
<li><p>When installing directly from wheel paths or urls, previous versions were not
uninstalled. (#1825, #804, #1838)</p></li>
<li><p>Detect the location of the <code><span>.egg-info</span></code> directory by looking for any file
located inside of it instead of relying on the record file listing a
directory. (#2075, #2076)</p></li>
<li><p>Use a randomized and secure default build directory when possible.
(#1964, #1935, #676, #2122, CVE-2014-8991)</p></li>
<li><p>Support environment markers in requirements.txt files. (#1433, #2134)</p></li>
<li><p>Automatically retry failed HTTP requests by default. (#1444, #2147)</p></li>
<li><p>Handle HTML Encoding better using a method that is more similar to how
browsers handle it. (#1100, #1874)</p></li>
<li><p>Reduce the verbosity of the pip command by default. (#2175, #2177, #2178)</p></li>
<li><p>Fixed <a href="https://github.com/pypa/pip/issues/2031">#2031</a> - Respect sys.executable on OSX when installing from
Wheels.</p></li>
<li><p>Display the entire URL of the file that is being downloaded when downloading
from a non PyPI repository. (#2183)</p></li>
<li><p>Support setuptools style environment markers in a source distribution. (#2153)</p></li>
</div></div>]]>
            </description>
            <link>https://pip.pypa.io/en/stable/news/#id4</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990891</guid>
            <pubDate>Mon, 01 Feb 2021 17:34:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analysing Clubhouse’s Growth Strategy: Invite-Only Exclusivity]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25990845">thread link</a>) | @PeteBoyle
<br/>
February 1, 2021 | https://have-a-word.com/clubhouse-marketing | <a href="https://web.archive.org/web/*/https://have-a-word.com/clubhouse-marketing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				
				<div id="post-content">
				
				
				
<p>Clubhouse is the brand new social media network that’s taking the marketing world by storm.&nbsp;</p>



<p>Seems like every time I log onto other platforms people are either talking about Clubhouse or inviting people to their clubhouse “rooms”.</p>



<p>What’s incredible though is how, at the time of writing, Clubhouse has grown to ~2,000,000 users despite being less than a year old.&nbsp;&nbsp;</p>



<p>With such meteoric growth, we thought Clubhouse’s growth strategy and business was worth a quick analysis.&nbsp;</p>



<p>Here’s what we’ve dug up.&nbsp;&nbsp;</p>



<h2><span id="Clubhouse_in_30_seconds"></span>Clubhouse in 30 seconds<span></span></h2>



<ul><li><strong>Who are we analysing today?: </strong>Clubhouse</li><li><strong>What does Clubhouse do?: </strong>It’s a live-audio social media app</li><li><strong>Why should you care?: </strong>It’s the hottest new social platform and growing at <em>lightspeed</em>.</li><li><strong>How are they doing it?:</strong> Invite-only memberships + strategic PR/content buzz.&nbsp;</li><li><strong>When was Clubhouse founded?</strong> – In March 2020</li></ul>



<h2><span id="Clubhouse_user_base"></span>Clubhouse user base<span></span></h2>



<p>According to the Clubhouse blog, in a single week during January 2021 they managed to get 2,000,000 users.&nbsp;&nbsp;</p>



<p>Up from December 2020’s total of 600,000, which is crazy growth.&nbsp;&nbsp;&nbsp;</p>







<p>According to that same article, those users were made up of…</p>



<ul><li>Musicians</li><li>Scientists</li><li>Creators</li><li>Athletes</li><li>Comedians</li><li>Parents</li><li>Entrepreneurs</li><li>Stock traders</li><li>Non-profit leaders</li><li>Authors</li><li>Artists</li><li>Real-estate agents</li><li>Sports fans</li><li>And more</li></ul>



<p>Which doesn’t really help us in analysing their ideal customer base.&nbsp;&nbsp;</p>



<p>In my experience, I’ve seen a huge number of marketers, VCs, and SaaS founders on the platform.&nbsp;&nbsp;</p>



<p>The main interesting point is how they grew their user base so quickly.&nbsp;</p>



<p>That 600,000 number for 2020 was taken in December, and the 2,000,000 number was in January 2021.&nbsp;</p>



<p>Which means they grew their user base by more than 50% in a 1-2 month time period.&nbsp;&nbsp;</p>



<p>It also puts them at a higher user base than other social media platforms when they were in their first year.&nbsp;</p>







<p>We’ll cover how we think they did this shortly.&nbsp;</p>



<h2><span id="Clubhouse_financials"></span>Clubhouse financials<span></span></h2>



<p>This is where things get interesting with Clubhouse.&nbsp;&nbsp;</p>



<p>There was a lot of buzz in May 2020 when they closed their first round of funding of $10,000,000.</p>



<p>This initial funding round led to them being valued at a whopping $100,000,000. Not bad for 2 months of operation.&nbsp;</p>



<p>However, in 2021, they <a href="https://www.crunchbase.com/organization/clubhouse-voice/company_financials" target="_blank" rel="noreferrer noopener">closed a Series B</a> of $100,000,000 which has pushed their valuation to $1,000,000,000 ($1B).</p>



<div><figure><img loading="lazy" src="https://lh6.googleusercontent.com/RpiCBFv9opf3p4l2w91kX0UjZ4OOhNZureu_eAmfxWYVKRU2HUmLpIWUfjE13ZLOhTFn6m2gLMIkk-pyD6DYWWmUFPte-ZWN3F7TRVWXeYwjQ1QKbDhi5ODffidIWSxSBCihyjxo" alt="Clubhouse funding and valuation" width="789" height="487" title="Points scored" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>According to Clubhouse, that Series B is funding from 180 different investors. Which is a crazy huge number and must make their cap table a nightmare to manage.&nbsp;&nbsp;</p>



<h2><span id="Clubhouses_revenue_model"></span>Clubhouse’s revenue model<span></span></h2>



<p>Right now, Clubhouse doesn’t actually have any revenue model.&nbsp;&nbsp;</p>



<p>They don’t charge for usage nor do they run ads on the platform.&nbsp;</p>



<p>Without a public revenue model, it’s hard to say how that $1B valuation is justified.&nbsp;&nbsp;</p>



<p>We’re sure they’ve got plans on monetisation strategies, but they’re not yet public knowledge.&nbsp; We have a few ideas of what they might explore, but it’s all just conjecture right now so we won’t spend a lot of time on this.&nbsp;</p>



<p>Here are a few options we think they might explore.&nbsp;&nbsp;</p>



<ul><li><strong>Sponsorships for people who can generate large audiences</strong> (maybe even build out a sponsor &lt;&gt; influencer management dashboard)</li><li><strong>A membership/patron system like Patreon/Only Fans</strong> (influencers have premium fans who get exclusive access)</li><li><strong>Built-in checkout and payments</strong> (so speakers can generate sales of their books/courses directly from Clubhouse)</li><li><strong>Tip-system like Twitch / YouTube live streaming</strong> (users tip a few bucks if they like the content)</li></ul>



<p>All is hypothetical and pure conjecture at this point.&nbsp;</p>



<p>It’ll be interesting to see how this side of the product develops.&nbsp;&nbsp;</p>



<h2><span id="Clubhouses_growth_strategy"></span>Clubhouse’s growth strategy<span></span></h2>



<div><figure><img loading="lazy" src="https://lh5.googleusercontent.com/11nHwbMdGfJEtmcn1eOsPR1MKw3p0QAH5wl8ImebeKAwt9XLIt41hciHuVbrKo3oLdPsv6t6vP8RvTeGtdhKWgz_i0EW11jU4qsoP2t00NKUWfDS0m5ObdBUZq7hE0ilY9sLs0BO" alt="Clubhouse's velvet rope strategy" width="685" height="513" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>Clubhouse is using what’s known as the “Velvet Rope” strategy. They’re creating exclusivity with a combination of invite-only memberships and strategic hype.&nbsp;</p>



<p>If you’ve never heard of the Velvet Rope strategy, think of the VIP area of a club.&nbsp;</p>



<p>It’s often separated by a velvet rope, which separates the “VIPs” from the rest of the crowd.&nbsp;</p>



<p>If you want in, you either need to be special or be invited in by someone special.&nbsp;&nbsp;</p>



<p>Once you’re in, you are now one of the “special people”.&nbsp;</p>



<p>Anything behind that velvet rope is seen as more desirable because it’s hard to acquire. It’s exclusive.</p>



<p>Clubhouse’s invitation-only approach makes their app exclusive, thus, making more people want it.&nbsp;&nbsp;&nbsp;&nbsp;</p>



<h2><span id="Why_is_Clubhouses_Velvet_Rope_Strategy_working_so_well"></span>Why is Clubhouse’s Velvet Rope Strategy working so well?&nbsp;<span></span></h2>



<p>There are some simple, but highly effective psychological principles at play with this strategy.&nbsp;</p>



<p>Let’s unpack them.&nbsp;</p>



<h3>Reason #1) Exclusivity builds FOMO.</h3>



<p>The more insiders are talking about Clubhouse, the more outsiders will want in.&nbsp;</p>



<div><figure><img loading="lazy" src="https://lh4.googleusercontent.com/ThR705zzdBmED6aATShcjoybpFze5sqvfItYOMTkoYpBw4YYfMj-w_IrYZ9zOi74wAs8QYA9wgSOIPShsnVxQM0ZB8R0I8o2A91nYPwrThAkuc5rfuWI0T2vOpz6QCqJ94aW2ZeA" alt="Clubhouse's velvet rope invite-only strategy" width="659" height="493" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>And if you spend any time on social, you’ll know a lot of people are talking about Clubhouse.&nbsp;&nbsp;</p>



<p><strong><em>This creates a lot of demand for relatively little supply.&nbsp;</em></strong></p>



<p>The result is people begging their friends for an invite, and people with invites treating them with a lot of care and consideration.</p>



<div><figure><img loading="lazy" src="https://lh4.googleusercontent.com/4sPsfM98Co6BvHKOJDEnLP5ZjG7G0dKtpGEeTkdrfnvvUEUDyPDUVGEMiqncTwjrU6XjsvvaiWXX75a-W0NHwvuBD-u5WaVE0pE2Sf974HVl8-tUEsbPnlrAT0HO_38q5RPybNTB" alt="Clubhouse viral marketing" width="669" height="821" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<div><figure><img loading="lazy" src="https://lh3.googleusercontent.com/iVLyRrI_LvEDUurlGVW1KqUPCe1jOK-sxx4aWwdOEq96nLX0G8btzWF_ysIb7OImq1eY9YCKg9j5fTBaRLSvmR271dNE9D-yres7LWbGk_yITOzlOIN0ygdDPLFKlLcjRdFmYelU" alt="C lubhouse's viral social media marketing" width="690" height="1190" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<h3>Reason #2) Invites from friends build trust in the app.</h3>



<p>It’s not just about getting invited to the app — <em>it’s about getting invited by a friend.</em></p>



<p>If you were to just receive an invite from a random internet stranger….it’d be weird, right?&nbsp;</p>



<p>And if the brand you’d never heard of sent it, would you check it out? Probably not.&nbsp;</p>



<p>But Clubhouse invites come from your friends.&nbsp;</p>



<p>And that means you’re getting “in” to something that’s already been vetted by someone you know and trust.&nbsp;</p>



<p><strong><em>You trust them, they trust Clubhouse, ergo, you trust Clubhouse.</em></strong>&nbsp;</p>



<div><figure><img loading="lazy" src="https://lh6.googleusercontent.com/FOSIARMhDkXCqYfnn5KQ0kL-4B1Lrwq6K3XR_0eWwOYtULABrpB1xalnhyHV0XHhswIcV2apm1zvYklUUhZynsbYs-NvMg9xD6qmH5PlhiUhjHLYLX16CWFNuj7X7CrDPFlJtoih" alt="Friend invites build more trust" width="696" height="521" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<h3>Reason #3) Invites from friends are more likely to convert.</h3>



<p>This doesn’t need any explanation.&nbsp;</p>



<p>The combination of FOMO and the trust friendly invites create means you’re way more likely to take the action.&nbsp;</p>



<h3>Reason #4) Invites from friends make it cheap to scale&nbsp;</h3>



<p>You might think gating your tool or service behind this kind of invite-only joining process would hamper your chances.&nbsp;</p>



<p>But it actually does the opposite.&nbsp;</p>



<p>As we’ve already mentioned, those invites obliterate any trust issues because a friend has already vetted the service.&nbsp;&nbsp;</p>



<p>So the actual sign up is an action happily taken.&nbsp;&nbsp;</p>



<p>It also doesn’t require any financial cost beyond finding the initial users.&nbsp;&nbsp;</p>



<p>As for scale, it also works insanely well.&nbsp;</p>



<p>Most brands can only dream of having each customer refer two of their friends.&nbsp;&nbsp;</p>



<p>If you make the process easy (as Clubhouse has) the potential scale is incredible.&nbsp;</p>



<p>The best illustration of this is to imagine you have a single penny.&nbsp;</p>



<p>Each day that penny’s value doubles.&nbsp;&nbsp;</p>



<p>So on day one you’d have 1p, day two that would double to 2p. Day three would see you collect 4p and so on.&nbsp;</p>



<p>Within 30 days you’d end up with over $5,300,000 dollars.&nbsp;&nbsp;</p>



<div><figure><img loading="lazy" src="https://lh4.googleusercontent.com/JAOBS65_TN66h_BAtglDGlHmCUZjTly5XbsNhafEk4uMXgQmiarbvT2sHDx1hrHc2RvgA9gpGjXvSrJUhycxwlw0tQr0UNKqipZe5hCUszx4JLVanGIS99BYu_y-hdnmA7OP2MBf" alt="Doubling users exponential scale" width="718" height="448" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>Once you hit a critical mass of users the scale from a double invite pays huge rewards.&nbsp;</p>



<p>Clubhouse’s invite approach offers the same kind of benefits.&nbsp;</p>



<p>Sure, it might be a low start, but as each person refers 2 others, you end up with an exponential growth machine.&nbsp;&nbsp;</p>



<div><figure><img loading="lazy" src="https://lh3.googleusercontent.com/B7OAUs5XY-MngXlfi-jG64t_mQKxgYakY-UrmM1aZKkR79506-p6BfpeMHMVeBjmhkCIrD8FQ1DzDgR3KhdFJ6OoX5_zG_qLzh0VkziO_llXETfzs_2FRXTId43eaEO7oU4EVeIE" alt="Clubhouse's growth strategy" width="566" height="377" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<h2><span id="How_can_you_recreate_Clubhouses_strategy_in_your_business"></span>How can you recreate Clubhouse’s strategy in your business?&nbsp;<span></span></h2>



<p>It’s easy to look at something that’s already been done and say “that’s genius”.&nbsp;</p>



<p>Knowing how to apply it to your business is another matter. And this is the difference between the brands that grow and those that don’t.&nbsp;</p>



<p>We’re going to attempt to recreate Clubhouse’s invite strategy within this blog article as an experiment.&nbsp;&nbsp;</p>



<div><div>
<div><div>
<p>Below this section you’ll find our own “velvet rope”.&nbsp;</p>



<p id="experiment">Behind it you’ll find a step-by-step process to action a similar strategy in your brand.&nbsp;</p>



<p>The cost of admission is to share this with your network (would be great if you could @ 2 people who would benefit from this info so we can better mimic the Clubhouse approach, that would be great).&nbsp;</p>



<p>This should, in theory, drive more targeted traffic to this post and help us “convert” more people.&nbsp;&nbsp;</p>



<p>Here’s how we’re viewing the experiment.&nbsp;</p>



<ul><li><strong>Hypothesis </strong>– If each interested person invites 2 of their friends to read this, we’ll 10X traffic for free because invites from friends carry intrinsic trust</li><li><strong>Action for you to take</strong> – Click on the below sharing buttons and mention a specific friend who would like this in the share (@friend)&nbsp;</li><li><strong>What you’ll get for helping – </strong>We’re offering a couple of rewards for helping us with this including…&nbsp;<ul><li>Detailed step-by-step guide to implementing a similar system yourself</li><li>A live tracker of traffic generated to this post specifically through this invite system</li><li>The red flags you need to be aware of if using an invite strategy&nbsp;</li><li>Recommendation of tools to use for this</li><li>Ability to join our email list where we detail more of these kinds of experiments</li></ul></li></ul>



<p><strong>If you want that stuff, you’re gonna have to share though. </strong></p>



<p><strong>We’re going through our mentions every day to see who has shared it and then we’re sending them the details in their DMs.  </strong></p>



<p>If you want to help with this experiment, click on one of the buttons below for the network you’re most active on.  </p>



<p>If it’s Twitter, a pre-written Tweet will show up. Feel free to share it as is, or (preferably) add the @name of someone you think could benefit from this.  </p>



<p>If LinkedIn, the button will take you to a post that I’ve written on my profile promoting this piece.  Drop a comment below it tagging the name of the person you think could benefit from this. </p>
</div></div>



<p>If there’s another network you prefer, feel free to simply share it with your friends who would benefit.  </p>
</div></div>















<h5><strong>Velvet rope ~~~~~~~~ Velvet rope</strong></h5>



<p>Thank you so much for helping out with our little experiment.&nbsp;</p>



<p>Below, I’ve listed a couple of actions that we would take were we trying to fully replicate Clubhousse’s invite system.&nbsp;</p>



<h3>#1) Pick the right influencers and get them on board.</h3>



<p>The Velvet Rope Strategy depends heavily on you seeding the “behind the rope” section with some genuine&nbsp; heavy hitters.&nbsp;</p>



<p>Influencers other people want to hear from, listen to, or be associated with.&nbsp;&nbsp;</p>



<p>If you can …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://have-a-word.com/clubhouse-marketing">https://have-a-word.com/clubhouse-marketing</a></em></p>]]>
            </description>
            <link>https://have-a-word.com/clubhouse-marketing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990845</guid>
            <pubDate>Mon, 01 Feb 2021 17:30:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Detections as Code]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25990739">thread link</a>) | @kartikeypan
<br/>
February 1, 2021 | https://blog.runpanther.io/detections-as-code/ | <a href="https://web.archive.org/web/*/https://blog.runpanther.io/detections-as-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <article id="post-1501">

                    
                    
                    
                    
                    
                    <div>
                        
<h4>How modern teams can automate security analysis at scale in the era of everything-as-code.</h4>



<p><em><strong>TL;DR</strong>: Detections-as-Code is a modern, TDD approach to writing custom, flexible detections.</em></p>



<p>Over the past decade, threat detection has become business-critical and even more complicated. As businesses move to the cloud, manual threat detection processes are no longer able to keep up. How can teams automate security analysis at scale and address the challenges that threaten business objectives? The answer lies in treating threat detections like software or detections-as-code.</p>



<p><em>Watch our&nbsp;</em><a href="https://runpanther.io/webinars/scaling-security-detections-as-code-panther-cedar/"><em><strong>On Demand Webinar: Scaling Security with Detections-as-Code with Cedar</strong></em></a><em>&nbsp;to find out how Cedar uses Panther to leverage Detections-as-Code to build high-signal alerts.</em></p>



<h2 id="what-are-detections"><span id="What_are_Detections"></span>What are Detections?<span></span></h2>



<p>Detections define logic for analyzing security log data to identify attacker behaviors. When a rule is matched, an alert gets sent to your team for containment or investigation.</p>



<h3 id="introduction-to-panther">Introduction to Panther</h3>



<p><a href="https://github.com/panther-labs/panther"><strong>Panther</strong></a>&nbsp;is an open source, security data analytics platform designed to alleviate the problems of traditional SIEMs. Panther is&nbsp;<strong>built</strong>&nbsp;<strong>for security engineers</strong>, by security engineers. Rather than inventing yet another DSL, Panther offers security teams a&nbsp;<strong>Python rules-engine</strong>&nbsp;to write expressive threat detections and automate detection and response at cloud-scale. Its modular and open approach offers easy integrations and&nbsp;<strong>flexible detections</strong>&nbsp;to help you build a modern security operations pipeline.</p>



<h3 id="an-example-detection-in-panther">An Example Detection in Panther</h3>



<p>When writing a detection in Panther, &nbsp;we start with a rule() function which identifies a specific behavior we want to identify.For example, let’s suppose we want to have a detection that sends an alert whenever a brute force Okta login is suspected. The following detection can help identify this behavior with Panther:</p>



<pre><code>from panther_base_helpers import deep_get, okta_alert_context


def rule(event):
    return (deep_get(event, 'outcome', 'result') == 'FAILURE' and
            event['eventType'] == 'user.session.start')


def title(event):
    return 'Suspected brute force Okta logins to account {} due to [{}]'.format(
        deep_get(event, 'actor', 'alternateId'),
        deep_get(event, 'outcome', 'reason'))


def alert_context(event):
    return okta_alert_context(event)</code></pre>



<p><em>Okta Brute Force Login Rule in Panther</em></p>



<p>In the above example:</p>



<ul><li>The rule() function takes one argument of ‘event’ and returns a boolean value.</li><li>The title() function controls the generated alert message sent to analysts. Values from the events can then be interpolated to add helpful contexts.</li></ul>



<p>Rules in Panther can be enabled and tested directly in the Panther UI, or modified and uploaded programmatically with the&nbsp;<a href="https://blog.runpanther.io/panthers-cli-tool/">Panther Analysis tool</a>, which enables you to test, package, and deploy detections via the command-line interface (CLI). And to assist with incident triage, Panther rules contain metadata such as severity, log types, unit tests, runbooks, and more.</p>



<h2 id="detections-as-code-a-new-hope-paradigm"><span id="DetectionsasCode_A_New_(Hope)_Paradigm"></span>Detections-as-Code: A New (Hope) Paradigm<span></span></h2>



<p>Detections-as-Code is a modern, flexible, and structured approach to writing detections that apply software engineering best practices to security. By adopting this new paradigm, teams can build scalable processes for writing and hardening detections to identify sophisticated threats across rapidly expanding environments.</p>



<h2 id="benefits-of-adopting-a-code-driven-workflow"><span id="Benefits_of_Adopting_a_CodeDriven_Workflow"></span>Benefits of Adopting a Code-Driven Workflow<span></span></h2>



<p>Threat detection programs that are fine-tuned for specific environments and systems are the most impactful. By treating detections as&nbsp;<strong>well-written code</strong>&nbsp;that can be tested, checked into source control, and code-reviewed by peers, teams can produce<strong>&nbsp;higher-quality alerts</strong>&nbsp;that reduce fatigue and quickly flag suspicious activity.</p>



<h3 id="1-build-custom-flexible-detections-with-a-programming-language">1- Build Custom, Flexible Detections with a Programming Language</h3>



<div><p>Writing detections in a universally-recognized, flexible, and expressive language such as&nbsp;<strong>Python</strong>&nbsp;offers several advantages instead of using domain-specific languages (DSL) that are too limited. With languages, such as Python, you can write more sophisticated and&nbsp;<strong>tailored detections</strong>&nbsp;to fit the needs specific to your enterprise. These rules also tend to be more readable and easy to understand as the complexity increases.</p><p>Another benefit of this approach is utilizing a rich set of built-in or third-party&nbsp;<strong>libraries</strong>&nbsp;developed by the security community for interacting with APIs or processing data, which increases the effectiveness of the detection.</p></div>



<h3 id="2-test-driven-development-tdd-">2- Test-Driven Development (TDD)</h3>



<p>A proper QA for detection code can enable teams to discover detection blind-spots early on, cover testing for false alerts, and promote&nbsp;<strong>detection efficacy</strong>. A TDD approach allows security teams to think like an attacker, document that knowledge, and curate an internal repository of insight into the attacker’s lifecycle.</p>



<p>The advantage of TDD is more than just validation of code correctness. A TDD approach to writing detections improves the quality of detection code and enables more&nbsp;<strong>modular, extensible, and flexible detections</strong>. Engineers can easily make changes to their detection without fear of breaking alerts or hamstringing everyday operations.</p>



<h3 id="3-collaboration-with-version-control-systems">3- Collaboration with Version Control Systems</h3>



<div><p>When writing new detections or modifying them, version control allows teams to quickly and easily revert to previous states. It also confirms that teams are using the most up-to-date detection rather than referencing outdated or wrong code. Version control can also help give needed context for specific detections that triggered an alert or help pinpoint when detections are changed.</p><p>As new and additional data enters the system over time, detections must also change. A change control process is essential to help teams address and&nbsp;<strong>adjust the detections as needed</strong>, while simultaneously ensuring that all changes are well-documented and well-reviewed.</p></div>



<h3 id="4-automated-workflows-for-reliable-detections">4- Automated Workflows for Reliable Detections</h3>



<p>A Continuous Integration/Continuous Deployment (CI/CD) pipeline can be beneficial for security teams that have long wanted to&nbsp;<a href="https://devops.com/shift-left-without-fear-the-role-of-security-in-enabling-devops/" target="_blank" rel="noreferrer noopener">move security further left</a>. Using a CI/CD pipeline helps achieve the following two goals:</p>



<ul><li>Eliminate&nbsp;<strong>silos</strong>&nbsp;between teams as they work together on a common platform, code-review each other’s work, and stay organized.</li><li>Provide automated testing and delivery pipelines for your security detections. Teams can&nbsp;<strong>stay agile</strong>&nbsp;by focusing on building fine-tuned detections. Instead of manually testing, deploying, and ensuring that the detections aren’t overly tuned, which could trigger false alerts.</li></ul>



<h3 id="5-reusable-code">5- Reusable Code</h3>



<div><p>Last but not least, Detections-as-Code can promote code reusability across a large set of detections. As teams write large numbers of detections over time, they start to see specific patterns emerge. Engineers can&nbsp;<strong>reuse the existing code</strong>&nbsp;to perform the same or very similar function across different detections without starting from scratch.</p><p>Code reusability can be a vital part of detection-writing that allows teams to share functions between detections or modify and adapt detections for specific use-cases. For example, suppose you needed to repeat a set of Allow/Deny lists (let’s say for access management) or a particular processing logic in multiple places. In that case, you can use Helpers in languages such as Python to&nbsp;<strong>share functions</strong>&nbsp;between detections.</p></div>



<h2 id="panther-s-approach-to-detections-as-code"><span id="Panther%E2%80%99s_Approach_to_DetectionsasCode"></span>Panther’s Approach to Detections-as-Code<span></span></h2>



<p>Panther offers reliable and resilient detections that can make it easy to:</p>



<ul><li>Write expressive and&nbsp;<strong>flexible detections in Python</strong>&nbsp;for needs specific to your enterprise.</li><li>Structure and normalize logs into a strict schema that enables detections with Python and&nbsp;<strong>queries with SQL</strong>.</li><li>Perform real-time threat detection and power investigations against&nbsp;<strong>massive volumes</strong>&nbsp;of security data.</li><li>Benefit from&nbsp;<strong>200+ pre-built detections</strong>&nbsp;mapped to specific threats, suspicious activity, and security frameworks like&nbsp;<a href="https://attack.mitre.org/" target="_blank" rel="noreferrer noopener">MITRE ATT&amp;CK</a>.</li></ul>



<figure><img src="https://lh3.googleusercontent.com/RK2uPbvJfk_bMHMCl2QHZDpEfmjVFcfEZ3Rq4bm3Gwvwy18GqBMgtGWHdscyD2sF-A_Xf-uXhbjCboG6bf6apo5lRNHz4OI3u1kljtrRWhpzxQdUk17Xz9eVH6DabIoA7p1VWBSE" alt="The flow of Detections-as-Code in Panther"><figcaption><em>The Flow of Detections-as-Code in Panther</em></figcaption></figure>



<h2 id="get-started"><span id="Get_Started"></span>Get Started<span></span></h2>



<div><p>Are you taking full advantage of all your security data to detect threats and suspicious activity? Follow our&nbsp;<a href="https://docs.runpanther.io/quick-start"><strong>Quick Start</strong></a>&nbsp;Community guide to getting started with Panther or&nbsp;<a href="https://runpanther.io/request-a-demo/"><strong>contact us</strong></a>&nbsp;for a demo.</p><p><em>To learn how you can write custom Python detections in Panther,&nbsp;</em><a href="https://runpanther.io/webinars/writing-custom-python-detections-with-panther/"><em><strong>watch our on-demand webinar</strong></em></a><em>.</em></p><p>Note: This is a two-part blog series on security automation using Detections-as-Code. In Part 2, we’ll show how you can deploy Detections-as-Code with Panther.</p></div>
                                            </div>

                </article>

                
                
                            		        		               
		        
            </div></div>]]>
            </description>
            <link>https://blog.runpanther.io/detections-as-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990739</guid>
            <pubDate>Mon, 01 Feb 2021 17:23:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Legacy database is outgrowing itself]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25990725">thread link</a>) | @sysoleg
<br/>
February 1, 2021 | https://ikonicscale.com/your-legacy-database-is-outgrowing-itself | <a href="https://web.archive.org/web/*/https://ikonicscale.com/your-legacy-database-is-outgrowing-itself">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><em>A note: this was originally posted on my good friend’s blog, at <a rel="noreferrer noopener" href="https://unstructed.tech/" target="_blank">unstructed.tech</a>. </em></p>



<p>Do you feel your database is growing too big or too old? Hard to maintain? Well, I hope I might be able to help you a bit with that. The text you’re about to read is a real life experience of scaling a monolith database to be able to support a top 250-website (according to <a rel="noreferrer noopener" href="https://www.alexa.com/" target="_blank">alexa.com</a>). At the moment of writing this article, <a rel="noreferrer noopener" href="https://www.alexa.com/" target="_blank">alexa.com</a> ranked <a rel="noreferrer noopener" href="https://www.chess.com/" target="_blank">chess.com</a> at 215th place in the world. We’ve got over 4M unique daily users and over 7B queries hitting all our MySQL databases combined. Went from under 1M unique users a day a year ago to 1.3M in March, to over 4M at the moment, with over 8M games played each day. I know it’s no where near the biggest players on the market, but our experience could help you “fix” your monolith database, and scale it to new heights.</p>



<p>Disclosure: <em>This is my first ever article, and it’s too long as it is – but I had to cut probably as much text as you see here in order to make it actually readable. So, some things might be confusing or not well explained, and I’m sorry for that. Hit me up on <a href="https://www.linkedin.com/in/ikonic/" target="_blank" rel="noreferrer noopener">LinkedIn</a>, and we can get into a deeper discussion.</em></p>



<p>Update: after reading a lot of comments, I’d like to add/clarify a few things. We do use caching, extensively. If we didn’t we wouldn’t survive a day. We do use Redis, often pushing it to its extremes. We’ve tested MongoDB and Vitess, but they didn’t do it for us. </p>



<h2>The state in which we were just couple of years ago</h2>



<p>Somewhere mid-2019 we’ve started noticing that our main DB cluster is slowly growing a bit too big. We had three smaller and less used databases on the side, but everything was always added to the main one. Surprisingly, it was in a fairly decent state for a database that started its life over 12 years ago. Not many unused/redundant indexes, the ones that were there were mostly good. We constantly monitored and improved heavy/slow queries. A nice chunk of data was denormalized, as well. No foreign keys, many things were done in the code itself (filtering, sorting, etc, to make sure the DB only ever uses the most efficient indexes) running on the latest version of MySQL, etc, etc. It wasn’t neglected and it evolved over time into something that did a good job for us. </p>



<p>Disclaimer: I’m not recommending anyone to do these sorts of micro-optimizations. They are working for chess.com, on its scale. We benchmark almost anything we’ve never done before, and see how it turns out, before actually implementing it. We know these work <strong>for us</strong>.</p>



<div>
<p>The biggest problem we were facing at that point in time was that altering almost any table required taking half the hosts out of rotation, run the alter there, put it back in rotation, alter the other half, put them back in. We had to do it off-peak, as taking half the hosts out during the peak time would probably result in the other half crashing. As the website was growing, old features got new improvements, so we had to run alters a lot (if you’re in the business, you know how it goes). Altering would’ve been far less stressful if we could could pull just a small set of tables out of rotation, instead of the entire DB. So, we created a 5 year plan for our main cluster (and boy, were we wrong about our timeline), in which we were to split the database into many smaller ones, and that would make things easier to maintain (we were right about this, at least). The plan assumed ~25% yearly growth, which was what we were seeing in previous years.</p>



<div>
<figure><img src="https://unstructed.tech/wp-content/uploads/2021/01/Untitled-Document-1.png" alt=""><figcaption><em>Where we were ~2 years ago</em></figcaption></figure>
</div>
</div>



<h2>The REAL problem appears and our plan implodes</h2>



<p>You’re all familiar with COVID-19, and how all of that went. Guess what – we weren’t really ready (or we didn’t expect it to have the impact it had on or traffic). Interest in chess exploded when (most of) Europe went into a lockdown. Fun fact – we could tell which country went into a lockdown just by looking at our registrations by country – it was so clear. And numbers skyrocketed across the board. Funnily enough, all our databases were doing fine (not great, but they handled the traffic). But at the same time we noticed that our “reports” host was constantly struggling to keep up with the production hosts (i.e., it was often 30-60 seconds behind on replication), which prompted us to analyse our replication stream and its remaining capacity. And it was close to being full, at peak traffic reaching over 95% of the capacity. At that point we knew that USA (where most of our players are from) would also go into a lock down, soon, and that would mean that our replicas wouldn’t be able to keep up with all the writes going to the master (or even if we just keep growing slowly). This would mean the end of <a href="http://www.chess.com/" target="_blank" rel="noreferrer noopener">chess.com</a>, as the code isn’t ready to handle big replication delays when reading data from replicas, and sending all the selects to master would take it down. That made our goal clear: decrease number of writes going to the main cluster, and do it as quickly as possible! This was actually part of our aforementioned plan, but that plan stretched over 5 years. Now we had just one or two months to do that. </p>



<h2>The solution</h2>



<p>How to decrease number of writes to a single DB? Sounds simple – identify tables that are written the most and rip them away from the DB. That way the number of writes handled remains the same, but they are just split into two separate streams. These can be either tables that get a lot of inserts, or not as many inserts, but with records that are frequently updated. Store them elsewhere. How to do it with no downtime? As you’d imagine – not really that simple. </p>



<p>We first identified all the tables that had most updates (inserts, deletes or updates). Most of them were nicely grouped together based on the feature for which they were used (most of game related tables would be written at a similar pace, etc), and we managed to gather a list of 10-15 tables, for 3 different website features. As soon as we started investigating them, another problem was revealed – since we can’t “join” between databases on different hosts, we would need to move as many tables as the feature used to make the project simpler (we were already aware of this, since when “the plan” first came into place, we did something similar for 3 smaller, less used tables as a PoC, and it turned out fine). </p>



<p>The 3 features we identified as high-traffic were logs (not really a feature, and not really logs, they were just poorly named), games (like you’d expect on a chess gaming platform) and puzzles. For logs we’ve found just 3 very isolated tables, which meant not a lot query/code changes were required. Similar for games, as well. But puzzles had over 15 tables to move, and the queries on those tables had lots of joins towards tables that were to remain in the main database cluster. We’ve rallied our troops, pulled over half of our backend developers, split them into teams, and started pushing on all of these in parallel. </p>



<p>It took just one week to move logs into its dedicated database, running on two hosts, which gave us some breathing space, as those had the most writes, by far. One more month to move games (which was oh so scary, as any mistake there would be a disaster, considering that’s the whole point of the website), and puzzles took over 2 months. After these, we were well under 80% of the replication capacity in the peak, which meant we had time to regroup, and plan upcoming projects a bit better.</p>



<h2>The execution</h2>



<p>So, how did we do it? </p>



<p>As you might assume, there are two sides to a project like this – code and database, and both require a lot of work. On the code side, there are a few prerequisites for a project like this one. First of all, we need some sort of <a href="https://en.wikipedia.org/wiki/Feature_toggle" target="_blank" rel="noreferrer noopener">feature flag</a> (aka feature toggle) system, either internal or 3rd party. Ours is custom built, pretty extensive, and maybe a topic for another post. The bare minimum the feature flag system needs to provide is to allow or deny access to a percent of checks from 0 to 100 percent. Another really useful thing to have is a good test coverage. Our entire codebase was rewritten from scratch a few years ago, so we were lucky enough to have that, as it saved us a couple of times.</p>



<div>
<p>Between code changes and database changes, some things can be done in parallel and some require going by numbers. The easiest thing to start with is to set up the new database. All our new databases pulled from the main one (we call them partitions, and this process partitioning) end up on a 2-host setup (master and failover-master (replica)), but it can really be anything we want. On the partition cluster, we create a new database with identical schema to the one we’re trying to split (just name it according our needs, in this case the first one was named<code> logs</code>). Then a backup of the main database is imported, after which we hook up the master of the partition cluster to be a replica of the main master (this is why we need the identical schema and backup import). This way the new cluster becomes just like any main cluster replica, only with a differently named database. Then it just sits there, looking pretty, replicating traffic, and being up-to-date with the rest of the cluster while we work on the code side of this project.</p>



<div>
<figure><img src="http://unstructed.tech/wp-content/uploads/2021/01/Before-DL-919x1024.png" alt=""><figcaption><em>This is what the cluster looks like after adding new hosts</em></figcaption></figure>
</div>
</div>



<p>Before we started working on this project, we essentially had 2 connections open to the database from the code: read only connection hitting replicas and read/write connection pointing to the master. Both actually hitting HAProxy, to get where they need to go. First thing we did is to create a parallel set of connections, where read/write connection goes to the <code>Partition Master</code> and read-only connection to the <code>Partition Replica</code>.</p>



<p><em>Chess.com is written in PHP, so I’ll use PHP examples to illustrate the needed changes, but I’ll keep it pseudo enough so that anyone can understand what’s going on (you’d be surprised how many websites in the top 1k are written in PHP, and …</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ikonicscale.com/your-legacy-database-is-outgrowing-itself">https://ikonicscale.com/your-legacy-database-is-outgrowing-itself</a></em></p>]]>
            </description>
            <link>https://ikonicscale.com/your-legacy-database-is-outgrowing-itself</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990725</guid>
            <pubDate>Mon, 01 Feb 2021 17:21:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snowflake Generator]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25990723">thread link</a>) | @visviva
<br/>
February 1, 2021 | https://viviariums.com/projects/snowflake/ | <a href="https://web.archive.org/web/*/https://viviariums.com/projects/snowflake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <p>
      Run the generator
      <a href="https://viviariums.com/projects/snowflake/interactive/">here.</a>
    </p>
    <p>
      This generator cycles a snowflake from a seed to its final state,
      and also loops its crystal distribution kaleidoscopically on two axis.
    </p>
    <p>
      <img src="https://viviariums.com/projects/snowflake/growth.gif"><img src="https://viviariums.com/projects/snowflake/kaleidoscope.gif">
    </p>
    <p>
      It takes the user input and distributes hexagons on a pinion accordingly, applies mirroring
      and sixfold symmetry, generates a height map, and adds lighting and refraction.
      This is done with a fragment shader; the snowflake lies on a plane and there is no geometry created.
    </p>
    <p>
      Thanks to Evan Wallace for the post-processing effects (blur and chromatic aberration).
    </p>
    <p>
      <img src="https://viviariums.com/projects/snowflake/compilation.jpg">
    </p>
  </article></div>]]>
            </description>
            <link>https://viviariums.com/projects/snowflake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990723</guid>
            <pubDate>Mon, 01 Feb 2021 17:21:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Continuous delivery makes JVM JIT an anti-pattern]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25990585">thread link</a>) | @foxgrover
<br/>
February 1, 2021 | https://blog.astradot.com/the-jvm-jit-is-an-antipattern-in-a-continuous-delivery-world/ | <a href="https://web.archive.org/web/*/https://blog.astradot.com/the-jvm-jit-is-an-antipattern-in-a-continuous-delivery-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>The JVM JIT compiler has long been sold as the way Java is able to compete with the performance of compiled languages like C/C++. Every benchmark for Java will tell you to first run your code many times for 'warmup' before you measure its performance, so that its JITed and optimized by the JVM's C2 compiler .</p><p>In the real world though, the calls to your application <em>before</em> its code is 'warmed up' are very much a part of your application's experience.</p><figure><blockquote><p lang="en" dir="ltr">Every Java benchmark is like ‘ignore first 1M calls to let code be fully JITed’. Yeah but those 1M calls are still part of your application, including that first call that caused the class hierarchy to be loaded. And they are pushing the 99th percentile of your app to the moon!</p>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1355754185858420738?ref_src=twsrc%5Etfw">January 31, 2021</a></blockquote>

</figure><h3 id="jvm-jit-and-our-signup-page">JVM JIT and our Signup page</h3><p>Astradot has a Kotlin microservice that takes care of auth activities like signup and login. If you try to signup right after the serviced was redeployed, it feels like the signup page has frozen after you click the 'signup' button. The page can take seconds to respond. It's because the JVM is loading the code of tons of Kotlin/Spring classes for the first time and running it through the interpreter with no optimizations. Sure the response time gets better the more you click the signup button, but the user who was signing up that first time might have thought our system was frozen and gone away. Since we have multiple instances of each microservice running its possible that the 2nd time you try to signup the request goes to a different JVM instance. For that JVM its the first time loading the signup code and so you again encounter the freezing behavior. From the end user's perspective, he has now tried signing up multiple times and encountered slow behavior each time. Thus that is the impression he has of our product now.</p><h3 id="continuous-delivery-kills-jit-compiler-s-core-assumption">Continuous Delivery kills JIT compiler's core assumption</h3><p>One of Astradot's metric collector service gets 500 requests per second per JVM. After a fresh deploy, even at that high throughput it takes a full 2 hours till the JVM C2 compiler is able to fully optimize that code path to get response times drop to their lowest. To put those 2 hours in context, here is a result from Sysdig's latest container usage survey:</p><figure><blockquote><p lang="en" dir="ltr">Latest Sysdig survey shows 74% of containers live &lt; 1 hour. So your Java app perpetually stays in interpreted/C1 non-optimized mode. Those amazing benchmark numbers you got from the C2 JIT, your users will never get to see them. JIT and Continuous Deployment are incompatible. <a href="https://t.co/fqLf7d3f9L">pic.twitter.com/fqLf7d3f9L</a></p>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1356183648131719175?ref_src=twsrc%5Etfw">February 1, 2021</a></blockquote>

</figure><p>74% of containers have lifespans ≤ 1 hour. This changes the core assumption behind the JIT compiler that the JVM is a long running process. Your container will get redeployed before it gets optimized by the JVM C2 compiler. Thus your users will never even get to experience that amazing performance that all those JVM benchmarks promised.</p><p>This gets worse for portions of code that are low throughput. Think of that Signup page I talked about earlier. Even if our auth microservice was deployed for days, the <code>signup()</code> function will still not get enough calls to trigger the C2 compiler to fully optimize it. So users will always experience the unoptimized version of that code.</p><h3 id="rise-of-modern-compiled-languages">Rise of modern compiled languages</h3><p>One of the selling points of the JVM JIT compiler was that it has runtime information so it can do better optimization. That might have been true 20 years ago. But Ahead of Time (AOT) compiled languages have evolved since then. Go, which is Garbage Collected like Java, but AOT compiled, is able to achieve similar or better performance. Rust is able to consistently beat Java in benchmarks.</p><p>This is due to the fundamental design of Java. It encourages uses of virtual methods and allocations on heap. A huge part of the JIT optimization revolves around trying to convert those virtual calls to static calls, inline them, perform escape analysis to convert those heap allocations to stack allocations. Go and Rust encourage use of static method calls and stack allocation everywhere by default thus they don't need all the complexity and overhead of a massive JIT to optimize them at runtime.</p><h3 id="aot-compiled-java">AOT Compiled Java</h3><p>There are signs that Java folks are realizing the pitfalls of JIT. GraalVM has an AOT compiler and frameworks like Quarkus and Micronaut are popping up to use them. They have had little uptake though. The dynamic nature of Java means that features like dynamic class loading, reflection, proxies, etc are unavailable or in limited from in AOT. Production Java apps also typically run with APM tracing agents that rely on runtime bytecode instrumentation. The entire JVM ecosystem is simply not designed around AOT compilation. Molding a 25 year old runtime ecosystem to adapt to AOT compilation feels like putting lipstick on a pig. It is easier to start afresh with modern compiled languages like Go and Rust.</p><h3 id="conclusion">Conclusion</h3><p>JVM vendors want you to ignore the fact that large portions of your code could indeed be running on the interpreter or the unoptimized C1 compiler. Continuous Delivery and the resulting frequent JVM restarts mean the core assumption behind the JIT compiler, that JVMs are long running processes, no longer holds.</p><p>At Astradot, we believe <a href="https://movingfulcrum.com/the-era-of-the-jvm-is-coming-to-an-end/">the era of the JVM is coming to an end</a>. We are writing our backend in AOT compiled languages to give you a great experience 100% of the time. &nbsp;We recently <a href="https://blog.astradot.com/why-we-moved-from-kotlin-spring-boot-to-go/">converted our microservices from Kotlin to Go</a> and found it to be a welcome change.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.astradot.com/the-jvm-jit-is-an-antipattern-in-a-continuous-delivery-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990585</guid>
            <pubDate>Mon, 01 Feb 2021 17:11:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian Pipeline Is Germany's Greatest Foreign Policy Embarrassment]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 91 (<a href="https://news.ycombinator.com/item?id=25990469">thread link</a>) | @Tomte
<br/>
February 1, 2021 | https://www.spiegel.de/international/germany/a-price-too-high-russian-pipeline-is-germany-s-greatest-foreign-policy-embarrassment-a-0fcefa58-ca51-41ca-b480-98015203e9fa | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/germany/a-price-too-high-russian-pipeline-is-germany-s-greatest-foreign-policy-embarrassment-a-0fcefa58-ca51-41ca-b480-98015203e9fa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-label="A Price Too High: Russian Pipeline Is Germany's Greatest Foreign Policy Embarrassment" data-area="article">
<header>
<div>

<div>
<h2>
<span>
A Price Too High
</span>
<span><span>Russian Pipeline Is Germany's Greatest Foreign Policy Embarrassment</span>
</span>
</h2>


<p>
Berlin is insisting on the construction of the Nord Stream 2 gas pipeline between Russia and Germany. By doing so, the country is isolating itself in Europe and alienating the United States. The political costs will be too great if the project is completed. It should now be scrapped.
</p>
<p><time datetime="2021-02-01 17:25:39">01.02.2021, 17.25 Uhr</time>
</p>
</div>
</div>
</header>
<div data-article-el="body">
<section data-app-hidden="">


</section>
<section>
<div>
<figure data-component="Image" data-zoom-id="fff3875a-fe1c-4f87-870d-10604da8a863" data-settings="{&quot;id&quot;:&quot;9fdd3db3-8707-46ea-8d4a-4197034af156&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;fff3875a-fe1c-4f87-870d-10604da8a863&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/9fdd3db3-8707-46ea-8d4a-4197034af156_w948_r1.77_fpx56_fpy56.jpg" srcset="https://cdn.prod.www.spiegel.de/images/9fdd3db3-8707-46ea-8d4a-4197034af156_w520_r1.77_fpx56_fpy56.jpg 520w, https://cdn.prod.www.spiegel.de/images/9fdd3db3-8707-46ea-8d4a-4197034af156_w948_r1.77_fpx56_fpy56.jpg 948w" width="948" height="536" sizes="948px">
</span>
</span>
</span>

</p>
<figcaption>
<span>
Foto: Alexander Demianchuk&nbsp;/ action press
</span>
</figcaption>
</figure>
</div><div>
<p>How much can a natural gas pipeline from Russia be worth to the German government? Is it worth sacrificing Germany’s foreign policy prestige? Is it worth isolating the country within the European Union and straining relations with Joe Biden, the new president of the United States? How can it be reconciled with Germany’s climate targets? And why should the German government back a pipeline that benefits the Russian regime, whose policies it otherwise opposes?</p>


<div>
<p>For years, the German government has stuck to this economically dubious and politically misguided project, the brainchild of Russian President Vladimir Putin and his pal, former Chancellor Gerhard Schröder. The greater the resistance within Europe to the project, the more stubbornly the German government has clung to the endeavor. It is increasingly difficult to find any other explanation for this than pride.</p><p>And this, despite the larger, more fundamental issue question facing Berlin: Can the German government achieve its self-proclaimed target of taking on a more significant role in global politics? Its behavior on Nord Stream 2 thus far suggests the contrary. The pipeline, indeed, has become Germany’s most embarrassing foreign policy problem.</p>
</div>

<p>From the very beginning, Berlin’s claim that the Nord Stream 2 was purely economic and not at all political in nature has been hypocritical. Pipelines are always political. And this is especially true of this pipeline, because Nord Stream 2 would transport natural gas directly from Russia to Germany through the Baltic Sea. It would allow the state-owned company Gazprom to bypass pipelines in Belarus and Ukraine, making the countries even more dependent on Russia because they will lose transit fees they otherwise would have received. The pipeline would also provide an additional source of foreign currency for the Russian government. This runs counter to the spirit of Europe's sanctions against a regime that for years has shown itself to be an adversary of the European Union and has had opposition figure Alexei Navalny poisoned and imprisoned.</p>

<p><strong>The most effective argument used by pipeline proponents</strong> in recent years has been Donald Trump and U.S. sanctions against the project. "We're not going to let them dictate where we buy our gas!" they would say. But Donald Trump has now been voted out of office, and the Americans are by no means the only ones who oppose the pipeline. Indeed, perhaps the strongest argument against Nord Stream 2 doesn’t even have anything to do with the U.S. This pipeline is an anti-European project. And the German government is growing increasingly isolated in the EU on the issue. Almost every Eastern European country is opposed to the project, especially Poland and the Baltic states. The project provides affirmation for critics who view Germany as a two-faced, hegemonic country that speaks of European values but pushes through its own interests in a pinch. Last month, the European Parliament once again voted against the pipeline. There has also been criticism from the European Commission, which wants to reduce dependence on individual supplier countries. Even Paris is voicing skepticism.</p>


<section data-area="contentbox">

</section>
<div>
<p>The pipeline doesn’t even provide any clear economic benefits. It doubles the supply capacity from Russia, but natural gas consumption is stagnating and would have to fall significantly by the middle of the century for Germany to meet its climate targets. The existing pipelines are by far sufficient. Russia is now talking about pumping climate-friendly hydrogen through the pipeline in the future. But those prospects are uncertain and it changes nothing about the political dilemma.</p><p><strong>Of course, the private companies involved</strong> could now try to finish building the last few kilometers of the pipeline, despite the U.S. sanctions – at their own risk. They have invested billions, after all. But the lengths to which some politicians in Germany - particularly within the center-left Social Democratic Party once run by Schröder - are willing to go to support the project has been appalling. Manuela Schwesig, the SPD governor of Mecklenburg-Western Pomerania, where Nord Stream 2’s terminus is located, has even set up a front foundation for environmental protection to complete the environmentally damaging pipeline despite U.S. sanctions. Such shadiness is harmful to Germany's international standing.</p>
</div>
<section>

</section>
<div>
<p>The German government has backed itself into a corner with Nord Stream 2 that can only be explained by economic selfishness or political naivety, but it is ultimately a self-inflicted wound. The time, though, has now come for a clear choice to be made – one that doesn’t chain the country to the pipeline. Nord Stream 2 must be stopped. It would be better to write it off now than to bear the political and economic costs of its completion.</p><p>Angela Merkel should withdraw support for the project, even if that could mean that companies end up having to be compensated. Doing so will be painful politically, but the German government should view the Nord Stream 2 debacle as quittance for the mistakes it has made – and as a lesson for the future.</p>
<p><span><svg aria-labelledby="title-d81807c5-def2-45e9-868c-4d50dedd2f8f" width="10" height="20" viewBox="0 0 10 20" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-d81807c5-def2-45e9-868c-4d50dedd2f8f">Icon: Der Spiegel</title><g id="l-s-flag-d81807c5-def2-45e9-868c-4d50dedd2f8f"><path id="vector-d81807c5-def2-45e9-868c-4d50dedd2f8f" d="M9.85 16.293v-8H3.212V4.667h3.533v2.24h3.212v-3.2C9.85 2.747 8.993 2 8.03 2H1.713C.749 2 0 2.747 0 3.707v7.253h6.638v4.373H3.105v-2.986H0v3.84c0 .96.75 1.706 1.713 1.706H8.03c.963.107 1.82-.64 1.82-1.6z" fill="#000"></path></g></svg>
</span>
</p></div>
</div>
</section>

</div>

</article></div>]]>
            </description>
            <link>https://www.spiegel.de/international/germany/a-price-too-high-russian-pipeline-is-germany-s-greatest-foreign-policy-embarrassment-a-0fcefa58-ca51-41ca-b480-98015203e9fa</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990469</guid>
            <pubDate>Mon, 01 Feb 2021 17:02:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Conway's Distributed Game of Life on Ethereum]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25990196">thread link</a>) | @basicallydan
<br/>
February 1, 2021 | https://conwaysgame.github.io/solidity-ethereum/ | <a href="https://web.archive.org/web/*/https://conwaysgame.github.io/solidity-ethereum/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>➡ Connecting to the network.</p><div>
      <h2>How To Use</h2>
      <p>This web page shows the output of an implementation of Conway's Game of Life written for the Ethereum network as a Smart Contract. In order to evolve the world to its next state (i.e., go to the next turn) one must simply send at least 0.00001 ETH or more to the smart contract's address on the network. Here are some more details:</p>
      <ol>
        <li>Have an Ethereum wallet, ideally as a browser extension like <a href="https://metamask.io/" target="_blank">MetaMask</a> (<a href="https://brave.com/" target="_blank">Brave</a> web brower includes a built-in MetaMask).</li>
        <li>Create an ETH account with your network set to <em>Rinkeby Test Network</em></li>
        <li>Visit <a href="https://faucet.rinkeby.io/" target="_blank">https://faucet.rinkeby.io/</a> and follow instructions to get funds. For now, it needs link of social media share of ethereum account ID.</li>
        <li>Send a transaction of at least <code>0.00001 ETH</code>, or <code>10000000000000 Wei</code> to the following address using the <em>Rinkeby Test Network</em>. You can click the address to start a transaction - I recommend a gas limit of at least 400,000.<br><a><span>Loading...</span></a></li>
      </ol>
    </div><div>
      <h2>How does it work?</h2>
      <p>I wrote up a blog post about this project on <a href="https://danhough.com/blog/conways-game-ethereum/">my website</a>, which explains some of the challenges.</p>
      <p>However, you can inspect the code yourself, it's all on GitHub. Just click the link below:</p>
      <p><a href="https://github.com/conwaysgame/solidity-ethereum"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/conwaysgame/solidity-ethereum?style=social"></a>
    </p></div><div>
      <h2>Explanation</h2>
      <p><a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life" target="_blank"><em>Conway's Game of Life</em></a> is a cellular automata, and can also be described as a turn-based "zero-player game."</p>
      <p>It is made up of a two-dimensional grid of cells. You can think of each cell as having the potential to be populated - it can be alive or dead, and during each turn in the game its state is reassessed based on the states of its 8 neighbours. These are the "rules" by which a cell's state is determined each turn.</p>
      <ol>
        <li>Any live cell with fewer than two live neighbours dies, as if by underpopulation.</li>
        <li>Any live cell with two or three live neighbours lives on to the next generation.</li>
        <li>Any live cell with more than three live neighbours dies, as if by overpopulation.</li>
        <li>Any dead cell with exactly three live neighbours becomes a live cell, as if by reproduction.</li>
      </ol>
      <p>Most implementations of the Game of Life simply have</p>
      <h3>Who did this?</h3>
      <p>My name is Dan, I'm a software engineer from the UK who lives in Vancouver, BC in Canada. I have <a href="https://danhough.com/">a website</a> where I talk about software, books, and the surprisingly good music that I make, plus <a href="https://twitter.com/basicallydan">a Twitter</a> and <a href="https://github.com/basicallydan">a GitHub page</a>.</p>
      <h3>Why did you do this?</h3>
      <p>Since 2014 I have been steadily writing <a href="https://github.com/conwaysgame" target="_blank">implementations of the Game of Life</a> in various languages. It's a fun exercise in TDD and a good way to be exposed to new technologies. The ever-increasing interest in cryptocurrencies and slow rise in availability of distributed apps (Dapps) and smart contracts prompted me to experiment with a version of the game which could run as a Dapp. Turns out, it can.</p>
      <h3>How did you do this?</h3>
      <p>I started by completing <a href="https://techbrij.com/hello-world-smart-contract-solidity-ethereum-dapp-part-1" target="_blank">a Hello World tutorial by Brij Mohan</a>, and then started from scratch with a new project. You can read more in <a href="https://danhough.com/blog/conways-gol-ethereum" target="_blank" rel="noopener noreferrer">a blog post I wrote</a> (PENDING).</p>
      <p>If you'd like to see the code, raise an issue, or open a pull request, you can do so on the <a href="https://github.com/conwaysgame/solidity-ethereum" target="_blank">GitHub repository</a>.</p>
    </div></div>]]>
            </description>
            <link>https://conwaysgame.github.io/solidity-ethereum/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990196</guid>
            <pubDate>Mon, 01 Feb 2021 16:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Please Stop Saying 'An AI']]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25990016">thread link</a>) | @YeGoblynQueenne
<br/>
February 1, 2021 | https://www.skynettoday.com/editorials/ai-definition/ | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/editorials/ai-definition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>        
      
      
      <h4>Popular usage of the term ‘Artificial Intelligence’ adds to misunderstanding of AI as it exists today.</h4>
      
      </div><div>
      <h2 id="the-options">The Options</h2>
<p>Definitions of the term ‘Artificial Intelligence’ tend to fit one of the following categories:</p>

<ol>
  <li>‘field of research’ definitions, e.g.: “a branch of computer science dealing with the simulation of intelligent behavior in computers” (<a href="https://www.merriam-webster.com/dictionary/artificial%20intelligence">Merriam-Webster</a>) , “the theory and development of computer systems able to perform tasks that normally require human intelligence” (Oxford)</li>
  <li>‘machine intelligence’ definitions, e.g.: “the capability of a machine to imitate intelligent human behavior “(<a href="https://www.merriam-webster.com/dictionary/artificial%20intelligence">Merriam-Webster</a>) , “intelligence demonstrated by machines, unlike the natural intelligence displayed by humans and animals.” (<a href="https://en.wikipedia.org/wiki/Artificial_intelligence">Wikipedia</a>) , “the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings.” (<a href="https://www.britannica.com/technology/artificial-intelligence">Encyclopedia Brittanica</a>)</li>
  <li>‘intelligent entity’ definitions, e.g.: “a computer, robot, or other programmed mechanical device having [the] humanlike capacity [to perform operations and tasks analogous to learning and decision making in humans, as speech recognition or question answering]”. (<a href="https://www.dictionary.com/browse/artificial-intelligence">Dictionary.com</a>)</li>
</ol>

<p>While all of these options are similar in that they deal with ‘intelligent behavior’ in computers, they are also quite different. The first refers to a research discipline, while the second and third describe what that research discipline seeks to create. The ways in which the term ‘AI’ can be used depend on which of these definitions you consider valid. For instance, news articles often have titles to the effect of “Google’s new AI learned X” or “A new AI can do Y,” such as:</p>

<ul>
  <li><a href="https://www.theatlantic.com/technology/archive/2017/06/artificial-intelligence-develops-its-own-non-human-language/530436/">“An Artificial Intelligence Developed Its Own Non-Human Language”</a></li>
  <li><a href="https://www.fastcompany.com/90455358/ai-can-now-design-cities-should-we-let-it">“AI can now design cities, but should we let it?”</a></li>
  <li><a href="https://www.forbes.com/sites/danadovey/2020/02/11/first-time-ever-artificial-intelligence-develops-drug-candidate/">“For The First Time Ever, A Drug Developed By AI Will Be Tested In Human Trials”</a></li>
  <li><a href="https://www.sciencealert.com/google-s-ai-built-it-s-own-ai-that-outperforms-any-made-by-humans">“Google AI creates its own ‘child’ AI that’s more advanced than systems built by humans”</a></li>
</ul>

<p>But, such usage (“An AI Developed”, “AI can now”, etc.) is only valid with that third ‘intelligent entity’ definition. If the first ‘field of research’ definition is chosen instead, these titles would have to be rewritten as “Google’s new AI algorithm learned X” or “A new AI system can do Y.” In this piece, I’ll make the case that this definition and form of usage is superior to the alternatives, and should be adopted in most cases.</p>

<h2 id="why-should-we-care">Why Should We Care</h2>
<p>It may seem pedantic to say one of these definitions is better than any of the others, and tempting to just say all of them are fine. However, I argue that the ‘field of research’ definition of AI is better than the alternatives, primarily because of the <a href="https://www.aimyths.org/ai-has-agency">common misunderstanding</a> that AI programs today are independent agents with some amount of ‘free will’. In fact, what AI researchers and engineers build today are just computer programs, which are capable of emulating some aspects of human intelligence but are otherwise (for the most part) no more independent than the apps on our smartphones. Nevertheless, AI researchers recently ranked the idea that the AI algorithms they create have some human-like independence as the most common and problematic myth about AI; it was “number one by a long shot” <a href="https://www.skynettoday.com/podcast/top-ai-myths">according to a survey</a> asking which myths about AI are most common.</p>

<p>I believe part of why this myth is so predominant has to do with thinking of AI in terms of the ‘intelligent entity’ definition type and using the term accordingly by saying statements such as “A new AI can do Y”. Expanding that statement results in “A new Artificial Intelligence can do Y,” and the notion that the sentence refers to ‘An Intelligence’ inevitably implies agency similar to those of animals and humans. AI researcher Julian Togelius addresses this notion well in his blog post <a href="http://togelius.blogspot.com/2017/07/some-advice-for-journalists-writing.html">“Some advice for journalists writing about artificial intelligence”</a>:</p>

<blockquote>
  <p><strong>Keep in mind</strong>: There is no such thing as “an artificial intelligence”. AI is a collection of methods and ideas for building software that can do some of the things that humans can do with their brains. Researchers and developers develop new AI methods (and use existing AI methods) to build software (and sometimes also hardware) that can do something impressive, such as playing a game or drawing pictures of cats.</p>
</blockquote>

<p>AI researcher Zachary Lipton made this point more bluntly:</p>

<figure>
<blockquote><p lang="en" dir="ltr">Dear world (CC <a href="https://twitter.com/businessinsider?ref_src=twsrc%5Etfw">@businessinsider</a>,
<a href="https://twitter.com/Hamilbug?ref_src=twsrc%5Etfw">@Hamilbug</a>):
stop saying "an AI". AI's an aspirational term, not a
thing you build. What Amazon actually built is a "machine learning
system", or even more plainly "predictive model". Using
"an AI" grabs clicks but misleads <a href="https://t.co/0kdTLBsrHJ">https://t.co/0kdTLBsrHJ</a></p>—
Zachary Lipton (@zacharylipton) <a href="https://twitter.com/zacharylipton/status/1050221929477664768?ref_src=twsrc%5Etfw">October
11, 2018</a></blockquote> 
</figure>

<p>As someone who has tried to use my knowledge as an AI researcher to address popular misconceptions about AI, I have observed and continue to observe the usage of “An AI” often, and think it has the negative side effect of feeding misunderstanding of what AI is today. While it may be tempting to once again say this is being pedantic and that it’s fine to have a more ‘pop culture’ view of AI, with AI becoming increasingly embedded in our society it is more important than ever that all of us understand it. Such understanding is crucial so that we can collectively correctly focus on the most pressing issues with respect to AI (such as bias, automation, its use for surveillance, its safety) and not the issues that the agency myth implies (its potential to go rogue a la Skynet in the near term).</p>

<p>Therefore, given the existence of the ‘agency’ myth with respect to AI and the importance of correctly understanding what AI is actually like today, I would argue the first ‘field of research’ definition of the term ‘AI’ is better than the alternatives. As I’ll show next, this is (unsurprisingly) typically how AI researchers themselves use the term.</p>

<h2 id="how-researchers-define-ai">How Researchers Define AI</h2>

<p><a href="https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)">John McCarthy</a>, one of the founders of the field of AI, defined AI as follows:</p>

<blockquote>
  <p>“It is the science and engineering of making intelligent machines, especially intelligent computer programs.”</p>
</blockquote>

<p>Professor <a href="https://nlp.stanford.edu/manning/">Christopher Manning</a><a href="https://hai.stanford.edu/sites/default/files/2020-09/AI-Definitions-HAI.pdf"> </a> <a href="https://hai.stanford.edu/sites/default/files/2020-09/AI-Definitions-HAI.pdf">recently cited</a> this as the definition of ‘Artificial Intelligence’ in his summary of definitions of terms related to AI. Similarly, in “Artificial Intelligence: A Modern Approach”, Stuart Russell and Peter Norvig defined AI as:</p>

<blockquote>
  <p>“the designing and building of intelligent agents that receive percepts from the environment and take actions that affect that environment.”</p>
</blockquote>

<p>To cite just one more example, in “The Quest for Artificial Intelligence: A History of Ideas and Achievements” <a href="https://en.wikipedia.org/wiki/Nils_John_Nilsson">Nils J. Nilsson</a> defines AI as follows:</p>

<blockquote>
  <p>“[the] activity devoted to making machines intelligent”</p>
</blockquote>

<p>There are of course many other definitions, but they tend to share the quality of considering AI a research or engineering discipline rather than a term that can be used to refer to singular algorithms or systems.</p>

<p>I conducted an informal survey to check whether AI researchers generally agree with this form of definition, with the following results:</p>

<figure>
<blockquote><div lang="en" dir="ltr"><p>AI Researchers: how do you define the term 'Artificial Intelligence'? </p><p>A: the science and engineering of making intelligent machines, especially intelligent computer programs</p><p>B: intelligence demonstrated by machines, unlike the natural intelligence of animals</p><p>C: Other</p></div>— Skynet Today (@skynet_today) <a href="https://twitter.com/skynet_today/status/1326239401912004611?ref_src=twsrc%5Etfw">November 10, 2020</a></blockquote>  
</figure>

<p>While hardly a careful study of what most AI researchers feel, the result of this poll agrees with my personal observations as an AI researcher that most in the field seem to prefer the John McCarthy definition of AI to the alternatives. I point this out because I think it further lends credence to the idea that the ‘field of research’ definition that does not allow for “An AI” as a phrase is superior to the alternatives. Granted, no one has any right to impose a particular way of defining terms on others, but I still think using the term ‘AI’ the same way the people actually working on AI in the real world (as opposed to science fiction, where ‘An AI’ is appropriate) makes a lot of sense.</p>

<h2 id="tldr">TLDR</h2>
<p>AI researchers tend to define ‘Artificial Intelligence’ to mean something along the lines of “the science and engineering of making intelligent machines, especially intelligent computer programs” – the ‘field of research’ definition. This is in contrast to definitions often used in popular media, which use ‘AI’ to refer to particular programs or systems with sentences – the ‘intelligent entity’ definition. The latter usage of AI reinforces an already common myth that present day AI has some amount of human-like agency, when in fact this is not really the case. Therefore, I believe that the ‘intelligent entity’ type definition should be avoided in favor of the ‘field of research’ definition, and the term should be used accordingly.</p>


    </div></div>]]>
            </description>
            <link>https://www.skynettoday.com/editorials/ai-definition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990016</guid>
            <pubDate>Mon, 01 Feb 2021 16:22:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Favorite Podcasts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989939">thread link</a>) | @dhruvparamhans
<br/>
February 1, 2021 | https://dhruv-sharma.ovh/blog/podcasts/ | <a href="https://web.archive.org/web/*/https://dhruv-sharma.ovh/blog/podcasts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Quizzing has been an important part of my life for many years now. In fact I have spent more years in my life playing, setting, and enjoying quizzes than I have without them. As I have progressed from school quizzes to university level and now open level quizzes, I have had to increase my knowledge base substantially. While early on, staying abreast with the latest news by reading newspapers or monthly magazines was enough, open quizzes require more in depth knowledge. I have also felt a discomfort in simply knowing superficial details about things, rather than actually taking the time to understand them in sufficient depth. While Feynman isn’t my favorite scientist, I do agree with him when he said that “simply knowing the names of things isn’t knowledge”.</p><p>In the quest of going beyond names of things (like Shakespeare’s last great comedy), I have sought out podcasts as an economical way of understanding the “story” behind the facts. Podcasts have also been a boon over the last few years because doing a masters and then a PhD makes claims on your time that don’t let other activities; however I can always listen to podcasts while I am doing other things like doing dishes or taking out the laundry.</p><p>And I listen to a lot of podcasts! For instance, since September 2019 I have spent close to 8 days listening to podcasts. That translates to close to 200 hours of listening. Also I am subscribed to about 150+ of them. While I obviously don’t listen to all of them on a regular basis, there are some which are my go-to shows. Here is a small-ish selection of them.</p><h2 id="general-listening">General listening</h2><p>These are shows that I listen to quite regularly and they cover a very wide range of subjects.</p><ol><li><a href="https://www.bbc.co.uk/programmes/b006qykl" target="_blank" rel="noopener">In our time</a> - This is probably the best radio show I have ever heard. Each week the host Melvyn Bragg invites 3 subject matter experts for discussing a whole host of topics: everything from feathered dinosaurs to the life of Thomas Aquinas. Each episode lasts about 45 minutes and it’s the best bang for your buck if you want to quickly get a more than superficial understanding of a subject. You can also subscribe to domain specific feeds on science, culture, history and philosophy as well.</li><li><a href="https://dhruv-sharma.ovh/blog/podcasts/philosophizethis.org">Philosophize this</a> - A podcast on philosophy, it gives a brief (20-30 mins) introduction to the major themes in western philosophy starting from the pre-Socratics to modern day philosophers. For a more detailed and global philosophy podcast, there is always “History of Philosophy without any gaps”.</li><li><a href="https://partiallyexaminedlife.com/" target="_blank" rel="noopener">The Partially Examined life</a> - This is another one of those general podcasts that discuss philosophy. What i like most about this podcast is it’s conversational nature. Unlike philosophize this, the discussion around the topic or philosopher at hand makes it, to me at least, a better way to understand things.</li><li><a href="https://dhruv-sharma.ovh/blog/podcasts/entitledopinions.stanford.edu">Entitled opinions</a> - This is one of my favorite podcasts of all time. Hosted by Stanford university professor Robert Harrison, this podcast and radio show takes the same approach as In Our Time but the conversations are even more wide-ranging. Harrison also has none of the coldness that Bragg has which makes it for a great experience. Harrison also sometimes does solo episodes where he talks with equal ease about Dante’s inferno as he does about the music of The Doors.</li></ol><p>In the next few sections, I will discuss some of my favorite podcasts within multiple categories.</p><h2 id="french-language-podcasts">French language podcasts</h2><p>One of the way in which I ended up listening to podcasts was during my <em>stage linguistique</em> as I was learning French. I believe that one of the best ways to actually acquire the language is via active listening and I created my very own, rather unique way of learning the language (more on that for a later blog post). Since 2013, I have reduced my French podcast listening, but I do have some favorites.</p><ol><li><a href="https://www.franceculture.fr/emissions/la-compagnie-des-auteurs" target="_blank" rel="noopener">La compagnie des œuvres</a> - This podcast, much in the same way as In Our Time does, focuses on a specific topic. For this podcast, it is is literary works or more generally <em>oeuvres</em>, creative works of any kind. This is also a radio show which is broadcast mondays to Fridays on France Culture</li><li><a href="https://www.franceculture.fr/emissions/le-cours-de-lhistoire" target="_blank" rel="noopener">Le cours de l’histoire</a> - Another podcast from France Culture is this podcast which focuses on historical events generally.</li><li><a href="https://www.binge.audio/podcast/parler-comme-jamais" target="_blank" rel="noopener">Parler comme jamais</a> - This is another one of my favorite podcasts since it is hosted by two linguists who give a deep dive into the various idiosyncrasies of the French language while also providing commentary on the social and political aspects of the language. This latter aspect is quite interesting because discussions on what is right and wrong in the French language can become a matter of serious contention.</li></ol><h2 id="music">Music</h2><ol><li><a href="https://www.bbc.co.uk/programmes/b006qnmr" target="_blank" rel="noopener">Desert island discs</a> - This is another podcast from the BBC where invited guests talk about and share what kind of music they would take if they were stranded on an island. I find this a great way of finding new music.</li><li><a href="https://www.bbc.co.uk/programmes/p02nrvd3" target="_blank" rel="noopener">Composer of the week</a> - One of the best podcasts there is if you are a fan of classical music. Each week we get to listen to a single composers life and work. There is also extra episodes that focus on a particular composer and follow their musical output throughout the year. Last year was Beethoven which was a real delight. Note that after brexit it seems that the podcast isn’t available in France. I tried with a VPN with some success.</li><li><a href="https://www.wnycstudios.org/podcasts/aria-code" target="_blank" rel="noopener">Aria code</a> - This is one of those serendipitous finds: I found this podcast while searching for shows doing a deep-dive on operas. Rhiannon Giddens, a MacArthur genius musician in her own right, interviews opera performers and they dissect well-known arias from operas. As a person who is a neophyte when it comes to operas, this is a great way of understanding this art form.</li></ol><h2 id="shakespeare">Shakespeare</h2><p>This might seem like a weird category , but I have recently become supremely interested in Shakespeare and his plays. Not just the text, I have also become interested in the historical context behind the plays, the themes and the metaphors at play, and so on. It is not for nothing that authors and thinkers all over the world keep going back to the Bard for inspiration.</p><ol><li><a href="https://shows.acast.com/the-plays-the-thing" target="_blank" rel="noopener">The Plays The Thing</a> - This podcast is an extremely comprehensive introduction to all of Shakespeare’s plays. Each episode takes a deep dive into a particular section of a play, usually a few scenes from an act of the play, and discusses it at length. There is usually also an introductory episode to lay the groundwork so to speak for the play.</li><li><a href="https://www.folger.edu/shakespeare-unlimited" target="_blank" rel="noopener">Folger Shakespeare library</a> - This podcast serves the opposite purpose to the previous one. While “The Plays the thing” focuses on individual plays, this podcast takes a step back and tries to examine the impact that Shakespeare has had on modern culture and popular culture through the years. Everything from the Bard’s influence on science and art to the Game of Thrones is fair play.</li></ol><h2 id="history">History</h2><p>Following on from culture are podcasts that I listen to regularly covering various regions of the world through various periods of history.</p><ol><li><a href="https://thehistoryofrome.typepad.com/revolutions_podcast/" target="_blank" rel="noopener">Revolutions</a> - The revolutions podcast as the name suggests is about…revolutions. While the first season talked about the French revolution, the current season is focusing on the Russian revolution. This is not just a blow by blow accounts of the events, but a detailed examination of the social and political realities that led to the revolution. Mike Duncan, the creator of the podcast, it turns out lives in Paris. Would love to have a chance to share a coffee with him once Covid is behind us.</li><li><a href="https://www.thebritishhistorypodcast.com/" target="_blank" rel="noopener">The British history podcast</a> - As the name suggests, covers British history. The podcast follows a chronological order and is very detailed and covers all aspects of the island across the channel.</li><li><a href="https://historyofafricapodcast.blogspot.com/" target="_blank" rel="noopener">The History of Africa</a> - Africa as a continent is generally neglected when it comes to the study of history. I don’t remember ever having a class or a chapter on African history. So this podcast is a nice entry point to the story of Africa. The first season focused on Egypt and in the current one we are taking a look at Ethiopia.</li><li><a href="https://historyofphilosophy.net/" target="_blank" rel="noopener">The History of Philosophy Without Any Gaps</a> - This was actually one of the earliest podcasts that I subscribed to. The objective of the podcast is a laudable one: it seeks to chart the course of philosophy starting from the pre-Socratics right t the present age. Furthermore, the podcast also tries to cover the story of philosophy from other parts of the world as well- we have sections on Arabic philosophy, Chinese and Indian pholiopshy and also African philosophy. The companion website is also a great resource.</li><li><a href="http://intellectualmathematics.com/opinionated-history-of-mathematics/" target="_blank" rel="noopener">The History of Mathematics</a> - This one is a recent favorite of mine. The podcast tries to give an opinionated account of the history of mathematics and place it within the current context. Highly recommended for people interested in mathematics.</li></ol><h2 id="conclusion">Conclusion</h2><p>In the next blogpost, I will cover other podcasts that I listen to regularly on art, food, fashion and culture along with some other quirky picks.</p></div></div>]]>
            </description>
            <link>https://dhruv-sharma.ovh/blog/podcasts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989939</guid>
            <pubDate>Mon, 01 Feb 2021 16:14:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Memgraph DB 1.3 release brings high availability replication (HA)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989934">thread link</a>) | @karimtr
<br/>
February 1, 2021 | https://memgraph.com/blog/memgraph-1-3-release | <a href="https://web.archive.org/web/*/https://memgraph.com/blog/memgraph-1-3-release">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Introduction</h3>
<p>Hello, graph-wrangling, database-lovin’ folks out there! It’s been a long winter for us all, but we’ve made the best out of the cold, dreary days to bring you a whole new bag of tricks to keep you occupied for a while. Without further ado, we’re happy to announce that <a href="https://memgraph.com/download">Memgraph 1.3</a> is officially out!</p>
<p>If there’s one thing we’re proud of, it’s that from now on, the all-new <a href="https://docs.memgraph.com/memgraph/reference-guide/replication">replication feature</a> will enable you to copy and sync your Memgraph database to multiple servers to ensure your data is always available even if your main server goes down.</p>
<p>Of course, we’ve thrown in some extra goodies to spice things up, so read on and bon appetite!</p>
<h2>Replication</h2>
<p>Starting with this release, if you’re a Memgraph Enterprise user, you’ll be able to sync your data between Memgraph instances that run on different machines. In other words, using the replication feature, you’ll be able to create and run clusters of nodes running synced Memgraph instances, ensuring high availability of your graph data.</p>
<p>We provide the <em>main</em>-<em>replica</em> cluster node relationship model (aka leader-follower). A node may take on the role of the main (containing data to be replicated to other nodes), and the nodes that take on the role of replicas work in concert with the main to reconstruct the data present on the main, and keep in sync with it.</p>
<p>To sync data, you’ll be able to choose between the sync, async and semi-sync mode, depending on how hard your consistency requirements are.</p>
<p><img src="https://i.imgur.com/4cO6nOM.png" alt=""></p>
<p>This simple but powerful setup enables you to create highly flexible and fault-tolerant clusters that can be easily configured and deployed anywhere!</p>
<p>“How does it work and how can I try it out?”, you may ask. Head on over to <a href="https://docs.memgraph.com/memgraph/reference-guide/replication">the reference guide</a> for a more in-depth explanation of replication, and check out the <a href="https://docs.memgraph.com/memgraph/database-functionalities/replication">how-to guide</a> to get you replicating in no time!</p>
<h2>Data Directory Locking</h2>
<p>Memgraph uses snapshots and WAL files as durability files. These are used to reconstruct the database to the most up-to-date version. Up to now, there was no reliable way to back up those durability files while an instance is running, so to back up a database, one had to either dump it (using the <code>DUMP DATABASE</code> query), or kill the instance, and then back up the durability files.</p>
<p>To make a live backup easier, we added a locking query <code>(LOCK | UNLOCK) DATA DIRECTORY</code> that does just what it says - it prevents the instance from deleting durability files from it, giving the user the opportunity to back them up without fear of data loss. No more backup roulette!</p>
<h2>New And Improved Logging</h2>
<p>We’ve also improved the logging, which is now both faster and more configurable. Now the user can control the level of logging with the <code>--log-level</code> flag. No more techno gibberish when you don’t want it, and more gibberish when you need it!</p>
<h2>Query Type Deduction Done Right</h2>
<p>We’ve gotten around to implementing the so-called read-write type deduction properly. We faked it before, just to appease the Neo4j driver gods. Turns out, this type can be actually useful! For example, we use the type of the query to forbid write queries on replicas. Nifty, right?</p>
<h2>What’s Next?</h2>
<p>Go on, try it out! You can <a href="https://memgraph.com/download">download the 1.3 version</a>.</p>
<p>If you’re interested in the replication feature, check out this <a href="https://docs.memgraph.com/memgraph/reference-guide/replication">reference guide</a>, or this <a href="https://docs.memgraph.com/memgraph/database-functionalities/replication">how-to guide</a> if you want to get your hands dirty.</p>
<p>If you catch any bugs or generally weird behavior, please drop us a line on our <a href="https://discourse.memgraph.com/">forum</a>.</p>
<p>Happy hacking!</p>
</div></div>]]>
            </description>
            <link>https://memgraph.com/blog/memgraph-1-3-release</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989934</guid>
            <pubDate>Mon, 01 Feb 2021 16:14:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DynamoDB Foreign Key Support]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989778">thread link</a>) | @bwship
<br/>
February 1, 2021 | https://docs.getcommandeer.com/blog/latest/introducing-dynamodb-foreign-keys | <a href="https://web.archive.org/web/*/https://docs.getcommandeer.com/blog/latest/introducing-dynamodb-foreign-keys">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>We have been using <a href="https://aws.amazon.com/dynamodb/" title="DynamoDB" target="_blank" rel="noopener noreferrer">DynamoDB</a> for the past 4-5 years both at Commandeer, and on previous projects we have built, including <a href="https://www.tuition.io/" title="Tuition.io" target="_blank" rel="noopener noreferrer">Tution.io </a>and the <a href="https://speedqueenlaundry.com/app/" title="Speed Queen Laundry App" target="_blank" rel="noopener noreferrer">Speed Queen Laundry App</a>.  It is a really great NoSQL system that allows for infinite scaleability, is easy to use, and provides a great API to allow developers to get and modify data easily.</p> <p>But, one of the hangups we have had with NoSQL, is that often times, even though it is unstructured in nature, we typically build it in a structured way.  This means we do things like having a Membership table that relates to a User table by a Global Secondary Index called userId.  Anytime we need to get data from it however, we were having to pull in developers to code it up.</p> <p>In our upcoming version of Commandeer, 1.7, we will be providing Foreign Key inference on tables.  Let's dive into an example, to visually show you what I am talking about.</p> <blockquote><p><a href="https://getcommandeer.com/" title="Download the Commandeer App" target="_blank" rel="noopener noreferrer">Download the Commandeer App</a> - 15-day Free Trial - The #1 developer IDE to manage your serverless and container infrastructures, both locally and in the cloud. With support for 30+ of the best cloud services out there.</p></blockquote> <h2 id="foreign-key-inference"><a href="#foreign-key-inference">#</a> Foreign Key Inference</h2> <p>For the initial version of foreign keys, if your columns are named things like userId or user_id or userID AND you have a User table, we will link the two.</p> <p>In subsequent releases, we will be adding even more functionality for this via IaC.  There will soon be plugins for <a href="https://www.ansible.com/" title="Ansible" target="_blank" rel="noopener noreferrer">Ansible</a>, <a href="https://www.terraform.io/" title="Terraform" target="_blank" rel="noopener noreferrer">Terraform</a>, and the<a href="https://www.serverless.com/" title="The Serverless Framework" target="_blank" rel="noopener noreferrer"> Serverless Framework</a> that allow you to specify the foreign keys in code, and we will pick them up.  Under the hood, we will then have them as tags on the table, and Commandeer will automatically read from them.</p> <p>Below you can see how our Membership table relates to our User and Team tables.</p> <p><img src="https://images.commandeer.be/_uploads/dynamo-er-diagram-small.png" alt=""></p> <hr> <h2 id="er-diagram"><a href="#er-diagram">#</a> ER Diagram</h2> <p>The first place you can easily see what I am talking about is within the DynamoDB ER Diagram.  This tool allows you to visualize your DynamoDB tables.  Here you can see that many of the tables have a userId column that points to the User table.  And also that some of the tables have a foreign key of teamId pointing to the Team table.</p> <p><img src="https://images.commandeer.be/_uploads/dynamodb-er-diagram.png" alt="DynamoDB ER Diagram" title="DynamoDB ER Diagram"></p> <hr> <h2 id="foreign-key-information"><a href="#foreign-key-information">#</a> Foreign Key Information</h2> <p>If we drill down into the Membership table, you can see the information about not only the Primary and Secondary indexes, but now also the foreign keys and what tables they are linked to.</p> <p><img src="https://images.commandeer.be/_uploads/membership-table.png" alt="DynamoDB Membership Table" title="DynamoDB Membership Table">And zooming in further to the Membership table itself, you can see that the userId column maps to the User table, and the teamId column maps to the Team table.</p> <p><img src="https://images.commandeer.be/_uploads/membership-table-foreign-keys.png" alt="DynamoDB Foreign Key Columns" title="DynamoDB Foreign Key Columns"></p> <p>You can also view this information from the side navigation.</p> <p><img src="https://images.commandeer.be/_uploads/membership-sideview.png" alt="Membership Schema" title="Membership Schema"></p> <div><pre><code># Legend

PK = Primary Key
SK = Sort Key
GSI = Global Secondary Index
FK = Foreign Key
</code></pre></div><hr> <h2 id="the-power-of-the-foreign-key"><a href="#the-power-of-the-foreign-key">#</a> The Power of the Foreign Key</h2> <p>The real power of the Foreign Key is two-fold.  First, as shown above, it gives you a great way to visualize your system with the ER Diagram.  When you are explaining your system to people, you don't have to draw it out on a white board every time to visualize it  The other great feature is that in Commandeer, we allow you to view your related data instantly when looking through a table.</p> <p>Below you can see a few records in the Membership table, and if you have the 'Format Data' toggle turned on, you will see a new drop down link called 'View' on each record.</p> <p><img src="https://images.commandeer.be/_uploads/membership-table2.png" alt=""></p> <p>Clicking on the 'View' link then brings up the related record in a modal.</p> <p><img src="https://images.commandeer.be/_uploads/membership-table-foreign-key-data.png" alt=""></p> <p>This is a great improvement over the old way of using DynamoDB, in which we would have the Membership table and the User table opened in separate tabs.  And then copy the userId from the Membership table, and and it to the query on the User tab.  Under the hood, it is doing a primary key query to retrieve the record, and it is only brought back on demand when you click the link.</p> <hr> <h2 id="conclusion"><a href="#conclusion">#</a> Conclusion</h2> <p>DynamoDB continues to be our go to NoSQL system, because it integrates with AppSync, Athena, and Lambda so well.  Foreign keys add a whole new level of data accessibility that has been lacking in the ecosystem until now.</p> <p>Happy Developing!</p> <blockquote><p><a href="https://getcommandeer.com/" title="Download the Commandeer App" target="_blank" rel="noopener noreferrer">Download the Commandeer App</a> - 15-day Free Trial - The #1 developer IDE to manage your serverless and container infrastructures, both locally and in the cloud. With support for 30+ of the best cloud services out there.</p></blockquote></div><div><!----> <p><span>Last update:</span> <span>February 1, 2021 15:46</span></p></div></div>]]>
            </description>
            <link>https://docs.getcommandeer.com/blog/latest/introducing-dynamodb-foreign-keys</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989778</guid>
            <pubDate>Mon, 01 Feb 2021 16:01:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Guide to Terminal User Interfaces in PowerShell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989724">thread link</a>) | @todsacerdoti
<br/>
February 1, 2021 | https://blog.ironmansoftware.com/tui-powershell/ | <a href="https://web.archive.org/web/*/https://blog.ironmansoftware.com/tui-powershell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main"><div><h2>The Ultimate Guide to Terminal User Interfaces in PowerShell</h2><h4>January 30, 2021</h4><p>Terminal User Interfaces (TUI) have a long history in computing and were some of the first forms of interfaces between human and machine. Sometimes referred to as text-based user interfaces, they are starting to gain popularity again with projects like <a href="https://github.com/migueldeicaza/gui.cs">Terminal.Gui</a> for .NET. In this guide, we take a deep dive into how to build TUIs with PowerShell and Terminal.Gui.</p><h2 id="table-of-contents">Table of Contents</h2><ul><li><a href="#intro">Intro to Terminal.Gui</a></li><li><a href="#installation">Installation</a></li><li><a href="#createwindow">Creating a Window</a></li><li><a href="#views">Controls</a><ul><li><a href="#buttons">Buttons</a></li><li><a href="#checkboxes">Checkboxes</a></li><li><a href="#dialogs">Dialogs</a></li><li><a href="#frame-view">Frame View</a></li><li><a href="#labels">Labels</a></li><li><a href="#list-view">List View</a></li><li><a href="#menus">Menus</a></li><li><a href="#text-fields">Text Fields</a></li></ul></li><li><a href="#layout-and-sizing">Layout and Sizing</a></li><li><a href="#events">Events</a><ul><li><a href="#click-events">Click Events</a></li><li><a href="#selection-events">Selection Events</a></li><li><a href="#keyboard-events">Keyboard Events</a></li></ul></li><li><a href="#threading">Threading</a><ul><li><a href="#Asynchronous-Execution">Asynchronous Execution</a></li><li><a href="#timers">Timers</a></li></ul></li><li><a href="#threading">Designer</a></li><li><a href="#conclusion">Conclusion</a></li></ul><h2 id="intro">Intro to Terminal.Gui</h2><p>Terminal.Gui is a .NET library for creating robust TUIs. It’s cross-platform and works with various types of terminals. It uses a nested view system that defines basic controls like windows, buttons, labels, and text fields. It also employs an absolute and calculated layout system to easily position controls.</p><p>Here’s an example of the <a href="https://ironmansoftware.com/powershell-pro-tools">PowerShell Pro Tools</a> TUI designer built with Terminal.Gui.</p><p><img src="https://blog.ironmansoftware.com/images/drag.gif" alt=""></p><h2 id="installation">Installation</h2><p>There are a couple ways of installing the Terminal.Gui library but the easiest is to install the <code>Microsoft.PowerShell.ConsoleGuiTools</code> module as it includes the library itself.</p><div><pre><code data-lang="powershell">Install-Module Microsoft.PowerShell.ConsoleGuiTools 
</code></pre></div><p>Once the module is installed, you will the need to load the assembly to ensure that the types are available for creating the TUI.</p><div><pre><code data-lang="powershell">Import-Module Microsoft.PowerShell.ConsoleGuiTools 
$module = (Get-Module Microsoft.PowerShell.ConsoleGuiTools -List).ModuleBase
Add-Type -Path (Join-path $module Terminal.Gui.dll)
</code></pre></div><p>Terminal.Gui requires that top level application be initialized before developing your TUI. This can be done with the <code>Application</code> class.</p><div><pre><code data-lang="powershell"><span>[Terminal.Gui.Application]</span>::Init()
</code></pre></div><p>Now that the library is loaded and initialized, we can start create our first TUI.</p><h2 id="createwindow">Creating a Window</h2><p>To create a window, we can use the <code>Window</code> class and add it to the top level view of the application. All views share similar properties such as position, size, and sub views.</p><p>To create a basic window, we can just invoke the default constructor and set it to a variable. Next, we need to add it to the top level view and run the application.</p><div><pre><code data-lang="powershell">$Window = <span>[Terminal.Gui.Window]</span>::new()
$Window.Title = <span>"Hello, World"</span>
<span>[Terminal.Gui.Application]</span>::Top.Add($Window)
<span>[Terminal.Gui.Application]</span>::Run()
</code></pre></div><p>Once the application is run, the TUI will be shown. You can exit it by pressing <code>Ctrl+Q</code>.</p><p><img src="https://blog.ironmansoftware.com/images/tui-helloworld.png" alt=""></p><h2 id="controls">Controls</h2><p>Now that we’ve looked at how to create a basic application with a window, we can start to look at different types of views, or controls, to add to your TUIs. Controls need to be added to their superview, like a window, in order for them to be displayed.</p><p>This is not a complete list of the available controls. For a complete list, visit the <a href="https://github.com/migueldeicaza/gui.cs#controls--features">Terminal.Guis GitHub page</a>.</p><h3 id="buttons">Buttons</h3><p>Buttons allow you to provide an interactive experience to your user. You can define a button’s text, action and position within the TUI.</p><p>Building on our previous example, we can add a button to a window like this.</p><div><pre><code data-lang="powershell">$Button = <span>[Terminal.Gui.Button]</span>::new()
$Button.Text = <span>"Button"</span> 
$Window.Add($Button)
</code></pre></div><p>The resulting TUI will look like this.</p><p><img src="https://blog.ironmansoftware.com/images/tui-button.png" alt=""></p><h3 id="checkboxes">Checkboxes</h3><p>Checkboxes allow for displaying boolean state or providing a way to the user to turn on or off a setting.</p><p>This example creates a simple check box with a label.</p><div><pre><code data-lang="powershell">$Label = <span>[Terminal.Gui.Label]</span>::new()
$Label.Text = <span>"Enable Disco"</span>
$Label.Height = 1
$Label.Width = 20
$Window.Add($Label)

$Checkbox = <span>[Terminal.Gui.Checkbox]</span>::new()
$Checkbox.Checked = $true
$Checkbox.X = <span>[Terminal.Gui.Pos]</span>::Right($Label)
$Window.Add($Checkbox)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-checkbox.png" alt=""></p><h3 id="frame-views">Frame Views</h3><p>Frame views are container views that have a title, border and contain other subviews. They are used to organize regions of your TUI.</p><p>This example creates two side-by-side frame views with labels in each.</p><div><pre><code data-lang="powershell">$Frame1 = <span>[Terminal.Gui.FrameView]</span>::new()
$Frame1.Width = <span>[Terminal.Gui.Dim]</span>::Percent(50)
$Frame1.Height = <span>[Terminal.Gui.Dim]</span>::Fill()
$Frame1.Title = <span>"Frame 1"</span>
$Window.Add($Frame1)

$Frame2 = <span>[Terminal.Gui.FrameView]</span>::new()
$Frame2.Width = <span>[Terminal.Gui.Dim]</span>::Percent(50)
$Frame2.Height = <span>[Terminal.Gui.Dim]</span>::Fill()
$Frame2.X = <span>[Terminal.Gui.Pos]</span>::Right($Frame1)
$Frame2.Title = <span>"Frame 2"</span>
$Window.Add($Frame2)

$Label1 = <span>[Terminal.Gui.Label]</span>::new()
$Label1.Text = <span>"Frame 1 Content"</span>
$Label1.Height = 1
$Label1.Width = 20
$Frame1.Add($Label1)

$Label2 = <span>[Terminal.Gui.Label]</span>::new()
$Label2.Text = <span>"Frame 2 Content"</span>
$Label2.Height = 1
$Label2.Width = 20
$Frame2.Add($Label2)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-frame.png" alt=""></p><h3 id="labels">Labels</h3><p>Labels are just text that you can place on your views. For a label to be visible, we need to set the width and height of the view. We’ll talk more about dimensions and sizing in the layout section.</p><div><pre><code data-lang="powershell">$Label = <span>[Terminal.Gui.Label]</span>::new()
$Label.Text = <span>"Hi, Mom!"</span> 
$Label.Width = <span>[Terminal.Gui.Dim]</span>::Fill()
$Label.Height = <span>[Terminal.Gui.Dim]</span>::Fill()
$Window.Add($Label)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-label.png" alt=""></p><h3 id="list-view">List View</h3><p>List views allow you to display collections of items in a list. Users can select the items and you can connect event handlers to listen for changes to those selections.</p><div><pre><code data-lang="powershell">$ListView = <span>[Terminal.Gui.ListView]</span>::new()
$ListView.SetSource(@(<span>"Item1"</span>, <span>"Item2"</span>, <span>"Item3"</span>))
$ListView.Width = <span>[Terminal.Gui.Dim]</span>::Fill()
$ListView.Height = <span>[Terminal.Gui.Dim]</span>::Fill()
$Window.Add($ListView)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-listview.png" alt=""></p><h3 id="text-fields">Text Fields</h3><p>Text fields are used to allow the user to input data. Text fields can also be used with a mask to allow users to enter passwords. Text fields, like other input controls, support tab stops so you can navigate the TUI by using the keyboard.</p><div><pre><code data-lang="powershell">$Textfield = <span>[Terminal.Gui.Textfield]</span>::new()
$Textfield.Text = <span>"What now?"</span> 
$Textfield.Width = <span>[Terminal.Gui.Dim]</span>::Fill()
$Window.Add($Textfield)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-textfield.png" alt=""></p><p>There are many other views that you can use with Terminal.Gui. You can learn about all of them on their documentation.</p><h3 id="dialogs">Dialogs</h3><p>There are various dialog views that you can show over the top of your main window. Dialogs are typically modal and you can allow users to perform specific actions. There are also specific dialogs for opening and saving files.</p><h4 id="message-boxes">Message Boxes</h4><p>The <code>MessageBox</code> class can be used to show information and error messages. It’s easy to use and doesn’t require too much code.</p><p>The following shows a message box with a title and a message.</p><div><pre><code data-lang="powershell"><span>[Terminal.Gui.MessageBox]</span>::Query(<span>"Hello"</span>, <span>"World"</span>)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-messsagebox.png" alt=""></p><p>Message boxes can also include buttons and will return the index of the button that was clicked. The below example creates a message box with multiple buttons. If Ok is clicked, the <code>$Result</code> variable will contain <code>0</code> and the web site will be opened.</p><div><pre><code data-lang="powershell">$result = <span>[Terminal.Gui.MessageBox]</span>::Query(<span>"Hello"</span>, <span>"Go to IronmanSoftware.com?"</span>, @(<span>"Ok"</span>, <span>"Cancel"</span>))
<span>if</span> ($result <span>-eq</span> 0)
{
    Start-Process https<span>:</span>//www.ironmansoftware.com
}
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-messsagebox-buttons.png" alt=""></p><p>Message boxes can also show errors dialogs. You can use the <code>ErrorQuery</code> to show these types of boxes.</p><div><pre><code data-lang="powershell"><span>[Terminal.Gui.MessageBox]</span>::ErrorQuery(<span>"Failed"</span>, <span>"Catastrophic failure"</span>);
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-error.png" alt=""></p><h4 id="dialogs-1">Dialogs</h4><p>The <code>MessageBox</code> class is a helper for creating dialogs to display simple text and buttons. You can also create dialogs directly. You can still add buttons but you can also add any control you’d like within the content of the dialog.</p><p>This example creates a dialog that includes a text field. You need to call <code>[Application]::Run</code> on the dialog in order to show it.</p><div><pre><code data-lang="powershell">$Dialog = <span>[Terminal.Gui.Dialog]</span>::new()
$Dialog.Title = <span>"Whoa"</span>
$Textfield = <span>[Terminal.Gui.Textfield]</span>::new()
$Textfield.Width = 10
$Dialog.Add($Textfield)
<span>[Terminal.Gui.Application]</span>::Run($Dialog)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-dialog.png" alt=""></p><h4 id="open-and-save-dialogs">Open and Save Dialogs</h4><p>Terminal.Gui also contains specific dialogs for open and saving files and folders. You can customize which folder to open to, whether multiple items can be selected and filter based on file type. The following example creates a open dialog that displays <code>.PS1</code> files.</p><div><pre><code data-lang="powershell">$Dialog = <span>[Terminal.Gui.OpenDialog]</span>::new(<span>"Open Powershell Script"</span>, <span>""</span>)
$Dialog.CanChooseDirectories = $false
$Dialog.CanChooseFiles = $true 
$Dialog.AllowsMultipleSelection = $false
$Dialog.AllowedFileTypes = @(<span>".ps1"</span>)
<span>[Terminal.Gui.Application]</span>::Run($Dialog)

<span>[Terminal.Gui.MessageBox]</span>::Query(<span>"File"</span>, $Dialog.FilePath)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-opendialog.png" alt=""></p><p>Menus can be added to the top of a window to provide drop down options. Items within the menus can provide actions to take when the menu item is clicked. You can create nested menus that contain sub menu items.</p><p>A basic menu can be added by using the <code>MenuBar</code>, <code>MenuBarItem</code> and <code>MenuItem</code> classes.</p><p>You can define shortcuts to invoke menu items by including a <code>_</code> in front of the character.</p><div><pre><code data-lang="powershell">$MenuItem = <span>[Terminal.Gui.MenuItem]</span>::new(<span>"_About"</span>, <span>""</span>, { <span>[Terminal.Gui.MessageBox]</span>::Query(<span>"About"</span>, <span>"Cool Tutorial 1.0"</span>) })
$MenuBarItem = <span>[Terminal.Gui.MenuBarItem]</span>::new(<span>"Help"</span>, @($MenuItem))
$MenuBar = <span>[Terminal.Gui.MenuBar]</span>::new(@($MenuBarItem))
$Window.Add($MenuBar)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-menu.png" alt=""></p><h2 id="layout-and-sizing">Layout and Sizing</h2><p>As you have seen in some of the examples above, we had to set the dimensions of components in order for them to appear within our window. In addition to controlling dimensions, you can also control positioning using both an absolute and a calculated system.</p><h3 id="sizing">Sizing</h3><p>Sizing controls is done using the <code>Dim</code> class. You can size controls based on an absolute value, the remaining size of the screen or a percentage. The width and height of view can be set using the <code>Width</code> and <code>Height</code> properties.</p><h4 id="absolute">Absolute</h4><p>Absolute sizing can be accomplished using the <code>Dim</code> class or by simply setting an integer value to the dimension you wish to set.</p><p>The following example creates a text field that is 5 in width.</p><div><pre><code data-lang="powershell">$Textfield = <span>[Terminal.Gui.Textfield]</span>::new()
$Textfield.Width = 10
$Window.Add($Textfield)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-absolute.png" alt=""></p><h4 id="fill">Fill</h4><p>You can use the <code>Fill</code> method of the <code>Dim</code> class to instruct the layout engine to fill the specified dimension with the control. This is useful for making a text field stretch across a window horizontally or stretch a frame view to the bottom of a window.</p><p>In this example, we stretch a text field horizontally across a window.</p><div><pre><code data-lang="powershell">$Textfield = <span>[Terminal.Gui.Textfield]</span>::new()
$Textfield.Width = <span>[Terminal.Gui.Dim]</span>::Fill()
$Window.Add($Textfield)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-fill.png" alt=""></p><h4 id="percentage">Percentage</h4><p>You can set a view to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ironmansoftware.com/tui-powershell/">https://blog.ironmansoftware.com/tui-powershell/</a></em></p>]]>
            </description>
            <link>https://blog.ironmansoftware.com/tui-powershell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989724</guid>
            <pubDate>Mon, 01 Feb 2021 15:57:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The career-changing art of reading the docs]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25989676">thread link</a>) | @forrestbrazeal
<br/>
February 1, 2021 | https://acloudguru.com/blog/engineering/the-career-changing-art-of-reading-the-docs | <a href="https://web.archive.org/web/*/https://acloudguru.com/blog/engineering/the-career-changing-art-of-reading-the-docs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="8a920a5" data-element_type="widget" data-widget_type="theme-post-content.default"><div><p>Every so often I get asked for advice on how to become an <a href="https://aws.amazon.com/developer/community/heroes/">AWS Hero</a>.</p><p>The specific answer isn’t that interesting – “get involved in the community and hope someone nominates you as a Hero” seems to be the process at AWS. I understand that the <a href="https://mvp.microsoft.com/en-us/overview">Microsoft MVP process</a> is a bit more transparent and better prescribed.</p><p>But the general question of “how do I become well-respected in my chosen technical specialty” is VERY interesting. Even if you don’t have any aspirations to build a public following, there is tremendous career value in becoming the go-to person within your technical niche.</p><p>The person who everybody on your team comes to with their toughest question about that language or framework. The person who knows where all the bodies are buried in ActiveDirectory or Typescript or DynamoDB. Those folks have great careers and job security because authoritative knowledge like that is rare.</p><p>To some extent, it’s rare because wisdom only comes with experience. But I know plenty of engineers who’ve sat in the same chair for ten years getting the same year of experience ten times. Heck, I’ve been there myself; I spent a couple of years as an “accidental DBA” who never really learned that much about SQL Server beyond what the daily firefighting required.</p><p>I used to spend a lot of time wondering how other people seemed to level up so quickly on new technologies. How do you break through that stagnant cycle of learning and forgetting stuff in bits and pieces, using the same technology for years without ever feeling like an expert?</p><p>A few years ago I learned a secret for doing this, a cheat code if you will, from my fellow AWS Hero <a href="https://acloudguru.com/blog/author/jared-short">Jared Short</a>. This is his secret recipe for leveling up in tech:</p><p><strong>Read the documentation for one job-relevant technology, cover-to-cover, every week. </strong></p><figure><div><blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">Forrest is giving away my secrets, but it's true. I'd estimate around 700+ hours of just reading AWS docs over my career with intent to retain / learn (not just reference). It feels silly until you almost immediately understand some esoteric side-effect or behavior. <a href="https://t.co/juQ0b9mENI">https://t.co/juQ0b9mENI</a></p>— Jared Short (@ShortJared) <a href="https://twitter.com/ShortJared/status/1347629518312378369?ref_src=twsrc%5Etfw">January 8, 2021</a></blockquote> </div></figure><h2 id="h-reading-docs-the-wrong-way-and-the-right-way">Reading docs: the wrong way and the right way</h2><p>I get it, that doesn’t sound revolutionary. “<a href="https://en.wikipedia.org/wiki/RTFM">RTFM</a>” is literally as old as computing itself. It’s the classic kiss-off answer to questions you ought to be able to Google.</p><p>And that betrays a key limitation in how a lot of us think about documentation. We think of it tactically, as a resource to query when we have a specific question or encounter a particular error. We use docs to fill in our <em>known unknowns.</em></p><p>That’s how you can get stuck for years, say, administering a PostgresSQL cluster and never really becoming that deep of an expert on Postgres. If you only learn something new when the situation demands it, your mental model of Postgres (or whatever) will look like a gradually expanding version of this:</p><figure><img loading="lazy" width="2181" height="1647" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 2181w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 1024w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 768w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 1536w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 2048w" sizes="(max-width: 2181px) 100vw, 2181px"></figure><p>Over time, as you encounter more new use cases for the technology, you’ll burn more “never forget” bubbles into the mental model. But you’ll still have this heavy sense of unknown unknowns hanging over you, and you’ll never be sure if you’re really using the optimal approach to solve a new problem.</p><p>Instead, Jared’s approach is to read docs strategically<em>, </em>preemptively, curiously: as a way to fill in your <em>unknown unknowns</em>. The things you might not encounter in ten years, but that would cost you two days of troubleshooting if you ran into them tomorrow.</p><p>Read docs like novels (cover to cover), not like dictionaries (look up the term, cross-reference, and stop). Over time, that strategy will lead to a mental model of your professional domain that looks more like this:</p><figure><img loading="lazy" width="727" height="549" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/strategic.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/strategic.png 727w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/strategic.png 300w" sizes="(max-width: 727px) 100vw, 727px"></figure><p>(This is <a href="https://acloudguru.com/blog/engineering/how-many-certifications-do-i-need-to-get-a-cloud-job">the same benefit</a> you get from studying for certifications, by the way: you’re building a mental map of the domain, so you don’t have to stumble through the darkness on every new quest.)</p><p>On the surface, that sounds simple, but it’s far from easy. Here are three common objections people raise when I advise reading docs as a career-advancement strategy:</p><h4 id="h-i-don-t-have-a-photographic-memory-i-ll-never-remember-a-bunch-of-random-docs"><strong>“I don’t have a photographic memory. I’ll never remember a bunch of random docs.”</strong></h4><p>Back when I was in college, a well-meaning friend convinced me I should read a book on SAP. Forget today — I couldn’t have told you a single thing about SAP <em>ten minutes after finishing that book</em>. I’d never been inside an enterprise, much less understood the problems these ERP integrations I was reading about were supposed to solve. It was like trying to talk to the aliens in the movie <em>Arrival</em>: my brain was the wrong shape.</p><p>Likewise, you probably won’t get much value out of glancing through docs for a technology you don’t use and have no context for.</p><p>So do these two things:</p><p>1. <strong>Focus on docs for technologies you are already using</strong>. We’ve all had that mind-numbing feeling when plowing through some esoteric text that doesn’t relate to our daily lives, where you glaze over for three pages and then go, “what did I just read?”</p><p>Avoid this by focusing on docs for technologies or languages you’ve already got a vested stake in – say, because they’re on your plate at work or you’re trying to build them into a side project.</p><p>Encourage active reading and engagement with the information by asking yourself questions like these as you read:</p><ul id="block-ef7bb5e0-252c-434f-98de-116c8c0e2003"><li>Did I understand that? (If not, maybe read the section again)</li><li>Does what I just read match my existing mental model of how this technology works? (If not, do I need to go review a different doc and then come back to this?)</li><li>Could this feature or fact help me on my current project?</li><li>If I had known this six months ago, what would I have done differently? (“Chosen a different technology” is a totally acceptable answer!)</li></ul><p>Then, <strong>2. Read those docs repeatedly, on a schedule, over and over</strong>. Seriously. If you’re on a team that’s building out centralized CI/CD for Azure, maybe read the part of the Azure DevOps docs on pipelines this week and the part on build agents next week, and when you get to the end, start over. The cloud changes fast. You’ll fold in new information at the same time you’re reinforcing the old.</p><h4 id="h-i-don-t-have-time-to-read-a-bunch-of-documentation"><strong>“I don’t have time to read a bunch of documentation.”</strong></h4><p>Yes, and weeks of work can save you hours of planning. Maybe use some of the time you currently spend injecting “HERE” print statements into your code to figure out why it’s not working.</p><figure><img src="https://faasandfurious.com/pages/debugging-tactics.png" alt="Debugging Tactics"></figure><p>More seriously, it’s not a bad idea to block a bit of time on your calendar each day – 30 minutes, even –  for targeted doc-reading. You may find it hard to carve that time out of your workday, but defending time and setting expectations with your manager is its own skill, worth practicing. Call the block of time “deep work.” It is.</p><h4 id="h-the-docs-for-technology-x-are-no-good-trust-me-they-re-not-worth-reading"><strong>“The docs for [technology X] are no good. Trust me, they’re not worth reading.”</strong></h4><p>I don’t always buy this excuse. The docs might not be that bad; you might just have the wrong expectations.</p><p>For example, the AWS documentation gets <a href="https://twitter.com/IanColdwater/status/1347737875991777280">a terrible rap</a> for being wordy and poorly-organized. And it’s maybe even worse than you’ve heard – if you’re trying to look up the name of an IAM action or the syntax of a CLI command, that is.</p><p>But as an educational tool that dives deep on the architectural underpinnings and technical limitations of services, the AWS docs are <em>fantastic. </em>They’re better than any book you could ever buy about the cloud. (And the <a href="https://aws.amazon.com/builders-library/">Builder’s Library</a> is better still.) The AWS docs are designed not just to be referenced, but to be read. Read ’em!</p><p>On the other hand, some types of docs like step-by-step tutorials are very much designed to be referenced during hands-on builder time. It may not make sense to spend a lot of time reading those in the abstract. So bring your common sense.</p><p>However. There are also plenty of technologies out there where the docs are truly incomplete, out of date, or just plain wrong – many smaller open-source projects, in particular.</p><p>Turns out you have another option here, at least for OSS projects: <em>read the source code.</em> Not sure what a module does, what its edge cases are, what the error code means? Read the source code and find out! It might be faster than (and will definitely be at least as accurate as) looking for the answer in the docs, <em>even if the docs are pretty good. </em></p><p>If you write code for a living, reading other people’s shipped, battle-tested code — not just PRs from your own team — is genuinely one of the most transformative things you can do for your career. Because while you’re answering your immediate question, you’ll also be picking up style, organization, and technique from professional programmers operating under all kinds of interesting constraints. Seriously. Read code.</p><p>(And then, if it’s open-source, maybe consider contributing some docs!)</p><h2 id="h-what-do-i-get-out-of-all-this"><strong>What do I get out of all this?</strong></h2><p>If you read a targeted set of docs consistently over a sustained period — say, a couple of years — while actively practicing on that technology, you will be able to perform magic. That’s a promise.</p><p>Let’s go back to Jared Short again for an example. (Yes, I checked with Jared, he graciously agreed to let me spill his secrets in this piece.) As an engineer at an AWS shop, Jared …</p><ul><li>Reads the documentation for one AWS service, cover to cover, every week.</li><li>Blocks daily time for this on his calendar.</li><li>Focuses on services he’s actually using at work (he tells me that so far in 2021, he’s been through all the docs for Lambda, AppSync, and Step Functions).</li></ul><p>Jared’s been doing this week in, week out, for *years*. And that  unglamorous commitment lets him perform nerd magic like this:</p><figure><div><blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">I needed to understand extensions better for a thing, read the docs cover to cover like an insane person.</p>— Jared Short (@ShortJared) <a href="https://twitter.com/ShortJared/status/1347612782389301249?ref_src=twsrc%5Etfw">January 8, 2021</a></blockquote> </div></figure><p>If you don’t want to take the time to read that whole Twitter thread, let me sum it up for you.</p><ol><li>An experienced AWS engineer encounters a weird behavior: AWS Lambda seems to be executing code when it should not be. He posts a plea for help on Twitter.</li><li>Other experienced engineers take a look and go, “huh. Weird.” To be clear, this is not a case of RTFM. The problem is nontrivial and the solution, if there is one, is not well-known. …</li></ol></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acloudguru.com/blog/engineering/the-career-changing-art-of-reading-the-docs">https://acloudguru.com/blog/engineering/the-career-changing-art-of-reading-the-docs</a></em></p>]]>
            </description>
            <link>https://acloudguru.com/blog/engineering/the-career-changing-art-of-reading-the-docs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989676</guid>
            <pubDate>Mon, 01 Feb 2021 15:51:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Generation X will save the web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989659">thread link</a>) | @isolli
<br/>
February 1, 2021 | https://webdevlaw.uk/2021/01/30/why-generation-x-will-save-the-web/ | <a href="https://web.archive.org/web/*/https://webdevlaw.uk/2021/01/30/why-generation-x-will-save-the-web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>I like to make things as difficult for myself as possible, so first, I decided to become an independent-minded female immigrant in a parochial and patriarchal nation; then, when that got boring, I decided to become a woman in tech, where I found myself giving conference talks to rooms of professionals who could, technically and biologically, be my grown adult children.</p>

<p><span>T</span>hen, when that got boring, I pivoted out of code tech to policy tech, where I now find myself in much more forgiving company. Which is to say, for the first time since my non-tech career, I work alongside and in partnership with other Gen Xers.</p>
<p><em>Insert any number of Buzzfeed listicles here about what it’s like to be a GenXer in tech: we learned on floppies and dialup; we coded out of print magazines; we sowed our teenage wild oats on the parental tether of nothing more than a coin in a pay phone; we lived entire years of our student lives without a single photograph being taken of us; we navigated 9/11 on dumb cell phones which had antennas; we now live datafied existences, raising datafied children attending datafied virtual schools, in a world where everything we were raised to believe would sort us for life turned out to be boomer bullshit.</em></p>
<p>All of those formative experiences give us (cough) fortysomethings a perspective on the internet which the boomers who birthed us lack, and which the millenials who followed us will never know.</p>
<p>In fact, we’ve gotten a lot of mileage out of the trope of the internet being threatened by elderly politicians who don’t understand it, or us. And that trope, for the most part, is as true as it ever was.</p>
<p>I can count on one hand the number of boomer-aged Parliamentarians in my network who well and truly understand the internet and its culture. They’re good folks who have my time, anytime. The rest, sadly, have more in common with the editorial board of the now-unreadable Glasgow broadsheet which issues weekly diatribes against the internet and all those who sail in her: every word steeped in all the offended sense of entitlement that bitter old men can muster, every rant beating the same dead horse against an internet which took away the newspaper readership that should, in their opinions, be hanging on every word that comes out of their privileged white Scottish male mouths.</p>
<p>So goes it for lawmakers, who – by nature and by privilege – have been insulated from the social and economic changes which necessitated the shift from the web as a geek hobby to the web as democratised culture. The ones who legislate aginst the web as if trying to restore an old world which existed before it, a world which only ever benefited people who looked and sounded like them.</p>
<p>Those lawmakers were who I expected to spend most of my time dealing with after my full-time pivot to policy.</p>
<p>The reality has been a lot more mind-blowing to comprehend than that.</p>
<p>Brace yourself.</p>
<p>When I was in my early twenties, in the late 90s and early 00s, running work missions across downtown Washington DC – pop into the Capitol complex here, run a folder to the White House there, drop off something for the Secretary of State on a long lunch break – everyone I encountered looked like me. The same age, the same countenance, the same Scully red hair (hey, it worked on me). Government may have been directed by professional politicians, but its actual daily mechanics were run by kids just out of university who had all the energy in the world and nothing and no one holding them down.</p>
<p>That’s universal, and it hasn’t changed. Government and policy – the mechanics and grunt work, not the media showmanship – are powered by an army of hard-working, very young people who have all of the academic knowledge and very little of the practical experience. Those young folks, now, in 2021, who were in nappies when I was on the Hill, now run whatever corridors of power they (virtually) travel through, in professional support of those older politicians.</p>
<p>And it’s these young professionals – <em>not the boomer career politicians</em> – who are setting the tone of internet policy.</p>
<p>And here’s the thing.</p>
<p>We – the GenXers – think of the internet as the open web. The land of dialup telnet Unix systems, the days of table layout, the days of dot com, the days of early tech startups, the days of the internet as a connector, the days of the internet as a business opportunity, the days of the internet as a path to social justice and revolutions, the days of the internet as a light in the darkness. That’s all we have ever known.</p>
<p>Today’s policy facilitators – the millenials – think of the internet as MySpace and Facebook. The closed web. The land of always-on broadband and wifi, the days of content management systems, the days of tech bros, the days of the internet as a divider, the days of the internet as an acquisition for the giants, the days of the internet as a path to radicalisation and hatred, the days of the internet as petrol on a spark. That is all they have ever known.</p>
<p>And that is what they draft policy briefings, proposals, and legislation against.</p>
<p>Laws on freedom of speech. Laws on privacy. Laws on encryption. Laws on private surveillance. Laws on state surveillance.</p>
<p>The truths I held to be self-evident are things they have never known.</p>
<p>And, politically, they are in the driving seat. They are running the show.</p>
<p><em>Not me. Not the old folks. Them.</em></p>
<p>Just like I was, a long time ago, with my Scully hair, in my Unix dialup world, a world before the TV signal briefly went out because the antenna which controlled the TV signal was on top of the tower with the plane-shaped hole in it, the hole which turned one of my university classmates into a centimetre-long fragment of a finger recovered 18 months later.</p>
<p>Today’s young tech policy professionals are are, quite rightfully, responding to the only internet in the only world they have ever known. The awful one. The one where the internet <em>was and is</em> a handful of billion-pound companies. The one where the internet has only ever been petrol on a fire. The one where the internet has been essential infrastructure like water and heat, not a thing you had to request and master. The closed internet made for them. Not the open internet I got to make.</p>
<p>So if you think that the biggest threat to encryption is elderly politicians who still need their secretaries to print out emails for them, it’s time you found yourself in a meeting with someone under the age of 30 who is going to war against encryption because <em>he</em> has never needed encryption in his life.</p>
<p>If you think that the biggest threat to internet freedom is old white men who hate the internet because it does not allow them to attack anyone who does not look or sound like them, it’s time you found yourself in a meeting with someone under the age of 30 who is unabashedly in favour of mandatory identity verification for all users of the internet to protect people who look and sound like her.</p>
<p>And if you think that the biggest threat to freedom of speech on the open web is a tech billionaire in California, it’s time you found yourself in a meeting with someone under the age of 30 who sees a legislative victory against online freedom of speech, cloaked in the mantle of a victory against the tech billionaire, as a useful stepping stone to his political ambitions.</p>
<p>Those old Thatcherites still in politics, the elderly dames in the Lords, the newspaper editors with the offended senses of entitlement, they can whinge all they want about how the internet has changed the world they knew. And you can continue to waste your time on them, and their tropes, if it makes you feel better about yourself.</p>
<p>But political power, now, rests in the hands of young professionals who are – <em>rightfully – </em>legislating to change the only internet they have ever known.</p>
<p>The shitty corporate one.</p>
<p>The open web we let slip through our fingers.</p>
<p>And maybe, just maybe, the best things standing in their way of their spite and their avarice and their political aspirations are the Gen X fortysomethings who saw something better about the open web, and comprehended what was on their screens in a way that nothing has ever touched them since, and still believe in what the open web can be, and understand where things went wrong, and have an idea of how to put things right, and know how to create and use and fork the tools to make it so, and know the north stars they navigate home by, and have never, ever forgotten them, and who need a little bit of reminding, in chaotic times, of what it was like to telnet into a blank screen which contained the entire world.</p>
					</div></div>]]>
            </description>
            <link>https://webdevlaw.uk/2021/01/30/why-generation-x-will-save-the-web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989659</guid>
            <pubDate>Mon, 01 Feb 2021 15:49:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reinforcement Learning at Facebook]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25989578">thread link</a>) | @agbell
<br/>
February 1, 2021 | https://corecursive.com/061-reinforcement-learning/ | <a href="https://web.archive.org/web/*/https://corecursive.com/061-reinforcement-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><i>Note: This podcast is designed to be heard. If you are able, we strongly encourage you to listen to the
audio, which includes emphasis that’s not on the page</i></p><div>
<h2 id="intro"><strong>Intro</strong></h2>
<p><strong>Adam:</strong>
Hey, so before We get into it, why don’t you state your name and what you do?</p>
<p><strong>Jason:</strong>
My name is Jason Gauci. And yeah, I bring machine learning to billions of people.</p>
<p><strong>Adam:</strong>
Hello and welcome to CoRecursive, the stories behind the code, I’m Adam Gordon Bell. Jason has worked on YouTube recommendations. He was an early contributor to TensorFlow, the open source machine learning platform. His thesis work was cited by DeepMind. They were the people who beat all human players at Go, and that’s StarCraft, I think. And who knows what else?</p>
<p>If you ever wanted to learn about machine learning, you could do worse than have Jason teach you. But what I find so fascinating with Jason is he recognized this problem that was being solved the wrong way and set out to find a solution to it.</p>
<p>The problem was making recommendations, like on Amazon, people who bought this book might like that book. He didn’t exactly know how to solve the problem, but he knew it could be done better. So that’s the show today, Jason’s going to share his story, but you will eventually change the way Facebook works. And we’ll learn about reinforcement learning and neural nets, and just about the stress of pursuing research at a large company. It all started in 2006 when Jason was in grad school.</p>
<h2 id="phd-program"><strong>PHD Program</strong></h2>
<p><strong>Jason:</strong>
Yeah, so I went to college, picked computer science, and I remember my parents found out a little strange. They said, “Oh, you could be a doctor or a lawyer or something, you have the brains for it.” And then at one point my dad thought it was kind of like going to school to be a TV repairman. And so he wasn’t really sure, he’s like, “Are you sure you really want to do this? Now I could just buy another TV or another computer if it breaks.” And to this day, I have to explain to people, I really don’t know how to fix computer. If this laptop broke right now, I’d just have to do the same thing my parents do and just go get another one, I have no idea. But I had an option to do a Master’s, PhD hybrid or basically do it all in one shot.</p>
<h2 id="capture-the-flag"><strong>Capture The Flag</strong></h2>

<p>And after two years, if I wanted to call it quits, then I would get the Master’s degree. Yeah, at the time I thought I will just do the Master’s, I didn’t really plan on getting a PhD. But actually the very last class that I took in my Master’s was a class called neuro evolution, which was all about trying to solve problems through neural networks and through evolutionary computation. So America Online had this capture the flag game for free. And I remember I downloaded it on a 56K modem, it took forever. And it was basically like a turn-based capture the flag where you played as one person, and there was a friendly AI for the other three players, and then there was four player enemy AI, and you’re trying to capture the flag. And if the enemy touched you, you’re in jail, but the friendly AI could bail you out of jail.</p>
<p><strong>Adam:</strong>
I think I played this. Do you get to see more and more of the ground as you travel?</p>
<p><strong>Jason:</strong>
Yeah, that’s right. Yeah. Yeah. Do you remember the name of it?</p>
<p><strong>Adam:</strong>
So the game is called Capture the Flag. If you’ve not played it, you view a large field with trees in it from overhead, and you can only see where your players have been, there’s a fog of war like in StarCraft. Except it’s turn-based, you move a certain number of moves and then your players freeze there, and the computer gets to take its turn and move its players.</p>
<h2 id="what-is-a-neural-net"><strong>What Is a Neural Net?</strong></h2>
<p><strong>Jason:</strong>
But for my neuro evolution course, my final project, I recreated this game, capture the flag. And then I built an AI for it using neuro evolution. And so just to unpack that, neural networks are effectively like function approximators that are inspired by the way the brain works. And so if you imagine graphing a function on your calculator, I’m sure everyone’s done this on their TI 85. You can punch in Y equals X squared and it’ll draw a little parabola on your TI 85 or whatever the calculator is nowadays. And so what a neural network will do is it will look at a lot of data and it can represent almost any function.</p>
<p><strong>Adam:</strong>
So if it’s your original graph thing, it’s like telling it X is two, Y is three. You’re feeding it all these pairs.</p>
<p><strong>Jason:</strong>
Exactly. Yep.</p>
<p><strong>Adam:</strong>
Memorizes them.</p>
<p><strong>Jason:</strong>
Yep. But because there’s contradictions and there’s noise in the data and all of that, you won’t tell it exactly, force it to be Y is three when X is three. But it’s a hint. You say, “Hey, when X is three, Y’s probably three.” So if you’re not there, get a little bit closer to there. And you do this over and over again for so many different Xs that you end up with some shape that won’t pass through every point, it’s usually impossible, but it will get close to a lot of the points.</p>
<h2 id="where-it-fails">Where It Fails</h2>
<p><strong>Adam:</strong>
This is basically back propagation. It’s a form of supervised learning. You’re training the neural net by supervising it and telling it when it gets the wrong answer, what it should have gotten instead. And to do this, you need to know what the right answer is so that you can train it.</p>
<p><strong>Jason:</strong>
And so that works great to when you have a person going and telling you the perfect answer or the right answer. But for puzzles and games, for example, you don’t have that. So look at Go, to this day, people haven’t found the perfect Go game, a Go game for people who are playing perfectly. And so you don’t have that. And so you have to do something different, you have to learn from experience. So you just say, “Look, this Go game, that’s a really good move. That’s better than any move we’ve ever seen at this point in the game.” It doesn’t mean it’s the best, it doesn’t mean that your goal should be to always make that move, but it’s really good. A simple way to do that is have a neural network and have it play a lot of Go, and then make a subtle change to it, and have it play a lot of Go again. And then say, “Okay, did that change make this player win more games?”</p>

<p>If it did, then you keep the change. And if it didn’t, then you throw it away. And so if you do this enough times, you will end up in what we call a local optimum. In other words, you’re making these small changes, you’re picking all the changes that make their Go player better, and eventually you just can’t find a small change that makes the player better. And so you could think of evolutionary computation at a high level as doing something like that, but it’s doing it a really large scale. So maybe you have a thousand small changes and 500 of them make the player better. And you can adapt all 500 of those different players and the existing players, you can take all 501 of those players and make a player that’s step-wise, that’s better in a big way. And you would just keep doing that.</p>
<p><strong>Adam:</strong>
So this is what Jason learned in his neuro evolution class. He would create all these generations of players, which had random changes, and like evolution, have them play capture the flags against each other, slowly breeding better and better players. Was there a moment where you tested out your algorithm?</p>
<h2 id="jason-watches-his-creation"><strong>Jason Watches His Creation</strong></h2>
<p><strong>Adam:</strong>
Did you try to play it and capture the flag?</p>
<p><strong>Jason:</strong>
Yeah, the real aha moment was, having this God’s eye view without the fog of war, because I was just an observer, and watching the AI. And specifically watching this almost like Wolfpack behavior, where three players would surround a player and trap them. Just seeing that thing that you’ve seen in nature just emerge organically, that to me was amazing. That was unbelievable. When I saw all the players converge and capture and do this methodical thing and then take the flag. And even, I think at one point two of them had been captured, and so the other two just decided to go for the flag and just forget about any strategy and just go for broke.</p>
<p><strong>Adam:</strong>
Did you watch it and anthropomorphize? Did you cheer for one team?</p>
<p><strong>Jason:</strong>
Yeah. Yeah. Yeah, I did. Naturally, you don’t want to cheer for the underdog. So yeah, you would see this scenario play out where they would chase after one person, even though there was four of them and only two of the other team, they would chase after one and the other one would get the flag.</p>
<p><strong>Adam:</strong>
I didn’t follow the strategy. One runs, and then…</p>
<p><strong>Jason:</strong>
Yeah. So one would run and the other four would all chase after that one. And then the second one would go and get the flag and win.</p>
<p><strong>Adam:</strong>
It’s like a decoy.</p>
<p><strong>Jason:</strong>
Yeah, but it would only happen when the AI was this advantaged. So the way it worked was there’s four players, so there’s a bunch of sensory information that was just repeated four times to make the input of the network. And I guess even though it’s playing against itself, it learned that when two of those inputs are completely shut off, which is what happened when they were captured, to then execute this hail Mary strategy. And yeah, it was just super fun to watch that play out. And I would remember just sitting in the lab cheering for this one person and they would try to come back. In your head, it was hard to know, because it was a big grid, can they get back quick enough to catch this person? So it’d be pretty suspenseful.</p>

<p>And just seeing all of that, just all encoded in this network, neural, excitation back prop and all these things for understanding what a neural network is doing, all this stuff hadn’t been invented yet. So it was just a black box and it was just magic. You would run it on the university cluster, who knows what it would do, you would get it back a few days later and you would just see all this amazing emergent behavior. That to me just really lit the spark. And so I had already accepted a job with the intention of just getting a Master’s and leaving because I just didn’t see anything that inspired me. But right there at the 11th hour, I took this course. And I said, “This is amazing.” The fact that it …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://corecursive.com/061-reinforcement-learning/">https://corecursive.com/061-reinforcement-learning/</a></em></p>]]>
            </description>
            <link>https://corecursive.com/061-reinforcement-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989578</guid>
            <pubDate>Mon, 01 Feb 2021 15:39:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Reshaped Mac Experience]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989450">thread link</a>) | @bluedino
<br/>
February 1, 2021 | http://morrick.me/archives/9150 | <a href="https://web.archive.org/web/*/http://morrick.me/archives/9150">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>Yesterday, a short <a href="https://twitter.com/lapcatsoftware/status/1355514848717791234">Twitter thread</a> by the excellent <a href="https://lapcatsoftware.com/articles/">Jeff Johnson</a> caught my eye. Since he often deletes past tweets, I’ll quote the relevant ones here (emphasis mine):</p>
<blockquote><p><strong>The selling point of the Macintosh was never the hardware, it was the user interface. So if the selling point now is the hardware, that’s a damning indictment of the current user interface.</strong></p>

<p><strong>I cannot emphasize enough how everyone seems to have lowered their standards with regard to the user interface.</strong> The “<a href="https://en.wikipedia.org/wiki/Overton_window">Overton window</a>” has moved. The Overton window now has rounded rects.</p>

<p>We’ve gone from “insanely great” and “It just works” to “Catalyst is good enough for most people.”</p>
<p>That’s fucking BS, and I won’t tolerate it.</p>

<p>Windows is “good enough for most people”. That’s why Windows has a 90% market share. Why should we aspire to that level, shouldn’t we have much higher aspirations? Mac is a niche. “Most people” are not even using Macs, so the majority is not even relevant. Mac is a premium brand.</p>

<p>The way I see it, the Mac now is merely milking the brand reputation and loyalty it previously built. That Jobs previously built. But neither Cook nor the current Mac deserves that reputation or loyalty.</p>

<p>Steve Jobs wasn’t an engineer. Not a hardware engineer, not a software engineer. At Apple, his role was as “proxy” for the&nbsp;users.</p>
<p>Apple no longer has a proxy for the users. Tim Cook is a proxy for the shareholders, nothing more.</p></blockquote>
<p>Jeff himself says that this criticism is hardly new, that these are things he already pointed out “a thousand times, to no effect”. While I am in no position to affect Apple or Mac development, this short Twitter rant had the effect of reminding me of something I, too, believe in; something I myself should emphasise more frequently. It’s those first two tweets I’ve quoted above.</p>
<p>As someone who still puts vintage Macs and older computers and devices to good use, the Mac’s user interface and user experience are in large part what still makes using 15–20-year-old machines enjoyable. This, by the way, also applies to other products of course. It’s thanks to well-designed user interfaces that we enjoy driving a classic car, or shooting with a 50-year-old film camera, or listening to vinyl records on a 40-year-old record-player and hi-fi stereo.</p>
<p>A couple of weeks ago I was on a group videochat with some friends and when I said that, frankly, using my 12-inch PowerBook G4 (2003) with Mac OS X 10.5 Leopard was more enjoyable than using my 13-inch retina MacBook Pro (2015) with Mac OS 11 Big Sur, the common reaction was that I was just being ‘nostalgic’; that surely my MacBook Pro was the better choice because it is orders of magnitude faster, with a ‘more modern’ OS, and that the sum of those parts was a better Mac experience. That I should ‘be rational’ and accept that.</p>
<p>Here, bringing up nostalgia is missing the point. And the point is that an admittedly faster hardware plus a purportedly ‘more modern’ operating system <em>do not necessarily</em> equal a better Mac experience. It’s interesting that my friends’ reaction was not to ask me <em>why</em> I was finding using an 18-year-old machine more enjoyable than an up-to-date Mac, but to promptly want to readjust my enjoyment, implying that there was something ‘wrong’ with&nbsp;it.</p>
<p>I’m finding that many people not only have lowered their standards with regard to the user interface, but more and more often when I bring up the subject, they seem to consider it a somewhat secondary aspect, something that’s only good for ‘geek talk’. The same kind of amused reaction laymen have to wine or coffee connoisseurs when they describe flavours and characteristics using specific lingo. Something that makes sense only to wine or coffee geeks but has little to no meaning or impact for the regular person.</p>
<p>The problem is that if an increasing number of people start viewing user interface design as an afterthought, or something that isn’t fundamental to the design of a product or experience — it’s all just ‘geek talk’ — then there is a reduced incentive to care about it on the part of the maker of the product. It’s more like a vicious circle, really; if Apple software’s quality declines but only a bunch of professional users and enthusiasts point that out, then Apple isn’t particularly incentivised to do a better job at it — the “good enough for most people” is really a dangerous, self-indulgent excuse. And in turn most people are fine with it, and in turn Apple think they’re on a ‘good’ path, and so&nbsp;forth.</p>
<p>At the very end of my piece <a href="http://morrick.me/archives/9141"><em> What about the M1 Macs?</em></a>, I&nbsp;wrote:</p>
<blockquote><p>They’re unbelievably good machines, and everything that is genuinely good about them and future Apple Silicon-based Macs — sheer performance, astounding power-efficiency, and great backward compatibility with Intel software thanks to Rosetta 2 — will also allow Apple to get away with a lot of things with regard to platform control, design decisions, and so&nbsp;forth.</p></blockquote>
<p>If you take a look at Jason Snell’s <a href="https://sixcolors.com/post/2021/01/apple-in-2020-the-six-colors-report-card/"><em>Apple in 2020: The Six Colors report card</em></a>, the Mac scored very good points overall, 4.7 out of 5, with a year-over-year increment of 1.1 points. The main reason has been of course the M1 Macs and Apple Silicon. Don’t get me wrong, Apple Silicon <em>is</em> groundbreaking, and Rosetta 2 is really an incredible performer on the software side. But what I contend is that a leap in hardware architecture and performance doesn’t necessarily mean that suddenly all is fine with the Mac as a platform or as an experience.</p>
<p>The Mac’s user interface is undergoing plastic surgery by the hand of surgeons who have studied on iOS books. The result is pretty much the same as when you see a favourite celebrity after a procedure. They look ‘younger’ but there’s also something weird about their appearance. Their traits have changed a bit. In certain cases you almost fail to recognise the person at first glance.</p>
<p>Similarly, the Mac experience today feels disjointed. The hardware has unquestionably improved with the introduction of Apple Silicon, and yes, it’s something worth celebrating and it’s something worth praising. On the other hand, the software that drives this hardware is a bit of a paradox: Big Sur and Apple Silicon Macs fit and work together well from a technical, architectural standpoint. From a user interface standpoint, however, Big Sur embodies what I’ve been fearing in recent years — a progressive iOS-ification of Mac OS. Big Sur provides a general user experience that is the least Mac-like in the history of the Mac. Going through Big Sur’s user interface with a fine-tooth comb reveals arbitrary design decisions that prioritise looks over function, and therefore reflect an un-learning of tried-and-true user interface and usability mechanics that used to make for a seamless, thoughtful, enjoyable Mac experience.</p>
<p>iOS was born as a ‘spinoff’ of Mac OS X, a sort of Lite version aimed at mobile devices like the iPhone and the iPod touch. The two platforms have maintained their separate paths and trajectories for years, and for a while using a Mac and an iPhone (or iPad) felt like having the best experience of each world. Then Apple became obsessed with thoughts of convergence, and features, UI ideas, paradigms, started bleeding through both platforms and in turn the respective experiences have become less clear-cut over time, with the software not fully capable of bringing out all that hardware power and potential.</p>
<p>This convergence will continue, of course, with Macs becoming more and more like ‘senior iOS devices’ from a UI and user experience standpoint. It seems clear to me that Apple is prioritising ecosystem experience because, let’s be honest, having a unified ‘operating system core’ underlying all platforms means having fewer framework-specific headaches and probably a faster, streamlined process when deploying new features. But this loss of differentiation is especially detrimental to Mac OS, which is being reduced to the lowest common denominator and loses an increasing amount of user interface ideas and conventions that were central to its superior user experience and ease of&nbsp;use.</p>
<p>I’m not annoyed because I see pieces of UI history fading away. I’m annoyed because I see pieces of <em>good</em> UI design fading away and being replaced by decisions that are puzzling and arbitrary, or the product of a trial-and-error process, rather than a meaningful, purposeful design.</p>
<p>You want an example that I find particularly glaring? Big Sur’s UI features a general increase of space between elements — icons, menus, labels, toolbars, sidebars, pretty much everywhere. On the surface it doesn’t seem like a bad decision. If you zoom in on certain parts of the user interface, you could say that more space between elements means that things looks cleaner, airier, sleeker.</p>
<p>But you’re looking at it on a 27-inch retina display. What about a display half that size? What about an 11-inch, non-retina display, like the one of the older 2013–2015 MacBook Airs that can be updated to Big Sur? It’s less pretty.</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=960%2C600" alt="" width="960" height="600" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?w=2560 2560w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=260%2C163 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=640%2C400 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=768%2C480 768w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=1536%2C960 1536w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=2048%2C1280 2048w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=1194%2C746 1194w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?w=1920 1920w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>I usually work with a lot of app windows and Finder windows, but when I’m using my 13-inch retina MacBook Pro with Big Sur, the workspace constantly feels cramped, while on the other hand I have no problems using High Sierra on my 11-inch MacBook Air. Sometimes it feels like looking at a zoomed-in interface. That increased space between elements becomes less of a good idea because it doesn’t scale gracefully when the overall screen real estate is reduced. It becomes an interference. Before installing Big Sur, the amount of icons on the right of the menu bar had never really been a concern. Now, the simple addition of a couple of third-party apps like Dropbox and iStat Menus — both essential for me — is enough to make that menu bar look crowded. (And thankfully Apple has been reducing the space between menu icons, because in the first Big Sur betas icon padding was so bad I had to remove a few icons and use Control Centre to check on their status).</p>
<p>This, like other UI design decisions in Big Sur, feels like …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://morrick.me/archives/9150">http://morrick.me/archives/9150</a></em></p>]]>
            </description>
            <link>http://morrick.me/archives/9150</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989450</guid>
            <pubDate>Mon, 01 Feb 2021 15:27:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs: From catching up to getting ahead]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989422">thread link</a>) | @mpereira
<br/>
February 1, 2021 | https://www.murilopereira.com/emacs-from-catching-up-to-getting-ahead/ | <a href="https://web.archive.org/web/*/https://www.murilopereira.com/emacs-from-catching-up-to-getting-ahead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>What does Emacs need for us to someday run M-x neuralink-mode and evaluate Lisp in the brain?</p><div><p>I started using <a href="https://github.com/mpereira/.emacs.d/commit/30024f963ed794ec3a4c41229dbd4fab81f9b912">Emacs</a> almost exactly four years ago, after almost a decade
of <a href="https://github.com/mpereira/.vim">Vim</a>. I made the switch cold turkey. I vividly remember being <em>extremely</em>
frustrated by unbearable slowness while editing a Clojure file at work.
With no sane way of debugging it, just moving the cursor up and down would
result in so much lag that I had to step away from the computer to breathe
for a while. When I came back I quit Vim (I knew how at that point), opened
Emacs, and started building my configuration.</p><p>More recently, I’ve been very put off by the performance and stability (or
lack thereof) of building large scale software via Tramp. This has been
sufficient to have me looking out again. On a whim, I installed VSCode for
the first time and tried its “remote development” capabilities and holy
smokes are they good. Getting up and running was trivial and the
performance was great. Saving files was snappy and LSP worked out of the
box. What a different experience from my carefully-put-together,
half-working, slow Emacs setup.</p><p>My common denominator for rage-quitting software seems to be
consistent: <i>bad performance</i>.</p><p>There has recently been more discussion than usual regarding “modernizing”
Emacs, by making keybindings more consistent with other applications and
using more attractive color schemes and visuals, with the end goal of
attracting more users and by extension more contributors.</p><p>In my view improving these aspects of user experience wouldn’t hurt. The
way I see it, though, is that for Emacs to attract more users it needs to
be objectively better than the alternatives. And the way to do it is for
Emacs to become <em>even more</em> like Emacs.</p><p>I see Emacs as being fundamentally two things: a programmable runtime,
and a beacon for free software. I'm talking more about the former.</p><p>It needs to be a <em>more</em> robust, <em>more</em> efficient, and <em>more</em> integrated
platform with a <em>more</em> powerful extension language, to empower its users to
build their own environment.</p><p>Getting LSP integrated <em>pervasively</em> in Emacs in a way that it reliably
<em>just works</em> and performs well out of the box, would go a long way towards
making Emacs more attractive not just to new users, but to existing ones
too. Imagine an experience similar to VSCode’s:</p><ol><li>Open Emacs for the first time</li><li>Open a source code file</li><li>Emacs asks if you want it to configure itself for the programming
language of that source file</li><li>Saying “yes” automatically sets up Emacs to have a modern programming
environment for that programming language with smart code completion,
navigation, and refactoring, rich hover information, highlighting,
automatic formatting, snippets, etc. Maybe even open a side window with
a buffer with a short “getting started” tutorial showing the available
keybindings.</li></ol><p>Given enough users, opinionated community-built Emacs “distributions” like
Spacemacs, Doom, and Prelude will do the job of making it easier for
newcomers to get started with typical contemporary tasks: building software
with popular programming languages, writing documents, managing machines,
etc.</p><p>Building and maintaining these “distributions” also becomes much easier
given a more robust, more efficient, and more integrated platform with a
more powerful extension language.</p><p>Having a <a href="https://blog.polaris64.net/post/could-emacs-have-a-set-up-wizard/">wizard</a> showing up in new Emacs installations might be a great
low-hanging fruit way of making Emacs more accessible. Assuming buy-in from
core maintainers, the wizard could even directly reference popular Emacs
“distributions” like the ones mentioned above, so that new users can
kickstart their lives in Emacs.</p><p>The way to attract contributors can also be <em>stated</em> simply: directly improve
the contribution process.</p><p>Easier said than done.</p><p><a href="https://www.youtube.com/watch?v=VADudzQGvU8">Many</a> have created their Emacs <a href="https://www.jwz.org/doc/xemacs-wishlist.html">wishlists</a>. This is mine:</p><ol><li>Improved single-core efficiency</li><li>Improved display efficiency and rendering engine</li><li>Leveraging preemptive parallelism</li><li>Emacs Lisp improvements</li><li>Enhanced stability</li><li>Dealing with non-text</li><li>Improved contribution and development process</li></ol><p>Let’s get into it.</p><h2 id="1-dot-improved-single-core-efficiency">1. Improved single-core efficiency</h2><p>There are two dimensions to this:</p><ul><li>garbage collection efficiency</li><li>code execution efficiency</li></ul><p>For the past one and a half years, <a href="https://twitter.com/Koral%5F001">Andrea Corallo</a>, a compiler engineer,
has been <a href="https://akrl.sdf.org/gccemacs.html">working</a> on adding native compilation capabilities to the Emacs
Lisp interpreter. His work is available in a branch in the official Emacs
repository. Folks have been trying it out, and according to the reports
I’m hearing, the results are staggeringly positive. I am <em>very</em> excited
about Andrea’s work, which seems to bring enough improvement to the “code
execution speed” side of the equation to make it a non-issue for now.</p><p>Andrea’s work will also allow for more of Emacs to be implemented in Emacs
Lisp itself (instead of C), which is what most contributors are used to.
This is a great win for maintainability and extensibility: incrementally
having more and more of Emacs be implemented in the language with which
it’s extended.</p><p>The garbage collector is still in much need of improvement. Many resort to
hacks to ameliorate frequent and sometimes long pauses that seem to be
unavoidable while working on large git repositories, fast-scrolling
font-locked Eshell buffers, displaying dynamically updating child frames,
navigating big Org files, and many other tasks.</p><p><span>Also, try this out:</span> <code>(setq garbage-collection-messages t)</code></p><h2 id="2-dot-improved-display-efficiency-and-rendering-engine">2. Improved display efficiency and rendering engine</h2><p>The display implementation in Emacs core is… less than ideal.</p><blockquote><p>GNU Emacs is an old-school C program emulating a 1980s Symbolics Lisp
Machine emulating an old-fashioned Motif-style Xt toolkit emulating a
1970s text terminal emulating a 1960s teletype. Compiling Emacs is a
challenge. Adding modern rendering features to the redisplay engine is a
miracle.</p><p>— <a href="https://www.facebook.com/notes/daniel-colascione/buttery-smooth-emacs/10155313440066102/">Daniel Colascione in “Buttery Smooth Emacs” (2016)</a></p></blockquote><p>It would be great if Emacs did like Neovim and decoupled the editor
runtime from the display engine. This would make it possible for the
community to build powerful <a href="https://neovim.io/news/2020/10/#guis">GUIs</a> without having to change <a href="https://raw.githubusercontent.com/emacs-mirror/emacs/master/src/xdisp.c">Emacs core</a>,
possibly <a href="https://lwn.net/ml/emacs-devel/CAO2hHWbUmgirn1gJ4OGbRghhCkOPcEsL=moc82Q-6QO+C=189Q@mail.gmail.com/">using technology</a> <a href="https://lwn.net/ml/emacs-devel/E1jPGhC-0003i1-W4@fencepost.gnu.org/">not fully sanctioned</a> by core maintainers.</p><p>Take a look at the screenshots of these Neovim GUIs:</p><ul><li><a href="https://github.com/Kethku/neovide">neovide</a></li><li><a href="https://github.com/smolck/uivonim">uivonim</a></li></ul><p>They’re powerful, look great, perform well, and more importantly, are
based on industry standard, cross-platform graphics APIs (Vulkan and WebGL
respectively) that get lots of personpower contributions from companies
and individuals alike.</p><p>The <a href="https://www.patreon.com/posts/40303878">Onivim</a> and <a href="https://github.com/xi-editor/xi-editor">Xi</a> text editors could also be sources of inspiration:</p><ul><li>Separating the core runtime from the user interface</li><li><a href="https://en.wikipedia.org/wiki/Rope%5F(data%5Fstructure)">Ropes</a> for faster incremental changes and parallelization of text
operations</li><li>Game-like drawing pipelines</li></ul><h2 id="3-dot-leveraging-preemptive-parallelism">3. Leveraging preemptive parallelism</h2><p>Emacs does not support parallel code execution via multi-core processing.
Code execution happening on any buffer will freeze the whole program,
preventing not only user interaction but other cooperative threads of
execution from making progress as well.</p><p>Adding parallelism to Emacs in a way that automatically makes existing
code run in parallel is about as close to impossible as it can get. What
would be more feasible is including new primitives for parallel execution
that new code could leverage, to build more powerful extensions to Emacs.</p><p><a href="https://github.com/emacs-ng/emacs-ng">Emacs-ng</a> is a recent effort that implements just that: an additive layer
over Emacs that brings not only parallelism, but also asynchronous I/O
capabilities via an embedded <a href="https://deno.land/">Deno</a> runtime, and GPU-based rendering via
<a href="https://github.com/servo/webrender">WebRender</a>. I am <em>super</em> excited about the very fast progress from the folks
working on emacs-ng, and I think the project holds great promise for the
future of Emacs itself.</p><p>There also seems to be advances in the area of immutable data structures
that could be leveraged by the Emacs core, as seen in “<a href="https://public.sinusoid.es/misc/immer/immer-icfp17.pdf">Persistence for the
Masses: RRB-Vectors in a Systems Language</a>”. Persistent data structures
would make building thread-safe parallel code much easier.</p><h2 id="4-dot-enhanced-stability">4. Enhanced stability</h2><p>It is very easy to either freeze Emacs or cause it to run very slowly.
Multiple times a day I have to hit <code>C-g</code> incessantly to bring it back from
being frozen. When that fails, I am sometimes able to get it back with
<code>pkill -SIGUSR2 Emacs</code>. At least once per week I have to <code>pkill -9 Emacs</code>
because it turned completely unresponsive. I suspect doing more work
outside of the main thread might help with this?</p><p>There are many hacks to ameliorate issues caused by long lines, but
they’re still fundamentally there. Advancements in the “display efficiency
and rendering engine” effort would help with this too.</p><p>I recently tried a package that displays pretty icons on completion
prompts, and noticed that it made scrolling through candidates really
slow. Profiling showed that the package was creating thousands of <a href="https://www.gnu.org/software/emacs/manual/html%5Fnode/elisp/Idle-Timers.html">timers</a>,
which were somehow causing the issue. There are lots of cases like this,
where folks attempt to create something nice, but inevitably have to
resort to <a href="https://github.com/domtronn/all-the-icons.el/issues/113">hacks</a> to either achieve acceptable performance, or to be able to
implement the thing at all. Having a more robust/efficient/integrated core
with a more powerful extension language would help here.</p><p>Impressive efforts from folks like Lars Ingebrigtsen who routinely comes
in and <a href="https://lars.ingebrigtsen.no/2020/10/26/5x10/">obliterates 10% of all reported Emacs bugs</a> also have a sizable
impact. We users should follow the lead and do a better job not only
creating good bug reports but also dipping in our toes and helping out:
fixing bugs, writing tests, and documentation.</p><p>Yuan Fu recently wrote a <a href="https://archive.casouri.cat/note/2020/contributing-to-emacs/">nice guide</a> for contributing to Emacs.</p><h2 id="5-dot-emacs-lisp-improvements">5. Emacs Lisp improvements</h2><p>Emacs Lisp is a much better language than Vimscript. Unfortunately, that’s
not saying much. It’s not a particularly good Lisp and has lots of room
for improvement.</p><blockquote><p>For example, if you want to use a map, you have three choices: you can use
alists, plists or hash maps. There are no namespaces in Emacs Lisp, so for
each of the three data types you get a bunch of functions with weird
names. For alists get is <code>assoc</code> and set is <code>add-to-list</code>, for hash maps get
is <code>gethash</code> and set is <code>puthash</code>, for plists get is <code>plist-get</code> and set is
<code>plist-put.</code> For each of those types it …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.murilopereira.com/emacs-from-catching-up-to-getting-ahead/">https://www.murilopereira.com/emacs-from-catching-up-to-getting-ahead/</a></em></p>]]>
            </description>
            <link>https://www.murilopereira.com/emacs-from-catching-up-to-getting-ahead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989422</guid>
            <pubDate>Mon, 01 Feb 2021 15:24:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Robinhood's awful UX exacerbated the GameStop crisis]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989369">thread link</a>) | @Signalvwhatsapp
<br/>
February 1, 2021 | https://builtformars.com/how-robinhood-handled-a-crisis/ | <a href="https://web.archive.org/web/*/https://builtformars.com/how-robinhood-handled-a-crisis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-id="ca3ca43" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">

<div>
<div>
<div data-id="ec20c55" data-element_type="column">
<div>
<div>
<div data-id="682e138" data-element_type="widget" data-widget_type="theme-post-content.default">
<div>
<div data-elementor-type="wp-post" data-elementor-id="11116" data-elementor-settings="[]">
<div>
<div>
<section data-id="00380cd" data-element_type="section">
<div>
<div>
<div data-id="73400e1" data-element_type="column">
<div>
<div>
<div data-id="c41ab36" data-element_type="widget" data-settings="{&quot;drop_cap&quot;:&quot;yes&quot;}" data-widget_type="text-editor.default">
<div>
<p>Last week Robinhood took unprecedented action and, without warning, temporarily restricted trading on immensely popular stocks like GameStop (GME).</p>
</div>
</div>
<div data-id="89fe3e7" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>The circumstances of these actions were controversial and upset millions of people.</p>
</div>
</div>
<div data-id="1ac2834" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But this isn’t a hit piece, and my opinion of whether the steps Robinhood took were necessary, fair or illegal are irrelevant.</p>
</div>
</div>
<div data-id="e7928c9" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>Instead, this provides a perfect example of <strong>why UX matters in a crisis</strong>.&nbsp;</p><p>…</p></div>
</div>
</div>
<div data-id="47c7425" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>In this instance, even the best user experience wouldn’t have stopped people from being upset, but would have acted as damage limitation.</p>
</div>
</div>
<div data-id="2c34603" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>As you’ll see, the total lack of context, explanation or empathy only fuelled the mob.</p>
</div>
</div>
<div data-id="8706992" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>So what can we learn from Robinhood’s actions / inactions?</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="3908660" data-element_type="section">
<div>
<div>
<div data-id="955ff27" data-element_type="column">
<div>
<div>
<div data-id="5795f5f" data-element_type="widget" data-widget_type="heading.default">
<p>
<h3>Summary (what Robinhood did):</h3> </p>
</div>
<section data-id="652f9f4" data-element_type="section">
<div>
<div>

<div data-id="5ed8e3a" data-element_type="column">
<div>
<div>
<div data-id="118ef6c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Removing GameStop from <strong>search results</strong>.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="87a1a79" data-element_type="section">
<div>
<div>

<div data-id="f3bb568" data-element_type="column">
<div>
<div>
<div data-id="a86c38b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Blocking people from <strong>buying</strong> GameStop shares.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="19bd816" data-element_type="section">
<div>
<div>

<div data-id="8836b54" data-element_type="column">
<div>
<div>
<div data-id="834b30b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Made<strong> fractional shares</strong>&nbsp;unavailable.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="1706663" data-element_type="section">
<div>
<div>

<div data-id="847c1f2" data-element_type="column">
<div>
<div>
<div data-id="763d542" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><strong>Creating sell orders</strong> on your behalf.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="e727702" data-element_type="section">
<div>
<div>

<div data-id="bbf23ee" data-element_type="column">
<div>
<div>
<div data-id="e6be231" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Failing to get <strong>statements</strong>.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="4c1c44c" data-element_type="section">

</section>
<section data-id="b8fbf65" data-element_type="section">
<div>
<div>
<div data-id="af60e8c" data-element_type="column">
<div>
<div>
<div data-id="ffa8b1d" data-element_type="widget" data-widget_type="heading.default">
<p>
<h3>1. Removing GameStop from search results</h3> </p>
</div>
<div data-id="6044e46" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>The first action that Robinhood took was to suddenly stop people from being able to purchase shares of GameStop.</p>
</div>
</div>
<div data-id="db89608" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But they also decided to actually <strong>remove GameStop from any search results</strong>.</p>
</div>
</div>
<div data-id="d88ea55" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>This was an awful decision for a few reasons:</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="c969585" data-element_type="section">
<div>
<div>
<div data-id="749e793" data-element_type="column">
<div>
<div>
<section data-id="cc6160e" data-element_type="section">
<div>
<div>

<div data-id="2a438d3" data-element_type="column">
<div>
<div>
<div data-id="412b57c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><strong>1. Adds ambiguity</strong></p><p>People <em>knew</em> that GameStop <em>should</em> be there, so just removing it creates ambiguity. Is this a bug? Should they close the app and try again?</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="94a2eff" data-element_type="section">
<div>
<div>

<div data-id="ed13002" data-element_type="column">
<div>
<div>
<div data-id="4055d58" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><b>2. Provides no&nbsp;explanation</b></p><p>By removing it entirely, you’ve not given any chance for the user to learn more about <em>why</em> they’re not seeing it.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="d2f6f2f" data-element_type="section">
<div>
<div>

<div data-id="cb4b003" data-element_type="column">
<div>
<div>
<div data-id="36a01f2" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><b>3. Adds suspicion</b></p><p>During a crisis, you want to calm your users down, not give them reasons to suspect you’re trying to mislead them.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="2413447" data-element_type="section">
<div>
<div>
<div data-id="b2b6797" data-element_type="column">
<div>
<div>
<div data-id="7c394bd" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But it didn’t have to be that way—this is what they should have done (right).</p>
</div>
</div>
<div data-id="57fbb73" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="720" height="323" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Hidingfromsearch-1-1024x460.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Hidingfromsearch-1-1024x460.jpg 1024w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Hidingfromsearch-1-300x135.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Hidingfromsearch-1-768x345.jpg 768w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Hidingfromsearch-1-100x45.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Hidingfromsearch-1-700x315.jpg 700w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Hidingfromsearch-1.jpg 1500w" sizes="(max-width: 720px) 100vw, 720px"> </p>
</div>
</div>
<div data-id="9991d1b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>Great UX is about being definitive and clear. The <strong><em>absence</em></strong> of information is the opposite of that.</p><p>…</p></div>
</div>
</div>
<div data-id="93ce83a" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>How long would it have taken Robinhood to add a few sentences, and a link to an additional resource? 15 minutes?</p>
</div>
</div>
<div data-id="ff2ce13" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>And if they didn’t have time to write a full article explaining the situation, then they could have linked directly to a Twitter thread. Or, <em>literally anything</em> giving some context about this decision.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="9ab277b" data-element_type="section">
<div>
<div>
<div data-id="11164e6" data-element_type="column">
<div>
<div>
<div data-id="7c8c29e" data-element_type="widget" data-widget_type="heading.default">
<p>
<h3>2. Blocking people from buying GameStop shares</h3> </p>
</div>
<div data-id="914f37f" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But, even though GameStop shares were hidden from the search results, it was still possible to get to the screen where you can normally buy and sell them.</p>
</div>
</div>
<div data-id="ed5a976" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Which introduced another complexity: <strong>how should Robinhood stop people from buying the shares, while still allowing them to sell their shares</strong>?</p>
</div>
</div>

<div data-id="bc49f13" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>1: Disable the ‘buy’ button.</p>
</div>
</div>
<div data-id="c854a0e" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>2: Add an unspecific notice explaining that you can’t buy shares right now.</p>
</div>
</div>
<div data-id="7a3a6ce" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>Robinhood’s users were missing out on what was being touted as the trade of a lifetime, and there’s not even an explanation why.</p><p>…</p></div>
</div>
</div>
<div data-id="d0c3060" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="720" height="323" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Block-from-buying-1024x460.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Block-from-buying-1024x460.jpg 1024w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Block-from-buying-300x135.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Block-from-buying-768x345.jpg 768w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Block-from-buying-100x45.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Block-from-buying-700x315.jpg 700w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Block-from-buying.jpg 1500w" sizes="(max-width: 720px) 100vw, 720px"> </p>
</div>
</div>
<div data-id="8c13831" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>It wouldn’t have taken much to make the UX of this considerably better. Even just a link to an explanation would have helped.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="9c3a6d8" data-element_type="section">
<div>
<div>
<div data-id="c9e092b" data-element_type="column">
<div>
<div>
<div data-id="33475ac" data-element_type="widget" data-widget_type="heading.default">
<p>
<h3>3. Fractional shares are unavailable</h3> </p>
</div>
<div data-id="48c7676" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>After some time, Robinhood announced that they would allow people to purchase a limited number of these shares, this included <strong>not allowing people to purchase <em>part</em> of a share</strong>.</p>
</div>
</div>
<div data-id="a80c454" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>For context, Robinhood is renown for fractional investing. This allows you to invest a small amount of money in companies with a high share price, for example, one share of Amazon costs more than $3,000, but a Robinhood user could invest $300 for 1/10th of a share.</p>
</div>
</div>
<div data-id="72f4a48" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>This is the message they showed to people who tried buying a fraction of a share:</p>
</div>
</div>
<div data-id="57cafaf" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="720" height="323" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/FractionalShares-1024x460.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/FractionalShares-1024x460.jpg 1024w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/FractionalShares-300x135.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/FractionalShares-768x345.jpg 768w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/FractionalShares-100x45.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/FractionalShares-700x315.jpg 700w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/FractionalShares.jpg 1500w" sizes="(max-width: 720px) 100vw, 720px"> </p>
</div>
</div>
<div data-id="021051e" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>There are a few nuances here worth pointing out:</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="c031c3e" data-element_type="section">
<div>
<div>
<div data-id="f789da0" data-element_type="column">
<div>
<div>
<section data-id="a82a513" data-element_type="section">
<div>
<div>

<div data-id="7510cee" data-element_type="column">
<div>
<div>
<div data-id="e2aea7f" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><strong>1. Clarify that this restriction is <em>temporary</em></strong></p><p>Is Robinhood not facilitating fractional shares anymore? Will this feature come back? Is this related to the other restrictions?</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="410dd9a" data-element_type="section">
<div>
<div>

<div data-id="c239494" data-element_type="column">
<div>
<div>
<div data-id="07996bd" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><b>2. Explain what “enough available” means</b></p><p>During this crisis there were many restrictions, including not being able to buy more than 3 shares. So is “<em>not enough</em>” related to the number of available shares you can buy until you reach that limit?</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="166c9fa" data-element_type="section">
<div>
<div>

<div data-id="500e290" data-element_type="column">
<div>
<div>
<div data-id="b815ddd" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><b>3. Add an&nbsp;explanation</b></p><p>As we’ve demonstrated before, it’s important to give context and rationale behind a decision. <em>Why</em> did they have to take this step?</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="2533534" data-element_type="section">
<div>
<div>
<div data-id="166bbd4" data-element_type="column">
<div>
<div>
<div data-id="6a4adcb" data-element_type="widget" data-widget_type="heading.default">
<p>
<h3>4. Creating sell orders on your behalf</h3> </p>
</div>
<div data-id="e53e593" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>As the chaos unfolded, people started complaining that Robinhood were creating sell orders on their account, without their consent. Once these orders were placed, the user could not cancel them, and were instead shown an error message.</p>
</div>
</div>
<div data-id="de68357" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>If this wasn’t bad enough, many people were complaining that the selling price was <em><strong>below</strong></em> market value, given how volatile the price was.</p><p>…</p></div>
</div>
</div>
<div data-id="91bd643" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>So, if there was ever an example of where a company <strong>needs to take an extra 5 minutes to really explain the situation</strong>, this is it.</p>
</div>
</div>
<div data-id="3ecd1a2" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Yet instead, Robinhood users saw an error message—and to demonstrate how rushed this entire process was, they forgot to put a full stop at the end.</p>
</div>
</div>
<div data-id="8e3c4b5" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="720" height="323" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Soldforyou-1024x460.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Soldforyou-1024x460.jpg 1024w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Soldforyou-300x135.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Soldforyou-768x345.jpg 768w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Soldforyou-100x45.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Soldforyou-700x315.jpg 700w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Soldforyou.jpg 1500w" sizes="(max-width: 720px) 100vw, 720px"> </p>
</div>
</div>
<div data-id="e630a3b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>I’ve made a few important changes here:</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="4ee30a4" data-element_type="section">
<div>
<div>
<div data-id="2b6451d" data-element_type="column">
<div>
<div>
<section data-id="b1a285a" data-element_type="section">
<div>
<div>

<div data-id="c9e7b83" data-element_type="column">
<div>
<div>
<div data-id="3d74881" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><strong>1. Change the title</strong></p><p>This isn’t an ‘error’, so labelling it as one feels misleading. Instead, be clear and tell the user <em>what’s happening</em>.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="06de0be" data-element_type="section">
<div>
<div>

<div data-id="4474737" data-element_type="column">
<div>
<div>
<div data-id="e106a06" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><b>2. Adding empathy</b></p><p>This isn’t just an inconvenience, it’s potentially costing the user a lot of money. Somehow, saying “we’re sorry” at the beginning just doesn’t cut it.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="6ef3ff9" data-element_type="section">
<div>
<div>

<div data-id="2b24020" data-element_type="column">
<div>
<div>
<div data-id="24cf674" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><b>3. Add an&nbsp;explanation</b></p><p>You probably saw this one coming—this is a necessity in this instance, and it’s easy to see why many people flocked to Twitter to complain.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="833ae0a" data-element_type="section">
<div>
<div>
<div data-id="9aa0b5d" data-element_type="column">
<div>
<div>
<div data-id="da706b8" data-element_type="widget" data-widget_type="heading.default">
<p>
<h3>5. Failing to get statements</h3> </p>
</div>
<div data-id="2acabad" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>This controversy unravelled over a few days, and led many people vowing to leave Robinhood and take their portfolio elsewhere.</p>
</div>
</div>
<div data-id="e2cc62c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But there was a problem: other brokerages were asking for your existing portfolio statement to initiate a transfer, and for some people, Robinhood’s statement download function was broken.</p>
</div>
</div>
<div data-id="32d0c00" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>So lets look at—and improve—the error message they displayed when people were trying to download their statements:</p>
</div>
</div>
<div data-id="53a98c7" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="720" height="323" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Servererror-1024x460.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Servererror-1024x460.jpg 1024w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Servererror-300x135.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Servererror-768x345.jpg 768w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Servererror-100x45.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Servererror-700x315.jpg 700w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Servererror.jpg 1500w" sizes="(max-width: 720px) 100vw, 720px"> </p>
</div>
</div>
<div data-id="8bd27d4" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Unlike the other examples above, this error message doesn’t require more <strong><em>context</em></strong>, but it would have benefitted from suggesting an alternative step (e.g., emailing their customer support).</p>
</div>
</div>
<div data-id="1589ced" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>This is a task that could be completed manually, and may be urgent. To simply <em>fail</em> is not good enough.</p><p>…</p></div>
</div>
</div>
<div data-id="750f62d" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Or rather, imagine how frustrated you’d be if your bank’s app was broken and you couldn’t make any payments. You’d appreciate a suggestion of: “<em>call us on [this number] to make a payment over the phone</em>“.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="faa873c" data-element_type="section">
<div>
<div>
<div data-id="c122bc0" data-element_type="column">
<div>
<div>

<div data-id="8a78ff0" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>One thing is certain: Robinhood were scrambling to react to these spontaneous decisions, and the execution was poor.</p>
</div>
</div>
<div data-id="897910b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But the rush to push changes is not a valid excuse for a poor experience. In fact, it just fuelled the fire—probably contributing to the hundreds of thousands of 1-star ratings on the app stores, and Robinhood trending on Twitter.</p>
</div>
</div>
<div data-id="85a773b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>It’s in moments like this, more than ever, that a thoughtful and empathetic user experience is required.</p><p>…</p></div>
</div>
</div>
<div data-id="90aebad" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>So let’s summarise the key points here:</p>
</div>
</div>
<div data-id="70f3e6c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><strong>1: Context matters —</strong> take those extra few minutes to explain to your users <em>why</em> you’ve made a difficult decision.</p>
</div>
</div>
<div data-id="7de0215" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><strong>2: Remove ambiguity&nbsp; —</strong> give people realistic expectations for when certain restrictions will be lifted, and what they can do in the meantime.</p>
</div>
</div>
<div data-id="f11d414" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><strong>3: Show empathy&nbsp; —</strong> apologising isn’t enough, you need to demonstrate that you understand why your users will be suffering, and how hard it is for them.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section></div>]]>
            </description>
            <link>https://builtformars.com/how-robinhood-handled-a-crisis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989369</guid>
            <pubDate>Mon, 01 Feb 2021 15:19:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scraping, analyzing and generating jobs and startups from YC's Work at a Startup]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989367">thread link</a>) | @misterbrian
<br/>
February 1, 2021 | https://briancaffey.github.io/2021/01/16/i-scraped-analyzed-and-generated-yc-companies-founders-and-work-at-a-startup-job-postings | <a href="https://web.archive.org/web/*/https://briancaffey.github.io/2021/01/16/i-scraped-analyzed-and-generated-yc-companies-founders-and-work-at-a-startup-job-postings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I always enjoy reading about new batches of YC companies. I came across YC's <a href="https://www.workatastartup.com/" rel="nofollow noopener noreferrer" target="_blank">Work at a Startup</a> (WaaS) recently while browsing HN and got pretty curious about all of the available data points on companies, jobs and founders.</p>
<p>This article will outline my process for collecting, cleaning, visualizing and analyzing the dataset.</p>
<p>After filling out my profile, WaaS recommended 750 matching YC startups which collectively list 1614 open positions. I think this is all of the available job openings and hiring companies, but I'm not sure.</p>
<h2 id="scraping-data">Scraping data</h2>
<p>I've used a few different tools to scrape data and automate web browsers. For collecting this data, I ended up just writing some JavaScript directly in the browser console and <code>Ctrl+S</code>aved the page HTML and assets (company logos and founder photos).</p>
<div><pre><code>
<span>const</span> toggleDetails <span>=</span> <span>document</span><span>.</span><span>getElementsByClassName</span><span>(</span><span>"checkbox-inline"</span><span>)</span><span>[</span><span>0</span><span>]</span>
toggleDetails<span>.</span><span>click</span><span>(</span><span>)</span>


<span>const</span> scroll <span>=</span> <span>setInterval</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><span>window</span><span>.</span><span>scrollTo</span><span>(</span><span>0</span><span>,</span><span>document</span><span>.</span><span>body</span><span>.</span><span>scrollHeight</span><span>)</span><span>;</span><span>}</span><span>,</span> <span>3000</span><span>)</span>


<span>clearInterval</span><span>(</span>scroll<span>)</span>


<span>const</span> jobs <span>=</span> <span>document</span><span>.</span><span>getElementsByClassName</span><span>(</span><span>"job-name"</span><span>)</span>
<span>for</span> <span>(</span><span>let</span> job <span>of</span> jobs<span>)</span> <span>{</span>
    job<span>.</span><span>click</span><span>(</span><span>)</span>
<span>}</span>


</code></pre></div>
<h2 id="parsing-the-html">Parsing the HTML</h2>
<p>Next I'll parse the company data into a python list of dictionaries and then <code>dumps</code> it into a JSON file. This code is a little bit scrappy, here's the pseudo code:</p>
<div><pre><code>
html <span>=</span> <span>open</span><span>(</span><span>"data.html"</span><span>)</span>
parsed_html <span>=</span> parseHtml<span>(</span>html<span>)</span>

companies <span>=</span> <span>[</span><span>]</span>
<span>for</span> company <span>in</span> parsed_html<span>.</span>find_all<span>(</span><span>"company"</span><span>)</span>
    
    company_details <span>=</span> extract_company_details<span>(</span>company<span>)</span>
    companies<span>.</span>append<span>(</span>company_details<span>)</span>

<span>with</span> <span>open</span><span>(</span><span>"output.json"</span><span>,</span> <span>"wb"</span><span>)</span> <span>as</span> f<span>:</span>
    f<span>.</span>write<span>(</span>json<span>.</span>dumps<span>(</span>companies<span>)</span><span>)</span>
</code></pre></div>
<p>To scrape the data I used my go-to library for this type of task: BeautifulSoup. There were a few tricky parts:</p>
<ul>
<li>
<p>Job details (visa requirements, salary, equity) were all labelled with the same class and they were inconsistent (sometimes salary or equity or both were excluded, for example).</p>
</li>
<li>
<p>Equity was mostly a range of percentages such as <code>1% - 2%</code> and sometimes a single percentage like <code>1.5%</code>. Some salary ranges had typos like <code>$90k - $10k</code></p>
</li>
<li>
<p>Years of experience required was also inconsistent with mixed types like <code>3+ Years</code>, <code>Any (recent grad ok)</code> and <code>Senior or Juniors</code>, for example.</p>
</li>
</ul>
<p>These were all pretty easy to account for, it just required some additional logic to handle default values for <code>&lt;div&gt;</code>s that were not included as well as mixed data types and representations where there were inconsistencies.</p>
<p>The resulting JSON structure for the big array of companies looks like this:</p>
<div><pre><code><span>[</span>
    <span>{</span>
        <span>"company_name"</span><span>:</span> <span>"Startup A"</span><span>,</span>
        <span>"logo"</span><span>:</span> <span>"logo.png"</span><span>,</span>
        <span>"jobs"</span><span>:</span> <span>[</span>
            <span>{</span>
                <span>"title"</span><span>:</span> <span>"Software Engineer"</span><span>,</span>
                <span>"skills"</span><span>:</span> <span>[</span><span>"python"</span><span>,</span> <span>"javascript"</span><span>]</span><span>,</span>
                <span>"salary"</span><span>:</span> <span>{</span>
                    <span>"min"</span><span>:</span> <span>90000</span><span>,</span>
                    <span>"max"</span><span>:</span> <span>110000</span><span>,</span>
                    <span>"avg"</span><span>:</span> <span>100000</span>
                <span>}</span>
            <span>}</span>
        <span>]</span><span>,</span>
        <span>"founders"</span><span>:</span> <span>[</span>
            <span>{</span>
                <span>"name"</span><span>:</span> <span>"Founder Name"</span><span>,</span>
                <span>"linkedin"</span><span>:</span> <span>"https://linkedin.com/founder"</span><span>,</span>
                <span>"education"</span><span>:</span> <span>"University A"</span><span>,</span>
                <span>"image"</span><span>:</span> <span>"abc.png"</span>
            <span>}</span>
        <span>]</span>
    <span>}</span>
<span>]</span>
</code></pre></div>
<h2 id="analysis">Analysis</h2>
<p>Here are some of the biggest questions I wanted to answer along with some simple python I used for extracting data from the main dictionary/JSON object containing all companies and jobs. For the following code, assume I have read the JSON file back into a python dictionary.</p>
<h3 id="what-are-the-most-in-demand-skills-for-yc-jobs">What are the most in demand skills for YC Jobs?</h3>
<p>I think skills are included mostly for engineering roles (not so much for sales, marketing, etc.). Here are the top skills:</p>
<div><pre><code>skills <span>=</span> <span>[</span><span>]</span>
<span>for</span> company <span>in</span> company_list<span>:</span>
    <span>if</span> company<span>[</span><span>"jobs"</span><span>]</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
        <span>for</span> job <span>in</span> company<span>[</span><span>"jobs"</span><span>]</span><span>:</span>
            <span>if</span> job<span>[</span><span>"job_skills"</span><span>]</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
                <span>for</span> skill <span>in</span> job<span>[</span><span>"job_skills"</span><span>]</span><span>:</span>
                    skills<span>.</span>append<span>(</span>skill<span>)</span>

top_skills <span>=</span> Counter<span>(</span>skills<span>)</span><span>.</span>most_common<span>(</span><span>)</span>
<span>print</span><span>(</span>top_skills<span>)</span>
</code></pre></div>
<!----><!---->
<p>I'll try to briefly describe what I know about each of these if I know what it means (without Googling!):</p>
<div><pre><code><span>[</span>
 <span>(</span><span>'JAVASCRIPT'</span><span>,</span> <span>330</span><span>)</span><span>,</span> 
 <span>(</span><span>'REACT'</span><span>,</span> <span>323</span><span>)</span><span>,</span> 
 <span>(</span><span>'PYTHON'</span><span>,</span> <span>312</span><span>)</span><span>,</span> 
 <span>(</span><span>'AMAZON WEB SERVICES (AWS)'</span><span>,</span> <span>200</span><span>)</span><span>,</span> 
 <span>(</span><span>'NODE.JS'</span><span>,</span> <span>195</span><span>)</span><span>,</span> 
 <span>(</span><span>'POSTGRESQL'</span><span>,</span> <span>132</span><span>)</span><span>,</span> 
 <span>(</span><span>'TYPESCRIPT'</span><span>,</span> <span>114</span><span>)</span><span>,</span> 
 <span>(</span><span>'JAVA'</span><span>,</span> <span>79</span><span>)</span><span>,</span> 
 <span>(</span><span>'SQL'</span><span>,</span> <span>74</span><span>)</span><span>,</span> 
 <span>(</span><span>'RUBY ON RAILS'</span><span>,</span> <span>72</span><span>)</span><span>,</span> 
 <span>(</span><span>'CSS'</span><span>,</span> <span>71</span><span>)</span><span>,</span> 
 <span>(</span><span>'HTML'</span><span>,</span> <span>71</span><span>)</span><span>,</span>
 <span>(</span><span>'DOCKER'</span><span>,</span> <span>66</span><span>)</span><span>,</span> 
 <span>(</span><span>'KUBERNETES'</span><span>,</span> <span>58</span><span>)</span><span>,</span> 
 <span>(</span><span>'GO'</span><span>,</span> <span>58</span><span>)</span><span>,</span> 
 <span>(</span><span>'REACT NATIVE'</span><span>,</span> <span>58</span><span>)</span><span>,</span>
 <span>(</span><span>'C++'</span><span>,</span> <span>55</span><span>)</span><span>,</span> 
 <span>(</span><span>'GRAPHQL'</span><span>,</span> <span>48</span><span>)</span><span>,</span> 
 <span>(</span><span>'GOOGLE CLOUD'</span><span>,</span> <span>46</span><span>)</span><span>,</span> 
 <span>(</span><span>'RUBY'</span><span>,</span> <span>44</span><span>)</span><span>,</span> 
 <span>(</span><span>'DJANGO'</span><span>,</span> <span>44</span><span>)</span><span>,</span> 
 <span>(</span><span>'MACHINE LEARNING'</span><span>,</span> <span>44</span><span>)</span><span>,</span> 
 <span>(</span><span>'MONGODB'</span><span>,</span> <span>43</span><span>)</span><span>,</span> 
 <span>(</span><span>'IOS'</span><span>,</span> <span>38</span><span>)</span><span>,</span> 
 <span>(</span><span>'MYSQL'</span><span>,</span> <span>36</span><span>)</span><span>,</span> 
 <span>(</span><span>'ANDROID'</span><span>,</span> <span>35</span><span>)</span><span>,</span> 
 <span>(</span><span>'DATA ANALYTICS'</span><span>,</span> <span>32</span><span>)</span><span>,</span> 
 <span>(</span><span>'GIT'</span><span>,</span> <span>30</span><span>)</span><span>,</span> 
 <span>(</span><span>'ANGULAR'</span><span>,</span> <span>29</span><span>)</span><span>,</span> 
 <span>(</span><span>'SWIFT'</span><span>,</span> <span>29</span><span>)</span><span>,</span> 
 <span>(</span><span>'LINUX'</span><span>,</span> <span>28</span><span>)</span><span>,</span> 
 <span>(</span><span>'SOFTWARE ARCHITECTURE'</span><span>,</span> <span>24</span><span>)</span><span>,</span> 
 <span>(</span><span>'KOTLIN'</span><span>,</span> <span>23</span><span>)</span><span>,</span> 
 <span>(</span><span>'TENSORFLOW'</span><span>,</span> <span>22</span><span>)</span><span>,</span> 
 <span>(</span><span>'DISTRIBUTED SYSTEMS'</span><span>,</span> <span>22</span><span>)</span><span>,</span> 
 <span>(</span><span>'PHP'</span><span>,</span> <span>22</span><span>)</span><span>,</span> 
 <span>(</span><span>'DATA WAREHOUSING'</span><span>,</span> <span>22</span><span>)</span><span>,</span> 
 <span>(</span><span>'DEEP LEARNING'</span><span>,</span> <span>20</span><span>)</span><span>,</span> 
 <span>(</span><span>'DATA MODELING'</span><span>,</span> <span>20</span><span>)</span><span>,</span> 
 <span>(</span><span>'C#'</span><span>,</span> <span>19</span><span>)</span><span>,</span> 
 <span>(</span><span>'FLASK'</span><span>,</span> <span>19</span><span>)</span><span>,</span> 
 <span>(</span><span>'C'</span><span>,</span> <span>19</span><span>)</span><span>,</span> 
 <span>(</span><span>'REDIS'</span><span>,</span> <span>18</span><span>)</span><span>,</span> 
 <span>(</span><span>'MICROSERVICES'</span><span>,</span> <span>18</span><span>)</span><span>,</span> 
 <span>(</span><span>'COMPUTER VISION'</span><span>,</span> <span>17</span><span>)</span><span>,</span> 
 <span>(</span><span>'EXPRESS'</span><span>,</span> <span>15</span><span>)</span><span>,</span> 
 <span>(</span><span>'BASH/SHELL'</span><span>,</span> <span>13</span><span>)</span><span>,</span> 
 <span>(</span><span>'OBJECTIVE-C'</span><span>,</span> <span>13</span><span>)</span><span>,</span> 
 <span>(</span><span>'FIREBASE'</span><span>,</span> <span>12</span><span>)</span><span>,</span> 
 <span>(</span><span>'SCALA'</span><span>,</span> <span>11</span><span>)</span><span>,</span> 
 <span>(</span><span>'SOFTWARE SECURITY'</span><span>,</span> <span>11</span><span>)</span><span>,</span>
 <span>(</span><span>'UNITY'</span><span>,</span> <span>11</span><span>)</span><span>,</span> 
 <span>(</span><span>'R'</span><span>,</span> <span>11</span><span>)</span><span>,</span> 
 <span>(</span><span>'KAFKA'</span><span>,</span> <span>10</span><span>)</span><span>,</span> 
 <span>(</span><span>'SPARK'</span><span>,</span> <span>10</span><span>)</span><span>,</span> 
 <span>(</span><span>'ELASTICSEARCH'</span><span>,</span> <span>10</span><span>)</span><span>,</span> 
 <span>(</span><span>'ETL'</span><span>,</span> <span>10</span><span>)</span><span>,</span> 
 <span>(</span><span>'NATURAL LANGUAGE PROCESSING'</span><span>,</span> <span>10</span><span>)</span><span>,</span>
 <span>(</span><span>'HEROKU'</span><span>,</span> <span>10</span><span>)</span><span>,</span> 
 <span>(</span><span>'NGINX'</span><span>,</span> <span>9</span><span>)</span><span>,</span> 
 <span>(</span><span>'JENKINS'</span><span>,</span> <span>9</span><span>)</span><span>,</span> 
 <span>(</span><span>'RUST'</span><span>,</span> <span>9</span><span>)</span><span>,</span> 
 <span>(</span><span>'IMAGE PROCESSING'</span><span>,</span> <span>8</span><span>)</span><span>,</span>
 <span>(</span><span>'SERVERLESS'</span><span>,</span> <span>8</span><span>)</span><span>,</span> 
 <span>(</span><span>'BLOCKCHAIN'</span><span>,</span> <span>8</span><span>)</span><span>,</span>
 <span>(</span><span>'OPENCV'</span><span>,</span> <span>8</span><span>)</span><span>,</span>
 <span>(</span><span>'CAD DESIGN'</span><span>,</span> <span>7</span><span>)</span><span>,</span> 
 <span>(</span><span>'JQUERY'</span><span>,</span> <span>7</span><span>)</span><span>,</span> 
 <span>(</span><span>'HADOOP'</span><span>,</span> <span>6</span><span>)</span><span>,</span> 
 <span>(</span><span>'.NET CORE'</span><span>,</span> <span>6</span><span>)</span><span>,</span> 
 <span>(</span><span>'TCP/IP'</span><span>,</span> <span>6</span><span>)</span><span>,</span> 
 <span>(</span><span>'ELIXIR'</span><span>,</span> <span>6</span><span>)</span><span>,</span> 
 <span>(</span><span>'INTERNET OF THINGS (IOT)'</span><span>,</span> <span>5</span><span>)</span><span>,</span>
 <span>(</span><span>'SASS'</span><span>,</span> <span>5</span><span>)</span><span>,</span> 
 <span>(</span><span>'OPENGL'</span><span>,</span> <span>5</span><span>)</span><span>,</span>
 <span>(</span><span>'DYNAMODB'</span><span>,</span> <span>5</span><span>)</span><span>,</span> 
 <span>(</span><span>'GOOGLE APP ENGINE'</span><span>,</span> <span>5</span><span>)</span><span>,</span> 
 <span>(</span><span>'UNIX'</span><span>,</span> <span>4</span><span>)</span><span>,</span>
 <span>(</span><span>'SPRING FRAMEWORK'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'CUDA'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'DART'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'ERLANG'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'RABBITMQ'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'KERAS'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'SCSS'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'ML'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'MATLAB'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'SPRING'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'CASSANDRA'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'HIVE'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'PUPPET'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'REDSHIFT'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'SQL SERVER'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'GROOVY'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'VERILOG'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'TORCH/PYTORCH'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'CLOJURE'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'MICROSOFT AZURE'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'HBASE'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'RDS/AURORA'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'FIRMWARE'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'ABAP'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'ARDUINO'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'MICROCONTROLLERS'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'SOLIDITY'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'UNREAL ENGINE'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'COFFEESCRIPT'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'LUA'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'MACOS'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'NEO4J'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'INFORMATION SECURITY'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'REINFORCEMENT LEARNING (RL)'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'DEVICE DRIVERS'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'EMBEDDED LINUX'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'ELASTIC STACK (ELK)'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'IIS'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'ORACLE'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'F#'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'SQLITE'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'HASKELL'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'SCHEME'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'MS SQL'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'MARIADB'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'MAVEN'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'SEARCH'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'OCAML'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'JULIA'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'GPU PROGRAMMING'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'HACK'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'XAMARIN'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'CORDOVA'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'SAS'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'ASSEMBLY'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'XML'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'MEMCACHED'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'LESS'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'AMAZON ECHO'</span><span>,</span> <span>1</span><span>)</span> 
<span>]</span>
</code></pre></div>
<p>The list above gives a count of the different skills in all job postings sorted by the most common skills. But what about the most common skills listed together with any given skill? This would allow us to answer questions like "what skills appear most frequently along with JavaScript?"</p>
<p>We can find this with by doing:</p>
<div><pre><code>skills_frequency <span>=</span> defaultdict<span>(</span><span>lambda</span><span>:</span> defaultdict<span>(</span><span>lambda</span><span>:</span> <span>0</span><span>)</span><span>)</span>

<span>for</span> company <span>in</span> company_list<span>:</span>
    <span>if</span> company<span>[</span><span>"jobs"</span><span>]</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
        <span>for</span> job <span>in</span> company<span>[</span><span>"jobs"</span><span>]</span><span>:</span>
            <span>if</span> job<span>[</span><span>"job_skills"</span><span>]</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
                job_skills <span>=</span> job<span>[</span><span>"job_skills"</span><span>]</span>

                skill_tuples <span>=</span> itertools<span>.</span>permutations<span>(</span>job_skills<span>,</span> <span>2</span><span>)</span>

                <span>for</span> skill_tuple <span>in</span> skill_tuples<span>:</span>
                    first <span>=</span> skill_tuple<span>[</span><span>0</span><span>]</span>
                    second <span>=</span> skill_tuple<span>[</span><span>1</span><span>]</span>

                    skills_frequency<span>[</span>first<span>]</span><span>[</span>second<span>]</span> <span>+=</span> <span>1</span>

pprint<span>.</span>pprint<span>(</span>
    <span>{</span>
        key<span>:</span> <span>sorted</span><span>(</span>value<span>.</span>items<span>(</span><span>)</span><span>,</span> key<span>=</span><span>lambda</span> kv<span>:</span> <span>-</span>kv<span>[</span><span>1</span><span>]</span><span>)</span>
        <span>for</span> key<span>,</span> value <span>in</span> skills_frequency<span>.</span>items<span>(</span><span>)</span>
    <span>}</span>
<span>)</span>
</code></pre></div>
<!----><!---->
<h3 id="what-are-these-companies-working-on">What are these companies working on?</h3>
<p>Here's a wordcloud made from the short company descriptions:</p>
<p><img alt="png" src="https://briancaffey.github.io/static/company_desc_wc.png"></p>
<div><pre><code><span>import</span> json
<span>import</span> random

<span>from</span> collections <span>import</span> Counter
<span>from</span> os <span>import</span> path

<span>import</span> matplotlib<span>.</span>pyplot <span>as</span> plt
<span>import</span> numpy <span>as</span> np

<span>from</span> PIL <span>import</span> Image
<span>from</span> wordcloud <span>import</span> WordCloud<span>,</span> STOPWORDS

HTML_FILE <span>=</span> <span>"waas_data.json"</span>
<span>with</span> <span>open</span><span>(</span>HTML_FILE<span>,</span> <span>'r'</span><span>)</span> <span>as</span> j<span>:</span>
     company_list <span>=</span> json<span>.</span>loads<span>(</span>j<span>.</span>read<span>(</span><span>)</span><span>)</span>

company_names <span>=</span> <span>[</span>company<span>.</span>get<span>(</span><span>"company_name"</span><span>,</span> <span>" "</span><span>)</span><span>.</span>lower<span>(</span><span>)</span> <span>for</span> company <span>in</span> company_list<span>]</span>
company_description_list <span>=</span> <span>[</span>company<span>.</span>get<span>(</span><span>"company_desc"</span><span>,</span> <span>" "</span><span>)</span><span>.</span>lower<span>(</span><span>)</span><span>.</span>replace<span>(</span><span>"."</span><span>,</span> <span>""</span><span>)</span> <span>for</span> company <span>in</span> company_list<span>]</span>
company_descriptions <span>=</span> <span>" "</span><span>.</span>join<span>(</span>company_description_list<span>)</span>

wc <span>=</span> WordCloud<span>(</span>background_color<span>=</span><span>"white"</span><span>,</span> width<span>=</span><span>1920</span><span>,</span> height<span>=</span><span>1080</span><span>,</span> max_words<span>=</span><span>500</span><span>,</span> stopwords<span>=</span>STOPWORDS<span>,</span> margin<span>=</span><span>10</span><span>,</span>
               random_state<span>=</span><span>1</span><span>)</span><span>.</span>generate<span>(</span>company_descriptions<span>)</span>

default_colors <span>=</span> wc<span>.</span>to_array<span>(</span><span>)</span>

plt<span>.</span>figure<span>(</span>figsize<span>=</span><span>(</span><span>40</span><span>,</span> <span>40</span><span>)</span><span>)</span>
plt<span>.</span>imshow<span>(</span>wc<span>,</span> interpolation<span>=</span><span>"bilinear"</span><span>)</span>

plt<span>.</span>axis<span>(</span><span>"off"</span><span>)</span>
plt<span>.</span>savefig<span>(</span><span>'company_description_wc.png'</span><span>)</span>
plt<span>.</span>show<span>(</span><span>)</span>
</code></pre></div>
<p>Here's a breakdown of YC companies by category and sub category:</p>
<!----><!---->
<h3 id="salary-equity-and-years-of-experience">Salary, Equity and Years of Experience</h3>
<p>Here's a scatterplot showing average salary and average equity for positions categorized by years of experience required.</p>
<!----><!---->
<h3 id="logos">Logos</h3>
<p>Here's a look at about 600 of the 750 logos that were made available in the list of companies. The logos are sorted by their average hex color, which puts them on a gradient of dark to light:</p>
<p><img alt="png" src="https://briancaffey.github.io/static/yc.png"></p>
<div><pre><code><span>import</span> os
<span>import</span> PIL
<span>from</span> PIL <span>import</span> Image
<span>from</span> IPython<span>.</span>display <span>import</span> display<span>,</span> Image <span>as</span> IPyImage
<span>import</span> matplotlib<span>.</span>pyplot <span>as</span> plt
<span>import</span> matplotlib<span>.</span>image <span>as</span> mpimg
<span>%</span>matplotlib inline

LOGO_DIR <span>=</span> <span>'data/waas_full_details_dump_files/'</span>
yc_logos <span>=</span> <span>[</span>LOGO_DIR <span>+</span> x <span>for</span> x <span>in</span> os<span>.</span>listdir<span>(</span>LOGO_DIR<span>)</span> <span>if</span> x<span>.</span>endswith<span>(</span><span>'.png'</span><span>)</span><span>]</span>

<span>def</span> <span>average_img_hex</span><span>(</span>img<span>)</span><span>:</span>
    <span>"""
    https://www.hackzine.org/getting-average-image-color-from-python.html
    """</span>
    img <span>=</span> Image<span>.</span><span>open</span><span>(</span>img<span>)</span>

    
    <span>if</span> img<span>.</span>mode <span>in</span> <span>[</span><span>"LA"</span><span>,</span> <span>"P"</span><span>,</span> <span>"L"</span><span>]</span><span>:</span>
        <span>return</span>

    
    img2 <span>=</span> img<span>.</span>resize<span>(</span><span>(</span><span>1</span><span>,</span> <span>1</span><span>)</span><span>)</span>
    color <span>=</span> img2<span>.</span>getpixel<span>(</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>)</span><span>)</span>
    average_hex <span>=</span> <span>'#{:02x}{:02x}{:02x}'</span><span>.</span><span>format</span><span>(</span><span>*</span>color<span>)</span>

    <span>return</span> average_hex


sorted_images <span>=</span> <span>sorted</span><span>(</span>
    <span>[</span><span>(</span>average_img_hex<span>(</span>img<span>)</span><span>,</span> img<span>)</span> <span>for</span> img <span>in</span> yc_logos <span>if</span> average_img_hex<span>(</span>img<span>)</span> <span>is</span> <span>not</span> <span>None</span><span>]</span><span>,</span>
    key<span>=</span><span>lambda</span> x<span>:</span> x<span>[</span><span>0</span><span>]</span>
<span>)</span>

images <span>=</span> sorted_images<span>[</span><span>:</span><span>600</span><span>]</span>

fig<span>,</span> axes <span>=</span> plt<span>.</span>subplots<span>(</span><span>20</span><span>,</span> <span>30</span><span>,</span> figsize<span>=</span><span>(</span><span>30</span><span>,</span> <span>15</span><span>)</span><span>,</span> sharex<span>=</span><span>False</span><span>,</span> sharey<span>=</span><span>Fal…</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://briancaffey.github.io/2021/01/16/i-scraped-analyzed-and-generated-yc-companies-founders-and-work-at-a-startup-job-postings">https://briancaffey.github.io/2021/01/16/i-scraped-analyzed-and-generated-yc-companies-founders-and-work-at-a-startup-job-postings</a></em></p>]]>
            </description>
            <link>https://briancaffey.github.io/2021/01/16/i-scraped-analyzed-and-generated-yc-companies-founders-and-work-at-a-startup-job-postings</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989367</guid>
            <pubDate>Mon, 01 Feb 2021 15:19:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Games can fix remote team building]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25989336">thread link</a>) | @masonhipp
<br/>
February 1, 2021 | https://slideswith.com/blog/games-for-remote-team-building | <a href="https://web.archive.org/web/*/https://slideswith.com/blog/games-for-remote-team-building">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>The problem: remote work makes it dramatically harder to socialize with your teammates.</strong></p>
<p>There's no going to the bar, you can't read body language, and spontaneous conversation evaporates. The fundamentals of team building are the same — communication, shared values, camaraderie, and a belief in the company mission  — but the avenues for establishing those foundations are severely limited when remote.</p>
<p><mark>Online games can solve many of challenges of inherit to remote team building.</mark></p>
<p>Games do several things that make them ideal for building strong connections and creating closeness between peers. They can:</p>
<ul>
<li>lower the bar to social interaction</li>
<li>create unique shared experiences</li>
<li>provide a safe environment for deeper conversation</li>
<li>provide beneficial structure to group interactions</li>
<li>make the most of limited-bandwidth video calls</li>
<li>allow teamwork to be practiced with lower stakes</li>
</ul>
<p>It's also much easier to get buy-in for a trivia night or a game that's fun and amusing than it is to get people excited about yet another zoom happy hour. Let's take a look at why game dynamics are so useful for online connection.</p>
<h2 id="games-create-inclusive-conversations-that-work-online">Games create inclusive conversations that work online</h2>
<p>An important aspect of building a strong team is breaking down the walls between each of the various team members and fostering connections between them. This can be difficult to do naturally in the real world and it is even more challenging virtually.</p>
<p>Most events don't run with an ideal structure for team building, and conversations end up too focused on one speaker or a free-for-all dominated by the loudest voices.</p>
<p><img alt="" src="https://d33wubrfki0l68.cloudfront.net/f9ffbdad43c032944434345296afb2464462dc95/c16e4/images/blog/natural-group-interaction-opt.svg"></p>
<p>With the right game you can create a conversational structure that is much more inclusive and ideal for team boding. Additionally, game conversations are frequently turn-based and lend themselves naturally to online conversation with larger groups.</p>
<p><img alt="" src="https://d33wubrfki0l68.cloudfront.net/8a4599e657de5c00626214a2e1199304450465b2/fed64/images/blog/ideal-group-conversation-opt.svg"></p>
<h2 id="games-teach-teamwork-in-fast-low-risk-environment">Games teach teamwork in fast, low-risk environment</h2>
<p>A high-functioning remote team will be able to work cohesively toward a single goal. The members will understand their strengths, understand how to communicate with one another, and be able to work as an effective and coordinated whole. Learning to do this can take a lot of time.</p>
<p><strong>Games offer a fast iteration cycle with lower consequences of failure, providing an ideal environment for learning to work as a team.</strong></p>
<p>The social cooperation required in games is often very similar to the real world. The communication and interpersonal challenges of a job are frequently replicated in online games — but without the high stakes and risk of real world performance and deadlines.</p>
<p>It's also possible to run through many more teamwork scenarios in a game than it is in a real-world work environment. Being able to play multiple games or challenges in a short period of time can also provide more opportunity to learn how to work together than the equivalent period of time working together on an actual project with real-world consequences.</p>
<h2 id="games-offer-a-safe-space-to-talk-about-real-things">Games offer a safe space to talk about real things</h2>
<p>Creating real friendships between team members requires a degree of vulnerability that can be difficult to surface in a day-to-day conversation, and is particularly challenging over video calls.</p>
<p>Friendships between team members generally start with small talk and slowly grow in trust and closeness over time. When it happens naturally, this process can take a long time and requires a lot of interaction (the ratio of real conversation to small talk is very low).</p>
<p>According to psychologist Arthur Aron, who you might know from the popular NY Times article <a href="https://www.nytimes.com/2015/01/09/style/no-37-big-wedding-or-small.html" rel="nofollow noopener noreferrer" target="_blank">36 Questions to Fall In Love</a>, the key to forming close bonds is a gradual increase in mutual vulnerability (real conversations):</p>
<blockquote>
<p>“One key pattern associated with the development of a close relationship among peers is sustained, escalating, reciprocal, personal self-disclosure.”</p>
<p>— Aurthor Aron, et. al. <a href="https://journals.sagepub.com/doi/pdf/10.1177/0146167297234003" rel="nofollow noopener noreferrer" target="_blank">The Experimental Generation of Interpersonal Closeness</a></p>
</blockquote>
<p>From a corporate team building perspective the point is this: creating bonds inside of your team will eventually require team members to show mutual vulnerability and have real conversations.</p>
<p>At a company office there is an enormous volume of interactions and all of this happens organically, but we don't have that luxury when working virtually. To be most effective at team building online requires a very intentional approach that prioritizes real conversation and self-disclosure.</p>
<p>Games can add exactly this structure to conversations (as mentioned above) and the games themselves can be specifically designed to foster self-disclosure and real conversation in an approachable and fun environment.</p>
<h2 id="games-help-overcome-the-lower-fidelity-of-video-calls">Games help overcome the lower fidelity of video calls</h2>
<p>Interpersonal communication typically uses an incredible amount of information bandwidth: we instinctively monitor body movements, miniscule sound inflections, facial micro-expressions, <a href="https://en.wikipedia.org/wiki/Proxemics" rel="nofollow noopener noreferrer" target="_blank">proxemics</a>, and much more in instantaneous real time.</p>
<p>Trying to have a conversation over video chat, on the other hand, leads to a near complete breakdown of nonverbal cues and a substantial degradation of verbal communication. Experts have roundly agreed that <a href="https://www.nationalgeographic.com/science/2020/04/coronavirus-zoom-fatigue-is-taxing-the-brain-here-is-why-that-happens/" rel="nofollow noopener noreferrer" target="_blank">Zoom fatigue is both real and costly</a>, and many of them agree that the root cause is related to latency, bandwidth, and the breakdown of natural information transfer between parties (e.g. eye contact).</p>
<blockquote>
<p>“For somebody who’s really dependent on non-verbal cues, it can be a big drain not to have them,”</p>
<p>— Andrew Franklin, assistant Professor of Cyberpsychology at Norfolk State University</p>
</blockquote>
<p>Given how much less bandwidth is available during online communication, many teams instinctively gravitate toward a "transactional only" approach to meetings. This can provide some benefits — calls are shorter, reducing overall fatigue, and there is a tighter schedule of defined work — but this approach entirely eliminates relationship building. Some teams can function this way (if they've known each other for a while), but for many this elimination of team interaction is a major problem.</p>
<p>Games can help overcome the bandwidth and latency issues by creating a clear structure for communication. Structured, rule-based conversations remove the need for each participant to dynamically read the room to know when to talk and what to say. <mark>The rule-based structure of games replaces the need to follow the meta-structure of a group conversation, allowing the participants focus on the <em>content</em> of the </mark>communication and not who's turn it is to talk.</p>
<p>Structured communication can also reduce conversational error rates (e.g. people talking over each other) and overall make the most of a reduced-bandwidth environment.</p>
<h2 id="games-lower-social-barriers-and-create-buy-in">Games lower social barriers and create buy-in</h2>
<p>The easiest way to silence a video call is to ask a deep or open-ended question — people will immediately shut down, trying avoid a situation where they might get burned in front of their peers.</p>
<p><img alt="" src="https://d33wubrfki0l68.cloudfront.net/617201462cf33e37820b89fe119005f69bd1e668/e35ff/images/blog/share-personal-information-optimized.svg"></p>
<p><strong>Sharing personal information is inherently risky, but games provide rules that make it safer. Few people will volunteer personal information to a group, but during a game almost everyone will participate freely when it comes to their turn.</strong></p>
<p>Games provide a safe space for interaction that can make it easier and less risky to be yourself, and in fact even rewards everyone for participating. How many people would do an impression of a farm animal in front of a group? How about during a game of charades?</p>
<p>The other interesting benefit of games is that they are more fun by default. Getting your team to buy into a zoom happy hour or team building exercise is tough — but getting them excited about a game of trivia or escape room is much easier.</p>
<h2 id="games-encourage-active-attention">Games encourage active attention</h2>
<p>One very powerful aspect of an online game is that it generally requires all participants to pay attention or risk losing or being called out. <mark>The active attention of a game environment is in direct contrast with many zoom meetings where half of the audience could be in a different tab while you're talking</mark>.</p>
<p>As you might imagine from real-world conversations, paying active attention is a prerequisite for building real relationships and bonds, and games are an excellent tool for creating an environment that's ripe for team building.</p>
<p>A word of caution: active engagement can be very tiring, particularly on video calls, and an overuse of games to force paying attention can easily result in a exhausted audience. The key to avoiding this is proper spacing, breaks, and the right frequency of use.</p>

<p>Think back to a conversation you had with a group of friends or close coworkers. How often did somebody say "do you remember when we did X" .. or ..  "what was that movie we watched during..?"</p>
<p>This kind of information sharing is called <strong>Transactive Memory</strong> and it is a key component to forming close relationships and creating a team that functions well together. <mark>Each person in a highly collaborative team will help <em>maintain the shared group memory and understanding</em> such that the group is maximizing each member's strengths, compensating for weaknesses, and the entire team can work together optimally toward a shared goal</mark>.</p>
<p>Games help to create these shared memories by putting group members into a new experience and then asking everybody to participate, recall information, and work together. These actions all combine into an event that team members can remember together and use to learn and understand each other more deeply.</p>
<blockquote>
<p>The existence of effective transactive memory systems in teams has been found to enhance task performance. Methods of developing transactive memory are therefore an important focus of research. This study aimed to explore one such method, the use of a generic team-skills training program, to develop transactive memory and subsequent task performance [...] <strong>Results confirmed that</strong> <strong>those teams that had been trained to develop a range of team skills such as problem-solving, interpersonal relationships, goal setting, and role allocation evidenced significantly higher team skill, transactive memory, and performance than those that were not trained in …</strong></p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://slideswith.com/blog/games-for-remote-team-building">https://slideswith.com/blog/games-for-remote-team-building</a></em></p>]]>
            </description>
            <link>https://slideswith.com/blog/games-for-remote-team-building</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989336</guid>
            <pubDate>Mon, 01 Feb 2021 15:16:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[These Are the 21 Best Developer Productivity Tools]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989252">thread link</a>) | @KaiserSanchez
<br/>
February 1, 2021 | https://www.7pace.com/blog/developer-productivity-tools | <a href="https://web.archive.org/web/*/https://www.7pace.com/blog/developer-productivity-tools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
<p>If work in the 21st century has a theme, it’s this: <a href="https://www.7pace.com/blog/how-to-measure-developer-productivity"><u>Productivity</u></a>.</p>



<p>We’re all striving to be more productive —&nbsp;at work, at home, and everywhere in between. And to help us achieve ultimate productivity, there are <em>countless</em>&nbsp;tools and resources that promise to make you able to work harder, better, faster, and stronger.</p>



<p>But not all productivity tools were created equal. Some are just better than others, and some are better suited to different tasks and workflows. That’s where this guide comes in.</p>



<p>If you’re a developer standing in front of the veritable sea of productivity apps and tools available and wondering where to start, don’t worry. We’ve got you. We’ve narrowed down the 21 best developer productivity tools, focusing on resources that will help you stave off distractions, find your flow, and work collaboratively across your team.</p>



<h2>The 21 Developer Productivity Tools You Need to Download Right Now</h2>



<p>Before we dive in, let’s cover the bad news: You’re <a href="https://www.7pace.com/blog/workplace-productivity"><u>never going to become 100 percent productive</u></a>. Sorry, but that’s just not how human brains work.</p>



<p>The first step is to approach this list with the right motives. If you’re looking to work better with your teammates or break bad work habits (like checking social media every few minutes), these tools can help. If your goal is to <a href="https://www.7pace.com/blog/deep-work-in-the-age-of-distraction"><u>deep work for 14 hours a day</u></a>, you need to accept that that’s just unrealistic.</p>



<p>Don’t think of productivity as an end goal or something you will eventually achieve. Think of it as a <a href="https://www.7pace.com/blog/healthier-work-systems"><u>journey you take every time you sit down to work</u></a>. And use these tools to help guide you on that daily journey.</p>



<h3>Developer Productivity Tools for Project Management, Teamwork, and Workflow</h3>



<figure><img loading="lazy" width="970" height="585" src="https://www.7pace.com/wp-content/uploads/2021/01/01-Image-4.jpg" alt="Developer Productivity Tools for Project Management, Teamwork, and Workflow" srcset="https://www.7pace.com/wp-content/uploads/2021/01/01-Image-4.jpg 970w, https://www.7pace.com/wp-content/uploads/2021/01/01-Image-4-300x181.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/01/01-Image-4-768x463.jpg 768w" sizes="(max-width: 970px) 100vw, 970px"></figure>



<p><a href="https://hey.space/" target="_blank" rel="noreferrer noopener"><strong><u>HeySpace</u></strong></a>&nbsp;is a task management software that also has a chat feature —&nbsp;sort of like a combination of Slack and Trello. Its innovative and user-friendly design allows you to see tasks and communications in just one screen. That means no more toggling between different screens (or different apps) to chat with your team about a project or task. HeySpace offers both free and paid premium plans, depending on the number of users on your team.</p>



<p><a href="https://www.codestream.com/" target="_blank" rel="noreferrer noopener"><strong><u>Codestream</u></strong></a>&nbsp;is for developers who are tired of the effort and frustration that come with code reviews. This tool lets you skip the pull request by simply highlighting a code block and adding a note. This means discussing code with your team simply and directly in the coding environment. Codestream offers support for every programming language and makes group problem solving a simple part of any team’s workflow.</p>



<p><a href="https://www.mantisbt.org/" target="_blank" rel="noreferrer noopener"><strong><u>MantisBT</u></strong></a>&nbsp;is the bug tracker of your dreams. Just like its namesake, the Mantis, this tool leaves no stone unturned in its search for bugs in your code. A web-based bug tracking program, MantisBT tracks your code for errors, and then sends an email notification to you and everyone on your team whenever it finds a problem. Don’t worry —&nbsp;you can customize notifications if an email for every bug isn’t your thing.</p>



<p><a href="https://codeanywhere.com/" target="_blank" rel="noreferrer noopener"><strong><u>Codeanywhere</u></strong></a>&nbsp;is a game-changing tool for teams of developers who need to work together on one code block at the same time. Think of it like Google Docs for code. It’s a code editor that supports more than 70 different programming languages, and allows all users to see who’s working on what in real time. All you have to do to get started is send a link to your code editor to anyone who’s on your team.</p>



<p><a href="https://anydesk.com/en" target="_blank" rel="noreferrer noopener"><strong><u>AnyDesk</u></strong></a><strong>&nbsp;</strong>is for anyone who has a killer desktop setup at work, and a similarly killer desktop setup at home, and wants to be able to work on both of them. Setting up the perfect virtual environment is a pain —&nbsp;and can take literal hours. So instead of doing it for every computer you use to code, just do it once and then use AnyDesk to connect to your work PC from any computer anywhere.</p>



<p><a href="https://tuple.app/" target="_blank" rel="noreferrer noopener"><strong><u>Tuple</u></strong></a><strong>&nbsp;</strong>is for developers who have realized that, as much as they’ve become standard for workers in 2020, Slack and Zoom weren’t made for programmers —&nbsp;and it shows. A trio of software engineers created Tuple to make pair programming easier for remote teams, and the result is an app with simple, high-quality screen sharing, crisp audio, and efficient CPU usage so it has full functionality even on a low-latency connection.</p>



<figure><img loading="lazy" width="970" height="585" src="https://www.7pace.com/wp-content/uploads/2021/01/03-Image-3.jpg" alt="todoist" srcset="https://www.7pace.com/wp-content/uploads/2021/01/03-Image-3.jpg 970w, https://www.7pace.com/wp-content/uploads/2021/01/03-Image-3-300x181.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/01/03-Image-3-768x463.jpg 768w" sizes="(max-width: 970px) 100vw, 970px"></figure>



<p><a href="https://todoist.com/home" target="_blank" rel="noreferrer noopener"><strong><u>Todolist </u></strong></a>is the only to-do list app that’s made just for developers. With just how many list apps exist, you’re probably wondering what makes this one good enough to make our list, so here it is: Todolist allows you to do all the same productivity tasks you’d do with any list app —&nbsp;prioritize tasks, filter and group them, and archive them —&nbsp;but from a code-like environment. You manage everything with simple commands that make it easy to check things off your list and queue up a new project, without breaking your flow.</p>



<p><a href="https://www.figma.com/" target="_blank" rel="noreferrer noopener"><strong><u>Figma</u></strong></a><strong>&nbsp;</strong>is a must-have tool for developers who work with designers, product managers, or product teams. It’s a browser-based tool that gives designers one, single link where they can access crucial information and assets like colors, widths, and heights for design elements.</p>



<h3>Developer Productivity Tools for Breaking Bad Habits (and Forming Good Ones)</h3>



<figure><img loading="lazy" width="970" height="585" src="https://www.7pace.com/wp-content/uploads/2021/01/02-Image-3.jpg" alt="Developer Productivity Tools for Breaking Bad Habits (and Forming Good Ones)" srcset="https://www.7pace.com/wp-content/uploads/2021/01/02-Image-3.jpg 970w, https://www.7pace.com/wp-content/uploads/2021/01/02-Image-3-300x181.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/01/02-Image-3-768x463.jpg 768w" sizes="(max-width: 970px) 100vw, 970px"></figure>



<p><a href="https://habitica.com/" target="_blank" rel="noreferrer noopener"><strong><u>Habitica</u></strong></a><strong>&nbsp;</strong>makes it fun to create good habits at work. Using pixel-like design, Habitica turns you into a hero in an in-platform world where you’re tasked with fighting through daily, weekly, and long-term goals. For completing tasks and building up good habits, you earn points, discover new animals, and build your strength. For failing at tasks, you lose strength — and your character can die. For developers who love gaming, this is an entertaining (and effective) way to build better work habits.</p>



<p><a href="https://justgetflux.com/" target="_blank" rel="noreferrer noopener"><strong><u>F.lux</u></strong></a>&nbsp;is the productivity tool that will save you from dry, tired eyes —&nbsp;a problem for developers everywhere. This tool automatically adjusts your screen color based on your time and location, making colors warmer as it gets dark where you are to make your screen more natural for your eyes in the dark. You can also override the automatic color-changes and set your own schedule, which is a great way to remind yourself to take breaks from the harsh light of your computer screen.</p>



<h3>Developer Productivity Tools for Banishing Distractions</h3>



<p><a href="https://www.sublimetext.com/" target="_blank" rel="noreferrer noopener"><strong><u>Sublime Text</u></strong></a>&nbsp;is designed to be a code editor with an easy-to-use interface and eye-friendly work environment. It allows you to markup and program in a variety of coding languages, while also easily moving across files, switching between projects, and changing specific lines of code. But one of the features we love most about Sublime Text is its built-in distraction mode, which is sort of like a do-not-disturb setting for when you want to deep work.</p>



<p><a href="https://pi-hole.net/" target="_blank" rel="noreferrer noopener"><strong><u>Pi-Hole</u></strong></a><strong>&nbsp;</strong>is for those developers who think there’s nothing more distracting than a webpage ad. Think about it: They clutter up your screen. They reduce network performance. By all accounts, they’re an unnecessary obstacle in the way of productive work. Enter Pi-Hole, an ad-blocker that connects to your router instead of your browser, making it able to provide network-wide ad blocking. Pairing Pi-Hole with a VPN protects every device on your network from ads that distract away from work.</p>



<p><a href="https://getcoldturkey.com/" target="_blank" rel="noreferrer noopener"><strong><u>Cold Turkey</u></strong></a><strong>&nbsp;</strong>requires you to know exactly what your vices are. But then it does a really great job at blocking you from accessing them. Set it up to limit access to certain websites, certain apps, and even your internet access. The result? A work environment that’s free of all distractions for as long as you need it to be, allowing you to work without the usual interruptions.</p>



<h3>Developer Productivity Tools for Getting Into Your Flow</h3>



<p><a href="https://chrome.google.com/webstore/detail/strict-workflow/cgmnfnmlficgeijcalkgnnkigkefkbhd?hl=en" target="_blank" rel="noreferrer noopener"><strong><u>Strict Workflow</u></strong></a><strong>&nbsp;</strong>embraces the research-backed success of the Pomodoro method —&nbsp;the idea that for maximum productivity, you should alternate 25-minute focused sprints with 5-minute breaks. Using the Pomodoro method used to require a timer, but not anymore. Strict Workflow is a Chrome extension that acts as a built-in timer for that uber-effective work-and-break cycle. It runs in the background and lets you know when it’s time to work, and when it’s time to take a breather. No egg timer required.</p>



<figure><img loading="lazy" width="970" height="585" src="https://www.7pace.com/wp-content/uploads/2021/01/04-Image-1.jpg" alt="Developer Productivity Tools for Getting Into Your Flow" srcset="https://www.7pace.com/wp-content/uploads/2021/01/04-Image-1.jpg 970w, https://www.7pace.com/wp-content/uploads/2021/01/04-Image-1-300x181.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/01/04-Image-1-768x463.jpg 768w" sizes="(max-width: 970px) 100vw, 970px"></figure>



<p><a href="https://memory.ai/dewo" target="_blank" rel="noreferrer noopener"><strong><u>Dewo</u></strong></a><strong>&nbsp;</strong>is the tool developers need to combat one of their biggest disruptors: Context switching. Dewo bills itself as users’ “personal assistant for deep work,” and that’s pretty much what it does. The app uses AI to analyze your productivity patterns, and then provides you with insights that should help you figure out how to work not harder, but smarter. Dewo can also toggle a do-not-disturb mode that silences other apps and sets your Slack status to “Away” once you enter a flow state, ensuring that nothing gets in the way of that sweet, sweet deep work.</p>



<p><a href="https://github.com/ggreer/the_silver_searcher" target="_blank" rel="noreferrer noopener"><strong><u>The Silver Searcher</u></strong></a><strong>&nbsp;</strong>is another app for developers that’s meant to minimize wasted time at work —&nbsp;by making it easier to search your code. Think about it: If you’re like a lot of devs, you probably spend a fair amount of your “coding time” actually reading and scanning code, not writing it. The Silver Searcher helps combat that by making it much easier —&nbsp;and much, <em>much</em>&nbsp;faster —&nbsp;to search through code.</p>



<p><a href="https://walrus.ai/" target="_blank" rel="noreferrer noopener"><strong><u>Walrus.ai</u></strong></a><strong>&nbsp;</strong>is yet another app that’s here to save money and effort for teams of developers, this time by automating QA testing. It makes testing more efficient and lightweight by providing full end-to-end testing via a single API call, as opposed to cumbersome in-house automated testing or manual QA. And if you’re concerned about accuracy, Walrus employs a whole team to monitor every run and keep a look out for false positives and negatives.</p>



<p><a href="https://www.programmersmusic.com/" target="_blank" rel="noreferrer noopener"><strong><u>Programmer’s Music</u></strong></a>&nbsp;is the perfect app for the developer that wants the perfect soundtrack for productive work, but doesn’t want to put in the time or effort to curate a playlist his or herself. There are plenty of sites out there that offer curated music lists to <a href="https://www.7pace.com/blog/heres-what-science-says-about-how-music-affects-your-productivity"><u>promote focus and productivity</u></a>, but this one is our favorite because of its non-vocal, distraction free songs that can be timed to the Pomodoro method if you want them to be.</p>



<h3>Developer Productivity Tools for Tracking Time (Hint: You Only Need One)</h3>



<figure><img loading="lazy" width="970" height="585" src="https://www.7pace.com/wp-content/uploads/2021/01/05-Image-1.jpg" alt="Developer Productivity Tools for Tracking Time (Hint: You Only Need One)" srcset="https://www.7pace.com/wp-content/uploads/2021/01/05-Image-1.jpg 970w, https://www.7pace.com/wp-content/uploads/2021/01/05-Image-1-300x181.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/01/05-Image-1-768x463.jpg 768w" sizes="(max-width: 970px) 100vw, 970px"></figure>



<p><a href="https://www.7pace.com/timetracker"><strong><u>7pace Timetracker</u></strong></a>&nbsp;…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.7pace.com/blog/developer-productivity-tools">https://www.7pace.com/blog/developer-productivity-tools</a></em></p>]]>
            </description>
            <link>https://www.7pace.com/blog/developer-productivity-tools</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989252</guid>
            <pubDate>Mon, 01 Feb 2021 15:06:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Robinhood Misled the Poor and Rewarded the Rich]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 89 (<a href="https://news.ycombinator.com/item?id=25989199">thread link</a>) | @iamspoilt
<br/>
February 1, 2021 | https://themeasureofaplan.com/robinhood/ | <a href="https://web.archive.org/web/*/https://themeasureofaplan.com/robinhood/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
		<!-- site-header -->
		<!-- /site-header --><article>
	
	<!-- post-title -->
	 <!-- /post-title -->

	<p>January 31st, 2021 | Posted in

		<a href="https://themeasureofaplan.com/category/uncategorized/">Uncategorized</a>
		</p>

	<img width="700" height="394" src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-header-image.jpg" alt="" loading="lazy" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%20394'%3E%3C/svg%3E" data-lazy-src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-header-image.jpg">	
	
    <!-- if URL contains "?v=clean" do not show the mailchimp email sign-up box-->
	        
        	
	
<p>[Feb-1 update: a new section “Clearing Houses &amp; the Plumbing Behind Financial Markets” has been added]</p>
<p>[Feb-2: updated with Robinhood’s Q4 2020 revenues from “payment for order flow”]</p>
<p>&nbsp;<br>
This is a story about Robinhood, an online broker that promised to “democratize finance for all”, but ended up deceiving its customers and helping the rich get richer.</p>
<p>So buckle up — we’re heading off to the moon 🚀🌙! But first, let’s pause for a glance at:</p>
<ul>
<li>A run-down of Robinhood’s business model, and how they were fined $65 million for failing to disclose that most of their revenues come from Wall Street partners</li>
<li>The opaque world of “payment for order flow”, and how this creates massive conflicts of interest for Robinhood</li>
<li>The ongoing GameStop ($GME) saga — where Robinhood conveniently ends up siding with the hedge funds, to the detriment of everyday investors around the globe</li>
</ul>

<h2>The Origins of Robinhood</h2>
<p>Robinhood’s co-founders Vlad Tenev and Baiju Bhatt were roommates at Stanford, and set off after graduation to work in New York, building trading software for hedge funds <em>(note to reader: this is one of many ties to the hedge fund world that we’ll come across)</em>.</p>
<p>In 2013, Vlad and Baiju decided to strike off on their own and launched Robinhood — an online platform that allowed investors to trade stocks, ETFs, and other financial assets without paying trading commissions.</p>
<p>At the time, competing brokers were charging $5 to $10 per trade, so Robinhood’s free model helped them to win the trust of millions of customers across America.</p>
<p>Fueled by crisp marketing, simple user interfaces, and their no-fee model, Robinhood grew by leaps and bounds over the next few years. The company now boasts more than 13 million customers, 1,200 employees, and a valuation of $11 billion after raising funds in August 2020.</p>
<p>The chart below from <a href="https://www.ft.com/content/b208cbbe-579c-4cbf-9358-01ae02b4381b" rel="noopener" target="_blank">FT and Pitchbook</a> captures Robinhood’s meteoric rise:</p>
<p><img src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-post-money-valuation-timeline-FT.png" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-post-money-valuation-timeline-FT.png"></p>

<h2>Robbing the Hood and Giving to the Rich?</h2>
<p>All was green and all was good for Robinhood and the merry men.</p>
<p>Their founders made proud claims that “we believe the financial system should be built to work for everyone”, and <a href="https://www.ft.com/content/c3ed6758-e51c-48b1-b6a6-a17ccb265b28" rel="noopener" target="_blank">“we didn’t build Robinhood to make the rich people richer”</a>.</p>
<p>However, these claims don’t hold up to close scrutiny.</p>
<p>In December 2020, the SEC (America’s financial markets regulator) <a href="https://www.sec.gov/news/press-release/2020-321" rel="noopener" target="_blank">fined Robinhood $65 million</a> for “misleading customers about revenue sources and failing to satisfy duty of best execution”.</p>
<p>This investigation shined a light on how Robinhood was operating beneath the glitzy marketing and lip service towards democratizing finance.</p>
<p>Excerpts from the <a href="https://www.sec.gov/news/press-release/2020-321" rel="noopener" target="_blank">SEC press release</a> (my emphasis added):</p>
<p>According to the SEC’s order, between 2015 and late 2018, <b>Robinhood made misleading statements and omissions in customer communications, including in FAQ pages on its website</b>, about its largest revenue source when describing how it made money – namely, payments from trading firms in exchange for Robinhood sending its customer orders to those firms for execution, also known as “payment for order flow.”</p>
<p>As the SEC’s order finds, one of Robinhood’s selling points to customers was that trading was “commission free,” but due in large part to its unusually high payment for order flow rates, <b>Robinhood customers’ orders were executed at prices that were inferior to other brokers’ prices</b>.  Despite this, according to the SEC’s order, Robinhood falsely claimed in a website FAQ between October 2018 and June 2019 that its execution quality matched or beat that of its competitors.</p>
<p>The order finds that <b>Robinhood provided inferior trade prices that in aggregate deprived customers of $34.1 million even after taking into account the savings from not paying a commission</b>.  Robinhood made these false and misleading statements during the time in which it was growing rapidly.</p>
<p>“Robinhood failed to seek to obtain the best reasonably available terms when executing customers’ orders, causing customers to lose tens of millions of dollars,” said Joseph Sansone, Chief of the SEC Enforcement Division’s Market Abuse Unit.  “Today’s action sends a clear message that the Commission will not allow brokers to ignore their obligations to customers.”</p>
<p>&nbsp;<br>
In other words:</p>
<ul>
<li>Robinhood was selling its customers’ trade data to market makers and high-frequency traders — Wall Street firms that profit off of these trades</li>
<li>This is Robinhood’s largest source of revenue — a fact that they curiously left out on their FAQ page describing how they made money</li>
<li>This practice meant that trades placed on Robinhood weren’t executed at the best price, costing customer tens of millions of dollars, <b>even after taking into account the savings from not paying a commission</b></li>
</ul>
<p>One more time: Robinhood lied about their business model, made money by selling customer data to Wall Street, at the ultimate expense of its own customers.</p>
<p>If you’re looking for other reasons to get riled up, how about this other time Robinhood was fined for <a href="https://www.finra.org/media-center/newsreleases/2019/finra-fines-robinhood-financial-llc-125-million-best-execution" rel="noopener" target="_blank">failing to protect their customers’ best interest</a>, or when Robinhood improperly stored their customers’ passwords, leading to <a href="https://www.bloomberg.com/news/articles/2020-10-15/robinhood-estimates-hackers-infiltrated-almost-2-000-accounts" rel="noopener" target="_blank">2,000 accounts being compromised and having funds siphoned off</a>.</p>
<p>Next — let’s dive into how the murky world of “payment for order flow” works, how Robinhood makes money from it, and why this makes Robinhood beholden to their Wall Street partners.</p>

<h2>Sally Schmo and “Payment for Order Flow”</h2>
<p>As we saw above, Robinhood’s main revenue source comes from selling customer trade data to other firms. This is a controversial practice known as “Payment for Order Flow” (PFOF in financial regulatory lingo).</p>
<p>To give you a sense of it, PFOF was <a href="https://web.archive.org/web/20200817124549/https://money.cnn.com/2000/05/29/investing/q_madoff/" rel="noopener" target="_blank">pioneered by Bernie Madoff</a> (one of history’s greatest con men), and the practice is <a href="https://www.gbm.scotiabank.com/content/dam/gbm/market-insights/etf/october/2019-10-02-Free-Trading.pdf" rel="noopener" target="_blank">banned in Canada</a>.</p>
<p>It’s a bit of a tangled web, so I’ve created the graphic below to lay it out in steps:</p>
<p><img src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-NOK-order-flow-v3.png" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-NOK-order-flow-v3.png"></p>
<p>Let’s take the example of a Robinhood customer who wants to buy 100 shares of Nokia (NOK).</p>
<ol>
<li>Investor submits an order to buy 100 shares of $NOK at a max price of $4.00 per share ($400 total)</li>
<li>Broker asks the market maker (MM) to find 100 shares of $NOK</li>
<li>MM buys 100 shares of $NOK at the best price it can find — $398 in this example – and collects $2 of profit</li>
<li>Stock exchange delivers 100 shares of $NOK to the MM</li>
<li>MM delivers 100 shares and gives the broker a cut of the profit (aka, PFOF)</li>
<li>Broker delivers 100 shares of $NOK to the investor for a total of $400</li>
</ol>
<p>After all is said and done, the market maker and Robinhood walk away with $2 in profit, and the investor receives 100 shares of Nokia for $400.</p>
<p>The example above is simplified and uses dummy numbers, but the concept holds true.</p>
<p>Robinhood doesn’t carry out customer orders itself, it routes them to MMs (such as Citadel) for the MM to execute.</p>
<p>The MM buys the requested shares for a price, resells those shares to the Robinhood customer at a slightly higher price, pockets the difference, and shares some of the profits with Robinhood.</p>
<p>So what’s the big deal? Why does “payment for order flow” harm the everyday investor?</p>
<p>When you place an order on Robinhood, you don’t get transparency on what the best price was, whether your order was executed at that best price, and how much profit was captured by the MM / Robinhood in the process.</p>
<p>Even though Robinhood customers don’t pay commissions on their trades (the $5 to $10 per trade that brokers used to charge), there is an “invisible cost” to the customer since they are paying more for the shares that they trade.</p>
<p>Taking this from a different angle, why does the MM pay Robinhood for the order? If the MM wasn’t able to make a profit on the execution of these trades what would be in it for them?</p>
<p>Keep in mind that Robinhood was fined $65 million by the SEC because Robinhood customers weren’t getting the best price on their trades, and since Robinhood misled their customer about this practice.</p>

<h2>How Much Does Robinhood Earn from “Payment for Order Flow”?</h2>
<p>According to <a href="https://cdn.robinhood.com/assets/robinhood/legal/RHS%20SEC%20Rule%20606a%20and%20607%20Disclosure%20Report%20Q4%202020.pdf" rel="noopener" target="_blank">Robinhood’s regulatory filings for Q4 2020</a>, Robinhood made a whopping $221 million in revenue from PFOF in Q4 2020 alone.</p>
<p>I’ve tabulated the data in a spreadsheet (<a href="https://drive.google.com/drive/u/0/folders/1pM7iQqZejiZIzmzX8XW36hQft7xJ2Hyt" rel="noopener" target="_blank">available here</a>), and have broken out their revenue from each partner:</p>
<p><img src="https://themeasureofaplan.com/wp-content/uploads/2021/02/Robinhood-Q4-2020-payment-for-order-flow-revenues.png" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://themeasureofaplan.com/wp-content/uploads/2021/02/Robinhood-Q4-2020-payment-for-order-flow-revenues.png"></p>
<p>Nearly half of Robinhood’s PFOF revenues — $108 million in Q4 2020 alone — come from Citadel. 🚨🚨 Remember that name, as they’ll feature prominently in the epic struggle for GameStop stock that follows.</p>
<p>Citadel is a hedge fund and market maker. Its success has vaulted founder Ken Griffin to a <a href="https://en.wikipedia.org/wiki/Kenneth_C._Griffin" rel="noopener" target="_blank">net worth of more than $20 billion</a>. Technically, the two sides of Citadel (hedge fund / market maker) are split into two separate arms — but they are both under <a href="https://en.wikipedia.org/wiki/Citadel_LLC" rel="noopener" target="_blank">one parent company</a> and both arms are owned by Ken Griffin.</p>
<p>As a side note, Citadel Securities (the market marker arm) has been fined numerous times in the past, for activities such as <a href="https://www.sec.gov/news/pressrelease/2017-11.html" target="_blank" rel="noopener">“misleading customers about pricing trades”</a>, <a href="https://www.bloomberg.com/news/articles/2020-07-21/citadel-securities-fined-by-finra-for-trading-ahead-of-clients" rel="noopener" target="_blank">“trading ahead of clients”</a>, and <a href="https://www.ft.com/content/16cee174-3b7f-11ea-b232-000f4477fbca" rel="noopener" target="_blank">“trading rule violations”</a>.</p>
<p>To reiterate — Robinhood makes hundreds of millions of dollars per quarter from selling customer data to Wall Street firms such as Citadel. These firms profit off of this ‘order flow’. And Robinhood has a documented history of misleading customers about these relationships.</p>
<p>So who is Robinhood beholden to: its customer — the general public who trades on the platform — or the Wall Street firms who profit off of these trades?</p>
<p>What was that in the back? Did someone say “conflict of interest”?</p>
<p>And yes, it’s true that most other brokers also make money from PFOF, but none rely on it nearly as much as Robinhood does.</p>
<p>From <a href="https://www.morningstar.ca/ca/news/208445/robinhood-was-indeed-too-good-to-be-true.aspx" rel="noopener" target="_blank">Forbes / Morningstar</a>:</p>
<p>In the first quarter of 2020, 70% of Robinhood’s revenues derived from payments for order flows, as opposed to 17% for E-Trade and just 3% for Schwab. Yes, Robinhood has observed standard practice–but with distinctly above-average enthusiasm.</p>
<p>Enough about PFOF. Let’s get to the action of the GameStop story to see how conflict of interest plays out in a live situation.</p>

<h2>$GME and Me</h2>
<p>You’ve likely all heard this story already but I’ll …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://themeasureofaplan.com/robinhood/">https://themeasureofaplan.com/robinhood/</a></em></p>]]>
            </description>
            <link>https://themeasureofaplan.com/robinhood/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989199</guid>
            <pubDate>Mon, 01 Feb 2021 14:59:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reframing Imposter Syndrome]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989195">thread link</a>) | @staccatomeasure
<br/>
February 1, 2021 | https://staysaasy.com/leadership/2021/01/31/reframing-imposter-syndrome.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/leadership/2021/01/31/reframing-imposter-syndrome.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>For about year when I worked at a 50-person startup, the most common thought that I had was “I have no idea what I’m doing.”</p>

<p>What should we build next? How should we set up a good process for performance reviews? How do we get more people to want to buy our product? Are we shipping too many bugs? Are we overly conservative and shipping too few? Almost every day involved at least one strategic decision that I didn’t feel that I had the qualifications to make.</p>

<p>These moments could be unsettling, and in retrospect I had a classic, low-grade case of imposter syndrome. I felt like I was playing in a band and improvising while everyone else knew the music. With the benefit of hindsight and substantially more experience, I wanted to write up a few thoughts on scaling companies to reframe this imposter syndrome in a more realistic light.</p>

<h2 id="everybody-is-improvising">Everybody is Improvising</h2>

<p>As that same company grew to over 500 people, I kept waiting for the magic moment where I (or others) suddenly knew how to handle the decisions that came our way. As a 50-person company we figured things out as we went along, or made the best call we could with imperfect processes, data, and first-principles thinking. After growing over 10x larger, the problems changed, the processes and data improved, but the approach didn’t.</p>

<p>In retrospect this should have been obvious. Every company and team is different, and there is no sheet music to play from.</p>

<p>Even startups that are widely considered to be successful still need to figure stuff out the old-fashioned way:</p>

<ul>
  <li>People at all levels of the organization, including the highest-level executives, often reason from first principles. There are techniques that one can learn to be more effective; there is no manual for how to respond to any arbitrary new situation.</li>
  <li>Most decisions are made with imperfect or incomplete information.</li>
  <li>Company leadership does not have all the answers, and very smart people make both brilliant decisions and damaging strategic errors.</li>
  <li>Experienced leaders are also capable of being irrational, reacting in an emotionally driven way, or surrendering to groupthink of various forms. People struggle, question decisions that they’ve made, and generally stress out.</li>
</ul>

<p>Simply put, if you’re feeling like a fraud for needing to figure things out from first principles, know that almost everyone else is doing the same at least from time-to-time (although experienced people do tend to have a more zen attitude and realize that it’s just a part of the process). All startups are messy, and things get done by smart people making the best decisions they can with the data and resources that they have. There is no secret cabal of “grownups” who know the secret to scaling companies.</p>

<h2 id="but-experts-are-actually-better-in-some-ways">But Experts Are Actually Better In Some Ways</h2>

<p>Of course, experience is extremely beneficial. I find that there are generally two major areas in which experience matters. Neither of them should make you feel like an imposter, and neither will give you definitive answers on how you should operate your company.</p>

<p>The first important dimension is that experts have a really wide portfolio of operating techniques. To extend the music analogy, these techniques are like chords or guitar licks that you can learn and later use to improvise. It might take a while to build a repertoire, but most startup techniques are straightforward and can be learned through reading, advice, or practice. These are technical skills, not God-given talents.</p>

<p>The other area where experience is critical, is giving you reps in challenging situations. Examples include:</p>

<ul>
  <li>How do you know if you’re wasting time on something unimportant? How do you know what to half-ass vs. whole-ass?</li>
  <li>How do you handle stress over long periods of time? How do you strike a balance between optimism and realism with your team? How do you stay calm in the face of pressure? How do you know when you or someone on your team is burning out?</li>
  <li>How do you handle difficult situations? What do you do the first time someone has a personal tragedy on your team, when you have to fire someone on your team?</li>
  <li>How do you know if a struggling team member’s performance is salvageable, or if they’re unlikely to be able to turn things around?</li>
</ul>

<p>For these skills, the fact of the matter is you just need to live through a lot of situations to build strength at identifying patterns and preparing your mind for future situations. In the musical performance of a startup, these skills are like practicing until your fingers are strong and you can easily play whatever comes your way.</p>

<h2 id="takeaways">Takeaways</h2>

<p>Decision-making from first principles is the default at most companies, even successful ones. There is no sheet music for running your team or business.</p>

<p>Experience can give you more operating techniques and build the muscle required to be a good manager or leader. We try to write about these transferable techniques and perspectives. But there is no playbook that will teach you how to make the right decisions.</p>


    

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/leadership/2021/01/31/reframing-imposter-syndrome.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989195</guid>
            <pubDate>Mon, 01 Feb 2021 14:59:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You are wrong about the RISC-V SFENCE.VMA instruction]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989139">thread link</a>) | @azhenley
<br/>
February 1, 2021 | https://blog.stephenmarz.com/2021/02/01/wrong-about-sfence/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2021/02/01/wrong-about-sfence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	<!-- Custom Header -->
		
	
	
	<!--Header Info-->	
	
	<!--/End of Header Info-->
	
	<nav role="navigation">
        
    </nav>
	
		<!-- Breadcrumb Start-->
	<!--========== Breadcrumb ==========-->

<!--========== END Breadcrumb ==========-->	<!-- Breadcrumb End single.php-->
<section id="content">
    <div>
		<div>
							<div>
									<div>
						
						<div>
							
													
							<div>
								
								<div>
									
<p>This post is part of a longer OS tutorial which can be found here: <a href="https://osblog.stephenmarz.com/">https://osblog.stephenmarz.com</a></p>



<h2>Contents</h2>



<ol><li><a href="#s_introduction">Introduction</a></li><li><a href="#s_what_is_satp">What is SATP?</a></li><li><a href="#s_what_is_sfence">What is SFENCE.VMA?</a></li><li><a href="#s_what_is_happening">What is happening?</a></li><li><a href="#s_the_tlb">The Translation Lookaside Buffer</a></li><li><a href="#conclusion">Conclusion</a></li><li><a href="#references">References</a></li></ol>



<hr>



<h2 id="s_introduction">Introduction</h2>



<p>My <a href="https://blog.stephenmarz.com/2020/11/23/back-that-s-up/" data-type="post" data-id="613">last post</a> garnered some attention by those telling me that I “forgot” to execute an SFENCE.VMA after I wrote to the SATP register–some with more tact than others. This post is here to clarify why I did what I did, and to clarify what the specification actually tells us needs to be done.</p>



<hr>



<h2 id="s_what_is_satp">What is SATP?</h2>



<p>The <em>supervisor address translation and protection</em> (SATP) register is a register that tells the MMU what mode it’s in, what address space it is working in, and where to find the first level page table in RAM (this would be level 2 for Sv39).</p>



<div><figure><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/12/image-1024x76.png" alt="" width="512" height="38" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/12/image-1024x76.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/12/image-300x22.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/12/image-768x57.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/12/image-1536x114.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/12/image-2048x153.png 2048w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>The SATP Register Fields</figcaption></figure></div>



<p>The SATP register stores three pieces of information, the MODE, the address space identifier (ASID), and the physical page number (PPN).</p>



<h4>The MODE</h4>



<p>If the MODE=0, then the MMU is turned off and any address is not translated. </p>



<p>If MODE=8, we’re in Sv39 (Supervisor 39-bit) mode which means that our virtual addresses are 39-bits long.</p>



<p>There are other modes, but I won’t cover them here.</p>



<h4>The ASID</h4>



<p>The address space identifier tags translations with a unique identifier.</p>



<h4>The PPN</h4>



<p>The physical page number is the upper 44-bits of a 56-bit memory address where we can find the first level page table.</p>



<hr>



<h2 id="s_what_is_sfence">What is SFENCE.VMA?</h2>



<p>In absolute terms, this means <em>supervisor fence</em>.<em>virtual memory address</em>. In real terms, it will flush the cache’s so that the MMU will “see” the new changes in memory. This means that the MMU will be forced to look in RAM where the page tables are stored.</p>



<p>The SFENCE.VMA instruction has several different ways to execute it as shown in the specification. This should clue us in to the fact that executing SFENCE.VMA every time we write to SATP might not be so cut and dry.</p>



<hr>



<h2 id="s_what_is_happening">What is Happening?</h2>



<p>So, why is this not straightforward? The issue is that “walking” a page table–meaning going into RAM and translating a virtual address into a physical address–is not a fast process. There are multiple levels of page tables, and several 8-byte entries that need to be dereferenced by the memory controller.</p>



<p>We can speed these walks up by “caching” frequently translated addresses into a table. The table has the virtual address number and the physical address number, so translation is just a table lookup instead of dereferencing several levels of page tables.</p>



<p>This caching can be speculative. If the MMU doesn’t speculate, then the first time we translate an address, that address will not be in the TLB (the cache table) and we will get what is known as a <em>compulsory miss</em>. If we speculate, we can predict the addresses that will be used and when the memory controller isn’t doing anything else, we can load the virtual address and physical address into cache.</p>



<p>This speculation is one of the reasons for SFENCE.VMA. Another reason is due to the fact that when we translate a page using the MMU, it stores the most recent translations in the TLB as well. </p>



<hr>



<h2 id="s_the_tlb">The Translation Lookaside Buffer</h2>



<p>The translation lookaside buffer or TLB is a fancy term for the MMU cache. It stores the most recent translations to exploit <em>temporal locality</em>–that is, the chances we’re going to translate the same address near in the future is likely. So, instead of having to walk the page tables all over again, we just look in the TLB.</p>



<p>The TLB has several entries, and with RISC-V, it stores an address space identifier (ASID). The address space identifier allows the TLB to store more entries than just the most recent page table. This has always been a problem with TLBs, including with the Intel/AMD processor. Writing to its MMU register (called CR3 for control register #3) will cause a TLB flush. This is NOT the case with RISC-V writing to the SATP register (the MMU register in RISC-V).</p>



<p>The specification just gives the general rules for a manufacturer to use. Therefore, the manufacturer can choose how they want to implement their MMU and TLB as long as it complies with RISC-V’s privileged specification. Here’s a simple implementation of a TLB that complies with the privileged specification.</p>



<hr>



<h2 id="conclusion">Conclusion</h2>



<p>The RISC-V specification doesn’t make it very clear, but you can see clarification on the spec’s github repository. If the MODE is not 0, then the MMU is allowed to <em>speculate</em>, meaning it can pre-populate the MMU based on the addresses it <em>thinks</em> will need to be translated in the near future. The specification allows this, but the MMU cannot throw a page fault if a speculatory translation is invalid.</p>



<p>So, bottom line — SFENCE.VMA should NOT be called every time SATP is changed. This will cause TLB thrashing since every time you context switch, you will need to change the SATP register to the kernel page table, schedule, then change the SATP register to the new scheduled process’ page table.</p>



<p>Instead, the SFENCE.VMA instruction should be invoked when one or more of the following occur:</p>



<ol><li>When software recycles an ASID (i.e., reassociates it with a different page table), it should first change satp to point to the new page table using the recycled ASID, then execute SFENCE.VMA with rs1=x0 and rs2 set to the recycled ASID. Alternatively, software can execute the same SFENCE.VMA instruction while a different ASID is loaded into satp, provided the next time satp is loaded with the recycled ASID, it is simultaneously loaded with the new page table.</li><li>If the implementation does not provide ASIDs, or software chooses to always use ASID 0, then after every satp write, software should execute SFENCE.VMA with rs1=x0. In the common case that no global translations have been modified, rs2 should be set to a register other than x0 but which contains the value zero, so that global translations are not flushed.</li><li>If software modifies a non-leaf PTE, it should execute SFENCE.VMA with rs1=x0. If any PTE along the traversal path had its G bit set, rs2 must be x0; otherwise, rs2 should be set to the ASID for which the translation is being modified.</li><li>If software modifies a leaf PTE, it should execute SFENCE.VMA with rs1 set to a virtual address within the page. If any PTE along the traversal path had its G bit set, rs2 must be x0; otherwise, rs2 should be set to the ASID for which the translation is being modified.</li><li>For the special cases of increasing the permissions on a leaf PTE and changing an invalid PTE to a valid leaf, software may choose to execute the SFENCE.VMA lazily. After modifying the PTE but before executing SFENCE.VMA, either the new or old permissions will be used. In the latter case, a page fault exception might occur, at which point software should execute SFENCE.VMA in accordance with the previous bullet point.</li></ol>



<p>Unfortunately, you have to dig through the issues and updates to the specification on GitHub to find out some of this information. I have provided links in references below.</p>



<hr>



<h2 id="references">References</h2>



<ul><li><a href="https://github.com/riscv/riscv-isa-manual/issues/226">SFENCE.VMA Before or After SATP Write · Issue #226 · riscv/riscv-isa-manual (github.com)</a></li><li><a href="https://github.com/riscv/riscv-isa-manual/issues/538">Can cached translations be visible when translation is off? · Issue #538 · riscv/riscv-isa-manual (github.com)</a></li><li><a href="https://github.com/riscv/riscv-isa-manual/commit/4a29140ef57e38532b3d3e43c9cd49e07066e7e0">PMP changes need an SFENCE when VM is enabled · riscv/riscv-isa-manual@4a29140 (github.com)</a></li><li><a href="https://github.com/riscv/riscv-isa-manual/issues/9">Reconsider SFENCE.VM/ASIDs · Issue #9 · riscv/riscv-isa-manual (github.com)</a></li></ul>
								</div>
							</div>
						</div>
							
				</div>
			</div>
			
		</div><!--/.row-->
	</div> <!--/.container-->
</section>

<!-- Footer Widget Secton -->
   <!--start footer-->
	    
		<hr>
				
		
	</div></div>]]>
            </description>
            <link>https://blog.stephenmarz.com/2021/02/01/wrong-about-sfence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989139</guid>
            <pubDate>Mon, 01 Feb 2021 14:53:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dealing with poor rendering performance using will-change CSS property]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989090">thread link</a>) | @fullstackwife
<br/>
February 1, 2021 | https://spartez-software.com/blog/2021/02/01/analysis-of-rendering-performance-issues-in-whiteboards | <a href="https://web.archive.org/web/*/https://spartez-software.com/blog/2021/02/01/analysis-of-rendering-performance-issues-in-whiteboards">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        <main id="page-content">
            
<section>
    <p><img src="https://spartez-software.com/assets/people/spartans560-2379.jpg" alt="Grzegorz Tańczyk">
        
    
    <time>Feb 1st, 2021</time>
</p>

    
</section>
<section>
    <div>
        <div>
            <article>
                                    <div>
                                                <div>
    <p><a href="https://spartez-software.com/products/whiteboards-for-jira">Whiteboards</a> is a real-time application designed for people who want to collaborate on visual elements like shapes, lines, images, or drawings, for managing their work, supporting an online meeting, or drawing diagrams.
</p>

<p>There are several challenges connected to this objective across the entire stack. Client-side performance is one of them.
</p>



<h2>How to implement real-time collaboration canvas</h2>

<p><span></span>Before we start digging into specifics of Whiteboards, let's have a look at the landscape of possible ways of implementing a collaboration canvas:
</p>

<ul>
<li>Native application</li>
<li>Web application
<ul>
<li>HTML5 Canvas API</li>
<li>SVG</li>
<li>DOM-based</li>
<li><strong>Hybrid of DOM, SVG, and HTML5 Canvas API</strong></li>
</ul></li>
</ul>

<p>Whiteboards are going the last way, as it allows us to maintain rapid development pace, good maintainability, better accessibility and interactions, and what’s most important in case of performance: leveraging existing tools and optimizations of web browser engines.
</p>

<p><img src="https://spartez-software.com/assets/traditional-setup-2-(1).png" alt="Online Collaboration on Whiteboards" width="760" height="429"><br>
</p>

<h2>Detecting performance issues</h2>

<p><span></span>A problem can be discovered either with synthetic tests or through user feedback. While we would love to avoid the latter method, because it means dissatisfaction with the product, sometimes it’s the only way to discover unusual combinations of content and the environment.
</p>

<p>Rendering performance can be expressed in an industry-standard metric: <strong>frame rate</strong>, which means how often the content is painted on the screen within one second. High frame rate means:
</p>

<ul>
<li>smooth interactions, unnoticeable delay between user action, and visual feedback;</li>
<li>low consumption of resources: memory, GPU, CPU, and what’s most important: the battery.</li>
</ul>

<p>Web applications rarely function in a vacuum and need to compete for resources with other processes. For Whiteboards, it’s a common situation to fight for CPU with Zoom or Google Meet. <br>End users especially at work usually don’t have top-notch computers, which means not enough memory, no dedicated GPU, and not so modern CPU.
</p>

<p>That’s why it’s important to keep our performance footprint as low as possible.
</p>

<p>Let’s start from customer feedback:
</p>

<blockquote><strong>"performance </strong>- using the whiteboard at train level (80+ users), the tool shows poor performance in terms of reactivity: moving a block can result in a real shift of the element with a delay in time of 3 to 5 seconds. Our need is to use the whiteboard managing together up to 7 agile teams planning 5 sprint each one, plus dependencies board all in the same physical whiteboard"
</blockquote>

<p>Our tool is designed to work fine at such a scale, so it was disappointing to learn that we failed to deliver on this promise. Keeping emotions aside, we should start from the decomposition of the problem into facts:
</p>

<ul>
<li>80 users → 7 teams → 5 sprints each → ~10 issues per sprint + companioning content → more than 100 visual elements on the screen → some of them moving all the time including cursors;</li>
</ul>

<p>Our assumptions, and guiding principles:
</p>

<ul>
<li>elements that are not visible in the viewport should not affect performance and responsiveness;</li>
<li>interactions such as zooming, scrolling, modifying elements should be smooth regardless of the number of elements visible on the screen. </li>
</ul>

<h2>Creating a test environment</h2>

<p><br>The problem can occur for many reasons: networking, server-side performance, application state management, style recalculations, layout, or rendering performance. In this blog post and during the analysis exercise I’m focusing on the last problem: rendering, which is the most expensive part of the page display pipeline:
</p>

<p><img src="https://spartez-software.com/assets/image-20210131-113850.png" alt="Page Display Pipeline" width="944" height="144"><sup>                                                                                                                                                                                      Source: </sup><a href="https://developers.google.com/web/fundamentals/performance/rendering/simplify-paint-complexity-and-reduce-paint-areas" title="https://developers.google.com/web/fundamentals/performance/rendering/simplify-paint-complexity-and-reduce-paint-areas" data-renderer-mark="true"><sup>developers.google.com</sup></a><sup>, licensed under the </sup><sup><a href="https://creativecommons.org/licenses/by/4.0/" title="https://creativecommons.org/licenses/by/4.0/" data-renderer-mark="true">Creative Commons Attribution 4.0 License</a></sup>
</p>





<p>My test environment consists of 350 elements, cards, lines, shapes, and drawings of various sizes layout and content:
</p>

<p><img src="https://spartez-software.com/assets/image-20210131-104417.png" alt="Whiteboards Test Environment" width="935" height="542">
</p>

<p>It does not seem to be a lot of content, so let’s jump into the basic testing procedure.
</p>



<h2>Collecting performance metric</h2>

<p><span></span>My performance smoke test procedure is straightforward: zoom in/zoom out, scroll around. That’s what a user would do as well, and my goal is to have those interactions as smooth as possible. Fortunately, I quickly notice a problem: zooming seems to be clunky. I’m not fully confident about scrolling performance either:
</p>

</div>

                    </div>
                                    <div>
                                                    <p>
        <iframe src="https://www.youtube.com/embed/hoQbwgzrAEA?rel=0&amp;showinfo=0" frameborder="0" allowfullscreen="" data-track="embed-video-iframe"></iframe>
    </p>

                    </div>
                                    <div>
                                                <div>
    

<p>This is additionally embarrassing as it did not require creating enormous test data set to notice the problem, so the likelihood of noticing this issue as an end-user is very high.
</p>

<p>Having this observation I can jump into metrics:
</p>

<h3>CPU/GPU/Memory</h3>



</div>

                    </div>
                                    <div>
                                                    <h2>Scrolling</h2>
                                                    <p>
        <iframe src="https://www.youtube.com/embed/aL7JYY4ahpg?rel=0&amp;showinfo=0" frameborder="0" allowfullscreen="" data-track="embed-video-iframe"></iframe>
    </p>

                    </div>
                                    <div>
                                                    <h2>Zooming</h2>
                                                    <p>
        <iframe src="https://www.youtube.com/embed/JEaBiAFAF6Q?rel=0&amp;showinfo=0" frameborder="0" allowfullscreen="" data-track="embed-video-iframe"></iframe>
    </p>

                    </div>
                                    <div>
                                                <div>
    

<p>Looks like a problem as CPU usage goes up unexpectedly high.
</p>

<h3>Frame rate</h3>

<p><span></span>It is possible to measure the frame rate in at least two ways:
</p>

<ul>
<li>Inside the application itself using the requestAnimationFrame function, which is supposed to execute the callback once the browser is ready for the next paint;</li>
<li>Using browser dev tools.</li>
</ul>

<p>This measurement is supposed to confirm my prior observations, it will not reveal new problems.
</p>

<p>I’m using both tools actually:
</p>

<ol>
<li>Whiteboards mini-devtools show ~12 FPS</li>
<li>Chrome frame rendering stats highlight lots of frames dropped</li>
</ol>

<p>Both facts mean that the browser was not able to render all frames on time, so scrolling/zooming with mouse or touchpad did not result in visual feedback.
</p>

</div>

                    </div>
                                    <div>
                                                    <p>
        <iframe src="https://www.youtube.com/embed/_QAfo9On_c0?rel=0&amp;showinfo=0" frameborder="0" allowfullscreen="" data-track="embed-video-iframe"></iframe>
    </p>

                    </div>
                                    <div>
                                                <div>
    

<h3>Paint flashing</h3>

<p><span></span>Using my prior experience, I immediately switched to <a href="https://developers.google.com/web/fundamentals/performance/rendering/simplify-paint-complexity-and-reduce-paint-areas#use_chrome_devtools_to_quickly_identify_paint_bottlenecks">this handy tool</a> useful for analyzing what is being rendered by the browser. While hovering over various elements, I can see that they are being repainted:
</p>

</div>

                    </div>
                                    <div>
                                                    <p>
        <iframe src="https://www.youtube.com/embed/v8Bd9JrVZ7o?rel=0&amp;showinfo=0" frameborder="0" allowfullscreen="" data-track="embed-video-iframe"></iframe>
    </p>

                    </div>
                                    <div>
                                                <div>
    

<p>This is expected - on hover, the application is adjusting the element so it is ready for interaction. There is no performance problem here.
</p>

<p>I can see the actual problem when zooming or scrolling. Pretty much everything is repainted:
</p>

<p><img src="https://spartez-software.com/assets/image-20210131-111213.png" alt="" width="979" height="462"><br>
</p>



<h2>Background grid seems to be a problem</h2>

<p>The grid is supposed to show lines accordingly to the current zoom, and viewport position, so that the content feels attached to space.
</p>

<p>It seemed to be a perfect suspect: grid is a html5 canvas, re-rendered accordingly to zoom/scroll on each frame, however disabling it did not improve the situation.
</p>

<p> <a href="https://spartez-software.com/products/whiteboards-for-jira">Whiteboard</a> content is still repainted:
</p>

<p><img src="https://spartez-software.com/assets/image-20210131-111615.png" alt="Background grid problem in Whiteboards" width="979" height="463"><br>
</p>

<h2>Common sense: you should not re-render content if it did not change</h2>

<p>It is reasonable to expect from browser to render Whiteboards at a low cost, because in the end, this is just a website, quite lightweight compared to sites you usually visit, that are filled with rich content, images, videos, animations, ads, trackers, social media scripts, etc.
</p>

<p><img src="https://spartez-software.com/assets/image-20210131-112127.png" alt="" width="470" height="470"><br>
</p>

<p>This is the browser's responsibility to render such content in the most effective way. We don’t want to implement our own rendering engine, the Chromium team at Google has much more expertise than we will ever get. This is also not our business objective.
</p>

<p>Whiteboards client is a React application, and from an application state management perspective - everything seemed to be fine. The only property that was changed during the interaction was CSS <strong>transform</strong> on the container element, so we expected everything to work fine - yet it did not!
</p>



<h2>The solution</h2>

<p><span></span>It would take a whole new blog post to explain the solution. Fortunately, I can simply drop <a href="https://developers.google.com/web/fundamentals/performance/rendering/simplify-paint-complexity-and-reduce-paint-areas">a link here</a>:
</p>

<p>Long story short:
</p>

<ul>
<li>the problem was managed with <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/will-change" title="https://developer.mozilla.org/en-US/docs/Web/CSS/will-change" data-renderer-mark="true"><strong>will-change</strong> CSS property</a>;</li>
<li>it creates temporary visual artifacts when zooming;</li>
<li>background grid must be refactored so that literally nothing will be painted during scroll/zoom.</li>
</ul>

</div>

                    </div>
                                    <div>
                                                    <p>
        <iframe src="https://www.youtube.com/embed/PZJM1Nj-CRY?rel=0&amp;showinfo=0" frameborder="0" allowfullscreen="" data-track="embed-video-iframe"></iframe>
    </p>

                    </div>
                                    <div>
                                                <div>
    

<p>This solution was developed a long time ago (6 months before this blog post), but it did not go live, because of the visual artifacts.
</p>

<p>Fortunately, as of February 2021, the browser rendering engine seems to be improved, and our problems are gone, so we will be enabling it shortly.
</p>

<p>Thanks for reading and have happy scrolling!
</p>

</div>

                    </div>
                
            </article>
        </div>
    </div>
    </section>
    
</main></div></div>]]>
            </description>
            <link>https://spartez-software.com/blog/2021/02/01/analysis-of-rendering-performance-issues-in-whiteboards</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989090</guid>
            <pubDate>Mon, 01 Feb 2021 14:45:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teachers’ Guide to Cranky Uncle]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989015">thread link</a>) | @ericdanielski
<br/>
February 1, 2021 | https://crankyuncle.com/teachers-guide-to-cranky-uncle/ | <a href="https://web.archive.org/web/*/https://crankyuncle.com/teachers-guide-to-cranky-uncle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
	
	<div role="document">

	<div id="content">
	<div itemscope="" itemtype="https://schema.org/BlogPosting">
		<div role="main">
					<article>
			<div><a href="https://crankyuncle.com/wp-content/uploads/2021/01/feature_cover.jpg" data-rel="lightbox" itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject"><img src="https://crankyuncle.com/wp-content/uploads/2021/01/feature_cover.jpg" width="770" height="400" srcset="https://crankyuncle.com/wp-content/uploads/2021/01/feature_cover.jpg 770w, https://crankyuncle.com/wp-content/uploads/2021/01/feature_cover-300x156.jpg 300w, https://crankyuncle.com/wp-content/uploads/2021/01/feature_cover-768x399.jpg 768w" sizes="(max-width: 770px) 100vw, 770px" alt=""><meta itemprop="url" content="https://crankyuncle.com/wp-content/uploads/2021/01/feature_cover.jpg"><meta itemprop="width" content="770"><meta itemprop="height" content="400"></a></div>				<header>

								
				</header>

				<div itemprop="articleBody">
					
<p><a href="http://crankyuncle.com/wp-content/uploads/2021/01/Cranky_Teachers_Guide_v1.pdf">The Teachers’ Guide to Cranky Uncle</a> offers background information and classroom activity ideas for educators interested in using the Cranky Uncle game to teach critical thinking in their classes.</p>



<div><figure><a href="http://crankyuncle.com/wp-content/uploads/2021/01/Cranky_Teachers_Guide_v1.pdf"><img loading="lazy" src="https://crankyuncle.com/wp-content/uploads/2021/01/cover_US_letter-791x1024.png" alt="" width="396" height="512" srcset="https://crankyuncle.com/wp-content/uploads/2021/01/cover_US_letter-791x1024.png 791w, https://crankyuncle.com/wp-content/uploads/2021/01/cover_US_letter-232x300.png 232w, https://crankyuncle.com/wp-content/uploads/2021/01/cover_US_letter-768x994.png 768w, https://crankyuncle.com/wp-content/uploads/2021/01/cover_US_letter-1187x1536.png 1187w, https://crankyuncle.com/wp-content/uploads/2021/01/cover_US_letter.png 1200w" sizes="(max-width: 396px) 100vw, 396px"></a></figure></div>



<p>For teachers interested in using the Cranky Uncle game in their classes, here are the steps to get started:</p>



<ol><li><strong><a href="http://sks.to/crankyclass">Register to get a group code</a>.</strong> I need a few details about your class in order to email you group code/s.</li><li><strong>Receive your group codes by email.</strong> I will get back to you asap with group codes (note that they’re case sensitive).</li><li><strong>Download the game.</strong> There are three ways that your students can access the game:<ol><li>iPhone: <a href="https://sks.to/crankyiphone">https://sks.to/crankyiphone</a></li><li>Android: <a href="https://sks.to/crankyandroid">https://sks.to/crankyandroid</a></li><li>Browser: <a href="https://app.crankyuncle.info/">https://app.crankyuncle.info</a></li></ol></li><li><strong>Research instructions.</strong> Student can voluntarily take part in research – this helps us assess the effectiveness of the game. No identifying info is collected so it is completely anonymous. To participate:<ol><li>If your students are younger than 18, distribute this <a href="https://sks.to/infosheet">Research Information Sheet</a> to your students’ parents (it informs the parents of the research and that the students can opt out any time they like).</li><li>Students check the two consent boxes when the game first starts, then select YES when asked if they want to take part in the research.</li><li>They then fill out a 10-question survey before the game starts.</li><li>Once they’ve completed all the denial techniques, they’ll be asked to fill out another 10-question survey. Once that’s completed, that’s it!</li><li>Note that students can opt-out of the research at any point – they can edit their consent settings via the About screen.</li></ol></li></ol>



<p>I’m keen to hear from teachers who have used the game in their classes. I’ve already been impressed by the creative ways that critical thinking is being taught in the classroom, hence the Teachers’ Guide already has a number of suggested activities. Keen to hear about other creative approaches and how your students responded to the game…</p>
				</div>

				
			</article>
				<!-- /#comments -->

	<section id="respond">
		<!-- #respond -->
		
		</section><!-- /#respond -->
		</div>
		<!-- /aside -->
			</div><!-- /.row-->
		</div><!-- /.content -->
	</div><!-- /.wrap -->
	

		</div></div>]]>
            </description>
            <link>https://crankyuncle.com/teachers-guide-to-cranky-uncle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989015</guid>
            <pubDate>Mon, 01 Feb 2021 14:35:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An unexpected find that freed 20GB of unused index space in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 356 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25988871">thread link</a>) | @haki
<br/>
February 1, 2021 | https://hakibenita.com/postgresql-unused-index-size | <a href="https://web.archive.org/web/*/https://hakibenita.com/postgresql-unused-index-size">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-progress-indicator="">
        <hr>
<p>Every few months we get an alert from our database monitoring to warn us that we are about to run out of space. Usually we just provision more storage and forget about it, but this time we were under quarantine, and the system in question was under less load than usual. We thought this is a good opportunity to do some cleanups that would otherwise be much more challenging.</p>
<p>To start from the end, <strong>we ended up freeing more than 70GB of un-optimized and un-utilized space</strong> without dropping a single index or deleting any data!</p>
<p>Using conventional technics such as rebuilding indexes and tables we cleared up a lot of space, but then <strong>one surprising find helped us clear an additional ~20GB of unused indexed values!</strong></p>
<p>This is what the free storage chart of one of our databases looked like in the process:</p>
<figure><img alt="Free space over time (higher means more free space)" src="https://hakibenita.com/images/00-postgresql-unused-index-size.png"><figcaption>Free space over time (higher means more free space)</figcaption>
</figure>
<details open="">
    <summary>Table of Contents</summary>

</details>
<hr>
<h2 id="the-usual-suspects"><a href="#the-usual-suspects">The Usual Suspects</a></h2>
<p>Provisioning storage is something we do from time to time, but before we throw money at the problem we like to make sure we make good use of the storage we already have. To do that, we start with the usual suspects.</p>
<h3 id="unused-indexes"><a href="#unused-indexes">Unused Indexes</a></h3>
<p>Unused indexes are double-edged swords; you create them to make things faster, but they end up taking space and slow inserts and updates. Unused indexes are the first thing we always check when we need to clear up storage.</p>
<p>To find unused indexes we use the following query:</p>
<div><pre><span></span><span>SELECT</span>
    <span>relname</span><span>,</span>
    <span>indexrelname</span><span>,</span>
    <span>idx_scan</span><span>,</span>
    <span>idx_tup_read</span><span>,</span>
    <span>idx_tup_fetch</span><span>,</span>
    <span>pg_size_pretty</span><span>(</span><span>pg_relation_size</span><span>(</span><span>indexrelname</span><span>::</span><span>regclass</span><span>))</span> <span>as</span> <span>size</span>
<span>FROM</span>
    <span>pg_stat_all_indexes</span>
<span>WHERE</span>
    <span>schemaname</span> <span>=</span> <span>'public'</span>
    <span>AND</span> <span>indexrelname</span> <span>NOT</span> <span>LIKE</span> <span>'pg_toast_%'</span>
<span>    <span>AND</span> <span>idx_scan</span> <span>=</span> <span>0</span>
</span><span>    <span>AND</span> <span>idx_tup_read</span> <span>=</span> <span>0</span>
</span><span>    <span>AND</span> <span>idx_tup_fetch</span> <span>=</span> <span>0</span>
</span><span>ORDER</span> <span>BY</span>
    <span>pg_relation_size</span><span>(</span><span>indexrelname</span><span>::</span><span>regclass</span><span>)</span> <span>DESC</span><span>;</span>
</pre></div>


<p>The query is looking for <strong>indexes that were not scanned or fetched</strong> since the last time the statistics were reset.</p>
<p>Some indexes may seem like they were not used but they were in-fact used:</p>
<ul>
<li>
<p><a href="https://www.postgresql.org/docs/current/monitoring-stats.html#MONITORING-PG-STAT-ALL-INDEXES-VIEW" rel="noopener">The documentation</a> lists a few scenarios when this is possible. For example, when the optimizer uses meta data from the index, but not the index itself.</p>
</li>
<li>
<p>Indexes used to enforce unique or primary key constraints for tables that were not updated in a while. The indexes will look like they were not used, but it doesn't mean we can dispose of them.</p>
</li>
</ul>
<p>The find the unused indexes you can actually drop, you usually have to go over the list one by one and make a decision. This can be time consuming in the first couple of times, but after you get rid of most unused indexes it becomes easier.</p>
<p>It's also a good idea to <strong>reset the statistics counters from time to time</strong>, usually right after you finished inspecting the list. PostgreSQL provides a few <a href="https://www.postgresql.org/docs/current/monitoring-stats.html#MONITORING-STATS-FUNCS-TABLE" rel="noopener">functions to reset statistics</a> at different levels. When we find an index we suspect is not being used, or when we add new indexes in place of old ones, we usually reset the counters for the table and wait for a while:</p>
<div><pre><span></span><span>-- Find table oid by name</span>
<span>SELECT</span> <span>oid</span> <span>FROM</span> <span>pg_class</span> <span>c</span> <span>WHERE</span> <span>relname</span> <span>=</span> <span>'table_name'</span><span>;</span>
<span>-- Reset counts for all indexes of table</span>
<span>SELECT</span> <span>pg_stat_reset_single_table_counters</span><span>(</span><span>14662536</span><span>);</span>
</pre></div>


<p>We do this every once in a while, so in our case there were no unused indexes to drop.</p>
<h3 id="index-and-table-bloat"><a href="#index-and-table-bloat">Index and Table Bloat</a></h3>
<p>The next suspect is bloat. When you update rows in a table, PostgreSQL marks the tuple as dead and adds the updated tuple in the next available space. This process creates what's called "bloat", which can cause tables to consume more space than they really need. Bloat also affects indexes, so to free up space, bloat is a good place to look.</p>
<p>Estimating bloat in tables and indexes is apparently not a simple task. Lucky for us, some good people on the world wide web already <a href="https://wiki.postgresql.org/wiki/Show_database_bloat" rel="noopener">did the hard work</a> and wrote queries to estimate <a href="https://github.com/ioguix/pgsql-bloat-estimation/blob/master/table/table_bloat.sql" rel="noopener">table bloat</a> and <a href="https://github.com/ioguix/pgsql-bloat-estimation/blob/master/btree/btree_bloat.sql" rel="noopener">index bloat</a>. After running these queries you will most likely find <em>some</em> bloat, so the next thing to do it clear up that space.</p>
<h4 id="clearing-bloat-in-indexes"><a href="#clearing-bloat-in-indexes">Clearing Bloat in Indexes</a></h4>
<p>To clear bloat in an index, you need to rebuild it. There are several ways to rebuild an index:</p>
<ol>
<li>
<p><strong>Re-create the index</strong>: If you re-create the index, it will be built in an optimal way.</p>
</li>
<li>
<p><strong>Rebuild the index</strong>: Instead of dropping and creating the index yourself, PostgreSQL provides a way to re-build an existing index in-place using the <a href="https://www.postgresql.org/docs/current/sql-reindex.html" rel="noopener"><code>REINDEX</code></a> command:</p>
</li>
</ol>
<div><pre><span></span><span>REINDEX</span> <span>INDEX</span> <span>index_name</span><span>;</span>
</pre></div>


<ol>
<li><strong>Rebuild the index concurrently</strong>: The previous methods will obtain a lock on the table and prevent it from being changed while the operation is in progress, which is usually unacceptable. To rebuild the index without locking it for updates, you can <a href="https://www.postgresql.org/docs/current/sql-reindex.html#SQL-REINDEX-CONCURRENTLY" rel="noopener">rebuilt the index concurrently</a>:</li>
</ol>
<div><pre><span></span><span>REINDEX</span> <span>INDEX</span> <span>CONCURRENTLY</span> <span>index_name</span><span>;</span>
</pre></div>


<p>When using <code>REINDEX CONCURRENTLY</code>, PostgreSQL creates a new index with a name suffixed with <code>_ccnew</code>, and syncs any changes made to the table in the meantime. When the rebuild is done, it will switch the old index with the new index, and drop the old one.</p>
<figure>
<figcaption>Clearing bloat in Indexes</figcaption>
</figure>
<p>If for some reason you had to stop the rebuild in the middle, the new index will not be dropped. Instead, it will be left in an invalid state and consume space. To identify invalid indexes that were created during <code>REINDEX</code>, we use the following query:</p>
<div><pre><span></span><span>-- Identify invalid indexes that were created during index rebuild</span>
<span>SELECT</span>
    <span>c</span><span>.</span><span>relname</span> <span>as</span> <span>index_name</span><span>,</span>
    <span>pg_size_pretty</span><span>(</span><span>pg_relation_size</span><span>(</span><span>c</span><span>.</span><span>oid</span><span>))</span>
<span>FROM</span>
    <span>pg_index</span> <span>i</span>
    <span>JOIN</span> <span>pg_class</span> <span>c</span> <span>ON</span> <span>i</span><span>.</span><span>indexrelid</span> <span>=</span> <span>c</span><span>.</span><span>oid</span>
<span>WHERE</span>
    <span>-- New index built using REINDEX CONCURRENTLY</span>
    <span>c</span><span>.</span><span>relname</span> <span>LIKE</span>  <span>'%_ccnew'</span>
    <span>-- In INVALID state</span>
    <span>AND</span> <span>NOT</span> <span>indisvalid</span>
<span>LIMIT</span> <span>10</span><span>;</span>
</pre></div>


<p>Once the rebuild process is no longer active, it should be safe to drop any remaining invalid indexes.</p>
<h4 id="activating-b-tree-index-deduplication"><a href="#activating-b-tree-index-deduplication">Activating B-Tree Index Deduplication</a></h4>
<p>PostgreSQL 13 introduced a new efficient way of storing duplicate values in B-Tree indexes called <a href="https://www.postgresql.org/docs/current/btree-implementation.html#BTREE-DEDUPLICATION" rel="noopener">"B-Tree Deduplication"</a>.</p>
<p>For each indexed value, a B-Tree index will hold in its leaf both the value and a pointer to the row (TID). The larger the indexed values, the larger the index. Up until PostgreSQL 12, when the index contained many duplicate values, all of these duplicate values would be stored in the index leaves. This is not very efficient and can take up a lot of space.</p>
<figure>
<figcaption>B-Tree Index Deduplication</figcaption>
</figure>
<p>Starting at PostgreSQL 13, when B-Tree deduplication is activated, duplicate values are only stored once. This can make a huge impact on the size of indexes with many duplicate values.</p>
<p>In PostgreSQL 13 index deduplication in enabled by default, unless you deactivate it:</p>
<div><pre><span></span><span>-- Activating de-deduplication for a B-Tree index, this is the default:</span>
<span>CREATE</span> <span>INDEX</span> <span>index_name</span> <span>ON</span> <span>table_name</span><span>(</span><span>column_name</span><span>)</span> <span>WITH</span> <span>(</span><span>deduplicate_items</span> <span>=</span> <span>ON</span><span>)</span>
</pre></div>


<p>If you are migrating from PostgreSQL versions prior to 13, you need to rebuild the indexes using the <code>REINDEX</code> command in order to get the full benefits of index de-deduplication.</p>
<p>To illustrate the effect of B-Tree deduplication on the size of the index, create a table with a unique column and a non unique column, and populate it with 1M rows. On each column create two B-Tree indexes, one with deduplication enabled and another with deduplication disabled:</p>
<div><pre><span></span><span>db</span><span>=#</span> <span>CREATE</span> <span>test_btree_dedup</span> <span>(</span><span>n_unique</span> <span>serial</span><span>,</span> <span>n_not_unique</span> <span>integer</span><span>);</span>
<span>CREATE</span> <span>TABLE</span>

<span>db</span><span>=#</span> <span>INSERT</span> <span>INTO</span> <span>test_btree_dedup</span> <span>(</span><span>n_not_unique</span><span>)</span>
<span>SELECT</span> <span>(</span><span>random</span><span>()</span> <span>*</span> <span>100</span><span>)::</span><span>int</span> <span>FROM</span> <span>generate_series</span><span>(</span><span>1</span><span>,</span> <span>1000000</span><span>);</span>
<span>INSERT</span> <span>0</span> <span>1000000</span>

<span>db</span><span>=#</span> <span>CREATE</span> <span>INDEX</span> <span>ix1</span> <span>ON</span> <span>test_btree_dedup</span> <span>(</span><span>n_unique</span><span>)</span>     <span>WITH</span> <span>(</span><span>deduplicate_items</span> <span>=</span> <span>OFF</span><span>);</span>
<span>CREATE</span> <span>INDEX</span>

<span>db</span><span>=#</span> <span>CREATE</span> <span>INDEX</span> <span>ix2</span> <span>ON</span> <span>test_btree_dedup</span> <span>(</span><span>n_unique</span><span>)</span>     <span>WITH</span> <span>(</span><span>deduplicate_items</span> <span>=</span> <span>ON</span><span>);</span>
<span>CREATE</span> <span>INDEX</span>

<span>db</span><span>=#</span> <span>CREATE</span> <span>INDEX</span> <span>ix3</span> <span>ON</span> <span>test_btree_dedup</span> <span>(</span><span>n_not_unique</span><span>)</span> <span>WITH</span> <span>(</span><span>deduplicate_items</span> <span>=</span> <span>OFF</span><span>);</span>
<span>CREATE</span> <span>INDEX</span>

<span>db</span><span>=#</span> <span>CREATE</span> <span>INDEX</span> <span>ix4</span> <span>ON</span> <span>test_btree_dedup</span> <span>(</span><span>n_not_unique</span><span>)</span> <span>WITH</span> <span>(</span><span>deduplicate_items</span> <span>=</span> <span>ON</span><span>);</span>
<span>CREATE</span> <span>INDEX</span>
</pre></div>


<p>Next, compare the sizes of the four indexes:</p>
<table>
<thead>
<tr>
<th>Column</th>
<th>Deduplication</th>
<th>Size</th>
</tr>
</thead>
<tbody>
<tr>
<td>Not unique</td>
<td>Yes</td>
<td>6840 kB</td>
</tr>
<tr>
<td>Not unique</td>
<td>No</td>
<td>21 MB</td>
</tr>
<tr>
<td>Unique</td>
<td>Yes</td>
<td>21 MB</td>
</tr>
<tr>
<td>Unique</td>
<td>No</td>
<td>21 MB</td>
</tr>
</tbody>
</table>
<p>As expected, deduplication had no effect on the unique index, but it had a significant effect on the index that had many duplicate values.</p>
<p>Unfortunately for us, PostgreSQL 13 was still fresh at the time, and our cloud provider did not have support for it yet, so we were unable to use deduplication to clear space.</p>
<h4 id="clearing-bloat-in-tables"><a href="#clearing-bloat-in-tables">Clearing Bloat in Tables</a></h4>
<p>Just like in indexes, tables can also contain dead tuples that cause bloat and fragmentation. However, unlike indexes that contain data from an associated table, a table can not just simply be re-created. To re-create a table you would have to create a new table, migrate the data over while keeping it synced with new data, create all the indexes, constraints and any referential constraints in other tables. Only after all of this is done, you can switch the old table with the new one.</p>
<figure>
<figcaption>Clearing bloat in Tables</figcaption>
</figure>
<p>There are several ways to rebuild a table and reduce bloat:</p>
<ol>
<li>
<p><strong>Re-create the table</strong>: Using this method as described above often requires a lot of development, especially if the table is actively being used as it's being rebuilt.</p>
</li>
<li>
<p><strong>Vacuum the table</strong>: PostgreSQL provides a way to reclaim space occupied by bloat and dead tuples in a table using the <a href="https://www.postgresql.org/docs/current/sql-vacuum.html" rel="noopener"><code>VACUUM FULL</code> command</a>. Vacuum full requires a lock on the table, and is not an ideal solution for tables that need to be available while being vacuumed:</p>
</li>
</ol>
<div><pre><span></span><span>-- Will lock the table</span>
<span>VACUUM</span> <span>FULL</span> <span>table_name</span><span>;</span>
</pre></div>


<p>The two options above require either a significant effort, or some down time.</p>
<h4 id="using-pg_repack"><a href="#using-pg_repack">Using pg_repack</a></h4>
<p>Both built-in options for rebuilding tables are not ideal unless you can afford downtime. One popular solution for rebuilding tables and indexes without downtime is the <a href="https://reorg.github.io/pg_repack/" rel="noopener">pg_repack extension</a>.</p>
<p>Being a popular extension, <code>pg_repack</code> is likely available from your package manager or already installed by your cloud provider. To use <code>pg_repack</code>, you first need to create the extension:</p>
<div><pre><span></span><span>CREATE</span> <span>EXTENSION</span> <span>pg_repack</span><span>;</span>
</pre></div>


<p>To "repack" a table along with its indexes, issue the following command from the console:</p>
<div><pre><span></span><span>$</span> pg_repack -k --table table_name db_name
</pre></div>


<p>To rebuild a table with no downtime, the extension creates a new table, loads the data from the original table into it while keeping it …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hakibenita.com/postgresql-unused-index-size">https://hakibenita.com/postgresql-unused-index-size</a></em></p>]]>
            </description>
            <link>https://hakibenita.com/postgresql-unused-index-size</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988871</guid>
            <pubDate>Mon, 01 Feb 2021 14:17:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Different Ways to Filter Containers in Modern C++]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988749">thread link</a>) | @joebaf
<br/>
February 1, 2021 | https://www.cppstories.com/2021/filter-cpp-containers/ | <a href="https://web.archive.org/web/*/https://www.cppstories.com/2021/filter-cpp-containers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img src="https://www.cppstories.com/2021/images/filter.png" alt=""></p>  
          
        

<p>Do you know how many ways we can implement a filter function in C++?</p>

<p>While the problem is relatively easy to understand - take a container, copy elements that match a predicate and the return a new container - it’s good to exercise with the Standard Library and check a few ideas. We can also apply some Modern C++ techniques.</p>

<p>Let’s start!</p>

<h2 id="the-problem-statement">The Problem Statement</h2>

<p>To be precise by <em>filter</em> I mean a function with the following interface:</p>

<pre><code>auto Filter(const Container&amp; cont, UnaryPredicate p) {}
</code></pre>

<p>It takes a container and a predicate, and then it creates an output container with elements that satisfies the predicate.</p>

<p>We can use it like the following:</p>

<pre><code>const std::vector&lt;std::string&gt; vec{ "Hello", "**txt", "World", "error", "warning", "C++", "****" };

auto filtered = FilterRaw(vec, [](auto&amp; elem) { return !elem.starts_with('*'); });
// filtered should have "Hello", "World", "error", "warning", "C++"
</code></pre>

<p>Additionally, we can have a look at <a href="https://en.wikipedia.org/wiki/Filter_(higher-order_function)">a definition from wikipedia</a> and functional programming:</p>

<blockquote>
<p>In functional programming, filter is a higher-order function that processes a data structure (usually a list) in some order to produce a new data structure containing exactly those elements of the original data structure for which a given predicate returns the boolean value true.</p>
</blockquote>

<p>Writing such a function can be a good exercise with various options and algorithms in the Standard Library. What’s more, our function hides internal things like iterators, so it’s more like a range based version.</p>

<p>Let’s start with the first option:</p>

<h2 id="good-old-raw-loops">Good old Raw Loops</h2>

<p>While it’s good to avoid raw loops, they might help us to fully understand the problem, especially for a simple problem like we have:</p>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterRaw(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    std::vector&lt;T&gt; out;
    for (auto&amp;&amp; elem : vec)
        if (p(elem))
            out.push_back(elem);
    return out;
}
</code></pre>

<p>Simple yet very effective.</p>

<p>Please notice some nice things about this straightforward implementation.</p>

<ul>
<li>The code uses <code>auto</code> return type deduction, so there’s no need to write the explicit type.</li>
<li>It returns the output vector by value, but the compiler will leverage the copy elision (in most case), or move semantics at worse.</li>
</ul>

<p>Since we’re at raw loops, we need can take a moment and appreciate range based for loops that we get with C++11. Without this functionality our code would look much worse:</p>

<pre><code>template &lt;typename T, typename Pred&gt;
std::vector&lt;T&gt; FilterRawOld(const std::vector&lt;T&gt;&amp; vec, Pred p) {
  std::vector&lt;T&gt; out;
  for (typename std::vector&lt;T&gt;::const_iterator it = begin(vec); it != end(vec); ++it)
    if (p(*it))
      out.push_back(*it);
  return out;
}
</code></pre>

<p>And now let’s move to something better and see some of the existing <code>std::</code> algorithms that might help us with the implementation.</p>

<h2 id="filter-by-std-copy-if">Filter by <code>std::copy_if</code></h2>

<p><code>std::copy_if</code> is probably the most natural choice. We can leverage <code>back_inserter</code> and then push matched elements into the output vector.</p>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterCopyIf(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    std::vector&lt;T&gt; out;
    std::copy_if(begin(vec), end(vec), std::back_inserter(out), p);
    return out;
}
</code></pre>

<h2 id="std-remove-copy-if"><code>std::remove_copy_if</code></h2>

<p>But we can also do the reverse:</p>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterRemoveCopyIf(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    std::vector&lt;T&gt; out;
    std::remove_copy_if(begin(vec), end(vec), 
                        std::back_inserter(out), std::not_fn(p));
    return out;
}
</code></pre>

<p>Depending on the requirements, we can also use <code>remove_copy_if</code> which copies elements that do not satisfy the predicate. For our implementation, I had to add <code>std::not_fn</code> to reverse the predicate.</p>

<p>One remark: <code>std::not_fn</code> is available since C++17.</p>

<h2 id="the-famous-remove-erase-idiom">The Famous Remove Erase Idiom</h2>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterRemoveErase(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    auto out = vec;
    out.erase(std::remove_if(begin(out), end(out), std::not_fn(p)), end(out));
    return out;
}
</code></pre>

<p>Here’s a little inconvenience. Because we don’t want to modify the input container, we had to copy it first. This might cause some extra processing and is less efficient than using <code>back_inserter</code>.</p>

<h2 id="adding-some-c-20">Adding Some C++20</h2>

<p>After seeing a few examples, we can finally see a convenient feature from C++20.</p>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterEraseIf(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    auto out = vec;
    std::erase_if(out, std::not_fn(p));
    return out;
}
</code></pre>

<p>One minor thing, this approach copies all elements first. So it might be slower than the approach with <code>copy_if</code>.</p>

<h2 id="adding-some-c-20-ranges">Adding Some C++20 Ranges</h2>

<p>And finally a solution with Ranges:</p>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterRangesCopyIf(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    std::vector&lt;T&gt; out;
    std::ranges::copy_if(vec, std::back_inserter(out), p);
    return out;
}
</code></pre>

<p>The code is super simple, and we might even say that our <code>Filter</code> function has no point here, since the Ranges interface is so easy to use in code directly.</p>

<h2 id="making-it-more-generic">Making it More Generic</h2>

<p>So far I showed you code that operates on <code>std::vector</code>. But how about other containers?</p>

<p>Let’s try and make our <code>Filter</code> function more generic. This is easy with <code>std::erase_if</code> which has overloads for many Standard containers:</p>

<pre><code>template &lt;typename TCont, typename Pred&gt;
auto FilterEraseIfGen(const TCont&amp; cont, Pred p) {
    auto out = cont;
    std::erase_if(out, std::not_fn(p));
    return out;
}
</code></pre>

<p>And another version for ranges.</p>

<pre><code>template &lt;typename TCont, typename Pred&gt;
auto FilterRangesCopyIfGen(const TCont&amp; vec, Pred p) {
    TCont out;
    std::ranges::copy_if(vec, std::back_inserter(out), p);
    return out;
}
</code></pre>

<p>Right now it can work with other containers, not only with <code>std::vector</code>:</p>

<pre><code>std::set&lt;std::string&gt; mySet{ 
    "Hello", "**txt", "World", "error", "warning", "C++", "****" 
};
auto filtered = FilterEraseIfGen(mySet, [](auto&amp; elem) { 
    return !elem.starts_with('*'); 
});
</code></pre>

<p>On the other hand, if you prefer not to copy all elements upfront, we might need more work.</p>

<h3 id="generic-copy-if-approach">Generic Copy If Approach</h3>

<p>The main problem is that we cannot use <code>back_inserter</code> on associative containers, or on containers that don’t support <code>push_back()</code> member function. In that case, we can fallback to <code>std::inserter</code> adapter.</p>

<p>That’s why one of a possible solution is to detect if a given container supports <code>push_back</code> :</p>

<pre><code>template &lt;typename T, typename = void&gt;
struct has_push_back : std::false_type {};

template &lt;typename T&gt;
struct has_push_back&lt;T,
  std::void_t&lt;
    decltype(std::declval&lt;T&gt;().push_back(std::declval&lt;typename T::value_type&gt;()))
    &gt;
  &gt; : std::true_type {};

template &lt;typename TCont, typename Pred&gt;
auto FilterCopyIfGen(const TCont&amp; cont, Pred p) {
    TCont out;
    if constexpr(has_push_back&lt;TCont&gt;::value)
        std::copy_if(begin(cont), end(cont), std::back_inserter(out), p);
    else
        std::copy_if(begin(cont), end(cont), std::inserter(out, out.begin()), p);

    return out;
}
</code></pre>

<p>This seems to work! But of course, I’m open to some better code and ideas :)</p>

<p>I took the approach from <a href="https://www.cppstories.com/2019/07/detect-overload-from-chars/">How To Detect Function Overloads in C++17, std::from_chars Example - C++ Stories</a>.</p>

<h2 id="adding-some-concepts">Adding Some Concepts</h2>

<p>Since we can use C++, why not adding some concepts.</p>

<p>For example, if I write:</p>

<pre><code>auto filtered = FilterCopyIf(vec, [](auto&amp; elem, int a) { 
    return !elem.starts_with('*'); 
});
</code></pre>

<p>So it’s two input arguments into an unary predicate I get the following in Visual Studio:</p>

<pre><code>C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\algorithm(1713,13): error C2672: 'operator __surrogate_func': no matching overloaded function found
1&gt;  C:\Users\Admin\Documents\GitHub\articles\filterElements\filters.cpp(38): message : see reference to function template instantiation '_OutIt std::copy_if&lt;std::_Vector_const_iterator&lt;std::_Vector_val&lt;std::_Simple_types&lt;_Ty&gt;&gt;&gt;,std::back_insert_iterator&lt;std::vector&lt;_Ty,std::allocator&lt;_Ty&gt;&gt;&gt;,Pred&gt;(_InIt,_InIt,_OutIt,_Pr)' being compiled
1&gt;          with
</code></pre>

<p>but then after a few lines, we have</p>

<pre><code>error C2780: 'auto main::&lt;lambda_4&gt;::operator ()(_T1 &amp;,int) const': expects 2 arguments - 1 provided
</code></pre>

<p>We can experiment with concepts and restrict our predicate to be <code>std::predicate</code>, an existing concept from the Standard Library. In our case, we need a function that takes one argument and then returns a type convertible to <code>bool</code>.</p>

<pre><code>template &lt;typename T, std::predicate&lt;const T&amp;&gt; Pred&gt;   // &lt;&lt;
auto FilterCopyIfConcepts(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    std::vector&lt;T&gt; out;
    std::copy_if(begin(vec), end(vec), std::back_inserter(out), p);
    return out;
}
</code></pre>

<p>And then the problematic code:</p>

<pre><code>auto filtered = FilterCopyIfConcepts(vec, [](auto&amp; elem, int a) { 
    return !elem.starts_with('*'); 
});
</code></pre>

<p>Says the following:</p>

<pre><code>1&gt;  filters.cpp(143,19): error C2672: 'FilterCopyIfConcepts': no matching overloaded function found
1&gt;  filters.cpp(143,101): error C7602: 'FilterCopyIfConcepts': the associated constraints are not satisfied
</code></pre>

<p>It’s a bit better, as we have messages about our top-level function and not some internals, but it would be great to see why and which constraint wasn’t satisfied.</p>

<h2 id="making-it-parallel">Making it Parallel?</h2>

<p>Since C++17 we also have parallel algorithms, so why not add it to our list?</p>

<p>As it appears <code>std::copy_if</code> par is not supported in Visual Studio, and this problem is a bit more complicated. We’ll leave this topic for now and try to solve it some next time.</p>

<p>You can write a manual version:</p>

<pre><code>std::mutex mut;
    std::for_each(std::execution::par, begin(vec), end(vec),
        [&amp;out, &amp;mut, p](auto&amp;&amp; elem) {
            if (p(elem))
            {
                std::unique_lock lock(mut);
                out.push_back(elem);
            }
        });
</code></pre>

<p>But this will often block, and it’s probably not the best approach. So stay tuned for our future experiments with this topic.</p>

<h2 id="summary">Summary</h2>

<p>In this article, I’ve shown at least 12 possible ways to filter elements from various containers. We started from code that worked on <code>std::vector</code>, and you’ve also seen multiple …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cppstories.com/2021/filter-cpp-containers/">https://www.cppstories.com/2021/filter-cpp-containers/</a></em></p>]]>
            </description>
            <link>https://www.cppstories.com/2021/filter-cpp-containers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988749</guid>
            <pubDate>Mon, 01 Feb 2021 14:04:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Julius Ruechel: Bystander at the Switch: The Moral Case Against Covid Lockdowns]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988743">thread link</a>) | @mrfusion
<br/>
February 1, 2021 | https://www.juliusruechel.com/2021/01/bystander-at-switch-moral-case-against.html?m=1 | <a href="https://web.archive.org/web/*/https://www.juliusruechel.com/2021/01/bystander-at-switch-moral-case-against.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-16392354600715661" itemprop="articleBody">
<p>Do you remember the moral riddle taught in grade school called the "Bystander at the Switch" (also known as the <a href="https://en.wikipedia.org/wiki/Trolley_problem" target="_blank">Trolley Problem</a>)? It was a story about a runaway train hurtling towards a cluster of people stuck on the tracks ahead. But you have the option to pull the switch and send the train down another track with a smaller number of people on it. You have the option of saving some lives by sacrificing a smaller number of others. Do you pull the switch?</p><p>In grade school the riddle was posed as a moral dilemma. But it's not. There was only ever one correct choice. We invented universal human rights to make it clear that no person or government has the right to pull the switch to send the train down another track towards a sacrificial group of victims.&nbsp;</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-Lvnx8GgBG44/YAShcMP093I/AAAAAAAAAhs/zPCv7xsW1lgf0gQkYuE29BKWxh22I3PDQCLcBGAsYHQ/s1626/Trolley%2BProblem.jpg"><img data-original-height="530" data-original-width="1626" height="91" src="https://1.bp.blogspot.com/-Lvnx8GgBG44/YAShcMP093I/AAAAAAAAAhs/zPCv7xsW1lgf0gQkYuE29BKWxh22I3PDQCLcBGAsYHQ/w640-h208/Trolley%2BProblem.jpg" width="280"></a></td></tr><tr><td>The Trolley Problem (The immoral dilemma of the bystander at the switch)</td></tr></tbody></table><p>In December of 1948, in the aftermath of the human rights violations committed during the Second World War, the member states of the United Nations formally adopted the <a href="https://www.un.org/en/universal-declaration-human-rights/" target="_blank">Universal Declaration of Human Rights</a>. It explicitly forbids government from treating some people as worth less than others. It forbids government from sacrificing some people for the benefit of others. It forbids government from knowingly imposing harm on some individuals in order to serve an alleged greater good. And it forbids government from imposing a hierarchy of rights on their citizens.</p><p>Lockdowns during COVID pose the exact same question as the Bystander at the Switch. But it's not a game; once again there are real lives at stake. Yet in direct violation of the principles of universal human rights, governments around the world are choosing to pull the switch by imposing lockdowns "for our safety." In doing so they have given themselves the authority to play God with our lives.</p><p>Are you essential or non-essential? Each category now has different rights and freedoms and different levels of individual autonomy. Some have the right to earn a living. Others do not. Some have the right to choose how to balance the risks and priorities in their lives. Others do not. How can any job that feeds a family not be essential?&nbsp;</p><p>What about the collateral damage caused by lockdowns? Mandatory lockdowns are leading to the deaths of countless individuals through cancelled/delayed medical operations, suicides, drug overdoses, loneliness and isolation in nursing homes, and more. None of these deaths would happen without lockdowns. Government is throwing one group of people onto the tracks with the goal of saving another.</p><p>How much misery and suffering is government allowed to impose on other people "for your safety"? How many jobs is the government allowed to destroy "for your safety"? How many people will lose their homes "for your safety"? How many people will lose their life savings, have their marriages broken, suffer bankruptcy, lose their careers, have their children's education irreparably damaged, or have their mental health destroyed because of actions taken by the government "for your safety"?&nbsp;</p><p><a href="https://www.thestar.com/news/gta/2020/12/05/one-in-10-canadians-say-theyve-contemplated-suicide-since-the-pandemic-began.html" target="_blank"><img data-original-height="485" data-original-width="821" height="165" src="https://1.bp.blogspot.com/-BCrzBC0_kLo/YAjo4CubHUI/AAAAAAAAAkY/jAtjXaAaJic9Fx_NqHGXPadyMdrRGvIWQCLcBGAsYHQ/w400-h236/1%2Bin%2B10%2BCanadians.jpg" width="280"></a></p><p>And how many people is the government allowed to force into poverty and starvation "for your safety"? Visitors to food banks are not just soaring here at home. We live in an interconnected world. What we do in one part of the world sets precedents and causes economic ripples that reach the farthest corners of the globe. Do those lives matter?&nbsp;</p><p>The head of the World Food Program WFP has warned that the "equivalent of 400 million full-time jobs have been destroyed" by government mandated COVID lockdowns and that there are now "270 million people marching towards the brink of starvation" (full article <a href="https://www.wfp.org/news/wfp-chief-warns-grave-dangers-economic-impact-coronavirus-millions-are-pushed-further-hunger" target="_blank">here</a>).&nbsp;</p><p><a href="https://1.bp.blogspot.com/-iPQaTjJiT8o/YAjTNs7gvtI/AAAAAAAAAig/QI80MazuQ207v9cf8SqVCAgQ0FF0d_BgwCLcBGAsYHQ/s1231/World%2BFood%2BProgram%2BWFP%2529%2BWarning.jpg"><img data-original-height="752" data-original-width="1231" height="170" src="https://1.bp.blogspot.com/-iPQaTjJiT8o/YAjTNs7gvtI/AAAAAAAAAig/QI80MazuQ207v9cf8SqVCAgQ0FF0d_BgwCLcBGAsYHQ/w640-h390/World%2BFood%2BProgram%2BWFP%2529%2BWarning.jpg" width="280"></a></p><p>Here are a few excerpts that I hope make you very uncomfortable:</p><div><p>On jobs lost during COVID:</p><p><a href="https://1.bp.blogspot.com/-L0aDesaThes/YAjTYAbbABI/AAAAAAAAAik/KnXj2JK02Howa3TP9q7A1Jqw3bjjkm_VgCLcBGAsYHQ/s859/WFP-jobs.jpg"><img data-original-height="173" data-original-width="859" height="56" src="https://1.bp.blogspot.com/-L0aDesaThes/YAjTYAbbABI/AAAAAAAAAik/KnXj2JK02Howa3TP9q7A1Jqw3bjjkm_VgCLcBGAsYHQ/w640-h128/WFP-jobs.jpg" width="280"></a></p><p>Increased child deaths in Africa due to missed routine vaccinations:</p></div><p><a href="https://1.bp.blogspot.com/-7Aso8PfH-w4/YAnl6sA3JTI/AAAAAAAAAlg/SKguFSakBkgaPr2mqT1g019_TE4kWy-hQCLcBGAsYHQ/s862/WFP-vaccinations.jpg"><img data-original-height="148" data-original-width="862" height="48" src="https://1.bp.blogspot.com/-7Aso8PfH-w4/YAnl6sA3JTI/AAAAAAAAAlg/SKguFSakBkgaPr2mqT1g019_TE4kWy-hQCLcBGAsYHQ/w640-h110/WFP-vaccinations.jpg" width="280"></a></p><p>Starvation in the Democratic Republic of the Congo:</p><p><a href="https://1.bp.blogspot.com/-aI_p2Wbslpc/YAjULGDGtSI/AAAAAAAAAi8/av7AeDG1gho0vRhOBDJ2M5zZVeD638vAQCLcBGAsYHQ/s873/WFP-DRC.jpg"><img data-original-height="148" data-original-width="873" height="47" src="https://1.bp.blogspot.com/-aI_p2Wbslpc/YAjULGDGtSI/AAAAAAAAAi8/av7AeDG1gho0vRhOBDJ2M5zZVeD638vAQCLcBGAsYHQ/w640-h108/WFP-DRC.jpg" width="280"></a></p><p>Starvation in Nigeria:</p><p><a href="https://1.bp.blogspot.com/-ZicomGhUusU/YAjULUeeroI/AAAAAAAAAjA/f1Guhsfgh041jb5_Xc_GlbzSYdWTPGgaQCLcBGAsYHQ/s837/WFP-Nigeria.jpg"><img data-original-height="155" data-original-width="837" height="51" src="https://1.bp.blogspot.com/-ZicomGhUusU/YAjULUeeroI/AAAAAAAAAjA/f1Guhsfgh041jb5_Xc_GlbzSYdWTPGgaQCLcBGAsYHQ/w640-h118/WFP-Nigeria.jpg" width="280"></a></p><p>Starvation in South Sudan:</p><div><p><a href="https://1.bp.blogspot.com/-xh6wIZYJCfU/YAjULtpQGRI/AAAAAAAAAjE/Syzqyj2-2FcS0SbUCyl_nYlgspwRVg09ACLcBGAsYHQ/s836/WFP-Sudan.jpg"><img data-original-height="128" data-original-width="836" height="42" src="https://1.bp.blogspot.com/-xh6wIZYJCfU/YAjULtpQGRI/AAAAAAAAAjE/Syzqyj2-2FcS0SbUCyl_nYlgspwRVg09ACLcBGAsYHQ/w640-h98/WFP-Sudan.jpg" width="280"></a></p><p>Starvation in Yemen:</p><p><a href="https://1.bp.blogspot.com/-BPYzhn1zC-w/YAjUMN1OBzI/AAAAAAAAAjI/uUwKUrqpPigs8AXG9KSWE1afKzaKNOypwCLcBGAsYHQ/s842/WFP-Yemen.jpg"><img data-original-height="179" data-original-width="842" height="59" src="https://1.bp.blogspot.com/-BPYzhn1zC-w/YAjUMN1OBzI/AAAAAAAAAjI/uUwKUrqpPigs8AXG9KSWE1afKzaKNOypwCLcBGAsYHQ/w640-h136/WFP-Yemen.jpg" width="280"></a></p><p>Starvation in Latin America:</p><p><a href="https://1.bp.blogspot.com/--yBmMPts5Z8/YAjULDLjwZI/AAAAAAAAAi0/TyR08zBb1I0u3pDjTmpF4753F4YLEHLoACLcBGAsYHQ/s844/WFP-Latin%2BAmerica.jpg"><img data-original-height="77" data-original-width="844" height="25" src="https://1.bp.blogspot.com/--yBmMPts5Z8/YAjULDLjwZI/AAAAAAAAAi0/TyR08zBb1I0u3pDjTmpF4753F4YLEHLoACLcBGAsYHQ/w640-h58/WFP-Latin%2BAmerica.jpg" width="280"></a></p><p>Starvation in Burkina Faso:</p><div><p><a href="https://1.bp.blogspot.com/-8depsiUwTXc/YAjULMZ6dgI/AAAAAAAAAi4/gsdA6bD2tSINueQeuVWn5qJYXfzZqRkygCLcBGAsYHQ/s847/WFP-Burkino%2BFaso.jpg"><img data-original-height="101" data-original-width="847" height="33" src="https://1.bp.blogspot.com/-8depsiUwTXc/YAjULMZ6dgI/AAAAAAAAAi4/gsdA6bD2tSINueQeuVWn5qJYXfzZqRkygCLcBGAsYHQ/w640-h76/WFP-Burkino%2BFaso.jpg" width="280"></a></p><p>Let's be clear, this unfolding horror is not because of COVID, it is because of the government's&nbsp;<i>response&nbsp;</i>to COVID. By crossing the line from making recommendations to imposing laws that take away the people's right to decide for themselves how to balance their risks and priorities, economies are grinding to a halt and millions are being forced into starvation. And the carnage doesn't miraculously end when the virus fades away. The slow-moving forces set in motion will be with us for a long time and in the meantime the bodies will just keep piling up. Should they be asked to pay this price "for your safety"? Or perhaps they don't matter since the media isn't counting them and can't leverage them into click-bait to exploit your feeling of vulnerability to the virus?</p><p>The first principle in medicine is the Hippocratic Oath, which says, "First do no harm." One consequence of this rule is that you're not allowed to protect one group of people by harming another. Empathy for one group doesn't give you the right to trample another. In the Trolly Problem, it's completely unethical (medical malpractice) for any doctor to pull the switch.</p><p>Yet health authorities imposing lockdowns are nevertheless inflicting horrific harms on those least at risk from the virus (the young and healthy) with the excuse that this is justified to protect those most at risk (the very old, especially those with pre-existing health conditions). This is a direct violation of the Hippocratic Oath. And it's completely nonsensical. If you're unwilling to risk exposure to the virus, stay home. Your risk as you shelter at home is exactly the same whether I'm at home in lockdown or whether I'm at work to feed my family or visiting my loved ones to protect my (or their) mental health.&nbsp;</p><p>The right to individual autonomy was specifically invented to allow free people to weigh their risks and priorities. For most of us there are many risks in our daily lives (like being unable to feed our families) that are far more dangerous than a virus that even the <a href="https://www.cdc.gov/coronavirus/2019-ncov/hcp/planning-scenarios.html" target="_blank">US CDC says</a> has an infection <i>survival</i> rate of 99.997% for those under 20 years of age, 99.98% for 20 to 49 year olds, 99.5% for 50 to 69 year olds and 94.6% for anyone over the age of 70. To put that in perspective, Dr. John Ioannidis, professor of epidemiology and biomedical statistics at the University of Stanford,&nbsp;<a href="https://www.medrxiv.org/content/10.1101/2020.04.05.20054361v1" target="_blank">has calculated</a> that for people under the age of 65, the COVID death risk is "equivalent to the death risk of driving from between 9 miles per day (in Germany) and 415 miles per day (in New York City)."</p><p><a href="https://1.bp.blogspot.com/-RqXjOJWQMHI/YAi7WuLr8jI/AAAAAAAAAiE/pTQhFrFPWhgCgEcMg3JbQ6xxFIySJ-9xQCLcBGAsYHQ/s409/CDC%2Bplanning%2Bscenarios.jpg"><img data-original-height="409" data-original-width="381" height="320" src="https://1.bp.blogspot.com/-RqXjOJWQMHI/YAi7WuLr8jI/AAAAAAAAAiE/pTQhFrFPWhgCgEcMg3JbQ6xxFIySJ-9xQCLcBGAsYHQ/s320/CDC%2Bplanning%2Bscenarios.jpg"></a></p><p>And are government lockdowns actually protecting those at risk? A very large proportion of COVID deaths worldwide are occurring in long-term care homes (in Canada 72% of COVID deaths have been in long-term care facilities!)&nbsp;</p><p>Lockdowns don't help those most at risk if they are already segregated from society in nursing homes. But isolation does accelerate deteriorating health conditions among nursing home patients who are denied the ability to spend the last few months of their lives surrounded by loved ones.&nbsp;</p><table><tbody><tr><td><a href="https://www.ctvnews.ca/health/facing-another-retirement-home-lockdown-90-year-old-chooses-medically-assisted-death-1.5197140" target="_blank"><img data-original-height="678" data-original-width="796" height="238" src="https://1.bp.blogspot.com/-w0QHXzPCGlk/YAjZDCxEsKI/AAAAAAAAAj0/f2Qa5p9jwRI6SAIkuJN0-p392GjBNjflQCLcBGAsYHQ/w400-h341/Nancy-Russell.jpg" width="280"></a></td></tr><tr><td>Why don't nursing home residents get to decide for themselves if they want to be isolated?</td></tr></tbody></table><p>By trying to "flatten the curve", lockdowns only extend the amount of time it takes for the rest of the population to acquire herd immunity, which increases the amount of time that the most vulnerable are at risk of being exposed to others carrying the virus. Instead of self-isolating for a month while the virus runs its course among the rest of the population (like influenza does every winter) they have now been at risk of catching COVID from the rest of us for almost 10 months - 10 months during which many have been forcibly stuck in isolation, separated from their loved ones!&nbsp;</p><p>In other words, if you don't pull the switch, the vulnerable are at risk. But if you do pull the switch, the risk increases to the most vulnerable while also putting everyone else in harm's way.&nbsp;</p><p>Another excuse given for lockdowns is that the health care system is at risk of getting overwhelmed. It's another bizarre and immoral argument. Since when does access to health care override our right to freedom, individual autonomy, and the ability to try to feed our families? If that were an acceptable excuse for lockdowns, the government would pull the switch and lock down society every winter. Hallway medicine and overworked hospital staff have long been the norm of our poorly managed health care systems every flu season. Here is a small sample of news articles illustrating the problem. Check the dates - <i>all</i> are from <i>before</i>&nbsp;COVID!</p><p>This&nbsp;<a href="https://www.cbc.ca/news/canada/toronto/ontario-hospital-hallway-medicine-healthcare-beyond-capacity-1.5420434" target="_blank">CBC article from January of 2020</a>&nbsp;shows that from January to June 2019 (180 days) some of the most overcrowded hospitals in Ontario spent between 148 and 179 of the 180-day study period operating above 100% capacity. In other words, they were essentially operating above capacity <i>every single day</i>!&nbsp;</p><p><a href="https://1.bp.blogspot.com/-UAxghG47dkw/YAjorm4HkDI/AAAAAAAAAkg/GSv--GCBtd8S3F0qVHR7vejMPq0dOI2dgCPcBGAYYCw/s1494/Ontario%2Bovercapacity.jpg"><img data-original-height="1494" data-original-width="770" height="543" src="https://1.bp.blogspot.com/-UAxghG47dkw/YAjorm4HkDI/AAAAAAAAAkg/GSv--GCBtd8S3F0qVHR7vejMPq0dOI2dgCPcBGAYYCw/w351-h681/Ontario%2Bovercapacity.jpg" width="280"></a></p><p>This <a href="https://www.cbc.ca/news/canada/ottawa/gatineau-hospitals-experiencing-overcrowding-1.4522191" target="_blank">CBC article from February 2018</a> shows&nbsp;hospitals in Quebec running at up to 245% capacity.&nbsp;</p><p><a href="https://1.bp.blogspot.com/-ICcyaUhMTKo/YAjoruYCKCI/AAAAAAAAAko/MlMVG6frqGkYcja6LJT9eaC9-AQSzHoDgCPcBGAYYCw/s1006/Gatineau%2B245%2Bpercent%2Bhospital.jpg"><img data-original-height="1006" data-original-width="745" height="378" src="https://1.bp.blogspot.com/-ICcyaUhMTKo/YAjoruYCKCI/AAAAAAAAAko/MlMVG6frqGkYcja6LJT9eaC9-AQSzHoDgCPcBGAYYCw/w474-h640/Gatineau%2B245%2Bpercent%2Bhospital.jpg" width="280"></a></p><p>This&nbsp;<a href="https://www.cbc.ca/news/canada/sudbury/hospital-health-sciences-north-overcrowding-1.5139909" target="_blank">CBC article from May 2019</a>&nbsp;discusses how common it has become for patients to be housed not just in hallways, but even in bathrooms!</p><p><a href="https://1.bp.blogspot.com/-V-tyjsNoWHU/YAjosRqS4XI/AAAAAAAAAkk/JqXMfB7n29w5D7oq2NLpyDME2V0lqWTVQCPcBGAYYCw/s878/Patients%2Bin%2Bbathrooms.jpg"><img data-original-height="766" data-original-width="878" height="244" src="https://1.bp.blogspot.com/-V-tyjsNoWHU/YAjosRqS4XI/AAAAAAAAAkk/JqXMfB7n29w5D7oq2NLpyDME2V0lqWTVQCPcBGAYYCw/w400-h349/Patients%2Bin%2Bbathrooms.jpg" width="280"></a></p><p>And&nbsp;this&nbsp;<a href="https://www.ctvnews.ca/health/about-1-000-patients-in-hospital-hallways-on-any-given-day-report-1.4276591" target="_blank">CTV article from January 2019</a> demonstrates that in Ontario about 1000 patients were being treated in hospital hallways <i>every single day</i>&nbsp;long before COVID hit. For context, as I write this today, January 21st, 2021, Ontario (a province of over 14 million) has a grand total of 1,533 COVID hospitalizations&nbsp;<i>in the entire province</i>. None are currently being treated in hallways;&nbsp;<a href="https://toronto.ctvnews.ca/toronto-s-icus-will-reach-capacity-by-late-january-as-pandemic-continues-to-worsen-top-doctor-says-1.5271345" target="_blank">some hospitals are nearing capacity</a>, but as I've just finished showing you, that means they are <i>below</i>&nbsp;the typical occupancy levels seen at this time of year prior to COVID.</p><p><a href="https://1.bp.blogspot.com/-MUqU1Yblw3c/YAjorki0N7I/AAAAAAAAAkc/RtaBEk9kgSsQ7ACNvd0TsmjgplXrzypBQCPcBGAYYCw/s792/1000%2Bpatients%2BJan2019.jpg"><img data-original-height="792" data-original-width="742" height="298" src="https://1.bp.blogspot.com/-MUqU1Yblw3c/YAjorki0N7I/AAAAAAAAAkc/RtaBEk9kgSsQ7ACNvd0TsmjgplXrzypBQCPcBGAYYCw/w375-h400/1000%2Bpatients%2BJan2019.jpg" width="280"></a></p><p>I've posted even more examples of the pre-COVID hospital crisis on a Twitter thread&nbsp;<a href="https://mobile.twitter.com/JuliusRuechel/status/1341826835924082690" target="_blank">here</a>. &nbsp;</p><p>The government's failure to provide adequate health care capacity is not an exemption that allows government to suspend the constitutional rights and freedoms of its citizens. But I encourage you to read the Universal Declaration of …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.juliusruechel.com/2021/01/bystander-at-switch-moral-case-against.html?m=1">https://www.juliusruechel.com/2021/01/bystander-at-switch-moral-case-against.html?m=1</a></em></p>]]>
            </description>
            <link>https://www.juliusruechel.com/2021/01/bystander-at-switch-moral-case-against.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988743</guid>
            <pubDate>Mon, 01 Feb 2021 14:03:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenSky Covid-19 Flight Dataset]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988731">thread link</a>) | @Nightlifer
<br/>
February 1, 2021 | https://opensky-network.org/community/blog/item/6-opensky-covid-19-flight-dataset | <a href="https://web.archive.org/web/*/https://opensky-network.org/community/blog/item/6-opensky-covid-19-flight-dataset">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Over the past year we have been inundated with requests regarding flight data related to the COVID-19 pandemic. While we have done our best to help researchers around the world using our trusted <a href="https://opensky-network.org/data/impala">Impala shell</a>, we have also released a public version of the flight meta data that we have collected over the whole year of 2020 plus the whole year of 2019 for a pre-COVID-19 comparison. If you are only interested in the data, you can find it over at CERN's Zenodo repository: <a href="https://doi.org/10.5281/zenodo.3737101">https://doi.org/10.5281/zenodo.3737101</a></p>
<p>We currently plan to update this dataset monthly during the pandemic. If you have research needs that go beyond this release model, you can <a href="https://opensky-network.org/data/apply">apply for full data access</a> with us.</p>
<p>The main use cases of flight data related to the pandemic are manifold: First, flight data can be used as input for models analysing and predicting the global spread of the virus. Second, flights as an indicator of economic activity can provide insights into the impact of the pandemic on both countries' economies in general and the aviation industry in particular. Finally, the data has become popular for analysis in Earth Systems Sciences over the course of the year. We have a pre-print discussing this here. [1] The data in this dataset is derived and cleaned from the full OpenSky dataset and made fully publicly available for the first time. It spans metadata for all flights seen by the network's more than 3500 members in 2019 and 2020.</p>
<p>The most important point to remember is that as these data are derived from our awesome feeders, we cannot provide every global flight movement in our dataset but only <strong>those ADS-B-equipped aircraft seen within our coverage</strong>!<br>An overview of our coverage is provided for any given day on our <a href="https://opensky-network.org/network/facts">Facts page</a>. An example for yesterday (2020-04-02) is shown here:</p>
<p><img src="https://opensky-network.org/images/coverage.png" alt="coverage"></p>
<p>If you have access to a place that is not yet covered by OpenSky and want to see researchers include that area in the future, please <a href="https://opensky-network.org/contribute/improve-coverage">do provide a feed</a>!</p>
<p>[1] Strohmeier, M., Olive, X., Lübbe, J., Schäfer, M., and Lenders, V.: <a href="https://essd.copernicus.org/preprints/essd-2020-223/">Crowdsourced Air Traffic Data from the OpenSky Network 2019–20</a>, Earth Syst. Sci. Data. [preprint], 2021.&nbsp;</p>
<h2>Usage Examples &amp; Tools</h2>
<p>Xavier Olive from ONERA has made some initial plots using this dataset, illustrating for example the drop in air traffic at specific airports during the early phase of the pandemic:</p>
<p><img src="https://opensky-network.org/images/canvas.png" alt="canvas"></p>

<p>More up-to-date visualisations and code for use with this dataset can be found over at <a href="https://traffic-viz.github.io/scenarios/covid19.html">Impact of COVID-19 on worldwide aviation.</a></p>
<p>Since the dataset is naturally large, we recommend using tools such as <a href="https://opensky-network.org/r-project.org">R</a>, <a href="https://opensky-network.org/python.org">Python</a> or <a href="https://opensky-network.org/mathworks.com">Matlab</a> for processing vast quantities of data. You can find more tools, that interface directly with our Live API and our Impala shell on our <a href="https://opensky-network.org/data/data-tools">data tools subpage</a>.</p>
<p>If you want to split these files into smaller .csv files before loading them into your preferred processing programme, we recommend using<a href="https://www.windows10download.com/csv-splitter/"> CSV Splitter (Windows)</a> or the Linux/<a href="https://eikhart.com/blog/autosplit-csv">MacOS</a> split command.</p>
        </div></div>]]>
            </description>
            <link>https://opensky-network.org/community/blog/item/6-opensky-covid-19-flight-dataset</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988731</guid>
            <pubDate>Mon, 01 Feb 2021 14:01:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Simple Way to Start Measuring Developer Efficiency]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988662">thread link</a>) | @pickledish
<br/>
February 1, 2021 | http://www.willett.io/posts/developer-friction/ | <a href="https://web.archive.org/web/*/http://www.willett.io/posts/developer-friction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

			<div>
				<div>
					<p>I’m a monitoring nut. I’m a firm believer that you can’t improve what you’re not measuring, so it’s always fun for me to try to quantify everything at work that people care about – even the stuff that’s generally too challenging to “pin down” to bother. So when the question at work comes up of “how do we make our developers more efficient”, the only response I can come up with is “well, how are we measuring it?”</p>

<p>The conversation around developer efficiency at larger software shops is of course worth having. But in order to make quantifiable progress in this area, we’ll need to have some numerical sense of the friction that developers face in their day-to-day tasks. Here, I’ll briefly describe one method I’ve been using for the last few years, which has served me well enough to start making useful comparisons across months, teams, and companies.</p>

<h2 id="comparing-to-a-baseline">Comparing to a Baseline</h2>

<p><img src="http://www.willett.io/assets/friction-none.png" alt=""></p>

<p>No measurement can be useful without units, right? A number line, an axis, some concept of “zero”. It doesn’t matter <em>where</em> on the number line this zero is; its main purpose is to be a easily-recognizable fixed point which we can compare to other points (and indeed, it allows us to compare points to each other).</p>

<p>In my scale of developer friction, the “zero point” for a software development (or ops) task is “<strong>how long this would take me to do for my own project on a Saturday morning</strong>”. No company infrastructure, no automated test suite and deployment process, no metrics or log aggregation or responsive alerting. Just you, one server with root access, and one or two apps running on that server. In this tiny-world model of your unit of work, how much time do you have to spend in order to see it through?</p>

<p>This kind of comparison against the requirements of a company’s <a href="https://en.wikipedia.org/wiki/Systems_development_life_cycle">SDLC</a> might not be perfectly “fair” for a number of reasons, but by comparing against this baseline, we can at least begin to quantify the help/hurt of that company’s infrastructure.</p>

<h2 id="reducing-friction">Reducing Friction</h2>

<p><img src="http://www.willett.io/assets/friction-less.png" alt=""></p>

<p>A developer facing less friction in getting their change safely validated and deployed is always a good thing, and work in this direction is usually very deliberate. Larger software companies will have entire teams dedicated to the effort. After all, if you can save each developer 5 minutes of time in deploying a change for example, you’re looking at dozens of hours (and thousands of dollars) saved per month.</p>

<p>Examples of reducing developer friction below the “baseline” include:</p>

<ul>
  <li>A CI/CD system which will automatically run <a href="https://www.terraform.io/docs/cli/commands/apply.html"><code>terraform apply</code></a> when a PR to a repository containing <a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">infrastructure as code</a> is merged</li>
  <li>An internal profiling system that allows developers to spend less time figuring out what caused an app’s memory usage to spike, and more time fixing it</li>
</ul>

<h2 id="increasing-friction">Increasing Friction</h2>

<p><img src="http://www.willett.io/assets/friction-more.png" alt=""></p>

<p>In contrast, “increased developer friction” almost universally happens by accident, or at least accumulates slowly over the lifetime of a software product.</p>

<p>Despite first instinct, it doesn’t generally come from leadership having bad prioritization, or coworkers who “just didn’t think things through enough”. Instead, it’s more due to the top-down necessity of additional security/compliance measures, or more often in my experience, added process as a direct result (a “follow-up”) of a previous outage in an effort to avoid the same thing happening again.</p>

<p>Examples of increasing developer friction above the “baseline” include:</p>

<ul>
  <li>A suite of unit tests that include a few “flaky tests”, which occasionally fail after 10 minutes and need to be re-run before a deployment can be triggered</li>
  <li>A change that needs to be executed across several different applications in different places, in a specific order or all at the same time</li>
</ul>

<h2 id="a-real-life-example">A Real Life Example</h2>

<p>One job I’ve done in the past made a <em>particularly good</em> example of this model. It involved the deployment of updates to configuration files that “lived” in various places – some rendered into our base machine image, some rendered at instance creation time, and some pulled dynamically at runtime (using something like <a href="https://www.consul.io/">Consul</a>).</p>

<p>In order to update a configuration file rendered into the base image, we needed to spin up a bare VM, install dependencies, run all provisioning scripts, save the image, hardcode the new image ID in various other places, and create some “real” VMs to verify it worked. This is significantly <strong><span>more friction</span></strong> than our “Saturday morning” baseline – the entire process took hours, and would often fail in the middle since it wasn’t performed very often.</p>

<p>In contrast, updating an instance-creation-time configuration was easy, and just required making a pull request and then running something like <a href="https://www.ansible.com/">Ansible</a> or <a href="https://www.chef.io/">Chef</a> on each already-existing VM. This is <strong>about even</strong> with the baseline – I had to update the file, make a PR, and run a script or two in order to make sure the instances were up to date.</p>

<p>And in comparison, updating a dynamic configuration took barely any thought at all. Our deployment system was always synced to the Git repository, so as soon as the field was updated there, each instance would start seeing the new value immediately. This is much <strong><span>less friction</span></strong> than the task would have been by myself – the update only required a short pull request, and the deployment happened automatically.</p>

<h2 id="vector-addition">Vector Addition</h2>

<p><img src="http://www.willett.io/assets/friction-math.png" alt=""></p>

<p>Of course, any real software project will be more nuanced than any example in a blog post. The real friction your developers feel is affected by dozens of small factors, some negative and some positive, each costing or freeing a few minutes of their time.</p>

<p>Fortunately, there’s no complicated math here, and the total friction they’ll experience is just the <strong>sum of each individual gain or loss</strong> of efficiency. So if a developer loses 10 minutes of her time setting up explicit new permissions for her app, and loses 10 more waiting on a suite of unit tests that have nothing to do with her change, but gained 30 minutes back by having the CD system roll out her change to each region (rolling back automatically when needed, so she doesn’t need to watch dashboards) – that’s a 10-minute win overall!</p>

<p>At the end of the day, requirements will often dictate that making change is slower than it would be on your own server on a Saturday. But hopefully, this can be a useful, <strong>concrete</strong> way to start telling the difference between a developer feeling frustrated or empowered by the company’s infrastructure, and to see if you’re really making progress.</p>

				</div>
			</div>

		</section></div>]]>
            </description>
            <link>http://www.willett.io/posts/developer-friction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988662</guid>
            <pubDate>Mon, 01 Feb 2021 13:52:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Verify Email Domains with Cognito]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988617">thread link</a>) | @adzicg
<br/>
February 1, 2021 | https://www.serverless.pub/cognito-verify-email-domains/ | <a href="https://web.archive.org/web/*/https://www.serverless.pub/cognito-verify-email-domains/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            

            <p>
                <a href="https://www.serverless.pub/author/gojko">Gojko Adzic</a> in <a href="https://www.serverless.pub/category/Serverless">Serverless</a> <i></i> <i></i> 

  2 minutes

            </p>

            <p>Mistyped emails can be a huge problem for user registrations. In this quick tip, I’ll show you how to prevent a huge percentage of such problems by adding a Cognito PreSignUp trigger to validate email domains.</p>

<p>At <a href="https://www.narakeet.com/">Narakeet</a>, an online app lets users script narrated videos with markdown, about 10% of user registrations went into a black hole because people mistyped their email. I’ve probably seen every possible way to butcher ‘gmail’ in the email bounce logs.</p>

<p>Because users could not confirm the registration, they could not sign in and use the app. That made a very bad first impression. Visitors might think that the application is broken and never come back, instead of fixing their email during registration. To add insult to injury, with an invalid email, I would not be able to get in touch with them to provide assistance.</p>

<h2 id="presignup-trigger-to-the-rescue">PreSignUp trigger to the rescue</h2>

<p>Cognito user pools can be customised with various triggers. The <code>PreSignUp</code> trigger allows you to modify the sign-up process. Most of the examples online show how to speed up the user funnel, automatically confirming attributes and skipping steps of the usual registration process. However, we can also use this trigger to slow users down then they make a mistake.</p>

<p>Here’s a trivial Node.js Lambda function that will check that the domain of the user provided email exists, and that it is actually configured to receive incoming email. It also logs some basic information for CloudWatch insights.</p>

<div><div><pre><code><span>'</span><span>use strict</span><span>'</span><span>;</span>
<span>const</span> <span>dns</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>dns</span><span>'</span><span>);</span>
<span>exports</span><span>.</span><span>handler</span> <span>=</span> <span>async</span> <span>(</span><span>event</span><span>)</span> <span>=&gt;</span> <span>{</span>
	<span>const</span> <span>email</span> <span>=</span> <span>event</span><span>.</span><span>request</span><span>.</span><span>userAttributes</span><span>.</span><span>email</span><span>,</span>
		<span>domain</span> <span>=</span> <span>email</span><span>.</span><span>replace</span><span>(</span><span>/^.*@/</span><span>,</span> <span>''</span><span>)</span> <span>||</span> <span>''</span><span>;</span>
	<span>try</span> <span>{</span>
		<span>if</span> <span>(</span><span>!</span><span>domain</span><span>)</span> <span>{</span>
			<span>throw</span> <span>'</span><span>Email format invalid</span><span>'</span><span>;</span>
		<span>}</span>
		<span>const</span> <span>servers</span> <span>=</span> <span>await</span> <span>dns</span><span>.</span><span>promises</span><span>.</span><span>resolveMx</span><span>(</span><span>domain</span><span>);</span>
		<span>if</span> <span>(</span><span>Array</span><span>.</span><span>isArray</span><span>(</span><span>servers</span><span>)</span> <span>&amp;&amp;</span> <span>servers</span><span>.</span><span>length</span> <span>&gt;</span> <span>0</span><span>)</span> <span>{</span>
			<span>console</span><span>.</span><span>log</span><span>(</span><span>JSON</span><span>.</span><span>stringify</span><span>({</span><span>verification</span><span>:</span> <span>true</span><span>,</span> <span>domain</span><span>}));</span>
			<span>return</span> <span>event</span><span>;</span>
		<span>}</span> <span>else</span> <span>{</span>
			<span>throw</span> <span>'</span><span>no-servers</span><span>'</span><span>;</span>
		<span>}</span>
	<span>}</span> <span>catch</span> <span>(</span><span>error</span><span>)</span> <span>{</span>
		<span>console</span><span>.</span><span>log</span><span>(</span><span>JSON</span><span>.</span><span>stringify</span><span>({</span><span>verification</span><span>:</span> <span>false</span><span>,</span> <span>domain</span><span>,</span> <span>error</span><span>}));</span>
		<span>throw</span> <span>`Cannot verify email domain </span><span>${</span><span>domain</span><span>}</span><span>. Please check for typos`</span><span>;</span>
	<span>}</span>
<span>};</span>
</code></pre></div></div>

<p>When a user mistypes <code>gmail.com</code> as <code>gmal.com</code>, instead of proceeding with the signup, they will see a message such as the one below:</p>

<p><img src="https://www.serverless.pub/img/cognito-domains-big.png" alt=""></p>

<p>The error isn’t ideal – I would prefer not to have the initial part showing users that a trigger failed, but with Cognito hosted UI that’s the best you can get.</p>

<p>Of course, this doesn’t protect you from people mistyping the first part of their email, or mistyping a domain that can also receive messages, but it will at least prevent a large portion of email issues. Popular email providers tend to buy up similarly-sounding domains to prevent squatting, so in practice this little trick can save a lot of users from dropping off the funnel.</p>



            

        </div><!-- main-content/col -->
    </div> <!--/row -->

</div></div>]]>
            </description>
            <link>https://www.serverless.pub/cognito-verify-email-domains/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988617</guid>
            <pubDate>Mon, 01 Feb 2021 13:47:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Short Seller’s Warning Helped to Expose Luckin Coffee's Accounting Fraud]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25988496">thread link</a>) | @1experience
<br/>
February 1, 2021 | https://www.wsj.com./articles/coffees-for-closers-how-a-short-sellers-warning-helped-take-down-luckin-coffee-11593423002 | <a href="https://web.archive.org/web/*/https://www.wsj.com./articles/coffees-for-closers-how-a-short-sellers-warning-helped-take-down-luckin-coffee-11593423002">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
         <p>In January, days after the shares of  Luckin Coffee Inc.  hit a record high on the  Nasdaq Stock Market ,  giving the company a $12 billion valuation, a cryptic email arrived in the inboxes of multiple short sellers. </p>
         <p>“A new generation of Chinese Fraud 2.0 has emerged,” it said. “Companies that start off as fundamentally and structurally flawed business model [sic] that evolves into fraud.” The author offered to share customer receipts and videos from Luckin Coffee outlets, attached a long report about the company and said the short sellers could publish and take credit for it.</p>
         <p>Several American money managers reviewed the report, which accused Luckin of inflating its sales. Carson Block of Muddy Waters LLC published it, posting the 89-page report on Twitter on Jan. 31.  </p>
         <p>Luckin’s auditor subsequently discovered that several employees had faked revenue and expenses and on April 2, <a href="https://www.wsj.com/articles/luckin-coffee-accuses-operating-chief-of-financial-misconduct-11585840274?mod=article_inline" target="_blank">the company disclosed</a> that as much as $310 million of its 2019 sales was fabricated. Its shares collapsed, less than 11 months after the company went public, <a href="https://www.wsj.com/articles/luckin-coffee-drops-nasdaq-appeal-shares-to-be-delisted-11593188282?mod=article_inline" target="_blank">and will soon be delisted</a>.</p>
         <p><a href="https://www.wsj.com/articles/behind-the-fall-of-chinas-luckin-coffee-a-network-of-fake-buyers-and-a-fictitious-employee-11590682336?mod=article_inline" target="_blank">The stunning fall of Luckin</a>, an upstart rival to  Starbucks Corp.  in China that touted itself as the country’s largest coffee chain by stores, has sparked a lot of investor soul-searching. Should they have followed the recommendation of Mr. Block, who has bet against multiple listed Chinese companies? Should they have doubted the company when it disputed the allegations in the anonymous report? Could they have done more due diligence to determine whether Luckin’s reported growth was too good to be true?</p>
  </div></div>]]>
            </description>
            <link>https://www.wsj.com./articles/coffees-for-closers-how-a-short-sellers-warning-helped-take-down-luckin-coffee-11593423002</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988496</guid>
            <pubDate>Mon, 01 Feb 2021 13:32:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Barriers and Atomic Smart Pointers in C++20]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988369">thread link</a>) | @ibobev
<br/>
February 1, 2021 | http://modernescpp.com/index.php/barriers-in-c-20 | <a href="https://web.archive.org/web/*/http://modernescpp.com/index.php/barriers-in-c-20">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blogContent">
				<p>In my last post, I introduced latches in C++20. A latch enables it threads to wait until a counter becomes zero. Additionally, to a latch, its big sibling barrier can be used more than once. Today, I write about barriers and present atomic smart pointers.</p>

<p>&nbsp;<img src="http://modernescpp.com/images/blog/Cpp20/Barrier/TimelineCpp20.png" alt="TimelineCpp20" width="650" height="224"></p>
<p>If you are not familiar with std::latch, read my last post: <a href="https://bit.ly/39eH23G">Latches in C++20</a>.</p>
<h2 id="h1-std-barrier"><code>std::barrier</code></h2>
<p>There are two differences between a <code>std::latch</code> and a <code>std::barrier</code>. A <code>std::latch</code> is useful for managing one task by multiple threads; a<code> std::barrier</code> is helpful for managing repeated tasks by multiple threads.&nbsp;Additionally, a <code>std::barrier</code> enables you to execute a function in the so-called completion step. The completion step is the state when the counter becomes zero. Immediately after the counter becomes zero, the so-called completion step starts. In this completion step, a callable is invoked. The <code>std::barrier</code> gets its callable in its constructor. A callable unit (short callable) is something that behaves like a function. Not only are these named functions, but also function objects or lambda expressions.</p>
<p>The completion step performs the following steps:</p>
<ol>
<li>All threads are blocked.</li>
<li>An arbitrary thread is unblocked and executes the callable.</li>
<li>If the completion step is done, all threads are unblocked.</li>
</ol>
<p>The following table presents you the interface of a <code>std::barrier bar.</code></p>
<p><img src="http://modernescpp.com/images/blog/Cpp20/Barrier/barrier.png" alt="barrier" width="650" height="222"></p>

<p>The<code> call bar.arrive_and_drop()</code> call means essentially, that the counter is decremented by one for the next phase. The following program<code> fullTimePartTimeWorkers.cpp</code> halves the number of workers in the second phase.</p>
<!-- HTML generated using hilite.me -->
<div>
<pre><span>// fullTimePartTimeWorkers.cpp</span>

<span>#include &lt;iostream&gt;</span>
<span>#include &lt;barrier&gt;</span>
<span>#include &lt;mutex&gt;</span>
<span>#include &lt;string&gt;</span>
<span>#include &lt;thread&gt;</span>

std<span>::</span>barrier workDone(<span>6</span>);
std<span>::</span>mutex coutMutex;

<span>void</span> <span>synchronizedOut</span>(<span>const</span> std<span>::</span>string<span>&amp;</span> s) noexcept {
    std<span>::</span>lock_guard<span>&lt;</span>std<span>::</span>mutex<span>&gt;</span> lo(coutMutex);
    std<span>::</span>cout <span>&lt;&lt;</span> s;
}

<span>class</span> <span>FullTimeWorker</span> {                                                   <span>// (1)</span>
 <span>public:</span>
    FullTimeWorker(std<span>::</span>string n)<span>:</span> name(n) { };
  
    <span>void</span> <span>operator</span>() () {
        synchronizedOut(name <span>+</span> <span>": "</span> <span>+</span> <span>"Morning work done!</span><span>\n</span><span>"</span>);
        workDone.arrive_and_wait();  <span>// Wait until morning work is done     (3)</span>
        synchronizedOut(name <span>+</span> <span>": "</span> <span>+</span> <span>"Afternoon work done!</span><span>\n</span><span>"</span>);
        workDone.arrive_and_wait();  <span>// Wait until afternoon work is done   (4)</span>
        
    }
 <span>private:</span>
    std<span>::</span>string name;
};
  
<span>class</span> <span>PartTimeWorker</span> {                                                   <span>// (2)</span>
 <span>public:</span>
    PartTimeWorker(std<span>::</span>string n)<span>:</span> name(n) { };
  
    <span>void</span> <span>operator</span>() () {
        synchronizedOut(name <span>+</span> <span>": "</span> <span>+</span> <span>"Morning work done!</span><span>\n</span><span>"</span>);
        workDone.arrive_and_drop();  <span>// Wait until morning work is done  // (5)</span>
    }
 <span>private:</span>
    std<span>::</span>string name;
};

<span>int</span> <span>main</span>() {

    std<span>::</span>cout <span>&lt;&lt;</span> <span>'\n'</span>;

    FullTimeWorker herb(<span>"  Herb"</span>);
    std<span>::</span><span>thread</span> herbWork(herb);
  
    FullTimeWorker scott(<span>"    Scott"</span>);
    std<span>::</span><span>thread</span> scottWork(scott);
  
    FullTimeWorker bjarne(<span>"      Bjarne"</span>);
    std<span>::</span><span>thread</span> bjarneWork(bjarne);
  
    PartTimeWorker andrei(<span>"        Andrei"</span>);
    std<span>::</span><span>thread</span> andreiWork(andrei);
  
    PartTimeWorker andrew(<span>"          Andrew"</span>);
    std<span>::</span><span>thread</span> andrewWork(andrew);
  
    PartTimeWorker david(<span>"            David"</span>);
    std<span>::</span><span>thread</span> davidWork(david);

    herbWork.join();
    scottWork.join();
    bjarneWork.join();
    andreiWork.join();
    andrewWork.join();
    davidWork.join();
  
}
</pre>
</div>

<p>This workflow consists of two kinds of workers: full-time workers (1) and part-time workers (2). The part-time worker work in the morning, the full-time worker in the morning and the afternoon. Consequently, the full time workers call<code> workDone.arrive_and_wait()</code> (lines (3) and (4)) two times. On the contrary, the part-time works call <code>workDone.arrive_and_drop()</code> (5) only once. This <code>workDone.arrive_and_drop()</code> call causes the part-time worker to skip the afternoon work. Accordingly, the counter has in the first phase (morning) the value 6, and in the second phase (afternoon) the value 3.</p>
<p><img src="http://modernescpp.com/images/blog/Cpp20/Barrier/fullTimePartTimeWorkers.png" alt="fullTimePartTimeWorkers" width="500" height="328"></p>
<p>Now to something, I missed in my posts to atomics.</p>
<h2 id="h2-atomic-smart-pointers">Atomic Smart Pointers</h2>
<p>A <code>std::shared_ptr</code> consists of a control block and its resource. The control block is thread-safe, but access to the resource is not. This means modifying the reference counter is an atomic operation and you have the guarantee that the resource is deleted exactly once. These are the guarantees <code>std::shared_ptr</code> gives you.</p>
<p>On the contrary, it is crucial that a <code>std::shared_ptr</code> has well-defined multithreading semantics. At first glance, the use of a <code>std::shared_ptr</code> does not appear to be a sensible choice for multithreaded code. It is by definition shared and mutable and is the ideal candidate for non-synchronized read and write operations and hence for undefined behavior. On the other hand, there is the guideline in modern C++: <strong>Don't use raw pointers</strong>. This means, consequently, that you should use smart pointers in multithreading programs when you want to model shared ownership.</p>
<p>The proposal <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4162">N4162</a> for atomic smart pointers directly addresses the deficiencies of the current implementation. The deficiencies boil down to these three points: consistency, correctness, and performance.</p>
<ul>
<li><strong>Consistency</strong>: the atomic operations for <code>std::shared_ptr</code> are the only atomic operations for a non-atomic data type.</li>
<li><strong>Correctness</strong>: the usage of the global atomic operations is quite error-prone because the correct usage is based on discipline. It is easy to forget to use an atomic operation - such as using <code>ptr = localPtr</code> instead of <code>std::atomic_store(&amp;ptr, localPt</code>r). The result is undefined behavior because of a data race. If we used an atomic smart pointer instead, the type-system would not allow it.</li>
<li><strong>Performance</strong>: the atomic smart pointers have a big advantage compared to the free <code>atomic_</code>* functions. The atomic versions are designed for the special use case and can internally have a<code> std::atomic_flag</code> as a kind of cheap <a href="https://en.wikipedia.org/wiki/Spinlock">spinlock</a>. Designing the non-atomic versions of the pointer functions to be thread-safe would be overkill if they are used in a single-threaded scenario. They would have a performance penalty.</li>
</ul>
<p>The correctness argument is probably the most important one. Why? The answer lies in the proposal. The proposal presents a thread-safe singly linked list that supports insertion, deletion, and searching of elements. This singly linked list is implemented in a lock-free way.</p>
<p><img src="http://modernescpp.com/images/blog/Cpp20/Barrier/AtomicSinglyLinkedList.png" alt="AtomicSinglyLinkedList"></p>

<p>All changes that are required to compile the program with a C++11 compiler are marked in red. The implementation with atomic smart pointers is a lot easier and hence less error-prone. C++20's type system does not permit it to use a non-atomic operation on an atomic smart pointer.</p>
<p>The proposal <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4162">N4162</a> proposed the new types <code>std::atomic_shared_ptr</code> and <code>std::atomic_weak_ptr</code> as atomic smart pointers. By merging them in the mainline ISO C++ standard, they became partial template specialization of <a href="https://en.cppreference.com/w/cpp/atomic/atomic">std::atomic</a>: <code>std::atomic&lt;std::shared_ptr&gt;</code>, and <code>std::atomic&lt;std::weak_ptr&gt;</code>.</p>
<p>Consequently, the atomic operations for <code>std::shared_ptr&lt;T&gt;</code> are deprecated with C++20.</p>
<h2 id="h3-what-s-next">What's next?</h2>
<p>With C++20, threads can be cooperatively interrupted.&nbsp; Let me show you in my next, what that means.</p>

<div>
	<p><strong>Thanks a lot to my <a href="https://www.patreon.com/rainer_grimm">Patreon Supporters</a></strong><strong>: Matt Braun, Roman Postanciuc, Tobias Zindl, Marko, </strong><span title="Emyr Williams"><strong>G Prvulovic, Reinhold Dröge, Abernitzke,</strong> </span><strong><span title="Emyr Williams">Frank Grimm</span></strong><span title="Emyr Williams"><strong>, Sakib, Broeserl, </strong></span><strong><span title="Emyr Williams">António Pina, Darshan Mody, Sergey Agafyin, <span data-tag="user-details-full-name">Андрей Бурмистров, Jake, GS, Lawton Shoemake, Animus24, Jozo Leko, John Breland, espkk, Wolfgang Gärtner</span></span><span title="Emyr Williams"><span><span></span></span></span>,&nbsp; Louis St-Amour, Stephan Roslen, Venkat Nandam, Jose Francisco, Douglas Tinkham, Kuchlong Kuchlong, Avi Kohn, Robert Blanch, Truels Wissneth, Kris Kafka, Mario Luoni, Neil Wang, Friedrich Huber, lennonli, Pramod Tikare Muralidhara, Peter Ware, and Tobi Heideman.<br></strong></p>

<p><strong>Thanks in particular to Jon Hess, Lakshman,</strong> <strong>Christian Wittenhorst, Sherhy Pyton, Dendi Suhubdy, Sudhakar Belagurusamy, and Richard Sargeant.<br></strong></p>
<p>My special thanks to Embarcadero <a href="https://www.embarcadero.com/products/cbuilder"><img src="http://modernescpp.com/images/Embarcadero/CBUIDER_STUDIO_FINAL_ICONS_1024_Small.png" alt="CBUIDER STUDIO FINAL ICONS 1024 Small" width="100" height="100"></a></p>

<h2>Seminars</h2>
<p>I'm happy to give online-seminars or face-to-face seminars world-wide. Please call me if you have any questions.</p>
<h3>Bookable (Online)</h3>
<h4>Deutsch</h4>
<ul>
<li><a href="https://www.modernescpp.de/index.php/c/2-c/30-embedded-programmierung-mit-modernem-c20210126195655">Embedded Programmierung mit modernem C++: </a>12.04.2021 - 14.04.2021</li>
</ul>
<h3>Standard Seminars&nbsp;</h3>
<p>Here is a compilation of my standard seminars. These seminars are only meant to give you a first orientation.</p>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/22">C++ - The Core Language</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/23">C++ - The Standard Library</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/23">C++ - Compact</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/18">C++11 and C++14</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/19">Concurrency with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/21">Design Patterns and Architecture Patterns with C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/17">Embedded Programming with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/17">Generic Programming (Templates) with C++</a></li>
</ul>
<h4>New</h4>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/16">Clean Code with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/25">C++20</a></li>
</ul>
<h3>Contact Me</h3>
<ul>
<li>Tel.: +49 7472 917441</li>
<li>Mobil: +49 152 31965939</li>
<li>Mail: <a href="http://modernescpp.com/%3Ca%20href="><span id="cloakdd1f6e3242e208830b42a2ac34d961aa">This email address is being protected from spambots. You need JavaScript enabled to view it.</span></a></li>
<li>German Seminar Page: <a href="https://www.modernescpp.de/">www.ModernesCpp.de</a></li>
<li>English Seminar Page: <a href="http://www.modernescpp.net/">www.ModernesCpp.net</a></li>
</ul>
<h3>Modernes C++,</h3>
<p><img src="http://modernescpp.com/images/signatur/RainerGrimmSmall.png" alt="RainerGrimmSmall"></p></div>
			</div></div>]]>
            </description>
            <link>http://modernescpp.com/index.php/barriers-in-c-20</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988369</guid>
            <pubDate>Mon, 01 Feb 2021 13:18:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Control Access to your on-prem services with Cloud IAP and inlets PRO]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988235">thread link</a>) | @alexellisuk
<br/>
February 1, 2021 | https://johansiebens.dev/posts/2020/12/control-access-to-your-on-prem-services-with-cloud-iap-and-inlets-pro/ | <a href="https://web.archive.org/web/*/https://johansiebens.dev/posts/2020/12/control-access-to-your-on-prem-services-with-cloud-iap-and-inlets-pro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<figure>
    <img src="https://johansiebens.dev/uploads/2020-12-29/banner.jpg" alt="photo by Scott Webb on Unsplash"> <figcaption>
            <p>photo by <a href="https://unsplash.com/@scottwebb?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank">Scott Webb</a> on <a href="https://unsplash.com/" target="_blank">Unsplash</a></p>
        </figcaption>
</figure>


<h2 id="introduction">Introduction</h2>

<p><a href="https://cloud.google.com/iap" target="_blank"><strong>Google Cloud Identity-aware Proxy</strong></a>, or in short IAP, is an access control tool on the Google Cloud Platform for controlling access based on <em>who</em> is making an HTTP request to your application or <em>who</em> is making SSH connections to your virtual servers. As part of the <a href="https://cloud.google.com/beyondcorp/" target="_blank">BeyondCorp</a> security model, it enables context-aware access from virtually any location to your applications or VMs without the need for bastion hosts or a traditional VPN.</p>

<figure><a href="https://inlets.dev/">
    <img src="https://johansiebens.dev/uploads/2020-12-29/inlets-pro-purple.png" width="80"> </a>
</figure>


<p><a href="https://inlets.dev/" target="_blank"><strong>inlets PRO</strong></a> is a Software Defined Network (SDN) for connecting applications. It allows you to tunnel your private service to a remote network, or get a public IP and serve traffic to your users. As it is Cloud Native by design, it can run on containers or VMs. By running the server part of the tunnel, also known as an exit-node, on a Google Compute Engine instance, and connecting a client running in a private datacenter, your private services become available for your employees or customers from anywhere without the hassle of VPNs.</p>

<p>What if we could combine Google IAP and inlets? In other words, can we use Google Cloud Identity-Aware Proxy and inlets to create context-aware access control for our on-premises services?</p>

<p>I’m sure the combination will be useful in many use cases. Perhaps you would like to give SSH access to some internal servers from anywhere. Or you want to expose administrative services such as Grafana dashboards or PostgreSQL’s admin interface.</p>

<p>inlets PRO is the perfect fit to make such administrative services available with a public endpoint, but exposing them directly to the internet introduces risk. Forwarding TCP traffic with IAP allows you to reduce that risk, ensuring only authorized users gain access to these sensitive services.</p>

<h2 id="tcp-forwarding-with-iap">TCP forwarding with IAP.</h2>

<p>So what does the IAP TCP forwarding looks like?</p>

<p>From the documentation:</p>

<blockquote>
<p><em>You can use IAP TCP forwarding for other TCP-based protocols by using the <code>gcloud compute start-iap-tunnel</code> command to allocate a local port. The local port tunnels data traffic from the local machine to the remote machine in an HTTPS stream. IAP then receives the data, applies access controls, and forwards the unwrapped data to the remote port. Conversely, any data from the remote port is also wrapped before it’s sent to the local port where it’s then unwrapped.</em></p>
</blockquote>

<figure>
    <img src="https://johansiebens.dev/uploads/2020-12-29/gcp-iap-diagram.svg" alt="a PostgreSQL server protected by Google IAP"> <figcaption>
            <p>a PostgreSQL server protected by Google IAP</p>
        </figcaption>
</figure>


<p>As an example, let’s say we have a PostgreSQL server running on a GCE VM instance, named <em>my-postgres-vm</em>. With the following command, we bring the database service to our local machine:</p>
<div><pre><code data-lang="bash">gcloud compute start-iap-tunnel my-postgres-vm <span>5432</span> <span>\
</span><span></span>  --local-host-port<span>=</span>localhost:5432 <span>\
</span><span></span>  --zone<span>=</span>europe-west1-b</code></pre></div>
<p>All traffic sent to localhost:5432 is forwarded to the VM instance. The port is only accessible by applications running on your local computer.</p>

<p>There are some necessary steps to follow before the command above will be successful.</p>

<p>First, to allow IAP to connect to your VM instances, a proper firewall rule is required. With this firewall rule, you allow ingress traffic from the IP range containing all the IP addresses used by IAP for TCP forwarding to all ports you want to be accessible using IAP TCP forwarding.</p>

<p>E.g. to allow PostgreSQL access to all VM instances in your network, run:</p>
<div><pre><code data-lang="bash">gcloud compute firewall-rules create allow-postgresql-ingress-from-iap <span>\
</span><span></span>  --direction<span>=</span>INGRESS <span>\
</span><span></span>  --action<span>=</span>allow <span>\
</span><span></span>  --rules<span>=</span>tcp:5432 <span>\
</span><span></span>  --source-ranges<span>=</span><span>35</span>.235.240.0/20</code></pre></div>
<p>Next, to control which users and groups are allowed to use IAP TCP forwarding and which VM instances they’re allowed to connect to, configure IAM permissions. These permissions can be granted on project-level or instance-level.</p>

<p>E.g.</p>
<div><pre><code data-lang="bash">gcloud projects add-iam-policy-binding PROJECT_ID <span>\
</span><span></span>    --member<span>=</span>user:EMAIL <span>\
</span><span></span>    --role<span>=</span>roles/iap.tunnelResourceAccessor</code></pre></div>
<p>Only users with the correct IAM permissions can access your service from any location via the Cloud Identity-Aware Proxy with those two steps. All ingress traffic is blocked by the firewall, except if coming from IAP, making it a secure setup.</p>

<blockquote>
<p>One extra step would be enabling <a href="https://cloud.google.com/iap/docs/audit-log-howto" target="_blank">Cloud Audit logs for IAP</a>, which lets you view a request and see all the access levels a user has and hasn’t met.</p>
</blockquote>

<h2 id="tcp-tunnelling-with-inlets-pro">TCP tunnelling with inlets PRO.</h2>

<p>The Cloud Native Tunnel for L4 TCP traffic, inlets PRO, is independent of Google Cloud. In fact, you could use any cloud provider to create a public exit-node for your services. The interesting part is that it is using somehow the same techniques as the Cloud IAP.</p>

<p>An inlets PRO client establishes an outbound connection an inlets PRO server over HTTPS. All traffic is sent over an encrypted WebSocket using HTTPS which works well with HTTP proxies, VPNs, and VM networks.</p>

<figure>
    <img src="https://johansiebens.dev/uploads/2020-12-29/gcp-inlets-diagram.svg" alt="inlets PRO exit-node running on Google Cloud Platform"> <figcaption>
            <p>inlets PRO exit-node running on Google Cloud Platform</p>
        </figcaption>
</figure>


<p>The fastest way to create such an exit-node is using a handy utility <code>inletsctl</code>, which automates the task of creating the server node on cloud infrastructure. It has support for many cloud provider, and obviously, Google Cloud Platform is one of them.</p>

<p>After creating a Service Account key file (more info <a href="https://docs.inlets.dev/#/tools/inletsctl?id=example-usage-with-google-compute-engine" target="_blank">here</a>), you are only one command away from having an inlets PRO server:</p>
<div><pre><code data-lang="bash">inletsctl create <span>\
</span><span></span>  --pro <span>\
</span><span></span>  --provider gce <span>\
</span><span></span>  --project-id $PROJECT_ID <span>\ </span>
  --access-token-file ./key.json</code></pre></div>
<p>The output of the command above will display how to connect an inlets PRO client to punch out a service like PostgreSQL:</p>
<div><pre><code data-lang="bash">inlets PRO <span>(</span><span>0</span>.7.0<span>)</span> exit-server summary:
  IP: <span>104</span>.154.249.125
  Auth-token: rekwwOPQhe2792hqtJDJHjrpR3ZhqsAzsFOW6nTSmzBIGCUkpe1tWGgWA3KXJa32

Command:
  export LICENSE<span>=</span><span>""</span>
  export PORTS<span>=</span><span>"8000"</span>
  export UPSTREAM<span>=</span><span>"localhost"</span>

  inlets-pro client --url <span>"wss://104.154.249.125:8123/connect"</span> <span>\
</span><span></span>	--token <span>"rekwwOPQhe2792hqtJDJHjrpR3ZhqsAzsFOW6nTSmzBIGCUkpe1tWGgWA3KXJa32"</span> <span>\
</span><span></span>	--license <span>"</span>$LICENSE<span>"</span> <span>\
</span><span></span>	--upstream $UPSTREAM <span>\
</span><span></span>	--ports $PORTS</code></pre></div>
<p>Now, there are some attention points when creating an exit-node with <code>inletsctl</code>.</p>

<p>For starters, it requires a <code>default</code> network in the target project and, at the time of writing, there is no option to define another network of your choice.</p>

<p>Next, maybe more important, it will create a rather coarse-grained firewall rule, allowing traffic from any source to any port of the instance. I understand the reasoning behind it, because they don’t know which ports a customer wants to expose, but perhaps you would rather see some more fine-grained firewall rules applied. Of course you can always add some stricter rules yourself, only allowing traffic from your datacenter to the control port 8123 and allowing traffic from your customer datacenter to the data port.</p>

<p>Those two remarks are maybe easy to fix, and as it is open source, reporting this as an issue or even contributing to the project is perhaps something I will do later on.</p>

<h2 id="inlets-pro-tunnel-with-identity-aware-proxy">inlets PRO tunnel with Identity-Aware Proxy</h2>

<p>What do we have to do to enable context-aware access control to on-prem service by combining <strong>Identity-Aware Proxy</strong> and <strong>inlets PRO</strong>?</p>

<p>When we combine the two, you will have:</p>

<ul>
<li>a GCE VM instance with a public IP running an inlets PRO server<br></li>
<li>a firewall rule allowing ingress traffic coming from your datacenter to port <code>8123</code>, the control port of inlets PRO<br></li>
<li>a firewall rule allowing ingress traffic coming from the IP range used by IAP to the ports you would like to expose<br></li>
<li>an inlets PRO client running in your datacenter connected to the server via encrypted WebSockets and an authentication token<br></li>
<li>IAM permissions granted to the users allowed to create IAP tunnels</li>
</ul>

<figure>
    <img src="https://johansiebens.dev/uploads/2020-12-29/gcp-iap-inlets-diagram.svg" alt="inlets PRO exit-node protected by Google IAP"> <figcaption>
            <p>inlets PRO exit-node protected by Google IAP</p>
        </figcaption>
</figure>


<p>Now, when a user is allowed to create an IAP tunnel, they can forward TCP traffic to the VM on a certain port. Instead of a service or an application, the inlets PRO server is listening on that specific port, tunnelling all the traffic to the inlets PRO client in your datacenter, which in turn forwards the traffic to the targeted service or application.</p>

<p><em>In short, with the proper IAM roles, one could securely access the on-premises service from everywhere. And that is what <strong>context-aware access</strong> is all about!</em></p>

<h3 id="known-limitations">Known limitations</h3>

<p>While this set up looks very promising, some limitations are worth to mention.</p>

<p>First, IAP’s TCP forwarding feature isn’t intended for bulk transfer of data, and Google reserves the right to rate-limit users abusing this service.</p>

<p>Second, IAP automatically disconnects sessions after 1 hour of inactivity, and they recommend having logic in your applications to handle reestablishing a tunnel when it becomes disconnected.</p>

<p>For use cases such as granting access to your private database servers to execute some administrative tasks, those limitations shouldn’t be a problem.</p>

<h2 id="provisioning-with-terraform">Provisioning with Terraform</h2>

<p>To make it a little bit easier to get you started, I put together a small <a href="https://terraform.io/" target="_blank">Terraform</a> Module.</p>

<p>This Terraform module provisions all the resources mentioned above, from the VM instance running inlets PRO to the firewall rules and IAM permissions.</p>

<p>In the above diagrams, we took PostgreSQL as an example. With the following Terraform manifest, you could easily install the pictured architecture.</p>
<div><pre><code data-lang="hcl">provider "google" {
  project = var.project
  region  = var.region
}

resource "google_compute_network" "inlets" {
  name                    = "inlets"
  auto_create_subnetworks = false
}

resource "google_compute_subnetwork" "inlets" {
  name          = "inlets"
  ip_cidr_range = var.ip_cidr_range
  region        = var.region
  network       = google_compute_network.inlets.id
}

module "postgresql" {
  source     = "../"
  name       = "postgresql"
  zone       = var.zone
  network    = google_compute_network.inlets.name
  subnetwork = google_compute_subnetwork.inlets.name
  ports      = [3306]
  members = [
    "user:jane@example.com",
    "user:john@example.com",
  ]
}

output "postgresql" {
  value = module.postgresql.inlets_cmd
}</code></pre></div>
<p>Just like <code>inletsctl</code>, the outcome of the <code>terraform apply</code> run displays the command for connecting the client …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://johansiebens.dev/posts/2020/12/control-access-to-your-on-prem-services-with-cloud-iap-and-inlets-pro/">https://johansiebens.dev/posts/2020/12/control-access-to-your-on-prem-services-with-cloud-iap-and-inlets-pro/</a></em></p>]]>
            </description>
            <link>https://johansiebens.dev/posts/2020/12/control-access-to-your-on-prem-services-with-cloud-iap-and-inlets-pro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988235</guid>
            <pubDate>Mon, 01 Feb 2021 13:00:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Attacking OSS Using Abandoned Resources – EvilPacket]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988204">thread link</a>) | @DyslexicAtheist
<br/>
February 1, 2021 | https://evilpacket.net/2021/attacking-oss-using-abandoned-resources/ | <a href="https://web.archive.org/web/*/https://evilpacket.net/2021/attacking-oss-using-abandoned-resources/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        
            
        

        
        
     
          
          
          

          
          
          

          <p>In December I discovered a supply chain vulnerability that impacted 6,530 public npm package versions, at least I thought I did. Turns out that earlier in October of 2020 Security Innovation published similar research dubbing the issue <a href="https://blog.securityinnovation.com/repo-jacking-exploiting-the-dependency-supply-chain">Repo Jacking</a>. This initially took the wind out of my sails but after I thought about it rediscovery is pretty cool and I was able to expand upon it a bit by focusing on abandoned S3 buckets, Google Cloud Storage bucket, expired domain names, and finding and reporting a vulnerability in GitHub to make exploitation possible in some conditions.</p>
<p>If you want to see if your organization is potentially at risk, here is a <a href="https://evilpacket.net/files/vulnerable_package_versions.csv">list of package versions</a> that were found to be vulnerable. If you are using these particular package versions I would recommend not.</p>
<p>While maintainers were notified by email a lot of those emails bounced. Please do not go screaming into the issues, email, or DMs of these package maintainers… and if you do reach out please be kind and respectful of their volunteer, unpaid, time. I encourage all security practitioners to get more involved in the open source communities they complain about (I too could do a better job here)… Anyway, on to the details!</p>
<h2 id="details">Details</h2>
<p>It’s typical for a Node.js based application to have many 3rd party dependencies. These npm packages can point to resources (the package) that are not hosted by the npm Registry. Typically these types of dependencies will be either a file or git repository that is available via HTTP/HTTPS or SSH.</p>
<p>If the dependency reference (domain, storage bucket, GitHub account) becomes abandoned and made available for an attacker to claim then an attacker can now control this resource as part of the npm install process creating an exploitable situation.</p>
<figure><img src="https://evilpacket.net/images/2021/01/dep1.png" data-sizes="auto" data-src="/images/2021/01/dep1.png" alt=""><figcaption></figcaption></figure>
<h3 id="attack-walk-through">Attack Walk Through</h3>
<p>Let’s look at an example of how this might be exploited using a GitHub repository.</p>
<figure><img src="https://evilpacket.net/images/2021/01/dep2.png" data-sizes="auto" data-src="/images/2021/01/dep2.png" alt=""><figcaption></figcaption></figure>
<p>The attacker registers the available GitHub username and creates a repository with the same name and the code they want to be their payload shaped like an npm package.</p>
<figure><img src="https://evilpacket.net/images/2021/01/dep3.png" data-sizes="auto" data-src="/images/2021/01/dep3.png" alt=""><figcaption></figcaption></figure>
<p>When the app owner runs npm install npm will run a git clone on the referenced repository. Let’s say the dependency reference looks like:  <code>github:evilpacket/beep-boop#beta</code> It will clone <code>evilpacket/beep-boop</code>. Once the clone is complete npm will try to git checkout whatever comes after the #, in this case the <code>beta</code> branch or in the case of the lock file it will checkout a particular commit hash.</p>
<h2 id="what-are-some-mitigating-circumstances">What are some mitigating circumstances</h2>
<p>There are some npm features that can change how exploitable this is from situation to situation.</p>
<p><strong>package-lock.json</strong></p>
<p>package-lock.json can save you in <em>some</em> situations, especially for anything that directly references a file vs a repository (repos are a special). This is because it has the integrity hashes that aren’t going to match when the attacker changes the payload.</p>
<p>Also a package-lock.json won’t help you on initial install or if package-lock.json isn’t being used. You should be checking that file into all your projects and using npm ci for builds.</p>
<p><strong>The local npm cache</strong></p>
<p>If the object that is requested is in the cache, you’re going to get that object and not a public or attacker controlled object.</p>
<p><strong>dev Dependencies</strong></p>
<p>Another aspect that shapes exploitability here is if the vulnerable dependency is a dev (development) dependency or not. Dev dependencies aren’t going to get installed with a typical npm install pkg but could still be useful in a targeted attack against a developer of one of those packages ( but who would want to do that 😈 )</p>
<p><strong>GitHub branch names &amp; policies</strong></p>
<p>GitHub (and others like gitlab) will block the creation of a branch name that is 40 hex characters (the same format as a commit hash) with an error like <code>remote: error: GH002: Sorry, branch or tag names consisting of 40 hex characters are not allowed.</code>, however I found a way around this security control so while I couldn’t forge a commit hash I could name a branch the same as the upstream commit hash and our payload would pass validation in the package-lock.json.</p>
<p>This issue was reported to GitHub security ❤️.</p>
<p>Additionally GitHub claims <code>“To prevent developers from pulling down potentially unsafe packages, we now retire the namespace of any open source project that had more than 100 clones in the week leading up to the owner’s account being renamed or deleted.”</code> That said I did not encounter any block when testing exploitation of this issue with older versions of the popular webpack-cli package, but it’s likely all these packages fall just below the popularity watermark set by this control.</p>
<h2 id="results-numbers-and-thats-it">Results, Numbers, and that’s it.</h2>
<p>While I’m never shocked to find vulnerable dependencies in the npm Registry I wasn’t expecting this many packages to be vulnerable.</p>
<p>You can find the package list here: <a href="https://evilpacket.net/files/vulnerable_package_versions.csv">https://evilpacket.net/files/vulnerable_package_versions.csv</a></p>
<p>Summary breakdown by resource type. As you can see the behavior of using GitHub repositories as dependencies and the forwarding behavior that GitHub allows creates a lot more vulnerability.</p>
<table>
<thead>
<tr>
<th>Resource</th>
<th>PKG Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>Google Cloud Storage Buckets abandoned</td>
<td>2</td>
</tr>
<tr>
<td>AWS S3 Bucket abandoned</td>
<td>7</td>
</tr>
<tr>
<td>Domain Name expired</td>
<td>2</td>
</tr>
<tr>
<td>GitHub Repo (not found or redirect)</td>
<td>743</td>
</tr>
</tbody>
</table>
<p>I think the conclusion of this is that you need to scrutinize the open source you use and your supply chain a lot more than you think you do. Enjoy typing npm install.</p>

    </div></div>]]>
            </description>
            <link>https://evilpacket.net/2021/attacking-oss-using-abandoned-resources/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988204</guid>
            <pubDate>Mon, 01 Feb 2021 12:55:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure your MQTT server with authentication and encryption]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25988196">thread link</a>) | @juriansluiman
<br/>
February 1, 2021 | https://jurian.slui.mn/posts/smqttt-or-secure-mqtt-over-traefik/ | <a href="https://web.archive.org/web/*/https://jurian.slui.mn/posts/smqttt-or-secure-mqtt-over-traefik/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">


<article itemscope="" itemtype="http://schema.org/BlogPosting" id="content">
    <header>
        
          <time datetime="" pubdate="" itemprop="datePublished" content="2021-01-31T00:00:00Z" title="2021-01-31T00:00:00Z">January 2021</time>
    </header>

    <section>
      <p>The last days I have been experimenting in different ways how I can secure a
MQTT setup for my home automation. There’s an increasing use of IoT here at my
home and most of the applications communicate over MQTT. You simply cannot
control every device and how it gathers information. To prevent eavesdropping,
it’s time to secure MQTT.</p>
<p>This post is written with the <a href="https://www.troyhunt.com/iot-unravelled-part-3-security/">Troy Hunt IoT series</a>
in mind. Of course, you should patch your devices and put them in a
separate VLAN. However, if you have an MQTT security system and an MQTT light
bulb, did you consider the light bulb had access to the security system via MQTT?
Or did you consider IoT devices that are inside the same VLAN, but don’t use
MQTT themselves, could sniff all (security) messages communicated over your
message broker? It all boils down to the principles of <em>zero trust</em>.</p>
<p>For my home automation I am an avid <a href="https://www.home-assistant.io/">Home Assistant</a>
user. Since a long time I have a Home Assistant setup which controls a variety
of lights, switches and appliances. When I started introducing MQTT to my
setup, I used it without TLS and without authentication. Over time more
applications communicate over MQTT and I was worrying about two things:</p>
<ol>
<li>Untrusted devices could find and connect to the MQTT server without any effort;</li>
<li>Every message in every topic could be listened for anonymously.</li>
</ol>
<p>That’s why I set three goals to tighten things up:</p>
<ol>
<li>Every MQTT client must authenticate via unique usernames/passwords. Every
client gets separate credentials so there’s no reuse of passwords anywhere.</li>
<li>Enable TLS encryption for communication. The MQTT protocol (including
authentication) is plain text, meaning username and password could be sniffed if
no encryption is used.</li>
<li>Use Access Control to prevent devices reading/writing topics they should have
no interest in. If a trusted (authenticated) client sniffs into topics for other
applications, they must be blocked.</li>
</ol>

<p>The message broker I personally use is Mosquitto, as it’s lightweight and
extremely easy to use. Out of the box, it does allow anonymous connections and
no users are registered, so you need to take care of both.</p>
<p>In your <code>mosquitto.conf</code> file, make sure you have those two lines present and
make sure the mosquitto.passwd file exists (just update the path of the password
file based on your installation):</p>
<pre><code>allow_anonymous false
password_file &lt;path/to/mosquitto&gt;/mosquitto.passwd
</code></pre>
<p>Then supply Mosquitto with the credentials you want to add:</p>
<pre><code>mosquitto_passwd &lt;path/to/mosquitto&gt;/mosquitto.passwd &lt;username&gt;
</code></pre>
<p>Again, replace the path &amp; your preferred username and complete the prompt with
the password.</p>
<p>My installation resides inside docker, so in my case, the configuration files
are located at <code>/mosquitto/config/</code> and I add all my clients in bulk (via Ansible)
using the following command (<code>mqtt</code> is the name of my container)</p>
<pre><code>docker exec mqtt mosquitto_passwd -b /mosquitto/config/mosquitto.passwd &lt;user&gt; &lt;password&gt;
docker exec mqtt kill -SIGHUP 1
</code></pre>
<p>The <code>SIGHUP</code> signal is used in Mosquitto to
<a href="https://mosquitto.org/man/mosquitto-8.html#idm296">reload the configuration</a>
without restarting Mosquitto (which otherwise will probably loose some messages
along the way).</p>
<p><strong>Well done: You completed the first part of your goal securing MQTT!</strong></p>

<p>My favourite reverse proxy for production apps and home installation is <a href="https://traefik.io/">Traefik</a>.
It just integrates flawless with the tools I prefer: a dockerized setup and
automated certification renewal via Let’s Encrypt. And it’s so lightweight you
have little overhead for hosts like a Raspberry Pi.</p>
<p>All of my frontend web applications are routed via Traefik’s HTTP(S) proxy. The
fun thing is it also supports TCP and UDP traffic (which I also utilize in my
failover <a href="https://jurian.slui.mn/posts/openvpn-with-traefik-2.2/">TCP+UDP setup for OpenVPN</a>).</p>
<p>MQTT is plain TCP traffic and Traefik is able to create a TLS tunnel for TCP
traffic, so this is a fairly straightforward thing to configure. To understand
the label configuration below, make sure you read the
<a href="https://doc.traefik.io/traefik/routing/providers/docker/">Traefik documentation</a>.</p>
<pre><code>labels:
  - traefik.enable=true
  
  - traefik.tcp.routers.mqtt.rule=HostSNI(`mqtt.example.com`)
  - traefik.tcp.routers.mqtt.entrypoints=mqtt
  - traefik.tcp.routers.mqtt.tls=true
  - traefik.tcp.routers.mqtt.service=mqtt
  
  - traefik.tcp.services.mqtt.loadBalancer.server.port=1883
</code></pre>
<p>Traefik usually connects to a container’s port if there’s only one port exposed.
To be explicit I define a <code>mqtt</code> service in this case, loadbalancing the only port
in the mosquitto container. I make this explicit because the default
(unencrypted) MQTT port is 1883 and the default TLS encrypted port is 8883. If you
ever read back the configuration you should be able to trace things back.</p>
<p>Next, the docker container uses an entrypoint called <code>mqtt</code> defined in the
static configuration. Most Traefik setups use at least a <code>web</code> and <code>websecure</code>
entrypoint, I added <code>mqtt</code> at port <code>8333</code>. This creates a setup where the
docker container itself exposes an (unencrypted) port 1883 towards Traefik, this
container is inaccessible from the outside. Traefik creates an accessible
entrypoint, which will be encrypted, at port 8883. This technique is called
<em>SSL Termination</em>.</p>
<pre><code>[entryPoints]
  [entryPoints.web]
    address = ":80"
  [entryPoints.websecure]
    address = ":443"
  [entryPoints.mqtt]
    address = ":8883"
</code></pre>
<p>Finally, the rule label in the docker container gives a URL to use (like
<code>mqtt.example.com</code>) and with  <code>tls=true</code> you tell Traefik to <a href="https://doc.traefik.io/traefik/https/overview/">handle it as a
TLS connection</a>.</p>
<p><strong>This is great: You are more than halfway through securing MQTT!</strong></p>

<p>Access control in an MQTT server is the final step in securing your messaging
system for IoT. Access control defines access on a per-user basis, so above
steps for authentication and encryption are required to go further down the
security lane. Initiating access control is a principle of a whitelist, anything
<em>not</em> specified means there is <em>no access</em>. You only need to state which clients
have access to which topics, anything else is excluded.</p>
<p>Like the password file, the ACL file is referenced in the mosquitto.conf:</p>
<pre><code>acl_file &lt;path/to/mosquitto&gt;/acl
</code></pre>
<p>Next, you need to fill your ACL file. Jaimyn Mayer has an <a href="https://jaimyn.com.au/mqtt-use-acls-multiple-user-accounts/">excellent tutorial
for composing an ACL file</a>
with the usage of Home Assistant in mind so I won’t elaborate too much on this.</p>
<p>The basic format of the file consists of sections per user, where every topic
is listed to grant read and/or write access. Because of the nested structure of
MQTT topics, you can use wildcards to group topics at a higher level.</p>
<p>From Jaimyn’s example, using Home Assistant, Sonoff (WiFi powered) lights and
light sensors:</p>
<pre><code># Give Home Assitant full access to everything
user homeassist
topic readwrite #

# Allow the sonoffs to read/write to cmnd/# and stat/#
user sonoffswitch
topic readwrite cmnd/#
topic readwrite stat/#

# Allows the light sensor to read/write to the sensor topics
user lightsense
topic cmnd/sensor/#
topic stat/sensor/#
</code></pre>
<p>Tip: if you don’t know which topics are used by your devices, send Mosquitto
the <code>SIGUSR2</code> signal and it outputs a hierarchy of topics:</p>
<pre><code>kill -SIGUSER2 &lt;pid-of-mosquitto&gt;
</code></pre>
<p>In my docker setup this translates to (the output is send to stdout, so you need
to check the container logs):</p>
<pre><code>docker exec mqtt kill -SIGUSR2 1
docker logs mqtt
</code></pre>
<p>Again, when finished composing your ACL file, make sure to reload Mosquitto:</p>
<pre><code>// For normal installation
kill -SIGHUP &lt;pid-of-mosquitto&gt;

// For docker installation
docker exec mqtt kill -SIGHUP 1
</code></pre>
<p><strong>You are awesome! You completed your goal in securing your MQTT message broker!</strong></p>

<p>This ended up as a much longer post than anticipated. I was reluctant to get
going with this setup but it ended up pretty nice. The overhead (and delay in
message delivery) with TLS encryption in comparison with unencrypted MQTT is
unnoticable for me. In addition, it gives me a much safer feeling
compartimentising all the variety of IoT devices. I simply don’t trust all the
‘things’, especially the cheap stuff from far abroad. Now I know that stuff just
can’t sniff around the communication of other devices.</p>
<h2 id="client-tls-capabilities">Client TLS capabilities</h2>
<p>Just to make one thing clear if you go down this road, it may seem obvious but
encrypting MQTT traffic means every client must connect over TLS only. Switching
over to Traefik means you go over the configuration of every MQTT client (lights,
switches, cameras and so on) to enable a security flag in their respective
settings. Otherwise you end up only <em>pretending</em> being a security endboss.</p>
    </section>

    
</article>

  </div></div>]]>
            </description>
            <link>https://jurian.slui.mn/posts/smqttt-or-secure-mqtt-over-traefik/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988196</guid>
            <pubDate>Mon, 01 Feb 2021 12:54:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Python course for 5 days with certificate, starts today]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25988140">thread link</a>) | @cobanov
<br/>
February 1, 2021 | https://globalaihub.com/event/introduction-to-python-programming-1-5-february/ | <a href="https://web.archive.org/web/*/https://globalaihub.com/event/introduction-to-python-programming-1-5-february/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="58158d8" data-element_type="widget" data-widget_type="jet-listing-dynamic-field.default">
<div>
<div><div><div><p>Welcome to our introduction to Python programming course!</p>
<p>In our Introduction to Python Programming course, we will be covering basic topics like syntax, data types, operators, control flows, functions and some libraries in Python. Also we prepared great materials using different worldwide resources to support your learning process!</p>
<p>During the class, we will create simple programs and a few homework will be given after the lessons to improve your coding skills.</p>
<p>Enroll our Python Introduction to Programming course and let’s start coding with the most popular language in today’s world!</p>
<p>You can ask all your questions via Python Hub in Global AI Hub Community.</p>
<p>You can check <a href="https://globalaihub.com/faq/">most frequently questions</a> about this course.</p>
</div></div></div> </div>
</div></div>]]>
            </description>
            <link>https://globalaihub.com/event/introduction-to-python-programming-1-5-february/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988140</guid>
            <pubDate>Mon, 01 Feb 2021 12:47:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top trends in Node.js to Watch in 2021]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988117">thread link</a>) | @annnikiel
<br/>
February 1, 2021 | https://selleo.com/blog/top-trends-in-node-js-to-watch-in-2021 | <a href="https://web.archive.org/web/*/https://selleo.com/blog/top-trends-in-node-js-to-watch-in-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The year 2021 has just started, and everyone is predicting trends in their respective fields. After the COVID-19 pandemic, the E-commerce industry has blossomed like never before. More and more businesses are shifting their business models to virtual markets. In this rapidly growing software development, choosing the right framework has become one of the most important and complicated tasks.</p><p>Developers all over the world are also assuming many predictions for trends in Node.js for 2021. In this article, we will explain the expected trend in Node.js for 2021.</p><p>Let’s start the article by learning more about Node.js and its popularity.</p><h2 id="what-is-nodejs">What is Node.js?</h2><p>Node.js is a JavaScript runtime built on Chrome’s V8 JS engine. It uses an event-driven, asynchronous, non-blocking input/output model (meaning how it interacts with the system’s disk and network, e.g., reading/writing data, making HTTP requests, etc.). It operates on a single thread event loop.</p><p>Node.js was created in 2009 by Ryan Dahl. He argued that software should be able to multi-task and said that the right way to handle several concurrent connections was to have a single-thread, an event loop, and non-blocking I/Os. This all made Node very efficient and eliminated the wait for requests.</p><p>More details about <a href="https://selleo.com/blog/why-choose-node-js">Node.js and why to choose it</a> is linked in the article.</p><h2 id="why-is-nodejs-so-popular">Why is Node.js so popular?</h2><p>The popularity of Node.js has grown significantly in recent years because of its extremely lightweight and high flexibility. Node.js comes with an extensive library of JavaScript</p><p>modules that simplify the development process. Due to its open-source nature, Node.js has become incredibly popular for both web and mobile application development.</p><p>Recent statistics show that:</p><ul><li>As of early 2020, more than 50% of the developers use Node.js in their projects.</li><li>In the USA, more than 28000 websites are built on Node.js technology.</li><li>Big names like eBay, AliExpress, and others are relying on Node.js.</li><li>Node.JS is used by websites that get heavy traffic, such as Netflix, PayPal, and Groupon.</li><li>Since 2009 when Node.js was introduced into the developer world, its popularity has wildly grown. In Github, Node.js has 75.9k stars, 19k forks, and 3k watchers. In Stack share, it has 71.8k followers and 8.3k votes. These numbers alone can show how popular Node.js is. Popular tech giants like Microsoft and Netflix use Node.js.</li><li>Node.js won the top spot in the StackOverflow’s 2020 developer survey. Over half of the respondents in the survey reported having used it in their projects.</li></ul><h2 id="top-nodejs-frameworks">Top Node.js Frameworks</h2><p>There are 6 top Node.js frameworks popular for their lightweight and simplified development process. Let’s get to know each one of them in small details.</p><h3 id="expressjs">Express.js</h3><p>Express.js is one of the top web application frameworks of Node.js. It is highly lightweight and flexible that comes with robust features for the website and mobile app development. The Express.js framework provides a layer of fundamental web application features without obscuring Node.js features. There are numerous popular frameworks based on Express.js.</p><p><img alt="Img" src="https://a.storyblok.com/f/86602/720x405/6f3f4cea60/node-trends2.jpg"></p><h3 id="meteorjs">Meteor.js</h3><p>Meteor.js is an open-source platform that is used by millions of developers to develop web and mobile apps. It is well-known among developers for making javascript applications simple, efficient, and scalable. It took over a decade of hard work by the industry giants to make it to its perfection. Meteor is a mature open-source framework that allows you to build and scale efficiently so you can serve millions of users.</p><h3 id="koajs">Koa.js</h3><p>Koa.js middleware stack flows in a stack-like manner, allowing a developer to perform actions downstream then filter and manipulate the response upstream. Koa is a new web framework designed by the team behind Express, aiming to be a smaller, more expressive, and more robust foundation for web applications and APIs. By leveraging async functions, Koa allows developers to ditch callbacks and greatly increase error-handling. Koa does not bundle any middleware within its core, and it provides an elegant suite of methods that make writing servers fast and enjoyable.</p><h3 id="sailsjs">Sails.js</h3><p>Sails.js  - one of the most famous MVC frameworks for Node.js. It is designed to match the familiar MVC pattern of frameworks like Ruby on Rails, but with support for modern apps' requirements. It provides features like data-driven APIs with a scalable and service-oriented architecture.</p><h3 id="hapijs">Hapi.js</h3><p>Hapi.js is an open-source framework for web and desktop applications. It is most commonly used to build web services such as JSON API, websites, and HTTP proxy applications. The mobile team created the framework at Walmart Labs. Mr. Eran Hammer, who created OAuth, was the brain behind this technology. He designed it to handle their traffic for Black Friday events, one of the busiest days for online shopping in the U.S. calendar. The original versions of Hapi used the Express framework.</p><h3 id="nestjs">NestJS</h3><p>NestJS is an open-source, extensible, versatile, progressive Node.js framework for creating compelling and demanding backend systems. It is currently the fastest-growing Node.js framework in TypeScript. NestJS is used for writing scalable, testable and loosely coupled applications. It brings scalable Node.js servers to a whole new level.</p><p>Check out more reasons why you should choose Nest.js as your desired Framework in this detailed <a href="https://selleo.com/blog/why-choose-nest-js-as-your-backend-framework">article.</a></p><p>Moving on to the main topic of the article and checking out the top trends in Node.js to watch in 2021.</p><h2 id="leading-trends-in-nodejs-to-watch-in-2021">Leading Trends in Node.js to Watch in 2021</h2><p>Here’re some of the most predicted trends in Node.js that will help businesses leverage their potential and get an edge over their competitors in 2021.</p><h3 id="trend--1-graphql-deployment-in-nodejs-apps">Trend # 1: GraphQL Deployment in Node.js apps</h3><p>GraphQL is a query language. By using GraphQL, a client can request for the data they need from the server, and the server will send a JSON response to the query. The interesting thing to note here is that the client can ask for exactly what they need, and they receive only what is required.</p><p><img alt="Img" src="https://a.storyblok.com/f/86602/720x348/67ad47822d/node-trends-1.jpg"></p><h4 id="the-popularity-of-graphql-in-2020">The Popularity of GraphQL in 2020</h4><ul><li>An emerging Node.js trend - GraphQL has grown immensely in popularity over the last two years. Due to its ability to streamline the workflow on multiple platforms, it has become the choice of millions of developers worldwide.</li><li>The GraphQL Foundation, a newly established organization hosted by the Linux Foundation, governs developments around GraphQL. GraphQL servers are available for multiple popular languages, e.g., Java, JavaScript, Ruby, Python, Perl, C#, Go, etc.</li><li>The popularity of GraphQL grew rapidly. E.g., The State of JavaScript 2018 report mentions that only 5% of developers surveyed had used it in 2016. However, 20.4% of developers used it in 2018.</li></ul><h4 id="graphql-is-the-best-alternative-for-rest-api-and-why-should-it-be-used">GraphQL is the best Alternative for REST API And Why should it be used?</h4><p>GraphQL offers several advantages over REST, which are as follows:</p><ul><li>Apps using REST APIs call endpoints. The entire data in that endpoint will be returned in the JSON format. This results in over-fetching as well as under-fetching, which can cause scalability and performance issues. GraphQL, with its queries, schemas, and resolvers, enables developers to design API calls that meet their specific data requirements. This way, GraphQL resolves the over-fetching and under-fetching challenges.</li><li>Due to designing the endpoints according to the view in the application using REST API, it can create a bottleneck when the application needs quick iterations on the frontend. Such iterations might require more data in the frontend, or they might require fewer data. GraphQL doesn’t create such a bottleneck due to its flexibility. The iterations for developing the frontend can continue without having to change the backend.</li><li>Applications built on REST API get all the data in the Endpoint. The application owner can’t gain insights into specific data elements since the entire data is returned every time. Whereas, in GraphQL, a developer can use the specific queries to retrieve specific data elements. This enables the application owner to gain insights into which data elements are in demand. Moreover, they will know which data elements aren’t being used by clients anymore.</li></ul><h3 id="trend--2-mean--mern-stack">Trend # 2: MEAN &amp; MERN Stack</h3><p>MEAN (MongoDB, Express, Angular, Node.JS) and MERN (MongoDB, Express, React, Node.JS) are the two stacks that constitute amazingly powerful technologies in the field of app development. These technologies are rapidly growing open-source web and app development frameworks that enable a developer to develop complex applications and frontend web apps.</p><p>These technologies are used by some of the biggest tech companies, like Netflix, which boost its popularity. Netflix's entire website relies on the MERN stack framework for the smooth web development experience.</p><h3 id="trend--3-real-time-apps">Trend # 3: Real-Time Apps</h3><p>In the year 2021, people demanded real-time apps for different online activities. These real-time apps are the most common cause of Node.js. With amazing user-engagement, real-time apps not only provide a set of incredible features but speed as well. These apps include features like live chats, social media integration, ad servers, gamification, stock exchange features, etc. Node.js fits all the requirements in this ecosystem.</p><p><img alt="Img" src="https://a.storyblok.com/f/86602/720x348/9c304b787f/real-time-assets.jpg"></p><p>Node.js apps can serve thousands of servers for data-intensive and real-time IoT device apps as well. However, there is one drawback of these real-time apps as they can overload a server. Node.js makes the collaboration environment update seamlessly due to Event API and Web Sockets. Trello is one of the biggest examples of a web-app where a real-time collaboration pattern is implemented.</p><p>The other kind of real-time apps which can be build using Node.js frameworks are:</p><ul><li>Video conference apps</li><li>Document sharing apps</li><li>Voice over Internet Protocol</li><li>Online gaming</li><li>E-commerce transactions like stockbroking</li><li>Instant messaging apps</li></ul><p>Because of the fast performance and open-source flexibility, Node.js has been a popular choice among the top-notch web and app developers worldwide.</p><h3 id="trend--4-serverless-architecture">Trend # 4: Serverless Architecture</h3><p>Node.js is most famous for its serverless architecture. It means that to create an …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://selleo.com/blog/top-trends-in-node-js-to-watch-in-2021">https://selleo.com/blog/top-trends-in-node-js-to-watch-in-2021</a></em></p>]]>
            </description>
            <link>https://selleo.com/blog/top-trends-in-node-js-to-watch-in-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988117</guid>
            <pubDate>Mon, 01 Feb 2021 12:42:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The house that Bitcoin built]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988070">thread link</a>) | @donohoe
<br/>
February 1, 2021 | https://restofworld.org/2021/rise-and-fall-of-the-house-of-bitcoin/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/rise-and-fall-of-the-house-of-bitcoin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p><span>A</span> small alleyway just a few blocks from the bustling Avenida Santa Fe, Pasaje Voltaire gives the impression that it’s keeping a secret. It carries the aura of the bygone era when bohemian<strong> </strong>artists and intellectuals dominated Palermo, long before it became one of the most fashionable barrios in Buenos Aires. A block over are bars where it’s rare to hear Spanish and common to overpay for drinks. This 100-meter long passageway, however, offers no such attractions. A tourist wouldn’t think twice about walking past it, nor would a local who lives in the area. With its cobblestones and squat houses, Pasaje Voltaire is a bastion of residential silence within the lively neighborhood. It’s completely inconspicuous, save for a two-story edifice dotted with clouded windows that offer no glimpses into what’s happening inside.</p>



<p>Until recently, the building was home to a rotating cast of recent engineering graduates. Here, in Jorge Luis Borges’s former neighborhood, they chased their own kind of dream, one they believed would change the world: cryptocurrency. When they weren’t founding companies, they hosted all-night hackathons, threw elaborate parties, and welcomed friends and allies for deep talks on the nature of the social contract and the inherent value of legal tender.</p>



<p>On the right-hand side<strong> </strong>of the<strong> </strong>façade is the only remaining trace of their presence. It’s a campy illustration of a samurai Darth Vader with an owl on his shoulder. The signature below it reads “Dilucious,” the nom de plume of an artist who used to live in the building. His real name is Agustín, and he’s one of the few people willing to speak to the media about his years in the building, which is known as Voltaire House.</p>



<p>In 2015, Agustín took a sabbatical from work with the aim of reinventing himself as an artist. He had studied engineering at the Buenos Aires Institute of Technology, or ITBA, and was making good money as a developer for an Argentine telecommunications company, but he felt trapped in corporate culture. As luck would have it, he heard about some ITBA alums who had transformed a building into a “crazy hacker haven” for cryptocurrency projects. The founders were on the same spiritual journey as Agustín. After a meeting and a short deliberation, the members of Voltaire House invited Agustín to be their artist-in-residence.</p>



<p>This was before “Bitcoin” became a familiar term and crypto bros began to be stereotyped as overnight millionaires. For the coder community of Argentina at that time, cryptocurrency meant something more serious — a way to create new forms of social interaction and to upend broken economic and political systems. Ever since a coder calling himself Satoshi introduced Bitcoin in a 2008 white paper, the prospect of a decentralized, peer-to-peer monetary system had become synonymous with a potential new world: one controlled not by banks or governmental institutions but by anyone with access to a computer.</p>



<p>This vision was particularly potent in Argentina. The hackers of Voltaire House had grown up amid the turbulence of the 1990s and 2000s — an era of the country’s history defined by corrupt political administration and economic collapse, precipitated by the central government. After the country defaulted on more than $100 billion of debt in 2001, the Argentine peso began a two-decade devaluation, going from 1:1 with the U.S. dollar to 85:1 today. Argentines grew accustomed to their paychecks being devalued the instant the money landed in their bank accounts. There was no access to a stable alternative, either, as U.S. dollars were either banned or severely restricted. Many resorted to buying black-market U.S. dollars, known as “blue dollars,” which often sold for more than twice the official exchange rate.</p>



<p>Cryptocurrency offered a means of circumventing the volatility of the local economy, and the members of Voltaire House were early adopters. They believed that Bitcoin would enable them to build a future that didn’t depend on decaying institutions. Two decades later, with the value of the peso plummeting and Bitcoin trading in Argentina soaring to historic highs, this kind of thinking has emerged again.<strong> </strong>Blockchain evangelists have long touted its revolutionary power to disrupt global economic models and supplant central authorities. While this seems unlikely in countries with stable monetary institutions like the United States, Argentina is in certain respects an ideal test case. Ultimately, however, Voltaire House offered a very different lesson about the cryptocurrency’s transformative power.<strong>&nbsp;</strong></p>



<p>The mainstays of Voltaire House — about 15 people, mostly men who knew one another from ITBA — believed transparency and decentralization could fix their broken country. In pursuit of this, over a roughly three-year period, they hosted daily lunches, fell into heated discussions about theoretical physics and social science, and once invited a hacker who had broken into the servers of the Buenos Aires subway system to come meet with them. All conversations inevitably came back to basic questions of economics and society: What is money? And who should control it? They didn’t just talk: They built what would become some of Argentina’s most successful blockchain companies, including Decentraland, Muun, and OpenZeppelin,<strong> </strong>which facilitated the exchange of tens of millions of real-world dollars.</p>



<p>“The house itself was a project,” said Sacha Lifszyc, a visitor during those years. For the few young programmers in Buenos Aires lucky enough to be extended an invitation, going to Voltaire House was like entering a refuge where everything contained the potential for innovation. From the outset, its members were famously secretive: There’s scarcely any digital footprint of the talks and parties they hosted, and Voltaire’s events and public discussions were promoted <em>boca en boca</em>. Aside from a <a href="https://medium.com/decentraland/an-inside-look-into-how-crypto-projects-are-made-bffae4b20eae">Medium article in 2017</a>, Voltaire House avoided media coverage. All of its key members dodged interview requests for this story, making it clear through intermediaries that they weren’t interested, and strongly discouraged others from speaking. “This ethos of being anonymous really resonates with them,” said Agustín Ferreira, a coder who was friends with many in the house. “Like being Satoshi, you know?”</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/GettyImages-483584244-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/GettyImages-483584244-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/GettyImages-483584244-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/GettyImages-483584244-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/GettyImages-483584244-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/GettyImages-483584244-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/GettyImages-483584244-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Voltaire House was located in Buenos Aires's Palermo neighborhood, known for its bustling nightlife and touristy offerings.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Victor J. Blue/Bloomberg/Getty Images</span>
			</figcaption>
		</figure>


<hr>



<p>Manuel Aráoz founded Voltaire House in 2014 after graduating from ITBA with a degree in computer science and joining a U.S.-based crypto wallet, BitPay, as one of its first employees. Thanks to the success of the e-commerce giant MercadoLibre, Argentina had acquired a reputation as a hotbed for highly trained software developers. Domestic and foreign tech companies employed <a href="https://www.progressivepolicy.org/wp-content/uploads/2016/05/2016.05-DiIonno_Mandel_Argentina_The-Road-to-the-App-Economy.pdf">tens of thousands</a> of coders in the country, <a href="https://www.quora.com/What-is-the-annual-salary-in-USD-of-a-senior-software-web-application-developer-in-Argentina-or-Buenos-Aires">often paying them</a> four or five times the national minimum wage. (Agustín described coding as the second-most lucrative job in the country after football.) Yet while computer engineering was an acceptable career, cryptocurrency was still new, as were most of the companies working with it. When Aráoz joined BitPay, it<strong> </strong>had about $2.5 million in funding. Today, it has raised a total of $72.5 million.</p>



<p>To build out BitPay’s development team in Argentina, Aráoz leased the building that would become Voltaire. The house soon became a creative laboratory for him and his friends. It hosted the regular crew of about 15 coders, with others streaming in and out. House members would congregate around a big table framed by a giant statue of the letter “V” or gather in the little back garden for cookouts. During these years, members were constantly tinkering. A visitor recalled how they had outfitted a small room with VR sensors and once tried to install a system that would play customized music for each person who entered the house.</p>



<p>This early experimentation would lead to Voltaire House’s highest-profile creation: Decentraland, a VR metaverse powered by the Ethereum blockchain with its own crypto token.<strong> </strong>To put it in layman’s terms, Decentraland was a virtual world with a limited number of properties that people could buy through a proprietary currency and sell for real money. It was a petri dish for the ideals of democracy and decentralization they championed, built on the premise that a virtual world controlled by its own “citizens” could more effectively govern itself — and offer more stable investment opportunities — than a real one governed by elites. Decentraland’s founders stipulated that it would be overseen by a “Decentralized Autonomous Organization,” a group of Decentraland residents who would vote on management decisions.&nbsp;</p>



<p>These were the heady days of cryptocurrency, when the possibilities for expansion seemed infinite. Between February and December of 2017 alone, the value of a single Bitcoin jumped from under $1,000 to almost $20,000, and the members of Voltaire House did not want to miss out on the opportunity. In August of that year, Decentraland hosted what is known as an initial coin offering, in which they started publicly selling their token. They <a href="https://bravenewcoin.com/insights/decentraland-raises-24-million-in-35-seconds-leaving-retail-investors-out-in-the-cold">raised</a> $24 million in 35 seconds, before shutting down the ICO. It’s unclear whether the creators ever cashed out, but some users did: One later told <a href="https://www.marketwatch.com/story/people-are-making-more-than-500-buying-property-that-doesnt-actually-exist-2018-09-04">MarketWatch</a> that he spent $60,000 on plots in Decentraland’s first city, which was&nbsp;eventually worth $350,000.</p>



<p>Decentraland is one of about a half-dozen products to achieve international recognition whose origins can be traced to Voltaire, despite the house’s low profile.<strong> </strong>Another of Aráoz’s contributions to the world of crypto was a service called <a href="https://www.coindesk.com/how-block-chain-technology-is-working-to-transform-intellectual-property">Proof of Existence</a>, a decentralized online notary, which made a splash as the first nonfinancial application of blockchain. In 2014, leading crypto-news outlet <em>Coindesk</em> projected that Proof of Existence could “revolutionize intellectual property rights,” and Voltaire House member Esteban Ordano went on <a href="https://blog.po.et/introducing-po-et-digital-media-blockchain-technology-collide-e53728fc1c24">to adapt</a> the technology underlying it for his own company, <a href="https://www.po.et/?utm_source=icodrops">Po.et</a>, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/rise-and-fall-of-the-house-of-bitcoin/">https://restofworld.org/2021/rise-and-fall-of-the-house-of-bitcoin/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/rise-and-fall-of-the-house-of-bitcoin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988070</guid>
            <pubDate>Mon, 01 Feb 2021 12:33:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Regulation as a Service]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987943">thread link</a>) | @csomar
<br/>
February 1, 2021 | https://omarabid.com/regulation-as-a-service | <a href="https://web.archive.org/web/*/https://omarabid.com/regulation-as-a-service">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="container">
  <article id="5GcF7g1wkjJLTc5cfjqR5t">
	<time datetime="2021-02-01">February  1, 2021</time>
  
	<p><a href="https://bitstamp.net/">Bitstamp</a> recently upped it’s KYC game: The exchange now requires a tons of documentation to allow you trading any amount there. To open an account and start trading you need to provide: Your passport, Proof of residence (some utility bill), You trading history (at other exchanges), Sources of funding (documents such as tax slips), and also you need to fill a questionnaire about your trading activity.</p>

<p>If you thought this is bad, here is one more: It costs 0.5% to trade on Bitstamp; whether you are a maker or a taker. The industry standard seems to be around 0.2-0.1%. Bitstamp is 5 times more expensive and 10 times more burdensome to trade with. Which really begs the question: Is there any reason for Bitstamp to exist?</p>

<p>The answer might be a surprising: Yes</p>

<p>See, centralized exchanges are a dead business. The only reason they exist today is that de-centralized exchanges are still impractical, complicated and very expensive. But this is bound to change: Instantaneous <a href="https://en.bitcoin.it/wiki/Atomic_swap">atomic swaps</a> are mostly theoretical for now, but they will become practical in the future. And much cheaper too.</p>

<p>To trade in a centralized exchange, first, you need to send your crypto to the said exchange and entrust its solvency. Then, you can access the pool of liquidity of that exchange, and rely on arbitrage traders to transfer liquidity from other exchanges. Once the trade is completed, you withdraw your converted crypto.</p>

<p>Things are different in a decentralized landscape: You only send your crypto to execute the trade. This means all the pools of liquidity are possible, and if there exists a good interface to trade with, you should be able to get the best price of all these available pools. Once the trade is settled, you don’t need to withdraw your crypto: There is no counter-party risk.</p>

<p>This completely flips the story: Most exchanges will have to shutdown eventually. There is no business in being a middle-men for traders, or an arbitrage trader. But Bitstamp will probably survive: It’s not exchange after all, it has turned into a regulatory service between crypto, the legacy banking system and the government.</p>

<p>Some players have already got the hint: <a href="https://erikvoorhees.medium.com/no-more-kyc-with-shapeshift-6d95a3e63ddf">Shapeshift has already moved</a> to a decentralized trading system with no KYC. With more pressure from regulators and improved efficiency from DEX exchanges, most of today exchanges will have no business model.</p>

  <figure id="kudo_5GcF7g1wkjJLTc5cfjqR5t">
    <a href="#kudo">
      
    </a>
    <p>3</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_5GcF7g1wkjJLTc5cfjqR5t">
    <a href="#kudo">
      
    </a>
    <p>3</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]>
            </description>
            <link>https://omarabid.com/regulation-as-a-service</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987943</guid>
            <pubDate>Mon, 01 Feb 2021 12:07:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building cross-platform CLIs on .NET Core]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987714">thread link</a>) | @waldekm
<br/>
February 1, 2021 | https://blog.mastykarz.nl/building-cross-platform-cli-dotnet-core/ | <a href="https://web.archive.org/web/*/https://blog.mastykarz.nl/building-cross-platform-cli-dotnet-core/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>Building CLIs on .NET has just changed thanks to a new experimental project that Microsoft is working on.</p> <h2>The revival of CLIs</h2> <p>Since the first release of Windows, graphical applications became the standard. Arcane command-line tools were pushed away to Linux, while the rest of the world enjoyed pointing and clicking. But recently things changed.</p> <p>Graphical interfaces are great for abstracting away the complexities of the underlying software, but they share one big problem. They're hard to make. It's hard to make the UI user-friendly and any adjustment is costly and time-consuming.</p> <p>More than ever, time to market matters. And so organizations, even Microsoft, choose to build command-line tools first, learn from their users, improve, and eventually release UI for the most common use-cases. And it turns out, that the professional audience doesn't mind. They're okay with using command-line tools if it means that they can get them quicker.</p> <h2>CLIs in .NET</h2> <p>Building console applications in .NET was never hard. All you had to do, was to spin up Visual Studio, create a new project and you were good to go. But you had a long way to go to build a true CLI in a console app.</p> <p>You see, a CLI is more than just a console app. It often has multiple commands, each with its own arguments and options, some required, some optional. It validates user input and provides them with meaningful error messages. It exposes rich help with examples that illustrate how the CLI works and what's possible.</p> <p>Yes, you could do all that in a .NET console application, but you had to do all of it yourself. Before you could start implementing the functionality for your CLI, you had to build the plumbing. Parsing user input, validating it, rendering help. In the end, whatever you've built, would work but only on Windows. But this is no longer the case, thanks to DragonFruit.</p> <h2>Easily build cross-platform CLIs on .NET with DragonFruit</h2> <p>DragonFruit is a part of a new experimental set of features meant to <a href="https://github.com/dotnet/command-line-api" target="_blank" rel="noopener">simplify building cross-platform CLIs on .NET</a>. It automatically takes care of the plumbing, allowing you to build a proper CLI in minutes. Literally. Take a look.</p> <h3>The basics</h3> <p>To illustrate the point, let's build a simple CLI with two commands: one that shows a greeting for the specified name and the other that adds two values.</p> <p>Let's start with creating a new console app project:</p>  <p>Next, add reference to the experimental command line packages:</p> <div><div><pre><code data-lang="sh">dotnet add package System.CommandLine.Experimental <span>-v</span> 0.3.0-<span>*</span>
dotnet add package System.CommandLine.DragonFruit <span>-v</span> 0.3.0-<span>*</span>
</code></pre></div></div> <p>In your code editor, open your newly created project and change its code to the following:</p> <div><div><pre><code data-lang="c#"><span>using</span> <span>System</span><span>;</span>
<span>using</span> <span>System.CommandLine</span><span>;</span>
<span>using</span> <span>System.CommandLine.Invocation</span><span>;</span>

<span>namespace</span> <span>netcore_cli</span>
<span>{</span>
  <span>class</span> <span>Program</span>
  <span>{</span>
    <span>static</span> <span>int</span> <span>Main</span><span>(</span><span>string</span><span>[]</span> <span>args</span><span>)</span>
    <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>RootCommand</span><span>();</span>
      <span>cmd</span><span>.</span><span>AddCommand</span><span>(</span><span>greeting</span><span>());</span>
      <span>return</span> <span>cmd</span><span>.</span><span>InvokeAsync</span><span>(</span><span>args</span><span>).</span><span>Result</span><span>;</span>
    <span>}</span>

    <span>private</span> <span>static</span> <span>Command</span> <span>greeting</span><span>()</span> <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>Command</span><span>(</span><span>"greeting"</span><span>,</span> <span>"Shows a greeting"</span><span>);</span>
      <span>cmd</span><span>.</span><span>Handler</span> <span>=</span> <span>CommandHandler</span><span>.</span><span>Create</span><span>(()</span> <span>=&gt;</span> <span>{</span>
        <span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>"Hello world"</span><span>);</span>
      <span>});</span>
      <span>return</span> <span>cmd</span><span>;</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div> <blockquote> <p>We use <code>--</code> to specify that everything that follows should be passed into our CLI and not to the <code>dotnet</code> CLI.</p> </blockquote> <p>If you test it, you should see the following result:</p> <div><div><pre><code data-lang="sh"><span>$ </span>dotnet run <span>--</span> greeting
Hello world
</code></pre></div></div> <p>To see the added value of DragonFruit and the experimental command-line features, execute:</p>  <p>Your CLI will show an error saying that you haven't specified any command along with help listing all available options and commands. All that, while you haven't programmed a line of code for it!</p> <h3>Accepting user input</h3> <p>In the previous step, we've just scratched the surface. Let's extend our CLI, with the ability to accept user input.</p> <p>Change the code in your application to the following:</p> <div><div><pre><code data-lang="c#"><span>using</span> <span>System</span><span>;</span>
<span>using</span> <span>System.CommandLine</span><span>;</span>
<span>using</span> <span>System.CommandLine.Invocation</span><span>;</span>

<span>namespace</span> <span>netcore_cli</span>
<span>{</span>
  <span>class</span> <span>Program</span>
  <span>{</span>
    <span>static</span> <span>int</span> <span>Main</span><span>(</span><span>string</span><span>[]</span> <span>args</span><span>)</span>
    <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>RootCommand</span><span>();</span>
      <span>cmd</span><span>.</span><span>AddCommand</span><span>(</span><span>greeting</span><span>());</span>
      <span>return</span> <span>cmd</span><span>.</span><span>InvokeAsync</span><span>(</span><span>args</span><span>).</span><span>Result</span><span>;</span>
    <span>}</span>

    <span>private</span> <span>static</span> <span>Command</span> <span>greeting</span><span>()</span> <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>Command</span><span>(</span><span>"greeting"</span><span>,</span> <span>"Greets the specified person"</span><span>);</span>
      <span>cmd</span><span>.</span><span>AddOption</span><span>(</span><span>new</span> <span>Option</span><span>(</span><span>new</span><span>[]</span> <span>{</span> <span>"--name"</span><span>,</span> <span>"-n"</span> <span>},</span> <span>"Name of the person to greet"</span><span>)</span> <span>{</span>
        <span>Argument</span> <span>=</span> <span>new</span> <span>Argument</span><span>&lt;</span><span>string</span><span>&gt;</span> <span>{</span>
          <span>Arity</span> <span>=</span> <span>ArgumentArity</span><span>.</span><span>ExactlyOne</span>
        <span>}</span>
      <span>});</span>
      <span>cmd</span><span>.</span><span>Handler</span> <span>=</span> <span>CommandHandler</span><span>.</span><span>Create</span><span>&lt;</span><span>string</span><span>&gt;((</span><span>name</span><span>)</span> <span>=&gt;</span> <span>{</span>
        <span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>$"Hello </span><span>{</span><span>name</span><span>}</span><span>"</span><span>);</span>
      <span>});</span>
      <span>return</span> <span>cmd</span><span>;</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div> <p>Test it out, by executing:</p> <div><div><pre><code data-lang="sh"><span>$ </span>dotnet run <span>--</span> greeting <span>--name</span> Joe
Hello Joe
</code></pre></div></div> <p>We've extended our command with an option that allows us to specify a name and can be used either in long format <code>--name</code> or short <code>-n</code> (line 18). Additionally, we said, that our option takes a value of type string (line 19), eg. <code>--name Steve</code> and that it should have exactly one value (line 20). Notice, how DragonFruit automatically maps user input to the arguments of your command handler (line 23)!</p> <h3>Switches</h3> <p>Let's extend the CLI further with an additional switch:</p> <div><div><pre><code data-lang="c#"><span>using</span> <span>System</span><span>;</span>
<span>using</span> <span>System.CommandLine</span><span>;</span>
<span>using</span> <span>System.CommandLine.Invocation</span><span>;</span>

<span>namespace</span> <span>netcore_cli</span>
<span>{</span>
  <span>class</span> <span>Program</span>
  <span>{</span>
    <span>static</span> <span>int</span> <span>Main</span><span>(</span><span>string</span><span>[]</span> <span>args</span><span>)</span>
    <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>RootCommand</span><span>();</span>
      <span>cmd</span><span>.</span><span>AddCommand</span><span>(</span><span>greeting</span><span>());</span>
      <span>return</span> <span>cmd</span><span>.</span><span>InvokeAsync</span><span>(</span><span>args</span><span>).</span><span>Result</span><span>;</span>
    <span>}</span>

    <span>private</span> <span>static</span> <span>Command</span> <span>greeting</span><span>()</span> <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>Command</span><span>(</span><span>"greeting"</span><span>,</span> <span>"Greets the specified person"</span><span>);</span>
      <span>cmd</span><span>.</span><span>AddOption</span><span>(</span><span>new</span> <span>Option</span><span>(</span><span>new</span><span>[]</span> <span>{</span> <span>"--name"</span><span>,</span> <span>"-n"</span> <span>},</span> <span>"Name of the person to greet"</span><span>)</span> <span>{</span>
        <span>Argument</span> <span>=</span> <span>new</span> <span>Argument</span><span>&lt;</span><span>string</span><span>&gt;</span> <span>{</span>
          <span>Arity</span> <span>=</span> <span>ArgumentArity</span><span>.</span><span>ExactlyOne</span>
        <span>}</span>
      <span>});</span>
      <span>cmd</span><span>.</span><span>AddOption</span><span>(</span><span>new</span> <span>Option</span><span>(</span><span>"--polite"</span><span>,</span> <span>"Show a polite greeting"</span><span>));</span>
      <span>cmd</span><span>.</span><span>Handler</span> <span>=</span> <span>CommandHandler</span><span>.</span><span>Create</span><span>&lt;</span><span>string</span><span>,</span> <span>bool</span><span>&gt;((</span><span>name</span><span>,</span> <span>polite</span><span>)</span> <span>=&gt;</span> <span>{</span>
        <span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>$"</span><span>{(</span><span>polite</span> <span>?</span> <span>"Good day"</span> <span>:</span> <span>"Hello"</span><span>)}</span><span> </span><span>{</span><span>name</span><span>}</span><span>"</span><span>);</span>
      <span>});</span>
      <span>return</span> <span>cmd</span><span>;</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div> <p>And let's test it:</p> <div><div><pre><code data-lang="sh"><span>$ </span>dotnet run <span>--</span> greeting <span>-n</span> Joe <span>--polite</span>
Good day Joe
</code></pre></div></div> <h3>Required options</h3> <p>Let's see what happens, when we run the CLI without specifying the person's name:</p> <div><div><pre><code data-lang="sh"><span>$ </span>dotnet run <span>--</span> greeting
Hello
</code></pre></div></div> <p>Unsurprisingly, we're missing the name. But haven't we specified that it should contain exactly one value with <code>ArgumentArity.ExactlyOne</code>? Yes and no. What it says exactly, is that the option, when specified, should have exactly one value. But it doesn't need to be specified. At the moment of writing this article, there is no built-in support for required options, but you can solve it easily, like this:</p> <div><div><pre><code data-lang="c#"><span>using</span> <span>System</span><span>;</span>
<span>using</span> <span>System.CommandLine</span><span>;</span>
<span>using</span> <span>System.CommandLine.Invocation</span><span>;</span>

<span>namespace</span> <span>netcore_cli</span>
<span>{</span>
  <span>class</span> <span>Program</span>
  <span>{</span>
    <span>static</span> <span>int</span> <span>Main</span><span>(</span><span>string</span><span>[]</span> <span>args</span><span>)</span>
    <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>RootCommand</span><span>();</span>
      <span>cmd</span><span>.</span><span>AddCommand</span><span>(</span><span>greeting</span><span>());</span>
      <span>return</span> <span>cmd</span><span>.</span><span>InvokeAsync</span><span>(</span><span>args</span><span>).</span><span>Result</span><span>;</span>
    <span>}</span>

    <span>private</span> <span>static</span> <span>Command</span> <span>greeting</span><span>()</span> <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>Command</span><span>(</span><span>"greeting"</span><span>,</span> <span>"Greets the specified person"</span><span>);</span>
      <span>cmd</span><span>.</span><span>AddOption</span><span>(</span><span>new</span> <span>Option</span><span>(</span><span>new</span><span>[]</span> <span>{</span> <span>"--name"</span><span>,</span> <span>"-n"</span> <span>},</span> <span>"Name of the person to greet"</span><span>)</span> <span>{</span>
        <span>Argument</span> <span>=</span> <span>new</span> <span>Argument</span><span>&lt;</span><span>string</span><span>&gt;</span> <span>{</span>
          <span>Arity</span> <span>=</span> <span>ArgumentArity</span><span>.</span><span>ExactlyOne</span>
        <span>}</span>
      <span>});</span>
      <span>cmd</span><span>.</span><span>AddOption</span><span>(</span><span>new</span> <span>Option</span><span>(</span><span>"--polite"</span><span>,</span> <span>"Show a polite greeting"</span><span>));</span>
      <span>cmd</span><span>.</span><span>Handler</span> <span>=</span> <span>CommandHandler</span><span>.</span><span>Create</span><span>&lt;</span><span>string</span><span>,</span> <span>bool</span><span>&gt;((</span><span>name</span><span>,</span> <span>polite</span><span>)</span> <span>=&gt;</span> <span>{</span>
        <span>if</span> <span>(</span><span>String</span><span>.</span><span>IsNullOrEmpty</span><span>(</span><span>name</span><span>))</span> <span>{</span>
          <span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>"Required option name missing"</span><span>);</span>
          <span>return</span> <span>1</span><span>;</span>
        <span>}</span>

        <span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>$"</span><span>{(</span><span>polite</span> <span>?</span> <span>"Good day"</span> <span>:</span> <span>"Hello"</span><span>)}</span><span> </span><span>{</span><span>name</span><span>}</span><span>"</span><span>);</span>
        <span>return</span> <span>0</span><span>;</span>
      <span>});</span>
      <span>return</span> <span>cmd</span><span>;</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div> <p>We check if the option has a value in the command's handler and show a meaningful error if it doesn't. To properly support using the CLI in scripts, we indicate a failure with a non-zero return value.</p> <h3>Rich formatting</h3> <p>Before we finish, let's take a look at how the experimental features that Microsoft is working help you focus on building the functionality instead of plumbing.</p> <p>Often, CLIs are used to list multiple values, like a list of running processes, active users, etc. For each returned object, you might want to print several properties like ID, display name, etc. Here is how you can do this with the experimental command-line features.</p> <p>Start, by adding a reference to the Rendering package:</p> <div><div><pre><code data-lang="sh">dotnet add package System.CommandLine.Rendering <span>-v</span> 0.3.0-<span>*</span>
</code></pre></div></div> <p>Then, let's change the CLIs code to the following:</p> <div><div><pre><code data-lang="c#"><span>using</span> <span>System</span><span>;</span>
<span>using</span> <span>System.CommandLine</span><span>;</span>
<span>using</span> <span>System.CommandLine.Invocation</span><span>;</span>
<span>using</span> <span>System.CommandLine.Rendering</span><span>;</span>
<span>using</span> <span>System.CommandLine.Rendering.Views</span><span>;</span>

<span>namespace</span> <span>netcore_cli</span> <span>{</span>
  <span>class</span> <span>Program</span> <span>{</span>
    <span>private</span> <span>static</span> <span>InvocationContext</span> <span>invocationContext</span><span>;</span>
    <span>private</span> <span>static</span> <span>ConsoleRenderer</span> <span>consoleRenderer</span><span>;</span>

    <span>static</span> <span>int</span> <span>Main</span><span>(</span><span>InvocationContext</span> <span>invocationContext</span><span>,</span> <span>string</span><span>[]</span> <span>args</span><span>)</span> <span>{</span>
      <span>Program</span><span>.</span><span>invocationContext</span> <span>=</span> <span>invocationContext</span><span>;</span>
      <span>consoleRenderer</span> <span>=</span> <span>new</span> <span>ConsoleRenderer</span><span>(</span>
        <span>invocationContext</span><span>.</span><span>Console</span><span>,</span>
        <span>mode</span><span>:</span> <span>invocationContext</span><span>.</span><span>BindingContext</span><span>.</span><span>OutputMode</span><span>(),</span>
        <span>resetAfterRender</span><span>:</span> <span>true</span><span>);</span>

      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>RootCommand</span><span>();</span>
      <span>cmd</span><span>.</span><span>AddCommand</span><span>(</span><span>list</span><span>());</span>
      <span>return</span> <span>cmd</span><span>.</span><span>InvokeAsync</span><span>(</span><span>args</span><span>).</span><span>Result</span><span>;</span>
    <span>}</span>

    <span>private</span> <span>static</span> <span>Command</span> <span>list</span><span>()</span> <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>Command</span><span>(</span><span>"list"</span><span>);</span>
      <span>cmd</span><span>.</span><span>Handler</span> <span>=</span> <span>CommandHandler</span><span>.</span><span>Create</span><span>(()</span> <span>=&gt;</span> <span>{</span>
        <span>var</span> <span>users</span> <span>=</span> <span>new</span> <span>User</span><span>[]</span> <span>{</span>
          <span>new</span> <span>User</span> <span>{</span>
            <span>ID</span> <span>=</span> <span>"1"</span><span>,</span>
            <span>Name</span> <span>=</span> <span>"Joe Doe"</span><span>,</span>
            <span>Email</span> <span>=</span> <span>"joe@doe.com"</span>
          <span>},</span>
          <span>new</span> <span>User</span> <span>{</span>
            <span>ID</span> <span>=</span> <span>"2"</span><span>,</span>
            <span>Name</span> <span>=</span> <span>"Jane Doe"</span><span>,</span>
            <span>Email</span> <span>=</span> <span>"jane@doe.com"</span>
          <span>}</span>
        <span>};</span>
        <span>var</span> <span>table</span> <span>=</span> <span>new</span> <span>TableView</span><span>&lt;</span><span>User</span><span>&gt;</span> <span>{</span>
          <span>Items</span> <span>=</span> <span>users</span>
        <span>};</span>
        <span>table</span><span>.</span><span>AddColumn</span><span>(</span><span>user</span> <span>=&gt;</span> <span>user</span><span>.</span><span>ID</span><span>,</span> <span>"ID"</span><span>);</span>
        <span>table</span><span>.</span><span>AddColumn</span><span>(</span><span>user</span> <span>=&gt;</span> <span>user</span><span>.</span><span>Name</span><span>,</span> <span>"Name"</span><span>);</span>

        <span>var</span> <span>screen</span> <span>=</span> <span>new</span> <span>ScreenView</span><span>(</span><span>consoleRenderer</span><span>,</span> <span>invocationContext</span><span>.</span><span>Console</span><span>)</span> <span>{</span> <span>Child</span> <span>=</span> <span>table</span> <span>};</span>
        <span>screen</span><span>.</span><span>Render</span><span>();</span>
      <span>});</span>
      <span>return</span> <span>cmd</span><span>;</span>
    <span>}</span>
  <span>}</span>

  <span>class</span> <span>User</span> <span>{</span>
    <span>public</span> <span>string</span> <span>ID</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
    <span>public</span> <span>string</span> <span>Name</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
    <span>public</span> <span>string</span> <span>Email</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div> <p>Let's …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.mastykarz.nl/building-cross-platform-cli-dotnet-core/">https://blog.mastykarz.nl/building-cross-platform-cli-dotnet-core/</a></em></p>]]>
            </description>
            <link>https://blog.mastykarz.nl/building-cross-platform-cli-dotnet-core/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987714</guid>
            <pubDate>Mon, 01 Feb 2021 11:27:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z-Index by Examples]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987669">thread link</a>) | @Arkh4m
<br/>
February 1, 2021 | https://juliu.is/z-index-by-examples | <a href="https://web.archive.org/web/*/https://juliu.is/z-index-by-examples">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I’ve been writing software “for a living” for more than ten years. I’m
afraid I have to admit that, for more than ten years, I’ve been using
<code>z-index</code> without really understanding it.</p>
<p><code>z-index</code> is a CSS property that is used to position elements above or
below one another. It’s your weapon of choice if you have two overlapping
elements and you want to decide which one goes on top. It’s quite useful
for modals, tooltips, banners, etc. You can set it to an integer and a
larger value will generally result in the element being rendered on top of
the rest.</p>
<p>That’s pretty much all I knew about it.</p>
<p>Usually, this is great in software: <em>“Learn enough to be dangerous”</em> they
say. But invariably I would find myself fighting with <code>z-index</code> and
spending hours trying to understand what is wrong with Life, the Universe,
and Everything.</p>
<p>I’m pretty sure it’s not just me. It’s common to bump into CSS like this:</p>
<blockquote>
<p>z-index: 99999</p>
</blockquote>
<p>Which is pretty much the equivalent of the developer saying:</p>
<blockquote>
<p>this is too wild, byeee</p>
</blockquote>
<p>Well, let’s tackle this beast with some examples.</p>
<h2>The setup</h2>
<p>I’ve created a <a href="https://z-index.juliu.is/">little app</a> to make things easy. It looks like this:</p>
<p><span>
    <span></span>
    <img alt="preview" title="" src="https://juliu.is/static/0934b66d1336f77082fefca1db90c94f/b9e4f/preview.png" srcset="https://juliu.is/static/0934b66d1336f77082fefca1db90c94f/cf440/preview.png 148w,
https://juliu.is/static/0934b66d1336f77082fefca1db90c94f/d2d38/preview.png 295w,
https://juliu.is/static/0934b66d1336f77082fefca1db90c94f/b9e4f/preview.png 590w,
https://juliu.is/static/0934b66d1336f77082fefca1db90c94f/f9b6a/preview.png 885w,
https://juliu.is/static/0934b66d1336f77082fefca1db90c94f/2d849/preview.png 1180w,
https://juliu.is/static/0934b66d1336f77082fefca1db90c94f/fce90/preview.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>The boxes on the right are positioned statically. This is the default when
you don’t specify a <code>position</code> property, therefore a statically positioned
box is also known as a <strong>non-positioned</strong> box. I’ve added some negative
margins so they overlap with one another.</p>
<p>On the left-hand side, you can type some styles which will be applied to
the boxes. Notice that you can also share the setup by copying the URL.
Let’s get started now!</p>
<h2>Ordering matters</h2>
<p>Here’s the HTML that powers the page:</p>
<div data-language="html"><pre><code><span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>purple<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>blue<span>"</span></span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>green<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>yellow<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>red<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre></div>
<p>As you can see, ordering in the HTML matters. The red box is positioned
above the rest because it appears later in the code.</p>
<h2>z-index doesn’t work by itself</h2>
<p>Look at <a href="https://z-index.juliu.is/?css=p%2Bz-index%3A%209999">this</a>:</p>
<p><span>
    <span></span>
    <img alt="z-index by itself" title="" src="https://juliu.is/static/fdba47018abddc6f09300b7df6e0c4ac/b9e4f/z-index-alone.png" srcset="https://juliu.is/static/fdba47018abddc6f09300b7df6e0c4ac/cf440/z-index-alone.png 148w,
https://juliu.is/static/fdba47018abddc6f09300b7df6e0c4ac/d2d38/z-index-alone.png 295w,
https://juliu.is/static/fdba47018abddc6f09300b7df6e0c4ac/b9e4f/z-index-alone.png 590w,
https://juliu.is/static/fdba47018abddc6f09300b7df6e0c4ac/f9b6a/z-index-alone.png 885w,
https://juliu.is/static/fdba47018abddc6f09300b7df6e0c4ac/2d849/z-index-alone.png 1180w,
https://juliu.is/static/fdba47018abddc6f09300b7df6e0c4ac/fce90/z-index-alone.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>That’s rule number one:</p>
<blockquote>
<p>z-index works only on positioned elements.</p>
</blockquote>
<p>So <code>z-index</code> only works on elements that have a <code>position</code> property set to:</p>
<ul>
<li><code>relative</code></li>
<li><code>absolute</code></li>
<li><code>fixed</code></li>
<li><code>sticky</code></li>
</ul>
<p><a href="https://z-index.juliu.is/?css=p%2Bposition%3A%20relative%3Bz-index%3A%209999">There</a> we go:</p>
<p><span>
    <span></span>
    <img alt="z-index positioned" title="" src="https://juliu.is/static/398562e10636c6bc7e9aa822c0b3d584/b9e4f/z-index-positioned.png" srcset="https://juliu.is/static/398562e10636c6bc7e9aa822c0b3d584/cf440/z-index-positioned.png 148w,
https://juliu.is/static/398562e10636c6bc7e9aa822c0b3d584/d2d38/z-index-positioned.png 295w,
https://juliu.is/static/398562e10636c6bc7e9aa822c0b3d584/b9e4f/z-index-positioned.png 590w,
https://juliu.is/static/398562e10636c6bc7e9aa822c0b3d584/f9b6a/z-index-positioned.png 885w,
https://juliu.is/static/398562e10636c6bc7e9aa822c0b3d584/2d849/z-index-positioned.png 1180w,
https://juliu.is/static/398562e10636c6bc7e9aa822c0b3d584/fce90/z-index-positioned.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>Would you be able to guess what happens when we remove the <code>z-index</code>
property from this example? Go on, I’ll wait.</p>
<p><a href="https://z-index.juliu.is/?css=p%2Bposition%3A%20relative">This</a> is what we see:</p>
<p><span>
    <span></span>
    <img alt="no z-index" title="" src="https://juliu.is/static/e896fb1635a9168646b81b937f7ad11d/b9e4f/no-z-index.png" srcset="https://juliu.is/static/e896fb1635a9168646b81b937f7ad11d/cf440/no-z-index.png 148w,
https://juliu.is/static/e896fb1635a9168646b81b937f7ad11d/d2d38/no-z-index.png 295w,
https://juliu.is/static/e896fb1635a9168646b81b937f7ad11d/b9e4f/no-z-index.png 590w,
https://juliu.is/static/e896fb1635a9168646b81b937f7ad11d/f9b6a/no-z-index.png 885w,
https://juliu.is/static/e896fb1635a9168646b81b937f7ad11d/2d849/no-z-index.png 1180w,
https://juliu.is/static/e896fb1635a9168646b81b937f7ad11d/fce90/no-z-index.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>It turns out that positioned boxes appear on top of non-positioned boxes.
If you’re inclined, the <a href="https://www.w3.org/TR/CSS2/zindex.html">spec</a> goes
into <strong>much</strong> more detail.</p>
<p>But if all the boxes are positioned, we revert to following the order in
the HTML source. Look at
<a href="https://z-index.juliu.is/?css=b%2Bposition%3A%20relative%7Cp%2Bposition%3A%20relative%7Cr%2Bposition%3A%20relative">this</a>:</p>
<p><span>
    <span></span>
    <img alt="all positioned" title="" src="https://juliu.is/static/d8f35f9142c93f271bd95751879bf1fb/b9e4f/all-positioned.png" srcset="https://juliu.is/static/d8f35f9142c93f271bd95751879bf1fb/cf440/all-positioned.png 148w,
https://juliu.is/static/d8f35f9142c93f271bd95751879bf1fb/d2d38/all-positioned.png 295w,
https://juliu.is/static/d8f35f9142c93f271bd95751879bf1fb/b9e4f/all-positioned.png 590w,
https://juliu.is/static/d8f35f9142c93f271bd95751879bf1fb/f9b6a/all-positioned.png 885w,
https://juliu.is/static/d8f35f9142c93f271bd95751879bf1fb/2d849/all-positioned.png 1180w,
https://juliu.is/static/d8f35f9142c93f271bd95751879bf1fb/fce90/all-positioned.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>And at that point, specifying a <code>z-index</code> <a href="https://z-index.juliu.is/?css=b%2Bposition%3A%20relative%3Bz-index%3A%201%7Cp%2Bposition%3A%20relative%3Bz-index%3A%202%7Cr%2Bposition%3A%20relative">does
work</a>!</p>
<p><span>
    <span></span>
    <img alt="finally z-index" title="" src="https://juliu.is/static/03a454c21d00f1e6821732738e1d70e1/b9e4f/finally-z-index.png" srcset="https://juliu.is/static/03a454c21d00f1e6821732738e1d70e1/cf440/finally-z-index.png 148w,
https://juliu.is/static/03a454c21d00f1e6821732738e1d70e1/d2d38/finally-z-index.png 295w,
https://juliu.is/static/03a454c21d00f1e6821732738e1d70e1/b9e4f/finally-z-index.png 590w,
https://juliu.is/static/03a454c21d00f1e6821732738e1d70e1/f9b6a/finally-z-index.png 885w,
https://juliu.is/static/03a454c21d00f1e6821732738e1d70e1/2d849/finally-z-index.png 1180w,
https://juliu.is/static/03a454c21d00f1e6821732738e1d70e1/fce90/finally-z-index.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>Using the powers of <code>z-index</code> we were able to reverse the default stacking order of
the boxes. Go us.</p>
<h2>A new mystery</h2>
<p>Let’s look at <a href="https://z-index.juliu.is/?css=b%2Bposition%3A%20relative%7Cr%2Bposition%3A%20relative%7Cy%2Bposition%3A%20relative%3Bz-index%3A%201%3Bheight%3A%20200px">this
example</a>:</p>
<p><span>
    <span></span>
    <img alt="mystery" title="" src="https://juliu.is/static/24196cc40311cf0559114651d8c9e25d/b9e4f/mystery.png" srcset="https://juliu.is/static/24196cc40311cf0559114651d8c9e25d/cf440/mystery.png 148w,
https://juliu.is/static/24196cc40311cf0559114651d8c9e25d/d2d38/mystery.png 295w,
https://juliu.is/static/24196cc40311cf0559114651d8c9e25d/b9e4f/mystery.png 590w,
https://juliu.is/static/24196cc40311cf0559114651d8c9e25d/f9b6a/mystery.png 885w,
https://juliu.is/static/24196cc40311cf0559114651d8c9e25d/2d849/mystery.png 1180w,
https://juliu.is/static/24196cc40311cf0559114651d8c9e25d/fce90/mystery.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>Out of the three positioned boxes, the yellow one has <code>z-index: 1</code>, and
therefore appears on top. Good, the world is making sense.</p>
<p>But what if we give a <code>z-index</code> to the blue box, the parent of the yellow box? Our
example would look like
<a href="https://z-index.juliu.is/?css=b%2Bposition%3A%20relative%3Bz-index%3A%200%7Cr%2Bposition%3A%20relative%7Cy%2Bposition%3A%20relative%3Bz-index%3A%201%3Bheight%3A%20200px">this</a>:</p>
<p><span>
    <span></span>
    <img alt="mystery part two" title="" src="https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/b9e4f/mystery-two.png" srcset="https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/cf440/mystery-two.png 148w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/d2d38/mystery-two.png 295w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/b9e4f/mystery-two.png 590w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/f9b6a/mystery-two.png 885w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/2d849/mystery-two.png 1180w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/fce90/mystery-two.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>What’s happening here? Our yellow box is now rendered below the red one?!
All this because we added a <code>z-index: 0</code> to the blue one?! The world is
making no sense again. 😿</p>
<p>Let’s take a bit of a detour…</p>
<h2>Auto is not zero</h2>
<p>If we don’t set the <code>z-index</code> property of an element, its default value is
going to be <code>auto</code>. Such elements will appear in front of elements with
negative <code>z-index</code> values and below elements with positive <code>z-index</code>
values.
<a href="https://z-index.juliu.is/?css=b%2Bposition%3A%20relative%7Cp%2Bposition%3A%20relative%3Bz-index%3A%201%7Cr%2Bposition%3A%20relative%3Bz-index%3A%20-1">This</a>
should convince you that I’m not lying:</p>
<p><span>
    <span></span>
    <img alt="z-index auto" title="" src="https://juliu.is/static/1786f16b25da7227a7897b16f922c345/b9e4f/z-index-auto.png" srcset="https://juliu.is/static/1786f16b25da7227a7897b16f922c345/cf440/z-index-auto.png 148w,
https://juliu.is/static/1786f16b25da7227a7897b16f922c345/d2d38/z-index-auto.png 295w,
https://juliu.is/static/1786f16b25da7227a7897b16f922c345/b9e4f/z-index-auto.png 590w,
https://juliu.is/static/1786f16b25da7227a7897b16f922c345/f9b6a/z-index-auto.png 885w,
https://juliu.is/static/1786f16b25da7227a7897b16f922c345/2d849/z-index-auto.png 1180w,
https://juliu.is/static/1786f16b25da7227a7897b16f922c345/fce90/z-index-auto.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>So in a way that element behaves as if we set <code>z-index: 0</code>. Indeed, if we
add that CSS rule, we see no notable changes in the
<a href="https://z-index.juliu.is/?css=b%2Bposition%3A%20relative%3Bz-index%3A%200%7Cp%2Bposition%3A%20relative%3Bz-index%3A%201%7Cr%2Bposition%3A%20relative%3Bz-index%3A%20-1">output</a>:</p>
<p><span>
    <span></span>
    <img alt="z-index zero" title="" src="https://juliu.is/static/e447a471c677ad3ed068d42015735809/b9e4f/z-index-zero.png" srcset="https://juliu.is/static/e447a471c677ad3ed068d42015735809/cf440/z-index-zero.png 148w,
https://juliu.is/static/e447a471c677ad3ed068d42015735809/d2d38/z-index-zero.png 295w,
https://juliu.is/static/e447a471c677ad3ed068d42015735809/b9e4f/z-index-zero.png 590w,
https://juliu.is/static/e447a471c677ad3ed068d42015735809/f9b6a/z-index-zero.png 885w,
https://juliu.is/static/e447a471c677ad3ed068d42015735809/2d849/z-index-zero.png 1180w,
https://juliu.is/static/e447a471c677ad3ed068d42015735809/fce90/z-index-zero.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>But things changed a lot! Giving a value to <code>z-index</code> to a relatively
positioned box creates a new <strong>stacking context</strong>.</p>
<p>A stacking what?
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Positioning/Understanding_z_index/The_stacking_context">MDN</a> says:</p>
<blockquote>
<p>The stacking context is a three-dimensional conceptualization of HTML
elements along an imaginary z-axis relative to the user, who is assumed
to be facing the viewport or the webpage. HTML elements occupy this space
in priority order based on element attributes.</p>
</blockquote>
<p>I thought this is what we were trying to do all along. Let’s keep reading.</p>
<p>The interesting part comes later:</p>
<blockquote>
<p>Within a stacking context, child elements are stacked according to the
same rules previously explained. Importantly, the z-index values of its
child stacking contexts only have meaning in this parent.</p>
</blockquote>
<p>That’s the key point. A stacking context will force the <code>z-index</code> of its
child stacking contexts to only have a local meaning. Let’s look at our
mysterious example again:</p>
<p><span>
    <span></span>
    <img alt="mystery part two" title="" src="https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/b9e4f/mystery-two.png" srcset="https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/cf440/mystery-two.png 148w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/d2d38/mystery-two.png 295w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/b9e4f/mystery-two.png 590w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/f9b6a/mystery-two.png 885w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/2d849/mystery-two.png 1180w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/fce90/mystery-two.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>Setting <code>z-index: 0</code> on the blue box changed the meaning of the <code>z-index</code>
declaration on the yellow box. Before, the yellow box was out there playing
with the big boys. Now, it can only affect stacking within the blue box.</p>
<p>This is a great cause of frustration. No matter how high you set a
<code>z-index</code> property, you will <em>never</em> be able to ‘escape’ the parent
stacking context.  And every time you are struggling with making <code>z-index</code>
work you can bet that it’s because <em>something</em> created a stacking context
that you can’t escape from.</p>
<p>With this newfound understanding, spend some time explaining why <a href="https://z-index.juliu.is/?css=b%2Bposition%3A%20relative%3Bz-index%3A%201%7Cg%2Bposition%3A%20relative%3Bz-index%3A%2010%7Cp%2Bposition%3A%20relative%3Bz-index%3A%202%7Cr%2Bposition%3A%20relative%7Cy%2Bposition%3A%20relative%3Bz-index%3A%205%3Bheight%3A%20200px">this
example</a> makes perfect sense:</p>
<p><span>
    <span></span>
    <img alt="no mystery" title="" src="https://juliu.is/static/3a1b4c6e74adfd5afaaa323f54c4c699/b9e4f/no-mystery.png" srcset="https://juliu.is/static/3a1b4c6e74adfd5afaaa323f54c4c699/cf440/no-mystery.png 148w,
https://juliu.is/static/3a1b4c6e74adfd5afaaa323f54c4c699/d2d38/no-mystery.png 295w,
https://juliu.is/static/3a1b4c6e74adfd5afaaa323f54c4c699/b9e4f/no-mystery.png 590w,
https://juliu.is/static/3a1b4c6e74adfd5afaaa323f54c4c699/f9b6a/no-mystery.png 885w,
https://juliu.is/static/3a1b4c6e74adfd5afaaa323f54c4c699/2d849/no-mystery.png 1180w,
https://juliu.is/static/3a1b4c6e74adfd5afaaa323f54c4c699/fce90/no-mystery.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>Also remember that before we said that positioned elements appear on top of
non-positioned elements? Well, now we can generalize by saying that
elements that form a stacking context appear on top of non-positioned
elements.</p>
<h2>The usual suspects</h2>
<p>The
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Positioning/Understanding_z_index/The_stacking_context">MDN article</a>
lists all cases when a new stacking context is formed. I’m going to go through a
list of usual suspects.</p>
<p><a href="https://z-index.juliu.is/?css=p%2Bopacity%3A%200.90">Opacity less than 1</a></p>
<p><span>
    <span></span>
    <img alt="opacity" title="" src="https://juliu.is/static/3809618b7219c0eb8aea13f481174227/b9e4f/opacity.png" srcset="https://juliu.is/static/3809618b7219c0eb8aea13f481174227/cf440/opacity.png 148w,
https://juliu.is/static/3809618b7219c0eb8aea13f481174227/d2d38/opacity.png 295w,
https://juliu.is/static/3809618b7219c0eb8aea13f481174227/b9e4f/opacity.png 590w,
https://juliu.is/static/3809618b7219c0eb8aea13f481174227/f9b6a/opacity.png 885w,
https://juliu.is/static/3809618b7219c0eb8aea13f481174227/2d849/opacity.png 1180w,
https://juliu.is/static/3809618b7219c0eb8aea13f481174227/fce90/opacity.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p><a href="https://z-index.juliu.is/?css=p%2Btransform%3A%20rotate(30deg)">Transform and filter effects</a></p>
<p><span>
    <span></span>
    <img alt="transform" title="" src="https://juliu.is/static/2efb5e9bce68c348867bb8a7ba089794/b9e4f/transform.png" srcset="https://juliu.is/static/2efb5e9bce68c348867bb8a7ba089794/cf440/transform.png 148w,
https://juliu.is/static/2efb5e9bce68c348867bb8a7ba089794/d2d38/transform.png 295w,
https://juliu.is/static/2efb5e9bce68c348867bb8a7ba089794/b9e4f/transform.png 590w,
https://juliu.is/static/2efb5e9bce68c348867bb8a7ba089794/f9b6a/transform.png 885w,
https://juliu.is/static/2efb5e9bce68c348867bb8a7ba089794/2d849/transform.png 1180w,
https://juliu.is/static/2efb5e9bce68c348867bb8a7ba089794/fce90/transform.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p><a href="https://z-index.juliu.is/?css=b%2Bdisplay%3A%20flex%7Cp%2Bposition%3A%20relative%3Bz-index%3A%201%7Cy%2Bz-index%3A%202">Flex child with z-index</a></p>
<p><span>
    <span></span>
    <img alt="flex child" title="" src="https://juliu.is/static/bfc982cc7751b6f9c688330abbb6f131/b9e4f/flex-child.png" srcset="https://juliu.is/static/bfc982cc7751b6f9c688330abbb6f131/cf440/flex-child.png 148w,
https://juliu.is/static/bfc982cc7751b6f9c688330abbb6f131/d2d38/flex-child.png 295w,
https://juliu.is/static/bfc982cc7751b6f9c688330abbb6f131/b9e4f/flex-child.png 590w,
https://juliu.is/static/bfc982cc7751b6f9c688330abbb6f131/f9b6a/flex-child.png 885w,
https://juliu.is/static/bfc982cc7751b6f9c688330abbb6f131/2d849/flex-child.png 1180w,
https://juliu.is/static/bfc982cc7751b6f9c688330abbb6f131/fce90/flex-child.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p><a href="https://z-index.juliu.is/?css=b%2Bdisplay%3A%20grid%7Cg%2Bz-index%3A%202%7Cp%2Bposition%3A%20relative%3Bz-index%3A%201">Grid child with z-index</a></p>
<p><span>
    <span></span>
    <img alt="grid child" title="" src="https://juliu.is/static/7b9b78fe695e1dcf2c857e801b593b9b/b9e4f/grid-child.png" srcset="https://juliu.is/static/7b9b78fe695e1dcf2c857e801b593b9b/cf440/grid-child.png 148w,
https://juliu.is/static/7b9b78fe695e1dcf2c857e801b593b9b/d2d38/grid-child.png 295w,
https://juliu.is/static/7b9b78fe695e1dcf2c857e801b593b9b/b9e4f/grid-child.png 590w,
https://juliu.is/static/7b9b78fe695e1dcf2c857e801b593b9b/f9b6a/grid-child.png 885w,
https://juliu.is/static/7b9b78fe695e1dcf2c857e801b593b9b/2d849/grid-child.png 1180w,
https://juliu.is/static/7b9b78fe695e1dcf2c857e801b593b9b/fce90/grid-child.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>Some of these examples might look surprising. In general, the underlying
reason why these configurations create a new stacking context is that they
render to an offscreen context. But in practice, you don’t need to remember
all of them: when you bump into a situation where <code>z-index</code> isn’t working
as intended, you can quickly check if there’s a runaway stacking context
that’s keeping you locked up.</p>
<p>I recommend going through each one of the examples, playing around with
them, and explaining in your head why they make perfect sense. It might be
helpful to install a browser extension to help check your intuition and
solidify your understanding
(<a href="https://chrome.google.com/webstore/detail/z-context/jigamimbjojkdgnlldajknogfgncplbh">Chrome</a>,
<a href="https://addons.mozilla.org/en-GB/firefox/addon/devtools-z-index/">Firefox</a>).</p>
<p>That’s all I have for you today. As always, thanks for reading!</p></div></div>]]>
            </description>
            <link>https://juliu.is/z-index-by-examples</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987669</guid>
            <pubDate>Mon, 01 Feb 2021 11:16:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do less and do it better]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987605">thread link</a>) | @todsacerdoti
<br/>
February 1, 2021 | http://qmacro.org/2021/02/01/do-less-and-do-it-better/ | <a href="https://web.archive.org/web/*/http://qmacro.org/2021/02/01/do-less-and-do-it-better/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>In 2021 I want to consolidate and improve upon some skills I already have, rather than add more. Here’s what I mean, and how I got inspired.</em></p>

<p>In October last year Samir Talwar <a href="https://twitter.com/SamirTalwar/status/1318904227935227905">tweeted</a> something simple yet profound: “<em>Do less, and do it better</em>”.</p>

<p>In my work and play I discover and start using various tools and technologies. The pace of change in this industry, coupled with the (not unpleasant) demands on what I have to produce, means that I often end up with only a shallow understanding of things. And sometimes these are things I use every day.</p>

<p>The nature of my job as a developer advocate (but I think this extends to development in general), in the context of that fast pace of change, means that there’s always something new to learn, to adopt, and to incorporate into a workflow, process or solution. But that can come at a price - of limited comprehension and mastery.</p>

<p>To explain further, I’m going to stretch a metaphor relating to ploughing a field and sowing seeds.</p>

<p><strong>Ploughing and sowing</strong></p>

<p>As an individual, I sometimes feel as though I’m trying to prepare a large field and plant seeds there using a poorly hand-constructed and inefficient plough made of the wrong sort of wood and bits of string, combined with a seed drill made out of old toilet rolls and sticky tape. Not only that, but I’m trying to plant across the entire field, 50 furrows wide, as I move along.</p>

<p>Needless to say, the ploughing doesn’t go very well, and the seeds are planted imprecisely, sometimes superficially, mostly wastefully, resulting in poor distribution, low growth and high energy expenditure.</p>

<p>But if I were to abandon the idea of going wide, and instead go narrow, focusing on just a handful of furrows, I could afford to take the time to correctly plant each seed, nurturing &amp; watering each one, producing strong plants with deep roots and healthy growth.</p>

<p>I’ve thought this for a while but never got round to doing anything about it. Samir’s tweet has galvanised me into spending some time working out what that means for me.</p>

<p><strong>Consolidating</strong></p>

<p>So this year I’m attempting to “do less, and do it better” by acknowledging the tools I use day in day out, and learn more about them, restricting myself to a narrow set of topics, move a step closer towards mastery in each, and really benefit from everything they have to offer.</p>

<p>Here’s an example from this weekend; I read the entirety of the main README for the excellent fuzzy-finder tool <a href="https://github.com/junegunn/fzf"><code>fzf</code></a>, all 16 pages. That might seem ridiculous to say (16 pages is not a lot) but I’ve used <code>fzf</code> for a year or so and never RTFM’d before. In my defence, I’ve also been constantly and painfully aware that I’ve merely scratched the surface. I’ve now discovered some <code>fzf</code> gems that I can put into practice immediately, and some areas that I need to dig into more.</p>

<p>Likewise for other tools that I use, tools that are not only essential, but which, when mastered, can make my workflows even better. I’m thinking of Vim (I’ve recently started watching my friend and colleague David Kunz’s <a href="https://www.youtube.com/channel/UCFU7a7OMYfcpjtIpu2j47_Q">DevOnDuty</a> series, which I can strongly recommend), <a href="https://github.com/tmux/tmux/wiki"><code>tmux</code></a> (<a href="http://rwxrob.live/">rwxrob</a> is a great practitioner, and I should re-read Brian P. Hogan’s great <a href="https://pragprog.com/titles/bhtmux2/tmux-2/">book on tmux</a> too) and of course the environment and language that ties it all together for me - <a href="https://www.gnu.org/software/bash/">Bash</a>.</p>

<p>The lockdown has afforded me time to read more, and I need to embrace that and work out how I can keep that momentum up. I want to tip the balance over from always having my fingers on the keyboard towards stepping away from the keyboard to read, reflect and consolidate my learning.</p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>http://qmacro.org/2021/02/01/do-less-and-do-it-better/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987605</guid>
            <pubDate>Mon, 01 Feb 2021 11:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reality is an evolved illusion]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987595">thread link</a>) | @paraschopra
<br/>
February 1, 2021 | https://invertedpassion.com/reality-is-an-evolved-illusion/ | <a href="https://web.archive.org/web/*/https://invertedpassion.com/reality-is-an-evolved-illusion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1514">
		<!-- .entry-header -->
	<div>
		
		
<p>Do we see reality as it is? </p>

<p>I discuss this question with <a href="https://www.cogsci.uci.edu/~ddhoff/">Donald Hoffman</a> who is professor emeritus at the University of California, Irvine. He studies consciousness and perception from an evolutionary point of view. His research has led him to make a bold claim that while we do not yet know what the underlying reality could be like. Rather, reality as we know it now – including space, time, and objects – is a useful fiction that <a href="https://invertedpassion.com/evolution-explains-everything/">evolution</a> invented for us.</p>

<p>His TED talk on our <a href="https://www.youtube.com/watch?v=oYp5XuGYqqY">perception of reality</a> has been watched over 3 million times, and in his recent pop-science book for the wider audience,<a href="https://www.goodreads.com/en/book/show/41817484"> <em>The Case Against Reality</em></a>, he makes a convincing case on how our perceived reality is an illusion that has evolved to help us survive and reproduce.</p>

<figure>
<p>
<iframe title="#3 Donald Hoffman - Reality is an evolved illusion" width="780" height="439" src="https://www.youtube.com/embed/kjxF6rcblTw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
</figure>

<h3>What we talk about</h3>

<p><strong>1:46</strong> – Towards building a mathematical understanding perception<br><strong>5:12</strong> – Evolutionary game theory to help understand perception<br><strong>6:26</strong> – Computing truth is expensive, so evolution get rids of it<br><strong>8:00</strong> – Mathematical proof that evolution doesn’t tune us to see the truth<br><strong>9:56</strong> – David Marr’s ideas and inverse optics<br><strong>11:30</strong> – What are fitness payoffs? Why do they matter? How are they determined?<br><strong>16:23</strong> – Maximizing for truth vs maximizing for winning<br><strong>18:40</strong> – Illusions that show physical reality doesn’t exist<br><strong>23:21</strong> – Physical reality not being fundamental as a scientific claim<br><strong>24:23</strong> – Existing physics points to spacetime not being fundamental<br><strong>30:25</strong> – The basics of the interface theory of perception<br><strong>34:40</strong> – We have to guess mathematically the deeper structure of reality<br><strong>38:00</strong> – Model-free planning in reinforcement learning<br><strong>44:45</strong> – Why should we care about what is objective reality?<br><strong>49:20</strong> – How can we use science to go beyond physical reality?<br><strong>56:57</strong> – Reality is a huge social network of conscious agents<br><strong>1:03:41</strong> –  Predictions from the mathematics of conscious agents<br><strong>1:09:26</strong> – “We will be able to warp space and time”<br><strong>1:09:35</strong> – Bridging conscious agents to physical reality<br><strong>1:15:32</strong> – How far along have we come in his journey of building a fundamental theory of reality based on consciousness?<br><strong>1:17:31</strong> – Is mathematics part of the underlying reality or is it a useful fiction too?<br><strong>1:30:12</strong> – Does your research on reality and consciousness impact your personal life and beliefs?</p>

<h3>Notes and Key Insights</h3>

<p>1/ Illusions show that we do not see reality as it is. For example, patches A and B in the image below are of the same color (which means the photons arriving from these two patches are of the same wavelength).</p>

<div>
<figure><img loading="lazy" width="480" height="372" src="https://invertedpassion.com/wp-content/uploads/2021/01/gallery_1425045941-kq2pcqd8jgz7mr0hnz63.png" alt="" srcset="https://invertedpassion.com/wp-content/uploads/2021/01/gallery_1425045941-kq2pcqd8jgz7mr0hnz63.png 480w, https://invertedpassion.com/wp-content/uploads/2021/01/gallery_1425045941-kq2pcqd8jgz7mr0hnz63-300x233.png 300w" sizes="(max-width: 480px) 100vw, 480px"></figure>
</div>

<p>2/ You can verify that the colors in the two patches are exactly the same via a color picker app. <strong>Yet our mind sees them as completely different colors</strong>. This clearly demonstrates that, at least in this case, we’re not seeing reality as it is.</p>

<p>3/ The reason this illusion works is because <strong>our vision isn’t like a camera</strong>. It cannot be because a) unlike a camera sensor, we have a big hole in the middle of our retina (<a href="https://en.wikipedia.org/wiki/Blind_spot_(vision)">blind spot</a>) that we never notice); b) incoming photons pass through many obstructions (most notably neurons) that we never notice.</p>



<p>4/ A true perception of reality should have a big black hole in the middle of the vision. Moreover, become we <a href="https://www.smithsonianmag.com/science-nature/our-eyes-are-always-darting-around-s-not-how-we-see-world-180972414/">saccade our gaze</a> several times a second, <strong>we should see constantly shifting images rather than the stable vision we perceive</strong>.</p>

<p>But we don’t.</p>



<p>5/ The reason our vision is oblivious to rapid eye saccades and the blind spot is that <strong>our senses haven’t evolved to perceive reality as it is</strong>. Rather, our senses have evolved to help us to survive and reproduce.</p>

<p>6/ In terms of calories and energy, it’s costly to process information. Take the housefly, for example. It has a tiny brain and needs fewer calories than us. It has eyes that are used to find food and mates. But given the size of its brain and calories its brain has for processing information, do you suppose the fly has a complete, rich, and accurate perception of the world around it?</p>

<p>7/ Well, from an evolution’s point of view, as long as the fly is able to find food and mates, it’s preferable to have an incomplete and distorted but calorically cheap representation of reality than an accurate perception of reality.</p>

<p>8/ In fact, that is what Donald Hoffman and his colleagues prove via a mathematical theorem called <a href="https://chrisfieldsresearch.com/FitnessBeatsTruth_ActaB_submitted_2019.pdf"><em>Fitness Beats Truth</em>.</a> Put simply, <strong>it suggests that the probability that our senses have evolved to report the truth about reality is zero</strong>. </p>

<p>9/ They suggest that instead of reporting the truth, <strong>our senses report fitness payoffs that our estimates of the potential for acquiring resources</strong>, attracting mates, and getting ahead of others. </p>

<p>In short, fitness payoffs are our estimates of reproductive potential.</p>

<p>10/ <strong>You can imagine fitness payoffs as points in a game</strong>. The more points you accumulate, the longer you can play the game. </p>

<p>In the game, if there are two players: one focused on acquiring as many points as possible (fitness) and another focused on understanding how the game works (truth), guess who will win?</p>

<p>11/ Of course, fitness depends on truth but it isn’t mapped to it one to one.</p>

<p>Take the example of oxygen – too little or too much of it will kill us. We just need the right amount of it.</p>

<p>This means an organism evolved to report the <em>true</em> amount of oxygen will get out-competed by an organism evolved to report the <em>right</em> amount of oxygen.</p>

<p><strong>Reverse engineering from fitness to the truth isn’t trivial.</strong> Oxygen wasn’t discovered until 1771.</p>

<p>12/ In summary, <strong>the claim is that our physical reality is like virtual reality. </strong>We do not know what true reality is but we can be sure that whatever we perceive isn’t likely to be it.</p>

<p>There are a few objections one can raise against this idea.</p>

<p>13/ OBJECTION 1 -&gt; Okay, so <strong>if we don’t perceive reality as it is, why not jump in front of a train?</strong></p>

<p>Donald Hoffman suggests that the reason you don’t jump in front of a train is similar to the reason you don’t drag your important files on your computer to the trash bin icon. Nobody believes that the trash bin icon is real (it’s implemented behind the scenes as transistors and electric signals), yet interaction with it has real consequences for you.</p>

<p>14/ Similarly, even though we don’t perceive true reality, it doesn’t mean that our perceptions are arbitrary. Our actions within the perceived reality have real consequences.</p>

<p>15/ OBJECTION 2 -&gt; <strong>If we are in virtual reality, how do we explain the <a href="https://invertedpassion.com/professional-success-and-personal-success-two-independent-dimensions/">success</a> of science and engineering?</strong> We have sent people to the moon, so surely we must be understand something about what reality is?</p>

<p>16/ Donald Hoffman says that <strong>our engineering success suggests an increased mastery over the virtual reality we’re embedded in</strong>. Just like a player can get better at a game by studying game mechanics, we can master our perceived reality better and better.</p>

<p>But just like a gamer doesn’t understand how the game is implemented under the hood, we don’t necessarily understand what the actual reality is.</p>

<p> 17/ Modern physics actually agrees with the interpretation that the actual reality could be much stranger than our perceptions. <a href="https://en.wikipedia.org/wiki/Bell%27s_theorem">Bell’s theorem</a> suggests that reality is not local and that quantum entanglement over large distances is a real thing. The <a href="https://en.wikipedia.org/wiki/Holographic_principle">holographic principle</a> suggests our 3D universe may actually be a projection from 2D.</p>

<p>18/ <strong>As a theme in physics, reality as we perceive has become less and less tenable</strong>. From this perspective, the claim that we don’t perceive true reality is not surprising.</p>

<p>19/ Although it should be recognized that our perception isn’t completely arbitrary. <strong>We do not have direct access to reality and our only access to it is via our senses</strong>. So when things change <em>out there</em>, our perception changes accordingly. </p>

<p>20/ For example, we perceive many objects as round because they share <em>something</em> that causes roundness to emerge in our perception for <em>all</em> of them. Similarly, different red things share <em>something</em> (a particular wavelength of light) which causes us to see red.</p>

<p>21/ In fact, finding out <a href="https://en.wikipedia.org/wiki/Invariant_(physics)">invariants of the world</a> might be is what science is all about. Coming back to the example of a game, an expert player might master game mechanics better and better, but you know what will be even more effective at winning the game? Reverse engineering how the game works and directly interfering with its source code.</p>

<p>22/ We do not yet have a complete understanding of reality and I’m not even sure if we will ever have it. But the success of science in predicting more and more phenomena over time suggests that we’re understanding the game mechanics of how reality works better and better. </p>

<p>23/ All this sounds nice and logical, but <strong>how do we explain conscious experiences?</strong> Any description of reality must accommodate the subjective experiences we have of seeing red or smelling coffee. Where do these subjective experiences come from?</p>

<p>24/ An incomplete but important answer is that <strong>these perceptions are compressed representations of reality that got evolved for adaptive <a href="https://invertedpassion.com/evidence-of-desire-customer-behavior/">behavior</a></strong>. Color vision helped our ancestors pick ripe fruits from unripe ones. Fragrances told them in an instant what to avoid (bitter) and what to crave (sweet).</p>

<p>25/ That’s good but <strong>it appears that what we subjectively experience represents reality in a completely arbitrary way</strong>. (Although it’s an ongoing area of research and there may be some structure). </p>

<p>For example, try to guess which of the molecules is <a href="https://en.wikipedia.org/wiki/Vanillin">vanilla</a> and which one is <a href="https://en.wikipedia.org/wiki/Thymol">thyme</a>.</p>

<figure>
<ul>
<li>
<figure><img loading="lazy" width="830" height="1024" src="https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_-830x1024.png" alt="" data-id="1520" data-full-url="https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_.png" data-link="https://invertedpassion.com/?attachment_id=1520" srcset="https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_-830x1024.png 830w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_-243x300.png 243w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_-768x947.png 768w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_-1245x1536.png 1245w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_-1661x2048.png 1661w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_-1560x1924.png 1560w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_.png 1920w" sizes="(max-width: 830px) 100vw, 830px"></figure>
</li>
<li>
<figure><img loading="lazy" width="940" height="1024" src="https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_-940x1024.png" alt="" data-id="1521" data-full-url="https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_.png" data-link="https://invertedpassion.com/?attachment_id=1521" srcset="https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_-940x1024.png 940w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_-275x300.png 275w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_-768x836.png 768w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_-1410x1536.png 1410w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_-1881x2048.png 1881w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_-1560x1699.png 1560w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_.png 1920w" sizes="(max-width: 940px) 100vw, 940px"></figure>
</li>
</ul>
</figure>

<p>26/ Can’t guess? That’s okay. </p>

<p>Thankfully, to operate in the world you don’t have to remember the molecular structure. Our brain directly translates the signals originating corresponding smelling these molecules into a distinct subjective experience which you can use to take action.</p>

<p>27/ <strong>It does this translation because the molecular structure of these molecules was irrelevant for our survival and reproduction</strong>. For success in an evolutionary competition, what matters is our actions and this compressed signal that there’s vanilla or thyme around is good enough for informing such actions.</p>

<p>27/ Donald Hoffman suggests that even the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invertedpassion.com/reality-is-an-evolved-illusion/">https://invertedpassion.com/reality-is-an-evolved-illusion/</a></em></p>]]>
            </description>
            <link>https://invertedpassion.com/reality-is-an-evolved-illusion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987595</guid>
            <pubDate>Mon, 01 Feb 2021 11:04:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Block out input-free time]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987391">thread link</a>) | @vitabenes
<br/>
February 1, 2021 | https://www.deprocrastination.co/blog/block-out-input-free-time | <a href="https://web.archive.org/web/*/https://www.deprocrastination.co/blog/block-out-input-free-time">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><img src="https://www.deprocrastination.co/assets/illustrations/block_out_time.png" alt="Block out input-free time"></p><p>How much time do you spend aimlessly scrolling? Looking for new and interesting information? Checking notifications, likes, or emails?</p><p>For many of us, the answer is hours every day. The question is: is that time well spent? Probably not.</p><p>Now, there's nothing wrong with occasionally watching a YouTube video or two in the evening (so long as it doesn't cut into your sleep schedule.) However, always seeking something&nbsp;<em>new</em>&nbsp;is not good for us.</p><p>Our screens have become addictive. They are visually stimulating, offering fast feedback for our actions.&nbsp;<em>Tap</em>&nbsp;and you're rewarded with infinite potentially interesting videos or games.</p><p>Worse, our screens control our behavior by controlling the choices presented to us.</p><h2>The default choice architecture</h2><p>When you have "nothing to do," what do you do?</p><p>You probably take your phone, or open the browser and are presented with choices. Facebook, Instagram, Twitter, TikTok, email,...</p><p>Here's why it's bad: those choices aren't designed to help you.</p><p>When we're presented with options, we choose from them. We rarely create&nbsp;<em>our own</em>&nbsp;additional and better options. That would take effort. We'd have to think. Our actions are guided by the interfaces we're looking at every day.</p><p>It's always easier to tap an icon and watch something than figure out what you need to do next. Yet, the latter is much better for us. The latter helps us make our lives better and easier in the future.</p><h3>The missing apps</h3><p>Here are some "apps" that you don't see when you're looking for something to do.</p><ul><li>Tidy up my room</li><li>Take out the trash</li><li>Wash the dishes</li><li>Think about what you want to accomplish this year</li><li>Re-decorate the room</li><li>Stretch for a bit</li><li>Set a goal and put it on a calendar</li></ul><p>You don't see the above when you open your laptop or unlock your phone. That's a shame, because these actions would actually make your life a bit better, unlike doomscrolling.</p><p>What you see influences what you do. If you're not reminded of productive actions by your surroundings, you'll take unproductive actions instead, against your interests, just because they are the easiest choice at the moment.</p><p>When we're not using our computer to produce something or to connect with someone, our time is often better spent off-screen. Many on-screen actions are optimized to suck away our attention, not use it to improve our lives.</p><p>That's one argument for less screen time. Here's another one.</p><h2>The catch-22 of digital distractions</h2><p>You don't feel great. Your life is not like the life of the celebrities you see on social media. You feel bad about yourself. So you escape. You watch something. You scroll. You turn off your brain and let the memes and silly GIFs take over. It takes your mind off your life.</p><p>Then you get tired or you finally fall asleep, way too late, disrupting your sleep schedule.</p><p>The next day, you wake up and are back at square 0. You still don't feel that great about yourself...</p><p>Digital distractions are self-perpetuating misery machines.</p><h3>Zombie mode: Low effort, low value entertainment</h3><p>You don't feel great, so you choose to get distracted.</p><p>But then you become distracted, which causes you to not feel great. After all, you haven't made any real progress.</p><p>So the cycle continues.</p><p>You rarely get off the Internet feeling excited and ready to take on the world.</p><p>No, you feel distracted. Unsure what to do. Unfocused. That mental state is not great. And it's not useful.</p><p>That's what we call Zombie mode: passively consuming online media to get cheap dopamine.</p><p>Let's stop this cycle.</p><p>"How?" you ask.</p><h2>Let your mind wander</h2><p>The solution is simple: get away from screens.</p><p>With the arrival of information technologies, information has become less and less connected to our daily lives. In other words, less relevant.</p><p>The news, social media, and much of the Internet is utterly irrelevant to your life right now.&nbsp;<strong>You don't need more information, you need to do more with the information you already have.</strong></p><p>And to do that, you need time to process it. Time to take the general lessons of others and figure out how you can implement them in your own life. Time to turn the information into action. Time to go from passive to active.</p><h3>Unprocessed thoughts = heavy burden</h3><p>When you've spent the whole day binging a Netflix show, then you won't have time to process the fact that you're getting out of shape, or that you've let your room be a mess, or that you still have not messaged John,... There's no time for left for it, you're always distracted. Always "not feeling like" doing what needs to be done.</p><p>Over time, unfinished business accumulates in our mind. Promises we've made, things we meant to do, requests from others.</p><p>When we don't create time to let all those things unwind in our mind and deal with them, they become a heavy burden in our mind.</p><h3>Afraid of your thoughts?</h3><p>When the unprocessed thoughts accumulate over long periods of time, they can turn into the fear of being alone with your own thoughts. The idea of thinking about what we need to deal with becomes so stressful that we want avoid it as much as we can.</p><p>We fill our time with podcasts, YouTube videos, Instagram scrolling, watching TikToks, and other passive activities because&nbsp;<strong>we fear the moments when our mind is free of external inputs.</strong></p><p>The only moment when we're alone is when falling asleep or in a shower, and some people fill even those moments with music or podcasts.</p><p>Needless to say, this is terrible for us.</p><h2>Most digital tools aren't suited for figuring things out</h2><p>The problem is that our digital environment is not well suited to letting our mind wander and being intentional.</p><p><strong>When you want to think, reflect, or figure things out, a screen is not your friend.</strong>&nbsp;(The one exception may be a blank screen of a distraction-free editor.)</p><p>To mull over your current circumstances and formulate what to do, go away from screens for an extended periods of time.</p><p>Create big chunks of time (1 hour or more) when you have "nothing to do." Create that space and then don't fill it with low-effort unproductive actions! Instead, let your mind be. Let yourself wander a bit. And then act on thoughts that are at least mildly productive.</p><p>Let yourself process the accumulated unfinished business. Unpack your baggage.</p><p>Here's one way to turn this into practice.</p><h3>⏱ Block out an Input-free Hour</h3><p>Set a timer for 60 minutes, and go away from any screens until the timer goes off.</p><p>Do anything, except for staring at screens. Don't consume any information from the outside, only from your own mind. No podcasts, no news, no social media. Tidy up, nap, go for a walk.</p><p>If you want to, write down some thoughts, but don't look of external information.</p><p>For 60 minutes, do not consume any more information, deal with the stuff already on your mind.</p><p>Put it on your calendar, or do it on the fly by setting a time.</p><p>You can try it right now. Stop reading. Set a timer for 1 hour on your phone, put your phone screen-side down and walk away from it.</p><h2>Block out input-free time in your life</h2><p>Let your mind wander.</p><p>Get away from time-sucking apps and do something offline that will make your life a bit better tomorrow, instead of waking up back at square 1 every day.</p><p><strong>You don't need more information. You need to do more with the information you already have.</strong></p></article></div>]]>
            </description>
            <link>https://www.deprocrastination.co/blog/block-out-input-free-time</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987391</guid>
            <pubDate>Mon, 01 Feb 2021 10:28:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring Kubernetes Operator Pattern]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987069">thread link</a>) | @alexellisuk
<br/>
February 1, 2021 | https://iximiuz.com/en/posts/kubernetes-operator-pattern | <a href="https://web.archive.org/web/*/https://iximiuz.com/en/posts/kubernetes-operator-pattern">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a name="cut"></a>
I've been using Kubernetes for almost a year now and, to be honest, I like the experience so far. Most of my use cases were rather trivial and thanks to its declarative approach, Kubernetes makes deploying and scaling stateless services pretty simple. I usually just describe my application in a YAML file as a set of interconnected services, feed it to Kubernetes, and let the built-in <a href="https://kubernetes.io/docs/concepts/architecture/controller/">control loops</a> bring the state of the cluster closer to the desired state by creating or destroying some resources for me automagically.</p>
<p>However, many times I've heard that <a href="https://www.lastweekinaws.com/podcast/screaming-in-the-cloud/the-staying-power-of-kubernetes-with-kelsey-hightower/">the real power of Kubernetes comes with its extensibility</a>. Kubernetes designed for automation. It brings a lot of useful automation out of the box. But it also provides extension points that can be used to customize Kubernetes capabilities. The cleverness of the Kubernetes design is that it encourages you to keep the extensions feel native! So when I stumbled upon the first few Kubernetes Operators on my Ops way, I could not even recognize that I'm dealing with custom logic...</p>
<p>In this article, I'll try to take a closer look at the Operators pattern, see which Kubernetes parts are involved in operators implementation, and what makes operators feel like first-class Kubernetes citizens. Of course, with as many pictures as possible.
<a name="eofcut"></a></p>
<h2 id="kubernetes-objects-and-controllers">Kubernetes Objects and Controllers</h2>
<p>Everything in Kubernetes seems to revolve around <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/">objects</a> and <a href="https://kubernetes.io/docs/concepts/architecture/controller/">controllers</a>.</p>
<p>Kubernetes objects such as Pods, Namespaces, ConfigMaps, or Events are persistent entities in the Kubernetes system. Kubernetes uses these entities to represent the state of your cluster. Objects are also used as "records of intent." By creating (or removing) objects one can describe the <em>desired</em> state of the Kubernetes cluster.</p>
<p><i>Objects are like data structures.</i></p>
<p>On the other hand, controllers are infinite loops that watch the <em>actual</em> and the <em>desired</em> states of your cluster. When these two states diverge, controllers start making changes aiming to bring the current state of the cluster closer to the desired one.</p>
<p><i>Controllers are like algorithms.</i></p>
<p><img src="https://iximiuz.com/kubernetes-operator-pattern/kube-control-loop-3000-opt.png" width="100%" alt="Kubernetes Control Loop">
</p>

<p>I'll get to the controllers part later in this article and now let's focus on the objects.</p>
<h2 id="kubernetes-api-architecture">Kubernetes API Architecture</h2>
<p>All interactions with Kubernetes objects, <a href="https://kubernetes.io/docs/reference/using-api/client-libraries/">directly</a> or <a href="https://kubernetes.io/docs/reference/kubectl/overview/">indirectly</a>, happen through <a href="https://kubernetes.io/docs/concepts/overview/kubernetes-api/">Kubernetes API</a> - a highly structured masterpiece of software design.</p>
<p>There is a ton of documentation written on Kubernetes API and related topics and I spent quite some time digesting it. Since we are going to talk about the Kubernetes Operator pattern which heavily depends on the capabilities of the Kubernetes API, it's important to familiarize ourselves with the API design principles first. Following is my super-condensed excerpt from the docs.</p>
<p>Kubernetes offers a RESTful declarative HTTP API. Still remember those Kubernetes objects? <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#custom-resources">A collection of objects of a certain kind form an <em>API resource</em></a>:</p>
<blockquote>
<p>A resource is an endpoint in the Kubernetes API that stores a collection of API objects of a certain kind; for example, the built-in pods resource contains a collection of Pod objects.</p>
</blockquote>
<p>You can always check the list of available API resources using <code>kubectl api-resources</code> command:</p>
<pre><code>$ kubectl api-resources
NAME          SHORTNAMES   APIVERSION   NAMESPACED   KIND
namespaces    ns           v1           false        Namespace
nodes         no           v1           false        Node
pods          po           v1           true         Pod
deployments   deploy       apps/v1      true         Deployment
jobs                       batch/v1     true         Job
...</code></pre>
<p>OK, great, we've got resources. But Kubernetes evolves quickly. What if a new attribute needs to be added to an existing resource definition? API versioning is always hard. <i>&lt;speculation mode&gt;</i>Apparently, Kubernetes API started with a common prefix <code>/api/&lt;version&gt;/&lt;resource&gt;</code> for all the API resources. However, a change in a single resource would require a whole API version bump. So, with the growth in the number of available resources, the need for some sort of grouping and subversioning emerged.<i>&lt;/speculation mode&gt;</i></p>
<p>API groups to the rescue! <a href="https://kubernetes.io/docs/concepts/overview/kubernetes-api/#api-groups-and-versioning">A bunch of related resources forms an API group</a>:</p>
<blockquote>
<p>To make it easier to evolve and to extend its API, Kubernetes implements API groups that can be enabled or disabled.</p>
</blockquote>
<p>You can also check the list of available API groups and their versions using <code>kubectl api-versions</code> command:</p>
<pre><code>$ kubectl api-versions
admissionregistration.k8s.io/v1
admissionregistration.k8s.io/v1beta1
apiextensions.k8s.io/v1
apiextensions.k8s.io/v1beta1
apiregistration.k8s.io/v1
apiregistration.k8s.io/v1beta1
apps/v1
...</code></pre>
<p>Well, at this point, I should warn you - it seems that in the documentation, the term <em>resource</em> is often used in the meaning of an <em>object</em> (but not vice versa). So, context matters.</p>
<p>In Kubernetes, objects of the same kind are distinguished by their names. So, if you start two Pods, both should get a unique name. But clusters can be pretty big and since names are supposed to be unique within a cluster, we need a mechanism to prevent collisions. Something like lots of logical clusters within one physical cluster. Allow me to introduce you to <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/#when-to-use-multiple-namespaces"><em>namespaces</em></a>!</p>
<blockquote>
<p>Kubernetes supports multiple virtual clusters backed by the same physical cluster. These virtual clusters are called namespaces.</p>
</blockquote>
<blockquote>
<p>...</p>
</blockquote>
<blockquote>
<p>Namespaces provide a scope for names. Names of resources need to be unique within a namespace, but not across namespaces. Namespaces cannot be nested inside one another and each Kubernetes resource can only be in one namespace.</p>
</blockquote>
<p>Thus, API objects are fully qualified by their API group, resource type, namespace (unless cluster-scoped), and name.</p>
<p>Have you become totally confused by this time? No, worries, I've got a <del>simple</del> diagram for you 🙈</p>
<div>
    <p><img src="https://iximiuz.com/kubernetes-operator-pattern/kube-api-structure-3000-opt.png" width="100%" alt="Kubernetes API structure"></p><p><i>Kubernetes API structure.</i></p>
</div>

<p>So, a quick summary - we've learned about objects, resources, groups, and namespaces. But what's up with the promised customization?</p>
<h2 id="kubernetes-custom-resources">Kubernetes Custom Resources</h2>
<p>It seems like there is <a href="https://github.com/kubernetes/community/blob/master/sig-api-machinery/README.md">a great deal of effort</a> in keeping the Kubernetes API coherent but extensible.</p>
<p>What do I mean by <em>coherent</em> here? Kubernetes API consists of endpoints called <em>resources</em>. These API resources adhere to a set of common requirements - they are nouns and manipulated in a declarative manner (RESTful CRUD), they should be updated relatively infrequently and be reasonably small in size, their names should be <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-subdomain-names">valid DNS subdomains</a>, etc.</p>
<p>These restrictions allow unifying the resource workflows. For instance, you can get, describe, or update a collection of Pods in pretty much the same way as a collection of Services, Nodes, or RBAC roles:</p>
<pre><code>$ kubectl get pods
$ kubectl get services
$ kubectl get roles

$ kubectl describe pods  # or services, or roles

$ kubectl edit pods  # or services, or roles</code></pre>
<p>Not only <code>kubectl</code> benefits from this uniformity. Here is a full list of <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#common-features">common features</a> enabled by the unified design:</p>
<div>
    <p><img src="https://iximiuz.com/kubernetes-operator-pattern/kube-api-common-features-3000-opt.png" width="100%" alt="Kubernetes API common features"></p>
</div>

<p>It's pretty handy, isn't it?</p>
<p>So, if I were to extend the API, it'd be reasonable for me to expect that my endpoints would benefit from this common functionality as well. But that would mean that the API extension should be done by adding more resources!</p>
<p>And indeed, in Kubernetes, one can easily register <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#custom-resources"><em>custom resources</em></a>. The procedure is fully dynamic and doesn't require restarting or updating the API server.</p>
<p>How such a custom resource can be added? Well, again, it's Kubernetes! Of course, by interacting with another, already existing resource! There is a special API resource called <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#customresourcedefinitions">CustomResourceDefinition (CRD)</a>:</p>
<blockquote>
<p>The CustomResourceDefinition API resource allows you to define custom resources. Defining a CRD object creates a new custom resource with a name and schema that you specify.</p>
</blockquote>
<p>And <a href="https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#create-a-customresourcedefinition">from another documentation page</a>:</p>
<blockquote>
<p>When you create a new CustomResourceDefinition (CRD), the Kubernetes API Server creates a new RESTful resource path for each version you specify.</p>
</blockquote>
<h2 id="how-to-create-custom-resource">How to Create Custom Resource</h2>
<p>Let's try to create a custom resource. Remember, a resource specifies a certain kind of Kubernetes object. Canonically, objects possess some attributes. So, our CustomResourceDefinition should be mostly concerned with describing the attributes of our future resource. Additionally, it's good to know that custom resources can be either namespaced or cluster-scoped. This is specified in the CRD's scope field.</p>
<pre><code>apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: blogposts.iximiuz.com
spec:
  group: iximiuz.com
  names:
    kind: BlogPost
    listKind: BlogPostList
    plural: blogposts
    singular: blogpost
  scope: Namespaced
  versions:
  - name: v1alpha1
    schema: ...
...</code></pre>
<details><summary>Click here to see the full CRD's YAML.</summary>
<pre><code>kubectl apply -f - &lt;&lt;EOF
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: blogposts.iximiuz.com
spec:
  group: iximiuz.com
  names:
    kind: BlogPost
    listKind: BlogPostList
    plural: blogposts
    singular: blogpost
  scope: Namespaced
  versions:
  - name: v1alpha1
    schema:
      openAPIV3Schema:
        description: BlogPost is a custom resource exemplar
        type: object
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation
              of an object. Servers should convert recognized schemas to the latest
              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this
              object represents. Servers may infer this from the endpoint the client
              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          metadata:
            type: object
          spec:
            description: BlogPostSpec is the spec for a BlogPost resource
            type: object
     …</code></pre></details></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iximiuz.com/en/posts/kubernetes-operator-pattern">https://iximiuz.com/en/posts/kubernetes-operator-pattern</a></em></p>]]>
            </description>
            <link>https://iximiuz.com/en/posts/kubernetes-operator-pattern</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987069</guid>
            <pubDate>Mon, 01 Feb 2021 09:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Does Lossless Compression in Fuji RAF Files Work?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987013">thread link</a>) | @dsego
<br/>
February 1, 2021 | https://capnfabs.net/posts/fuji-raf-compression-algorithm/ | <a href="https://web.archive.org/web/*/https://capnfabs.net/posts/fuji-raf-compression-algorithm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody" id="content"><p>Oh boy, this is going to be a doozy of a blog post.</p><p>I’ve spent the last three months in New York<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> at the <a href="https://www.recurse.com/">Recurse Center</a>, developing an understanding of the fundamentals of digital photography.</p><p>Something that’s been really, really rewarding about this project is that I’ve been able to take my own images, start with the actual bits in a <a href="https://ridiculousfish.com/hexfiend/">hex editor</a>, and interpret them into images that progressively become more faithful and more beautiful, the more code I write.</p><p>Well, almost. There was one minor hiccup – all of the RAW files I’ve shot over the last 3 years have been encoded with Fuji’s lossless image compression algorithm. This is a fantastic technology as a photographer – 50 MB files are swiftly reduced to 25 MB, with literally no reduction in quality – but if you’re writing your own processor, then you need to decompress the data, and compression algorithms are usually <em>complex</em>.</p><h2 id="when-should-you-implement-something-yourself">When should you implement something yourself?</h2><p>I <em>knew</em> that this was going to be a rabbit hole before I started. I could <em>hear</em> the voice of my former boss saying “Fabian. Do you really need to be doing this?”.</p><p>I’ve written about <a href="https://capnfabs.net/posts/when-do-you-stop-writing/">Yak Shaves before</a>, and in theory I should know better – but, part of what attracted me to the Recurse Center in the first place was it seemed like a place where going down rabbit holes was permitted. Maybe not advised, but definitely permitted. So, in the first week of February, I found myself trying to figure out how Fuji’s lossless image compression technology worked.</p><p>The thing was, I already had the ability to load compressed Fuji RAF files in my software – the excellent, albeit minimally documented, <a href="https://www.libraw.org/">LibRaw</a> project has had support for this since 2016, and my code was initially loading files by binding to LibRaw. At some point, though, I got frustrated with not knowing exactly what was <em>in</em> my RAW file. Libraw is functionally very good, but it doesn’t do a good job of surfacing what its sources are for any given piece of data<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. One thing led to another, and at some point I’d decided to replace LibRaw with my own code. Which meant I’d need to re-implement Fuji’s lossless compression algorithm, at least for the photos from my specific camera model.</p><h2 id="how-does-it-work">How does it work?</h2><p>Fuji RAF lossless compression can be characterised as an adaptive, differential compression algorithm. Let’s break that down:</p><ul><li><em>Adaptive</em>: the algorithm changes with the data it has processed in the past</li><li><em>Differential</em>: the algorithm is predicated on storing the <em>difference</em> between an ‘expected’ value and the actual value.</li></ul><h2 id="step-1-split-into-stripes">Step 1: Split into stripes</h2><p>First, split the image into a set of vertical stripes. My camera (the Fuji X-T2) uses 8. Each of these stripes is encoded independently (i.e. with separate input, output, and state), which means it’s <em>possible to parallelise the encoding and decoding</em>. This turns out to be super important for performance on modern CPUs – parallelising my decoder resulted in a 6x speedup in user time (on a 4-core hyperthreaded machine).</p><figure><figcaption><p>Splitting the image into vertical stripes</p></figcaption></figure><h2 id="step-2-sensor-data--colored-vector-collation">Step 2: Sensor data → Colored vector collation</h2><p>Now that we’ve split the image into stripes, we can break each stripe down further into <em>lines</em> of nx6 pixels. We’ll take each of those lines, and map their pixels into color vectors. It’s probably easiest to explain this with a diagram:</p><figure><figcaption><p>Mapping Sensor Pixels to Colored Blocks</p></figcaption></figure><p>If you’ve never worked with digital imaging before, you might be surprised that each pixel in a camera sensor <em>only represents one color</em>. The pixels themselves aren’t capable of differentiating between different colors of light, just of counting approximate numbers of photons, so manufacturers usually slap a <a href="https://en.wikipedia.org/wiki/Color_filter_array">Color Filter Array</a> on top to narrow the color range that each pixel responds to.</p><p>We collate the pixels by color because later, we’ll apply a transform that encodes the differences between neighbouring pixels. If the neighbouring pixels all represent the same component color, those differences are smaller, which allows for better compression.</p><p>Now that we’ve got the data collated into solid color blocks, we’re ready to start processing.</p><h2 id="step-3-color-vectors--bits">Step 3: Color vectors → bits</h2><p>Here’s where it gets real interesting. Now that we’ve collected the data into color vectors, we interleave two color vectors and compress them together.</p><p>Let’s use R0 and G0 as our first pair of color-lines. We now need to iterate through each item of R and G, but the order is kinda special:</p><blockquote><p>R[0], G[0], R[2], G[2], R[4], G[4], R[6], G[6], R[1], G[1], R[8], G[8], R[3], G[3], …</p></blockquote><p>We start by iterating through the <em>even</em> slots in R and G. After we’ve done the first 4 of each, we can <em>also</em> start iterating through the odd slots, which will always be 5 positions behind the even slots.</p><p>Here it is again in diagram format:</p><figure><figcaption><p>Iteration Order. Notice that we start jumping back to the odd pixels after we’ve started with the even pixels.</p></figcaption></figure><p>This feels weird, but hold with me, we’ll be able to explain it very soon! I promise.</p><h3 id="making-a-sample-for-a-single-value">Making a sample for a single value</h3><p>Now, the idea for a single value is:</p><ul><li>Figure out an <em>expected value</em> for the cell, by (approximately) taking a weighted average of the <em>already processed values</em> around it</li><li>Compute the difference between the <em>actual</em> value and the expected value</li><li>Encode the difference and send to output</li><li>Adapt the encoding process so that it gives better compression ratios in future.</li></ul><p>Let’s examine each of those steps individually:</p><h3 id="computing-an-expected-value">Computing an expected value</h3><p>Loosely, the expected value of a cell is computed as a weighted average of values around it. What’s vital about this, however, is that these are values that we’ve <em>already processed</em>, because when we’re decoding, we’ll use <em>expected value</em> + <em>difference</em> to compute the output value. The decoder will need to be able to compute the <em>expected value</em>, which means that the encoder can only use values it’s already decoded to compute an expected value.</p><p>The details of this are probably better represented in code, but here’s a visual indication of the cells we’re selecting for the weighted average. For even cells, we select these:</p><figure><figcaption><p>Reference pixels for computing Weighted Average, for <strong>even</strong>-indexed pixels</p></figcaption></figure><p>And for odd cells, it’s these:</p><figure><figcaption><p>Reference pixels for computing Weighted Average, for <strong>odd</strong>-indexed pixels</p></figcaption></figure><p>This reveals a couple of important ordering dependencies:</p><ol><li>Part of the reason why we don’t start iterating on odd cells until we’ve done a bunch of even cells is because we need the even cells to be processed in order to process the odd cells<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>.</li><li>To compute the weighed average for each row, we need the values of the previous two rows.</li></ol><p>The specifics of the weighted average formulas feel <em>pretty</em> esoteric to me. I’m inclined to suggest that engineers within Fuji were trying stuff out to see what gave the best compression ratios across a bunch of different sample images, found something that worked and was low-cost, and baked that in to the format<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>.</p><h3 id="compute-the-difference">Compute the difference</h3><p>This is straightforward! The difference is simply <code>actual_value - expected_value</code>. 🎉</p><h3 id="encode-the-difference">Encode the difference</h3><p>Because photographic images tend to have big blocks of color, and to change slowly across the image, it’s typically possible to represent the difference from the weighted average in less bits than are required to store the value directly. For an image where every pixel is encoded with 14 bits, we can typically represent the difference between neighbouring pixels with maybe 5 or 6 bits.</p><p>Unfortunately, we can’t simply store the differences and call it ‘done’ – just because the differences are <em>typically</em> low, it doesn’t mean they’re <em>always</em> low, and in order to capture <em>every possible</em> difference from the weighted average, we require the same number of bits as we had to start with. We’re going to need a clever encoding scheme to handle this discrepancy.</p><p>Let’s say that we’ve got a difference of 27 from the expected value. We’ll represent that in binary as:</p><pre><code>11011
</code></pre><p>Now, let’s say that most of the time, it only requires 6 bits to encode the difference between neighbouring pixels. We’d pad the binary number out to 6 bits:</p><pre><code>011011
</code></pre><p>… but we still need to encode whether we should add or subtract from the expected value. So let’s use <a href="https://en.wikipedia.org/wiki/Two%27s_complement">two’s complement</a>. We now need to encode 2x the range of numbers (positive and negative), so we need to add another bit. For our example of adding to the expected value, this just means we need to add another zero at the front:</p><pre><code>0011011
</code></pre><p>If we needed to instead <em>subtract</em> 27, we’d use:</p><pre><code>1100101
</code></pre><p>With this 7-bit scheme, we could encode differences between -128 and +127 from the expected value.</p><h3 id="variable-length-codes">Variable Length Codes</h3><p>So, what should we do if we need to encode a difference <em>outside</em> of this range?</p><p>Let’s say that we need to encode a difference of 300 in our 7-bit scheme. We’ll start by converting to binary, which requires 10 bits as a signed two’s complement integer:</p><pre><code>+300 = 0100101100
</code></pre><p>Now, let’s split on the 7-bit boundary. We know we can store the last 7 bits using the scheme we already have:</p><pre><code>???
|   7-bit fixed width
|   |
010 0101100
</code></pre><p>So we’ve got <code>0b010</code> remaining at the front. That translates to 2 in decimal, which is a pretty small number. It’s worth noting that we’d expect it to be less likely for this overflow to be a 3, and even less likely again for it to be a 4, or 5, or a 6, because in general, we’re expecting the differences to be small.</p><p>This sounds like the perfect candidate for a <a href="https://en.wikipedia.org/wiki/Variable-length_code"><em>variable length code</em></a>. In fact, this is exactly what the algorithm does, converting the ‘2’ prefix into two 0s, followed by a 1:</p><pre><code>     2 zeros
     |  terminating one
     |  |
2 =&gt; 00 1
</code></pre><p>Similarly:</p><pre><code>5 =&gt; 000001
4 =&gt; 00001
3 =&gt; 0001
2 =&gt; 001
1 =&gt; 01
0 =&gt; 1
</code></pre><p>Simple, right? And now, we can encode our difference of 300 as:</p><pre><code>        [variable-length]
        |
        |   [7-bit fixed-length]
        |   |
+300 =&gt; 001 0101100
</code></pre><p>For a difference of +300, we’re still only paying 3 + 7 bits = 10 bits, instead of the usual 14 to encode a full sample.</p><h3 id="when-twos-complement-_isnt_-the-right-tool-for-the-job">When two’s complement <em>isn’t</em> the right tool for the job</h3><p>We’ve made a problem for ourselves now: notice how we effectively ‘dropped’ the leading sign bit when we converted to variable length?</p><p>Consider the encoding of the following …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://capnfabs.net/posts/fuji-raf-compression-algorithm/">https://capnfabs.net/posts/fuji-raf-compression-algorithm/</a></em></p>]]>
            </description>
            <link>https://capnfabs.net/posts/fuji-raf-compression-algorithm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987013</guid>
            <pubDate>Mon, 01 Feb 2021 09:18:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Player Movement System in “The Witness”]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25986914">thread link</a>) | @obl
<br/>
February 1, 2021 | https://caseymuratori.com/blog_0032 | <a href="https://web.archive.org/web/*/https://caseymuratori.com/blog_0032">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://caseymuratori.com/blog_0032</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986914</guid>
            <pubDate>Mon, 01 Feb 2021 09:03:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BioNTech's Long-Term Dream: From Coronavirus to a Cancer Vaccine]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25986454">thread link</a>) | @lawrenceyan
<br/>
January 31, 2021 | https://www.spiegel.de/international/world/biontech-s-long-term-dream-from-coronavirus-to-a-cancer-vaccine-a-b136a53d-baee-4b94-b43c-e8c45faa19d1 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/biontech-s-long-term-dream-from-coronavirus-to-a-cancer-vaccine-a-b136a53d-baee-4b94-b43c-e8c45faa19d1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="">


</section>
<section>
<div>
<figure data-component="Image" data-zoom-id="b105f7b5-384d-4c37-a6e3-68014ea42825" data-settings="{&quot;id&quot;:&quot;cbb1c4fd-65e2-4b2e-acb1-6443bdf20dec&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;b105f7b5-384d-4c37-a6e3-68014ea42825&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/cbb1c4fd-65e2-4b2e-acb1-6443bdf20dec_w948_r1.77_fpx29.61_fpy54.97.jpg" srcset="https://cdn.prod.www.spiegel.de/images/cbb1c4fd-65e2-4b2e-acb1-6443bdf20dec_w520_r1.77_fpx29.61_fpy54.97.jpg 520w, https://cdn.prod.www.spiegel.de/images/cbb1c4fd-65e2-4b2e-acb1-6443bdf20dec_w948_r1.77_fpx29.61_fpy54.97.jpg 948w" width="948" height="536" sizes="948px" title="A BioNTech laboratory in Mainz, Germany: The company jumped into the race for a coronavirus vaccine essentially overnight." alt="A BioNTech laboratory in Mainz, Germany: The company jumped into the race for a coronavirus vaccine essentially overnight.">
</span>
</span>
</span>

</p>
<figcaption>
<p><strong>A BioNTech laboratory in Mainz, Germany: </strong>The company jumped into the race for a coronavirus vaccine essentially overnight.<br></p>
<span>
Foto: Biontech / dpa
</span>
</figcaption>
</figure>
</div><div>
<p>The timing could hardly have been better. The number of coronavirus infections had risen to a horrific high, as had the number of deaths from the virus, when the news hit global headlines: A new kind of vaccine is 90 percent effective against COVID-19.</p>


<div>
<p>"This data brings us a step closer to a possible solution for the current global pandemic," says Uğur Şahin, medical doctor and CEO of BioNTech, the Mainz-based biotech company that developed the vaccine together with the American pharmaceutical firm Pfizer. The two companies are currently seeking regulatory approval in the United States.</p><p>The breakthrough may not only signify the beginning of the end of the corona crisis -- it could also end up radically changing the entire approach to vaccine development. People receiving serums developed with this technology are injected with a packaged molecule containing a construction blueprint in the form of messenger RNA, or mRNA.</p>
</div>

<div>
<p>These molecules are absorbed by cells in the body, whereupon the mRNA prompts them to produce a specific protein. This protein, though, is "foreign" to the body and is attacked by immune cells -- thus developing immunity.</p><h3>"An Historic Result"</h3><p>Research into the technology has been ongoing for decades due to its potential effectiveness in fighting all kinds of diseases, including cancer. And now, in the fight against the SARS-CoV-2 virus, BioNTech and Pfizer have apparently proven that it works.</p><p>"This is a historic result, the first mRNA vaccine to show interim efficacy," says immunologist Nicholas Jackson of the Coalition for Epidemic Preparedness Innovations, an international alliance for the advancement of vaccine research. If there are no setbacks, Jackson told DER SPIEGEL, "this positive result could drive a new era of effort to apply mRNA technologies towards infectious diseases."</p>
</div>

<p>Norbert Pardi, a research assistant professor at the University of Pennsylvania, agrees. In comments to DER SPIEGEL, he said: "It is fantastic that the mRNA vaccine works so well." Should it prove itself, he believes, "there will very likely be more and more approved mRNA vaccines against cancer and infectious diseases in the coming years."</p>
<section>

</section>
<p>Researchers turned to mRNA technology for the production of vaccines in part because traditional methods are so laborious. Such vaccines are produced using weakened viruses or parts of viruses. For the production of the flu vaccine, for example, 500 million eggs are used each year to breed the influenza virus. Furthermore, this approach has proven ineffective in the battle against certain infectious diseases, such as AIDS or Dengue fever - much less in the production of a vaccine for cancer patients.</p>

<div>
<p>As such, it seemed all the more attractive to program cells in the body to produce the vaccine by introducing mRNA containing the appropriate construction blueprint. Researchers began experimenting with this approach more than three decades ago, injecting foreign mRNA into laboratory animals – which then implemented the blueprint and produced the foreign substance in their muscle cells.</p><h3>A Cancer Vaccine?</h3><p>But after this encouraging start, the field saw few advances for quite some time. The reason: mRNA proved to be extremely instable, often breaking down immediately after being injected into the body or disappearing completely. The goal became that of employing molecular tricks to pack the mRNA in such a way that it could find its way into cells without being damaged. Only in the last 10 years, says Pardi, have technical innovations and research funding transformed mRNA into a "promising therapeutic tool."</p><p>The medical expert Özlem Türeci and her husband Uğur Şahin both participated in that research. The couple was hoping to discover improved methods for treating tumors – and early on, they dreamed of being able to produce a cancer vaccine.</p><p>The basis for that vision: When cancerous tissue begins to grow, abnormal cells that look foreign to the immune system are produced. Türeci and Şahin compared healthy tissue with abnormal tissue from a specific cancer patient and were thus able to find those cells that looked foreign. They then produced mRNA containing a blueprint for precisely these foreign structures. They also improved the mRNA so that it would, in fact, reach the target cells in the body.</p><p>In one study, Türeci and Şahin administered the appropriate mRNA to 13 patients suffering from malignant melanoma, and found that each patient's immune system responded. Eight of them experienced no remission in the 12 to 23 months afterward. The treatment is unable to prevent cancer, but it could help treat it and to prevent metastasis.</p>
</div>
<div>

<div>
<p>Similar results expected for the vaccine produced by Moderna in Cambridge, Massachusetts</p>
</div>

</div>
<div>
<p>The trick is that each patient receives an mDNA that is precisely tailored to the genetic profile of the cancer they are suffering from. These personalized cancer immunotherapies are still considered experimental, but the results of the initial study were so promising that Türeci, Şahin and their team were able to publish their results in July 2017 in <em>Nature</em>, the prominent scientific magazine. Almost two years later, a 52-year-old skin cancer patient in the U.S. received the experimental BioNTech treatment, after which he told <em>Nature</em>: "I was actually witnessing the cancer cells shrinking before my eyes."</p><p>Such statements should always be approached with caution, of course, but these days, dozens of companies and universities are conducting research into the technology. Clinical studies with mRNA vaccines - targeting breast cancer, lung cancer, prostate cancer and colon cancer, among others – are underway. The variety of different kinds of cancer being targeted, mRNA expert Pardi said not long ago, prove that mRNA vaccines can be instrumental in the fight against the disease.</p><h3>1.3 Billion Doses</h3><p>In January, though, Türeci and Şahin jumped into the race for a coronavirus vaccine essentially overnight, once they realized the gravity of the looming pandemic. Inside BioNTech, they slapped together a team that was initially 40-people strong. On the basis of the virus' genetic sequence, that team rapidly developed 20 possible vaccine candidates and began testing them on laboratory animals, narrowing down the field of potential serums. At the same time, BioNTech turned to the pharmaceuticals giant Pfizer with an offer to team up for the clinical study phase.</p><p>More than 43,500 people have thus far taken part in the Phase III study. Some of the participants received two injections of a placebo three weeks apart, with the others receiving the vaccine candidate. Neither the test subjects nor the participating doctors knew who received what. Once a total of 94 of the test subjects came down with COVID-19, the data was analyzed for the first time by independent experts. According to that analysis, the vaccine produced "more than 90 percent" protection, as the press release noted.</p><p>What about the other mRNA vaccines in direct competition with BioNTech? Franz-Werner Haas, CEO of the Tübingen-based biotech firm Curevac, told DER SPIEGEL that his company's vaccine candidate has proven to be safe at all dosage levels tested. The decisive study for approval, he said, will begin before the end of the year. And the biotech company Moderna, located in Cambridge, Massachusetts, says Norbert Pardi, could soon be able to show "similar results" to those produced by BioNTech.</p><p>Until that happens, though, all eyes are on the biotech company in Mainz, the mRNA pioneer. Despite the fact that the vaccine has to be stored and transported at minus 70 degrees Celsius, despite the fact that each dose is to cost almost $20 in the U.S., and despite its efficacy not yet being conclusively proven, the vaccine is sold out through the end of 2021. Every single one of the projected 1.3 billion doses.</p>
<p><span><svg aria-labelledby="title-e7275cce-60e1-488f-9413-c995dc816dac" width="10" height="20" viewBox="0 0 10 20" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-e7275cce-60e1-488f-9413-c995dc816dac">Icon: Der Spiegel</title><g id="l-s-flag-e7275cce-60e1-488f-9413-c995dc816dac"><path id="vector-e7275cce-60e1-488f-9413-c995dc816dac" d="M9.85 16.293v-8H3.212V4.667h3.533v2.24h3.212v-3.2C9.85 2.747 8.993 2 8.03 2H1.713C.749 2 0 2.747 0 3.707v7.253h6.638v4.373H3.105v-2.986H0v3.84c0 .96.75 1.706 1.713 1.706H8.03c.963.107 1.82-.64 1.82-1.6z" fill="#000"></path></g></svg>
</span>
</p></div>
</div>
</section>

</div></div>]]>
            </description>
            <link>https://www.spiegel.de/international/world/biontech-s-long-term-dream-from-coronavirus-to-a-cancer-vaccine-a-b136a53d-baee-4b94-b43c-e8c45faa19d1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986454</guid>
            <pubDate>Mon, 01 Feb 2021 07:34:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case Against Fauci]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25986443">thread link</a>) | @andrewon
<br/>
January 31, 2021 | https://www.thedriftmag.com/the-case-against-fauci/ | <a href="https://web.archive.org/web/*/https://www.thedriftmag.com/the-case-against-fauci/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><strong>T</strong><span>here is no one in American government — or perhaps any government — quite like Dr. Anthony Fauci. His position, with its mixture of informal power and public visibility, scientific authority and beltway influence, is sui generis. Few other unconfirmed civil servants have access to as many rooms in the executive interagency; no public official commands as much respect in the world of science and medicine. As director of the National Institute of Allergy and Infectious Diseases (NIAID) since 1984, he has advised six presidents (and now a seventh) on domestic and global health issues — HIV/AIDS, SARS, Ebola, Zika, and MERS — and overseen decades of research on infectious disease, pandemics, and virology. Under his stewardship, NIAID’s mission has been reshaped around his personage: its priorities are </span><i><span>his</span></i><span> priorities, its research agenda is </span><i><span>his</span></i><span> research agenda. And that agenda has borne fruit: breakthrough treatments for HIV and other deadly diseases and now, a vaccine for Covid-19. As Stanford microbiologist David Relman told </span><i><span>The</span></i> <i><span>New Yorker</span></i><span> in April, “Tony has essentially become the embodiment of the biomedical and public-health research enterprise in the United States.”</span></p>
<p><span>Although Fauci has no statutory authority to preside over a public health crisis, he has become the nation’s de facto Doctor-in-Chief during this pandemic. His face — elven and expressive — is the face of the medical establishment’s response to the novel coronavirus. I doubt most Americans can name the (</span><a href="https://www.washingtonpost.com/us-policy/2021/01/20/biden-surgeon-general-resignation/" target="_blank" rel="noopener noreferrer"><span>outgoing</span></a><span>) U.S. Surgeon General, CDC Director, or Fauci’s nominal boss, the director of the National Institutes of Health (Jerome Adams, Robert Redfield, and Francis Collins, respectively), but everyone knows Dr. Fauci. His plaintive but never pessimistic patter and disarming outer-borough rasp are soothing sonic features of our daily dirge of death, doom, and statistics. I was relieved when I first saw Fauci on TV — sometime in March 2020 — thinking dimly to myself, for the millionth time, “Ah, an adult in the room.” Amid a ceaseless current of chaos and grief, Fauci’s egoless display of competence, his grandfatherly warmth and irony, were ports in a storm.&nbsp;</span></p>
<p><span>But a comforting bedside manner has done little to mitigate catastrophe. Over 400,000 Americans are dead, twice as many as any other country. Infections, hospitalizations, and deaths are currently at record highs. And although we have a vaccine, the rollout has already been stymied by a dearth of resources and coordination. As one public health expert told <em>The </em></span><i><span>New York Times </span></i><span>on January 17</span><i><span>,</span></i><span> our pandemic response has been “a colossal failure at every level of government.” And herein lies a paradox. America is suffering from a disease outbreak whose morbid scope is the consequence of world-historic negligence. We are desperately and needlessly sick. And yet, the man known as “America’s Doctor,” the undisputed personification of public health research and pandemic preparedness, faces no reputational consequences. On the contrary, Dr. Fauci remains one of our most beloved public figures.&nbsp;&nbsp;</span></p>
<p><span>What explains this? Liberals, who otherwise harshly condemn the federal government’s pandemic response, are especially besotted with the diminutive virologist. For fans of the #Resistance, a well-timed </span><a href="https://www.businessinsider.com/dr-anthony-fauci-did-a-facepalm-during-trumps-coronavirus-briefing-2020-3" target="_blank" rel="noopener noreferrer"><span>facepalm</span></a><span> during one of the Mad King’s early soliloquies guaranteed Fauci’s place on a Mount Rushmore of replacement patriarchs, alongside James Comey and Robert Mueller. (Fauci later insisted the gesture was innocuous; he was merely obscuring his face to dislodge a lozenge from his throat.) Still, Democrats’ devotion has never waned. They see in Fauci a lonely champion of “truth” and “facts” in a White House otherwise hostile to “science.” Brad Pitt earned an Emmy nomination for portraying the 80-year-old physician on Saturday Night Live. One Hamilton-inspired TikTok (“My name is Dr. Anthony Fau-CHEE…”) went viral. Just since the beginning of the “third wave” of Covid infections in October, Fauci has received leadership awards from the National Academy of Medicine, the FBI Agents Association, the Arthur Ashe Institute for Urban Health, and the Boy Scouts of America. Joe Biden has </span><a href="https://www.cnn.com/2020/12/03/politics/anthony-fauci-biden-transition/index.html" target="_blank" rel="noopener noreferrer"><span>asked</span></a><span> Fauci to stay on at NIAID and serve in his administration as a chief medical advisor. D.C. Mayor Muriel Bowser proclaimed “Anthony S. Fauci Day” on December 24.&nbsp;</span></p>
<p><span>Fauci’s celebrity, however, cannot obscure empirical reality. As America’s Doctor would surely agree, the numbers don’t lie: 2,824 Americans died of Covid-19 on Anthony S. Fauci Day.&nbsp;</span></p>
<p><span>Anthony Fauci is no doubt a dedicated public servant, respected by his colleagues, beloved by many Americans. But the puzzle remains: why has the man most closely associated with the public health response to the pandemic entirely avoided accountability for its failure?&nbsp;</span></p>

<p><strong>F</strong><span>irst, the most straightforward defense: it wasn’t his fault. He did the best he could, but Fauci’s better instincts were thwarted by Trump and his coterie of idiots. Of course, there’s truth in this. The uneasy peace between Trump and his medical advisors started to unravel almost before it began. By the end of March, Trump was sweating the stocks and tweeting that the “cure” must not be worse “than the problem itself.” He clashed with Fauci throughout the spring — over masks, hydroxychloroquine, school openings, and Easter. By summer, Trump was publicly lambasting the good doctor, leaking anti-Fauci talking points to the press and sidelining him in task force meetings, which were themselves increasingly rare. Scott Atlas, the libertarian radiologist and herd-immunity advocate whom Trump hired based on his Fox News appearances, was calling the shots.</span></p>
<p><span>But Fauci seldom contradicted the president’s lies outright, opting for tact and de-escalation instead. “I can’t jump in front of the microphone and push him down,” Fauci </span><a href="https://www.theguardian.com/world/2020/mar/23/dr-fauci-press-conference-white-house-coronavirus" target="_blank" rel="noopener noreferrer"><span>said</span></a><span> in late March. “OK, he said it. Let’s try and get it corrected for the next time.” On July 4, Trump said 99 percent of Covid cases were “harmless.” Fauci characterized this as a misinterpretation. (“I’m trying to figure out where the president got that number…” he said.) Though Fauci has a reputation for bluntness, as the </span><i><span>Financial Times</span></i><span>’s Hannah Kuchler </span><a href="https://www.ft.com/content/57834c2c-a078-4736-9173-8fb32cfbbf4e" target="_blank" rel="noopener noreferrer"><span>observed</span></a><span>, “he clearly also tries to hold back, believing he will make a bigger difference to the course of the pandemic if he keeps his job.”</span></p>
<p><span>This logic pervades the most common defense of Fauci’s record. “Tony is unique, in that he has such credibility with politicians that he’s been able to insert hard facts into the conversation,” Nobel laureate biologist David Baltimore told </span><i><span>The</span></i> <i><span>New Yorker</span></i><span> in April. “That has been wonderful for our country and the world.” In this view, Fauci was </span><i><span>handling</span></i><span> Trump, just as he handled previous presidents, including a reluctant Ronald Reagan during the AIDS epidemic. When he pulls his punches, it’s always for the greater good; namely, the cause of remaining in the room. Stepping too far out of line, contradicting Trump with too much vigor, would have imperiled his standing. “The argument for Fauci saying more,” </span><a href="https://www.washingtonpost.com/opinions/2020/07/16/anthony-fauci-built-truce-trump-is-destroying-it/?arc404=true" target="_blank" rel="noopener noreferrer"><span>wrote</span></a><span> Molly Roberts in <em>The</em> </span><i><span>Washington Post</span></i><span>, “… is also an argument for self-exile.” And then what? Truth and facts would have had no advocate inside the White House. As Fauci himself </span><a href="https://www.nytimes.com/2021/01/24/health/fauci-trump-covid.html?action=click&amp;module=Top%20Stories&amp;pgtype=Homepage" target="_blank" rel="noopener noreferrer"><span>told</span></a><span> the </span><i><span>Times</span></i><span> on Sunday, “I felt that if I stepped down, that would leave a void. Someone’s got to not be afraid to speak out the truth.”</span></p>
<p><span>At a briefing in July, Trump </span><a href="https://www.cnn.com/2020/07/28/politics/donald-trump-anthony-fauci-approval-rating/index.html" target="_blank" rel="noopener noreferrer"><span>mused</span></a><span>, “It’s interesting: [Fauci’s] got a very good approval rating. And I like that, it’s good. Because remember, he’s working for this administration. He’s working with us.” Winding his way to his point, Trump said, “So why don’t I have a high approval rating… with respect to the virus?” After a pause, he deadpanned, “It can only be my personality, that’s all.”&nbsp;</span></p>
<p><span>As is often the case with Trump, he had a point, just not the one he meant. The liberal apologia for Fauci </span><i><span>was</span></i><span> internally contradictory. As one scientist said to me, “We can’t deify Fauci’s response to the pandemic as fantastic while simultaneously condemning Trump, when for months, the two were hand in hand.” Indeed, Fauci is only blameless if he was utterly powerless to stop the administration’s disastrous plans. And if he </span><i><span>was</span></i><span> powerless, he should’ve resigned and communicated the truth bluntly to the public long ago. Otherwise, he knowingly lent credibility to an abject failure he couldn’t control.&nbsp;</span></p>
<p><span>To put an even finer point on it, the precise conditions that would maximally exonerate Fauci — i.e., Trump is solely at fault; Fauci had no influence — are conditions under which Fauci </span><i><span>absolutely </span></i><span>should have bolted. The more aberrant Trump’s behavior, the more he diverged from the medically prudent course of action, the greater Fauci’s responsibility to leave and blow the whistle. If Fauci knew better but didn’t say, what use was he inside the room? If he </span><i><span>didn’t</span></i><span> know better, then he shares the blame.&nbsp;</span></p>
<p><span>In recent days, Fauci and Covid task force coordinator Dr. Deborah Birx — another veteran AIDS researcher who’s received slightly </span><a href="https://www.politico.com/news/2020/11/18/biden-coronavirus-team-deborah-birx-437923" target="_blank" rel="noopener noreferrer"><span>less deferential</span></a><span> treatment from the media than her male counterpart — have undertaken a goodwill tour. Birx </span><a href="https://twitter.com/FaceTheNation/status/1353332977560735744?s=20" target="_blank" rel="noopener noreferrer"><span>told</span></a><span> CBS that denialists in the White House “derailed” the pandemic response, putting out information she knew to be false. Fauci joked with Rachel Maddow that Trump had </span><a href="https://www.msnbc.com/rachel-maddow/watch/fauci-to-maddow-i-ve-been-wanting-to-come-on-your-show-for-months-and-months-99905093921" target="_blank" rel="noopener noreferrer"><span>forbidden</span></a><span>&nbsp;him from coming on her show and </span><a href="https://www.usatoday.com/story/news/politics/2021/01/21/anthony-fauci-speaking-covid-liberating-under-biden-vs-trump/4244169001/" target="_blank" rel="noopener noreferrer"><span>told</span></a><span> the White House press corps, “The idea that you can get up here and… let the science speak, it is somewhat of a liberating feeling.” Meanwhile, liberal pundits like Ezra Klein have </span><a href="https://www.nytimes.com/2021/01/18/opinion/biden-covid-19-plan.html" target="_blank" rel="noopener noreferrer"><span>praised</span></a><span> Biden’s “maddeningly obvious” Covid plans, describing their simplicity as a “damning indictment” of Trump’s negligence. But if Biden’s life-saving interventions are so straightforward and crucial, why weren’t Fauci and Birx loudly demanding them months ago?&nbsp;</span></p>
<p><span>“To keep their jobs” should not be a satisfying answer — not for the living or for the dead.&nbsp;</span></p>

<p><strong>F</strong><span>rank assessments of Fauci’s performance are hard to come by. Those in a position to judge him from an informed public …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thedriftmag.com/the-case-against-fauci/">https://www.thedriftmag.com/the-case-against-fauci/</a></em></p>]]>
            </description>
            <link>https://www.thedriftmag.com/the-case-against-fauci/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986443</guid>
            <pubDate>Mon, 01 Feb 2021 07:30:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Element suspended on Google Play Store: now resolved]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25986438">thread link</a>) | @sjamaan
<br/>
January 31, 2021 | https://element.io/blog/element-on-google-play-store/ | <a href="https://web.archive.org/web/*/https://element.io/blog/element-on-google-play-store/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      
      <div><p>Hi all,</p><p>At 2021-01-29 at 21:35 UTC Google suspended Element from the Play Store without warning or notification. &nbsp;We submitted an appeal asking for clarification at 23:18, and at 05:31 received a generic update from the Google Play Policy team citing that the app has been removed due to content which contravenes their terms of use, and asking us to “make the necessary changes to [our] app” and “upload a new app using a new package name and a new app name”.</p><p>As of 11:44 UTC we’ve submitted a detailed appeal to reiterate that Element is a generic chat app for connecting to the global Matrix communication network, just as Chrome is a generic web browser for connecting to the Web - and just as Google does not control the content on the Web, Element does not control the content on Matrix.</p><p>We have also explained that the Matrix servers that we <em>do</em> run as Element (including the default Matrix.org homeserver, which we run on behalf of <a href="https://matrix.org/foundation">The Matrix.org Foundation</a>) have <a href="https://matrix.org/legal/terms-and-conditions#6-play-nice-clauses">strict Terms of Use</a> which we actively enforce. We abhor abuse, and Element is not an app that caters to abusive content.</p><p>In order to enforce our terms of use on the Matrix servers we run as Element, we have a formal Trust and Safety team hired full-time who are dedicated to investigating and tracking abuse reports sent to <a href="https://element.io/cdn-cgi/l/email-protection#ccadaeb9bfa98ca1adb8bea5b4e2a3beab"><span data-cfemail="630201161006230e0217110a1b4d0c1104">[email&nbsp;protected]</span></a> or reported from the app. &nbsp;The team takes appropriate action on a ticket by ticket basis - deactivating abusive accounts and blocking chatrooms from our servers which contravene our terms of use, and building tooling to help enforce the terms of use on the servers we run.</p><p>Managing abuse is an ongoing activity, and <a href="https://sifted.eu/articles/element-whatsapp-exodus/">Matrix is expanding massively at the moment</a>. We are expanding Element’s Trust and Safety team to match that growth, focusing on improving our anti-abuse mechanisms, and we are also constantly expanding the <a href="https://matrix.org/docs/guides/moderation/">moderation tools</a> we provide to the community.</p><p>Meanwhile, we’re also continuing to work on decentralised reputation as a <a href="https://matrix.org/blog/2020/10/19/combating-abuse-in-matrix-without-backdoors/">scalable solution to empower other users to combat abuse</a> for the wider Matrix network - effectively bringing control back to users and empowering communities to remain safe online.</p><p>Element and Matrix are used by the French, German, UK and US governments, <a href="https://matrix.org/blog/2021/01/29/this-week-in-matrix-2021-01-29#dept-of-status-of-matrix-%EF%B8%8F">countless universities</a>, thousands of businesses and millions of people across the world - we can only apologise for the disruption caused by the app disappearing like this.</p><p>We’re currently waiting for an update to Google and will keep this blog post updated as the situation develops. &nbsp;We look forward to resolving the problem and getting the app back in the store shortly.</p><p>-- The Element Team</p><p>Update: reminder that in the interim you can download a (slightly outdated) version of Element Android from F-Droid at <a href="https://f-droid.org/en/packages/im.vector.app/">https://f-droid.org/en/packages/im.vector.app</a>. &nbsp;We're also looking into running our own F-Droid repository going forwards so the most recent build is always available there.</p><p>UPDATE: At 2021-01-30 23:17 UTC we received a call from a VP at Google who apologised for the bad communication from Google and explained the situation, which related to some extremely abusive content which was accessible on the default matrix.org homeserver. &nbsp;Our Trust and Safety team had already identified and acted on this content to enforce the server's terms of use, and so we've explained how Element and Matrix works, established a channel for communication over any future moderation concerns, and expect the app to be restored shortly.</p><p>UPDATE: The app is restored as of 2021-01-31 00:30 UTC. &nbsp;Huge thanks to everyone for your patience and support while we sorted this out, and to the wider Element team who spent their Saturday on this. &nbsp;Thanks also to Google for being transparent and apologetic and the rapid resolution once we'd established contact.</p></div>
      
    </div>
  </div></div>]]>
            </description>
            <link>https://element.io/blog/element-on-google-play-store/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986438</guid>
            <pubDate>Mon, 01 Feb 2021 07:29:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[gemini:// space]]>
            </title>
            <description>
<![CDATA[
Score 261 | Comments 155 (<a href="https://news.ycombinator.com/item?id=25986378">thread link</a>) | @pabs3
<br/>
January 31, 2021 | https://spwhitton.name//blog/entry/geminispace/ | <a href="https://web.archive.org/web/*/https://spwhitton.name//blog/entry/geminispace/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">







<div id="pagebody">

<div id="content">
<p>Recently I have become curious about <a href="https://gemini.circumlunar.space/">the Gemini
Project</a> and the content that people have
made available to be retrieved over the gemini:// protocol.  I’m not convinced
by the arguments for not just using http, and mostly it’s just that I
typically find more things that I am interested in casually reading through on
people’s gemlogs than I would on, say, reddit, and similar aggregators.  But
presumably advocates of gemini:// and the text/gemini format would argue that
it’s various respects in which it differs from the web that makes geminispace
conducive to the production of the sort of content you find there.  So I’m
remaining open minded about the possibility that having a completely separate
protocol is important, and not just an annoyance because rss2email doesn’t
work and I had to spend time writing
<a href="https://manpages.debian.org/gmi2email">gmi2email</a>.</p>

<p>I now have a games console at home for the first time in some years, which I
bought in response to the ongoing pandemic, and one thing that I have noticed
is that using it feels like being offline in a way that playing games on a
regular computer never would.  It has a WiFi connection but it doesn’t have a
web browser, and I am glad that using it provides an opportunity to be
disconnected from the usual streams of information.  And perhaps something
similar ought to be said in favour of how the Gemini project does not just use
http.  There is, perhaps, a positive psychological effect induced by making
the boundary between text/gemini and the web as hard as it is made by using
gemini:// rather than http.</p>

<p>Something about which I find myself much more sceptical is how the
specification for gemini:// and text/gemini is not extensible.  Advocates of
Gemini have this idea that they can’t include, say, a version number in the
protocol, because the extensibility of the web is what has led to the problems
they think it has, so they want to make it impossible.  Now on the one hand
perhaps the people behind Gemini are in the best position that anyone is in to
come up with a spec which they will finalise and render effectively
unchangeable, because a lot of them have been using Gopher for decades, and so
they have enough experience to be able to say exactly what Gopher is missing,
and be confident that they’ve not missed anything.  But on the other hand,
Gemini is one technological piece in attempts to make a version of the
Internet which is healthier for humans – the so-called “small Internet”
movement – and maybe there will be new ideas about how the small Internet
should be which would benefit from a new version of the Gemini specification.
So it seems risky to lock-in to one version.</p>

<p><a href="https://news.ycombinator.com/item?id=25986378">Comments on Hacker News</a>.</p>

</div>









</div>



</div></div>]]>
            </description>
            <link>https://spwhitton.name//blog/entry/geminispace/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986378</guid>
            <pubDate>Mon, 01 Feb 2021 07:14:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloud Computing Explained: Public vs. Private vs. Virtual Private]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25986359">thread link</a>) | @recepinancc
<br/>
January 31, 2021 | https://recepinanc.com/cloud-computing-explained-public-vs.-private-vs.-virtual-private/ | <a href="https://web.archive.org/web/*/https://recepinanc.com/cloud-computing-explained-public-vs.-private-vs.-virtual-private/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p>Let’s talk about cloud in simpler terms!</p>

<p>Coming across different terms about a technology without actually getting your head around what they meant is a common issue. Recently, I decided to study Cloud Computing and I wanted start by learning the terminology and then diving deeper into the specific topics.</p>

<p>With the first post of the “Cloud Computing Explained” series, we will look at a small but commonly used subset of cloud terms:</p>
<ul>
  <li>Public Cloud</li>
  <li>Private Cloud</li>
  <li>Virtual Private Cloud</li>
</ul>

<p>Let’s first look at the definitions, and then create an analogy to make them easy to remember!</p>



<p>A Public Cloud is a set of cloud services provided to you and other customers by a vendor.</p>

<p>The Public Cloud enables us to provision resources on-demand according to our needs. There are many different vendors for public cloud services that offer you variant solutions based on your needs to build your software.</p>

<p>As these solutions’ levels <strong>go down</strong>, it gives you <strong>more control over the resource</strong>. However, this also means more <strong>overhead</strong> since you’ll have more things to do for that resource to be working reliably.</p>

<p>And one of the tremendous benefits of the public cloud is that you only pay for what you use. That gives you the ability to <strong>optimize your expenses</strong>.</p>

<h2 id="different-levels-of-services">Different Levels of Services</h2>

<p>Take a look at the below diagram to visualize solutions at different levels. At the lowest level (bare-metal), you are the most flexible since you got all the control over your system. However, you also have to deal with almost everything by yourself, including scaling, monitoring and, deployment. On the highest level (Serverless, FaaS), you can concentrate solely on writing your application. You give up some of the flexibility for more convenience.</p>

<figure>
  <img src="https://recepinanc.com/assets/images/content/different_levels_of_abstraction.png" alt="Different levels of cloud service abstractions"><figcaption>
      By Nate Schutta (Developer Advocate, Pivotal) at SpringOne Platform 2018

    </figcaption></figure>



<p>The Private Cloud is having a public cloud environment on the infrastructure that is <strong>dedicated to you</strong>.</p>

<p>That brings the disadvantage of being limited by <strong>your infrastructure’s limits</strong> and the advantage of having <strong>no other neighbors to share your resources</strong>.</p>



<p>A Virtual Private Cloud is where a public cloud’s resources are divided into <strong>virtually isolated</strong> divisions - “private clouds”.</p>

<p>Isolating each division from each other creates the illusion of customers have their private cloud - but it’s only there virtually. Virtual Private Clouds are similar to virtual machines where there are no actual physical machines but only the isolation of resources.</p>

<p>Virtual Private Clouds are a type of Hybrid Clouds. Virtual Private Clouds are a type of <a href="https://www.redhat.com/en/topics/cloud-computing/what-is-hybrid-cloud">Hybrid Clouds</a>.</p>

<figure>
  <img src="https://recepinanc.com/assets/images/content/different_clouds.png" alt="Different Cloud Types Visualization"><figcaption>
      Different Cloud Types Visualization

    </figcaption></figure>



<p>Imagine the <strong>public cloud</strong> as an internet cafe where they have these computers and charge you for the time you use them. In that case, the internet cafe is the <strong>vendor</strong> (in real life, this could be Amazon, Google, Microsoft, etc.). When you go and there and ask for a computer, they start your session on one of the available computers in the public area with others, using the same underlying infrastructure.</p>

<p>The private gaming rooms, in which they provide you an isolated internet connection from the ones in the public area and the other private gaming rooms. These rooms can be an analogy for <strong>virtual private clouds</strong>.</p>

<p>Let’s say this internet cafe vendor provides you the service to build one of these private gaming rooms at your house. They use your house’s infrastructure but with their computers and all the software in it. That would be the equivalent of a <strong>private cloud</strong>.</p>



<ul>
  <li><a href="https://azure.microsoft.com/en-us/overview/what-are-private-public-hybrid-clouds/">https://azure.microsoft.com/en-us/overview/what-are-private-public-hybrid-clouds/</a></li>
  <li><a href="https://www.cloudflare.com/learning/cloud/what-is-a-public-cloud/">https://www.cloudflare.com/learning/cloud/what-is-a-public-cloud/</a></li>
  <li><a href="https://www.cloudflare.com/learning/cloud/what-is-a-virtual-private-cloud/">https://www.cloudflare.com/learning/cloud/what-is-a-virtual-private-cloud/</a></li>
  <li><a href="https://www.redhat.com/en/topics/cloud-computing/what-is-public-cloud">https://www.redhat.com/en/topics/cloud-computing/what-is-public-cloud</a></li>
  <li><a href="https://www.redhat.com/en/topics/cloud-computing/public-cloud-vs-private-cloud-and-hybrid-cloud">https://www.redhat.com/en/topics/cloud-computing/public-cloud-vs-private-cloud-and-hybrid-cloud</a></li>
  <li><a href="https://www.youtube.com/watch?v=8tOj4A7jgWg">https://www.youtube.com/watch?v=8tOj4A7jgWg</a></li>
</ul>

        
      </section></div>]]>
            </description>
            <link>https://recepinanc.com/cloud-computing-explained-public-vs.-private-vs.-virtual-private/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986359</guid>
            <pubDate>Mon, 01 Feb 2021 07:11:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Counterfeiting Stock – Explaining illegal naked shorting and stock manipulation]]>
            </title>
            <description>
<![CDATA[
Score 333 | Comments 379 (<a href="https://news.ycombinator.com/item?id=25986320">thread link</a>) | @lelf
<br/>
January 31, 2021 | http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html | <a href="https://web.archive.org/web/*/http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<center><b>Counterfeiting Stock 2.0</b></center>

<p>
Illegal naked shorting and stock manipulation are two of Wall Street's deep, dark secrets. These practices have been around for decades and have resulted in trillions of dollars being fleeced from the American public by Wall Street. In the process, many emerging companies have been put out of business. This report will explain the magnitude of this problem, how it happens, why it has been covered up and how short sellers attack a company. It will also show how all of the participants; the short hedge funds, the prime brokers and the Depository Trust Clearing Corp. (DTCC)—make unconscionable profits while the fleecing of the small American investor continues unabated.
</p>
<p>
<span>Why is This Important?</span> This problem affects the investing public. Whether invested directly in the stock market or in mutual funds, IRAs, retirement or pension plans that hold stock — it touches the majority of Americans.
</p>
<p>
The participants in this fraud, which, when fully exposed, will make Enron look like child's play, have been very successful in maintaining a veil of secrecy and impenetrability. Congress and the SEC have unknowingly (?) helped keep the closet door closed. The public rarely knows when its pocket is being picked as unexplained drops in stock price get chalked up to “market forces” when they are often market manipulations.
</p>
<p>
The stocks most frequently targeted are those of emerging companies who went to the stock market to raise start–up capital. Small business brings the vast majority of innovative new ideas and products to market and creates the majority of new jobs in the United States. It is estimated that over 1000 of these emerging companies have been put into bankruptcy or had their stock driven to pennies by predatory short sellers. 
</p>
<p>
It is important to understand that selling a stock short is not an investment in American enterprise. A short seller makes money when the stock price goes down and that money comes solely from investors who have purchased the company's stock. A successful short manipulation takes money from investment in American enterprise and diverts it to feed Wall Street's insatiable greed—the company that was attacked is worse off and the investing public has lost money. Frequently this profit is diverted to off–shore tax havens and no taxes are paid. This national disgrace is a parasite on the greatest capital market in the world.
</p>
<p>
<span>A Glossary of Illogical Terms</span> — The securities industry has its own jargon, laws and practices that may require explaining. Most of these concepts are the creation of the industry, and, while they are promoted as practices that ensure an orderly market, they are also exploited as manipulative tools. This glossary is limited to naked short abuse, or counterfeiting stock as it is more correctly referred to. 
</p>

<ol>
<li><b>Broker Dealer or Prime Broker</b> — The big stockbrokers who clear their own transactions, which is to say they move transacted shares between their customers directly, or with the DTC. Small brokers will clear through a clearing house — also known as a broker's broker.
</li>
<li><b>Hedge Funds</b> — Hedge funds are really unregulated investment pools for rich investors. They have grown exponentially in the past decade and now number over 10,000 and manage over one trillion dollars. They don't register with the SEC, are virtually unregulated and frequently foreign domiciled, yet they are allowed to be market makers with access to all of the naked shorting loopholes. Frequently they operate secretively and collusively. The prime brokers cater to the hedge funds and allegedly receive eight to ten billion dollars annually in fees and charges relating to stock lend to the short hedge funds.
</li>
<li><b>Market Maker</b> — A broker, broker dealer or hedge fund who makes a market in a stock. In order to be a market maker, they must always have shares available to buy and sell. Market makers get certain sweeping exemptions from SEC rules involving naked shorting.
</li>
<li><b>Short Seller</b> — An individual, hedge fund, broker or institution who sells stock short. The group of short sellers is referred to as “the shorts.”
</li>
<li><b>The Securities and Exchange Commission</b> — The SEC is the federal enforcement agency that oversees the securities markets. The top–level management is a five–person Board of Governors who are Presidential appointees. Three of the governors are usually from the securities industry, including the chairman. The SEC adopted Regulation SHO in January 2005 in an attempt to curb naked short abuse.
</li>
<li><b>Depository Trust Clearing Corp</b> — Usually known as the DTCC, this privately held company is owned by the prime brokers and it clears, transacts and holds most stock in this country. It has four subsidiaries, which include the DTC and the NCSS. The operation of this company is described in detail later.
</li>
<li><b>Short Sale</b> — Selling a stock short is a way to make a profit while the stock price declines. For example: If investor S wishes to sell short, he borrows a share from the account of investor L. Investor S immediately sells that share on the open market, so investor S now has the cash from the sale in his account, and investor L has an IOU for the share from investor S. When the stock price drops, investor S takes some of the money from his account and buys a share, called “covering”, which he returns to investor L's account. Investor S books a profit and investor L has his share back.
<p>This relatively simple process is perfectly legal—so far. The investor lending the share most likely doesn't even know the share left his account, since it is all electronic and occurs at the prime broker or DTC level. If shares are in a margin account, they may be loaned to a short without the consent or knowledge of the account owner. If the shares are in a cash account, IRA account or are restricted shares they are not supposed to be borrowed unless there is express consent by the account owner.
</p></li>
<li><b>Disclosed Short</b> — When the share has been borrowed or a suitable share has been located that can be borrowed, it is a disclosed short. Shorts are either naked or disclosed, but, in reality, some disclosed shorts are really naked shorts as a result of fraudulent stock borrowing. 
</li>
<li><b>Naked Short</b> — This is an invention of the securities industry that is a license to create counterfeit shares. In the context of this document, a share created that has the effect of increasing the number of shares that are in the market place beyond the number issued by the company, is considered counterfeit. This is not a legal conclusion, since some shares we consider counterfeit are legal based upon today's rules. The alleged justification for naked shorting is to insure an orderly and smooth market, but all too often it is used to create a virtually unlimited supply of counterfeit shares, which leads to widespread stock manipulation—the lynchpin of this massive fraud. 
<p>
Returning to our example, everything is the same except the part about borrowing the share from someone else's account: There is no borrowed share — instead a new one is created by either the broker dealer or the DTC. Without a borrowed share behind the short sale, a naked short is really a counterfeit share.
</p></li>
<li><b>Fails–to–Deliver</b> — The process of creating shares via naked shorting creates an obvious imbalance in the market as the sell side is artificially increased with naked short shares or more accurately, counterfeit shares. Time limits are imposed that dictate how long the sold share can be naked. For a stock market investor or trader, that time limit is three days. According to SEC rules, if the broker dealer has not located a share to borrow, they are supposed to take cash in the short account and purchase a share in the open market. This is called a “buy–in,” and it is supposed to maintain the total number of shares in the market place equal to the number of shares the company has issued.
<p>
Market makers have special exemptions from the rules: they are allowed to carry a naked short for up to twenty–one trading days before they have to borrow a share. When the share is not borrowed in the allotted time and a buy–in does not occur, and they rarely do, the naked short becomes a fail–to–deliver (of the borrowed share).
</p></li>
<li><b>Options</b> — The stock market also has separate, but related markets that sell options to purchase shares (a “call”) and options to sell shares (a “put”). Options are an integral part of short manipulations, the result of SEC promulgated loopholes in Reg SHO. A call works as follows: Assume investor L has a share in his account that is worth $25. He may sell an option to purchase that share to a third party. That option will be at a specific price, say $30, and expires at a specific future date. Investor L will get some cash from selling this option. If at the expiration date, the market value of the stock is below $30 (the “strike price”), the option expires as worthless and investor L keeps the option payment. This is called “out of the money.” If the market value of the stock is above the strike price, then the buyer of the option “calls” the stock. Assume the stock has risen to $40. The option buyer tenders $30 to investor L and demands delivery of the share, which he may keep or immediately sell for a $10 profit.
</li>
<li><b>Naked call</b> — The same as above except that investor L, who sells the call, has no shares in his account. In other words, he is selling an option on something he does not own. The SEC allows this. SEC rules also allow the seller of a naked short to treat the purchase of a naked call as a borrowed share, thereby keeping their naked short off the SEC's fails–to–deliver list. A share of stock that has a naked call as its borrowed shares is marked as a disclosed short when it is sold, even though nobody in the transaction actually owns a share.
</li>
</ol>




<p>
<span>How The System Transacts Stocks</span> — This explanation has been greatly simplified in the interest of brevity. 
</p>

<img src="http://counterfeitingstock.com/CS2.0/diagram.png">

<ol>
<li><b>Customers</b> — These can be individuals, institutions, hedge funds and prime broker's house accounts.</li></ol></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html">http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html</a></em></p>]]>
            </description>
            <link>http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986320</guid>
            <pubDate>Mon, 01 Feb 2021 06:59:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[F# is gaining independence from .NET]]>
            </title>
            <description>
<![CDATA[
Score 205 | Comments 170 (<a href="https://news.ycombinator.com/item?id=25986316">thread link</a>) | @sidcool
<br/>
January 31, 2021 | https://onurgumus.github.io/2021/01/31/What-the-F.html | <a href="https://web.archive.org/web/*/https://onurgumus.github.io/2021/01/31/What-the-F.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper">
      <div>
         <section id="main-content">
            

<p>In a previous <a href="https://onurgumus.github.io/2020/12/26/Functional-Programming.html">post</a> I have explained my motivations for functional programming.
It’s no secret I love F# because F# makes me sleep better. In this post, I would like to discuss some different aspects of F#.</p>

<h2 id="f-is-gaining-independence-from-net">F# is gaining independence from .NET</h2>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/platform.png" alt="F# platforms"></p>

<!--more-->

<p>F# is mostly known to the developer community as the small ignored brother of C# running on the .NET platform. However, what is less known about F# is that it
has come to a level to be .NET independent. Thanks to <a href="https://fable.io/">Fable</a>, today F# can be considered as a complete replacement of TypeScript. Yes,
people do write full-blown SPA, React, Svelte applications by using F# instead of TypeScript. If you think Fable is just a transpiler, think again:  https://github.com/kunjee17/awesome-fable . I would say Fable is on the way being an ecosystem by itself.</p>

<p>There is also a new prototype target for Fable that allows F# code to transpile to Python developed by Dag Brattli.</p>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/python2.gif" alt="Python"></p>

<p>F# also works as on WebAssembly with <a href="https://fsbolero.io/">Bolero</a> which is still based on .NET. And not to forget another F# web platform called <a href="https://websharper.com/">WebSharper</a> from the same people who developed Bolero.</p>

<p>Just like JavaScript people were using NodeJs to bring the front-end devs to the backend zone, F# also can be used to bring the backend-devs to the front-end realm. I am a living example myself. By using F# in the font-end you can practically share the code between your .NET/Node backend and the browser, giving you an isomorphic development experience.</p>

<p>This somewhat puts F# in an interesting position as historically most dotnet has been languages are managed by Microsoft. But Fable simply liberates
F# from Microsoft and .NET.</p>

<h2 id="the-f-fanboys">The F# fanboys</h2>

<p>You might have heard “one of those guys” like me who is talking about how great functional programming and/or F# is. And from that point, it looks like below</p>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/music.png" alt="music"></p>

<p>I know it’s annoying, however, let’s look at it from the side and this is how an F# developer feels when he or she is suggesting you using F#:
<img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/wheel.png" alt="wheels"></p>

<h2 id="microsofts-and-communitys-stance">Microsoft’s and community’s stance</h2>

<p>From Microsoft’s point of view, F# is actively supported and maintained. There are Microsoft developers actively fixing things and adding new features however as a general Microsoft’s point of view .NET == C# and that is that. From .NET developer community’s
point of view, things are even worse. Since all Microsoft docs and tools geared towards C#, adding up unfamiliarity with the functional paradigm, most people follow C# way and completely ignore its little brother F#. I still think this is a missed 
opportunity for the .NET community. For example, let’s look at the excellent server side F# web framework <a href="https://giraffe.wiki/">Giraffe</a>. 
While C# and asp.net developers are busy memorizing the Microsoft way of handling requests, learning what attributes to decorate their
classes and members, the F# developers who use giraffe, simply rely on functional composition:</p>

<div><div><pre><code><span>let</span> <span>app</span> <span>=</span>
    <span>route</span> <span>"/"</span>
    <span>&gt;=&gt;</span> <span>setHttpHeader</span> <span>"X-Foo"</span> <span>"Bar"</span>
    <span>&gt;=&gt;</span> <span>setStatusCode</span> <span>200</span>
    <span>&gt;=&gt;</span> <span>setBodyFromString</span> <span>"Hello World"</span>
</code></pre></div></div>

<p>As HTTP processing is usually treated as a pipeline by itself on the server-side, it’s an excellent target for functional programming. Just like lego, plug-in your pipes, and you are good to go.</p>

<p>Furthermore, most developers worry about if they could find an F# job whereas companies who consider making the switch worry if they could find an F# developer.
As of today on linked in there are approximately 700 F# jobs and even most of these are not F# specific rather than they are like “C# or F# developers wanted”.</p>

<p>And most non-.NET people are not willing to touch anything related to Microsoft even with a 10 foot pole. (Of course, the major exceptions to this are TypeScript and Visual Studio Code which both are widely popular). The  Functional programmers’ camp also dismisses F# at sight blaming it’s not like Haskell as in for example F# does not support type classes.</p>

<h2 id="couple-of-unique-features-of-f">Couple of unique features of F#</h2>

<p>I am not going to talk about the features of F# but just wanted to highlight a couple of them.</p>

<p>The first one is the file order. Please look at the below photo:</p>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/files.png" alt="file-order"></p>

<p>In F# the order of the files matter. It is somewhat a disliked feature by the newcomers, but it makes the dependencies immediately visible.
So the code in the top file has no dependency on any others below and the 2nd file from the top only depends on the first. When you open a project which you are not 
familiar, file ordering helps to find your way.</p>

<p>The second one is Type Providers:</p>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/sqlprovider.gif" alt="type-providers"></p>

<p>Type providers are somewhat code generators but they do that non-intrusively. Very roughly similar to LISP style macros they expand at compile time. Type providers make it very easy to discover HTML or JSON documents read database rows, file system, and discover DDL and rows within the coding screen without leaving your editor. And everything becomes so type-safe.</p>

<h2 id="develop-fantastic-ui-apps-with-f-and-elmish">Develop fantastic UI apps with F# and Elmish</h2>

<p>Well they say seeing is believing, so let’s see how well F# handles UI development. While React devs on Facebook trying to solve the state problem over and over again by using hooks and perhaps new experimental
recoil and contexts IMHO, all are horrible options as they encourage rendering code inter-mix with business code reminding me asp.net web forms times where you could write your SQL statements right into the page itself.</p>

<p>F# developers have ported elm architecture to something called elmish and it flourished well among F# community.</p>

<p>Here’s a list of things you can do with Elmish as you can write your business code once and port it to any UI platform below:</p>

<ul>
  <li>React: <a href="https://github.com/elmish/react">Elmish React</a></li>
  <li>Windows Desktop: <a href="https://github.com/elmish/Elmish.WPF">Elmish WPF</a></li>
  <li>Gaming: <a href="https://github.com/ChrisPritchard/Xelmish">Xelmish</a></li>
  <li>Cross platform UI: <a href="https://github.com/AvaloniaCommunity/Avalonia.FuncUI">Avalonia.FuncUI</a></li>
  <li>Mobile development: <a href="https://github.com/fsprojects/Fabulous">Fabulous</a></li>
  <li>Terminal: <a href="https://github.com/DieselMeister/Terminal.Gui.Elmish">Terminal.Gui.Elmish</a></li>
  <li>Web Assembly: <a href="https://fsbolero.io/">Bolero</a></li>
</ul>

<p>They all share the same single architecture: Elmish. So you can write your code for one and port it to another.</p>

<h2 id="getting-started-and-some-resources">Getting started and some resources</h2>

<p>If you want to get started to F#, the first place you should check out is <a href="https://fsharp.org/">F# Software Foundation</a></p>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/fsf2.png" alt="fsharp-foundation"></p>

<p>As you can see FSharp Software Foundation offers mentorship programs periodically, which means you can have a free weekly 1 on 1 session with an experienced F# developer! As of today the program is open for people who want to have an F# mentor or want to be
an F# mentor. You can apply from <a href="https://docs.google.com/forms/d/e/1FAIpQLSdKgZaAcjf7ZxVqBZzyZcBi609BOc0etBnV5XhR6BMihdyYRw/viewform">here</a>.</p>

<p>If you are sold with F# there is one important point to highlight. Do not treat F#, just another language with different syntax especially if you are familiar
with Python, Ruby, JavaScript, C#, etc. You have to embrace functional programming as a paradigm. F# is a functional-first programming language. In other words,
although F# has OOP syntax as well, it mostly makes sense to use F# when you want to get benefit from functional programming concepts. If you try to program
F# the same way you program other imperative languages you won’t get much benefit.</p>

<p>If you are a C# develeoper and you want to start functional programming with F# this is the go-to book:
<em>Disclaimer: I do not know the author nor I am affiliated with the publisher by any way</em></p>

<p><a href="https://www.manning.com/books/functional-programming-in-c-sharp">Functional programming in C#</a></p>

<p>Although the book is mostly about C#, it will show you how painful to do functional programming with C# and only perhaps then you can develop
some love for F#. Having that said it will also help you to understand some more new coming but confusing features of C# 9 like Records and Pattern matching.
If you think  C# records are for immutability, no they are not. They are for Value semantics and <a href="https://www.sitepoint.com/what-is-referential-transparency/#:~:text=In%20functional%20programming%2C%20referential%20transparency,the%20result%20of%20the%20program.">referential transparency</a>.</p>

<p>To try F# right away you may use the following links:</p>

<p>https://try.fsharp.org/</p>

<p>https://fable.io/repl/</p>

<p>https://tryfsharp.fsbolero.io/</p>

<h2 id="syntax">Syntax</h2>

<p>When you are unfamiliar with F# syntax, it might look a bit cryptic. And I have seen some people complained that it is very verbose. On the contrary, I would make a bold claim that F# beats most other languages when it comes to conciseness. You don’t believe me? see it your self (make sure you check all implementations)</p>

<p><a href="https://rosettacode.org/wiki/Category:F_Sharp">F# problems on Rosetta Code</a></p>

<h2 id="a-couple-of-toy-projects-of-mine">A couple of toy projects of mine</h2>

<p>I have developed commercial applications with F#, but as public stuff here are a couple of projects I have built. One is a full blazor/web assembly project:</p>

<p>https://github.com/OnurGumus/FBlazorShop</p>

<p>And the actual app for the 3D bin packing problem, in which items of different volumes must be packed into a finite number of bins or containers each of a fixed given volume in a way that minimizes the number of bins used.</p>

<p>https://github.com/OnurGumus/BinDrake</p>

<p>http://bindrake.com/</p>

<p>Trying and learning F# really requires you to dismiss your prejudices and be patient. But in the end, once you master the functional paradigm,
it makes you sleep better as a developer.</p>


             
            
            
            
                  
         </section>
         
      </div>
   </div></div>]]>
            </description>
            <link>https://onurgumus.github.io/2021/01/31/What-the-F.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986316</guid>
            <pubDate>Mon, 01 Feb 2021 06:59:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Safari and Firefox Decline WebHID and Other Privacy Sensitive APIs (2020)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25986282">thread link</a>) | @jdc
<br/>
January 31, 2021 | https://usefulangle.com/web-updates/post/80/firefox-decines-to-implement-web-usb-api | <a href="https://web.archive.org/web/*/https://usefulangle.com/web-updates/post/80/firefox-decines-to-implement-web-usb-api">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="middle-container">
			<div id="posts-main-container">
				<div id="posts-container">
					<div data-news-id="80">
						
						
						<p><img src="https://s3.amazonaws.com/usefulangle/news/80-5f02e5e13bd9f.jpg"></p><div><p>After Apple declined to implement 16 Web APIs in Safari browser citing privacy and security reasons, Firefox has specified that they will be doing the same.</p>
<p>Almost all of these APIs are hardware oriented, either enabling web applications to connect with external devices or device's sensors :</p>
<ul>
	<li>Web Bluetooth — enables web apps to interact with Bluetooth devices</li>
	<li>Web MIDI — enables web apps to interact with MIDI devices (digital instruments, synthesizers, audio devices etc)</li>
	<li>Web Magnetometer — can provide information about the magnetic field as detected by the device</li>
	<li>Web NFC — enables web apps to interact with NFC devices</li>
	<li>Device Memory — can measure the amount of device's memory</li>
	<li>Network Information — can give information on current network information of the device</li>
	<li>Ambient Light Sensor — can detect ambient light level of the device's environment</li>
	<li>Proximity Sensor — can provide information about the proximity level as detected by the device</li>
	<li>WebHID — enables web apps to interact with HID (human interface devices) devices</li>
	<li>Serial API — enables web apps to interact with serial devices (e.g. Arduino)</li>
	<li>Web USB — enables web apps to interact with USB devices</li>
	<li>Geolocation Sensor — enables webapps to get geolocation data in the background</li>
	<li>User Idle Detection — can detect whether user is lying idle on the webpage</li>
</ul>
<p>Looks like Google Chrome will be the only browser supporting these APIs in the near future.</p>
<p>Read more on <a href="https://twitter.com/marcosc/status/1277737614687170560" target="_blank">this Twitter thread</a></p>

<h4>Related</h4>
<ul>
<li><a href="https://usefulangle.com/web-updates/post/78/safari-decines-to-implement-web-usb-api" target="_blank">Safari Declines to Implement Web USB and 15 Other APIs, Mentions User Privacy Risk</a></li>
</ul></div>
						
					</div>
				</div>
			</div>
			
		</div></div>]]>
            </description>
            <link>https://usefulangle.com/web-updates/post/80/firefox-decines-to-implement-web-usb-api</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986282</guid>
            <pubDate>Mon, 01 Feb 2021 06:51:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[195 gigapixel 360-degree panorama of Shanghai]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25986212">thread link</a>) | @lelf
<br/>
January 31, 2021 | http://pf.bigpixel.cn/zh-CN/pano/771906131130847232.html | <a href="https://web.archive.org/web/*/http://pf.bigpixel.cn/zh-CN/pano/771906131130847232.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="id_pano_ad"><div></div></div><p>大像素看世界第4期：上海</p><p>陆家嘴是上海的经济脉动中心，也是向世界展示中国经济腾飞的窗口。受上海市新闻办的邀请，大像素团队为其创作上海互联网城市名片。</p><div><p> 最热评论</p><a id="social-comment" target="_blank" href="http://pf.bigpixel.cn/zh-CN/downapp.html"><div><p> 暂无评论 </p></div></a><p><a target="_blank" href="http://pf.bigpixel.cn/zh-CN/downapp.html"> 更多 ...</a></p></div></div></div>]]>
            </description>
            <link>http://pf.bigpixel.cn/zh-CN/pano/771906131130847232.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986212</guid>
            <pubDate>Mon, 01 Feb 2021 06:37:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WallStreetBets vs. Wall Street and the Populist Rebellion]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25986122">thread link</a>) | @lettergram
<br/>
January 31, 2021 | https://austingwalters.com/wallstreetbets-vs-wall-street-and-the-populist-rebellion/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/wallstreetbets-vs-wall-street-and-the-populist-rebellion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3831">

<div>
<p>I have been engaging with WSB (<a href="https://www.reddit.com/r/wallstreetbets/" target="_blank" rel="noopener">/r/WallStreetBets</a>) since 2014.</p>
<p>Every regular person on WSB understands it’s a game. You can loose it all, make it big, sometimes both in the same day — it’s all a game. The most accurate assessment of WSB culture was clearly:</p>
<blockquote><p>Like 4chan found a Bloomberg Terminal.</p></blockquote>
<p>While the influx of new users may change the community, prior to January 15, 2021 the above was indeed an accurate description.</p>

<p>Honestly, this world feels like we are in a simulation. The company GameStop appears to be poised to bring down the entire financial system — stopping the game.</p>
<p>The infinity squeeze appears to be coming, what is an infinity squeeze you ask? It’s a really massive short squeeze:</p>
<blockquote><p>A short squeeze occurs when a stock or other asset jumps sharply higher, forcing traders who had bet that its price would fall, to buy it in order to forestall even greater losses. Their scramble to buy only adds to the upward pressure on the stock’s price.</p></blockquote>
<p>Short positions can technically lead to infinite losses. Simply put, if I open a short position for $10 and the share price drops 10%, I make $1. However, if the stock price increases say 10,000% I now owe $1,000.</p>
<p>In the case of GameStop, the situation appears dire. At one point the short positions were 140% of available shares of the market. This means that more shares were lent out than were available on float, i.e. shorts were resold / lent several times. At this point, several things are happening[<a href="https://www.investopedia.com/ask/answers/05/shortsaleclosed.asp" target="_blank" rel="noopener">1</a>]:</p>
<ul>
<li>Those holding short positions are paying ridiculously high interest rates</li>
<li>If the short positions were forced to close, it would cause a major loss to multiple hedge funds (tens of billions total &amp; bankrupcies)</li>
<li>Due to the level of shorting, exiting the short positions would be excessively expensive and cause a <a href="https://www.investopedia.com/terms/s/shortsqueeze.asp" target="_blank" rel="noopener">short squeeze</a></li>
<li>There is less GameStop stock available for purchase</li>
<li>The price of GameStop stock is rising</li>
</ul>
<p>As a result, it appears to me that:</p>
<ul>
<li>Short holders cannot exit their positions without going bankrupt</li>
<li>Short holders are being hit by high interest rates</li>
<li>Closing other positions in the stock market should help them cover the interest rates</li>
<li>Best option for short position holders is is to wait &amp; pray the stock price drops</li>
<li>What happens if not enough people are willing to sell?</li>
</ul>
<p>Personally, I believe all of this will suck all the liquidity from the stock market. Either those shorting suffer the loss and close their positions or wait as the stock continues to stay high… in either case hundreds of billions of dollars is leaving the market.</p>
<p>How did we get here?</p>
<h3>Infinity Squeeze – Short Positions</h3>
<p>There’s a lot to this story I’ll come back an fill in, but the gist is this — In mid-January 2021 GameStop was <em>extremely</em> shorted.</p>
<figure id="attachment_3832" aria-describedby="caption-attachment-3832"><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png" alt="" width="424" height="417" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-300x295.png 300w" sizes="(max-width: 424px) 100vw, 424px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-300x295.png 300w"></a><figcaption id="caption-attachment-3832">Courtesy of <a href="https://finance.yahoo.com/quote/GME/key-statistics?p=GME" target="_blank" rel="noopener">Yahoo Finance</a></figcaption></figure>
<p>The massive short position and didn’t go unnoticed, WSB had been <a href="https://web.archive.org/web/20201222153244/https://old.reddit.com/r/wallstreetbets/" target="_blank" rel="noopener">discussing it for months</a>. That being said, the massive spikes in purchases did not start until January 12:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png" alt="" width="916" height="411" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png 916w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-300x135.png 300w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-768x345.png 768w" sizes="(max-width: 916px) 100vw, 916px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png 916w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-300x135.png 300w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-768x345.png 768w"></a></p>
<p>What happened at that time? The <a href="https://web.archive.org/web/20210118091858/https://old.reddit.com/r/wallstreetbets/comments/kxeq23/gme_yolo_update_jan_14_2021/" target="_blank" rel="noopener">YOLO updates</a> definitely started at that time and stocks started to rise. Once the stocks started to rise, I believe institutions and WSB itself started piling into GameStop. The stock started to move and if they could get in they could make a boat load. It’s important to remember WSB is often visited by hedge fund mangers, CEOs, day traders big and small, etc. It’s not always the little guy(s). When they piled in, the price started to rise further.</p>
<h3>Infinity Squeeze – Let’s Make Money</h3>
<p>As they purchased, I personally believe some short sellers managed to exit their positions (about 7m shares, per Yahoo Finance data)</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png" alt="" width="424" height="417" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted-300x295.png 300w" sizes="(max-width: 424px) 100vw, 424px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted-300x295.png 300w"></a></p>
<p>What this indicates to me is that many of those holding short positions did not realize what was about to happen. They kept holding believing this was a classic pump-and-dump. Even WSB at the time didn’t not necessarily think about much <a href="https://web.archive.org/web/20210115023914/https://old.reddit.com/r/wallstreetbets/" target="_blank" rel="noopener">besides making money</a>. I know I even purchased call options during this week, particularly when the new data came out January 15, 2021. To me, it became clear the stock was about to rocket.</p>
<h3>Infinity Squeeze – Let’s Stick it to the Man</h3>
<p>In light of the massive number of short position(s) open in January 15, 2021, WSB realized they could (a) make money and (b) stick it to the hedge funds. Frankly, WSB have been waging a war on short selling for years. With GameStop they had a company with relatively few shares&nbsp; in float (47m), a low market cap, basically something that purchases would have an outsized impact.</p>
<p>I’m not 100% sure this was intentional, but as people started buying and holding waiting for the squeeze the stock started to rise.The rising stock both led to discussions on news outlets and the stock started going viral on social media platforms outside of WSB – further raising the going rate for a share of GameStop.</p>
<p>Those holding short positions did not want to sell as they’d lose money, so they were searching for capital to cover their leveraged positions. Citadel and Point72 partners appears to have <a href="https://www.wsj.com/articles/citadel-point72-to-invest-2-75-billion-into-melvin-capital-management-11611604340" target="_blank" rel="noopener">come to at least one short sellers aid</a>. This showed they were weak and further emboldened the WSB folks – “Let’s make some money on the hedge funds behalf”</p>
<p>Purchases from Jan 19 to Jan 23, 2021 and the stock price increased exponentially as it went viral:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png" alt="" width="507" height="423" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png 507w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17-300x250.png 300w" sizes="(max-width: 507px) 100vw, 507px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png 507w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17-300x250.png 300w"></a></p>
<h3>Infinity Squeeze – The Rebellion</h3>
<p>On January 27, 2021 across the board buying for GameStop was <a href="https://www.clickondetroit.com/money/2021/01/27/robinhood-td-ameritrade-other-brokerages-have-tech-problems-at-market-open/" target="_blank" rel="noopener">restricted (along with multiple other stocks) across various trading platforms</a>. This effectively forced purchase volume lower and as users of these platforms could only sell it drove down the share price. This likely startled many GameStop shareholds and many liquidated their positions, letting the short sellers exit some of their positions. Through January 29, 2021 the ability to purchase in an unrestricted manner has not been restored.</p>
<p>What happened?</p>
<p>Personally, I’m of the opinion that there was not enough shares to go around and likely these platforms colluded to drive down the stock price. What’s more interesting is how few people sold. As of January 29, 2021 the price of a GameStop share was back at $325. This has led to some very VERY strong backlash and I know I’ll be joining a lawsuit at some point (if not filing my own), as this collusion cost me tens to hundreds of thousands of dollars.</p>
<p>One essay that particularly struck me was made on WSB: <a href="https://web.archive.org/web/20210130034124/https://www.reddit.com/r/wallstreetbets/comments/l6omry/an_open_letter_to_melvin_capital_cnbc_boomers_and/" target="_blank" rel="noopener">An Open Letter to Melvin Capital, CNBC, Boomers, and WSB</a></p>
<p>I recommend reading the comments on this essay to really get an under standing of what’s happening. Look at the charts. This is personal now. The market manipulation is obvious and people want revenge. For the current events, for 2008, for the entire corrupt system. They want to send a message. This is a protest.</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg" alt="" width="474" height="567" srcset="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg 474w, https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH-251x300.jpg 251w" sizes="(max-width: 474px) 100vw, 474px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg 474w, https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH-251x300.jpg 251w"></a>Many retail investors will hold until the bitter end.</p>
<h3>Infinity Squeeze – End Game</h3>
<p>So what happens next?</p>
<ul>
<li>Starting on January 27-29 people were trying to transfer funds off Robinhood and the other platforms which disabled purchasing of GameStop shares.</li>
<li>Come the <span>first week of February</span> these assets will be again available and can be used to purchase GameStop shares.</li>
<li>Everyone saw much fewer shares being traded Friday</li>
<li>Everyone is talking with their families</li>
<li>People are going to purchase more GameStop shares &amp; hold</li>
<li>I expect many are going to pull their assets out of the stock market</li>
</ul>
<p>There are some unknowns, for instance have the short positions been closed? Have there been backroom deals to stave off the infinity squeeze?</p>
<p>If neither of those assumptions above hold, then what happens when the price rises further and there’s not enough shares for sale?</p>
<p>Hedge funds either bleed out as they pay the massive interest rates on holding those short positions or they will close their short positions causing an infinity squeeze (GameStop shares will be priced in the thousands). In either case hundreds of billions would likely leave the market.</p>
<h3>Conclusion – The Black Hole</h3>
<p>It’s a <a href="https://en.wikipedia.org/wiki/Nash_equilibrium" target="_blank" rel="noopener">Nash Equilibrium</a>, essentially the share holders have every reason to ask the maximum amount they can get for a share of GameStop (i.e. make money). If for some reason these GameStop share holders are unwilling to sell at a low rate, then these hedge funds stand to lose hundreds of billions and will go bankrupt (slowly via interest payments or quickly via short squeeze). To try and pay for their debts, they’ll have to sell off market wide and the entire market collapses.</p>
<p>There are three ways to alleviate the issue:</p>
<ul>
<li>GameStop issues a massive number of new shares</li>
<li>Market manipulation (such as Robinood and friends only enabling selling – of course that didn’t work last time)</li>
<li>Government settles the matter by confiscating shares</li>
</ul>
<p>Personally, I view government involvement as inevitable. They could settle everyone accounts fairly by giving everyone the current share price or what they bought it for, which every is higher. That being said, I suspect the more likely course of action is some flat rate $100/share or something to that effect. In either case, if they don’t get involved, I suspect the system really will collapse.</p>
<p>Unless of course, I am wrong. I am not a financial expert and nothing in this article should be taken as advice.</p>
<p>It’s completely possible I’m inaccurately reading the situation and those shorting GameStop have already exited their position(s) and GameStop is currently just in a classic bubble.</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/wallstreetbets-vs-wall-street-and-the-populist-rebellion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986122</guid>
            <pubDate>Mon, 01 Feb 2021 06:18:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[10 Years of Nlnog Ring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25986010">thread link</a>) | @janvdberg
<br/>
January 31, 2021 | https://ring.nlnog.net/post/10-years-of-nlnog-ring/ | <a href="https://web.archive.org/web/*/https://ring.nlnog.net/post/10-years-of-nlnog-ring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>This month marks the tenth anniversary of the <a href="https://ring.nlnog.net/">NLNOG RING</a> project.
In this article we look back on how the project came to be and how it evolved over this past decade.</p>
<h3 id="a-network-engineers-tale">A network engineer’s tale…</h3>
<p>The story of NLNOG RING starts on the <a href="https://nlnog.net/irc/">#nlnog</a> IRC channel, at the end of 2010.
A network engineer received complaints that his customers had difficulty reaching various destinations in several Dutch networks.
The case was a curious one, because the problem would come and go.
Some TCP sessions would establish immediately, whereas others would take multiple attempts before a connection was made.
It was clear something was broken, but locating the root cause proved to be difficult.</p>
<p>To find the source of the problem, the engineer proceeded to ask engineers from other networks for traceroute outputs, gathering data about how packets would travel from their networks to his.
The other engineers were of course happy to help, but because each question had to be answered individually it took a long time to gather the necessary data.
All in all it took several days to get a complete picture and identify a root cause, which turned out to be a faulty backbone link within the fabric of a large Dutch internet exchange point.</p>
<p><img src="https://ring.nlnog.net/images/post/10-years-of-nlnog-ring/original-problem.png" alt="Manual coordination of network troubleshooting" title="Manual coordination of network troubleshooting"></p>
<p>During the surrounding discussion on the IRC channel, seeing the amount of effort it took to collect the required information from different vantage points, the question came up: “What if we had a way for an engineer to access other networks securely, and collect troubleshooting data, without having to wait for the other side?”
Several people immediately offered to dedicate servers or virtual machines to the project, and a few others started building tooling for software installation and user management.
And so, in January 2011, NLNOG RING <a href="http://mailman.nlnog.net/pipermail/nlnog/2011-January/002433.html">was born</a>.</p>
<h3 id="architecture-and-tools">Architecture and tools</h3>
<p>The NLNOG RING is a “looking glass on steroids”. Participants join the project by making a (virtual) server available, hosted inside their own network. In return they gain access to their own shell account on all the machines provided by all other participating networks.</p>
<p>Right from the start we were conscious of the fact that we would have to manage a potentially large number of systems with a small group of volunteers.
To do this in a time-efficient manner we deployed <a href="https://puppet.com/">Puppet</a> on all provided systems.
This allowed us to install software tools and configure users in a centralized manner.
To further limit the scope of work we decided to support only a single operating system: <a href="https://ubuntu.com/blog/what-is-an-ubuntu-lts-release">Ubuntu LTS</a>.
For security we did not want to rely on passwords. All user access is controlled through SSH keys and there is no superuser access for any of the participants.</p>
<p>The basis of the NLNOG RING is a shell account, which offers a lot of freedom to participants to run their own troubleshooting scripts or programs.
To add extra value to this, each machine is provisioned with a collection of commonly used network troubleshooting tools.
We provide a DNS-interface and a <a href="https://ring.nlnog.net/toolbox/restful-api/">RESTful API</a> for retrieving participant and node information, and we have a regular BGP <a href="http://lg.ring.nlnog.net/">looking glass</a> providing insight into many networks.</p>
<p>NLNOG RING is a community project.
Over the years, many people have contributed tools and code to make the project more useful.
One of the first tools was <a href="https://github.com/NLNOG/nlnog-ring/blob/master/scripts/ring-trace">ring-trace</a>, a piece of software to run traceroutes from different vantage points, and display them in a graphical format.</p>
<p><img src="https://ring.nlnog.net/images/post/10-years-of-nlnog-ring/trace-ring.nlnog.net.jpeg" alt="Example of ring-trace output" title="Example of ring-trace output"></p>
<p>Another user-contributed tool is <a href="https://github.com/NLNOG/ring-sqa">ring-sqa</a>, a piece of software that attempts to automatically detect connectivity problems between NLNOG RING nodes and notifies their owners.
Events are also correlated to detect larger, sometimes Internet-wide outages, which are published on a <a href="http://sqa.ring.nlnog.net/">dashboard</a>.</p>
<p>Since 2013 we also cooperate with <a href="https://atlas.ripe.net/">RIPE Atlas</a>, to combine the strengths of the two platforms.
NLNOG RING nodes are selectable as <a href="https://atlas.ripe.net/targets/ringnodes/list/">measurement targets</a> in the RIPE Atlas interface.
Furthermore, the RIPE Atlas <a href="https://github.com/RIPE-NCC/ripe-atlas-tools">tools package</a> is installed on all NLNOG RING nodes, so participants can integrate RIPE Atlas measurements in scripts run on the RING.</p>
<h3 id="operating-model-and-sponsoring">Operating model and sponsoring</h3>
<p>The NLNOG RING was started by a couple of network engineers in their free time, and is still completely run by a small number of volunteers.
All participating networks provide their own machines.
In most cases (75%) this is a VM, making the barrier to participate very low.</p>
<p>At the start of the project all management tooling was running on infrastructure from <a href="https://intouch.eu/">InTouch</a>, the employer of one of our founding volunteers.
As the project grew the requirement for some dedicated management infrastructure arose.
In 2013 we successfully held a <a href="https://ring.nlnog.net/post/ring-fundraiser-successfully-closed/">fundraiser</a>, which enabled us to obtain the necessary hardware for hosting our management tooling.
Over the years more <a href="https://ring.nlnog.net/patrons/">sponsors</a> donated resources. These generous donations help us to run the project on essentially zero budget.</p>
<h3 id="growth">Growth</h3>
<p>Because the project originated within the Dutch ISP community, the first participants were all Dutch network operators.
After giving our first public presentation at <a href="https://ripe62.ripe.net/presentations/176-JobSnijders_NLNOG_RING_RIPE62.pdf">RIPE62</a> in May of 2011, ISPs from outside The Netherlands also showed interest in participating.
While The Netherlands is still the country with the most active participants (93 nodes as of January 2021), the majority of participants is based elsewhere.
At the time of writing we have 472 participating autonomous systems, with (virtual) machines in <a href="http://map.ring.nlnog.net/">56 countries</a>.</p>
<p><img src="https://ring.nlnog.net/images/post/10-years-of-nlnog-ring/ring-map=january-2021.png" alt="Map of NLNOG RING nodes (January 2021)" title="Map of NLNOG RING nodes (January 2021)"></p>
<p>Supporting all these machines was significantly increasing in load on our central Puppet server, to a point where in 2016 configuration of a single machine would take more than 30 minutes.
In addition to this we were facing the planned obsolescence of Puppet 2, which meant we would have to rewrite a significant part of our configurations to a syntax supported by Puppet 3.
Altogether a good opportunity to re-evaluate our architecture.</p>
<p>After evaluating several configuration management systems we decided on <a href="https://www.ansible.com/">Ansible</a>, mostly because of its support for a masterless “pull” model.
In this model all servers download their latest configs from a source code repository, and apply their changes locally.
This removes the need for a centralized management server, which means we can scale to a virtually unlimited number of machines.
All configuration files are published on our <a href="https://github.com/NLNOG/ring-ansible/">GitHub repository</a>, so that all participants can contribute.</p>
<p>To further cope with the increased growth in participants and machines we automated <a href="https://ring.nlnog.net/toolbox/health-monitoring/">health monitoring</a>, to automatically notify participants of problems with the (virtual) machines they provided to us.</p>
<h3 id="whats-next">What’s next?</h3>
<p>In ten years the NLNOG RING has grown from a handful of machines in the Netherlands to over 500 nodes worldwide, and we continue to see the number of active nodes grow.
To scale the platform further we plan to invest some time in building more self service tooling for provisioning of machines.
Another item high on our wishlist is a graphing solution that displays latency and packet loss on the full mesh of network paths between all nodes.
We will also continue to add features and tools <a href="https://github.com/NLNOG/ring-ansible/issues">requested</a> by participants.</p>
<p>We of course hope to continue to see a diverse set of ISPs join the project. The success of the project largely depends on the networks that provide us with resources. We thank all <a href="https://ring.nlnog.net/participants/">current participants</a> for making the NLNOG RING a huge success! Tell your friends to join too!</p>

        </div></div>]]>
            </description>
            <link>https://ring.nlnog.net/post/10-years-of-nlnog-ring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986010</guid>
            <pubDate>Mon, 01 Feb 2021 06:00:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Many Paths of Length K?: and I Show You How Deep the Rabbit Hole Goes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25985890">thread link</a>) | @chillee
<br/>
January 31, 2021 | http://horace.io/walks.html | <a href="https://web.archive.org/web/*/http://horace.io/walks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>Here's a (surprisingly interesting) programming problem: Given a directed unweighted graph with V vertices and E edges, how many paths of length K are there from node A to node B? Paths may visit the same node or edge multiple times<sup><a href="#fn1" id="fnref1">[1]</a></sup>. To avoid dealing with very large numbers, assume that we're computing our answer modulo a large prime.</p>
<p engine="dot"><!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<!-- Generated by graphviz version 2.40.1 (20161225.0304)
 -->
<!-- Title: Figure Pages: 1 -->
<svg width="466pt" height="270pt" viewBox="0.00 0.00 466.00 269.60" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 265.6)">
<title>Figure</title>
<polygon fill="#ffffff" stroke="transparent" points="-4,4 -4,-265.6 462,-265.6 462,4 -4,4"></polygon>
<text text-anchor="middle" x="229" y="-245" font-family="Times,serif" font-size="14.00" fill="#000000">There are 2 paths of length 2 from node A to node B</text>
<g id="clust1">
<title>cluster_first</title>
<polygon fill="none" stroke="#000000" points="8,-8 8,-228.8 150,-228.8 150,-8 8,-8"></polygon>
<text text-anchor="middle" x="79" y="-212.2" font-family="Times,serif" font-size="14.00" fill="#000000">Graph</text>
</g>
<g id="clust2">
<title>cluster_second</title>
<polygon fill="none" stroke="#000000" points="158,-8 158,-228.8 300,-228.8 300,-8 158,-8"></polygon>
<text text-anchor="middle" x="229" y="-212.2" font-family="Times,serif" font-size="14.00" fill="#000000">Path 1</text>
</g>
<g id="clust3">
<title>cluster_third</title>
<polygon fill="none" stroke="#000000" points="308,-8 308,-228.8 450,-228.8 450,-8 308,-8"></polygon>
<text text-anchor="middle" x="379" y="-212.2" font-family="Times,serif" font-size="14.00" fill="#000000">Path 2</text>
</g>
<!-- A1 -->
<g id="node1">
<title>A1</title>
<ellipse fill="none" stroke="#000000" cx="79" cy="-178" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="79" y="-173.8" font-family="Times,serif" font-size="14.00" fill="#000000">A</text>
</g>
<!-- C1 -->
<g id="node3">
<title>C1</title>
<ellipse fill="none" stroke="#000000" cx="43" cy="-106" rx="27" ry="18"></ellipse>
</g>
<!-- A1&#45;&gt;C1 -->
<g id="edge1">
<title>A1-&gt;C1</title>
<path fill="none" stroke="#000000" d="M70.2854,-160.5708C66.0403,-152.0807 60.8464,-141.6929 56.1337,-132.2674"></path>
<polygon fill="#000000" stroke="#000000" points="59.237,-130.6477 51.6343,-123.2687 52.976,-133.7782 59.237,-130.6477"></polygon>
</g>
<!-- D1 -->
<g id="node4">
<title>D1</title>
<ellipse fill="none" stroke="#000000" cx="115" cy="-106" rx="27" ry="18"></ellipse>
</g>
<!-- A1&#45;&gt;D1 -->
<g id="edge3">
<title>A1-&gt;D1</title>
<path fill="none" stroke="#000000" d="M87.7146,-160.5708C91.9597,-152.0807 97.1536,-141.6929 101.8663,-132.2674"></path>
<polygon fill="#000000" stroke="#000000" points="105.024,-133.7782 106.3657,-123.2687 98.763,-130.6477 105.024,-133.7782"></polygon>
</g>
<!-- B1 -->
<g id="node2">
<title>B1</title>
<ellipse fill="none" stroke="#000000" cx="79" cy="-34" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="79" y="-29.8" font-family="Times,serif" font-size="14.00" fill="#000000">B</text>
</g>
<!-- C1&#45;&gt;B1 -->
<g id="edge2">
<title>C1-&gt;B1</title>
<path fill="none" stroke="#000000" d="M51.7146,-88.5708C55.9597,-80.0807 61.1536,-69.6929 65.8663,-60.2674"></path>
<polygon fill="#000000" stroke="#000000" points="69.024,-61.7782 70.3657,-51.2687 62.763,-58.6477 69.024,-61.7782"></polygon>
</g>
<!-- D1&#45;&gt;B1 -->
<g id="edge4">
<title>D1-&gt;B1</title>
<path fill="none" stroke="#000000" d="M106.2854,-88.5708C102.0403,-80.0807 96.8464,-69.6929 92.1337,-60.2674"></path>
<polygon fill="#000000" stroke="#000000" points="95.237,-58.6477 87.6343,-51.2687 88.976,-61.7782 95.237,-58.6477"></polygon>
</g>
<!-- A2 -->
<g id="node5">
<title>A2</title>
<ellipse fill="none" stroke="#000000" cx="229" cy="-178" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="229" y="-173.8" font-family="Times,serif" font-size="14.00" fill="#000000">A</text>
</g>
<!-- C2 -->
<g id="node7">
<title>C2</title>
<ellipse fill="none" stroke="#000000" cx="193" cy="-106" rx="27" ry="18"></ellipse>
</g>
<!-- A2&#45;&gt;C2 -->
<g id="edge5">
<title>A2-&gt;C2</title>
<path fill="none" stroke="#ff0000" stroke-width="3" d="M220.2854,-160.5708C216.0403,-152.0807 210.8464,-141.6929 206.1337,-132.2674"></path>
<polygon fill="#ff0000" stroke="#ff0000" stroke-width="3" points="209.237,-130.6477 201.6343,-123.2687 202.976,-133.7782 209.237,-130.6477"></polygon>
</g>
<!-- D2 -->
<g id="node8">
<title>D2</title>
<ellipse fill="none" stroke="#000000" cx="265" cy="-106" rx="27" ry="18"></ellipse>
</g>
<!-- A2&#45;&gt;D2 -->
<g id="edge7">
<title>A2-&gt;D2</title>
<path fill="none" stroke="#000000" d="M237.7146,-160.5708C241.9597,-152.0807 247.1536,-141.6929 251.8663,-132.2674"></path>
<polygon fill="#000000" stroke="#000000" points="255.024,-133.7782 256.3657,-123.2687 248.763,-130.6477 255.024,-133.7782"></polygon>
</g>
<!-- B2 -->
<g id="node6">
<title>B2</title>
<ellipse fill="none" stroke="#000000" cx="229" cy="-34" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="229" y="-29.8" font-family="Times,serif" font-size="14.00" fill="#000000">B</text>
</g>
<!-- C2&#45;&gt;B2 -->
<g id="edge6">
<title>C2-&gt;B2</title>
<path fill="none" stroke="#ff0000" stroke-width="3" d="M201.7146,-88.5708C205.9597,-80.0807 211.1536,-69.6929 215.8663,-60.2674"></path>
<polygon fill="#ff0000" stroke="#ff0000" stroke-width="3" points="219.024,-61.7782 220.3657,-51.2687 212.763,-58.6477 219.024,-61.7782"></polygon>
</g>
<!-- D2&#45;&gt;B2 -->
<g id="edge8">
<title>D2-&gt;B2</title>
<path fill="none" stroke="#000000" d="M256.2854,-88.5708C252.0403,-80.0807 246.8464,-69.6929 242.1337,-60.2674"></path>
<polygon fill="#000000" stroke="#000000" points="245.237,-58.6477 237.6343,-51.2687 238.976,-61.7782 245.237,-58.6477"></polygon>
</g>
<!-- A3 -->
<g id="node9">
<title>A3</title>
<ellipse fill="none" stroke="#000000" cx="379" cy="-178" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="379" y="-173.8" font-family="Times,serif" font-size="14.00" fill="#000000">A</text>
</g>
<!-- C3 -->
<g id="node11">
<title>C3</title>
<ellipse fill="none" stroke="#000000" cx="343" cy="-106" rx="27" ry="18"></ellipse>
</g>
<!-- A3&#45;&gt;C3 -->
<g id="edge9">
<title>A3-&gt;C3</title>
<path fill="none" stroke="#000000" d="M370.2854,-160.5708C366.0403,-152.0807 360.8464,-141.6929 356.1337,-132.2674"></path>
<polygon fill="#000000" stroke="#000000" points="359.237,-130.6477 351.6343,-123.2687 352.976,-133.7782 359.237,-130.6477"></polygon>
</g>
<!-- D3 -->
<g id="node12">
<title>D3</title>
<ellipse fill="none" stroke="#000000" cx="415" cy="-106" rx="27" ry="18"></ellipse>
</g>
<!-- A3&#45;&gt;D3 -->
<g id="edge11">
<title>A3-&gt;D3</title>
<path fill="none" stroke="#ff0000" stroke-width="3" d="M387.7146,-160.5708C391.9597,-152.0807 397.1536,-141.6929 401.8663,-132.2674"></path>
<polygon fill="#ff0000" stroke="#ff0000" stroke-width="3" points="405.024,-133.7782 406.3657,-123.2687 398.763,-130.6477 405.024,-133.7782"></polygon>
</g>
<!-- B3 -->
<g id="node10">
<title>B3</title>
<ellipse fill="none" stroke="#000000" cx="379" cy="-34" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="379" y="-29.8" font-family="Times,serif" font-size="14.00" fill="#000000">B</text>
</g>
<!-- C3&#45;&gt;B3 -->
<g id="edge10">
<title>C3-&gt;B3</title>
<path fill="none" stroke="#000000" d="M351.7146,-88.5708C355.9597,-80.0807 361.1536,-69.6929 365.8663,-60.2674"></path>
<polygon fill="#000000" stroke="#000000" points="369.024,-61.7782 370.3657,-51.2687 362.763,-58.6477 369.024,-61.7782"></polygon>
</g>
<!-- D3&#45;&gt;B3 -->
<g id="edge12">
<title>D3-&gt;B3</title>
<path fill="none" stroke="#ff0000" stroke-width="3" d="M406.2854,-88.5708C402.0403,-80.0807 396.8464,-69.6929 392.1337,-60.2674"></path>
<polygon fill="#ff0000" stroke="#ff0000" stroke-width="3" points="395.237,-58.6477 387.6343,-51.2687 388.976,-61.7782 395.237,-58.6477"></polygon>
</g>
</g>
</svg>
</p><p>This problem is fairly standard -  many of you may have seen it or heard it in an interview. Personally, I've seen this problem on Hackernews in some form at least three times, <a href="https://news.ycombinator.com/item?id=22953404">here</a>, <a href="https://news.ycombinator.com/item?id=19193405">here</a>, and <a href="https://news.ycombinator.com/item?id=17758800">here</a>.</p>
<p>I found this comment from the last link particularly interesting.<br>
<img src="http://horace.io/img/walks_hn.jpg" alt=""></p>
<p>He states of the most advanced level:</p>
<blockquote>
<p>I've never seen anyone get this and I only learned about it after months of asking this question.</p>
</blockquote>
<p>And that's where he left the problem. Seems like a pretty cool problem with plenty of depth, doesn't it?</p>
<p>As it turns out, this problem has even more depth than that Google interviewer thought. What if I told you, that drawing on concepts from coding theory, abstract algebra, and signal processing, we could solve this problem in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>E</mi><mi>V</mi><mo>+</mo><mi>V</mi><mi>log</mi><mo>⁡</mo><mi>V</mi><mi>log</mi><mo>⁡</mo><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(EV + V \log V \log K)</annotation></semantics></math></span></span> time?</p>
<p>To my knowledge, despite being a common problem, I have not seen this faster solution presented anywhere.</p>
<p>Let's dive down the rabbit hole of solutions to this problem, starting from the top.</p>


<p>The most straightforward solution to this problem is to enumerate all the paths and stopping once our path reaches K nodes. We can implement it with a breadth first search, like so:</p>
<pre data-role="codeBlock" data-info="python">ans <span>=</span> <span>0</span>
queue <span>=</span> <span>[</span><span>(</span>A<span>,</span> <span>0</span><span>)</span><span>]</span> 
<span>while</span> <span>not</span> queue<span>.</span>empty<span>(</span><span>)</span><span>:</span>
    curNode<span>,</span> curLength <span>=</span> queue<span>.</span>front<span>(</span><span>)</span>
    queue<span>.</span>pop<span>(</span><span>)</span>
    <span>if</span> curLength <span>==</span> K<span>:</span>
        <span>if</span> curNode <span>==</span> B<span>:</span>
            ans <span>+=</span> <span>1</span>
        <span>break</span>
    <span>for</span> neighbor <span>in</span> neighbors<span>(</span>curNode<span>)</span><span>:</span>
        queue<span>.</span>push<span>(</span><span>(</span>neighbor<span>,</span> curLength <span>+</span> <span>1</span><span>)</span><span>)</span>
</pre><p>However, this solution is exponential. Take this simple graph</p>
<p><!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<!-- Generated by graphviz version 2.40.1 (20161225.0304)
 -->
<!-- Title: G Pages: 1 -->
<svg width="152pt" height="62pt" viewBox="0.00 0.00 152.00 62.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 58)">
<title>G</title>
<polygon fill="#ffffff" stroke="transparent" points="-4,4 -4,-58 148,-58 148,4 -4,4"></polygon>
<!-- 0 -->
<g id="node1">
<title>0</title>
<ellipse fill="none" stroke="#000000" cx="27" cy="-18" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-13.8" font-family="Times,serif" font-size="14.00" fill="#000000">0</text>
</g>
<!-- 0&#45;&gt;0 -->
<g id="edge3">
<title>0-&gt;0</title>
<path fill="none" stroke="#000000" d="M11.7729,-33.1666C7.1587,-43.6641 12.2344,-54 27,-54 36.9207,-54 42.4671,-49.3342 43.6394,-43.0884"></path>
<polygon fill="#000000" stroke="#000000" points="47.1015,-42.5736 42.2271,-33.1666 40.1713,-43.5601 47.1015,-42.5736"></polygon>
</g>
<!-- 1 -->
<g id="node2">
<title>1</title>
<ellipse fill="none" stroke="#000000" cx="117" cy="-18" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="117" y="-13.8" font-family="Times,serif" font-size="14.00" fill="#000000">1</text>
</g>
<!-- 0&#45;&gt;1 -->
<g id="edge1">
<title>0-&gt;1</title>
<path fill="none" stroke="#000000" d="M52.5497,-11.8449C61.4801,-11.2634 71.6762,-11.1082 81.2822,-11.3793"></path>
<polygon fill="#000000" stroke="#000000" points="81.2372,-14.8808 91.3865,-11.8408 81.5566,-7.8881 81.2372,-14.8808"></polygon>
</g>
<!-- 1&#45;&gt;0 -->
<g id="edge2">
<title>1-&gt;0</title>
<path fill="none" stroke="#000000" d="M91.3865,-24.1592C82.45,-24.7387 72.2523,-24.8919 62.6491,-24.6188"></path>
<polygon fill="#000000" stroke="#000000" points="62.6997,-21.1175 52.5497,-24.1551 62.3786,-28.1101 62.6997,-21.1175"></polygon>
</g>
<!-- 1&#45;&gt;1 -->
<g id="edge4">
<title>1-&gt;1</title>
<path fill="none" stroke="#000000" d="M101.7729,-33.1666C97.1587,-43.6641 102.2344,-54 117,-54 126.9207,-54 132.4671,-49.3342 133.6394,-43.0884"></path>
<polygon fill="#000000" stroke="#000000" points="137.1015,-42.5736 132.2271,-33.1666 130.1713,-43.5601 137.1015,-42.5736"></polygon>
</g>
</g>
</svg>
</p><p>Let's count the number of paths of length K from node 0 to node 1. We see that any sequence of 0s and 1s that ends at node 1 is a valid path, implying that there are <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mi>K</mi></msup></mrow><annotation encoding="application/x-tex">2^K</annotation></semantics></math></span></span> valid paths. As this solution counts each valid path separately, it must be doing exponential work as well.</p>
<p>An interviewer (like that Googler) wouldn't be too impressed.</p>


<p>Looking at the above solution, we notice that there is a lot of wasted work - our queue will often visit the same state many times. For example, we'll visit node B with a path of length K as many times as our answer. Noticing that the same state is visited multiple times naturally leads to a dynamic programming solution.</p>
<p>In this case, we choose the same state as we did in our above problem: (node, length). This time, however, we consolidate all of our redundant states.</p>
<p>Thus, <code>dp[node][length] = sum(dp[neighbors(node)][length-1])</code>.</p>
<pre data-role="codeBlock" data-info="python">dp<span>[</span>A<span>]</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>1</span>
<span>for</span> length <span>in</span> <span>0</span><span>.</span><span>.</span>K<span>:</span>
    <span>for</span> node <span>in</span> <span>0</span><span>.</span><span>.</span>N<span>:</span>
        <span>for</span> neighbor <span>in</span> neighbors<span>(</span>node<span>)</span><span>:</span>
            dp<span>[</span>node<span>]</span><span>[</span>length<span>]</span> <span>+=</span> dp<span>[</span>neighbor<span>]</span><span>[</span>length<span>-</span><span>1</span><span>]</span>
</pre><p>We can either do this iteratively (which allows us to reduce memory complexity by only storing one layer of DP at a time), or recursively with memoization. I've presented the iterative solution above.</p>
<p>The complexity of this solution is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>E</mi><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(EK)</annotation></semantics></math></span></span>. So far, this seems like a standard DP problem. Most interviewers would probably be satisfied with this solution.</p>
<p>We aren't. :^)</p>


<p>If there aren't many nodes but <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span> is extremely large, then we need to give up on the above DP approach. The naive approach above finds the answer for "how many paths of length <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">K-1</annotation></semantics></math></span></span>" before it finds the answer to "how many paths of length <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span>". As a result, even if we <strong>could</strong> find the answer for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span> from the answer for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">K-1</annotation></semantics></math></span></span> in constant time, we wouldn't be able to solve this problem with the above constraints.</p>
<p>There's 2 different ways to proceed. The first is to note that we don't actually <em>need</em> the answer for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">K-1</annotation></semantics></math></span></span> before we can find the answer for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span>. For example, if we know that that there are 3 paths of length 50 from A to C and 4 paths of length 50 from C to B, then there are <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>⋅</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">3 \cdot 4</annotation></semantics></math></span></span> paths of length 100 from A to B with C at the midpoint. More generally, consider any node C. The number of paths from A to B of length <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span> that include C at the midpoint is the number of paths from A to C of half length multiplied by the number of paths from C to B of half length. If we sum over all possible nodes for C, then we have our answer for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span>.</p>
<p><!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<!-- Generated by graphviz version 2.40.1 (20161225.0304)
 -->
<!-- Title: G Pages: 1 -->
<svg width="376pt" height="74pt" viewBox="0.00 0.00 375.87 73.95" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 69.9469)">
<title>G</title>
<polygon fill="#ffffff" stroke="transparent" points="-4,4 -4,-69.9469 371.8676,-69.9469 371.8676,4 -4,4"></polygon>
<text text-anchor="middle" x="183.9338" y="-49.3469" font-family="Times,serif" font-size="14.00" fill="#000000">12 paths from A to B of length 100 if each edge is of length 50</text>
<!-- A -->
<g id="node1">
<title>A</title>
<ellipse fill="none" stroke="#000000" cx="93.9338" cy="-20.5735" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="93.9338" y="-16.3735" font-family="Times,serif" font-size="14.00" fill="#000000">A</text>
</g>
<!-- C -->
<g id="node2">
<title>C</title>
<ellipse fill="none" stroke="#000000" cx="183.9338" cy="-20.5735" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="183.9338" y="-16.3735" font-family="Times,serif" font-size="14.00" fill="#000000">C</text>
</g>
<!-- A&#45;&gt;C -->
<g id="edge1">
<title>A-&gt;C</title>
<path fill="none" stroke="#000000" d="M114.8078,-8.9719C126.167,-6.9892 140.438,-6.5595 153.0593,-7.6829"></path>
<polygon fill="#000000" stroke="#000000" points="152.8064,-11.1792 163.173,-8.9917 153.7049,-4.2371 152.8064,-11.1792"></polygon>
</g>
<!-- A&#45;&gt;C -->
<g id="edge2">
<title>A-&gt;C</title>
<path fill="none" stroke="#000000" d="M120.9368,-20.5735C128.9615,-20.5735 137.9003,-20.5735 146.4647,-20.5735"></path>
<polygon fill="#000000" stroke="#000000" points="146.6389,-24.0736 156.6388,-20.5735 146.6388,-17.0736 146.6389,-24.0736"></polygon>
</g>
<!-- A&#45;&gt;C -->
<g id="edge3">
<title>A-&gt;C</title>
<path fill="none" stroke="#000000" d="M114.8078,-32.175C126.167,-34.1577 140.438,-34.5874 153.0593,-33.4641"></path>
<polygon fill="#000000" stroke="#000000" points="153.7049,-36.9098 163.173,-32.1552 152.8064,-29.9677 153.7049,-36.9098"></polygon>
</g>
<!-- B -->
<g id="node3">
<title>B</title>
<ellipse fill="none" stroke="#000000" cx="273.9338" cy="-20.5735" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="273.9338" y="-16.3735" font-family="Times,serif" font-size="14.00" fill="#000000">B</text>
</g>
<!-- C&#45;&gt;B -->
<g id="edge4">
<title>C-&gt;B</title>
<path fill="none" stroke="#000000" d="M198.3939,-5.229C212.171,.1403 233.1793,1.1019 249.5467,-2.3441"></path>
<polygon fill="#000000" stroke="#000000" points="248.93,-5.8097 259.5096,-5.243 250.8857,.9116 248.93,-5.8097"></polygon>
</g>
<!-- C&#45;&gt;B -->
<g id="edge5">
<title>C-&gt;B</title>
<path fill="none" stroke="#000000" d="M209.4835,-14.4184C218.4139,-13.8369 228.61,-13.6817 238.216,-13.9528"></path>
<polygon fill="#000000" stroke="#000000" points="238.171,-17.4543 248.3203,-14.4142 238.4904,-10.4615 238.171,-17.4543"></polygon>
</g>
<!-- C&#45;&gt;B -->
<g id="edge6">
<title>C-&gt;B</title>
<path fill="none" stroke="#000000" d="M209.4835,-26.7286C218.4139,-27.3101 228.61,-27.4653 238.216,-27.1942"></path>
<polygon fill="#000000" stroke="#000000" points="238.4904,-30.6854 248.3203,-26.7327 238.171,-23.6927 238.4904,-30.6854"></polygon>
</g>
<!-- C&#45;&gt;B -->
<g id="edge7">
<title>C-&gt;B</title>
<path fill="none" stroke="#000000" d="M198.3939,-35.9179C212.171,-41.2872 233.1793,-42.2488 249.5467,-38.8029"></path>
<polygon fill="#000000" stroke="#000000" points="250.8857,-42.0585 259.5096,-35.9039 248.93,-35.3372 250.8857,-42.0585"></polygon>
</g>
</g>
</svg>
</p><p>This allows us to remove our linear dependence on <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span> and transforms it into a logarithmic one, for a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>V</mi><mn>3</mn></msup><mi>log</mi><mo>⁡</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">V^3 \log K</annotation></semantics></math></span></span> algorithm.</p>
<p>Using graph theory, however, there's an even easier way to come up with this algorithm. One way to represent graphs is as an adjacency matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span>. If one views the values in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{ij}</annotation></semantics></math></span></span> as the number of edges between <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span></span>, then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">A_{ij}^k</annotation></semantics></math></span></span> represents the number of paths between <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span></span> of length <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>.</p>
<p>Thus, this problem has been reduced to computing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>k</mi></msup></mrow><annotation encoding="application/x-tex">A^k</annotation></semantics></math></span></span> (i.e: matrix power). This is a standard problem that can be done in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>V</mi><mn>3</mn></msup><mi>log</mi><mo>⁡</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">V^3 \log K</annotation></semantics></math></span></span> time through <a href="https://news.ycombinator.com/item?id=22946710">binary exponentiation</a>.</p>
<p>The two approaches outlined above end up being identical, but use radically different approaches. The difficulty of the first approach lies in thinking about first principles, while the difficulty of the second approach lies in abstracting the problem to matrices. However, once you've abstracted the problem appropriately, the solution becomes obvious.</p>


<p>For the vast majority of people (including the aforementioned HN commenter), their ability to solve this problem stops here. And thus far, I've covered nothing that existing articles haven't already done (see <a href="http://www.math.ucsd.edu/~gptesler/184a/slides/184a_ch10.3slides_17-handout.pdf">this</a> or <a href="https://www.geeksforgeeks.org/count-possible-paths-source-destination-exactly-k-edges/">this</a>).</p>
<p>At this point, unfortunately, it's not clear how to proceed with standard approaches. We've already used dynamic programming to reduce unneeded work, and then we even reduced the problem to matrix exponentiation. But how can we perform matrix exponentiation even faster?</p>
<p>One approach when we're stuck is to convert our problem into another abstraction. In this case, a concept that's closely related to matrix exponentiation is linear recurrences.</p>


<p>A linear recurrence is a recurrence like: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>k</mi></msub><mo>=</mo><mn>3</mn><msub><mi>a</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mn>2</mn><msub><mi>a</mi><mrow><mi>k</mi><mo>−</mo><mn>2</mn></mrow></msub><mo>−</mo><msub><mi>a</mi><mrow><mi>k</mi><mo>−</mo><mn>3</mn></mrow></msub></mrow><annotation encoding="application/x-tex">a_k = 3a_{k-1} + 2a_{k-2} - a_{k-3}</annotation></semantics></math></span></span>. One famous example of a linear recurrence is the Fibonacci series (itself an inexplicably popular interview problem)<sup><a href="#fn2" id="fnref2">[2]</a></sup>. The linear recurrence for Fibonacci can be written as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>k</mi></msub><mo>=</mo><msub><mi>A</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>A</mi><mrow><mi>k</mi><mo>−</mo><mn>2</mn></mrow></msub></mrow><annotation encoding="application/x-tex">A_k = A_{k-1} + A_{k-2}</annotation></semantics></math></span></span>. The order of a linear recurrence is the number of terms it depends on. So, the first example would have order 3, and Fibonacci would have order 2.</p>
<p>How are linear recurrences tied to matrix exponentiation? Well, you might know that finding the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span>-th Fibonacci number can be done in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log(K)</annotation></semantics></math></span></span> time using <a href="https://www.nayuki.io/page/fast-fibonacci-algorithms">matrix exponentiation</a>. In fact, this is a special case of the more general algorithm to find the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span>-th term of any order <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> linear recurrence using matrix exponentiation in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>3</mn></msup><mi>log</mi><mo>⁡</mo><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^3 \log K)</annotation></semantics></math></span></span> time. This is a <a href="https://community.topcoder.com/tc?module=Static&amp;d1=features&amp;d2=010408">good resource if you're unfamiliar</a>.</p>
<p>So, we can convert a linear recurrence problem to a matrix exponentiation problem. Clearly, there is some connection here. Sadly, as we currently have a matrix exponentiation problem, this doesn't immediately help. Could we be lucky enough to have a way to turn a matrix exponentiation problem into a linear recurrence problem?</p>


<p><a href="https://en.wikipedia.org/wiki/Cayley%E2%80%93Hamilton_theorem">Wikipedia</a> writes that</p>
<blockquote>
<p>If A is a given n×n matrix and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">I_n</annotation></semantics></math></span></span>  is the n×n identity matrix, then the characteristic polynomial of A is defined as<br>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi>p</mi><mo stretchy="false">(</mo><mi>λ</mi><mo stretchy="false">)</mo><mo>=</mo><mi>det</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>λ</mi><msub><mi>I</mi><mi>n</mi></msub><mo>−</mo><mi>A</mi><mo stretchy="false">)</mo><mtext>&nbsp;</mtext></mstyle></mrow><annotation encoding="application/x-tex">{\displaystyle p(\lambda )=\det(\lambda I_{n}-A)~}</annotation></semantics></math></span></span></span></p>
</blockquote>
<p>Not immediately helpful (to me at least). However, several lines down we see that</p>
<blockquote>
<p>The [Cayley Hamilton] theorem allows A^n to be expressed as a linear combination of the lower matrix powers of A.</p>
</blockquote>
<p>In other words, we know that this equation holds true for some values of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span></span>.</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>A</mi><mi>n</mi></msup><mo>=</mo><msub><mi>x</mi><mn>0</mn></msub><mi>I</mi><mo>+</mo><msub><mi>x</mi><mn>1</mn></msub><mi>A</mi><mo>+</mo><msub><mi>x</mi><mn>2</mn></msub><msup><mi>A</mi><mn>2</mn></msup><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">A^n = x_0I + x_1A + x_2A^2 ...</annotation></semantics></math></span></span></span></p>
<p>In other words, we are <strong>guaranteed</strong> that the powers of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> form a linear recurrence! This is not obvious at all, but it does highlight some of the powers of math. Good job, Cayley Hamilton.<sup><a href="#fn3" id="fnref3">[3]</a></sup></p>
<p>Now that we know that matrix exponentiation problems can be converted to a linear recurrence problem, this doesn't help us unless we can calculate the k-th term of a linear recurrence faster than we compute the k-th power of a matrix. So... can we?</p>
<p>As you may have inferred, yes! But to do so, we must first take a small detour into polynomials and generating functions.</p>
<h4 id="polynomials-and-generating-functions">Polynomials and Generating Functions</h4>

<p>Let's define a (kinda weird) function <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span></span>, which takes in a polynomial and replaces <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mi>k</mi></msup></mrow><annotation encoding="application/x-tex">x^k</annotation></semantics></math></span></span> with the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>-th term in our linear recurrence. More formally, given a polynomial <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mo>∑</mo><msub><mi>c</mi><mi>i</mi></msub><msup><mi>x</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">f(x) = \sum c_i x^i</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(f)</annotation></semantics></math></span></span> returns <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∑</mo><msub><mi>c</mi><mi>i</mi></msub><msub><mi>a</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\sum c_i a_i</annotation></semantics></math></span></span>.</p>
<p>So, for Fibonacci, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>0</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">G(x^0)=1</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>1</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">G(x^1) = 1</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>2</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">G(x^2) = 2</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>3</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">G(x^3)=3</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>4</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">G(x^4)=5</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>5</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">G(x^5)=8</annotation></semantics></math></span></span>, and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mi>k</mi></msup><mo stretchy="false">)</mo><mo>=</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">G(x^k) = k</annotation></semantics></math></span></span>-th Fibonacci element (ie: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">A_k</annotation></semantics></math></span></span>). <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>x</mi><mn>3</mn></msup><mo stretchy="false">)</mo><mo>=</mo><msub><mi>A</mi><mn>2</mn></msub><mo>+</mo><msub><mi>A</mi><mn>3</mn></msub><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">G(x^2 + x^3) = A_2 + A_3 = 5</annotation></semantics></math></span></span>. Finally, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span></span> is also a linear function, which means that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>f</mi><mo>+</mo><mi>g</mi><mo stretchy="false">)</mo><mo>=</mo><mi>G</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo><mo>+</mo><mi>G</mi><mo stretchy="false">(</mo><mi>g</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(f+g) = G(f) + G(g)</annotation></semantics></math></span></span>.</p>
<p>Some more examples:<br>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><msup><mi>x</mi><mn>3</mn></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>3</mn></msup><mo>+</mo><mn>2</mn><msup><mi>x</mi><mn>4</mn></msup><mo stretchy="false">)</mo><mo>=</mo><msub><mi>A</mi><mn>3</mn></msub><mo>+</mo><mn>2</mn><msub><mi>A</mi><mn>4</mn></msub><mo>=</mo><mn>3</mn><mo>+</mo><mn>2</mn><mo>⋅</mo><mn>5</mn><mo>=</mo><mn>13</mn></mrow><annotation encoding="application/x-tex">G(x(x^2 + 2x^3)) = G(x^3 + 2x^4) = A_3 + 2A_4 = 3 + 2\cdot 5 = 13</annotation></semantics></math></span></span></span><br>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>20</mn></msup><mo>+</mo><mn>3</mn><mo stretchy="false">)</mo><mo>=</mo><msub><mi>A</mi><mn>20</mn></msub><mo>+</mo><mn>3</mn><msub><mi>A</mi><mn>0</mn></msub><mo>=</mo><mn>6765</mn><mo>+</mo><mn>3</mn><mo>=</mo><mn>6768</mn></mrow><annotation encoding="application/x-tex">G(x^{20} + 3) = A_{20} + 3A_0 = 6765 + 3 = 6768</annotation></semantics></math></span></span></span></p>
<p>If someone gave us a magical black box to evaluate <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span></span>, we could simply evaluate <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x^k)</annotation></semantics></math></span></span> and get our answer! Unfortunately, no such box exists (I wish). If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> was small enough, we could compute the terms up to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> ourselves. But needing to computing the terms up to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> ourselves puts us back where we started.</p>
<p>Another way we could evaluate <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x^k)</annotation></semantics></math></span></span> is to find a polynomial equivalent to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x^k)</annotation></semantics></math></span></span> and evaluate that instead. And if this polynomial had low degree, then evaluating this function would be easy.</p>
<p>For example, this is one way to find an equivalent polynomial of lower degree:<br>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>5</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>3</mn></msup><mo>+</mo><msup><mi>x</mi><mn>4</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>3</mn></msup><mo>+</mo><mo stretchy="false">(</mo><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>x</mi><mn>3</mn></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>G</mi><mo stretchy="false">(</mo><mn>2</mn><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><mn>3</mn><msup><mi>x</mi><mn>3</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mn>2</mn><msub><mi>F</mi><mn>2</mn></msub><mo>+</mo><mn>3</mn><msub><mi>F</mi><mn>3</mn></msub><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">G(x^5) = G(x^3 + x^4) = G(x^3 + (x^2 + x^3)) = G(2x^2 + 3x^3) = 2F_2 + 3F_3 = 8</annotation></semantics></math></span></span></span></p>
<p>Note that despite the fact that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mn>2</mn><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><mn>3</mn><msup><mi>x</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(2x^2 + 3x^3)</annotation></semantics></math></span></span> represents <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>5</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x^5)</annotation></semantics></math></span></span>, we only needed to know Fibonacci values up to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x^3)</annotation></semantics></math></span></span>.</p>
<p>Thus, if we could easily compute a polynomial <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span></span> with low degree such that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mi>k</mi></msup><mo stretchy="false">)</mo><mo>=</mo><mi>G</mi><mo stretchy="false">(</mo><mi>h</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x^k) = G(h)</annotation></semantics></math></span></span>, we would be done! In order to do so, however, we need one final detour into the ominously named "annihilator" polynomials.</p>


<p>An annihilator is a non-zero polynomial <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> such that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">G(f) = 0</annotation></semantics></math></span></span>. On Fibonacci, for example, examples of annihilators would be <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mn>3</mn></msup><mo>−</mo><msup><mi>x</mi><mn>2</mn></msup><mo>−</mo><msup><mi>x</mi><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">x^3 - x^2 - x^1</annotation></semantics></math></span></span> or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mn>6</mn></msup><mo>−</mo><msup><mi>x</mi><mn>5</mn></msup><mo>−</mo><msup><mi>x</mi><mn>4</mn></msup></mrow><annotation encoding="application/x-tex">x^6 - x^5 - x^4</annotation></semantics></math></span></span>. Remember that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span></span> turns polynomial terms into Fibonacci terms. So, plugging in the last annihilator into <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span></span> provides us <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>6</mn></msup><mo>−</mo><msup><mi>x</mi><mn>5</mn></msup><mo>−</mo><msup><mi>x</mi><mn>4</mn></msup><mo stretchy="false">)</mo><mtext>  </mtext><mo>⟹</mo><mtext>  </mtext><msub><mi>F</mi><mn>6</mn></msub><mo>−</mo><msub><mi>F</mi><mn>5</mn></msub><mo>−</mo><msub><mi>F</mi><mn>4</mn></msub><mo>=</mo><mn>0</mn><mtext>  </mtext><mo>⟹</mo><mtext>  </mtext><msub><mi>F</mi><mn>6</mn></msub><mo>=</mo><msub><mi>F</mi><mn>4</mn></msub><mo>+</mo><msub><mi>F</mi><mn>5</mn></msub></mrow><annotation encoding="application/x-tex">G(x^6 - x^5 - x^4) \implies F_6 - F_5 - F_4 = 0 \implies F_6 = F_4 + F_5</annotation></semantics></math></span></span>. In other words, the 6th Fibonacci term is equal to the 5th and 4th Fibonacci terms added together.</p>
<p>Note that the last statement is clearly true. After all, that's the definition of Fibonacci.</p>
<p>This observation leads to an easy way of generating annihilators: We just use the definition of our linear recurrence! If the n-th term of our linear recurrence is some combination of the previous terms, then the n-th term minus those previous terms is equal to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span>.</p>
<p>For illustration, let's take the linear recurrence <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>n</mi></msub><mo>=</mo><msub><mi>a</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>−</mo><mn>2</mn><msub><mi>a</mi><mrow><mi>n</mi><mo>−</mo><mn>2</mn></mrow></msub><mo>+</mo><mn>3</mn><msub><mi>a</mi><mrow><mi>n</mi><mo>−</mo><mn>3</mn></mrow></msub></mrow><annotation encoding="application/x-tex">a_n = a_{n-1} - 2a_{n-2} + 3a_{n-3}</annotation></semantics></math></span></span>. Specifically, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mn>3</mn></msub><mo>=</mo><msub><mi>a</mi><mn>2</mn></msub><mo>−</mo><mn>2</mn><msub><mi>a</mi><mn>1</mn></msub><mo>+</mo><mn>3</mn><msub><mi>a</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">a_3 = a_2 - 2a_1 + 3a_0</annotation></semantics></math></span></span>. This implies that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mn>3</mn></msub><mo>−</mo><msub><mi>a</mi><mn>2</mn></msub><mo>+</mo><mn>2</mn><msub><mi>a</mi><mn>1</mn></msub><mo>−</mo><mn>3</mn><msub><mi>a</mi><mn>0</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">a_3 - a_2 + 2a_1 - 3a_0 = 0</annotation></semantics></math></span></span>. Thus, one …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://horace.io/walks.html">http://horace.io/walks.html</a></em></p>]]>
            </description>
            <link>http://horace.io/walks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25985890</guid>
            <pubDate>Mon, 01 Feb 2021 05:41:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When to Use Vue over React]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25985888">thread link</a>) | @hactually
<br/>
January 31, 2021 | https://michaeltimbs.me/when-to-use-vue-over-react/ | <a href="https://web.archive.org/web/*/https://michaeltimbs.me/when-to-use-vue-over-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A highly opinionated article based on my experience as a front-end web developer over the last four years.</p>
<p>I use <a href="https://reactjs.org/">React</a> professionally at my current job, but I choose <a href="https://vuejs.org/">Vue</a> for all personal projects. It’s my preferred framework of choice. I’ve used Vue in previous (publicly traded) companies, and it scaled incredibly well.</p>
<p>Any seasoned developer will tell you software is all about trade-offs and throwing around objective statements like “Framework x is better than Framework y” are generally meaningless. By what metrics? In whose opinion? For this reason, I’ll compare Vue and React across three main concerns that are often competing trade-offs.</p>
<ol>
<li>Performance</li>
<li>Scalability</li>
<li>Job Market</li>
</ol>
<h2>Performance</h2>
<p>Performance is usually where people want to start when discussing frameworks or languages. Everyone who writes software is building the next FAANG company, and every nanosecond of performance must be extracted from our code.</p>
<p>I’m going to compare both frameworks on two components of performance, namely silicon time and carbon time. <em>Silicon time</em> refers to the raw execution performance — how fast it can run in the browser. <em>Carbon time</em> refers to how fast developers can build products in the code.</p>
<h3>Silicon-time comparison</h3>
<p><span>
      <a href="https://michaeltimbs.me/static/2eb2e4fd514290eb574580d5a9c2cfd9/50e7d/framework-perf-tradeoffs.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="JS framework trade-offs for performance" title="JS framework trade-offs for performance" src="https://d33wubrfki0l68.cloudfront.net/47139e95f26c14568aeaf97616a53b2663e6fa3d/65e58/static/2eb2e4fd514290eb574580d5a9c2cfd9/2a195/framework-perf-tradeoffs.png" srcset="https://d33wubrfki0l68.cloudfront.net/71e8f312d39cb583a83b4501f34069bc5cffd7b2/f6af9/static/2eb2e4fd514290eb574580d5a9c2cfd9/158c9/framework-perf-tradeoffs.png 155w,
https://d33wubrfki0l68.cloudfront.net/058b9d544c7568bcb687e0811ccf6dc66183e78f/3b7d7/static/2eb2e4fd514290eb574580d5a9c2cfd9/5fad2/framework-perf-tradeoffs.png 310w,
https://d33wubrfki0l68.cloudfront.net/47139e95f26c14568aeaf97616a53b2663e6fa3d/65e58/static/2eb2e4fd514290eb574580d5a9c2cfd9/2a195/framework-perf-tradeoffs.png 620w,
https://d33wubrfki0l68.cloudfront.net/5299bc393d5ad765c84310fddb0920581eb78587/a14eb/static/2eb2e4fd514290eb574580d5a9c2cfd9/416ee/framework-perf-tradeoffs.png 930w,
https://d33wubrfki0l68.cloudfront.net/f05d4eda630989d60b934c5b17420e8f3cdd3203/45eaf/static/2eb2e4fd514290eb574580d5a9c2cfd9/7a4b2/framework-perf-tradeoffs.png 1240w,
https://d33wubrfki0l68.cloudfront.net/92d1b36a76d2c9d6ec32ab081ab456b3c944b254/7e6f5/static/2eb2e4fd514290eb574580d5a9c2cfd9/50e7d/framework-perf-tradeoffs.png 1738w" sizes="(max-width: 620px) 100vw, 620px" loading="lazy">
  </a>
    </span><em>JS framework trade-offs for performance</em></p>
<p>React leverages JSX, which gives developers a lot of power to build arbitrarily complex logic. We can harness the Turing-complete power of JavaScript and treat our view as data. Something like Svelte leverages templates for markup that provide a rigid structure to the view layer.</p>
<p>React and Vue both use a <a href="https://stackoverflow.com/questions/21965738/what-is-virtual-dom">virtual DOM</a> (VDOM), which, while practically fast enough, is inherently expensive and <a href="https://svelte.dev/blog/virtual-dom-is-pure-overhead">almost purely overhead</a>. Svelte compiles template code to raw JS and manipulates the DOM directly, which means it doesn’t have the performance overheads of maintaining a VDOM.</p>
<p>What I love about Vue is it hedges its bets a little bit. The most common way to use Vue is to use templates in <a href="https://vuejs.org/v2/guide/single-file-components.html">single-file components</a>. This has allowed the Vue team to do some very clever things in the upcoming Vue 3 release with ahead-of-time (AOT) optimisations.</p>
<p>The structured nature of a templates means a compiler can know things about your code and perform optimisations. The main optimisation Vue introduces is dropping all static data from the VDOM diff. VDOM performance is directly affected by the number of nodes it has to track. By filtering out static data from this VDOM-diffing process, we can reduce the number of nodes being tracked. This makes the code run much faster as it doesn’t have to compare a recursive tree of arbitrary nodes at each render cycle.</p>
<p>While Vue appears to use templates in most cases, the compiler actually turns these templates into <a href="https://vuejs.org/v2/guide/render-function.html">render functions</a> for you under the hood. This means any time the templating of Vue is getting in your way, you can directly drop down and write render functions exactly like you would in React. This means you get all the flexibility of render functions and JSX that you get in React with some of the performance benefits you get from a templated framework like Svelte. Obviously, if you write a Vue application with 100% render functions, you lose all of the template optimisations.</p>
<p>Code benchmarks are a bit of a waste of time, in my opinion, but a few show Vue 2 around 2.5x faster than default React, and Vue 3 is benchmarking 3-5x faster than Vue 2. In practice, the JS framework you use is going to be such a small component of your application that these benchmarks are nearly meaningless. However, if you’re building templates that’ll leverage Vue 3’s AoT optimisations from templates, there’s just no way the same app will be faster written in React.</p>
<p><strong>Winner: Vue</strong></p>
<h3>Carbon-time performance</h3>
<p><span>
      <a href="https://michaeltimbs.me/static/3da73100deb391d774f1a6e4f1e95c02/599ea/carbon-silicon-time.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Carbon cost versus silicon cost for software development" title="Carbon cost versus silicon cost for software development" src="https://d33wubrfki0l68.cloudfront.net/114d131b506056439904ac59ea89a8cf30d02c3f/c875b/static/3da73100deb391d774f1a6e4f1e95c02/2a195/carbon-silicon-time.png" srcset="https://d33wubrfki0l68.cloudfront.net/e70ce6273e8d875734d9c2de8f95812c7c3d1941/3c9ca/static/3da73100deb391d774f1a6e4f1e95c02/158c9/carbon-silicon-time.png 155w,
https://d33wubrfki0l68.cloudfront.net/339310ece365efa3674e27b224e30be3c8490b5c/de697/static/3da73100deb391d774f1a6e4f1e95c02/5fad2/carbon-silicon-time.png 310w,
https://d33wubrfki0l68.cloudfront.net/114d131b506056439904ac59ea89a8cf30d02c3f/c875b/static/3da73100deb391d774f1a6e4f1e95c02/2a195/carbon-silicon-time.png 620w,
https://d33wubrfki0l68.cloudfront.net/82dbbf5f6eed42acc48f78671017fe3727007716/e4234/static/3da73100deb391d774f1a6e4f1e95c02/416ee/carbon-silicon-time.png 930w,
https://d33wubrfki0l68.cloudfront.net/e109f9298665387c5a117300e01fa8ae825ad130/f5b32/static/3da73100deb391d774f1a6e4f1e95c02/7a4b2/carbon-silicon-time.png 1240w,
https://d33wubrfki0l68.cloudfront.net/789c23396ca0e59c7b62624fb264a311fa4107e0/96a70/static/3da73100deb391d774f1a6e4f1e95c02/599ea/carbon-silicon-time.png 1926w" sizes="(max-width: 620px) 100vw, 620px" loading="lazy">
  </a>
    </span><em>Carbon cost versus silicon cost for software development</em></p>
<p>A senior developer will cost you around $150/hr depending on where you are in the world. Even junior to midlevel developers are earning a good enough salary that you want to be factoring in development time and costs into your technical stack. It’s the reason why languages such as PHP, Python, Node, Ruby, etc. are so popular and we don’t just write everything in C.</p>
<p>For front-end applications, we’re constrained by the browser, device resources, and network latency, so silicon performance is still a contributing factor — but carbon performance should also be at the forefront of any CTO’s mind.</p>
<p>In my opinion, the single greatest contributing factor in the success of Vue has been its approachable documentation, resources, and ease of learning. I learned React and Vue at the same time, and Vue was noticeably easier to get started with. If you know HTML, CSS, and the bare basics of JS, you can build an application with Vue. I’ve spent half a day with a design team and had them shipping changes to production front ends in Vue. This frees up a lot of time for the dev team and allows designers to implement A/B tests and design updates without getting blocked by the software backlog.</p>
<p>One of the things I love about Vue is the layered design of its opt-in tooling. You can start by pulling in Vue via a CDN. That means you can play with it without needing to go through complex build steps (webpack/Babel config, npm, etc). You can then progress to the Vue CLI and build basic apps. If you then need a state management solution, there’s an officially supported and documented solution in Vuex. Similarly, Vue Router is an officially endorsed and supported router solution for Vue.</p>
<p>On the other hand, React introduces the <a href="https://en.wikipedia.org/wiki/The_Paradox_of_Choice">paradox of choice,</a> which can make things hard for newcomers.</p>
<p>React is a small-scope, single-purpose library that introduces a component model that receives props and returns a VDOM tree. This provides a lot of flexibility and the React community has built many complex systems on top of this simple library.</p>
<p>There’s a large ecosystem with many, many options available to solve tasks. These are maintained independently by users. This model provides a lot of opportunities for people to build things on top of React and build popular libraries and tools.</p>
<p>It also makes things very difficult to find and learn. You’re stuck choosing the best option for state management or routing or configuring a new application. In my experience, this also makes hiring React developers harder. When there’s multiple ways to do things, onboarding new members to a React project has more friction than onboarding to a Vue project.</p>
<p><strong>Winner: Vue</strong></p>
<h2>Scalability</h2>
<p>Most of my thoughts on the scalability of these frameworks was touched on in the performance section. Scalability is often intrinsically linked with performance, so it’s not surprising.</p>
<p>I generally think of scalability in terms of:</p>
<h3>Scaling the number of views/components/workflows in an application</h3>
<p>In terms of scaling out the number of components, I’m a really big fan of the single-file component (SFC). The logical grouping of a component makes a lot of sense to me. Many people disagree with this, and it’s a matter of opinion rather than an objective statement.</p>
<p>The reason I love SFCs is because they provides a great way to enforce the <a href="https://blog.cleancoder.com/uncle-bob/2014/05/08/SingleReponsibilityPrinciple.html">separation of concerns</a> (SoC).* *Some people argue that mixing HTML, CSS, and JavaScript is doing the opposite of separating concerns. I’ve changed the way I think about this principle on the front end, largely with my obsessive adoption of <a href="https://tailwindcss.com/">Tailwind CSS</a> for styling my components.</p>
<p>Adam Wathan wrote a <a href="https://adamwathan.me/css-utility-classes-and-separation-of-concerns/">great article</a>on the notion of SoC and how it applies to HTML and CSS. I think about my front-end components in a similar way. In my mind, a component is how it looks (HTML/CSS) <em>and</em> how it works. Separating the markup from the JS feels arbitrary to me. If you consider your views as data, then (to me) it makes sense to group them with your data.</p>
<p>Don’t even get me started on JSX and CSS-in-JS. HTML and CSS are not dead. They’re incredibly powerful building blocks of the web. Use them!</p>
<p>The benefits of officially supported solutions to common problems also comes in handy at scale. If you’re having trouble scaling a Vue application, then chances are any other Vue application at scale has used the same architecture, and you’ll be able to find advice and help. You don’t need to worry about people saying, “Just use hooks/<a href="https://mobx.js.org/README.html">MobX</a>/<a href="https://medium.com/p/9a4e0f01e064/edit">Redux</a>/<a href="https://redux-saga.js.org/">Redux-Saga</a>.”</p>
<h3>Scaling the number of developers on a team</h3>
<p>I’ve already mentioned I’ve previously seen a design team empowered to push changes to production with a few hours of help. That’s an insane productivity boost to any consumer-facing application.</p>
<p>The general consensus that Vue is easier to learn also means you can train junior developers to a point of net benefit to the team much much faster. You can also onboard a React developer (assuming they know HTML and CSS) with little effort.</p>
<p>Again, having consistent solutions to common problems makes code review and reasoning about a large codebase that much easier for everyone on the team.</p>
<p>The key thing with both of these is maintaining development velocity while keeping a performant application that meets the needs of your users. Vue strikes the perfect balance here as far as I’m concerned.</p>
<p><strong>Winner: Vue</strong></p>
<h2>The Job Market</h2>
<p>OK, so I’ve convinced you Vue is better than React in every conceivable way. But this is meaningless if you can’t get paid (or find devs to hire).</p>
<p>React has a much higher share of the job market (at least in Australia and the United States). If you look on most job boards, the number of React jobs advertised relative to Vue is significant (nearly 8x as many React jobs at the time of writing this based on 10 seconds of job-board searches).</p>
<p>While React appears to win on this metric, I refuse to let React get points on the board, so I’ll make the following (water-tight, unassailable) argument.</p>
<p>There are opportunities for both React and Vue in the job market. Companies using Vue or React both find it difficult to hire, and, in my experience, there’s a skills shortage for both. As someone looking for work, you can achieve mastery (or perceived mastery) of Vue much …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://michaeltimbs.me/when-to-use-vue-over-react/">https://michaeltimbs.me/when-to-use-vue-over-react/</a></em></p>]]>
            </description>
            <link>https://michaeltimbs.me/when-to-use-vue-over-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25985888</guid>
            <pubDate>Mon, 01 Feb 2021 05:41:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Reshaped Mac Experience]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25985859">thread link</a>) | @todsacerdoti
<br/>
January 31, 2021 | http://morrick.me/archives/9150 | <a href="https://web.archive.org/web/*/http://morrick.me/archives/9150">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>Yesterday, a short <a href="https://twitter.com/lapcatsoftware/status/1355514848717791234">Twitter thread</a> by the excellent <a href="https://lapcatsoftware.com/articles/">Jeff Johnson</a> caught my eye. Since he often deletes past tweets, I’ll quote the relevant ones here (emphasis mine):</p>
<blockquote><p><strong>The selling point of the Macintosh was never the hardware, it was the user interface. So if the selling point now is the hardware, that’s a damning indictment of the current user interface.</strong></p>

<p><strong>I cannot emphasize enough how everyone seems to have lowered their standards with regard to the user interface.</strong> The “<a href="https://en.wikipedia.org/wiki/Overton_window">Overton window</a>” has moved. The Overton window now has rounded rects.</p>

<p>We’ve gone from “insanely great” and “It just works” to “Catalyst is good enough for most people.”</p>
<p>That’s fucking BS, and I won’t tolerate it.</p>

<p>Windows is “good enough for most people”. That’s why Windows has a 90% market share. Why should we aspire to that level, shouldn’t we have much higher aspirations? Mac is a niche. “Most people” are not even using Macs, so the majority is not even relevant. Mac is a premium brand.</p>

<p>The way I see it, the Mac now is merely milking the brand reputation and loyalty it previously built. That Jobs previously built. But neither Cook nor the current Mac deserves that reputation or loyalty.</p>

<p>Steve Jobs wasn’t an engineer. Not a hardware engineer, not a software engineer. At Apple, his role was as “proxy” for the&nbsp;users.</p>
<p>Apple no longer has a proxy for the users. Tim Cook is a proxy for the shareholders, nothing more.</p></blockquote>
<p>Jeff himself says that this criticism is hardly new, that these are things he already pointed out “a thousand times, to no effect”. While I am in no position to affect Apple or Mac development, this short Twitter rant had the effect of reminding me of something I, too, believe in; something I myself should emphasise more frequently. It’s those first two tweets I’ve quoted above.</p>
<p>As someone who still puts vintage Macs and older computers and devices to good use, the Mac’s user interface and user experience are in large part what still makes using 15–20-year-old machines enjoyable. This, by the way, also applies to other products of course. It’s thanks to well-designed user interfaces that we enjoy driving a classic car, or shooting with a 50-year-old film camera, or listening to vinyl records on a 40-year-old record-player and hi-fi stereo.</p>
<p>A couple of weeks ago I was on a group videochat with some friends and when I said that, frankly, using my 12-inch PowerBook G4 (2003) with Mac OS X 10.5 Leopard was more enjoyable than using my 13-inch retina MacBook Pro (2015) with Mac OS 11 Big Sur, the common reaction was that I was just being ‘nostalgic’; that surely my MacBook Pro was the better choice because it is orders of magnitude faster, with a ‘more modern’ OS, and that the sum of those parts was a better Mac experience. That I should ‘be rational’ and accept that.</p>
<p>Here, bringing up nostalgia is missing the point. And the point is that an admittedly faster hardware plus a purportedly ‘more modern’ operating system <em>do not necessarily</em> equal a better Mac experience. It’s interesting that my friends’ reaction was not to ask me <em>why</em> I was finding using an 18-year-old machine more enjoyable than an up-to-date Mac, but to promptly want to readjust my enjoyment, implying that there was something ‘wrong’ with&nbsp;it.</p>
<p>I’m finding that many people not only have lowered their standards with regard to the user interface, but more and more often when I bring up the subject, they seem to consider it a somewhat secondary aspect, something that’s only good for ‘geek talk’. The same kind of amused reaction laymen have to wine or coffee connoisseurs when they describe flavours and characteristics using specific lingo. Something that makes sense only to wine or coffee geeks but has little to no meaning or impact for the regular person.</p>
<p>The problem is that if an increasing number of people start viewing user interface design as an afterthought, or something that isn’t fundamental to the design of a product or experience — it’s all just ‘geek talk’ — then there is a reduced incentive to care about it on the part of the maker of the product. It’s more like a vicious circle, really; if Apple software’s quality declines but only a bunch of professional users and enthusiasts point that out, then Apple isn’t particularly incentivised to do a better job at it — the “good enough for most people” is really a dangerous, self-indulgent excuse. And in turn most people are fine with it, and in turn Apple think they’re on a ‘good’ path, and so&nbsp;forth.</p>
<p>At the very end of my piece <a href="http://morrick.me/archives/9141"><em> What about the M1 Macs?</em></a>, I&nbsp;wrote:</p>
<blockquote><p>They’re unbelievably good machines, and everything that is genuinely good about them and future Apple Silicon-based Macs — sheer performance, astounding power-efficiency, and great backward compatibility with Intel software thanks to Rosetta 2 — will also allow Apple to get away with a lot of things with regard to platform control, design decisions, and so&nbsp;forth.</p></blockquote>
<p>If you take a look at Jason Snell’s <a href="https://sixcolors.com/post/2021/01/apple-in-2020-the-six-colors-report-card/"><em>Apple in 2020: The Six Colors report card</em></a>, the Mac scored very good points overall, 4.7 out of 5, with a year-over-year increment of 1.1 points. The main reason has been of course the M1 Macs and Apple Silicon. Don’t get me wrong, Apple Silicon <em>is</em> groundbreaking, and Rosetta 2 is really an incredible performer on the software side. But what I contend is that a leap in hardware architecture and performance doesn’t necessarily mean that suddenly all is fine with the Mac as a platform or as an experience.</p>
<p>The Mac’s user interface is undergoing plastic surgery by the hand of surgeons who have studied on iOS books. The result is pretty much the same as when you see a favourite celebrity after a procedure. They look ‘younger’ but there’s also something weird about their appearance. Their traits have changed a bit. In certain cases you almost fail to recognise the person at first glance.</p>
<p>Similarly, the Mac experience today feels disjointed. The hardware has unquestionably improved with the introduction of Apple Silicon, and yes, it’s something worth celebrating and it’s something worth praising. On the other hand, the software that drives this hardware is a bit of a paradox: Big Sur and Apple Silicon Macs fit and work together well from a technical, architectural standpoint. From a user interface standpoint, however, Big Sur embodies what I’ve been fearing in recent years — a progressive iOS-ification of Mac OS. Big Sur provides a general user experience that is the least Mac-like in the history of the Mac. Going through Big Sur’s user interface with a fine-tooth comb reveals arbitrary design decisions that prioritise looks over function, and therefore reflect an un-learning of tried-and-true user interface and usability mechanics that used to make for a seamless, thoughtful, enjoyable Mac experience.</p>
<p>iOS was born as a ‘spinoff’ of Mac OS X, a sort of Lite version aimed at mobile devices like the iPhone and the iPod touch. The two platforms have maintained their separate paths and trajectories for years, and for a while using a Mac and an iPhone (or iPad) felt like having the best experience of each world. Then Apple became obsessed with thoughts of convergence, and features, UI ideas, paradigms, started bleeding through both platforms and in turn the respective experiences have become less clear-cut over time, with the software not fully capable of bringing out all that hardware power and potential.</p>
<p>This convergence will continue, of course, with Macs becoming more and more like ‘senior iOS devices’ from a UI and user experience standpoint. It seems clear to me that Apple is prioritising ecosystem experience because, let’s be honest, having a unified ‘operating system core’ underlying all platforms means having fewer framework-specific headaches and probably a faster, streamlined process when deploying new features. But this loss of differentiation is especially detrimental to Mac OS, which is being reduced to the lowest common denominator and loses an increasing amount of user interface ideas and conventions that were central to its superior user experience and ease of&nbsp;use.</p>
<p>I’m not annoyed because I see pieces of UI history fading away. I’m annoyed because I see pieces of <em>good</em> UI design fading away and being replaced by decisions that are puzzling and arbitrary, or the product of a trial-and-error process, rather than a meaningful, purposeful design.</p>
<p>You want an example that I find particularly glaring? Big Sur’s UI features a general increase of space between elements — icons, menus, labels, toolbars, sidebars, pretty much everywhere. On the surface it doesn’t seem like a bad decision. If you zoom in on certain parts of the user interface, you could say that more space between elements means that things looks cleaner, airier, sleeker.</p>
<p>But you’re looking at it on a 27-inch retina display. What about a display half that size? What about an 11-inch, non-retina display, like the one of the older 2013–2015 MacBook Airs that can be updated to Big Sur? It’s less pretty.</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=960%2C600" alt="" width="960" height="600" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?w=2560 2560w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=260%2C163 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=640%2C400 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=768%2C480 768w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=1536%2C960 1536w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=2048%2C1280 2048w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=1194%2C746 1194w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?w=1920 1920w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>I usually work with a lot of app windows and Finder windows, but when I’m using my 13-inch retina MacBook Pro with Big Sur, the workspace constantly feels cramped, while on the other hand I have no problems using High Sierra on my 11-inch MacBook Air. Sometimes it feels like looking at a zoomed-in interface. That increased space between elements becomes less of a good idea because it doesn’t scale gracefully when the overall screen real estate is reduced. It becomes an interference. Before installing Big Sur, the amount of icons on the right of the menu bar had never really been a concern. Now, the simple addition of a couple of third-party apps like Dropbox and iStat Menus — both essential for me — is enough to make that menu bar look crowded. (And thankfully Apple has been reducing the space between menu icons, because in the first Big Sur betas icon padding was so bad I had to remove a few icons and use Control Centre to check on their status).</p>
<p>This, like other UI design decisions in Big Sur, feels like …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://morrick.me/archives/9150">http://morrick.me/archives/9150</a></em></p>]]>
            </description>
            <link>http://morrick.me/archives/9150</link>
            <guid isPermaLink="false">hacker-news-small-sites-25985859</guid>
            <pubDate>Mon, 01 Feb 2021 05:35:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is How Google will Collapse (2017)]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25985843">thread link</a>) | @partingshots
<br/>
January 31, 2021 | https://www.googliath.org/this-is-how-google-will-collapse-by-daniel-colin-james/ | <a href="https://web.archive.org/web/*/https://www.googliath.org/this-is-how-google-will-collapse-by-daniel-colin-james/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<!-- ARTICAL CONTENT -->
                                                        <h2>Reporting from the very near, post-Google future</h2>
<p>Google made almost all its money from ads. It was a booming business — until it wasn’t. Here’s how things looked right before the most spectacular crash the technology industry had ever seen.<br>
The crumbling of Google’s cornerstone</p>
<p>Search was Google’s only unambiguous win, as well as its primary source of revenue, so when Amazon rapidly surpassed Google as the top product search destination, Google’s foundations began to falter. As many noted at the time, the online advertising industry experienced a major shift from search to discovery in the mid-2010s.</p>
<p>While Google protected its monopoly on the dying search advertising market, Facebook — Google’s biggest competitor in the online advertising space — got on the right side of the trend and dominated online advertising with its in-feed native display advertising.</p>
<p><a href="https://hackernoon.com/how-google-collapsed-b6ffa82198ee" target="_blank" rel="noopener">Read the full article here.</a></p>
                                                    </div></div>]]>
            </description>
            <link>https://www.googliath.org/this-is-how-google-will-collapse-by-daniel-colin-james/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25985843</guid>
            <pubDate>Mon, 01 Feb 2021 05:32:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Create Luck]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25985474">thread link</a>) | @exolymph
<br/>
January 31, 2021 | https://www.swyx.io/create_luck/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/create_luck/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>My entire worldview changed when I realized that <strong>luck can be created</strong>.</p>
<p>More precisely, you can actively <strong>create optimal conditions for lucky things to happen to you</strong>. The more I looked into this, the more I realized that this is not only <em>not</em> a new insight, but successful people have studied this for <em>decades</em> and I am just late to the party.</p>
<p>In this post we'll briefly review the "Literature of Luck", and then I'll end with some personal thoughts on how it could be extended.</p>
<section>
  <h2 id="binary-luck"><a href="#binary-luck">Binary Luck</a></h2>
  <p>Most people have a binary view of luck:</p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/kgd335km9x3ujfmhxnz7.png" alt="Alt Text">
  </p>
  <p>This is true enough. Some people are born into privilege, some people just win some literal or figurative lottery or other.</p>
  <p>The closing question of every episode of Guy Raz's <a href="https://www.npr.org/podcasts/510313/how-i-built-this">How I Built This</a> podcast asks successful people: <em>"How much of your success is due to skill, and how much is due to luck?"</em></p>
  <p>Those who believe in their own agency answer the former. Others - who've seen people smarter and harder working than them fail - answer the latter. Those who are politically correct cop-out with the half-and-half.</p>
  <p>It can be comforting to subscribe to the binary luck model. If you just got a bad roll of the dice, there's nothing you could do. Your lack of success is not your fault.</p>
  <p>But what if I told you <strong>there are people who have skill at creating luck</strong> for themselves?</p>
</section>
<section>
  <h2 id="luck-surface-area"><a href="#luck-surface-area">Luck Surface Area</a></h2>
  <p>Jason Roberts coined the term "<a href="https://www.codusoperandi.com/posts/increasing-your-luck-surface-area">Luck Surface Area</a>", and it was expanded by <a href="https://www.skmurphy.com/blog/2019/04/03/increase-your-luck-surface-area-to-get-more-customers/">Sean Murphy</a> and popularized by <a href="https://www.perell.com/podcast/patrick-mckenzie-internet-famous">Patrick McKenzie</a>.</p>
  <p>I liken this model of luckiness to a "catchment area" (<a href="https://en.wikipedia.org/wiki/Catchment_area">a term from urban and hydrological geography</a>). Luck is still randomly occurring, but you can position yourself in a way that captures more of it:</p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/ogbkk8weenqb9nltrl34.png" alt="Alt Text">
  </p>
  <p>Jason has a really simple model of how to grow your LSA - do more things, and tell more people about it. <strong>Doing and Telling</strong>. Already this embodies a more active attitude toward how you can orient your life for more positive random events. It's "<a href="https://www.brainpickings.org/2014/01/29/carol-dweck-mindset/">Fixed vs Growth mindset</a>" adapted for luck.</p>
</section>
<section>
  <h2 id="four-kinds-of-luck"><a href="#four-kinds-of-luck">Four Kinds of Luck</a></h2>
  <p>A parallel, older school of thought dates back to James Austin in 1978 and was repopularized by <a href="https://pmarchive.com/luck_and_the_entrepreneur.html">Marc Andreesen</a> in 2007, then <a href="https://twitter.com/nivi/status/1094940675353784320?lang=en">Naval and Nivi</a> a decade later.</p>
  <p>Here, there are no helpful visuals. James Austin just gives a list of types, and Marc quotes verbatim. <a href="https://twitter.com/naval/status/1093981014920052736">Naval summarizes</a> the 4 kinds of luck as such:</p>
  <blockquote>
    <ol>
      <li>
        <p>Hope luck finds you.</p>
      </li>
      <li>
        <p>Hustle until you stumble into it.</p>
      </li>
      <li>
        <p>Prepare the mind and be sensitive to chances others miss.</p>
      </li>
      <li>
        <p>Become the best at what you do. Refine what you do until this is true. Opportunity will seek you out. Luck becomes your destiny.</p>
      </li>
    </ol>
  </blockquote>
  <p>I've quoted this many times to friends and always had trouble remembering what the 4 types are. I gave it some thought and visualized/organized it as such:</p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/5ycsicfgoxsvxoyys5ip.png" alt="Alt Text">
  </p>
  <ol>
    <li>
      <p><strong>🌱 Accidental Luck</strong>: You have the same luck as a plant. A plant does not move. Whether or not a plant does well pretty much just depends on where it's seed lands. It's not very interesting since by definition you can't do anything about it, but ofc privilege plays a huge part.</p>
    </li>
    <li>
      <p><strong>🏃🏽‍♀️ Active Luck</strong>: The luck you get from constantly moving around. There's no particular direction in mind, but you're more likely to find something good if you move around and explore instead of stay put and hope. You're more likely to roll a 6 if you roll more dice.</p>
      <blockquote>
        <p>"I have never heard of anyone stumbling on something sitting down." - <a href="https://due.com/blog/keep-going-charles-f-kettering/">Charles Kettering</a></p>
      </blockquote>
      <blockquote>
        <p>"You don’t get extreme results without extreme actions." - <a href="https://sive.rs/extremex">Derek Sivers</a></p>
      </blockquote>
    </li>
    <li>
      <p><strong>💊 Prepared Luck</strong>: The luck you get from noticing that something lucky has happened, that most would miss. The canonical story on this is Alexander Fleming's discovery of penicillin, which was a huge medical breakthrough. The discovery was a total accident (some mold happened to fall in the right spot + Fleming happened to see it + he had a similar experience that was a nonevent 9 years ago), but Fleming was not only "uniquely equipped to observe it" by his background, he took action to confirm the observation.</p>
      <blockquote>
        <p>"Luck is what happens when preparation meets opportunity." - Seneca</p>
      </blockquote>
      <blockquote>
        <p>"Chance favors the prepared mind." - Louis Pasteur</p>
      </blockquote>
      <blockquote>
        <p>"Richard Feynman was fond of giving the following advice on how to be a genius. You have to keep a dozen of your favorite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps. Every once in a while there will be a hit, and people will say: “How did he do it? He must be a genius!”" - <a href="http://themattheweffect.org/tag/richard-feynman/">Gian-Carlo Rota</a></p>
      </blockquote>
    </li>
    <li>
      <p><strong>🧲 Magnetic Luck</strong>: <em>"Chance IV comes to you, unsought, because of who you are and how you behave."</em> All sources call it "individualized action" but I've renamed it "magnetic luck" to emphasize the end result rather than how you get there. I'm quite familiar with this as <a href="https://www.swyx.io/writing/learning-gears/#miner">the "Miner" gear of my Learning Gears</a> terminology (since updated to 4 gears in <a href="https://learninpublic.org/">my book</a>). This was already a thing pre-Internet, but search and social media have given tremendous reach and influence to the oddballs and obsessives that become the spiritual leaders of every idea and purpose both big and niche.</p>
    </li>
  </ol>
  <p>I find the 4 of these hard to remember, so I've organized them along two axes - <strong>active vs passive</strong>, and <strong>general vs individual</strong>. The first axis is the same realization as "Luck Surface Area" - you actually have the power to do things to create more luck than you were given.</p>
  <p>The second axis is the insight - that there are forms of luck that apply to everyone, and there are forms of luck that are available only to someone in your unique position. There is a you-shaped hole in the universe and you can either passively occupy it or you can become a beacon for some idea or purpose.</p>
</section>
<section>
  <h2 id="habits-and-strategy"><a href="#habits-and-strategy">Habits and Strategy</a></h2>
  <p>I of course find the Four Kinds of Luck very appealing, since I've quoted it so much to friends that I'm writing this post at all. But upon closer reading I think there's a <em>slightly</em> different direction that is unaddressed by the Four Kinds (I originally thought this was embedded in the Four Kinds, only to discover that it wasn't in the source material and I had completely read my own thinking into it).</p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/poue5zg9homy1eo4ml05.png" alt="Alt Text">
  </p>
  <p>This model differs in two ways. It treats both axes as a spectrum rather than a 2x2. It also focuses more on <strong>actions</strong> (you can take) rather than <strong>classification</strong> (which are a little more abstract). I've also swapped out "Active vs Passive" for "Active Habits" and "Individual vs General" for "Good Strategy". So my version is more about HOW you get more lucky. It's not very actionable to be "more magnetic", but you can Claim a Domain or Hustle and have a good sense of what those things entail.</p>
  <p>I've written about a few of these ideas in prior posts so I won't elaborate:</p>
  <ul>
    <li><a href="https://www.swyx.io/writing/marketing-yourself/">Claiming a Domain, Personal Branding</a></li>
    <li>"Copywork" I wrote about in the "Clone Open Source Apps" chapter of the book</li>
  </ul>
  <p>I think <strong>Exploring</strong> and <strong>Prospecting</strong> are worth elaborating here.</p>
  <p><strong>Exploring</strong> (and to a lesser extent Grinding and Copywork) are <strong>Actively Habitual, non Strategic</strong> activities. But this doesn't mean it is bad. I think this is what you do when you take in general life and career advice and apply them to yourself. You know there are a list of <strong>Principles</strong> which are just generally good things to do in life, and trust that you will do well if you do those things (e.g. <a href="https://www.swyx.io/writing/learn-in-public/">Learn in Public</a>). Keep doing the "right" things, and "trust the process".</p>
  <p><strong>Prospecting</strong> is a term I've <a href="https://en.wikipedia.org/wiki/Prospecting">borrowed from the oil exploration industry</a>. <strong>Prospecting is a highly Active habit, and highly Strategic.</strong> These days, when you look for oil, there is a whole science to handicapping whether or not a plot of land is likely to have oil. You don't know it for a fact, all you're doing is estimating probabilities. Not to get too tautological, but you will be luckier if you can consistently assess and move towards areas where you are more likely to be "lucky". It might look like luck to others, but the motion and intention you invested to get yourself in a position to be lucky was far from random. I've also written many times about how I think strategic <a href="https://www.google.com/search?&amp;q=swyx.io+%22megatrends%22&amp;oq=swyx.io+%22megatrends%22">manoeuvring for "Megatrends"</a> is a good idea.</p>
</section>
<section>
  <h2 id="in-summary"><a href="#in-summary">In Summary</a></h2>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/5075sq79y4pstxpp4pdk.png" alt="Alt Text">
  </p>
  <p>This is the state of my thinking on luck right now. That last bit you just read is pretty fresh, I might come back and change this in a couple years when I have refined my thoughts. I welcome any and all feedback.</p>
  <p>But overall, the message I really want to leave you with is this: <strong>you can create luck</strong>. That's it. I don't care how you do it, what mental model you use, who you quote. I just care <em>that</em> you do it. <strong>Go make yourself more lucky.</strong></p>
  <blockquote>
    <p>Ordinarily I'd wish you good luck, but now you have something better than a mere wish 😂</p>
  </blockquote>
</section>
<section>
  
  <ul>
    <li>The Serendipity Mindset: The Art and Science of Creating Good Luck (<a href="https://www.amazon.com/gp/product/B0818ZH58R/ref=as_li_tl">Book</a>, <a href="https://www.artofmanliness.com/articles/podcast-662-the-art-and-science-of-creating-good-luck/">Podcast</a>)</li>
    <li><a href="https://www.perell.com/blog/serendipity">How to Maximize Serendipity</a> by David Perell</li>
    <li><a href="https://modernwisdom.libsyn.com/269-richard-meadows-optionality-how-to-make-your-own-luck-in-life">Richard Meadows - Optionality: How To Make Your Own Luck In Life</a></li>
  </ul>
</section>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/create_luck/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25985474</guid>
            <pubDate>Mon, 01 Feb 2021 04:17:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s time for a new, progressive supply-side economics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25984996">thread link</a>) | @apsec112
<br/>
January 31, 2021 | https://www.thecgo.org/news/its-time-for-a-new-progressive-supply-side-economics/ | <a href="https://web.archive.org/web/*/https://www.thecgo.org/news/its-time-for-a-new-progressive-supply-side-economics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article id="post-15709">
<section>
<p><img src="https://www.thecgo.org/wp-content/uploads/2021/01/Benchmark-its-time-for-a-new-Supply-side-economics-1068x396-c-default.jpg" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://www.thecgo.org/wp-content/uploads/2021/01/Benchmark-its-time-for-a-new-Supply-side-economics-1068x396-c-default.jpg">
</p>
<div>
<h2>We need productivity improvements in the sectors that disproportionately affect the&nbsp;poor</h2>
<p>Supply-side economics has a dirty reputation. Since the late 1970s, the term has been associated with “trickle-down” economics: the now-defunct theory that cuts in the highest tax brackets would boost economic productivity so much that government revenue would increase and all of society, even the poor, would benefit.</p>
<p>The trickle-down theory is all but dead, but there is more to the supply side of the economy than taxes. Thousands of government decisions affect real output and economic productivity. A new supply-side economics would recognize that productivity growth is the right target, but it would reject tax policy as the primary means of stimulating productivity. Instead, it would examine how everything government does — from permitting to procurement — could be improved to increase productivity.</p>
<p>In contrast with the old supply-side economics, this approach could be progressive from the outset. Productivity growth has stagnated for decades, with a particularly sharp decline for the last 15 years. What little productivity growth we have experienced has been uneven — there have been many productivity improvements in television manufacturing and few in hospital services, as Mark Perry’s <a href="https://www.aei.org/carpe-diem/chart-of-the-day-or-century-5/" target="_blank" rel="noopener" data-href="https://www.aei.org/carpe-diem/chart-of-the-day-or-century-5/">famous chart</a> shows.</p>
<figure><img src="https://cdn-images-1.medium.com/max/800/0*963226iwV9_Z3HHo" data-image-id="0*963226iwV9_Z3HHo" data-width="1214" data-height="1406" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></figure>
<p>These productivity changes are not neutral with respect to the distribution of income. Some high-cost items impose an especially large burden on the budgets of the poor. If we could increase productivity growth in particular sectors, we would reduce real income inequality. Doing so would also unambiguously grow the size of the overall economy.</p>
<p>What are the sectors where productivity gains would have the biggest progressive effect? A look at the Bureau of Labor Statistics’s Consumer Expenditure Surveys, particularly its <a href="https://www.bls.gov/cex/2019/combined/decile.pdf" target="_blank" rel="noopener" data-href="https://www.bls.gov/cex/2019/combined/decile.pdf">table on income deciles</a>, can help us figure that out.</p>
<h2>Shelter</h2>
<p>By far, the biggest share of the lowest income decile’s consumer expenditures go to housing, and specifically shelter (as opposed to other household expenses such as household operations, housekeeping supplies, or furnishings that all fall under BLS’s housing category). Much has been made about NIMBYism, zoning reform, and the need to decrease housing costs. This emphasis is completely warranted from a progressive supply-side perspective. The lowest decile spends 25.8 percent of its budget on shelter, whereas the top decile spends 17.7 percent. A decrease in the cost of shelter would, therefore, disproportionately benefit the poorest in America.</p>
<figure><img src="https://cdn-images-1.medium.com/max/800/0*KGzix8fAQ2LagqkT" data-image-id="0*KGzix8fAQ2LagqkT" data-width="1600" data-height="1164" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></figure>
<p>Progressive supply-siders, therefore, must continue to unite against excessive zoning and NIMBYism. We need to build a lot more housing to drive down its cost. And we must support new and innovative building methods (like Cover’s LEGO-like <a href="https://buildcover.com/product/building-system" target="_blank" rel="noopener" data-href="https://buildcover.com/product/building-system">building system</a>) that leverage economies of scale in construction. A victory on housing productivity would result in hundreds of extra dollars a month in the pockets of the poor.</p>
<p><iframe src="https://player.vimeo.com/video/343493885?title=0&amp;byline=0&amp;portrait=0" width="640" height="360" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p><a href="https://vimeo.com/343493885">Cover’s Building System</a></p>
<h2>Energy</h2>
<p>The three lowest income deciles spend between 8.7 and 8.9 percent of their budgets on what the BLS calls “utilities, fuels, and public services.” This category includes energy — natural gas, electricity, and heating oil — as well as telephone service and a catchall “water and other public services.” More than half of the category lies in the three energy items.</p>
<figure><img src="https://cdn-images-1.medium.com/max/800/0*9Kua433F5y6OkWDm" data-image-id="0*9Kua433F5y6OkWDm" data-width="1600" data-height="1164" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></figure>
<p>We are fortunate in the United States to have achieved energy independence through the shale oil boom. The boom has resulted in ultra-cheap natural gas, which is basically a waste product from the search for petroleum. US electricity prices are a fraction of what they are in Europe. But even so, we have not realized the 1950s-era goal of clean energy too cheap to meter. Instead, we have moderated our per-capita energy consumption, as shown in this chart from J. Storrs Hall’s book, <em>Where’s My Flying Car?</em></p>
<figure><img src="https://cdn-images-1.medium.com/max/800/0*1GRx9e3NBMn9JoaU" data-image-id="0*1GRx9e3NBMn9JoaU" data-width="1600" data-height="878" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></figure>
<p>The falling cost of wind and solar electricity combined with my favorite energy technology, <a href="https://www.vox.com/energy-and-environment/2020/10/21/21515461/renewable-energy-geothermal-egs-ags-supercritical" target="_blank" rel="noopener" data-href="https://www.vox.com/energy-and-environment/2020/10/21/21515461/renewable-energy-geothermal-egs-ags-supercritical">advanced geothermal energy</a>, could unlock significantly cheaper energy costs, as well as zero carbon dioxide emissions. The low cost of clean energy would have ramifications not only for the pocketbooks of the poor but also throughout the entire economy.</p>
<h2>Food at&nbsp;home</h2>
<p>Another major line item in the budgets of the lower income deciles is food. All deciles spend about the same percentage of their budget on food away from home — the numbers vary from 5.1 to 5.9 percent. Where the deciles differ is on food at home. The lowest deciles spend 9.7 percent of their total expenditures on food at home, whereas the top decile spends 5.2 percent.</p>
<figure><img src="https://cdn-images-1.medium.com/max/800/0*_CQyuU-3avch6wTC" data-image-id="0*_CQyuU-3avch6wTC" data-width="1600" data-height="1164" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></figure>
<p>Food and beverage inflation has increased in the past two decades nearly as much as housing inflation. As the data shows, this budget item hits the poorest the hardest. Through innovation in vertical farming, lab-grown meat, and the energy technologies mentioned in the previous section, we could reduce the cost of groceries and increase the level of nutrition available for any spending level. Cheaper healthy food options could reduce obesity, a condition <a href="https://diabetes.diabetesjournals.org/content/60/11/2667" target="_blank" rel="noopener" data-href="https://diabetes.diabetesjournals.org/content/60/11/2667">disproportionally prevalent</a> among the poor. This food innovation benefits everyone, but it benefits the poor the most.</p>
<h2>Healthcare</h2>
<p>Healthcare is a tricky topic to evaluate from the Consumer Expenditure Surveys, as the surveys only capture costs borne by consumers — their personal portion of the cost of health insurance as well as out-of-pocket medical expenses. It doesn’t include the employer portion of health insurance or the contribution of programs like Medicaid, nor does it include services paid for by insurance. Total <a href="https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/NationalHealthExpendData/NationalHealthAccountsHistorical" target="_blank" rel="noopener" data-href="https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/NationalHealthExpendData/NationalHealthAccountsHistorical">national health expenditures</a>, if we include all of the above, would be 17.7 percent of GDP.</p>
<p>Yet even in personal and out-of-pocket medical expenditures, there is a clear trend suggesting that health innovation would benefit the poor the most. The second income decile spends 11.3 percent of its budget on these health expenses, while the top decile spends 6.6 percent. The first decile may spend less than the second because its household members are younger and healthier — people in the second decile are twice as likely to be elderly than those in the first.</p>
<figure><img src="https://cdn-images-1.medium.com/max/800/0*IkmKcN7Y6D8VxlDU" data-image-id="0*IkmKcN7Y6D8VxlDU" data-width="1600" data-height="1164" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></figure>
<p>We badly need health innovation to drive down costs. As <a href="https://fortune.com/2020/12/30/anti-aging-research-health-care-spending-biden/" target="_blank" rel="noopener" data-href="https://fortune.com/2020/12/30/anti-aging-research-health-care-spending-biden/">I argued in <em>Fortune</em></a>, research on biological aging could lead to longer healthspans, compressed morbidity, reduced chronic disease prevalence, and lower medical expenditures. Additionally, consumer medical devices could lower the cost of high-quality medical monitoring, replacing the annual physical with continuous observation of health indicators. With better monitoring, serious conditions could be detected earlier, when they are cheaper to address. Other breakthroughs in biology, like mRNA vaccines and computer-simulated protein folding, could lead to quicker and less expensive cures for virtually every disease.</p>
<h2>Putting it all&nbsp;together</h2>
<p>Combining these four elements — shelter, utilities, food at home, and direct healthcare expenditures — adds up to a lot. Together, they make up 52.7 percent of the first decile’s total expenditures and 53.1 percent of the second decile’s. For the top decile they account for only 33.8 percent of expenditures. Innovation in these sectors, then, directly and disproportionately benefits the poorest in America.</p>
<p>A progressive supply-side agenda, therefore, would target productivity growth in the necessities that make up over half the budget of the poor. Through smarter regulation and entrepreneurial policy, we can drive down the cost of these goods and increase the real standard of living at the bottom of the income distribution.</p>
<p>To be sure, a supply-side approach is a complement, not a substitute, for many government transfer programs. Even so, the potential of progressive supply-side policy exceeds that of transfers over the long run. Total annual expenditures for the first income decile average $25,856. A 10 percent across-the-board increase in productivity — less than five years’ economic growth in the 1960s or the late 1990s — would be worth $2,586 per year to these households, twice the average value of direct public assistance as reported in the survey. A progressive approach that targeted productivity improvements specifically to necessities could do even better, as would productivity gains that compounded over a longer period of time. In addition, progressive supply-side policy could “trickle up” to provide gains in the rest of the income distribution, a benefit worth considering.</p>
<p>As necessary as government transfers are, the policy conversation has overrelied on them. Need to stimulate the economy? Write people checks. Have a poverty problem? People won’t be poor if we send them enough checks. Global pandemic? Checks. These demand-side policies have their virtues — they are simple to implement and they often at least partially achieve their goals.</p>
<p>But for true prosperity across the income distribution, we need a more creative supply-side approach. We policy wonks need to do the hard work of finding policies that increase productivity growth, particularly for those goods and services consumed disproportionately at the bottom of the income distribution.</p>
</div>
<p>
CGO scholars and fellows frequently comment on a variety of topics for the popular press. The views expressed therein are those of the authors and do not necessarily reflect the views of the Center for Growth and Opportunity or the views of Utah State University.
 </p>
</section>
</article>
</div></div>]]>
            </description>
            <link>https://www.thecgo.org/news/its-time-for-a-new-progressive-supply-side-economics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25984996</guid>
            <pubDate>Mon, 01 Feb 2021 02:49:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That’s Big Sir to You]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 49 (<a href="https://news.ycombinator.com/item?id=25984970">thread link</a>) | @zdw
<br/>
January 31, 2021 | https://www.shirtpocket.com/blog/index.php/shadedgrey/thats_big_sir_to_you/ | <a href="https://web.archive.org/web/*/https://www.shirtpocket.com/blog/index.php/shadedgrey/thats_big_sir_to_you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Hey, folks. Sorry it's been a while, but it's been a busy time. Let's start with the bad news first.</p>

<h2>Bad news</h2>

<p>As you know, SuperDuper 3.3.1 cannot copy a volume with Big Sur on it. We're currently blocked on some issues I don't have direct control over, and as such I don't have a new version for you that <strong>fully</strong> supports Big Sur, nor a timeframe for when that will be released.</p>

<p>Right now, as many of you know, v3.3.1 <strong>will</strong> work with non-boot volumes, but it <strong>won't</strong> work with volumes that have macOS on them, because it will try to do some of the things that no longer work in macOS 11.</p>

<p>I know that's been a disappointment, but that's where we are with v3.3.1.</p>

<h2>Good news!</h2>

<p>However, after wracking my brain for <strong>far</strong> too long, I've come up with a <strong>workaround</strong> that will let you make the backups you need to save your files, and to supplement your Time Machine backup. And for that, we need to go Back...to the Future!</p>

<h2>Huh?</h2>

<p>Let me try to explain.</p>

<p>In Catalina, as I explain in <a href="https://www.shirtpocket.com/blog/index.php/shadedgrey/comments/breaking_the_tape/">Breaking the Tape</a>, Apple split the startup volume into two parts: the System volume and the Data volume. We did a ton of work that year to support this new setup in a way that was transparent to the user; SuperDuper automatically creates the proper volumes, converts the drives to APFS as needed, etc.</p>

<p>Worked great.</p>

<p>In macOS 10.15.5, though, <a href="https://www.shirtpocket.com/blog/index.php/shadedgrey/comments/black_boxes_and_bugs/">Apple broke 3rd party copy tools</a> in a way that couldn't be worked around without the use of <code>asr</code>, a low-level drive copy tool that has its own issues. They fixed that in 10.15.6...but it was a rather ominous sign for the future.</p>

<p>That ominous sign became terrifying reality in macOS 11. Due to the new Sealed System Volume, use of <code>asr</code> became mandatory if you wanted to make a copy that was bootable. And even <strong>that</strong> didn't work <strong>at all</strong> until <a href="https://www.shirtpocket.com/blog/index.php/shadedgrey/comments/big_sur/">November 5th</a> of last year—just before Big Sur's official release.</p>

<p>Even now, as of the time of this writing, <code>asr</code> won't make a bootable copy of an M1-based Mac.</p>

<p>So, as of Big Sur, 3rd party tools like SuperDuper can no longer make bootable copies on their own. For that, it's <code>asr</code> or nothing.</p>

<p>It is, indeed, <a href="https://mjtsai.com/blog/2007/06/13/a-very-sweet-solution/">a <em>very</em> <strong>sweet solution</strong></a>.</p>

<p>But, 3.3.1 doesn't know that. It tries to do all the special stuff that we had to do for Catalina, and those things no longer work. And so, as you've seen, that copy generates errors or seems to hang right at the start (because it's thrown exceptions that stop the copy).</p>

<h2>Didn't You Say "Good News"?</h2>

<p>I'm getting there.</p>

<p>SuperDuper! 3.3.1's magic was all about dealing with the split startup volume. It built on the APFS support and scheduling fixes we put into the previous version...and added new things for compatibility with Catalina.</p>

<p>But...what if it <strong>didn't</strong> do that? What if SuperDuper was...<strong>stupider</strong>?</p>

<h2>Wonderfully Awful</h2>

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/oUUdW2bTa3Y" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>I've been testing this out for a while in-house. and I've come up with a weird-sounding workaround that...works!</p>

<p>Basically, you can use SuperDuper to copy the Data volume of the volume group. The result contains all <strong>your</strong> data and applications, can be restored in a few different ways...and can even be made bootable.</p>

<blockquote>
  <p>Note that, as I indicated above, M1 Macs <strong>can't readily boot from external drives</strong>. There are things you can do, if you have an external Thunderbolt 3 drive (USB-C isn't sufficient), but even that won't work if the internal drive is dead. Unless things change, bootable backups are basically a thing of the past on M1-based Macs.</p>
</blockquote>

<h2>How?</h2>

<p>It's actually easy. To accomplish this, use an old version of SuperDuper—<a href="https://www.shirtpocket.com/downloads/SuperDuper!+3.2.5.dmg">specifically, v3.2.5</a>—to copy the Data volume, which is shown in the older version!</p>

<p>v3.2.5 is well tested, having been on the market for quite some time, and is reliable. So we don't have to worry about doing a broad beta test of a partially complete new release. It's already tested, and I've been busy doing the additional testing necessary to prove it works on Big Sur.</p>

<p>Again, this will make a copy of the data that you need to preserve <strong>your</strong> stuff, both Applications and Data, while leaving the Sealed System Volume alone.</p>

<p>And it's a valid source for "restore" during a clean install or migration! So restoration is <strong>easy</strong> and <strong>fast</strong> should it become necessary.</p>

<h2>Neat!</h2>

<p>Yeah, I wish I had thought of this earlier.</p>

<p>So, if you're on Big Sur, and you want to copy a startup drive, here's what to do:</p>

<ol>
<li>Make sure you have your license information handy. You can retrieve it from SuperDuper's Register... page should you need to.</li>
<li>Download and install <a href="https://www.shirtpocket.com/downloads/SuperDuper!+3.2.5.dmg">SuperDuper! v3.2.5 from here</a>.</li>
<li>Remove SuperDuper! from the Security &amp; Privacy preference pane and restart your Mac. This is important, and works around an Apple bug triggered by the change of SuperDuper!'s bundle ID.</li>
<li>Run SuperDuper and follow the steps to add it back into Security &amp; Privacy.</li>
<li>If your license is missing, re-enter it from your license email. </li>
<li>Turn off "Check for Updates" in our Preferences so we don't nag you about v3.3.1.</li>
<li>Select the "Data" volume in the source pop-up, and a <strong>new</strong> APFS backup volume in the destination pop-up, along with "Backup - all files" (or whatever script you want).
&gt; If you already have a backup volume, you can use Disk Utility to delete <strong>just</strong> the System volume, rather than create a new one. After doing this, you may need to repair it with Disk First Aid before it will show up in SuperDuper.</li>
<li>Make your copy as normal, set up your schedule as needed, etc. Your regular Smart Updates will work as expected.</li>
</ol>

<p>To fully restore, it's easiest to boot to recovery, erase the internal drive you want to restore to, <a href="https://support.apple.com/en-us/HT204904">reinstall the OS from Recovery mode</a>, and then, when prompted to restore during the first boot of the fresh copy of macOS, point at the backup. All your data and applications will be brought in automatically.</p>

<blockquote>
  <p>If you want to make the backup bootable and have an Intel Mac, boot to Recovery (Cmd+R during power on) and install Big Sur to the backup drive. You can then start up from the backup. Note, though, that once made bootable, you can no longer copy <strong>to</strong> the backup until you delete the system volume as above. So <strong>don't</strong> do this unless you need to.</p>
</blockquote>

<h2>Forward-Looking Statements</h2>

<p>It seems clear that the future of bootable backups is unclear.</p>

<p>M1 Macs <strong>can't</strong> be copied in a way that makes them bootable. Bare metal recovery on an M1 Mac isn't possible, since they depend on the contents of their internal drive even when booting externally. And the tools required to make bootable copies of Intel Macs are limited, often fail, and produce inscrutable and undocumented diagnostics when they do.</p>

<p>Everything's a tradeoff, and with the M1 Macs, Apple has given us an amazing new platform, while taking away some of the things that made macOS such a joy to work with. And one of those things is bootable backups.</p>

<p>I have <strong>no idea</strong> if this is going to change for the better in whatever the next macOS version brings, and have no insight into Apple's future plans.</p>

<p>But I <a href="https://www.shirtpocket.com/blog/index.php/shadedgrey/comments/practices_make_perfect_backups/">continue to advise multiple backup strategies</a>, including Time Machine (to an APFS volume under Big Sur), SuperDuper! (for a simple copy of your data and applications) and an online backup program (as a last resort).</p>

<p>With that, back to plugging away at a new version.</p>

<p>Thanks for reading, and for using SuperDuper.</p>

</div></div>]]>
            </description>
            <link>https://www.shirtpocket.com/blog/index.php/shadedgrey/thats_big_sir_to_you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25984970</guid>
            <pubDate>Mon, 01 Feb 2021 02:43:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 and the Global Shift Towards Authoritarian Governance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25984929">thread link</a>) | @mrfusion
<br/>
January 31, 2021 | http://asenseofplacemagazine.com/covid-19-and-the-global-shift-towards-authoritarian-governance/ | <a href="https://web.archive.org/web/*/http://asenseofplacemagazine.com/covid-19-and-the-global-shift-towards-authoritarian-governance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://asenseofplacemagazine.com/covid-19-and-the-global-shift-towards-authoritarian-governance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25984929</guid>
            <pubDate>Mon, 01 Feb 2021 02:32:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ariane is just like a web browser but for browsing 'Geminispace']]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25984902">thread link</a>) | @gaius_baltar
<br/>
January 31, 2021 | https://oppen.digital/ariane/ | <a href="https://web.archive.org/web/*/https://oppen.digital/ariane/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://oppen.digital/ariane/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25984902</guid>
            <pubDate>Mon, 01 Feb 2021 02:25:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I Built Conway's Game of Life for Ethereum]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25984884">thread link</a>) | @basicallydan
<br/>
January 31, 2021 | https://danhough.com/blog/conways-game-ethereum/ | <a href="https://web.archive.org/web/*/https://danhough.com/blog/conways-game-ethereum/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<header>
			
			<p>
				<span>Published 31 January 2021 in Vancouver, Canada</span>
				
				<span title="It took me about 7 minutes to read this blog post back to myself.">(~7min read)</span>
				
			</p>
		</header>
		<p>Want to see it??<br>➡️ Visit <a href="https://conwaysgame.github.io/solidity-ethereum/">Conway’s Game of Life for Ethereum</a>.</p>

<p>Since 2014 I have been slowly (very slowly) building <a href="https://github.com/conwaysgame/">implementations of Conway’s Game of Life for different programming languages and technologies</a>.</p>

<p>Most recently I set out to write a version of the Game of Life which “runs on Ethereum”. In other words, it’s a Smart Contract. In other words, it’s a Distributed App (Dapp). In other words, it’s a small application written in Solidity. There are many ways to describe it but the coolest way, in my opinion is, “it’s Conway’s Game of Life for Ethereum.”</p>

<figure>
	
	<img src="https://media.giphy.com/media/iuAP1ssht7ufmaxLmo/source.gif" title="Here's a transaction taking place." alt="Here's a transaction taking place.">
	
	
	<figcaption>Here's a transaction taking place.</figcaption>
	
</figure>

<h2 id="try-it-out">Try it out</h2>

<p>As I’ll explain later, I decided not to deploy this on the Ethereum main-net, so if you want to play with it, you can do so using the Rinkeby Test Network - or you can just watch as others do.</p>

<ul>
  <li>Visit <a href="https://conwaysgame.github.io/solidity-ethereum/">the web application</a>.</li>
  <li>See the current state of the world.</li>
  <li>(Optional) Get some ETH from the <a href="https://faucet.rinkeby.io/">Rinkeby Faucet</a>.</li>
  <li>Transfer 0.00001 ETH to the contract address (and pay the gas charge) listed on the page<br>(you can do this easily via MetaMask, or just manually).</li>
  <li>Check the web app again, the state of the world should have changed.</li>
</ul>

<p>I’d recommend also installing <a href="https://chrome.google.com/webstore/detail/metamask/nkbihfbeogaeaoehlefnkodbefgpgknn?hl=en">MetaMask</a>, or using <a href="https://brave.com/">Brave</a> as your browser, in order to make transactions more easily.</p>

<hr>

<h2 id="howd-i-do-it">How’d I do it?</h2>

<p>I started by completing <a href="https://techbrij.com/hello-world-smart-contract-solidity-ethereum-dapp-part-1">a Hello World tutorial by Brij Mohan</a>, and then started from scratch with a new project. This involved using Truffle, a CLI to help with writing and interacting with smart contracts and Ganache, a personal ethereum blockchain (for much quicker development), among some more common JavaScript tools.</p>

<p>I did it entirely using TDD, so I wrote my tests first (in JavaScript, thank goodness) and then slowly but surely implemented the rules of the game.</p>

<p>I’ve written many Games of Life, but this was the most challenging.</p>

<h2 id="challenges">Challenges</h2>

<h3 id="unforgiving">Unforgiving</h3>

<p>Before starting, I vaguely knew that the more work my contract did, the more ‘expensive’ it was to run. So I focused on trying to make it efficient. Normally when implementing the game of life, I create a two-dimensional array to represent the world, loop through all the possible neighbours of each cell and I check if it is on or off the grid. With the languages I’ve used so far this is straightforward: many allow signed, negative integers for indexes and automatically allocate memory, and often won’t complain if I’m referencing an element which doesn’t exist.</p>

<p>With Solidity, I tried to make sure I wasn’t going to even <em>try</em> to reference a position in the grid that didn’t exist (such as <code>-1</code>), since I’d then need to handle an error. It’s definitely better to <em>avoid</em> an error here.</p>

<p>In an effort to make my contract more efficient, I tried to avoid allocating too much memory for a number, e.g., 16 bits when all I needed was 8. I also tried to avoid switching between byte arrays and strings, when replacing the old world with the new one, so that less casting would be necessary.</p>

<p>Thanks to some very helpful compilers and interpreters doing most of this work for me, my usual programming work (mostly JavaScript) doesn’t often involve quite so much decision-making around integer sizes. This was surprisingly fun and a very different challenge than usual.</p>

<h3 id="deployment---too-much-gas">Deployment - too much Gas?!</h3>

<p>After I got it all working, I started learning more seriously about the cost of Ethereum transactions. It turns out that despite all this thought about performance and the runtime cost, I had inadventedly made my contract expensive even to deploy onto a network.</p>

<p>Ethereum has this concept of “gas.” Each time you perform a transaction of any kind (send ETH, deploy smart contract, interact with smart contract, etc) the initiating party must offer some ETH to the various miners on the network whose hardware processes the transactions. “One gas” is worth an amount in “Gwei”, which is a denomination of the currency worth 0.000000001 ETH. That amount can be set by the person initiating, but the recommended price is a value which fluctuates based on supply and demand.</p>

<p>With all of this in mind, I decided to find out how much it might cost to deploy in a fiat currency such as the US Dollar. I opened up <code>truffle console</code> to estimate the gas by running <code>ConwaysGameOfLife.new.estimateGas()</code>, looked up how much 1 gas would be on the main-net at <a href="https://ethgasstation.info/">https://ethgasstation.info/</a>, and found out the rate of ETH to USD. This is how I worked out the cost.</p>

<div><div><pre><code>gasPrice = 145                        # Obtained from ethgasstation
gasTxCost = 722539                    # Obtained using `estimateGas()`
ethToUSDPrice = 1305.33               # Obtained from Google
costInGwei = gasPrice * gasTxCost     # =&gt; 104768155
costInETH = costInGwei * 0.000000001  # =&gt; 0.104768155
costInUSD = costInETH * ethToUSDPrice # =&gt; $136.76
</code></pre></div></div>

<p>That’s $136.76 USD at the time of writing. This is hypothetical, until I decide to deploy to the main-net.</p>

<p>To me, for a fun little project which probably nobody would use, that price was too high. I don’t know how much I’d be willing to spend, but $136.76 is too much.</p>

<p>I Googled how to improve the efficiency of a contract’s deployment and found <a href="http://article.nadiapub.com/IJGDC/vol10_no12/6.pdf">this little paper</a>. So I got rid of some variables and hard-coded the values instead, among other changes. With each change, I’d run <code>truffle compile</code> and <code>estimateGas()</code>.</p>

<p>First, I got it down to <strong>708,354 gas</strong>, then <strong>644,904 gas</strong>. Then it went up again to <strong>695,936 gas</strong>; some things I did made it worse. Unintuitively, using larger integer types such as <code>uint</code> (256 bits) instead of smaller (<code>uint8</code>) reduces gas costs.</p>

<p>I also experimented with increasing the size of the world from 5x5 to 10x5. That brought the deployment price up to <strong>652,508 gas</strong> and the transaction price to <strong>106,708 gas</strong>. Committing to this, though, would mean re-doing the tests since the size is now hardcoded in the contract. By this point, I had sunk more than enough time into it.</p>

<p>In the end, I settled on a solution with these hypothetical costs:</p>

<ul>
  <li>Deployment price: <strong>611,944 gas</strong>, which would be equivalent to about $115.82.
    <ul>
      <li>Saving: <strong>110,595 gas</strong>, or $20.93.</li>
    </ul>
  </li>
  <li>Transaction price: <strong>72,213 gas</strong>, which would be equivalent to about $13.66.
    <ul>
      <li>Saving: <strong>298,057 gas</strong>, or $56.41.</li>
    </ul>
  </li>
</ul>

<p>I was happy with this amount of rewriting in order to get a more efficient contract working.</p>

<h3 id="networks">Networks</h3>

<p>I’ve become quite familiar with the concept of “Web 3.0.” In this “version” of the web, everything is distributed across a network rather than centralised in servers and served up to clients. It would appear though that for the time being, the only part of traditional web app which gets distributed is the backend.</p>

<p>In order to interact with this backend from a web browser, I had to install <code>web3</code>, a JavaScript API for Ethereum, which involved a lot of async <code>await</code> statements and polling.</p>

<p>In this world, rather than my backend being located at an IP address, resolved by a domain such as <code>gameoflife.com</code>, it’s located at an Ethereum address which is resolved by a contract name such as <code>GameOfLife</code>, which may or may not be on the specified network.</p>

<p>It’s an interesting paradigm shift, but interacting with it through a web browser currently still involves using traditional HTTP-based servers. Maybe there’s a future where that isn’t the case?</p>

<h2 id="whyd-i-do-it">Why’d I do it?</h2>

<p>The future of cryptocurrency is uncertain, and my feelings about the subject change every day. However, Bitcoin and Ethereum are in the news a lot right now, so it feels relevant. There is a chance there’ll be more demand for smart contracts and developers who know how to work with them in the future. It feels important for me to keep on learning new skills not only to progress my career, but to make life more interesting.</p>

<h2 id="why-not-put-it-on-the-main-net">Why not put it on the main-net?</h2>

<p>As I explained earlier, the gas price for deployment is fairly high. After showing it to a few Ethereum enthusiasts, I came to the conclusion that there was no need to spend the money, buy the ETH and put it on the main-net. There are better uses of this blockchain out there than Conway’s Game of Life. My goal here was experimentation and learning, both of which I achieved with the Rinkeby test network. Oh, and if you come across a contract called <code>ConwaysGameOfLife</code> on the main-net, unless I edit this post and mention it here, it isn’t mine!</p>

<h2 id="reflections">Reflections</h2>

<p>I learned that writing basic Smart Contracts for Ethereum isn’t too tricky - like with any sofware, there’s an input and an output. The challenge, as expected, was getting my environment set up. It wasn’t too difficult to do that, though.</p>

<p>I also learned how one can create an interface between “web 2.0” applications and “web 3.0” applications, and the tooling available for that is pretty decent too. <span id="sendEthBlock">For instance, if I wanted to <a href="#">ask for a donation in ETH I could make it super easy with a JavaScript function</a>.</span></p>

<p>Also, a mind to application performance means a heck of a lot more when the operating cost can be measured in direct, immediate currency transactions, as opposed to a some-time-in-the-future slight increase in AWS fees over time, for example.</p>

<hr>

<p>Remember, you can <a href="https://conwaysgame.github.io/solidity-ethereum/">take a look at Conway’s Game of Life for Ethereum</a> right now. If you’d like to check out the code or maybe make some improvements or raise an issue, <a href="https://github.com/conwaysgame/solidity-ethereum">the code is on GitHub</a> and I’d love to hear from you.</p>

<p>As a final note, I’d like to offer sincere thanks to <a href="https://twitter.com/mr_ligi">ligi</a> for trying it out and offering valuable opinions, as well as Reddit users /u/FrequentMushroom, /u/liberated, /u/Phistofeles, /u/hodak2 and /u/squeeze_tooth_paste for trying it also. I’d also like to thank my very good friends for their keen eyes and candid critique: the ever-encouraging and intelligent <a href="https://twitter.com/jonfinerty">Jon Finerty</a> and <a href="https://twitter.com/yjhda">Matt Lewis</a>.</p>




		<p>Heckle me on Twitter <a href="http://twitter.com/basicallydan">@basicallydan</a>.</p>
	</div></div>]]>
            </description>
            <link>https://danhough.com/blog/conways-game-ethereum/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25984884</guid>
            <pubDate>Mon, 01 Feb 2021 02:23:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Evil in Paradise]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25984274">thread link</a>) | @AndrewBissell
<br/>
January 31, 2021 | https://newsinteractives.cbc.ca/longform/peter-nygard-bahamas-allegations | <a href="https://web.archive.org/web/*/https://newsinteractives.cbc.ca/longform/peter-nygard-bahamas-allegations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
		<article>
						<section>
				
			</section>
						
			<section id="section-1">
				<div>
					<div>
													
							
									<p><strong>WARNING: This story contains graphic content.</strong></p>
<p>One afternoon in 2015, word went out to staff at Peter Nygard's palatial seaside compound in the Bahamas. A meeting between Nygard and a senior politician had the green light. 
</p>
<p>A well-oiled machine comprised of staff members who knew what to do when encounters like these were planned sprang into action. Cash was prepared by accountants. Vehicles were readied. The former Canadian fashion mogul was informed it was time.
</p>
<p>The massive wooden gates at the sprawling estate named for its owner, Nygard Cay, slowly rose to allow a convoy of cars to leave. Nygard would often meet powerful and influential people in the Bahamas under unusual circumstances.
</p>
<p>"I know of the instructions for the accountants to get cash for [Nygard] to take to his private meeting after hours," said a longtime employee, whose identity we are protecting. He still fears retribution from Nygard, and those close to him.
</p>
<ul><li><strong>Watch <a href="https://www.cbc.ca/fifth/">"Peter Nygard: The Secret Videos"</a></strong> on <em>The Fifth Estate</em> and listen to CBC Podcasts' new series about Peter Nygard, <strong><a href="https://www.cbc.ca/listen/cbc-podcasts/475-evil-by-design"><em>Evil By Design</em></a></strong>.</li></ul>
<p>The employee, who worked at Nygard Cay in various roles for nearly eight years starting in 2008, was responsible for directing staff to make arrangements for the meeting. For him, it was a familiar scene. 
</p>
<p>The former employee, and three other sources, describe attempts by Nygard to forge connections at the highest levels in the Bahamas where he is accused of operating an elaborate sex trafficking ring spanning more than two decades, involving dozens of young women and girls, an investigation by the CBC podcast <em>Evil By Design</em> and <em>The Fifth Estate</em> has found.
</p>
<p>"I felt broken, like a piece of me was taken from me," a woman known as Jane Doe No. 1 said in an interview.
</p>
								
																					
							
									
									
									
									
									
									<figure data-src="https://newsinteractives.cbc.ca/craft-assets/images/Jane-Doe-1-revised.jpg">
										<img width="100%" data-srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Jane-Doe-1-revised.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Jane-Doe-1-revised.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Jane-Doe-1-revised.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Jane-Doe-1-revised.jpg 490w" data-sizes="(max-width: 490px) 90vw, 60vw" data-src="https://newsinteractives.cbc.ca/craft-assets/images/Jane-Doe-1-revised.jpg" alt="Jane Doe No. 1 was 14 years old when she says Peter Nygard raped her in 2015. (John Badcock/CBC)" srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Jane-Doe-1-revised.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Jane-Doe-1-revised.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Jane-Doe-1-revised.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Jane-Doe-1-revised.jpg 490w" src="https://newsinteractives.cbc.ca/craft-assets/images/Jane-Doe-1-revised.jpg">
										<figcaption>
											
											Jane Doe No. 1 was 14 years old when she says Peter Nygard raped her in 2015. (John Badcock/CBC)
																						
										</figcaption>
									</figure>

									

																														
							
									<p>She is one of 10 original women who went public in a class-action lawsuit with allegations against Nygard exposing for the first time what was going on behind the gates at Nygard Cay.</p>
<p>According to the suit, filed in New York last February, she was 14 years old when Nygard raped her in 2015.
</p>
<p>Since then, more than 70 additional women have stepped forward with similar allegations. In December, U.S. authorities charged Nygard with nine counts of sex trafficking, sex assault and racketeering involving at least dozens of survivors. He was arrested in Winnipeg on an extradition request. 
</p>
<p>The CBC investigation, involving interviews with 19 women who say they were raped by Nygard and many more conversations with lawyers, private investigators, politicians, local activists and former employees, reveals an elaborate effort to cultivate influence with prominent decision-makers in the Bahamas, silence victims and block anyone who tried to expose him.
</p>
<p>The tactics include payments to senior politicians and police officers in the Bahamas, drugging and holding young women and girls against their will, an alleged campaign of violence against a group of local people who stood up to him and an aggressive legal offensive aimed at the CBC that began investigating reports of sexual misconduct involving Nygard in the Bahamas as far back as 2009.
</p>
								
																					
							
									
									
									
									
									
									<figure data-src="https://newsinteractives.cbc.ca/craft-assets/images/Nygard-and-Lion-edit.jpg">
										<img width="100%" data-srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Nygard-and-Lion-edit.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Nygard-and-Lion-edit.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Nygard-and-Lion-edit.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Nygard-and-Lion-edit.jpg 490w" data-sizes="(max-width: 490px) 90vw, 60vw" data-src="https://newsinteractives.cbc.ca/craft-assets/images/Nygard-and-Lion-edit.jpg" alt="Peter Nygard and Nygard employees are alleged to have used pamper parties at Nygard Cay as a way to recruit woman and girls. (Jonathan Becker/Contour by Getty Images)" srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Nygard-and-Lion-edit.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Nygard-and-Lion-edit.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Nygard-and-Lion-edit.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Nygard-and-Lion-edit.jpg 490w" src="https://newsinteractives.cbc.ca/craft-assets/images/Nygard-and-Lion-edit.jpg">
										<figcaption>
											
											Peter Nygard and Nygard employees are alleged to have used pamper parties at Nygard Cay as a way to recruit woman and girls. (Jonathan Becker/Contour by Getty Images)
																						
										</figcaption>
									</figure>

									

																														
							
									<p>Nygard denies all of the allegations, and says they are lies and part of a conspiracy meant to destroy his reputation spearheaded by his former neighbour in the Bahamas, billionaire Louis Bacon.</p>
<p>For the women who told CBC they were assaulted, Nygard’s methods created a climate where it seemed impossible to come forward against someone who appeared so powerfully connected on the Caribbean island, keeping his alleged campaign of rape and sexual assault in the Bahamas a secret for more than two decades. 
</p>
<p>"The government of the Bahamas gave him a sanctuary in which to operate a criminal sex trafficking ring," said Lisa Haba, one of two U.S. lawyers who is suing Nygard on behalf of survivors. 
</p>
<p>"He uses power, his influence, his brand, to show the world that I am Peter Nygard, and I control everything I touch."</p>
								
																					
							
							</div>
						</div>
					</section>
					
					<section>
						<div>
							<div>
																<h2>I: ‘A corrupter of men’</h2>
								
																					
							
									<p>In 1984, Nygard purchased a modest bungalow on a breathtaking piece of property on the western tip of New Providence island in the Bahamas.</p>
<p>Known as Simms Point for more than 400 years, the piece of Caribbean paradise is surrounded on both sides by the sparkling Atlantic Ocean and is perched at the edge of a wealthy gated community called Lyford Cay.
</p>
<p>Nygard, the Finnish-Canadian founder of a Manitoba-based multimillion-dollar fashion empire, had fallen in love with the Bahamas.
</p>
<p>"We'd been living in Winnipeg … with 40 below [temperatures]. And I'd never been to a warm country in my life," he told a Bahamian TV production in 2008.
</p>
<p>"I saw this beautiful place with beautiful white sand, these beautiful people here. And I said, 'That's for me.' "</p>
								
																					
							
									
									
									
									
									
									<figure data-src="https://newsinteractives.cbc.ca/craft-assets/images/Nygard-Cay-drone-shot-1.jpg">
										<img width="100%" data-srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Nygard-Cay-drone-shot-1.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Nygard-Cay-drone-shot-1.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Nygard-Cay-drone-shot-1.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Nygard-Cay-drone-shot-1.jpg 490w" data-sizes="(max-width: 490px) 90vw, 60vw" data-src="https://newsinteractives.cbc.ca/craft-assets/images/Nygard-Cay-drone-shot-1.jpg" alt="In 1984, Nygard purchased a modest bungalow on the western tip of New Providence island in the Bahamas and turned it into a Mayan-inspired estate called Nygard Cay. (CBC)" srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Nygard-Cay-drone-shot-1.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Nygard-Cay-drone-shot-1.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Nygard-Cay-drone-shot-1.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Nygard-Cay-drone-shot-1.jpg 490w" src="https://newsinteractives.cbc.ca/craft-assets/images/Nygard-Cay-drone-shot-1.jpg">
										<figcaption>
											
											In 1984, Nygard purchased a modest bungalow on the western tip of New Providence island in the Bahamas and turned it into a Mayan-inspired estate called Nygard Cay. (CBC)
																						
										</figcaption>
									</figure>

									

																														
							
									<p>Over the next 20 years, Nygard constructed a 2.4-hectare estate consisting of a series of tree house-type buildings made of rock and glass that jut out over the sea. It has 12 bedrooms, a berth for a 25-metre yacht, pools and jacuzzis carved out of stone, a 21-car garage, tennis courts, volleyball courts, a disco and a movie theatre.</p>
<p>As you approach the compound, tall wooden gates, edged with barbed wire, are under constant surveillance by a series of cameras. From above, a soaring glass roofed structure shaped like a star, known as the main hall, anchors the centre of the property while giant stone lions guard a turquoise lagoon and a vast white sand beach dominates the southern edge of the estate.
</p>
<p>While the natural beauty is striking, it’s a stark contrast to the decades of pain and damage Nygard is accused of inflicting on so many there. 
</p>
<p>The entire compound is styled after a Mayan temple.
</p>
<p>"I've been very careful not to build a Beverly Hills house in the Caribbean," Nygard said in a 2005 legal deposition.
</p>
<p>"It's finally a dream come true that I can do for me and that I can share it with a lot of my friends, the Bahamians."</p>
<p>Indeed, Nygard made influential friends in the Bahamas.</p>
								
																					
							
									<p>In a 1992 letter Nygard sent to a local up-and-coming-politician, he offered a reminder of his "significant" $45,000 pledge to the politician’s party and asked for a series of favours.</p>
<p>The politician at the time was the minister of agriculture, trade and industry in the ruling Progressive Liberal Party, or PLP.
</p>
<p>Nygard wrote that he’d already been "given approval" to extend his property, and that he now wanted to make it a "legal fact." He also asked to officially change the name of his property from Simms Point to Nygard Cay in time for an upcoming shoot with celebrity television show <em>Lifestyles of the Rich and Famous</em>.
</p>
<p>"Obviously, this whole world is based on one hand helping the other," wrote Nygard. "And you know that I am prepared to do whatever is in my capacity to help out the Bahamas and the PLP party and of course yourself in any way I can."</p>
<p>That politician was Perry Christie, who would go on to become prime minister of the Bahamas in 2002. 
</p>
								
																					
							
									
									
									
									
									
									<figure data-src="https://newsinteractives.cbc.ca/craft-assets/images/Loretta-Butler-Turner.JB.JPG">
										<img width="100%" data-srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Loretta-Butler-Turner.JB.JPG 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Loretta-Butler-Turner.JB.JPG 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Loretta-Butler-Turner.JB.JPG 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Loretta-Butler-Turner.JB.JPG 490w" data-sizes="(max-width: 490px) 90vw, 60vw" data-src="https://newsinteractives.cbc.ca/craft-assets/images/Loretta-Butler-Turner.JB.JPG" alt="Former Bahamian opposition leader Loretta Butler-Turner says Nygard was 'a corrupter of men.'  (John Badcock/CBC)">
										<figcaption>
											
											Former Bahamian opposition leader Loretta Butler-Turner says Nygard was 'a corrupter of men.'  (John Badcock/CBC)
																						
										</figcaption>
									</figure>

									

																														
							
									<p>Fast forward to 2011. Christie, now leader of the opposition, was preparing a campaign for a second run at prime minister. </p>
<p>He took time to fly to Winnipeg in July to attend the wedding of Nygard’s daughter. He celebrated there with Nygard's friends and family and the mayor of Winnpeg at the time, Sam Katz.
</p>
<p>Nygard "is a significant personality in the Bahamas, known for his philanthropy, a contributor to those who are in need," Christie said in a speech at the wedding, and then he went on to describe a favour he provided to Nygard.
</p>
<p>"He was having some difficulty with his residency. I was introduced to him and facilitated the granting of that certificate that enabled him to be a resident in the Bahamas."</p>
<p>Later that same year, Christie travelled with Nygard to Las Vegas for a conference. Video from that trip shows Nygard introducing a series of young women to Christie in a hotel suite after a meeting. A photo, obtained by CBC News, shows Nygard and Christie seated between two young women in a restaurant. One of the women has a rolled-up wad of cash in her bra.
</p>
								
																					
							
									
									
									
									
									
									<figure data-src="https://newsinteractives.cbc.ca/craft-assets/images/Christie-and-Nygard-at-restaurant.jpg">
										<img width="100%" data-srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Christie-and-Nygard-at-restaurant.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Christie-and-Nygard-at-restaurant.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Christie-and-Nygard-at-restaurant.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Christie-and-Nygard-at-restaurant.jpg 490w" data-sizes="(max-width: 490px) 90vw, 60vw" data-src="https://newsinteractives.cbc.ca/craft-assets/images/Christie-and-Nygard-at-restaurant.jpg" alt="Nygard and former Bahamian prime minister Perry Christie in a Las Vegas restaurant with two young women. (Submitted by Stephen Feralio) " srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Christie-and-Nygard-at-restaurant.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Christie-and-Nygard-at-restaurant.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Christie-and-Nygard-at-restaurant.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Christie-and-Nygard-at-restaurant.jpg 490w" src="https://newsinteractives.cbc.ca/craft-assets/images/Christie-and-Nygard-at-restaurant.jpg">
										<figcaption>
											
											Nygard and former Bahamian prime minister Perry Christie in a Las Vegas restaurant …</figcaption></figure></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://newsinteractives.cbc.ca/longform/peter-nygard-bahamas-allegations">https://newsinteractives.cbc.ca/longform/peter-nygard-bahamas-allegations</a></em></p>]]>
            </description>
            <link>https://newsinteractives.cbc.ca/longform/peter-nygard-bahamas-allegations</link>
            <guid isPermaLink="false">hacker-news-small-sites-25984274</guid>
            <pubDate>Mon, 01 Feb 2021 00:42:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dimensions of the Khufu Pyramid]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25983747">thread link</a>) | @joubert
<br/>
January 31, 2021 | https://www.cheops-pyramide.ch/khufu-pyramid/khufu-numbers.html | <a href="https://web.archive.org/web/*/https://www.cheops-pyramide.ch/khufu-pyramid/khufu-numbers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="75%"> 
      <p>Numbers and figures of the Cheops (Khufu) pyramid: <br>
        <a href="#khufu">The pyramid of Khufu</a> - <a href="#performance">Output 
        / performance</a> - <a href="#baumasse">Building material</a> - <a href="#zahlen">Dimensions 
        of the pyramid</a> - <a href="#cubits">Dimensions in Royal Cubits</a> 
        - <a href="#quellen">Sources</a></p>
      
      <h2><a href="#top" target="_top"><img src="https://www.cheops-pyramide.ch/image/icons/top-schwarz.gif" width="14" height="10"></a> 
        Cheops-pyramid (pyramid of Khufu)<a name="khufu"></a></h2>
      <p>Of the the famous Seven Wonders of the Ancient World the Great Pyramid 
        of Khufu (Cheops) at Giza is the only one still standing. Even for modern 
        men it is amazing how this man-made structure lasted so long. </p>
      <p>The Giza pyramids must have made an incredible visual impact - at the 
        edge of the desert three abstract geometrical symbols were rising, huge 
        luminous white triangles reflecting the blinding light of the sun! </p>
      <p>The pyramids on the Giza plateau are with 146.59m (Khufu / Cheops) and 
        143.87m (Khafre / Chefren) respectively the largest, however there are 
        over 30 major pyramids and a myriad of smaller pyramids in Egypt. </p>
      
      <p><img src="https://www.cheops-pyramide.ch/khufu-pyramid/great-pyramid/khufu-interior-view.GIF" alt="" width="400" height="250" usemap="#Map">
        <map name="Map">
          <area shape="poly" coords="106,106" href="#">
        </map>
      </p>
      <p><strong> Cheops-Pyramid</strong><br>
        1. Entrance 2. Entrance cut by grave robbers 3. Subterranean chamber 4. 
        Grand Gallery 5. King's chamber, relieving chambers, granite portcullis 
        slabs 6. Queen's chamber 7. Shaft 8. Limestone plugging the air shaft 
        A= "Air shafts"</p>
      
      
      <h2><a href="#top" target="_top"><img src="https://www.cheops-pyramide.ch/image/icons/top-schwarz.gif" width="14" height="10"></a> 
        Output / performance<a name="performance"></a></h2>
      <p><a href="https://www.cheops-pyramide.ch/khufu-pyramid/pyramid-workers.html"><img src="https://www.cheops-pyramide.ch/image/icons/arrow-right-braun.gif" width="10" height="10"></a> 
        <a href="https://www.cheops-pyramide.ch/khufu-pyramid/pyramid-workers.html">Detailed calculations how many workers 
        were necessary to build the pyramid</a><br>
        <a href="https://www.cheops-pyramide.ch/khufu-pyramid/pyramid-construction.html"><img src="https://www.cheops-pyramide.ch/image/icons/arrow-right-braun.gif" width="10" height="10"></a> 
        <a href="https://www.cheops-pyramide.ch/khufu-pyramid/pyramid-construction.html">Overview pyramid building</a></p>
      <table>
        <tbody><tr> 
          <td><strong>Builder<br>
            <span color="#EFD685">-------------------</span> </strong></td>
          <td>&nbsp;</td>
          <td>Khufu (Chuefui-Chnum or Khnum-Khuf, Cheops in Greek) during the 
            4th dynasty of the old kingdom</td>
        </tr>
        <tr> 
          <td><strong>Time to build</strong></td>
          <td>&nbsp;</td>
          <td>Probably max. 23 years (Khufu reigned from<span color="#FF0000">&nbsp; 
            </span>2551 to 2528 before Christ *). Herodotus writes about 10 years 
            of preparation and 20 years of building (<a href="https://www.cheops-pyramide.ch/khufu-pyramid/pyramid-workers.html#quellen">details 
            of the text</a>)</td>
        </tr>
        <tr> 
          <td><strong>Per day</strong></td>
          <td>&nbsp;</td>
          <td>With 2'500'000 stones 342 stones have to be moved daily (working 
            during 365 days a year) or 431 stones daily (working during 290 days 
            a year).</td>
        </tr>
        <tr> 
          <td><p><strong>Per </strong><strong> minute</strong></p>
            </td>
          <td>&nbsp;</td>
          <td> <p>10-hour day: every 2 minutes a stone (34 to 43 per hour)<br>
              8-hour day: nearly a stone every minute (42 to 53 stones per hour)</p></td>
        </tr>
        <tr> 
          <td><strong>Rule of thumb</strong></td>
          <td>&nbsp;</td>
          <td> <p bordercolor="#333333"> <strong>While construction 
                  the pyramid the rate of delivery was 1 stone weighting 2.5 tons 
                  every minute.</strong></p>
            <p>For our <a href="https://www.cheops-pyramide.ch/khufu-pyramid/pyramid-workers.html">calculations</a> we assume 
              500 stones a day. This is a rough estimate, assuming a 8-hour day, 
              during 290 days a year, with 20 years to build the pyramid. Also 
              assuming, that more time had to be used for the huge granite blocks 
              for the King's chamber and for the more difficult upper part of 
              the pyramid, where work went slower than in the lower parts. There 
              probably were also other factors delaying the building of the pyramid 
              such as the weather or a temporary shortage of certain building 
              materials.</p></td>
        </tr>
      </tbody></table>
      
      <h2><a href="#top" target="_top"><img src="https://www.cheops-pyramide.ch/image/icons/top-schwarz.gif" width="14" height="10"></a> 
        Building materials for the Cheops-pyramid<a name="baumasse"></a></h2>
      <p><img src="https://www.cheops-pyramide.ch/khufu-pyramid/great-pyramid/stonelayers.gif" alt="the 210 stone layrs of the cheops-pyramid and the percentage of building substance" width="480" height="300"></p>
      <p>The Khufu-pyramid (Cheops) probably originally had 210 stone 
        layers. At 50m height already 82% of the entire pyramid was built [<a href="#quellen">3</a>]<a href="https://www.cheops-pyramide.ch/pyramidensteine/steinbearbeitung.html"></a>.</p>
      <p><a href="https://www.cheops-pyramide.ch/khufu-pyramid/stone-quarries.html"><img src="https://www.cheops-pyramide.ch/image/icons/arrow-right-braun.gif" width="10" height="10"></a> 
        <a href="https://www.cheops-pyramide.ch/khufu-pyramid/stone-quarries.html">Quarrying stones for the pyramid</a><br>
        <a href="https://www.cheops-pyramide.ch/khufu-pyramid/nile-shipping.html"><img src="https://www.cheops-pyramide.ch/image/icons/arrow-right-braun.gif" width="10" height="10"></a> 
        <a href="https://www.cheops-pyramide.ch/khufu-pyramid/nile-shipping.html">Shipping the stone blocks down the Nile to Giza</a><br>
        <a href="https://www.cheops-pyramide.ch/khufu-pyramid/sledge-tracks.html"><img src="https://www.cheops-pyramide.ch/image/icons/arrow-right-braun.gif" width="10" height="10"></a> 
        <a href="https://www.cheops-pyramide.ch/khufu-pyramid/sledge-tracks.html">Transporting the stone blocks using a sledge on tracks</a><br>
        <a href="https://www.cheops-pyramide.ch/khufu-pyramid/rope-roll.html"><img src="https://www.cheops-pyramide.ch/image/icons/arrow-right-braun.gif" width="10" height="10"></a> 
        <a href="https://www.cheops-pyramide.ch/khufu-pyramid/rope-roll.html">Löhner's 
        rope roll</a></p>
      <table>
        <tbody><tr> 
          <td><strong>Stone blocks<br>
            <span color="#EFD685">-------------------</span> </strong></td>
          <td>&nbsp;</td>
          <td>2'300'000 stones</td>
        </tr>
        <tr> 
          <td><strong>Casing blocks</strong></td>
          <td>&nbsp;</td>
          <td>115'000 to 200'000 stones or 67'390m³ [<a href="#quellen">1</a>]</td>
        </tr>
        <tr> 
          <td><strong>Total blocks</strong></td>
          <td>&nbsp;</td>
          <td>2'500'000 stones</td>
        </tr>
        <tr> 
          <td><strong>Stone layers</strong></td>
          <td>&nbsp;</td>
          <td>Originally probably 210 stone layers, now only 201 layers [<a href="#quellen">2</a>]</td>
        </tr>
        <tr> 
          <td><strong>Stone size</strong></td>
          <td>&nbsp;</td>
          <td>The stone blocks usually are larger in the lower layers (1.5m = 
            3 cubit) and smaller in the upper layers. Most are between 1.5 and 
            2 cubit large (average of 127 x 127 x 71cm). 1 cubit = 0.524m - <a href="https://www.cheops-pyramide.ch/khufu-pyramid/casing-stones.html#steinschicht">Details</a></td>
        </tr>
        <tr> 
          <td><strong>Weight of the stone blocks</strong></td>
          <td>&nbsp;</td>
          <td>With an average density of 2,6 - 2,9 t/m³ the large limestone 
            blocks weighted 6.5 - 10 tons and the smaller ones about 1.3 tons. 
            For all calculations on this website an average weight of 2.5 tons 
            was used.</td>
        </tr>
        <tr> 
          <td><strong>Special blocks</strong></td>
          <td>&nbsp;</td>
          <td>For the King's chamber granite blocks weighting 40 to 50 tons were 
            used</td>
        </tr>
        <tr> 
          <td><strong>Total weight</strong></td>
          <td>&nbsp;</td>
          <td>6'500'000 tons (average weight of a block was about 2.5 tons)</td>
        </tr>
        <tr> 
          <td><strong>Pyramidion</strong></td>
          <td>&nbsp;</td>
          <td>The final stone on the top was a large block in the shape of a pyramid. 
            It was perhaps around 1.5m by 1.5m wide and 1.3m high (about 3 cubits). 
            It was made from white Tura limestone (Turah), granite or perhaps 
            diorite and perhaps gold plated. <a href="https://www.cheops-pyramide.ch/khufu-pyramid/granite-transport.html">More 
            information </a></td>
        </tr>
        <tr> 
          <td><strong>Building materials</strong></td>
          <td>&nbsp;</td>
          <td> <p><strong>Pyramid:</strong> Nummulite limestone from quarries 
              about 200-400m south of the pyramid were used for the core stones.<br>
              <strong>Casing:</strong> light white limestone, so called Tura-limestone 
              from quarries from the eastern shores of the Nile<br>
              <strong>King's chamber:</strong> Rose granite from Aswan 900km away<br>
              <strong>Further materials:</strong> Graywacke from the Wadi Hammamat 
              (Eastern desert), basalt from the northern Faiyum <br>
              <a href="https://www.cheops-pyramide.ch/khufu-pyramid/stone-quarries.html#herkunft"><img src="https://www.cheops-pyramide.ch/image/icons/arrow-right-braun.gif" width="10" height="10"></a> 
              <a href="https://www.cheops-pyramide.ch/khufu-pyramid/stone-quarries.html#herkunft">Map of quarries in Egypt</a></p></td>
        </tr>
      </tbody></table>
      
      <h2><a href="#top" target="_top"><img src="https://www.cheops-pyramide.ch/image/icons/top-schwarz.gif" width="14" height="10"></a> 
        Dimensions of the pyramid of Khufu<a name="zahlen"></a></h2>
      <p><img src="https://www.cheops-pyramide.ch/khufu-pyramid/great-pyramid/pyramid-dimensions.GIF" alt="Dimensions of the Cheops (Khufu) pyramid, angles, lenght, hight" width="500" height="250"></p>
      <table>
        <tbody><tr> 
          <td><strong>Length (a)</strong><br> <span color="#EFD685">-------------------</span></td>
          <td>&nbsp;</td>
          <td>The average length of the edge is ~ 230.360m (230,12m = 440 cubits). 
            Northern edge 230.328m - eastern edge 230.369m - southern edge 230.372m 
            - western edge 230.372m. Largest difference is only 4.4cm. [<a href="#quellen">3</a>]</td>
        </tr>
        <tr> 
          <td> <strong>Height (h)</strong></td>
          <td>&nbsp;</td>
          <td>Originally 146.59m high (= 280 cubits), the pyramid is now only 
            138.75m high [<a href="#quellen">7</a>]</td>
        </tr>
        <tr> 
          <td><strong>Diagonal (d)</strong></td>
          <td>&nbsp;</td>
          <td>325.77m </td>
        </tr>
        <tr> 
          <td><strong>Ridge (g)</strong></td>
          <td>&nbsp;</td>
          <td>219m</td>
        </tr>
        <tr> 
          <td><strong>Height of the lateral surface</strong></td>
          <td>&nbsp;</td>
          <td>186.42m </td>
        </tr>
        <tr> 
          <td><strong>Pyramid angle α</strong></td>
          <td>&nbsp;</td>
          <td>51° 50' 40'' = inclination of the lateral surface (= 52° 
            rounded off) [<a href="#quellen">3</a>] which corresponds to a seked 
            of 5½ palms</td>
        </tr>
        <tr> 
          <td><strong>Pyramid angle β</strong></td>
          <td>&nbsp;</td>
          <td> 58.3° = the two angles of the triangular lateral surface (62° 
            = angle of the apex or tip of the pyramid) - nearly forming an equilateral 
            triangle! </td>
        </tr>
        <tr> 
          <td><strong>Pyramid angle γ</strong></td>
          <td>&nbsp;</td>
          <td>41.9° = angle of the ridge</td>
        </tr>
        <tr> 
          <td><strong>Corner angle</strong></td>
          <td>&nbsp;</td>
          <td>Right angle base with angles from 89° 59' to 90° </td>
        </tr>
        <tr> 
          <td><strong>Base area</strong></td>
          <td>&nbsp;</td>
          <td> 53'065.73m²</td>
        </tr>
        <tr> 
          <td><strong>Superficies surface</strong></td>
          <td>&nbsp;</td>
          <td> 85'890.69m²</td>
        </tr>
        <tr> 
          <td><strong>Pyramid volume</strong></td>
          <td>&nbsp;</td>
          <td>2'592'968.43m³ including the rock core. This would be a cube 
            with a length of 137.38m. Probable volume of stones used: 2'583'283m³ 
            [<a href="#quellen">1</a>] or 2'326'501m³ [<a href="#quellen">2</a>].</td>
        </tr>
        <tr> 
          <td><strong>Alignment</strong></td>
          <td>&nbsp;</td>
          <td>Exactly to the north (deviation only 2' 28'')</td>
        </tr>
        <tr> 
          <td><strong>Latitude and longitude</strong></td>
          <td>&nbsp;</td>
          <td>N 29° 58’ 44.3830” latitude and E 31° 07’ 
            57.0194” longitude [<a href="#quellen">5</a>]</td>
        </tr>
        <tr> 
          <td><strong>Altitude</strong></td>
          <td>&nbsp;</td>
          <td>The base of the pyramid of Khufu lies about 60m above sea level, so 
            the tip of the pyramid used to be on 206m above sea level [<a href="#quellen">6</a>].</td>
        </tr>
      </tbody></table>
      <p><a href="https://www.cheops-pyramide.ch/khufu-pyramid/pyramid-alignment.html"><img src="https://www.cheops-pyramide.ch/image/icons/arrow-right-braun.gif" width="10" height="10"></a> 
        <a href="https://www.cheops-pyramide.ch/khufu-pyramid/pyramid-alignment.html">Alignment of the pyramids and controlling the shape of the pyramid</a> (north-south alignment etc.)</p>
      
      <h2><a href="#top" target="_top"><img src="https://www.cheops-pyramide.ch/image/icons/top-schwarz.gif" width="14" height="10"></a> 
        Dimensions of the pyramid of Khufu in Egyptian Royal Cubits <a name="cubits" id="cubits"></a></h2>
      <table>
        <tbody><tr> 
          <td rowspan="9"> <img src="https://www.cheops-pyramide.ch/khufu-pyramid/great-pyramid/pyramid-triple.gif" width="250" height="250"></td>
          <td><strong>Length (a)</strong></td>
          <td>&nbsp;</td>
          <td><strong>440</strong> Royal Cubits</td>
        </tr>
        <tr> 
          <td> <strong>Height (h)</strong></td>
          <td>&nbsp;</td>
          <td><strong>280</strong> Royal Cubits</td>
        </tr>
        <tr> 
          <td><strong>Height of the lateral surface (c)</strong></td>
          <td>&nbsp;</td>
          <td><strong>356</strong> Royal Cubits (356.09)</td>
        </tr>
        <tr> 
          <td><strong>Diagonal (d)</strong></td>
          <td>&nbsp;</td>
          <td>622.25 Royal Cubits</td>
        </tr>
        <tr> 
          <td><strong>Ridge (g)</strong></td>
          <td>&nbsp;</td>
          <td>418.56 Royal Cubits</td>
        </tr>
        <tr> 
          <td><strong>Pyramid angle α</strong></td>
          <td>&nbsp;</td>
          <td>51.843°</td>
        </tr>
        <tr> 
          <td><strong>Pyramid angle β</strong></td>
          <td>&nbsp;</td>
          <td> 58.3° </td>
        </tr>
        <tr> 
          <td><strong>Pyramid angle γ</strong></td>
          <td>&nbsp;</td>
          <td>41.9°</td>
        </tr>
        <tr> 
          <td><strong>Corner angle</strong></td>
          <td>&nbsp;</td>
          <td>90° </td>
        </tr>
      </tbody></table>
      <p>It is suggested, that the Egyptians used a right angled triangle to determinate 
        the angle of inclination of the pyramid, using the numbers a=11 and b=14 
        with c=17.8 (or a=22 - b=28 - c= 35.6). This determines a so called seked 
        of 5½ palms. <br>
        <a href="https://www.cheops-pyramide.ch/khufu-pyramid/pyramid-alignment.html"><img src="https://www.cheops-pyramide.ch/image/icons/arrow-right-braun.gif" width="10" height="10"></a> 
        <a href="https://www.cheops-pyramide.ch/khufu-pyramid/pyramid-alignment.html">Alignment of the pyramids and controlling the shape of the pyramid</a> (seked)</p>
      
      <h2><a href="#top" target="_top"><img src="https://www.cheops-pyramide.ch/image/icons/top-schwarz.gif" width="14" height="10"></a> 
        Sources <a name="quellen"></a></h2>
      <p>[1] <a href="https://www.cheops-pyramide.ch/khufu-pyramid/literature.html#lehner">M. Lehner</a> The Complete 
        Pyramids of Egypt <br>
        [2] <a href="https://www.cheops-pyramide.ch/khufu-pyramid/literature.html#goyon">G. Goyon</a> Die Cheops-Pyramide <br>
        [3] <a href="https://www.cheops-pyramide.ch/khufu-pyramid/literature.html#stadelmann">R. Stadelmann</a> Die grossen 
        Pyramiden von Giza <br>
        [4] <a href="https://www.cheops-pyramide.ch/khufu-pyramid/literature.html#abitz">F. Abitz</a> Der Bau der grossen Pyramide 
        mit einem Schrägaufzug <br>
        [5] GPS-coordinates of a brass disk on top of the pyramid of Khufu, Giza 
        Plateau Mapping Project (<a href="http://www.aeraweb.org/gpmp_grid.asp" target="_blank">GPMP</a>)<br>
        [6] Maps of the Giza Plateau Mapping Project show the altitude as 60m<br>
        [7] <a href="https://www.cheops-pyramide.ch/khufu-pyramid/literature.html#arnold">D. Arnold</a> Building in Egypt</p>
      <p> * Dates according to conventional Egyptian chronology are 
        used in this website. These are based on several list of the dynasties 
        of pharaohs, for example the Aegyptiaca of Manetho of Sebennytos. </p>
      
      
      
      <p><strong><a href="https://www.cheops-pyramide.ch/grosse-pyramide.html">Diese Seite auf Deutsch</a></strong></p></div></div>]]>
            </description>
            <link>https://www.cheops-pyramide.ch/khufu-pyramid/khufu-numbers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25983747</guid>
            <pubDate>Sun, 31 Jan 2021 23:33:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Git to manage configuration files]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25983734">thread link</a>) | @abhilb
<br/>
January 31, 2021 | https://blog.abhilashbabuj.com/2021/01/26/Git-for-config-management/ | <a href="https://web.archive.org/web/*/https://blog.abhilashbabuj.com/2021/01/26/Git-for-config-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Though the most common use of git is source code version control, it also works well for maintaining Software configuration files. Consider the case of a Software that receives some data, does some processing based on some parameters provided by the user and generates some results. The user could tinker with the parameters to find the optimal solution. As long as the change history is maintained the user can go back and forth with all the parameter combinations that were tried so far. It is a common approach to save these parameters, settings and user preferences in flat, ini, xml or json files. But once the program ends it wouldn’t be possible to get back to the previous parameter combinations, or to know if someone else accidentally changed the parameters. </p>
<p>Just like checkpoints feature in jupyter notebooks, one could use git to make snapshots of configuration files. It gives all the goodies of a version control system, like change history, tags etc. The user can revert to older configurations using git commands. To integrate this feature into the software, one could use the library <a href="https://libgit2.org/" target="_blank" rel="noopener">libgit</a>. It is a portable, pure C implementation of the Git core methods. Bindings are available for most of the popular languages like python, ruby, lua, C# etc.</p>
<p>To further demonstrate this use case, let us consider this toy application written in Python with Qt bindings. It converts a color image to binary image. It needs two parameters, a lower threshold and an upper threshold. As the application starts, it creates a git repository to store the configuration file. When the user saves the settings it creates a new commit. As shown in the gif below the git log shows all the commits.</p>
<p><img src="https://blog.abhilashbabuj.com/contents/img/demo_libgit.gif" alt="png"></p>
<p>Following code snippet shows all the API’s that were used for the toy application</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br></pre></td><td><pre><span></span><br><span>repo = pygit2.init_repository(config_path, <span>False</span>)</span><br><span></span><br><span></span><br><span>repo.index.add(<span>"config.json"</span>)</span><br><span>repo.index.write()</span><br><span></span><br><span></span><br><span>author = pygit2.Signature(<span>"Author"</span>, <span>"mailto@authors.tld"</span>)</span><br><span>committer = pygit2.Signature(<span>"Committer"</span>, <span>"mailto@committers.tld"</span>)</span><br><span></span><br><span>parents = []</span><br><span>commit = <span>None</span></span><br><span><span>try</span>:</span><br><span>    commit = repo.revparse_single(<span>"HEAD"</span>)</span><br><span><span>except</span> (KeyError, AttributeError):</span><br><span>    <span>pass</span></span><br><span></span><br><span><span>if</span> commit:</span><br><span>    parents = [commit.oid.hex]</span><br><span></span><br><span>repo.create_commit( <span>"HEAD"</span>, author, committer, str(datetime.now()),</span><br><span>                     repo.index.write_tree(), parents)</span><br></pre></td></tr></tbody></table></figure>

  </div></div>]]>
            </description>
            <link>https://blog.abhilashbabuj.com/2021/01/26/Git-for-config-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25983734</guid>
            <pubDate>Sun, 31 Jan 2021 23:32:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doctor Do-Little – The Case Against Anthony Fauci]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25983611">thread link</a>) | @mhb
<br/>
January 31, 2021 | https://www.thedriftmag.com/the-case-against-fauci/ | <a href="https://web.archive.org/web/*/https://www.thedriftmag.com/the-case-against-fauci/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><strong>T</strong><span>here is no one in American government — or perhaps any government — quite like Dr. Anthony Fauci. His position, with its mixture of informal power and public visibility, scientific authority and beltway influence, is sui generis. Few other unconfirmed civil servants have access to as many rooms in the executive interagency; no public official commands as much respect in the world of science and medicine. As director of the National Institute of Allergy and Infectious Diseases (NIAID) since 1984, he has advised six presidents (and now a seventh) on domestic and global health issues — HIV/AIDS, SARS, Ebola, Zika, and MERS — and overseen decades of research on infectious disease, pandemics, and virology. Under his stewardship, NIAID’s mission has been reshaped around his personage: its priorities are </span><i><span>his</span></i><span> priorities, its research agenda is </span><i><span>his</span></i><span> research agenda. And that agenda has borne fruit: breakthrough treatments for HIV and other deadly diseases and now, a vaccine for Covid-19. As Stanford microbiologist David Relman told </span><i><span>The</span></i> <i><span>New Yorker</span></i><span> in April, “Tony has essentially become the embodiment of the biomedical and public-health research enterprise in the United States.”</span></p>
<p><span>Although Fauci has no statutory authority to preside over a public health crisis, he has become the nation’s de facto Doctor-in-Chief during this pandemic. His face — elven and expressive — is the face of the medical establishment’s response to the novel coronavirus. I doubt most Americans can name the (</span><a href="https://www.washingtonpost.com/us-policy/2021/01/20/biden-surgeon-general-resignation/" target="_blank" rel="noopener noreferrer"><span>outgoing</span></a><span>) U.S. Surgeon General, CDC Director, or Fauci’s nominal boss, the director of the National Institutes of Health (Jerome Adams, Robert Redfield, and Francis Collins, respectively), but everyone knows Dr. Fauci. His plaintive but never pessimistic patter and disarming outer-borough rasp are soothing sonic features of our daily dirge of death, doom, and statistics. I was relieved when I first saw Fauci on TV — sometime in March 2020 — thinking dimly to myself, for the millionth time, “Ah, an adult in the room.” Amid a ceaseless current of chaos and grief, Fauci’s egoless display of competence, his grandfatherly warmth and irony, were ports in a storm.&nbsp;</span></p>
<p><span>But a comforting bedside manner has done little to mitigate catastrophe. Over 400,000 Americans are dead, twice as many as any other country. Infections, hospitalizations, and deaths are currently at record highs. And although we have a vaccine, the rollout has already been stymied by a dearth of resources and coordination. As one public health expert told <em>The </em></span><i><span>New York Times </span></i><span>on January 17</span><i><span>,</span></i><span> our pandemic response has been “a colossal failure at every level of government.” And herein lies a paradox. America is suffering from a disease outbreak whose morbid scope is the consequence of world-historic negligence. We are desperately and needlessly sick. And yet, the man known as “America’s Doctor,” the undisputed personification of public health research and pandemic preparedness, faces no reputational consequences. On the contrary, Dr. Fauci remains one of our most beloved public figures.&nbsp;&nbsp;</span></p>
<p><span>What explains this? Liberals, who otherwise harshly condemn the federal government’s pandemic response, are especially besotted with the diminutive virologist. For fans of the #Resistance, a well-timed </span><a href="https://www.businessinsider.com/dr-anthony-fauci-did-a-facepalm-during-trumps-coronavirus-briefing-2020-3" target="_blank" rel="noopener noreferrer"><span>facepalm</span></a><span> during one of the Mad King’s early soliloquies guaranteed Fauci’s place on a Mount Rushmore of replacement patriarchs, alongside James Comey and Robert Mueller. (Fauci later insisted the gesture was innocuous; he was merely obscuring his face to dislodge a lozenge from his throat.) Still, Democrats’ devotion has never waned. They see in Fauci a lonely champion of “truth” and “facts” in a White House otherwise hostile to “science.” Brad Pitt earned an Emmy nomination for portraying the 80-year-old physician on Saturday Night Live. One Hamilton-inspired TikTok (“My name is Dr. Anthony Fau-CHEE…”) went viral. Just since the beginning of the “third wave” of Covid infections in October, Fauci has received leadership awards from the National Academy of Medicine, the FBI Agents Association, the Arthur Ashe Institute for Urban Health, and the Boy Scouts of America. Joe Biden has </span><a href="https://www.cnn.com/2020/12/03/politics/anthony-fauci-biden-transition/index.html" target="_blank" rel="noopener noreferrer"><span>asked</span></a><span> Fauci to stay on at NIAID and serve in his administration as a chief medical advisor. D.C. Mayor Muriel Bowser proclaimed “Anthony S. Fauci Day” on December 24.&nbsp;</span></p>
<p><span>Fauci’s celebrity, however, cannot obscure empirical reality. As America’s Doctor would surely agree, the numbers don’t lie: 2,824 Americans died of Covid-19 on Anthony S. Fauci Day.&nbsp;</span></p>
<p><span>Anthony Fauci is no doubt a dedicated public servant, respected by his colleagues, beloved by many Americans. But the puzzle remains: why has the man most closely associated with the public health response to the pandemic entirely avoided accountability for its failure?&nbsp;</span></p>

<p><strong>F</strong><span>irst, the most straightforward defense: it wasn’t his fault. He did the best he could, but Fauci’s better instincts were thwarted by Trump and his coterie of idiots. Of course, there’s truth in this. The uneasy peace between Trump and his medical advisors started to unravel almost before it began. By the end of March, Trump was sweating the stocks and tweeting that the “cure” must not be worse “than the problem itself.” He clashed with Fauci throughout the spring — over masks, hydroxychloroquine, school openings, and Easter. By summer, Trump was publicly lambasting the good doctor, leaking anti-Fauci talking points to the press and sidelining him in task force meetings, which were themselves increasingly rare. Scott Atlas, the libertarian radiologist and herd-immunity advocate whom Trump hired based on his Fox News appearances, was calling the shots.</span></p>
<p><span>But Fauci seldom contradicted the president’s lies outright, opting for tact and de-escalation instead. “I can’t jump in front of the microphone and push him down,” Fauci </span><a href="https://www.theguardian.com/world/2020/mar/23/dr-fauci-press-conference-white-house-coronavirus" target="_blank" rel="noopener noreferrer"><span>said</span></a><span> in late March. “OK, he said it. Let’s try and get it corrected for the next time.” On July 4, Trump said 99 percent of Covid cases were “harmless.” Fauci characterized this as a misinterpretation. (“I’m trying to figure out where the president got that number…” he said.) Though Fauci has a reputation for bluntness, as the </span><i><span>Financial Times</span></i><span>’s Hannah Kuchler </span><a href="https://www.ft.com/content/57834c2c-a078-4736-9173-8fb32cfbbf4e" target="_blank" rel="noopener noreferrer"><span>observed</span></a><span>, “he clearly also tries to hold back, believing he will make a bigger difference to the course of the pandemic if he keeps his job.”</span></p>
<p><span>This logic pervades the most common defense of Fauci’s record. “Tony is unique, in that he has such credibility with politicians that he’s been able to insert hard facts into the conversation,” Nobel laureate biologist David Baltimore told </span><i><span>The</span></i> <i><span>New Yorker</span></i><span> in April. “That has been wonderful for our country and the world.” In this view, Fauci was </span><i><span>handling</span></i><span> Trump, just as he handled previous presidents, including a reluctant Ronald Reagan during the AIDS epidemic. When he pulls his punches, it’s always for the greater good; namely, the cause of remaining in the room. Stepping too far out of line, contradicting Trump with too much vigor, would have imperiled his standing. “The argument for Fauci saying more,” </span><a href="https://www.washingtonpost.com/opinions/2020/07/16/anthony-fauci-built-truce-trump-is-destroying-it/?arc404=true" target="_blank" rel="noopener noreferrer"><span>wrote</span></a><span> Molly Roberts in <em>The</em> </span><i><span>Washington Post</span></i><span>, “… is also an argument for self-exile.” And then what? Truth and facts would have had no advocate inside the White House. As Fauci himself </span><a href="https://www.nytimes.com/2021/01/24/health/fauci-trump-covid.html?action=click&amp;module=Top%20Stories&amp;pgtype=Homepage" target="_blank" rel="noopener noreferrer"><span>told</span></a><span> the </span><i><span>Times</span></i><span> on Sunday, “I felt that if I stepped down, that would leave a void. Someone’s got to not be afraid to speak out the truth.”</span></p>
<p><span>At a briefing in July, Trump </span><a href="https://www.cnn.com/2020/07/28/politics/donald-trump-anthony-fauci-approval-rating/index.html" target="_blank" rel="noopener noreferrer"><span>mused</span></a><span>, “It’s interesting: [Fauci’s] got a very good approval rating. And I like that, it’s good. Because remember, he’s working for this administration. He’s working with us.” Winding his way to his point, Trump said, “So why don’t I have a high approval rating… with respect to the virus?” After a pause, he deadpanned, “It can only be my personality, that’s all.”&nbsp;</span></p>
<p><span>As is often the case with Trump, he had a point, just not the one he meant. The liberal apologia for Fauci </span><i><span>was</span></i><span> internally contradictory. As one scientist said to me, “We can’t deify Fauci’s response to the pandemic as fantastic while simultaneously condemning Trump, when for months, the two were hand in hand.” Indeed, Fauci is only blameless if he was utterly powerless to stop the administration’s disastrous plans. And if he </span><i><span>was</span></i><span> powerless, he should’ve resigned and communicated the truth bluntly to the public long ago. Otherwise, he knowingly lent credibility to an abject failure he couldn’t control.&nbsp;</span></p>
<p><span>To put an even finer point on it, the precise conditions that would maximally exonerate Fauci — i.e., Trump is solely at fault; Fauci had no influence — are conditions under which Fauci </span><i><span>absolutely </span></i><span>should have bolted. The more aberrant Trump’s behavior, the more he diverged from the medically prudent course of action, the greater Fauci’s responsibility to leave and blow the whistle. If Fauci knew better but didn’t say, what use was he inside the room? If he </span><i><span>didn’t</span></i><span> know better, then he shares the blame.&nbsp;</span></p>
<p><span>In recent days, Fauci and Covid task force coordinator Dr. Deborah Birx — another veteran AIDS researcher who’s received slightly </span><a href="https://www.politico.com/news/2020/11/18/biden-coronavirus-team-deborah-birx-437923" target="_blank" rel="noopener noreferrer"><span>less deferential</span></a><span> treatment from the media than her male counterpart — have undertaken a goodwill tour. Birx </span><a href="https://twitter.com/FaceTheNation/status/1353332977560735744?s=20" target="_blank" rel="noopener noreferrer"><span>told</span></a><span> CBS that denialists in the White House “derailed” the pandemic response, putting out information she knew to be false. Fauci joked with Rachel Maddow that Trump had </span><a href="https://www.msnbc.com/rachel-maddow/watch/fauci-to-maddow-i-ve-been-wanting-to-come-on-your-show-for-months-and-months-99905093921" target="_blank" rel="noopener noreferrer"><span>forbidden</span></a><span>&nbsp;him from coming on her show and </span><a href="https://www.usatoday.com/story/news/politics/2021/01/21/anthony-fauci-speaking-covid-liberating-under-biden-vs-trump/4244169001/" target="_blank" rel="noopener noreferrer"><span>told</span></a><span> the White House press corps, “The idea that you can get up here and… let the science speak, it is somewhat of a liberating feeling.” Meanwhile, liberal pundits like Ezra Klein have </span><a href="https://www.nytimes.com/2021/01/18/opinion/biden-covid-19-plan.html" target="_blank" rel="noopener noreferrer"><span>praised</span></a><span> Biden’s “maddeningly obvious” Covid plans, describing their simplicity as a “damning indictment” of Trump’s negligence. But if Biden’s life-saving interventions are so straightforward and crucial, why weren’t Fauci and Birx loudly demanding them months ago?&nbsp;</span></p>
<p><span>“To keep their jobs” should not be a satisfying answer — not for the living or for the dead.&nbsp;</span></p>

<p><strong>F</strong><span>rank assessments of Fauci’s performance are hard to come by. Those in a position to judge him from an informed public …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thedriftmag.com/the-case-against-fauci/">https://www.thedriftmag.com/the-case-against-fauci/</a></em></p>]]>
            </description>
            <link>https://www.thedriftmag.com/the-case-against-fauci/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25983611</guid>
            <pubDate>Sun, 31 Jan 2021 23:18:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Counterfeiting Stock 2.0]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25983343">thread link</a>) | @twooster
<br/>
January 31, 2021 | http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html | <a href="https://web.archive.org/web/*/http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<center><b>Counterfeiting Stock 2.0</b></center>

<p>
Illegal naked shorting and stock manipulation are two of Wall Street's deep, dark secrets. These practices have been around for decades and have resulted in trillions of dollars being fleeced from the American public by Wall Street. In the process, many emerging companies have been put out of business. This report will explain the magnitude of this problem, how it happens, why it has been covered up and how short sellers attack a company. It will also show how all of the participants; the short hedge funds, the prime brokers and the Depository Trust Clearing Corp. (DTCC)—make unconscionable profits while the fleecing of the small American investor continues unabated.
</p>
<p>
<span>Why is This Important?</span> This problem affects the investing public. Whether invested directly in the stock market or in mutual funds, IRAs, retirement or pension plans that hold stock — it touches the majority of Americans.
</p>
<p>
The participants in this fraud, which, when fully exposed, will make Enron look like child's play, have been very successful in maintaining a veil of secrecy and impenetrability. Congress and the SEC have unknowingly (?) helped keep the closet door closed. The public rarely knows when its pocket is being picked as unexplained drops in stock price get chalked up to “market forces” when they are often market manipulations.
</p>
<p>
The stocks most frequently targeted are those of emerging companies who went to the stock market to raise start–up capital. Small business brings the vast majority of innovative new ideas and products to market and creates the majority of new jobs in the United States. It is estimated that over 1000 of these emerging companies have been put into bankruptcy or had their stock driven to pennies by predatory short sellers. 
</p>
<p>
It is important to understand that selling a stock short is not an investment in American enterprise. A short seller makes money when the stock price goes down and that money comes solely from investors who have purchased the company's stock. A successful short manipulation takes money from investment in American enterprise and diverts it to feed Wall Street's insatiable greed—the company that was attacked is worse off and the investing public has lost money. Frequently this profit is diverted to off–shore tax havens and no taxes are paid. This national disgrace is a parasite on the greatest capital market in the world.
</p>
<p>
<span>A Glossary of Illogical Terms</span> — The securities industry has its own jargon, laws and practices that may require explaining. Most of these concepts are the creation of the industry, and, while they are promoted as practices that ensure an orderly market, they are also exploited as manipulative tools. This glossary is limited to naked short abuse, or counterfeiting stock as it is more correctly referred to. 
</p>

<ol>
<li><b>Broker Dealer or Prime Broker</b> — The big stockbrokers who clear their own transactions, which is to say they move transacted shares between their customers directly, or with the DTC. Small brokers will clear through a clearing house — also known as a broker's broker.
</li>
<li><b>Hedge Funds</b> — Hedge funds are really unregulated investment pools for rich investors. They have grown exponentially in the past decade and now number over 10,000 and manage over one trillion dollars. They don't register with the SEC, are virtually unregulated and frequently foreign domiciled, yet they are allowed to be market makers with access to all of the naked shorting loopholes. Frequently they operate secretively and collusively. The prime brokers cater to the hedge funds and allegedly receive eight to ten billion dollars annually in fees and charges relating to stock lend to the short hedge funds.
</li>
<li><b>Market Maker</b> — A broker, broker dealer or hedge fund who makes a market in a stock. In order to be a market maker, they must always have shares available to buy and sell. Market makers get certain sweeping exemptions from SEC rules involving naked shorting.
</li>
<li><b>Short Seller</b> — An individual, hedge fund, broker or institution who sells stock short. The group of short sellers is referred to as “the shorts.”
</li>
<li><b>The Securities and Exchange Commission</b> — The SEC is the federal enforcement agency that oversees the securities markets. The top–level management is a five–person Board of Governors who are Presidential appointees. Three of the governors are usually from the securities industry, including the chairman. The SEC adopted Regulation SHO in January 2005 in an attempt to curb naked short abuse.
</li>
<li><b>Depository Trust Clearing Corp</b> — Usually known as the DTCC, this privately held company is owned by the prime brokers and it clears, transacts and holds most stock in this country. It has four subsidiaries, which include the DTC and the NCSS. The operation of this company is described in detail later.
</li>
<li><b>Short Sale</b> — Selling a stock short is a way to make a profit while the stock price declines. For example: If investor S wishes to sell short, he borrows a share from the account of investor L. Investor S immediately sells that share on the open market, so investor S now has the cash from the sale in his account, and investor L has an IOU for the share from investor S. When the stock price drops, investor S takes some of the money from his account and buys a share, called “covering”, which he returns to investor L's account. Investor S books a profit and investor L has his share back.
<p>This relatively simple process is perfectly legal—so far. The investor lending the share most likely doesn't even know the share left his account, since it is all electronic and occurs at the prime broker or DTC level. If shares are in a margin account, they may be loaned to a short without the consent or knowledge of the account owner. If the shares are in a cash account, IRA account or are restricted shares they are not supposed to be borrowed unless there is express consent by the account owner.
</p></li>
<li><b>Disclosed Short</b> — When the share has been borrowed or a suitable share has been located that can be borrowed, it is a disclosed short. Shorts are either naked or disclosed, but, in reality, some disclosed shorts are really naked shorts as a result of fraudulent stock borrowing. 
</li>
<li><b>Naked Short</b> — This is an invention of the securities industry that is a license to create counterfeit shares. In the context of this document, a share created that has the effect of increasing the number of shares that are in the market place beyond the number issued by the company, is considered counterfeit. This is not a legal conclusion, since some shares we consider counterfeit are legal based upon today's rules. The alleged justification for naked shorting is to insure an orderly and smooth market, but all too often it is used to create a virtually unlimited supply of counterfeit shares, which leads to widespread stock manipulation—the lynchpin of this massive fraud. 
<p>
Returning to our example, everything is the same except the part about borrowing the share from someone else's account: There is no borrowed share — instead a new one is created by either the broker dealer or the DTC. Without a borrowed share behind the short sale, a naked short is really a counterfeit share.
</p></li>
<li><b>Fails–to–Deliver</b> — The process of creating shares via naked shorting creates an obvious imbalance in the market as the sell side is artificially increased with naked short shares or more accurately, counterfeit shares. Time limits are imposed that dictate how long the sold share can be naked. For a stock market investor or trader, that time limit is three days. According to SEC rules, if the broker dealer has not located a share to borrow, they are supposed to take cash in the short account and purchase a share in the open market. This is called a “buy–in,” and it is supposed to maintain the total number of shares in the market place equal to the number of shares the company has issued.
<p>
Market makers have special exemptions from the rules: they are allowed to carry a naked short for up to twenty–one trading days before they have to borrow a share. When the share is not borrowed in the allotted time and a buy–in does not occur, and they rarely do, the naked short becomes a fail–to–deliver (of the borrowed share).
</p></li>
<li><b>Options</b> — The stock market also has separate, but related markets that sell options to purchase shares (a “call”) and options to sell shares (a “put”). Options are an integral part of short manipulations, the result of SEC promulgated loopholes in Reg SHO. A call works as follows: Assume investor L has a share in his account that is worth $25. He may sell an option to purchase that share to a third party. That option will be at a specific price, say $30, and expires at a specific future date. Investor L will get some cash from selling this option. If at the expiration date, the market value of the stock is below $30 (the “strike price”), the option expires as worthless and investor L keeps the option payment. This is called “out of the money.” If the market value of the stock is above the strike price, then the buyer of the option “calls” the stock. Assume the stock has risen to $40. The option buyer tenders $30 to investor L and demands delivery of the share, which he may keep or immediately sell for a $10 profit.
</li>
<li><b>Naked call</b> — The same as above except that investor L, who sells the call, has no shares in his account. In other words, he is selling an option on something he does not own. The SEC allows this. SEC rules also allow the seller of a naked short to treat the purchase of a naked call as a borrowed share, thereby keeping their naked short off the SEC's fails–to–deliver list. A share of stock that has a naked call as its borrowed shares is marked as a disclosed short when it is sold, even though nobody in the transaction actually owns a share.
</li>
</ol>




<p>
<span>How The System Transacts Stocks</span> — This explanation has been greatly simplified in the interest of brevity. 
</p>

<img src="http://counterfeitingstock.com/CS2.0/diagram.png">

<ol>
<li><b>Customers</b> — These can be individuals, institutions, hedge funds and prime broker's house accounts.</li></ol></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html">http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html</a></em></p>]]>
            </description>
            <link>http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25983343</guid>
            <pubDate>Sun, 31 Jan 2021 22:41:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Does my face look odd in this? Staying anonymous with Fawkes cloaking tech]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25983168">thread link</a>) | @dddavid
<br/>
January 31, 2021 | https://thecrow.uk/does-my-face-look-odd-in-this-fawkes-cloaking-anonymous/ | <a href="https://web.archive.org/web/*/https://thecrow.uk/does-my-face-look-odd-in-this-fawkes-cloaking-anonymous/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p><img src="https://thecrow.uk/assets/fawkes_face_cloaking.jpg" alt="a randomly generated face from ThisPersonDoesNot Exist"></p>
<center><h6><em> This is not the author. It was generated by <a href="https://thispersondoesnotexist.com/">thispersondoesnotexist.com</a>.</em></h6></center>

<p>I admitted to myself before I started writing that this probably wasn’t going to succeed. Bad habits were too ingrained for too long. The technology was too easy to use, and now I’m fucked.</p>

<p>Between around 2013 when the first Android device arrived in the Crow’s nest and 2018 when I ditched Google entirely, I’ve uploaded around 12,000 photographs to Google. They’re pictures of myself, of my wife, of my kids, and of the landscapes and scenery where I live and where I visit.</p>

<p>Before that, I used to manually upload similar pics to Facebook, where I would dutifully tag myself, tag my friends, and help train the Facebook AI in recognising me, my friends, and my family to the extent that it probably no longer needs human input.</p>

<p>It’s not like either of the tech giants made my private photos public. I can’t type my name into Google images and see the thousands of images snapped over the years as I travelled the world.</p>

<p>But Google knows exactly what I look like. Facebook knows exactly what I look like. Intelligences owned by both companies have been trained on my features with the massive dataset I provided for them.</p>

<p>If an unknown stranger snaps a picture as I make my way around town or if I’m caught on one of the many security cameras which litter the towns and villages of the British Isles, and that photo makes its way back to one of the behemoths, I can be auto-tagged.</p>

<p>I don’t like this idea.</p>

<p>There’s no particular reason I want to flee from Facebook. Google isn’t gunning for me. I have nothing to hide.</p>

<p>But I don’t like it.</p>

<h2> Privacy is now a privilege</h2>

<p>The photos exist, and they’re out in the wild - during the (very extended) period when I was uploading to Facebook and Google, I didn’t read the Terms of service - dumb, I know, but I was young and naive. While I was <em> vaguely </em> aware that facial recognition would be improved using my pictures, I didn’t thoroughly think through the implications as they applied to the real world - only how cool it would be to not have to tag my pictures by hand. So, young, naive, and incredibly short-sighted to boot.</p>

<p>If you’re so inclined, and if you used the photo sharing platform, Flickr in the last decade or so, you can see which, if any of the facial recognition datasets - which are used by police, security service, and marketers across the world - are using the snaps you uploaded to the platform.</p>

<p>Hop across to <a href="https://exposing.ai/"> Exposing.ai</a> and plug in your Flickr username, photo URL, or #tag, and in a second or so, the tool will run through datasets from VGG Face, People in Photo Albums (PIPA), MegaFace, IARPA Janus Benchmark C, FaceScrub, and DiveFace.</p>

<p>It’s important to note that with the exception of MegaFace, Flickr is a minority contributor to these datasets. Most of the snapshots are acquired through other sources, and are used by commercial operators, police and governments.</p>

<p>Other people may have something to hide. Demonstrators in a crowd may have good reason to resent the fact that captured images of them can be run against the datasets, and their true identity revealed to the relevant authorities.</p>

<p>If you think that’s bad, it gets worse - <a href="https://clearview.ai/"> Clearview AI</a>, an unregulated service, <a href="https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html"> is used by more than 600 law enforcement agencies and private companies in the US and around the world.</a> Its facial recognition models were built using over 3 billion photos of people from the Internet and social media without their knowledge or permission.</p>

<p><img src="https://thecrow.uk/assets/hong_kong_protests_facial_recognition.jpg" alt="Pro-democracy protest at Hong Kong International airport. August 2019"></p>
<center><h6><em>The people in this shot from the pro-democracy protests of 2019 are probably feeling a little uneasy right now. | Credit: <a href="https://www.flickr.com/photos/studiokanu/48527530027/"> Studio Incendo </a> / <a href="https://creativecommons.org/licenses/by/2.0/"> CC BY 2.0 </a></em></h6></center>

<p>But the truth is that it’s their own fault, in allowing their images to be associated with their identity, their online accounts, and every other aspect of their lives.</p>

<h2>Fawkes is the digital equivalent of a false moustache</h2>

<p>But you can’t go through life in disguise, donning a <a href="https://amzn.to/3t7zho9"> Guy Fawkes mask</a> every time you shoot a selfie to send to your paramour. You’d look silly, and the recipient wouldn’t recognise you - which kind of defeats the point of taking the photograph in the first place.</p>

<p>It’s important that <em>real people</em> - including me - can recognise my beautiful visage in photographs, but I’d prefer that I couldn’t be recognised by machines.</p>

<p>Which is where a nifty piece of software called <a href="https://sandlab.cs.uchicago.edu/fawkes/"> Fawkes </a> comes in.</p>

<p>It was built by researchers at the University of Chicago specifically to baffle the AIs whose job it is to match a face to an identity, while keeping the subject recognisable to a human viewer.</p>

<p>Although Fawkes is as-yet unfinished, and the current release version is v0.31, <a href="https://sandlab.cs.uchicago.edu/fawkes/#faq">tests </a> have shown protection against “state-of-the-art facial recognition models from Microsoft Azure, Amazon Rekognition, and Face++ are at or near 100%.”</p>

<p>Fawkes runs locally on your computer, and doesn’t need to connect to the Chicago servers once you’ve installed it. I’m not going to attempt to explain <em>how</em> Fawkes works. I’m a man pretending to be a bird, writing humorous and mildly interesting articles for a general audience.</p>

<p>Here’s how its creators describe Fawkes face cloaking technology:</p>

<blockquote>
At a high level, Fawkes "poisons" models that try to learn what you look like, by putting hidden changes into your photos, and using them as Trojan horses to deliver that poison to any facial recognition models of you. Fawkes takes your personal images and makes tiny, pixel-level changes that are invisible to the human eye, in a process we call image cloaking. <p>You can then use these "cloaked" photos as you normally would, sharing them on social media, sending them to friends, printing them or displaying them on digital devices, the same way you would any other photo. The difference, however, is that if and when someone tries to use these photos to build a facial recognition model, "cloaked" images will teach the model an highly distorted version of what makes you look like you. </p><p>The cloak effect is not easily detectable by humans or machines and will not cause errors in model training. However, when someone tries to identify you by presenting an unaltered, "uncloaked" image of you (e.g. a photo taken in public) to the model, the model will fail to recognize you.
</p></blockquote>

<p>I recently had cause to upload a photograph of my face to a new work-related Slack group (Yes. The crow <em> does </em> have a day job (sort of)), and I thought this was the perfect opportunity to put Fawkes to the test.</p>

<p>I cropped a headshot from a family picture, dumped it in the Fawkes directory, and let rip. The process took around a minute, and the fans of my <a href="https://thecrow.uk/gpd-p2-max-ultrabook-cyberdeck-review/"> teeny tiny laptop</a> went into overdrive. This was for one cropped photo.</p>

<p>The result was OK. It was still very recognisably me, athough there was something slightly different around the eyes, and the resolution was <em> slightly</em> off. But it was definitely me, and if I had a mind to, I could hang it on my hallway wall. Guests would ask me, “Crow, why do you have a photograph of yourself on the hallway wall.” So yes, it holds up to being recognisable by people, but not recognisable by machine - which was the point of the exercise.</p>

<p>I’m not going to show you this photo, instead, here’s a Fawkes-treated example using AI generated images from <a href="https://thispersondoesnotexist.com/">thispersondoesnotexist.com</a>.</p>

<p><img src="https://thecrow.uk/assets/fawkes_cloaked_face.jpg" alt="An AI generated model from thispersondoesnotexist.com cloaked using Fawkes"></p>

<p>Yes. There are visible differences, and some artefacts I’d prefer were not present, but it is still recognisably the same person, and remember - Fawkes is currently only on version 0.31. It’s a work in progress.</p>

<p>The fans kicked in after 18 seconds, and the entire process took 77.842498 seconds. That’s a lot for a single picture. If I were to apply cloaking to my entire photo album (kept locally, not online), my machine would need to be running Fawkes for 270 hours straight.</p>

<p>And there is a limit to how much Fawkes will help me, personally. I surrendered my 12,000 or so images to Facebook and Google years ago, and it’s safe to assume that they’re already part of the dataset.</p>

<p>Since then, I’ve disengaged from social media altogether. No photos of me have been uploaded in the last two years or so (at least by me).</p>

<p>To poison the model, I would need to re-engage. I would need a new Facebook account tied to my real name and identity and I would have to upload handfuls of Fawkes-doctored selfies and snapshots every day before it would begin to make a difference. I would be spamming Facebook, Google, Flickr, Pinterest, and every other outlet I could think of. It would be almost a full-time job, and I would be disclosing different information which would otherwise have remained private.</p>

<p>It’s a difficult one. All I can <em>really</em> do is run Fawkes going forwards, and write this article to help any other people who may benefit from it in the future.</p>

<p>Spread the word.</p>

  </div></div>]]>
            </description>
            <link>https://thecrow.uk/does-my-face-look-odd-in-this-fawkes-cloaking-anonymous/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25983168</guid>
            <pubDate>Sun, 31 Jan 2021 22:22:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disrupted schooling, learning loss will have effects long after pandemic]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25983078">thread link</a>) | @throwawaysea
<br/>
January 31, 2021 | https://www.cbc.ca/news/pandemic-learning-gap-unesco-report-1.5888860 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/pandemic-learning-gap-unesco-report-1.5888860">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>From switching between remote and in-person learning to juggling&nbsp;class&nbsp;quarantines due to school-related&nbsp;cases, students continue to grapple with a&nbsp;tumultuous education&nbsp;experience amid COVID-19. Education experts say disrupted schooling and learning loss&nbsp;will persist long after the pandemic wanes.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5865738.1610073673!/cumulusImage/httpImage/image.jpg_gen/derivatives/16x9_780/1st-day-online-learning.jpg"></p></div><figcaption>Canadian students continue to grapple with a&nbsp;tumultuous education&nbsp;experience amid COVID-19, with education experts highlighting disrupted schooling and learning loss&nbsp;as longer-term concerns even after the coronavirus pandemic.&nbsp;<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure><p><span><p>Compared to last spring's nationwide school shutdown, Monica Belyea&nbsp;and her children are having a slightly easier time with remote learning this winter term. But the Toronto parent is already worried about the next school year.</p>  <p>While her kids Maddie and Ben have "amazing teachers who are doing the very best they can" amid Ontario's current school closure during a COVID-19 lockdown,&nbsp;Belyea wonders about how much curriculum is being covered in their respective Grade 6 and Grade 4 classes.</p>  <p>During her kids' remote classes, Belyea hears the teachers' time taken up troubleshooting tech problems and repeatedly walking students through online tools. Opportunities for one-on-one assistance have also waned. Ben, who is nine,&nbsp;shies away from asking for help online because he's self-conscious about classmates hearing him struggle.</p>  <p>"What happens in September? Are there going to be accommodations made for the fact that [many students] are going to be behind?" Belyea said.</p>  <p>"It's obviously not fair to the kids if they're suddenly just thrown back into — hopefully — a regular school in September and be expected to go full speed into the regular curriculum, if they're already behind from the year before."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5893147.1611962275!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/monica-belyea.jpg 300w,https://i.cbc.ca/1.5893147.1611962275!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/monica-belyea.jpg 460w,https://i.cbc.ca/1.5893147.1611962275!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/monica-belyea.jpg 620w,https://i.cbc.ca/1.5893147.1611962275!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/monica-belyea.jpg 780w,https://i.cbc.ca/1.5893147.1611962275!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/monica-belyea.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5893147.1611962275!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/monica-belyea.jpg"></p></div><figcaption>While her kids Maddie and Ben have 'amazing teachers who are doing the very best they can,' Toronto parent Monica Belyea wonders how much of the curriculum is being covered, and how the education system will address pandemic learning loss. <!-- --> <!-- -->(Turgut Yeter/CBC)</figcaption></figure></span></p>  <p>From switches between remote and in-person learning to juggling&nbsp;class&nbsp;quarantines due to school-related&nbsp;cases, Canadian students continue to grapple with a&nbsp;tumultuous education&nbsp;experience amid COVID-19. Education advocates and international experts alike are highlighting pandemic-disrupted schooling and learning loss&nbsp;as longer-term concerns that will persist even after COVID-19 wanes.</p>  <p>A year into the coronavirus pandemic, more than 800 million students&nbsp;— representing more than half the world's student population — continue to experience major disruptions in their schooling, according to <a href="https://en.unesco.org/news/unesco-figures-show-two-thirds-academic-year-lost-average-worldwide-due-covid-19-school" target="_blank">a new report from the&nbsp;United Nations Educational, Scientific and Cultural Organization (UNESCO)</a>.</p>  <p>In-person schools were completely shuttered for an average of 3.5 months since the global emergency began, UNESCO said. The figure rises&nbsp;to an average of 5.5 months when localized school closures are factored in, according to the report.</p>  <p>"The global shift to remote learning... has not served everyone equally in the world," said Stefania Giannini, UNESCO's assistant director general of education.</p>  <p><span><blockquote lang="en"><p>🔴 NEW DATA&lt;br&gt;&lt;br&gt;Two thirds of an academic year lost on average worldwide due to &lt;a href="https://twitter.com/hashtag/COVID19?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#COVID19&lt;/a&gt; school closure.&lt;br&gt;&lt;br&gt;Closures of &lt;a href="https://twitter.com/hashtag/education?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#education&lt;/a&gt; systems are impacting the most vulnerable. They must be a last resort &amp;amp; reopening them safely a priority.&lt;br&gt;&lt;br&gt;ℹ️ &lt;a href="https://t.co/DPfjoTkMYV"&gt;https://t.co/DPfjoTkMYV&lt;/a&gt; &lt;a href="https://twitter.com/hashtag/EducationDay?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#EducationDay&lt;/a&gt; &lt;a href="https://t.co/vaAVHyzUOL"&gt;pic.twitter.com/vaAVHyzUOL&lt;/a&gt;</p>&amp;mdash;<a href="https://twitter.com/UNESCO/status/1353611069416206338">@UNESCO</a></blockquote></span></p>  <p>More than 450 million students around the globe have been unable to access education during the pandemic, including many excluded from online learning due to lack of internet access at home, Giannini said.&nbsp;UNESCO currently projects that about 24 million children and youth are at risk of dropping out of school worldwide.</p>  <p>"It's about&nbsp;…&nbsp;those who were already behind being left behind&nbsp;more," Giannini said in an interview from Paris.&nbsp;"They are facing a kind of shadow pandemic."&nbsp;</p>  <p>Major school disruptions are something that countries like Canada cannot ignore, she said.</p>    <p>"We talk about the more marginalized in advanced countries as well," Giannini said. "It is a global crisis which is affecting children who are more disadvantaged because of their background, family background and not being so supported as the richest [students]."&nbsp;</p>  <h2>Some students were 'already scrambling to catch up'</h2>  <p>UNESCO's findings didn't come as any surprise to Toronto teacher Sam Tecle, who works with Success Beyond Limits, an education support, enrichment and&nbsp;mentoring organization based in the Jane and Finch neighbourhood where he grew up.</p>  <p>Success Beyond Limits formed in 2010 to help tackle the Jane and Finch neighbourhood's higher-than-normal high-school dropout rate&nbsp;and to work&nbsp;with incoming high school students who had already faced a difficult school experience before Grade 9.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5892483.1611933710!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_300/sam-tecle-covid-education.jpg 300w,https://i.cbc.ca/1.5892483.1611933710!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_460/sam-tecle-covid-education.jpg 460w,https://i.cbc.ca/1.5892483.1611933710!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_620/sam-tecle-covid-education.jpg 620w,https://i.cbc.ca/1.5892483.1611933710!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/sam-tecle-covid-education.jpg 780w,https://i.cbc.ca/1.5892483.1611933710!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_1180/sam-tecle-covid-education.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5892483.1611933710!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/sam-tecle-covid-education.jpg"></p></div><figcaption>'It always, always comes back to haunt us when we don't invest in education and our young people's futures, which is our future,' says Sam Tecle, a schoolteacher, professor at the University of Toronto and community advocate working with youth in Toronto’s Jane and Finch neighbourhood.<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure></span></p>  <p>"The kind of learning gaps UNESCO has just detailed in their recent report, we've been seeing that in communities like Jane and Finch — or others like it in Toronto&nbsp;— &nbsp;for the last 10 years," said Tecle, who is also a&nbsp;university professor and community advocate.</p>  <p>"Often we find that the students&nbsp;…&nbsp;who do not find success in the school system&nbsp;just find it difficult to find success, period&nbsp;—&nbsp;in the city, city life and social life. So that's the danger."&nbsp;</p>  <p><em><strong>WATCH | Sociology prof Janice Aurini explains&nbsp;how learning losses develop:</strong></em></p>  <p><span><span><div><div title="How learning gaps develop when students are out of school" role="button" tabindex="0"><div><div aria-labelledby="1794575939693-metadata-" title="How learning gaps develop when students are out of school"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/337/1007/JWO_ONLINE_LEARNING_GAP.transfer_frame_1341_corrected.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Sociology professor Janice Aurini explains how learning gaps can develop over summer breaks and why the pandemic has put the students most at risk in an even more vulnerable position.<!-- --> <!-- -->1:49</span></span></span></p>  <p>For students already working through challenges at school, the pandemic exacerbated their struggle to have an enriching educational experience, Tecle said.&nbsp;</p>  <p>"They were&nbsp;already scrambling to catch up."</p>  <p>The sudden&nbsp;changes and major structural shifts to education made amidst the pandemic —&nbsp;including the pivot to learning remotely online — have hit marginalized communities hard and taken them longer to adjust to, he said.</p>  <p>Many marginalized&nbsp;families face multiple challenges. They might include adequate internet access, a&nbsp;sufficient number of devices for online learning, parents who are unable to work from home and support their children, and a lack of supervised&nbsp;care for younger children.</p>    <p>Beyond what individual educators or groups like Success Beyond Limits are doing to address learning loss, "we know that our program alone cannot mitigate the tide," says Tecle. He&nbsp;believes school districts and governments must pay greater attention to it and invest in fixing the problem.</p>  <p>"It always, always comes back to haunt us when we don't invest in education and our young people's futures, which is our future," he said.</p>  <h2>Education investments needed, says UNESCO</h2>  <p>Outside of a pandemic, teachers are typically already on the lookout for students struggling with learning loss and subsequently working toward eliminating that gap. Canada also has pre-existing summer school programs designed to help students catch up.&nbsp;Ontario, for instance, funds two- to three-week summer programs. They are&nbsp;offered by nearly every school board in the province&nbsp;to support students with learning loss.&nbsp;&nbsp;</p>    <p>Beyond what's in place, Ontario is exploring measures to support learning recovery and working on a further plan to target learning loss "head on —&nbsp;with enhanced supports for reading and math for all students, for vulnerable children, including students with exceptionalities and from underrepresented communities," said Caitlin Clark, spokesperson for Ontario Education Minister Stephen Lecce.&nbsp;</p>  <p><span><span><iframe src="https://www.youtube.com/embed/2gV9UBgoCRw" frameborder="no" title="YouTube content" allowfullscreen=""></iframe></span></span></p>  <p>Protecting and increasing investments into education&nbsp;is what UNESCO's Giannini&nbsp;wants to see. It was first among the priorities in a "roadmap" that came out of the&nbsp;organization's&nbsp;<a href="https://unesdoc.unesco.org/ark:/48223/pf0000375301?posInSet=2&amp;queryId=75386d01-3f82-4af9-bf18-0fa529ce8505" target="_blank">global education meeting</a>, held virtually last October.</p>  <p>Next is reopening schools with layers of preventative health and safety measures in place, followed by supporting teachers receiving "better and more training," as well as prioritizing them as "classroom front-line workers" in vaccination campaigns, according to Giannini.</p>  <p>Equitably bridging the digital divide and reimagining education systems to make schools more resilient and adaptable for the future are also on UNESCO's to-do list.</p>  <p>"Political leaders have to realize that not investing in education today is about compromising the future of our young people [and] it's also compromising development and and economic growth," Giannini said.&nbsp;</p>  <p>"It's not a competition&nbsp;…&nbsp;between reopening schools and reopening restaurants or pubs. It's about prioritizing education as the real basic human right."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/pandemic-learning-gap-unesco-report-1.5888860</link>
            <guid isPermaLink="false">hacker-news-small-sites-25983078</guid>
            <pubDate>Sun, 31 Jan 2021 22:11:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NES.css – NES-Style CSS Framework]]>
            </title>
            <description>
<![CDATA[
Score 687 | Comments 117 (<a href="https://news.ycombinator.com/item?id=25982999">thread link</a>) | @dsego
<br/>
January 31, 2021 | https://nostalgic-css.github.io/NES.css/ | <a href="https://web.archive.org/web/*/https://nostalgic-css.github.io/NES.css/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <a :class="{ active:  scrollPos < 200 }" href="https://github.com/nostalgic-css/NES.css" target="_blank" rel="noopener" @mouseover="startAnimate" @mouseout="stopAnimate">
            <p>Fork me<br>on GitHub</p>
            <i :class="animateOctocat ? 'animate' : ''"></i>
          </a>

          <!-- About -->
          <section>
            <h2 id="about"><a href="#about">#</a>About</h2>
            <p>NES.css is NES-style (8bit-like) CSS Framework.</p>
          </section>


          <!-- Installation -->
          <section>
            <h2 id="installation"><a href="#installation">#</a>Installation</h2>
            <p>NES.css is available via either npm or Yarn, or a CDN.</p>
            <p>Please read <a href="https://github.com/nostalgic-css/NES.css" target="_blank" rel="noopener">README.md</a>.</p>
          </section>

          <!-- Usage -->
          <section>
            <h2 id="usage"><a href="#usage">#</a>Usage</h2>
            <p>NES.css only provides components. You will need to define your own layout.</p>

            <section v-for="sample in collection" :key="sample">
              <section>
                <h3>{{ sample.title | capitalize }}</h3>
                
                <p v-if="sample.description">{{ sample.description }}</p>
                <p v-if="sample.note">{{ sample.note }}</p>
                
              </section>
              <section v-show="sample.showCode">
                
                <pre><code>{{ sample.code }}</code></pre>
              </section>
            </section>
          </section>

          <!-- Members -->
          <section>
            <h2 id="members"><a href="#members">#</a>Members</h2>
            <section>
              <h3><i></i>Core Team Members</h3>
              <p>Here is core team members developing NES.css.</p>

              
            </section>
            <section v-if="emeriti.length > 0">
              <h3><i></i>Core Team Emeriti</h3>
              <p>Here we honor some no-longer-active core team members.</p>

              
            </section>
            <section>
              <h3><i></i>Contributors</h3>
              <template v-for="user in contributors">
                <a class="contributor" :href="'https://github.com/' + user" target="_black">
                  <img class="nes-avatar is-large is-rounded lazy" :data-src="'https://github.com/' + user + '.png?size=64'" :alt="'Contributor ' + user">
                  <p>{{ user }}</p>
                </a>
              </template>
            </section>
          </section>

          <!-- Articles -->
          <section>
              <h2 id="articles"><a href="#articles">#</a>Articles</h2>
              <article>
                <h3>
                  <a href="https://medium.com/@bc_rikko/why-i-created-and-released-nes-css-ee8966bacd09" target="_blank" rel="noopener"><i></i><span>Why I created and released NES.css</span></a>
                </h3>
              </article>
              <article>
                <h3>
                  <a href="https://github.blog/2019-01-20-release-radar-december-2018/#nes-css-1-0" target="_blank" rel="noopener"><i></i><span>Release Radar·December 2018|The GitHub Blog</span></a>
                </h3>
              </article>
          </section>

        </div></div>]]>
            </description>
            <link>https://nostalgic-css.github.io/NES.css/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25982999</guid>
            <pubDate>Sun, 31 Jan 2021 22:04:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhatsApp and the Domestication of Users]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 106 (<a href="https://news.ycombinator.com/item?id=25982860">thread link</a>) | @upofadown
<br/>
January 31, 2021 | https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemscope="" itemtype="https://schema.org/BlogPosting">
	<article itemprop="mainEntityOfPage">
		
		<section itemprop="articlebody">
			<p>I have never used WhatsApp, and never will. Despite this, I still feel the need to write an article about WhatsApp since it’s the perfect case study to help understand a class of businesses models I call “user domestication”. The domestication of users is high on my list of problems plaguing the human race, and is worth a detailed explanation.</p>
<p>WhatsApp wasn’t the first instant messenger of its kind, and probably won’t be the last. I simply chose to focus on WhatsApp since its recent privacy issues have made it a hot topic.</p>
<p>With the meta-explanation out of the way, let us begin.</p>
<h2 id="whatsapps-rise">WhatsApp’s rise</h2>
<p>For those unfamiliar, WhatsApp is a tool that makes it convenient and easy to help Facebook further its core mission: the optimization and auctioning of human behavior (colloquially known as “targeted advertising”). It originally persuaded people to consent to this by allowing them to send text to each other over the Internet, something that was <a href="https://en.wikipedia.org/wiki/Comparison_of_instant_messaging_protocols">already possible</a>, and combining an easy-to-learn UI with successful marketing. It then expanded to include features such as free voice and video calls. Free calls helped it grow to become the de-facto communication platform many regions. I’m stunned at its ubiquity every time I visit my extended family in India; I’m frequently greeted by looks of confusion when I remind them that I don’t use WhatsApp.</p>
<p>Having its own proprietary chat system incompatible with other clients allowed WhatsApp to build a <a href="https://en.wikipedia.org/wiki/Network_effect">network effect</a>: WhatsApp’s existing users were held captive by the fact that leaving WhatsApp meant losing the ability to communicate with WhatsApp users. People switching from WhatsApp must convince all their friends to switch, too; this includes less technically inclined friends who had a hard time learning WhatsApp in the first place.</p>
<p>In a WhatsApp world, people who want to keep in touch must abide by the following rules:</p>
<ul>
<li>Everyone can only use the proprietary WhatsApp client to send messages; developing alternative clients isn’t supported.</li>
<li>Everyone’s mobile device must run an operating system supported by said client. Since WhatsApp developers will only write a client for popular operating systems, the Android and iOS duopoly strengthens.</li>
<li>Users fully depend on WhatsApp developers. If WhatsApp developers decide to include user-hostile features in the app, users must go with it. They can’t switch to a different server or client without switching away from WhatsApp and losing the ability to communicate with all their WhatsApp contacts.</li>
</ul>
<h2 id="user-domestication">User domestication</h2>
<p>WhatsApp rose by trapping previously-free beings in their corral and changing their habits to create dependence on masters. Over time, this made it difficult or impossible to return to their previous lifestyle. That process should sound familiar: it’s eerily similar to the domestication of animals. I call this type of vendor lock-in <strong>user domestication:</strong> the removal of user autonomy to trap users into serving vendors.</p>
<p>I chose this metaphor because animal domestication is a gradual process that isn’t always deliberate, and typically revolves around one group becoming dependent upon another. For example: there’s evidence that domestication of dogs began with socialization, resulting in not-entirely-artificial selection promoting genes that resulted in more friendliness with and dependence upon humans.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Whether it happens on purpose or by accident, user domestication almost always follows the same three steps:</p>
<ol>
<li>A high level of dependence given from users to a software vendor</li>
<li>An inability for users to control their software, through at least one of the following methods:
<ol>
<li>Preventing modification of the software</li>
<li>Preventing migration onto a different platform</li>
</ol>
</li>
<li>The exploitation of now-captive users who are unable to resist</li>
</ol>
<p>The completion of the first two steps left WhatsApp users vulnerable to user domestication. With investors to answer to, they had every incentive to implement user-hostile features without consequence.</p>
<p>So, of course, they did.</p>
<h2 id="whatsapps-descent">WhatsApp’s descent</h2>
<p>Domestication has a purpose: it enables a master species to exploit the domesticated species for its own gain.</p>
<p>Recently, WhatsApp updated its privacy policy to allow sharing data with its parent, Facebook. Users who agreed to use WhatsApp under its previous privacy policy had two options: agree to the new policy or be unable to use WhatsApp again. The WhatsApp privacy policy update is a classic bait-and-switch: WhatsApp lured users in with a sleek interface and the impression of privacy, domesticated them to remove their autonomy to migrate, and then backtracked on its previous commitment to privacy with minimal consequence. Each step in this process enabled the next; had user domestication not taken place, it would be easy for most users to switch away with minimal friction.</p>
<p>Those of us who were sounding the alarm a few years ago experienced a brief moment of sadistic bliss when our titles were upgraded from “annoying and paranoid conspiracy theorists” to just “annoying”.</p>
<h3 id="an-attempt-at-damage-control">An attempt at damage control</h3>
<p>The bait-and-switch operation incurred backlash significant enough for a noticeable minority of users to actually migrate; this number turned out to be slightly more than the rounding error WhatsApp was likely expecting. In response, WhatsApp delayed the change and published the following ad:</p>
<picture>
	<source srcset="https://seirdy.one/p/whatsapp_ad_dark.3e9ad6a0c2c8c377c4583cf92bddcd47.avif" type="image/avif" media="(prefers-color-scheme: dark)">
	<source srcset="https://seirdy.one/p/whatsapp_ad_dark.09f935219fb9d5ac9fa9bc4acb733d13.webp" type="image/webp" media="(prefers-color-scheme: dark)">
	<source srcset="https://seirdy.one/p/whatsapp_ad_dark.8792c2187d444ebc32bf8c386ea0cda9.png" type="image/png" media="(prefers-color-scheme: dark)">
	<source srcset="https://seirdy.one/p/whatsapp_ad.94ed78578e240dfd57f833807f8167ed.avif" type="image/avif">
	<source srcset="https://seirdy.one/p/whatsapp_ad.9efe174613a8b02274fa62feff7b8374.webp" type="image/webp">
	<source srcset="https://seirdy.one/p/whatsapp_ad.b81802ac13cd4a2540211e05819cd29e.png" type="image/png">
	<img width="600" src="https://seirdy.one/p/whatsapp_ad.png" alt="WhatsApp ad describing data not collected">
</picture>

<p>The ad lists various data that WhatsApp doesn’t collect or share. Allaying data collection concerns by listing data <em>not</em> collected is misleading. WhatsApp doesn’t collect hair samples or retinal scans either; not collecting that information doesn’t mean it respects privacy because it doesn’t change the information WhatsApp <em>does</em> collect.</p>
<p>The ad denies “keep[ing] logs of who everyone is messaging or calling”. Collecting data is not the same as “keeping logs”; it’s possible for metadata to be fed into an algorithm before being discarded. A model can thus learn that two users call each other frequently without keeping logs of the metadata for each call. The fact that they specifically chose to phrase this line around logging implies that WhatsApp either already collects this class of data or has deliberately left the door open to collecting it in the future.</p>
<p>A stroll through WhatsApp’s <a href="https://web.archive.org/web/20210124061525/https://www.whatsapp.com/legal/updates/privacy-policy/?lang=en">actual privacy policy</a> at the time reveals that they do collect considerable metadata used for marketing through Facebook.</p>
<h2 id="software-freedom">Software freedom</h2>
<p>With user domestication, providing useful software to users is a means to the end of exploiting them. The alternative is simple: make serving users the end in and of itself.</p>
<p>To prevent being controlled by software, users must be in control. Software that allows users to be in control is called <a href="https://en.wikipedia.org/wiki/Free_software">free software</a>. The word “free” in this context refers to freedom rather than price. Software freedom is similar to the concept of open-source, but the latter is focused on practical benefits rather than ethics. A less ambiguous term that neutrally refers to both free and open-source software is <strong><abbr title="free and open-source software">FOSS</abbr></strong>.</p>
<p>Others have <a href="https://www.gnu.org/philosophy/free-sw.en.html">explained</a> the concepts underpinning free software better than I can, so I won’t go into detail. It comes down to four essential freedoms:</p>
<ul>
<li>The freedom to run the program as you wish, for any purpose</li>
<li>The freedom to study how the program works, and change it so it does your computing as you wish</li>
<li>The freedom to redistribute copies so you can help others</li>
<li>The freedom to distribute copies of your modified versions to others</li>
</ul>
<h3 id="making-money-with-foss">Making money with FOSS</h3>
<p>The most common objection I hear is that FOSS makes it harder to make money.</p>
<p>The key to making money with FOSS is to make software a <a href="https://www.gwern.net/Complement">commoditized complement</a> of other, more profitable services. Examples of such services include selling support, customization, consulting, training, managed hosting, hardware, and certifications. Plenty of companies use this approach instead of building proprietary software: Red Hat, Collabora, System76, Purism, Canonical, SUSE, Hashicorp, Databricks, and Gradle are some names that come to mind.</p>
<p>Managed hosting isn’t a basket worth all your eggs if giants like AWS can do the same at a lower price. Being the developer can give an edge in areas like customization, support, and training; it doesn’t offer as obvious an advantage when it comes to hosting.</p>
<h2 id="foss-isnt-always-enough">FOSS isn’t always enough</h2>
<p>Free software is a necessary but sometimes insufficient requirement to build domestication immunity. Two more measures include <strong>simplicity</strong> and <strong>open platforms.</strong></p>
<h3 id="simplicity">Simplicity</h3>
<p>When software grows too complex, it needs to be maintained by a large team. Users who disagree with a vendor can’t easily fork and maintain a multi-million-line codebase, especially if the software in question potentially contains security vulnerabilities. Dependence on the vendor can grow quite problematic when complexity causes development costs to skyrocket; the vendor might resort to implementing user-hostile features to stay afloat.</p>
<p>Complex software that can’t be developed by a different group of people creates dependence, step one of user domestication. That alone is enough to open the door to problematic developments.</p>
<h4 id="case-study-mozilla-and-the-web">Case study: Mozilla and the Web</h4>
<p>Mozilla was a ray of hope in the browser wars, a space dominated by adtech, surveillance, and vendor lock-in. Unfortunately, developing a browser engine is a monumental task difficult enough for Opera and Microsoft to give up and re-skin Chromium. Browsers are more than the document readers they were meant to be: they’ve evolved into application runtimes with their own stacks for GPU acceleration, Bluetooth, permissions, device enumeration, bundled media codecs, <abbr title="digital rights management">DRM</abbr><sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, extension APIs, developer tools…the list goes on. It takes billions of dollars a year to respond to vulnerabilities in such a massive attack surface and keep up with a standard that grows at such a worrying rate. Those billions have to come from somewhere.</p>
<p>Mozilla ended up having to make major compromises to stay afloat. It cut search deals with blatantly user-hostile companies, and bundled the browser with <a href="https://blog.mozilla.org/advancingcontent/2014/02/11/publisher-transformation-with-users-at-the-center/">ads</a> and bloatware such as a partially …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html">https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html</a></em></p>]]>
            </description>
            <link>https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25982860</guid>
            <pubDate>Sun, 31 Jan 2021 21:45:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Radio-Carbon Dating of the Voynich MS]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25982774">thread link</a>) | @Hooke
<br/>
January 31, 2021 | http://www.voynich.nu/extra/carbon.html | <a href="https://web.archive.org/web/*/http://www.voynich.nu/extra/carbon.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">





<h2>Introduction</h2>

<p>
In 2009 the parchment of the Voynich MS was subjected to radio-carbon dating and the result was that this parchment dates to sometime between 1404 and 1438 with 95% probability. The analysis was done in the frame of an ORF TV documentary, and the public announcement was made during a press conference on 8 December 2009. The radio-carbon dating was performed by the University of Arizona, and described in some detail in an internal report. It has been publicly presented at several occasions
<a href="#n01">(1)</a>,
but I am not aware of a published paper on this topic.
</p>

<p>
The present page is meant as an explanation of the relevant aspects of this analysis, for non-experts. It is not copying information from the internal report (except when specifically stated), but an independent explanation and calculation.
</p>

<h2>The principle behind radio-carbon dating</h2>

<p>
All organic matter is based on ‘normal’ carbon, with a small fraction of ‘different’ carbon. This normal carbon is denoted as <sup>12</sup>C and the different carbon as <sup>14</sup>C, where <sup>14</sup>C atoms are not stable. Additional types ('isotopes') exist, for example <sup>13</sup>C, but their role in this process may be left outside the present discussion.
<sup>14</sup>C atoms decay slowly but steadily. When an organism is alive, it will tend to have the same ratio of <sup>12</sup>C and <sup>14</sup>C as its environment, as it is in an equilibrium with this environment, because it feeds from it (breathing the atmosphere and feeding from other organic matter). However, when the organism dies, this feeding stops, and the decay of the <sup>14</sup>C atoms begins. This decay follows an exponential trend, such that after about 5700 years only half of the original fraction of <sup>14</sup>C remains. By measuring the ratio of <sup>14</sup>C atoms to <sup>12</sup>C atoms, and comparing it with the present time, one can see how much decay has taken place, and derive how old this organic matter is.
</p>

<p>
The Voynich MS has been written on parchment and parchment is made from animal skin. It can be dated based on the principle described above, and the result gives the time that the animal, whose skin was used, died.
</p>

<p>
One complication in this process is, that the ratio of <sup>12</sup>C and <sup>14</sup>C in the environment was not constant over time in the past centuries, or millennia. This fact has been established by comparing the <sup>14</sup>C contents of trees that could be precisely dated using tree ring analysis.
</p>

<p>
A second complication is, that as from World War II nuclear detonations have generated large amounts of <sup>14</sup>C in the atmosphere that has nothing to do with the natural decay process. As a result, the <sup>14</sup>C content after 1950 is severely disturbed, and the year 1950 has been defined as the reference. In the radio-carbon dating world, ‘before present’ therefore means before 1950.
</p>

<p>
Had complication one not existed, a very simple and smooth curve would have allowed to date any item based on its <sup>14</sup>C contents compared to the 1950 standard. Dates or ages computed in this way are referred to as <i>un-calibrated</i>.
</p>

<p>
Instead, based on the tree ring analysis, reality looks very different. In Figure 1a below, the smooth blue curve is the hypothetical relation between <sup>14</sup>C fraction and age, while the more complicated red curve more closely represents reality reconstructed from the above-mentioned tree ring analysis
<a href="#n02">(2)</a>.
This second graph represents the so-called <i>calibrated</i> date. Both are shown for the time frame of interest for the Voynich MS, but can be used also for times much further in the past.
</p>

<p>
&nbsp;
<br>
<img src="http://www.voynich.nu/extra/img/14C_fig01.gif">
<br>
<span>Figure 1a: The radio-carbon calibration curve.</span>
</p>

<p>
In Figure 1b, <i>un-calibrated</i> and <i>calibrated</i> dates are shown against each other, with the <i>un-calibrated</i> date on the vertical scale.
</p>

<p>
&nbsp;
<br>
<img src="http://www.voynich.nu/extra/img/14C_fig01b.gif">
<br>
<span>Figure 1b: The radio-carbon calibration curve expressed in dates. Calibrated dates are on the horizontal scale and un-calibrated dates on the vertical scale.</span>
</p>

<h2>The samples of the Voynich MS to be subjected to radio carbon dating</h2>

<p>
The discussion to decide which folio or folios to test started in 2008. There were large uncertainties related to the origin of the Voynich MS, with theories ranging between the 13th Century (Roger Bacon autograph), 15th Century (based on the style of the MS), around 1600 (Dee/Kelley fake MS) up to 1912 (fake by W. Voynich). Since it is possible that the Voynich MS was written over a longer time period, or perhaps using parchment from several different origins, it was considered important to take several samples. However, radio-carbon dating is a very expensive procedure, and the MS should not be damaged too much, so it was agreed between the group funding the research and the Beinecke library to use a maximum of four samples. These samples were selected to allow the largest possible variety and therefore possibly time range. More specifically, the following reasoning was applied:
</p>

<ul>
 <li>
Already in the 1970’s Prescott Currier suggested that the Voynich MS is written in two different ‘hands’ and two different ‘languages’, which he called ‘A’ and ‘B’. The difference is most visible in the herbal section of the MS. The different hands/languages could be from two scribes, or from one scribe at very different times.  It was decided that it would be important to have at least one sample from each.
 </li>

 <li>
Furthermore, a small number of folios have been observed to be clearly thicker than others, for example the bifolio 42 + 47. As this could indicate a different batch of parchment, it was decided to include a sample from this thick bifolio.
</li> 

 <li>
The manuscript is particular in that it has quite a number of oversized foldout folios. It is clearly of interest to include a sample from one of these.
 </li> 

 <li>
Finally, it was recommended to include samples from pages that have other dating evidence as well. In the Voynich MS these are:
  <ul>
   <li>
The <span>ex libris</span> of Tepenec (around 1608). Instead of the heavily stained folio 1, one could use the other part of the bifolio, which is folio 8.
   </li>
   <li>
A castle in a style used only after ~1300 (on the so-called rosettes page). The library did not wish this folio to be damaged.
   </li>
  </ul> 
 </li> 
</ul>

<p>
The final decision on the samples to be taken was as follows:
</p>

<table>
 <tbody><tr>
  <th>Fol.8</th>
  <td>
Herbal A, standard folio, thin parchment, Tepenec <span>ex libris</span>
  </td>
 </tr>
 <tr>
  <th>Fol.26</th>
  <td>
Herbal B, standard folio, thin parchment, ink and pigments also sampled for chemical analysis
  </td>
 </tr>
 <tr>
  <th>Fol.47</th>
  <td>
Herbal A, standard folio, thick parchment, ink and pigments also sampled for chemical analysis
  </td>
 </tr>
 <tr>
  <th>Fol.68</th>
  <td>
Astronomical, foldout folio
  </td>
 </tr>
</tbody></table>

<p>
<span>Table 1: the four samples that were taken from the Voynich MS for radio-carbon dating.</span> 
</p>

<h2>Results as presented</h2>

<p>
Following are the measured <sup>14</sup>C content of the four samples as presented by G.Hodgins during the Voynich MS centenary event in Villa Mondragone on 11 May 2012. The error distribution of these measurements is assumed to be Gaussian and the sigma (standard deviation) of this distribution is also given. This standard deviation is based on the uncertainty of the measurement process
<a href="#n03">(3)</a>.
</p>

<table>

<tbody><tr><th>Fol. Nr.</th> <th>Description</th>
<th><sup>14</sup>C fraction</th> <th>Sigma</th></tr>

<tr>
<td>8</td> <td>Herbal-A (Tepenec signature)</td>
<td>0.9409</td> <td>0.0044</td>
</tr>

<tr>
<td>26</td> <td>Herbal-B</td>
<td>0.9380</td> <td>0.0041</td>
</tr>

<tr>
<td>47</td> <td>Herbal-A (thick folio)</td>
<td>0.9389</td> <td>0.0041</td>
</tr>

<tr>
<td>68</td> <td>Astronomical foldout</td>
<td>0.9338</td> <td>0.0041</td>
</tr>

</tbody></table>

<p>
<span>Table 2: measured <sup>14</sup>C content for the four samples.</span> 
</p>

<p>
The probability distributions of the four measurements are shown together in Figure 2 below:
</p>

<p>
<img src="http://www.voynich.nu/extra/img/14C_fig02.jpg">
<br>
<span>Figure 2: The probability distributions of the measurements for the four samples of the Voynich MS.</span>
</p>

<p>
This shows in a very visual, yet qualitative way that the four measurements are consistent. There is no indication that the samples represent a different age.
</p>

<p>
The unweighted mean of the four observed values in the Table above is 0.9379, and the standard deviation of these four values is 0.0030. While a standard deviation of only four samples cannot have a high level of confidence, the value is well below the standard deviation of the individual measurements. In other words: the spread of the measurements is less than their inherent error. This quantitatively confirms the consistency of the measurements.
</p>

<h2>Uncalibrated age</h2>

<p>
The red curve above, showing the relation between <sup>14</sup>C fraction and age, was published by Reimer et al in 2013
<a href="#n02">(see note 2)</a>.
This publication presents the relationship between <i>un-calibrated</i> age and <i>calibrated</i> age, where the <i>un-calibrated</i> age is derived from the <sup>14</sup>C fraction using an exponential decay with a half life of 5568 years
<a href="#n04">(4)</a>.
The practical advantage of using <i>un-calibrated</i> age instead of <sup>14</sup>C fraction is that the relation between <i>un-calibrated</i> and <i>calibrated</i> age is close to linear over the full range of its validity, going back tens of thousands of years before present. Apart from that, the quantity <i>un-calibrated</i> age is not particularly meaningful by itself.
</p>

<p>
The relation between <sup>14</sup>C fraction and un-calibrated age is sufficiently close to linear in our range of interest, to consider also the un-calibrated age to follow a normal error distribution, and the age and standard deviation for the four sampled leaves may be computed as follows:
</p>

<table>

<tbody><tr><th>Fol. Nr.</th> <th>Age (before 1950)</th>
<th>Year</th> <th>Sigma</th></tr>

<tr>
<td>8</td> <td>489</td>
<td>1461</td> <td>38</td>
</tr>

<tr>
<td>26</td> <td>514</td>
<td>1436</td> <td>35</td>
</tr>

<tr>
<td>47</td> <td>506</td>
<td>1444</td> <td>35</td>
</tr>

<tr>
<td>68</td> <td>550</td>
<td>1400</td> <td>35</td>
</tr>

</tbody></table>

<p>
<span>Table 3: un-calibrated ages and dates for the four samples.</span> 
</p>

<p>
The probability distributions may again be shown together in one graph:
</p>

<p>
<img src="http://www.voynich.nu/extra/img/14C_fig03.jpg">
<br>
<span>Figure 3: The probability distributions of the un-calibrated dates for the four samples of the Voynich MS.</span>
</p>

<p>
In this case, the mean and standard deviation of the four measurements are 1435 and 26 years respectively.
</p>

<h2>Calibrated age</h2>

<p>
The process to derive the calibrated age from the <sup>14</sup>C fraction or the un-calibrated age can best be illustrated in several steps. Taking fol.26 as an example, one can see where the fraction 0.9380 intersects the red calibration curve and derive the calibrated age. Doing this results in the year 1420:
</p>

<p>
<img src="http://www.voynich.nu/extra/img/14C_fig04.gif">
<br>
<span>Figure 4: deriving calibrated date for fol.26 from the <sup>14</sup>C fraction and the calibration curve.</span>
</p>

<p>
However, both the measurement of the <sup>14</sup>C fraction and the calibration curve have their uncertainties or errors, which need to be taken into account. Let us look at the uncertainty or error of the calibration curve …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.voynich.nu/extra/carbon.html">http://www.voynich.nu/extra/carbon.html</a></em></p>]]>
            </description>
            <link>http://www.voynich.nu/extra/carbon.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25982774</guid>
            <pubDate>Sun, 31 Jan 2021 21:34:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Isometric Blocks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25982749">thread link</a>) | @autoditype
<br/>
January 31, 2021 | http://shaunlebron.github.io/IsometricBlocks/ | <a href="https://web.archive.org/web/*/http://shaunlebron.github.io/IsometricBlocks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<a href="https://github.com/shaunew/IsometricBlocks"><img src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub"></a>


	

	<p>
In an <a href="http://en.wikipedia.org/wiki/Isometric_projection">isometric</a>
display, it can be tricky to draw boxes of various sizes in the correct order
to keep them appropriately in front of or behind one another.  The figure below
shows an example.  The blue box should be drawn first, then green, then red.
	</p>

	<figure>
		<canvas id="figure1a" width="350" height="200"></canvas>
		<canvas id="figure1b" width="350" height="200"></canvas>
		<figcaption>
Figure 1: The boxes on the left are <u>not</u> drawn in the correct order, whereas the
boxes on the right are drawn correctly.
		</figcaption>
		
	</figure>

	<p>
We will explore a simple solution for determining the correct order to draw a
given set of boxes.  But first, we must define what we mean by <em>boxes</em>.
	</p>

	<h3>What do we mean by <em>boxes</em>?</h3>

	<p>
We define boxes as <em>axis-aligned</em> and <em>non-intersecting</em>
rectangular prisms. Take a look at the above Figure 1 again.  Each box is
parallel to the <em>x</em>, <em>y</em>, and <em>z</em> axis (i.e.
axis-aligned).  Also, note that the boxes are next to each other but do not
intersect.
	</p>

	<h3>Determine if boxes overlap on screen.</h3>

	<p>
First of all, if two boxes do not overlap on the screen, then we do not have to
worry about which one is drawn first.  This is the first test we must perform,
which we explore in this section.
	</p>

	<figure>
		<canvas id="figure2a" width="350" height="200"></canvas>
		<canvas id="figure2b" width="350" height="200"></canvas>
		<figcaption>
Figure 2: No overlap on the left; overlap on the right.  (Note: we are talking
about overlap on screen, not intersection in space.)
		</figcaption>
		
	</figure>

	<p>
The silhouettes of the 3D boxes become 2D hexagons in the isometric view, as seen below.  We use the
outline of these silhouettes to test for overlap.
	</p>

	<figure>
		<canvas id="figure3a" width="350" height="200"></canvas>
		<canvas id="figure3b" width="350" height="200"></canvas>
		<figcaption>
Figure 3: The box silhouettes in an isometric view are simple hexagons.  Note
that their sides are always parallel to the vertical and two diagonal axes.
		</figcaption>
		
	</figure>

	<p>
We take advantage of the fact that the hexagon sides are always parallel to
some axis.  This allows us to easily determine if the hexagons overlap by
checking for intersection of their regions on each axis.  We add an <em>h</em>
(horizontal) axis to help.
	</p>

	<figure>
		<canvas id="figure4a" width="350" height="200"></canvas>
		<canvas id="figure4b" width="350" height="200"></canvas>
		<figcaption>
The red and blue boxes do not overlap on the h axis, therefore they do not overlap.
The green and blue boxes do overlap since their region on every axis overlap.
		</figcaption>
		
	</figure>

	<p>
Now that we have outlined our concept for <em>determining if two boxes overlap
on the screen</em>, we will fill in the details necessary for implementing it.
	</p>

	<p>
The act of flattening the 3D box into a 2D hexagon involves getting rid of the
Z coordinate.  Notice that increasing a point's Z coordinate by 1 is the same
as incrementing both X and Y coordinates by 1.  Thus, we can add Z to both X
and Y and drop Z completely.  Shown below is the source code for a function
that performs this conversion.
	</p>

<code>
<span>function</span> spaceToIso(spacePos) <span>{</span>

    
    <span>var</span> isoX = spacePos.x + spacePos.z;
    <span>var</span> isoY = spacePos.y + spacePos.z;

    <span>return</span> <span>{</span>
        x: isoX,
        y: isoY,

        
        h: (isoX - isoY) * Math.cos(Math.PI/6),

        
        v: (isoX + isoY) / 2;
    <span>}</span>;
<span>}</span></code>

	<p>
And finally, after determining the bounds of each hexagon, we can determine if
they overlap by using the source code below.
	</p>

<code><span>function</span> doHexagonsOverlap(hex1, hex2) <span>{</span>
    
    <span>return</span> (

        
        !(hex1.xmin &gt;= hex2.xmax || hex2.xmin &gt;= hex1.xmax) &amp;&amp;

        
        !(hex1.ymin &gt;= hex2.ymax || hex2.ymin &gt;= hex1.ymax) &amp;&amp;

        
        !(hex1.hmin &gt;= hex2.hmax || hex2.hmin &gt;= hex1.hmax));
<span>}</span></code>

	<p>
Now that we have determined if two boxes overlap on the screen, we can begin exploring how to determine which box is in front of the other.
	</p>

	<h3>Determine which box is in front.</h3>

	<p>
Recall that our boxes do not intersect each other. we can visualize their separation
as a thin plane between them (see Figure 5 below).  After identifying this
plane, we can determine which box is in front by selecting the one on the
correct side of this plane.
	</p>

	<figure>
		<canvas id="figure5a" width="230" height="200"></canvas>
		<canvas id="figure5b" width="230" height="200"></canvas>
		<canvas id="figure5c" width="230" height="200"></canvas>
		<figcaption>
Figure 5: A pair of blocks can be separated in one of three ways shown here.
The dark glass illustrates this separation.
		</figcaption>
		
	</figure>

	<p>
We can find this plane of separation by looking at each axis individually.  In
particular, we look for an axis which has non-intersecting box ranges (see
Figure 6 below).
	</p>

	<figure>
		<canvas id="figure6a" width="350" height="200"></canvas>
		<canvas id="figure6b" width="350" height="200"></canvas>
		<figcaption>
Figure 6: On the left, the blocks are separated on the y-axis.  On the right,
the blocks are separated on the x-axis. (The z-axis is omitted for simplicity.)
		</figcaption>
		
	</figure>

	<p>
In Figure 6 above, we have chosen a coordinate system which make lesser values
of <em>x</em> and <em>y</em> to be closer to the camera.  Though not shown, the
<em>z</em> axis is positive in the up direction, so a greater value makes it
closer to the camera.
	</p>

	<p>
The following is a javascript function for determining if the first block is in
front of the second:
	</p>

	<code><span>function</span> isBoxInFront(box1, box2) <span>{</span>

    
    
    <span>if</span> (box1.xmin &gt;= box2.xmax) <span>{</span> <span>return</span> <span>false</span>; <span>}</span>
    <span>else</span> <span>if</span> (box2.xmin &gt;= box1.xmax) <span>{</span> <span>return</span> <span>true</span>; <span>}</span>

    
    
    <span>if</span> (box1.ymin &gt;= box2.ymax) <span>{</span> <span>return</span> <span>false</span>; <span>}</span>
    <span>else</span> <span>if</span> (box2.ymin &gt;= box1.ymax) <span>{</span> <span>return</span> <span>true</span>; <span>}</span>

    
    
    <span>if</span> (box1.zmin &gt;= box2.zmax) <span>{</span> <span>return</span> <span>true</span>; <span>}</span>
    <span>else</span> <span>if</span> (box2.zmin &gt;= box1.zmax) <span>{</span> <span>return</span> <span>false</span>; <span>}</span>

<span>}</span></code>

	<h3>Draw boxes in the correct order.</h3>

	<p>
In general, <u>a box should not be drawn until all the ones behind it are
drawn</u>.  Thus, we begin by drawing the boxes that have nothing behind them.
Then, we can draw the boxes that are only in front of those that are already
drawn. This process continues until all boxes are drawn. (See Figure 4 below
for an example.)
	</p>

	<figure>
		<canvas id="figure7" width="650" height="200"></canvas>
		<figcaption>
Figure 4: (1) Nothing is behind blue, so draw it first. (2) Draw green next
since blue was the only one behind it and is already drawn.  (3) Then draw red,
since both blocks that were behind it have been drawn.
		</figcaption>
		
	</figure>

	<p>
To implement this algorithm, each box must know exactly which boxes are behind
it.  We have already determined how to do this in the last section.  A search
must be implemented so that each box has a list of boxes behind it.
	</p>

	<p>
You are now armed with everything you need to know to render isometric boxes in
the correct order.
	</p>

	<h3>A conundrum</h3>

	<p>
It is possible to have a situation seen in the figure below.  The aforementioned drawing
methods dictate that we first draw the box with nothing behind it, but this example illustrates
a case where this cannot be done.
	</p>

	<figure>
		<canvas id="figure8" width="650" height="200"></canvas>
		<figcaption>
Here are three boxes intertwined in a way such that one is always behind
another.  This prevents us from drawing a first box.
		</figcaption>
		
	</figure>

	<p>
The figure above cheats by segmenting the orange box into two.
This is one method of breaking this type of cycle.
	</p>

	<p>
There are formal methods used for detecting
such cycles mentioned in the appendix.  After detection of a cycle, the blocks in that cycle
could be drawn with special clipping regions to respect front boxes or to segment a block or blocks
that will break the cycle.  These are solutions that I will be exploring and updating this article as
my experiments progress.
	</p>

	<hr>
	<h2>Appendix</h2>

	<h4>A formal description of the solution</h4>

	<p>
This is a special case of the <a href="https://en.wikipedia.org/wiki/Painter%27s_algorithm">Painter's Algorithm</a>,
which handles occlusion by drawing back-to-front.
	</p>

	<p>
For those who are interested, our method for determining if hexagons and boxes
are overlapping is a result of the <a href="http://en.wikipedia.org/wiki/Hyperplane_separation_theorem">hyperplane separation theorem</a>.
	</p>

	<p>
Also, the way in which we determined the drawing order of the boxes is known in graph theory as a <a href="http://en.wikipedia.org/wiki/Topological_sorting">topological sort</a>,
which is essentially a depth-first search of a directed graph.
	</p>

	<p>
You can build a directed graph of the <em>boxes</em>, with directed edges to
the boxes that are behind it.  Topologically sorting this graph will produce an
ordered list of boxes that can be drawn in that exact order.
	</p>

	<p>
Mathematicians will recognize this directed graph as a <a href="http://en.wikipedia.org/wiki/Partially_ordered_set">partially ordered
set</a>.
	</p>

	<p>
Finally, to prevent the aforementioned cycle conundrum, we can use <a href="">Tarjan's
strongly connection components</a> algorithm.  After computing these cycles,
one could either split a block to prevent a cycle, or to use a clipping region
to prevent drawing over any blocks that are supposed to be in front of it.
	</p>

	<h4>Alternative Solutions</h4>

	<p>
You may be able to just use <a href="https://en.wikipedia.org/wiki/Z-buffering">Z-buffering</a>,
though drawing order is still important for transparent sprites.  Also, if all
bounding boxes are unit cubes, sorting is much simpler.
	</p>

	<h4>Full example of working code</h4>

	<p>
All the diagrams above were created using a simple isometric box renderer
written in Javascript, which applies all the techniques described in this
article.  You can study the fully annotated source code on <a href="https://github.com/shaunew/IsometricBlocks">IsometricBlocks project on
GitHub</a>.
	</p>

	<h4>Real game examples</h4>

	<ul>
		<li><a href="http://andrewrussell.net/2016/06/how-2-5d-sorting-works-in-river-city-ransom-underground/">How 2.5D Sorting works in River City Ransom: Underground</a> - allowing bounding boxes to intersect by specifying heightmaps within them (<a href="https://news.ycombinator.com/item?id=12313271">summary</a>)</li>
		<li><a href="http://bannalia.blogspot.co.uk/2008/02/filmation-math.html">Filmation engine on the ZX Spectrum</a></li>
	</ul>
	

	<h4>Thanks</h4>

	<p>
Thanks to Ted Suzman at <a href="http://playbuildy.com/">buildy</a> for
introducing this problem and solution to me.  And thanks to adamhayek for <a href="http://www.reddit.com/r/gamedev/comments/18222r/how_to_determine_the_draw_order_for_an_isometric/c8ayzby">further
insight</a> on a general solution. And thanks to <a href="http://www.reddit.com/r/gamedev/comments/18bg95/tutorial_how_to_render_isometric_blocks_correctly/c8dfx51">Slime0 at reddit</a> for pointing out errors in this article by illustrating the cycle example shown in this article, and for illustrating why we cannot deduce relative drawing order between two non-overlapping boxes.
Thanks to <a href="https://lobste.rs/s/bengjo/drawing_isometric_boxes_correct_order/comments/rzgvnc#c_rzgvnc">Mark Nelson</a> for extra context on painter's algorithm and z-buffering.
	</p>

	<hr>

	<figure>
		<canvas id="figure5" width="700" height="200"></canvas>
		
	</figure>



</div>]]>
            </description>
            <link>http://shaunlebron.github.io/IsometricBlocks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25982749</guid>
            <pubDate>Sun, 31 Jan 2021 21:32:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What scientists must know about hardware to write fast code]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25982673">thread link</a>) | @spekcular
<br/>
January 31, 2021 | https://biojulia.net/post/hardware/ | <a href="https://web.archive.org/web/*/https://biojulia.net/post/hardware/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><strong>Find this notebook at <a href="https://github.com/jakobnissen/hardware_introduction">https://github.com/jakobnissen/hardware_introduction</a></strong></p>
<p>Programming is used in many fields of science today, where individual scientists often have to write custom code for their own projects. For most scientists, however, computer science is not their field of expertise; They have learned programming by necessity. I count myself as one of them. While we may be reasonably familiar with the <em>software</em> side of programming, we rarely have even a basic understanding of how computer <em>hardware</em> impacts code performance.</p>
<p>The aim of this tutorial is to give non-professional programmers a <em>brief</em> overview of the features of modern hardware that you must understand in order to write fast code. It will be a distillation of what have learned the last few years. This tutorial will use Julia because it allows these relatively low-level considerations to be demonstrated easily in a high-level, interactive language.</p>
<h3 id="this-is-not-a-guide-to-the-julia-programming-language">This is not a guide to the Julia programming language</h3>
<p>To write fast code, you must first understand your programming language and its idiosyncrasies. But this is <em>not</em> a guide to the Julia programming language. I recommend reading the <a href="https://docs.julialang.org/en/v1/manual/performance-tips/">performance tips section</a> of the Julia documentation.</p>
<h3 id="this-is-not-an-explanation-of-specific-datastructures-or-algorithms">This is not an explanation of specific datastructures or algorithms</h3>
<p>Besides knowing your language, you must also know your own code to make it fast. You must understand the idea behind big-O notation, why some algorithms are faster than others, and how different data structures work internally. Without knowing <em>what an <code>Array</code> is</em>, how could you possibly optimize code making use of arrays?</p>
<p>This too, is outside the scope of this paper. However, I would say that as a minimum, a programmer should have an understanding of:</p>
<ul>
<li>How a binary integer is represented in memory</li>
<li>How a floating point number is represented in memory (learning this is also necessary to understand computational inacurracies from floating point operations, which is a must when doing scientific programming)</li>
<li>The memory layout of a <code>String</code> including ASCII and UTF-8 encoding</li>
<li>The basics of how an <code>Array</code> is structured, and what the difference between a dense array of e.g. integers and an array of references to objects are</li>
<li>The principles behind how a <code>Dict</code> (i.e. hash table) and a <code>Set</code> works</li>
</ul>
<p>Furthermore, I would also recommend familiarizing yourself with:</p>
<ul>
<li>Heaps</li>
<li>Deques</li>
<li>Tuples</li>
</ul>
<h3 id="this-is-not-a-tutorial-on-benchmarking-your-code">This is not a tutorial on benchmarking your code</h3>
<p>To write fast code <em>in practice</em>, it is necessary to profile your code to find bottlenecks where your machine spends the majority of the time. One must benchmark different functions and approaches to find the fastest in practice. Julia (and other languages) have tools for exactly this purpose, but I will not cover them here.</p>
<h2 id="content">Content</h2>
<ul>
<li><a href="#disk">Minimize disk writes</a></li>
<li><a href="#cachemisses">CPU cache</a></li>
<li><a href="#alignment">Alignment</a></li>
<li><a href="#assembly">Inspect generated assembly</a></li>
<li><a href="#allocations">Minimize allocations</a></li>
<li><a href="#simd">Exploit SIMD vectorization</a></li>
<li><a href="#soa">Struct of arrays</a></li>
<li><a href="#instructions">Use specialized CPU instructions</a></li>
<li><a href="#inlining">Inline small functions</a></li>
<li><a href="#unrolling">Unroll tight loops</a></li>
<li><a href="#branches">Avoid unpredictable branches</a></li>
<li><a href="#multithreading">Multithreading</a></li>
<li><a href="#gpus">GPUs</a></li>
</ul>
<h2 id="before-you-begin-install-packages">Before you begin: Install packages</h2>
<pre><code># If you don't already have these packages installed, outcomment these lines and run it:
# using Pkg
# Pkg.add("BenchmarkTools")
# Pkg.add("StaticArrays")

using StaticArrays
using BenchmarkTools

"Print median elapsed time of benchmark"
function print_median(trial)
    println("Median time: ", BenchmarkTools.prettytime(median(trial).time))
end;
</code></pre>
<h2 id="the-basic-structure-of-computer-hardware">The basic structure of computer hardware</h2>
<p>For now, we will work with a simplified mental model of a computer. Through this document, I will add more details to our model as they become relevant.</p>
<br>
<center><span size="4">
[CPU] ↔ [RAM] ↔ [DISK]
</span></center>
<p>In this simple diagram, the arrows represent data flow in either direction. The diagram shows three important parts of a computer:</p>
<ul>
<li>The central processing unit (CPU) is a chip the size of a stamp. This is where all the computation actually occurs, the brain of the computer.</li>
<li>Random access memory (RAM, or just “memory”) is the short-term memory of the computer. This memory requires electrical power to maintain, and is lost when the computer is shut down. RAM serves as a temporary storage of data between the disk and the CPU. Much of time spent “loading” various applications and operating systems is actually spent moving data from disk to RAM and unpacking it there. A typical consumer laptop has around 10^11 bits of RAM memory.</li>
<li>The disk is a mass storage unit. This data on disk persists after power is shut down, so the disk contains the long-term memory of the computer. It is also much cheaper per gigabyte than RAM, with consumer PCs having around 10^13 bits of disk space.</li>
</ul>
<h2 id="avoid-write-to-disk-where-possiblea-iddiska">Avoid write to disk where possible<a id="disk"></a></h2>
<p>Even with a fast mass storage unit such as a solid state drive (SSD) or even the newer Optane technology, disks are many times, usually thousands of times, slower than RAM. In particular, <em>seeks</em>, i.e. switching to a new point of the disk to read from or write to, is slow. As a consequence, writing a large chunk of data to disk is much faster than writing many small chunks.</p>
<p>To write fast code, you must therefore make sure to have your working data in RAM, and limit disk writes as much as possible.</p>
<p>The following example serves to illustrate the difference in speed: The first function opens a file, accesses one byte from the file, and closes it again. The second function randomly accesses 1,000,000 integers from RAM.</p>
<pre><code># Open a file
function test_file(path)
    open(path) do file
        # Go to 1000'th byte of file and read it
        seek(file, 1000)
        read(file, UInt8)
    end
end
@time test_file("test_file")

# Randomly access data N times
function random_access(data::Vector{UInt}, N::Integer)
    n = rand(UInt)
    mask = length(data) - 1
    @inbounds for i in 1:N
        n = (n &gt;&gt;&gt; 7) ⊻ data[n &amp; mask + 1]
    end
    return n
end

data = rand(UInt, 2^24)
@time random_access(data, 1000000);
</code></pre>
<pre><code>  0.001321 seconds (15 allocations: 976 bytes)
  0.130833 seconds
</code></pre>
<p>Benchmarking this is a little tricky, because the <em>first</em> invokation will include the compilation times of both functions. And in the <em>second</em> invokation, your operating system will have stored a copy of the file (or <em>cached</em> the file) in RAM, making the file seek almost instant. To time it properly, run it once, then <em>change the file</em>, and run it again. So in fact, we should update our computer diagram:</p>
<br>
<center><span size="4">
[CPU] ↔ [RAM] ↔ [DISK CACHE] ↔ [DISK]
</span></center>
<p>On my computer, finding a single byte in a file (including opening and closing the file) takes about 13 miliseconds, and accessing 1,000,000 integers from memory takes 131 miliseconds. So RAM is on the order of 10,000 times faster than disk.</p>
<p>When working with data too large to fit into RAM, load in the data chunk by chunk, e.g. one line at a time, and operate on that. That way, you don't need <em>random access</em> to your file and thus need to waste time on extra seeks, but only sequential access. And you <em>must</em> strive to write your program such that any input files are only read through <em>once</em>, not multiple times.</p>
<p>If you need to read a file byte by byte, for example when parsing a file, great speed improvements can be found by <em>buffering</em> the file. When  buffering, you read in larger chunks, the <em>buffer</em>, to memory, and when you want to read from the file, you check if it's in the buffer. If not, read another large chunk into your buffer from the file. This approach minimizes disk reads. Both your operating system and your programming language will make use of caches, however, sometimes <a href="https://github.com/JuliaLang/julia/issues/34195">it is necessary to manually buffer your files</a>.</p>
<h2 id="cpu-cachea-idcachemissesa">CPU cache<a id="cachemisses"></a></h2>
<p>The RAM is faster than the disk, and the CPU in turn is faster than RAM. A CPU ticks like a clock, with a speed of about 3 GHz, i.e. 3 billion ticks per second. One “tick” of this clock is called a <em>clock cycle</em>. While this is not really true, you may imagine that every cycle, the CPU executes a single, simple command called a <em>CPU instruction</em> which does one operation on a small piece of data. The clock speed then can serve as a reference for other timings in a computer. It is worth realizing that in a single clock cycle, a photon will travel only around 10 cm, and this puts a barrier to how fast memory (which is placed some distance away from the CPU) can operate. In fact, modern computers are so fast that a significant bottleneck in their speed is the delay caused by the time needed for electricity to move through the wires inside the computer.</p>
<p>On this scale, reading from RAM takes around 100 clock cycles. Similarly to how the slowness of disks can be mitigated by copying data to the faster RAM, data from RAM is copied to a smaller memory chip physically on the CPU, called a <em>cache</em>. The cache is faster because it is physically on the CPU chip (reducing wire delays), and because it uses a faster type of RAM, static RAM, instead of the slower (but cheaper to manufacture) dynamic RAM. Because it must be placed on the CPU, limiting its size, and because it is more expensive to produce, a typical CPU cache only contains around 10^8 bits, around 1000 times less than RAM. There are actually multiple layers of CPU cache, but here we simplify it and just refer to “the cache” as one single thing:</p>
<br>
<center><span size="4">
[CPU] ↔ [CPU CACHE] ↔ [RAM] ↔ [DISK CACHE] ↔ [DISK]
</span></center>
<p>When the CPU requests a piece of data from the RAM, say a single byte, it will first check if the memory is already in cache. If so, it will read from it from there. This is much faster, usually just a few clock cycles, than access to RAM. If not, we have a <em>cache miss</em>, and your program will stall for tens of nanoseconds while your computer copies data from RAM into the cache.</p>
<p>It is not possible, except in very low-level languages, to manually manage the CPU cache. Instead, you must make sure to use your cache effectively.</p>
<p>Effective use of the cache comes down to <em>locality</em>, temporal and spacial locality:</p>
<ul>
<li>By <em>temporal locality</em>, I mean that data you recently accessed likely resides in cache already. Therefore, if you must access a piece of memory multiple times, make sure you do it close together in time.</li>
<li>By <em>spacial locality</em>, I mean that you should …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://biojulia.net/post/hardware/">https://biojulia.net/post/hardware/</a></em></p>]]>
            </description>
            <link>https://biojulia.net/post/hardware/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25982673</guid>
            <pubDate>Sun, 31 Jan 2021 21:21:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun with an ATTiny85, Liyafy HC-35 with 8 LEDs, & a serial to parallel shifter]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25982614">thread link</a>) | @nanis
<br/>
January 31, 2021 | https://www.nu42.com/2021/01/attiny85-liyafy-hc-35-8-led-keypad-serial-in-parallel-out-shift-register.html | <a href="https://web.archive.org/web/*/https://www.nu42.com/2021/01/attiny85-liyafy-hc-35-8-led-keypad-serial-in-parallel-out-shift-register.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
<header>
<h3><time datetime="2020-01-31T21:00:00-00:00">January 31, 2020</time></h3>
</header>
</p><div><p>Some months ago, I got curious about ESP32 microcontrollers. The exact reason is not important. I ended up learning about <a href="https://www.nodemcu.com/">NodeMCU</a>, <a href="https://micropython.org/">MicroPython</a>, <a href="https://www.i2c-bus.org/">I<sup>2</sup>C</a>. In the end, I was able to wire up an ESP32 to an OLED screen which showed a small set of rotating fortune cookies.</p>
<p>It turned out to be rather straightforward. I wanted more artificial constraints. After all, I am not doing this for real work. It’s just a different way of having a well defined task that can be accomplished in a short amount of time with a visible outcome. In that sense, it is similar to <a href="https://stackoverflow.com/users/100754/sinan-%c3%9cn%c3%bcr">answering questions on Stackoverlow</a>. I find it helpful in a way others might find meditation helpful.</p>
<p>Before going further, I am know I late to the party. People have been doing this stuf for quite some time now. This gives me the ability to more easily discover how to solve a given problem because others did and wrote blog posts about them years ago.</p>
<p>My search for a <em>reasonably</em> constrained environment led me to <a href="https://www.microchip.com/wwwproducts/en/ATtiny85" title="ATtiny85 datasheet">ATtiny85</a>. I decided I wanted to do something with it, but I did not know what. So, the first thing I tried was to wire up an ATtiny85 to an OLED screen and display a (now much smaller) set of rotating <a href="https://www.nu42.com/2020/12/small-is-beautiful.html">fortune cookies</a>.</p>
<p>ATtiny85 has 8 kilobytes of <a href="https://en.wikipedia.org/wiki/Flash_memory">programmable flash</a>, 512 bytes of programmable <a href="https://en.wikipedia.org/wiki/EEPROM">EEPROM</a>, and 512 bytes of <a href="https://en.wikipedia.org/wiki/Static_random-access_memory">SRAM</a>. As I said, for a while I did not know what I wanted to do with it. I would occasionally browse Amazon and order things that looked cheap and fun.</p>
<p><em>Note that in what follows, I will be using shortened Amazon affiliate links to the products I actually bought and used in making this blog post. The advantage of shortened links is that just loading the page does not immediately result in tracking images and cookies to be fetched (of course, if your browser does aggressive <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Link_prefetching_FAQ">link prefetching</a>, all bets are off). Linking to those products do not mean I endorse them or even recommend them. I am just writing about my experience using them.</em></p>
<p>Among the things I bought because it looked cheap at the time was <a title="Amazon afiliate link to Liyafy HC-35 product page" href="https://amzn.to/3raaH4b">Liyafy HC-35 8 LED 4x4 push button matrix keyboard</a>. From my perspective, it looked appealing because it came with no documentation, there were no useful comments or Q&amp;A on the product page, and a Google search only revealed <a href="https://forum.arduino.cc/index.php?topic=500018.0">an unanswered question from 2017 on the Arduino forums</a>.</p>
<p>In the package were two keypads on a single board with a slight perforation running through the middle. So, I cracked them apart :-) Now, I had two keypads with no documentation. Here is one of them:</p>
<p><a href="https://www.nu42.com/2021/01/liyafy-hc-35-lg.jpg"><img src="https://www.nu42.com/2021/01/liyafy-hc-35-sm.jpg"></a></p>
<p>Documentation or not, the task seemed simple to me: There are three banks of pins on the left side of the board. The bottom bank is for manipulating the LEDs, and the two banks above that are for reading the state of the red buttons and the state of the black buttons, respectively. Eight LEDs, eight bits in a byte, not a huge leap to assume that each LED maps to a bit in a byte. It is not really clear whether the LEDs are ordered MSB first or LSB first. I am not good at reading board traces.</p>
<p>So, we need to have eight wires to drive the LEDs. VCC is clearly marked, but I didn’t know whether the board needed 5V or 3.3V. In fact, at first I guessed wrong and tried 5V. It doesn’t seem to have harmed the board, but after the fact, I thought maybe it would have been better to try the lower voltage first :-)</p>
<p>The ATtiny85 has 8 pins in <em>total</em>. We need a further four wires to read the state of the KEY B bank consisting of the red buttons, and we need an additional eight wires to read state of the KEY A bank consisting of the 4x4 keypad. Note the pins on the KEY A bank are labeled <var>L<sub>i</sub></var> and <var>R<sub>i</sub></var> where I would expect L to stand for “line” and R to stand for “row” which seem like the same thing to me. I decided to anchor on “R is row” and “L is column” as a working assumption, and focus solely on getting some lights to blink first.</p>
<p>Before going further, I should note that by the time I got around the thinking about this, a couple of months had gone by. Luckily, I had picked some other bits and pieces I thought might come in handy if I ever got around to trying this. Here is a list of what I ended up using:</p>
<ul>
<li><a href="https://amzn.to/2NNFi97" title="Amazon affiliate link to ATtiny85 10 pack">A ten-pack of ATtiny85 chips</a></li>
<li><a href="https://amzn.to/2NNF1TD" title="Amazon affiliate link to Belker 45W/3A AC/DC adapter">Belker 45W 5V 6V 7.5V 9V 12V 13.5V 15V Universal AC DC Power Supply</a></li>
<li><a href="https://amzn.to/3tfScgj" title="Amazon affiliate link to REXQualis Electronics Component Fun Kit">REXQualis Electronics Component Fun Kit</a>
<ul>
<li>Breadboard</li>
<li>Jumper wires</li>
<li>Extra LEDs</li>
<li>Power supply module</li>
<li><a href="https://www.ti.com/product/SN74HC595" title="595 8 bit serial to parallel shifter data sheet">74HC595</a></li>
</ul></li>
<li><a href="https://amzn.to/3r5mXmo" title="Amazon affiliate link to Tiny AVR Programmer">Tiny AVR programmer</a></li>
</ul>
<p>Note that stuff you find on Amazon tends to have a markup compared to the unit prices you find when shopping at speciality or overseas suppliers. And, prices on Amazon tend to vary a lot. I was not in a rush, did not have a specific project in mind, and just grabbed a thing or two when I thought the price was right. The Belker adapter is great. I have, of course, a box of wall warts accumulated over time, but with those either the specs turn out not to be what you want (if you can read them) or the tips don’t match etc. Since I bought this, it’s already been useful in multiple other contexts.</p>
<p>Well, I figured the first task was to actually be able to get something on the ATtiny85 to execute. I knew that I needed to install some drivers for the “programmer”, stick the chip in the right way (here’s where the 10-pack comes in handy: If you insert the chip in the wrong way, it burns because you end up swapping VCC and GND and 5V runs through going the wrong way … don’t trust your eyes, triple check before plugging the programmer in to your computer’s USB port). The <a href="https://www.microchip.com/wwwproducts/en/ATtiny85" title="ATtiny85 datasheet">datasheet</a> has the pin out diagram as well as other good information:</p>
<p><a href="https://www.nu42.com/2021/01/attiny85-8pin-dip.png"><img title="ATtiny85 8 pin DIP package pinout diagram" alt="[ ATtiny85 8 pin DIP package pinout diagram ]" src="https://www.nu42.com/2021/01/attiny85-8pin-dip-thumb.png"></a></p>
<p>I followed <a href="https://learn.sparkfun.com/tutorials/tiny-avr-programmer-hookup-guide/all">SparkFun’s Tiny AVR programming hookup guide</a> followed by <a href="https://hackaday.com/2018/11/01/drawing-on-an-oled-with-an-attiny85-no-ram-buffers-allowed/">Drawing On An OLED With An ATtiny85</a> to produce some output on a <a href="https://amzn.to/3aiv5JA" title="Amazon affilliate link to SSD1306 128x32 OLED 3-pack">128x32 OLED screen</a> to get warmed up.</p>
<p>The next task was to figure out how to drive the LEDs which require 8 wires using the five pins I had at my disposal. So, I started by staring at the contents of the “Fun Kit”. There are only two ICs included in the pack. I did not know what the 4N35 was for (it turned out to be a <a href="https://www.vishay.com/docs/81181/4n35.pdf">light sensor</a>) but it has only six pins, so clearly it could not do anything with mapping one bit at a time (aka serial) output to eight bits at a time (parallel). So, I searched the web for the only other IC in the package, <a href="https://www.nu42.com/2021/01/sipo">74HC595</a>. TI’s page for the product mentions “<a href="https://www.nu42.com/2021/01/ti-595-snip.png">8-bit shift registers with 3-state output registers</a>” right under the product name. To be honest, that didn’t mean any thing to me and I almost navigated away from the page, but scrolling down a little (is it me, or is everything on the web in huge and huger fonts now?) revealed the description:</p>
<blockquote>
<p>The SNx4HC595 devices contain an 8-bit, serial-in, parallel-out shift register that feeds an 8-bit D-type storage register. The storage register has parallel 3-state outputs. Separate clocks are provided for both the shift and storage register. The shift register has a direct overriding clear (SRCLR) input, serial (SER) input, and serial outputs for cascading. When the output-enable (OE) input is high, the outputs are in the high-impedance state.</p>
</blockquote>
<p>Yay! It looks like the “fun kit” includes just the part I needed for this! Good.</p>
<p>Time to learn what the gobbledygook means … It sounds like it’s saying it takes serial input, puts bits in eight bins, and, when you give it the all clear, it puts those zeros and ones on some IO pins. Here is the pin-out:</p>
<p><a href="https://www.nu42.com/2021/01/SN74HC595-pins.png"><img alt="[ SN74HC595 pin out diagram ]" width="326" src="https://www.nu42.com/2021/01/SN74HC595-pins.png"></a></p>
<p><var>Q<sub>A</sub></var> - <var>Q<sub>H</sub></var> are the eight output pins. VCC is VCC, GND is GND. <u>SER</u> better be serial. O̅E̅ is “output enable” meaning put “put the bits you buffered on the pins”. <var>Q<sub>H</sub><sup>′</sup></var> seems to provide the same output serially.</p>
<p>OK, so I need to connect <var>Q<sub>A</sub></var> - <var>Q<sub>H</sub></var> to the LED inputs … I think I did this the “wrong” way by connecting <var>Q<sub>A</sub></var> to <var>D<sub>1</sub> on the keypad, but at this stage, I didn’t care what lit up … just that something did.</var></p>
<p>The big question is what to do with the five other pins. How do I drive them from the ATtiny85? I was confronted with a choice: I could read the datasheet, draw on my “vast” knowledge from electronics all gained in 8th grade, and translate the information in the datasheet to a program. Or, I could see if anyone else had done something similar. Searching for 74HC595 and Arduino led me to the documentation for the <a href="https://www.arduino.cc/reference/en/language/functions/advanced-io/shiftout/">shiftout</a> function:</p>
<blockquote>
<p>Shifts out a byte of data one bit at a time. Starts from either the most (i.e. the leftmost) or least (rightmost) significant bit. Each bit is written in turn to a data pin, after which a clock pin is pulsed (taken high, then low) to indicate that the bit is available.</p>
</blockquote>
<p>Nice. It turns out Arduino documentation is really good like Perl documentation (docs on both focus on giving you the information you need to be able to use a specific piece of functionality – For a contrast, see Python’s documentation which tends to obscure the information you need in dense prose). The docs for <code>shiftout</code> came with a complete example as well as a link to a <a href="https://www.arduino.cc/en/Tutorial/Foundations/ShiftOut" title="Serial to Parallel Shifting-Out with a 74HC595">tutorial on controlling the 74HC595 shift register</a>. Of course, the mnemonics used in the pin-out diagram in the tutorial do not fully match the datasheet, but it is really nice to have these resources when you are trying to take the baby steps. It is easier to understand how you ended up blinking those if you can get them to blink in the first place.</p>
<p>Obviously, the tutorial is great. Explains all you need to know really. It is geared towards an Arduino board and those tend to have way more available pins than the ATtiny85. Laying cable on a breadboard is not my strong suit (never touched a soldering iron either), but after spending a moment considering my options, I decided to use the three available pins on the right side of the ATtiny85 (<var>PB<sub>0</sub></var> … <var>PB<sub>2</sub></var>) for interfacing with the 595. While reading the tutorial, I noticed this:</p>
<blockquote>
<p>“3 states” refers to the fact that you can set the output pins as either high, low or “high impedance.” … Neither example takes advantage of this feature and you won’t usually need to worry about getting a chip that has it.</p>
</blockquote>
<p>Good. One less thing to worry about.</p>
<p>Anyway, I used whatever wires were available within the routing constraints and came up with this wiring:</p>
<p><a href="https://www.nu42.com/2021/01/attiny85-SN74HC595-HC-35-breadboard.jpg"><img src="https://www.nu42.com/2021/01/attiny85-SN74HC595-HC-35-breadboard-thumb.jpg" width="400" title="ATtiny85 SN74HC595 Liyafy HC-35 keypad breadboard wiring" alt="[ ATtiny85 SN74HC595 Liyafy HC-35 keypad breadboard wiring ]"></a></p>
<p>The colors of the wires were dictated by available …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nu42.com/2021/01/attiny85-liyafy-hc-35-8-led-keypad-serial-in-parallel-out-shift-register.html">https://www.nu42.com/2021/01/attiny85-liyafy-hc-35-8-led-keypad-serial-in-parallel-out-shift-register.html</a></em></p>]]>
            </description>
            <link>https://www.nu42.com/2021/01/attiny85-liyafy-hc-35-8-led-keypad-serial-in-parallel-out-shift-register.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25982614</guid>
            <pubDate>Sun, 31 Jan 2021 21:12:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built a dashboard where you can monitor my not scrapers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25982525">thread link</a>) | @fstopmick
<br/>
January 31, 2021 | https://www.pmalerts.com/internals-jobs | <a href="https://web.archive.org/web/*/https://www.pmalerts.com/internals-jobs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="what">
            <p>
                PMAlerts is a social media monitoring tool that lets you monitor the web for mentions of the things you care about. It's similar to Google Alerts, but tuned for social media.
            </p>
        </div><div id="what2">
            <p>
                Listeners are special-purpose workers that periodically ask your target platforms (Twitter, Reddit, etc) for the latest activity related to your alerts.
            </p>
        </div><div id="why">
            <div><p>
                I'd like for PMAlerts to become a decentralized, collectively owned, mostly-autonomous platform that generates democratically managed profit.</p><p>
                To do that, I need to give developers an easy way to build and monetize their own listeners. </p><p>
                I've started this work here: <a href="https://www.pmalerts.com/listeners">Listeners</a>. </p><p>
                Before developers can plug in, I need to give them an easy way to monitor the performance of their own listeners. That's what this page is for.</p><p>
                Note that this page doesn't display all PMAlerts listeners - it's just the ones I've had time to instrument for this dashboard.
            </p></div>
        </div><div id="how">
            <div><p>
                This is a list of listeners, each with a bunch of square boxes next to it. Every box represents the execution of a task by the listener. This page shows you all task executions over the past 24 hours.</p><p>
                Red = error. Green = new results found. Red X = human intervention was needed. Purple = obstacle automatically overcome. Numbers in the boxes = alerts processed. Listeners batch their work into groups of 25 alerts.</p><p>
                You can click on the boxes to dig a bit deeper into the task execution data.
            </p></div>
        </div></div>]]>
            </description>
            <link>https://www.pmalerts.com/internals-jobs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25982525</guid>
            <pubDate>Sun, 31 Jan 2021 21:00:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[About Domain Validation and Padlocks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25982520">thread link</a>) | @autoditype
<br/>
January 31, 2021 | https://jomo.tv/security/domain-validation-and-padlocks | <a href="https://web.archive.org/web/*/https://jomo.tv/security/domain-validation-and-padlocks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <article itemscope="" itemtype="http://schema.org/BlogPosting">

    

    <section itemprop="articleBody">
      <p><strong>Note</strong>: This post is a copy of <a href="https://paypal.gift/">https://paypal.gift</a>.</p>

<hr>

<p>Web browsers show a padlock icon next to the URL of HTTPS websites with a valid <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">TLS certificate</a>. This padlock indicates that the <em>connection</em> between your browser and the server is secure.</p>

<p><img src="https://jomo.tv/img/fakepal.png#border" alt="PayPal phishing"></p>

<p>It does <em>not</em> indicate that the website is safe to use, or that the domain name is not misleading, or anything, really. It just means that you’re connected to the address displayed in the address bar with nobody else reading or manipulating content. This type of certificate is also known as <a href="https://en.wikipedia.org/wiki/Domain-validated_certificate">Domain Validation</a> (“DV”) certificate and is the most common.</p>

<p>A different validation method called <a href="https://en.wikipedia.org/wiki/Extended_Validation_Certificate">Extended Validation</a> (“EV”) exists, where the company owning<sup id="fnref:1"><a href="#fn:1">1</a></sup> the domain is included in the certificate, but otherwise it’s not very different. For sites with these certificates, browsers usually show a padlock and the company name next to the URL, which can give the user a false sense of security. See <a href="https://stripe.ian.sh/">Stripe, Inc</a> and <a href="https://www.typewritten.net/writer/ev-phishing/">Identity Verified</a>.</p>

<p><img src="https://jomo.tv/img/ev.png#border" alt="Website with EV cert"></p>

<p>This website, <em>paypal.gift</em>, uses a DV certificate from <a href="https://letsencrypt.org/">Let’s Encrypt</a>. Some people would argue that they shouldn’t have issued the certificate because the website is obviously not owned by “the real PayPal” and/or because it might be used for malicious activities. However, this is ultimately wrong because <strong>a certificate does not certify that a website is safe to use!</strong> (whatever that even means). Doing so wouldn’t be an easy task, anyway. What is a malicious site and what’s not? Who gets to decide? Is <a href="https://en.wikipedia.org/wiki/Criticism_of_Facebook">Facebook</a> a malicious site? And if so, should they send data in plain text?</p>

<p>Some people still expect the <span title="Certificate Authority">CA</span>s to do something about bad sites. Let’s Encrypt disagrees, but for a while decided to use the Google <a href="https://en.wikipedia.org/wiki/Google_Safe_Browsing#Privacy">Safe Browsing</a> API to figure out if a domain is a known bad website (by Google’s terms) before issuing a certificate. They eventually <a href="https://community.letsencrypt.org/t/let-s-encrypt-no-longer-checking-google-safe-browsing/82168">stopped doing that</a> because it’s simply not relevant for the certificate. It would also give Google and their false positives<sup id="fnref:2"><a href="#fn:2">2</a></sup> the power to decide.</p>

<p>What Let’s Encrypt <em>does</em>, however, is holding a blacklist of “high value” domains<sup id="fnref:3"><a href="#fn:3">3</a></sup> for which they won’t automatically issue certificates until the legitimate domain owner explicitly asks them to. This is to lower the practical impact of a hostile domain takeover or <a href="https://en.wikipedia.org/wiki/BGP_hijacking">BGP hijack</a>. This blacklist includes <code>paypal.com</code>, but it does not include previously unregistered <code>paypal.*</code> domains, as I demonstrated in April 2018.<sup id="fnref:4"><a href="#fn:4">4</a></sup> This approach obviously does not scale and is only in place to prevent the worst, although it’s not the responsibility of the CA to prevent domain takeovers. They only validate that someone <em>technically</em> controls the domain.</p>

<p>Ultimately all HTTP websites should move to HTTPS, regardless of their content, and browsers should only indicate when a connection is <em>not</em> secure, instead of the other way around. Padlocks and company names need to disappear. And luckily this is what’s already happening. More than ¾ of page loads now <a href="https://letsencrypt.org/stats/#percent-pageloads">use HTTPS</a>. Mozilla has <a href="https://blog.mozilla.org/security/2015/04/30/deprecating-non-secure-http/">deprecated HTTP</a> in 2015. Firefox, Safari and Chrome are already marking some or all <a href="https://badssl.com/#http">HTTP sites</a> as insecure. <a href="https://www.chromium.org/Home/chromium-security/marking-http-as-non-secure">Eventually</a> browsers won’t connect to HTTP sites, just like sites with broken HTTPS.</p>

<p><img src="https://jomo.tv/img/http.png#border" alt="Browser warning about HTTP"></p>

<hr>



    </section>

    <section>Tags: web-browsers, ssl-certificates, tls, domain-validation, padlocks</section>

    

  </article>
</div></div>]]>
            </description>
            <link>https://jomo.tv/security/domain-validation-and-padlocks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25982520</guid>
            <pubDate>Sun, 31 Jan 2021 20:59:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NEF: A static site generator in 445 bytes of Posix sh]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25982279">thread link</a>) | @acdw
<br/>
January 31, 2021 | https://www.acdw.net/nef/ | <a href="https://web.archive.org/web/*/https://www.acdw.net/nef/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>an even <i>smaller</i> static site generator</p>
<hr>
<p>from the mind that brought you <b>UNK</b>, comes the new and improved SON OF
UNK, <b>NEF</b>.  Where <b>UNK</b> was a bloated <i>one thousand bytes</i>, the
entirety of <b>NEF</b> is <i>four hundred forty-four</i>, over a fifty per cent
<i>reduction</i> in size.</p>
<h2>installation</h2>
<p>clone this repo.
<b>NEF</b> requires a POSIX environment.</p>
<h2>use</h2>
<p>create the following files and directories in the same directory as <b>NEF</b>:</p>
<ul>
    <li><b>L</b>, the <i>Layout</i> file, which gets expanded by <b>NEF</b>.
        if <b>L</b> isn't provided, a default <b>L</b> will be generated.
    </li><li><b>H</b>, the <i>Html</i> generator, which converts the input files to
        HTML.  if <b>H</b> isn't provided, a default function H is called, which
        is pretty stupid: it wraps blank-line-separated paragraphs in 
        <code>&lt;p&gt;</code> blocks.  otherwise, it's pure HTML (mostly; see
        <b>layouts</b>, below).
    </li><li><b>I/</b>, where the <i>Input</i> files, like pages, go.
        each page should have a name of the form 
        <code>NAME.OUT-FMT.IN-FMT</code>, where
        <code>NAME</code> is the basename of the file,
        <code>OUT-FMT</code> is the output format (usually HTML),
        and <code>IN-FMT</code> is the input format (whatever -- in this repo
        it's called <code>.h</code>).
    </li><li><b>S/</b>, where the <i>Static</i> files, like CSS and images, go.
</li></ul>
<h2>layouts</h2>
<p>the <b>L</b> file is basically a big here-doc, meaning that you can write
arbitrary shell in it however you'd like.  the following variables and functions
are made available to <b>L</b>'s environment (in addition, of course, to
whatever <b>NEF</b>'s environment is):</p>
<ul>
    <li><b>X</b>, the <i>eXpander</i>.  it turns <b>L</b> into a here-doc.
        <i>make sure to escape your files properly!</i>
    </li><li><b>H</b>, the <i>Htmlizer</i>.  it's a dumb awk function.  even if you
        have a file <b>H</b> in <b>NEF</b>'s directory, this function will 
        still be here, taunting you with its stupidity.
    </li><li><b>P</b>, aliased to <code>echo</code>.
    </li><li><b>T</b>, aliased to <code>sed q</code>, which pulls the first line from
        a file.  aka, the <i>Title</i>.
    </li><li><b>$H</b>, which keeps track of whether you're using the <b>H</b> file
        or function.  you probably don't need this.  but it's here.
    </li><li><b>$F</b>, the <i>Filename</i> of the current input file.
    </li><li><b>$N</b>, the <i>baseName</i> (without <code>I/</code>) of the current
        input file.
</li></ul>
<p>the default <b>L</b> <i>also</i> runs each input file through the
<b>X</b> function (<b>UNK</b> devotees will be aware of the <b>X</b> function;
it's basically <a href="https://github.com/zimbatm/shab">shab</a> but stupider and
smaller), meaning that input files can basically function as templates
themselves, and create their own fun.</p>
<h2>uh, yeah, that's it</h2>
<p>look, the script is a super short POSIX shell script.  it's barely usable by
itself.  you're probably going to throw it out and write something else --
that's what I do.</p>
<h2>copying</h2>
<p><b>UNK</b> used the <a href="http://www.wtfpl.net/">WTFPL</a>, which is the
shortest license I've been able to find.  however, for <b>NEF</b>, 443 bytes is
<i>far</i> too long: it basically <i>doubles</i> the size of the repo!  so I
wrote my own license, which I'm calling the <b>good choices license</b>, or
<b>GCL</b> for short.  you can read the LICENSE file, or just read it here:</p>
<blockquote>
(c) 2020 Case Duckworth &lt;acdw@acdw.net&gt;
<p>Everyone is permitted to do whatever with this software, without limitation.
This software comes without any warranty whatsoever.
Don't hurt yourself.
Make good choices.
</p></blockquote>
<p>a trim 169 bytes, exclusive of the copyright information!</p>
<p>i mean, shit, if you wanna copy the thing, here it is, copy it:</p>
<pre><code>#!/bin/sh
rm -r O;mkdir O;cp -r S O;alias P=echo T=sed\ q
X()(eval "$(P 'cat&lt;&lt;.';cat;P;P .)");H()(awk -F'
' -vRS='' '!/^&lt;.*&gt;$/{./nef="&lt;p&gt;"./nef"&lt;/p&gt;"}{print}')
[ -x H ]&amp;&amp;H=./H||H=H
[ -f L ]||P '&lt;!DOCTYPE html&gt;&lt;title&gt;$(T I/index.html.lh)&lt;/title&gt;
&lt;style&gt;body{max-width:70ch;padding:1%}&lt;/style&gt;
&lt;h1&gt;$(T I/index.html.lh)&lt;/h1&gt;$(sed 1d $F|X|$H)&lt;hr&gt;/ $(for P in I/*;do
[ $P = $F ]||(N=;P "&lt;a href=./index.html&gt;$(T )&lt;/a&gt; ")
done)'&gt;L;for F in I/*;do N=${F#I/};X&lt;L&gt;O/${N%.*};done
</code></pre>
<p>or
<a href="https://www.acdw.net/nef/">view the website</a>
or
<a href="https://git.sr.ht/~acdw/nef">view the source code</a>.</p>
<h2>contributing</h2>
<p>uh... send me an email?  yeah.  do that.</p><hr>/ <a href="https://www.acdw.net/nef/carpe-diem.html">Carpe diem</a> 
<a href="https://www.acdw.net/nef/rosa-rosa-rosam.html">Rosa Rosa Rosam</a> 
<a href="https://www.acdw.net/nef/spqr.html">S.P.Q.R.</a> 
<a href="https://www.acdw.net/nef/tu-quoque.html">Tu quoque</a> 

</div>]]>
            </description>
            <link>https://www.acdw.net/nef/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25982279</guid>
            <pubDate>Sun, 31 Jan 2021 20:31:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elite family decades-old secret sparked a reckoning about sexual abuse in France]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25982146">thread link</a>) | @SirLJ
<br/>
January 31, 2021 | https://www.cbc.ca/news/world/france-sexual-abuse-book-elites-1.5892765 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/france-sexual-abuse-book-elites-1.5892765">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Sexual abuse within families had long been a problem France failed to confront. That appears to have changed recently with the release of a book that exposed a dark and decades-old secret of a prominent French family.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5892776.1611882672!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/france-tackling-incest.jpg"></p></div><figcaption>Graffiti on a wall in Paris reads, 'Duhamel, and the others, you will never be in peace,' referring to prominent French political expert Olivier Duhamel. The French government pledged on Thursday to toughen laws on the sexual abuse of children as a massive online movement has seen hundreds of victims share accounts about sexual abuses within their families under the hashtag #MeTooInceste.<!-- --> <!-- -->(Francois Mori/The Associated Press)</figcaption></figure><p><span><p>A 30-year-old family secret has shaken the elite of France.</p>  <p>And it has nothing to do with the usual money scandals that rock the French establishment.</p>  <p>This is about alleged sexual abuse of a minor and the powerful people accused of staying silent.</p>  <p>The allegation, which was detailed in a bestselling book and is now under investigation by Paris prosecutors, involves an influential political scientist sexually abusing his teenage stepson.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5892780.1611882816!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/france-sexual-abuse-children.jpg 300w,https://i.cbc.ca/1.5892780.1611882816!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/france-sexual-abuse-children.jpg 460w,https://i.cbc.ca/1.5892780.1611882816!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/france-sexual-abuse-children.jpg 620w,https://i.cbc.ca/1.5892780.1611882816!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/france-sexual-abuse-children.jpg 780w,https://i.cbc.ca/1.5892780.1611882816!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/france-sexual-abuse-children.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5892780.1611882816!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/france-sexual-abuse-children.jpg"></p></div><figcaption>A person holds the book La Familia Grande by Camille Kouchner in a Paris bookstore. The author is the stepdaughter of prominent French political expert Olivier Duhamel, whom she accuses of sexually abusing her twin brother during the late 1980s, when the siblings were teenagers.<!-- --> <!-- -->(Francois Mori/The Associated Press)</figcaption></figure></span></p>  <p>Investigators have yet to finish their work, but the case has already touched off a huge national debate on the extent of incest and sexual crimes in families, and the culture of silence that has helped to hide the problem.</p>  <p>The debate is so intense, French President Emmanuel Macron felt obliged to jump in on Jan. 23. He issued a video, telling victims, "We are there, we hear you, we believe you. You will never be alone."&nbsp;&nbsp;</p>  <p>He promised tougher laws on sexual crimes. The French parliament is already debating them.</p>  <h2>Book reveals dark secret</h2>  <p>This began, and stayed for years, a family story. But not just any family. Olivier Duhamel, 70, was a high-flyer in the tight French elite, not a politician in public view but an adviser, a political scientist and constitutional expert. And friend to French presidents.</p>  <p>When the scandal erupted, he was the president of the powerful Fondation Nationale des Sciences Politiques, which runs one of France's most influential universities, the Paris Institute of Political Studies.</p>  <p>He was also the president of Le Siècle, a club of France's political and intellectual elite. For good measure, he appeared weekly on radio and television.</p>  <p>That carefully constructed world collapsed in early January with the publication of a book. It's called <em>La Familia Grande</em> and is written by his stepdaughter, Camille Kouchner, 45. In it, she details&nbsp;the alleged sexual abuse&nbsp;of her twin brother, whom she calls Victor in the book to protect his privacy, by her&nbsp;stepfather, Olivier Duhamel, when Victor was 13 and 14.</p>  <p>Duhamel immediately resigned all his posts and went to ground. He admitted nothing, simply saying he had been the target of personal attacks.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5892782.1611890445!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/france.JPG 300w,https://i.cbc.ca/1.5892782.1611890445!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/france.JPG 460w,https://i.cbc.ca/1.5892782.1611890445!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/france.JPG 620w,https://i.cbc.ca/1.5892782.1611890445!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/france.JPG 780w,https://i.cbc.ca/1.5892782.1611890445!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/france.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5892782.1611890445!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/france.JPG"></p></div><figcaption>Olivier Duhamel, second from right, used to be an influential political scientist in France, seen here in 2007 with French President Nicolas Sarkozy, left. <!-- --> <!-- -->(Philippe Wojazer/Reuters)</figcaption></figure></span></p>  <p>Others also resigned, including a former justice minister, Elisabeth Guigou. She was a close friend of Duhamel and his family but, for the record, denied knowing of the allegations. Almost unbelievably, the post she resigned from was as chair of a government commission on incest.</p>  <p>According to Camille Kouchner, Duhamel's family, and then others close to the family, had known for a dozen years of the alleged sexual abuse, but Victor had not wanted the facts to become public.</p>  <p>Her book unleashed a storm. The social media hashtag&nbsp;#MeTooInceste attracted thousands of testimonies from people saying they had been victims of incest. This reflected the shocking result of an opinion poll from Ipsos in November 2020 that surveyed a random sample of 1,033 French adults. In it, one in 10 people surveyed said they had been victims of incest. (In France, incest is defined more widely, and includes sexual abuse by a family member even if not related by blood.)</p>  <h2>Change to the law</h2>  <p>Camille Kouchner's book has already had a print run of more than 300,000 copies. Two weeks after its publication, Victor was interviewed by French police. An investigation 10 years earlier had been dropped because the statute of limitations on incest and sexual aggression against minors was limited to 20 years.&nbsp;</p>  <p>Two years ago, the statute of limitations was lengthened to 30 years from the age of majority of the minor.&nbsp;</p>  <p>And, in response to the groundswell of outrage, Macron said, "We will go after the aggressors."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5892849.1611888315!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/france-mali.JPG 300w,https://i.cbc.ca/1.5892849.1611888315!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/france-mali.JPG 460w,https://i.cbc.ca/1.5892849.1611888315!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/france-mali.JPG 620w,https://i.cbc.ca/1.5892849.1611888315!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/france-mali.JPG 780w,https://i.cbc.ca/1.5892849.1611888315!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/france-mali.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5892849.1611888315!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/france-mali.JPG"></p></div><figcaption>French President Emmanuel Macron, wearing a protective face mask, has offered his support to victims of sexual abuse within families.<!-- --> <!-- -->(Gonzalo Fuentes/Reuters)</figcaption></figure></span></p>  <p>On Jan. 26, Victor officially indicated that he considered his stepfather an aggressor. He made a criminal complaint against Olivier Duhamel.</p>  <p>Victor's brother, Julien Kouchner, was quoted in the newspaper Le Parisien two days earlier saying, "In our circle, many people knew of the behaviour of my stepfather." That circle was one of the highest in France. The father of Julien, Victor and Camille is Bernard Kouchner, a former French foreign minister and co-founder of Médecins Sans Frontières (Doctors Without Borders). His second wife is Christine Ockrent, a famous television anchor and journalist.&nbsp;</p>  <p>According to Camille and Julien, Kouchner and Ockrent were horrified when Victor told them of Duhamel's behaviour in 2008, but Victor&nbsp;didn't want it made public because his mother, Evelyne Pisier, was still with Duhamel and refused to accept he had raped her son. But Kouchner and Ockrent allegedly told friends.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5892783.1611883020!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/usa-iran-opposition.JPG 300w,https://i.cbc.ca/1.5892783.1611883020!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/usa-iran-opposition.JPG 460w,https://i.cbc.ca/1.5892783.1611883020!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/usa-iran-opposition.JPG 620w,https://i.cbc.ca/1.5892783.1611883020!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/usa-iran-opposition.JPG 780w,https://i.cbc.ca/1.5892783.1611883020!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/usa-iran-opposition.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5892783.1611883020!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/usa-iran-opposition.JPG"></p></div><figcaption>Bernard Kouchner, former foreign minister of France, is seen during the 2018 Iran Uprising Summit in Manhattan, New York. <!-- --> <!-- -->(Amr Alfiky/Reuters)</figcaption></figure></span></p>  <p>Julien told Le Parisien: "Our world then divided into two, those who distanced themselves or even broke with [Duhamel], and others who stayed with him because of disbelief or opportunism…. But I've since discovered a third category, that of the accomplices who said things were only rumours which they knew to be exact facts."</p>  <p>For 12 years, Olivier Duhamel carried on untouched. He lost none of his positions or clout.</p>  <p>Only after Evelyne Pisier died in 2017 did Camille, with Victor's permission and support, decide to write about what happened.</p>  <h2>Social reckoning&nbsp;</h2>  <p>The detonation has been huge, but there was another bomb a year earlier. It, too, took the form of a book, this one called <em>Le Consentement</em> (<em>Consent</em>). The author, Vanessa Springora, told of being sexually pursued and possessed at age 14 in the 1980s by a man more than 30 years older.&nbsp;</p>  <p>The man was Gabriel Matzneff, 84, a successful author whose works detailed the pursuit and conquest of teenage girls and boys. He was rewarded with editing jobs at a big publishing house and major French literary prizes.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5892781.1611882879!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/france-sexual-consent.jpg 300w,https://i.cbc.ca/1.5892781.1611882879!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/france-sexual-consent.jpg 460w,https://i.cbc.ca/1.5892781.1611882879!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/france-sexual-consent.jpg 620w,https://i.cbc.ca/1.5892781.1611882879!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/france-sexual-consent.jpg 780w,https://i.cbc.ca/1.5892781.1611882879!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/france-sexual-consent.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5892781.1611882879!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/france-sexual-consent.jpg"></p></div><figcaption>The book Le Consentement by Vanessa Springora is displayed in a bookstore outside Paris. The literary editor alleges that she had a destructive underage sexual relationship with French author Gabriel Matzneff, now in his eighties.<!-- --> <!-- -->(Christophe Ena/The Associated Press)</figcaption></figure></span></p>  <p>Springora's book, which sold more than 200,000 copies, brought about an abrupt change. Matzneff was stripped of his positions and charged with justifying&nbsp;aggravated rape.</p>  <p>He expressed "regret" for his sexual activities, but, in an interview with the New York Times in February 2020, seemed unrepentant. "Even the silly things I might have done in those euphoric days of freedom, I wasn't the only one. What hypocrisy."</p>  <p>"Those days of freedom" refers to the years after what in France are called "the events of 1968." France was brought to a halt in May 1968 by massive strikes. The call was for revolution, and for sexual freedom in particular.&nbsp;</p>  <p>The 1960s, '70s and '80s among elites in France became an era of open sex and open marriages. The mother of Victor, Evelyne&nbsp;Pisier, both before and after she divorced Bernard Kouchner, embraced this ethos with several lovers, including, for four years, Fidel Castro, Cuba's president.</p>  <p>Then she met and married Olivier Duhamel. Even when Victor told her of her husband's behaviour, she refused to believe it, her children say.</p>  <p>There is now a sad reckoning in France.</p>  <p>"How do you resist the call of the flesh, liberated from all restraints? How do you say no when imposed sexuality is labelled as emancipation?" Malka Marcovich says in her book <em>L'Autre Héritage de 1968: La Face Cachée de la Révolution Sexuelle</em> (<em>The Other Heritage of 1968: The Hidden Face of the Sexual Revolution</em>), published in 2018. "So people, male and female, who were dragged into a premature sexuality, now seen as violent, preferred to keep quiet."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5892784.1611883098!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/france-sexual-misconduct.jpg 300w,https://i.cbc.ca/1.5892784.1611883098!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/france-sexual-misconduct.jpg 460w,https://i.cbc.ca/1.5892784.1611883098!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/france-sexual-misconduct.jpg 620w,https://i.cbc.ca/1.5892784.1611883098!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/france-sexual-misconduct.jpg 780w,https://i.cbc.ca/1.5892784.1611883098!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/france-sexual-misconduct.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5892784.1611883098!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/france-sexual-misconduct.jpg"></p></div><figcaption>Emmanuel Pierrat, lawyer of French writer Gabriel Matzneff, leaves Paris's courthouse on Feb. 12, 2020. The legal woes of the once-celebrated writer, Matzneff, are mounting. <!-- --> <!-- -->(Michel Euler/The Associated Press)</figcaption></figure></span></p>  <p>Matzneff pushed the "call of the flesh" even further, drawing up an open letter in 1977 calling for sex with minors under 15 to be decriminalized. Sixty-nine French intellectuals including Simone de Beauvoir and Jean-Paul Sartre signed. So did two future cabinet ministers. One of them was Bernard Kouchner, Victor's father.&nbsp;</p>  <p>After Springora's book was published, Kouchner recanted in an interview with the French magazine Le Point in January 2020. "That was idiocy. I didn't even read it. A friend said I should sign it."</p>    <p>And in an interview with Le Nouvel Obs, a French magazine, on Jan. 17, author Camille Kouchner offered a harsh verdict on that time, a verdict that, along with her stepfather, finds her mother guilty.</p>  <p>"Liberty, women, the couple, joyous infidelity, intelligent modernity — I was brought up with these ideas. My …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cbc.ca/news/world/france-sexual-abuse-book-elites-1.5892765">https://www.cbc.ca/news/world/france-sexual-abuse-book-elites-1.5892765</a></em></p>]]>
            </description>
            <link>https://www.cbc.ca/news/world/france-sexual-abuse-book-elites-1.5892765</link>
            <guid isPermaLink="false">hacker-news-small-sites-25982146</guid>
            <pubDate>Sun, 31 Jan 2021 20:16:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rainbow Warrior on shipbreaking beach in Bangladesh (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25981951">thread link</a>) | @Tomte
<br/>
January 31, 2021 | https://www.mo.be/en/news/rainbow-warrior-shipbreaking-beach-bangladesh | <a href="https://web.archive.org/web/*/https://www.mo.be/en/news/rainbow-warrior-shipbreaking-beach-bangladesh">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
              <div property="schema:articleBody content:encoded"><p><img alt="" src="https://www.mo.be/sites/default/files/styles/3_2_standard_photo_format/public/field/image/null_114156_WkfBC4.jpeg?itok=Xzf9Y7xN" title=" "></p>  <p>On November 15, Greenpeace International posted a remarkable announcement on its website. “We have made a mistake, one that we have tried to correct”, the announcement opens. The mistake is not a minor calculation error or a hasty social media campaign, but: “We have allowed the Rongdhonu, formerly the Rainbow Warrior (II), to be scrapped on a beaching yard in Bangladesh, in a way that does not live up to the standards we set ourselves and campaigned with our allies to have adopted across the world.”</p>  <p>Greenpeace was, indeed, together with the NGO Shipbreaking Platform, one of the first organizations to campaign against beaching for shipbreaking. How, then, is it possible that its own iconic Rainbow Warrior II (the first ship with that name was sunk by the French secret services in a terrorist attack in 1985 because of Greenpeace’s campaign against the French nuclear tests in Polynesia) ends up on a shipbreaking beach?</p>  <h2><strong>Mistake, with a capital M</strong></h2>  <p>The story actually begins in 2011, when Greenpeace determined that the Rainbow Warrior II was deemed no longer fit to sail the high seas, and the ship was donated to Friendship, a medical NGO from Bangladesh. Friendship rebaptised the boat Rongdhonu — Rainbow in Bengali — and used it to serve the climate impacted population of the coastal belt of the Bay of Bengal. It has, since then, served over 150.000 people, children and women which otherwise would have had no access to health care, and about 5400 surgeries were performed on board.</p>  <p>This year, Friendship came to the decision to phase out the 61-year old ship, due to the fact that the level of requirements of the authorities in Bangladesh have become such that a more than 60 year old ship would not have its navigation permits renewed. In the agreement signed by Greenpeace with Friendship, there was a clause giving Greenpeace International a veto on proposals for the demolition of the ship, when it would be taken out of service. When Friendship suggested that the ship be scrapped at PHP shipbreaking yard in Chittagong, Bangladesh, GPI could have said no. But it did not.</p>  <blockquote> 	<p>‘The error was due to the fact that the decision was taken “without consulting either its own expertise or allies within the NGO Shipbreaking Platform or Basel Action Network”.</p> </blockquote>  <p>The operational service of Greenpeace International was convinced that the Rongdhonu could no longer make a big trip to a shipbreaking yard that would meet its own standards and requirements. That was the mistake, the organization now admits. Greenpeace Norway is a bit more outspoken than the international umbrella, and states that the decision to send the ship to a beach shipyard was “the result of a major internal error”. &nbsp;According to the Norwegian section, the error was due to the fact that the decision was taken “without consulting either its own expertise or allies within the NGO Shipbreaking Platform or Basel Action Network”.</p>  <p>Greenpeace International promises an internal investigation, and for the sake of clarity, adds that “Greenpeace does not believe that breaking ships apart on tidal beaches is green”. This clarification is not superfluous, as some players from the shipbreaking or shipping industry immediately tried to use the story to suggest that Greenpeace finally came around to recognize that shipbreaking on “improved beaches” would be a good and sustainable option. GMS, for example, congratulated “both Greenpeace and Friendship for actively participating in the green transformation of the ship recycling industry in Bangladesh”.</p>  <h2>Peace, Happiness, Prosperity</h2>  <p>The breaking of the Rongdhondu / Rainbow Warrior II on a Chittagong beach does not only threathen to cause environmental, but also reputational damage to Greenpeace. Reason enough for Greenpeace International to try to buy back the ship from the PHP yard, but apparently that effort is not succesful. Greenpeace International, for reasons of confidentiality in the talks, can not disclose how much the owner of PHP asked for the discarded vessel. Greenpeace Netherlands quotes a number of 10 million dollars, for a vessel that would be worth around 176,000 euros in steel value. What is clear, is that the gap between the real price and the price asked was far too large .</p>  <p>No small detail: PHP — in full Peace Happiness Prosperity — is the only shipbreaking yard in Chittagong that can present a Hong Kong Convention Certificate of Compliance, stating that the yard operates in accordance with the rules outlined in the Hong Kong Convention for Ship Recycling. It is not unlikely that this Certificate of Compliance has caused confusion, even on the level of the Greenpeace operational service. It certainly played a big role in the choice of Friendship to propose PHP as the scrapping yard fort he Rongdhonu, says executive director Runa Khan in a reaction to our questions: “PHP shipyard is the most environmentally friendly shipyard available in Bangladesh and in particular has all certifications regarding the fact that it meets the requirements of the Hong Kong Convention.”</p>  <blockquote> 	<p>The Hong Kong Convention applies low standards for shipbreaking, and is not even in force, even though it was already concluded in 2009</p> </blockquote>  <p>For the uninitiated, it is important to realize that the Hong Kong Convention applies low standards for shipbreaking, and is not even in force, even though it was already concluded in 2009, because there are still only six countries that have ratified it.</p>  <p>Moreover, the certificates that have to prove that a yard complies with the requirements of the HKC are issued by private companies, and are not controlled by any government or international institution as long as the convention has not entered into force. Baskut Tuncak, UN Special Rapporteur on harmful substances and toxic waste: “I thoroughly studied the management structure of one of the certification companies — ClassNK. This shows that such private companies do not operate independently at all and should rather be seen as extensions of the shipping industry. The question is therefore what the authority is of the certificates they issue or of such a company itself. ” The certificate for PHP was awarded by the Italian certification company Rina.</p>  <p><img alt="" src="https://www.mo.be/sites/default/files/styles/3_2_standard_photo_format/public/field/image/null_114157_iwnfw6.jpeg?itok=5A0UkDik" title=" "></p>  <h2>Missing shipbreaking policy</h2>  <p>What the communication from Greenpeace does not clarify, is how it is possible that such a “mistake” could happen within an internationally operating environmental movement. Mike Townsley, communications manager at Greenpeace International, is brief and clear when we ask the question: “Because we did not have a clear shipbreaking policy.”</p>  <blockquote> 	<p>“We apparently counted on the collective memory of the shipbreaking campaigns and thought that would suffice to always opt for clean and responsible ship recycling. But it is clearly not enough.”</p> </blockquote>  <p>That in itself is difficult to explain for an organization that has been using a small fleet for fifty years to be able to carry out its actions — against nuclear tests, palm oil or other issues — on the high seas. “True”, Townsley reacts. “It is an institutional error. We apparently counted on the collective memory of the shipbreaking campaigns of ten years ago, and we seem to have thought that would suffice to always opt for clean and responsible ship recycling. But it is clearly not enough.”</p>  <p>And so Greenpeace International is currently working on a formal shipbreaking policy for its own ships, in consultation with Shipbreaking Platform. The latter organization has suspended Greenpeace from its membership following the clear breach with the Platform’s policy against beaching, and may propose at its next General Meeting that Greenpeace International will no longer be a member of the platform, for fear that the Rainbow Warrior error might cause confucion about the clear position SBP has always maintained. Townsley can not yet say when that policy will be finalized and operational, but he thinks “in months, rather than years”. “In any case, this policy must be operational before a next ship is taken out of service”, he adds.</p>  <h2>Greenpeace asks for the waste</h2>  <p>While it seems to be impossible to buy back the ship and give it a final destination that corresponds with its own principles, Greenpeace still tries to reach an agreement with PHP about everything that is harmful or toxic waste in the Rongdhonu. Greenpeace wants to export that waste to a country where there is suitable infrastructure to store or process it. The complete absence of the necessary infrastructure in Chittagong, both on the tidal mudflats and downstream, is one of the important points of criticism from NGOs such as Shipbreaking Platform and Basel Action Network on shipbreaking there. At this moment it is not yet certain whether an agreement with the PHP yard can be reached.</p>  <blockquote> 	<p>“Greenpeace now has to prove that it is serious about its commitment to continue to fully and publicly support our “off the beach” campaign”</p> </blockquote>  <p>Martin Besieux, a Belgian who worked for more than thirty years at Greenpeace and, since retirement, is part of the board of Shipbreaking Platform, reacts disappointed bur firm to the whole story: “Greenpeace now has to prove that it is serious about its commitment to continue to fully and publicly support our “off the beach” campaign. The shipping industry can no longer escape the most logical and effective scrapping rules that apply to virtually all other industrial sectors.”</p> </div>
      </div>
</div></div>]]>
            </description>
            <link>https://www.mo.be/en/news/rainbow-warrior-shipbreaking-beach-bangladesh</link>
            <guid isPermaLink="false">hacker-news-small-sites-25981951</guid>
            <pubDate>Sun, 31 Jan 2021 19:53:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Interactive Virtual Keyboard to Visualize Keyboard Shortcuts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25981900">thread link</a>) | @tkainrad
<br/>
January 31, 2021 | https://tkainrad.dev/posts/visualize-collections-of-keyboard-shortcuts/ | <a href="https://web.archive.org/web/*/https://tkainrad.dev/posts/visualize-collections-of-keyboard-shortcuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentdiv">

<p>An important part of <a href="https://keycombiner.com/">KeyCombiner</a> is displaying collections of keyboard shortcuts. Therefore, I have invested a lot of time to design searching and filtering features that help to browse even large collections.</p>
<p>Unfortunately, these feature are not sufficient when you want to understand a collection of hundreds of shortcuts at a glance. I have been thinking about this problem since I started working on KeyCombiner almost precisely one year ago. Today, I am happy to announce that KeyCombiner offers a solution:<br>
The Shortcut Collection Visualizer</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/visual-keyboard-short-blog-bg.gif" alt="Collection Visualizer for XCode, one of very few applications that use all 4 modifier keys at the same time."> <figcaption>
<p>Collection Visualizer for <a href="https://keycombiner.com/collections/xcode/">XCode</a>, one of very few applications that use all 4 modifier keys at the same time.</p>
</figcaption>
</figure>
<p>It is heavily inspired by Waldo Bronchart’s open-source <a href="https://github.com/waldobronchart/ShortcutMapper">Application Shortcut Mapper</a>. However, it is a new VueJS-based implementation, adding several additional features that work together with the rest of KeyCombiner. Most importantly, it can efficiently process KeyCombiner’s collection tables and hence works for any shortcut collection on KeyCombiner, <a href="https://keycombiner.com/collecting/collections/public/search/?description=dialog&amp;keys=&amp;mac_keys=&amp;submit=Search">even search results</a>.</p>
<p>If you want to play around with it right away, go to any public KeyCombiner collection, e.g. for <a href="https://keycombiner.com/collections/vscode/">VSCode</a>, <a href="https://keycombiner.com/collections/intellij-idea/winlinux/">IntelliJ IDEA</a>, <a href="https://keycombiner.com/collections/xcode/">XCode</a>, <a href="https://keycombiner.com/collections/chrome/winlinux/">Chrome</a> or one of <a href="https://keycombiner.com/collections/">the other 60+ public collections</a>. If you want to fully undestand its potential, please read on.</p>

<h2 id="overview">Overview</h2>
<p>The virtual keyboard packs a lot of data into a relatively small space. Each button of the keyboard consists of the following elements:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/visual-keyboard-description.png" alt="Elements on each key of the virtual keyboard."> <figcaption>
<p>Elements on each key of the virtual keyboard.</p>
</figcaption>
</figure>
<h2 id="grouping-by-modifier-combination">Grouping by Modifier Combination</h2>
<p>A proper keyboard shortcut consists of 0 or more modifier keys and exactly one non-modifier key. There are 4 modifier keys:</p>
<ol>
<li><kbd>Ctrl</kbd></li>
<li><kbd>Shift</kbd></li>
<li><kbd>Alt</kbd></li>
<li><kbd>Cmd</kbd> (macOS) / <kbd>Super</kbd> (Windows and Linux)</li>
</ol>
<p>This order of modifiers is not random. KeyCombiner <em>always</em> shows keyboard shortcuts with precisely this order. <a href="https://twitter.com/ThomasKainrad/status/1340769935971282946">There are good reasons for this</a>.</p>
<p>This means that we have four boolean variables, resulting in $2^4$ possible modifier combinations. For each of these 16 states, the Collection Visualizer uses a different background color, or background gradient if there are multiple active modifiers.</p>
<p>To toggle modifiers, click on the virtual buttons with your mouse, or press the respective modifier key on on your physical keyboard. The entire virtual keyboard will then update according to the active combination of modifiers.</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/all-modifier-states.gif" alt="It is very rare that a key has a shortcut for every modifier combination. However, it can happen, especially when combining shortcuts of multiple applications in personal collections. (Please don&amp;rsquo;t tell me I forgot one of the 16 modifier combinations - it took me way too long to create this animation.)"> <figcaption>
<p>It is very rare that a key has a shortcut for every modifier combination. However, it can happen, especially when combining shortcuts of multiple applications in personal collections. <br> (Please don’t tell me I forgot one of the 16 modifier combinations - it took me way too long to create this animation.)</p>
</figcaption>
</figure>
<h2 id="filter-collection-table">Filter Collection Table</h2>
<p>One of my favorite things about KeyCombiner’s shortcut collections is that I can filter them by context, category, or modifier combination with a single click using the panes on the side.</p>
<p>The collection visualizer expands on this concept. If you click on any non-modifier key, the collection table will show all shortcuts that use this particular key. To show all shortcuts containing the key <kbd>F</kbd> click on the F button on the virtual keyboard.</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/filter-by-key-press.gif" alt="Filtering the collection table for all shortcuts that contain the F key."> <figcaption>
<p>Filtering the collection table for all shortcuts that contain the <kbd>F</kbd> key.</p>
</figcaption>
</figure>
<h2 id="real-time-updates-on-changes">Real-time updates on changes</h2>
<p>Building personal collections of keyboard shortcuts and text snippets is the foundational concept behind KeyCombiner. You can then practice these collections with its interactive trainer, relying on spaced repetition techniques and advanced statistics to guide your learning progress. You can also use <a href="https://keycombiner.com/desktop/">KeyCombiner Desktop</a> to instantly look up all combinations in your collections without leaving your current context.</p>
<p>Oh wait, I am getting side-tracked. I meant to say that the collection visualizer updates immediately whenever you make a change to one of your collections. A change could be adding new shortcuts, editing existing entries, or re(moving) entries. This works in the blink of an eye, even if you remove hundreds of combinations at once.</p>
<h2 id="additional-features">Additional Features</h2>
<p>I am getting the sense that this post will be too long for the average person’s interest in keyboard shortcuts. So, I will list some additional features in shorter form:</p>
<ul>
<li>There are three levels of opacity:
<ol>
<li>Keys without any mapped combinations</li>
<li>Keys with mapped shortcuts, but none that use the current modifiers</li>
<li>Keys that have a combination with the currently activated modifiers</li>
</ol>
</li>
</ul>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/opacity.png" alt="Different levels of opacity carry information."> <figcaption>
<p>Different levels of opacity carry information.</p>
</figcaption>
</figure>
<ul>
<li>If, for any modifier combination, there are two or more shortcuts bound to a key, the number of combinations in the top right of the button is marked red.</li>
<li>If there are two or more combinations on a key for the current modifier state, the shortcut description for this key says <em>Conflict</em>.</li>
<li>There is a small text below the virtual keyboard saying how many shortcuts are mapped onto the virtual keyboard, and how many combinations had to be skipped. (See <a href="#current-limitations">Current Limitations</a>)</li>
<li>The keyboard must be in focus if you want to activate modifiers by pressing the respective buttons on your physical keyboard. This is so that you can still use <kbd>Ctrl</kbd> and <kbd>Shift</kbd> for table selection operations without affecting the visualizer. Buttons below the virtual keyboard allow toggling the focus.</li>
</ul>

<h2 id="quickly-grasp-a-set-of-shortcuts">Quickly Grasp a Set of Shortcuts</h2>
<p>Perhaps the most obvious use case is exploring a collection of shortcuts. The visual keyboard helps immensely in this process. Within seconds, you can get a feeling of which modifiers are used by a specific application and whether it uses Vim-like home row navigation or something else entirely.</p>
<p>The different layers of opacity aid this use case. Without activating any modifiers, you can already understand where the most shortcuts are located. This is supported further by the combination count in each virtual keyboard button’s top right.
Filtering the collection table by clicking on a specific key lets you see all shortcuts for that key and understand how they are related.</p>
<h2 id="see-conflicts-and-free-combinations">See Conflicts and Free Combinations</h2>
<p>At the moment, this is my favorite use case, as I have used it plenty of times already with great success.</p>
<p>I recently <a href="https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">learned all VSCode shortcuts</a> with KeyCombiner’s interactive trainer. However, since then, I have started to experiment with <a href="https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">Foam</a> and picked up some other extensions. All of these come with their own set of commands. So, I frequently have to find an available key combination for a new command I want to use efficiently. VSCode itself is not much help with that. It tells you <em>after</em> setting a combination that it is already taken:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/vscode-binding-exists.png" alt="Different levels of opacity carry information."> <figcaption>
<p>Different levels of opacity carry information.</p>
</figcaption>
</figure>
<p>I guess it’s better than nothing, but trying multiple combinations and manually checking what other combination is already using that binding and whether you might be able to remove that other binding is not much fun.
The collection visualizer made it trivial to see that there are actually plenty of free combinations in VSCode, only <kbd>Ctrl</kbd> and <kbd>Shift</kbd> are quite busy by default. Things start happening if you mix in <kbd>Alt</kbd>:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/vscode-free-combinations.png" alt="All modifier combinations with Alt are wide open for your own assignments in VSCode."> <figcaption>
<p>All modifier combinations with <kbd>Alt</kbd> are wide open for your own assignments in VSCode.</p>
</figcaption>
</figure>
<p>You can then go one step further and find free combinations that are easy to type. For me, these are combinations that I can type with just my left hand. If the non-modifier key is on the home row, that’s another big plus. In any case, a convenient shortcut should have a maximum of two modifiers.</p>
<h2 id="design-a-coherent-set-of-shortcuts">Design a Coherent Set of Shortcuts</h2>
<p>The collection visualizer helps design a coherent set of shortcuts, either for yourself or for an application you are developing.</p>
<p>Unfortunately, many application designers do not think very hard about keyboard shortcuts. Often, you end up with a set that is neither intuitive nor easy to type. Heck, even <a href="https://keycombiner.com/collections/keycombiner/">KeyCombiner’s own shortcuts</a> are all over the place with sequences and different modifier combinations. Given that I work more or less alone on the project and try to be very efficient with my time, I didn’t think about these bindings enough. The collection visualizer makes this painfully obvious, and I will soon come up with new shortcuts. However, it will be very hard not to annoy users who have already memorized these shortcuts.
So, I recommend that you be smarter than me and start to design a coherent set of shortcuts for your application right away. The collection visualizer is here to help you with that.</p>
<p>If you are not an application designer, you might still want to design a coherent set of key bindings for your personal use. Without any tools to assist you, this is a suprisingly hard taks, especially when you try to find a coherent set for or <em>multiple</em> applications. You have to keep in mind which commands are available in these different apps, what the defaults are, and how to resolve these constraints into a set that works everywhere.
The collection visualizer, along with KeyCombiner’s other collection management features, can help you get there.</p>

<p>Above, I have written that a proper keyboard shortcut consists of 0 or more modifier keys and exactly one non-modifier key. However, KeyCombiner also allows sequences, such as the <em>Go To</em> shortcuts used by Gmail. I have been thinking a lot about how to visualize those on a virtual keyboard, but have not found a good solution yet.</p>
<p>Furthermore, KeyCombiner collections can also hold short text snippets, such as commands and programming language syntax. Many people use these snippets with the <a href="https://tkainrad.dev/posts/app-to-show-shortcuts-of-current-application-windows-linux-macos">Desktop Apps' instant lookup</a>. It turns your collections into an instant, context-aware, searchable cheatsheet. However, I struggle to find a way to visualize them on a keyboard.</p>

<p>In its first days, the collection visualizer has already helped me plenty of times. I improved my VSCode bindings, realized that KeyCombiner’s own default bindings are not intuitive, and found better ways to reuse my VSCode bindings in PyCharm and Eclipse.
I’d be thrilled to hear about your experiences in the comments below or via <a href="https://tkainrad.dev/cdn-cgi/l/email-protection#eb9f8384868a98ab9f808a8285998a8fc58f8e9d">mail</a>.</p>
<p>I will write about the collection visualizer’s implementation in a future blog post. Spoiler: Vue and (S)CSS do the heavy lifting.</p>
<br>
</div></div>]]>
            </description>
            <link>https://tkainrad.dev/posts/visualize-collections-of-keyboard-shortcuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25981900</guid>
            <pubDate>Sun, 31 Jan 2021 19:47:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better C Bracing Style]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25981730">thread link</a>) | @kazinator
<br/>
January 31, 2021 | https://www.usenetarchives.com/view.php?id=net.lang.c&mid=eWFsZS1jb20uMTU5 | <a href="https://web.archive.org/web/*/https://www.usenetarchives.com/view.php?id=net.lang.c&mid=eWFsZS1jb20uMTU5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="popup-article">
    <div>
        <h2 id="label">Welcome to UsenetArchives.com</h2>
        <p>We are one of the most extensive archives of Usenet newsgroups on the Internet, archiving millions of Usenet posts.<br>
            The free of charge access is possible via the web interface, without a requirement for a third party Newsreader.</p>

        <p>To access a specific newsgroup, search for the newsgroup name and navigate to the discussion thread of your choice.</p>

        <p>Currently we're in the process of migration to a new database engine, to see the real-time collection stats, visit the <a href="https://www.usenetarchives.com/stats.php">Stats</a> page.</p>

        <p>We are working on a full content search capability, however, a feasible solution for such an extensive amount of content/data is costly. You can help us by becoming our <span><a href="#">Patron</a></span></p>

        <p><a href="#">close</a>
    </p></div>
</div></div>]]>
            </description>
            <link>https://www.usenetarchives.com/view.php?id=net.lang.c&amp;mid=eWFsZS1jb20uMTU5</link>
            <guid isPermaLink="false">hacker-news-small-sites-25981730</guid>
            <pubDate>Sun, 31 Jan 2021 19:31:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Write an Email to Delete an Online Account]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25981692">thread link</a>) | @behnamoh
<br/>
January 31, 2021 | https://www.loginhit.com.ng/a-sample-on-how-to-write-a-mail-to-delete-an-online-account/ | <a href="https://web.archive.org/web/*/https://www.loginhit.com.ng/a-sample-on-how-to-write-a-mail-to-delete-an-online-account/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
        
 <!-- A generated by theme --> 



 <!-- end A --> 


<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->


<p><strong>How To Write A Mail To Delete An Online Account.</strong></p>



<p>Old accounts are a major security risk. Not only do many old accounts have weaker passwords, but those sites may also have poor data protection policies. Reduce your security risks by deleting old accounts. And navigate the process more easily using our service</p>
<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->





<p>In today’s woke internet culture, if someone tells you to “delete your account”, it’s usually not because they’re concerned for your internet privacy. Nevertheless, you may want to delete online accounts that you haven’t used in a while. Old accounts are susceptible to hackers, and any information you’ve left sitting around could leave you vulnerable to identity theft, financial loss, and additional account takeovers.</p>



<p>But as anyone who’s ever tried to delete an online account can attest to, it’s not always as simple as logging into the website and clicking “delete account” in the settings. Many sites now hide their account deletion methods within a labyrinth of web page links, while others won’t let you delete your account without imposing archaic rigamarole, like sending a support email.</p>




 <!-- A generated by theme --> 



 <!-- end A --> 

<p>This being the case, you may need to use send an account deletion email to the company requesting account deletion.</p>



<p>There are <strong>five (5) ways</strong> in which an account created online can be deleted, canceled or removed. These <strong>five (5) ways</strong> are as follows:</p>
<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->





<p><strong>1.</strong>  By calling the <strong>customer service/support</strong>  on mobile phone to delete your account</p>



<p><strong>2.</strong> Chatting the <strong>customer services/support</strong> to delete your online account.</p>



<p><strong>3.</strong> Deleting your account through the official website of the company. </p>
<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->





<p><strong>4. By composing and sending email to the company requesting them to delete your online account.</strong></p>



<p><strong>5. </strong>None use of an online account for a relatively long period, after which the account may be permanently deleted. (This is true in some special types of account).</p>



<p>Meanwhile, in this article, therefore, we going to give you “a sample on How to Write a Mail to Delete An Online Account” which is the <strong>NO. 4</strong> as listed above.</p>



<h2>Here is a Sample on How to Write a Mail to Delete An Online Account</h2>



<p>SUBJECT: <strong>Request To Delete My Account From Your Database</strong></p>



<p>Dear (Company Name) Team, </p>



<p>I have an account in your database with the name ……………. and the email address that is linked to the account is ………………..<br>Meanwhile, for some reasons, I have decided not to use the account again, therefore I request that you kindly delete my account from your database and also wipe all notifications if any.</p>



<p>From:<br>Your Name.<br>Email Account.<br>Phone Number.</p>



<p><strong>NOTE</strong>: The name, email address and phone number that will be contained in the mail must be linked to the account you want to delete. This will evidence that you are the real owner of the account.</p>



<p>Meanwhile, if you mobile number is not linked to the account, there will be no need of you adding any phone number. </p>



<p>See the sample below:</p>



<figure><ul><li><figure><img loading="lazy" width="515" height="549" src="https://www.loginhit.com.ng/wp-content/uploads/2019/10/How-to-Write-a-Mail-to-Delete-An-Online-Account-1.png" alt="" data-id="431" data-link="https://www.loginhit.com.ng/?attachment_id=431" srcset="https://www.loginhit.com.ng/wp-content/uploads/2019/10/How-to-Write-a-Mail-to-Delete-An-Online-Account-1.png 515w, https://www.loginhit.com.ng/wp-content/uploads/2019/10/How-to-Write-a-Mail-to-Delete-An-Online-Account-1-281x300.png 281w" sizes="(max-width: 515px) 100vw, 515px" data-srcset="https://www.loginhit.com.ng/wp-content/uploads/2019/10/How-to-Write-a-Mail-to-Delete-An-Online-Account-1.png 515w, https://www.loginhit.com.ng/wp-content/uploads/2019/10/How-to-Write-a-Mail-to-Delete-An-Online-Account-1-281x300.png 281w" data-src="https://www.loginhit.com.ng/wp-content/uploads/2019/10/How-to-Write-a-Mail-to-Delete-An-Online-Account-1.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>How to Write a Mail to Delete An Online Account</figcaption></figure></li></ul></figure>



<h2>Account deletion process:</h2>



<p><strong>The deletion process normally consist of following steps:</strong></p>
<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->





<ul><li><strong>REQUEST:</strong> A user who wishes to delete their account/data may have to submit an account deletion request.</li><li><strong>VALIDATION:</strong> Their support team member may have to cross-check your information with their internal database. If data matches, they will initiate the deletion process and notify you that the deletion has started.</li><li><strong>DELETION:</strong> At this level, all the records of your account will be deleted.</li><li><strong>FINAL NOTIFICATION: </strong>Now, once the deletion process has been deleted, they will notify you that your account has been successfully deleted.</li></ul>



<h2>NOTE ALSO</h2>



<p>Some websites simply do not allow you to delete your account. At all. Many websites now sell user information or incorporate user information into their business practices. What you may find is that instead of allowing you to delete an account, some services instead only let you delete your personal information on the site, while the account itself (including the username and password) are maintained in the system.</p>



<p>To note, this is legally allowed in the US. While all US businesses must offer at least two avenues to identify and delete account information—one of which must be a toll-free number—US businesses do not have to delete the account itself. Instead, businesses are allowed to de-identify and aggregate your personal information.</p>



<h4>Some major companies and sites which do not allow account deletion include:</h4>



<ul><li>Barnes and Noble</li><li>Gawker Media websites (Lifehacker, Gizmodo, Kotaku, etc.)</li><li>Kik</li><li>Netflix</li><li>Steam</li><li>Wikipedia</li><li>YouTube&nbsp;</li><li>WordPress</li><li>Starbucks</li><li>Playstation Network</li><li>Pinterest</li></ul>



<p>There’s more, of course. And many, many others do allow account deletion but make it incredibly difficult to delete your account by employing strict and notably annoying user retention methods</p>



<h2>Why You Must Delete Your Old Online Accounts </h2>



<p>If you have old online accounts, you’ve likely had your information stolen in a past data breach, at a minimum. While nearly half of the US was impacted by the Equifax breach, many online users likely lost their name, email address, phone numbers, and even SSNs in smaller, lesser-reported data breaches over the years. And for many people, that data loss is likely tied to older online accounts, many of which were long forgotten.&nbsp;</p>



<p><strong>A major concern with old accounts is also credential stuffing.</strong> This occurs when hackers use leaked data breaches to attempt to login to other websites. This process is fairly automated, and hackers will use username and password combinations across a number of sites to determine which ones work.&nbsp;</p>



<h2>Know More About Credential Stuffing</h2>



<p>Credential stuffing is a type of cyberattack where stolen account credentials typically consisting of lists of usernames and/or email addresses and the corresponding passwords are used to gain unauthorized access to user accounts through large-scale automated login requests directed against a web application.</p>



<p>Unlike credential cracking, credential stuffing attacks do not attempt to brute force or guess any passwords – the attacker simply automates the logins for a large number (thousands to millions) of previously discovered credential pairs using standard web automation tools like Selenium, cURL, PhantomJS or tools designed specifically for these types of attacks such as: Sentry MBA, SNIPR, STORM, Blackbullet and Openbullet.</p>




<!-- Quick Adsense WordPress Plugin: http://quickadsense.com/ -->

<p>Credential stuffing attacks are possible because many users reuse the same username/password combination across multiple sites, with one survey reporting that 81% of users have reused a password across two or more sites and 25% of users use the same password across a majority of their accounts.</p>



<p>.<br>All rights reserved.<br>This material and other digital  content on this website may not be reproduced, republished, broadcast,  rewritten or redistributed in whole or in part without prior express  written permission from LoginHit.com.ng </p>


 <!-- A generated by theme --> 



 <!-- end A --> 

        </div></div>]]>
            </description>
            <link>https://www.loginhit.com.ng/a-sample-on-how-to-write-a-mail-to-delete-an-online-account/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25981692</guid>
            <pubDate>Sun, 31 Jan 2021 19:27:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Publication of Hiroshima in the New Yorker (1997)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25981452">thread link</a>) | @Tomte
<br/>
January 31, 2021 | http://www.herseyhiroshima.com/hiro.php | <a href="https://web.archive.org/web/*/http://www.herseyhiroshima.com/hiro.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p><b>Go to my <a href="http://www.herseyhiroshima.com/index.php">home page</a>
for some related links.</b></p>

<hr>

<dl>

  <dd>by: Steve Rothman &lt;<a href="mailto:steve@palmerrothman.com?subject=Hersey%20Hiroshima%20Paper">steve@palmerrothman.com</a>&gt;
January 8, 1997 </dd>

  <dd>class: Science and Society in the 20th Century </dd>

  <dd>taught by: Everett Mendelsohn, Professor of the History of
Science, Harvard University
  </dd>

</dl>

<h2>The Publication of "Hiroshima" in <i>The New Yorker</i></h2>

<h3>Overview</h3>

<p>A year after World War II ended, a leading American weekly
magazine published a striking description of what life was like for
those who survived a nuclear attack. The article, simply titled
"Hiroshima," was published by <i>The New Yorker</i> in its
August 31,
1946 issue. The thirty- one thousand word article displaced virtually
all other editorial matter in the issue.<br>

</p>

<p>"Hiroshima" traced the experiences of six residents who
survived
the blast of August 6, 1945 at 8: 15 am. There was a personnel clerk,
Miss Toshiko Sasaki; a physician, Dr. Masakazu Fujii; a tailor's
widow with three small children, Mrs. Hatsuyo Nakamura; a German
missionary priest, Father Wilhelm Kleinsorge; a young surgeon, Dr.
Terufumi Sasaki; and a Methodist pastor, the Reverend Mr. Kiyoshi
Tanimoto. The article told the story of their experiences, starting
from when the six woke up that morning, to what they were doing the
moment of the blast and the next few hours, continuing through the
next several days and then ending with the situations of the six
survivors several months later.<br>

</p>

<p>The article, written by John Hersey, created a blast of its
own in
the publishing world. <i>The New Yorker</i> sold out
immediately, and
requests for reprints poured in from all over the world. Following
publication, "Hiroshima" was read on the radio in the United States
and abroad. Other magazines reviewed the article and referred their
readers to it. The Book-of-the-Month Club sent a copy of the article
in book form to its entire membership as a free selection. Later that
fall, "Hiroshima" was published as a book by Alfred A. Knopf and has
remained in print ever since.<br>

</p>

<p>"Hiroshima" was not the first exposure that readers had to the
events that took place on August 6. Many articles in the popular
press described the destruction of the city, such as a Collier's
story published in the spring of 1946 crammed full of details about
the power of the atom bombs dropped on Hiroshima and Nagasaki (" at a
distance of 4,200 feet - about eight tenths of a mile - the pressure
was 2,160 pounds a square foot") and anecdotes about the horrific
effects of nuclear weapons on human beings ("Men in black-striped
shirts were burned in strips. Heat stenciled dress figures onto the
bodies of women."). <b><a href="#1">[1]</a></b>
Collier's also
included an artist's rendition of the effect of a nuclear blast on
downtown Manhattan. But most of these stories steered clear of
details that would help readers identify with the dead or the
survivors. Usually, "the statistics of devastation and death were
simply recited as prefatory to a plea for international control,
civil defense, or some other cause. On a canvas whose broadbrush
background scenes were already familiar, Hersey etched several
vividly realized foreground figures." <b><a href="#2">[2]</a></b><br>

</p>

<p>The direct effect of "Hiroshima" on the American public is
difficult to gauge. No mass movement formed as a result of the
article, no laws were passed, and reaction to the piece probably
didn't have any specific impact on U. S. military strategy or foreign
policy. But certainly the vivid depictions in the book must have been
a strong contributor to a pervasive sense of dread (and guilt) about
nuclear weaponry felt by many Americans ever since August 1945.<br>

</p>

<h3>Historical background --<i>The New Yorker</i></h3>

<p><i>The New Yorker</i> was founded in 1925 by
Harold Ross as a
sophisticated urban weekly that combined humor, fiction, poetry, art,
reporting, criticism, and a guide to New York cultural events. It
attracted some of the best twentieth- century writers available: E.
B. White, James Thurber, S. J. Perelman, Rebecca West, A. J.
Liebling, and Eudora Welty are a few of the names associated with the
magazine.<br>

</p>

<p>Although <i>The New Yorker</i> had an elitist
reputation it made
its own contribution to the war effort. A twenty- four page "pony
editon" containing no advertising was widely distributed to overseas
troops, along with equivalent editions of <i>Time</i> and
<i>Newsweek</i>, and other popular magazines. "By the end
of the war,
the pony edition [of <i>The New Yorker</i>] had a larger
circulation
than its parent." <b><a href="#3">[3]</a></b>
By 1946 <i>The New
Yorker</i> had a paid circulation of about 300,000, mostly
outside of
the New York metropolitan area.<br>

</p>

<h3>Historical background -- John Hersey</h3>

<p>John Hersey was born on June 17, 1914 in Tientsin, China to
missionaries Roscoe and Grace Baird Hersey. He lived in Tientsin
until he was ten years old and then returned to the U. S. with his
parents. Hersey attended Yale and then went on to graduate study at
Cambridge. He obtained a summer job as a secretary for Sinclair Lewis
in the summer of 1937, and, that fall, started work at Time magazine.
Two years later he was transferred to Time's Chungking bureau. During
World War II he covered the fighting in both Europe (Sicily) and Asia
(Guadalcanal), writing articles for <i>Time</i>, <i>Life</i>,
and
<i>The New Yorker</i>. Hersey's first article for <i>The
New
Yorker</i> was a piece about John F. Kennedy and the PT-109
rescue,
which was later reprinted in <i>Reader's Digest</i>.<br>

</p>

<p>Hersey's first book, Men on Bataan (1942) was a patriotic look
at
General Douglas MacArthur and his troops in the Pacific at the
beginning of the second World War. His second book, Into the Valley
(1943), described the fighting at Guadalcanal from the perspective of
the soldiers. At Guadalcanal, Hersey had become a participant rather
than just a reporter. The unit he was accompanying came under heavy
fire and suffered many casualties; Hersey was pressed into service as
a stretcher bearer and was later commended by the Navy for his
assistance in aiding the wounded.<br>

</p>

<p>Hersey was subsequently transferred to the Mediterranean
Theater,
where he reported on the Allies' invasion and occupation of Sicily.
He won the Pulitzer Prize for his first novel, A Bell for Adano
(1944), a fictionalized account of the occupation government in a
small Italian town. (<i>The New York Times</i> listed his
Pulitzer on
the same front page of its May 8, 1945 edition that announced the end
of the war in Europe.)<br>

</p>

<p>In 1944-45, Hersey was posted in Moscow by <i>Time</i>,
but after
the war in the Pacific ended he received a joint assignment to cover
China and Japan, with expenses shared by <i>Time</i> and <i>The
New
Yorker</i>.<br>

</p>

<h3>The Production of "Hiroshima"</h3>

<p>In the winter of 1945- 46, William Shawn, managing editor of
<i>The New Yorker</i>, discussed with Hersey a story idea
that would
illustrate the human dimension of the effects of the atomic bomb in
Hiroshima. Shawn was "astonished that in all the millions of words
being written about the bomb -- how and why the decision was made,
how the bomb came to be built, whether it should have been dropped at
all -- what had actually happened in Hiroshima itself... was being
ignored." In March 1946, Shawn sent a cable to Hersey (who was in
Shanghai at the time) encouraging the idea: "The more time that
passes, the more convinced we are that piece has wonderful
possibilities. No one has even touched it." The story was to be
published in August 1946, on the one-year anniversary of the dropping
of the bomb. <b><a href="#4">[4]</a></b><br>

</p>

<p>Engaged in many other ongoing projects, Hersey didn't begin
working on the story until May. He spent three weeks in Japan, first
doing some interviews and research in Tokyo, and then traveling to
Hiroshima to find and interview bomb survivors. Hersey decided not to
focus on the explosion or the wrecked city, but to investigate the
effects on people, later saying "I felt I would like to write about
what happened not to buildings but to human beings."
<b><a href="#5">[5]</a></b><br>

</p>

<p>Hersey flew back to the U. S. in late June and spent several
weeks
writing the article. Although he had interviewed many people in
Hiroshima, he decided to focus exclusively on the six "because they
had been good interview subjects, and not for any more dramatic
reasons such as their closeness to ground zero ... or because they
made up any convenient cross- section of Hiroshima."
<b><a href="#6">[6]</a></b><br>

</p>

<p>"Hiroshima" was written in a dry, calm manner that struck some
readers as emotionless but permitted the survivors' stories to speak
for themselves. Forty years after he wrote the article, Hersey said
in a letter to historian Paul Boyer, "The flat style was deliberate,
and I still think I was right to adopt it. A high literary manner, or
a show of passion, would have brought me into the story as a
mediator; I wanted to avoid such mediation, so the reader's
experience would be as direct as possible."
<b><a href="#7">[7]</a></b><br>

</p>

<p>In August, Hersey presented Shawn with the completed 150-page
manuscript. Hersey had arranged it as a four-part article to be run
in four consecutive issues, with separate introductions for the
second, third, and fourth parts. Shawn felt the introductions
interrupted the flow of the story and would lessen the effect, so he
asked Harold Ross, the founder and editor of <i>The New Yorker</i>,
if the piece could be published in a single issue. This would require
nearly all of the editorial space in the entire issue.<br>

</p>

<p>Ross deliberated for a week. He worried about disappointing
readers with the loss of their familiar features, and he was not
interested in doing something so extreme merely for the shock value.
On the other hand, omitting all of the editorial content for the
issue did solve the awkward situation posed by running cartoons and
other non-weighty matter in proximity with the piece. Ross wrote to
E. B. White, one of the few people to find out about the planned
article in advance: "Hersey has written thirty thousand words on the
bombing of Hiroshima (which I can now pronounce in a new and fancy
way), one hell of a story, and we are wondering what to do about
it...[ Shawn] wants to wake people up and says we are the people with
a chance to do it, and probably the only people that …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.herseyhiroshima.com/hiro.php">http://www.herseyhiroshima.com/hiro.php</a></em></p>]]>
            </description>
            <link>http://www.herseyhiroshima.com/hiro.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25981452</guid>
            <pubDate>Sun, 31 Jan 2021 18:58:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manless climbing: Dorothy Pilley Richards 1894-1986]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25981323">thread link</a>) | @fanf2
<br/>
January 31, 2021 | https://akennedysmith.com/2021/01/30/manless-climbing-dorothy-pilley-richards-1894-1986/ | <a href="https://web.archive.org/web/*/https://akennedysmith.com/2021/01/30/manless-climbing-dorothy-pilley-richards-1894-1986/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<figure><img loading="lazy" data-attachment-id="2353" data-permalink="https://akennedysmith.com/dorothy_pilley/" data-orig-file="https://akennedysmith.files.wordpress.com/2021/01/dorothy_pilley.jpg" data-orig-size="458,559" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="dorothy_pilley" data-image-description="" data-medium-file="https://akennedysmith.files.wordpress.com/2021/01/dorothy_pilley.jpg?w=246" data-large-file="https://akennedysmith.files.wordpress.com/2021/01/dorothy_pilley.jpg?w=458" src="https://akennedysmith.files.wordpress.com/2021/01/dorothy_pilley.jpg?w=458" alt="" width="358" height="437" srcset="https://akennedysmith.files.wordpress.com/2021/01/dorothy_pilley.jpg?w=358 358w, https://akennedysmith.files.wordpress.com/2021/01/dorothy_pilley.jpg?w=123 123w, https://akennedysmith.files.wordpress.com/2021/01/dorothy_pilley.jpg?w=246 246w, https://akennedysmith.files.wordpress.com/2021/01/dorothy_pilley.jpg 458w" sizes="(max-width: 358px) 100vw, 358px"></figure>



<p>On 11 November 1918 Dorothy Pilley was 22 years old and in London when news of the Armistice reached her. She rushed to Buckingham Palace, where she spotted an irresistible challenge. ‘I saw in a flash the Victoria Memorial waiting to be climbed: white, untouched, a secret ambition of mine to scale its dizzy heights,’ she wrote in her diary that evening. Pilley was secretary of the British Patriotic Women’s League at the time, earning £200 a year writing newspaper articles to promote the League’s work. But her passion in life was for climbing the mountains of North Wales and Skye. So it was natural that on Armistice Day  she would use mountaineering terms to describe her joyous ascent of the 25-metre-high monument. ‘Pitches correspondingly tricky; an arm pull, then followed some ordinary scrambling onto a Cherubim’s head,’ she noted. Standing triumphantly at the peak, holding tightly to the golden statue of the Winged Victory, ‘I was exhilarated as only climbing can make me,’ she recalled.</p>



<p>Dorothy Pilley is one of thirteen women who feature in a new book, <em>Rebel Women Between the Wars</em> by Sarah Lonsdale (which I reviewed recently for <em><a href="https://www.historytoday.com/archive/review/manless-climbing">History Today</a></em>). As an experienced former journalist herself, Lonsdale’s focus is on how these disparate women forged their careers in the world of newspapers and magazines in the interwar years, including Shiela Grant Duff, who reported on the Nazi violence following the Saar plebiscite in 1935, and Margaret Lane, whose interview with ‘Scarface’ Al Capone made the front page of the <em>Daily Express</em> in October 1931. Most of these enterprising writers are little remembered today, including Edith Shackleton, who is usually mentioned only in passing as the bisexual ‘last mistress’ of the poet W.B. Yeats, despite being one of Fleet Street’s highest paid journalists in 1930.</p>



<p>Dorothy Pilley’s journalism was mainly a way of funding her climbing expeditions, which her well-off father refused to pay for. After the War ended, she stopped writing articles about patriotic women and took a regular job at the <em>Daily</em> and <em>Sunday Express</em>. She enjoyed ‘the rush of Fleet Street’ and working in a busy newspaper office, noting in 1920 that ‘to write in that heat – among a noisy, moving mob is the most exciting yet nerve-wracking experience’. Journalism gave her the independence she craved, yet she wanted to find a way of combining her skills as a writer with her love of mountaineering. So in March 1921 she co-founded <a href="https://pinnacleclub.co.uk/">The Pinnacle Club</a> in Snowdonia, with the aim of encouraging rock climbing and mountaineering amongst women (the club celebrates its centenary this year). Pilley took on editorship of the <em>Pinnacle Club Journal</em>, which, like <em><a href="https://www.theiet.org/publishing/library-archives/the-iet-archives/online-exhibitions/women-and-engineering/the-woman-engineer-journal/">The Woman Engineer</a></em>, launched in 1919 and published quarterly ever since, provided a public platform for women’s voices to be heard without interference from male editors. Both the club and its journal helped to normalize climbing as something all women could do, not just a few extraordinary individuals: as a lifelong feminist, Pilley wanted to use her experience and enthusiasm to encourage others.</p>



<div><figure><img loading="lazy" data-attachment-id="2355" data-permalink="https://akennedysmith.com/pinnacle-club-journal/" data-orig-file="https://akennedysmith.files.wordpress.com/2021/01/pinnacle-club-journal.jpg" data-orig-size="221,228" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pinnacle-club-journal" data-image-description="" data-medium-file="https://akennedysmith.files.wordpress.com/2021/01/pinnacle-club-journal.jpg?w=221" data-large-file="https://akennedysmith.files.wordpress.com/2021/01/pinnacle-club-journal.jpg?w=221" src="https://akennedysmith.files.wordpress.com/2021/01/pinnacle-club-journal.jpg?w=221" alt="" width="334" height="345" srcset="https://akennedysmith.files.wordpress.com/2021/01/pinnacle-club-journal.jpg 221w, https://akennedysmith.files.wordpress.com/2021/01/pinnacle-club-journal.jpg?w=145 145w" sizes="(max-width: 334px) 100vw, 334px"></figure></div>



<p>Pilley would continue to edit the <em>Pinnacle Club Journal</em> for the next twenty years. Its first issue contained an article called ‘Three Pinnaclers in the Alps’ by Lilian Bray, describing how she, Pilley and another English woman friend travelled by train to Switzerland in the summer of 1921. There, they covered their hair with cotton bandanas, exchanged their dresses for breeches and hobnail boots, and put ropes and knapsacks on their backs before scaling the Matterhorn together; it was the first Alpine <em>cordée féminine</em>, or female roped party. ‘Manless climbing’ – without male guides or companions – was seen as a dangerous practice and condemned as ‘insane’ by members of the distinguished Alpine Club. </p>



<p>Not all male climbers of the time doubted women mountaineers’ abilities, or their right to climb independently. The Cambridge scholar and literary critic Ivor Armstrong Richards (I.A. Richards, 1893-1979) and Dorothy Pilley first met clambering up Tryfan in Snowdonia in 1917. ‘You were the first original thinker I had met,’ she later told him, ‘and in your conversation I discovered even as barely more than a schoolgirl the “something more in life” which I had ever so vaguely suspected – a country of the mind.’ They soon became close friends and tackled several Alpine ascents together in the early 1920s. But in 1925 Pilley wrote a 60-page letter to him setting out all the reasons why she had to turn down his offer of marriage. She could not marry Richards because, she explained, marriage would mean ‘lots of housework and twenty children’, a prospect that made her ‘go cold and stiff with disdain’.</p>



<p>Pilley wrote her long letter from British Columbia, where she was beginning the two-year global climbing adventure that she had always dreamed of. She started by tackling the Canadian Rockies, the Selkirks and the American Rockies, her climbs funded by her journalism for various American and Canadian newspapers. Then, in August 1926, she was joined by a new climbing companion: Ivor Richards, who had travelled to America to persuade Dorothy to reconsider his offer of marriage. That month they climbed Mount Baker (2, 686 metres) from the north-east side together&nbsp; – Pilley was the first woman to do so – and after several other peaks she was convinced that marrying Richards would not hold her back, or lead to a conventional life.  They married in Honolulu on New Year’s Eve 1926 (there’s a photo of them on a climbing trip together <a href="https://www.theguardian.com/travel/2016/sep/15/dorothy-pilley-climbing-dan-richards-adventure-travel">here</a>).&nbsp;</p>



<p>Pilley was, according to her entry in the <em>Oxford Dictionary of National Biography</em>, ‘one of the most outstanding mountaineers of the interwar and post-war periods’. She became famous when in July 1928 she and Richards made the first ascent of the north ridge of the Dent Blanche in the Alps, together with Joseph and Antoine Georges, thereby solving ‘one of the last great alpine problems’ as the <em>ODNB</em> puts it. She herself wrote about the Dent Blanche ascent in the final chapter of her climbing memoir, <em>Climbing Days</em> (1935) and, thanks to Ivor Richards’ academic appointments in Bejing and Harvard, she continued scale peaks in many different locations including China, Japan, Korea and Myanmar for the next thirty years, sometimes with Richards and guides, sometimes alone.</p>



<p>Her international climbing career ended in 1958 when she broke her hip in a car accident. While she was recovering in hospital, her husband wrote a touching poem called ‘Hope’ for her, recalling the night they accidentally spent together on a dangerous mountain glacier before they married: <strong>‘”Leaping crevasses in the dark/ That’s how to live!”, you said/ No room in that to hedge./ A razor’s edge of a remark.’</strong> Ivor was right to remind Dorothy that there would be better days to come, and more adventures for her. The <em>ODNB</em> records that at the age of 91, the irrepressible Dorothy spent New Year’s Eve at the climbers’ hut at Glen Brittle, Skye, ‘drinking whisky and talking mountains’ with a party of Scottish climbers. “It is the reverberation of one’s life among them,” she once wrote, explaining her lifelong love of mountains. “Therein, reflected, is the experience of being ardently alive.’</p>



<p><strong>© Ann Kennedy Smith 30 January 2021</strong></p>



<p><strong>POSTSCRIPT: </strong>The couple returned to live in Magdalene College, Cambridge in 1973. ‘I.A. Richards, sometimes credited as the ‘founding father’ of modern literary criticism,&nbsp;began as an undergraduate at Magdalene in 1911. After 35&nbsp;years teaching at Harvard, he returned to the College and&nbsp;lived here until his death in 1979.’ <a href="https://www.magd.cam.ac.uk/about/history">Magdalene College website</a> (accessed 30 January 2021) Dorothea Pilley-Richards left over a million pounds to Magdalene College when she died in 1986. Her great-great nephew, the writer and broadcaster Dan Richards, published a book <em><a href="https://www.faber.co.uk/9780571311927-climbing-days.html">Climbing Days</a></em> (Faber &amp; Faber, 2016) about following in Pilley’s challenging footsteps. There is a fascinating 30-minute discussion about her on his recent ‘Dan Talks To Interesting People’ podcast <a href="https://www.listennotes.com/podcasts/dan-talks-to/episode-3-sarah-lonsdale-VO3LlNSx8_H/">here</a>. For her lifelong work encouraging women climbers, Dorothy Pilley is my nomination for this year’s ‘Woman In History’ campaign by the writer Kate Mosse for International Women’s Day 2021.</p>



<p><strong>SOURCES:</strong> Sarah Lonsdale, <em><a href="https://manchesteruniversitypress.co.uk/9781526137111/">Rebel Women Between the Wars</a></em> (Manchester University Press, 2020); ‘The pioneering women who took on Hitler… and Fleet Street’  <em><a href="https://www.theguardian.com/media/2020/oct/25/the-pioneering-women-who-took-on-hitler-and-fleet-street">The Guardian</a></em> 25 October 2020; ‘Recipes and resolutions’ <a href="https://www.the-tls.co.uk/articles/recipes-and-resolutions-essay-sarah-lonsdale/">Times Literary Supplement</a>, 3 July 2020; Dorothy Pilley <em>Climbing Days</em> (1935; 2nd edition 1965): ‘Richards [née Pilley, Dorothy Eleanor] 1894-1986’ Carol A. Osborne, <em>ODNB</em>, September 2004; Dan Richards, ‘ In the footholds of Dorothy Pilley: how my great-great aunt became a climbing inspiration’, <em><a href="https://www.theguardian.com/travel/2016/sep/15/dorothy-pilley-climbing-dan-richards-adventure-travel">The Guardian</a></em> 15 September 2016; ‘Dorothea Richards’ Magdalene College Libraries <a href="https://magdlibs.com/2016/07/07/dorothea-richards/">blog</a> 7 July 2016. All websites accessed 30 January 2021. </p>
					</div></div>]]>
            </description>
            <link>https://akennedysmith.com/2021/01/30/manless-climbing-dorothy-pilley-richards-1894-1986/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25981323</guid>
            <pubDate>Sun, 31 Jan 2021 18:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The true power of regular expressions]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25981212">thread link</a>) | @mfbx9da4
<br/>
January 31, 2021 | https://nikic.github.io/2012/06/15/The-true-power-of-regular-expressions.html | <a href="https://web.archive.org/web/*/https://nikic.github.io/2012/06/15/The-true-power-of-regular-expressions.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <p>As someone who frequents the <a href="https://stackoverflow.com/questions/tagged/php">PHP tag on StackOverflow</a> I pretty often see questions about how to parse some
particular aspect of HTML using regular expressions. A common reply to such a question is:</p>

<blockquote>
  <p>You cannot parse HTML with regular expressions, because HTML isn’t regular. Use an XML parser instead.</p>
</blockquote>

<p>This statement - in the context of the question - is somewhere between very misleading and outright wrong. What I’ll try
to demonstrate in this article is how powerful modern regular expressions <em>really</em> are.</p>

<h2 id="what-does-regular-actually-mean">What does “regular” actually mean?</h2>

<p>In the context of <a href="https://en.wikipedia.org/wiki/Formal_language">formal language theory</a>, something is called “regular” when it has a grammar where all production
rules have one of the following forms:</p>



<p>You can read those <code>-&gt;</code> rules as “The left hand side can be replaced with the right hand side”. So the first rule would
be “B can be replaced with a”, the second one “B can be replaced with aC” and the third one “B can be replaced with the
empty string” (<code>ε</code> is the symbol for the empty string).</p>

<p>So what are <code>B</code>, <code>C</code> and <code>a</code>? By convention, uppercase characters denote so called “non-terminals” - symbols which <em>can</em>
be broken down further - and lowercase characters denote “terminals” - symbols which <em>cannot</em> be broken down any
further.</p>

<p>All that probably sounds a bit abstract, so let’s look at an example: Defining the natural numbers as a grammar.</p>

<div><div><pre><code>N -&gt; 0
N -&gt; 1
N -&gt; 2
N -&gt; 3
N -&gt; 4
N -&gt; 5
N -&gt; 6
N -&gt; 7
N -&gt; 8
N -&gt; 9
N -&gt; 0N
N -&gt; 1N
N -&gt; 2N
N -&gt; 3N
N -&gt; 4N
N -&gt; 5N
N -&gt; 6N
N -&gt; 7N
N -&gt; 8N
N -&gt; 9N
</code></pre></div></div>

<p>What this grammar says is:</p>

<div><div><pre><code>A natural number (N) is
... one of the digits 0 to 9
or
... one of the digits 0 to 9 followed by another natural number (N)
</code></pre></div></div>

<p>In this example the digits 0 to 9 would be terminals (as they can’t be broken down any further) and <code>N</code> would be the
only non-terminal (as it can be and is broken down further).</p>

<p>If you have another look at the rules and compare them to the definition of a regular grammar from above, you’ll see
that they meet the criteria: The first ten rules are of the form <code>B -&gt; a</code> and the second ten rules follow the form
<code>B -&gt; aC</code>. Thus the grammar defining the natural numbers is <em>regular</em>.</p>

<p>Another thing you might notice is that even though the above grammar defines such a simple thing, it is already quite
bloated. Wouldn’t it be better if we could express the same concept in a more concise manner?</p>

<p>And that’s where regular expressions come in: The above grammar is equivalent to the regex <code>[0-9]+</code> (which is a hell lot
simpler). And this kind of transformation can be done with <em>any</em> regular grammar: Every regular grammar has a
corresponding regular expression which defines all its valid strings.</p>

<h2 id="what-can-regular-expressions-match">What can regular expressions match?</h2>

<p>Thus the question arises: Can regular expressions match only regular grammars, or can they also match more? The answer
to this is both yes <em>and</em> no:</p>

<p>Regular expressions in the formal grammar sense can (pretty much by definition) only parse regular grammars and nothing
more.</p>

<p>But when programmers talk about “regular expressions” they aren’t talking about formal grammars. They are talking about
the regular expression <em>derivative</em> which their language implements. And those regex implementations are only very
slightly related to the original notion of regularity.</p>

<p>Any modern regex flavor can match a <em>lot</em> more than just regular languages. How much exactly, that’s what the rest of
the article is about.</p>

<p>To keep things simple, I’ll focus on the PCRE regex implementation in the following, simply because I know it best (as
it’s used by PHP). Most other regex implementations are quite similar though, so most stuff should apply to them too.</p>

<h2 id="the-language-hierarchy">The language hierarchy</h2>

<p>In order to analyze what regular expressions can and cannot match, we first have to look at what other types of
languages there are. A good starting point for this is the <a href="https://en.wikipedia.org/wiki/Chomsky_hierarchy">Chomsky hierarchy</a>:</p>

<div><div><pre><code>Chomsky hierarchy:

/-------------------------------------------\
|                                           |
|     Recursively enumerable languages      | Type 0
|                                           |
|   /-----------------------------------\   |
|   |                                   |   |
|   |    Context-sensitive languages    |   | Type 1
|   |                                   |   |
|   |   /---------------------------\   |   |
|   |   |                           |   |   |
|   |   |  Context-free languages   |   |   | Type 2
|   |   |                           |   |   |
|   |   |   /-------------------\   |   |   |
|   |   |   | Regular languages |   |   |   | Type 3
|   |   |   \-------------------/   |   |   |
|   |   \---------------------------/   |   |
|   \-----------------------------------/   |
\-------------------------------------------/
</code></pre></div></div>

<p>As you can see the Chomsky hierarchy divides formal languages into four types:</p>

<p>Regular languages (Type 3) are the least-powerful, followed by the context-free languages (Type 2), the
context-sensitive languages (Type 1) and at last the all-mighty recursively enumerable languages (Type 0).</p>

<p>The Chomsky hierarchy is a containment hierarchy, so the smaller boxes in the above image are fully contained in the
larger boxes. For example every regular language is also a context-free language (but <em>not</em> the other way around!)</p>

<p>So, let’s move one step up in that hierarchy: We already know that regular expressions can match any regular language.
But can they also match context-free languages?</p>

<p>(Reminder: When I say “regular expression” here I obviously mean it in the programmer sense, not the formal language
theory sense.)</p>

<h2 id="matching-context-free-languages">Matching context-free languages</h2>

<p>The answer to this is <em>yes</em>, they can!</p>

<p>Let’s take the classical example of a context-free language, namely <code>{a^n b^n, n&gt;0}</code>, which means “A number of <code>a</code>
characters followed by the <em>same</em> number of <code>b</code> characters”. The (PCRE) regex for this language is:</p>



<p>The regular expression is very simple: <code>(?1)</code> is a reference to the first subpattern, namely <code>(a(?1)?b)</code>. So basically
you could replace the <code>(?1)</code> by that subpattern, thus forming a recursive dependency:</p>

<div><div><pre><code>/^(a(?1)?b)$/
/^(a(a(?1)?b)?b)$/
/^(a(a(a(?1)?b)?b)?b)$/
/^(a(a(a(a(?1)?b)?b)?b)?b)$/
# and so on
</code></pre></div></div>

<p>From the above expansions it should be clear that this expression can match any string with the same number of <code>a</code>s and
<code>b</code>s.</p>

<p>Thus regular expressions can match at least some non-regular, context-free grammars. But can they match all? To answer
that, we first have to look at how context-free grammars are defined.</p>

<p>In a context-free grammar all production rules take the following form:</p>



<p>Here <code>A</code> once again is a non-terminal symbol and <code>β</code> is an arbitrary string of terminals and non-terminals. Thus every
production rule of a context-free grammar has a non-terminal on the left hand side and an arbitrary symbol string on
the right hand side.</p>

<p>As an example, have a look at the following grammar:</p>

<div><div><pre><code>function_declaration -&gt; T_FUNCTION is_ref T_STRING '(' parameter_list ')' '{' inner_statement_list '}'

is_ref -&gt; '&amp;'
is_ref -&gt; ε

parameter_list -&gt; non_empty_parameter_list
parameter_list -&gt; ε

non_empty_parameter_list -&gt; parameter
non_empty_parameter_list -&gt; non_empty_parameter_list ',' parameter

// ... ... ...
</code></pre></div></div>

<p>What you see there is an excerpt from the PHP grammar (just a few sample rules). The syntax is slightly different from
what we used before, but should be easy to understand. One aspect worth mentioning is that the uppercase <code>T_SOMETHING</code>
names here also are terminal symbols. These symbols which are usually called <em>tokens</em> encode more abstract concepts.
E.g. <code>T_FUNCTION</code> represents the <code>function</code> keyword and <code>T_STRING</code> is a label token (like <code>getUserById</code> or
<code>some_other_name</code>).</p>

<p>I’m using this example to show one thing: Context-free grammars are already powerful enough to encode quite complex
languages. That’s why pretty much all programming languages have a context-free grammar. In particular this also
includes well-formed HTML.</p>

<p>Now, back to the actual question: Can regular expressions match all context-free grammars? Once again, the answer is
<em>yes</em>!</p>

<p>This is pretty easy to prove as regular expressions (at least PCRE and similar) provide a syntax very similar to the
above for constructing grammars:</p>

<div><div><pre><code>/
    (?(DEFINE)
        (?&lt;addr_spec&gt; (?&amp;local_part) @ (?&amp;domain) )
        (?&lt;local_part&gt; (?&amp;dot_atom) | (?&amp;quoted_string) | (?&amp;obs_local_part) )
        (?&lt;domain&gt; (?&amp;dot_atom) | (?&amp;domain_literal) | (?&amp;obs_domain) )
        (?&lt;domain_literal&gt; (?&amp;CFWS)? \[ (?: (?&amp;FWS)? (?&amp;dtext) )* (?&amp;FWS)? \] (?&amp;CFWS)? )
        (?&lt;dtext&gt; [\x21-\x5a] | [\x5e-\x7e] | (?&amp;obs_dtext) )
        (?&lt;quoted_pair&gt; \\ (?: (?&amp;VCHAR) | (?&amp;WSP) ) | (?&amp;obs_qp) )
        (?&lt;dot_atom&gt; (?&amp;CFWS)? (?&amp;dot_atom_text) (?&amp;CFWS)? )
        (?&lt;dot_atom_text&gt; (?&amp;atext) (?: \. (?&amp;atext) )* )
        (?&lt;atext&gt; [a-zA-Z0-9!#$%&amp;'*+/=?^_`{|}~-]+ )
        (?&lt;atom&gt; (?&amp;CFWS)? (?&amp;atext) (?&amp;CFWS)? )
        (?&lt;word&gt; (?&amp;atom) | (?&amp;quoted_string) )
        (?&lt;quoted_string&gt; (?&amp;CFWS)? " (?: (?&amp;FWS)? (?&amp;qcontent) )* (?&amp;FWS)? " (?&amp;CFWS)? )
        (?&lt;qcontent&gt; (?&amp;qtext) | (?&amp;quoted_pair) )
        (?&lt;qtext&gt; \x21 | [\x23-\x5b] | [\x5d-\x7e] | (?&amp;obs_qtext) )

        # comments and whitespace
        (?&lt;FWS&gt; (?: (?&amp;WSP)* \r\n )? (?&amp;WSP)+ | (?&amp;obs_FWS) )
        (?&lt;CFWS&gt; (?: (?&amp;FWS)? (?&amp;comment) )+ (?&amp;FWS)? | (?&amp;FWS) )
        (?&lt;comment&gt; \( (?: (?&amp;FWS)? (?&amp;ccontent) )* (?&amp;FWS)? \) )
        (?&lt;ccontent&gt; (?&amp;ctext) | (?&amp;quoted_pair) | (?&amp;comment) )
        (?&lt;ctext&gt; [\x21-\x27] | [\x2a-\x5b] | [\x5d-\x7e] | (?&amp;obs_ctext) )

        # obsolete tokens
        (?&lt;obs_domain&gt; (?&amp;atom) (?: \. (?&amp;atom) )* )
        (?&lt;obs_local_part&gt; (?&amp;word) (?: \. (?&amp;word) )* )
        (?&lt;obs_dtext&gt; (?&amp;obs_NO_WS_CTL) | (?&amp;quoted_pair) )
        (?&lt;obs_qp&gt; \\ (?: \x00 | (?&amp;obs_NO_WS_CTL) | \n | \r ) )
        (?&lt;obs_FWS&gt; (?&amp;WSP)+ (?: \r\n (?&amp;WSP)+ )* )
        (?&lt;obs_ctext&gt; (?&amp;obs_NO_WS_CTL) )
        (?&lt;obs_qtext&gt; (?&amp;obs_NO_WS_CTL) )
        (?&lt;obs_NO_WS_CTL&gt; [\x01-\x08] | \x0b | \x0c | [\x0e-\x1f] | \x7f )

        # character class definitions
        (?&lt;VCHAR&gt; [\x21-\x7E] )
        (?&lt;WSP&gt; [ \t] )
   …</code></pre></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nikic.github.io/2012/06/15/The-true-power-of-regular-expressions.html">https://nikic.github.io/2012/06/15/The-true-power-of-regular-expressions.html</a></em></p>]]>
            </description>
            <link>https://nikic.github.io/2012/06/15/The-true-power-of-regular-expressions.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25981212</guid>
            <pubDate>Sun, 31 Jan 2021 18:31:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time tracking with plain text files]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25981157">thread link</a>) | @dpree
<br/>
January 31, 2021 | https://www.jotaen.net/9zRPA/klog-time-tracking-plain-textfiles/ | <a href="https://web.archive.org/web/*/https://www.jotaen.net/9zRPA/klog-time-tracking-plain-textfiles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <main>
      

      <p>One topic that kept me thinking on and off for a couple of years now is time tracking. That is for very practical reasons, as I was (and still am) interested to keep track of my working hours. Back in the day, when I used to work full-time, I wanted to know how well on track I was with the 40&nbsp;hours that I agreed to devote to my employer. Nowadays, as a freelancer, I need to log my working hours for bookkeeping reasons, as my invoices are based on an hourly rate.</p>

<p>There exist countless web services for time tracking, some of which offering an impressive feature set that cater for all imaginable use-cases. However, I never felt too much appeal to use them. It’s not that I have any special requirements or practice an extravagant workflow. My reluctance is instead stemming from a conceptual thought: keeping track of times is a rather mundane and simple thing to do, so why rely on (semi-) commercial online services that build on complex technology stacks for something that you can basically do with a pencil and a piece of paper?</p>

<p>What did the trick somewhat well for me throughout the years was a spreadsheet that I setup and maintained by hand. It allowed me to enter data quickly and I could also run some simple evaluations, e.g. in order to aggregate the entries by week or month. While this solution was both simple and flexible, it also felt a bit cumbersome, especially for things like writing more sophisticated formulas or configuring pivot tables. As luck would have it I am in the fortunate position of being able to build my own tools. But before we get to this I need to share another thing with you first.</p>

<p>The longer I have been working with computers the more I appreciate the freedom and simplicity of plain text files: not being bound to proprietary software for opening or editing them; not being exposed to the risk that your data gets sold to advertising companies; no lock-in on arbitrary subscription plans; no connectivity issues that would prevent or slow down access. Instead, the data is just there, it’s all yours and you can rest assured that you will be able to work with it for decades to come. Viewing or manipulating the files can be done with any off-the-shelf text editor, and syncing them across multiple devices is as easy as putting them into your Dropbox folder. While plain-text formats don’t work for each and every application obviously, they seem to be a more than reasonable choice for this task here.</p>

<p>Born out of this conception I experimented with different formats to record time tracking data using plain text files. Over the past weeks I tried out various structures to model and layout the information. What I came up with is a lightweight format with minimal syntax that I called “klog”. The idea is to record the data in a similar style as you would using a physical notebook: it’s basically the date, then time-related entries such as a time range or duration of how long something took, and maybe a short note about what you did.</p>

<p><img src="https://www.jotaen.net/posts/2021-01-31-klog/demo.gif" alt="A terminal window demonstrating the file format and the command line tool usage"></p>

<p>I implemented a parser for the klog file format along with a small command line tool that allows to evaluate the data programatically. You find the project <a href="https://github.com/jotaen/klog">on Github</a>, where you can also download the binary in order to experiment with klog. If you happen to be interested in this idea I’d appreciate some feedback and learn about your use-cases – drop me an <a href="https://www.jotaen.net/mail">email</a> or open an issue on Github. klog obviously fits <em>my</em> needs, but I aimed for making it general-purpose enough so that other people may find it useful too.</p>

<p>Building klog was not just a fun programming exercise, I also ran into some interesting questions along the way: is it necessary to support timezones? Is it okay to restrict time values to hours and minutes, but to omit the seconds part for convenience? What if someone starts an activity close to midnight and finishes it on the next day, like working a night shift? Which of the numerous date and time notations need to be understood? How can you start tracking something that’s not yet finished and therefore doesn’t have an end time? I wrote a brief guide (that you find in the repository) that gives a tour of klog and also covers these questions.</p>

<p>The command line tool is fairly minimalistic for now, as I first and foremostly want to validate that my basic idea sustains before investing more work into it. The cli tool has read-only functionality so far and can basically pretty-print, filter and evaluate files. I attributed special attention to error handling, so in case there are formatting errors you should see precise and (hopefully) helpful error messages. The application is written in Go, which ensures that it runs cross-platform without relying on runtime dependencies, and – as a bonus – it’s also quite fast even on large data sets.</p>

<p>And as for the name, “klog” is what we call a “Kofferwort” in German: since my original use-case was tracking work times it is a blend of the two terms “work” and “log”.</p>

    </main>
  </div></div>]]>
            </description>
            <link>https://www.jotaen.net/9zRPA/klog-time-tracking-plain-textfiles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25981157</guid>
            <pubDate>Sun, 31 Jan 2021 18:26:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The antidote to fake news is to nourish our epistemic wellbeing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25980945">thread link</a>) | @haltingproblem
<br/>
January 31, 2021 | https://psyche.co/ideas/the-antidote-to-fake-news-is-to-nourish-our-epistemic-wellbeing | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/the-antidote-to-fake-news-is-to-nourish-our-epistemic-wellbeing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>We typically think about</strong> â€˜wellbeingâ€™ in terms of physical and mental health. To improve your physical wellbeing, it might be best to exercise; to increase your mental wellbeing, consider putting your phone down once in a while. There is another, less noted way in which we should think about our wellbeing: in terms of knowledge. Knowledge is <em>good</em> for us not only because we generally want to know the truth, but because knowledge dramatically affects our ability to navigate the world and accomplish our goals. Ignorance, on the other hand, is <em>bad</em> for us in that it prevents us from having an accurate representation of the world and stands in the way of our achieving those goals. Just as there are factors that affect our physical and mental wellbeing, there are factors that affect our <em>epistemic wellbeing</em>. Itâ€™s not exactly a new notion, but it can help us make better sense of what has been called our current â€˜epistemic crisisâ€™.</p>
<p>Youâ€™ve no doubt been exposed to this crisis in a number of ways: much has been written about our â€˜post-truthâ€™ era of media production and consumption, conspiracy theories are rampant, and a lot of nonsense is passed around on Facebook. Consuming media these days is exhausting and frustrating, having discussions with those you disagree with is more difficult than ever, and it can often seem hard to identify sources of information that can be trusted. While much has been said about why all of this is bad, here I want to focus on how it is specifically bad <em>for us</em>.</p>
<p>Epistemic wellbeing is your reasonably based sense that youâ€™ll be able to know what you want and need to know about the world in order for your life to go well. This could involve knowledge in general â€“ you want to feel like you can find answers to questions that you think are important to satiate your curiosity â€“ as well as knowing more specific things â€“ there will be some things you need to know in order to accomplish your lifeâ€™s projects. If you have access to lots of good sources of information and can get your questions answered when you need them, then you have a high degree of epistemic wellbeing. If, on the other hand, youâ€™re surrounded by liars, or just have no way of finding out what you need to know, youâ€™re not doing nearly as well.</p>
<p>There are three components of epistemic wellbeing: access to truths; access to trustworthy sources of information; and opportunities to participate in productive dialogue. Letâ€™s think about these each in turn.</p>
<p>When youâ€™re presented with information or looking for answers to questions, you want to be confident that what youâ€™re getting is the truth. Access to truth, the first component, is the basis of epistemic wellbeing. Access might be thwarted in many ways: you might be unable to go online, books might be banned, important information could be redacted. Or, in less extreme cases, you might be presented with different media outlets presenting conflicting information about an event. In this case, you might feel that youâ€™re being prevented from accessing truths insofar as youâ€™re unable to determine which information being presented is correct.</p>
<p>If youâ€™ve ever been dismissed in conversation because of your race, gender, sex, then youâ€™ve experienced epistemic injustice</p>
<p>The internet contains, for better or worse, a significant amount of humanityâ€™s intellectual and creative outputs. Itâ€™s also a cesspool of outrageous falsehoods. Having access to so much information, then, is useful only if youâ€™re able to separate the wheat from the chaff. For instance, the amount of information related to <span>COVID-19</span> has been <a href="https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(20)30461-X/fulltext" rel="nofollow noreferrer noopener">called</a> an â€˜infodemicâ€™ by the World Health Organization: there is so much information that itâ€™s impossible to keep up with all of it, and often difficult to determine what to believe. In order to make sure that weâ€™re getting at the truth, then, we need to figure out which sources of information are good ones.</p>
<p>Here we have the second component of epistemic wellbeing, which is largely in service of the first: access to trustworthy sources of information. While weâ€™re all interested in obtaining truths, weâ€™re unable to acquire all of these truths on our own, and so weâ€™re reliant on others. This is a good thing. Dividing the cognitive labour among many people means that we donâ€™t have to be experts in everything in order to know much about the world. We can just rely on others to figure out things for us. Feeling as though we can find these trustworthy sources is crucial in being able to know what we need to know, and is thus an important component of our epistemic wellbeing.</p>
<p>Finally, while we rely on others for information, itâ€™s not enough to passively receive information. We need to engage in discussion. Often the things we want to know about are complex and difficult, and figuring out these things requires more than just one-off answers to a question, and discussions with others can introduce us to new questions and interests. We also like to share what we know: if I know something that could be useful to others, then I want to be able to contribute. Here, then, is the third component of epistemic wellbeing: the feeling that you can participate in productive dialogue.</p>
<p>Lack of opportunity to participate in productive dialogue can be detrimental to your wellbeing. There are many ways in which you can be excluded explicitly or implicitly on the basis of facts about your identity, a phenomenon philosophers <a href="https://global.oup.com/academic/product/epistemic-injustice-9780199570522?cc=dk&amp;lang=en&amp;" rel="nofollow noreferrer noopener">call</a> epistemic injustice. If youâ€™ve ever been denied the chance to have your input heard when you could have made an important contribution, or were assumed to be incapable when you werenâ€™t, or otherwise dismissed in conversation because of your race, gender, sex, etc, then youâ€™ve experienced epistemic injustice. These are all examples, then, of one way in which your epistemic wellbeing might be adversely affected. The notion Iâ€™m working with here, however, doesnâ€™t necessarily depend on exclusions on these kinds of bases, and instead concerns any kind of sense of lacking opportunities to engage in productive dialogue (it remains the case, of course, that members of marginalised and minority groups will tend to experience these kinds of detriments most often).</p>
<p><strong>Already, we can see</strong> how the current epistemic crisis might affect our epistemic wellbeing: the actual and perceived amount of false and misleading information that weâ€™re exposed to by traditional and social media could make us feel as though we donâ€™t have good access to truths. With so much competing information, and what looks to be people presenting information in bad faith, it might be difficult to identify trustworthy sources, and the experience of people being unwilling to engage in productive dialogue can make it seem that weâ€™re significantly diminished in our ability to acquire and share information. No wonder things feel so difficult.</p>
<p>If we canâ€™t get the epistemological crisis under control, the marketplace of ideas will cease to function, and so too will a well-functioning democracy</p>
<p>Thinking about our epistemic wellbeing can also help to explain why it is that the epistemic crisis isnâ€™t getting any better. If people are, as I have suggested, driven by a pursuit of truth, trust and dialogue, then, when they feel theyâ€™re thwarted in these efforts, theyâ€™re going to pursue them by other means. One of the most lamentable aspects of our current epistemic situation is the rise of conspiratorial thinking: people are willing both to believe a whole host of outlandish theories, and to share them widely on social media. This might come about partly as a response to a decreased sense of epistemic wellbeing, with the result that we look to potentially surprising places to try to find truths, trustworthy sources and opportunities for dialogue. While itâ€™s in an important sense irrational to <em>believe</em> in many conspiracy theories, the <em>motivation</em> behind doing so is not necessarily irrational.</p>
<p>Similar things can be said about another disturbing trend: the increasing distrust in experts. Consider the responses to the <span>COVID-19</span> pandemic. Failures to believe in its severity, the effectiveness of preventative measures (such as social distancing and wearing masks) and scepticism towards the development of a vaccine have come about in part because of a feeling that those who are deemed experts canâ€™t be trusted. This isnâ€™t to say that people who donâ€™t trust experts donâ€™t care about finding trustworthy sources of information. Instead, trust is sought elsewhere â€“ and often not in the best places, such as confident but ignorant Facebook friends. A decreased sense of epistemic wellbeing might be both a cause and a consequence of an epistemic crisis: if you feel unable to engage in dialogue, youâ€™ll find alternative opportunities to do so, resulting in more extreme views, which in turn make it more difficult to engage in dialogue â€“ a vicious cycle, harmful to epistemic wellbeing.</p>
<p>In a recent interview in <em>The Atlantic</em> magazine, Barack Obama warned of potentially dire consequences if we couldnâ€™t get the epistemological crisis under control. The marketplace of ideas will cease to function, and so too will a well-functioning democracy. Part of the problem in addressing the epistemic crisis, I propose, will involve trying to balance various aspects of peopleâ€™s epistemic wellbeing in the right way. Itâ€™s not clear what the best way of doing this is. Many social media outlets have taken measures to try to stem the tide of misinformation on their platforms, be it through fact-checking or banning users. These actions can help with the epistemic wellbeing of a platformâ€™s users by trying to ensure that said users have access to truths. At the same time, they could be interpreted by some to be affecting their ability to engage in dialogue. As a result, users who are fact-checked or banned will look elsewhere to have their epistemic needs met. This isnâ€™t to say that …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/the-antidote-to-fake-news-is-to-nourish-our-epistemic-wellbeing">https://psyche.co/ideas/the-antidote-to-fake-news-is-to-nourish-our-epistemic-wellbeing</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/the-antidote-to-fake-news-is-to-nourish-our-epistemic-wellbeing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25980945</guid>
            <pubDate>Sun, 31 Jan 2021 18:06:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Edamagit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25980913">thread link</a>) | @kahole
<br/>
January 31, 2021 | https://hole.dev/articles/edamagit-introduction/ | <a href="https://web.archive.org/web/*/https://hole.dev/articles/edamagit-introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<h2 id="introduction-to-edamagit">edamagit introduction</h2>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#status-view">Status View</a></li>
<li><a href="#navigating-the-menus">Navigating the menus</a></li>
<li><a href="#committing">Committing</a></li>
<li><a href="#switches">Switches</a></li>
<li><a href="#tips-tricks">Tips &amp; Tricks</a></li>
<li><a href="#learn-more">Learn more</a></li>
</ul>
</nav>
<hr>
<h3 id="title"><a id="title" href="https://marketplace.visualstudio.com/items?itemName=kahole.magit">edamagit</a></h3> is a keyboard-driven git interface for VSCode. It's made in the style of the emacs extension, 'magit'.
<p>Git commands are mapped to keypresses for efficient use. E.g. pressing <code>b c</code> will allow you to checkout a new branch.</p>
<p>Install it in VSCode by searching for <code>edamagit</code> in the extension manager.</p>
<p>Or get it here on one of these marketplaces - <a href="https://marketplace.visualstudio.com/items?itemName=kahole.magit">VSCode Marketplace</a> - <a href="https://open-vsx.org/extension/kahole/magit">OpenVSX</a></p>
<h3 id="status-view">Status View</h3>
<p>Bring up the status view by pressing <kbd>Alt+x g</kbd> <em>(<kbd>Alt</kbd> and <kbd>x</kbd> together, then <kbd>g</kbd> by itself)</em>. Or by running the command <code>'Magit Status'</code> in the vscode <a href="https://code.visualstudio.com/docs/getstarted/userinterface#_command-palette">command palette</a>.</p>
<p>Once in the status view, press <kbd>Tab</kbd> to fold and unfold sections, files, and change hunks.</p>
<p>Place the cursor on a section</p>
<img src="https://hole.dev/images/edamagit_introduction/tab_closed.jpg">
<p>press <kbd>Tab</kbd> to unfold/fold:</p>
<img src="https://hole.dev/images/edamagit_introduction/tab_open.jpg">
<h4 id="staging">Staging</h4>
<p>Pressing <kbd>s</kbd> and <kbd>u</kbd> allows you to stage and unstage changes under the cursor. Either a file, change hunk, or a just a selected part of a hunk.</p>
<p>From</p>
<img src="https://hole.dev/images/edamagit_introduction/unstaged_file.jpg">
<p>pressing <kbd>s</kbd> will stage the file:</p>
<img src="https://hole.dev/images/edamagit_introduction/staged_file.jpg">
<h4 id="other-status-view-actions">Other status view actions</h4>
<ul>
<li><kbd>a</kbd> to apply the entity under the cursor. E.g. apply a stash</li>
<li><kbd>k</kbd> to delete changes/file/stash under cursor.</li>
<li><kbd>Enter</kbd> to open up the entity under cursor. (E.g. show commit details or open a file)</li>
</ul>

<p>From the status view press <kbd>?</kbd> to bring up the help view.</p>
<p>This shows you the available edamagit menus and which key to press to invoke them. For example, pressing <kbd>b</kbd> brings up the <code>Branching</code>-menu.</p>
<img src="https://hole.dev/images/edamagit_introduction/help_view.jpg">
<p>This menu-system is based on a modified version of VSCode’s QuickPick selection menu.</p>
<p>Similarly to the help view, the entries in this menu show a key and which action it activates. (e.g.&nbsp;<code>c Checkout new branch</code>)</p>
<p>From here, a single press of <kbd>c</kbd> invokes the action <code>Checkout new branch</code>.</p>
<img src="https://hole.dev/images/edamagit_introduction/branching_menu_1.jpg">
<p>Choose a branch to base the new branch on. Search and/or select with arrow keys. Confirm choice with <kbd>Enter</kbd>.</p>
<img src="https://hole.dev/images/edamagit_introduction/branching_menu_2.jpg">
<p>Give the new branch a name and press <kbd>Enter</kbd></p>
<p><img src="https://hole.dev/images/edamagit_introduction/branching_menu_3.jpg"></p>
<h3 id="committing">Committing</h3>
<p>Now you have staged some changes and want to commit. Press <kbd>c</kbd> to bring up committing menu, and <kbd>c</kbd> once again to start a normal commit.</p>
<p>This brings up the commit view where you will write a commit message. Next to an editor showing which changes you are committing is shown.</p>
<img src="https://hole.dev/images/edamagit_introduction/committing.jpg">
<p>Once you have written a commit-message press <kbd>ctrl+c ctrl+c</kbd> to finish the commit. Or manually save and close the commit-message editor, this has the same effect.</p>
<p><kbd>ctrl+c ctrl+k</kbd> will abort the commit. (Saving and closing with the message empty is the same.)</p>
<h3 id="switches">Switches</h3>
<p>Some git commands are frequently used with switches or flags to enable some behaviors. E.g. <code>push --force</code></p>
<p>Many of the edamagit command menus have a switches menu which can be activated by pressing <kbd>-</kbd>.</p>
<img src="https://hole.dev/images/edamagit_introduction/switches_1.jpg">
<p>Toggle a switch by pressing its letter. E.g. <kbd>F</kbd> (uppercase) for <code>--force</code>.</p>
<img src="https://hole.dev/images/edamagit_introduction/switches_2.jpg">
<p>Press <kbd>Enter</kbd> to confirm the switch selection.</p>
<img src="https://hole.dev/images/edamagit_introduction/switches_3.jpg">
<p>Now you’ll see the active switches listed in the ‘Switches’ menu entry.</p>
<img src="https://hole.dev/images/edamagit_introduction/switches_4.jpg">
<h3 id="tips-tricks">Tips &amp; Tricks</h3>
<ul>
<li>Using the vscode command palette and typing <code>Magit</code> will show you all available magit actions from where you currently are.</li>
<li>Pressing <kbd>$</kbd> brings up the git process log where you can see the git commands that have been run, and their output/errors/etc.</li>
<li>Enable Forge features in settings <code>Magit: Forge Enabled</code> to interact with Issues and PRs from github.</li>
<li>Be aware that edamagit sometimes uses the vscode bottom status bar to hint at possible actions or display messages. (e.g.&nbsp;when committing it shows the keyboard shortcuts)</li>
</ul>
<h3 id="learn-more">Learn more</h3>
<ul>
<li><a href="https://www.youtube.com/watch?v=kDISNtPYhjk">Youtube Tutorial - Jack Franklin</a></li>
<li><a href="https://magit.vc/manual/magit.html">Emacs Magit User Manual</a></li>
</ul>

<p>Updated 2021/01/29</p>


</div>]]>
            </description>
            <link>https://hole.dev/articles/edamagit-introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25980913</guid>
            <pubDate>Sun, 31 Jan 2021 18:03:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practical and Ruthless Prioritization Rules for PMs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25980908">thread link</a>) | @designium
<br/>
January 31, 2021 | https://chimkan.com/practical-and-ruthless-prioritization-rules/ | <a href="https://web.archive.org/web/*/https://chimkan.com/practical-and-ruthless-prioritization-rules/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
		<div>
		<p>One of the biggest challenges for Product Managers is to prioritize features or bugs. Choosing what goes first can have a significant impact on all businesses. Unfortunately, there are very few opportunities where you will be able to satisfy all your stakeholders. But you can apply a few rules that can help you in most scenarios you will face as a PM.</p><p>The first rule is that if you don't have the necessary information such as What, Who, How, How much, and Why, you will need to complete your scope work. A bug that you don't know who is being impacted or a new feature that you don't know the reasons to have is not worthy of pursuing. You will not be able to communicate why they should be prioritized or backlogged.</p><p>It sounds obvious when you are developing a new product - it does not matter if it is for a startup or an existing company. Always give more priority to features that can bring you short-term and immediate value to your users and company over the longer-term benefits. For example, if you cannot launch something to monetize and your startup is cash strapped, you won't have tomorrow to build the perfect solution. The same applies to larger organizations. If you don't show results early, executives may lose patience or faith in the project.</p><p>B2C and B2B business requirements are fundamentally different. B2C customers can quit your product at any time. B2B clients are bound to contracts with a longer timeline, and they may have costs to leave your product. I'm not advocating to provide a sub-par service to B2B customers, but that influences prioritization rules.</p><p>Finally, this is just a practical and short version of prioritization rules. Some situations are not as straightforward, and you may have to evaluate the prioritization from other metrics, but the following diagram can help you in most cases.</p><figure><img src="https://chimkan.com/content/images/2021/01/Practical-Prioritization-20210131.png" alt="" srcset="https://chimkan.com/content/images/size/w600/2021/01/Practical-Prioritization-20210131.png 600w, https://chimkan.com/content/images/size/w1000/2021/01/Practical-Prioritization-20210131.png 1000w, https://chimkan.com/content/images/2021/01/Practical-Prioritization-20210131.png 1265w" sizes="(min-width: 720px) 720px"></figure>
			</div>
</article></div>]]>
            </description>
            <link>https://chimkan.com/practical-and-ruthless-prioritization-rules/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25980908</guid>
            <pubDate>Sun, 31 Jan 2021 18:02:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: YaHNd – HN Books: The Best Books of Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25980892">thread link</a>) | @yaj54
<br/>
January 31, 2021 | https://yahnd.com/books/ | <a href="https://web.archive.org/web/*/https://yahnd.com/books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://yahnd.com/books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25980892</guid>
            <pubDate>Sun, 31 Jan 2021 18:01:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Play bans open source Matrix client Element, citing “abusive content”]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25980728">thread link</a>) | @guybedo
<br/>
January 31, 2021 | Https://arstechnica.com/gadgets/2021/01/google-play-bans-open-source-matrix-client-element-citing-abusive-content/ | <a href="https://web.archive.org/web/*/Https://arstechnica.com/gadgets/2021/01/google-play-bans-open-source-matrix-client-element-citing-abusive-content/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h4>
      We need a "Section 230" for the Play Store    —
</h4>
            
            <h2 itemprop="description">Banning a Matrix client for content is really no different from banning a Web browser. </h2>
            <section>

  



  
</section>        </div><section>
            <div itemprop="articleBody">
                                    
<figure><img src="https://cdn.arstechnica.net/wp-content/uploads/2021/01/15-1-800x450.jpg" alt="Google Play bans open source Matrix client Element, citing â€œabusive contentâ€� [Updated]"><figcaption></figcaption></figure><!-- cache hit 177:single/related:f5ad687345fb5db54153ecf87a4c7210 --><!-- empty --><p>The latest app to catch an illogical ban from the Google Play Store <a href="https://element.io/blog/element-on-google-play-store/">is Element</a>, an open source, end-to-end encrypted messaging client for the federated Matrix chat protocol. Google banned Element late Friday night, a ban thatÂ&nbsp;<a href="https://twitter.com/element_hq/status/1355465650114846720">Element said</a> "is due to abusive content somewhere on Matrix." Matrix has millions of users, and as a federated chat protocol, Element does not control the content on Matrix, so this is a bit like banning a Web browser for displaying Web content. Element says it is working with Google to "explain how Element works and get the situation resolved."</p>
<p>Google has <a href="https://arstechnica.com/tech-policy/2021/01/google-bans-parler-from-android-app-store/">been cracking down</a> on apps that display hateful content, but Element says that it shouldn't be part of the crackdown. "We have also explained that the Matrix servers that we <em>do</em> run as Element (including the default Matrix.org homeserver, which we run on behalf of <a href="https://matrix.org/foundation">The Matrix.org Foundation</a>) have <a href="https://matrix.org/legal/terms-and-conditions#6-play-nice-clauses">strict Terms of Use</a> which we actively enforce," Element said. "We abhor abuse, and Element is not an app that caters to abusive content."</p>
<p>Element says it has a full-time team dedicated to handling abuse reports.</p>
<p>Element (which was formerly called Riot.im) is <a href="https://matrix.org/docs/projects/try-matrix-now">often cited</a> as one of the best Matrix clients. It looks a lot likeâ€”and is actually <a href="https://element.io/blog/slack-bridging/">interoperable with</a>â€”Slack and Discord. Element says it is used by "the French, German, UK and US governments, countless universities, thousands of businesses and millions of people across the world." The app has recently seen <a href="https://sifted.eu/articles/element-whatsapp-exodus/">an influx of new users</a> after WhatsApp's announcement about <a href="https://arstechnica.com/tech-policy/2021/01/whatsapp-users-must-share-their-data-with-facebook-or-stop-using-the-app/">Facebook data sharing</a>, so maybe that triggered deeper scrutiny from Google. At press time, <a href="https://play.google.com/store/search?q=matrix%20chat&amp;c=apps">many other Matrix apps</a>â€”which by definition show the same content as Elementâ€”are still active on the Play Store.</p>                                            
                                                        
<p>Google takes a 30 percent cut of all Play Store transactions, which is supposed to pay for the cost of running the Store, but the company doesn't hire humans to primarily review apps the way Apple does, choosing instead to let the bots handle it. Apple <a href="https://arstechnica.com/gadgets/2020/11/apple-lowers-its-cut-of-app-store-revenues-for-some-developers/">recently cut</a> its App Store tax from 30 percent to 15 percent, so Apple actually charges developers less than Google while also offering better human support.
</p><p>Element's <a href="https://twitter.com/element_hq/status/1355595359582638080">latest update</a> on the situation as of this writing said it has been waiting more than eight hours for an email response. Element says it was not notified of the takedown, which has now passed the 24-hour mark.</p>
<p>The bots' interpretation of Google's rules often make no sense, and as a result Google regularly bans random small apps from the Play Store because they can display content from the Internet. We've seen <a href="https://www.reddit.com/r/androiddev/comments/96kpsf/more_issues_with_google_play_suspended_for_hate/">Reddit apps,</a> <a href="https://www.androidpolice.com/2020/05/19/podcast-addict-pulled-play-store-allegedly-violating-coronavirus-policy/">podcast apps</a>, and other apps that display third-party Web content all "win" the Google Play ban-of-the-week lottery, just because they can be made to display third-party content. The same is true of Google Search, Chrome, Gmail, all of Google's chat apps, YouTube, Google Drive, and Google Podcasts, but those apps never get banned. Earlier this week Google <a href="https://arstechnica.com/gadgets/2021/01/googles-bots-decide-ass-subtitle-support-is-too-risque-for-the-play-store/">banned a video app</a> because it listed support for the standard ".ass" subtitle filetype in its description.</p>
<p>The one benefit of the Play Store is that you don't have to use it, since Android supports sideloading. Element is also up <a href="https://f-droid.org/en/packages/im.vector.app/">on F-Droid</a>, an all-open source repository of Android apps, though the version offered there is a month out of date. A more up-to-date version is on <a href="https://www.apkmirror.com/apk/vector-creations-limited/riot-im-communicate-your-way/riot-im-communicate-your-way-1-0-14-release/">APKmirror</a>, the Android hacking community's biggest app store.</p>
<p>These bans are almost always temporary mistakes that are rectified after a few hours or days, but that gives little solace to app developers who can suddenly have their businesses ripped out from under them because of an enforcement mistake. Element says, "we can only apologize for the disruption caused by the app disappearing like this."</p>
<p><strong>Update:</strong> Element got in touch with a person at Google and says the app should be back up soon.</p>
<blockquote>
<p dir="ltr" lang="en">Update: we just got a call from a Google VP who explained the suspension was triggered by a report of extremely abusive content accessible on the <a href="https://t.co/g01j4u6O2e">https://t.co/g01j4u6O2e</a> server. Our trust &amp; safety team had already acted on it, and the app should be reinstated shortly.</p>
<p>â€” Element (@element_hq) <a href="https://twitter.com/element_hq/status/1355663753380032512?ref_src=twsrc%5Etfw">January 30, 2021</a></p></blockquote>

                                                </div>

            
            
        </section></div>]]>
            </description>
            <link>Https://arstechnica.com/gadgets/2021/01/google-play-bans-open-source-matrix-client-element-citing-abusive-content/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25980728</guid>
            <pubDate>Sun, 31 Jan 2021 17:45:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CrayZee Eighty: a Z80 RC2014 backplane shaped like a Cray 1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25980701">thread link</a>) | @fanf2
<br/>
January 31, 2021 | https://rc2014.co.uk/1865/crayzee-eighty/ | <a href="https://web.archive.org/web/*/https://rc2014.co.uk/1865/crayzee-eighty/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty00.jpg" alt="" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty00.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty00-300x225.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"></figure>



<p>Ever wished that you had a <a href="https://en.wikipedia.org/wiki/Cray-1">Cray 1</a> Supercomputer? Ever wondered if an RC2014 backplane could wrap around a cylinder? Ever thought about how many retweets a Z80 drawing a Mandelbrot fractal could get? Ever had an idea that’s so daft, the only way to exorcise it is to do it? If so, would you like to Seymore…</p>



<div><figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty01-1.jpg" alt="" width="341" height="341" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty01-1.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty01-1-300x300.jpg 300w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty01-1-150x150.jpg 150w" sizes="(max-width: 341px) 100vw, 341px"></figure></div>



<p>Like most ideas in Lockdown, things started with a throwaway comment on Twitter and quickly escalated to laser cutting a toilet roll. I blame <a href="https://twitter.com/shieladixon/status/1262781895038902272">Shirley Knott</a></p>



<figure><ul><li><figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty3-2.jpg" alt="" data-id="1887" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty3-2.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty3-2-300x300.jpg 300w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty3-2-150x150.jpg 150w" sizes="(max-width: 600px) 100vw, 600px"></figure></li><li><figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty02-2.jpg" alt="" data-id="1888" data-link="https://rc2014.co.uk/?attachment_id=1888" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty02-2.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty02-2-300x300.jpg 300w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty02-2-150x150.jpg 150w" sizes="(max-width: 600px) 100vw, 600px"></figure></li><li><figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty04-1.jpg" alt="" data-id="1889" data-full-url="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty04-1.jpg" data-link="https://rc2014.co.uk/?attachment_id=1889" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty04-1.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty04-1-300x300.jpg 300w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty04-1-150x150.jpg 150w" sizes="(max-width: 600px) 100vw, 600px"></figure></li></ul></figure>



<p>So, as a practical joke, the homage to the powerful Cray 1, and also the less powerful Rolodex worked surprisingly well. This inevitably lead to the question of making it work for real</p>



<figure><ul><li><figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty05-1.jpg" alt="" data-id="1890" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty05-1.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty05-1-300x300.jpg 300w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty05-1-150x150.jpg 150w" sizes="(max-width: 600px) 100vw, 600px"></figure></li><li><figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty06-1.jpg" alt="" data-id="1891" data-link="https://rc2014.co.uk/?attachment_id=1891" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty06-1.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty06-1-300x225.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"></figure></li><li><figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty07-1.jpg" alt="" data-id="1892" data-full-url="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty07-1.jpg" data-link="https://rc2014.co.uk/?attachment_id=1892" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty07-1.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty07-1-300x225.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"></figure></li></ul></figure>



<p>Taking some measurements from the toilet roll, I laser cut a simple jig to hold 12 40 pin sockets around 270 degrees, with the intention of soldering wire from pin to pin in situ. This quickly demonstrated that it just wasn’t practical to get the soldering iron in such a tight area. </p>



<p>Another jig was made to hold the sockets at an even distance, and use brass wire to connect them up, with the intention of bending them around afterwards. This also became quickly apparent that it wasn’t going to work.</p>



<div><figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty08-1.jpg" alt="" width="349" height="349" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty08-1.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty08-1-300x300.jpg 300w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty08-1-150x150.jpg 150w" sizes="(max-width: 349px) 100vw, 349px"></figure></div>



<p>Luckily <a href="https://docs.oshpark.com/services/flex/">OSHPark</a> offer a flex PCB option. I’ve been aware of this for a while, and wanted to try it, but there hadn’t been anything suitable within the RC2014 ecosystem. (Well, there have been requests for a Floppy Module, but I don’t think anybody actually wants a module which is floppy!).  At $10 per square inch, it isn’t cheap, but, after a bit of KiCad work, the smallest 12 slot RC2014 backplane was ordered.</p>



<figure><ul><li><figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty09-1.jpg" alt="" data-id="1894" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty09-1.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty09-1-300x300.jpg 300w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty09-1-150x150.jpg 150w" sizes="(max-width: 600px) 100vw, 600px"></figure></li><li><figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty10-1.jpg" alt="" data-id="1895" data-link="https://rc2014.co.uk/?attachment_id=1895" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty10-1.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty10-1-300x300.jpg 300w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty10-1-150x150.jpg 150w" sizes="(max-width: 600px) 100vw, 600px"></figure></li><li><figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty11-1.jpg" alt="" data-id="1896" data-full-url="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty11-1.jpg" data-link="https://rc2014.co.uk/?attachment_id=1896" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty11-1.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty11-1-300x300.jpg 300w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty11-1-150x150.jpg 150w" sizes="(max-width: 600px) 100vw, 600px"></figure></li></ul></figure>



<p>Soldering through hole components on to flex PCB is not easy, and 480 solder joints generate a lot of heat which will warp the plastic if it is not done carefully in a controlled manner. The Flex PCB was designed to fit the existing jigs, and when soldered up, it fitted perfectly!</p>



<figure><ul><li><figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty12-1.jpg" alt="" data-id="1897" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty12-1.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty12-1-300x300.jpg 300w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty12-1-150x150.jpg 150w" sizes="(max-width: 600px) 100vw, 600px"></figure></li><li><figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty13-1.jpg" alt="" data-id="1898" data-link="https://rc2014.co.uk/?attachment_id=1898" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty13-1.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty13-1-300x300.jpg 300w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty13-1-150x150.jpg 150w" sizes="(max-width: 600px) 100vw, 600px"></figure></li><li><figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty14-1.jpg" alt="" data-id="1899" data-full-url="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty14-1.jpg" data-link="https://rc2014.co.uk/?attachment_id=1899" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty14-1.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty14-1-300x300.jpg 300w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty14-1-150x150.jpg 150w" sizes="(max-width: 600px) 100vw, 600px"></figure></li></ul></figure>



<p>Using the jig dimensions, I was able to 3D print a couple of end caps which held the slots in place and made things much more solid.  I filled it with a bunch of spare modules and tested out if the backplane itself worked…</p>



<figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty15-1.jpg" alt="" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty15-1.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty15-1-300x300.jpg 300w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty15-1-150x150.jpg 150w" sizes="(max-width: 600px) 100vw, 600px"></figure>



<p>Huston we have a problem! Nothing came up when I plugged in a FTDI cable :-(</p>



<p>A few hours were wasted going down different rabbit holes chasing too many red herrings.  The modules I’d put together essentially made up a <a href="https://www.tindie.com/products/semachthemonkey/rc2014-zed-homebrew-z80-computer-kit/">RC2014 Zed</a>, and were picked from some of my non-current module archive. What I’d forgotten about is that old versions of RomWBW which are built for use with a DS1302 RTC Module will hang for about 2 minutes on startup if the RTC cannot be found. So, in fact, it was all working perfectly, I just had to wait a little while after plugging in!</p>



<p>A quick upgrade to RomWBW v3.0.1 overcomes this problem, and should have been done right at the start!</p>



<figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty16-1.jpg" alt="" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty16-1.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty16-1-300x300.jpg 300w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty16-1-150x150.jpg 150w" sizes="(max-width: 600px) 100vw, 600px"></figure>



<p>To make things more Cray-like, I redesigned the end caps to be open at the top and bottom, and extended the lower one to support a laser cut skirt.  One day this will house an IDE hard drive, but for now, it’s just there to mimic the bench seat on the Cray 1</p>



<figure><img src="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty17-1.jpg" alt="" srcset="https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty17-1.jpg 600w, https://rc2014.co.uk/wp-content/uploads/2020/08/CrazeeEighty17-1-300x225.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"></figure>



<p>The irony is not lost on me that the Pi Zero, which is only used to generate HDMI from serial data, is several orders of magnitude more powerful than the Cray 1, which is, itself, way more powerful than the Z80 which is calling all the shots!</p>



<p>There are no plans to release this as a product at this stage. The price would be too high to justify for a kit which really is not very practical at all.</p>
				</div></div>]]>
            </description>
            <link>https://rc2014.co.uk/1865/crayzee-eighty/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25980701</guid>
            <pubDate>Sun, 31 Jan 2021 17:43:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hardware Is Hard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25980678">thread link</a>) | @yarapavan
<br/>
January 31, 2021 | https://digitstodollars.com/2021/01/21/hardware-is-hard/ | <a href="https://web.archive.org/web/*/https://digitstodollars.com/2021/01/21/hardware-is-hard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>We have written a lot about the blind spot the US venture ecosystem has for <a href="https://digitstodollars.com/2019/09/30/3042/">semiconductors</a> (<a href="https://digitstodollars.com/2020/08/10/not-a-drop-for-you/">and here</a>) and hardware more generally. We recently helped a venture firm conduct due diligence on an electronics company, which put us in the awkward position of having to walk in someone else’s shoes. Sympathy for the devil, and all that. In our posts we have attempted to be fair, pointing out that US VCs are making sensible economic decisions albeit on a short-sighted viewpoint. Investing in hardware is much more capital intensive and thus risky than investing in software. In this post, we want to work through some of the math behind that. </p>



<p>Let’s say we have a company, Unicorn Electronics, that wants to build The SmartHorn <sup>TM</sup>, a device that magically solves customers’ problems perfectly. How do we get the company to “escape velocity” – positive cashflow sufficient to fund the company’s immediate growth needs?</p>



<p>First, Unicorn needs to design the Horn. Depending on how complex the device is this can cost anywhere from $100,000 to $1 million, from a third party design shop. Some people can do this design themselves, others are going to need outside help. For our purposes, let’s say the Horn design costs $500,000. This amount gets the company the “blueprints” and a few prototypes.  </p>



<p>But most devices today are fairly complex. Even if the hard computation is done in the cloud or in the app, the device itself needs to be able to function, to be programmed and to communicate with the Internet. That means firmware. This is low-level software, and not only is their no standard “firmware” programming language or operating system, pretty much every chip company has its own instruction language. Hiring firmware engineers is not that expensive in dollars, but it can be very expensive in time. Here’s a typical scenario. The design shop hands the firmware designers some prototypes. The firmware team finds a bug that requires a new wire or capacitor. So the design firm has to build (by hand) a new prototype. The firmware team then finds that two of the chips are not speaking to each other – the Bluetooth and the temperature sensor for instance. Is the problem in one chip or the other or somewhere in the wiring in between? Often this will mean the design team needs to spin up yet another prototype. And since these teams are likely in different cities, if not different countries, every re-spin loses days in shipping and re-work. </p>



<p>So far, we have spent $500,000 and a month on the design, and $100,000 and four months on firmware.</p>



<p>Now we have to find a manufacturer. This company will need to create tools and molds as well as designing a manufacturing flow. They can do this fairly quickly, but as they are operating on expensive machine tools, they will have minimum quantity requirements. These can be as low as a few thousand units, but here is where the costs really start to add up. </p>



<p>Let’s say the SmartHorn costs $100 in parts and manufacturing, but the manufacturer requires a minimum of 5,000 units. Then the tricky part becomes sourcing parts. The global electronics supply chain is incredibly tight right now. <a href="https://digitstodollars.com/2020/10/27/what-is-happening-to-the-supply-chain/">We wrote about this back in October</a>, and the <a href="https://www.nytimes.com/2021/01/13/business/auto-factories-semiconductor-chips.html">New York Times was catching up last week</a>. Lead times for many parts can be several months, and frustratingly it is hard to predict with often some of the lowest value parts in the shortest supply. So add $500,000 (5,000 units X $100 BOM) and four months. </p>



<p>Then we enter into a whole sea of minutiae. The device will need various certifications UL, FCC, etc. Add $50,000, but fortunately this can be done while the manufacturing is ramping up. But there are bigger costs as well such as insurance. Most distributors (i.e. retail) and enterprise customers will want the company to maintain a range of insurance policies, tack on another $50,000 or so. Then we have to factor in shipping and customs and taxes, so maybe $20 per device. </p>



<p>Next up, the company has to factor in warranties and returns. The accountants have requirements for setting reserves for these, but a rough rule of thumb (sufficient for our purposes here only) is 10% of the costs of the materials needs to be set aside to cover the cost of returns and replacements. </p>



<p>Finally, the company has to contend with marketing. This amount can range from nothing to A Lot, depending on whether they are selling to consumers or to a single large enterprise customer. A basic PR budget and some content marketing runs about $50,000, plus or minus. </p>



<p>Adding this up we have the following budget:</p>



<figure><table><tbody><tr><td>Item</td><td>Amount</td><td data-align="center">Time</td></tr><tr><td>Design</td><td>$500,000</td><td data-align="center">1 Month</td></tr><tr><td>Firmware</td><td>$100,000</td><td data-align="center">4 Months</td></tr><tr><td>Manufacture</td><td>$500,000</td><td data-align="center">4 Months</td></tr><tr><td>Certification</td><td>$50,000</td><td data-align="center"></td></tr><tr><td>Insurance</td><td>$50,000</td><td data-align="center"></td></tr><tr><td>Shipping </td><td>$100,000</td><td data-align="center">1 Month</td></tr><tr><td>Marketing</td><td>$50,000</td><td data-align="center"></td></tr><tr><td>Sub-total Cost of Goods Sold</td><td>$1,350,000</td><td data-align="center"></td></tr><tr><td>Warranty Reserve</td><td>$135,000</td><td data-align="center"></td></tr><tr><td><strong>TOTAL</strong></td><td><strong>$1,485,000</strong></td><td data-align="center"><strong>9 Months</strong></td></tr></tbody></table></figure>



<p>All of this has to take place before the company can collect any revenue, unless they have done some form of crowdsourcing. So just to break even the company has to charge $297/unit, and to get a 50% gross margin the retail price would need to be $594. </p>



<p>We also need to factor in software costs. For this example, we will assume Unicorn Electronics does their own app and back-end software. The company could probably build all of the hardware and software with a team of ten people. If the average salary is $150,000 year (assume some expensive onshore talent and some less expensive offshore talent), the total comes out to $1.5 million for a year. </p>



<p>So $1.485 million in hardware costs and $1.5 million for headcount, for a total of $2.985 million. The company then sells 5,000 units for $594 a piece or $2.97 million in revenue and yielding a net <em><strong>loss</strong></em> of ($15,000). Hardware can be dispiriting.</p>



<p>The good news is that there is a heavy fixed costs component to this model, so tweaking a few variables can have a big impact. For instance, if they raise prices by $6/unit to an even $600, the net profit goes to $15,000 (positive). Sell an additional 1,000 units and the net profits are close to half a million dollars. If they sell 100,000 units then the company has a path to becoming a true Unicorn. There is a lot of leverage in the model, which is why people keep trying to build hardware. </p>



<p>That being said, the realities of hardware can be daunting. Take the $3 million the company needs to get a product out the door, a similarly sized team could build a software application that can potentially grow much faster and they would still have a million dollars to do customer acquisition. Compounding this, the software would come with a recurring revenue stream. The trouble with hardware is that for the company to grow, they have to come out with the Smart Horn 2 and the Smart Horn 3, and go through all of the above again, and again. </p>



<p>Hardware has immense financial leverage, but the upfront costs and more crucially the time required are daunting. </p>



<p><em>Photo by <a href="https://unsplash.com/@usmanyousaf?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Usman Yousaf</a> on <a href="https://unsplash.com/s/photos/headache?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></em></p>
			</div></div>]]>
            </description>
            <link>https://digitstodollars.com/2021/01/21/hardware-is-hard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25980678</guid>
            <pubDate>Sun, 31 Jan 2021 17:41:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linguistic Miracle of the Quran [video] – Abdullah Sameer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25980642">thread link</a>) | @whereistimbo
<br/>
January 31, 2021 | https://abdullahsameer.com/linguistic-miracle-of-the-quran/ | <a href="https://web.archive.org/web/*/https://abdullahsameer.com/linguistic-miracle-of-the-quran/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-43">

<div>
<p>Contrary to popular belief not all the Arabs believed the Qur’an was of a the highest literary standard. The Qur’an itself attests to those who said it was the ramblings of a madman or a poet full of myths and fairytales. Al-Razi, one of the great scholars of the Islamic Golden Age said the Qur’an was inferior to many works of contemporary poets and writers. Here are more quotes:</p>
<ul>
<li>Al-Jaʿd ibn Dirham, tutor to the Umayyad Caliph Marwan, said “The Qur’an’s eloquence is not a miracle and people can do the like of it and better.”[ref]Mustafa Sadiq al-Rafiì, “The Miraculous Nature of the Qurʾān and the Prophetic Rhetoric.” Page 160.[/ref]</li>
<li>The Mu’tazilite scholar Abu Musa said “People are able to produce the like of the Qurʾān as regards eloquence, and composition and rhetorical beauty.”[ref]Al-Baghdadi, “The Difference Between the Groups” Page 164–165; and<br>
al-Shahrastani, “The Book of Sects and Creeds”, 1/68–69.[/ref]</li>
<li>The 11th century Sunni scholar Abu al-Qushairy said: “We do not claim that everything in the Qurʾān is in the highest rank of eloquence.”[ref]Al-Baghdadi, “The Difference Between the Groups” Page 164–165; and al-Shahrastani, “The Book of Sects and Creeds”, 1/68–69.[/ref]</li>
<li>Ibn al-Rawandi (former Mu’tazilite scholar) (d. 910 ad) said “Indeed the Qurʾān is not the speech of a wise god. In it are contradictions and mistakes and passages that are in the realms of the absurd.”[ref]Quoted from Dr. Abd al-Rahman Badawi, from “History of Disbelief in Islam” page 216.[/ref]</li>
</ul>
<blockquote><p>Writing in the mid-700s, John of Damascus mocked the Qur’an as a bizarre mishmash of heretical Christian teachings that Muhammad had cobbled together. Even Voltaire, who lauded Islam warmly when it suited his satirical ends (like belittling the Catholic Church or Jews), dismissed the Qur’an as full of contradictions, absurdities and patent scientific falsehoods.7 Though he counted Muhammad as the most sincere of men (indeed one of the ‘great men’ who changed the course of history), Thomas Carlyle described the Qur’an as impenetrably befuddling, ‘insupportable stupidity, in short.’</p>
<p>Even Voltaire, who lauded Islam warmly when it suited his satirical ends (like belittling the Catholic Church or Jews), dismissed the Qur’an as full of contradictions, absurdities and patent scientific falsehoods.7 Though he counted Muhammad as the most sincere of men (indeed one of the ‘great men’ who changed the course of history), Thomas Carlyle described the Qur’an as impenetrably befuddling, ‘insupportable stupidity, in short.’[ref]Misquoting Muhammad, Jonathan Brown[/ref]</p></blockquote>
<p>The Quran has some parts which are eloquent and beautiful. &nbsp;And it has some parts that sound strange and akward. &nbsp;Yet the Quran’s biggest miracle claim is the language. &nbsp;How can someone the proof of divinity is in the language, when language is such a subjective issue.</p>
<p><iframe title="Is the Qur'an a Miracle?" width="1140" height="855" src="https://www.youtube.com/embed/2CHm2xigkBc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>al-Razi wrote,</p>
<blockquote><p>“You claim that the evidentiary miracle is present and available, namely, the Koran. You say: ‘Whoever denies it, let him produce a similar one.’ Indeed, we shall produce a thousand similar, from the works of rhetoricians, eloquent speake<span>rs and valiant poets, which are more appropriately phrased and state the issues more succinctly. They convey the meaning better and their rhymed prose is in better meter. … By God what you say astonishes us! You are talking about a work which recounts ancient myths, and which at the same time is full of contradictions and does not contain any useful information or explanation. Then you say: ‘Produce something like it’?”<br>
― <a href="https://en.wikipedia.org/wiki/Muhammad_ibn_Zakariya_al-Razi">Muhammad ibn Zakariya al-Razi</a></span></p></blockquote>
<p>It is not at all true that the Arabs were amazed by the language of the Quran and thought it was from God.</p>

<p>I am working on a longer response to this, but here is the argument:</p>
<p>وَإِن كُنتُمْ فِي رَيْبٍ مِّمَّا نَزَّلْنَا عَلَىٰ عَبْدِنَا فَأْتُوا بِسُورَةٍ مِّن مِّثْلِهِ وَادْعُوا شُهَدَاءَكُم مِّن دُونِ اللَّ إِن كُنتُمْ صَادِقِينَ</p>
<blockquote><p>And if you are in doubt about what We have sent down upon Our Servant [Muhammad], then produce a surah the like thereof and call upon your witnesses other than Allah , if you should be truthful. (2:23)</p></blockquote>
<p>قُل لَّئِنِ اجْتَمَعَتِ الْإِنسُ وَالْجِنُّ عَلَىٰ أَن يَأْتُوا بِمِثْلِ هَٰذَا الْقُرْآنِ لَا يَأْتُونَ بِمِثْلِهِ وَلَوْ كَانَ بَعْضُهُمْ لِبَعْضٍ ظَهِيرًا</p>
<blockquote><p>Say, “If mankind and the jinn gathered in order to produce the like of this Qur’an, they could not produce the like of it, even if they were to each other assistants.” (17:88)</p></blockquote>
<p>And here is one Surah like it.</p>

<p>بِسْمِ اللَّهِ الرَّحْمَنِ الرَّحِيمِ</p>
<p>فقۤ {١<br>
إنَّا خَلَقْنَا الدَّجَاجَ خَلْقًا {٢<br>
وَسَلَقْنَا الْبَيْضَ سَلْقًا {٣<br>
وَأَطْلَقْنَا مَعَ الرَّعْدِ بَرْقًا {٤<br>
وَجَعَلْنَا الجَوَّ طَلْقًا {٥<br>
فَمَنْ يَكْفُرْ بِآياتِنَا شَنَقْنَاهُ شَنْقًا {٦<br>
ثُمَّ خَنَقْنَاهُ خَنْقًا {٧<br>
وَمَنْ يَطْرُقْ بَابَ فَاسِقَةٍ طَرْقًا {٨<br>
وَيَفْعَلْ فِي بَيْتِهَا فِسْقًا {٩<br>
حَرَقْنَاهُ فِي النَّارِ حَرْقًا {١٠<br>
إنَّ عَذَابَنَا هُوَ الْأَبْقَى {١١<br>
وَإنَّ عَدُوَّنَا هُوَالْأَشْقَى {١٢<br>
فَلَا أُقْسِمُ بِبَرِيقِ الدِّينَارِ {١٣<br>
وَلَا أُقْسِمُ بِنَهِيقِ الْحِمَارِ {١٤<br>
إنَّي أنَا اللهُ الخَالِقُ الْقَهَّارُ {١٥<br>
فَأَطِيعُونِي وَلَا تَكُونُوا مِنَ الْكُفَّارِ {١٦<br>
وَاتَّقُوا يَوْمًا لَا يَنْفَعُ فِيهِ دِرْهَمٌ وَلَا دُولَارٌ {١٧<br>
يَوْمَ يُقْذَفُ بِالْكُفِّارِ فِي النَّارِ {١٨<br>
فَلَا يَسْتَطِيعُونَ صَبْرًا وَمَا لَهُمْ مِنْ فِرارٍ {١٩<br>
أَمَّا الَذِينَ اتَّقَوْا رَبَّهُمْ فَإنهم هُمُ الأَخْيَارُ {٢٠<br>
لَهُمْ جَنَّاتٌ تَجْرِي مِنْ تَحْتِهَا الْأَنْهَارُ {٢١<br>
وَصَنَادِيقُ وِيسْكِي وَرَاقِصَاتٌ بِلَا خِمَارَ {٢٢</p>

<p>In the Name of Allah, the Beneficent the Merciful,</p>
<p>1. Faa’ Qaaf<br>
2. Verily, We created the chicken a (wonderful) creation,<br>
3. And We boiled the eggs, a boiling,<br>
4. And We sent with thunder, lightning<br>
5. And We made the air fresh<br>
6. As for he who denies our signs, We shall hang him a hanging,<br>
7. And choke him, a choking<br>
8. As for he who knocks on the door of a harlot, a knocking<br>
9. Then commits in her house; philandering<br>
10. We shall burn him in the fire, a burning<br>
11. Indeed our punishment it is the abiding<br>
12. Indeed our enemy he is the most wretched.<br>
13. For I swear by the glitter of the Dinar<br>
14. And I swear by the braying of the Ass<br>
15. Indeed I am Allah the Creator, the Conqueror<br>
16. So obey me and do not be of the unbelievers<br>
17. And fear a day when no Dirham will benefit nor will a Dollar<br>
18. The day the unbelievers will be cast into the fire<br>
19. And they shall not be able to bear it nor escape<br>
20. As for those who feared their Lord, they are the best<br>
21. They shall have gardens under which run rivers<br>
22. And crates of whiskey and dancing girls with no veil</p>
<p>Author Hassan</p>
<p>Here is another:</p>
<h2>Surah Atheism</h2>
<p>By science and reason we depend. To be revived is Atheism the sublime! (1)</p>
<p>A book we’ve written and bestowed as Arabian and have recited it lyrically. To show the ones who’ve strayed from the path that which has been to revealed to them was a book man-made, ironically. (2)</p>
<p>And the oppressors whom have mislead the People and interpreted in their Book craftily (3)</p>
<p>And they (oppressors, aka sheikhs imams) said: They should offer to us, those liars who’ve rejected our miraculous verses, a book written identically! (4)</p>
<p>For when they (challengers) said that [we replied]: For there is no difficulty for us to state statements equally (5).</p>
<p>Have the believers in the Quran assumed that we shall never come up with a contender, more than deservedly? (6)</p>
<p>Surely we are more than capable of coming with something counter to what came to them, yet superior intellectually. (7)</p>
<p>Do they not see that they fight about the Quran with contradictions and fusses extensively? (8)</p>
<p>Did your [beloved] friend/companion not claim that “verily, the sun has taken via the Earth an orbit, periodically? (9)</p>
<p>And: “Verily, your Lord descends in the last third of the night, and the last third of the night has oscillated on this Earth endlessly.” (10)</p>
<p>And when you [Muslims] were confronted with knowledge from the scientists/scholars; demonstrating the [Quran’s] error regarding the night and day, and how: “The Earth has taken around the Sun a course, orbiting routinely” (11)</p>
<p>For instead, you rejected them [scientists]; and thus a faction amongst you [exmooses] believed in them, and each departed with what they hold and preached with it nightly and daily. (12)</p>
<p>And you [Muslims] wove in ‘The Book’ [Quran] weaves to produce by it financial gain and veneration for it, immutably (13).</p>
<p>And regarding the ones who lied [Muslims: emulating Quranic hate style], for they became stubborn and boastful, and they said: “How can we say that [science is true] and we have revealed to us from The Prophet his sacred methods, frequently and repeatedly?” (14)</p>
<p>Look at how they have disputed amongst their affairs when ‘they are the pious’; and adopted divergent paths, their ideals left cleft asunder. Surely, they are a People that do not wish to contemplate critically. (15)</p>
<p>And they erected between themselves and the ones who do not support them (Kuffar) a barrier, veiled separately (16).</p>
<p>And they [Muslim scholars] said: “Do not get persuaded by them [seculars]; for they spread nothing except deceit; spun maliciously!” (17).</p>
<p>Did you not blame the [pre-islamic] ancients when they said: “Do not entertain the Quran”? Have you today come to lay such claim, identically? (18)</p>
<p>For surely you have falsified and rejected science and the [secular] scholars when they offered their opinions, antithetically (19).</p>
<p>For when Science &amp; Reason eventually prevailed; the truth became apparent and you said: “For these are truths that have existed in the Book [Quran], preserved &amp; written previously! (20)</p>
<p>For then they will definitely say: “What came with you is distinctly wrong from what came to us. Say: “Yes! Indeed, and your prevention of the masses to hear anything of it [science, reason, facts] proves that, evidently!”/s (21).</p>
<p>Translated from this <a href="https://www.youtube.com/watch?v=s0fNL00cCAs">youtube video</a> by Havtho[ref]Reddit: <a href="https://www.reddit.com/r/exmuslim/comments/60jzs0/surah_alathiesm_a_response_to_the_qurans_claim_of/">Surah Al-Atheism</a>[/ref]</p>

<p>Also see:</p>
<ul>
<li><a href="https://abdullahsameer.com//the-atheist-quran-parody/">The Atheist Quran</a></li>
</ul>
</div>

</article></div>]]>
            </description>
            <link>https://abdullahsameer.com/linguistic-miracle-of-the-quran/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25980642</guid>
            <pubDate>Sun, 31 Jan 2021 17:37:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ESP8266 WiFi People Counter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25980601">thread link</a>) | @milankragujevic
<br/>
January 31, 2021 | https://www.hackster.io/ferrithemaker/esp8266-wifi-people-counter-8cc40c | <a href="https://web.archive.org/web/*/https://www.hackster.io/ferrithemaker/esp8266-wifi-people-counter-8cc40c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>With ESP8266 WiFi people counter project you can track and count people near a defined zone using the WiFi capabilities of the ESP8266 microcontroller. Then you can send anonymous data from the ESP8266 to your own MQTT broker, store it using influxDB server and show the information online in real-time using grafana.</p><h3 id="toc-the-project-step-by-step-0"><span>The project step by step:</span></h3><ul><li><span>Download the files from </span><a href="https://github.com/ferrithemaker/esp8266-wifi-people-counter" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;Github Repo&quot;,&quot;href&quot;:&quot;https://github.com/ferrithemaker/esp8266-wifi-people-counter&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">Github Repo</a></li><li>Setup and configure the ESP8266 program code located at WiFiPeopleCounter directory. You need to put your config data (WiFi SSID / WiFi Password / MQTT data) at credentials.h file.</li></ul><div data-hypernova-key="ImageCarousel" data-hypernova-id="41b84a73-66c0-493c-9265-e3f029230b88"><div data-reactroot=""><div><p><span>ESP8266 configuration file</span></p></div></div></div>
<ul><li>Upload the code to your ESP8266 device.</li><li><span>Install and configure </span><a href="https://mosquitto.org/" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;MQTT server &quot;,&quot;href&quot;:&quot;https://mosquitto.org/&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">MQTT server </a><span>(communications), </span><a href="https://www.influxdata.com/" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;influxDB &quot;,&quot;href&quot;:&quot;https://www.influxdata.com/&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">influxDB </a><span>(data store) and </span><a href="https://grafana.com/" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;grafana &quot;,&quot;href&quot;:&quot;https://grafana.com/&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">grafana </a><span>(data visualization) on your server.</span></li><li>Setup the Python script (mqttreceiver.py). You will need to setup the MQTT and influxDB data (snifferconfig.py file) and load the proper Python modules (using apt-get, pip, …)</li></ul><div data-hypernova-key="ImageCarousel" data-hypernova-id="ef947899-3e5d-4da5-9f3a-a9b1f0a0a74b"><div data-reactroot=""><div><p><span>Python script configuration file</span></p></div></div></div>
<ul><li>Open grafana with your browser (usually at port 3000) and configure the connection with the influxDB as datasource.</li><li>Create a dashboard and queries from grafana.</li></ul>
<div data-hypernova-key="ImageCarousel" data-hypernova-id="563a0970-3af0-4e21-94bf-cf0220a8caa4"><div data-reactroot=""><div><p><span>Final visualization of the grafana dashboard</span></p></div></div></div>
<h3 id="toc-script-options-1"><span>Script options:</span></h3><p><strong>debug</strong><span> (True / False) enables information output</span></p><p><strong>log</strong><span> (True / False) enables creation of data csv file of the data flow</span></p><p><strong>mac_randomizer_mode</strong><span> (True / False) enables mac randomizer mode detection to (try to) avoid privacy settings of some WiFi devices*</span></p><p><span>*Recent versions of mobile operatig systems like </span><a href="https://www.android.com/android-10/" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;Android 10 &quot;,&quot;href&quot;:&quot;https://www.android.com/android-10/&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">Android 10 </a><span>uses a new privacy setting to avoid tracking, randomizing the last 3 bytes of the device MAC address.</span></p><p><span>To override this, a new </span><code>mac_randomizer_mode</code><span> option has been added to the MQTT script. This mode marks as the same MAC address if the first 3 bytes of the MAC address appears in the last 15 minutes (you can change the threshold). It’s not a perfect solution, but the chances to get the same first 3 bytes (often related to a brand specific model series) in a short time window within a few meters distance from the detector device are very few indeed.</span></p><p><span>Check lastest updates at </span><a href="https://ferrithemaker.github.io/" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;github.io &quot;,&quot;href&quot;:&quot;https://ferrithemaker.github.io/&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">github.io </a><span>site</span></p></div></div>]]>
            </description>
            <link>https://www.hackster.io/ferrithemaker/esp8266-wifi-people-counter-8cc40c</link>
            <guid isPermaLink="false">hacker-news-small-sites-25980601</guid>
            <pubDate>Sun, 31 Jan 2021 17:33:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Game of mocks – Mocking a GraphQL API as a proof of concept]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25980436">thread link</a>) | @lnenad
<br/>
January 31, 2021 | https://blog.mockadillo.com/posts/game-of-mocks-mocking-a-graphql-api-as-poc/ | <a href="https://web.archive.org/web/*/https://blog.mockadillo.com/posts/game-of-mocks-mocking-a-graphql-api-as-poc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <figure>
    <img src="https://blog.mockadillo.com/images/graphql.png" alt="Is it worth the trouble?">
    <figcaption>Is it worth the trouble?</figcaption>
  </figure>

<h2 id="intro">Intro</h2>
<p>So you’ve come to a point where it just seems like a good idea to simplify the frontend implementations and get rid of the dozens (dozens) of endpoints scattered throughout your application. The time has come to switch to GraphQL (or you just like shiny, new, things).</p>
<h2 id="graphql">GraphQL</h2>
<p>For a long time, a classic REST(ful) API has been the de facto standard for data sharing between applications and services. The issue with REST stands in its lack of flexibility, most new use cases on the UI require more work from the backend. Syncing these requirements is a tedious task that requires time and coordination that might be better spent elsewhere.</p>
<p>A new solution appeared in the form of GraphQL which tackles these issues by allowing the client to specify the schema of what it needs. This allows the clients to have more flexibility and gives product managers more power to improve user facing features without worrying about wasting too much time.</p>
<blockquote>
<p>The results from a survey made by The State of JavaScript stated that from 20,000 JavaScript developers, 83% are using or intending to learn GraphQL.</p>
</blockquote>
<h2 id="how-does-graphql-work">How does GraphQL work?</h2>
<p>Most of the readers are probably familiar with GraphQL.</p>
<blockquote>
<p>GraphQL is a query language for APIs and a runtime for fulfilling those queries with your existing data.</p>
</blockquote>
<p>What it does is it exposes a API endpoints, which allow you to be fully independent of the backend implementation and only worry about the query which is executing on them. This means that you no longer have to rework the backend for every change on the client, if you need another data point that is held in the database, using GraphQL you can fetch it by just adding it to the query.</p>
<p>For example, executing the following query</p>
<pre><code>{
  product {
    name
    current_price
    available_qty
  }
}
</code></pre>
<p>Would yield the following results</p>
<pre><code>{
  "product": {
    "name": "Banana",
    "current_price": "I MEAN IT'S ONE BANANA, MICHAEL, WHAT COULD IT COST? TEN DOLLARS?",
    "available_qty": 100001
  }
}
</code></pre>
<p>By adding or removing the fields in the query you would get a result with different structure. It is a great way of having flexibility in how you want to build things, and reduce unnecessary payload size if your API is riddled with god endpoints which return half of your database.</p>
<h2 id="downsides">Downsides</h2>
<p>The biggest downside is additional complexity, as you now have another layer to implement, and in case of issues debug. There is also the need to actually know how to query the API, and the fact that you might expose some database design details depending on how you expose the GraphQL server. And don’t get me started on trying to cache results.</p>
<h2 id="selling-the-idea-to-your-vp">Selling the idea to your VP</h2>
<p>So once you reach the point of understanding what GraphQL helps you with, and the downsides aren’t scaring you off, you actually need to persuade your VP that it makes sense to implement it. It sure does sound nice, but what will it look like on the client, how will we actually make it work?</p>
<h2 id="using-mocking-to-demonstrate-value">Using mocking to demonstrate value</h2>
<p>You can write your own mock server and try to get up and running, but it will be time consuming, and even after spending all that time the idea might not be accepted. We think you should use Mockadillo. With Mockadillo you can do this, depending on the scope of the API, in a very short time period. Let’s demonstrate that.</p>
<h2 id="real-life-example">Real life example</h2>
<p>Let’s build a GraphQL backend for a produce store. For this demonstration it’s going to be a pretty simple one.</p>
<p>First we have to define some structure for data. Let’s say we can query for <code>products</code></p>
<pre><code>type Query {
  product: Product
}
</code></pre>
<p>Which has the following structure.</p>
<pre><code>type Product {
  id: String,
  name: String,
  current_price: Int,
  available_qty: Int,
  price_history: [PriceHistory],
  active: Boolean,
}
 
type PriceHistory {
  price: Int
  active_from: Date
  active_to: Date
}
</code></pre>
<p>It is obvious here that, if we’re building a storefront, some pages might not need <code>price_history</code>. Other pages might not need the <code>active</code> parameter, where others might (for an admin interface). We can mock these queries easily by using <strong>conditions</strong>, specifically <strong>body request conditions</strong>.</p>
<h2 id="implementing-the-proof-of-concept-through-mockadillo">Implementing the proof of concept through Mockadillo</h2>
<p>After creating the <strong>API</strong> and <strong>Route</strong> in your admin dashboard (if you’re unfamiliar with the process visit <a href="https://docs.mockadillo.com/docs/prologue/introduction/">the getting started page</a>), we need to create and setup the successful <strong>Response</strong>.</p>
<p>For this demo we see a couple of pages that the client will need:</p>
<ul>
<li>Main page that will return a list of products.</li>
<li>A single page that will return detailed product information.</li>
<li>A single page that will be shown to admins with extra information.</li>
</ul>
<p>With these requirements, it’s obvious we need to create 4 different responses. The first one will be a default response, returning an error since it means that the query must have been invalid since we didn’t match any request conditions. The other three represent the data needed for the rest of the pages we will need. We will go into detail for one of these, as the principle is the same for the rest.</p>
<h3 id="list-of-products-response">List of products response</h3>
<p>For this endpoint, we want to return a couple of products, and we assume the page will render certain information limited to</p>
<pre><code>{
    "id": "1",
    "name": "Banana",
    "current_price": 1000,
    "available_qty": 100001,
    "active": true
}
</code></pre>
<p>As in most cases we don’t need other fields. Let’s define the conditions:</p>
<p>So at the least we expect the query to contain the keyword <code>products</code>. This means that we will create a new <strong>body</strong> condition, with the <strong>jsonpath</strong> value of <strong>$.query</strong>, using the <strong>contains</strong> filter, looking for the <strong>products</strong> value.</p>
<figure>
    <img src="https://blog.mockadillo.com/images/graphql-condition.png" alt="Condition requiring &amp;lsquo;products&amp;rsquo; string in the query">
    <figcaption>Condition requiring 'products' string in the query</figcaption>
  </figure>

<p>We can repeat the same process for the fields we want to return, so let’s add 5 more conditions for <code>id</code>, <code>name</code>, <code>current_price</code>, <code>available_qty</code> and <code>active</code> so that the end results looks like this.</p>
<figure>
    <img src="https://blog.mockadillo.com/images/graphql-conditions.png" alt="Five body conditions for this response">
    <figcaption>Five body conditions for this response</figcaption>
  </figure>

<p>You could also click on <code>Toggle editing mode</code> to switch to the raw conditions json and paste the following</p>
<pre><code>{
  "headers": [],
  "body": [
    {
      "source": "$.query",
      "kind": "contains",
      "value": "products"
    },
    {
      "source": "$.query",
      "kind": "contains",
      "value": "id"
    },
    {
      "source": "$.query",
      "kind": "contains",
      "value": "name"
    },
    {
      "source": "$.query",
      "kind": "contains",
      "value": "current_price"
    },
    {
      "source": "$.query",
      "kind": "contains",
      "value": "available_qty"
    },
    {
      "source": "$.query",
      "kind": "contains",
      "value": "active"
    }
  ],
  "queryString": [],
  "origin": []
}
</code></pre>
<p>And let’s add the response body to show some data to the client</p>
<pre><code>{
  "data": { 
    "products": [
    {
      "id": "1",
      "name": "Banana",
      "current_price": 1000,
      "available_qty": 100001,
      "active": true
    },
    {
      "id": "2",
      "name": "Juice",
      "current_price": 300,
      "available_qty": 55,
      "active": true
    },
    {
      "id": "3",
      "name": "Bread",
      "current_price": 100,
      "available_qty": 8,
      "active": false
    }]
  }
}
</code></pre>
<p>Let’s repeat the process for other pages that the application will have. For the details page, according to the GraphQL spec, we expect the query to be similar but to contain a singular <code>product</code> instead of <code>products</code>, and we don’t need the <code>id</code> field for it. On the other hand it might be useful to show the user previous prices (though probably only if they were higher). And for the admin we want to be able to toggle the <code>active</code> field, if we want to disable showing a certain product.</p>
<h3 id="the-end-result">The end result</h3>
<p>In the end, we should have the rest of the conditions setup for each of the responses, totaling 4 different responses.</p>
<figure>
    <img src="https://blog.mockadillo.com/images/graphql-responses.png" alt="Four different responses, three with conditions">
    <figcaption>Four different responses, three with conditions</figcaption>
  </figure>

<p>This is pretty much already enough for our POC application, we can start testing.</p>
<h2 id="testing">Testing</h2>
<p>For API testing we use <a href="https://insomnia.rest/">Insomnia</a>. Let’s first try to get a list of our products.</p>
<figure>
    <img src="https://blog.mockadillo.com/images/insomnia-products.png" alt="The products endpoint returning a list">
    <figcaption>The products endpoint returning a list</figcaption>
  </figure>

<p>Now let’s see if we can get a single product</p>
<figure>
    <img src="https://blog.mockadillo.com/images/insomnia-products.png" alt="The product endpoint returning a single product">
    <figcaption>The product endpoint returning a single product</figcaption>
  </figure>

<h2 id="conclusion">Conclusion</h2>
<p>In the end, it took us (me) under 5 minutes to create everything that was needed to achieve this. You can go for more granularity and implement more responses to support more use cases. But for now I think this should be enough to show you how Mockadillo can be useful for quickly prototyping a GraphQL application. You can go one step further, plan out the features in more detail, and implement the end schema in Mockadillo. This allows you to, when you are done with the actual implementation, to just swap out the API host URL, and technically your application should work.</p>
<p>Thanks for reading, if you think that you have a similar use case, <a href="https://mockadillo.com/register">signup now and try us out</a></p>
<p>The endpoint is live now <a href="https://graphqlpoc-qptviu.mockadillo.com/graphql">here</a></p>

        </div></div>]]>
            </description>
            <link>https://blog.mockadillo.com/posts/game-of-mocks-mocking-a-graphql-api-as-poc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25980436</guid>
            <pubDate>Sun, 31 Jan 2021 17:19:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cab Ride: Drive a train, forever, through a dreamlike land]]>
            </title>
            <description>
<![CDATA[
Score 444 | Comments 81 (<a href="https://news.ycombinator.com/item?id=25980060">thread link</a>) | @polm23
<br/>
January 31, 2021 | https://powersaurus.itch.io/cab-ride | <a href="https://web.archive.org/web/*/https://powersaurus.itch.io/cab-ride">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Drive a train, forever, through a dreamlike land. <br></p>
<p>Transport passengers to their destination.</p>
<p>Watch the world go by.</p>
<p>Listen to chilled out chiptune music.</p>
<p>In Cab Ride you can drive thousands of different train routes through rolling hills, winding tunnels and weaving between the tall buildings&nbsp;of vast cities. You can drive the train for as long as you like. When you're ready to end your journey, hold down the left arrow key to announce the last station. Stopping at stations along the way means you can pick up and drop off passengers. Try and stop at the marker at each station for a high rating. Or don't! It's up to you.</p>
<p>Cab Ride is a casual train simulation, not aiming for real world accuracy, but like a real train, it takes a while to brake. If you're overshooting stations, watch for the alert for the next station and reduce the throttle so you're ready to stop.</p><p>You can get the PICO-8 cart on the <a href="https://www.lexaloffle.com/bbs/?tid=41332" rel="nofollow noopener">PICO-8 BBS</a> (also play in your browser there if you prefer)<br></p>
<h2>Controls</h2>

<h2>Credits</h2>
<p>Programming - Ben Jones / <a href="https://twitter.com/Powersaurus" rel="nofollow noopener">@Powersaurus</a><br></p>
<p>Music - Stephen 'rych-t' Jones / <a href="https://twitter.com/rych_t" rel="nofollow noopener">Twitter</a> / <a href="https://www.instagram.com/rych_t/" rel="nofollow noopener">Instagram</a> / <a href="https://soundcloud.com/floor-machoor" rel="nofollow noopener">Soundcloud</a><br></p>
<p>Based on code from tutorials by Tom Mulgrew <a href="https://www.lexaloffle.com/bbs/?tid=35767" rel="nofollow noopener">https://www.lexaloffle.com/bbs/?tid=35767</a> licensed under Creative Commons 4 (CC BY 4.0) <a href="https://creativecommons.org/licenses/by/4.0/" rel="nofollow noopener">https://creativecommons.org/licenses/by/4.0/<br></a></p>
<p><span></span><a href="https://www.lexaloffle.com/pico-8.php?page=manual" rel="nofollow noopener">Made using PICO-8</a></p></div></div>]]>
            </description>
            <link>https://powersaurus.itch.io/cab-ride</link>
            <guid isPermaLink="false">hacker-news-small-sites-25980060</guid>
            <pubDate>Sun, 31 Jan 2021 16:44:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modest Vue for the HTML You Already Have]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25979894">thread link</a>) | @phaedryx
<br/>
January 31, 2021 | https://tad.thorley.dev/2021/01/31/vue-for-the-html-you-already-have.html | <a href="https://web.archive.org/web/*/https://tad.thorley.dev/2021/01/31/vue-for-the-html-you-already-have.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="page">
  <section id="post">
  <header>
    
    <time>31 Jan 2021</time>
  </header>
  <article>
    <p>Stimulus has a description top and center of its home page: â€œA modest JavaScript
framework for the HTML you already have.â€� By â€œmodestâ€� I think it is claiming that: 
it wonâ€™t take over your routing, it wonâ€™t bury its view code deep in JavaScript
code, it can be applied to the pages you choose (and wonâ€™t affect the pages that
you donâ€™t), etc. By â€œHTML you already haveâ€� I think it is claiming that you can
take an HTML-first approach; you can write your HTML and then â€œsprinkleâ€� in some
JavaScript functionality later.</p>

<p>I like Simulusâ€™s proposition, but <a href="https://tad.thorley.dev/2021/01/24/writing-stimulus-sold-me-on-vue.html">I donâ€™t like the implementation</a>. So letâ€™s do it in a Ruby on Rails
application with Vue instead (<a href="https://github.com/phaedryx/modest-vue-for-your-html">source code</a>).</p>

<p>Even though <a href="https://v3.vuejs.org/">Vue 3</a> was released in September 2020, Rails
still doesnâ€™t support it as an option for creating new applications, so weâ€™ll
have to create the app first and then configure it for Vue.</p>

<p>
$ rails new modest-vue-for-your-html<br>
$ cd modest-vue-for-your-html
</p>

<p>Next add vue, the vue loader (for webpack).</p>

<div>
<p>
$ yarn add vue@next<br>
$ yarn add vue-loader@next<br>
</p></div>

<p>Now that Vue is installed, it needs some configuration. Edit the webpack configuration
file:</p>

<figure><figcaption>config/webpack/environment.js</figcaption><div><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
</pre></td><td><pre><span>const</span> <span>{</span> <span>environment</span> <span>}</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>@rails/webpacker</span><span>'</span><span>)</span>
<span>const</span> <span>{</span> <span>DefinePlugin</span> <span>}</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>webpack</span><span>'</span><span>)</span>
<span>const</span> <span>{</span> <span>VueLoaderPlugin</span> <span>}</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>vue-loader</span><span>'</span><span>)</span>
<span>const</span> <span>customConfig</span> <span>=</span> <span>{</span>
  <span>resolve</span><span>:</span> <span>{</span>
    <span>alias</span><span>:</span> <span>{</span>
      <span>vue</span><span>:</span> <span>'</span><span>vue/dist/vue.esm-bundler.js</span><span>'</span> <span>// Use the variation that allows Vue to use existing HTML (e.g. Rails views)</span>
    <span>}</span>
  <span>}</span>
<span>}</span>

<span>environment</span><span>.</span><span>config</span><span>.</span><span>merge</span><span>(</span><span>customConfig</span><span>)</span>

<span>environment</span><span>.</span><span>plugins</span><span>.</span><span>prepend</span><span>(</span>
  <span>'</span><span>Define</span><span>'</span><span>,</span>
  <span>new</span> <span>DefinePlugin</span><span>({</span>
    <span>__VUE_OPTIONS_API__</span><span>:</span> <span>false</span><span>,</span> <span>// To use the Composition API exclusively (I like it, but this is optional)</span>
    <span>__VUE_PROD_DEVTOOLS__</span><span>:</span> <span>false</span> <span>// Ensure development code tools stay out of production code</span>
  <span>})</span>
<span>)</span>

<span>environment</span><span>.</span><span>plugins</span><span>.</span><span>prepend</span><span>(</span>
  <span>'</span><span>VueLoaderPlugin</span><span>'</span><span>,</span>
  <span>new</span> <span>VueLoaderPlugin</span><span>()</span>
<span>)</span>

<span>environment</span><span>.</span><span>loaders</span><span>.</span><span>prepend</span><span>(</span><span>'</span><span>vue</span><span>'</span><span>,</span> <span>{</span>
  <span>test</span><span>:</span> <span>/</span><span>\.</span><span>vue$/</span><span>,</span>
  <span>use</span><span>:</span> <span>[{</span> <span>loader</span><span>:</span> <span>'</span><span>vue-loader</span><span>'</span> <span>}]</span>
<span>})</span>

<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>environment</span>
</pre></td></tr></tbody></table></div></figure>

<p>Now that the Vue is configured letâ€™s give it some HTML to work with</p>

<p>
$ rails generate scaffold Widget style:string color:string runcible:boolean<br>
$ rails db:migrate
</p>

<p>and edit the routes file to use it.</p>

<figure><figcaption>config/routes.rb</figcaption><div><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre><span>Rails</span><span>.</span><span>application</span><span>.</span><span>routes</span><span>.</span><span>draw</span> <span>do</span>
  <span>root</span> <span>'widgets#index'</span>

  <span>resources</span> <span>:widgets</span>
<span>end</span>
</pre></td></tr></tbody></table></div></figure>

<p>Suppose I want to ensure that people fill out the style name correctly. I could 
add a Rails validation that the name matches a certain regular expression (and I
will later) but that means filling out the form, submitting it, and <em>then</em> discovering
a problem. It would be nicer if I got a warning as I was filling the form out. A
bit of JavaScript could be nice.</p>

<p>There are a lot of ways to set this up, but since it is a comparison to Stimulus
letâ€™s set it up in a Stimulus style. In Stimulus you give an element a specific
<code>data-controller</code> attribute and it hooks code to the element. Letâ€™s add a 
<code>data-component</code> (because Vue uses components) attribute to our HTML and then
hook some Vue code to it.</p>

<p>Our Widget views share a common form, so letâ€™s add it to the form partial:</p>

<figure><figcaption>app/views/widgets/_form.html.erb</figcaption><div><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre><span>&lt;div</span> <span>data-component=</span><span>"Widget"</span><span>&gt;</span>
  <span>&lt;%=</span> <span>form_with</span><span>(</span><span>model: </span><span>widget</span><span>)</span> <span>do</span> <span>|</span><span>form</span><span>|</span> <span>%&gt;</span>
    ...
  <span>&lt;%</span> <span>end</span> <span>%&gt;</span>
<span>&lt;/div&gt;</span>
</pre></td></tr></tbody></table></div></figure>

<p>Create the component:</p>

<figure><figcaption>app/javascript/components/Widget.js</figcaption><div><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre><span>const</span> <span>Widget</span> <span>=</span> <span>{</span>
  <span>name</span><span>:</span> <span>'</span><span>Widget</span><span>'</span><span>,</span>
  <span>setup</span><span>()</span> <span>{</span>
    <span>return</span> <span>{}</span>
  <span>}</span>
<span>}</span>

<span>export</span> <span>default</span> <span>Widget</span>
</pre></td></tr></tbody></table></div></figure>

<p>And add code to hook them together:</p>

<figure><figcaption>app/javascript/packs/application.js</figcaption><div><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>// standard Rails stuff</span>
<span>import</span> <span>Rails</span> <span>from</span> <span>"</span><span>@rails/ujs</span><span>"</span>
<span>import</span> <span>Turbolinks</span> <span>from</span> <span>"</span><span>turbolinks</span><span>"</span>
<span>import</span> <span>*</span> <span>as</span> <span>ActiveStorage</span> <span>from</span> <span>"</span><span>@rails/activestorage</span><span>"</span>
<span>import</span> <span>"</span><span>channels</span><span>"</span>

<span>Rails</span><span>.</span><span>start</span><span>()</span>
<span>Turbolinks</span><span>.</span><span>start</span><span>()</span>
<span>ActiveStorage</span><span>.</span><span>start</span><span>()</span>

<span>// Vue stuff here</span>
<span>import</span> <span>{</span> <span>createApp</span> <span>}</span> <span>from</span> <span>'</span><span>vue</span><span>'</span>

<span>import</span> <span>Widget</span> <span>from</span> <span>'</span><span>../components/Widget</span><span>'</span>
<span>// I could import more components here</span>

<span>const</span> <span>components</span> <span>=</span> <span>{</span> <span>Widget</span> <span>}</span> <span>// An object to hold components</span>

<span>// Normally this would be done with 'DOMContentLoaded', but Turbolinks breaks that</span>
<span>document</span><span>.</span><span>addEventListener</span><span>(</span><span>"</span><span>turbolinks:load</span><span>"</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>// Find everything with a data-component</span>
  <span>document</span><span>.</span><span>querySelectorAll</span><span>(</span><span>'</span><span>[data-component]</span><span>'</span><span>).</span><span>forEach</span><span>((</span><span>node</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>// mount the respective Vue component</span>
    <span>createApp</span><span>(</span><span>components</span><span>[</span><span>node</span><span>.</span><span>dataset</span><span>.</span><span>component</span><span>]).</span><span>mount</span><span>(</span><span>node</span><span>)</span>
  <span>})</span>
<span>})</span>
</pre></td></tr></tbody></table></div></figure>

<p>The plan is to run a check on a form field when it loses focus (<code>onBlur</code>), so letâ€™s
start with that. In our component letâ€™s write a function that takes a parameter and
logs it out with <code>console.log</code>.</p>

<figure><figcaption>app/javascript/components/Widget.js</figcaption><div><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
</pre></td><td><pre><span>const</span> <span>Widget</span> <span>=</span> <span>{</span>
  <span>name</span><span>:</span> <span>'</span><span>Widget</span><span>'</span><span>,</span>
  <span>setup</span><span>()</span> <span>{</span>
    <span>const</span> <span>log</span> <span>=</span> <span>(</span><span>message</span><span>)</span> <span>=&gt;</span> <span>{</span> <span>console</span><span>.</span><span>log</span><span>(</span><span>message</span><span>)</span> <span>}</span>

    <span>return</span> <span>{</span> <span>log</span> <span>}</span>
  <span>}</span>
<span>}</span>

<span>export</span> <span>default</span> <span>Widget</span>
</pre></td></tr></tbody></table></div></figure>

<p>Update your HTML to use the new function:</p>
<figure><figcaption>app/views/widgets/_form.html.erb</figcaption><div><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
</pre></td><td><pre><span>&lt;div</span> <span>data-component=</span><span>"Widget"</span><span>&gt;</span>
  <span>&lt;%=</span> <span>form_with</span><span>(</span><span>model: </span><span>widget</span><span>)</span> <span>do</span> <span>|</span><span>form</span><span>|</span> <span>%&gt;</span>
    ...
    <span>&lt;div</span> <span>class=</span><span>"field"</span><span>&gt;</span>
      <span>&lt;%=</span> <span>form</span><span>.</span><span>label</span> <span>:style</span> <span>%&gt;</span>
      <span>&lt;%=</span> <span>form</span><span>.</span><span>text_field</span> <span>:style</span><span>,</span> <span>"@blur"</span> <span>=&gt;</span> <span>"log('it got blurry')"</span> <span>%&gt;</span>
    <span>&lt;/div&gt;</span>
    ...
  <span>&lt;%</span> <span>end</span> <span>%&gt;</span>
<span>&lt;/div&gt;</span>
</pre></td></tr></tbody></table></div></figure>

<p>If you start the server and start up the page, you should be able to click in the first text field,
click out of the text field, and see the message in the browserâ€™s console.</p>

<p>This is interesting, but not terribly useful. Letâ€™s assume that widget styles start with â€œWX-â€œ and
we want to check that in the component:</p>
<figure><figcaption>app/javascript/components/Widget.js</figcaption><div><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td><pre><span>const</span> <span>Widget</span> <span>=</span> <span>{</span>
  <span>name</span><span>:</span> <span>'</span><span>Widget</span><span>'</span><span>,</span>
  <span>setup</span><span>()</span> <span>{</span>
    <span>const</span> <span>check</span> <span>=</span> <span>(</span><span>name</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>if</span> <span>(</span><span>/^WX-.+/</span><span>.</span><span>test</span><span>(</span><span>name</span><span>))</span> <span>{</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>valid</span><span>'</span><span>)</span>
      <span>}</span> <span>else</span> <span>{</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>invalid</span><span>'</span><span>)</span>
      <span>}</span>
    <span>}</span>

    <span>return</span> <span>{</span> <span>check</span> <span>}</span>
  <span>}</span>
<span>}</span>

<span>export</span> <span>default</span> <span>Widget</span>
</pre></td></tr></tbody></table></div></figure>

<p>And hook the new code in:</p>
<figure><figcaption>app/views/widgets/_form.html.erb</figcaption><div><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
</pre></td><td><pre><span>&lt;div</span> <span>data-component=</span><span>"Widget"</span><span>&gt;</span>
  <span>&lt;%=</span> <span>form_with</span><span>(</span><span>model: </span><span>widget</span><span>)</span> <span>do</span> <span>|</span><span>form</span><span>|</span> <span>%&gt;</span>
    ...
    <span>&lt;div</span> <span>class=</span><span>"field"</span><span>&gt;</span>
      <span>&lt;%=</span> <span>form</span><span>.</span><span>label</span> <span>:style</span> <span>%&gt;</span>
      <span>&lt;%=</span> <span>form</span><span>.</span><span>text_field</span> <span>:style</span><span>,</span> <span>"@blur"</span> <span>=&gt;</span> <span>"check($event.target.value)"</span> <span>%&gt;</span>
    <span>&lt;/div&gt;</span>
    ...
  <span>&lt;%</span> <span>end</span> <span>%&gt;</span>
<span>&lt;/div&gt;</span>
</pre></td></tr></tbody></table></div></figure>

<p>When you try out the modified page you should see â€œvalidâ€� and â€œinvalidâ€� when you type different
strings into the text field and remove focus.</p>

<p>This is nice, but users arenâ€™t going to look in their web console for messages. Letâ€™s output a
message into the HTML. First weâ€™ll create a Vue <code>ref</code> in our Widget:</p>

<figure><figcaption>app/javascript/components/Widget.js</figcaption><div><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td><pre><span>import</span> <span>{</span> <span>ref</span> <span>}</span> <span>from</span> <span>'</span><span>vue</span><span>'</span>

<span>const</span> <span>Widget</span> <span>=</span> <span>{</span>
  <span>name</span><span>:</span> <span>'</span><span>Widget</span><span>'</span><span>,</span>
  <span>setup</span><span>()</span> <span>{</span>
    <span>var</span> <span>errorMessage</span> <span>=</span> <span>ref</span><span>(</span><span>null</span><span>)</span>

    <span>// ...</span>

    <span>return</span> <span>{</span> <span>errorMessage</span><span>,</span> <span>check</span> <span>}</span>
  <span>}</span>
<span>}</span>

<span>export</span> <span>default</span> <span>Widget</span>
</pre></td></tr></tbody></table></div></figure>

<p>And add a corresponding div to the HTML:</p>
<figure><figcaption>app/views/widgets/_form.html.erb</figcaption><div><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td><pre><span>&lt;div</span> <span>data-component=</span><span>"Widget"</span><span>&gt;</span>
  <span>&lt;%=</span> <span>form_with</span><span>(</span><span>model: </span><span>widget</span><span>)</span> <span>do</span> <span>|</span><span>form</span><span>|</span> <span>%&gt;</span>
    ...
    <span>&lt;div</span> <span>class=</span><span>"field"</span><span>&gt;</span>
      <span>&lt;%=</span> <span>form</span><span>.</span><span>label</span> <span>:style</span> <span>%&gt;</span>
      <span>&lt;%=</span> <span>form</span><span>.</span><span>text_field</span> <span>:style</span><span>,</span> <span>"@blur"</span> <span>=&gt;</span> <span>"check($event.target.value)"</span> <span>%&gt;</span>
      <span>&lt;div</span> <span>ref=</span><span>"errorMessage"</span> <span>style=</span><span>"color: #C00"</span><span>&gt;&lt;/div&gt;</span>
    <span>&lt;/div&gt;</span>
    ...
  <span>&lt;%</span> <span>end</span> <span>%&gt;</span>
<span>&lt;/div&gt;</span>
</pre></td></tr></tbody></table></div></figure>

<p>Which leads to the final version of the component:</p>
<figure><figcaption>app/javascript/components/Widget.js</figcaption><div><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td><pre><span>import</span> <span>{</span> <span>ref</span> <span>}</span> <span>from</span> <span>'</span><span>vue</span><span>'</span>

<span>const</span> <span>Widget</span> <span>=</span> <span>{</span>
  <span>name</span><span>:</span> <span>'</span><span>Widget</span><span>'</span><span>,</span>
  <span>setup</span><span>()</span> <span>{</span>
    <span>var</span> <span>errorMessage</span> <span>=</span> <span>ref</span><span>(</span><span>null</span><span>)</span>

    <span>const</span> <span>check</span> <span>=</span> <span>(</span><span>name</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>if</span> <span>(</span><span>/^WX-.+/</span><span>.</span><span>test</span><span>(</span><span>name</span><span>))</span> <span>{</span>
        <span>errorMessage</span><span>.</span><span>value</span><span>.</span><span>textContent</span> <span>=</span> <span>''</span>
      <span>}</span> <span>else</span> <span>{</span>
        <span>errorMessage</span><span>.</span><span>value</span><span>.</span><span>textContent</span> <span>=</span> <span>'</span><span>This style name is incorrect</span><span>'</span>
      <span>}</span>
    <span>}</span>

    <span>return</span> <span>{</span> <span>errorMessage</span><span>,</span> <span>check</span> <span>}</span>
  <span>}</span>
<span>}</span>

<span>export</span> <span>default</span> <span>Widget</span>
</pre></td></tr></tbody></table></div></figure>

<p>And here is the complete, final version of the form partial:</p>
<figure><figcaption>app/views/widgets/_form.html.erb</figcaption><div><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre></td><td><pre><span>&lt;div</span> <span>data-component=</span><span>"Widget"</span><span>&gt;</span>
  <span>&lt;%=</span> <span>form_with</span><span>(</span><span>model: </span><span>widget</span><span>)</span> <span>do</span> <span>|</span><span>form</span><span>|</span> <span>%&gt;</span>
    <span>&lt;%</span> <span>if</span> <span>widget</span><span>.</span><span>errors</span><span>.</span><span>any?</span> <span>%&gt;</span>
      <span>&lt;div</span> <span>id=</span><span>"error_explanation"</span><span>&gt;</span>
        <span>&lt;h2&gt;</span><span>&lt;%=</span> <span>pluralize</span><span>(</span><span>widget</span><span>.</span><span>errors</span><span>.</span><span>count</span><span>,</span> <span>"error"</span><span>)</span> <span>%&gt;</span> prohibited this widget from being saved:<span>&lt;/h2&gt;</span>

        <span>&lt;ul&gt;</span>
          <span>&lt;%</span> <span>widget</span><span>.</span><span>errors</span><span>.</span><span>each</span> <span>do</span> <span>|</span><span>error</span><span>|</span> <span>%&gt;</span>
            <span>&lt;li&gt;</span><span>&lt;%=</span> <span>error</span><span>.</span><span>full_message</span> <span>%&gt;</span><span>&lt;/li&gt;</span>
          <span>&lt;%</span> <span>end</span> <span>%&gt;</span>
        <span>&lt;/ul&gt;</span>
      <span>&lt;/div&gt;</span>
    <span>&lt;%</span> <span>end</span> <span>%&gt;</span>

    <span>&lt;div</span> <span>class=</span><span>"field"</span><span>&gt;</span>
      <span>&lt;%=</span> <span>form</span><span>.</span><span>label</span> <span>:style</span> <span>%&gt;</span>
      <span>&lt;%=</span> <span>form</span><span>.</span><span>text_field</span> <span>:style</span><span>,</span> <span>"@blur"</span> <span>=&gt;</span> <span>"check($event.target.value)"</span> <span>%&gt;</span>
      <span>&lt;div</span> <span>ref=</span><span>"errorMessage"</span> <span>style=</span><span>"color: #C00"</span><span>&gt;&lt;/div&gt;</span>
    <span>&lt;/div&gt;</span>

    <span>&lt;div</span> <span>class=</span><span>"field"</span><span>&gt;</span>
      <span>&lt;%=</span> <span>form</span><span>.</span><span>label</span> <span>:color</span> <span>%&gt;</span>
      <span>&lt;%=</span> <span>form</span><span>.</span><span>text_field</span> <span>:color</span> <span>%&gt;</span>
    <span>&lt;/div&gt;</span>

    <span>&lt;div</span> <span>class=</span><span>"field"</span><span>&gt;</span>
      <span>&lt;%=</span> <span>form</span><span>.</span><span>label</span> <span>:runcible</span> <span>%&gt;</span>
      <span>&lt;%=</span> <span>form</span><span>.</span><span>check_box</span> <span>:runcible</span> <span>%&gt;</span>
    <span>&lt;/div&gt;</span>

    <span>&lt;div</span> <span>class=</span><span>"actions"</span><span>&gt;</span>
      <span>&lt;%=</span> <span>form</span><span>.</span><span>submit</span> <span>%&gt;</span>
    <span>&lt;/div&gt;</span>
  <span>&lt;%</span> <span>end</span> <span>%&gt;</span>
<span>&lt;/div&gt;</span>
</pre></td></tr></tbody></table></div></figure>

<p>Final observations:</p>

<ul>
  <li>I think this code is quite readable. You can look at the HTML and get a good
  sense of what the JavaScript will do. You can look at the JavaScript and get
  a good sense of what will happen in the HTML.</li>
  <li>I donâ€™t have to reason about JavaScript to know what the resulting HTML is
  going to be.</li>
  <li>This is easy to backtrace. If you â€œview sourceâ€� on this in a browser it is
  finding the corresponding partial in your Rails views and component in your
  JavaScript should be pretty easy.</li>
  <li>It is easy to see what is being passed to the JavaScript functions.</li>
  <li>I chose a naming scheme and setup that made sense to me, but there are a lot
  of different approaches that would work.</li>
  <li>Vue is a â€œprogressiveâ€� framework. That means that you can add more techniques
  as needed. If you want to evolve this into a single page application you can.
  If you want to add child components to this component you can. If you want to
  start using <a href="https://v3.vuejs.org/guide/single-file-component.html#introduction">single file components</a> you can (I like this tutorial: <a href="https://dev.to/vannsl/vue3-on-rails-l9d">https://dev.to/vannsl/vue3-on-rails-l9d</a>).</li>
  <li>Because the components are just objects with functions, it would be easy to
  extract this into something …</li></ul></article></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tad.thorley.dev/2021/01/31/vue-for-the-html-you-already-have.html">https://tad.thorley.dev/2021/01/31/vue-for-the-html-you-already-have.html</a></em></p>]]>
            </description>
            <link>https://tad.thorley.dev/2021/01/31/vue-for-the-html-you-already-have.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979894</guid>
            <pubDate>Sun, 31 Jan 2021 16:25:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What to Expect from Old Windows PC's]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25979810">thread link</a>) | @TLM275
<br/>
January 31, 2021 | https://cheapskatesguide.org/articles/end-of-life.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/end-of-life.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/end-of-life.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979810</guid>
            <pubDate>Sun, 31 Jan 2021 16:13:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub Should Start an App Store]]>
            </title>
            <description>
<![CDATA[
Score 807 | Comments 286 (<a href="https://news.ycombinator.com/item?id=25979774">thread link</a>) | @quaintdev
<br/>
January 31, 2021 | https://www.ankshilp.com/time_for_github_app_store/ | <a href="https://web.archive.org/web/*/https://www.ankshilp.com/time_for_github_app_store/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><header>
    <div>
        <p><a href="https://www.ankshilp.com/">
                <img id="home-image" src="https://www.ankshilp.com/images/avatar.png">
            </a>
        </p>
        
    </div>
    <hr>
</header>
<div>
    <div>
        <h2 id="github-should-start-an-app-store">GitHub Should Start An App Store</h2>
<p>Yesterday, Google suspended Elements - matrix chat app - from play store <a href="https://news.ycombinator.com/item?id=25965443">without any reasonable explanation</a>. I think this was an automated removal triggered by user reports or some other factors. The matrix team tried to reach out to them for explanation to no avail. We have seen this pattern in many cases now. Either it’s getting overwhelming for Google to monitor apps in its store or they don’t want apps like Elements which is decentralized to be on their store. The later mostly seems like a conspiracy theory and I think former is more true. In any case, it doesn’t make any sense for a single entity to govern what gets installed and not on billions of devices. A decentralized app store whould be best to fight this sort of suspensions but it’s far from reality at the moment. The alternative? GitHub App Store.</p>
<h3 id="but-why-github">But Why GitHub?</h3>
<p>Few reasons why I think GitHub is our best bet:</p>
<ol>
<li>They already host source code of millions of apps. Release integration should be trivial to implement.</li>
<li>Unlike Google they actually listen to their users. They were awesome during <a href="https://github.blog/2020-11-16-standing-up-for-developers-youtube-dl-is-back/">youtube-dl</a> debacle.</li>
<li>Backed by Microsoft. Microsoft has been playing good by the developers for years now. I trust them more than Apple and Google.</li>
<li>They could finally give the desktop the app store it deserves</li>
<li>This is a minor but users will be able to raise issues with developers directly instead writing comments over app pages which I think you would agree completely suck.</li>
</ol>
<p>They will have to create app store applications for major platforms along with provision to host closed source applications on their store and they should be good to go. Honestly I can not imagine any other player being more successful in app stores than GitHub.</p>
<p><em>Update: <a href="https://twitter.com/element_hq/status/1355663753380032512">Google has reinstated Elements</a></em></p>

    </div>

            </div>
        </div></div>]]>
            </description>
            <link>https://www.ankshilp.com/time_for_github_app_store/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979774</guid>
            <pubDate>Sun, 31 Jan 2021 16:07:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital Gardening: Growing ideas and projects]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25979766">thread link</a>) | @jackyzhao
<br/>
January 31, 2021 | https://blog.jzhao.xyz/posts/digital-gardening/ | <a href="https://web.archive.org/web/*/https://blog.jzhao.xyz/posts/digital-gardening/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mainText"><p>The first image that comes to my head when I hear the word ‘gardening’ is of a small plot with some leafy greens sprouting their heads from an earthy bed. A gardener tenderly shovels and removes unwanted weeds and pours water to nourish the plants he wants to grow. He takes care to make sure the soil isn’t too wet and that each plant has ample space to grow. When the time comes, he harvests each fruit and vegetable and makes sure to plant seeds so that he can repeat the process anew in a few weeks time.</p><p>A garden is a metaphor for a lot of things: growth, persistence, and the constant battle against entropy.</p><p>When I talk about digital gardening, I don’t mean digital gardening in the Stardew Valley or FarmVille sense. I mean gardening as in the tending and growth of my own ideas and projects on my own little plot of the world wide web — namely through my blog, personal site, and GitHub projects. After reading Joel Hook’s blog post on his own <a href="https://joelhooks.com/digital-garden">digital garden</a>, I’ve been thinking and reflecting on my own processes for managing my garden.</p><p>I wanted to use this blog post as a way for me to document said processes and, in a sort of meta-round-a-bout way, grow and refine this process further.</p><h2 id="the-garden-plot">The garden plot</h2><p>According to <a href="https://github.com/jackyzha0/blog/commit/74f7460c49a7c56acfadf3f8f1cdd892005ebed4">GitHub</a>, I first created this blog in late August of 2020. At the time, it was more of a novelty thing. I wanted to get off of Medium and onto my own platform where I had more fine-grained control over how I could present my work and how people discover it.</p><p>I spent a few hours building out my own Hugo theme, making it as frictionless as possible to write produce new content. I threw up a few of my old Medium blog posts just to see how it would look, and I was happy with it. However, even with the novelty of the blog, I had nothing to write about.</p><p>The plot was there; I just didn’t have anything to plant in it.</p><p><img src="https://blog.jzhao.xyz/img/plot_1.png" alt="The Garden Plot"></p><h2 id="planting-the-seeds">Planting the seeds</h2><p>If you have no seeds in your garden, the only things that will grow are weeds. I could barely remember the last time I read a book on my own time. Needless to say, garbage in, garbage out.</p><p>Over the summer, I began to read again. Technical write-ups, fiction novels, traversing into self-help, and memoirs. I started to read more about the state of the world and critically discuss these with family and friends. Reading helped me colour in the lines as to why we need to build in the first place. I started to realize that the problems we try so hard to solve with technology are not actually tech problems, but inherently human ones.</p><p>I’ve started to write more about some these ideas (like within this blog post!), at first to help me organize my own thoughts, but eventually segued into an excuse for me to talk to people about interesting ideas and get their perspective. It’s started a sort of chain reaction, with observations from a book leading to a conversation with a friend to a blog post ad infinitum. I’ve been able to slowly build up my <a href="https://blog.jzhao.xyz/posts/collaborative-thinking/">base of knowledge</a> so that I can contribute meaningfully to conversations.</p><p>These are the seeds I plant in my garden, but these seeds will stay seeds unless watered.</p><p><img src="https://blog.jzhao.xyz/img/plot_2.png" alt="Planting the seeds"></p><h2 id="watering-the-plants">Watering the plants</h2><p>I have a Notion page of random thoughts and ideas. Whenever I come across something interesting in a conversation or book or article, I file it away in this Notion page. Slowly, categories have appeared as blog posts, articles, and papers coalesce and self-organize.</p><p>This input of information – the water – is what allows the ideas to grow. Just as it’s not enough to just water a plant once and forget about it, I’ve found that in-taking information inconsistently is about as good as not doing it at all. To be an effective watering can, I need to be intentional and consistent with my watering.</p><p>My process of collecting random scraps of information first sprung up from coming across interesting blog posts on Reddit. I’d always just read a cool post, follow a few hyperlinks, nod to myself and say “huh”, and maybe forward it to a friend or two. While it may have been entertaining to read, I got no value out of it. Now that I’ve started cultivating this garden of ideas, I have a reason to be more intentional in how I sift through the information and be more mindful of what I’m actually taking away from each piece. Writing, specifically on this blog and on my newsletter (which you can subscribe to at the bottom of this page), has helped me to go back to more mature ideas and condense and refine them into something presentable and legible to others – quite literally picking the fruit of my labour.</p><blockquote><p>We are all constantly bombarded with information, a lot of it is really good information too, but the challenge is absorbing it and applying it to the context of our lives and careers. — Joel Hooks</p></blockquote><p>Now that I have all of these new-found ideas and tidbits of information, what do I do with them? Keep growing them forever? At some point on the <a href="https://towardsdatascience.com/intro-to-reinforcement-learning-the-explore-exploit-dilemma-463ceb004989">explore-exploit curve</a>, this knowledge should be applied to something in order to manifest it into something useful. The problem is, which ideas get priority of my time and effort?</p><p><img src="https://blog.jzhao.xyz/img/plot_3.png" alt="Watering the plants"></p><h2 id="pulling-weeds">Pulling weeds</h2><p>No garden has unlimited space or nutrition to go around. Maybe you have a bigger garden than most, but that doesn’t mean you can grow whatever you want silly-willy. Some will need more space than others and others you simply just cannot grow in the same garden plot.</p><p>Similarly, no one has unlimited time and energy they can put into projects and learning. I, unfortunately, have yet to fully learn this lesson. After having an empty plot for so long, having a little greenery show up has inspired me into a planting frenzy, trying to cram as much into the garden as possible.</p><p>I’m starting to step back and reflect on my current commitments and deciding to either to step down from things that I’m less passionate about to make more time and room to double down on the things I’m truly passionate about.</p><p><img src="https://blog.jzhao.xyz/img/plot_4.png" alt="Pulling weeds"></p><h2 id="end">End</h2><p>None of what I do is perfect. Looking back at writing from a year ago, reading code from a few months ago even, makes me cringe a little. Like any garden, this one evolves and grows over time; there is no ‘end-state’ that I’m trying to get the garden to. This little garden is just a little place for me to experiment, to push out things that I’m working on, and to provide snapshots of all the in-progress things going on in my life.</p><p>Through tending to this garden in public, I hope to show my success, failures, and everything in between and offer it as an open garden to learn from for anyone who stumbles upon it in the future. If just one person is inspired by it, learns from a mistake I made, or builds off of my work, then I would consider this garden a success.</p><p>Maybe you’ll find this as an incentive to start your own.</p></div></div>]]>
            </description>
            <link>https://blog.jzhao.xyz/posts/digital-gardening/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979766</guid>
            <pubDate>Sun, 31 Jan 2021 16:06:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Robinhood disabled buys but not sells]]>
            </title>
            <description>
<![CDATA[
Score 699 | Comments 677 (<a href="https://news.ycombinator.com/item?id=25979673">thread link</a>) | @stu2b50
<br/>
January 31, 2021 | https://stu2b50.dev/posts/why-robinhood-d3580b | <a href="https://web.archive.org/web/*/https://stu2b50.dev/posts/why-robinhood-d3580b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="layout">
      <div id="main">
        

    

    <div>
        <p>There's been enough time for the dust to settle and for Robinhood's actual reason for halting trades to come out. But the question of why only buys and not sells has not really been answered in detail, and that's mainly because it's a pain-in-the-ass and delves deep into how the deposit requirements are calculated by the DTCC for brokers. </p>
<h2>First, what happened</h2>
<p>On that fateful day, Gamestop stock had massive volatility, and given the cries of "Buy!" and "Hold!" from /r/WSBs, I'd assume on Robinhood, a broker targeted at retail investors, it'd be heavily imbalanced towards buy trades.</p>
<p>As volatility increased, the DTCC (Depository Trust &amp; Clearing Corporation) increased the deposit requirements for brokers. Basically, when you submit a trade on a broker, the exchange of money for stock doesn't actually happen until 2 days later, and the firm that handles that exchange is called a clearing firm. Before then, Robinhood just sends records: John bought 2 GME for $600, Mary sold 1 GME for $290. If that's all that happened that day, then Robinhood would need to provide $310 dollars to the clearing firm, and receive 1 stock.</p>
<p>That's a credit risk - what if Robinhood doesn't have the money on settlement? The clearing firm would be on the hook. So the DTCC requires that brokers put up a deposit beforehand. On that day, the DTCC massively increased the deposit requirements for brokers</p>
<blockquote>
<p>A spokesman for the DTCC wouldn’t specify how much it required from specific firms but said that by the end of the day industrywide collateral requirements jumped to $33.5 billion, up from $26 billion.</p>
</blockquote>
<p><a href="https://www.bloomberg.com/opinion/articles/2021-01-29/reddit-traders-on-robinhood-are-on-both-sides-of-gamestop">Levine</a></p>
<blockquote>
<p>The amount required by clearinghouses to cover the settlement period of some securities rose tremendously this week. How much? To put it in perspective, this week alone, our clearinghouse-mandated deposit requirements related to equities increased ten-fold. </p>
</blockquote>
<p><a href="https://blog.robinhood.com/news/2021/1/29/what-happened-this-week">Robinhood</a></p>
<p>So, Robinhood legally could not submit trades on $GME until they could muster the deposits for GME that they needed. And they quickly <a href="https://www.cnn.com/2021/01/29/investing/robinhood-gamestop-reddit/index.html">scrounged up some capital</a> so they could continue on Friday.</p>
<h3>Robinhood's Clearing Firm</h3>
<p>Robinhood actually has their own clearing firm, Robinhood Securities... for some reason, but it's still a DTCC member and must listen to what the SEC regulates. </p>
<h3>update 12:32 - On margin?</h3>
<p>Some people seem to be mistaking the situation. It is not about margin accounts - while yes, Robinhood "instant transfers" provides the illusion of being instant effectively with margin, it's not really the issue here.</p>
<p>Brokers cannot use client money to satisfy their clearing fund obligation.  So whether or not the accounts had a settled balance didn't matter - as you can see from the other brokers which halted buys and did not have "instant transfers".</p>
<p>Again, this is about what's effectively <em>collateral</em> the brokers must put up so that all parties can mitigate the risk of a broker failing. Of course client money is used when the transaction <em>settles</em>, but, naturally, you can't use their money, which isn't yours, as collateral.</p>
<h2>But why ONLY Buys?</h2>
<p>The deposit requirement is </p>
<p><code>deposit = min( 99% 2d VaR + Gap Risk Measure, Deposit Floor Calc) + Mark-to-Market</code></p>
<p>And the variable to look at is the 99% 2d VaR</p>
<blockquote>
<p>The volatility component is designed to capture the market price risk associated with each Member’s portfolio at a 99th percentile level of confidence. The VaR Charge is the volatility component applicable to most Net Unsettled Positions, and usually comprises the largest portion of a Member’s Required Deposit. Procedure XV of the Rules currently provides that the VaR Charge shall be calculated in accordance with a generally accepted portfolio volatility margin model utilizing assumptions based on reasonable historical data and an appropriate volatility range. As such, NSCC currently calculates a Member’s VaR Charge utilizing the VaR model, which incorporates an EWMA volatility
estimation. </p>
</blockquote>
<p><a href="https://www.sec.gov/rules/sro/nscc-an/2018/34-82631.pdf">SEC</a></p>
<p>Remember when I subtracted John's buys of $600 with Mary's sell of $290 to get $310? That's the broker's net unsettled cash positions. The 99% VaR is basically, "99% of the time the broker's net unsettled will not be higher than X". You might remember if you took statistics about confidence intervals; this is the upper 99% confidence interval.</p>
<h3>Bad Desmos Graphs</h3>
<p>So, let's model our risk as a Normal curve, for simplicity's sake. Here I've graphed a normal distribution with a line representing the 95% percentile</p>
<p><img src="https://stu2b50.dev/images/get/why-robinhood-d3580b/r1.png" alt=""></p>
<p>The Y axis is probability, the X axis is Robinhood's net unsettled positions. The more positive, the more money they'd owe theoretically.</p>
<p>Now, what happens if more people buy than sell? Then it'd shift over to the right</p>
<p><img src="https://stu2b50.dev/images/get/why-robinhood-d3580b/r2" alt=""></p>
<p>Hasn't the 95% percentile moved rightward as well? Now, what happens if the market is super volatile (i.e, the std dev of the distribution increases)</p>
<p><img src="https://stu2b50.dev/images/get/why-robinhood-d3580b/r3" alt=""></p>
<p>Wow, now it's even more to the right! </p>
<p>As you can see, <strong>buys make this worse</strong>, <strong>sells make it better</strong>. Robinhood <em>could not</em> execute buys, because it would increase the deposits they'd need, which they legally must obligate by.  Sells, on the other hand, do not have this problem. They would not push the 95% boundary more to the right.</p>
<h2>The Decision</h2>
<p>So really, it's not a bad decision or good decision that Robinhood halted buys of GME - it wasn't a decision, and it wasn't something they alone did.</p>
<p>These brokers halted buys of GME</p>
<ul>
<li>Robinhood</li>
<li>Webull</li>
<li>M1 Finance</li>
<li>Public</li>
<li>E-Trade</li>
</ul>
<p>While others only halted options</p>
<ul>
<li>Interactive</li>
<li>TDA</li>
<li>Schwab</li>
<li>Tradeing212</li>
</ul>
<p>Hmm, see a pattern? The former group includes companies like Robinhood (2013), WeBull (2017), M1 Finance (2015), while the latter has TDA (1975), Schwab(1971), Trading212 (2004).</p>
<p>(Okay, E-Trade is actually old too, but I guess they're just cash-strapped right now?)</p>
<p>Looks like young brokers with a limited capital resources to me.</p>
<h2>Stay or Switch?</h2>
<p>If there's something to fault Robinhood, it's that they're a young, janky broker (and also you might be getting screwed on the spread by Citadel). If they had more money on-hand they might not have had to stop buys of Gamestop. Perhaps they should have expected this and raised more capital earlier. </p>
<p>And that's a real reason to stay away from Robinhood. But for the love of god do not swap to WeBull or something if that's your concern.</p>
<p>And don't do it because you're abhorred by Robinhood's class warfare or something. Because that didn't happen - it was a mixture of SEC regulations and a cash-strapped startup (well, cash-strapped on big broker scales).</p>
<p>Although if you want to get mad at Hedge Funds anyway, feel free! You should always be mad at Hedge Funds. But please pick a real reason - you have no lack of choice to pick from.</p>

    </div>
  

      </div>
    </div></div>]]>
            </description>
            <link>https://stu2b50.dev/posts/why-robinhood-d3580b</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979673</guid>
            <pubDate>Sun, 31 Jan 2021 15:55:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From catching up to getting ahead: an Emacs wishlist]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25979530">thread link</a>) | @mpereira
<br/>
January 31, 2021 | https://www.murilopereira.com/emacs-from-catching-up-to-getting-ahead/ | <a href="https://web.archive.org/web/*/https://www.murilopereira.com/emacs-from-catching-up-to-getting-ahead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>What does Emacs need for us to someday run M-x neuralink-mode and evaluate Lisp in the brain?</p><div><p>I started using <a href="https://github.com/mpereira/.emacs.d/commit/30024f963ed794ec3a4c41229dbd4fab81f9b912">Emacs</a> almost exactly four years ago, after almost a decade
of <a href="https://github.com/mpereira/.vim">Vim</a>. I made the switch cold turkey. I vividly remember being <em>extremely</em>
frustrated by unbearable slowness while editing a Clojure file at work.
With no sane way of debugging it, just moving the cursor up and down would
result in so much lag that I had to step away from the computer to breathe
for a while. When I came back I quit Vim (I knew how at that point), opened
Emacs, and started building my configuration.</p><p>More recently, I’ve been very put off by the performance and stability (or
lack thereof) of building large scale software via Tramp. This has been
sufficient to have me looking out again. On a whim, I installed VSCode for
the first time and tried its “remote development” capabilities and holy
smokes are they good. Getting up and running was trivial and the
performance was great. Saving files was snappy and LSP worked out of the
box. What a different experience from my carefully-put-together,
half-working, slow Emacs setup.</p><p>My common denominator for rage-quitting software seems to be
consistent: <i>bad performance</i>.</p><p>There has recently been more discussion than usual regarding “modernizing”
Emacs, by making keybindings more consistent with other applications and
using more attractive color schemes and visuals, with the end goal of
attracting more users and by extension more contributors.</p><p>In my view improving these aspects of user experience wouldn’t hurt. The
way I see it, though, is that for Emacs to attract more users it needs to
be objectively better than the alternatives. And the way to do it is for
Emacs to become <em>even more</em> like Emacs.</p><p>I see Emacs as being fundamentally two things: a programmable runtime,
and a beacon for free software. I'm talking more about the former.</p><p>It needs to be a <em>more</em> robust, <em>more</em> efficient, and <em>more</em> integrated
platform with a <em>more</em> powerful extension language, to empower its users to
build their own environment.</p><p>Getting LSP integrated <em>pervasively</em> in Emacs in a way that it reliably
<em>just works</em> and performs well out of the box, would go a long way towards
making Emacs more attractive not just to new users, but to existing ones
too. Imagine an experience similar to VSCode’s:</p><ol><li>Open Emacs for the first time</li><li>Open a source code file</li><li>Emacs asks if you want it to configure itself for the programming
language of that source file</li><li>Saying “yes” automatically sets up Emacs to have a modern programming
environment for that programming language with smart code completion,
navigation, and refactoring, rich hover information, highlighting,
automatic formatting, snippets, etc. Maybe even open a side window with
a buffer with a short “getting started” tutorial showing the available
keybindings.</li></ol><p>Given enough users, opinionated community-built Emacs “distributions” like
Spacemacs, Doom, and Prelude will do the job of making it easier for
newcomers to get started with typical contemporary tasks: building software
with popular programming languages, writing documents, managing machines,
etc.</p><p>Building and maintaining these “distributions” also becomes much easier
given a more robust, more efficient, and more integrated platform with a
more powerful extension language.</p><p>Having a <a href="https://blog.polaris64.net/post/could-emacs-have-a-set-up-wizard/">wizard</a> showing up in new Emacs installations might be a great
low-hanging fruit way of making Emacs more accessible. Assuming buy-in from
core maintainers, the wizard could even directly reference popular Emacs
“distributions” like the ones mentioned above, so that new users can
kickstart their lives in Emacs.</p><p>The way to attract contributors can also be <em>stated</em> simply: directly improve
the contribution process.</p><p>Easier said than done.</p><p><a href="https://www.youtube.com/watch?v=VADudzQGvU8">Many</a> have created their Emacs <a href="https://www.jwz.org/doc/xemacs-wishlist.html">wishlists</a>. This is mine:</p><ol><li>Improved single-core efficiency</li><li>Improved display efficiency and rendering engine</li><li>Leveraging preemptive parallelism</li><li>Emacs Lisp improvements</li><li>Enhanced stability</li><li>Dealing with non-text</li><li>Improved contribution and development process</li></ol><p>Let’s get into it.</p><h2 id="1-dot-improved-single-core-efficiency">1. Improved single-core efficiency</h2><p>There are two dimensions to this:</p><ul><li>garbage collection efficiency</li><li>code execution efficiency</li></ul><p>For the past one and a half years, <a href="https://twitter.com/Koral%5F001">Andrea Corallo</a>, a compiler engineer,
has been <a href="https://akrl.sdf.org/gccemacs.html">working</a> on adding native compilation capabilities to the Emacs
Lisp interpreter. His work is available in a branch in the official Emacs
repository. Folks have been trying it out, and according to the reports
I’m hearing, the results are staggeringly positive. I am <em>very</em> excited
about Andrea’s work, which seems to bring enough improvement to the “code
execution speed” side of the equation to make it a non-issue for now.</p><p>Andrea’s work will also allow for more of Emacs to be implemented in Emacs
Lisp itself (instead of C), which is what most contributors are used to.
This is a great win for maintainability and extensibility: incrementally
having more and more of Emacs be implemented in the language with which
it’s extended.</p><p>The garbage collector is still in much need of improvement. Many resort to
hacks to ameliorate frequent and sometimes long pauses that seem to be
unavoidable while working on large git repositories, fast-scrolling
font-locked Eshell buffers, displaying dynamically updating child frames,
navigating big Org files, and many other tasks.</p><p><span>Also, try this out:</span> <code>(setq garbage-collection-messages t)</code></p><h2 id="2-dot-improved-display-efficiency-and-rendering-engine">2. Improved display efficiency and rendering engine</h2><p>The display implementation in Emacs core is… less than ideal.</p><blockquote><p>GNU Emacs is an old-school C program emulating a 1980s Symbolics Lisp
Machine emulating an old-fashioned Motif-style Xt toolkit emulating a
1970s text terminal emulating a 1960s teletype. Compiling Emacs is a
challenge. Adding modern rendering features to the redisplay engine is a
miracle.</p><p>— <a href="https://www.facebook.com/notes/daniel-colascione/buttery-smooth-emacs/10155313440066102/">Daniel Colascione in “Buttery Smooth Emacs” (2016)</a></p></blockquote><p>It would be great if Emacs did like Neovim and decoupled the editor
runtime from the display engine. This would make it possible for the
community to build powerful <a href="https://neovim.io/news/2020/10/#guis">GUIs</a> without having to change <a href="https://raw.githubusercontent.com/emacs-mirror/emacs/master/src/xdisp.c">Emacs core</a>,
possibly <a href="https://lwn.net/ml/emacs-devel/CAO2hHWbUmgirn1gJ4OGbRghhCkOPcEsL=moc82Q-6QO+C=189Q@mail.gmail.com/">using technology</a> <a href="https://lwn.net/ml/emacs-devel/E1jPGhC-0003i1-W4@fencepost.gnu.org/">not fully sanctioned</a> by core maintainers.</p><p>Take a look at the screenshots of these Neovim GUIs:</p><ul><li><a href="https://github.com/Kethku/neovide">neovide</a></li><li><a href="https://github.com/smolck/uivonim">uivonim</a></li></ul><p>They’re powerful, look great, perform well, and more importantly, are
based on industry standard, cross-platform graphics APIs (Vulkan and WebGL
respectively) that get lots of personpower contributions from companies
and individuals alike.</p><p>The <a href="https://www.patreon.com/posts/40303878">Onivim</a> and <a href="https://github.com/xi-editor/xi-editor">Xi</a> text editors could also be sources of inspiration:</p><ul><li>Separating the core runtime from the user interface</li><li><a href="https://en.wikipedia.org/wiki/Rope%5F(data%5Fstructure)">Ropes</a> for faster incremental changes and parallelization of text
operations</li><li>Game-like drawing pipelines</li></ul><h2 id="3-dot-leveraging-preemptive-parallelism">3. Leveraging preemptive parallelism</h2><p>Emacs does not support parallel code execution via multi-core processing.
Code execution happening on any buffer will freeze the whole program,
preventing not only user interaction but other cooperative threads of
execution from making progress as well.</p><p>Adding parallelism to Emacs in a way that automatically makes existing
code run in parallel is about as close to impossible as it can get. What
would be more feasible is including new primitives for parallel execution
that new code could leverage, to build more powerful extensions to Emacs.</p><p><a href="https://github.com/emacs-ng/emacs-ng">Emacs-ng</a> is a recent effort that implements just that: an additive layer
over Emacs that brings not only parallelism, but also asynchronous I/O
capabilities via an embedded <a href="https://deno.land/">Deno</a> runtime, and GPU-based rendering via
<a href="https://github.com/servo/webrender">WebRender</a>. I am <em>super</em> excited about the very fast progress from the folks
working on emacs-ng, and I think the project holds great promise for the
future of Emacs itself.</p><p>There also seems to be advances in the area of immutable data structures
that could be leveraged by the Emacs core, as seen in “<a href="https://public.sinusoid.es/misc/immer/immer-icfp17.pdf">Persistence for the
Masses: RRB-Vectors in a Systems Language</a>”. Persistent data structures
would make building thread-safe parallel code much easier.</p><h2 id="4-dot-enhanced-stability">4. Enhanced stability</h2><p>It is very easy to either freeze Emacs or cause it to run very slowly.
Multiple times a day I have to hit <code>C-g</code> incessantly to bring it back from
being frozen. When that fails, I am sometimes able to get it back with
<code>pkill -SIGUSR2 Emacs</code>. At least once per week I have to <code>pkill -9 Emacs</code>
because it turned completely unresponsive. I suspect doing more work
outside of the main thread might help with this?</p><p>There are many hacks to ameliorate issues caused by long lines, but
they’re still fundamentally there. Advancements in the “display efficiency
and rendering engine” effort would help with this too.</p><p>I recently tried a package that displays pretty icons on completion
prompts, and noticed that it made scrolling through candidates really
slow. Profiling showed that the package was creating thousands of <a href="https://www.gnu.org/software/emacs/manual/html%5Fnode/elisp/Idle-Timers.html">timers</a>,
which were somehow causing the issue. There are lots of cases like this,
where folks attempt to create something nice, but inevitably have to
resort to <a href="https://github.com/domtronn/all-the-icons.el/issues/113">hacks</a> to either achieve acceptable performance, or to be able to
implement the thing at all. Having a more robust/efficient/integrated core
with a more powerful extension language would help here.</p><p>Impressive efforts from folks like Lars Ingebrigtsen who routinely comes
in and <a href="https://lars.ingebrigtsen.no/2020/10/26/5x10/">obliterates 10% of all reported Emacs bugs</a> also have a sizable
impact. We users should follow the lead and do a better job not only
creating good bug reports but also dipping in our toes and helping out:
fixing bugs, writing tests, and documentation.</p><p>Yuan Fu recently wrote a <a href="https://archive.casouri.cat/note/2020/contributing-to-emacs/">nice guide</a> for contributing to Emacs.</p><h2 id="5-dot-emacs-lisp-improvements">5. Emacs Lisp improvements</h2><p>Emacs Lisp is a much better language than Vimscript. Unfortunately, that’s
not saying much. It’s not a particularly good Lisp and has lots of room
for improvement.</p><blockquote><p>For example, if you want to use a map, you have three choices: you can use
alists, plists or hash maps. There are no namespaces in Emacs Lisp, so for
each of the three data types you get a bunch of functions with weird
names. For alists get is <code>assoc</code> and set is <code>add-to-list</code>, for hash maps get
is <code>gethash</code> and set is <code>puthash</code>, for plists get is <code>plist-get</code> and set is
<code>plist-put.</code> For each of those types it …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.murilopereira.com/emacs-from-catching-up-to-getting-ahead/">https://www.murilopereira.com/emacs-from-catching-up-to-getting-ahead/</a></em></p>]]>
            </description>
            <link>https://www.murilopereira.com/emacs-from-catching-up-to-getting-ahead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979530</guid>
            <pubDate>Sun, 31 Jan 2021 15:34:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IoT Network Watches You as You Shop – Without Cameras]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 44 (<a href="https://news.ycombinator.com/item?id=25979480">thread link</a>) | @adunk
<br/>
January 31, 2021 | https://www.thingsquare.com/blog/articles/iot-mesh-retail/ | <a href="https://web.archive.org/web/*/https://www.thingsquare.com/blog/articles/iot-mesh-retail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <section><p>Online retailers know a lot about how their customers are navigating their virtual stores. Offline retailers are not so&nbsp;lucky.</p>
<p>Together with consumer behavior experts <a href="https://b-clarity.com/2020/01/08/what-is-the-role-of-touching-in-store/" target="_blank">B:Clarity</a> and a multinational home appliance brand we built a system to help understand customer movement and&nbsp;behavior.</p>
<p>The system consists of wireless sensors that are installed in electronics stores. A few hundred sensors in each&nbsp;store.</p>
<p>There are two types of&nbsp;sensors:</p>
<ul>
<li>Vibration sensors. That trigger when someone is trying out a&nbsp;product.</li>
<li>Light sensors. Trigger when someone is standing in front of a&nbsp;product.</li>
</ul>
<p>With these sensors, we can see what items are most popular, how it correlates to sales data – and how to take action to improve&nbsp;sales.</p>
<p>But without collecting any <a href="https://en.wikipedia.org/wiki/Personal_data" target="_blank">personally identifiable information</a>.</p>
<p>This is what the sensors look&nbsp;like:</p>
<div>
<div data-animation="quicksand" data-x-gap="16" data-y-gap="16" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 2},
{&quot;width&quot;: 1100, &quot;cols&quot;: 2},
{&quot;width&quot;: 800, &quot;cols&quot;: 2},
{&quot;width&quot;: 480, &quot;cols&quot;: 2},
{&quot;width&quot;: 300, &quot;cols&quot;: 2}
]">

<p><a href="https://www.thingsquare.com/blog/articles/iot-mesh-retail/sensor1.jpg" data-title="Laptops with IoT shopping sensors">
<img width="704" height="938" data-src="sensor1.jpg" alt="Laptops with IoT shopping sensors" src="https://www.thingsquare.com/blog/articles/iot-mesh-retail/sensor1.jpg">
<span>
<span>
<span></span>
</span>
</span>
</a>
</p>


<p><a href="https://www.thingsquare.com/blog/articles/iot-mesh-retail/sensor2.jpg" data-title="Cleaning equipment with IoT shopping sensors">
<img width="661" height="881" data-src="sensor2.jpg" alt="Cleaning equipment with IoT shopping sensors" src="https://www.thingsquare.com/blog/articles/iot-mesh-retail/sensor2.jpg">
<span>
<span>
<span></span>
</span>
</span>
</a>
</p>

</div>
</div>


<p>And this is where they are&nbsp;installed:</p>



<h2 id="why-monitor-shoppers-">Why monitor&nbsp;shoppers?</h2>
<p>Online retailers and e-commerce has many ways to gain insight into their customers. Examples include seeing the <a href="https://help.shopify.com/en/manual/reports-and-analytics/shopify-reports/report-types/behaviour-reports#top-online-store-searches" target="_blank">toplist of searched-for items</a>, and the <a href="https://help.shopify.com/en/manual/reports-and-analytics/shopify-reports/report-types/behaviour-reports#top-online-store-searches-with-no-results" target="_blank">toplist of searched-for items with no results</a>.</p>
<p>Physical retailers don’t want to be left&nbsp;behind.</p>
<p>So many different ways to monitor shoppers in physical stores have been&nbsp;developed.</p>
<p>Amazon Go stores extensively <a href="https://techcrunch.com/2018/01/21/inside-amazons-surveillance-powered-no-checkout-convenience-store/" target="_blank">use cameras</a> to track everything that happens inside their&nbsp;stores.</p>
<p>Many stores provide free WiFi so that they can <a href="https://www.retaildive.com/spons/wi-fi-tracking-a-data-gold-mine-or-privacy-nightmare/572937/" target="_blank">track their customers</a>.</p>
<p>All these solutions have a big problem:&nbsp;privacy.</p>
<p>Cameras see everything – much more than they need. And this data is collected and stored. Free WiFi hotspots may capture all kinds of&nbsp;traffic.</p>
<p>This is an obvious privacy problem for the&nbsp;shoppers.</p>
<p>But it is not just a problem for the&nbsp;shoppers.</p>
<p>It also creates a major problem for the companies storing the data: <a href="https://techcrunch.com/2019/09/19/silicon-valley-terrified-california-privacy-law/" target="_blank">personally identifiable data is a liability</a>.</p>
<p>This is why we chose vibration sensors and light sensors. No liability from owning any personally identifiable&nbsp;information.</p>
<p>With only vibration and light, there simply is nothing there to identify individual&nbsp;shoppers.</p>
<div>
<div>
<div data-src="washingmachines.jpg">
<div>
<div>
<div>
<div>
<figure>
<svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 8 8" style="enable-background:new 0 0 8 8;" space="preserve">
<path d="M3,1.3C2,1.7,1.2,2.7,1.2,3.6c0,0.2,0,0.4,0.1,0.5c0.2-0.2,0.5-0.3,0.9-0.3c0.8,0,1.5,0.6,1.5,1.5c0,0.9-0.7,1.5-1.5,1.5
C1.4,6.9,1,6.6,0.7,6.1C0.4,5.6,0.3,4.9,0.3,4.5c0-1.6,0.8-2.9,2.5-3.7L3,1.3z M7.1,1.3c-1,0.4-1.8,1.4-1.8,2.3
c0,0.2,0,0.4,0.1,0.5c0.2-0.2,0.5-0.3,0.9-0.3c0.8,0,1.5,0.6,1.5,1.5c0,0.9-0.7,1.5-1.5,1.5c-0.7,0-1.1-0.3-1.4-0.8
C4.4,5.6,4.4,4.9,4.4,4.5c0-1.6,0.8-2.9,2.5-3.7L7.1,1.3z"></path>
</svg>
</figure>
<blockquote>
Our IoT shopper system uses simple sensors: vibration and light.
</blockquote>
</div>
</div>
</div>
</div>
</div>
</div>
</div>

<h2 id="understanding-shopper-behavior">Understanding shopper&nbsp;behavior</h2>
<p>As a shopper, you want to find the best products, and – ideally – pay the lowest possible&nbsp;price.</p>
<p>The retailers and producers have slightly different&nbsp;motivations:</p>
<ul>
<li>Brands want customer to buy their products, and not their&nbsp;competitors’</li>
<li>Retailers want to sell more&nbsp;products</li>
</ul>
<p>And when the motivations of shoppers, retailers, and brands align, business is made. And the more business, the better for&nbsp;all.</p>
<p>Understanding customer behavior is key to improving the experience for&nbsp;everyone.</p>
<p>The sensors detect when people are looking at items. And they report this immediately, so that we can see in real-time where shoppers&nbsp;are.</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
Shopper hotspots: the IoT mesh network collects its data in real-time, so that we can see where shoppers are – right now.
</small>
</p>
</div>
</div>
</div>

<p>But the data is also posted to a backend database. This lets us to more <a href="https://b-clarity.com/case/100-000-human-interactions-cant-be-wrong-touch-increases-sales/" target="_blank">in-depth, off-line analysis</a> of the data, see how it changes over time, and how it improves the&nbsp;sales.</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
The data is also stored in a backend database so that we can run powerful off-line analytics on the data.
</small>
</p>
</div>
</div>
</div>

<p>To be able to cover large electronics stores, we use a wireless IoT mesh&nbsp;network.</p>
<div>
<div>
<div>
<div>
<div>
<div>
<div>
<figure>
<svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 8 8" style="enable-background:new 0 0 8 8;" space="preserve">
<path d="M3,1.3C2,1.7,1.2,2.7,1.2,3.6c0,0.2,0,0.4,0.1,0.5c0.2-0.2,0.5-0.3,0.9-0.3c0.8,0,1.5,0.6,1.5,1.5c0,0.9-0.7,1.5-1.5,1.5
C1.4,6.9,1,6.6,0.7,6.1C0.4,5.6,0.3,4.9,0.3,4.5c0-1.6,0.8-2.9,2.5-3.7L3,1.3z M7.1,1.3c-1,0.4-1.8,1.4-1.8,2.3
c0,0.2,0,0.4,0.1,0.5c0.2-0.2,0.5-0.3,0.9-0.3c0.8,0,1.5,0.6,1.5,1.5c0,0.9-0.7,1.5-1.5,1.5c-0.7,0-1.1-0.3-1.4-0.8
C4.4,5.6,4.4,4.9,4.4,4.5c0-1.6,0.8-2.9,2.5-3.7L7.1,1.3z"></path>
</svg>
</figure>
<blockquote>
Electronics stores are large. But a wireless sub-GHz IoT mesh network can easily cover the entire area.
</blockquote>
</div>
</div>
</div>
</div>
</div>
</div>
</div>

<h2 id="why-use-a-wireless-iot-mesh-network-">Why use a wireless IoT mesh&nbsp;network?</h2>
<p>A wireless mesh network is a wireless network that automatically extend its&nbsp;range.</p>
<p>The Thingsquare IoT mesh network solution uses so-called <a href="https://www.thingsquare.com/blog/articles/what-is-subghz-networking/" target="_blank">sub-GHz wireless technology</a> that has way better range than traditional WiFi or&nbsp;Bluetooth.</p>
<p>But even with a longer range, it is not always&nbsp;enough.</p>
<p>Electronics stores can be very large. And there is plenty of metal inside them that hampers the wireless&nbsp;coverage.</p>
<p>A mesh network is the ideal technology in these&nbsp;situations:</p>
<ul>
<li><p><strong>Coverage</strong>. Electronics stores can be huge. With a mesh network, we can cover it&nbsp;all.</p>
</li>
<li><p><strong>It just works</strong>. No network planning is&nbsp;needed.</p>
</li>
<li><p><strong>Easy to install</strong>. Just put each device where it should&nbsp;be.</p>
</li>
<li><p><strong>Easy to maintain</strong>. If there are issues with coverage, just add extenders as&nbsp;needed.</p>
</li>
<li><p><strong>Robustness</strong>. If something changes, the network will automatically adapt and&nbsp;overcome.</p>
</li>
</ul>
<p>This is what the wireless mesh network typically looks&nbsp;like:</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
The IoT mesh network uses range extenders to cover the entire area of the electronics store.
</small>
</p>
</div>
</div>
</div>

<p>In this deployment, the mesh network used one access point and two extenders. Most device are able to reach the access point directly, but some chose to talk to one of the&nbsp;extenders.</p>
<h2 id="battery-life">Battery&nbsp;life</h2>
<p>The sensors are equipped with batteries: one coin-cell battery&nbsp;each.</p>
<p>The Thingsquare IoT mesh system is <a href="https://www.thingsquare.com/blog/articles/sensortag-power/" target="_blank">tailored for extreme low-power operation</a>. Extreme low-power operation in this case means that the sensors can go for several months one a single&nbsp;charge.</p>
<p>For example, the sensors are automatically turned off at night, to conserve their precious&nbsp;power.</p>
<p>But most importantly, the Thingsquare system continuously collects power consumption data from each and every&nbsp;sensor.</p>
<p>This data lets us see the exact behavior at any given time: are there any sensors that behave in a way that require their batteries to be replaced earlier? The Thingsquare system knows the answers to this, and alerts us if this would be the&nbsp;case.</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
Each sensor measures and reports a detailed break-down of their power consumption.
</small>
</p>
</div>
</div>
</div>

<h2 id="connectivity">Connectivity</h2>
<p>The ioT mesh network is connected to the Internet via a 4G modem. The network maintains a stable encrypted connection to the backend system so that the devices always can be&nbsp;reached.</p>
<p>If the Internet connection would go down at any point during the deployment, the devices hold off from reporting their data until the Internet connection is&nbsp;restored.</p>
<p>With this technique, no data is ever&nbsp;lost.</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
A vibration sensor installed on top of a washing machine.
</small>
</p>
</div>
</div>
</div>

<h2 id="technical-details">Technical&nbsp;details</h2>
<p>The software used in the project is the <a href="https://www.thingsquare.com/iot-platform/" target="_blank">Thingsquare IoT platform</a>, with its wireless mesh network and the backend controller in the&nbsp;cloud:</p>
<ul>
<li>Thingsquare’s IoT mesh <a href="https://www.thingsquare.com/blog/articles/what-is-subghz-networking/" target="_blank">Sub-GHz</a> radio&nbsp;technology</li>
<li>Thingsquare’s IoT mesh IPv6 networking and the <span>RPL</span> mesh routing&nbsp;protocol</li>
<li><span>TLS</span> end-to-end&nbsp;encryption</li>
<li><a href="https://www.thingsquare.com/blog/articles/channel-hopping/" target="_blank">Channel hopping</a> to avoid problematic radio&nbsp;channels</li>
<li>Cloud deployment on&nbsp;<span>AWS</span></li>
</ul>
<p>The project uses the following hardware&nbsp;components:</p>
<ul>
<li>The Texas Instrument <span>CC1350</span> wireless System-on-a-Chip (which is an earlier version of the current <a href="https://www.ti.com/tool/LPSTK-CC1352R" target="_blank"><span>CC1352R</span> SoC</a> that we currently&nbsp;use)</li>
<li>An <a href="https://invensense.tdk.com/products/motion-tracking/9-axis/mpu-9250/" target="_blank"><span>MPU9250</span> accelerometer</a> to detect&nbsp;vibrations</li>
<li>An <a href="https://www.ti.com/product/OPT3001" target="_blank"><span>OPT3001</span> digital ambient light sensor</a> to measure changes in lighting&nbsp;conditions</li>
</ul>
<h2 id="conclusions">Conclusions</h2>
<p>This project is a multi-year collaboration between a Thingsquare customer and a major multinational home appliance brand. Thingsquare is the technology partner, providing our wireless IoT technology and expertise to make the project come&nbsp;true.</p>
<p>Are you looking to build an IoT project with extreme requirements in terms of scale, coverage, or power consumption? <a href="#" data-modal-target="#start">Get in touch with us today</a> to see how we can help you make your project come&nbsp;true!</p>
</section>
        </div></div>]]>
            </description>
            <link>https://www.thingsquare.com/blog/articles/iot-mesh-retail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979480</guid>
            <pubDate>Sun, 31 Jan 2021 15:28:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rome in 3D]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25979436">thread link</a>) | @GizmoSwan
<br/>
January 31, 2021 | https://relivehistoryin3d.com/projects/rome-in-3d/ | <a href="https://web.archive.org/web/*/https://relivehistoryin3d.com/projects/rome-in-3d/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div id="primary"><main id="main" role="main"> <img src="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt.jpg" data-src="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt.jpg" alt="" width="1600" height="900" data-srcset="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt.jpg 1600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-600x338.jpg 600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-768x432.jpg 768w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-1024x576.jpg 1024w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-400x225.jpg 400w" data-sizes="(max-width: 1600px) 100vw, 1600px" srcset="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt.jpg 1600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-600x338.jpg 600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-768x432.jpg 768w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-1024x576.jpg 1024w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Rome-in-3D_opt-400x225.jpg 400w"><p>What is our “Rome in 3D” project in general? Broadly speaking, it is an attempt to give you an opportunity to take a look at Rome as it really was, by the eyes of humans who lived there in that time. Due to this, we are already paying much attention (and will proceed) to the level of details, adding realistic materials, colors, visual and weather effects. That’s why we are concentrating just on the center of the Rome for now, just to focus on quality and details.</p><p>Now we are planning to add a little additional territory (such as Circus Maximus, Velabrum area), and release our project as a 3d walkthrough application. I hope we will be able to complete it in a year approximately.</p> <img src="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt.jpg" data-src="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt.jpg" alt="" width="1600" height="900" data-srcset="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt.jpg 1600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-600x338.jpg 600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-768x432.jpg 768w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-1024x576.jpg 1024w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-400x225.jpg 400w" data-sizes="(max-width: 1600px) 100vw, 1600px" srcset="https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt.jpg 1600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-600x338.jpg 600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-768x432.jpg 768w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-1024x576.jpg 1024w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/Enscape_2019-10-16-22-47-45_opt-400x225.jpg 400w"><p>Boasting some impressive in-video lighting features, the animation focuses on the monumental scale that was flaunted by Rome during its apical architectural stage. And furthermore according to&nbsp; the animators of this video – this movie is just a promo, with the entire scope (which took years to animate) to be inducted into a game engine that would be accessible to the interested people.</p><figure id="attachment_92" aria-describedby="caption-attachment-92"><img src="https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt.jpg" data-src="https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt.jpg" alt="" width="1600" height="900" data-srcset="https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt.jpg 1600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-600x338.jpg 600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-768x432.jpg 768w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-1024x576.jpg 1024w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-400x225.jpg 400w" data-sizes="(max-width: 1600px) 100vw, 1600px" srcset="https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt.jpg 1600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-600x338.jpg 600w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-768x432.jpg 768w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-1024x576.jpg 1024w, https://relivehistoryin3d.com/wp-content/uploads/2019/11/BC_caldarium_opt-400x225.jpg 400w"><figcaption id="caption-attachment-92"><strong>Baths of Caracalla</strong></figcaption></figure><p>The « History in 3D » creative team continues working on a virtual reconstruction of ancient Rome. Our goal is to carry out this project at a new qualitative level using modern available data and technical capabilities. Some time ago, three video trailers about Rome in 3D reconstruction have already been released on our YouTube channel, representing the various stages of work on the reconstruction. Since the recent video was released, a lot of work has been done to update and expand the content, and we believe that the project has been transformed crucially and reached a new level of quality.</p><p>Here, our 3rd trailer about Colosseum district:<br></p><center><br> <iframe title="&quot;HISTORY IN 3D&quot; - ANCIENT ROME 320 AD -  3rd trailer &quot;Walking around Colosseum&quot;" width="500" height="281" src="https://www.youtube.com/embed/btKooS7k3nw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br></center><br> &nbsp;<hr><h2>Recent project articles</h2><div><p><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src=""></p>   </div></main></div></div></div>]]>
            </description>
            <link>https://relivehistoryin3d.com/projects/rome-in-3d/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979436</guid>
            <pubDate>Sun, 31 Jan 2021 15:22:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First Principles as a Life Strategy]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25979431">thread link</a>) | @Bluestein
<br/>
January 31, 2021 | https://vineet.bearblog.dev/first-principles/ | <a href="https://web.archive.org/web/*/https://vineet.bearblog.dev/first-principles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>Pioneered 2000 years ago by Aristotle and popularized most recently by Elon Musk, <em>First Principles</em> is a method of reasoning which involves breaking down a complex problem into its most fundamental parts and reasoning upwards from there.</p>
<p>In his interview with Kevin Rose, Musk says:</p>
<blockquote>
<p>“It’s important to reason from first principles rather than by analogy. So the normal way we conduct our lives is, we reason by analogy. We are doing this because it’s like something else that was done, or it is like what other people are doing… with slight iterations on a theme. And it’s … mentally easier to reason by analogy rather than from first principles. First principles is kind of a physics way of looking at the world, and what that really means is, you … boil things down to the most fundamental truths and say, “okay, what are we sure is true?”</p>
</blockquote>
<p>Given his ubiquitous popularity in the mainstream culture, it is easy to forget that what Musk is doing is literally <em>unearthly</em>! Take a minute and read <a href="https://www.spacex.com/human-spaceflight/mars/">this page</a> on SpaceX's mission statement. It's hard to fathom how courageous, confident and clear one needs to be in their thinking, to come up with a plan to colonize Mars(!) and saying it publicly without the fear of being ridiculed. How does he do it?</p>
<p>He takes an insanely complicated problem, goes to the bottom of it and comes up with intuitive solutions which people before him never came up with because they reasoned by analogy. Notice how this theme of <em>first principles</em> based problem-solving underlies all of his work:</p>
<ul>
<li><p><strong>SpaceX</strong> — Space flight is crazy expensive. Why? Because we use new rockets for every launch. That sounds dumb. Let's find a way to make reusable rockets. To the layman it sounds obvious. But why didn't people before him question these basics? Lack of <em>first principles</em> based thinking.</p>
</li>
<li><p><strong>Tesla</strong> — Fuel-based automobiles are bad for the planet. Why can't people switch to electric cars? Because they are not battery efficient, lack performance and are often poorly designed. Boom! Tesla now builds some of the most good looking and fastest cars on the planet.</p>
</li>
<li><p><strong>The Boring Company</strong> — There's too much traffic on the road. Why? Human settlements are multiple storeyed. But human transport is still archaic and restricted to one plane. Let's change that by boring underground transportation tunnels.</p>
</li>
</ul>
<p>All of this sounds so damn obvious and it is hard to believe that people never questioned these basic premises in their fields. It is mind-blowing how restrictive reasoning by analogy can be.</p>
<h2 id="first-principles-approach-to-life">First Principles Approach to Life</h2>
<p>I know. <em>First principles</em> seems overly simplistic in theory. But trust me, it can be quite difficult to implement. Now I don't know how to make rockets like Elon but over time I have learned how to use <em>first principles</em> as a strategy for living life.</p>
<p>Living abroad and building your life from scratch in a new country is a great way to identify with these principles. In retrospect, I realise that the most fundamental elements of my life were often the things which I took for granted while living at home. Which included my physical and mental health, my friends and family, and a sense of belonging which your homeland provides.</p>
<p>Lockdown-induced self-introspection made 2020 a year of tremendous personal growth and I realised that I had made a lot of decisions in my personal and professional life which did not allign with my principles. But that's okay. We all get influenced by culture and the people around us. We try to replicate other people's life strategies because we see them working. Once you identify and build your life around your own principles, you quickly become unapologetic and make decisions without seeking external validation.</p>
<p>Imagine your life is a tree and every decision you make branches you out into the world. Now all trees branch out differently so it is futile to imitate the trees around you. Of course, you can get some idea about what kind of decisions lead you where but it is really stupid to shape yourself in somebody else's reflection. The reason why <em>first principles</em> drastically improves your decision making and life satisfaction is because every decision you take, every new branch you create, is strongly attached to your own core. Even if it doesn't work out, you will love it as your own.</p>
<p>As it often happens with people, your principles may change over time and that's okay. You can rebranch your tree gradually but honestly, I do believe that there are some core, non-negotiable principles to live a good life. These can also be a good starting point to create your own list of <em>first principles</em>. Here are three undeniable ones — taking care of your body, maintaining healthy relationships and doing satisfying work which pays the bills. Everytime I find myself in a rut, I reason upwards from here.</p>
<h2 id="first-principles-as-opposed-to-backwards-induction">First Principles as opposed to <em>Backwards Induction</em></h2>
<p>I have never found it useful to set specific goals. An unpopular opinion, I know. A notoriously flawed concept in self-improvement circles is the concept of S.M.A.R.T. goals. It is an acronym for goals which are specific, measurable, attainable, relevant and time-bound. This life strategy is a derivative of <em>Backwards Induction</em> way-of-reasoning where you take the end goal in mind and reason backwards from there. Personally, I've found this strategy to be too restrictive and given my temparament and personality-type, I have always enjoyed some amount of spontaneity in life. I like to diversify my interests, trying different things and adjusting my sails as I move forward making sure that I don't miss the forest for the trees. In Tim Minchin's words, "the disciplined pursuit of short-term goals."</p>
<p>I would rather aim to build systems which are in allignment with my principles. Instead of setting a goal to run a sub-4 hour marathon in 6 months, it is more sustainable to create a system which allows me to become a better runner. This means I run every other day, focus on recovery and nutrition, and push my self everyday without injuring myself. Since I don't care about the specifics, I am never dissapointed even if I fail to reach these arbitary metrics. You might say that every system inherently has a goal, no matter how vague. That is true. But the important point is not to make these goals <em>too</em> specific.</p>
<p>This way, reasoning by <em>first principles</em> clears your head, getting rid of assumptions, external influences and perceived limitations drastically improving life satisfaction.</p>
</div>
</div></div>]]>
            </description>
            <link>https://vineet.bearblog.dev/first-principles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979431</guid>
            <pubDate>Sun, 31 Jan 2021 15:21:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Delivering Software: The Product Management Triangle]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25979302">thread link</a>) | @mhay
<br/>
January 31, 2021 | https://blog.mariohayashi.com/delivering-software-product-management-triangle | <a href="https://web.archive.org/web/*/https://blog.mariohayashi.com/delivering-software-product-management-triangle">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blog.mariohayashi.com/delivering-software-product-management-triangle</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979302</guid>
            <pubDate>Sun, 31 Jan 2021 15:01:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On structured and unstructured data, or the case for cattrs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25979241">thread link</a>) | @luord
<br/>
January 31, 2021 | https://threeofwands.com/on-structured-and-unstructured-data-or-the-case-for-cattrs/ | <a href="https://web.archive.org/web/*/https://threeofwands.com/on-structured-and-unstructured-data-or-the-case-for-cattrs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><p>If you've ever gone through the Mypy docs, you might have seen the section on <a href="https://mypy.readthedocs.io/en/stable/more_types.html#typeddict">TypedDict</a>. The section goes on to introduce the feature by stating:</p>
<blockquote>
<p>Python programs often use dictionaries with string keys to represent objects. [...] you can use a TypedDict to give a precise type for objects like movie, where the type of each dictionary value depends on the key:</p>
</blockquote>
<pre><code>from typing_extensions import TypedDict

Movie = TypedDict('Movie', {'name': str, 'year': int})

movie = {'name': 'Blade Runner', 'year': 1982}  # type: Movie
</code></pre>
<p>In other words, TypedDict exists to make dictionaries a little more like classes (in the eyes of Mypy, in this particular case), and is only one example of a growing menagerie of similar efforts to make dictionaries classes.</p>
<p>In this post, I maintain that in modern Python classes already exist, are fit-for-purpose and dictionaries should just be left to be dictionaries.</p>
<h2 id="valueobjects">Value Objects</h2>
<p>Pretty much every application and every API has a notion of data models on some level. These are prime examples of <em>structured data</em> - pieces of information with a defined shape (usually the names and types of subfields). The TypedDict example from the introduction defines a data model with two fields. Let's call these pieces of data <strong>value objects</strong>. Value objects come in a million flavors on many different abstraction layers; they can range from a Django model to a class you define in a one-liner to be able to return multiple values from a function, to just a dictionary. Value objects usually don't have a lot of business logic attached to them so it might be a stretch calling some of these value objects, but let's roll with it here.</p>
<p>In Python, the most natural way of modeling value objects is a class; since an instance of a class is just that - a piece of structured data.</p>
<p>When the TypedDict docs claim that Python programs often use dictionaries to model value objects, they aren't incorrect. The reason for this is, however, that historically Python has not had good tools for using classes for value objects, not that dictionaries are actually good or desireable for this purpose. Let's look at why this is the case.</p>
<h2 id="jsonvalueobjects">JSON Value Objects</h2>
<p>One of the biggest reasons, I believe, is JSON, probably the most popular serialization format of our time. Python has great tools for converting a piece of JSON into unstructured data (Python primitives, lists and dictionaries) - there's a JSON library included in Python's standard library, and very robust, well-known and performant third-party JSON libraries. Pretty much all Python HTTP libraries (client and server) have special cases for easy handling of JSON payloads.</p>
<p>Now, take into account that the most straightforward way to model a value object in JSON is simply using a JSON object with fields corresponding to the value object fields. So, parsing the JSON payload <code>{"name": "Blade Runner", "year": 1982}</code> into a dictionary is extremely easy, and converting this into a proper Python value object much less so.</p>
<h2 id="modernpythonvalueobjects">Modern Python Value Objects</h2>
<p>Historically, creating Python value object classes and populating them with data from somewhere (like a JSON payload) has been very cumbersome. There have been three recent development in the broader Python ecosystem to make this much better.</p>
<h3 id="attrs">attrs</h3>
<p>We now have <code>attrs</code>. <code>attrs</code> is a Python library for declaratively defining Python classes, and is particularly amazing for modeling value objects. <code>attrs</code> itself has excellent docs and makes a great case against manually writing classes (which it whimsically calls <em>artisinal classes</em>) <a href="https://www.attrs.org/en/stable/why.html#hand-written-classes">here</a>. The example nicely illustrates the amount of code needed for a well-behaved value object. No wonder the Python ecosystem used to default to dictionaries.</p>
<p>A small note on dataclasses: the <code>dataclasses</code> module is basically a subset clone of attrs present in the Python standard library. In my opinion, the only use of dataclasses is if you don't have access to third-party libraries (i.e. <code>attrs</code>), for example if you're creating simple scripts that don't require a virtual environment or are writing code for the standard library. If you can use pip you should be using <code>attrs</code> instead, since it's just better.</p>
<h3 id="fieldleveltypeannotations">Field-level type annotations</h3>
<p>We now (since Python 3.6) have field-level type annotations in classes (aka <a href="https://www.python.org/dev/peps/pep-0526/">PEP 526</a>).</p>
<p>This makes it possible to define a value object thusly:</p>
<pre><code>@attr.define
class Movie:
    name: str
    year: int
</code></pre>
<p>The most important part of this PEP is that the type information for the value object fields is available at runtime. (Classes like this were possible before this PEP using type comments, but that's not usable in runtime.)</p>
<p>The field type information is necessary for handling structured data; especially any kind of nested structured data.</p>
<h3 id="cattrs">cattrs</h3>
<p>We now have <code>cattrs</code>. <code>cattrs</code> is my library for efficiently converting between unstructured and structured Python data. To simplify, <code>cattrs</code> ingests dictionaries and spits out classes, and ingests classes and spits out dictionaries. <code>attrs</code> classes are supported out of the box, but anything can be structured and unstructured. For example, the <a href="https://cattrs.readthedocs.io/en/latest/usage.html">usage docs</a> show how to convert Pendulum <code>DateTime</code> instances to strings, which can then be embedded in JSON.</p>
<p><code>cattrs</code> uses converters to perform the actual transformations, so the un/structuring logic is not on the value objects themselves. This keeps the value objects leaner and allows you to use different rules for the same value object, depending on the context.</p>
<p>So <code>cattrs</code> is the missing layer between our existing unstructured infrastructure (our JSON/msgpack/bson/whatever libraries) and the rich <code>attrs</code> ecosystem, and the Python type system in general. (<code>cattrs</code> goes to efforts to support higher-level Python type concepts, like enumerations and unions.)</p>
<p>I believe this functionality is sufficiently complex for it to have a layer of its own and that it doesn't really make sense for lower-level infrastructure (like JSON libraries) to implement it itself, since the conversion rules between higher-level components (like Pendulum <code>DateTime</code>s) and their serialized representations need to be very customizable. (In other words, there's a million ways of dumping <code>DateTime</code>s to JSON.)</p>
<p>Also, if the unstructured layer only concerns itself with creating unstructured data, the structuring logic can be in one place. In other words, if you use <code>ujson</code> + <code>cattrs</code>, you can easily switch to <code>msgpack</code> + <code>cattrs</code> later (or at the same time).</p>
<h2 id="puttingitalltouse">Putting it all to use</h2>
<p>Let's try putting this to use. Let's say we want to load a movie from a JSON HTTP endpoint.</p>
<p>First, define our value object in code. This serves as documentation, runtime information for cattrs, and type information for Mypy.</p>
<pre><code>@attr.frozen
class Movie:
    name: str
    year: int
</code></pre>
<p>Second, grab the unstructured JSON payload.</p>
<pre><code>&gt;&gt;&gt; payload = httpx.get('http://my-movie-url.com/movie').json()
</code></pre>
<p>Third, structure the data into our value object (this will throw exceptions if the data is not the shape we expect). If our data is not exotic and doesn't require manual customization, we can just import <code>structure</code> from <code>cattr</code> and use that.</p>
<pre><code>&gt;&gt;&gt; movie = cattr.structure(payload, Movie)
</code></pre>
<p>Done!</p>
<h2 id="addendumwhatshoulddictionariesactuallybeusedfor">Addendum: What should dictionaries actually be used for?</h2>
<p>The <code>attrs</code> docs already have a <a href="https://www.attrs.org/en/stable/why.html#dicts">great section on what dictionaries should be</a>, so I'll be short in adding my two cents.</p>
<p>If the value type of your dictionary is any sort of union, it's not really a dictionary but a value object in disguise. For the movie example, the type of the dictionary would be <code>dict[str, Union[str, int]]</code>, and that's a tell-tale sign something's off (and the raison d'etre for TypedDict). A true dictionary would, for example, be a mapping of IDs to <code>Movie</code>s (if movies had IDs), the type of which would be <code>dict[int, Movie]</code>. There's no way to turn this kind of data into a class.</p>
</div>
        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://threeofwands.com/on-structured-and-unstructured-data-or-the-case-for-cattrs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979241</guid>
            <pubDate>Sun, 31 Jan 2021 14:54:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Perpetual Storytelling Apparatus]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25979163">thread link</a>) | @uptown
<br/>
January 31, 2021 | https://www.allesblinkt.com/projects/perpetual-storytelling-apparatus/ | <a href="https://web.archive.org/web/*/https://www.allesblinkt.com/projects/perpetual-storytelling-apparatus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    
    <p>2009<br>
    Julius von Bismarck, Benjamin Maus</p>
  </header>

  <p>Drawing machine illustrating a never-ending story by the use of
patent drawings.</p>
  
  <figure>
    <p>
        
        
        <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/QYwPQxbYtc0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
        
    </p>
    
</figure>

<figure>
    

    
    
        <img src="https://www.allesblinkt.com/projects/perpetual-storytelling-apparatus/IMG_8354@article.jpg" alt="">
    

    
</figure>

<p>The “Perpetual Storytelling Apparatus” is a drawing machine illustrating a never-ending story by the
use of patent drawings. The machine translates words of a text (e.g. a novel) into a stream of patent
drawings. Eight million patents – linked by over 22 million references – form the vocabulary. By using
references to earlier patents, it is possible to find paths between the patents that have been found for
word-combinations in the story. Those connections form a subtext. New visual connections and narrative layers emerge through the interweaving of the story with the depiction of technical developments.</p>

<figure>
    

    
    
        <img src="https://www.allesblinkt.com/projects/perpetual-storytelling-apparatus/inventor@article.jpg" alt="References to the orginal patent document">
    

    
    <figcaption>
        <p>References to the orginal patent document</p>

    </figcaption>
    
</figure>

<figure>
    

    
    
        <img src="https://www.allesblinkt.com/projects/perpetual-storytelling-apparatus/IMG8351@article.jpg" alt="">
    

    
</figure>

<p><h2 id="principle">Principle</h2></p>

<figure>
    

    
    
        <img src="https://www.allesblinkt.com/projects/perpetual-storytelling-apparatus/explanation.ai.svg" alt="">
    

    
</figure>

<p>The apparatus takes a combination of words in the story and searches for a patent document, whose
text contains those words. Then it extracts the main drawing from the patent document and draws it.
Advancing in the story, it finds the next patent document. Between the found patent and the previously drawn patent, the patents that connect the two are drawn in between. This process repeats and ingests one story after another, and generates an endless stream of patent drawings.</p>

<figure>
    

    
    
        <img src="https://www.allesblinkt.com/projects/perpetual-storytelling-apparatus/edingurgh@article.jpg" alt="">
    

    
</figure>

<figure>
    

    
    
        <img src="https://www.allesblinkt.com/projects/perpetual-storytelling-apparatus/leute@article.jpg" alt="">
    

    
</figure>

<p>The first two instances of the “Perpetual Storytelling Apparatus” are using the database of the US Patent and Trademark Office. The third apparatus, which has recently been installed at the German Patent Office in Munich, uses the whole backlog of patents applied for in Germany.</p>

<figure>
    <p>
        
        
        <iframe src="https://player.vimeo.com/video/27330697" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
        
    </p>
    
    <figcaption>
        Details
    </figcaption>
    
</figure>

  

  
</article></div>]]>
            </description>
            <link>https://www.allesblinkt.com/projects/perpetual-storytelling-apparatus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979163</guid>
            <pubDate>Sun, 31 Jan 2021 14:43:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is how Google will collapse]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25979135">thread link</a>) | @partingshots
<br/>
January 31, 2021 | https://www.hccr.com/this-is-how-google-will-collapse/ | <a href="https://web.archive.org/web/*/https://www.hccr.com/this-is-how-google-will-collapse/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>
			<span itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
			   <span itemprop="url">https://www.hccr.com/wp-content/themes/osmosis/images/empty/thumbnail.jpg</span>
			   <span itemprop="height">150</span>
			   <span itemprop="width">150</span>
			</span>
						
			<span itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
				<span itemprop="name">HCCR - Human Capital Consulting Recruiting</span>
				<span itemprop="logo" itemscope="" itemtype="http://schema.org/ImageObject">
					<span itemprop="url">https://www.hccr.com/wp-content/themes/osmosis/images/empty/thumbnail.jpg</span>
				</span>
			</span>
						<time itemprop="datePublished" datetime="2019-07-17T14:39:52+09:00">July 17, 2019</time>
			<time itemprop="dateModified" datetime="2019-08-21T16:24:13+09:00">August 21, 2019</time>
			<span itemprop="mainEntityOfPage" itemscope="" itemtype="http://schema.org/WebPage" itemid="https://www.hccr.com/this-is-how-google-will-collapse/"></span>
		</span></p><div itemprop="articleBody">
				<p><img src="https://hccr.com/wp-content/uploads/2019/07/1_BGD9g1PoepfxaPn1Uxyzfg.jpeg" alt="" width="700" height="598" srcset="https://www.hccr.com/wp-content/uploads/2019/07/1_BGD9g1PoepfxaPn1Uxyzfg.jpeg 700w, https://www.hccr.com/wp-content/uploads/2019/07/1_BGD9g1PoepfxaPn1Uxyzfg-300x256.jpeg 300w" sizes="(max-width: 700px) 100vw, 700px" data-srcset="https://www.hccr.com/wp-content/uploads/2019/07/1_BGD9g1PoepfxaPn1Uxyzfg.jpeg 700w, https://www.hccr.com/wp-content/uploads/2019/07/1_BGD9g1PoepfxaPn1Uxyzfg-300x256.jpeg 300w" data-src="https://hccr.com/wp-content/uploads/2019/07/1_BGD9g1PoepfxaPn1Uxyzfg.jpeg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p><span>Google made almost all its money from ads. It was a booming business—until it wasn’t. Here’s how things looked right before the most spectacular crash the technology industry had ever seen.</span></p>
<p><span><strong><span>The crumbling of Google’s cornerstone</span></strong></span><br>
<span>Back when Google was still just an idea, its founders thought that “advertising funded search engines [would] be inherently biased towards the advertisers and away from the needs of the consumers.”</span></p>
<p><span>They changed their minds.</span></p>
<p><span>With that change, Google became one of the wealthiest, most powerful companies in history. Search was Google’s golden goose, as well as its only unambiguous win. So when Amazon rapidly surpassed Google as the top product search destination in 2017, Google’s foundations began to falter.</span></p>
<p><span>Amazon was fighting Google on its home turf, and it was winning. Even worse, the people turning to Amazon over Google for their shopping searches were from the most important group for advertisers and the future: young people. Advertisers followed them, and Amazon began to siphon away ad dollars that once went to Google search ads. Google’s mighty engine had started to sputter.</span></p>
<p><span><em>Google realized that it was hard to convince people who were used to getting something for free that they should now pay for it.</em></span></p>
<p><span>A shift from search to discovery also started to take shape in the late 2010s: When shoppers weren’t searching for things directly on Amazon, things were finding them. Advertisers realized that money previously spent on Google’s search ads was better spent either on Amazon ads or native ads in content feeds, like Instagram and Facebook. Google had no engaging content feeds, so it completely missed the wave, just like it had with social media and instant messaging.</span></p>
<p><span>Seeing the signs on the horizon, Google tried unsuccessfully to find revenue in areas other than advertising. Google struggled to make money with its hardware, cloud services, and wildly ambitious “Other Bets” categories.</span></p>
<p><span>For all its efforts, the money Google earned from its nonadvertising ventures only ever accounted for a mere 15% of their revenue. And revenue from Google’s moonshot “Other Bets” didn’t even cover a small fraction of the increasingly massive fines the company started to receive from looming regulators.</span></p>
<p><span><strong>The war on ads</strong></span><br>
<span>In late 2015, Apple—Google’s main competitor in the mobile space—added a feature to their devices that allowed users to block ads.</span></p>
<p><span>Devices running iOS were responsible for as much as 75% of Google’s revenue from mobile search ads, which is probably why Google was paying Apple billions of dollars every year to remain the default search engine on Apple devices. By making this move, Apple was simultaneously weighing in decisively on the great ad blocking debate of the 2010s and dealing a substantial blow to the future of online advertising.</span></p>
<p><span>This move from Apple reflected the unprecedented mainstream adoption of ad blocking software happening at the time. Having one of the biggest technology companies on the planet standing behind consumers only emboldened the movement.</span></p>
<p><span>Well over a quarter of desktop and laptop users in the United States were blocking ads by the year 2018. Those users would soon block ads on their mobile devices, too, as mobile ad block usage eclipsed desktop usage in 2017 and rose even faster.</span></p>
<p><img src="https://hccr.com/wp-content/uploads/2019/07/1_TxJ2u-DmfEfE7v86Z9RgNg.jpeg" alt="" width="1000" height="500" srcset="https://www.hccr.com/wp-content/uploads/2019/07/1_TxJ2u-DmfEfE7v86Z9RgNg.jpeg 1000w, https://www.hccr.com/wp-content/uploads/2019/07/1_TxJ2u-DmfEfE7v86Z9RgNg-300x150.jpeg 300w, https://www.hccr.com/wp-content/uploads/2019/07/1_TxJ2u-DmfEfE7v86Z9RgNg-768x384.jpeg 768w" sizes="(max-width: 1000px) 100vw, 1000px" data-srcset="https://www.hccr.com/wp-content/uploads/2019/07/1_TxJ2u-DmfEfE7v86Z9RgNg.jpeg 1000w, https://www.hccr.com/wp-content/uploads/2019/07/1_TxJ2u-DmfEfE7v86Z9RgNg-300x150.jpeg 300w, https://www.hccr.com/wp-content/uploads/2019/07/1_TxJ2u-DmfEfE7v86Z9RgNg-768x384.jpeg 768w" data-src="https://hccr.com/wp-content/uploads/2019/07/1_TxJ2u-DmfEfE7v86Z9RgNg.jpeg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p>Source: <a href="https://pagefair.com/blog/2017/adblockreport/">2017 Adblock Report/PageFair</a></p>
<p><span>Mobile ads were one of Google’s biggest areas of growth during its final years of domination, but people started to block mobile ads en masse once they realized that ads and tracking scripts were costing them as much as $23 per month in bandwidth and using up a significant portion of their battery life.</span></p>
<p><span>Research showed that 54% of users reported a lack of trust as their reason for not clicking banner ads, and 33% found them completely intolerable. The average banner ad was clicked on by a dismal 0.06% of viewers, and of those clicks, over 60% were accidental.</span></p>
<p><span>Even those who weren’t blocking ads had trained themselves to ignore them entirely. Researchers dubbed this phenomenon “banner blindness.”</span><br>
<span>The people most likely to block ads were also the most valuable to advertisers: millennials and high earners. Young users are a strong indicator for future trends, and they were heavy users of ad blocking software. Internet users had spoken, and they hated Google’s ads.</span></p>
<p><span>The ad blocking epidemic presented significant threats to Google’s business: People were getting used to using the internet without seeing ads, and Google was losing money every time their ads were blocked.</span></p>
<p><span>In early 2017, Google made the desperate, confusing, and legally questionable decision to add its own form of ad blocker to Chrome, but it did nothing except attract more antitrust regulation. It would quickly become clear to Google that even though ads were getting slightly better, ad blocking numbers would continue to rise.</span></p>
<p><img src="https://hccr.com/wp-content/uploads/2019/07/1__L_0UuwYZTraQ6TBxLUwjQ.jpeg" alt="" width="500" height="469" srcset="https://www.hccr.com/wp-content/uploads/2019/07/1__L_0UuwYZTraQ6TBxLUwjQ.jpeg 500w, https://www.hccr.com/wp-content/uploads/2019/07/1__L_0UuwYZTraQ6TBxLUwjQ-300x281.jpeg 300w" sizes="(max-width: 500px) 100vw, 500px" data-srcset="https://www.hccr.com/wp-content/uploads/2019/07/1__L_0UuwYZTraQ6TBxLUwjQ.jpeg 500w, https://www.hccr.com/wp-content/uploads/2019/07/1__L_0UuwYZTraQ6TBxLUwjQ-300x281.jpeg 300w" data-src="https://hccr.com/wp-content/uploads/2019/07/1__L_0UuwYZTraQ6TBxLUwjQ.jpeg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p>Source:&nbsp;<a href="https://pagefair.com/blog/2017/adblockreport/">2017 Adblock Report/PageFair</a></p>
<p><span>Later, in 2019, Google tried to make it harder for users to block ads in its then-dominant Chrome browser. All while Google was paying huge sums of money to let its ads through the most popular ad blocking software.</span></p>
<p><span>Google wasn’t willing to acknowledge the problems people had with the system they helped create, and it was clear that the company had no idea what to do when people started rejecting it. Too many people had become accustomed to a web without invasive banner ads following them around and slowing down every site they visited. Internet users had waged a war on ads, and Google was losing.</span></p>
<p><span><strong><span>An unprofitable behemoth</span></strong></span><br>
<span>A key platform where Google served ads was YouTube, which it bought in 2006 and quickly turned into one of its biggest entities. But even with a sixth of the world visiting this video-sharing behemoth every month, YouTube never became profitable.</span></p>
<p><span>While attempting to coax big brands and advertisers onto the platform in the hopes of finally turning a profit, YouTube misunderstood, alienated, and downright angered the creators and communities that had turned the platform into a global phenomenon.</span></p>
<p><span>In an attempt to combat the effect of ad blockers, Google launched an ad-free subscription model in late 2015, but the subscription numbers were underwhelming, and eventually, Google realized that it was hard to convince people who were used to getting something for free that they should now pay for it.</span></p>
<p><span>YouTube ads were interruptive and annoying to users, and the video-sharing site never proved to be as effective for brand awareness advertising as Google needed it to be. Global ad spend continued to move online from traditional media, but it wasn’t going to Google’s platforms.</span></p>
<p><span><strong><span>The turning tides</span></strong></span><br>
<span>Google’s products were free, innovative, and used by billions of people. In order to get access to these free products, people had to give up their personal data and their valuable attention. Google’s ads weren’t something its users wanted—they were simply a tax for accessing the Google ecosystem.</span></p>
<p><span>Google was enticing people into trading their privacy, data, and attention for the convenience of its amazing free products and services, some of which had no good alternatives. However, scandal after scandal after scandal proved that the trade might not be worth it, and people started to question what they were giving up by clicking “I agree.”</span></p>
<p><em><span>Every word uttered to Google Assistant, every action in any of Google’s numerous apps, and every data point about every one of their billions of users was stored and analyzed in the name of more accurate advertising.</span></em></p>
<p><span>And it wasn’t just Google’s users questioning the trade-off. Regulators and decision makers also finally started to understand how free internet products and services made money, and the companies behind them soon faced a long-awaited reckoning.</span></p>
<p><span>With its golden goose getting old, ad blocking rising, public opinion shifting, regulation closing in, and all of its ambitious bets on the future failing to make money, a lot was riding on Google’s next moves.</span></p>
<p><span>It made the wrong ones.</span></p>
<p><strong><span>How Google missed the chance to pivot</span></strong><br>
<span>If losing a major portion of their audience and annoying the rest wasn’t bad enough, Google also failed to get ahead of one of the biggest shifts in the internet’s history.</span></p>
<p><span>Google’s strategy since day one could be summed up as “aggregate and advertise,” as George Gilder put it in Life After Google. Every word uttered to Google Assistant, every action in any of Google’s numerous apps, and every data point about every one of their billions of users was stored and analyzed in the name of more accurate advertising.</span></p>
<p><span>Google’s business model was built on the foundational belief that in order to serve ads accurately, it had to collect and analyze as much data as possible from as many people as possible. This belief led the entire advertising industry to turn the web into a monstrosity of tracking and surveillance.</span></p>
<p><span>The holy grail of accurate advertising is perfect targeting and perfect attribution: getting an ad in front of the right people, knowing exactly when and where someone saw an ad, and being able to prove where credit is due when they make a purchase.</span></p>
<p><span>The entire industry was spinning its wheels chasing this vision, but eventually realized that its approach to the problem was completely backward. A vast, seedy, unfathomable landscape of tracking tendrils spanning the entire web would only ever overcomplicate things, ruin the user experience, and enable a staggering amount of ad fraud.</span><br>
<span>True attribution and accurate targeting used to be rocket science, black magic, and nearly impossible.</span></p>
<p><span>The breakthrough was this: If everything from interest matching to ad placement happened inside the user’s device, it would be possible to show the user ads they would actually find …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.hccr.com/this-is-how-google-will-collapse/">https://www.hccr.com/this-is-how-google-will-collapse/</a></em></p>]]>
            </description>
            <link>https://www.hccr.com/this-is-how-google-will-collapse/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979135</guid>
            <pubDate>Sun, 31 Jan 2021 14:40:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advice to My Younger Software Developer Self]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25979046">thread link</a>) | @jdhornby
<br/>
January 31, 2021 | https://joshhornby.com/blog/advice-to-my-younger-software-developer-self | <a href="https://web.archive.org/web/*/https://joshhornby.com/blog/advice-to-my-younger-software-developer-self">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<p>As I look back over what’s almost a decade in software development, there are some things I wish I’d started doing sooner. This is the advice I’d give my younger self, who has just landed their first professional software development job.</p>
<h2 id="1-read-more-books-on-software-development">1. Read more books on software development</h2>
<p>When ever I took the time to properly read a book (by properly I mean taking notes, consolidating my thoughts and re-reading) I leveled up.</p>
<p>I wish I had read more software related books at the start of my career as a developer. I’d recommend reading language agnostic books such as <a href="https://amzn.to/3ox1hOg" target="_blank">Clean Code: A Handbook of Agile Software Craftsmanship</a>, <a href="https://fi.ort.edu.uy/innovaportal/file/2032/1/design_principles.pdf" target="_blank">Design Principles and Design Patterns</a>, <a href="https://amzn.to/3ac7UR2" target="_blank">Soft Skills: The software developer’s life manual</a>. The ideas you will learn in these books translate to the majority of programming languages you will use through out your career.</p>
<p>It took me a long time to understand the value of taking notes whilst reading, it’s taken me even longer to start <a href="https://joshhornby.com/books">publishing these notes online</a>.</p>
<p>Why read books over blogs or videos? I’ve found returning to a book months or even years after you’ve read them and re-reading your notes is a great way to consolidate your thoughts. Although I read the majority of my book on a Kindle now, I still enjoy thumbing through a physical version of my favourite software books.</p>
<h2 id="2-sharing-my-thoughts-online">2. Sharing my thoughts online</h2>
<p>One of my biggest regrets is not sharing what I’ve learned or my experiences online sooner. Until recently I didn’t understand the value of building an audience online.</p>
<p>Although I’m <a href="https://twitter.com/joshua_hornby" target="_blank">working</a> <a href="https://6minutesoftwaredevelopment.com/" target="_blank">on</a> <a href="https://www.linkedin.com/in/joshhornby" target="_blank">rectifying</a> that currently, I often wonder where could I be if I started 1, 2 or 3 years ago? This reminds me of the quote “The best time to start was yesterday. The next best time is now.”</p>
<p>It’s common to vastly underestimate the value of your knowledge, don’t assume that what you know is common when it’s not. We just believe it is because we can’t imagine not knowing it.</p>
<h2 id="3-pair-with-other-developers-more-often">3. Pair with other developers more often</h2>
<p>I understand it can be daunting to pair with another developer, especially one who is more senior than you but looking back some of my biggest professional leaps came after pairing with developers I looked up to.</p>
<p>A pairing session can be as simple as sending someone a PR to review, and then sitting down with them to discuss their comments. In my experience you’ll gain more from discussing code with someone verbally than you would through comments on a screen.</p>
<p>A pleasant side effect of pairing is you form relationships with the developers you pair with. This can be useful when you’re new at a company, so don’t be afraid to ask to pair with someone.</p>
<div>
<h4>Join the newsletter</h4>
<p>Join my weekly newsletter containing some thoughts, life lessons and interesting content I discovered on the internet that week.</p>

</div>
<h2 id="4-spend-less-time-worrying">4. Spend less time worrying</h2>
<p>I was the worst at worrying about what might happen in the future. “What if I release this and break something?” or “Have I coded this in the correct way?”.</p>
<p>One thing that experience has taught me is it’s ok to make mistakes, and if you do make mistakes it’ll be ok. I understand it’s easy for me to say that now, but as of yet there is no issue that me or a team I’m working with has yet to solve.</p>
<p>Some advice for anyone who struggles to leave work behind when they leave the office:</p>
<ul>
<li>Find a hobby that doesn’t involve a computer, this could be taking up a sport or volunteering for example.</li>
<li>Before you finish work for the day, write down what you want to achieve tomorrow. I’ve found this task helps tell my brian “Work is finished for the day, time to switch off”</li>
</ul>
<h2 id="5-learn-to-communicate-effectively">5. Learn to Communicate Effectively</h2>
<p>Software development is a collaborative process where you work together as a team to achieve a common goal. Your communication skills need to be as good as your programming skills.</p>
<p>Communication comes in many forms, from reviewing pull-requests, discussing code solutions with peers to 1-on-1s with your manager. Some relatively easy wins to level up your communication skills are:</p>
<ul>
<li>
<p><a href="https://iridakos.com/programming/2019/06/26/composing-better-emails" target="_blank">Learning how to write better emails</a></p>
</li>
<li>
<p>How to say “No” effectively. You’ll often find you have too much work on your plate and sometimes need to push back, but how can you do this?</p>
<ol>
<li>Stay respectful to the to the individual requesting help.</li>
<li>Be straightforward regarding the reason why you are not able to assist.</li>
<li>Propose another option: Recommend someone they can turn to instead, or suggest an alternate source of information.</li>
<li>Approach your manager if you are consistently being given a high workload.</li>
</ol>
</li>
<li>
<p>Using the right language for your audience. If you are talking in detail about a bug to a fellow developer, feel free to be fully technical. Communicating to tech support, you can be technical about sysadmin stuff, but not include programmer-specific details.</p>
</li>
</ul>
<h2 id="6-build-more-things">6. Build more things</h2>
<p>Practice makes perfect. You can read all the books, or watch videos on particular technologies but if you really want to learn something new you need to try and build something. Unsure what you could work on?</p>
<ul>
<li>Pick a language you want to learn, and using a public API (<a href="https://pokeapi-graphiql.herokuapp.com/" target="_blank">Pokemon API</a>, <a href="https://reqres.in/" target="_blank">Fake REST-API</a>) create a CRUD application</li>
<li>Using a framework in your day job? Can you contribute to it? This can be as simple as documentation updates or helping other users with their issues.</li>
<li>Scratch your own itch. Build something that you’d find useful, it can be as simple as a CLI wrapper around a task you do every day.</li>
</ul>
<hr>
<span>
Published on <time datetime="2021-01-25T14:30:00+00:00">January 25, 2021.</time>
</span>
<div>
<h4>Join the newsletter</h4>
<p>Join my weekly newsletter containing some thoughts, life lessons and interesting content I discovered on the internet that week.</p>

</div>

</section></div>]]>
            </description>
            <link>https://joshhornby.com/blog/advice-to-my-younger-software-developer-self</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979046</guid>
            <pubDate>Sun, 31 Jan 2021 14:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good design is like a powerful GPU]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25979033">thread link</a>) | @hidden-spyder
<br/>
January 31, 2021 | http://eatlovecode.com/good-design-bad-design/ | <a href="https://web.archive.org/web/*/http://eatlovecode.com/good-design-bad-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-224" itemscope="itemscope" itemtype="http://schema.org/BlogPosting" itemprop="blogPost"><!-- .entry-header --><!-- .entry-meta --><div><p><span>When I first started as a designer, I thought frequently about experiences that were well-designed compared to those that were not, and how the outcome differed. What was the value of design? For example, when I click a button and expect a drop down menu to appear, I feel cognitive dissonance when the menu suddenly appears. When the menu slides out however, I feel more at ease. When I use a UI with a lot of jump-cuts (a la things suddenly appearing) my brain has to pretend that all the in-between frames are there. When we use interfaces that actually animate all those in-between frames, however, we can take a shortcut through our visual cortex. The change in interface no longer disrupts the main task.</span></p><p><span>Think of the human brain like a computer. You have first, a main thread, and second, a GPU – a graphics processing unit in your visual cortex. You can feed people a lot of information through their visual cortex without interrupting what they’re thinking about. Animation allows the user to continue thinking. Imagine using your smartphone without animations. It would be like a tap and jump cut for everything you do. Would you have still bought it?*</span></p></div> <br> <!--<div class="entry-meta-category entry-meta entry-meta-header"><ul><li> <span class="entry-meta-first-category"> <a href="http://eatlovecode.com/category/product-design/">Product Design</a> </span></li></ul></div> --><!-- .entry-content --><!-- <footer class="entry-meta entry-meta-footer"> This entry was posted in <a href="http://eatlovecode.com/category/product-design/" rel="category tag">Product Design</a>. Bookmark the <a href="http://eatlovecode.com/good-design-bad-design/" rel="bookmark">permalink</a>. --><!-- .entry-meta --></article></div>]]>
            </description>
            <link>http://eatlovecode.com/good-design-bad-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979033</guid>
            <pubDate>Sun, 31 Jan 2021 14:28:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ASCII Camera]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25979016">thread link</a>) | @kome
<br/>
January 31, 2021 | https://andrei.codes/ascii-camera/ | <a href="https://web.archive.org/web/*/https://andrei.codes/ascii-camera/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://andrei.codes/ascii-camera/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25979016</guid>
            <pubDate>Sun, 31 Jan 2021 14:25:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Counterfeiting Stock 2.0]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25978985">thread link</a>) | @punnerud
<br/>
January 31, 2021 | http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html | <a href="https://web.archive.org/web/*/http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<center><b>Counterfeiting Stock 2.0</b></center>

<p>
Illegal naked shorting and stock manipulation are two of Wall Street's deep, dark secrets. These practices have been around for decades and have resulted in trillions of dollars being fleeced from the American public by Wall Street. In the process, many emerging companies have been put out of business. This report will explain the magnitude of this problem, how it happens, why it has been covered up and how short sellers attack a company. It will also show how all of the participants; the short hedge funds, the prime brokers and the Depository Trust Clearing Corp. (DTCC)—make unconscionable profits while the fleecing of the small American investor continues unabated.
</p>
<p>
<span>Why is This Important?</span> This problem affects the investing public. Whether invested directly in the stock market or in mutual funds, IRAs, retirement or pension plans that hold stock — it touches the majority of Americans.
</p>
<p>
The participants in this fraud, which, when fully exposed, will make Enron look like child's play, have been very successful in maintaining a veil of secrecy and impenetrability. Congress and the SEC have unknowingly (?) helped keep the closet door closed. The public rarely knows when its pocket is being picked as unexplained drops in stock price get chalked up to “market forces” when they are often market manipulations.
</p>
<p>
The stocks most frequently targeted are those of emerging companies who went to the stock market to raise start–up capital. Small business brings the vast majority of innovative new ideas and products to market and creates the majority of new jobs in the United States. It is estimated that over 1000 of these emerging companies have been put into bankruptcy or had their stock driven to pennies by predatory short sellers. 
</p>
<p>
It is important to understand that selling a stock short is not an investment in American enterprise. A short seller makes money when the stock price goes down and that money comes solely from investors who have purchased the company's stock. A successful short manipulation takes money from investment in American enterprise and diverts it to feed Wall Street's insatiable greed—the company that was attacked is worse off and the investing public has lost money. Frequently this profit is diverted to off–shore tax havens and no taxes are paid. This national disgrace is a parasite on the greatest capital market in the world.
</p>
<p>
<span>A Glossary of Illogical Terms</span> — The securities industry has its own jargon, laws and practices that may require explaining. Most of these concepts are the creation of the industry, and, while they are promoted as practices that ensure an orderly market, they are also exploited as manipulative tools. This glossary is limited to naked short abuse, or counterfeiting stock as it is more correctly referred to. 
</p>

<ol>
<li><b>Broker Dealer or Prime Broker</b> — The big stockbrokers who clear their own transactions, which is to say they move transacted shares between their customers directly, or with the DTC. Small brokers will clear through a clearing house — also known as a broker's broker.
</li>
<li><b>Hedge Funds</b> — Hedge funds are really unregulated investment pools for rich investors. They have grown exponentially in the past decade and now number over 10,000 and manage over one trillion dollars. They don't register with the SEC, are virtually unregulated and frequently foreign domiciled, yet they are allowed to be market makers with access to all of the naked shorting loopholes. Frequently they operate secretively and collusively. The prime brokers cater to the hedge funds and allegedly receive eight to ten billion dollars annually in fees and charges relating to stock lend to the short hedge funds.
</li>
<li><b>Market Maker</b> — A broker, broker dealer or hedge fund who makes a market in a stock. In order to be a market maker, they must always have shares available to buy and sell. Market makers get certain sweeping exemptions from SEC rules involving naked shorting.
</li>
<li><b>Short Seller</b> — An individual, hedge fund, broker or institution who sells stock short. The group of short sellers is referred to as “the shorts.”
</li>
<li><b>The Securities and Exchange Commission</b> — The SEC is the federal enforcement agency that oversees the securities markets. The top–level management is a five–person Board of Governors who are Presidential appointees. Three of the governors are usually from the securities industry, including the chairman. The SEC adopted Regulation SHO in January 2005 in an attempt to curb naked short abuse.
</li>
<li><b>Depository Trust Clearing Corp</b> — Usually known as the DTCC, this privately held company is owned by the prime brokers and it clears, transacts and holds most stock in this country. It has four subsidiaries, which include the DTC and the NCSS. The operation of this company is described in detail later.
</li>
<li><b>Short Sale</b> — Selling a stock short is a way to make a profit while the stock price declines. For example: If investor S wishes to sell short, he borrows a share from the account of investor L. Investor S immediately sells that share on the open market, so investor S now has the cash from the sale in his account, and investor L has an IOU for the share from investor S. When the stock price drops, investor S takes some of the money from his account and buys a share, called “covering”, which he returns to investor L's account. Investor S books a profit and investor L has his share back.
<p>This relatively simple process is perfectly legal—so far. The investor lending the share most likely doesn't even know the share left his account, since it is all electronic and occurs at the prime broker or DTC level. If shares are in a margin account, they may be loaned to a short without the consent or knowledge of the account owner. If the shares are in a cash account, IRA account or are restricted shares they are not supposed to be borrowed unless there is express consent by the account owner.
</p></li>
<li><b>Disclosed Short</b> — When the share has been borrowed or a suitable share has been located that can be borrowed, it is a disclosed short. Shorts are either naked or disclosed, but, in reality, some disclosed shorts are really naked shorts as a result of fraudulent stock borrowing. 
</li>
<li><b>Naked Short</b> — This is an invention of the securities industry that is a license to create counterfeit shares. In the context of this document, a share created that has the effect of increasing the number of shares that are in the market place beyond the number issued by the company, is considered counterfeit. This is not a legal conclusion, since some shares we consider counterfeit are legal based upon today's rules. The alleged justification for naked shorting is to insure an orderly and smooth market, but all too often it is used to create a virtually unlimited supply of counterfeit shares, which leads to widespread stock manipulation—the lynchpin of this massive fraud. 
<p>
Returning to our example, everything is the same except the part about borrowing the share from someone else's account: There is no borrowed share — instead a new one is created by either the broker dealer or the DTC. Without a borrowed share behind the short sale, a naked short is really a counterfeit share.
</p></li>
<li><b>Fails–to–Deliver</b> — The process of creating shares via naked shorting creates an obvious imbalance in the market as the sell side is artificially increased with naked short shares or more accurately, counterfeit shares. Time limits are imposed that dictate how long the sold share can be naked. For a stock market investor or trader, that time limit is three days. According to SEC rules, if the broker dealer has not located a share to borrow, they are supposed to take cash in the short account and purchase a share in the open market. This is called a “buy–in,” and it is supposed to maintain the total number of shares in the market place equal to the number of shares the company has issued.
<p>
Market makers have special exemptions from the rules: they are allowed to carry a naked short for up to twenty–one trading days before they have to borrow a share. When the share is not borrowed in the allotted time and a buy–in does not occur, and they rarely do, the naked short becomes a fail–to–deliver (of the borrowed share).
</p></li>
<li><b>Options</b> — The stock market also has separate, but related markets that sell options to purchase shares (a “call”) and options to sell shares (a “put”). Options are an integral part of short manipulations, the result of SEC promulgated loopholes in Reg SHO. A call works as follows: Assume investor L has a share in his account that is worth $25. He may sell an option to purchase that share to a third party. That option will be at a specific price, say $30, and expires at a specific future date. Investor L will get some cash from selling this option. If at the expiration date, the market value of the stock is below $30 (the “strike price”), the option expires as worthless and investor L keeps the option payment. This is called “out of the money.” If the market value of the stock is above the strike price, then the buyer of the option “calls” the stock. Assume the stock has risen to $40. The option buyer tenders $30 to investor L and demands delivery of the share, which he may keep or immediately sell for a $10 profit.
</li>
<li><b>Naked call</b> — The same as above except that investor L, who sells the call, has no shares in his account. In other words, he is selling an option on something he does not own. The SEC allows this. SEC rules also allow the seller of a naked short to treat the purchase of a naked call as a borrowed share, thereby keeping their naked short off the SEC's fails–to–deliver list. A share of stock that has a naked call as its borrowed shares is marked as a disclosed short when it is sold, even though nobody in the transaction actually owns a share.
</li>
</ol>




<p>
<span>How The System Transacts Stocks</span> — This explanation has been greatly simplified in the interest of brevity. 
</p>

<img src="http://counterfeitingstock.com/CS2.0/diagram.png">

<ol>
<li><b>Customers</b> — These can be individuals, institutions, hedge funds and prime broker's house accounts.</li></ol></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html">http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html</a></em></p>]]>
            </description>
            <link>http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25978985</guid>
            <pubDate>Sun, 31 Jan 2021 14:19:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pascal Soriot: AstraZeneca's CEO on EU Vaccines Aggreement]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25978951">thread link</a>) | @elorant
<br/>
January 31, 2021 | https://www.repubblica.it/cronaca/2021/01/26/news/interview_pascal_soriot_ceo_astrazeneca_coronavirus_covid_vaccines-284349628/ | <a href="https://web.archive.org/web/*/https://www.repubblica.it/cronaca/2021/01/26/news/interview_pascal_soriot_ceo_astrazeneca_coronavirus_covid_vaccines-284349628/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            

                <div>
                  

    
        <!-- static_include: http://www.repstatic.it/cless/main/nazionale/2020-v1/include/detail/floating-sharebar.html -->
        
    <!--  include/detail/floating-sharebar -->

<!-- #end include/detail/floating-sharebar -->

    


                  <div id="article-body">
                    <!-- main-content-->
                    

<!-- TODO: middle1 -->

  

    
    <div>
        <p>LONDON. <strong>Mr Pascal Soriot, CEO of AstraZeneca, why hasn't AstraZeneca been more specific on detailing the supply problem detected on its European plants? What exactly is the problem? &nbsp;</strong></p>

<div><p>“I think we have been relatively specific with the information. Of course, we are all very disappointed. We would like to produce more. I think we will deliver up to Europe in the month of February a reasonable quantity actually, very similar to what others have delivered on a monthly basis. But of course, it's less than expected and also because our vaccine is easy to use people expected more so we could scale up.&nbsp;Our team is working 24/7 to fix the very much issues of production of the vaccine itself. You have two steps in the production of a vaccine: one is you produce the vaccine itself. We call it a drug substance, the vaccine. Then, when we are finished with it, we move this into different plants where we put the vaccine into vials and we call that the drug product, the final product.&nbsp;For Europe the drugs substance is essentially produced in two plants, one in the Netherlands, one in Belgium. The drug product is actually produced in Italy and Germany. So from a drug product viewpoint, we have full capacity. We have zero problem. The current problems have to do with manufacturing the drugs substance”. &nbsp;</p><p>
&nbsp;
“So maybe I need to give you a little bit of explanation as to how we manufacture those vaccines. Essentially, we have cell cultures, big batches, 1000-litre or 2000-litre batches. We have cell cultures inside those batches and we inject them with the virus, the vaccine, if you will. Then those cells produce the vaccine, it’s a biotechnology protection. Now, some of those batches have very high yield and others have low yield. Particularly in Europe, we had one site with large capacity that experienced yield issues. So it's essentially a question of when you scale up to the level we are scaling up to - &nbsp;something like this that's never been done. We are scaling up to hundreds of millions, billions of doses of vaccines at a very high speed".</p></div>

<div><p>“A year ago, we didn't have a vaccine. When you do that, you have glitches, you have scale-up problems. Therefore, the yield varies from one to three, by the factor of three. The best site we have produces three times more vaccine out of a batch than the lowest producing site. We do this with a series of partners: in the US, those partners are actually approved by BARDA, the US administration, the group that manages those things and manages the capacity”.</p></div><p>
"In the US, we also have issues of yield and essentially our engineers have worked with our partners to identify what the issues are. We believe we have sorted out the issues now. The issues are different, for instance, in Belgium: we believe it was more a question of downstream filtering because when you finish making the vaccine, you have to filter it. When you filter it, you put it into vials.&nbsp;Our partner in Australia for instance also had yield issues. And they have been in the vaccine business for 20 years. But it's complicated, especially in the early phase where you have to really kind of sort out all sorts of issues. We believe we've sorted out those issues, but we are basically two months behind where we wanted to be. We've had also teething issues like this in the UK supply chain.&nbsp;But the UK contract was signed three months before the European vaccine deal. So with the UK we have&nbsp; had an extra three months to fix all the glitches we experienced. As for Europe, we are three months behind in fixing those glitches. Would I like to do better? Of course. But, you know, if we deliver in February what we are planning to deliver, it's not a small volume. We are planning to deliver millions of doses to Europe, it is not small”.</p>

<div><p><strong>You say that EU is going to receive a reasonable quantity of doses by February. Could you please quantify this?</strong><br>
"First of all, as soon as we get an approval by EMA, in the next few days, we will be shipping at least three million doses immediately to Europe, then we'll have another shipment about a week later and then the third or fourth week of February. And the target is to deliver 17 million doses by February. So, I am just estimating roughly, that would mean like about 3 million doses for Germany, probably 2,5 million for Italy and something like 2 million for Spain. I don't know exactly what the precise allocation is, but it's based on the population of each country. If you're in Germany, you can vaccinate three million people in one month. It's actually not so bad especially for the people who are the most exposed and most at risk. That's not a small proportion. And if you apply the three month regimen, then in March, you can do the same again or more potentially because we are working hard to increase our goals. It's not as good as we would like to, but it's really it's not so bad”.</p><p>
&nbsp;
<strong>So Europe signed the contract too late, instead of the UK?</strong><br>
“I will not pass judgment on this. But I can only tell you the facts and the facts are that we basically signed an agreement with the UK three months before we did have it with Europe. Now, part of this can be easily explained. When we entered the agreement with Oxford, they had already been working with the UK government on this. So they had a head start. We were able to quite quickly take the UK supply chain and improve it. We had to modify the formula in the process, because Oxford gave us a process that needed to be modified to enable manufacturing at scale.&nbsp;Just think about, we've done all of this in months. Usually, it takes years. We got a manufacturing process that Oxford gave us, which was producing a good vaccine, but not at an industrial scale. It was just able to produce quantities for clinical trials. So then we had to modify the process to turn it into a process that could manufacture billions of doses. At a cost that is reasonable and at a speed that is reasonable".</p><p>
&nbsp;
"We had to change all of these. Then we had to do what we call technology transfer. So we go to each partner and we train them on the process. We train them on how to manufacture. And then, you know, some people are new to this process. It's like they learn the process. They don't know how to make the vaccine and they're not as efficient as others".</p><p>
&nbsp;
"So you may have lower productivity. That's why we have a productivity going from one to three. And so, unfortunately, it's really bad luck. Actually, there's nothing mysterious about it. But look, the sites that have the lowest productivity in the network are the sites that are supplying Europe. And quite honestly, I mean, we're not doing it on purpose. I'm European, I have Europe at heart. Our chairman is Swedish, is European. Our CFO is European. Many people in the management are European. So we want to treat Europe as best we can. You know, we do this at no profit, remember? We didn't go into this to try and make money or whatever. We would like to treat Europe as good as possible. I actually do believe we treated Europe fairly". &nbsp;</p><p>
&nbsp;
"Now, let me give you another number. Our total capacity globally now is about 100 million doses a month.&nbsp;From February onwards we are able to make 100 million doses a month, that's not small. Most vaccines have 100 million doses a year, that already takes us on a 1,2 billion pace per year. We are going to keep growing. Of course, we are ramping up production and Europe is getting 17 percent of this global production in February for a population that is 5 percent of the world population.&nbsp; Now, from the beginning we took very seriously the approach that Europe took, which we thought was fair and we all took. In fact, the US didn't say that Europe said that. Europe said the vaccine is common good and everybody needs to get access at the same time globally. That's what we are doing. Europe is getting 17 percent of our global supply for a month for 5 percent of the world population. The problem is: 100 million doses is a lot, but we have 7,5 billion people in the world".</p><p>
&nbsp;
"We are in the ramp-up phase and basically it will improve, but it takes time. Having said all of this, I'm not looking for excuses, honestly.&nbsp; We take accountability. We want to do better and we're working day and night. Our people in manufacturing, we have hundreds of people, thousands of people now. Many of them didn't take any Christmas vacation. I'm not asking you feel sorry for us but you know, we're doing our very best. But it's a very complicated process and a big scale”. &nbsp;</p><p>
&nbsp;
<strong>After the explanation you just gave at the same time it is striking the aggressive way which the EU has responded, even threatning to impose a new control on exports of activity out of Europe. Some are suggesting that you're selling your product to some other countries.&nbsp; </strong><br>
“The suggestion we sell to other countries to make more money is not right because we make no profit everywhere.That's the approach we took and we agreed on that. That’s the agreement we have with Oxford University.&nbsp;It's actually even written in a contract we have with Oxford University: that we will be at no profit. We have slightly different prices from one geographic to the other because the cost of goods may be different. We have a supply chain in Brazil, we have another one in Latin America, another one in South Asia. We have one in Japan. Of course, you know, local costs are different. So you've got slight variations, but more or less, it's about three to four dollars, more or less everywhere.&nbsp;It makes no difference. Zero difference. I understand we all want to be vaccinated. I think the populations of Europe, like everywhere else in the world, have been under so much stress with this pandemic for so long now, for a year or so, that people are tired. And I think the people who didn't want to be vaccinated maybe …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.repubblica.it/cronaca/2021/01/26/news/interview_pascal_soriot_ceo_astrazeneca_coronavirus_covid_vaccines-284349628/">https://www.repubblica.it/cronaca/2021/01/26/news/interview_pascal_soriot_ceo_astrazeneca_coronavirus_covid_vaccines-284349628/</a></em></p>]]>
            </description>
            <link>https://www.repubblica.it/cronaca/2021/01/26/news/interview_pascal_soriot_ceo_astrazeneca_coronavirus_covid_vaccines-284349628/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25978951</guid>
            <pubDate>Sun, 31 Jan 2021 14:14:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fuzzy Sets for Ada]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25978901">thread link</a>) | @joubert
<br/>
January 31, 2021 | http://www.dmitry-kazakov.de/ada/fuzzy.htm | <a href="https://web.archive.org/web/*/http://www.dmitry-kazakov.de/ada/fuzzy.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<p>
<big><big><big><b>FUZZY SETS FOR ADA</b></big></big><br>
<em>version 5.14</em><br>
by Dmitry A. Kazakov</big><br>
(<a href="mailto:mailbox@dmitry-kazakov.de">mailbox@dmitry-kazakov.de</a>)<br>
<a href="http://www.dmitry-kazakov.de/"><img src="http://www.dmitry-kazakov.de/ada/home.jpg" alt="[Home]" width="40" height="40"></a></p>
<p>
This library is free software; you can redistribute it and/or modify it under 
the terms of the GNU General Public License as published by the Free Software 
Foundation; either version 2 of the License, or (at your option) any later 
version. This library is distributed in the hope that it will be useful, but 
WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
FITNESS FOR A PARTICULAR PURPOSE. See the
<a href="http://www.gnu.org/licenses/gpl.html">GNU General Public License</a>
for more details. You should have received a copy of the GNU General Public 
License along with this library; if not, write to the Free Software Foundation, 
Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.</p>
<p>
As a special exception, if other files instantiate generics from this unit, or 
you link this unit with other files to produce an executable, this unit does not 
by itself cause the resulting executable to be covered by the GNU General Public 
License. This exception does not however invalidate any other reasons why the 
executable file might be covered by the GNU Public License.</p>
<hr>
<p><a name="0"></a><a href="#11"><img src="http://www.dmitry-kazakov.de/ada/index.gif" alt="[TOC]" width="29" height="29"></a><a href="#1"><img src="http://www.dmitry-kazakov.de/ada/next.gif" alt="[Next]" width="29" height="29"></a></p>
The current version includes
distributions of string edit, interval arithmetic and simple components 
packages. It provides implementations of:<ul>
  <li>Confidence factors with the operations not, and, or, xor, +, *;</li>
  <li>Classical fuzzy sets with the set-theoretic operations and the operations 
  of the possibility theory;</li>
  <li>Intuitionistic fuzzy sets with the operations on them;</li>
  <li>Fuzzy logic based on the intuitionistic fuzzy sets and the possibility 
  theory;</li>
  <li>Fuzzy numbers both integer and floating-point ones with conventional 
  arithmetical operations;</li>
  <li>Dimensioned fuzzy numbers;</li>
  <li>Fuzzy linguistic variables and sets of linguistic variables with operations on 
  them;</li>
	<li>Dimensioned fuzzy linguistic variables and sets;</li>
  <li>String-oriented I/O is supported;</li>
	<li>GUI interface based on GTK+ (The GIMP Toolkit) with fuzzy set editors, truth values widgets 
	and renderers, linguistic variables sets editors.</li>
  </ul>
<p>See also the <a href="#changes_log">changes log</a>.</p>
<u><b>Quick reference</b></u>:<blockquote>
<p>
<a href="#Confidence_Factors">Confidence factors</a> (truth values)<br>
<a href="#Fuzzy">Fuzzy sets</a><br>
<a href="#intuitionistic_set">Intuitionistic_fuzzy sets</a><br>
<a href="#fuzzy_proposition">Fuzzy logic</a><br>
<a href="#fuzzy_numbers">Fuzzy numbers</a><br>
<a href="#linguistic_variable">Linguistic variables</a><br>
<a href="#Fuzzy.Linguistics.Sets">Sets of linguistic variables</a><br>
<a href="#GTK_support">Graphical User Interface</a>&nbsp; (GTK+ widgets)</p></blockquote>
<p><img src="http://www.dmitry-kazakov.de/ada/gtk_fuzzy_linguistic_set_editor_vertical.gif" alt="fuzzy linguistic set editor vertical"></p>
<table>
	<tbody><tr>
		<td colspan="4">&nbsp;</td>
		<td>&nbsp;</td>
		<td>&nbsp;</td>
		<td>ARM</td>
		<td colspan="3">Intel</td>
	</tr>
	<tr>
		<td colspan="4"><b>Download Fuzzy Sets for Ada</b></td>
		<td><b>Platform:</b></td>
		<td>&nbsp;</td>
		<td>v7</td>
		<td>64-</td>
		<td>32</td>
		<td>bit</td>
	</tr>
	<tr>
		<td>
		<a name="fedora_packages"></a>Fedora packages </td>
		<td>
		<img src="http://www.dmitry-kazakov.de/ada/fedora-logo.jpg" width="16" height="16" alt="fedora"></td>
		<td>&nbsp;</td>
		<td>precompiled and packaged using RPM</td>
		<td>&nbsp;</td>
		<td>&nbsp;</td>
		<td>
		<a href="http://www.dmitry-kazakov.de/distributions/fuzzy_fedora_armv7hl.htm"><img src="http://www.dmitry-kazakov.de/ada/in.jpg" alt="[Download page]" width="29" height="29"></a></td>
		<td><a href="http://www.dmitry-kazakov.de/distributions/fuzzy_fedora_x86_64.htm"><img src="http://www.dmitry-kazakov.de/ada/in.jpg" alt="[Download page]" width="29" height="29"></a></td>
		<td colspan="2"><a href="http://www.dmitry-kazakov.de/distributions/fuzzy_fedora_i686.htm"><img src="http://www.dmitry-kazakov.de/ada/in.jpg" alt="[Download page]" width="29" height="29"></a></td>
	</tr>
	<tr>
		<td>
		<a name="CentOS_packages"></a>CentOS packages </td>
		<td>
		<img src="http://www.dmitry-kazakov.de/ada/centos-logo.jpg" width="16" height="16" alt="CentOS"></td>
		<td>&nbsp;</td>
		<td>precompiled and packaged using RPM</td>
		<td>&nbsp;</td>
		<td>&nbsp;</td>
		<td>&nbsp;</td>
		<td><a href="http://www.dmitry-kazakov.de/distributions/centos/fuzzy_centos_x86_64.htm"><img src="http://www.dmitry-kazakov.de/ada/in.jpg" alt="[Download page]" width="29" height="29"></a></td>
		<td colspan="2"><a href="http://www.dmitry-kazakov.de/distributions/centos/fuzzy_centos_i686.htm"><img src="http://www.dmitry-kazakov.de/ada/in.jpg" alt="[Download page]" width="29" height="29"></a></td>
	</tr>
	<tr>
		<td>
		<a name="debian_packages"></a>Debian packages </td>
		<td>
		<img src="http://www.dmitry-kazakov.de/ada/debian-logo.jpg" width="16" height="16" alt="Debian"></td>
		<td>&nbsp;</td>
		<td colspan="2">precompiled and packaged for dpkg</td>
		<td>&nbsp;</td>
		<td>
		<a href="http://www.dmitry-kazakov.de/distributions/fuzzy_debian_armhf.htm"><img src="http://www.dmitry-kazakov.de/ada/in.jpg" alt="[Download page]" width="29" height="29"></a></td>
		<td><a href="http://www.dmitry-kazakov.de/distributions/fuzzy_debian_x86_64.htm"><img src="http://www.dmitry-kazakov.de/ada/in.jpg" alt="[Download page]" width="29" height="29"></a></td>
		<td colspan="2"><a href="http://www.dmitry-kazakov.de/distributions/fuzzy_debian_i686.htm"><img src="http://www.dmitry-kazakov.de/ada/in.jpg" alt="[Download page]" width="29" height="29"></a></td>
	</tr>
	<tr>
		<td>
		<a name="ubuntu_packages"></a>Ubuntu packages </td>
		<td>
		<img src="http://www.dmitry-kazakov.de/ada/ubuntu-logo.jpg" width="16" height="16" alt="Ubuntu"></td>
		<td>&nbsp;&nbsp;&nbsp;&nbsp; </td>
		<td colspan="2">precompiled and packaged for dpkg</td>
		<td>&nbsp;</td>
		<td><a href="http://www.dmitry-kazakov.de/distributions/ubuntu/fuzzy_ubuntu_armhf.htm"><img src="http://www.dmitry-kazakov.de/ada/in.jpg" alt="[Download page]" width="29" height="29"></a></td>
		<td><a href="http://www.dmitry-kazakov.de/distributions/ubuntu/fuzzy_ubuntu_x86_64.htm"><img src="http://www.dmitry-kazakov.de/ada/in.jpg" alt="[Download page]" width="29" height="29"></a></td>
		<td colspan="2"><a href="http://www.dmitry-kazakov.de/distributions/ubuntu/fuzzy_ubuntu_i686.htm"><img src="http://www.dmitry-kazakov.de/ada/in.jpg" alt="[Download page]" width="29" height="29"></a></td>
	</tr>
	<tr>
		<td colspan="2">Source distribution (any platform)</td>
		<td>&nbsp;</td>
		<td colspan="2"><a href="http://www.dmitry-kazakov.de/ada/fuzzy_5_14.tgz">fuzzy_5_14.tgz</a> (<b>tar</b> + <b>gzip</b>, Windows users may use WinZip)</td>
		<td>&nbsp;</td>
		<td>&nbsp;</td>
		<td><a href="http://www.dmitry-kazakov.de/ada/fuzzy_5_14.tgz"><img src="http://www.dmitry-kazakov.de/ada/download.jpg" alt="[Download]" width="29" height="29"></a></td>
		<td>&nbsp;</td>
		<td>&nbsp;</td>
	</tr>
</tbody></table>
<p>See also
<a href="#changes_log">changes log</a>.</p>
<hr>
<p>
  <a name="1"></a><a href="#0"><img src="http://www.dmitry-kazakov.de/ada/prev.gif" alt="[Back]" width="29" height="29"></a><a href="#11"><img src="http://www.dmitry-kazakov.de/ada/index.gif" alt="[TOC]" width="29" height="29"></a><a href="#1.1"><img src="http://www.dmitry-kazakov.de/ada/next.gif" alt="[Next]" width="29" height="29"></a>
</p>
<h2>1. Truth values</h2>
<p>
<a name="Confidence"></a><a name="Confidence_Factors"></a>The type <a href="#Confidence">
Confidence</a> is defined in the package
<a href="#Confidence_Factors">Confidence_Factors</a>. A value of the type <a href="#Confidence">
Confidence</a> indicates the level of certainty&nbsp; that an element belongs to 
the fuzzy set. An instance of <a href="#Confidence">Confidence</a>
can be viewed as a number in [0,1]. The value 0 corresponds to <span color="#800000"><i>
false</i></span>
of Boolean logic. The value 1 is an equivalent of <i><span color="#800000">true</span></i>. 
The package
<a href="#Confidence_Factors">Confidence_Factors</a> has the constant <i>
Resolution</i>
that defines the granularity of <a href="#Confidence"> Confidence</a>. The 
following operations are defined on the instances of <a href="#Confidence">
Confidence</a>:<br>
</p><blockquote>
<tt>
<span color="#0000FF">function</span> "<span color="#FF0000">not</span>" (<b>Left</b> 
: Confidence)
<span color="#0000FF">return</span>  Confidence;<br>
<span color="#0000FF">function</span> "<span color="#FF0000">and</span>"&nbsp;(<b>Left</b>, <b>
Right</b> : Confidence) <span color="#0000FF">return</span> Confidence;
<br><span color="#0000FF">function</span> "<span color="#FF0000">mod</span>" (<b>Left</b>, <b>
Right</b> : Confidence) <span color="#0000FF">return</span> 
  Confidence;
  <br>
  <span color="#0000FF">function</span> "<span color="#FF0000">or</span>"&nbsp; 
(<b>Left</b>, <b>Right</b> : Confidence) <span color="#0000FF">return</span> 
  Confidence;<br>
  <span color="#0000FF">function</span> "<span color="#FF0000">rem</span>" (<b>Left</b>, <b>
Right</b> : Confidence) <span color="#0000FF">return</span> 
  Confidence;<br>
<span color="#0000FF">function</span> "<span color="#FF0000">xor</span>"&nbsp;(<b>Left</b>, <b>
Right</b> : Confidence) <span color="#0000FF">return</span> 
  Confidence;<br>
  <span color="#0000FF">function</span> "<span color="#FF0000">+</span>"&nbsp;&nbsp; 
(<b>Left</b>, <b>Right</b> : Confidence) <span color="#0000FF">return</span> 
  Confidence;<br>
  <span color="#0000FF">function</span> "<span color="#FF0000">-</span>"&nbsp;&nbsp; 
(<b>Left</b>, <b>Right</b> : Confidence) <span color="#0000FF">return</span> 
  Confidence;<br>
  <span color="#0000FF">function</span> "<span color="#FF0000">*</span>"&nbsp;&nbsp;...
<span color="#008000">
<i>-- predefined by the language</i></span></tt></blockquote>
<p>These operations are defined as follows:<br>
</p><blockquote>
  <table>
    <tbody><tr>
      <td><b><span color="#FFFFFF">Operation</span></b></td>
      <td><b><span color="#FFFFFF">&nbsp;Name&nbsp;</span></b></td>
      <td><b><span color="#FFFFFF">Definition</span></b></td>
    </tr>
    <tr>
      <td>Complement</td>
      <td><tt><span color="#FF0000">not</span></tt></td>
      <td>1<i> - x = <span>x</span></i></td>
    </tr>
    <tr>
      <td>Fuzzy <i>and</i></td>
      <td><tt><span color="#FF0000">and</span></tt></td>
      <td><i>min</i> (<i>x</i>, <i>y</i>) = <i>x</i>&amp;<i>y</i></td>
    </tr>
    <tr>
      <td>Truncation</td>
      <td><tt><span color="#FF0000">mod</span></tt></td>
      <td><i>x</i> if <i>x</i> &gt; <i>y</i>, otherwise 0</td>
    </tr>
    <tr>
      <td>Fuzzy <i>or</i></td>
      <td><tt><span color="#FF0000">or</span></tt></td>
      <td><i>max</i> (<i>x</i>, <i>y</i>) = <i>x</i>∨<i>y</i></td>
    </tr>
    <tr>
      <td>Rounding</td>
      <td><tt><span color="#FF0000">rem</span></tt></td>
      <td><i>x</i> if <i>x</i> &lt; <i>y</i>, otherwise 1</td>
    </tr>
    <tr>
      <td>Fuzzy <i>xor</i> (distance)</td>
      <td><tt><span color="#FF0000">xor</span></tt></td>
      <td><i>max</i> (<i>min</i> (<i>x</i>, 1 - <i>y</i>), <i>min</i> (1 - <i>x</i>, <i>
      y</i>)) = (<i>x</i>&amp;<span><i>y</i></span>)&nbsp;∨&nbsp;(<span><i>x</i></span>&amp;<i>y</i>)</td>
    </tr>
    <tr>
      <td>Distance</td>
      <td><tt><span color="#FF0000">-</span></tt></td>
      <td>| <i>x - y </i>|</td>
    </tr>
    <tr>
      <td>Probabilistic <i>or</i></td>
      <td><tt><span color="#FF0000">+</span></tt></td>
      <td><i>x</i> + <i>y</i> <i>-</i> <i>x </i>·<i> y</i></td>
    </tr>
    <tr>
      <td>Probabilistic <i>and</i></td>
      <td><tt><span color="#FF0000">*</span></tt></td>
      <td><i>x </i>·<i> y</i></td>
    </tr>
  </tbody></table>
</blockquote>
<p><u><b><a name="confidence-xor"></a>Notes about <i>xor</i></b></u>. Fuzzy <span color="#0000FF">xor</span> can be defined in two
ways equivalent in crisp logic: (<i>x</i>&amp;<span><i>y</i></span>)&nbsp;∨&nbsp;(<span><i>x</i></span>&amp;<i>y</i>)
and (<i>x</i>∨<i>y</i>)&nbsp;&amp;&nbsp;(<i><span>x</span></i>∨<i><span>y</span></i>).
These two definitions stay equivalent when <i>x</i> and <i>y</i> become fuzzy, despite the fact that
<i>x</i>&amp;<span><i>x</i></span> might be
greater than 0 and <i>x</i>∨<span><i>x</i></span>
be less than 1. It can be shown that:
</p><blockquote>
<p>(<i>x</i>&amp;<span><i>x</i></span>)&nbsp;∨&nbsp;(<i>y</i>&amp;<span><i>y</i></span>)
≤
(<i>x</i>&amp;<span><i>y</i></span>)&nbsp;∨&nbsp;(<span><i>x</i></span>&amp;<i>y</i>)
= (<i>x</i>∨<i>y</i>)&nbsp;&amp;&nbsp;(<i><span>x</span></i>∨<i><span>y</span></i>)
≤ (<i>x</i>∨<span><i>x</i></span>)&nbsp;&amp;&nbsp;(y∨<i><span>y</span></i>).
</p></blockquote>
<p>The upper and lower bounds here characterize fuzziness of the arguments. For <i>x</i>=<i>y</i>  <span color="#0000FF">xor</span> reaches its lower bound <i>x</i>&amp;<span><i>x</i></span>
= <i>x</i>  <span color="#0000FF">xor</span> <i>x</i>. For <i>x</i>=<i><span>y</span></i>
 <span color="#0000FF">xor</span> reaches its upper bound: <i>x</i>  <span color="#0000FF">xor</span> <i><span>x</span></i>
= <i>x</i>∨<span><i>x</i></span>.</p><p>
  <a name="1.1"></a><a href="#1"><img src="http://www.dmitry-kazakov.de/ada/prev.gif" alt="[Back]" width="29" height="29"></a><a href="#11"><img src="http://www.dmitry-kazakov.de/ada/index.gif" alt="[TOC]" width="29" height="29"></a><a href="#2"><img src="http://www.dmitry-kazakov.de/ada/next.gif" alt="[Next]" width="29" height="29"></a>
</p>
<h3>
1.1. String I/O of truth values</h3>
<p><a name="Confidence_Factors.Edit"></a>The child package
<a href="#Confidence_Factors.Edit">Confidence_Factors.Edit </a>defines I/O 
operations on <a href="#Confidence">Confidence</a>.
</p><blockquote>
  <p>
  <tt><span color="#0000FF">procedure</span> Get<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (&nbsp;
  <b>Source</b>&nbsp; : String;<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>Pointer</b> : <span color="#0000FF">in out</span>  Integer;<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>Value</b>&nbsp;&nbsp; : <span color="#0000FF">out</span>  Confidence<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; );</tt></p>
</blockquote>
<p>This procedure gets a confidence factor from the string <b>Source</b>. The 
factor can be given either in a numeric form or as
<i>  <span color="#800000">  true</span></i>  or <i> <span color="#800000"> false</span></i>  (case insensitive). The process starts from
<b>   Source</b> (<b>Pointer</b>). Upon successful completion <b>Pointer</b> is 
advanced to the first unmatched character. The following exceptions are 
propagated out of the procedure:<br>
</p><table>
  <caption>
    <i>Exceptions</i>
  </caption>
  <tbody><tr>
    <td>Constraint_Error</td>
    <td>The factor is not in the range 0..1</td>
  </tr>
  <tr>
    <td>Data_Error</td>
    <td>Syntax error in the number</td>
  </tr>
  <tr>
    <td>End_Error</td>
    <td>There is no confidence factor in the string</td>
  </tr>
  <tr>
    <td>Layout_Error</td>
    <td>The value of <b>Pointer</b> is not in the range
      <b>Source</b>'First..<b>Source</b>'Last+1&nbsp;</td>
  </tr>
</tbody></table>
<blockquote>
  <p>
  <tt> <span color="#0000FF">function</span>
  Value (<b>Source</b> : String)
  <span color="#0000FF">return</span>  Confidence;</tt></p>
</blockquote>
<p>
This function gets a confidence factor from the string <b>Source</b>. The 
confidence factor specification in the string can be surrounded by the 
characters representing UTF-8 encoded code points from the set
<a href="#Name_Tables.Blanks">Blanks</a>. The whole 
string should be matched. Otherwise the exception Data_Error is propagated. The 
following exceptions are propagated out of the procedure:<br>
</p><table>
  <caption>
    <i>Exceptions</i>
  </caption>
  <tbody><tr>
    <td>Constraint_Error</td>
    <td>The factor is not in the range 0..1</td>
  </tr>
  <tr>
    <td>Data_Error</td>
    <td>Syntax error in the number</td>
  </tr>
  <tr>
    <td>End_Error</td>
    <td>There is no confidence factor in the string</td>
  </tr>
</tbody></table>
<blockquote>
  <p>
  <tt><span color="#0000FF">procedure</span> Put<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (&nbsp;
  <b>Destination</b> : <span color="#0000FF">in out</span> String;<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>Pointer</b>&nbsp;&nbsp;&nbsp;&nbsp; : <span color="#0000FF">in out</span>
  Integer;<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>Value</b>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : Confidence;<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>Field</b>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : Natural :=
  <span color="#800080">0</span>;<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>Justify</b>&nbsp;&nbsp;&nbsp;&nbsp; : Strings_Edit.Alignment := Strings_Edit.Left;<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>Fill</b>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : Character := ' '<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ); </tt>
  </p>
  </blockquote>
<p>
This procedure places the confidence factor specified by the parameter <b>Value</b>
into the output string <b>Destination</b>. <i><span color="#800000">True</span></i> 
and <i><span color="#800000">false</span></i> (Confidence'Last, Confidence'First) 
are put as 1 and 0, correspondingly. Other values are put in a fixed point 
numeric format. The string is written starting from <b>
Destination (Pointer)</b>. When the parameter
<b>Field</b> is not zero then <b>Justify</b> specifies alignment and
<b>Fill</b> is the character used for filling. When <b> Field</b> is greater 
than
<b>Destination</b>'Last - <b>Pointer</b> + 1, the latter is used instead. After 
successful completion <b>Pointer</b> is advanced to the first character 
following the output or to <b>Destination</b>'Last + 1.<br>
</p><table>
  <caption>
    Exceptions
  </caption>
  <tbody><tr>
    <td>Layout_Error</td>
    <td><b>Pointer</b> is not in <b>Destination</b>'Range or there is<br>
      no room for the output</td>
  </tr>
</tbody></table>
<blockquote>
  <p>
  <tt> <span color="#0000FF">function</span>
  Image (<b>Value</b>
  : Confidence)
  <span color="#0000FF">return</span> String;</tt></p>
</blockquote>
<p>
This function is used to convert <a href="#Confidence">Confidence</a> to 
String.&nbsp;</p><blockquote>
  <p>
  <tt> <span color="#0000FF">function</span> 
  To_Confidence (<b>Value</b>
  : Boolean)
  <span color="#0000FF">return</span> Confidence;</tt></p>
</blockquote>
<p>
This function is used to convert a Boolean value to <a href="#Confidence">
Confidence</a>.
</p><hr>
<p>
  <a name="2"></a><a href="#1.1"><img src="http://www.dmitry-kazakov.de/ada/prev.gif" alt="[Back]" width="29" height="29"></a><a href="#11"><img src="http://www.dmitry-kazakov.de/ada/index.gif" alt="[TOC]" width="29" height="29"></a><a href="#2.1"><img src="http://www.dmitry-kazakov.de/ada/next.gif" alt="[Next]" width="29" height="29"></a>
</p>
<h2>2. Fuzzy sets</h2>
<p>
<a name="Set"></a><a name="Fuzzy"></a>A fuzzy set mathematically is a function mapping its domain to [0,1]. So a fuzzy 
set A over some domain set D is A:&nbsp;D→[0,1].&nbsp;For any domain value <i>x</i>∈D it 
gives a confidence factor (or else a level of truth) telling how possible is 
that <i>x</i> belongs to A, i.e. A(<i>x</i>) = P<sub>A|{<i>x</i>}</sub> = P<sub><i>x</i>∈A</sub>. 
Customary the membership function of A is distinguished from the set and notated 
as μ<sub>A</sub>(<i>x</i>), but we will not do it. Though the meaning of A(<i>x</i>) 
was defined as a possibility, it is both a necessity that <i>x</i> belongs to A. 
This is because for fuzzy sets we postulate that P<sub>A|{<i>x</i>} </sub>= N<sub>A|{<i>x</i>}</sub> 
= N<sub><i>x</i>∈A</sub>. Which is equivalent to a definition of the fuzzy set 
complement as
<span>A</span>(<i>x</i>) = 1-A(<i>x</i>).
</p><p>
The type <a href="#Set">Set</a> is defined 
in the package
<a href="#Fuzzy">Fuzzy</a>. It represents a fuzzy set over an interval of 
integer numbers. A more natural approach would be to define fuzzy sets with the 
domain of any discrete type. Unfortunately it would make the package generic, 
with the consequence that it would be almost impossible to use it for things 
like fuzzy decision trees. So I chose the following definition of the type <a href="#Set">
Set</a>:<br>
</p><blockquote>
<tt> <span color="#0000FF">   type</span> Set <span color="#0000FF"> is array</span> 
(Integer <span color="#0000FF">range</span> &lt;&gt;)<span color="#0000FF"> of</span> 
Confidence;</tt></blockquote>
<p>
The package
<a href="#Fuzzy">Fuzzy</a> defines various operations on the instances of <a href="#Set">Set</a>.</p><p>
  <a name="2.1"></a><a href="#2"><img src="http://www.dmitry-kazakov.de/ada/prev.gif" alt="[Back]" width="29" height="29"></a><a href="#11"><img src="http://www.dmitry-kazakov.de/ada/index.gif" alt="[TOC]" width="29" height="29"></a><a href="#2.2"><img src="http://www.dmitry-kazakov.de/ada/next.gif" alt="[Next]" width="29" height="29"></a>
</p>
<h3>
2.1. Tests</h3>
<p>
<a href="#Confidence">Confidence</a> of an element can be obtained either by using 
the predefined array indexing operation or by the function Is_In:
</p><blockquote>
  <p><tt><span color="#0000FF">function</span>
  Is_In (<b>Point</b> : Integer; <b> A</b> : Set) <span color="#0000FF"> return</span> 
  Confidence;</tt></p>
</blockquote>
<p>
The function Is_In does not raise an exception even if <b>Point</b> is not in <b>
A</b>'Range,&nbsp;in which case it returns 0.</p><p>
  <a name="2.2"></a><a href="#2.1"><img src="http://www.dmitry-kazakov.de/ada/prev.gif" alt="[Back]" width="29" height="29"></a><a href="#11"><img src="http://www.dmitry-kazakov.de/ada/index.gif" alt="[TOC]" width="29" height="29"></a><a href="#2.3"><img src="http://www.dmitry-kazakov.de/ada/next.gif" alt="[Next]" width="29" height="29"></a>
</p>
<h3>
2.2. Operations producing a new set</h3>
<blockquote>
  <tt> <span color="#0000FF">function</span>
  "<span color="#FF0000">not</span>" (<b>A</b> : Set)
  <span color="#0000FF">return</span>  Set;<span color="#0000FF">function</span> "<span color="#FF0000">and</span>" (<b>A</b>, <b>
  B</b> : Set) <span color="#0000FF">return</span>  Set;<span color="#0000FF"><br>
  &nbsp;&nbsp; function</span> "<span color="#FF0000">and</span>" (<b>A</b> : 
  Set; <b>B</b> : Confidence) <span color="#0000FF">return</span> 
  Set;<span color="#0000FF"><br>
  &nbsp;&nbsp; function</span> "<span color="#FF0000">and</span>" (<b>A</b> : 
  Confidence; <b>B</b> : Set) <span color="#0000FF">return</span> 
  Set;<span color="#0000FF"><p>
  
  function</p></span> "<span color="#FF0000">mod</span>" (<b>A</b>, <b>B</b> : Set) <span color="#0000FF">
  return</span>  Set;<span color="#0000FF"><br>
  &nbsp;&nbsp; function</span> "<span color="#FF0000">mod</span>" (<b>A</b> : 
  Set; <b>B</b> : Confidence) <span color="#0000FF">return</span> 
  Set;<span color="#0000FF"><br>
  &nbsp;&nbsp; function</span> "<span color="#FF0000">mod</span>" (<b>A</b> : 
  Confidence; <b>B</b> : Set) <span color="#0000FF">return</span> 
  Set;<span color="#0000FF"><p>
  
  function</p></span> "<span color="#FF0000">or</span>" (<b>A</b>, <b>B</b> : Set) <span color="#0000FF">
  return</span>  Set;<span color="#0000FF"><br>
  &nbsp;&nbsp; function</span> "<span color="#FF0000">or</span>" (<b>A</b> : 
  Set; <b>B</b> : Confidence) <span color="#0000FF">return</span>  Set;<span color="#0000FF"><br>
  &nbsp;&nbsp; function</span> "<span color="#FF0000">or</span>" (<b>A</b> : 
  Confidence, <b>B</b> : Set) <span color="#0000FF">return</span> Set;<span color="#0000FF"><p>
  
  function</p></span> "<span color="#FF0000">xor</span>" (<b>A</b>, <b>B</b> : Set) <span color="#0000FF">
  return</span>  Set;<span color="#0000FF"><br>
  &nbsp;&nbsp; function</span> "<span color="#FF0000">xor</span>" (<b>A</b> : 
  Set; <b>B</b> : Confidence) <span color="#0000FF">return</span> 
  Set;<span color="#0000FF"><br>
  &nbsp;&nbsp; function</span> "<span color="#FF0000">xor</span>" (<b>A</b> : 
  Confidence; <b>B</b> : Set) <span color="#0000FF">return</span> 
  Set;<span color="#0000FF"><p>
  
  function</p></span> "<span color="#FF0000">rem</span>" (<b>A</b>, <b>B</b> : Set) <span color="#0000FF">
  return</span>  Set;<span color="#0000FF"><br>
  &nbsp;&nbsp; function</span> "<span color="#FF0000">rem</span>" (<b>A</b> : 
  Set; <b>B</b> : Confidence) <span color="#0000FF">return</span> 
  Set;<span color="#0000FF"><br>
  &nbsp;&nbsp; function</span> "<span color="#FF0000">re…</span></tt></blockquote></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.dmitry-kazakov.de/ada/fuzzy.htm">http://www.dmitry-kazakov.de/ada/fuzzy.htm</a></em></p>]]>
            </description>
            <link>http://www.dmitry-kazakov.de/ada/fuzzy.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25978901</guid>
            <pubDate>Sun, 31 Jan 2021 14:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Understand Algorithms, Abstraction and Pseudocode]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25978704">thread link</a>) | @coderslang
<br/>
January 31, 2021 | https://learn.coderslang.com/0017-algorithms-abstraction-and-pseudocode/ | <a href="https://web.archive.org/web/*/https://learn.coderslang.com/0017-algorithms-abstraction-and-pseudocode/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>“There are 10 types of people, those who understand the binary system and everyone else.” — Unknown Author</p><blockquote><p><strong>This is an excerpt from the Full Stack JS course <a href="https://js.coderslang.com/sign-in" target="_blank">CoderslangJS</a>
.</strong></p></blockquote><p>— Good day, Hero! Today you’ll learn with C2H5. He is a robot and our ally in the fight against machines.</p><p>— Thanks for the introduction, Professor. Machines aren’t very different from humans in terms of general thinking, but we have our own characteristics.</p><h2 id="binary-number-system">Binary number system</h2><p>Since you will have to return to the simulation of 2021, we will consider everything in terms of that time. We believe that full-fledged artificial intelligence had not yet been created and you can still stop the apocalypse.</p><p>First, imagine 10 light bulbs. Each of them can be turned on or off.</p><p><a href="https://learn.coderslang.com/Group%20104956_en.svg" target="_blank"><img src="https://learn.coderslang.com/Group%20104956_en.svg" alt=""></a></p><p>Let’s stop here for a second. How many numbers can you represent using these 10 bulbs?</p><p>— <em>Eeeemmm, up to 10?</em></p><p>— We can definitely count up to 10 if we only count the total number of bulbs that are “on”. But do you think we could count to 1000 using the same 10 bulbs?</p><p><em>— No, I think it’s impossible.</em></p><p>— Well, I’ll try to show you that nothing is impossible for machines.</p><p>Try to imagine that each light bulb is not just “on” or “off”, but displays a single digit from 0 to 9.</p><p><a href="https://learn.coderslang.com/Group%20104961_en.svg" target="_blank"><img src="https://learn.coderslang.com/Group%20104961_en.svg" alt=""></a></p><p>Then, we could get all combinations from 0,000,000,000 to 9,999,999,999. Or 10 billion different numbers, including 0, of course.</p><p><em>— Ok, but it’s still unclear how we could count up to 1000 using 10 regular bulbs.</em></p><p>— Now let’s figure out the details. Imagine on our “tube calculator” some random number. For example, 2375. We’ll discard zeros to ease the calculation. To understand that this number is “two thousand three hundred seventy five” you do several operations:</p><blockquote><p>5 * 1 + 7 * 10 + 3 * 100 + 2 * 1000 = 5 + 70 +300 + 2000 = 2375</p></blockquote><p>As you see, <strong>each digit has its own weight</strong>. It is calculated according to the formula:</p><blockquote><p>BASE to the power of POSITION</p></blockquote><p>The BASE is the basis of the numeral system. Humans usually use the numeral system with the base 10. Machines, on the other hand, use a different one with base 2. It’s a lot easier for us to operate with it.</p><p>We start counting positions from the right and the initial position is always 0, so the weight of the first digit is 1, since raising any BASE to the zero power is 1.</p><p>The next “slots” in the decimal system have their own weights of 10, 100, 1000, 10000, etc.</p><p>Of course, you don’t count it every time you see a decimal number. But we need an understanding of this formula to move forward.</p><p>— <em>This is quite obvious, but if I remember correctly, there were no numbers in the original task. You’ve only mentioned 2 states - on/off.</em></p><p>— That’s right. Now let’s try not just to count the number of lights that are <strong>on</strong>, also taking into account their position.</p><p>Imagine a sequence of lights like this - 0 0 1 0 1 0 1 1 0 1</p><p><a href="https://learn.coderslang.com/Group%20104963_en.svg" target="_blank"><img src="https://learn.coderslang.com/Group%20104963_en.svg" alt=""></a></p><p>We’ll start by assigning a weight to each position.</p><p>Position 0 = 2 ^ 0 = 1</p><p>Position 1 = 2 ^ 1 = 2</p><p>Position 2 = 2 ^ 2 = 4</p><p>…</p><p>Position 9 = 2 ^ 9 = 512</p><p>Now, to calculate the final number, we just have to multiply the weight of each position by its value (0 or 1).</p><p>So, 1 * 1 + 0 * 2 + 1 * 4 + 1 * 8 + 0 * 16 + 1 * 32 + 0 * 64 + 1 * 128 + 0 * 256 + 1 * 512 = 1 + 4 + 8 + 32 + 128 = 173</p><p><a href="https://learn.coderslang.com/Group%20104968_en.svg" target="_blank"><img src="https://learn.coderslang.com/Group%20104968_en.svg" alt=""></a></p><p>— <em>Now it’s clear. It turns out if we turn on all the lights, then we get 1 + 2 + 4 + 8 + 16 + 32 + 64 + 128 + 256 + 512 = 1023?</em></p><p>— That’s right. In a way, this is even easier to calculate, because we either take into account the weight of a certain category or discard it.</p><h2 id="abstraction">Abstraction</h2><p>— If you move closer, then, in fact, both decimal numbers and binary ones exist only in our imagination.</p><p><em>— What do you mean? I can well imagine 12 chairs at the dining table or 40 people standing in line. They can exist not only in my head but also in reality.</em></p><p>— Of course, both people and chairs will exist. But to associate the number 12 in decimal or 10100 in binary with a well-defined number of chairs, we need to agree on how to count them.</p><p>If there were 3 chairs, not 12, then the easiest way would be to show them as 3 fingers on one hand or 3 light bulbs that are <strong>on</strong>. This is the simplest and most obvious way to calculate something. But what if there are 12, 40, 125? We’ll quickly run out of both fingers and the light bulbs.</p><p><a href="https://learn.coderslang.com/Group%20104922.svg" target="_blank"><img src="https://learn.coderslang.com/Group%20104922.svg" alt=""></a></p><p>Therefore, people came up with numeral systems. And the decimal system was not always so widespread. The Romans would have marked the same chairs as <strong>XII</strong> and most likely would not have understood what the inscription <strong>12</strong> means.</p><p>As a matter of fact, everything we talk about is an abstraction. We’ve made it harder to count the number of items, but it’s much easier to operate with large numbers.</p><p><em>— It seems to me that numbers are so common in our lives that no one even perceives it as a complication.</em></p><p>— That’s right. A first grader needs quite some time to calculate the amount of money he needs to buy a kilo of apples and oranges. But adults don’t have this problem, because when you do something very often, it becomes natural.</p><p>Please note that if at some point, instead of the numbers <strong>0, 1, 2 … 9</strong>, people decided to use the letters <strong>a, b, c … k</strong>, then your <strong>12</strong> chairs would turn into <strong>bc</strong> chairs, but the physical chairs themselves would not be affected in any way.</p><p><a href="https://learn.coderslang.com/Group%20104923_en.svg" target="_blank"><img src="https://learn.coderslang.com/Group%20104923_en.svg" alt=""></a></p><h2 id="algorithms-and-pseudocode">Algorithms and Pseudocode</h2><p>— In 2021, the machines were not yet fully autonomous and, mainly, served humans to make their life easier. Routine operations that could have taken months or years for humans to do, were performed by computers in seconds.</p><p>The only difficulty was that the human couldn’t simply say to a computer “<strong>do something good, useful, and important</strong>.” It was necessary to write a program that would do this “something”.</p><p>The good news is that after this program was written, anyone in the world could use it.</p><p><a href="https://learn.coderslang.com/Group%20104924.svg" target="_blank"><img src="https://learn.coderslang.com/Group%20104924.svg" alt=""></a></p><p>As a result, fewer and fewer people were aware of what was happening inside the machines. First, the computer helped the person find the right number in the contact list to order pizza by phone. Then, they began to understand voice commands and started to place orders on their own. Further - to decide which pizzeria to place an order in. And at the end - which route the courier should take.</p><p>The goal of the best programmers of those times was to create a full-fledged artificial intelligence. One that could solve any task, and not just distinguish cats from dogs.</p><p>How it all ended - you already know. At some point, even the creators themselves could no longer predict how the machines would behave. They justified it with the common good and talked about how terrible human life was before the invention of AI.</p><p><a href="https://learn.coderslang.com/Group%20104925.svg" target="_blank"><img src="https://learn.coderslang.com/Group%20104925.svg" alt=""></a></p><p>But in the end, people have become for machines what ants once were for people. They are everywhere, but there is no point in exterminating them. As well as feeling anything about the fact that they will take away a few grains of sugar that have fallen from the kitchen table.</p><p><em>— And do you think that I can really figure out what the best minds have not coped in 2021?</em></p><p>— Otherwise, we wouldn’t be wasting time on your preparation, Hero. Your advantage is the fact that we know exactly how to make a programmer out of you and integrate into the <strong>company that cannot be named</strong>.</p><p>But, let’s not get distracted. Let’s try to figure out how to find a person in the telephone directory. Let his name be John Snow.</p><h3 id="method-1---linear-search">Method 1 - Linear Search</h3><div><pre><code data-lang="bash">open the directory on the first page
look through all entries from top to bottom
<span>if</span> a match is found <span>(</span>John Snow<span>)</span>
    we call the found number
<span>else</span>
    go to the next entry
repeat <span>until</span> we run out of pages
</code></pre></div><p><em>— C2H5, don’t get me wrong, but no one searches like that. Even my grandma will make sure to first to look at the table of contents, find on which page the letter “S” is, and only then will she start the search according to your algorithm.</em></p><p>— You’re right. If you have a table of contents, it’s definitely worth a look. This technique is called <strong>indexing</strong> and is very commonly used in databases.</p><p>But, regardless of how non-optimal the linear search is, it will definitely help us find Peter Vasiliev’s phone number or make sure that it is not in the directory.</p><p>How would you <strong>optimize the linear search algorithm</strong> if you didn’t have indexes (table of contents), but you knew that all records are ordered from A to Z?</p><p><em>— I would probably try to guess on which page the letter “S” is. I would open the directory closer to the beginning, but not on the very first page. If I hadn’t guessed right, I would have tried again, depending on which page I was on.</em></p><p>— It’s a great approach because you assume that the directory has about the same number of surnames for each letter of the alphabet. But this was not mentioned in the initial description. We can theoretically find ourselves in a world where 90% of people have a surname starting with the letter A, then I would suggest opening the directory exactly in the middle. Then, evaluate the accuracy of the hit and go right or left, discarding half of the entries.</p><p>Since I am a robot, I will try to formalize this algorithm for you in “almost” human language.</p><h3 id="method-2---binary-search">Method 2 - Binary Search</h3><div><pre><code data-lang="bash">open the directory in the middle
look where we are
<span>if</span> a match is found <span>(</span>John Snow<span>)</span>
    we call the found number
otherwise
    <span>if</span> surnames with the letter <span>"S"</span> are earlier
        discard the right side of the directory and go to step <span>1</span>
    <span>if</span> surnames with the letter <span>"S"</span> are later
        discard the left side of the directory and go to step <span>1</span>
repeat <span>until</span> pages run out
</code></pre></div><p>As in the case of linear search, we will either find the required entry or make sure that it is not there.</p><blockquote><p>IMPORTANT! Binary search only works in sorted data structures, such as phone books or dictionaries.</p></blockquote><p>It is also much faster than a linear search. And the more elements in the data structure, the stronger the advantage becomes!</p><p>If you imagine that a single iteration (repetition) of the search algorithm takes 1 second and there are 100 entries in our phone book, then a linear search will take 100 seconds in the worst case, or 50 on average, and a binary search will take less than 7!</p><p><em>— That’s quite obvious. Reducing the amount of data to search 2 times after each repetition is very useful.</em></p><p>— But it gets even more interesting …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://learn.coderslang.com/0017-algorithms-abstraction-and-pseudocode/">https://learn.coderslang.com/0017-algorithms-abstraction-and-pseudocode/</a></em></p>]]>
            </description>
            <link>https://learn.coderslang.com/0017-algorithms-abstraction-and-pseudocode/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25978704</guid>
            <pubDate>Sun, 31 Jan 2021 13:35:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yet Another New Email]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25978573">thread link</a>) | @marksmillibend
<br/>
January 31, 2021 | https://ph1lter.bitbucket.io/blog/2021-01-31-yet-another-new-email.html | <a href="https://web.archive.org/web/*/https://ph1lter.bitbucket.io/blog/2021-01-31-yet-another-new-email.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<a href="https://ph1lter.bitbucket.io/index.html">(home)</a> <span>2021-01-31</span>
<p>I've designed an implemented <em>yet another new email system</em>.
</p>
<p>If there is any interest I will whip the code into shape and publish it.
<span>Control your expectations tho. The system works but doesn't have any of the polish a multi-dollar project might.</span>
</p>
<p>The mail system has the following features
</p>
<ul><li>
the system is intended to be self-hosted. There is no central server or authority.
</li><li>
the components are very small and simple to install. Compared to other systems in this space the components are tiny. C is used
as the implementation language along with libsodium and sqlite (server) as the only dependencies.
</li><li>
The system is intended for small groups (or even a single user) per server. Of course you can send email to anyone, on any server,
as long as you have his public key and the server's key and address, and also that you are a registered sender on his server.
</li><li>
emails are stored on the server using pubkey encryption. The server cannot read their content.
</li><li>
end-to-end encryption. The phone app contains a (libsodium) keypair which is used to decrypt emails for the user and the outgoing
emails are encrypted with the pubkey of the recipient.
</li><li>
emails are encrypted in the phone app with the recipient's public key before being transmitted over a secure channel to the server.
</li><li>
the sender of the email is authenticated/verified.
</li><li>
only the intended recipient can download the email from the server; pubkey authenticated connections are used for sending and receiving.
</li><li>
only the intended recipient can open the downloaded email (encrypted with his pubkey).
</li><li>
not federated. One connects directly to the recipient's home-server to send him an email. Unlike <em>real email</em>, server's don't
communicate with one another.
</li></ul>
<p>I had planned on peer-to-peer (phone-to-phone) initially, but the problem with mobile is phones is that they are mobile. They shift IP address arbitrarily
and may even be turned off for periods of time <span>tho this latter is very unlikely</span>.
</p>
<p>I realized that since I'd need a server for discoverability anyway, I might
as well just use the server as the mail repository too.
</p>
<p>The user app runs on android (phones etc.) and the server is self-deployed on any linux server accessible from the internet.
</p>
<p>This system is not intended for non-technical users, although it is quite simple to build and deploy. You will be required to run your own
server, although you can host email addresses for multiple users, not just your own.
</p>
<p>So far I have a working prototype consisting of the following
</p>
<ul><li>
newmaild - A server which holds the (pubkey encrypted) emails for its users (linux/C).
</li><li>
yane - an android app which allows sending and receiving of emails (simple text for now).
</li><li>
some command line tools for sending/receiving emails and generating keys.
</li></ul>
<p>There are lots of other things which I plan to implement
</p>
<ul><li>
richer email formats and attachments (currently only simple text messages are sent)
</li><li>
better (any) key management/contacts management.
</li><li>
threaded conversations
</li><li>
mail search
</li><li>
mail navigation
</li><li>
mail plain text export (good idea or not?)
</li></ul>
<h2> references</h2>
<ul><li>
<a href="https://doc.libsodium.org/">https://doc.libsodium.org/</a>
</li><li>
<a href="https://sqlite.org/index.html">https://sqlite.org/index.html</a>
</li></ul>
<p><span>Tags: email crypto libsodium sqlite android</span>
<a href="https://ph1lter.bitbucket.io/index.html">(home)</a><br>


</p></div>]]>
            </description>
            <link>https://ph1lter.bitbucket.io/blog/2021-01-31-yet-another-new-email.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25978573</guid>
            <pubDate>Sun, 31 Jan 2021 13:17:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[dl – simple file sharing service for quick one-off file transfers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25978439">thread link</a>) | @app4soft
<br/>
January 31, 2021 | https://www.thregr.org/~wavexx/software/dl/ | <a href="https://web.archive.org/web/*/https://www.thregr.org/~wavexx/software/dl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div id="dl-download-ticket-service">

<div>
<iframe width="560" height="315" src="https://www.youtube.com/embed/w7aUDkI_Ws8?rel=0" frameborder="0" allowfullscreen=""></iframe><p>Introduction to <span>DL</span></p>
</div>

<p><span>“</span>dl” is a simple file sharing service for quick/one-off file transfers. Upload
a file to get a link you can share. Or create a sharing link to receive files
from others. The uploaded files are automatically removed when left unused,
requiring zero additional&nbsp;maintenance.</p>
<p><span>“</span>dl” is <em>built for your users</em>: easy to use with any browser, integrates
smoothly with <a href="https://www.thregr.org/~wavexx/software/dl/thunderbird.html">Thunderbird</a> for large attachments, works on
<a href="https://www.thregr.org/~wavexx/software/dl/pokedl.html">Android</a>, <a href="https://www.thregr.org/~wavexx/software/dl/dl-wx.html">Windows, <span>OSX</span></a> or straight from the
<a href="https://www.thregr.org/~wavexx/software/dl/README.html#command-line-client-dl-cli">command line</a> for maximum&nbsp;convenience.</p>
<div id="files">

<p>Files as found in the latest release of&nbsp;“dl”:</p>
<table>
<colgroup><col>
<col>
</colgroup><tbody>
<tr><th><a href="https://www.thregr.org/~wavexx/software/dl/NEWS.html"><span>NEWS</span></a>:</th><td>Summary of changes.</td>
</tr>
<tr><th><a href="https://www.thregr.org/~wavexx/software/dl/pokedl.html">Poké<span>DL</span></a>:</th><td><span>DL</span> client for Android.</td>
</tr>
<tr><th><a href="https://www.thregr.org/~wavexx/software/dl/README.html"><span>README</span></a>:</th><td>Notes about usage and installation.</td>
</tr>
<tr><th><a href="https://www.thregr.org/~wavexx/software/dl/RESTAPI.html"><span>RESTAPI</span></a>:</th><td><span>DL</span> <span>REST</span> <span>API</span> documentation for developers.</td>
</tr>
<tr><th><a href="https://www.thregr.org/~wavexx/software/dl/THANKS.html"><span>THANKS</span></a>:</th><td>Contributors.</td>
</tr>
<tr><th colspan="2"><a href="https://www.thregr.org/~wavexx/software/dl/thunderbird.html"><span>DL</span> for Thunderbird</a>:</th></tr>
<tr><td>&nbsp;</td><td>Thunderbird extension which converts
large attachments to <span>DL</span>
tickets/links automatically.</td>
</tr>
<tr><th><a href="https://www.thregr.org/~wavexx/software/dl/dl-wx.html">dl-wx</a>:</th><td>dl-wx is a graphical native client to the dl
web-service. This page contains the pre-built
binary versions for Windows.</td>
</tr>
<tr><th><a href="https://www.thregr.org/~wavexx/software/dl/guide/">Guide</a>:</th><td>Sample usage guide for your users (included in the
distribution in several languages).</td>
</tr>
</tbody>
</table>
</div>



</div>

    </div></div>]]>
            </description>
            <link>https://www.thregr.org/~wavexx/software/dl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25978439</guid>
            <pubDate>Sun, 31 Jan 2021 12:54:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Have Entered the Climate Decade]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25978413">thread link</a>) | @imartin2k
<br/>
January 31, 2021 | https://worldpositive.com/we-have-entered-the-climate-decade-70b7f433271b | <a href="https://web.archive.org/web/*/https://worldpositive.com/we-have-entered-the-climate-decade-70b7f433271b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><h2 id="b1b1"><strong>A long boom of climate tech is just getting started</strong></h2><div><div><div><div><a href="https://medium.com/@andrewbeebe?source=post_page-----70b7f433271b--------------------------------" rel="noopener"><div><p><img alt="Andrew Beebe" src="https://miro.medium.com/fit/c/96/96/1*JBEejpi9-cWRgZRbEif_Iw.jpeg" width="48" height="48"></p></div></a></div></div></div></div></div></div></div><div><figure><div role="button" tabindex="0"><div><p><img alt="Image for post" src="https://miro.medium.com/max/8000/1*XgJam9icd0IYa5ok2IqjBQ.jpeg" width="4000" height="2000" srcset="https://miro.medium.com/max/552/1*XgJam9icd0IYa5ok2IqjBQ.jpeg 276w, https://miro.medium.com/max/1104/1*XgJam9icd0IYa5ok2IqjBQ.jpeg 552w, https://miro.medium.com/max/1280/1*XgJam9icd0IYa5ok2IqjBQ.jpeg 640w, https://miro.medium.com/max/1456/1*XgJam9icd0IYa5ok2IqjBQ.jpeg 728w, https://miro.medium.com/max/1632/1*XgJam9icd0IYa5ok2IqjBQ.jpeg 816w, https://miro.medium.com/max/1808/1*XgJam9icd0IYa5ok2IqjBQ.jpeg 904w, https://miro.medium.com/max/1984/1*XgJam9icd0IYa5ok2IqjBQ.jpeg 992w, https://miro.medium.com/max/2160/1*XgJam9icd0IYa5ok2IqjBQ.jpeg 1080w, https://miro.medium.com/max/2700/1*XgJam9icd0IYa5ok2IqjBQ.jpeg 1350w, https://miro.medium.com/max/3240/1*XgJam9icd0IYa5ok2IqjBQ.jpeg 1620w, https://miro.medium.com/max/3780/1*XgJam9icd0IYa5ok2IqjBQ.jpeg 1890w, https://miro.medium.com/max/4320/1*XgJam9icd0IYa5ok2IqjBQ.jpeg 2160w, https://miro.medium.com/max/4800/1*XgJam9icd0IYa5ok2IqjBQ.jpeg 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*XgJam9icd0IYa5ok2IqjBQ.jpeg?q=20"></p></div></div></figure></div><div><div><p id="42df">As we finally put 2020 into hindsight, the road ahead is uncertain. On the one hand, stock markets continue to thrive, and the economy feels poised to come roaring back, fueled by a population vaccinated and ready to work and play with others again. On the other hand, many worry which bull markets might stumble, and which bubbles might burst.</p><p id="046c">Beyond the legitimate handwringing, there’s one economy that will provide steady, consistent opportunities and growth in the coming decade: The Decarbonization Economy. Call this ClimateTech, Cleantech 2.0, or something new, but know this about the transition to an economy free of carbon emissions: it’s big, it’s getting bigger, and it won’t be going away. This new economy is different. We’re not shoehorning sustainability into old systems. We’re redesigning the economy. The scale of this transformation is on par with the digitization economy before it.</p><p id="1612">Andrew, you say, give me a break. We’ve seen this movie before — in fact, I think you were <a href="https://www.nytimes.com/2007/03/14/technology/14valley.html" rel="noopener"><em>in this movie</em></a>. The Cleantech 1.0 “revolution” turned out to be a dud. The promises were massive, and the results were not. Aren’t you just setting us up to repeat history? Can’t we learn from the past?</p><blockquote><p id="a701">The decarbonization of the global economy is a transformation on par with the digitization of the economy before it.</p></blockquote><p id="fa32"><strong>We <em>can </em>learn from the past — and we are soon to learn that this time is different.</strong> As with many transformations, the visions laid out over a decade ago were powerful, but not ready to scale. Renewable generation was too expensive, batteries weren’t ready to power our vehicles, and much of the world had not felt the sting of climate change. We did the work, but it certainly took longer than we all wanted.</p><h2 id="768d">2000–2021, In Brief</h2><p id="ea54">When I started my journey as a founder in the cleantech world in 2003, “climate change” was a thermostat setting. Al Gore’s documentary <a href="https://www.imdb.com/title/tt0497116/" rel="noopener"><em>An Inconvenient Truth</em></a> was three years from release, and oil was at historic low pricing. What a difference a decade (or two) makes. By 2010, climate was moving up the ladder of “most important” issues on polls, solar was much cheaper, and proof points of climate-related start-ups were starting to appear — including <a href="http://www.tesla.com/" rel="noopener">Tesla</a>, <a href="http://www.sunrun.com/" rel="noopener">Sunrun</a>, <a href="https://www.nextracker.com/" rel="noopener">Nextracker</a>, and <a href="http://www.nest.com/" rel="noopener">Nest</a>, which helped reimagine that thermostat.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4200/0*zbZcrpb21UlhotvX.png" width="2100" height="3243" srcset="https://miro.medium.com/max/552/0*zbZcrpb21UlhotvX.png 276w, https://miro.medium.com/max/1000/0*zbZcrpb21UlhotvX.png 500w" sizes="500px" data-old-src="https://miro.medium.com/max/38/0*zbZcrpb21UlhotvX.png?q=20"></p></div></div></div><figcaption>This Lazard data sums up the steady transformation which took place in the last decade, predicted by <a href="https://www.amazon.com/Solar-Revolution-Publisher-MIT-Press/dp/B004QJYVA6/ref=sr_1_3?dchild=1&amp;keywords=solar+revolution+travis+bradford&amp;qid=1611681942&amp;sr=8-3" rel="noopener">almost </a>no one.</figcaption></figure><p id="df7d">But it wasn’t enough. We didn’t “solve” the existential crisis of climate overnight, and we didn’t create a new fusion device with infinite carbon-free power. Investors used venture dollars for project finance, and mainstream venture just plain missed some of the big winners from FirstSolar to Chinese solar start-ups. So, the attention of tech founders focused elsewhere. All but a resolute few went back to that other transformation of our economy, digitization…and decarbonization was a side-effect, at best (see <a href="https://blog.zoom.us/how-video-meetings-are-helping-reduce-environmental-impact-infographic/" rel="noopener">Zoom</a>).</p><p id="10bf">Fast forward another decade, and we’re back. Early-stage founders, funders, and change-makers are uniting in their commitment to making it work.</p><p id="3f22">But why is this time different? This time is so much broader — we’re talking about all aspects of climate and our economy, not just energy. But beyond that, there are specific drivers of change this time around.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5200/0*uNe1Ojg6nhXXQ2UN.png" width="2600" height="98" srcset="https://miro.medium.com/max/552/0*uNe1Ojg6nhXXQ2UN.png 276w, https://miro.medium.com/max/1104/0*uNe1Ojg6nhXXQ2UN.png 552w, https://miro.medium.com/max/1280/0*uNe1Ojg6nhXXQ2UN.png 640w, https://miro.medium.com/max/1400/0*uNe1Ojg6nhXXQ2UN.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*uNe1Ojg6nhXXQ2UN.png?q=20"></p></div></div></div></figure><h2 id="0012"><strong>Today: Five Key Differences</strong></h2><p id="0e8b">What clear signals make me confident in our ability to create massive value while transforming our global economy, and why today? Here’s my top five.</p><p id="22f5"><strong><em>1. Corporate and Consumer Demand Both Go Clean</em></strong><em><br></em>There’s a <a href="https://sproutsocial.com/insights/retail-social-sustainability-trend/" rel="noopener">perfect storm today</a> of consumers, investors, and corporations all pushing in the same direction. Large multinationals are tripping over each other in an effort to become the leaders in speed (“<a href="https://www.apple.com/newsroom/2020/07/apple-commits-to-be-100-percent-carbon-neutral-for-its-supply-chain-and-products-by-2030/" rel="noopener">Carbon Neutral by 2030</a>!”) or depth (“<a href="https://blogs.microsoft.com/blog/2020/01/16/microsoft-will-be-carbon-negative-by-2030/" rel="noopener">Carbon <em>Negative </em>by 2030</a>!”). These are not pie-in-the-sky, free-of-charge goals. These ambitions cost money, and take time and focus. Compared to the last go-around, these companies are now tooling up and learning from the past. They have met some of those early goals (<a href="https://sustainability.google/progress/" rel="noopener">see: Google</a>), and know what it takes. Expect to see more mention of “100%” and “Net Neutral” in the coming years. These labels will apply to energy, but also water, agriculture, and mobility. Corporate board rooms are already <a href="https://youtu.be/wj0UrF2T130" rel="noopener">boning up</a> on the differences between scope 1, scope 2, and scope 3 emissions because they know the next generation of customers will demand they get it (see #4).</p><p id="ce0f">Consumers are also behaving differently this time around. Whereas before climate change was more in the movies than a lived experience, today they see it — and are increasingly living it — year round.<strong> </strong>The fact that Californians talk about “fire season” now like it’s just part of the calendar is <a href="https://www.nationalgeographic.com/science/2020/09/climate-change-increases-risk-fires-western-us/" rel="noopener">the tip of the melting iceberg</a>. According to <a href="https://www.edf.org/sites/default/files/Business-and-the-Fourth-Wave-of-Environmentalism_2019.pdf" rel="noopener">one survey</a>, 93% of executives believe customers hold them accountable for their environmental impact.</p><p id="df35">The availability of transparent information plays a role here as well. Younger generations leading today’s buying power use the internet to clearly understand their ingredient labels — not just for what they put in their bodies, but what they put on their bodies, feed their pets, and use to build (and clean)<strong> </strong>their homes. They are coming to expect that those ingredient labels also help them understand their carbon and environmental impact.</p><p id="f1cd"><strong><em>2. Cost and Performance</em></strong><em> <br></em>Today, evidence is everywhere that we are in the midst of a complete transformation of carbon-producing economies. Solar costs have dropped by 90% in the last decade alone (and 90% in the decade before that). Wind energy is now cost competitive in most parts of the world. Batteries are powering some of the most popular passenger cars ever made. It took us two decades to get to this point, but the better way is now also the more economical way.</p><p id="89e3">What’s even more exciting is that, <a href="https://www.vox.com/2015/10/12/9510879/iea-underestimate-renewables" rel="noopener">if history is any guide</a>, we’re still radically underestimating what’s ahead:</p></div></div><div><div><div><div><figure><div role="button" tabindex="0"><div><p><img alt="Image for post" src="https://miro.medium.com/max/1706/1*syOjrjnKiut146fUr9tuCw.jpeg" width="853" height="759" srcset="https://miro.medium.com/max/552/1*syOjrjnKiut146fUr9tuCw.jpeg 276w, https://miro.medium.com/max/1008/1*syOjrjnKiut146fUr9tuCw.jpeg 504w" sizes="504px" data-old-src="https://miro.medium.com/max/60/1*syOjrjnKiut146fUr9tuCw.jpeg?q=20"></p></div></div></figure><figure><div role="button" tabindex="0"><div><p><img alt="Image for post" src="https://miro.medium.com/max/1690/1*tp-b8eDBngvE0Fc7ne1MIA.jpeg" width="845" height="763" srcset="https://miro.medium.com/max/552/1*tp-b8eDBngvE0Fc7ne1MIA.jpeg 276w, https://miro.medium.com/max/994/1*tp-b8eDBngvE0Fc7ne1MIA.jpeg 497w" sizes="497px" data-old-src="https://miro.medium.com/max/60/1*tp-b8eDBngvE0Fc7ne1MIA.jpeg?q=20"></p></div></div><figcaption>The International Energy Agency has been woefully off in forecasting renewables growth.</figcaption></figure></div></div></div></div><div><div><p id="049f">These charts take a minute to digest, but it’s worth the effort. Solar and wind cost estimates from the IEA have been so far off for so long, it’s staggering. Luckily, there are <a href="https://about.bnef.com/new-energy-outlook/" rel="noopener">better sources</a>.</p><p id="ff8e">If these trends continue to be this far off not only for clean energy, but also for energy storage, things are about to get interesting. With solar, wind, and energy storage as the only obvious choices for generation and land-based mobility, <a href="https://www.greentechmedia.com/articles/read/almost-all-new-us-power-plants-in-2021-will-be-carbon-free" rel="noopener">it appears</a> we are at the beginning of radical disruption.</p><p id="6e60"><strong><em>3. Follow the Money</em></strong><em><br></em>While scientists and industry insiders have seen this wave coming for some time, the money has now definitively entered the building. Unlike last time around, this isn’t about loan guarantees or DARPA grants (<a href="https://www.greentechmedia.com/articles/read/what-renewable-energy-and-energy-storage-did-and-didnt-get-from-congress-this-week" rel="noopener">though they’re there too</a>), it’s about every layer of the capital stack. One need look no further than <a href="https://www.google.com/search?q=tesla+stock+perfomance&amp;rlz=1C5CHFA_enUS879US879&amp;oq=tesla+stock+perfomance+&amp;aqs=chrome..69i57j0i13i457j0i13l6.5962j1j9&amp;sourceid=chrome&amp;ie=UTF-8" rel="noopener">Tesla’s stock price</a> to see the demand on the electric vehicle (EV) front. <a href="http://www.proterra.com/" rel="noopener">Proterra</a>, our first investment in the EV space over four years ago, announced a <a href="https://digiday.com/media/wtf-is-a-spac/" rel="noopener">SPAC </a>last week, and shared revenue forecasts in the many hundreds of millions. The SPACfest now in full swing around EVs and energy storage is next up. The retail investor demand for future-proof, anti-fragile tech and business models is clear.</p><p id="7f25">Below that, the private money is also showing up. An increasing number of LPs, family offices, and institutional investors understand this transition is happening, and is where alpha returns will be derived. With <a href="https://pitchbook.com/newsletter/former-goldman-sachs-head-to-lead-climate-fund-at-tpg" rel="noopener">TPG</a>, <a href="https://techcrunch.com/2020/02/12/financing-for-social-impact-and-climate-businesses-gets-a-billion-dollar-boost-with-new-kkr-fund/" rel="noopener">KKR</a>, <a href="https://www.wellingtonfunds.com/en-gb/intermediary/wellington-launches-climate-strategy-ucits-fund/" rel="noopener">Wellington</a>, <a href="https://www.breakthroughenergy.org/" rel="noopener">Breakthrough Energy Ventures</a>, <a href="https://www.wsj.com/articles/union-square-ventures-plans-its-first-climate-tech-fund-11605661084" rel="noopener">Union Square Ventures</a>, <a href="https://techcrunch.com/2020/12/15/fifth-wall-adds-new-partner-as-it-seeks-at-least-200-million-for-a-new-climate-impact-fund/" rel="noopener">Fifth Wall</a>, <a href="https://www.energyimpactpartners.com/" rel="noopener">EIP</a>, <a href="https://congruentvc.com/" rel="noopener">Congruent</a>, <a href="http://www.g2vp.com/" rel="noopener">G2VP</a>, <a href="https://www.preludeventures.com/" rel="noopener">Prelude</a>, <a href="http://www.dblpartners.vc/" rel="noopener">DBL</a>, <a href="https://www.techstars.com/the-line/pov/accelerators-tackling-climate-change-industry-breakdown" rel="noopener">Techstars</a>, <a href="https://twitter.com/MoxxieVentures/status/1334182509697929216?s=20" rel="noopener">Moxxie </a>and many more, the <a href="https://climatetechvc.substack.com/p/-a-running-list-of-climate-tech-vcs" rel="noopener">list of climate-focused funds</a> (and their fund sizes) is growing rapidly. Of course, corporates are getting in the game as well. You can expect to see all of the Oil Majors convert to “Energy Majors” as many in Europe have <a href="https://orsted.com/en" rel="noopener">already</a> <a href="https://www.fortum.com/" rel="noopener">done</a>. Even <a href="https://sustainability.aboutamazon.com/about/climate-pledge-fund" rel="noopener">Amazon </a>and <a href="https://www.microsoft.com/en-us/corporate-responsibility/sustainability/climate-innovation-fund" rel="noopener">Microsoft </a>are all in. Also critical is the vibrant ecosystem of seed and early-stage investors like <a href="https://twitter.com/sacca" rel="noopener">Chris Sacca’s</a> <a href="https://lowercarboncapital.com/" rel="noopener">Lowercarbon Capital</a>, <a href="https://www.linkedin.com/in/matt-petersen-0771691/" rel="noopener">Matt </a>and <a href="https://www.linkedin.com/in/tajahmadeldridge/" rel="noopener">Taj </a>at <a href="https://laincubator.org/programs/" rel="noopener">LACI</a>, <a href="https://www.linkedin.com/in/kirschemily/" rel="noopener">Emily </a>at <a href="https://www.powerhouse.fund/ventures" rel="noopener">Powerhouse Ventures</a>, <a href="https://www.linkedin.com/in/sundeep/" rel="noopener">Sundeep </a>at <a href="https://www.climatecapital.co/" rel="noopener">Climate Capital</a>, <a href="https://www.linkedin.com/in/dawnlippert/" rel="noopener">Dawn </a>at <a href="https://elementalexcelerator.com/" rel="noopener">Elemental Excelerator</a>, Seth and Ela at <a href="https://fiftyyears.com/" rel="noopener">50Years</a>, <a href="https://www.linkedin.com/in/joshfelser/" rel="noopener">Josh </a>(of <a href="https://freestyle.vc/" rel="noopener">Freestyle </a>fame) and <a href="https://www.linkedin.com/in/jjacobs22/" rel="noopener">Jason </a>of <a href="https://www.myclimatejourney.co/" rel="noopener">My Climate Journey</a>. Great angels like <a href="https://www.linkedin.com/in/sierrap/" rel="noopener">Sierra Peterson</a>, <a href="https://jetstream.io/" rel="noopener">Tommy Leep</a> and <a href="https://pinver.medium.com/" rel="noopener">Pietro Invernizzi</a> (now at <a href="https://stride.vc/" rel="noopener">Stride</a>) are also working hard to move the conversation <a href="https://medium.com/r?url=https%3A%2F%2Fairtable.com%2FshrD3pdi6zuYLH6PV%2FtblF44FWZHDMt4bIp" rel="noopener">forward</a>.</p><p id="d6f1"><strong><em>4. The Next Generation</em></strong><em><br></em>In addition to demanding clarity on the impact of their purchases, Millennials and Gen Z also want to find impact in their work. <a href="https://www.fastcompany.com/90306556/most-millennials-would-take-a-pay-cut-to-work-at-a-sustainable-company" rel="noopener">According to one survey</a>, 70% of Millennials are more likely to join companies strong in sustainability. This conviction in livelihood and purchasing intent seems only to increase with younger survey respondents — and there is no evidence whatsoever that it will slow down. As we’ve seen in recent elections the world around, the climate issue polls higher and higher with every new cycle. We also see a clear push to do this in a more diverse, inclusive and equitable way. Leadership at the grassroots level is everywhere (see <a href="https://www.edictnow.org/" rel="noopener">Edict</a>, <a href="https://twitter.com/familiavc?s=21" rel="noopener">VCFamilia</a>, <a href="http://browningthegreenspace.org/" rel="noopener">Browning the Green Space</a>, <a href="https://www.greentechnoir.com/" rel="noopener">GreenTech Noir</a>, <a href="http://earthincolor.co/" rel="noopener">Earth in Color</a>).</p><p id="2efc"><strong><em>5. Policy and Regulation</em></strong><em><br></em>Consumer behavior and corporate response act as a virtuous cycle of improvement for these industries. That’s the carrot, but there are sticks as well. Governments around the world have offered varying levels of support and pressure in this transition. Chinese mandates, European subsidies, and even the U.S.’s distributed (state-level) efforts — all point to a world clearly moving in the same direction: fewer emissions, and fast. Let’s face it: fearless, consistent leaders like <a href="https://www.linkedin.com/in/franpavley/" rel="noopener">Fran Pavley</a>, <a href="https://www.linkedin.com/in/david-hochschild-1520106/" rel="noopener">David Hochschild</a> and <a href="https://www.linkedin.com/in/mary-nichols-2b68bb6/" rel="noopener">Mary Nichols</a> stepped up in California for much of the nation (and at times for <a href="https://www.cnbc.com/2020/07/23/teslas-sale-of-environmental-credits-help-drive-to-profitability.html" rel="noopener">Tesla</a>), while others at the federal level walked.</p><p id="9bfe">While the U.S. movement has relied heavily on state-level efforts to date, there’s <a href="https://www.nytimes.com/2021/01/19/climate/biden-climate-change.html" rel="noopener">real reason to believe</a> that this new administration, coupled with many Republicans who want to support climate action now, will be aggressively playing catch up in the coming years. <a href="https://www.nytimes.com/2020/12/15/business/economy/fed-climate-network.html" rel="noopener">Even …</a></p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://worldpositive.com/we-have-entered-the-climate-decade-70b7f433271b">https://worldpositive.com/we-have-entered-the-climate-decade-70b7f433271b</a></em></p>]]>
            </description>
            <link>https://worldpositive.com/we-have-entered-the-climate-decade-70b7f433271b</link>
            <guid isPermaLink="false">hacker-news-small-sites-25978413</guid>
            <pubDate>Sun, 31 Jan 2021 12:47:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Playing Tetris over Serial Console]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25978368">thread link</a>) | @hggh
<br/>
January 31, 2021 | http://meta.libera.cc/2021/01/playing-tetris-over-serial-console.html | <a href="https://web.archive.org/web/*/http://meta.libera.cc/2021/01/playing-tetris-over-serial-console.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-wrapper">
<div id="main"><div data-version="1" id="Blog1">
<div>

          <div>
        
<h2><span>samedi 30 janvier 2021</span></h2>

          <div>
        
<div>
<div itemprop="blogPost" itemscope="itemscope" itemtype="http://schema.org/BlogPosting">
<meta content="https://asciinema.org/a/388067.svg" itemprop="image_url">
<meta content="7143401328277522244" itemprop="blogId">
<meta content="2041729387144771878" itemprop="postId">
<h3 itemprop="name">
Playing Tetris over serial console
</h3>
<div>

</div>
<div id="post-body-2041729387144771878" itemprop="description articleBody">
<div><p>Today I played Tetris over a serial console connection, on a Vax 4000 running OpenBSD. I haven't felt that <i>1337 </i>since a long time.<br>I am going to get rid of that Vax system though. If that's your stuff, contact me privately.</p><p><a href="https://asciinema.org/">asciinema</a> in its greatness:</p></div>
<p><a href="https://asciinema.org/a/388067" target="_blank"><img src="https://asciinema.org/a/388067.svg"></a></p>
</div>
<div>
<div>
<p><span>
Publié par
<span itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person">
<meta content="https://www.blogger.com/profile/09406228937831964688" itemprop="url">
<a href="https://www.blogger.com/profile/09406228937831964688" rel="author" title="author profile">
<span itemprop="name">Emmanuel Kasper</span>
</a>
</span>
</span>
<span>
à
<meta content="http://meta.libera.cc/2021/01/playing-tetris-over-serial-console.html" itemprop="url">
<a href="http://meta.libera.cc/2021/01/playing-tetris-over-serial-console.html" rel="bookmark" title="permanent link"><abbr itemprop="datePublished" title="2021-01-30T20:10:00+01:00">20:10</abbr></a>
</span>
<span>
</span>
<span>
</span>
<span>
<span>
<a href="https://www.blogger.com/post-edit.g?blogID=7143401328277522244&amp;postID=2041729387144771878&amp;from=pencil" title="Modifier l'article">
<img alt="" height="18" src="https://resources.blogblog.com/img/icon18_edit_allbkg.gif" width="18">
</a>
</span>
</span></p>
</div>
<div>
<p><span>
Libellés :
<a href="http://meta.libera.cc/search/label/floss" rel="tag">floss</a>
</span>
</p></div>

</div>
</div>
<div id="comments">
<h4>Aucun commentaire:</h4>
<div id="Blog1_comments-block-wrapper">
<dl id="comments-block">
</dl>
</div>
<p>
<a href="https://www.blogger.com/comment.g?blogID=7143401328277522244&amp;postID=2041729387144771878" onclick="">Publier un commentaire</a>
</p>
</div>
</div>

        </div></div>
      
</div>
<div id="blog-pager">
<p><span id="blog-pager-older-link">
<a href="http://meta.libera.cc/2021/01/how-to-move-single-vm-between-cloud.html" id="Blog1_blog-pager-older-link" title="Article plus ancien">Article plus ancien</a>
</span>
<a href="http://meta.libera.cc/">Accueil</a>
</p></div>

<div>
<div><p>
Inscription à :
<a href="http://meta.libera.cc/feeds/2041729387144771878/comments/default" target="_blank" type="application/atom+xml">Publier les commentaires (Atom)</a>
</p></div>
</div>
</div></div>
</div></div>]]>
            </description>
            <link>http://meta.libera.cc/2021/01/playing-tetris-over-serial-console.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25978368</guid>
            <pubDate>Sun, 31 Jan 2021 12:39:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Run containers without pulling images]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25978284">thread link</a>) | @harporoeder
<br/>
January 31, 2021 | https://www.scrivano.org/2019/10/24/run-containers-without-pulling-images/ | <a href="https://web.archive.org/web/*/https://www.scrivano.org/2019/10/24/run-containers-without-pulling-images/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<div>
<div>
<article role="main">
<p>CRFS is a Google project that aims at running a container without pre-pulling the image first.</p>
<p>The idea is quite smart: an OCI layer (that is basically a compressed tarball), is modified in a way that it is possible to seek content inside of it and access a single file.
It is designed around the stargz (Seekable tar.gz) format. Instead of having a single compressed tar stream, the stargz modifies it to concatenate the gzipped stream of each file. Old clients are still able to handle the stargz’ipped stream as a regular .tar.gz file.</p>
<p>In an attempt to support CRFS with fuse-overlayfs, I’ve worked on adding a plugin system to fuse-overlayfs (<a href="https://github.com/containers/fuse-overlayfs/pull/119">https://github.com/containers/fuse-overlayfs/pull/119</a>). It will make possible to extend it and support different ways to retrieve data from the lower layers.</p>
<p>The second step is a plugin that can handle CRFS, it is still a PoC but seems to work quite nicely: <a href="https://github.com/giuseppe/crfs-plugin">https://github.com/giuseppe/crfs-plugin</a></p>
<p>To create a stargz image, you’d need to use stargzify</p>
<div><pre><code data-lang="bash"><span># go get -u github.com/google/crfs/stargz/stargzify</span>
</code></pre></div><p>Once stargzify is installed, an image can be converted as:</p>
<div><pre><code data-lang="bash"><span># stargzify docker.io/fedora docker.io/gscrivano/test:stargz</span>
2019/10/24 20:33:33 pushed blob: sha256:c7155ae298b145d79e75c396ab5cb917023c4fd8b9cf8c7ff2f0332b41ef8651
2019/10/24 20:33:34 pushed blob: sha256:5a419d36bce538fa32fc21cbe11134ccbd70597379d9320f3a32eb6be78e4ad5
2019/10/24 20:33:35 docker.io/gscrivano/test:stargz: digest: sha256:ca6723c15c5b3b0947deef12048ee64126ed237e112cfbde300ce0f4066a4b4d size: <span>428</span>
</code></pre></div><p>The image was pushed to the registry. Let’s create a container:</p>
<div><pre><code data-lang="bash"><span># mkdir lower upper workdir merged</span>
<span># export DATA=$(echo -n docker://docker.io/gscrivano/test:stargz | base64 -w0)</span>
<span># OPTS=fast_ino=1,plugins=/path/to/crfs-plugin.so,lowerdir=//crfs/$DATA/lower,upperdir=upper,workdir=work</span>
<span># fuse-overlayfs -o $OPTS merged</span>
</code></pre></div><p>The image, passed to fuse-overlayfs encoded in base 64, is mounted at the merged directory.</p>
<div><pre><code data-lang="bash"><span># ls merged/</span>
bin   dev  home   lib    lost+found  mnt  proc  run   srv   sys  usr
boot  etc  hosts  lib64  media       opt  root  sbin  tmp  var
</code></pre></div><p>To run the container, we can take advantage of the Podman –rootfs feature. It tells Podman to not manage the storage for the container, but to use the specified path as its rootfs.</p>
<div><pre><code data-lang="bash"><span># podman run --rm -ti --rootfs merged /bin/sh</span>
sh-5.0#
</code></pre></div><p>Now we are in a container where files from the lower layers will be loaded on demand when requested.</p>
</article>

</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.scrivano.org/2019/10/24/run-containers-without-pulling-images/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25978284</guid>
            <pubDate>Sun, 31 Jan 2021 12:22:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Whirlwind Tour of the Apple Sandbox]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25978051">thread link</a>) | @tosh
<br/>
January 31, 2021 | https://ubrigens.com/posts/sandbox_tour.html | <a href="https://web.archive.org/web/*/https://ubrigens.com/posts/sandbox_tour.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
        
        <div id="content"><div>
    <h2>
        A Whirlwind Tour of the Apple Sandbox
        <span>February 17, 2020</span>
    </h2>
    <p>No-one knows how to design truly secure software. Any sufficiently complex software <em>will</em> contain vulnerabilities that can be abused by motivated attackers to subvert a program’s execution. Accepting this reality, the focus of the last few decades has been on developing exploit mitigation techniques such as <em>Address Space Layout Randomisation</em> (ASLR) and <em>Data Execution Prevention</em> (DEP) which focus on <em>increasing difficulty and costs</em> for attackers.</p>
<figure>
<img src="https://ubrigens.com/assets/images/sandbox_tour/dac_mac.svg" alt="Overview: DAC vs MAC"><figcaption>Overview: DAC vs MAC</figcaption>
</figure>
<p>Sandboxing is one such mitigation. It aims to reduce the damage of successful attacks on the host system. On traditional UNIX systems, programs run <em>as</em> a user (in what’s referred to as <em>discretionary access control</em> — DAC), inheriting all her capabilities and permissions. Most of these capabilities and permissions however are never actually required by the executing program. Sandboxing (a form of <em>mandatory access control</em> or MAC) uses per-application security policies to limit the actions a program may take and the resources it is allowed to access; it aims to make <em>what a program can do</em> the same as <em>what a program was made to do</em>. In this way, sandboxing implements the foundational information security principle of <strong>least privilege</strong>, which states that programs and users should operate using the least amount of privilege necessary to complete a certain job. Sandboxed applications – even when compromised – can access only predefined parts of the system, limiting their damage potential and requiring attackers to escape the sandbox to compromise the system itself.</p>
<p>Security benefits afforded by sandboxing hinge on proper configuration and understanding of the sandbox mechanism itself. No mitigation is perfect; <a href="https://twitter.com/halvarflake/status/1156815950873804800">Mitigations have complexity, inspectability and debuggability costs</a>. The App Sandbox is no exception: it has had a massive impact on developers scrambling to sandbox their software which was largely designed without sandboxing in mind. Apple’s sandbox implementation lacks public documentation. It “just works”, until it doesn’t. In 2018, I wrote my Master’s Thesis on the topic. In this series of posts, I am sharing what I learned in the process. My focus today is on implementation, configuration and design internals that might not be known to a wider audience.</p>
<h3 id="threat-model">Threat Model</h3>
<p>A threat model states what you (a user / a mitigation / a security system) are protecting against (and also what’s not covered). It is crucial to motivate the need for any mitigation; Unfortunately, Apple does not provide an explicit threat model for the App Sandbox. I pieced together my own version here from available marketing materials, developer-facing documentation and public sandbox-related patents.</p>
<p>The App Sandbox “<a href="https://developer.apple.com/library/archive/documentation/Security/Conceptual/AppSandboxDesignGuide/AboutAppSandbox/AboutAppSandbox.html">is designed to contain damage to the system and the user’s data if an app becomes compromised</a>”. However, it is “<a href="https://developer.apple.com/videos/play/wwdc2011/204/">not an anti-virus system; does not target intentionally malicious software</a>”. There is no practical difference between “intentionally malicious software” and software “compromised by malicious software”. This last quote can therefore only mean that <em>sandboxing in itself cannot stop malicious applications from abusing their officially granted permissions</em>, i.e.&nbsp;a malicious app can steal all user data it legitimately has access to. Sandboxing however should restrict even malicious applications from accessing resources that the app is not entitled to access. This interpretation of the former quote is consistent with Apple’s own patents on the topic, which motivate the need for sandboxing by stating that a “<a href="https://patents.google.com/patent/US9280644B2/en">program may be a malicious program that is developed to intentionally cause damages</a>” and “<a href="https://patents.google.com/patent/US9280644B2/en">by restricting the execution of a program within a restricted operating environment, such damages can be greatly reduced</a>”. Related patents echo this interpretation [<a href="https://patents.google.com/patent/US8943550">1</a>, <a href="https://www.researchgate.net/publication/302691438_System_and_method_for_preserving_references_in_sandboxes">2</a>].</p>
<p>All programs are initially launched <em>non-sandboxed</em> because they “<a href="https://patents.google.com/patent/US8635663">may not have had an opportunity to compile and prepare a profile to express permitted actions</a>”. This is argued to be “<a href="https://patents.google.com/patent/US8635663">consistent with the […] design of [the Sandbox] that permits intentional user actions</a>”. Here, a user launching an application is interpreted as user intent. This little-known fact, which is completely absent from all official documentation, is the achilles heel of the whole system. Under <em>normal</em> circumstances, the sandbox is initialised before transfer is controlled to application code. However, because initialisation happens in the context of the application itself, there is precious little room for error. As it stands, there is no process to ensure applications, whose metadata suggest they should run sandboxed, actually run sandboxed. I feel that this runs counter to the idea of <em>mandatory</em> sandboxing on macOS.</p>
<h2 id="configuration">Configuration</h2>
<p>Apple’s sandbox restricts programs in what they can do on the user’s system. As every application is unique, the sandbox theoretically has to be configured individually for each app. This cumbersome process falls to developers to do. For software distributed in the Mac App Store (MAS), sandboxing is mandatory and enforced by Apple. <a href="https://svs.informatik.uni-hamburg.de/publications/2019/2019-11-Blochberger-State-of-the-Sandbox.pdf">Outside the MAS, sandboxing is still the exception, not the rule</a>.</p>
<p>To configure per-program sandbox policies, two options are available: <em>SBPL</em>, a low-level configuration language, and <em>entitlements</em>, which offer a high-level interface and are the only officially supported sandbox configuration option.</p>
<h3 id="sbpl">SBPL</h3>
<p>The Sandbox Profile Language (SBPL) is implemented on top of the Scheme programming language. In what is referred to as an embedded domain specific language (EDSL), the base language (Scheme) is extended and augmented by custom identifiers, functions and macros to encode sandbox rules.</p>
<figure>
<img src="https://ubrigens.com/assets/images/sandbox_tour/sbpl_components.svg" alt="SBPL Language Components"><figcaption>SBPL Language Components</figcaption>
</figure>
<p>Sandbox profiles written in SBPL consist of multiple rules specified one after the other. Later rules can overwrite preceding rules, which is commonly used to implement whitelisting profiles: Deny everything first, then selectively re-enable only what is needed. Confirmed by extensive testing, the <em>last applicable rule</em> in a profile guides the final sandbox decision for a certain resource. Each rule consists of up to four components: An <em>action</em>, one or more <em>operations</em>, and optional <em>filters</em> and <em>modifiers</em>. Actions decide whether to allow or deny resource accesses. Operations denote the kind of resource access the rule applies to. Filters restrict a rule’s effect to a subset of all resources, for example only to files in a certain directory. Lastly, modifiers change the default behaviour of the sandbox. By default, only denied resource accesses are logged; a modifier changes this. A few years back, <a href="https://twitter.com/osxreverser">@osxreverser</a> bothered to <a href="https://reverse.put.as/wp-content/uploads/2011/09/Apple-Sandbox-Guide-v0.1.pdf">document the language</a>. It’s somewhat outdated, but still very useful.</p>
<p>While the core SBPL language as described above is conceptually simple, SBPL profiles can include arbitrary Scheme code to dynamically <em>generate sandbox rules during evaluation</em>. Consider the following two SBPL snippets; Their compiled sandbox bytecode is identical.</p>


<p>Developers wishing to write SBPL sandbox profiles directly call <code>sandbox_init</code> from their application to voluntarily enable sandboxing. Well intentioned power users can use the <code>sandbox-exec</code> command line utility to run third-party software in custom sandboxes. Don’t bother doing this however; the software will not work correctly. On the off chance it does work correctly, your sandbox profile will be too permissive.</p>
<p>SBPL is complex and difficult to use, even for experienced developers. Though only rarely used <em>directly</em> nowadays, it still forms the foundation for sandboxing on macOS and therefore remains important to understand.</p>
<h3 id="entitlements">Entitlements</h3>
<p><em>Entitlements</em> were introduced for reasons of usability. A “<a href="https://patents.google.com/patent/US20130283344">developer does not need to know how to program or set up a set of rules for the purpose of generating a security profile</a>”. Instead, developers specify entitlements that represent the resources and capabilities their software needs to use (and hopefully no others).</p>
<p>Entitlements are not specific to sandboxing; They are also used for <em>iCloud</em>, <em>Push Notifications</em> and <em>Apple Pay</em>, to name just a few. At its core, each <em>entitlement</em> is a key-value pair, where the key is a string identifying the entitlement and the value configures the entitlement. Values can be of any type supported in property lists, including booleans, strings, dictionaries or arrays. <em>Entitlements</em> are then simply a collection of a program’s individual capabilities. Developers add the entitlements their applications require using Xcode or manually by editing a property list file. This list is securely embedded in the target program as part of its code signature and cannot be tampered with without invaliding an app’s cryptographic code signature. Using the <code>codesign</code> utility shows you which entitlements are embedded in binaries on your system:</p>

<p>Here we see <code>Calculator.app</code>’s entitlements. Applications enabling the App Sandbox using the <code>com.apple.security.app-sandbox</code> entitlement are automatically sandboxed before any application code has the chance to execute (or so in theory…). Apple mandates sandboxing for applications from the MAS and ensures new apps possess this crucial entitlement. <code>Calculator.app</code> further declares entitlements allowing it to make outbound network connections (<code>*.network.client</code>), print, as well as read <em>and</em> write user-selected files. However, <code>Calculator.app</code> will for example never be able to use the microphone.</p>
<p>The list of documented (and undocumented) entitlements grows with every new macOS release. Check out <a href="http://newosxbook.com/ent.jl">Levin’s entitlement database</a> and setup <a href="https://github.com/ChiChou/wiggle">wiggle</a> on your Mac to investigate further.</p>
<p>In contrast to SBPL, entitlements are easy to understand and use. They hide the underlying complexity of the sandbox from developers, at the expense of policy flexibility.</p>
<h2 id="architecture">Architecture</h2>
<p>Apple’s sandbox is made up of components both in user space and in the kernel. Kernel components “<a href="https://patents.google.com/patent/US20130283344">increase security and provide an efficient mechanism</a>”. The following graphic and text gives an …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ubrigens.com/posts/sandbox_tour.html">https://ubrigens.com/posts/sandbox_tour.html</a></em></p>]]>
            </description>
            <link>https://ubrigens.com/posts/sandbox_tour.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25978051</guid>
            <pubDate>Sun, 31 Jan 2021 11:33:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Turn an IKEA Coffee Table into a DIY Server Rack]]>
            </title>
            <description>
<![CDATA[
Score 408 | Comments 195 (<a href="https://news.ycombinator.com/item?id=25978013">thread link</a>) | @thejokersthief
<br/>
January 31, 2021 | https://wiki.eth0.nl/index.php/LackRack | <a href="https://web.archive.org/web/*/https://wiki.eth0.nl/index.php/LackRack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><div><div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lackrack_manual_page_1_400x566.png"><img alt="" src="https://wiki.eth0.nl/images/3/33/Lackrack_manual_page_1_400x566.png" decoding="async" width="400" height="566" data-file-width="400" data-file-height="566"></a></p></div></div>



<div><div><p><a href="https://wiki.eth0.nl/index.php/File:LackRack.jpg"><img alt="" src="https://wiki.eth0.nl/images/7/7a/LackRack.jpg" decoding="async" width="400" height="300" data-file-width="3072" data-file-height="2304"></a></p><div><p>The first implementation: Red LackRack with Ethernet switch and table lamp</p></div></div></div>
<p>First occurrence on <a href="https://wiki.eth0.nl/index.php/Eth0:2010_Winter" title="Eth0:2010 Winter">eth0:2010 Winterlan</a>, the LackRack is the ultimate, low-cost, high shininess solution for your modular datacenter-in-the-living-room. Featuring the <a rel="nofollow" href="http://www.ikea.com/us/en/catalog/products/40104270">LACK</a> (side table) from Ikea, the LackRack is an easy-to-implement, exact-fit datacenter building block.
It's a little known fact that we have seen Google engineers tinker with Lack tables since way back in 2009.
</p><p>The LackRack will certainly make its appearance again this summer at <a href="https://wiki.eth0.nl/index.php/Eth0:2010_Summer" title="Eth0:2010 Summer">eth0:2010 Summer</a>.
</p>

<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lack-offline.jpg"><img alt="" src="https://wiki.eth0.nl/images/7/79/Lack-offline.jpg" decoding="async" width="250" height="244" data-file-width="250" data-file-height="244"></a></p><div><p>When temporarily not in use, multiple LackRacks can be stacked in a space-efficient way <i>without disassembly</i>, unlike competing 19" server racks.</p></div></div></div><p>The LackRack was first seen on <a href="https://wiki.eth0.nl/index.php/Eth0:2010_Winter" title="Eth0:2010 Winter">eth0:2010 Winterlan</a> in the no-shoe Lounge area. Its low-cost and perfect fit are great for mounting up to 8 U of 19" hardware, such as switches (see below), or perhaps other 19" gear. It's very easy to assemble, and thanks to the design, they are stable enough to hold (for example) 19" switches and you can put your bottle of Club-Mate on top! Multi-shiny LackRack can also be painted to your specific preferences and the airflow is unprecedented!
</p>
<p>You can find a howto on buying a LackRack on <a rel="nofollow" href="http://mrngm.com/eth0/LackRack/">this page</a>. This includes the proof that a 19" switch can indeed be placed in the LackRack in its natural habitat!
</p>
<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lackrack-w-switch.jpg"><img alt="" src="https://wiki.eth0.nl/images/d/d7/Lackrack-w-switch.jpg" decoding="async" width="250" height="188" data-file-width="2592" data-file-height="1944"></a></p><div><p>Close-up of the LackRack, with a switch, in its natural habitat (the IKEA)</p></div></div></div>

<div><div><p><a href="https://wiki.eth0.nl/index.php/File:5x_lackrack.jpg"><img alt="" src="https://wiki.eth0.nl/images/9/99/5x_lackrack.jpg" decoding="async" width="250" height="250" data-file-width="800" data-file-height="800"></a></p><div><p>Illustration of the LackRack's modularity</p></div></div></div><p><i>For assembly in terms of a programming language, this is not the page you need.</i>
</p><p>However, in order to assemble the LackRack, there are a few prerequisites or tools that are needed:
</p>
<ul><li>1 (or more) LACK side table from Ikea</li>
<li>Screwdriver (whether muscle-driven or motor-driven, with preference of the latter)</li>
<li>Wood screws (they should fit in the rack mounts on your appliance, and not exceed 1" in length)</li>
<li>Spare time</li></ul>
<p>That's all! First, follow the assembly instructions in the Ikea manual in order to assemble the LACK.
After that, the installation of your 19" hardware can begin. When assembling a larger number of LACKs, <a rel="nofollow" href="http://www.instructables.com/id/IKEA_Hack_a_Lack/">this link</a> describes a useful tool for fitting the legs to the tabletop.
</p><p>The LackRack is a stackable modular product. Additional elements can be stacked on top easily. Brackets to secure the top element to the bottom one are not included but available from your local non-computer hardware store.
</p>
<ul><li>If you put several LackRacks side by side, the higher levels can be staggered to form a pyramid. This feature is not present in any other of the commercially available rack products.</li></ul>

<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lackrack2.jpg"><img alt="" src="https://wiki.eth0.nl/images/7/76/Lackrack2.jpg" decoding="async" width="300" height="400" data-file-width="1536" data-file-height="2048"></a></p><div><p>Due to their light weight design, Lackracks will grow to any required size without compromise</p></div></div></div>
<p>Installing hardware in your LackRack is easy!
</p>
<ul><li><i>Optional but recommended</i> - Put the table on its side (which one is your decision) or upside down</li>
<li>Mount the hardware between the left and right leg
<ul><li>If you mount the first item, it is recommended to install it against the table top for good fit. This happens automatically if you have the LackRack upside down, except in zero gravity environments.</li></ul></li>
<li>Screw all the screws that fit in the rack mount in the left and right leg (for stability).
<ul><li>With deep units, a Z-shaped bracket may be advisable to secure the rear of the unit against the underside of the tabletop.</li></ul></li>
<li>&nbsp;???</li>
<li>Profit! (note how <a rel="nofollow" href="http://www.rackable.com/">lackable.com</a> has been bought by sgi recently)</li></ul>
<h2><span id="Note">Note</span></h2>
<p>Current LACK tables have hollow legs; only the top 5 cm (2") is solid. Fitting equipment below the solid section may require the use of cavity plugs, such as <a rel="nofollow" href="https://www.fischer-international.com/en/products/cavity-fixings/board-fixing/metal-cavity-fixing-hm/519772-hm-5-x-37-s">these</a>
</p>
<h2><span id="Goodies">Goodies</span></h2>
<ul><li>You can put food and/or drink on your rack.</li>
<li>You can put a small lamp on top of the rack to see your hardware and/or better find the aforementioned food and drink.</li>
<li>The table can be painted in a color of your preference, or decorated in various ways. The eth0 Design team can advise, for a fee, how to optimally decorate the rack to suit your environment.
<ul><li>That means, no more dull black/gray racks!</li>
<li>Or you can put <a href="https://wiki.eth0.nl/index.php/File:Lack2.jpg" title="File:Lack2.jpg">stickers of your favorite event</a> on them.</li></ul></li>
<li>It's easy to colour-code your datacentre: e.g. <span>red</span> for critical services, <span>grey</span> for office automation, <span>green</span> for file-servers, <span>black</span> for systems and network management.</li>
<li>Cheap!</li>
<li>Easy!</li>
<li>Looks good!</li></ul>
<h2><span id="Alternative_configuration">Alternative configuration</span></h2>
<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lack_alt1.jpg"><img alt="" src="https://wiki.eth0.nl/images/7/74/Lack_alt1.jpg" decoding="async" width="300" height="225" data-file-width="768" data-file-height="576"></a></p><div><p>fitting the equipment to the rear of the front legs</p></div></div></div>
<ul><li>Mounting the equipment to the rear of the front legs is recommended if you plan to fit switches with fiber uplinks; the created tabletop overhang shields the fiber connections from minor mishap</li></ul>
<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lack_alt2.jpg"><img alt="" src="https://wiki.eth0.nl/images/5/57/Lack_alt2.jpg" decoding="async" width="300" height="225" data-file-width="768" data-file-height="576"></a></p><div><p>front view: 8 port switch with fiber uplink, and power bar</p></div></div></div>
<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lack_alt3.jpg"><img alt="" src="https://wiki.eth0.nl/images/f/f3/Lack_alt3.jpg" decoding="async" width="300" height="225" data-file-width="768" data-file-height="576"></a></p></div></div>

<ul><li>Q: Does the LackRack provide redundant power supply?
<ul><li>A: Only if you add it yourself</li></ul></li>
<li>Q: Can I put my (coffee) mug on top and don't have to worry about it if I spill liquid on the LackRack?
<ul><li>A: You can spill coffee on the LackRack, since it can be cleaned quite easily. However, if you have appliances <b>in</b> the LackRack, there is a chance that these appliances cannot handle the coffee (or any other liquid). You should take precautions in order to protect your appliances</li></ul></li></ul>

<p>As from the Ikea <a rel="nofollow" href="http://www.ikea.com/us/en/catalog/products/40104270">product page</a>:
</p>
<ul><li>Product information
<ul><li>Easy to assemble.</li>
<li>Low weight; easy to move.</li>
<li>Readily available desktop area holding your laptop during maintenance.</li>
<li>Levenstein distance of "Lack" and "Rack" is 1. Can this still be a coincidence?</li></ul></li></ul>
<ul><li>Designer:
<ul><li>IKEA of Sweden</li></ul></li></ul>
<ul><li>Product dimensions
<ul><li>Length: 55cm (21 5/8 ")</li>
<li>Width: 55cm (21 5/8 ")</li>
<li>Height: 45cm (17 3/4 ")</li>
<li>Almost 9U of rack space</li></ul></li></ul>
<ul><li>Care instructions
<ul><li>Wipe clean using a damp cloth and a mild cleaner.</li>
<li>Wipe dry with a clean cloth</li></ul></li></ul>
<ul><li>Product description
<ul><li>Top: Particleboard, Fiberboard, ABS plastic, Printed and embossed acrylic paint, Clear acrylic lacquer</li>
<li>Filling material: Paper</li>
<li>Leg: Particleboard, Fiberboard, Foil, Foil</li></ul></li></ul>

<h2><span id="Enterprise_Edition">Enterprise Edition</span></h2>
<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Lackrack_enterprise.jpg"><img alt="" src="https://wiki.eth0.nl/images/4/41/Lackrack_enterprise.jpg" decoding="async" width="400" height="300" data-file-width="1024" data-file-height="768"></a></p><div><p><a rel="nofollow" href="http://revspace.nl/">RevSpace</a> branded LackRack Enterprise Edition</p></div></div></div>
<div><div><p><a href="https://wiki.eth0.nl/index.php/File:Norco-3216-LackRack.jpg"><img alt="" src="https://wiki.eth0.nl/images/0/0f/Norco-3216-LackRack.jpg" decoding="async" width="400" height="300" data-file-width="720" data-file-height="540"></a></p><div><p><a rel="nofollow" href="http://www.norcotek.com/item_detail.php?categoryid=1&amp;modelno=RPC-3216">Norco RPC-3216</a> mounted in a LackRack Enterprise Edition.<br>Additional brackets used to raise the shelf and support the 45kg+ weight.</p></div></div></div>
<p><a rel="nofollow" href="http://www.ikea.com/nl/nl/catalog/products/00095036">Ikea LACK coffee table</a>: almost twice as deep, and comes with a shelf. Its size allows both short ends to be used as rack space simultaneously. It's interesting to note that Ikea photographed it from the side; an uncommon artistic approach to 19" server rack photography.
It provides for 8 U of hardware: 4 on either side of the shelf.
</p><p>Following ICT tradition, the Enterprise Edition is more than three times as expensive, while providing less stability than two of the regular products combined.
</p>
<ul><li>Product information
<ul><li>Easy to assemble.</li>
<li>Low weight; easy to move.</li>
<li>Readily available desktop area holding your laptop during maintenance.</li>
<li>Levenstein distance of "Lack" and "Rack" is 1. Can this still be a coincidence?</li></ul></li></ul>
<ul><li>Designer:
<ul><li>IKEA of Sweden</li></ul></li></ul>
<ul><li>Product dimensions
<ul><li>Length: 90cm</li>
<li>Width: 55cm (21 5/8 ")</li>
<li>Height: 45cm (17 3/4 ")</li></ul></li></ul>
<ul><li>Care instructions
<ul><li>Wipe clean using a damp cloth and a mild cleaner.</li>
<li>Wipe dry with a clean cloth</li></ul></li></ul>
<ul><li>Product description&nbsp;:
<ul><li>Top: Particleboard, Fiberboard, ABS plastic, Printed and embossed acrylic paint, Clear acrylic lacquer</li>
<li>Filling material: Paper</li>
<li>Leg: Particleboard, Fiberboard, Foil, Foil</li></ul></li></ul>

<p>It is clear that Ikea has strived to keep many of their products
rack compatible since so many of them are capable of housing 19"
equipment. See <a href="https://wiki.eth0.nl/index.php/List_of_IkeaRacks" title="List of IkeaRacks">List_of_IkeaRacks</a>
</p>


<ul><li><a rel="nofollow" href="http://search.twitter.com/search?q=lackrack">Twitter search on <i>lackrack</i></a></li>
<li><a rel="nofollow" href="http://www.facebook.com/pages/LackRack/267773044028">LackRack fans on Facebook</a></li>
<li><a rel="nofollow" href="http://fenrir.high5.net/view_album.php?set_albumName=LackRack">Photos of an installed RackLack</a> with (fanless) HP Procurve 2510 <b>(in production)</b></li></ul>
<dl><dt>Danish</dt></dl>
<ul><li><a rel="nofollow" href="http://www.sunech.com/2010/01/21/serverrack-fra-ikea/"><b>Sunech</b>: Server rack from Ikea?</a></li>
<li><a rel="nofollow" href="http://www.lydmaskinen.dk/viewtopic.php?f=17&amp;p=273452"><b>Lydmaskinen</b>: Forum thread</a></li></ul>
<dl><dt>Dutch</dt></dl>
<ul><li><a rel="nofollow" href="http://www.webhostingtalk.nl/webhostingtalk-lounge/157237-het-lackrack-van-ikea-3.html"><b>WebHostingTalk</b>: Forum thread</a></li>
<li><a rel="nofollow" href="http://rapture.tweakblogs.net/blog/3449/lackrack.html"><b>Rapture's logs</b>: LackRack</a> (Blogger discovers that his 19" gear lacks mounting brackets, after buying a new LackRack...)</li>
<li><a rel="nofollow" href="http://blog.webwereld.nl/2010/01/25/een-datacenter-in-je-huiskamer/"><b>Webwereld</b>: Een datacenter in je huiskamer</a></li>
<li><a rel="nofollow" href="http://www.matthijs.org/lackrack_2_0"><b>Matthijs.org</b>: LackRack v2.0</a> (LackRack variation for more practical everyday office use)</li></ul>
<dl><dt>English</dt></dl>
<ul><li><a rel="nofollow" href="http://mrngm.com/eth0/LackRack/"><b>mrngm</b>: LackRack - an odyssee</a> (Buyer's guide)</li>
<li><a rel="nofollow" href="http://www.instructables.com/id/IKEA_Hack_a_Lack/"><b>instructables</b>: IKEA Hack-a-Lack</a> (Not about the LackRack per se, but a method for assembling a large number of them)</li>
<li><a rel="nofollow" href="http://www.datacenterknowledge.com/archives/2010/01/21/the-new-data-center-rack-from-ikea/"><b>Data Center Knowledge</b>: The New Data Center Rack From ... IKEA?</a></li>
<li><a rel="nofollow" href="http://blog.makezine.com/archive/2010/01/lackrack_ikea_server_racks_for_livi.html"><b>Make:</b>: Ikea server racks for living room datacenters</a> (<a rel="nofollow" href="http://www.edugeek.net/forums/general-chat/48713-lackrack-ikea-server-racks-living-room-datacenters.html">forum 1</a>, <a rel="nofollow" href="http://forums.hexus.net/general-discussion/179779-lackrack-ikea-server-racks-living-room-datacenters.html">forum 2</a>)</li>
<li><a rel="nofollow" href="http://idle.slashdot.org/story/10/01/21/1717224/LackRack-Makes-Home-Colocation-More-Affordable"><b>Slashdot</b>: LackRack Makes Home Colocation More Affordable</a></li>
<li><a rel="nofollow" href="http://www.nordichardware.com/news,10613.html"><b>NordicHardware</b>: The LackRack - €5 server rack, for real!</a> (<a rel="nofollow" href="http://www.nordichardware.com/forum/view-previous-topic-vt13397.html">forum</a>)</li>
<li><a rel="nofollow" href="http://dailydiy.com/2010/01/22/lackrack-ikea-server-racks-for-living-room-datacenters/"><b>Daily DIY</b>: LackRack: Ikea server racks for living room datacenters</a></li>
<li><a rel="nofollow" href="http://zedomax.com/blog/2010/01/22/server-hack-how-to-build-your-own-ikea-servers/"><b>Zedomax</b>: Server Hack – How to Build Your Own IKEA Servers!</a></li>
<li><a rel="nofollow" href="http://ikeahacker.blogspot.com/2010/01/lack-rack-hack.html"><b>Ikea hacker</b>: The Lack rack hack</a></li>
<li><a rel="nofollow" href="http://www.askcharly.net/blog/buzz/lackrack-tech-enabled-furniture/"><b>AskCharly</b>: LackRack: Tech Enabled Furniture</a></li>
<li><a rel="nofollow" href="http://www.unplggd.com/unplggd/inspiration/ikea-lack-tablenetwork-rackthe-lackrack-107711"><b>unplggd</b>: IKEA Lack+Network Rack=The LackRack</a></li>
<li><a rel="nofollow" href="http://blog.isabel-drost.de/index.php/archives/tag/lackrack"><b>Inductive Bias</b>: Shopping at Ikea</a></li>
<li><a rel="nofollow" href="http://lincgeek.org/blog/?p=940"><b>LincolnBlogs</b>: LackRack</a></li>
<li><a rel="nofollow" href="http://www.lackcluster.org/"><b>LackCluster</b>: LackRack-ed Cluster Computer</a> Practical use of the LackRack</li></ul>
<dl><dt>French</dt></dl>
<ul><li><a rel="nofollow" href="http://www.artiflo.net/2010/01/ikea-arrive-dans-les-datacenter/"><b>Artiflo</b>: Ikea arrives in the datacentre</a></li></ul>
<dl><dt>German</dt></dl>
<ul><li><a rel="nofollow" href="http://blogmmix.ch/kategorie/aktuell/happy-birthday-30-jahre-lack-beistelltisch.html"><b>BlogMMix</b>: Happy birthday, 30 year old sidetable!</a></li>
<li><a rel="nofollow" href="http://www.gamestar.de/hardware/news/vermischtes/2312088/lackrack.html"><b>GameStar</b>: IKEA table as server rack</a></li>
<li><a rel="nofollow" href="http://tipuraneo.blogspot.com/2010/01/gunstiges-19-rack.html"><b>Tipuraneo</b>: Cheap 19" rack</a></li>
<li><a rel="nofollow" href="http://www.sysadminslife.com/hardware/lackrack-billigstes-19-zoll-serverrack-made-by-ikea/"><b>Sysadminslife</b>: LackRack – billigstes 19 Zoll Serverrack made by IKEA?</a></li></ul>
<dl><dt><span title="Swedish :)">Ikeaspråk</span></dt></dl>
<ul><li><a rel="nofollow" href="http://www.techworld.idg.se/2.2524/1.287656/serverracket-du-hittar-pa-ikea"><b>Techworld</b>: Server racks at Ikea</a> (<a rel="nofollow" href="http://www.sweclockers.com/forum/showthread.php?threadid=906172">forum</a>)</li>
<li><a rel="nofollow" href="http://www.nordichardware.se/nyhet,17256.html"><b>NordicHardware</b>: The world's cheapest 19-inch rack from IKEA</a> (<a rel="nofollow" href="http://nhw.se/forum/viewtopic.php?topic=182544&amp;forum=17">forum</a>)</li>
<li>Mah lackrack is teh shit - <a rel="nofollow" href="http://mickenordin.se/blog/index.php/2011/01/mah-lackrack-is-teh-shit/">http://mickenordin.se/blog/index.php/2011/01/mah-lackrack-is-teh-shit/</a></li></ul>
<dl><dt>Japanese</dt></dl>
<ul><li><a rel="nofollow" href="http://www.isisaka.com/blog/archives/2010/01/ikea19.html"><b>石坂</b>: Ikea-made 19" rack</a></li></ul>
<dl><dt>Russian</dt></dl>
<ul><li><a rel="nofollow" href="http://habrahabr.ru/tag/LACKRack/"><b>Хабрахабр</b>: Server rack from Ikea</a></li></ul>
<dl><dt>Spanish</dt></dl>
<ul><li><a rel="nofollow" href="http://www.internetlab.es/post/857/una-nueva-estructura-para-servidores-de-ikea"><b>internetlab</b>: The New Data Center Rack From ... IKEA?</a></li>
<li><a rel="nofollow" href="http://www.acens.com/blog/ikea-diversifica-y-entra-en-el-sector-de-infraestructura-para-datacenters"><b>acens</b>: Ikea diversifies and enters infrastructure market for datacenters</a></li>
<li><a rel="nofollow" href="http://alsanan.info/5456"><b>alasan</b>: LackRack</a></li></ul>
<dl><dt>Portugese</dt></dl>
<ul><li><a rel="nofollow" href="http://blackhold.nusepas.com/2012/02/lackrack-rack-de-bajo-coste-fase-i/">Lackrack, rack de bajo coste: Fase I</a></li></ul>

<ul>
		<li><div>
			<div><p><a href="https://wiki.eth0.nl/index.php/File:2x3U_LackRack.jpg"><img alt="" src="https://wiki.eth0.nl/images/2/26/2x3U_LackRack.jpg" decoding="async" width="90" height="120" data-file-width="2304" data-file-height="3072"></a></p></div>
			<p>2 by 3U LackRack.
</p>
		</div></li>
		<li><div>
			<div><p><a href="https://wiki.eth0.nl/index.php/File:TripleLackRackDeLuxe.jpg"><img alt="" src="https://wiki.eth0.nl/images/7/7f/TripleLackRackDeLuxe.jpg" decoding="async" width="90" height="120" data-file-width="960" data-file-height="1280"></a></p></div>
			<p>Triple LackRack DeLuxe.
</p>
		</div></li>
		<li><div>
			<div><p><a href="https://wiki.eth0.nl/index.php/File:LackRackAtIKEA_1.JPG"><img alt="" src="https://wiki.eth0.nl/images/e/e6/LackRackAtIKEA_1.JPG" decoding="async" width="90" height="120" data-file-width="2736" data-file-height="3648"></a></p></div>
			<p>LackRack at IKEA
</p>
		</div></li>
		<li><div>
			<div><p><a href="https://wiki.eth0.nl/index.php/File:Image005.jpg"><img alt="" src="https://wiki.eth0.nl/images/b/b7/Image005.jpg" decoding="async" width="90" height="120" data-file-width="1046" data-file-height="1395"></a></p></div>
			<p>CCNA Lab LackRack 01
</p>
		</div></li>
		<li><div>
			<div><p><a href="https://wiki.eth0.nl/index.php/File:Image002.jpg"><img alt="" src="https://wiki.eth0.nl/images/f/f5/Image002.jpg" decoding="async" width="90" height="120" data-file-width="1046" data-file-height="1395"></a></p></div>
			<p>CCNA Lab LackRack 02
</p>
		</div></li>
</ul>
<!-- 
NewPP limit report
Cached time: 20210129104829
Cache expiry: 604800
Dynamic content: false
Complications: []
[SMW] In‐text annotation parser time: 0.001 seconds
CPU time usage: 0.097 seconds
Real time usage: 0.102 seconds
Preprocessor visited node count: 80/1000000
Preprocessor generated node count: 0/1000000
Post‐expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 2/40
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 2224/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%    0.000      1 -total
-->

<!-- Saved in parser cache with key eth0_wiki:pcache:idhash:625-0!canonical and timestamp 20210129104829 and revision id 12216
 -->
</div></div></div>]]>
            </description>
            <link>https://wiki.eth0.nl/index.php/LackRack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25978013</guid>
            <pubDate>Sun, 31 Jan 2021 11:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a personal data warehouse in Snowflake for fun and no profit]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25978000">thread link</a>) | @thomasdziedzic
<br/>
January 31, 2021 | https://www.thomasdziedzic0.com/blog/building-a-personal-data-warehouse-in-snowflake-for-fun-and-no-profit | <a href="https://web.archive.org/web/*/https://www.thomasdziedzic0.com/blog/building-a-personal-data-warehouse-in-snowflake-for-fun-and-no-profit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5fffb1fb083bda4cd2029cf2" id="sections">
  
    <section data-test="page-section" data-section-theme="white" data-section-id="5fffb1fb083bda4cd2029cf4" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
          &quot;imageOverlayOpacity&quot;: 0.15,
          &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
          &quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
          &quot;customSectionHeight&quot;: 10,
          &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
          &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
          &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
          &quot;customContentWidth&quot;: 50,
          &quot;sectionTheme&quot;: &quot;white&quot;,
          &quot;sectionAnimation&quot;: &quot;none&quot;,
          &quot;backgroundMode&quot;: &quot;image&quot;
        }" data-animation="none">
  
  <div>
    <div>
      
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-600f55010fc2501849ebea9b"><div><div><div data-block-type="2" id="block-ee8fde62179b7bb27e53"><div><p>I’ve always wanted to build a personal data warehouse and after watching Simon Willison’s <a href="https://simonwillison.net/2020/Nov/14/personal-data-warehouses/">talk</a>, I got the motivation to finally build it out. In case you aren’t familiar with the term “data warehouse”, it’s basically a database that centralizes your data to be used for analysis. There are many databases you can choose from, for example in Simon Willison’s talk, he uses <a href="https://www.sqlite.org/index.html">SQLite</a>. I chose <a href="https://www.snowflake.com/">Snowflake</a> because I’m familiar with it and so far I have liked what Ive seen. Some features that make it stand out for me are things like <a href="https://docs.snowflake.com/en/user-guide/data-time-travel.html">time travel</a>, <a href="https://docs.snowflake.com/en/sql-reference/sql/undrop-table.html">undrop table</a>, a rich set of <a href="https://docs.snowflake.com/en/sql-reference/intro-summary-operators-functions.html">functions</a>, among many others.</p><p>Ok great, so we now have an empty database to start with. But a database is only useful when there is data in it to query. So we must choose which datasets to pull into our freshly minted database. I’m going to start with bringing in <a href="https://news.ycombinator.com/">Hacker News</a> data because I’m a big fan of the site and it has an actual <a href="https://github.com/HackerNews/API">API</a> which means we wont have to be scraping HTML. I’m also going to bring in stock data into the warehouse to see if we can get any stock information out of Hacker News. Finally we’ll analyze the stock market and correlate stocks to the latest GameStop stock craze.</p><p>The first part of the plan will be to get the Hacker News data loaded into Snowflake. Then I’ll use Snowflake’s Data Marketplace to bring in the stock data, which will save me from writing an ELT (Extract, Load, Transform).</p><h2>Getting an initial dump of the Hacker News data.</h2><p>I wanted to write as little code as possible to get this initial historical dump of Hacker News so I decided to use a combination of curl, bash and parallel to get the job done. I first used <a href="https://ec2instances.info/">ec2instances.info</a> to find a relatively cheap CPU per dollar machine. I spun up a c5a.8xlarge on AWS which has 32 vCPUs.<br>I wouldn’t be surprised if there were cheaper options, but I just eyeballed it.</p><p>Let’s get the largest item ID:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611791428293_3993"><div><pre><code>curl https://hacker-news.firebaseio.com/v0/maxitem.json</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611792427454_4138"><div><p>Which returned: 25,806,058</p><p>Sigh, looks like we’re going to have to do 25 million HTTP calls. Let’s get started:</p><p>Let’s generate a file with all of the endpoints we will need to hit. This will be needed for my next one liner:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611792427454_5677"><div><pre><code>for ((i=1; i&lt;25806059; ++i)); do echo "https://hacker-news.firebaseio.com/v0/item/${i}.json"; done &gt; list-of-item-urls</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611793513046_4897"><p>Ok, so we have 25 million URLs that we need to download. Let’s use curl with parallel to download this:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1611793677899_11393"><div><pre><code>time { parallel --jobs 500 --progress --arg-file ../list-of-item-urls "curl --silent -O {}"; }</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611793677899_11459"><p>This fails with an error that we’ve reached a limit regarding the number of open file handles, you will need to add the following line to limits.conf and then reboot the machine:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1611793677899_14036"><div><pre><code>cat /etc/security/limits.conf 
...
ubuntu           soft    nofile          10000
...</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611793677899_14107"><p>Lets try running the download job again and fast forwarding till the end:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1611793677899_15450"><div><pre><code>~/hackernews/data$ time { parallel --jobs 500 --progress --arg-file ../list-of-item-urls "curl --silent -O {}"; }                                                                               

Computers / CPU cores / Max jobs to run
1:local / 32 / 500

Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete
local:0/25806058/100%/0.0s   

real    1419m19.537s
user    5375m8.349s
sys     3894m15.079s</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611793677899_15519"><div><p>The rate at which we were downloading URLs was 25,806,058 / (1,419 * 60 + 19) = 303 URLs per second. </p><p>This was a really slow process, especially given that I used a medium-end machine. My guess is that EBS volumes might not like 25 million files getting created.</p><p>Let’s see how big the data directory is:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611793677899_17011"><div><pre><code>~/hackernews$ du -hs data
100G    data</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611793677899_17077"><p>Ouch, lots of little files definitely take up a lot of space. In addition, I haven’t thought this through. It’s probably going to be painful uploading 25 million files to Snowflake so lets combine all the files into a single file:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1611793677899_18389"><div><pre><code>~/hackernews/data$ time { find . -name '*.json' -exec cat {} \; -exec echo \; &gt; ../items ; }

real    2120m33.575s
user    740m24.364s
sys     1208m22.212s
</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611793677899_18455"><div><p>Well it doesn’t look like my laziness paid off.<br>Combining the 25 million files into 1 file on this ec2 instance using an EBS volume took longer than downloading the files at a rate of 25,806,058  / (2,120 * 60 + 33) = 202 files per second. Maybe using a native storage instance would make this go faster, but still, combining millions of little files is a really slow process.’</p><p>Eighty dollar lesson learned.</p><p>Additionally, when combined into a single file, it takes about 11 gigs.</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611793677899_19766"><div><pre><code>ls -lh items
-rw-rw-r-- 1 ubuntu ubuntu 11G Jan 19 12:48 items</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611854158631_9850"><p>And compressed, it's still even lower, 4 gigs:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1611854158631_11094"><div><pre><code>ls -lh items.gz
-rw-rw-r-- 1 ubuntu ubuntu 4.1G Jan 19 12:48 items.gz</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611854158631_12186"><div><p>Copying to AWS S3 takes almost no time. So we finally have the data where Snowflake can access it!</p><p>Let's load it in:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611854158631_13561"><div><pre><code>use database main_db;

create schema hackernews;

use schema hackernews;

create table raw_items(item variant not null);

copy into raw_items
from s3://hacker-news-dump/items.gz
credentials = (aws_key_id = 'REDACTED' aws_secret_key = 'REDACTED')
file_format = (type = json);

create table items(
  id bigint,
  deleted boolean,
  type string,
  by_ string,
  time timestamp,
  text string,
  dead boolean,
  parent bigint,
  poll bigint,
  kids array,
  url string,
  score bigint,
  title string,
  parts array,
  descendants bigint
);

insert into items(
  id,
  deleted,
  type,
  by_,
  time,
  text,
  dead,
  parent,
  poll,
  kids,
  url,
  score,
  title,
  parts,
  descendants
)
select
  item:id,
  item:deleted,
  item:type,
  item:by,
  item:time,
  item:text,
  item:dead,
  item:parent,
  item:poll,
  item:kids,
  item:url,
  item:score,
  item:title,
  item:parts,
  item:descendants
from raw_items;</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611854158631_14726"><div><p>Loading the data takes a couple of minutes but now we have all Hacker News items loaded into Snowflake!</p><h2>Data Quality Checks.</h2><p>Let’s run some sanity checks on our data by looking for gaps between the ids:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611854158631_16858"><div><pre><code>select lag(id, 1) over (order by id) prev_id, id
from items
qualify id - prev_id &gt; 1
order by 1;</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611854158631_20248"><div><p>I have 15k gaps in my data. To quote Dyatlov from Chernobyl, <a href="https://www.youtube.com/watch?v=Mg5HOnq7zD0">“Not great, not terrible”</a>.</p><p>I ended up writing a python <a href="https://github.com/thomasdziedzic/hackernews-fill-gaps/blob/master/main.py">script</a> to calculate and download these missing items. If you know how one would generate the missing ids between the gaps (which could be of variable size), I would sure like to learn how you accomplish that because it might have spared me from writing this python script. Moving on…</p><p>I also found that the API returns some nulls for items. So I ran the following to clean those up:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611854158631_21920"><div><pre><code>delete from items where id is null;
</code></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1611854158631_23295"><div><h2>Review so far and writing an incremental script.</h2><p>I just spent $80 getting the data into Snowflake and I’m not happy with the performance of the extraction.</p><p>In fact, I was thinking how I was going to maintain this data moving forward, and how I was going to load the data incrementally.<br>I was not satisfied enough with the current approach to keep using it. We must do better, for the sake of my wallet.</p><p>I gave up trying to figure out how to do it purely from a shell scripting perspective, and wrote my own <a href="https://github.com/thomasdziedzic/hackernews-etl/blob/master/main.py">Python script</a> to figure out which items it needs to extract, and then load into Snowflake. This script can be run without user intervention and will keep the data up-to-date. Using Python to write the ELT gave me more flexibility to fix some things that I saw as issues. For example, the script starts N * 4 (where N is the number of logical cpus) jobs and only produces N * 4 files instead of 1 file per item. This approach will avoid having to do an expensive file combination step at the end. I also added some awesome progress bars to the script so that I knew how many requests remain thanks to <a href="https://github.com/alphatwirl/atpbar/issues/21#issuecomment-766468695">Tai Sakuma</a>.</p><p>Running this script from my laptop (a Dell 9370 Developer Edition with 8 logical cores) and spotty Wi-Fi, script extracts items from the API at about 130 items/second. This is slower than extracting from a c5a.8xlarge machine, but at least my laptop isn’t charging me $1.232/hour for using it. And my script has the benefit of not having to combine millions of tiny files at the end. Let’s test my incremental loading script out on an ec2 instance to see how it really compares with my naive approach.</p><h2>Downloading incremental data from Hacker News using my script</h2></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1611883239126_31321"><div><pre><code>$ time { poetry run python main.py ; }
fetching 116738 items
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-22
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-47
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-14
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-36
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-54
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-19
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-58
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-13
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-52
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-56
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-63
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-62
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-29
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-57
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-26
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-12
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-17
 100.00% :::::::::::::::::::::::::::::::::::::::: |     1824 /     1824 |:  ForkPoolWorker-4
 100.00% …</code></pre></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thomasdziedzic0.com/blog/building-a-personal-data-warehouse-in-snowflake-for-fun-and-no-profit">https://www.thomasdziedzic0.com/blog/building-a-personal-data-warehouse-in-snowflake-for-fun-and-no-profit</a></em></p>]]>
            </description>
            <link>https://www.thomasdziedzic0.com/blog/building-a-personal-data-warehouse-in-snowflake-for-fun-and-no-profit</link>
            <guid isPermaLink="false">hacker-news-small-sites-25978000</guid>
            <pubDate>Sun, 31 Jan 2021 11:24:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Black Bart – The Buried TV Sequel to Blazing Saddles]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25977514">thread link</a>) | @rbanffy
<br/>
January 31, 2021 | https://reprobatepress.com/2021/01/30/black-bart-the-buried-tv-sequel-to-blazing-saddles/ | <a href="https://web.archive.org/web/*/https://reprobatepress.com/2021/01/30/black-bart-the-buried-tv-sequel-to-blazing-saddles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main" role="main">

		
<article id="post-38544">

	
	
	
	<div>

		<p><img loading="lazy" src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=840%2C606&amp;ssl=1" alt="" width="840" height="606" srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?w=850&amp;ssl=1 850w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=300%2C216&amp;ssl=1 300w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=768%2C554&amp;ssl=1 768w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=840%2C606&amp;ssl=1 840w" sizes="(max-width: 840px) 100vw, 840px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?w=850&amp;ssl=1 850w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=300%2C216&amp;ssl=1 300w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=768%2C554&amp;ssl=1 768w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=840%2C606&amp;ssl=1 840w" data-lazy-src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-4.png?resize=840%2C606&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><em><strong>The Mel Brooks classic that became a TV series that ran for four seasons without being broadcast anywhere.</strong></em></p>

<p><em>Update: large parts of this story may, in fact, be fiction. See the addendum at the end for details.</em></p>
<p>Film rights are a strange and complex thing, especially when it comes to existing properties. The contracts for these things can involve a labyrinthine series of clauses and negotiations, where the owners of the original property want to include cut-off clauses that will enable them to claw back the rights and sell them again, possibly for much more money if the adaptation has been a success, the artistic creator wants to hold on to some level of creative control and the film studio wants to ensure that neither of those things happens. We’ve seen assorted shenanigans at work across the board – the <a href="https://reprobatepress.com/2018/08/30/big-bond-themes-and-secret-agent-cover-versions/">James Bond</a> copyright snafu that saw the film rights for <strong>Casino Royale</strong> owned and exploited by another company than the one that made the official series, and perhaps most famously in terms of contractual obligations, the first <strong>Fantastic Four</strong> movie, made as a low-budget throwaway affair simply to ensure that the film rights stayed with Constantin Film, who was not quite ready to make a ‘proper’ version of the story but who saw the potential in the property and didn’t want to let it go.</p>
<p>But perhaps the most absurd of these contractual obligation projects came with <strong>Blazing Saddles</strong>, which was adapted into a TV series that ran for four seasons – which would suggest a major hit show by 1970s television standards, except for the fact that it never aired. Not a single episode beyond the pilot was shown on TV anywhere.</p>
<p><strong>Blazing Saddles</strong> was a major hit in 1974 and remains one of the most beloved Hollywood comedies – well, perhaps not with Millenials and Generation Z, given the film’s rather liberal use of the sort of racist language that is now strictly forbidden, even in context. Mel Brooks’ comedy western mocked American racism brutally – perhaps a little too brutally in the use of one particular word, which is bandied about throughout the film. It was a different time.</p>
<p><img loading="lazy" src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=840%2C605&amp;ssl=1" alt="" width="840" height="605" srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?w=850&amp;ssl=1 850w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=300%2C216&amp;ssl=1 300w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=768%2C553&amp;ssl=1 768w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=840%2C605&amp;ssl=1 840w" sizes="(max-width: 840px) 100vw, 840px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?w=850&amp;ssl=1 850w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=300%2C216&amp;ssl=1 300w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=768%2C553&amp;ssl=1 768w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=840%2C605&amp;ssl=1 840w" data-lazy-src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-3.png?resize=840%2C605&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>Brooks was on fire as a filmmaker in 1974, and there was every reason to expect <strong>Blazing Saddles</strong> to be a massive hit, as indeed it was. Having dealt with studios enough by this point, Brooks knew that they might want to take the project away from him and produce sequels – the story essentially opened itself up for on-going narratives. And so he came up with a cunning plan. The contracts for the film stated that there could only be film sequels if a TV series follow-up was made within six months. Brooks and his legal team were pretty certain that the film was too profane and vulgar to ever be adapted as a TV series. I mean, what could they do? Strip it back to its most basic elements while throwing out everything that made the film what it was?</p>
<p>Well, that was precisely what happened. In 1977, Warner Brothers announced plans for a sequel film – in fact, a series of sequels – to <strong>Blazing Saddles</strong>, and when Brooks and his lawyers waved the contract at them, they pulled their ace card – a four-season series based on the original film that had gone into production very quickly in 1974. As Brooks explained, <em>“Warner Bros comes to me and says they want to make another Blazing Saddles, and I say, ‘No. You don’t have the right to do that.’ They say, ‘Yes we do, we’ve been making a TV series and still control the rights.’ What TV series? I haven’t seen a TV show. They take me onto the lot, into a projection booth, and show me three episodes. My lawyers never thought to put in language that said they had to air the damn thing, only that they had to make it.”</em></p>
<p>You have to almost admire Warner Brothers’ gall here, and – oddly – their belief in <strong>Blazing Saddles</strong>. Not only did they rush a series into production in 1974, but they kept it in production – because the contract only allowed a new movie within six months of the last <strong>Blazing Saddles</strong> project – for four years until they finally had a movie ready. TV shows might be cheaper than films, but nevertheless, imagine how much they had to spend, making four seasons of a show just to hold onto the film rights.</p>
<p>In fact, the pilot episode of <strong>Black Bart</strong>, as the series is called, was shown once in 1975 on CBS, with no one even noticing. Well, why would they? As well as changing the title (because the contract also failed to state that any TV series be <em>called</em> <strong>Blazing Saddles</strong>), Brooks wasn’t credited, with Andrew Bergman, who originally came up with the <strong>Blazing Saddles</strong> idea listed as creator. The show starred Louis Gossett Jr as Sheriff Bart, continuing his battles against both criminals and racists, while the other film characters were replaced with similar, but not identical characters to avoid crediting Brooks. Both the cast – including Gerrit Graham – and the characters are lightweight versions of the originals, the humour is almost non-existent and the laugh track just hammers home how unfunny the show is. And yet it is a professional work, and arguably no less forced than several other sitcoms of the era. So the question is: why didn’t they just put in a bit more effort and then show the damn thing instead of paying everyone to shoot twenty-four episodes that would sit, unseen, in the Warner Brothers vaults?</p>
<p><img loading="lazy" src="https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=840%2C602&amp;ssl=1" alt="" width="840" height="602" srcset="https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?w=850&amp;ssl=1 850w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=300%2C215&amp;ssl=1 300w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=768%2C550&amp;ssl=1 768w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=840%2C602&amp;ssl=1 840w" sizes="(max-width: 840px) 100vw, 840px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?w=850&amp;ssl=1 850w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=300%2C215&amp;ssl=1 300w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=768%2C550&amp;ssl=1 768w, https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=840%2C602&amp;ssl=1 840w" data-lazy-src="https://i2.wp.com/reprobatepress.com/wp-content/uploads/2021/01/black-bart-blazing-saddles-tv-series-2.png?resize=840%2C602&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>Presumably, the answer is that a TV show – even a good TV show – would have diluted the appeal of another film. The 1970s were a different time (we mentioned that, right?) and there was less crossover of film and TV – sure, some films – like <a href="https://reprobatepress.com/2020/09/27/go-ape-the-planet-of-the-apes-book-and-comics-of-the-1970s/"><strong>Planet of the Apes</strong></a> – were adapted into TV shows, but those shows were rarely successful and were seen as having essentially killed off any chance of audiences then going to the cinema to watch a movie version. If anything, <strong>Black Bart</strong> might have served as a sign of just how bad a Mel Brooks-free version of <strong>Blazing Saddles</strong> could be. So instead of putting any effort into making a decent TV series based on the property (and there’s certainly the potential there), Warner Brothers simply put the least possible effort into making something that would still legally stand up as a TV show that could, in theory, be broadcast – and then buried it.</p>
<p>What the cast and crew thought of all this is hard to gauge – Gossett has talked about the weirdness of it all, but you have to wonder just how anyone managed to drum up any enthusiasm once it became clear that the show would never air. Ironically, the plans for a <strong>Blazing Saddles</strong> sequel ultimately went nowhere – by 1979, it was clear that the moment had passed and audience tastes had changed. The sequel was shelved, and the series was finally cancelled. The pilot episode has since turned up on the <strong>Blazing Saddles</strong> DVD and blu-ray, but the other episodes have yet to be seen. It’s entirely possible that they were never even completed beyond the ones shown to Brooks, and may have been trashed. A pity, as we’ll never know if it accidentally improved.</p>
<p><strong>IMPORTANT UPDATE:</strong> We feel it’s important to point out that some sources are claiming since we originally posted this that the entire story – with the exception of the<strong> Black Bart</strong> pilot, which definitely exists and is perhaps a weird enough thing in itself – is in fact a spoof that has somehow become accepted as reality – ‘fake news’, as I believe it is known. There are several sources online claiming that this story is authentic; others claiming that it is satire (links appear in the comments). Unless Mel Brooks – or perhaps Louis Gossett – wants to come clean on the actual facts, it perhaps remains a mystery. Stranger-than-fiction may, or may not, be actual fiction, and isn’t that depressing when it’s a story as good as this? As Tony Wilson said (or possibly didn’t say, there’s the rub), <em>“when&nbsp;you have to choose between the truth and the legend, choose the legend.”</em></p>
<p>DAVID FLINT</p>
<p><em><strong>Help support The Reprobate:</strong></em></p>
<p><em><strong><a href="https://www.buymeacoffee.com/reprobatepress" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://i0.wp.com/reprobatepress.com/wp-content/uploads/2020/06/buy-me-a-beer.png?resize=199%2C59&amp;ssl=1" alt="buy-me-a-beer" width="199" height="59" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/reprobatepress.com/wp-content/uploads/2020/06/buy-me-a-beer.png?resize=199%2C59&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><br>
<a href="https://www.patreon.com/reprobatepress" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?resize=567%2C283&amp;ssl=1" alt="Patreon" width="567" height="283" srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?w=567&amp;ssl=1 567w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?resize=300%2C150&amp;ssl=1 300w" sizes="(max-width: 567px) 100vw, 567px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?w=567&amp;ssl=1 567w, https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?resize=300%2C150&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/reprobatepress.com/wp-content/uploads/2020/03/Patreon_White_on_Navy.jpg?resize=567%2C283&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></strong></em></p>


		
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article>

	<!-- #comments -->


		</main><!-- #main -->
	</section><!-- #primary -->

	
	<!-- #secondary -->



	</div></div>]]>
            </description>
            <link>https://reprobatepress.com/2021/01/30/black-bart-the-buried-tv-sequel-to-blazing-saddles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25977514</guid>
            <pubDate>Sun, 31 Jan 2021 09:42:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WallStreetBets vs. Wall Street and the Populist Rebellion]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25977022">thread link</a>) | @lettergram
<br/>
January 30, 2021 | https://austingwalters.com/wallstreetbets-vs-wall-street-and-the-populist-rebellion/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/wallstreetbets-vs-wall-street-and-the-populist-rebellion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3831">

<div>
<p>I have been engaging with WSB (<a href="https://www.reddit.com/r/wallstreetbets/" target="_blank" rel="noopener">/r/WallStreetBets</a>) since 2014.</p>
<p>Every regular person on WSB understands it’s a game. You can loose it all, make it big, sometimes both in the same day — it’s all a game. The most accurate assessment of WSB culture was clearly:</p>
<blockquote><p>Like 4chan found a Bloomberg Terminal.</p></blockquote>
<p>While the influx of new users may change the community, prior to January 15, 2021 the above was indeed an accurate description.</p>

<p>Honestly, this world feels like we are in a simulation. The company GameStop appears to be poised to bring down the entire financial system — stopping the game.</p>
<p>The infinity squeeze appears to be coming, what is an infinity squeeze you ask? It’s a really massive short squeeze:</p>
<blockquote><p>A short squeeze occurs when a stock or other asset jumps sharply higher, forcing traders who had bet that its price would fall, to buy it in order to forestall even greater losses. Their scramble to buy only adds to the upward pressure on the stock’s price.</p></blockquote>
<p>Short positions can technically lead to infinite losses. Simply put, if I open a short position for $10 and the share price drops 10%, I make $1. However, if the stock price increases say 10,000% I now owe $1,000.</p>
<p>In the case of GameStop, the situation appears dire. At one point the short positions were 140% of available shares of the market. This means that more shares were lent out than were available on float, i.e. shorts were resold / lent several times. At this point, several things are happening[<a href="https://www.investopedia.com/ask/answers/05/shortsaleclosed.asp" target="_blank" rel="noopener">1</a>]:</p>
<ul>
<li>Those holding short positions are paying ridiculously high interest rates</li>
<li>If the short positions were forced to close, it would cause a major loss to multiple hedge funds (tens of billions total &amp; bankrupcies)</li>
<li>Due to the level of shorting, exiting the short positions would be excessively expensive and cause a <a href="https://www.investopedia.com/terms/s/shortsqueeze.asp" target="_blank" rel="noopener">short squeeze</a></li>
<li>There is less GameStop stock available for purchase</li>
<li>The price of GameStop stock is rising</li>
</ul>
<p>As a result, it appears to me that:</p>
<ul>
<li>Short holders cannot exit their positions without going bankrupt</li>
<li>Short holders are being hit by high interest rates</li>
<li>Closing other positions in the stock market should help them cover the interest rates</li>
<li>Best option for short position holders is is to wait &amp; pray the stock price drops</li>
<li>What happens if not enough people are willing to sell?</li>
</ul>
<p>Personally, I believe all of this will suck all the liquidity from the stock market. Either those shorting suffer the loss and close their positions or wait as the stock continues to stay high… in either case hundreds of billions of dollars is leaving the market.</p>
<p>How did we get here?</p>
<h3>Infinity Squeeze – Short Positions</h3>
<p>There’s a lot to this story I’ll come back an fill in, but the gist is this — In mid-January 2021 GameStop was <em>extremely</em> shorted.</p>
<figure id="attachment_3832" aria-describedby="caption-attachment-3832"><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png" alt="" width="424" height="417" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-300x295.png 300w" sizes="(max-width: 424px) 100vw, 424px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-300x295.png 300w"></a><figcaption id="caption-attachment-3832">Courtesy of <a href="https://finance.yahoo.com/quote/GME/key-statistics?p=GME" target="_blank" rel="noopener">Yahoo Finance</a></figcaption></figure>
<p>The massive short position and didn’t go unnoticed, WSB had been <a href="https://web.archive.org/web/20201222153244/https://old.reddit.com/r/wallstreetbets/" target="_blank" rel="noopener">discussing it for months</a>. That being said, the massive spikes in purchases did not start until January 12:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png" alt="" width="916" height="411" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png 916w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-300x135.png 300w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-768x345.png 768w" sizes="(max-width: 916px) 100vw, 916px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png 916w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-300x135.png 300w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-768x345.png 768w"></a></p>
<p>What happened at that time? The <a href="https://web.archive.org/web/20210118091858/https://old.reddit.com/r/wallstreetbets/comments/kxeq23/gme_yolo_update_jan_14_2021/" target="_blank" rel="noopener">YOLO updates</a> definitely started at that time and stocks started to rise. Once the stocks started to rise, I believe institutions and WSB itself started piling into GameStop. The stock started to move and if they could get in they could make a boat load. It’s important to remember WSB is often visited by hedge fund mangers, CEOs, day traders big and small, etc. It’s not always the little guy(s). When they piled in, the price started to rise further.</p>
<h3>Infinity Squeeze – Let’s Make Money</h3>
<p>As they purchased, I personally believe some short sellers managed to exit their positions (about 7m shares, per Yahoo Finance data)</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png" alt="" width="424" height="417" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted-300x295.png 300w" sizes="(max-width: 424px) 100vw, 424px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted-300x295.png 300w"></a></p>
<p>What this indicates to me is that many of those holding short positions did not realize what was about to happen. They kept holding believing this was a classic pump-and-dump. Even WSB at the time didn’t not necessarily think about much <a href="https://web.archive.org/web/20210115023914/https://old.reddit.com/r/wallstreetbets/" target="_blank" rel="noopener">besides making money</a>. I know I even purchased call options during this week, particularly when the new data came out January 15, 2021. To me, it became clear the stock was about to rocket.</p>
<h3>Infinity Squeeze – Let’s Stick it to the Man</h3>
<p>In light of the massive number of short position(s) open in January 15, 2021, WSB realized they could (a) make money and (b) stick it to the hedge funds. Frankly, WSB have been waging a war on short selling for years. With GameStop they had a company with relatively few shares&nbsp; in float (47m), a low market cap, basically something that purchases would have an outsized impact.</p>
<p>I’m not 100% sure this was intentional, but as people started buying and holding waiting for the squeeze the stock started to rise.The rising stock both led to discussions on news outlets and the stock started going viral on social media platforms outside of WSB – further raising the going rate for a share of GameStop.</p>
<p>Those holding short positions did not want to sell as they’d lose money, so they were searching for capital to cover their leveraged positions. Citadel and Point72 partners appears to have <a href="https://www.wsj.com/articles/citadel-point72-to-invest-2-75-billion-into-melvin-capital-management-11611604340" target="_blank" rel="noopener">come to at least one short sellers aid</a>. This showed they were weak and further emboldened the WSB folks – “Let’s make some money on the hedge funds behalf”</p>
<p>Purchases from Jan 19 to Jan 23, 2021 and the stock price increased exponentially as it went viral:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png" alt="" width="507" height="423" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png 507w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17-300x250.png 300w" sizes="(max-width: 507px) 100vw, 507px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png 507w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17-300x250.png 300w"></a></p>
<h3>Infinity Squeeze – The Rebellion</h3>
<p>On January 27, 2021 across the board buying for GameStop was <a href="https://www.clickondetroit.com/money/2021/01/27/robinhood-td-ameritrade-other-brokerages-have-tech-problems-at-market-open/" target="_blank" rel="noopener">restricted (along with multiple other stocks) across various trading platforms</a>. This effectively forced purchase volume lower and as users of these platforms could only sell it drove down the share price. This likely startled many GameStop shareholds and many liquidated their positions, letting the short sellers exit some of their positions. Through January 29, 2021 the ability to purchase in an unrestricted manner has not been restored.</p>
<p>What happened?</p>
<p>Personally, I’m of the opinion that there was not enough shares to go around and likely these platforms colluded to drive down the stock price. What’s more interesting is how few people sold. As of January 29, 2021 the price of a GameStop share was back at $325. This has led to some very VERY strong backlash and I know I’ll be joining a lawsuit at some point (if not filing my own), as this collusion cost me tens to hundreds of thousands of dollars.</p>
<p>One essay that particularly struck me was made on WSB: <a href="https://web.archive.org/web/20210130034124/https://www.reddit.com/r/wallstreetbets/comments/l6omry/an_open_letter_to_melvin_capital_cnbc_boomers_and/" target="_blank" rel="noopener">An Open Letter to Melvin Capital, CNBC, Boomers, and WSB</a></p>
<p>I recommend reading the comments on this essay to really get an under standing of what’s happening. Look at the charts. This is personal now. The market manipulation is obvious and people want revenge. For the current events, for 2008, for the entire corrupt system. They want to send a message. This is a protest.</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg" alt="" width="474" height="567" srcset="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg 474w, https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH-251x300.jpg 251w" sizes="(max-width: 474px) 100vw, 474px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg 474w, https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH-251x300.jpg 251w"></a>Many retail investors will hold until the bitter end.</p>
<h3>Infinity Squeeze – End Game</h3>
<p>So what happens next?</p>
<ul>
<li>Starting on January 27-29 people were trying to transfer funds off Robinhood and the other platforms which disabled purchasing of GameStop shares.</li>
<li>Come the <span>first week of February</span> these assets will be again available and can be used to purchase GameStop shares.</li>
<li>Everyone saw much fewer shares being traded Friday</li>
<li>Everyone is talking with their families</li>
<li>People are going to purchase more GameStop shares &amp; hold</li>
<li>I expect many are going to pull their assets out of the stock market</li>
</ul>
<p>There are some unknowns, for instance have the short positions been closed? Have there been backroom deals to stave off the infinity squeeze?</p>
<p>If neither of those assumptions above hold, then what happens when the price rises further and there’s not enough shares for sale?</p>
<p>Hedge funds either bleed out as they pay the massive interest rates on holding those short positions or they will close their short positions causing an infinity squeeze (GameStop shares will be priced in the thousands). In either case hundreds of billions would likely leave the market.</p>
<h3>Conclusion – The Black Hole</h3>
<p>It’s a <a href="https://en.wikipedia.org/wiki/Nash_equilibrium" target="_blank" rel="noopener">Nash Equilibrium</a>, essentially the share holders have every reason to ask the maximum amount they can get for a share of GameStop (i.e. make money). If for some reason these GameStop share holders are unwilling to sell at a low rate, then these hedge funds stand to lose hundreds of billions and will go bankrupt (slowly via interest payments or quickly via short squeeze). To try and pay for their debts, they’ll have to sell off market wide and the entire market collapses.</p>
<p>There are three ways to alleviate the issue:</p>
<ul>
<li>GameStop issues a massive number of new shares</li>
<li>Market manipulation (such as Robinood and friends only enabling selling – of course that didn’t work last time)</li>
<li>Government settles the matter by confiscating shares</li>
</ul>
<p>Personally, I view government involvement as inevitable. They could settle everyone accounts fairly by giving everyone the current share price or what they bought it for, which every is higher. That being said, I suspect the more likely course of action is some flat rate $100/share or something to that effect. In either case, if they don’t get involved, I suspect the system really will collapse.</p>
<p>Unless of course, I am wrong. I am not a financial expert and nothing in this article should be taken as advice.</p>
<p>It’s completely possible I’m inaccurately reading the situation and those shorting GameStop have already exited their position(s) and GameStop is currently just in a classic bubble.</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/wallstreetbets-vs-wall-street-and-the-populist-rebellion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25977022</guid>
            <pubDate>Sun, 31 Jan 2021 07:57:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Font loading on the web]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25976844">thread link</a>) | @payne
<br/>
January 30, 2021 | https://www.industrialempathy.com/posts/high-performance-web-font-loading/ | <a href="https://web.archive.org/web/*/https://www.industrialempathy.com/posts/high-performance-web-font-loading/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When I started thinking about writing a post about web font loading my intention was to propose relatively sophisticated ideas that I've been playing with for a while. However, as I was trying to use them in real-world websites I realized that deployment of the more advanced techniques is de-facto impossible without the creation of new web standards.</p><p>With that the TL;dr of this post is: Use <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@font-face/font-display"><code>font-display: optional</code></a>. However, I and many others really like our custom fonts. See the rest of the post for how we can get our cake and eat it, too–with a <a href="https://www.industrialempathy.com/perfect-ish-font-fallback/?font=Montserrat">tool</a> that automatically makes fallback fonts behave like their respective custom font counterpart.</p><h2 id="web-fonts-and-core-web-vitals">Web fonts and Core Web Vitals <a href="#web-fonts-and-core-web-vitals">#</a></h2><p>2 metrics in <a href="https://web.dev/vitals/">Google's Core Web Vitals</a> are directly impacted by font loading:</p><ol><li><a href="https://web.dev/lcp/">Largest Contentful Paint (LCP)</a> measures (among other things) when text renders. With text rendering blocked behind the web font download, LCP may be delayed.</li><li><a href="https://web.dev/cls/">Cumulative Layout Shift (CLS)</a> measures the document shifting around as the browser loads additional data. A browser switching from fallback font to a custom font leads to layout shift if fallback and custom font flow differently.</li></ol><p>The following video is showing the layout-shift created by font-loading.</p><h3 id="cls-and-invisible-text">CLS and invisible text <a href="#cls-and-invisible-text">#</a></h3><p>Font-based layout shift doesn't require the fallback font ever having displayed. If the page renders without the custom font having loaded but the fallback text remains invisible (this happens with <code>font-display: auto</code>, the default) then the space that is reserved for the invisible text depends on the space that <em>would</em> be taken up by the <em>fallback text</em>. Once the custom font comes in and the text becomes visible, there is a layout shift as the space taken up for text changes.</p><h2 id="stop-worrying-and-use-font-display%3A-optional">Stop worrying and use <code>font-display: optional</code> <a href="#stop-worrying-and-use-font-display%3A-optional">#</a></h2><h3 id="why-font-display%3A-optional-is-currently-the-only-good-option">Why <code>font-display: optional</code> is currently the only good option <a href="#why-font-display%3A-optional-is-currently-the-only-good-option">#</a></h3><p>With <code>font-display: optional</code> the browser only renders the custom font if it is available extremely quickly. In most scenarios that requires it being cached locally.</p><p>This leads to the best possible LCP: Your text always renders quickly, independent of network speed.</p><p>And it leads to the best possible CLS: Your custom font loading never causes layout shift because it is only used when it is available for the first text paint.</p><h3 id="when-not-to-use-font-display%3A-optional">When not to use <code>font-display: optional</code> <a href="#when-not-to-use-font-display%3A-optional">#</a></h3><p>The one reason that makes usage of <code>font-display: optional</code> impossible is if there is no viable fallback font: You need the custom font to load to make sense of the content. Generally that is the case for icon fonts. You probably shouldn't use these in the first place as they are bad for accessibility: You need to see the icons to comprehend them, and you cannot assign them alt-text.</p><h3 id="using-preload-with-font-display%3A-optional">Using preload with <code>font-display: optional</code> <a href="#using-preload-with-font-display%3A-optional">#</a></h3><p>Browsers will only download a font for a web page when CSS evaluation completes and it is determined that it is actually used on the page. That is much later than e.g. when image downloads are initiated which are done by the so-called pre-parser that does a quick scan of the HTML document as soon as it is available to the browser (and without blocking on synchronous scripts, stylesheets, etc.).</p><p>The common work-around is to use a link-preload element like this which explicitly instructs the browser to start the font download as soon as it discovers the element.</p><pre><code><span><span><span>&lt;</span>link</span><br>  <span>rel</span><span><span>=</span><span>"</span>preload<span>"</span></span><br>  <span>href</span><span><span>=</span><span>"</span>/fonts/Inter-Bold.woff2<span>"</span></span><br>  <span>as</span><span><span>=</span><span>"</span>font<span>"</span></span><br>  <span>type</span><span><span>=</span><span>"</span>font/woff2<span>"</span></span><br>  <span>crossorigin</span><br><span>/&gt;</span></span></code></pre><p>The question is: Should you use these together with <code>font-display: optional</code>? The conventional wisdom is: No. The reason being that with <code>font-display: optional</code> either your font is already in cache in which case this doesn't do anything, or the font download is likely not fast enough to make the short deadline and the browser would render the fallback font anyway. In the latter case you give bandwidth at the most urgent time to the font which will never render and that bandwidth could be used to download other critical resources instead.</p><p>With that said: My website does it anyway. The reason is that in my experience users with very fast connections can actually download the font in time, and because my website has no other critical resources there is really nothing the fonts compete with. This is certainly not true for most websites.</p><h2 id="fonts-and-cdns">Fonts and CDNs <a href="#fonts-and-cdns">#</a></h2><p>One of the big changes in the web ecosystem over the last few years is that browsers no longer cache resources across top level sites. That means if your site and my site both load the exact same Roboto from Google Fonts, the browser will download it twice as opposed to only once like they used to do. This is very sad. It is, however, also the right call in the short-term from a privacy &amp; security perspective. In the long-term, maybe we can define web standards that eliminate the privacy &amp; security threats from cross-origin caching for heavily shared resources like fonts.</p><p>So, what are the consequences of this change in browser caching behavior? The main change is that font CDNs like Google Fonts and Adobe TypeKit now strictly make your site slower. They used to help with cross-site caching, but that benefit is gone. Instead they add expensive cross-origin requests (and their DNS lookups, TLS negotiations, etc.) into the critical path of loading your website.</p><p>With that it is clear that we should self-host all fonts on our primary domain for maximum performance. With fonts this can sometimes be problematic for licensing reasons, etc. but there is a good middle ground: Instead of self-hosting the fonts, self-host the loading code. For all common Font CDNs (<a href="https://blog.typekit.com/2017/10/11/advanced-web-font-loading-with-typekits-css-embed-code/">even TypeKit with some digging</a>, they default to JS based loading) this is simply a CSS file. Just download that CSS file. It won't bite 😄. Or, if your font provider likes to sometimes change it, just fetch the CSS file once during your build process. Then inline the CSS file into your HTML and you completely eliminate the expensive cross-origin request from your critical path. While this approach still downloads the fonts themselves from the CDNs this doesn't hurt when you are using our friend <code>font-display: optional</code>.</p><h2 id="what-if-i-really-don't-want-to-use-font-display%3A-optional">What if I really don't want to use <code>font-display: optional</code> <a href="#what-if-i-really-don't-want-to-use-font-display%3A-optional">#</a></h2><p>So, I have a solution for you. It works remarkably well. This is based on <a href="https://meowni.ca/font-style-matcher/">an idea/tool by Monica Dinculescu</a> that she published in 2016. It allows tweaking your fallback font such that it uses approximately as much space as the custom font.</p><p>This is an awesome idea as it avoids the layout shift issues associated with loading the custom font: With the fallback already taking up the right amount of space, the custom font just swaps back into the same space when it loads.</p><h3 id="tool%3A-perfect-ish-font-fallbacks">Tool: Perfect-ish font fallbacks <a href="#tool%3A-perfect-ish-font-fallbacks">#</a></h3><p>My contribution over Monica's idea is that <a href="https://www.industrialempathy.com/perfect-ish-font-fallback/?font=Montserrat">I made a tool</a> that <em>automatically</em> matches the fallback font to the custom font–because computers are good at that stuff. <a href="https://www.industrialempathy.com/perfect-ish-font-fallback/?font=Montserrat">Try it out here.</a></p><p>The tool allows you to select every Google Font from a select menu. If you aren't using a Google Fonts, you can <a href="https://glitch.com/edit/#!/perfect-ish-font-fallback?path=inter.html%3A1%3A0">remix this Glitch</a> for a custom solution.</p><h4 id="samples">Samples <a href="#samples">#</a></h4><p>The fallback-to-custom-font matching works really well in most cases. Here the left font is the custom font and on the right side is Arial:</p><p><picture><source type="image/avif" srcset="https://www.industrialempathy.com/img/remote/Z1kjMzm-1920w.avif 1920w, https://www.industrialempathy.com/img/remote/Z1kjMzm-1280w.avif 1280w, https://www.industrialempathy.com/img/remote/Z1kjMzm-640w.avif 640w, https://www.industrialempathy.com/img/remote/Z1kjMzm-320w.avif 320w" sizes="(max-width: 608px) 100vw, 608px"><source type="image/webp" srcset="https://www.industrialempathy.com/img/remote/Z1kjMzm-1920w.webp 1920w, https://www.industrialempathy.com/img/remote/Z1kjMzm-1280w.webp 1280w, https://www.industrialempathy.com/img/remote/Z1kjMzm-640w.webp 640w, https://www.industrialempathy.com/img/remote/Z1kjMzm-320w.webp 320w" sizes="(max-width: 608px) 100vw, 608px"><source type="image/jpeg" srcset="https://www.industrialempathy.com/img/remote/Z1kjMzm-1920w.jpg 1920w, https://www.industrialempathy.com/img/remote/Z1kjMzm-1280w.jpg 1280w, https://www.industrialempathy.com/img/remote/Z1kjMzm-640w.jpg 640w, https://www.industrialempathy.com/img/remote/Z1kjMzm-320w.jpg 320w" sizes="(max-width: 608px) 100vw, 608px"><img loading="lazy" decoding="async" width="1556" src="https://www.industrialempathy.com/img/remote/Z1kjMzm.png" height="450" alt="Comparison of rendering of Montserrat and Arial"></picture></p><p>However, the whole thing is just an approximation. It definitely happens that things do not match 100%. (The screenshot shows the same text/font as before, but uses a different viewport width). The solution works most of the time. It isn't perfect but better than always having a major layout jump.</p><p><picture><source type="image/avif" srcset="https://www.industrialempathy.com/img/remote/1JBfb6-1920w.avif 1920w, https://www.industrialempathy.com/img/remote/1JBfb6-1280w.avif 1280w, https://www.industrialempathy.com/img/remote/1JBfb6-640w.avif 640w, https://www.industrialempathy.com/img/remote/1JBfb6-320w.avif 320w" sizes="(max-width: 608px) 100vw, 608px"><source type="image/webp" srcset="https://www.industrialempathy.com/img/remote/1JBfb6-1920w.webp 1920w, https://www.industrialempathy.com/img/remote/1JBfb6-1280w.webp 1280w, https://www.industrialempathy.com/img/remote/1JBfb6-640w.webp 640w, https://www.industrialempathy.com/img/remote/1JBfb6-320w.webp 320w" sizes="(max-width: 608px) 100vw, 608px"><source type="image/jpeg" srcset="https://www.industrialempathy.com/img/remote/1JBfb6-1920w.jpg 1920w, https://www.industrialempathy.com/img/remote/1JBfb6-1280w.jpg 1280w, https://www.industrialempathy.com/img/remote/1JBfb6-640w.jpg 640w, https://www.industrialempathy.com/img/remote/1JBfb6-320w.jpg 320w" sizes="(max-width: 608px) 100vw, 608px"><img loading="lazy" decoding="async" width="1352" src="https://www.industrialempathy.com/img/remote/1JBfb6.png" height="508" alt="Same fonts as in previous image but showing that Arial flows one line shorter"></picture></p><p>Finally, your mileage may vary with more extreme fonts. For very narrow fonts the fallback font may become unreadable. Having said that, for fonts that are commonly used this is not a problem.</p><p><picture><source type="image/avif" srcset="https://www.industrialempathy.com/img/remote/Z2sOknd-1920w.avif 1920w, https://www.industrialempathy.com/img/remote/Z2sOknd-1280w.avif 1280w, https://www.industrialempathy.com/img/remote/Z2sOknd-640w.avif 640w, https://www.industrialempathy.com/img/remote/Z2sOknd-320w.avif 320w" sizes="(max-width: 608px) 100vw, 608px"><source type="image/webp" srcset="https://www.industrialempathy.com/img/remote/Z2sOknd-1920w.webp 1920w, https://www.industrialempathy.com/img/remote/Z2sOknd-1280w.webp 1280w, https://www.industrialempathy.com/img/remote/Z2sOknd-640w.webp 640w, https://www.industrialempathy.com/img/remote/Z2sOknd-320w.webp 320w" sizes="(max-width: 608px) 100vw, 608px"><source type="image/jpeg" srcset="https://www.industrialempathy.com/img/remote/Z2sOknd-1920w.jpg 1920w, https://www.industrialempathy.com/img/remote/Z2sOknd-1280w.jpg 1280w, https://www.industrialempathy.com/img/remote/Z2sOknd-640w.jpg 640w, https://www.industrialempathy.com/img/remote/Z2sOknd-320w.jpg 320w" sizes="(max-width: 608px) 100vw, 608px"><img loading="lazy" decoding="async" width="1354" src="https://www.industrialempathy.com/img/remote/Z2sOknd.png" height="332" alt="Text with negative letter spacing that has the characters flow into each other"></picture></p><h4 id="deploying-fallback-corrections-to-the-website">Deploying fallback corrections to the website <a href="#deploying-fallback-corrections-to-the-website">#</a></h4><p>The output of the tool is a bit of CSS like</p><pre><code><span><span><span>&lt;</span>style</span> <span>id</span><span><span>=</span><span>"</span>font-correction<span>"</span></span><span>&gt;</span></span><span><span><br>  <span>html</span> <span>{</span><br>    <span>letter-spacing</span><span>:</span> 0.0605em<span>;</span><br>    <span>line-height</span><span>:</span> 1.3<span>;</span><br>  <span>}</span><br></span></span><span><span><span>&lt;/</span>style</span><span>&gt;</span></span></code></pre><p>Unfortunately, this is where things get complicated. What you need to do is have your page use this CSS but only (and that is very important) until the moment that it renders the custom font. You can try out <a href="https://www.industrialempathy.com/perfect-ish-font-fallback/demo.html">this demo</a> for a working implementation. This is based on <a href="https://www.bramstein.com/">Bram Stein's</a> excellent <a href="https://fontfaceobserver.com/">FontFaceObserver</a> and the magic is basically here:</p><pre><code><span>new</span> <span>FontFaceObserver</span><span>(</span><span>"Montserrat"</span><span>)</span><span>.</span><span>load</span><span>(</span><span>)</span><span>.</span><span>then</span><span>(</span><span>function</span> <span>(</span><span>)</span> <span>{</span><br>  <span>var</span> s <span>=</span> document<span>.</span><span>getElementById</span><span>(</span><span>"font-correction"</span><span>)</span><span>;</span><br>  s<span>.</span>parentElement<span>.</span><span>removeChild</span><span>(</span>s<span>)</span><span>;</span><br><span>}</span><span>)</span><span>;</span></code></pre><p>What this does is: When our custom font loads (<code>Montserrat</code>), then remove the style element we defined above such that the correction for the fallback font is eliminated.</p><p>So far, so simple.</p><p>Where things get really complicated is when trying to deploy this with more than one web font (or variant of the same logical font). Then you need to manage N corrections (<code>letter-spacing</code> and <code>line-height</code>), apply them only to the correct text that is styled with that font, and remove them individually as the respective font file loads.</p><p>I've decided for myself that it isn't worth the effort as it would be too fragile to ever work in practice.</p><h3 id="a-web-standard-solution">A web standard solution <a href="#a-web-standard-solution">#</a></h3><p>While handling the font-loading state machine is complicated in JavaScript (besides the ridiculousness of using JavaScript to control font-loading) and expressing the font-changes in CSS relative to the base styling is even more complicated, there is a party that could handle this quite easily: The browser. What if I could say: "When Arial is a fallback font for X, then use the following letterSpacing, etc.".</p><p>In CSS that would look something like this:</p><pre><code><span><span>@font-face</span></span> <span>{</span><br>  <span>font-family</span><span>:</span> <span>"My font"</span><span>;</span><br>  <span>src</span><span>:</span> …<span>;</span><br>  <br>  <br>  <span>fallback-font</span><span>:</span> <span>"Arial"</span><span>;</span> <br>  <span>fallback-font-letter-spacing</span><span>:</span> 0.0605em<span>;</span><br>  <span>fallback-font-word-spacing</span><span>:</span> 0.001em<span>;</span><br>  <span>fallback-font-line-height</span><span>:</span> 1.3<span>;</span><br><span>}</span></code></pre><p>And the best part of an approach like this: browsers could just ship better defaults for common fonts. There aren't that many fonts in use, and at &lt;=64bit of information needed per font, browsers could easily ship fallback configuration for the ~1000 most common web font names.</p><h2 id="summary">Summary <a href="#summary">#</a></h2><p>Using <code>font-display: optional</code> together with self-hosting the CSS for your web fonts gets you in really good shape with respect to LCP and CLS. There are more sophisticated techniques …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.industrialempathy.com/posts/high-performance-web-font-loading/">https://www.industrialempathy.com/posts/high-performance-web-font-loading/</a></em></p>]]>
            </description>
            <link>https://www.industrialempathy.com/posts/high-performance-web-font-loading/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25976844</guid>
            <pubDate>Sun, 31 Jan 2021 07:17:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My experience passing CKA and CKAD]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25976625">thread link</a>) | @micuffaro
<br/>
January 30, 2021 | https://blog.cuffaro.com/blog/2021/01/24/cka-ckad | <a href="https://web.archive.org/web/*/https://blog.cuffaro.com/blog/2021/01/24/cka-ckad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>In December last year I was able to sit for the coveted Certified Kubernetes Administrator and Certified Kubernetes Application Developer exams, and clear them both after some preparation.</p>

<p>This post is meant to share my exam experience, and all the materials used.</p>

<h3 id="tldr">TL;DR</h3>
<ul>
  <li>Read the exam questions carefully.</li>
  <li>Know imperative commands with <code>kubectl</code> like the back of your hand.</li>
  <li>Get comfortable looking things up on <a href="https://kubernetes.io/">kubernetes.io</a>.</li>
  <li>Build a bookmark folder in Chrome with relevant pages in kubernetes.io: you can use it during the exam!</li>
  <li>Seriously, read the damn questions carefully.</li>
  <li>Practice, practice and practice more.</li>
</ul>

<h3 id="the-exams">The exams</h3>
<p>The exam for any of these Kubernetes certifications consists in solving a set of tasks, in a 2 hour terminal session.</p>

<p>There are 17 scenarios/questions for CKA, and 19 for CKAD.
The whole time, a proctor is watching and listening to you via webcam and microphone, and seeing the content of your screens (you can use more than one).
You communicate with the proctor only via a live chat application which is part of the PSI interface for the exam.</p>

<p>At the beginning they will ask you to show your ID, and then you will need to show them your working area from the webcam.
You will need to show your desk, and the room youâ€™re in.
Ensure that nothing written is visibile on the walls, and that you are the only person in the room.</p>

<p>Once the exam starts, the proctor may ask you every once in a while to show your hands to the webcam.
Donâ€™t bother asking questions about the exam itself, chances are the proctor really doesnâ€™t know about the subject and is only there to ensure you donâ€™t cheat.
You will need to share your screens for the proctor to see.
If you have 2 screens you can have the exam terminal on one, and the tab with k8s docs on the other.</p>

<p>In the terminal itself, you are given 6 or so k8s clusters, and you will need to switch between them.
You will always have a command printed at the beginning of each question, for easy copy paste:</p>
<div><div><pre><code>kubectl config use-context bla
</code></pre></div></div>
<p>Make sure to <strong>use it</strong>!</p>

<p>Do not be fooled by the fact that you are able to search documentation during the exam.
The tasks that you will be given are often complex ones; time is of the essence! If you waste it while reading up docs you will not be able to complete all of the tasks in time.</p>

<h3 id="resources-used">Resources used</h3>
<ul>
  <li>Official docs <a href="https://kubernetes.io/">kubernetes.io</a></li>
  <li><a href="https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/">Certified Kubernetes Administrator by Mumshad Mannambeth (Udemy)</a></li>
  <li><a href="https://www.udemy.com/course/certified-kubernetes-application-developer/">Certified Kubernetes Application Developer by Mumshad Mannambeth (Udemy)</a></li>
  <li>Exam simulator <a href="https://killer.sh/">killer.sh</a></li>
  <li>Kodekloud community slack</li>
  <li>Kubernetes community slack</li>
</ul>


<ul>
  <li><a href="https://www.amazon.com/Cloud-Native-DevOps-Kubernetes-Applications/dp/1492040762/ref=sr_1_1?crid=24TO6CY3JORE4&amp;dchild=1&amp;keywords=cloud+native+devops+with+kubernetes&amp;qid=1612074068&amp;sprefix=cloud+native+dev%2Caps%2C260&amp;sr=8-1">Cloud Native Devops with Kubernetes</a>, by John Arundel and Justin Domingus.</li>
  <li><a href="https://www.amazon.com/Kubernetes-Running-Dive-Future-Infrastructure/dp/1492046531/ref=pd_bxgy_img_2/140-4642137-3991249?_encoding=UTF8&amp;pd_rd_i=1492046531&amp;pd_rd_r=9b0a86b5-7a7a-48b7-af2d-8caf1db3aeef&amp;pd_rd_w=8ickO&amp;pd_rd_wg=F4zT9&amp;pf_rd_p=f325d01c-4658-4593-be83-3e12ca663f0e&amp;pf_rd_r=GERZBQPX5AYFFCB14S8R&amp;psc=1&amp;refRID=GERZBQPX5AYFFCB14S8R">Kubernetes Up &amp; Running</a>, by Brendan Burns, Joe Beda and Kelsey Hightower.</li>
</ul>

<h2 id="cka">CKA</h2>
<p>I will start with the CKA, as it is the first exam I attempted.</p>

<h3 id="objectives">Objectives</h3>
<p>The CKA ensures we have the skillset to setup and maintain a Kubernetes cluster, and manage it by using best practices.</p>

<h3 id="requirements">Requirements</h3>
<p>As this exam is aimed at the Systems administrator/devops engineer, some linux as well as infrastructure skills are expected, such as:</p>
<ul>
  <li>Knowledge of Linux OS.</li>
  <li>Being comfortable on the terminal.</li>
  <li>Knowing how to quickly edit files with text editors like Vi/Vim.</li>
  <li>Working knowledge of networking concepts.</li>
  <li>Working knowledge of TLS encryption concepts.</li>
  <li>Working knowledge of docker and containerization concepts.</li>
</ul>

<p>A deep dive is done on Kubernetes concepts and architecture during the indicated courses.</p>

<h3 id="study-plan">Study plan</h3>
<p>I began studying around the end of September 2020, by purchasing Mumshad Mannambethâ€™s excellent Udemy course for both CKA and CKAD, both on sale at the time.
That was a major source of material for me, as the courses included access to Katacoda/Kodekloud practice labs, and access to a Slack community where the trainer and other exam-takers participated.
The videos of Mumshadâ€™s course are very well done, each in the 5-10 minute range in length, slowly and clearly explaining each concept.
I would get to practice that concept later with labs provided by Mumshadâ€™s platform, KodeKloud.</p>

<p>The course itself has a section later on where we must manually install a Kubernetes cluster from scratch on a local vagrant setup, based on <a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">Kelsey Hightowerâ€™s excellent Kubernetes the Hard way project</a> (the original project leverages infrastructure on Google Cloud instead).
During the same course, we get to setup another cluster by using <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">kubeadm</a>, which is part of the exam curriculum.</p>

<p>I would say that before taking the exam, I spent an average of about 1 hour every day watching the course videos and playing around with the labs (around 2 hours or more during weekends), for a couple months;
I took care of understanding every concept presented in the videos, and verified my knowledge with the labs and on a local cluster where I spent some practice time on, on top of study time.
I also re-did all of the course labs multiple times until I knew almost all of the answers by heart, and could get around them easily.</p>

<p>When something was unclear, the slack communities on kodekloud and kubernetes were always very helpful, always answering all of my questions, no matter how dumb I thought they were :)</p>

<p>I made sure to know <code>kubectl</code> imperative commands like the back of my hand, and building a library of bookmarks in my browser with relevant pages ready, as we are allowed an extra tab with the documentation during the exam.</p>

<p>After 2 months of that, I felt like I was ready.</p>

<h3 id="cka-exam-attempt-1">CKA Exam attempt #1</h3>
<p>I booked the exam for end of November, on a Saturday morning at 8AM, and sat for it in the guest room of my home.
The exam setup time with the proctor went pretty smoothly, and I was able to start on time.</p>

<p>I was not so confident by the end of the two hours. After 36 hours I got the news that I failed that attempt with 60% (minimum passing grade is 66%).
What went wrong for me was that I did not read/understand one specific question, which was related to ETCD backup and restore (part of the official curriculum); because of this, I ended up performing a task that effectively made one of the exam clusters unavailable.</p>

<p>Looking back, I am quite sure I invalidated several correct answers due to this mistake, which resulted in the score.
The method of how to backup/restore an ETCD cluster was also not entirely clear to me at the time, so I was not 100% sure of what I was doing.</p>

<p>Clearly I overestimated my knowledge, and depended too much on memorizing certain commands on one study platform, instead of being completely confident in all concepts and commands applied.</p>

<h3 id="new-study-plan">New study plan</h3>
<p>Enter <a href="https://killer.sh/">killer.sh</a>.
A CKA/CKAD/CKS exam simulator created by <a href="https://www.linkedin.com/in/kimwuestkamp/">Kim Wuestkampf</a>.</p>

<p>For CKA, the simulator offered 25 HARD questions to be done in 2 hours, with guided and comprehensive answers made available after the alotted time.
Such answers also offered different ways to do things, for maximized learning experience.</p>

<p>This alternative platform helped a lot in understanding things that werenâ€™t clear to me, and to practice more varied scenarios.
Completing a killer.sh simulator in under two hours gives good confidence in being able to tackle the real exam.</p>

<h3 id="cka-exam-attempt-2">CKA Exam attempt #2</h3>
<p>I booked the exam one week after getting the results of the previous one.
The exam setup experience was again pretty smooth and I was up and ready to go 10 minutes before the start time.</p>

<p>I felt pretty confident the whole time and finished up all of the questions around 1 hour and 10 minutes later.</p>

<p>The results came around 36 hours after the end of the exam, in an email.
Score was a pass with 85% :)!
As it is not possible to see the actual answers, to this day I donâ€™t really donâ€™t know what I got wrong, but am still satisfied with the result.</p>

<h2 id="ckad">CKAD</h2>
<p>I took the CKAD exam while the knowledge of the previous training was still fresh, so I felt like I had an easier time with this one.</p>

<h3 id="objectives-1">Objectives</h3>
<p>To be able to efficiently design and implement working kubernetes production workloads.</p>

<h3 id="requirements-1">Requirements</h3>
<p>Not so much system administration knowledge, but more focus on k8s concepts, architecture and best practices.
Actual programming experience is not required for the exam (although in â€œreal lifeâ€� it will probably not hurt either ;) ).</p>

<h3 id="study-plan-1">Study plan</h3>
<p>I booked the CKAD exam roughly for 3 weeks after passing the CKA.
In those 3 weeks, I took my time and spent again around 30min to 1 hour a day on Mumshadâ€™s course and labs.</p>

<p>When exam time was closer, I booked two sessions on killer.sh and focused on practicing there.
I challenged myself by finishing all the questions under 2 hours, and afterwards going through slowly through the answers section on the site.
This was very helpful and allowed me to learn different, more effective approaches.</p>

<h3 id="ckad-exam-attempt-1">CKAD Exam attempt #1</h3>
<p>I once again took the exam from the guest room in my home.</p>

<p>This time the exam setup with the proctor wasnâ€™t so smooth.
The connection from my end and theirs wasnâ€™t great, and we kept getting disconnected from the session. Webcam images werenâ€™t so clear so they had to ask me to show identification more than once. It took about 40 minutes to start the actual exam, and that did get me a bit stressed out.</p>

<p>Nevertheless, I felt comfortable and finished all the questions in about 1 hour and a half.
36 hours later, I got the email with the good news of a pass with 83%.
Doing the CKA before really helped with the whole experience.</p>

<h2 id="conclusion">Conclusion</h2>
<p>From my experience, I would say that the hardest exam was the one for CKA, as it didnâ€™t just go through the new knowledge of k8s concepts, but also on existing understanding of systems administration.
I felt like doing CKAD immediately afterwards made it a bit easier, as the knowledge was still fresh.</p>

<p>The CKAD questions however were much more time consuming, in the sense that one task would require to perform several smaller tasks quickly, building a workload and making sure everything works together.</p>

<p>All in all, I feel the time trying to tackle these certifications was well spent; since the exams are performance based, they are fair in what they expect …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cuffaro.com/blog/2021/01/24/cka-ckad">https://blog.cuffaro.com/blog/2021/01/24/cka-ckad</a></em></p>]]>
            </description>
            <link>https://blog.cuffaro.com/blog/2021/01/24/cka-ckad</link>
            <guid isPermaLink="false">hacker-news-small-sites-25976625</guid>
            <pubDate>Sun, 31 Jan 2021 06:37:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Japan API – Free and Open Data]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25976575">thread link</a>) | @irevenko
<br/>
January 30, 2021 | https://japan-api.github.io/docs/ | <a href="https://web.archive.org/web/*/https://japan-api.github.io/docs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://japan-api.github.io/docs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25976575</guid>
            <pubDate>Sun, 31 Jan 2021 06:26:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Freelancers and Agencies: Think Niche]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25976522">thread link</a>) | @chrisrickard
<br/>
January 30, 2021 | https://www.devtoagency.com/think-niche | <a href="https://web.archive.org/web/*/https://www.devtoagency.com/think-niche">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
                <p>We build web and mobile applications - that's the generic website tagline 90% of your competitors will have. They all look the same, all talk the same, and are all pitching for the same clients as you are.</p><blockquote>"<em>If everybody is doing it one way, there's a good chance you can find your niche by going exactly in the opposite direction"</em> ― Sam Walton, entrepreneur and founder of Walmart</blockquote><p>A niche is a "<em>specialised segment of the market for a particular kind of product or service</em>", and when applied to software agencies, it means you don't just specialise in "web and mobile applications" like the rest, but instead you carve out a specific focus area. A focus area that your agency becomes an authority in, allowing you to provide deep value to your clients, and in turn charge a premium for your specialised expertise.</p><p>For your small software agency to punch above its weight and deliver high quality work, I believe focusing on a niche is a superpower to get you there faster.</p><h2 id="why-should-software-agencies-focus-on-a-niche">Why should software agencies focus on a niche?</h2><p>Authority is key to attracting clients and showing your competency in your field, but unfortunately gaining authority is especially challenging when just starting out. How can you build authority in a specific area when your first few projects are all so vastly different? An API integration for an old eLearning platform, a mobile app to track walking your dog, and a community website for financial advisors to exchange ideas - what area are you an authority in? Of course you can highlight your "high quality" or your "cheaper rates" - and this is what the other 90% do. But what if instead of your website tagline being "We build web and mobile applications" it said "Experts in delivering internal business software" or instead of "Technology specialists" it said "Specialists in building mobile apps for your startup". A clearer value proposition for potential clients that succinctly captures what you do best, and what niche you play in.</p><p>It's obviously more than just your website tagline, but if your entire website is focused on the single specific problem you solve, it makes the sale a lot easier. Say potential client lands on your site, they can see right off the bat that you not only specialise in mobile apps, but more specifically, you focus on startups just like them. This draws them in, and as they scroll down they see some images of startup apps you have delivered along with positive testimonials from founders just like them. They call your phone number, and your conversation with them continues to reinforce your experience and authority with working for people <em>just like them</em>. You now stand out from the rest, your agency has increased authority in the eyes of the buyer, and that gives you a competitive edge.</p><h3 id="2-reduced-competition-">2. Reduced c<strong>ompetition 🏆</strong></h3><p>If you're the only software agency in your city, then you are one lucky bastard. But unfortunately I don't think you will be. Your small agency will most likely be one of many around your geographical area, along with the hundreds of freelance software developers that are looking for work. Besides the physical world there are also the millions of competitors on the internet, and as business being conducted fully online is becoming more and more normal, remote competitors is a bigger consideration.</p><p>You already know all this, and it's a big reason why starting is scary - but you don't have to run the same race as all those competitors. You can instead run your own race, and separate yourself from the pack by targeting a specific subset of clients, and by solving a specific subset of problems. If you were to specialise in "web and mobile apps" then you have twice the competition as those that specialise in just "mobile apps". If you niched down even further and focused on "mobile apps for startups" your competition is reduced even further, or "mobile apps for financial startups" even further still. In such a competitive space as software development, reducing competition is huge.</p><h3 id="3-laser-focus-">3. Laser focus 🔍</h3><p>Don't be misled by the "small" in small business, there will be a very gigantic number of priorities competing for your attention. On top of the normal business owner things, you may be getting familiar with how "Karate competition scoring" works for a project you are about to start, grappling with submitting a React native mobile app to all the different app stores, all whilst researching how blockchain works for an upcoming project your pitching for. Focusing on one niche can help you regain some control and realise projects that are not aligned with your niche are really just distractions. You realise the blockchain project is actually not an area you want to work in - and that's good, you can't be an expert in everything, and your clients deserve an expert. </p><p>Minimising distractions allows a laser focus on what is really important. Focus on having a concise and memorable sales experience demonstrating your niche authority, focus on gaining even deeper experience in your niche, focus on delivering amazing projects in your niche (and possibly writing great content on your niche), focus on training your staff in your niche - all of this could be more valuable than researching blockchain for a project that doesn't align with the work you want to focus on.</p><h3 id="4-depth-of-experience-">4. Depth of experience 👨‍🏫</h3><p>You may not be an expert from the first day you start your agency, but to separate yourself from the generic masses you should aim to become one as fast you can. Being able to provide you clients with deep, expert experience in their problem area is one of the biggest differentiators out there. And it will open up far more doors than any well-crafted website tagline ever can. Experience compounds, and if you concentrate on a niche, you will win more projects in that niche, allowing you to become an expert quicker than if you take every project that pops its head up. As your experience in your niche deepens you become even more valuable to your clients - and this is what can take you from being viewed as just a "dev shop" to being viewed as a high value partner.</p><blockquote>"<em>No one achieves greatness by becoming a generalist. You don't hone a skill by diluting your attention to its development. The only way to get to the next level is focus</em>" ― John C. Maxwell</blockquote><p>At the end of the day a dev shop and a high value partner are both just delivering client services, however it's deep expertise and knowledge which is the true value to the client, and is what will allow you cross that chasm into becoming an indispensable technology partner.</p><h3 id="5-expert-rates-">5. Expert rates 💵</h3><p>Unfortunately it's common for agencies to use the "race to the bottom" pricing strategy, which is basically who can do it the cheapest (especially common with outsourced dev shops). There may be a time where you price as low as you can just to win a project (especially when starting out), but then move as fast as you can to charging what you are really worth. Separate yourself from the cheaper crowd, and instead aim for the exclusive expert crowd. Obviously this is the dream right? No one wants to be viewed as cheap, but how do you compete with those that charge $7 per hour? Charging what you're worth is tied to being seen as an expert. Experts charge a premium because they know more than the others (or appear to know more). Experts have the deep experience gained from fighting many battles in the trenches, and it's that experience the clients pay for. Having a niche will allow you focus on gaining deeper experience, which will in turn help you charge more, which in turn will make life a lot easier.</p><h2 id="possible-negatives-of-niche">Possible negatives of niche?</h2><h3 id="being-pigeonholed-">Being pigeonholed 🐦</h3><p>Being known as the company that "just does X" could leave you feeling trapped, especially if "X" is not truly something you want to do - or there are not enough clients that actually want "X". To mitigate this it is important to discover a niche area that is at the intersection of</p><ol><li>Something you are interested in and want to do</li><li>Something you are experienced in (or can gain experience in)</li><li>Something that the market wants (that people will pay for)</li></ol><p>Without any of these your niche may feel more like a pigeonhole.</p><h3 id="reduced-market-">Reduced m<strong>arket 📈</strong></h3><p>If a pie represents "all possible clients that want custom software", then yes, your niche is a reduced portion of that pie. That's a fact. The total possible market for custom software is no longer your target market, and this a bi-product of niching down. However with the right niche this is not a negative thing, as a small company cannot waste time talking with thousands of potential clients that ultimately choose another agency. A small software agency doesn't need or want thousands of customers like a $5 per month SaaS app does. You want a small group of quality clients who respect you and value your work (that's the goal). There is plenty of work out there for everyone, and as long as you don't pick too small a niche, then a smaller market is not a bad thing.</p><h3 id="the-expert-barrier-">The e<strong>xpert barrier 🚧</strong></h3><p>How does your agency become an expert in anything if you are just starting out? This is the chicken or the egg problem, you cannot become the industry leading expert if you don't get the experience. This is a common barrier of entry when deciding on whether to focus or remain a generalist - but every expert had to start somewhere.</p><p>My advice is: As honestly as you can, "fake it till you make it". I am not telling you to lie about being specialist in something you have no experience in (but I also don't think you should choose a niche you have zero experience in), I am saying to creatively highlight the experience you DO have - no matter how limited - and focus communicating the benefits of what you can do with that experience. This is sales, and oftentimes you need to sell where you want to be as opposed to where you are right now tomorrow. I would also recommend immersing yourself in your niche. Read all you can, talk to as many people as you can, and ask all the questions you can. You need to be pro-active …</p></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.devtoagency.com/think-niche">https://www.devtoagency.com/think-niche</a></em></p>]]>
            </description>
            <link>https://www.devtoagency.com/think-niche</link>
            <guid isPermaLink="false">hacker-news-small-sites-25976522</guid>
            <pubDate>Sun, 31 Jan 2021 06:11:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Deep Learning for Time Series Frameworks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25976337">thread link</a>) | @rsvpdd2
<br/>
January 30, 2021 | http://pytorchforecasting.com/2021/01/deep-learning-for-time-series-forecasting-frameworks-2021/ | <a href="https://web.archive.org/web/*/http://pytorchforecasting.com/2021/01/deep-learning-for-time-series-forecasting-frameworks-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-13">

	

	<div>
		
<p>In this post we will look at some of the top open source deep learning for time series forecasting frameworks. In particular we will look at PyTorch time series forecasting frameworks.</p>



<ol><li><a href="https://github.com/awslabs/gluon-ts">Gluon</a> This framework by Amazon remains one of the top DL based time series forecasting frameworks on GitHub. However, there are some down sides including lock-in to MXNet (a rather obscure architecture). The repository also doesn’t seem to be quick at adding new research. </li><li><a href="https://github.com/AIStream-Peelout/flow-forecast">Flow Forecast</a>: This is an upcoming PyTorch based deep learning for time series forecasting framework. The repository features a lot of recent models out of research conferences along with an easy to use deployment API. The repository is one of the few repositories to have new research models, coverage tests, and interpretability metrics. </li><li><a href="https://github.com/sktime/sktime-dl">sktime dl</a> This is another time series forecasting repository. Unfortunately it looks like particularly recent activity has diminished on it. On the main page it looks </li><li><a href="https://github.com/zalandoresearch/pytorch-ts">PyTorch-TS</a> Another framework, written in PyTorch, this repository focuses more on probabilistic models. The repository isn’t that active (last commit was in November). However, the group behind it appears active in the research community and adds newer models to it. </li></ol>



<p>These seem to be the major time series forecasting framework out there at moment. Interestingly at present there doesn’t seem to be a time series forecasting built exclusively in Tensorflow/Keras. However there are <a href="https://www.tensorflow.org/tutorials/structured_data/time_series">several tutorials</a> out there.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>http://pytorchforecasting.com/2021/01/deep-learning-for-time-series-forecasting-frameworks-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25976337</guid>
            <pubDate>Sun, 31 Jan 2021 05:35:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Google needs to build an open chat client like Elemen]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25976275">thread link</a>) | @rukshn
<br/>
January 30, 2021 | https://ruky.me/2021/01/31/why-google-needs-to-build-an-open-chat-client-like-element/ | <a href="https://web.archive.org/web/*/https://ruky.me/2021/01/31/why-google-needs-to-build-an-open-chat-client-like-element/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><a rel="noreferrer noopener" href="https://twitter.com/element_hq/status/1355290296947499013" target="_blank">Google recently blocked the Matrix based chat app Element from the Play Store sighting sexual content on the platform.</a> It’s really hard to define the explanation because WhatsApp, Telegram users of other chat clients also share the same content. <a href="https://www.redpoints.com/blog/telegram-book-piracy/" target="_blank" rel="noreferrer noopener">Telegram is also known to host groups sharing pirated content as well.</a></p>
<p>This post is not going to bash Google on the ban of Element. It’s about how Google can win the chat app, but how google can build a chat app based on an open chat protocol and create a winning chat platform for them.</p>
<p>Chat apps have been hot for the past couple of years. When I initially Tweeted that chat apps are the new social network, 6-7 years ago (I wish if I can find that tweet, but I can’t seem to find it, maybe it was lost when I deleted all my tweets sometime ago), I remember how people laughed replying how can that even possible, but now as Facebook is on the decline, chat apps are the goto place to hang out with friends.</p>
<p>Google currently doesn’t have a house in the chat app race. Google tried with several chat applications, like Allo, Hangout, Google Talk, none of them took off. Even though Allo looked promising, and was integrated into Android, people never jumped the ship to Allo. And since Google now allowing several chat/video platforms like Hangout, Meet etc, Google’s direction in communication platform seems big vague.</p>
<p>Google also has had a poor history with social networking, Google does not have social in their DNA, it feels like they are engineering, technology first in their approach, while Facebook feels more social first than anything else.</p>
<p>However, after seeing this ban I feel what Google should have a horse in the chat app race, and it should be a matrix/element based chat client. Allow me to explain,</p>
<p>Google should embrace an open protocol like Matrix and build a chat client on top of it, yes it’s against their pattern of hoarding data, and usage of open protocol.</p>
<p>But Google was able to win the email, the email protocol is an open protocol, anyone can implement it, anyone can use any client they want, but still Google was able to create the most popular email service available out their, and even monetise it. </p>
<p>Before Google started gmail, services like hotmail only allowed 200mb of storage, I remember Yahoo deleting my email account because I didn’t login for 6 months (I was still schooling at that time, and didn’t use email much), and not to mention Yahoo, and hotmail had atrocious ads on their email service. But google changed all that, they gave a better UI, more storage, and even a better ad experience.</p>
<p>So what makes then incapable of using an open chat protocol and build a great experience around it? With engineers and money to back a project like that Google can build a good chat service around an open chat protocol.</p>
<p>Even ads might not be a thing, Google can still provide enterprise chat service to organisations, powered by their data servers. They can even keep their source closed if they want to, like they are doing with Gmail, but an open source client would be great.</p>
<p>And Google’s backing for a open chat platform will make people interested about it, and even more people will use it just because it’s from Google. People will be able to use their own clients like Element, or another Matrix client, still and users can build a network greater than a centralised chat service, like we use gmail in our mail app to chat with someone else with a different email provider. </p>
<p>And the bottom line is Facebook, Telegram, Signal, and other chat platforms are going on a race without Google, all providing a centralised experience, with the exception of Signal, who is providing a semi-centralised experience. So even if you can’t beat them, why not try to destroy them all with an open chat protocol?</p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2021/01/31/why-google-needs-to-build-an-open-chat-client-like-element/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25976275</guid>
            <pubDate>Sun, 31 Jan 2021 05:24:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[QuietKeys – win32/C++ native sys tray app to automatically mute mic while typing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25976273">thread link</a>) | @jfdi
<br/>
January 30, 2021 | https://www.thomaswilley.com/2021/01/28/introducing-quietkeys-a-tiny-app-to-make-conf-calls-a-little-nicer/ | <a href="https://web.archive.org/web/*/https://www.thomaswilley.com/2021/01/28/introducing-quietkeys-a-tiny-app-to-make-conf-calls-a-little-nicer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>
    
    <p><span>January 28, 2021</span></p><p><a href="https://github.com/thomaswilley/quietkeysapp"><img alt="QuietKeys *inline *line-height" src="https://raw.githubusercontent.com/thomaswilley/quietkeysapp/master/Icons/Source/mic-fill.png"> QuietKeys</a> is a tiny app for Windows that
automatically mutes your <span>PC</span>’s mic when you type. If you’re on a conf call and
you can hear someone’s typing - send them the link to install&nbsp;QuietKeys!</p>
<p><img alt="QuietKeys Demo" src="https://raw.githubusercontent.com/thomaswilley/quietkeysapp/master/quietkeys_demo.gif"></p>
<p>If you’re on a conf call and you can hear someone’s typing - send them the link
to install QuietKeys! Hope this helps make calls from the <span>PC</span> a little bit&nbsp;nicer.</p>
<p>QuietKeys is written in win32/C++/C as a native windows application. Basically,
it’s a tiny file, runs super fast, and sips very little battery - so you won’t
even notice it’s there in the background. QuietKeys is a single executable
(quietkeysapp.exe) which can be set to automatically run at startup. The
QuietKeys app lives down in the system tray alongside your wifi icon, battery %
icon, etc. Left-click the icon to toggle whether QuietKeys is enabled or
disabled. Right-click to manage the&nbsp;app.</p>
<p>QuietKeys is an Increment project (<a href="https://increment.me/">https://increment.me</a>) - I’d welcome your <a href="https://www.increment.me/tw/feedback/feedback-about-quietkeys/">feedback</a>!</p>
<p>The full source is on Github and you can download a pre-compiled binary or compile it yourself.
<a href="https://github.com/thomaswilley/quietkeysapp">Get QuietKeys&nbsp;Now</a></p>
  </div>
</div>
      </div></div>]]>
            </description>
            <link>https://www.thomaswilley.com/2021/01/28/introducing-quietkeys-a-tiny-app-to-make-conf-calls-a-little-nicer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25976273</guid>
            <pubDate>Sun, 31 Jan 2021 05:23:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The G-Machine in Detail, or How Lazy Evaluation Works]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25976167">thread link</a>) | @colinprince
<br/>
January 30, 2021 | https://abby.how/posts/the-gmachine-in-detail.html | <a href="https://web.archive.org/web/*/https://abby.how/posts/the-gmachine-in-detail.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<span id="reading-length">4426</span>



<p>With Haskell now more popular than ever, a great deal of programmers deal with lazy evaluation in their daily lives. They’re aware of the pitfalls of lazy I/O, know not to use <code>foldl</code>, and are masters at introducing bang patterns in the right place. But very few programmers know the magic behind lazy evaluation—graph reduction.</p>
<p>This post is an abridged adaptation of Simon Peyton Jones’ and David R. Lester’s book, <em>“Implementing Functional Languages: a tutorial.”</em>, itself a refinement of SPJ’s previous work, 1987’s <em>“The Implementation of Functional Programming Languages”</em>. The newer book doesn’t cover as much material as the previous: it focuses mostly on the evaluation of functional programs, and indeed that is our focus today as well. For this, it details three abstract machines: The G-machine, the Three Instruction Machine (affectionately called Tim), and a parallel G-machine.</p>
<p>In this post we’ll take a look first at a stack-based machine for reducing arithmetic expressions. Armed with the knowledge of how typical stack machines work, we’ll take a look at the G-machine, and how graph reduction works (and where the name comes from in the first place!)</p>
<p>This post is written as <a href="https://abby.how/lhs/2020-01-31.lhs">a Literate Haskell source file</a>, with Cpp conditionals to enable/disable each section. To compile a specific section, use GHC like this:</p>
<div>
<p><span>Bash</span></p><div id="cb1"><pre><code><span id="cb1-1"><span>ghc</span> -XCPP -DSection1 2020-01-09.lhs</span></code></pre></div>
</div>
<hr>


<p>Stack machines are the base for all of the computation models we’re going to explore today. To get a better feel of how they work, the first model of computation we’re going to describe is stack-based arithmetic, better known as reverse polish notation. This machine also forms the basis of the programming language FORTH. First, let us define a data type for arithmetic expressions, including the four basic operators (addition, multiplication, subtraction and division.)</p>
<div>
<p><span>Haskell</span></p><div id="cb3"><pre><code><span id="cb3-1"><span>data</span> <span>AExpr</span></span>
<span id="cb3-2">  <span>=</span> <span>Lit</span> <span>Int</span></span>
<span id="cb3-3">  <span>|</span> <span>Add</span> <span>AExpr</span> <span>AExpr</span></span>
<span id="cb3-4">  <span>|</span> <span>Sub</span> <span>AExpr</span> <span>AExpr</span></span>
<span id="cb3-5">  <span>|</span> <span>Mul</span> <span>AExpr</span> <span>AExpr</span></span>
<span id="cb3-6">  <span>|</span> <span>Div</span> <span>AExpr</span> <span>AExpr</span></span>
<span id="cb3-7">  <span>deriving</span> (<span>Eq</span>, <span>Show</span>, <span>Ord</span>)</span></code></pre></div>
</div>
<p>This language has an ‘obvious’ denotation, which can be realised using an interpreter function, such as <code>aInterpret</code> below.</p>
<div>
<p><span>Haskell</span></p><div id="cb4"><pre><code><span id="cb4-1"><span>aInterpret ::</span> <span>AExpr</span> <span>-&gt;</span> <span>Int</span></span>
<span id="cb4-2">aInterpret (<span>Lit</span> n) <span>=</span> n</span>
<span id="cb4-3">aInterpret (<span>Add</span> e1 e2) <span>=</span> aInterpret e1 <span>+</span> aInterpret e2</span>
<span id="cb4-4">aInterpret (<span>Sub</span> e1 e2) <span>=</span> aInterpret e1 <span>-</span> aInterpret e2</span>
<span id="cb4-5">aInterpret (<span>Mul</span> e1 e2) <span>=</span> aInterpret e1 <span>*</span> aInterpret e2</span>
<span id="cb4-6">aInterpret (<span>Div</span> e1 e2) <span>=</span> aInterpret e1 <span>`div`</span> aInterpret e2</span></code></pre></div>
</div>
<p>Alternatively, we can implement the language through its <em>operational</em> behaviour, by compiling it to a series of instructions that, when executed in an appropriate machine, leave it in a <em>final state</em> from which we can extract the expression’s result.</p>
<p>Our abstract machine for aritmethic will be a <em>stack</em> based machine with only a handful of instructions. The type of instructions is <code><span>AInstr</span></code>.</p>
<div>
<p><span>Haskell</span></p><div id="cb5"><pre><code><span id="cb5-1"><span>data</span> <span>AInstr</span></span>
<span id="cb5-2">  <span>=</span> <span>Push</span> <span>Int</span></span>
<span id="cb5-3">  <span>|</span> <span>IAdd</span> <span>|</span> <span>IMul</span> <span>|</span> <span>ISub</span> <span>|</span> <span>IDiv</span></span>
<span id="cb5-4">  <span>deriving</span> (<span>Eq</span>, <span>Show</span>, <span>Ord</span>)</span></code></pre></div>
</div>
<p>The state of the machine is simply a pair, containing an instruction stream and a stack of values. By our compilation scheme, the machine is never in a state where more values are required on the stack than there are values present; This would not be the case if we let programmers directly write instruction streams.</p>
<p>We can compile a program into a sequence of instructions recursively.</p>
<div>
<p><span>Haskell</span></p><div id="cb6"><pre><code><span id="cb6-1"><span>aCompile ::</span> <span>AExpr</span> <span>-&gt;</span> [<span>AInstr</span>]</span>
<span id="cb6-2">aCompile (<span>Lit</span> i)     <span>=</span> [<span>Push</span> i]</span>
<span id="cb6-3">aCompile (<span>Add</span> e1 e2) <span>=</span> aCompile e1 <span>++</span> aCompile e2 <span>++</span> [<span>IAdd</span>]</span>
<span id="cb6-4">aCompile (<span>Mul</span> e1 e2) <span>=</span> aCompile e1 <span>++</span> aCompile e2 <span>++</span> [<span>IMul</span>]</span>
<span id="cb6-5">aCompile (<span>Sub</span> e1 e2) <span>=</span> aCompile e1 <span>++</span> aCompile e2 <span>++</span> [<span>ISub</span>]</span>
<span id="cb6-6">aCompile (<span>Div</span> e1 e2) <span>=</span> aCompile e1 <span>++</span> aCompile e2 <span>++</span> [<span>IDiv</span>]</span></code></pre></div>
</div>
<p>And we can write a function to represent the state transition rules of the machine.</p>
<div>
<p><span>Haskell</span></p><div id="cb7"><pre><code><span id="cb7-1"><span>aEval ::</span> ([<span>AInstr</span>], [<span>Int</span>]) <span>-&gt;</span> ([<span>AInstr</span>], [<span>Int</span>])</span>
<span id="cb7-2">aEval (<span>Push</span> i<span>:</span>xs, st)   <span>=</span> (xs, i<span>:</span>st)</span>
<span id="cb7-3">aEval (<span>IAdd</span><span>:</span>xs, x<span>:</span>y<span>:</span>st) <span>=</span> (xs, (x <span>+</span> y)<span>:</span>st)</span>
<span id="cb7-4">aEval (<span>IMul</span><span>:</span>xs, x<span>:</span>y<span>:</span>st) <span>=</span> (xs, (x <span>*</span> y)<span>:</span>st)</span>
<span id="cb7-5">aEval (<span>ISub</span><span>:</span>xs, x<span>:</span>y<span>:</span>st) <span>=</span> (xs, (x <span>-</span> y)<span>:</span>st)</span>
<span id="cb7-6">aEval (<span>IDiv</span><span>:</span>xs, x<span>:</span>y<span>:</span>st) <span>=</span> (xs, (x <span>`div`</span> y)<span>:</span>st)</span></code></pre></div>
</div>
<p>A state is said to be <em>final</em> when it has an empty instruction stream and a single result on the stack. To run a program, we simply repeat <code>aEval</code> until a final state is reached.</p>
<div>
<p><span>Haskell</span></p><div id="cb8"><pre><code><span id="cb8-1"><span>aRun ::</span> [<span>AInstr</span>] <span>-&gt;</span> <span>Int</span></span>
<span id="cb8-2">aRun is <span>=</span> go (is, []) <span>where</span></span>
<span id="cb8-3">  go st <span>|</span> <span>Just</span> i <span>&lt;-</span> final st <span>=</span> i</span>
<span id="cb8-4">  go st <span>=</span> go (aEval st)</span>
<span id="cb8-5"></span>
<span id="cb8-6">  final ([], [n]) <span>=</span> <span>Just</span> n</span>
<span id="cb8-7">  final _ <span>=</span> <span>Nothing</span></span></code></pre></div>
</div>
<p>A very important property linking our compiler, abstract machine and interpreter together is that of <em>compiler correctness</em>. That is:</p>
<div>
<p><span>Haskell</span></p><div id="cb9"><pre><code><span id="cb9-1"><span>forall</span> x<span>.</span> aRun (aCompile x) <span>==</span> aInterpret x</span></code></pre></div>
</div>
<p>As an example, the arithmetic expression <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>+</mo><mn>3</mn><mo>×</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">2 + 3 \times 4</annotation></semantics></math></span></span> produces the following code sequence:</p>
<div>
<p><span>Haskell</span></p><div id="cb10"><pre><code><span id="cb10-1">[<span>Push</span> <span>2</span>,<span>Push</span> <span>3</span>,<span>Push</span> <span>4</span>,<span>IMul</span>,<span>IAdd</span>]</span></code></pre></div>
</div>
<p>You can interactively follow the execution of this program with the tool below. Pressing the Step button is equivalent to <code>aEval</code>. The stack is drawn in boxes to the left, and the instruction sequence is presented on the right, where the <code>&gt;</code> marks the currently executing instruction (the “program counter”, if you will).</p>



<hr>

<p>In the previous section, we looked at how stack machines can be used to implement arithmetic. This is nothing exciting, though: FORTH is from the late 1960s! In this section, we’re going to look at a <em>much</em> more modern idea, only 30-something years old, which uses stack machines to implement <em>functional</em> languages via <em>lazy graph reduction</em>.</p>
<p>But first, we need to understand what that technobabble means in the first place. We define a functional language to be one in which the evaluation of a program expression is the same as evaluating a mathematical function: When you’re executing a “function application”, substitute the actual value of the argument wherever the parameter appears in the body of the function, then reduce any <em>reducible expressions</em>.</p>
<blockquote>
<div>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>λ</mi><mi>x</mi><mi mathvariant="normal">.</mi><mi>x</mi><mo>+</mo><mn>2</mn><mo stretchy="false">)</mo><mtext>&nbsp;</mtext><mn>5</mn></mrow><annotation encoding="application/x-tex">
( \lambda{x}. x + 2 )\ 5
</annotation></semantics></math></span></span></span></p>
<p>Evaluation of a functional program starts by identifying a <em>reducible expression</em>, that is, an expression that isn’t “done” evaluating yet. By convention, we call reducible expressions redexes for short<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>, and expressions that are done evaluating are called <em>head-normal forms</em>.</p>
<p>Every application is a reducible expression. Here, reduction proceeds by substituting <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn></mrow><annotation encoding="application/x-tex">5</annotation></semantics></math></span></span> in the place of every mention of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span>. Substituting an expression <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">E_2</annotation></semantics></math></span></span> in place of the variable <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span></span>, in a bigger expression <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">E_1</annotation></semantics></math></span></span> is notated <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mn>1</mn></msub><mo stretchy="false">[</mo><msub><mi>E</mi><mn>2</mn></msub><mi mathvariant="normal">/</mi><mi>v</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">E_1[E_2/v]</annotation></semantics></math></span></span> (read “<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">E_1</annotation></semantics></math></span></span> with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">E_2</annotation></semantics></math></span></span> for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span></span>”).</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mn>2</mn><mo stretchy="false">)</mo><mo stretchy="false">[</mo><mn>5</mn><mi mathvariant="normal">/</mi><mi>x</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">
(x + 2)[5/x]
</annotation></semantics></math></span></span></span></p>
<p>This step of the evaluation isn’t exactly an expression, but it serves to illustrate what reducing a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span></span> expression does: replacing the bound variable (or the “formal parameter” in fancy-pants speak. I’ll stick to bound variable).</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>5</mn><mo>+</mo><mn>2</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
(5 + 2)
</annotation></semantics></math></span></span></span></p>
<p>By this step, the function has disappeared entirely. The expression has been replaced entirely with addition between numbers.</p>
<p>Of course, addition, when both sides have been evaluated to a number, is <em>itself</em> a redex. This program isn’t done yet.</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn></mrow><annotation encoding="application/x-tex">
7
</annotation></semantics></math></span></span></span></p>
<p>Replacing the addition by its value, our original program has reached its end: The number <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn></mrow><annotation encoding="application/x-tex">7</annotation></semantics></math></span></span>, and indeed any other number, is a head-normal form.</p>
</div>
</blockquote>
<p>This all sounds good when described on paper, but how does one actually wire up (or, well, program) a computer to reduce functional programs?</p>
<p>Among the first and most comprehensive answers to this question was the G-machine, whose G stands for “Graph”. More specifically, the G-machine is an implementation of <em>graph reduction</em>: The expression to be reduced is represented as a graph that might have some redexes.</p>
<p>Once the machine has identified some particular redex to reduce, it’ll evaluate exactly as much as is needed to reach a head-normal form, and <em>replace</em> (or update) the graph so that the old redex points to its normal form.</p>
<p>To explore the workings of the G-machine, we’ll need to choose a functional language. Any will do, but simpler is better. Since I’ve already written a Lazy ML that compiles as described in this post, we’ll go with that.</p>
<p><a href="https://github.com/plt-abigail/rio">Rio</a>’s core language is a very simple functional language, notable only in that <em>it doesn’t have <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span></span>-abstractions</em>. All functions are defined at top-level, in the form of supercombinators.</p>
<blockquote>
A <strong>supercombinator</strong> is a function that only refers to its arguments or other supercombinators.
</blockquote>
<p>There’s a data type for terms:</p>
<div>
<p><span>Haskell</span></p><div id="cb11"><pre><code><span id="cb11-1"><span>data</span> <span>Term</span></span>
<span id="cb11-2">  <span>=</span> <span>Let</span> [(<span>Var</span>, <span>Term</span>)] <span>Term</span> </span>
<span id="cb11-3">  <span>|</span> <span>Letrec</span> [(<span>Var</span>, <span>Term</span>)] <span>Term</span></span>
<span id="cb11-4">  <span>|</span> <span>App</span> <span>Term</span> <span>Term</span></span>
<span id="cb11-5">  <span>|</span> <span>Ref</span> <span>Var</span></span>
<span id="cb11-6">  <span>|</span> <span>Num</span> <span>Integer</span></span>
<span id="cb11-7">  <span>deriving</span> <span>Show</span></span></code></pre></div>
</div>
<p>And one for supercombinators:</p>
<div>
<p><span>Haskell</span></p><div id="cb12"><pre><code><span id="cb12-1"><span>data</span> <span>SC</span> <span>=</span> <span>SC</span> {<span> name ::</span> <span>Var</span>,<span> args ::</span> [<span>Var</span>],<span> body ::</span> <span>Term</span> }</span>
<span id="cb12-2">  <span>deriving</span> <span>Show</span></span></code></pre></div>
</div>
<p>Consider the reduction of this functional program:</p>
<div>
<p><span>Haskell</span></p><div id="cb13"><pre><code><span id="cb13-1">double x <span>=</span> x <span>+</span> x</span>
<span id="cb13-2">main <span>=</span> double (double <span>4</span>)</span></code></pre></div>
</div>
<p>Here, <code>double</code> and <code>main</code> are the supercombinators that constitute the program. By convention, execution starts with the supercombinator <code>main</code>.</p>
<p>
<img src="https://abby.how/diagrams/template/step1.svg">
</p>
<p>The initial graph is the trivial graph containing only the node <code>main</code> and no edges. Since the node points directly to a supercombinator, we can replace it by a copy of its body:</p>
<p>
<img src="https://abby.how/diagrams/template/step2.svg">
</p>
<p>Now starts the actual work. There are many strategies for selecting a redex, and all of them are equally good, with the caveat that some may not terminate. However, if <em>any</em> evaluation strategy terminates, then so does “always choose the outermost redex”. This is called normal order evaluation. It’s what the G-machine implements.</p>
<p>The outermost redex here is the outer application of <code>double</code>, so that’s where reduction will happen. To reduce an application, update the redex with a copy of the supercombinator body, and replace the bound variables with pointers to the arguments.</p>
<p>
<img src="https://abby.how/diagrams/template/step3.svg">
</p>
<p>Observe that, since the subexpression <code>double 4</code> has two edges leading into it, the <em>tree</em> representing the program has degenerated into a general graph. However, this isn’t a bad thing: it means that the work to evaluate <code>double 4</code> will only be needed once.</p>
<p>The application of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span></span> isn’t reducible yet because it requires its arguments to be evaluated, so the next reducible expression down the chain is the application node representing <code>double 4</code>. The expansion there is similarly simple.</p>
<p>Here, it’s a bit hard to see what’s actually going on, so I’ll highlight in <span>blue</span> the <em>whole</em> next redex, <code>4 + 4</code>.</p>
<div>
<!-- reduction + highlight {{{ -->
<div>
<div>
<p><img src="https://abby.how/diagrams/template/step4.svg"></p>
<p>
The state of the graph after reduction of <code>double 4</code>.
</p>
</div>
<div>
<p><img src="https://abby.how/diagrams/template/step4red.svg"></p>
<p>
… with the entirety of the next redex highlighted for clarity.
</p>
</div>
</div>
</div>

<p>But, wait. That redex has <em>two</em> …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://abby.how/posts/the-gmachine-in-detail.html">https://abby.how/posts/the-gmachine-in-detail.html</a></em></p>]]>
            </description>
            <link>https://abby.how/posts/the-gmachine-in-detail.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25976167</guid>
            <pubDate>Sun, 31 Jan 2021 05:06:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Passing Runtime Data to Awk]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25975788">thread link</a>) | @signa11
<br/>
January 30, 2021 | https://blog.sanctum.geek.nz/passing-runtime-data-to-awk/ | <a href="https://web.archive.org/web/*/https://blog.sanctum.geek.nz/passing-runtime-data-to-awk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Shell script and AWK are very complementary languages.  AWK was designed from
its very beginnings at Bell Labs as a pattern-action language for short
programs, ideally one or two lines long.  It was intended to be used on the
Unix shell interactive command line, or in shell scripts.  Its feature set
filled out some functionality that shell script at the time lacked, and often
still lacks, as is the case with floating point numbers; it thereby
(indirectly) brings much of the C language’s expressive power to the shell.</p>

<p>It’s therefore both common and reasonable to see AWK one-liners in shell
scripts for data processing where doing the same in shell is unwieldy or
impossible, especially when floating point operations or data delimiting are
involved.  While AWK’s full power is in general tragically underused, most
shell script users and developers know about one of its most useful properties:
selecting a single column from whitespace-delimited data.  Sometimes,
<a href="https://www.man7.org/linux/man-pages/man1/cut.1p.html"><code>cut(1)</code></a> doesn’t, uh, cut it.</p>

<p>In order for one language to cooperate with another usefully via embedded
programs in this way, data of some sort needs to be passed between them at
runtime, and here there are a few traps with syntax that may catch out unwary
shell programmers.  We’ll go through a simple example showing the problems, and
demonstrate a few potential solutions.</p>

<h2>Easy: Fixed data</h2>

<p>Embedded AWK programs in shell scripts work great when you already know
<em>before</em> runtime what you want your patterns for the pattern-action pairs to
be.  Suppose our company has a vendor-supplied program that returns temperature
sensor data for the server room, and we want to run some commands for any and
all rows registering over a certain threshold temperature.  The output for the
existing <code>server-room-temps</code> command might look like this:</p>

<pre><code>$ server-room-temps
ID  Location    Temperature_C
1   hot_aisle_1 27.9
2   hot_aisle_2 30.3
3   cold_aisle_1    26.0
4   cold_aisle_2    25.2
5   outer       23.9
</code></pre>

<p>The task for the monitoring script is simple: get a list of all the locations
where the temperature is above 28°C.  If there are any such locations, we need
to email the administrator the full list.  Easy!  It looks like every
introductory AWK example you’ve ever seen—it could be straight out of <a href="https://www.amazon.com/AWK-Programming-Language-Alfred-Aho/dp/020107981X">the
book</a>.  Let’s type it up on the shell to test it:</p>

<pre><code>$ server-room-temps | awk 'NR &gt; 1 &amp;&amp; $3 &gt; 28 {print $2}'
hot_aisle_2
</code></pre>

<p>That looks good.  The script might end up looking something like this:</p>

<pre><code>#!/bin/sh
alerts=/var/cache/temps/alerts
server-room-temps |
    awk 'NR &gt; 1 &amp;&amp; $3 &gt; 28 {print $2}' &gt; "$alerts" || exit
if [ -s "$alerts" ] ; then
    mail -s 'Temperature alert' sysadmin &lt; "$alerts"
fi
</code></pre>

<p>So, after writing the alerts data file, we test if with <code>[ -s ... ]</code> to see
whether it’s got any data in it.  If it does, we send it all to the
administrator with <code>mail(1)</code>.  Done!</p>

<p>We set that running every few minutes with <code>cron(8)</code> or <code>systemd.timer(5)</code>, and
we have a nice stop-gap solution until the lazy systems administrator gets
around to fixing the Nagios server.  He’s probably just off playing
<a href="https://www.adom.de/home/index.html">ADOM</a> again…</p>

<h2>Hard: runtime data</h2>

<p>A few weeks later, our sysadmin still hasn’t got the Nagios server running,
because his high elf wizard is about to hit level 50, and there’s a new request
from the boss: can we adjust the script so that it accepts the cutoff
temperature data as an argument, and other departments can use it?  Sure, why
not.  Let’s mock that up, with a threshold of, let’s say, 25.5°C.</p>

<pre><code>$ server-room-temps &gt; test-data
$ threshold=25.5
$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; $threshold {print $2}' test-data
hot_aisle_1
hot_aisle_2
</code></pre>

<p>Wait, that’s not right.  There are <em>three</em> lines with temperatures over 25.5°C,
not two.  Where’s <code>cold_aisle_1</code>?</p>

<p>Looking at the code more carefully, you realize that you assumed your shell
variable would be accessible from within the AWK program, when of course, it
isn’t; AWK’s variables are independent of shell variables.  You don’t know why
the hell it’s showing those two rows, though…</p>

<p>Maybe we need double quotes?</p>

<pre><code>$ awk "NR &gt; 1 &amp;&amp; $3 &gt; $threshold {print $2}" test-data
awk: cmd. line:1: NR &gt; 1 &amp;&amp;  &gt; 25.5 {print}
awk: cmd. line:1:            ^ syntax error
</code></pre>

<p>Hmm.  Nope.  Maybe we need to expand the variable inside the quotes?</p>

<pre><code>$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; "$threshold" {print $2}' test-data
hot-aisle-1
hot-aisle-2
cold-aisle-1
cold-aisle-2
outer
</code></pre>

<p>That’s not right, either.  It seems to have printed <em>all</em> the locations, as if
it didn’t test the threshold at all.</p>

<p>Maybe it should be <em>outside</em> the single quotes?</p>

<pre><code>$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; '$threshold' {print $2}' test-data
hot-aisle-1
hot-aisle-2
cold-aisle-1
</code></pre>

<p>The results look right, now … ah, but wait, we still need to <a href="https://mywiki.wooledge.org/Quotes">quote it to
stop spaces expanding</a>…</p>

<pre><code>$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; '"$threshold"' {print $2}' test-data
hot-aisle-1
hot-aisle-2
cold-aisle-1
</code></pre>

<p>Cool, that works.  Let’s submit it to the security team and go to lunch.</p>

<h3>Caught out</h3>

<p>To your surprise, the script is rejected.  The security officer says you have
an unescaped variable that allows arbitrary code execution.  What?  Where?
It’s just AWK, not SQL…!</p>

<p>To your horror, the security officer demonstrates:</p>

<pre><code>$ threshold='0;{system("echo rm -fr /*");exit}'
$ echo 'NR &gt; 1 &amp;&amp; $3 &gt; '"$threshold"' {print $2}'
NR &gt; 1 &amp;&amp; $3 &gt; 0;{system("echo rm -fr /*");exit} {print $2}
$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; '"$threshold"' {print $2}' test-data
rm -fr /bin /boot /dev /etc /home /initrd.img ...
</code></pre>

<p>Oh, hell… if that were installed, and someone were able to set <code>threshold</code> to
an arbitrary value, they could execute <em>any</em> AWK code, and thereby shell
script, that they wanted to.  It’s <em>AWK injection</em>!  How embarrassing—good
thing that was never going to run as <code>root</code> (…right?)  Back to the drawing
board …</p>

<h3>Validating the data</h3>

<p>One approach that might come readily to mind is to ensure that no unexpected
characters appear in the value.  We could use a <code>case</code> statement before
interpolating the variable into the AWK program to check it contains no
characters outside digits and a decimal:</p>

<pre><code>case $threshold in
    *[!0-9.]*) exit 2 ;;
esac
</code></pre>

<p>That works just fine, and it’s appropriate to do some data validation at the
opening of the script, anyway.  It’s certainly better than leaving it as it
was.  But we <a href="https://en.wikipedia.org/wiki/SQL_injection">learned this lesson</a> with PHP in the 90s; you don’t just
filter on characters, or slap in some backslashes—that’s missing the point.
Ideally, we need to safely pass the data into the AWK process <em>without</em> ever
parsing it as AWK code, sanitized or nay, so the situation doesn’t arise in the
first place.</p>

<h3>Environment variables</h3>

<p>The shell and your embedded AWK program may not share the shell’s local
variables, but they <em>do</em> share environment variables, accessible in AWK’s
<code>ENVIRON</code> array.  So, passing the threshold in as an environment variable
works:</p>

<pre><code>$ THRESHOLD=25.5
$ export THRESHOLD
$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; ENVIRON["THRESHOLD"] {print $2}' test-data
hot-aisle-1
hot-aisle-2
cold-aisle-1
</code></pre>

<p>Or, to be a little cleaner:</p>

<pre><code>$ THRESHOLD=25.5 \
    awk 'NR &gt; 1 &amp;&amp; $3 &gt; ENVIRON["THRESHOLD"] {print $2}' test-data
hot-aisle-1
hot-aisle-2
cold-aisle-1
</code></pre>

<p>This is already much better.  AWK will parse our data <em>only</em> as a variable, and
won’t try to execute anything within it.  The only snag with this method is
picking a name; make sure that you don’t overwrite another, more important
environment variable, like <code>PATH</code>, or <code>LANG</code>…</p>

<h3>Another argument</h3>

<p>Passing the data as another <em>argument</em> and then reading it out of the <code>ARGV</code>
array works, too:</p>

<pre><code>$ awk 'BEGIN{ARGC--} NR &gt; 1 &amp;&amp; $3 &gt; ARGV[2] {print $2}' test-data 25.5
</code></pre>

<p>This method is also safe from arbitrary code execution, but it’s still somewhat
awkward because it requires us to decrease the argument count <code>ARGC</code> by one so
that AWK doesn’t try to process a file named “25.5” and end up upset when it’s
not there.  AWK arguments can mean whatever you need them to mean, but unless
told otherwise, AWK generally assumes they are filenames, and will attempt to
iterate through them for lines of data to chew on.</p>

<p>Here’s another way that’s very similar; we read the threshold from the second
argument, and then blank it out in the <code>ARGV</code> array:</p>

<pre><code>$ awk 'BEGIN{threshold=ARGV[2];ARGV[2]=""}
    NR &gt; 1 &amp;&amp; $3 &gt; threshold {print $2}' test-data 25.5
</code></pre>

<p>AWK won’t treat the second argument as a filename, because it’s blank by the
time it processes it.</p>

<h3>Pre-assigned variables</h3>

<p>There are two lesser-known syntaxes for passing data into AWK that allow you
safely to assign variables at runtime.  The first is to use the <code>-v</code> option:</p>

<pre><code>$ awk -v threshold="$threshold" \
    'NR &gt; 1 &amp;&amp; $3 &gt; threshold {print $2}' \
    test-data
</code></pre>

<p>Another, perhaps even more obscure, is to set them as arguments before the
filename data, using the <code>var=value</code> syntax:</p>

<pre><code>$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; threshold {print $2}' \
    threshold="$threshold" test-data
</code></pre>

<p>Note that in both cases, we still <em>quote</em> the <code>$threshold</code> expansion; this is
because the shell is expanding the value before we pass it in.</p>

<p>The difference between these two syntaxes is when the variable assignment
occurs.  With <code>-v</code>, the assignment happens straight away, before reading any
data from the input sources, as if it were in the <code>BEGIN</code> block of the program.
With the argument form, it happens when the program’s data processing reaches
that argument.  The upshot of that is that you could test several files with
several different temperatures in one hit, if you wanted to:</p>

<pre><code>$ awk 'NR &gt; 1 &amp;&amp; $3 &gt; threshold {print $2}' \
    threshold=25.5 test-data-1 threshold=26.0 test-data-2
</code></pre>

<p>Both of these assignment syntaxes are standardized in <a href="https://www.man7.org/linux/man-pages/man1/awk.1p.html">POSIX <code>awk</code></a>.</p>

<p>These are my preferred methods for passing runtime data; they require no
argument count munging, avoid the possibility of trampling on existing
environment variables, use AWK’s own variable and expression syntax, and most
importantly, the chances of anyone reading the script being able to grasp
what’s going on are higher.  You can thereby avoid a mess of quoting and
back-ticking that often plagues these sorts of embedded programs.</p>

<h2>Safety not guaranteed</h2>

<p>If you take away only one thing from this …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.sanctum.geek.nz/passing-runtime-data-to-awk/">https://blog.sanctum.geek.nz/passing-runtime-data-to-awk/</a></em></p>]]>
            </description>
            <link>https://blog.sanctum.geek.nz/passing-runtime-data-to-awk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25975788</guid>
            <pubDate>Sun, 31 Jan 2021 04:03:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is how Google will collapse]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25975560">thread link</a>) | @partingshots
<br/>
January 30, 2021 | https://empirics.asia/this-is-how-google-will-collapse/ | <a href="https://web.archive.org/web/*/https://empirics.asia/this-is-how-google-will-collapse/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p id="473e">Google made almost all its money from ads. It was a booming business — until it wasn’t. Here’s how things looked right before the most spectacular crash the technology industry had ever seen.</p><h3 id="816d">The crumbling of Google’s cornerstone</h3><p id="ce3a">Search was Google’s only unambiguous win, as well as its <a href="https://www.cnbc.com/2017/01/26/googlealphabet-reports-fourth-quarter-2016-earnings-q4.html" target="_blank" rel="noopener" data-href="http://www.cnbc.com/2017/01/26/googlealphabet-reports-fourth-quarter-2016-earnings-q4.html">primary source of revenue</a>, so when Amazon <a href="https://www.geekwire.com/2017/amazon-continues-grow-lead-google-starting-point-online-shoppers/" target="_blank" rel="noopener" data-href="http://www.geekwire.com/2017/amazon-continues-grow-lead-google-starting-point-online-shoppers/">rapidly surpassed Google</a> as the top product search destination, Google’s foundations began to falter. <span data-creator-ids="anon">As <a href="https://techcrunch.com/2016/08/11/google-isnt-safe-from-yahoos-fate/" target="_blank" rel="noopener" data-href="https://techcrunch.com/2016/08/11/google-isnt-safe-from-yahoos-fate/">many noted</a> at the time, the online advertising industry experienced a major shift from search to discovery in the mid-2010s.</span></p><p id="652c">While Google protected its monopoly on the dying search advertising market, Facebook — Google’s biggest competitor in the online advertising space — got on the <a href="https://www.emarketer.com/Article/Google-Facebook-Increase-Their-Grip-on-Digital-Ad-Market/1015417" target="_blank" rel="noopener" data-href="https://www.emarketer.com/Article/Google-Facebook-Increase-Their-Grip-on-Digital-Ad-Market/1015417">right side of the trend</a> and dominated online advertising with its in-feed native display advertising.</p><figure id="88e5"><div></div><figcaption>The people who turned to Amazon over Google? <a <a="" href="https://cdn.geekwire.com/wp-content/uploads/2017/01/Screen-Shot-2017-01-13-at-10.40.08-AM.png" target="_blank" rel="noopener" data-href="https://cdn.geekwire.com/wp-content/uploads/2017/01/Screen-Shot-2017-01-13-at-10.40.08-AM.png">The 18–29 crowd led the&nbsp;way</a>.</figcaption></figure><p id="93c5">In late 2015, Apple — Google’s main competitor in the mobile space — added a feature to their phones and tablets that allowed users to block ads.</p><p id="0ebe">Devices running iOS were responsible for an <a href="http://appleinsider.com/articles/15/05/27/apples-ios-drives-75-of-googles-mobile-advertising-revenue" target="_blank" rel="noopener" data-href="http://appleinsider.com/articles/15/05/27/apples-ios-drives-75-of-googles-mobile-advertising-revenue">estimated 75%</a> of Google’s revenue from mobile search ads, so by making this move, Apple was simultaneously weighing in decisively on the great ad blocking debate of the 2010s and dealing a substantial blow to the <a href="https://techcrunch.com/2016/07/24/apple-lays-the-groundwork-to-kill-online-advertising/" target="_blank" rel="noopener" data-href="https://techcrunch.com/2016/07/24/apple-lays-the-groundwork-to-kill-online-advertising/">future of online advertising</a>.</p></div><div><p id="4b96">A year later, as the internet went mobile, so too did ad blocking. The number of people blocking ads on a mobile device grew <a href="https://pagefair.com/blog/2016/mobile-adblocking-report/" target="_blank" rel="noopener" data-href="https://pagefair.com/blog/2016/mobile-adblocking-report/">102% from 2015 to 2016</a>; by the end of 2016, an estimated 16% of smartphone users globally were <a href="https://pagefair.com/blog/2016/mobile-adblocking-report/" target="_blank" rel="noopener" data-href="https://pagefair.com/blog/2016/mobile-adblocking-report/">blocking ads</a> when browsing the internet on a mobile device. The number was <a href="https://www.emarketer.com/Article/Why-More-than-Quarter-of-US-Internet-Users-Block-Ads/1014333" target="_blank" rel="noopener" data-href="https://www.emarketer.com/Article/Why-More-than-Quarter-of-US-Internet-Users-Block-Ads/1014333">as high as 25%</a> for desktop and laptop users in the United States, a country that accounted for <a href="https://www.statista.com/statistics/266250/regional-distribution-of-googles-revenue/" target="_blank" rel="noopener" data-href="https://www.statista.com/statistics/266250/regional-distribution-of-googles-revenue/">47% of Google’s revenue</a>.</p><p id="9580">The people most likely to block ads were also the most valuable demographic: <a href="http://marketingland.com/ad-blocker-usage-highest-among-key-advertiser-demos-millennials-and-high-earners-143546" target="_blank" rel="noopener" data-href="http://marketingland.com/ad-blocker-usage-highest-among-key-advertiser-demos-millennials-and-high-earners-143546"><em>millennials and high earners</em></a><em>.</em></p></div><div><p id="ab13"><strong>Internet users had spoken, and they hated ads.</strong></p><p id="f036">In early 2017, Google announced its plans to build an ad blocker into its popular Google Chrome browser. Google’s ad blocker would only block ads that were deemed unacceptable by the <a href="http://www.thedrum.com/news/2016/09/16/procter-gamble-unilever-google-facebook-and-more-form-coalition-better-ads" target="_blank" rel="noopener" data-href="http://www.thedrum.com/news/2016/09/16/procter-gamble-unilever-google-facebook-and-more-form-coalition-better-ads">Coalition For Better Ads</a>, effectively allowing the company to use its dominant web browser to strengthen its already dominant advertising business.</p><p id="d68f">Even after making this desperate and <a href="http://fortune.com/2017/04/20/google-ad-blocker/" target="_blank" rel="noopener" data-href="http://fortune.com/2017/04/20/google-ad-blocker/">legally questionable</a> move, it would quickly become clear to Google that even though ads were getting better, ad blocking numbers would <a href="http://adage.com/article/digital/ad-blocking-increases-consumers-improving/305978/" target="_blank" rel="noopener" data-href="http://adage.com/article/digital/ad-blocking-increases-consumers-improving/305978/">continue to rise</a>. Google had given even more people a small taste of what an ad-free internet experience could look like.</p><p id="5e12"><strong>The company discovered that it wasn’t just annoying ads that people didn’t like; it was ads in general.</strong></p></div><div><p id="5603">A key platform where Google served ads was YouTube, which it bought in 2006 and quickly turned into one of its biggest entities. But even with a <a href="http://www.huffingtonpost.com/2013/03/21/youtube-stats_n_2922543.html" target="_blank" rel="noopener" data-href="http://www.huffingtonpost.com/2013/03/21/youtube-stats_n_2922543.html">sixth of the world</a> visiting this video-sharing behemoth every month, YouTube <a href="https://www.wsj.com/articles/viewers-dont-add-up-to-profit-for-youtube-1424897967" target="_blank" rel="noopener" data-href="https://www.wsj.com/articles/viewers-dont-add-up-to-profit-for-youtube-1424897967">never became profitable</a>. In an attempt to combat the effect of ad blockers, YouTube launched an ad-free subscription model in late 2015, but the subscription numbers were <a href="https://www.theverge.com/2016/11/2/13498470/youtube-red-subscribers-video-content-music" target="_blank" rel="noopener" data-href="http://www.theverge.com/2016/11/2/13498470/youtube-red-subscribers-video-content-music">underwhelming</a>.</p><p id="7afb">YouTube’s already insurmountable problems multiplied in early 2017 as advertisers <a href="http://www.fiercepharma.com/marketing/google-scrambling-for-solutions-after-advertiser-departures-youtube" target="_blank" rel="noopener" data-href="http://www.fiercepharma.com/marketing/google-scrambling-for-solutions-after-advertiser-departures-youtube">began to pull out amid ad placement controversies</a>, and huge revenue generators began to <a href="http://www.ibtimes.com/pewdiepie-starts-weekly-twitch-show-uploads-youtube-over-party-video-2523797" target="_blank" rel="noopener" data-href="http://www.ibtimes.com/pewdiepie-starts-weekly-twitch-show-uploads-youtube-over-party-video-2523797">leave the site</a>.</p><p id="f0ab">Even those who weren’t blocking ads had trained themselves to ignore them entirely. Researchers dubbed this phenomenon “<a href="http://www.tobiipro.com/fields-of-use/marketing-consumer-research/advertising/" target="_blank" rel="noopener" data-href="http://www.tobiipro.com/fields-of-use/marketing-consumer-research/advertising/">banner blindness</a>”. The average banner ad was clicked on by a dismal <a href="https://www.thinkwithgoogle.com/intl/en-gb/planning-tool/display-benchmarks/" target="_blank" rel="noopener" data-href="https://www.thinkwithgoogle.com/intl/en-gb/planning-tool/display-benchmarks/">0.06% of viewers</a>, and of those clicks, roughly <a href="http://www.goldspotmedia.com/fat-finger-report/" target="_blank" rel="noopener" data-href="http://www.goldspotmedia.com/fat-finger-report/">50% were accidental</a>.</p><p id="c67f">Research showed that <a href="https://www.bannersnack.com/blog/build-trust-display-ads/" target="_blank" rel="noopener" data-href="http://www.bannersnack.com/blog/build-trust-display-ads/">54% of users</a> reported a lack of trust as their reason for not clicking banner ads and 33% found them completely <a href="http://downloads.pagefair.com/reports/adblocking_goes_mainstream_2014_report.pdf" target="_blank" rel="noopener" data-href="http://downloads.pagefair.com/reports/adblocking_goes_mainstream_2014_report.pdf">intolerable</a>. These figures painted a pretty grim picture for the sustainability of online advertising, but especially for Google’s position within the industry.</p><blockquote id="8a50"><p>Google’s mighty engine had started to&nbsp;sputter.</p></blockquote><h3 id="def0">A chance to pivot, and how Google missed&nbsp;it</h3><p id="ec19">If losing a major portion of their audience and annoying the rest wasn’t bad enough, Google also failed to get ahead of one of the biggest shifts in technology’s history. They recognized the importance of artificial intelligence but their approach missed the mark. Since Google’s search pillar had become unstable, a lot was riding on the company’s strategy for artificial intelligence.</p><blockquote id="2408"><p>“We will move from mobile first to an AI first&nbsp;world.”</p></blockquote><p id="814d">Google’s then-CEO Sundar Pichai <a href="https://blog.google/topics/inside-google/this-years-founders-letter/" target="_blank" rel="noopener" data-href="https://blog.google/topics/inside-google/this-years-founders-letter/">famously predicted</a> in 2016 that “<em>the next big step will be for the very concept of the ‘device’ to fade away” </em>and that<em> “over time, the computer itself — whatever its form factor — will be an intelligent assistant helping you through your day. We will move from mobile first to an AI first world.”</em></p><p id="6d2f">Google’s ability to acknowledge the coming trend and still fail to land in front of it reminded many observers of its catastrophic failures in the booming industries of social media and instant messaging.</p><figure id="179f"><div></div><figcaption>Sundar Pichai wondering how to monetize a virtual assistant</figcaption></figure><h3 id="deb3">Google vs.&nbsp;Amazon</h3><p id="d2e7">Meanwhile, in 2014, Amazon released a product called Amazon Echo, a small speaker that could sit in your home and answer questions, perform tasks, and buy things online for you. The Echo was a <a href="http://www.businessinsider.com/amazon-echo-success-could-spell-big-trouble-for-google-2017-1" target="_blank" rel="noopener" data-href="http://www.businessinsider.com/amazon-echo-success-could-spell-big-trouble-for-google-2017-1">smash success</a>. Google released its copycat product, Google Home, two years later, but it was already <a href="https://www.theguardian.com/technology/2017/jan/22/home-battleground-amazon-google-voice-technology" target="_blank" rel="noopener" data-href="https://www.theguardian.com/technology/2017/jan/22/home-battleground-amazon-google-voice-technology">too late to catch up</a>, and had no clear revenue strategy.</p><p id="a3f9">Alexa — the assistant that lived inside the Echo — on the other hand, was quickly integrated into several products and services, and its monetization model was clear, viable, and most importantly future-friendly. The Echo made it easy to order products through Amazon, and every time someone used an Echo to purchase something, Amazon made money.</p><p id="dde3">Google extended the reach of their virtual assistant by building it into Android, but doing so still didn’t provide an answer for how the technology would generate enough revenue to sustain Google’s expanding repertoire of expensive innovations.</p><p id="c590">Google’s ads relied on screens, yet voice interaction subverted screens entirely. Google briefly tried playing audio ads with the Google Home, but consumers were <a href="https://www.engadget.com/2017/03/17/google-home-ads-bad-precedent/" target="_blank" rel="noopener" data-href="https://www.engadget.com/2017/03/17/google-home-ads-bad-precedent/">far from receptive</a>. Investors <a href="http://www.businessinsider.com/google-ceo-sundar-pichai-responds-to-concerns-over-monetizing-voice-search-2017-1" target="_blank" rel="noopener" data-href="http://www.businessinsider.com/google-ceo-sundar-pichai-responds-to-concerns-over-monetizing-voice-search-2017-1">started to voice their concerns in 2017</a>, but Sundar Pichai told them not to worry, leaving them to assume that Google would use their age-old strategy and analyze users’ voice searches so that users could be shown more suitable ads on devices with screens.</p><figure id="388c"><div></div><figcaption>Alexa celebrating its victory over&nbsp;Google</figcaption></figure><p id="f6d7">Headlines in early 2017 <a href="https://www.wired.com/2017/01/ces-alexa-in-everything/" target="_blank" rel="noopener" data-href="https://www.wired.com/2017/01/ces-alexa-in-everything/">proclaimed</a> that “Alexa Just Conquered CES. The World is Next.” Amazon then made their technology <a href="https://www.zdnet.com/article/amazon-opens-echo-microphone-tech-to-third-party-alexa-devices/" target="_blank" rel="noopener" data-href="http://www.zdnet.com/article/amazon-opens-echo-microphone-tech-to-third-party-alexa-devices/">available</a> to third party manufacturers, putting even more distance between the two companies. Amazon <a href="http://www.investors.com/news/technology/amazon-confronts-microsoft-google-ibm-in-cloud-computing-wars/" target="_blank" rel="noopener" data-href="http://www.investors.com/news/technology/amazon-confronts-microsoft-google-ibm-in-cloud-computing-wars/">had already beaten Google once before</a>, holding 54% of the cloud computing market (compared to Google’s 3%) in 2016, and they were just getting started.</p><p id="2d79">By early 2017, Amazon <a href="https://www.cnbc.com/2017/03/31/competing-with-amazon-is-crushing-retailers.html" target="_blank" rel="noopener" data-href="http://www.cnbc.com/2017/03/31/competing-with-amazon-is-crushing-retailers.html">had begun closing in</a> on <a href="https://www.forbes.com/sites/groupthink/2017/02/03/amazon-go-is-the-future-plus-4-reasons-why-amazon-might-just-win-retail" target="_blank" rel="noopener" data-href="https://www.forbes.com/sites/groupthink/2017/02/03/amazon-go-is-the-future-plus-4-reasons-why-amazon-might-just-win-retail">the entire</a> <a href="http://www.businessinsider.com/retailers-are-going-bankrupt-at-a-staggering-rate-2017-4" target="_blank" rel="noopener" data-href="http://www.businessinsider.com/retailers-are-going-bankrupt-at-a-staggering-rate-2017-4">retail industry</a>.</p><h3 id="a95b">Ads weren’t&nbsp;forever</h3><p id="99b5">At its peak, Google had a massive and loyal user-base across a staggering number of products, but advertising revenue was the glue that held everything together. As the numbers waned, Google’s core began to buckle under the weight of its vast empire.</p><p id="4f07">Google was a driving force in the technology industry ever since its disruptive entry in 1998. But in a world where people despised ads, Google’s business model was not innovation-friendly, and they missed several opportunities to pivot, ultimately rendering their numerous grand and ambitious projects unsustainable. Innovation costs money, and Google’s main stream of revenue had started to dry up.</p><p id="dd33">In a few short years, Google had gone from a fun, commonplace verb to a reminder of how quickly a giant can fall.</p><p>___________________________________________</p><p><strong>About the Author</strong></p><p><em>This article was written by&nbsp;<a dir="auto" href="https://hackernoon.com/@dacoja?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="6502e16a569a" data-action-type="hover" data-user-id="6502e16a569a" data-collection-slug="hacker-daily">Daniel Colin James</a>,developer, writer, master’s student. <a href="http://danielcolinjames.com/">See more</a>. <a href="https://empirics.asia/this-is-how-google-will-collapse/danielcolinjames@gmail.com">Contact</a>.&nbsp;</em></p></div></div>]]>
            </description>
            <link>https://empirics.asia/this-is-how-google-will-collapse/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25975560</guid>
            <pubDate>Sun, 31 Jan 2021 03:25:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Onion's Genome Has Five Times More DNA Than Humans (2019)]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25975457">thread link</a>) | @disqard
<br/>
January 30, 2021 | https://geneticsunzipped.com/news/2019/1/31/the-onion-test | <a href="https://web.archive.org/web/*/https://geneticsunzipped.com/news/2019/1/31/the-onion-test">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-yui_3_17_2_1_1565793939038_266584"><div><p>The human genome is an incredible thing. Six billion letters of DNA – that’s more than two metres of DNA in every single cell – containing all the genes that enable a single cell to grow into a fully-formed, fully functioning person. </p><p>So when the first draft sequence of the human genome was published in 2001, researchers around the world were eager to discover exactly how many genes must be packed into our glorious genome.</p><p>The answer was a big surprise.</p><p>Many people thought that it must take at least a hundred thousand genes to make a human – with a sweepstake on offer to the person who made the closest guess to the final number – yet the human genome turns out to contain only 20,000 or so genes (roughly the same number of genes as a fruit fly or nematode worm).</p><p>This seems remarkably low to make an organism with as much dazzling complexity as a human being.  Even more perplexingly, the genes that we do have make up less than two per cent of all that DNA. So what’s the rest?</p><p>To find out, we need to go back in time to 1972.</p><p>That’s when geneticist Susumu Ohno published a paper entitled “So much ‘junk’ DNA in our genome” in an obscure scientific journal, the Brookhaven Symposia in Biology, in which he mused upon a mathematical problem.</p><p>By that point, scientists had already measured how much DNA was present in bacteria and figured out that these little bugs must contain a few thousand genes. They also knew that a single human cell contained at least 750 times as much DNA.</p><p>Ohno did a quick back-of-the-envelope calculation – if the number of genes in any genome was directly proportional to the amount of DNA, then humans should have….. three million genes, more or less.</p><p>But, as he pointed out in his paper, ‘lowly lungfish and salamanders’ can have 36 times more DNA in their cells than is present in ours, suggesting that they should have…. A hundred million genes.</p><p>He didn’t believe it. What would a slimy salamander need with all those genes? Therefore, Ohno concluded, the vast majority of the human genome must be junk. And, correspondingly, varying proportions of other organisms’ genomes must be junk too. And once the Human Genome project revealed that the vast majority of our genome doesn’t seem to contain actual genes, it looked like he was right.</p><p>The function of this remaining 98% of the human genome - sometimes called ‘junk DNA’ but more accurately referred to as non-coding DNA – is a hotly debated topic in the world of genetics, fought out within the dignified pages of journals and the more febrile atmosphere of scientific conferences.</p><p>An absolutely massive study published in 2012, known as ENCODE, suggested that around 80% of the human genome was functional – namely, that it did something important for the proper functioning of our cells and bodies. Just under 10 per cent is thought to be control switches responsible for turning genes on and off at the right time and in the right place, while the rest does all manner of things, from producing little pieces of RNA that control gene activity to organising the three-dimensional structure of the DNA inside a cell.</p><p>Others were unconvinced. For example, evolutionary geneticist Chris Ponting suggests that less than 10% of the human genome is functional, based on how much has been strongly preserved through evolutionary time and must therefore be very important.</p><p>It’s against this backdrop we bring in the Onion Test, devised by T. Ryan Gregory and posted on his blog in April 2007. It was later formalised as a scientific paper that he published in 2014, together with Alexander Palazzo.</p><p>Put simply, the Onion Test goes like this.</p><p>The onion in your vegetable drawer has five times more DNA than humans. So if you’re a researcher who thinks that non-coding DNA has a particular function in the genome, can you explain why an onion needs about five times more of it than a human to do the same thing?</p><p>Unpeeling this idea a bit further, Gregory points out that some species of onions have around double the amount of DNA as your regular onions, while others have less than half. Yet they’re pretty much the same and have the same number of genes, so why would they need double or half the amount of non-coding DNA?</p><p>This argument works for all kinds of species, from Ohno’s lowly salamanders with their giant genomes containing roughly the same set of genes as other vertebrates, including humans, to the biggest genome discovered to date, which belongs to the Japanese canopy flower, Paris Japonica, with around 150 time more DNA in its genome than a human.</p><p>Then there’s the poisonous Fugu pufferfish – often eaten (very carefully!) as a delicacy in Japan.  They have remarkably compact genomes, roughly an eighth of the size of our own yet containing almost exactly the same repertoire of genes and very little junk.</p><p>Perhaps our obsession with finding function for all the junk in our genome comes from a desire to think that humans are something special in the biological world – certainly more special than an onion.</p><p> But in the words of the grumpy geneticist Dan Graur, who I interviewed for my book Herding Hemingway’s Cats in which I dig into the junk in our genetic trunk,  “Either you have to assume that humans are the pinnacle of creation –that everything is functional and those organisms with more DNA than us have junk DNA but we don’t. Or you have to assume that humans are a regular organism that has junk DNA just like everything else.”</p><p><strong>Further reading:</strong></p><ul data-rte-list="default"><li><p><a href="http://www.genomicron.evolverzone.com/2007/04/onion-test/" target="_blank">T. Ryan Gregory’s original post about the onion test</a></p></li><li><p><a href="https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1004351" target="_blank">The case for junk DNA, Palazzo &amp; Gregory (2014), PLoS Genetics</a></p></li><li><p><a href="https://www.sciencemag.org/news/2010/10/scienceshot-biggest-genome-ever" target="_blank">The biggest ever genome - Paris Japonica </a></p></li><li><p><a href="http://bit.ly/HerdingHemingwaysCats" target="_blank">Herding Hemingway’s Cats - Kat Arney </a>(aff) Chapters 1 and 2</p></li></ul></div></div></div>]]>
            </description>
            <link>https://geneticsunzipped.com/news/2019/1/31/the-onion-test</link>
            <guid isPermaLink="false">hacker-news-small-sites-25975457</guid>
            <pubDate>Sun, 31 Jan 2021 03:13:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Element on Google Play Store]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25975378">thread link</a>) | @keskadale
<br/>
January 30, 2021 | https://element.io/blog/element-on-google-play-store/ | <a href="https://web.archive.org/web/*/https://element.io/blog/element-on-google-play-store/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      
      <div><p>Hi all,</p><p>At 2021-01-29 at 21:35 UTC Google suspended Element from the Play Store without warning or notification. &nbsp;We submitted an appeal asking for clarification at 23:18, and at 05:31 received a generic update from the Google Play Policy team citing that the app has been removed due to content which contravenes their terms of use, and asking us to “make the necessary changes to [our] app” and “upload a new app using a new package name and a new app name”.</p><p>As of 11:44 UTC we’ve submitted a detailed appeal to reiterate that Element is a generic chat app for connecting to the global Matrix communication network, just as Chrome is a generic web browser for connecting to the Web - and just as Google does not control the content on the Web, Element does not control the content on Matrix.</p><p>We have also explained that the Matrix servers that we <em>do</em> run as Element (including the default Matrix.org homeserver, which we run on behalf of <a href="https://matrix.org/foundation">The Matrix.org Foundation</a>) have <a href="https://matrix.org/legal/terms-and-conditions#6-play-nice-clauses">strict Terms of Use</a> which we actively enforce. We abhor abuse, and Element is not an app that caters to abusive content.</p><p>In order to enforce our terms of use on the Matrix servers we run as Element, we have a formal Trust and Safety team hired full-time who are dedicated to investigating and tracking abuse reports sent to <a href="https://element.io/cdn-cgi/l/email-protection#ccadaeb9bfa98ca1adb8bea5b4e2a3beab"><span data-cfemail="630201161006230e0217110a1b4d0c1104">[email&nbsp;protected]</span></a> or reported from the app. &nbsp;The team takes appropriate action on a ticket by ticket basis - deactivating abusive accounts and blocking chatrooms from our servers which contravene our terms of use, and building tooling to help enforce the terms of use on the servers we run.</p><p>Managing abuse is an ongoing activity, and <a href="https://sifted.eu/articles/element-whatsapp-exodus/">Matrix is expanding massively at the moment</a>. We are expanding Element’s Trust and Safety team to match that growth, focusing on improving our anti-abuse mechanisms, and we are also constantly expanding the <a href="https://matrix.org/docs/guides/moderation/">moderation tools</a> we provide to the community.</p><p>Meanwhile, we’re also continuing to work on decentralised reputation as a <a href="https://matrix.org/blog/2020/10/19/combating-abuse-in-matrix-without-backdoors/">scalable solution to empower other users to combat abuse</a> for the wider Matrix network - effectively bringing control back to users and empowering communities to remain safe online.</p><p>Element and Matrix are used by the French, German, UK and US governments, <a href="https://matrix.org/blog/2021/01/29/this-week-in-matrix-2021-01-29#dept-of-status-of-matrix-%EF%B8%8F">countless universities</a>, thousands of businesses and millions of people across the world - we can only apologise for the disruption caused by the app disappearing like this.</p><p>We’re currently waiting for an update to Google and will keep this blog post updated as the situation develops. &nbsp;We look forward to resolving the problem and getting the app back in the store shortly.</p><p>-- The Element Team</p><p>Update: reminder that in the interim you can download a (slightly outdated) version of Element Android from F-Droid at <a href="https://f-droid.org/en/packages/im.vector.app/">https://f-droid.org/en/packages/im.vector.app</a>. &nbsp;We're also looking into running our own F-Droid repository going forwards so the most recent build is always available there.</p><p>UPDATE: At 2021-01-30 23:17 UTC we received a call from a VP at Google who apologised for the bad communication from Google and explained the situation, which related to some extremely abusive content which was accessible on the default matrix.org homeserver. &nbsp;Our Trust and Safety team had already identified and acted on this content to enforce the server's terms of use, and so we've explained how Element and Matrix works, established a channel for communication over any future moderation concerns, and expect the app to be restored shortly.</p><p>UPDATE: The app is restored as of 2021-01-31 00:30 UTC. &nbsp;Huge thanks to everyone for your patience and support while we sorted this out, and to the wider Element team who spent their Saturday on this. &nbsp;Thanks also to Google for being transparent and apologetic and the rapid resolution once we'd established contact.</p></div>
      
    </div>
  </div></div>]]>
            </description>
            <link>https://element.io/blog/element-on-google-play-store/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25975378</guid>
            <pubDate>Sun, 31 Jan 2021 02:59:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pristine Apple-1 on eBay for $1.5M]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25974996">thread link</a>) | @gridder
<br/>
January 30, 2021 | https://www.ebay.it/itm/174195921349 | <a href="https://web.archive.org/web/*/https://www.ebay.it/itm/174195921349">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span title="icon"></span>
									Impossibile calcolare le spese di spedizione. Inserisci un CAP valido.</p><div>
									
									<!-- Local pickup --> <!-- ebn only -->
									<p><span>Luogo in cui si trova l'oggetto:</span> Boca Raton, Florida, Stati Uniti</p>
										<!-- ShipsTo -->
										<p><span id="shipsToTab">
<p>
			Spedizione verso: Tutto il mondo</p>

	
		<p>
							Paesi in cui non si effettua la spedizione: Angola, Camerun, Isole Cayman, Polinesia francese, Libia, Mongolia, Suriname, Guyana, Panama, Mauritius, Brunei Darussalam, Ciad, Madagascar, Nuova Caledonia, Bahamas, Bermuda, Iran, Saint Kitts e Nevis, Sahara Occidentale, Bolivia, Laos, Congo, Repubblica del, Seychelles, Sudan, Guadalupa, Venezuela, Somalia, Birmania, Cuba, Repubblica di, Riunione, Yemen, Barbados, Belize, Liberia, Sierra Leone, Repubblica Centrafricana, Martinica, Dominica, Niger, Guyana francese, Saint Pierre e Miquelon, Arabia Saudita, Nicaragua, Tajikistan, Anguilla, Antigua e Barbuda, Isole Vergini britanniche, Capo Verde, Isole, Honduras, Saint Vincent e Grenadine, Isole Turks e Caicos, Botswana, Eritrea, Swaziland, Lesotho</p>
					</span></p><!-- Calculate Row -->
									<div id="medium">
	<table>
			<tbody>
				<tr>
					<td nowrap="nowrap">
						
						<p>Sono presenti 1 oggetti disponibili. Inserisci un numero inferiore o uguale a 1.</p>
						<p>Seleziona un Paese valido.</p>
					</td>
					<td>
						<div aria-live="assertive" role="alert" id="shZipCodeDiv">
							 										
							<p><label for="shZipCode" id="shZipCodeTextDiv">CAP:</label></p>
							<p>Inserisci un CAP valido.</p>
							<p>Inserisci 5 o 9 numeri per il CAP.</p>
						</div>
						
					</td>
				</tr>
			</tbody>
		</table>
	</div>
	<!-- Shipping Table -->
											<div id="shippingSection" aria-live="assertive" role="alert">
												<table role="presentation">
		<thead>
		<tr>
			<th><p>Spedizione e imballaggio</p></th>
							<th><p>in</p></th>
							<th><p>Servizio</p></th>
							<th><p>Consegna<a target="_blank" aria-label="Nota" href="#instrTextTable">*</a></p></th>
								</tr>
		</thead>
		<tbody>
			<!-- skip displaying eBayPlus service for non-members -->
									<tr>
										<td>
											<!-- Column 1 -->
												<p>
															US $1,00</p>
													</td>
										<!-- Column 2 -->
										<td>
										<!-- Column 3 -->
										<!-- TODO replace this with shipsTo from Shipping service because of each service -->
											<p>Stati Uniti</p>
												</td>
										<td>
										<!-- Column 4 -->										
											<p>
														Spedizione celere (USPS Priority Mail Padded Flat Rate Envelope<sup>Â®</sup>)
															</p>
													
														</td>
										<!-- Column 5 -->
										<td>
												<p>
				Stimata entro <b>ven. 19 feb. </b> al CAP  </p>
		</td>
											<!-- Column 6 -->
										 </tr>
									<!-- skip displaying eBayPlus service for non-members -->
									<tr>
										<td>
											<!-- Column 1 -->
												<p>Ritiro gratuito dell'oggetto in zona</p>
															</td>
										<!-- Column 2 -->
										<td>
										<!-- Column 3 -->
										<!-- TODO replace this with shipsTo from Shipping service because of each service -->
											<p>Stati Uniti</p>
												</td>
										<td>
										<!-- Column 4 -->										
											<p>
														Local Pickup</p>
													</td>
										<!-- Column 5 -->
										<td>
												
</td>
											<!-- Column 6 -->
										 </tr>
									<!-- TODO see if colspan if loops are necessary -->
								</tbody>
	</table>
<!-- Shipping Delivery Transit time Text -->
<div id="instrTextTable" tabindex="-1">
                    <p>
			 				* <a href="https://pages.ebay.it/help/buy/contextual/estimated-delivery.html" target="_blank">Le date di consegna stimate<b>- si apre in una nuova finestra o scheda</b></a> includono i tempi di imballaggio del venditore, il CAP del mittente, il CAP del destinatario e i tempi di accettazione e dipendono dal servizio di spedizione selezionato e dalla ricezione del pagamento. I tempi di consegna possono variare, specialmente durante le festivitÃ&nbsp;. </p>
					</div>
	 		</div>
										</div></div>]]>
            </description>
            <link>https://www.ebay.it/itm/174195921349</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974996</guid>
            <pubDate>Sun, 31 Jan 2021 01:53:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Currents 025: Ben Goertzel on Decentralizing Social Media]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25974871">thread link</a>) | @tartoran
<br/>
January 30, 2021 | https://www.jimruttshow.com/currents-ben-goertzel/ | <a href="https://web.archive.org/web/*/https://www.jimruttshow.com/currents-ben-goertzel/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.jimruttshow.com/currents-ben-goertzel/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974871</guid>
            <pubDate>Sun, 31 Jan 2021 01:32:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Skidl – Skidl]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25974843">thread link</a>) | @riebs
<br/>
January 30, 2021 | https://xesscorp.github.io/skidl/docs/_site/ | <a href="https://web.archive.org/web/*/https://xesscorp.github.io/skidl/docs/_site/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
            <!-- <article class="notepad-index-post post row" role="main"> -->
            <article role="main">
                <div>
                    

<p><strong>Never use a lousy schematic editor again!</strong>
SKiDL is a simple module that lets you describe electronic circuits using Python.
The resulting Python program outputs a netlist that a PCB layout tool uses to
create a finished circuit board.</p>

<h3 id="contents">Contents</h3>

<ul>
  <li><a href="#tldr">TL;DR</a>
    <ul>
      <li><a href="#contents">Contents</a></li>
    </ul>
  </li>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#installation">Installation</a></li>
  <li><a href="#basic-usage">Basic Usage</a>
    <ul>
      <li><a href="#accessing-skidl">Accessing SKiDL</a></li>
      <li><a href="#finding-parts">Finding Parts</a>
        <ul>
          <li><a href="#command-line-searching">Command-line Searching</a></li>
          <li><a href="#zyc-a-gui-search-tool">Zyc: A GUI Search Tool</a></li>
        </ul>
      </li>
      <li><a href="#instantiating-parts">Instantiating Parts</a></li>
      <li><a href="#connecting-pins">Connecting Pins</a></li>
      <li><a href="#checking-for-errors">Checking for Errors</a></li>
      <li><a href="#generating-a-netlist">Generating a Netlist</a></li>
    </ul>
  </li>
  <li><a href="#going-deeper">Going Deeper</a>
    <ul>
      <li><a href="#basic-skidl-objects-parts-pins-nets-buses">Basic SKiDL Objects: Parts, Pins, Nets, Buses</a></li>
      <li><a href="#creating-skidl-objects">Creating SKiDL Objects</a></li>
      <li><a href="#finding-skidl-objects">Finding SKiDL Objects</a></li>
      <li><a href="#copying-skidl-objects">Copying SKiDL Objects</a></li>
      <li><a href="#accessing-part-pins-and-bus-lines">Accessing Part Pins and Bus Lines</a>
        <ul>
          <li><a href="#accessing-part-pins">Accessing Part Pins</a></li>
          <li><a href="#accessing-bus-lines">Accessing Bus Lines</a></li>
        </ul>
      </li>
      <li><a href="#making-connections">Making Connections</a></li>
      <li><a href="#making-serial-parallel-and-tee-networks">Making Serial, Parallel, and Tee Networks</a></li>
      <li><a href="#aliases">Aliases</a></li>
      <li><a href="#units-within-parts">Units Within Parts</a></li>
      <li><a href="#part-fields">Part Fields</a></li>
      <li><a href="#hierarchy">Hierarchy</a>
        <ul>
          <li><a href="#subcircuits">Subcircuits</a></li>
          <li><a href="#packages">Packages</a></li>
        </ul>
      </li>
      <li><a href="#interfaces">Interfaces</a></li>
      <li><a href="#libraries">Libraries</a></li>
      <li><a href="#doodads">Doodads</a>
        <ul>
          <li><a href="#no-connects">No Connects</a></li>
          <li><a href="#net-and-pin-drive-levels">Net and Pin Drive Levels</a></li>
          <li><a href="#pin-net-bus-equivalencies">Pin, Net, Bus Equivalencies</a></li>
          <li><a href="#selectively-supressing-erc-messages">Selectively Supressing ERC Messages</a></li>
          <li><a href="#customizable-erc-using-ercassert">Customizable ERC Using <code>erc_assert()</code></a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#going-really-deep">Going Really Deep</a>
    <ul>
      <li><a href="#circuit-objects">Circuit Objects</a></li>
    </ul>
  </li>
  <li><a href="#converting-existing-designs-to-skidl">Converting Existing Designs to SKiDL</a></li>
  <li><a href="#spice-simulations">SPICE Simulations</a></li>
</ul>



<p>SKiDL is a module that allows you to compactly describe the interconnection of 
electronic circuits and components using Python.
The resulting Python program performs electrical rules checking
for common mistakes and outputs a netlist that serves as input to
a PCB layout tool.</p>

<p>First, let’s look at a “normal” design flow in <a href="https://kicad-pcb.org/">KiCad</a>:</p>

<p><img src="https://xesscorp.github.io/skidl/docs/_site/images/schematic-process-flow.png" alt="Schematic-based PCB design flow"></p>

<p>Here, you start off in a <em>schematic editor</em> (for KiCad, that’s EESCHEMA) and
draw a schematic. From that, EESCHEMA generates
a <em>netlist file</em> that lists what components are used and how their pins are interconnected.
Then you’ll use a <em>PCB layout tool</em> (like KiCad’s PCBNEW) to arrange the part footprints
and draw the wire traces that connect the pins as specified in the netlist.
Once that is done, PCBNEW outputs a set of <em>Gerber files</em> that are sent to a
<em>PCB fabricator</em> who will create a physical PCB and ship it to you.
Then you’ll post a picture of them on Twitter and promptly dump them
in a drawer for a few years because you got bored with the project.</p>

<p>In the SKiDL-based design flow, you use a <em>text editor</em> to create a <em>Python code file</em>
that employs the SKiDL library to describe interconnections of components.
This code file is executed by a <em>Python interpreter</em> and a netlist file is output.
From there, the design flow is identical to the schematic-based one
(including dumping the PCBs in a drawer).</p>

<p><img src="https://xesscorp.github.io/skidl/docs/_site/images/skidl-process-flow.png" alt="Schematic-based PCB design flow"></p>

<p>So, why would you <em>want</em> to use SKiDL?
Here are some of the features SKiDL brings to electronic design:</p>

<ul>
  <li>Requires only a text editor and Python.</li>
  <li>Has a powerful, flexible syntax (because it <em>is</em> Python).</li>
  <li>Permits compact descriptions of electronic circuits (think about <em>not</em> tracing
signals through a multi-page schematic).</li>
  <li>Allows textual descriptions of electronic circuits (think about using 
<code>diff</code> and <a href="https://en.wikipedia.org/wiki/Git">git</a> for circuits).</li>
  <li>Performs electrical rules checking (ERC) for common mistakes (e.g., unconnected device I/O pins).</li>
  <li>Supports linear / hierarchical / mixed descriptions of electronic designs.</li>
  <li>Fosters design reuse (think about using <a href="https://xesscorp.github.io/skidl/docs/_site/pypi.org">PyPi</a> and <a href="https://xesscorp.github.io/skidl/docs/_site/github.com">Github</a>
to distribute electronic designs).</li>
  <li>Makes possible the creation of <em>smart circuit modules</em> whose behavior / structure are changed parametrically
(think about filters whose component values are automatically adjusted based on your
desired cutoff frequency).</li>
  <li>Can work with any ECAD tool (only two methods are needed: one for reading the part libraries and another
for outputing the correct netlist format).</li>
  <li>Takes advantage of all the benefits of the Python ecosystem (because it <em>is</em> Python).</li>
  <li>Free software: MIT license.</li>
  <li>Open source: <a href="https://github.com/xesscorp/skidl">https://github.com/xesscorp/skidl</a></li>
</ul>

<p>As a very simple example, the SKiDL program below describes a circuit that
takes an input voltage, divides it by three, and outputs it:</p>

<div><div><pre><code><span>from</span> <span>skidl</span> <span>import</span> <span>*</span>

<span># Create input &amp; output voltages and ground reference.
</span><span>vin</span><span>,</span> <span>vout</span><span>,</span> <span>gnd</span> <span>=</span> <span>Net</span><span>(</span><span>'VI'</span><span>),</span> <span>Net</span><span>(</span><span>'VO'</span><span>),</span> <span>Net</span><span>(</span><span>'GND'</span><span>)</span>

<span># Create two resistors.
</span><span>r1</span><span>,</span> <span>r2</span> <span>=</span> <span>2</span> <span>*</span> <span>Part</span><span>(</span><span>"Device"</span><span>,</span> <span>'R'</span><span>,</span> <span>TEMPLATE</span><span>,</span> <span>footprint</span><span>=</span><span>'Resistor_SMD.pretty:R_0805_2012Metric'</span><span>)</span>
<span>r1</span><span>.</span><span>value</span> <span>=</span> <span>'1K'</span>   <span># Set upper resistor value.
</span><span>r2</span><span>.</span><span>value</span> <span>=</span> <span>'500'</span>  <span># Set lower resistor value.
</span>
<span># Connect the nets and resistors.
</span><span>vin</span> <span>+=</span> <span>r1</span><span>[</span><span>1</span><span>]</span>      <span># Connect the input to the upper resistor.
</span><span>gnd</span> <span>+=</span> <span>r2</span><span>[</span><span>2</span><span>]</span>      <span># Connect the lower resistor to ground.
</span><span>vout</span> <span>+=</span> <span>r1</span><span>[</span><span>2</span><span>],</span> <span>r2</span><span>[</span><span>1</span><span>]</span> <span># Output comes from the connection of the two resistors.
</span>
<span># Or you could do it with a single line of code:
# vin &amp;&amp; r1 &amp;&amp; vout &amp;&amp; r2 &amp;&amp; gnd
</span>
<span># Output the netlist to a file.
</span><span>generate_netlist</span><span>()</span>
</code></pre></div></div>

<p>And this is the netlist output that is passed to <code>PCBNEW</code> to
do the PCB layout:</p>

<div><div><pre><code>(export (version D)                                                                                    
  (design                                                                                              
    (source "C:\xesscorp\KiCad\tools\skidl\tests\vdiv.py")                                             
    (date "09/14/2018 08:49 PM")                                                                       
    (tool "SKiDL (0.0.23)"))                                                                           
  (components                                                                                          
    (comp (ref R1)                                                                                     
      (value 1K)                                                                                       
      (footprint Resistor_SMD.pretty:R_0805_2012Metric)                                                                 
      (fields                                                                                          
        (field (name description) Resistor)                                                            
        (field (name keywords) "r res resistor"))                                                      
      (libsource (lib device) (part R))                                                                
      (sheetpath (names /top/12995167876889795071) (tstamps /top/12995167876889795071)))               
    (comp (ref R2)                                                                                     
      (value 500)                                                                                      
      (footprint Resistor_SMD.pretty:R_0805_2012Metric)                                                                 
      (fields                                                                                          
        (field (name description) Resistor)                                                            
        (field (name keywords) "r res resistor"))                                                      
      (libsource (lib device) (part R))                                                                
      (sheetpath (names /top/8869138953290924483) (tstamps /top/8869138953290924483))))                
  (nets                                                                                                
    (net (code 0) (name GND)                                                                           
      (node (ref R2) (pin 2)))                                                                         
    (net (code 1) (name VI)                                                                            
      (node (ref R1) (pin 1)))                                                                         
    (net (code 2) (name VO)                                                                            
      (node (ref R1) (pin 2))                                                                          
      (node (ref R2) (pin 1))))                                                                        
)                                                                                                      
</code></pre></div></div>



<p>SKiDL is pure Python so it’s easy to install:</p>



<p>To give SKiDL some part libraries to work with,
you’ll also need to install <a href="http://kicad-pcb.org/">KiCad</a>.
Then, you’ll need to set an environment variable so SKiDL can find the libraries.
For Windows, do this:</p>

<div><div><pre><code>set KICAD_SYMBOL_DIR=C:\Program Files\KiCad\share\kicad\kicad-symbols
</code></pre></div></div>

<p>And for linux-type OSes, define the environment variable in your <code>.bashrc</code> like so:</p>

<div><div><pre><code>export KICAD_SYMBOL_DIR="/Library/Application Support/kicad/kicad-symbols"
</code></pre></div></div>

<p><strong>These paths are OS-dependent</strong>, so launch KiCAD and click <code>Preferences-&gt;Configure Paths</code>
to reveal the needed paths.</p>



<p>This is the minimum that you need to know to design electronic circuitry
using SKiDL:</p>

<ul>
  <li>How to get access to SKiDL.</li>
  <li>How to find and instantiate a component (or <em>part</em>).</li>
  <li>How to connect <em>pins</em> of the parts to each other using <em>nets</em>.</li>
  <li>How to run an ERC on the circuit.</li>
  <li>How to generate a <em>netlist</em> for the circuit that serves as input to a PCB layout tool.</li>
</ul>

<p>I’ll demonstrate these steps using SKiDL in an interactive Python session,
but normally the statements that are shown would be entered into a file and
executed as a Python script.</p>

<h2 id="accessing-skidl">Accessing SKiDL</h2>

<p>To use skidl in a project, just place the following at the top of your file:</p>



<p>But for this tutorial, I’ll just import everything:</p>



<h2 id="finding-parts">Finding Parts</h2>

<h3 id="command-line-searching">Command-line Searching</h3>

<p>SKiDL provides a convenience function for searching for parts called
(naturally) <code>search</code>.
For example, if you needed an operational amplifier, then the following command would
pull up some likely candidates:</p>

<div><div><pre><code><span>&gt;</span><span>&gt;&gt;</span> search<span>(</span><span>'opamp'</span><span>)</span>
<span>linear.lib: LT1492
linear.lib: MCP601SN (2.7V to 6.0V Single Supply CMOS Operational Amplifier, SO-8)
linear.lib: LM321 (Low Power Single Operational Amplifier)
linear.lib: MCP601R (2.7V to 6.0V Single Supply CMOS Operational Amplifier, SOT-23-5)
linear.lib: LM555N (Dual Op amp, rail-to-rail, 8MHz, MSOP8, SOIC8)
</span><span>...
</span><span>linear.lib: MCP603ST (2.7V to 6.0V Single Supply CMOS Operational Amplifier, with Chip Select, TSSOP-8)
linear.lib: NE5534 (Low-Noise High-Speed Audio Operational Amplifier)
linear.lib: LT1493
linear.lib: MCP601P (2.7V to 6.0V Single Supply CMOS Operational …</span></code></pre></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://xesscorp.github.io/skidl/docs/_site/">https://xesscorp.github.io/skidl/docs/_site/</a></em></p>]]>
            </description>
            <link>https://xesscorp.github.io/skidl/docs/_site/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974843</guid>
            <pubDate>Sun, 31 Jan 2021 01:28:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Rwx Theory of Programming Languages]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25974673">thread link</a>) | @harporoeder
<br/>
January 30, 2021 | https://blog.yossarian.net/2016/02/13/An-rwx-Theory-of-Programming-Languages | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2016/02/13/An-rwx-Theory-of-Programming-Languages">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Feb 13, 2016</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>
    
  
  </p>


<p>A great deal of effort has been expended on figuring out what makes a
programming language “good” (or, more accurately, <em>popular</em>).</p>

<p>What I’m about to propose is really just conjecture, but I think the conclusions
drawable from it are amusingly accurate.</p>

<h2 id="the-theory">The Theory</h2>

<p><em>The popularity of a given programming language can be described accurately
as if the language were a file on a Unix filesystem, with <strong>read</strong>, <strong>write</strong>,
and <strong>execute</strong> bits. A language with all three “bits” set is more likely to
be popular than a language with two or less.</em></p>

<p>That alone is fairly meaningless, so I’ll detail exactly what is meant by
“readability”, “writability”, and “executability”.</p>

<h2 id="readability">Readability</h2>

<p>What does it mean for a programming language to be readable? That’s an
inflammatory question.</p>

<p>At the risk of being overly simplistic and broad, I’ll say that a language’s
readability is largely a function of 3 characteristics:</p>

<h3 id="similarity-to-other-popular-languages-or-overall-styles">Similarity to other popular languages, or overall styles.</h3>

<p>To a certain extent, this characteristic can be simplified to a single question:</p>

<p><em>“How similar is it to C?”</em></p>

<p>For the last 50 years, the vast majority of programming has been done
in procedural fashion, in languages with syntaxes directly derived from
or heavily inspired by ALGOL and C. Even languages that aren’t directly
procedural (read: anything remotely object-oriented) regularly borrow
constructions from their ALGOL-derived cousins.</p>

<p>This doesn’t mean that ALGOL-like syntaxes are objectively <em>good</em>, just that
their universal familiarity has a tangible effect on how we approach <em>new</em>
languages.</p>

<p>For example, how do you feel about these function calling syntaxes?</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>(1): foo(bar, baz, quux)
(2): foo bar baz quux
(3): foo bar withBaz: baz withQuux: quux
(4): [quux;baz;bar | foo]
</pre></td></tr></tbody></table></code></pre></div></div>

<p>If you’re like me, <code>(1)</code> is the most immediately understandable - it’s standard
function-with-arguments-separated-by-commas-in-parentheses-style. <code>(2)</code> might
also be fairly recognizable, if you’re used to working in a shell - it’s
utility-with-stringy-arguments-separated-by-whitespace-style. <code>(3)</code> will feel
familiar to Smalltalk programmers - the
receiver-object-taking-a-message-and-keyword-arguments-style. Finally, <code>(4)</code>
should feel relatively foreign to everybody - the argument list is reversed to
reflect the structure of the stack.</p>

<p>Without getting into which one of these styles is objectively best (I wouldn’t
be able to tell you), it’s apparent to most people that <code>(1)</code> is the most
<em>readable</em> simply by virtue of being so common. If I see <code>foo(bar, baz, quux)</code>
in a language I’ve never used before, I can be <em>relatively</em> confident that it
will behave like the other languages I’ve seen it in. The principle would be
the same, even if we lived in a world where Smalltalk or Lisp styles were
overwhelmingly popular.</p>

<h3 id="apparent-meaning">Apparent meaning.</h3>

<p>If you had (or have) never written a line of code in your life, which one of
these lines is most apparent in meaning? It’s okay if neither is apparent:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>(1): foobar[0]
(2): foobar.first
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Although <code>(1)</code> is what I learned first and is significantly more common, I find
<code>(2)</code> much more apparent. Compared to <code>(1)</code>, which requires that I know that
arrays are (usually) zero-based and accessed with <code>[]</code>, <code>(2)</code> only requires
that I recognize what I want (getting the first element of <code>foobar</code>) and
the general pattern for “doing things” from the line’s surroundings (calling a
method on an object with <code>.</code>).</p>

<p>What about this pair?</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>(1): foo = bar * baz + quux
(2): = foo + * bar baz quux
</pre></td></tr></tbody></table></code></pre></div></div>

<p><code>(2)</code> is conceptually cleaner (no memorization of
<a href="https://en.wikipedia.org/wiki/Order_of_operations">PEMDAS</a> required), but it’s
also significantly less apparent to someone who’s already gone through
basic arithmetic with infix notation.</p>

<p>These are simple examples, but I think that they demonstrate a truth in
language design that we’re often not willing to admit, namely that precedent
and apparency matter more than conceptual purity. It’s nice to think of
radically new languages the reimagine common operations in</p>

<h3 id="complexity-of-mental-representation">Complexity of mental representation.</h3>

<p>This ties closely into apparent meaning, although it’s slightly different.</p>

<p>Consider each of the following:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>for</span><span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>foobar</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++)</span> <span>{</span>
	<span>foobar</span><span>[</span><span>i</span><span>].</span><span>baz</span><span>();</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>



<p>In both examples, I call <code>baz</code> on every element in the <code>foobar</code> array.</p>

<p>However, in the first one, I have to keep track of an index variable (<code>i</code>), a
loop condition and iteration (<code>i &lt; foobar.length; i++</code>), and a new scope (<code>{}</code>).</p>

<p>In the second one, I take advantage of a little bit of magic in the form of
an <code>each</code> method and a <code>:baz</code> symbol to reduce <em>N</em> operations to a single line.
I don’t have to worry about my index variable, the correctness of my condition,
or my scope.</p>

<p>Although <code>(1)</code> is probably more immediately <em>apparent</em> and much more similar
to currently popular styles, it also requires me to maintain a mental
representation of <em>details irrelevant to what I’m actually trying to
accomplish</em>. I don’t want (or need) to know <em>how</em> each element is accessed or
that there are <code>foobar.length</code> elements, I just want to apply <code>baz</code>.</p>

<h2 id="writability">Writability</h2>

<p>A programming language’s writability is closely related to its readability.
The readability of a language refers to analyzing idiomatic programs written by
<em>everybody</em>, while the writability of a language refers to an <em>individual’s</em>
ability to <em>produce</em> idiomatic programs.</p>

<p>My thoughts on writability fall into a few already well-defined categories:</p>

<h3 id="pola">POLA</h3>

<p>POLA stands for the
<a href="https://en.wikipedia.org/wiki/Principle_of_least_astonishment">Principle of Least Astonishment</a>.</p>

<p>It’s hard to think of a language that is uniformly unastonishing (in a good
way!), but I often point to Ruby as one that <em>can</em> be unastonishing.</p>

<p>Ruby’s <a href="http://ruby-doc.org/core-2.3.0/Array.html">Array</a> class is a good
example of this. Compare the following code snippets:</p>

<h4 id="testing-an-array-for-emptiness">Testing an array for emptiness</h4>

<p>Python:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>foobar</span> <span>=</span> <span>[]</span>

<span>not</span> <span>foobar</span> <span># =&gt; True
# OR
</span><span>len</span><span>(</span><span>foobar</span><span>)</span> <span>==</span> <span>0</span> <span># =&gt; True
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>Java:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>foobar</span> <span>=</span> <span>{};</span>

<span>foobar</span><span>.</span><span>length</span> <span>==</span> <span>0</span> <span>// =&gt; true</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Ruby:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>foobar</span> <span>=</span> <span>[]</span>

<span>foobar</span><span>.</span><span>empty?</span> <span># =&gt; true</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="testing-an-array-for-element-inclusion">Testing an array for element inclusion</h4>

<p>Python:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>foobar</span> <span>=</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]</span>

<span>6</span> <span>in</span> <span>foobar</span> <span># =&gt; False
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>Java:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre><span>foobar</span> <span>=</span> <span>{</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>};</span>
<span>found</span> <span>=</span> <span>false</span><span>;</span>

<span>for</span> <span>(</span><span>i</span> <span>:</span> <span>foobar</span><span>)</span> <span>{</span>
	<span>if</span> <span>(</span><span>i</span> <span>==</span> <span>6</span><span>)</span> <span>{</span>
		<span>found</span> <span>=</span> <span>true</span><span>;</span>
		<span>break</span><span>;</span>
	<span>}</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Ruby:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>foobar</span> <span>=</span> <span>[</span><span>1</span><span>..</span><span>5</span><span>]</span>

<span>foobar</span><span>.</span><span>include?</span><span>(</span><span>6</span><span>)</span> <span># =&gt; false</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>In both examples, the Ruby solution is fairly unastonishing. Predicates are
trailed by “<code>?</code>”, and are single English words corresponding to their behavior.</p>

<p>The Python examples tend to be equally short, but not as unastonishing.
<code>not foobar</code> relies on empty arrays being considered falsey (just be careful
with tuples!). Checking the length is not particularly astonishing (aside from
<code>len()</code> being called from the global namespace), but “the size of <code>foobar</code> is
zero” is an awfully roundabout way of saying “<code>foobar</code> is empty”.</p>

<p>The first Java example is about as short and astonishing as its Python
counterpart. The second one, on the other hand, is absolutely insane. It
could be shortened by using a helper like <code>Arrays.asList(foobar).contains(6)</code>,
except that this is invalid (primitives and Java generics don’t mix) and
also completely astonishing (an <code>Arrays</code> class? <code>asList</code>?).</p>

<h3 id="timtowtdi">TIMTOWTDI</h3>

<p><a href="https://en.wikipedia.org/wiki/There's_more_than_one_way_to_do_it">There’s more than one way to do it</a>
is a longstanding Perl principle. People don’t often think of Perl when it
comes to <em>readability</em>, but I would argue that it is one of the most
<em>writable</em> languages (perhaps even
<a href="https://en.wikipedia.org/wiki/Write-only_language">write-only</a>).</p>

<p>Some examples:</p>

<h4 id="a-read-loop-that-capitalizes-input-and-spits-it-back">A read-loop that capitalizes input and spits it back</h4>

<p>In C, this would involve buffering <code>stdin</code> in a loop, converting each character
to its uppercase equivalent (don’t forget Unicode!), and printing them back out.
The process in Java would be similar.</p>

<p>In Perl:</p>



<p>a little more explicitly (and off of the command line):</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>while</span> <span>(</span><span>&lt;&gt;</span><span>)</span> <span>{</span>
	<span>print</span> <span>uc</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>even more explicit:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>while</span> <span>(</span><span>my</span> <span>$line</span> <span>=</span> <span>&lt;</span><span>STDIN</span><span>&gt;</span><span>)</span> <span>{</span>
	<span>print</span> <span>uc</span><span>(</span><span>$line</span><span>);</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>and so on:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>while</span> <span>(</span><span>my</span> <span>$line</span> <span>=</span> <span>readline</span><span>(</span><span>*STDIN</span><span>))</span> <span>{</span>
	<span>print</span> <span>uc</span><span>(</span><span>$line</span><span>));</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Although this may seem like a shortcut to terse and unreadable code, it
<em>is</em> a legitimate reason to like a language (and enjoy writing in it). Perl
provides an astounding number of primitives and shortcuts for common operations
(<a href="http://perldoc.perl.org/perlop.html">look at all of these operators!</a>), making
quick scripting painless and straightforward.</p>

<p>(By the way, the Ruby version: <code>ruby -pe '$_.upcase!'</code>).</p>

<h2 id="executability">Executability</h2>

<p>This is probably the murkiest of the three “bits”.</p>

<p>Let’s clarify it:</p>

<h3 id="ease-of-setup">Ease of setup</h3>

<p>Let’s say I found a cool program written in “Etaoin”. How am I going to run it?</p>

<p>If Etaoin is compiled and the developer was kind enough to provide a package
or installer, I’d probably just download their package and let my system take
care of the little details. The is the <strong>best case scenario</strong>.</p>

<p>But what if Etaoin is interpreted? Well, the developer <em>might</em> bundle the
interpreter into a package, but this would be a bit overkill. It would probably
be better to install Etaoin discretely, a process that involves either a package
or manual compilation, depending on Etaoin’s popularity.</p>

<p>Once I’ve got the interpreter, what about the program’s dependencies? Does
Etaoin have a package manager? Are the dependencies available through it? Are
they compatible with my release of the language? Am I going to need other
languages and tools to build them?</p>

<p>Whenever I see a new language or an interesting project written in a new
language, these are the very first questions I ask. It’s a lot harder to
justify installing a relatively simple program If it requires me to manually
build an interpreter and dependencies, solely by virtue of being written in an
uncommon language.</p>

<p>Of course, this is not a completely fair or accurate characterization. It’s a
little ridiculous to place the onus of “executability” solely upon package
maintainers.</p>

<h3 id="integration-with-the-system">Integration with the system</h3>

<p>Now that I have Etaoin all set up, it’s time to run this cool program.</p>

<p>But wait, Etaoin programs run in a virtual machine that needs to be invoked:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>$ </span>etaoin cool_program <span># runs cool_program.et</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This isolation between my system and the …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2016/02/13/An-rwx-Theory-of-Programming-Languages">https://blog.yossarian.net/2016/02/13/An-rwx-Theory-of-Programming-Languages</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2016/02/13/An-rwx-Theory-of-Programming-Languages</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974673</guid>
            <pubDate>Sun, 31 Jan 2021 01:02:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PDP-11/04 – Restoration – Finished]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25974507">thread link</a>) | @segfaultbuserr
<br/>
January 30, 2021 | http://www.datormuseum.se/computers/digital-equipment-corporation/pdp-11-04 | <a href="https://web.archive.org/web/*/http://www.datormuseum.se/computers/digital-equipment-corporation/pdp-11-04">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span face="verdana, sans-serif">Of course some nice soul has scanned the&nbsp;</span><a href="http://bitsavers.informatik.uni-stuttgart.de/pdf/dec/unibus/EK-BA11L-TM-001_Oct77.pdf">BA11L maintenance manual</a><span face="verdana, sans-serif">&nbsp;which describes in detail the inner workings of the power supply.&nbsp;<br></span></p><div><p><span face="verdana, sans-serif">The big filtering capacitors rated at 50 V 22000uf to filter the raw DC was able to charge through a 10k resistor perfectly well and the leakage was very small. The output capacitor for 5V was in worse shape. A 3900 uF / 6VDC Sprague with impressive connectors never managed to get to the nominal voltage even using a 560 ohm resistor and plenty of time. <br></span></p><p><span face="verdana, sans-serif">&nbsp;<p><a href="http://i.imgur.com/O4FWlpH.png" imageanchor="1"><img alt="Capacitor replacement" src="http://i.imgur.com/O4FWlpH.png"></a></p><br><span><img alt="Zooma in (verklig storlek: 800 x 598)" src="http://elektronikforumet.com/forum/images/spacer.gif" title="Zooma in (verklig storlek: 800 x 598)"></span><p>Nowadays there are no such capacitors as 3900 uF / 6VDC with screw connectors so I replaced it with a 6800uF / 40VDC RIFA&nbsp; </p></span></p><p><span face="verdana, sans-serif">With a new capacitor the power supply managed well to deliver 3 Amps in my dummy load which after while smelt nicely from hot pertinax<br></span></p><p><span face="verdana, sans-serif"><p><a href="http://i.imgur.com/3v9ATUo.jpg" imageanchor="1"><img alt="test" src="http://i.imgur.com/3v9ATUo.jpg"></a></p><br><span><img alt="Zooma in (verklig storlek: 1000 x 747)" src="http://elektronikforumet.com/forum/images/spacer.gif" title="Zooma in (verklig storlek: 1000 x 747)"></span><p>But does the it work if one connects the power supply to the back plane? Unfortunately it doesn't. Apparently two signals from the power supply was permanently in low state, BUS DC LO L and BUS AC LO L. These are active low signals and in its' low state the inhibits the clock generation of the main CPU.</p></span></p><p><span face="verdana, sans-serif">The schematics above describes the 5V regulator of the H777 power supply. The blue marked area is a current source circuit which is fed by incoming raw DC and which charges a 50uF capacitor which thus creates a nice ramp signal. A resistor ladder circuit and a number of comparators generate the BUS DC LO L, BUS AC LO L and an internal signal which causes the clock signal to the main PWM switch. The voltage over the capacitor never exceeded 20.4 V which was not enough to get the two of the comparators to change polarity. It seems like to much current is consumed from the current source. The capacitor was replaced, but no difference. But the current source was not only connected to the capacitor. It was also connected to the red marked area which is a crow bar circuit. If any of the main switch transistors would fail a 38 V raw DC would be the result on the output. Not very good. Therefore there is a zener diode and a couple of thyristors which fires off if the output voltage exceeded 5.6 VDC. This will also short circuit the current source, effectively stopping all activities in&nbsp; power supply. The problem seemed to be that even under normal circumstances 1.5 mA was consumed by leakage in the thyristor even though hasn't fired. Apparently all thyristors have leakages but not this much.<p><a href="http://i.imgur.com/U0GunMu.png" imageanchor="1"><img alt="Thyristor" height="389" src="http://i.imgur.com/U0GunMu.png" width="400"></a></p><p>Change of thyristor to a modern BT145 resulted in a fully functional power supply!</p><p><span>Testing the CPU</span></p><p>All cables were connected and the power was switched on. No smoke leaked anywhere which was a good sign. But the RUN lamp were just flashing briefly. Pressing INIT switch on the console only gave a short blink of the RUN lamp. Not very promising.</p><p>A check with the oscilloscope on the main clock signal of then CPU board showed that is starts up does 8 cycles, the stops for a couple micro seconds then does three more cycles, yet another stop and the three cycles and then nothing.</p><p><span><img alt="Zooma in (verklig storlek: 1200 x 961)" src="http://elektronikforumet.com/forum/images/spacer.gif" title="Zooma in (verklig storlek: 1200 x 961)"></span></p><p><a href="http://i.imgur.com/O3QASBs.png" imageanchor="1"><img alt="8 micro cycles" src="http://i.imgur.com/O3QASBs.png"></a></p><br>From the picture above one can deduce that the cycle time is closer to 250 ns rather than 260 ns&nbsp; specified in "Computer Engineering". However using a delay line in a feedback loop may not be that accurate. 4 MHz is a quite impressive speed at least in the mid seventies. </span></p><p><span face="verdana, sans-serif">Further than this is probably not possible using an oscilloscope only. For that purpose I have gotten this little USB connected tool:<br></span></p><p><span face="verdana, sans-serif">But to cover the entire machine with address and data bus one would need four of these. Luckily at this point in time I was offered to buy a HP1664A logic analyser at an affordable price!<br></span></p><div><p><span face="verdana, sans-serif"><b>Logic&nbsp;analyser&nbsp;fault tracing</b></span></p><p><span face="verdana, sans-serif">After some initial problems which was caused by mixed-up signals and also forgetting that the machine is active low I got some good traces from the analyser:<br></span></p><div><p><span face="verdana, sans-serif"><p><a href="http://i.imgur.com/SPIxi1B.png" imageanchor="1"><img alt="micro code" src="http://i.imgur.com/SPIxi1B.png"></a></p><p>The picture above shows the output of the micro address pipeline register. So it actually shows the second micro step as the first micro-step. But this is actually the correct sequence comparing to this <a href="http://vaxhaven.com/images/1/11/EK-KD11D-TM-PRE.pdf">document</a>. </p><p><a href="http://i.imgur.com/vCoTm8v.png" imageanchor="1"><img alt="Address bus and databus" src="http://i.imgur.com/vCoTm8v.png"></a></p><br>The interesting with this trace is that the CPU output addresses 24 and the 26 on the address bus. On the data bus it then receives 165020 which is the to be PC to start execution at after power fail, this is also the first address of the diagnostics program of the M9312. But looking at the address the CPU subsequently outputs on the address bus it is 167020. For some reason bit 10 has became high! Measuring more closely on a bus receiver chip, DS8641 shows that even though the input is at 3.31 V the output is a 3.78 V! This seems to be wrong!</span></p><p><span><span face="verdana, sans-serif">It is alive</span></span></p><p><span face="verdana, sans-serif"><b><br></b>This is the little evil thing:<p><a href="http://i.imgur.com/XojS9FU.png" imageanchor="1"><img alt="DS8641" height="320" src="http://i.imgur.com/XojS9FU.png" width="319"></a></p><br>Unfortunately DS8641 is not a very common IC. It is especially adapted to Digital open collector buses. I ordered some from a seller on Ebay located in China but since the delivery time is quite long I resorted to desoldered an IC from another board and replaced the faulty chip on the CPU board.<p>This time the result was much better:</p></span></p><p><span face="verdana, sans-serif"><p><a href="http://i.imgur.com/soZUSxo.png" imageanchor="1"><img alt="Waiting for TX ready" src="http://i.imgur.com/soZUSxo.png"></a></p><br>However it ends up spinning waiting for TX ready bit of the console serial port to become ready. Strange. Maybe the M7800 is faulty?</span></p><p><span face="verdana, sans-serif"><b>Another M7800</b><br></span></p><p><span face="verdana, sans-serif"><br>Another M7800 was configured a put into the back plane. A serial port was connected to the my laptop.<p><a href="http://i.imgur.com/0OiZWz0l.png" imageanchor="1"><img src="http://i.imgur.com/0OiZWz0l.png"></a></p></span></p></div><p><span face="verdana, sans-serif">Perfect! Now it passed diagnostics step 1 to 4. But pressing DL to make it boot from the (non existent) RL device causes it to halt. <br></span></p><p><span face="verdana, sans-serif">It seems that when trying to execute the memory tests it fails and then it gets a double bus fault when handling the first. This very well matches the TRAP handling of the CPU.<br></span></p><div><p><span><span face="verdana, sans-serif">Failing DIP switch!</span></span></p><p><span face="verdana, sans-serif">While investigating the memory board and checking the jumpers and switch settings I found that although I changed the DIP switches back and forth regardless of position 6 out of 8 of the switches remained open circuit. Not very promising<span>.<br></span></span></p><p><span face="verdana, sans-serif"><p><a href="http://i.imgur.com/QdUYcEjl.png" imageanchor="1"><img alt="DIP switches" src="http://i.imgur.com/QdUYcEjl.png"></a></p><p>New switch to the left and old to the right.</p><p>Finally it runs!</p><p><a href="http://i.imgur.com/CwHpbFnl.png" imageanchor="1"><img alt="Memory OK!" src="http://i.imgur.com/CwHpbFnl.png"></a></p></span></p><div><p><span face="verdana, sans-serif">It is possible Examine and Deposit in the memory!</span></p><p><span face="verdana, sans-serif"><span>PDP11GUI</span></span></p><p><span face="verdana, sans-serif"><a href="http://retrocmp.com/tools/pdp11gui">PDP11GUI</a>&nbsp;is a nice windows tool to control your PDP-11. It can be used to load files into memory, examining memory and starting the CPU to run. <p><span><img alt="Zooma in (verklig storlek: 1279 x 775)" src="http://elektronikforumet.com/forum/images/spacer.gif" title="Zooma in (verklig storlek: 1279 x 775)"></span></p><p><a href="http://i.imgur.com/4UYRAjsl.png" imageanchor="1"><img alt="PDP11GUI" src="http://i.imgur.com/4UYRAjsl.png"></a></p><br></span></p><p><span face="verdana, sans-serif" size="2">There are papertapes of&nbsp;<a href="http://iamvirtual.ca/PDP-11/Basic-11/DEC-11-AJPB-PB.ptap">BASIC</a>&nbsp;to be found on many places on the internet. But it comes in an Absolute Binary Loader format which&nbsp;<a href="http://retrocmp.com/tools/pdp11gui">PDP11GUI</a>&nbsp;currently cannot read. However writing a small C program to convert it is simple and then it can be fee into the machine, but it is not very fast to run over a 9600 bps serial line.</span></p><p><span face="verdana, sans-serif" size="2">The Absolute Loader is a small paper tape that need to be bootstrapped into memory for the machine to be able to load files in Absolute Loader format, like to BASIC interpreter above. The Absolute loader comes on a tape called&nbsp;<span>DEC-11-L2PC-PO.</span></span></p><div><p><span face="verdana, sans-serif"><b>UPDATE</b>: As of v1.38 of&nbsp;<a href="http://retrocmp.com/tools/pdp11gui">PDP11GUI</a>&nbsp;it is not necessary to convert the file before using it with&nbsp;<a href="http://retrocmp.com/tools/pdp11gui">PDP11GUI</a>&nbsp;since this conversion has been included in&nbsp;<a href="http://retrocmp.com/tools/pdp11gui">PDP11GUI</a>.<br></span></p></div><p><span face="verdana, sans-serif">Starting the PDP at 016104 gives the BASIC prompt!<br></span></p>
</div><p><span face="verdana, sans-serif">It seems that I haven't been around doing any BASIC programming for a long long time :-)</span></p>
<p><b><span face="verdana, sans-serif">Running diagnostics</span></b></p></div><p><span face="verdana, sans-serif">To really check that the CPU was working as it should there are two diagnostics to run. These are GKAA and GKAB. There are actually two ways to run them. Either you have an image of the paper tape which you load by PDP11GUI or you run the XXDP environment. I tried both ways.&nbsp;</span></p><p><span face="verdana, sans-serif">Originally these are paper tape software but unfortunately I was unable to find images of these paper tapes. But I did find a XXDP image with the GKAAA0.BIC and GKABC0.BIC on them. It turns out that these binaries in reality has exactly the same format as a paper tape. I used the <a href="http://www.dbit.com/putr/">PUTR</a>&nbsp;tool to extract them from the image. Please make sure to copy them as binary otherwise you end up like me scratching my head for hours... I then used PDP11GUI to load them into memory and starting them at address 200.&nbsp;</span></p><p><b><span face="verdana, sans-serif">Booting XXDP</span></b></p><p><span face="verdana, sans-serif">XXDP needs to be booted from some kind of mass storage. The only thing than would be quite easy to get running on the machine right now is TU58 since it is using a standard serial port to connect to the drive. The drive itself can be emulated using a PC or MAC. I downloaded&nbsp;<a href="http://www.ak6dn.com/PDP-11/TU58/tu58em/index.html">tu58em</a>&nbsp;and compiled it on my Mac. It needed just a few modifications to the serial port code to compile cleanly.</span></p><p><span face="verdana, sans-serif">Then I started the work to get a bootable TU58 image for my TU58 emulator. It is far simpler to use an emulator to all this kind of work. I used&nbsp;<a href="http://www.dbit.com/">E11</a>&nbsp;to do all this. First I tried XXDP 2.6 which I found an image for on bitsavers:</span></p><p><span face="verdana, sans-serif">Unfortunately it required more memory than my machine had so it won't be possible to run this version. Besides the GKAB diagnostics doesn't run at all on the emulated PDP-11/04 for some reason!</span></p><p><span face="verdana, sans-serif">I then spent some time to make a TU58 image for XXDP+, an earlier version of the XXDP suite.</span></p><p><span face="verdana, sans-serif">This is how I did that using E11:</span></p><p><span face="verdana, sans-serif">Running GKAAA0.BIC under XXDP+ on the real machine works fine. Most of the machine is in perfect order! Here is a link to the <a href="http://storage.datormuseum.se/u/96935524/Datormusuem/dddp2.dsk">image</a> I used.</span></p><div><p><span face="verdana, sans-serif"><p><a href="http://storage.datormuseum.se/u/96935524/Datormusuem/Screenshot%20XXDP%20boot.png" imageanchor="1"><img src="http://storage.datormuseum.se/u/96935524/Datormusuem/Screenshot%20XXDP%20boot.png"></a></p><br></span></p></div><p><span face="verdana, sans-serif">But running the GKABC0 unfortunately ends with a halt. It is impossible to find a listing for this diagnostic but the PDP-11/34 version is very similar. Looking through the <a href="http://bitsavers.informatik.uni-stuttgart.de/pdf/dec/pdp11/xxdp/diag_listings/1134/AC-8045D-MC_CFKABD0-1134-Traps-Tst_Apr77.pdf">code</a>&nbsp;gives that the section where it halts is testing the stack overflow logic in the CPU. It does this by setting the stack pointer to 400 and then enable console TX interrupts. This will cause an immediate TX interrupt to occur. This will decrement the stack pointer below 400 and immediately trigger a trap to vector 4/6. My machine on the other hand will trigger new console interrupts until the stack wraps to 177774 (where there are no memory) and then halt with a double bus fault!</span></p><p><b><span face="verdana, sans-serif">Faulty DL11-W!</span></b></p><p><span face="verdana, sans-serif">By swapping cards I found that the using a replacement DL11-W the problem vanished. It seems that the interrupt logic inside the DL11-W has broken down. The interrupt shall be cleared as soon as the CPU responds with an SSYN. This doesn't happen on the faulty board. As soon as the CPU has started serving the interrupt till interrupt again and again.</span></p><p><span face="verdana, sans-serif">This is the unibus interrupt cycle. The device asserts /BRn line and the CPU responds with a BGn when the CPU is ready to serve the interrupt. The device will then respond with the /SACK and then put the vector on to the bus and assert the /INTR signal. The CPU will respond with a …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.datormuseum.se/computers/digital-equipment-corporation/pdp-11-04">http://www.datormuseum.se/computers/digital-equipment-corporation/pdp-11-04</a></em></p>]]>
            </description>
            <link>http://www.datormuseum.se/computers/digital-equipment-corporation/pdp-11-04</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974507</guid>
            <pubDate>Sun, 31 Jan 2021 00:33:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gamestop Insider Trading Data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25974342">thread link</a>) | @jackhalford
<br/>
January 30, 2021 | http://openinsider.com/GME | <a href="https://web.archive.org/web/*/http://openinsider.com/GME">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://openinsider.com/GME</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974342</guid>
            <pubDate>Sun, 31 Jan 2021 00:05:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why are machine learning algorithms hard to tune?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25974311">thread link</a>) | @giorgiop
<br/>
January 30, 2021 | https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/ | <a href="https://web.archive.org/web/*/https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                <div>
                                    <section>
                                        <p>11 min read</p>
                                        <div><h2 id="why-are-machine-learning-algorithms-hard-to-tune">Why are machine learning algorithms hard to tune?</h2><p>In machine learning, linear combinations of losses are all over the place. In fact, they are commonly used as the standard approach, despite that they are a perilous area full of dicey pitfalls. Especially regarding how these linear combinations make your algorithm hard to tune.</p><p>Therefore, in this post we hope to lay out the following arguments:</p><ul><li>A lot of problems in machine learning should be treated as multi-objective problems, while they currently are not.</li><li>This lack of multi-objective treatment leads to difficulties in tuning the hyper-parameters for these machine learning algorithms.</li><li>It is nigh on impossible to detect when these problems are occurring, making it tricky to work around them.</li><li>There are methods to solve this which might be slightly involved, but do not require more than a few lines of code. <a href="https://engraved.ghost.io/how-we-can-make-machine-learning-algorithms-tunable">One of these methods is laid out in a follow-up blog post.</a></li></ul><p>Nothing of this article is novel. You might already be aware of everything we wanted to say. However, we have the impression that most machine learning curricula do not discuss optimisation methods very well (I know mine did not), and consequently, gradient descent is being treated as the one method to solve all problems. And the general message is that if an algorithm does not work for your problem, you need to spend more time tuning the hyper-parameters to your problem. </p><p><a href="https://engraved.ghost.io/how-we-can-make-machine-learning-algorithms-tunable">In the next blog post, a solution is introduced</a>, based on the NIPS’88 paper which introduced the Modified Differential Method of Multipliers.</p><p>So we hope that this blogpost can remove some confusion on how to handle this issue in a more foundational and principled way. And hey, maybe it can make you spend less time tuning your algorithms, and more time making research progress.</p><h2 id="linear-combinations-of-losses-are-everywhere">Linear combinations of losses are everywhere</h2><p>While there are single-objective problems, it is common for these objectives to be given additional regularisation. We have picked a selection of such optimisation objectives from across the field of machine learning field.</p><p>First off, we have the regularisers, weight decay and lasso. It is obvious that when you add these regularisations, you effectively have created a multi-objective loss for your problem. After all, what you really care about, is that both the original loss \(L_0\) and the regulariser loss are kept low. And you will tune the balance between the two using a \(\lambda\) parameter.</p><p>$$ L(\theta) = L_0(\theta) + \lambda \sum \left| \theta \right| $$</p><p>$$ L(\theta) = L_0(\theta) + \lambda \sum \theta^2 $$</p><p>As a consequence, losses found in e.g. VAE’s are effectively multi-objective, with a first objective to maximally cover the data, and a second objective to stay close to the prior distribution. In this case, occasionally KL annealing is used to introduce a tunable parameter \(\beta\) to help handle the multi-objectiveness of this loss.</p><p>$$ L(\theta) =\mathbb{E}_{q_{\phi}(z | x )} \left[ \log p_\theta ( x | z) \right] &nbsp;- \beta D_{KL} \left( q_\phi ( z | x) \| p(z) \right) $$</p><p>Also in reinforcement learning, you can see this multi-objectiveness. Not only is it common for many environments to simply sum rewards received for obtaining partial goals. The policy loss is usually also a linear combination of losses. Take as an example here the losses on the policy for PPO, SAC and MPO, entropy regularized methods with their tunable parameter <strong><em>α</em></strong>.</p><p>$$ L(\pi) = - \sum_t \mathbb{E}_{(s_t, a_t)} \left[ r(s_t, a_t) + \alpha \mathcal{H}(\cdot , s_t)\right]$$</p><p>$$ L(\pi) = - \sum_t \mathbb{E}_{(s_t, a_t)} \left[ \mathbb{E}_\pi\left(Q(s_t, a_t)\right) - \alpha D_{KL} \left( q \| \pi \right) \right]$$</p><p>Finally, the GAN-loss is of course a sum between the discriminator and the generator loss:</p><p>$$ L(\theta) = - \mathbb{E}_x \left[ \log D_\theta(x)\right] - \mathbb{E}_z \left[ \log ( 1- D_\theta(G_\theta(z))\right]$$</p><p>All of these losses have something in common, they are effectively trying to optimise for multiple objectives simultaneously, and argue that the optimum is found in balancing these often contradicting forces. In some cases, the sum is more ad hoc and a hyper-parameter is introduced to weigh the parts against each other. In some cases, there are clear theoretical foundations on why the losses are combined this way, and no hyper-parameter is used for tuning the balance between the parts. </p><blockquote>In this post, we hope to show you this approach of combining losses may sound appealing, but that this linear combination is actually precarious and treacherous. The balancing act is often more like a tightrope walk.</blockquote><p>Let us consider a simple case, where we are trying to optimise for such a linear combination of losses. We take the approach of optimising the total loss, which is a sum of losses. We optimise this with gradient descent, and we observe the following behaviour.</p><figure><img src="https://lh5.googleusercontent.com/953U2daXgDAO_97ugiYVEKnbK69gZVKUmlY9hNpCqtYlTso-XFw8WQ-dWRcBNeNtx7KNvXi1bM5mB8cfmnjXUMg4gU6fp5LvADys1WtoWIW-mqiJt1Uzu-Lw8VceNfQeLLQa9IZa" alt=""></figure><p>Our code in Jax would look something like this:</p><pre><code>def loss(θ):
  return loss_1(θ) + loss_2(θ)
loss_derivative = grad(loss)
for gradient_step in range(200):
  gradient = loss_derivative(θ)
  θ = θ - 0.02 * gradient</code></pre><p>As is usually the case, we are not immediately happy about the tradeoff between the two losses. So we introduce a scaling coefficient <strong><em>α</em></strong> on the second loss and run the following code:</p><pre><code>def loss(θ, α):
  return loss_1(θ) + α*loss_2(θ)
loss_derivative = grad(loss)
for gradient_step in range(200):
  gradient = loss_derivative(θ, α=0.5)
  θ = θ - 0.02 * gradient
</code></pre><p>The behaviour we hope to see is that when tuning this <strong><em>α</em></strong>, we can choose the trade-off between the two losses and select the point we are most happy with for our application. We effectively will go on a hyper-parameter tuning loop, manually select an <strong><em>α</em></strong>, run the optimisation process, decide we would like the second loss to be lower, tune our <strong><em>α</em></strong> up accordingly and repeat the whole optimisation process. After several iterations, we settle for the solution we found and continue writing our papers.</p><p>However, that is not what is always happening. The actual behaviour we sometimes observe for our problem looks like the one below.</p><figure><img src="https://lh6.googleusercontent.com/iZlk4MRVx7JYgLbaqIv-jH8zZGSc78Jj-aqk_YWy5e80tf_hgMMaBn41yRFR2rpRFGE8vuRGWjljGZ6Ri8XbyDhZbAQbSCX-putykGEpxgmcuPTmrQH1VHKpaKfjra3AG4u-x9K7" alt=""></figure><blockquote>It seems that no matter how we finetune our <strong><em>α</em></strong>-parameter, we cannot make a good trade-off between our two losses. </blockquote><p>We see two clusters of solutions, one where the first loss is ignored, and one where the second loss is ignored. However, both of these solutions are not useful for most applications. Most of the time, a point where the two losses were more balanced is a more preferred solution.</p><p>In fact, this diagram of the two losses over the course of training is barely ever plotted, so the dynamics illustrated in this figure often goes unobserved. We just look at the training curve plotting the total loss, and we might conclude that this hyper-parameter needs more time tuning, as it seems to be really sensitive. Alternatively, we could settle for an approach of early stopping to make the numbers in the paper work. After all, reviewers love data efficiency.</p><p>Where did it go wrong though? <strong>Why does this method sometimes work, and why does it sometimes fail to give you a tunable parameter?</strong> For that, we need to look deeper into the difference between the two figures.</p><p>Both figures are generated for the same problem, using the same losses and are optimising these losses using the same optimisation method. So none of these aspects are to blame for the difference. The thing which has changed between these problems is the model. In other words, the effect the model parameters <strong><em>θ</em></strong> have on the output of the model is different.</p><p>Therefore, let us <em>cheat</em> and visualise something which is normally not visualisable, the Pareto front for both of our optimisations. This is the set of all solutions achievable by our model, which are not dominated by any other solution. In other words, it is the set of achievable losses, where there is no point where <em>all</em> of the losses are better. No matter how you choose to trade off between the two losses, your preferred solution always lies on the Pareto front. By tuning the hyper-parameter of your loss, you usually hope to merely find a different point on that same front.</p><figure><img src="https://lh6.googleusercontent.com/6qA_NcRMUK8mWT3j3-t_bPl-oZkwg5Q9lWcOgBn9IB3qF_yQ7p1dyH6eq_DtKpTGeACMsLE-YfiIY9DH3yhF7swsmMFGMjNwI_oHdKKbNTuO0M8a_oDZQTUhKGcEuAfTpomqHX-M" alt=""></figure><figure><img src="https://lh6.googleusercontent.com/kVqsudO8-j48MEsdlaZgDgc22jMO9myzwdbTTWQ-KufWjuXqIr9gNHKrgV-fRzTb5gMgDnO-sFp1z_lS3UhX3wjwXHRowiaO7Vp04ZaYEAthw7y6wyN3zltH3o0wgB5ZbTDjRuRb" alt=""></figure><p>The difference between the two Pareto fronts is what is causing the tuning to turn out well for the first case, but to fail horribly after changing our model. It turns out that when the Pareto front is convex, we can achieve all possible trade-offs by tuning our <strong><em>α</em></strong>-parameter. However, when the Pareto front is concave, that approach does not seem to work well anymore.</p><h2 id="why-does-gradient-descent-optimisation-fail-for-concave-pareto-fronts">Why does gradient descent optimisation fail for concave Pareto fronts?</h2><p>We can illustrate why that is the case, by looking at the total loss in the third dimension, the loss which is actually optimised with gradient descent. In the following figure, we visualise the plane of total loss in relation to each of the losses. While we actually descend on this plane using the gradient with respect to the parameters, each gradient descent step we take will also necessarily go downwards on this plane. You can imagine the gradient descent optimisation process as putting a spherical pebble on that plane, letting it wobble down under gravity and wait until it comes to a halt.</p><p>The point where the optimisation process halts is the result of the optimisation process, here indicated by a star. As you can see in the following figure, no matter how you wobble down the plane, you will always end up in the optimum.</p><figure><img src="https://lh4.googleusercontent.com/U43_rJCiufKMSZ4gtci5kTQ2DRIH_r8WyvFi0aFV0wjpxXTNSFnMzR8a9DHvBc_ONbi0rEIBfXRQXUSxAcriZDGBNWVRhMQ-ifaIXdgeNf1K6cEIeXzMjYZUk94EWMH_bOBzvhOa" alt=""></figure><p>By tuning <strong><em>α</em></strong>, this space stays a plane. After all, by changing <strong><em>α</em></strong>, we are only changing the tilt of this plane. As you can see, &nbsp;in the convex case any solution on the Pareto curve can be achieved by tuning <strong><em>α</em></strong>. A little more <strong><em>α</em></strong> pulls the star to the left, a little less <strong><em>α</em></strong> pushes the star to the right. Every starting point of the optimisation process will converge on the same solution, and that is true for all values of <strong><em>α</em></strong>.</p><figure><img src="https://engraved.ghost.io/content/images/2021/01/visualising_the_convex_case.mp4.hq.gif" alt=""></figure><p>However, if we take a look at the differently modeled problem with a concave Pareto front, it becomes apparent where …</p></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/">https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/</a></em></p>]]>
            </description>
            <link>https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25974311</guid>
            <pubDate>Sun, 31 Jan 2021 00:00:49 GMT</pubDate>
        </item>
    </channel>
</rss>
